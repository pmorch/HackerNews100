<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 26 Sep 2024 18:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[DoNotPay has to pay $193K for falsely touting untested AI lawyer, FTC says (154 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/09/startup-behind-worlds-first-robot-lawyer-to-pay-193k-for-false-ads-ftc-says/</link>
            <guid>41659324</guid>
            <pubDate>Thu, 26 Sep 2024 15:13:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/09/startup-behind-worlds-first-robot-lawyer-to-pay-193k-for-false-ads-ftc-says/">https://arstechnica.com/tech-policy/2024/09/startup-behind-worlds-first-robot-lawyer-to-pay-193k-for-false-ads-ftc-says/</a>, See on <a href="https://news.ycombinator.com/item?id=41659324">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/09/GettyImages-1354189344-800x450.jpg" alt="DoNotPay has to pay $193K for falsely touting untested AI lawyer, FTC says">
      <figcaption></figcaption>  </figure>

  




<!-- cache hit 34:single/related:549d5f76a98e00c43222795cec9f2af2 --><!-- empty -->
<p>Among the first AI companies that the Federal Trade Commission has exposed as deceiving consumers is DoNotPay—which initially was advertised as "the world's first robot lawyer" with the ability to "sue anyone with the click of a button."</p>
<p>On Wednesday, the FTC <a href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes">announced</a> that it took action to stop DoNotPay from making bogus claims after learning that the AI startup conducted no testing "to determine whether its AI chatbot’s output was equal to the level of a human lawyer." DoNotPay also did not "hire or retain any attorneys" to help verify AI outputs or validate DoNotPay's legal claims.</p>
<p>DoNotPay accepted no liability. But to settle the charges that DoNotPay violated the FTC Act, the AI startup agreed to pay $193,000 if the FTC's consent agreement is confirmed following a 30-day public comment period. Additionally, DoNotPay agreed to warn "consumers who subscribed to the service between 2021 and 2023" about the "limitations of law-related features on the service," the FTC said.</p>
<p>Moving forward, DoNotPay would also be prohibited under the settlement from making baseless claims that any of its features can be substituted for any professional service.</p>                                                                        
                                                                                
<p>A DoNotPay spokesperson told Ars that the company "is pleased to have worked constructively with the FTC to settle this case and fully resolve these issues, without admitting liability."</p>
<p>"The complaint relates to the usage of a few hundred customers some years ago (out of millions of people), with services that have long been discontinued," DoNotPay's spokesperson said.</p>
<p>The FTC's settlement with DoNotPay is part of a larger agency effort to crack down on deceptive AI claims. Four other AI companies were hit with enforcement actions Wednesday, the FTC said, and FTC Chair Lina Khan confirmed that the agency's so-called "Operation AI Comply" will continue monitoring companies' attempts to "lure consumers into bogus schemes" or use AI tools to "turbocharge deception."</p>
<p>“Using AI tools to trick, mislead, or defraud people is illegal,” Khan said. “The FTC’s enforcement actions make clear that there is no AI exemption from the laws on the books. By cracking down on unfair or deceptive practices in these markets, FTC is ensuring that honest businesses and innovators can get a fair shot and consumers are being protected.”</p>
<h2>DoNotPay never tested robot lawyer</h2>
<p>DoNotPay was initially released in 2015 as a free way to contest parking tickets. Soon after, it quickly expanded its services to cover 200 areas of law—aiding with everything from breach of contract claims to restraining orders to insurance claims and divorce settlements.</p>
<p>As DoNotPay's legal services expanded, the company defended its innovative approach to replacing lawyers while acknowledging that it was likely on shaky ground. In 2018, DoNotPay CEO Joshua Browder <a href="https://www.abajournal.com/news/article/file_a_smalls_claims_suit_anywhere_in_the_country_through_an_app#google_vignette">confirmed to the ABA Journal</a> that the legal services were provided with "no lawyer oversight." But he said that he was only "a bit worried" about threats to sue DoNotPay for unlicensed practice of law. Because DoNotPay was free, he expected he could avoid some legal challenges.</p>
<p>According to the FTC <a href="https://www.ftc.gov/system/files/ftc_gov/pdf/DoNotPayInc-Complaint.pdf">complaint</a>, DoNotPay began charging subscribers $36 every two months in 2019 while making several false claims in ads to apparently drive up subscriptions.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NKRYPT Sculpture (148 pts)]]></title>
            <link>https://www.meme.net.au/nkrypt/</link>
            <guid>41658766</guid>
            <pubDate>Thu, 26 Sep 2024 14:24:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.meme.net.au/nkrypt/">https://www.meme.net.au/nkrypt/</a>, See on <a href="https://news.ycombinator.com/item?id=41658766">Hacker News</a></p>
Couldn't get https://www.meme.net.au/nkrypt/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[PostgreSQL 17 Released (356 pts)]]></title>
            <link>https://www.postgresql.org/about/news/postgresql-17-released-2936/</link>
            <guid>41657986</guid>
            <pubDate>Thu, 26 Sep 2024 13:10:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.postgresql.org/about/news/postgresql-17-released-2936/">https://www.postgresql.org/about/news/postgresql-17-released-2936/</a>, See on <a href="https://news.ycombinator.com/item?id=41657986">Hacker News</a></p>
Couldn't get https://www.postgresql.org/about/news/postgresql-17-released-2936/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Sam Altman: Long con was "child's play for me" (216 pts)]]></title>
            <link>https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/</link>
            <guid>41657001</guid>
            <pubDate>Thu, 26 Sep 2024 11:13:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/">https://old.reddit.com/r/AskReddit/comments/3cs78i/whats_the_best_long_con_you_ever_pulled/cszwpgq/</a>, See on <a href="https://news.ycombinator.com/item?id=41657001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h6><a href="http://www.reddit.com/r/askreddit/submit?selftext=true&amp;title=%5BSerious%5D"> [ SERIOUS ] </a></h6>

<h5><a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_rules">Rules</a>:</h5>

<ol>
<li><p>You must post a clear and direct question in the title. The title may contain two, short, necessary context sentences.
No text is allowed in the textbox. Your thoughts/responses to the question can go in the comments section. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_1-">more &gt;&gt;</a></p></li>
<li><p>Any post asking for advice should be generic and not specific to your situation alone. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_2-">more &gt;&gt;</a></p></li>
<li><p>AskReddit is for open-ended discussion questions. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_3-">more &gt;&gt;</a></p></li>
<li><p>Posting, or seeking, any identifying personal information, real or fake, will result in a ban without a prior warning. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_4-">more &gt;&gt;</a></p></li>
<li><p>AskReddit is not your soapbox, personal army, or advertising platform. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_5-">more &gt;&gt;</a></p></li>
<li><p>[Serious] tagged posts are off-limits to jokes or irrelevant replies. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_6-">more &gt;&gt;</a></p></li>
<li><p>Soliciting money, goods, services, or favours is not allowed. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_7-">more &gt;&gt;</a></p></li>
<li><p>Mods reserve the right to remove content or restrict users' posting privileges as necessary if it is deemed detrimental to the subreddit or to the experience of others. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_8-">more &gt;&gt;</a></p></li>
<li><p>Comment replies consisting solely of images will be removed. <a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_9-">more &gt;&gt;</a></p></li>
<li><p>Do not post harmful misinformation. <a href="https://www.reddit.com/r/AskReddit/wiki/index/#wiki_-rule_10-">more &gt;&gt;</a></p></li>
<li><p>Spam, machine-generated content, and karma farming are not permitted. <a href="https://www.reddit.com/r/AskReddit/wiki/index/#wiki_-rule_11-">more &gt;&gt;</a></p></li>
</ol>

<h5>If you think your post has disappeared, see spam or an inappropriate post, please do not hesitate to <a href="https://www.reddit.com/message/compose?to=%2Fr%2FAskReddit">contact the mods</a>, we're happy to help.</h5>

<hr>

<h4>Tags to use:</h4>

<blockquote>
<h2><a href="https://www.reddit.com/r/AskReddit/wiki/index#wiki_-rule_6-">[Serious]</a></h2>
</blockquote>

<h3>Use a <strong>[Serious]</strong> post tag to designate your post as a serious, on-topic-only thread.</h3>



<h4>Filter posts by subject:</h4>

<p><a href="http://ud.reddit.com/r/AskReddit/#ud">Mod posts</a>
<a href="https://www.reddit.com/r/AskReddit/search/?q=flair%3Aserious&amp;sort=new&amp;restrict_sr=on&amp;t=all">Serious posts</a>
<a href="http://bu.reddit.com/r/AskReddit/#bu">Megathread</a>
<a href="http://nr.reddit.com/r/AskReddit/#nr">Breaking news</a>
<a href="https://old.reddit.com/r/AskReddit">Unfilter</a></p>



<h3>Please use spoiler tags to hide spoilers. <code>&gt;!insert spoiler here!&lt;</code></h3>



<h4>Other subreddits you might like:</h4>

<table><thead>
<tr>
<th>Related</th>
<th>Subreddits</th>
</tr>
</thead><tbody>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_advice_and_relationships">Advice and Assistance</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_ask_a_______">Ask Others</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_askreddit_offshoots">AskReddit Offshoots</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_general_discussion">General Discussion</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_requests_.26amp.3B_assistance">Requests &amp; Assistance</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_what_is_this______">Help Me Identify This</a></td>
</tr>
<tr>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_reddit.2Fmeta">Reddit/Meta</a></td>
<td><a href="https://reddit.com/r/AskReddit/wiki/sidebarsubs/#wiki_find_subreddits">Find Subreddits</a></td>
</tr>
</tbody></table>



<h3>Ever read the reddiquette? <a href="https://old.reddit.com/wiki/reddiquette">Take a peek!</a></h3>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to Become For-Profit Company (783 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639</link>
            <guid>41655954</guid>
            <pubDate>Thu, 26 Sep 2024 08:34:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639">https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639</a>, See on <a href="https://news.ycombinator.com/item?id=41655954">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/openai-chief-technology-officer-resigns-7a8b4639: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Rewriting Rust (319 pts)]]></title>
            <link>https://josephg.com/blog/rewriting-rust/</link>
            <guid>41654871</guid>
            <pubDate>Thu, 26 Sep 2024 05:37:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://josephg.com/blog/rewriting-rust/">https://josephg.com/blog/rewriting-rust/</a>, See on <a href="https://news.ycombinator.com/item?id=41654871">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>The Rust programming language feels like a first generation product.</p>

<p>You know what I mean. Like the first iPhone - <a href="https://www.youtube.com/watch?v=MnrJzXM7a6o">which was amazing by the way</a>. They made an entire operating system around multitouch. A smart phone with no keyboard. And a working web browser. Within a few months, we all realised what the iPhone really wanted to be. Only, the first generation iphone wasn't quite there. It didn't have 3G internet. There was no GPS chip. And there was no app store. In the next few years, iPhones would get a lot better.</p>

<p>Rust feels a bit like that first iPhone.</p>

<p>I fell in love with Rust at the start. Algebraic types? Memory safety without compromising on performance? A modern package manager? Count me in. But now that I've been programming in rust for 4 years or so, it just feels like its never quite there.</p>

<p>And I don't know if it will ever be there. Progress on the language has slowed <em>so much</em>. When I first started using it, every release seemed to add new, great features in stable rust. Now? Crickets. The <a href="https://doc.rust-lang.org/unstable-book/the-unstable-book.html">rust "unstable book"</a> lists <em>700</em> different unstable features - which presumably are all implemented, but which have yet to be enabled in stable rust. Most of them are changes to the standard library - but seriously. Holy cow.</p>

<p>How much of this stuff will <em>ever</em> make it into the language proper? The rust RFC process is a graveyard of good ideas.</p>

<p>Features like <a href="https://doc.rust-lang.org/unstable-book/language-features/coroutines.html">Coroutines</a>. This RFC is 7 years old now. Make no mistake - coroutines are implemented in the compiler. They're just, not available for us "stable rust" peasants to use. If coroutines were a child, they would be in grade school by now. At this point, the coroutines RFC has lasted longer than World War 1 or 2.</p>

<p>I suspect rust is calcifying because its consensus process just doesn't scale. Early on, rust had a small group of contributors who just <em>decided</em> things. The monsters. Now, there are issue threads like <a href="https://github.com/rust-lang/rust/issues/93740#issuecomment-1041391284">this</a>, in which 25 smart, well meaning people spent 2 years and over 200 comments trying to figure out how to improve <code>Mutex</code>. And as far as I can tell, in the end they more or less gave up.</p>

<p>Maybe this is by design. Good languages are stable languages. It might be time to think of rust as a fully baked language - warts and all. Python 2.7 for life.</p>

<p>But that doesn't change anything for me. I want a better rust, and I feel powerless to make that happen. Where are my coroutines? Even javascript has <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/function*">coroutines</a>.</p>

<h2 id="fantasylanguage">Fantasy language</h2>

<p>Sometimes I lie awake at night fantasising about forking the compiler. I know how I'd do it. In my fork, I'd leave all the rust stuff alone and but make my own "seph" <a href="https://doc.rust-lang.org/edition-guide/editions/">edition</a> of the rust language. Then I could add all sorts of breaking features to that edition. So long as my compiler still compiles mainline rust as well, I could keep using all the wonderful crates on Cargo.</p>

<p>I think about this a lot. If I did it, here's what I'd change:</p>

<h3 id="functiontraitseffects">Function traits (effects)</h3>

<p>Rust has traits on structs. These are used in all sorts of ways. Some are markers. Some are understood by the compiler (like <code>Copy</code>). Some are user defined.</p>

<p>Rust should also define a bunch of traits for functions. In other languages, function traits are called "effects".</p>

<p>This sounds weird at first glance - but hear me out. See, there's lots of different "traits" that functions have. Things like:</p>

<ul>
<li>Does the function ever panic?</li>
<li>Does the function have a fixed stack size?</li>
<li>Does the function run to the end, or does it yield / await?</li>
<li>If the function is a coroutine, what is the type of the continuation?</li>
<li>Is the function "pure" (ie, the same input produces the same output, and it has no side effects)</li>
<li>Does the function (directly or indirectly) run unsafe code in semi-trusted libraries?</li>
<li>Is the function guaranteed to terminate?</li>
</ul>

<p>And so on.</p>

<p>A function's parameters and return type are just associated types on the function:</p>

<pre><code>fn some_iter() -&gt; impl Iterator&lt;Item = usize&gt; {  
    vec![1,2,3].into_iter()
}

fn main() {  
    // Why doesn't this work already via FnOnce?
    let x: some_iter::Output = some_iter();
}
</code></pre>

<p><a href="https://rust-lang.github.io/rfcs/2515-type_alias_impl_trait.html">TAIT</a> eat your heart out.</p>

<p>Exposing these properties is super useful. For example, the linux kernel wants to guarantee (at compile time) that some block of code will never panic. This is impossible to do in rust today. But using function traits, we could explicitly mark a function as being able - or unable - to panic:</p>

<pre><code>#[disallow(Panic)] // Syntax TBD.
fn some_fn() { ... }  
</code></pre>

<p>And if the function does anything which could panic (even recursively), the compiler would emit an error.</p>

<p>The compiler already sort of implements traits on functions, like <code>Fn</code>, <code>FnOnce</code> and <code>FnMut</code>. But for some reason they're anemic. (Why??)</p>

<p>I want something like this:</p>

<pre><code>/// Automatically implemented on all functions.
trait Function {  
  type Args,
  type Output,
  type Continuation, // Unit type () for normal functions
  // ... and so on.

  fn call_once(self, args: Self::Args) -&gt; Self::Output;
}

trait NoPanic {} // Marker trait, implemented automatically by the compiler.

/// Automatically implemented on all functions which don't recurse.
trait KnownStackSize {  
  const STACK_SIZE: usize,
}
</code></pre>

<p>Then you could write code like this:</p>

<pre><code>fn some_iter() -&gt; impl Iterator&lt;Item = usize&gt; {  
  vec![1,2,3].into_iter();
}

struct SomeWrapperStruct {  
  iter: some_iter::Output, // In 2024 this is still impossible in stable rust.
}
</code></pre>

<p>Or with coroutines:</p>

<pre><code>coroutine fn numbers() -&gt; impl Iterator&lt;Item = usize&gt; {  
  yield 1;
  yield 2;
  yield 3;
}

coroutine fn double&lt;I: Iterator&lt;Item=usize&gt;&gt;(inner: I) -&gt; impl Iterator&lt;Item = usize&gt; {  
  for x in inner {
    yield x * 2;
  }
}

struct SomeStruct {  
  // Suppose we want to store the iterator. We can name it directly:
  iterator: double&lt;numbers&gt;::Continuation,
}
</code></pre>

<p>Or, say, take a function parameter but require that the parameter itself doesn't panic:</p>

<pre><code>fn foo&lt;F&gt;(f: F)  
    where F: NoPanic + FnOnce() -&gt; String
{ ... }
</code></pre>

<p>Yoshua Wuyts has an excellent <a href="https://blog.yoshuawuyts.com/extending-rusts-effect-system/">talk &amp; blog post</a> going into way more detail about effects - why they're useful and how this could work.</p>

<h3 id="compiletimecapabilities">Compile-time Capabilities</h3>

<p>Most rust projects pull in an insane number of 3rd party crates. Most of these crates are small utility libraries - like the <a href="https://crates.io/crates/human-size"><code>human-size</code></a> crate which formats file sizes for human consumption. Great stuff! But unfortunately, all of these little crates add supply chain risk. Any of those authors could push out an update which contains malicious code - cryptolockering our computers, our servers or sneaking bad code into our binaries.</p>

<p>I think this problem is similar to the problem of memory safety. Sure - its sometimes useful to write memory-unsafe code. The rust standard library is full of it. But rust's <code>unsafe</code> keyword lets authors opt in to potentially unsafe things. We only add <code>unsafe</code> blocks when its necessary.</p>

<p>Lets do the same thing for privileged function calls - like reading and writing to and from the filesystem or the network. This is useful stuff, but its potentially dangerous. Developers should actively whitelist code that is allowed to call these functions.</p>

<p>To implement this, first we want to add marker traits to all the security-sensitive functions in the standard library (opening a file from a string, <code>exec</code>, FFI, opening network connections, most unsafe functions that interact with raw pointers, and so on). So, for example, <a href="https://doc.rust-lang.org/std/fs/fn.write.html"><code>std::fs::write(path, contents)</code></a> writes to an arbitrary path on disk with the credentials of the user. We add some <code>#[cap(fs_write)]</code> marker tag to the function itself, marking that this can only be called from code which is in some way trusted. The compiler automatically "taints" any other functions which call <code>write</code> in the entire call tree.</p>

<p>Suppose I call a function in a 3rd party crate which needs the <code>fs_write</code> capability. In order to call that function, I need to explicitly whitelist that call. (Either by adding the permission explicitly in my <code>Cargo.toml</code> or maybe with an annotation at the call site).</p>

<p>So, lets say the <code>foo</code> crate contains a function like this. The function will be marked (tainted) with the "writes to filesystem" tag:</p>

<pre><code>// In crate `foo`.

// (this function is implicitly tagged with #[cap(fs_write)])
pub fn do_stuff() {  
  std::fs::write("blah.txt", "some text").unwrap();
}
</code></pre>

<p>When I try to run that function from my code:</p>

<pre><code>fn main() {  
  foo::do_stuff();
}
</code></pre>

<p>The compiler can give me a nice rusty error, like this:</p>

<pre><code>Error: foo::do_stuff() writes to the local filesystem, but the `foo` crate has not been trusted with this capability in Cargo.toml.

Tainted by this line in do_stuff:

  std::fs::write("blah.txt", "some text").unwrap();

Add this to your Cargo.toml to fix:

foo = { version = "1.0.0", allow_capabilities: ["fs_write"] }  
</code></pre>

<p>Obviously, most uses of <code>unsafe</code> would also require explicit whitelisting.</p>

<p>Most crates I use - like <code>human-size</code> or <code>serde</code> don't need any special capabilities to work. So we don't need to worry so much about their authors "turning evil" and adding malicious code to our software. Reducing the supply chain risk from the 100 or so crates I currently transitively depend on down to just a few would be massive.</p>

<p>This is a very simple, static way that capabilities could be introduced to Rust. But it might be possible &amp; better to change privileged code to require an extra <code>Capability</code> parameter (some unit struct type). And heavily restrict how <code>Capability</code> objects can be instantiated. Eg:</p>

<pre><code>struct FsWriteCapability;

impl FsWriteCapability {  
    fn new() { Self } // Only callable from the root crate
}

// Then change std::fs::write's signature to this:
pub fn write(path: Path, contents: &amp;[u8], cap: FsWriteCapability) { ... }  
</code></pre>

<p>This requires more boilerplate, but its much more flexible. (And obviously, we'd also need to, somehow, apply a similar treatment to <code>build.rs</code> scripts and <code>unsafe</code> blocks.)</p>

<p>The result of all of this is that utility crates become "uncorruptable". Imagine if crates.io is hacked and serde is maliciously updated to include with cryptolocker code. Today, that malicious code would be run automatically on millions of developer machines, and compiled into programs everywhere. With this change, you'd just get a compiler error.</p>

<p>This is huge, and singlehandedly this one feature is probably worth the cost of forking rust. At least, to someone. (Anyone want to sponsor this work?)</p>

<h3 id="pinmoveandstructborrows">Pin, Move and Struct Borrows</h3>

<blockquote>
  <p>Feel free to skip this section if Pin &amp; the borrow checker gives you a migraine.</p>
</blockquote>

<p><code>Pin</code> in rust is a weird, complicated hack to work around a hole in the borrow checker. Its a band-aid from the land of bizzaro choices that only make sense when you need to maintain backwards compatibility at all costs.</p>

<ul>
<li>Its the reverse of the trait you actually want. It would make way more sense to have a <code>Move</code> marker trait (like <code>Copy</code>) indicating objects which <em>can</em> move.</li>
<li>But <code>Pin</code> isn't an actual trait. There's only <code>Unpin</code> (double negative now) and <code>!Unpin</code> - which is not-not-not-<code>Move</code>. For example <a href="https://doc.rust-lang.org/1.81.0/src/core/marker.rs.html#923"><code>impl !Unpin for PhantomPinned</code></a>. Is <code>!Unpin</code> the same as <code>Pin</code>? Uhhhh, ... No? Because .. reasons? I get an instant headache when I think about this stuff. Here's the <a href="https://doc.rust-lang.org/std/marker/trait.Unpin.html">documentation for Unpin</a> if you want to try your luck.</li>
<li>Pin only applies to reference types. If you read through code which uses <code>Pin</code> a lot, you'll find unnecessary <code>Box</code>-ing of values <em>everywhere</em>. For example, <a href="https://docs.rs/tokio-stream/latest/src/tokio_stream/wrappers/broadcast.rs.html#11-18">in tokio</a>, or helper libraries like <a href="https://lib.rs/crates/ouroboros">ouroboros</a>, <a href="https://docs.rs/async-trait/latest/async_trait/">async<em>trait</em></a><em> and <a href="https://docs.rs/self_cell/latest/self_cell/">self</a></em><a href="https://docs.rs/self_cell/latest/self_cell/">cell</a>.</li>
<li>The pain spreads. Any function that takes a pinned value needs the value wrapped using some horrible abomonation <a href="https://doc.rust-lang.org/std/future/trait.Future.html">like <code>Future::poll(self: Pin&lt;&amp;mut Self&gt;, ..)</code></a>. And then you need to figure out how to read the actual values out using projections, which are so complicated there are <a href="https://docs.rs/pin-project/latest/pin_project/">multiple</a> <a href="https://crates.io/crates/pin-project-lite/">crates</a> for dealing with them. The pain cannot be confined. It spreads outwards, forever, corrupting everything.</li>
</ul>

<p>I swear, it took more effort to learn pinning in rust than it took me to learn the entire Go programming language. And I'm still not convinced I'm totally across it. And I'm not alone. I've heard the <a href="https://fuchsia.dev/">Fuchsia operating system project</a> abandoned Rust for C++ in some parts because of how impossibly complex Pin makes everything.</p>

<p>Why is <code>Pin</code> needed, anyway?</p>

<p>We can write rust functions like this:</p>

<pre><code>fn main() {  
    let x = vec![1,2,3];
    let y = &amp;x;

    //drop(x); // error[E0505]: cannot move out of `x` because it is borrowed
    dbg!(y);
}
</code></pre>

<p>All variables in a rust function are actually, secretly in one of 3 different states:</p>

<ul>
<li>Normal (owned)</li>
<li>Borrowed</li>
<li>Mutably borrowed</li>
</ul>

<p>While a variable is borrowed (<code>y = &amp;x</code>), you can't move, mutate or drop the variable. In this example, <code>x</code> is put into a special "borrowed" state throughout the lifetime of <code>y</code>. Variables in the "borrowed" state are pinned, immutable, and have a bunch of other constraints. This "borrowed state" is visible to the compiler, but its completely invisible to the programmer. You can't tell that something is borrowed until you try to compile your program. (Aside: I wish Rust IDEs made this state visible while programming!)</p>

<p>But at least this program <em>works</em>.</p>

<p>Unfortunately, there's no equivalent to this for structs. Lets turn the function <code>async</code>:</p>

<pre><code>async fn foo() {  
    let x = vec![1,2,3];
    let y = &amp;x;

    some_future().await;

    dbg!(y);
}
</code></pre>

<p>When you compile this, the compiler creates a hidden struct for you, which stores the suspended state of this function. It looks something like this:</p>

<pre><code>struct FooFuture {  
  x: Vec&lt;usize&gt;,
  y: &amp;'_ Vec&lt;usize&gt;,
}

impl Future for FooFuture { ... }  
</code></pre>

<p><code>x</code> is borrowed by <code>y</code>. So it needs to be placed under all the constraints of a borrowed variable:</p>

<ul>
<li>It must not move in memory. (It needs to be Pinned)</li>
<li>It must be immutable</li>
<li>We can't take mutable references to <code>x</code> (because of the &amp; xor &amp;mut rule).</li>
<li><code>x</code> must outlive <code>y</code>.</li>
</ul>

<p>But there's no syntax for this. Rust doesn't have syntax to mark a struct field as being in a borrowed state. And we can't express the lifetime of <code>y</code>.</p>

<p>Remember: the rust compiler already generates and uses structs like this whenever you use <code>async</code> functions. The compiler just doesn't provide any way to write code like this ourselves. Lets just extend the borrow checker and fix that!</p>

<p>I don't know what the ideal syntax would be, but I'm sure we can come up with something. For example, maybe <code>y</code> gets declared as a "local borrow", written as <code>y: &amp;'Self::x Vec&lt;usize&gt;</code>. The compiler uses that annotation to figure out that <code>x</code> is borrowed. And it puts it under the same set of constraints as a borrowed variable inside a function.</p>

<p>This would also let you work with self-referential structs, like an <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">Abstract Syntax Tree (AST)</a> in a compiler:</p>

<pre><code>struct Ast {  
  source: String,
  ast_nodes: Vec&lt;&amp;'Self::source str&gt;,
}
</code></pre>

<p>This syntax could also be adapted to support partial borrows:</p>

<pre><code>impl Foo {  
  fn get_some_field&lt;'a&gt;(&amp;'a self) -&gt; &amp;'a::some_field usize {
    &amp;self.some_field
  }
}
</code></pre>

<p>This isn't a complete solution.</p>

<p>We'd also need a <code>Move</code> marker trait, to replace <code>Pin</code>. Any struct with borrowed fields can't be Moved - so it wouldn't have <code>impl Move</code>. I'd also consider a <code>Mover</code> trait, which would allow structs to intelligently move themselves in memory. Eg:</p>

<pre><code>trait Mover {  
  // Something like that.
  unsafe fn move(from: *Self, to: MaybeUninit&lt;&amp;mut Self&gt;);
}
</code></pre>

<p>We'd also need a sane, safe way to construct structs like this in the first place. I'm sure we can do better than <code>MaybeUninit</code>.</p>

<p>Miguel Young de la Sota <a href="https://www.youtube.com/watch?v=UrDhMWISR3w">gave a fantastic talk a few years ago</a> talking about <code>Move</code> in rust. But I think it would be much more "rusty" to lean on the borrow checker instead.</p>

<p>If you ask me, <code>Pin</code> is a dead end solution. Rust already has a borrow checker. Lets use it for structs.</p>

<h3 id="comptime">Comptime</h3>

<p>This is a hot opinion. I haven't spent a lot of time with zig, but at least from a distance I adore <a href="https://zig.guide/language-basics/comptime/">comptime</a>.</p>

<p>In the rust compiler we essentially implement two languages: Rust and the Rust Macro language. (Well, arguably there's 3 - because proc macros). The Rust programming language is lovely. But the rust macro languages are horrible.</p>

<p>But, if you already know rust, why not just use rust itself instead of sticking another language in there? This is the genius behind Zig's <code>comptime</code>. The compiler gets a little interpreter tacked on that can run parts of your code at compile time. Functions, parameters, if statements and loops can all be marked as compile-time code. Any non-comptime code in your block is emitted into the program itself.</p>

<p>I'm not going to explain the feature in full here. Instead, take in just how <em>gorgeous</em> this makes Zig's <a href="https://ziglang.org/documentation/master/#Case-Study-print-in-Zig">std <code>print</code> function</a>.</p>

<p>Its entirely implemented using comptime. So when you write this in zig:</p>

<pre><code>pub fn main() void {  
    print("here is a string: '{s}' here is a number: {}\n", .{ a_string, a_number });
}
</code></pre>

<p><code>print</code> takes the format string as a comptime parameter, and parses it within a <code>comptime</code> loop. Aside from a couple keywords, the function is just regular zig code - familiar to anyone who knows the language. It just gets executed within the compiler. And the result? It emits this beauty:</p>

<pre><code>pub fn print(self: *Writer, arg0: []const u8, arg1: i32) !void {  
    try self.write("here is a string: '");
    try self.printValue(arg0);
    try self.write("' here is a number: ");
    try self.printValue(arg1);
    try self.write("\n");
    try self.flush();
}
</code></pre>

<p>Read the <a href="https://ziglang.org/documentation/master/#Case-Study-print-in-Zig">full case study</a> for more details.</p>

<p>In comparison, I tried to look up how rust's <code>println!()</code> macro is implemented. But <a href="https://doc.rust-lang.org/src/std/macros.rs.html#138-145">println! calls some secret <code>format_args_nl</code> function</a>. I assume that function is hardcoded in the rust compiler itself.</p>

<p>Its not a great look when even the rust compiler authors don't want to use rust's macro language.</p>

<h3 id="weirdlittlefixes">Weird little fixes</h3>

<p>Bonus round time. Here's some other little "nits" I'd love to fix while we're at it:</p>

<ul>
<li><code>impl&lt;T: Copy&gt; for Range&lt;T&gt;</code>. If you know, you know.</li>
<li>Fix <a href="https://github.com/rust-lang/rust/issues/26925">derive with associated types</a>. <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=6fd2c813f411f6eb1abb66a473425c89">Full example here</a>.</li>
<li>Make if-let expressions support logical AND. Its so simple, so obvious, and so useful. This should work:</li>
</ul>

<pre><code>// Compile error! We can't have nice things.
if let Some(x) = some_var &amp;&amp; some_expr { }  
</code></pre>

<p>You can sort of work around this problem today as below, but its awkward to write, hard to read and the semantics are different from how normal <code>if</code> statements work because it lacks short-circuit evaluation.</p>

<pre><code>// check_foo() will run even if some_var is None.
if let (Some(x), true) = (some_var, check_foo()) { ... }  
</code></pre>

<p><a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2021&amp;gist=e4c4521e6a0ab49462c0b9d55da97480">Full example here</a>.</p>

<p>Rust's ergonomics for raw pointers are also uniquely horrible. When I work with unsafe code, my code should be as easy to read &amp; write as humanly possible. But the rust compiler seems intent on punishing me for my sins. For example, if I have a reference to a struct in rust, I can write <code>myref.x</code>. But if I have a pointer, rust insists that I write <code>(*myptr).x</code> or, worse: <code>(*(*myptr).p).y</code>. Horrible. Horrible and entirely counterproductive. Unsafe code should be clear.</p>

<p>I'd also change all the built in collection types to take an <code>Allocator</code> as a constructor argument. I personally don't like Rust's decision to use a global allocator. Explicit is better than implicit.</p>

<h2 id="closingthoughts">Closing thoughts</h2>

<p>Thats all the ideas I have. I mean, async needs some love too. But there's so much to say on the topic that async deserves a post of its own.</p>

<p>Unfortunately, most of these changes would be incompatible with existing rust. Even adding security capabilities would require a new rust edition, since it introduces a new way that crates can break semver compatibility.</p>

<p>A few years ago I would have considered writing RFCs for all of these proposals. But I like programming more than I like dying slowly in the endless pit of github RFC comments. I don't want months of work to result in yet another idea in <a href="https://doc.rust-lang.org/reference/items/associated-items.html">rust's landfill of unrealised dreams</a>.</p>

<p>Maybe I should fork the compiler and do it myself. Urgh. So many projects. If I could live a million lifetimes, I'd devote one to working on compilers.</p>
            </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Cronexpr, a Rust library to parse and iter crontab expression (127 pts)]]></title>
            <link>https://docs.rs/cronexpr/latest/cronexpr/</link>
            <guid>41654723</guid>
            <pubDate>Thu, 26 Sep 2024 05:10:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.rs/cronexpr/latest/cronexpr/">https://docs.rs/cronexpr/latest/cronexpr/</a>, See on <a href="https://news.ycombinator.com/item?id=41654723">Hacker News</a></p>
Couldn't get https://docs.rs/cronexpr/latest/cronexpr/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Git-absorb: Git commit –fixup, but automatic (369 pts)]]></title>
            <link>https://github.com/tummychow/git-absorb</link>
            <guid>41653191</guid>
            <pubDate>Thu, 26 Sep 2024 00:12:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tummychow/git-absorb">https://github.com/tummychow/git-absorb</a>, See on <a href="https://news.ycombinator.com/item?id=41653191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">git absorb</h2><a id="user-content-git-absorb" aria-label="Permalink: git absorb" href="#git-absorb"></a></p>
<p dir="auto">This is a port of Facebook's <a href="https://www.mercurial-scm.org/repo/hg/rev/5111d11b8719" rel="nofollow"><code>hg absorb</code></a>, which I first read about on <a href="https://groups.google.com/forum/#!msg/mozilla.dev.version-control/nh4fITFlEMk/ZNXgnAzxAQAJ" rel="nofollow">mozilla.dev.version-control</a>:</p>
<blockquote>
<ul dir="auto">
<li>Facebook demoed <code>hg absorb</code> which is probably the coolest workflow enhancement I've seen to version control in years. Essentially, when your working directory has uncommitted changes on top of draft changesets, you can run <code>hg absorb</code> and the uncommitted modifications are automagically folded ("absorbed") into the appropriate draft ancestor changesets. This is essentially doing <code>hg histedit</code> + "roll" actions without having to make a commit or manually make history modification rules. The command essentially looks at the lines that were modified, finds a changeset modifying those lines, and amends that changeset to include your uncommitted changes. If the changes can't be made without conflicts, they remain uncommitted. This workflow is insanely useful for things like applying review feedback. You just make file changes, run <code>hg absorb</code> and the mapping of changes to commits sorts itself out. It is magical.</li>
</ul>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Elevator Pitch</h2><a id="user-content-elevator-pitch" aria-label="Permalink: Elevator Pitch" href="#elevator-pitch"></a></p>
<p dir="auto">You have a feature branch with a few commits. Your teammate reviewed the branch and pointed out a few bugs. You have fixes for the bugs, but you don't want to shove them all into an opaque commit that says <code>fixes</code>, because you believe in atomic commits. Instead of manually finding commit SHAs for <code>git commit --fixup</code>, or running a manual interactive rebase, do this:</p>
<div data-snippet-clipboard-copy-content="git add $FILES_YOU_FIXED
git absorb --and-rebase"><pre><code>git add $FILES_YOU_FIXED
git absorb --and-rebase
</code></pre></div>
<p dir="auto"><code>git absorb</code> will automatically identify which commits are safe to modify, and which staged changes belong to each of those commits. It will then write <code>fixup!</code> commits for each of those changes.</p>
<p dir="auto">With the <code>--and-rebase</code> flag, these fixup commits will be automatically integrated into the corresponding ones. Alternatively, you can check its output manually if you don't trust it, and then fold the fixups into your feature branch with git's built-in <a href="https://git-scm.com/docs/git-rebase#Documentation/git-rebase.txt---autosquash" rel="nofollow">autosquash</a> functionality:</p>
<div data-snippet-clipboard-copy-content="git add $FILES_YOU_FIXED
git absorb
git log # check the auto-generated fixup commits
git rebase -i --autosquash master"><pre><code>git add $FILES_YOU_FIXED
git absorb
git log # check the auto-generated fixup commits
git rebase -i --autosquash master
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing</h2><a id="user-content-installing" aria-label="Permalink: Installing" href="#installing"></a></p>
<p dir="auto">The easiest way to install <code>git absorb</code> is to download an artifact from the latest <a href="https://github.com/tummychow/git-absorb/releases">tagged release</a>. Artifacts are available for Windows, MacOS, and Linux (built on Ubuntu with statically linked libgit2). If you need a commit that hasn't been released yet, check the <a href="https://github.com/tummychow/git-absorb/actions/workflows/build.yml?query=event%3Apush+branch%3Amaster">latest CI artifact</a> or file an issue.</p>
<p dir="auto">Alternatively, <code>git absorb</code> is available in the following system package managers:</p>
<a href="https://repology.org/project/git-absorb/versions" rel="nofollow">
    <img src="https://camo.githubusercontent.com/782be13a15856ff171807dc4f47a704c26e7dd85ca9250a4f191dfdd1264fa03/68747470733a2f2f7265706f6c6f67792e6f72672f62616467652f766572746963616c2d616c6c7265706f732f6769742d6162736f72622e737667" alt="Packaging status" data-canonical-src="https://repology.org/badge/vertical-allrepos/git-absorb.svg">
</a>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Repository</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Arch Linux</td>
<td><code>pacman -S git-absorb</code></td>
</tr>
<tr>
<td>Debian</td>
<td><code>apt install git-absorb</code></td>
</tr>
<tr>
<td>DPorts</td>
<td><code>pkg install git-absorb</code></td>
</tr>
<tr>
<td>Fedora</td>
<td><code>dnf install git-absorb</code></td>
</tr>
<tr>
<td>FreeBSD Ports</td>
<td><code>pkg install git-absorb</code></td>
</tr>
<tr>
<td>Homebrew and Linuxbrew</td>
<td><code>brew install git-absorb</code></td>
</tr>
<tr>
<td>MacPorts</td>
<td><code>sudo port install git-absorb</code></td>
</tr>
<tr>
<td>nixpkgs stable and unstable</td>
<td><code>nix-env -iA nixpkgs.git-absorb</code></td>
</tr>
<tr>
<td>openSUSE</td>
<td><code>zypper install git-absorb</code></td>
</tr>
<tr>
<td>Ubuntu</td>
<td><code>apt install git-absorb</code></td>
</tr>
<tr>
<td>Void Linux</td>
<td><code>xbps-install -S git-absorb</code></td>
</tr>
<tr>
<td>GNU Guix</td>
<td><code>guix install git-absorb</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling from Source</h2><a id="user-content-compiling-from-source" aria-label="Permalink: Compiling from Source" href="#compiling-from-source"></a></p>
<p dir="auto"><a href="https://crates.io/crates/git-absorb" rel="nofollow"><img src="https://camo.githubusercontent.com/f476a92ce2878451af440486bc81ef2165b4c3717400beb4b8a9b189ddfcff10/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6769742d6162736f72622e737667" alt="crates.io badge" data-canonical-src="https://img.shields.io/crates/v/git-absorb.svg"></a> <a href="https://github.com/tummychow/git-absorb/actions/workflows/build.yml"><img src="https://github.com/tummychow/git-absorb/actions/workflows/build.yml/badge.svg?branch=master&amp;event=push" alt="Build"></a></p>
<p dir="auto">You will need the following:</p>
<ul dir="auto">
<li><a href="https://github.com/rust-lang/cargo">cargo</a></li>
</ul>
<p dir="auto">Then <code>cargo install git-absorb</code>. Make sure that <code>$CARGO_HOME/bin</code> is on your <code>$PATH</code> so that git can find the command. (<code>$CARGO_HOME</code> defaults to <code>~/.cargo</code>.)</p>
<p dir="auto">Note that <code>git absorb</code> does <em>not</em> use the system libgit2. This means you do not need to have libgit2 installed to build or run it. However, this does mean you have to be able to build libgit2. (Due to <a href="https://github.com/alexcrichton/git2-rs/commit/76f4b74aef2bc2a54906ddcbf7fbe0018936a69d">recent changes</a> in the git2 crate, CMake is no longer needed to build it.)</p>
<p dir="auto">Note: <code>cargo install</code> does not currently know how to install manpages (<a href="https://github.com/rust-lang/cargo/issues/2729" data-hovercard-type="issue" data-hovercard-url="/rust-lang/cargo/issues/2729/hovercard">cargo#2729</a>), so if you use <code>cargo</code> for installation then <code>git absorb --help</code> will not work. Here is a manual workaround, assuming your system has a <code>~/.local/share/man/man1</code> directory that <code>man --path</code> knows about:</p>
<div data-snippet-clipboard-copy-content="wget https://raw.githubusercontent.com/tummychow/git-absorb/master/Documentation/git-absorb.1
mv git-absorb.1 ~/.local/share/man/man1"><pre><code>wget https://raw.githubusercontent.com/tummychow/git-absorb/master/Documentation/git-absorb.1
mv git-absorb.1 ~/.local/share/man/man1
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li><code>git add</code> any changes that you want to absorb. By design, <code>git absorb</code> will only consider content in the git index (staging area).</li>
<li><code>git absorb</code>. This will create a sequence of commits on <code>HEAD</code>. Each commit will have a <code>fixup!</code> message indicating the message (if unique) or SHA of the commit it should be squashed into.</li>
<li>If you are satisfied with the output, <code>git rebase -i --autosquash</code> to squash the <code>fixup!</code> commits into their predecessors. You can set the <a href="https://stackoverflow.com/a/29094904" rel="nofollow"><code>GIT_SEQUENCE_EDITOR</code></a> environment variable if you don't need to edit the rebase TODO file.</li>
<li>If you are not satisfied (or if something bad happened), <code>git reset --soft</code> to the pre-absorption commit to recover your old state. (You can find the commit in question with <code>git reflog</code>.) And if you think <code>git absorb</code> is at fault, please <a href="https://github.com/tummychow/git-absorb/issues/new">file an issue</a>.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works (roughly)</h2><a id="user-content-how-it-works-roughly" aria-label="Permalink: How it works (roughly)" href="#how-it-works-roughly"></a></p>
<p dir="auto"><code>git absorb</code> works by checking if two patches P1 and P2 <em>commute</em>, that is, if applying P1 before P2 gives the same result as applying P2 before P1.</p>
<p dir="auto"><code>git absorb</code> considers a range of commits ending at HEAD. The first commit can be specified explicitly with <code>--base &lt;ref&gt;</code>. By default the last 10 commits will be considered (see <a href="#configuration">Configuration</a> below for how to change this).</p>
<p dir="auto">For each hunk in the index, <code>git absorb</code> will check if that hunk commutes with the last commit, then the one before that, etc. When it finds a commit that does not commute with the hunk, it infers that this is the right parent commit for this change, and the hunk is turned into a fixup commit. If the hunk commutes with all commits in the range, it means we have not found a suitable parent commit for this change; a warning is displayed, and this hunk remains uncommitted in the index.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Stack size</h3><a id="user-content-stack-size" aria-label="Permalink: Stack size" href="#stack-size"></a></p>
<p dir="auto">When run without <code>--base</code>, git-absorb will only search for candidate commits to fixup within a certain range (by default 10). If you get an error like this:</p>
<div data-snippet-clipboard-copy-content="WARN stack limit reached, limit: 10"><pre><code>WARN stack limit reached, limit: 10
</code></pre></div>
<p dir="auto">edit your local or global <code>.gitconfig</code> and add the following section</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    maxStack=50 # Or any other reasonable value for your project"><pre><span>[absorb]</span>
    <span>maxStack</span>=50 <span><span>#</span> Or any other reasonable value for your project</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">One fixup per fixable commit</h3><a id="user-content-one-fixup-per-fixable-commit" aria-label="Permalink: One fixup per fixable commit" href="#one-fixup-per-fixable-commit"></a></p>
<p dir="auto">By default, git-absorb will generate separate fixup commits for every absorbable hunk. Instead, can use the <code>-F</code> flag to create only 1 fixup commit for all hunks that absorb into the same commit.
To always have this behavior, set</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    oneFixupPerCommit = true"><pre><span>[absorb]</span>
    <span>oneFixupPerCommit</span> = true</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Auto-stage all changes if nothing staged</h3><a id="user-content-auto-stage-all-changes-if-nothing-staged" aria-label="Permalink: Auto-stage all changes if nothing staged" href="#auto-stage-all-changes-if-nothing-staged"></a></p>
<p dir="auto">By default, git-absorb will only consider files that you've staged to the index via <code>git add</code>. However, sometimes one wants to try and absorb from all changes, which would require to stage them first via <code>git add .</code>. To avoid this extra step, set</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    autoStageIfNothingStaged = true"><pre><span>[absorb]</span>
    <span>autoStageIfNothingStaged</span> = true</pre></div>
<p dir="auto">which tells git-absorb, when no changes are staged, to auto-stage them all, create fixup commits where possible, and unstage remaining changes from the index.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Fixup target always SHA</h3><a id="user-content-fixup-target-always-sha" aria-label="Permalink: Fixup target always SHA" href="#fixup-target-always-sha"></a></p>
<p dir="auto">By default, git-absorb will create fixup commits with their messages pointing to the target commit's summary, and if there are duplicate summaries, will fallback to pointing to the target's SHA. Instead, can always point to the target's SHA via:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[absorb]
    fixupTargetAlwaysSHA = true"><pre><span>[absorb]</span>
    <span>fixupTargetAlwaysSHA</span> = true</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">TODO</h2><a id="user-content-todo" aria-label="Permalink: TODO" href="#todo"></a></p>
<ul dir="auto">
<li>implement force flag</li>
<li>implement remote default branch check</li>
<li>add smaller force flags to disable individual safety checks</li>
<li>stop using <code>failure::err_msg</code> and ensure all error output is actionable by the user</li>
<li>slightly more log output in the success case</li>
<li>more tests (esp main module and integration tests)</li>
<li>document stack and commute details</li>
<li>more commutation cases (esp copy/rename detection)</li>
<li>don't load all hunks in memory simultaneously because they could be huge</li>
<li>implement some kind of index locking to protect against concurrent modifications</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WP Engine is banned from WordPress.org (148 pts)]]></title>
            <link>https://wordpress.org/news/2024/09/wp-engine-banned/</link>
            <guid>41652760</guid>
            <pubDate>Wed, 25 Sep 2024 22:59:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/news/2024/09/wp-engine-banned/">https://wordpress.org/news/2024/09/wp-engine-banned/</a>, See on <a href="https://news.ycombinator.com/item?id=41652760">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Any WP Engine customers having trouble with their sites should <a href="https://wpengine.com/contact/">contact WP Engine support and ask them to fix it</a>.</p>



<p>I won’t bore you with the story of how WP Engine <a href="https://x.com/photomatt/status/1838502185879167069">broke thousands of customer sites yesterday in their haphazard attempt to block our attempts to inform the wider WordPress community</a> regarding their disabling and locking down a WordPress core feature in order to extract profit.</p>



<p><strong>What I will tell you is that, pending their legal claims and litigation against WordPress.org, WP Engine no longer has free access to WordPress.org’s resources.</strong></p>



<p>WP Engine wants to control your WordPress experience, they need to run their own user login system, update servers, plugin directory, theme directory, pattern directory, block directory, translations, photo directory, job board, meetups, conferences, bug tracker, forums, Slack, Ping-o-matic, and showcase. Their servers can no longer access our servers for free.</p>



<p>The reason WordPress sites don’t get hacked as much anymore is we work with hosts to block vulnerabilities at the network layer, WP Engine will need to replicate that security research on their own.</p>



<p>Why should WordPress.org provide these services to WP Engine for free, given their attacks on us?</p>



<p>WP Engine is free to offer their hacked up, bastardized simulacra of WordPress’s GPL code to their customers, and they can experience WordPress as WP Engine envisions it, with them getting all of the profits and providing all of the services.</p>



<p>If you want to experience WordPress, use any other host in the world besides WP Engine. <a href="https://wordpress.org/news/2024/09/wp-engine/">WP Engine is not WordPress</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI to remove non-profit control and give Sam Altman equity (381 pts)]]></title>
            <link>https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/</link>
            <guid>41651548</guid>
            <pubDate>Wed, 25 Sep 2024 20:31:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/">https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/</a>, See on <a href="https://news.ycombinator.com/item?id=41651548">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/artificial-intelligence/openai-remove-non-profit-control-give-sam-altman-equity-sources-say-2024-09-25/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Mira Exits OpenAI (760 pts)]]></title>
            <link>https://twitter.com/miramurati/status/1839025700009030027</link>
            <guid>41651038</guid>
            <pubDate>Wed, 25 Sep 2024 19:35:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/miramurati/status/1839025700009030027">https://twitter.com/miramurati/status/1839025700009030027</a>, See on <a href="https://news.ycombinator.com/item?id=41651038">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Httpdbg – A tool to trace the HTTP requests sent by your Python code (182 pts)]]></title>
            <link>https://github.com/cle-b/httpdbg</link>
            <guid>41650905</guid>
            <pubDate>Wed, 25 Sep 2024 19:18:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cle-b/httpdbg">https://github.com/cle-b/httpdbg</a>, See on <a href="https://news.ycombinator.com/item?id=41650905">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">httpdbg</h2><a id="user-content-httpdbg" aria-label="Permalink: httpdbg" href="#httpdbg"></a></p>
<p dir="auto"><code>httpdbg</code> is a tool for Python developers to easily debug the HTTP(S) client requests in a Python program.</p>
<p dir="auto">To use it, execute your program using the <code>pyhttpdbg</code> command instead of <code>python</code> and that's it. Open a browser to <code>http://localhost:4909</code> to view the requests:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/cle-b/httpdbg/blob/main/ui.png?raw=true"><img src="https://github.com/cle-b/httpdbg/raw/main/ui.png?raw=true" alt=""></a></p>
<p dir="auto">Full documentation =&gt; <a href="https://httpdbg.readthedocs.io/en/latest/" rel="nofollow">https://httpdbg.readthedocs.io/</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">installation</h2><a id="user-content-installation" aria-label="Permalink: installation" href="#installation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">usage</h2><a id="user-content-usage" aria-label="Permalink: usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">interactive console</h3><a id="user-content-interactive-console" aria-label="Permalink: interactive console" href="#interactive-console"></a></p>
<p dir="auto">Open an interactive console using the command <code>pyhttpdbg</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(venv) dev@host:~/dir$ pyhttpdbg 
.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.
  httpdbg - HTTP(S) requests available at http://localhost:4909/
.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.
Python 3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0] on linux
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
(InteractiveConsole)
>>> "><pre><span>(venv) dev@host:~/dir</span>$ <span>pyhttpdbg </span>
<span>.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.</span>
<span>  httpdbg - HTTP(S) requests available at http://localhost:4909/</span>
<span>.... - - .--. -.. -... --. .... - - .--. -.. -... --. .... - - .--. -.. -... --.</span>
<span>Python 3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0] on linux</span>
<span>Type "help", "copyright", "credits" or "license" for more information.</span>
<span>(InteractiveConsole)</span>
<span>&gt;&gt;&gt; </span></pre></div>
<p dir="auto">Perform HTTP requests.</p>
<p dir="auto">You can inspect the HTTP requests directly in your web browser at <a href="http://localhost:4909/" rel="nofollow">http://localhost:4909</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">script</h3><a id="user-content-script" aria-label="Permalink: script" href="#script"></a></p>
<p dir="auto">You can trace all the HTTP requests performed by a script</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg --script filename.py [arg1 --arg2 ...]"><pre><span>pyhttpdbg --script filename.py [arg1 --arg2 ...]</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">pytest</h3><a id="user-content-pytest" aria-label="Permalink: pytest" href="#pytest"></a></p>
<p dir="auto">You can trace all the HTTP requests performed during your tests</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -m pytest [arg1 --arg2 ...]"><pre><span>pyhttpdbg -m pytest [arg1 --arg2 ...]</span></pre></div>
<p dir="auto">If you use the <code>pytest-xdist</code> plugin to execute your tests in parallel, then you must install the <code>pytest-httpdbg</code> plugin if you want to trace the requests done by the pytest workers.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install httpdbg[pytest]"><pre><span>pip install httpdbg[pytest]</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">module</h3><a id="user-content-module" aria-label="Permalink: module" href="#module"></a></p>
<p dir="auto">You can trace all the HTTP requests performed by a library module run as a script using the <code>-m</code> command line argument.</p>
<p dir="auto">For example, you can view which HTTP requests are performed by <code>pip</code> when you install a package.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -m pip install hookdns --upgrade"><pre><span>pyhttpdbg -m pip install hookdns --upgrade</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Initiators</h2><a id="user-content-initiators" aria-label="Permalink: Initiators" href="#initiators"></a></p>
<p dir="auto">An initiator is the function/method that is at the origin of the HTTP requests. By default, we already support some packages but you can add your own initiators.</p>
<p dir="auto">To add a new package in the list of initiators, you can use the <code>-i</code> command line argument:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pyhttpdbg -i api_client_pck --script my_script.py"><pre><span>pyhttpdbg -i api_client_pck --script my_script.py</span></pre></div>
<p dir="auto">You can use any package as an initiator, this is not limited to HTTP requests.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Already supported packages</h3><a id="user-content-already-supported-packages" aria-label="Permalink: Already supported packages" href="#already-supported-packages"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>packages</th>
<th>status</th>
</tr>
</thead>
<tbody>
<tr>
<td>requests</td>
<td>supported</td>
</tr>
<tr>
<td>urllib3</td>
<td>supported</td>
</tr>
<tr>
<td>httpx</td>
<td>supported</td>
</tr>
<tr>
<td>aiohttp</td>
<td>supported</td>
</tr>
<tr>
<td>pytest</td>
<td>supported</td>
</tr>
<tr>
<td><em>your_package</em></td>
<td>yes, with the arg <em>-i your_package</em></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">configuration</h2><a id="user-content-configuration" aria-label="Permalink: configuration" href="#configuration"></a></p>
<p dir="auto">No configuration is necessary to start but some few settings are available for particular use.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">command line</h3><a id="user-content-command-line" aria-label="Permalink: command line" href="#command-line"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="usage: pyhttpdbg [-h] [--port PORT] [--version] [--initiator INITIATOR] [--keep-up | --force-quit]
                 [--console | --module MODULE | --script SCRIPT]

httdbg - a very simple tool to debug HTTP(S) client requests

options:
  -h, --help            show this help message and exit
  --port PORT, -p PORT  the web interface port
  --version, -v         print the httpdbg version
  --initiator INITIATOR, -i INITIATOR
                        add a new initiator (package)
  --keep-up, -k         keep the server up even if the requests have been read
  --force-quit, -q      stop the server even if the requests have not been read
  --console             run a python console (default)
  --module MODULE, -m MODULE
                        run library module as a script (the next args are passed to pytest as is)
  --script SCRIPT       run a script (the next args are passed to the script as is)"><pre><span>usage: pyhttpdbg [-h] [--port PORT] [--version] [--initiator INITIATOR] [--keep-up | --force-quit]</span>
<span>                 [--console | --module MODULE | --script SCRIPT]</span>

<span>httdbg - a very simple tool to debug HTTP(S) client requests</span>

<span>options:</span>
<span>  -h, --help            show this help message and exit</span>
<span>  --port PORT, -p PORT  the web interface port</span>
<span>  --version, -v         print the httpdbg version</span>
<span>  --initiator INITIATOR, -i INITIATOR</span>
<span>                        add a new initiator (package)</span>
<span>  --keep-up, -k         keep the server up even if the requests have been read</span>
<span>  --force-quit, -q      stop the server even if the requests have not been read</span>
<span>  --console             run a python console (default)</span>
<span>  --module MODULE, -m MODULE</span>
<span>                        run library module as a script (the next args are passed to pytest as is)</span>
<span>  --script SCRIPT       run a script (the next args are passed to the script as is)</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">web interace</h3><a id="user-content-web-interace" aria-label="Permalink: web interace" href="#web-interace"></a></p>
<p dir="auto">Clic on the <strong>⚙</strong> button on the top right of the page.</p>
<p dir="auto">Some options are available:</p>
<ul dir="auto">
<li>Hide the netloc in the url</li>
<li>Hide the initiator rows</li>
</ul>
<p dir="auto">To keep your configuration, bookmark the page with the full search query.</p>
<p dir="auto">Fox example, if you want to hide the initiator rows by default, the url will be:</p>
<div data-snippet-clipboard-copy-content="http://localhost:4909/?hi=on"><pre><code>http://localhost:4909/?hi=on
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">web interface</h2><a id="user-content-web-interface" aria-label="Permalink: web interface" href="#web-interface"></a></p>
<p dir="auto">All the requests recorded are available on the web interface.</p>
<p dir="auto">The requests:</p>
<ul dir="auto">
<li>are still available in the web page even if the python process stopped (except if you force quit before the requests have been loaded by the web page).</li>
<li>are automatically cleaned if a new execution is detected.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">documentation</h2><a id="user-content-documentation" aria-label="Permalink: documentation" href="#documentation"></a></p>
<p dir="auto"><a href="https://httpdbg.readthedocs.io/" rel="nofollow">https://httpdbg.readthedocs.io</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Eliminating Memory Safety Vulnerabilities at the Source (291 pts)]]></title>
            <link>https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html</link>
            <guid>41650647</guid>
            <pubDate>Wed, 25 Sep 2024 18:49:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html">https://security.googleblog.com/2024/09/eliminating-memory-safety-vulnerabilities-Android.html</a>, See on <a href="https://news.ycombinator.com/item?id=41650647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to avoid a BSOD on your 2B dollar spacecraft (167 pts)]]></title>
            <link>https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/</link>
            <guid>41650534</guid>
            <pubDate>Wed, 25 Sep 2024 18:40:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/">https://clarkwakeland.com/blog/2024/avoiding-a-BSOD-on-your-satellite/</a>, See on <a href="https://news.ycombinator.com/item?id=41650534">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div id="markdown-content"> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/satellitesafemode-480.webp 480w,https://clarkwakeland.com/assets/img/satellitesafemode-800.webp 800w,https://clarkwakeland.com/assets/img/satellitesafemode-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/satellitesafemode.png" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p>Short answer: turn it off and turn it back on</p> <p>Long Answer…</p> <h3 id="background">Background</h3> <p>The lifecycle of most spacecraft consists of a final phase where all the systems are tested to various levels of synergy. One of the most important and complex set of tests are the <strong>C</strong>losed <strong>L</strong>oop <strong>T</strong>ests (<strong>CLT</strong>s), where the spacecraft is sent simulated orbital data, and then its attitude response is observed. It’s a closed loop because the attitude telemetry is fed back into the simulation while the test is occurring, effectively making the spacecraft and whatever hardware is currently being used part of the simulation. This particular test involved observing the response from control thrusters on the spacecraft when commanded to perform a slew and engine burn to a transfer orbit.</p> <p>To get the spacecraft response data back to in the loop, a set of memory addresses mapped to the sim needs to be uploaded onto the spacecraft RAM. These memory addresses were not determined while this test was being developed. Instead, a set of placeholder addresses meant for the previous spacecraft was used in the development environment.</p> <p>Ok, fair enough. When we’re developing our tests prior to them being run on the spacecraft, it’s useful to have <em>something</em> to upload, even if it’s not the final product.</p> <h2 id="the-vehicle">The Vehicle</h2> <p>The placeholder memory addresses were the <strong>actual memory addresses used for a previously developed spacecraft</strong>. As such, the name of the file containing the addresses was something like “XProp_transducer_addr_val.upx”. In all of the review meetings, this was most likely ignored because of how official it looked. All the engineers who worked on the last spacecraft assumed the naming convention was the same on this one, and those like me who were working on their first spacecraft had no other point of reference.</p> <p>The day comes and it’s finally time to run this test. Naturally, we get an unexplainable error, which is something I wish I could say we weren’t used to. The standard procedure is to stop the test and asses the vehicle state before deciding if we can redo the test or continue with other tests on different systems. We decide to run a seperate test but are still getting some strange errors, so we agree to turn the spacecraft off and back on to get it in a nominal configuration. Again, fairly standard procedure.</p> <p>Except turning the spacecraft off and on isn’t as simple as just flipping a switch or unplugging it. There are about a dozen steps that need to happen in a fairly specific order to ensure no hardware gets damaged in the process. We’re constantly checking telemetry during this teardown to see that nothing is on when a component further down the process is about to turn off.</p> <p>In our teardown script, we get an error we’ve never seen before. Some of the motors on the vehicle are not turning off. Ok, that’s weird. Let’s send the off command again, maybe there was a routing failure. Still nothing, but the commands are showing as “received”. Hmmmm. Well, unfortunately we can’t just continue, but we’ve got a few ideas as to what’s happening.</p> <p>Some of the telemetry that’s being downlinked from the satellite is displaying as active but showing no variation. I.e., a voltage or temperature reading is actively being downlinked as the same value, down to five sig figs, with no change. Further inspection of telemetry shows errors on the connection between the onboard computer and the ERIU.</p> <p>The <strong>E</strong>nhanced <strong>R</strong>emote <strong>I</strong>nterface <strong>U</strong>nits (<strong>ERIU</strong>s) are how the computer onboard the spacecraft communicates with all the different sensors and systems that read actual orbit and mission data. Think of the ERIUs as the pony express, relaying commands from the onboard computer to the wild west frontier of the satellite sensors. The sensors in turn send their telemetry back through the ERIU to the onboard computer for processing, or anywhere else that was specified in memory, like a CLT sim.</p> <div> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/ponyExpress-480.webp 480w,https://clarkwakeland.com/assets/img/ponyExpress-800.webp 800w,https://clarkwakeland.com/assets/img/ponyExpress-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/ponyExpress.jpg" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p> They don't make ERIUs like they used to </p> </div> <p>I think you can see where this is going. The addresses we loaded at the start of the test are meant for a completely different spacecraft and simulation setup. When the ERIU tried to send telemetry back to the sim, the addresses it was given weren’t actually pointing to anything, and it bascially throws a null pointer dereference and crashes. Some bus communication quirk is causing the last valid telemetry broadcast by the ERIU to be continously sent to the onboard computer.</p> <h2 id="the-problems">The Problems</h2> <p>There are two significant problems that are immediately apparent to us:</p> <ol> <li>Because the ERIU has crashed, we have no way of commanding different subsystems off, and cannot safely enter a powered off vehicle state.</li> <li>We are no longer getting active telemetry from the vehicle, which means that if something bad were happening to any system, we would not know about it.</li> </ol> <p>Problem #1 can luckily be put off for the time being while we focus on the more time sensitive problem #2. I should clarify that the vehicle is in a very safe and stable configuration at the moment. There is almost zero chance that something significant would break while we’re in this tricky spot of not recieving valid telemetry. That being said, as an engineer, having no way of describing your state is incredibly concering. An apt comparison would be if you were the flying an airplane at cruise altitude and your altimeter, airspeed indicator, and attitude indicator suddenly stopped updating. You’re <em>probably</em> not going to have anything bad happen to you, and there’s not much reason to believe your state is rapidly changing, but I doubt any pilot would want to experience that.</p> <p>Ok, we’ve got a clear goal: reboot the ERIU. Just like waking up for a morning swim, it is much easier said than done. In fact, the only way to reboot the ERIU is to reboot the whole damn onboard computer. This of course comes with its own set of issues and risks.</p> <p>The onboard computer, as part of its normal operation, continuously restarts a watchdog timer. If the watchdog timer has not been restarted and instead times out after ~30 seconds, the satellite enters something called <strong>safemode</strong>. Safemode is when all non critical functions are automatically shut down and the satellite becomes entirely focused on generating power by pointing its solar panels towards the Sun and trying to reestablish any communication that was lost. It’s a state the vehicle goes into when something bad happens, like total loss of attitude control or some other system failure.</p> <div> <div> <figure> <picture> <source srcset="https://clarkwakeland.com/assets/img/vaderfighter-480.webp 480w,https://clarkwakeland.com/assets/img/vaderfighter-800.webp 800w,https://clarkwakeland.com/assets/img/vaderfighter-1400.webp 1400w," sizes="95vw" type="image/webp"> <img src="https://clarkwakeland.com/assets/img/vaderfighter.gif" width="100%" height="auto" title="" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <p> Vader's tie fighter entering safemode </p> </div> <p>Safemode is the satellite equivalent of a blue screen of death. An unexpected safemode occurring on the satellite during testing is something that must be communicated to the customer, even though it’s completely recoverable. Again, I wish I could say this hasn’t happened before. Long story short, the US government isn’t burning taxpayer dollars on a ten figure spaceship just to have us push a Crowdstrike update on it. They would be pretty upset, to put it lightly.</p> <p>Alright. Let’s not focus on the worst outcome. We can disable the watchdog timer, turn off some other telemetry, finally power cycle the onboard computer, and then turn everything else back on. Oh, and we need to do the exact same thing at the same time on the redundant computer as well. And there are a couple dozen commands in this manually created sequence, and getting one of them wrong could send the satellite to safemode. We got this. Did I mention that all of this is happening at midnight on a Saturday?</p> <p>After confirming our commands with a very tired flight software lead, we send the sequence, and it works! The onboard computer is back on, the ERIU is back on, and we’re getting what looks like reasonable telemetry from the other systems. We continue with the power off sequence and sure enough everything is powering down as expected. After ~12 hours of troubleshooting and communicating with other system engineers, we finally power down the vehicle safely at 1:45am.</p> <h2 id="retrospective">Retrospective</h2> <p>I hope I managed to explain the relevant systems in enough detail and not use too many acronyms, and at least explain the ones I did use. Working on space systems has exposed me to a seemingly infinite amount of different acronyms, some of which are the same but have different meanings. There was also a lot I glossed over, with the main time sink being the proper identification of the issue. There were many red herrings that were chased before we correctly determined that it was an ERIU crash. This would have ended much worse without the support of the amazing systems engineers who answered our calls in the middle of the night on a Saturday.</p> <p>I think what surprised me the most was how nonchalant the response was. We had documented all of our actions, so other people had read what happened and knew something had gone on. I wasn’t expecting any fanfare but we weren’t even debriefed on what happened. I guess this is the event that really got the point across to me about how if you do your job right, it’ll be like nothing ever happened. But I’ll take that over a BSOD on a multi billion dollar satellite any day.</p> </div> </article></div>]]></description>
        </item>
    </channel>
</rss>