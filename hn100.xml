<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 22 Sep 2024 04:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[WP Engine is not WordPress (114 pts)]]></title>
            <link>https://wordpress.org/news/2024/09/wp-engine/</link>
            <guid>41613628</guid>
            <pubDate>Sun, 22 Sep 2024 00:16:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/news/2024/09/wp-engine/">https://wordpress.org/news/2024/09/wp-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=41613628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
	
	
	

	
	<hr>
	

	
	<div>
<p>It has to be said and repeated: <em>WP Engine is not WordPress</em>. My own mother was confused and thought <a href="https://wpengine.com/">WP Engine</a> was an official thing. Their branding, marketing, advertising, and entire promise to customers is that they’re giving you WordPress, but they’re not. And they’re profiting off of the confusion.</p>



<p><a href="https://www.youtube.com/watch?v=fnI-QcVSwMU">I spoke yesterday at WordCamp</a> about how <a href="https://www.silverlake.com/people/lee-wittlinger/">Lee Wittlinger</a> at <a href="https://www.silverlake.com/">Silver Lake</a>, a private equity firm with $102B assets under management, can hollow out an open source community. Today, I would like to offer a specific, technical example of how they break the trust and sanctity of our software’s promise to users to save themselves money so they can extract more profits from you.</p>



<p>WordPress is a content management system, and the content is <em>sacred</em>. Every change you make to every page, every post, is tracked in a revision system, just like the Wikipedia. This means if you make a mistake, you can <em>always</em> undo it. It also means if you’re trying to figure out why something is on a page, you can see precisely the history and edits that led to it. These revisions are stored in our database.</p>



<p>This is very important, it’s at the core of the user promise of protecting your data, and it’s why WordPress is architected and designed to never lose anything.</p>



<p><strong>WP Engine turns this off.</strong> They disable revisions because it costs them more money to store the history of the changes in the database, and they don’t want to spend that to protect your content. It strikes to the very heart of what WordPress does, and they shatter it, the integrity of your content. If you make a mistake, you have no way to get your content back, breaking the core promise of what WordPress does, which is manage and protect your content.</p>



<p>Here is a screenshot of <a href="https://wpengine.com/support/platform-settings/#Post_Revisions">their support page</a> saying they disable this across their 1.5 million WordPress installs.</p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="864" src="https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03%E2%80%AFPM.png?resize=1024%2C864&amp;ssl=1" alt="" srcset="https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=1024%2C864&amp;ssl=1 1024w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=300%2C253&amp;ssl=1 300w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=768%2C648&amp;ssl=1 768w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?w=1472&amp;ssl=1 1472w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p>They say it’s slowing down your site, but what they mean is they want to avoid paying to store that data. We tested revisions on <em>all</em> of the recommended hosts on WordPress.org, and <em>none</em> disabled revisions by default. <strong>Why is WP Engine the only one that does?</strong> They are strip-mining the WordPress ecosystem, giving our users a crappier experience so they can make more money.</p>



<p><strong>What WP Engine gives you is not WordPress</strong>, it’s something that they’ve chopped up, hacked, butchered to look like WordPress, but actually they’re giving you a cheap knock-off and charging you more for it.</p>



<p>This is one of the many reasons they are a cancer to WordPress, and it’s important to remember that unchecked, cancer will spread. WP Engine is setting a poor standard that others may look at and think is ok to replicate. We must set a higher standard to ensure WordPress is here for the next 100 years.</p>



<p>If you are a customer of “WordPress Engine,” you should <a href="https://wpengine.com/contact/">contact their support</a> immediately to at least get the 3 revisions they allow turned on so you don’t accidentally lose something important. Ideally, they should go to unlimited. <strong>Remember that you, the customer, hold the power; they are nothing without the money you give them.</strong> And as you vote with your dollars, consider literally any other WordPress host as WP Engine is the only one we’ve found that completely disables revisions by default.</p>
</div>
	
</article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happened to the Japanese PC platforms? (124 pts)]]></title>
            <link>https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/</link>
            <guid>41612984</guid>
            <pubDate>Sat, 21 Sep 2024 22:06:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/">https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/</a>, See on <a href="https://news.ycombinator.com/item?id=41612984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>(This was originally posted on a social media site; I’ve revised and updated it for my blog.)</em></p>

<p>The other day <a href="https://nex-3.com/">a friend</a> asked me a pretty interesting question: what <em>happened</em> to all those companies who made those Japanese computer platforms that were never released outside Japan? I thought it’d be worth expanding that answer into a full-size post.</p>

<h3>A quick introduction: the players</h3>

<p>It’s hard to remember these days, but there there used to be an incredible amount of variety in the computer space. There were a <em>lot</em> of different computer platforms, pretty much all of them totally incompatible with each other. North America settled on the IBM PC/Mac duopoly pretty early<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, but Europe still had plenty of other computers popular well into the 90s, and Japan had its own computers that essentially didn’t exist anywhere else.</p>

<p>So who were they? By the 16-bit computer era, there’s three I’m going to talk about today<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>: NEC’s PC-98, Fujitsu’s FM Towns, and Sharp’s X68000. The PC-98 was far and away the biggest of those platforms, with the other two having a more niche market.</p>

<h3>The PC-98 in a time of transition</h3>

<p>First, a quick digression: what is this DOS thing?</p>

<p>The thing about DOS is that it’s a much thinner OS than what we think of in 2024. When you’re writing DOS software of any kind of complexity, you’re talking straight to the hardware, or to drivers that are specific to particular classes of hardware. When we talk about “DOS” in the west, we specifically mean “DOS on IBM compatible PCs”. PC-98 and FM Towns both had DOS-based operating systems, but their hardware was nothing at all like IBM compatible PCs and there was no level of software compatibility between them. The PC-98 was originally a DOS-based computer without a GUI of any kind - just like DOS-based IBM PCs. When we talk about “PC-98” games and software, what we really mean is DOS-based PC-98 software that only runs on that platform.</p>

<p>Windows software is very different from DOS in one important way: Windows incorporates a hardware abstraction layer. Software written for Windows APIs doesn’t need to be specific to particular hardware, and that set the stage for the major transition that was going to come.</p>

<p>NEC and Microsoft teamed up on porting Windows to the PC-98 platform. Both the PC-98 and the IBM PC use the same CPU, even though the rest of their hardware is very different, which made the port technically feasible. The first Windows release for PC-98 came out in 1992, but Windows didn’t really take off in a big way until Windows 95 in the mid-90s. And so, suddenly, for the first time software could run on both IBM PCs running Japanese language Windows <em>and</em> PC-98 running Windows.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> Software developers didn’t have to do anything special to get that compatibility: it happened by default, so long as they were using the standard Windows software features and didn’t talk directly to the hardware.</p>

<p>Around the same time, NEC started making IBM-compatible PCs. As far as I can tell, they made both PC-98s and IBM PCs alongside each other for quite a few years. With Windows software not caring what the underlying hardware was, the distinction between “PC-98” and “PC” got a lot fuzzier. If you were buying a PC, you had no reason to buy a PC-98 unless you wanted to run DOS-based PC-98 software. If you just wanted that shiny new Windows software, why not buy the cheaper IBM PC that NEC would also sell you?</p>

<p>So, for the PC-98, the answer isn’t really that it <em>died</em> - it sort of faded away and merged into what every other system was becoming.</p>

<h3>The FM Towns</h3>

<p>The FM Towns had a similar transition. While it had a homegrown GUI-based OS called Towns OS, it was relatively primitive compared to Windows 3 and especially Windows 95. The FM Towns also used the same CPU as IBM PCs and the PC-98, which means Microsoft could work with Fujitsu to port their software to the platform. And, just like what happened with the PC-98, the platform became far less relevant and less distinctive when it was just another platform to run Windows software on. If you didn’t care about running the older FM Towns-specific software, why would you care about buying an FM Towns instead of any other IBM PC?</p>

<p>Fujitsu, just like NEC, made the transition to making standard Windows PCs and discontinued the FM Towns a few years later.</p>

<h3>The X68000 loses out in the CPU wars</h3>

<p>Unlike the other two platforms, the X68000 had a different CPU and a distinct homegrown OS. It used the 68000 series of processors from Motorola, which were incredibly popular in the 80s and 90s. The same CPU was used by the Mac until the mid 90s, the Amiga, and a huge number of home consoles and arcade boards. It was a powerful CPU, but when every other platform was looking for a way to merge with the Windows platform, they had a big problem: you simply couldn’t port Windows to the platform and get it to run regular Windows software because they didn’t use the same CPUs. Sharp were locked out. While they also switched to making Windows PCs in the 90s, they had no way to bring their existing users with them by giving them a transition path.</p>

<h3>The lure of multitasking</h3>

<p>Why did Windows win out, though? In the west we often credit Microsoft Office as the killer app, but it wasn’t a major player in Japan where Japanese language-specific word processors were huge in the market for years. I’d argue instead that multitasking was the killer feature.</p>

<p>In the DOS era, you ran one program at a time. You might have a lot of software you used, but you’d pick one program to use at a time. If you wanted to switch to something else, you’d have to save whatever you’re doing, quit, and open a completely different full-screen app. While competing platforms like the Mac<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> had multitasking via their GUIs for years, Windows and especially Windows 3 is what brought it to the wider market.</p>

<p>If you’re going to be using more than one program at the same time, having a wider amount of software <em>that’s inter-compatible</em> becomes more important. I’d argue that multitasking is what nudged market consolidation onto a smaller number of computers. Windows, and especially Windows 95, became <em>very</em> hard for other platforms to compete with because its base of software was just so large. It made far more sense for NEC and Fujitsu to bring Windows to their users even if it meant losing the lock-in that their unique OSs and platform-specific software had gotten them.</p>

<h3>Shifts in the gaming market</h3>

<p>In the 16-bit era, the FM Towns and X68000 were doing great in the computer gaming niche. They had powerful 2D gaming hardware and a lot of very sophisticated action games. Their original games and ports of arcade games compared extremely well against what 16-bit consoles could do, giving them a reputation of being the real gamers' platforms. By 1994 though, they had a problem: the 32-bit consoles were out, which could do 2D games just as well as the FM Towns and X68000, and the consoles could also do 3D that blew away anything those computers could handle. Fujitsu and Sharp, meanwhile, just weren’t releasing new hardware that could keep up. The PC gaming niche had already been shrinking and moving towards consoles for a few years, and this killed off a lot of what was left.</p>

<p>I also suspect that Sony’s marketing for the PlayStation changed things significantly. Home computers had older players than the 16-bit consoles did, but Sony was marketing the PS1 towards those same older audiences. It probably made it easy for computer players to look at the new consoles and decide to move on.</p>

<h3>What about the 8-bit platforms?</h3>

<p>Japan had a variety of 8-bit computer platforms, some of which (like the MSX) were also well-known in western countries. While in Europe the 8-bit micros held on right into the 90s, and many users upgraded straight from 8-bit micros to Windows PCs, in Japan the 8-bit computers had already been supplanted by native 16-bit computing platforms before the Windows era. In some cases, these were 16-bit computers by the same manufacturers - both Sharp and NEC had been major players in the 8-bit computing era too. The MSX, meanwhile, had failed to produce either a 16-bit evolution of the platform or a 16-bit successor and so many of its users had already moved on by the time Windows 95 came out.</p>

<h3>So, in conclusion</h3>

<p>None of the 16-bit Japanese computer makers acutally died off - they just switched to making standard Windows PCs that were interchangeable with anything else out there. Microsoft took over that market just like they did everywhere else in the world, but at least the companies themselves survived better than the Commodores and Ataris of the world.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sanding UI (377 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2024/sanding-ui/</link>
            <guid>41612154</guid>
            <pubDate>Sat, 21 Sep 2024 19:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2024/sanding-ui/">https://blog.jim-nielsen.com/2024/sanding-ui/</a>, See on <a href="https://news.ycombinator.com/item?id=41612154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <p>One of the ways I like to do development is to build something, click around <em>a ton</em>, make tweaks, click around more, more tweaks, more clicks, etc., until I finally consider it done.</p>
<p>The <em>clicking around a ton</em> is the important part. If it’s a page transition, that means going back and forth a ton. Click, back button. Click, right-click context menu, “Back”. Click, in-app navigation to go back (if there is one). Click, keyboard shortcut to go back. Over and over and over. You get the idea.</p>
<p>It’s kind of a QA tactic in a sense, just click around and try to break stuff. But I like to think of it as being more akin to woodworking. You have a plank of wood and you run it through the belt sander to get all the big, coarse stuff smoothed down. Then you pull out the hand sander, sand a spot, run your hand over it, feel for splinters, sand it some more, over and over until you’re satisfied with the result.</p>
<p>With software, the fact is that sometimes there are just <a href="https://daverupert.com/2024/02/ui-states/">too many variables</a> to know and test and smooth out. So I click around, <a href="https://notes.jim-nielsen.com/#2023-03-08T1210">using the UI over and over</a>, until I finally cannot give myself any more splinters.</p>
<p>Just the other day, I was working on a list of radio options, pretty standard-fare stuff:</p>
<ul>
<li>Create a <code>&lt;label&gt;</code> with an associated <code>&lt;input type="radio"&gt;</code>.</li>
<li>Put them on the same row, center align them with a gap between the control and the label.</li>
<li>Etc.</li>
</ul>
<p>As an oldie who used to leverage floats in CSS, I’m still amazed when I can use flexbox to do this stuff — it’s so easy!</p>
<pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"container"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"control"</span>&gt;</span>Foo<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"control"</span> <span>type</span>=<span>"radio"</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>

<span>&lt;<span>style</span>&gt;</span><span>
    <span>.container</span> {
      <span>display</span>: flex;
      <span>flex-direction</span>: row;
      <span>align-items</span>: center;
      <span>gap</span>: .<span>5rem</span>;
    }
</span><span>&lt;/<span>style</span>&gt;</span>
</code></pre>
<p>As I was doin’ my thang — clicking around a bunch, trying to get some splinters — I realized there was a dead spot in the UI, a place between the radio and the label where clicking didn’t toggle the control like I expected.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-flexbox-animated.gif" width="172" height="135" alt="Animated gif of some radio inputs where the space between the control and the label doesn’t select the radio grouping.">

</p><p>“What the?” I thought. “I’ve got my <code>&lt;label&gt;</code> and <code>&lt;input&gt;</code> and associated <code>for</code> attribute, why isn’t this working?” Then I thought, “<code>gap</code> in my flex display must be the culprit!”</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-flexbox.png" width="312" height="159" alt="Screenshot of Chrome developer tools where an item has a flex layout with a CSS gap in between a label and an input.">

</p><p>Sure enough, it was. While flexbox had made it super easy to add some visual spacing between the control and its label, that spacing had become a dead zone of interaction even though it wasn’t my intention!</p>
<p>There’s probably a million different ways to solve this problem — because <a href="https://blog.jim-nielsen.com/2021/css-is-in-fact-awesome/">CSS is awesome</a> — but I just removed the <code>gap</code> and added some padding to my label, then voilà!</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox-padding.png" width="95" height="29" alt="Screenshot Chrome developer tools with a label that has a left padding.">

</p><p>Putting padding on the label, instead of the containing flexbox, made the whole thing clickable without a deadzone.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox.png" width="269" height="81" alt="Screenshot of the Chrome developer tools where an element has a flex layout but no gap.">

</p><p>A bunch more clicking around and things were working as expected.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox-animated.gif" width="135" height="106" alt="Animated gif of some radio inputs where the space between the control and the label can be clicked and it selects the entire radio grouping.">

</p><p>It’s a small thing, but lots of small splinters lead to an agonizing experience.</p>
<p>So my recipe is: sand it, feel the grain, get a splinter, sand again, and repeat until smooth.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Particle? (2020) (111 pts)]]></title>
            <link>https://www.quantamagazine.org/what-is-a-particle-20201112/</link>
            <guid>41612049</guid>
            <pubDate>Sat, 21 Sep 2024 19:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/what-is-a-particle-20201112/">https://www.quantamagazine.org/what-is-a-particle-20201112/</a>, See on <a href="https://news.ycombinator.com/item?id=41612049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>Given that everything in the universe reduces to particles, a question presents itself: What are particles?</p>
<p>The easy answer quickly shows itself to be unsatisfying. Namely, electrons, photons, quarks and other “fundamental” particles supposedly lack substructure or physical extent. “We basically think of a particle as a pointlike object,” said <a href="https://physics.berkeley.edu/people/faculty/mary-k-gaillard">Mary Gaillard</a>, a particle theorist at the University of California, Berkeley who predicted the masses of two types of quarks in the 1970s. And yet particles have distinct traits, such as charge and mass. How can a dimensionless point bear weight?</p>
<p>“We say they are ‘fundamental,’” said <a href="https://web.mit.edu/physics/people/faculty/wen_xiao-gang.html">Xiao-Gang Wen</a>, a theoretical physicist at the Massachusetts Institute of Technology. “But that’s just a [way to say] to students, ‘Don’t ask! I don’t know the answer. It’s fundamental; don’t ask anymore.’”</p>
<p>With any other object, the object’s properties depend on its physical makeup — ultimately, its constituent particles. But those particles’ properties derive not from constituents of their own but from mathematical patterns. As points of contact between mathematics and reality, particles straddle both worlds with an uncertain footing.</p>
<p>When I recently asked a dozen particle physicists what a particle is, they gave remarkably diverse descriptions. They emphasized that their answers don’t conflict so much as capture different facets of the truth. They also described two major research thrusts in fundamental physics today that are pursuing a more satisfying, all-encompassing picture of particles.</p>
<p>“‘What is a particle?’ indeed is a very interesting question,” said Wen. “Nowadays there is progress in this direction. I should not say there’s a unified point of view, but there’s several different points of view,<a id="back1"></a> and all look interesting.”</p>
<h2><a href="#Nanopoulos">A Particle Is a ‘Collapsed Wave Function’<sup>1</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The quest to understand nature’s fundamental building blocks began with the ancient Greek philosopher Democritus’s assertion that such things exist. Two millennia later, Isaac Newton and Christiaan Huygens debated whether light is made of particles or waves. The discovery of quantum mechanics some 250 years after that proved both luminaries right: Light comes in individual packets of energy known as photons, which behave as both particles and waves.</p>
<p>Wave-particle duality turned out to be a symptom of a deep strangeness. Quantum mechanics revealed to its discoverers in the 1920s that photons and other quantum objects are best described not as particles or waves but by abstract “wave functions” — evolving mathematical functions that indicate a particle’s probability of having various properties. The wave function representing an electron, say, is spatially spread out, so that the electron has possible locations rather than a definite one. But somehow, strangely, when you stick a detector in the scene and measure the electron’s location, its wave function suddenly “collapses” to a point, and the particle clicks at that position in the detector.</p>
<figure>
    <p><img width="1120" height="784" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle-WAVE.gif" alt="" decoding="async" loading="lazy"><img width="1120" height="784" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle-WAVE-MOBILE.gif" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>A particle is thus a collapsed wave function. But what in the world does that mean? Why does observation cause a distended<a id="back2"></a> mathematical function to collapse and a concrete particle to appear? And what decides the measurement’s outcome? Nearly a century later, physicists have no idea.</p>
<h2><a href="#Quinn">A Particle Is a ‘Quantum Excitation of a Field’<sup>2</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The picture soon got even stranger. In the 1930s, physicists realized that the wave functions of many individual photons collectively behave like a single wave propagating through conjoined electric and magnetic fields — exactly the classical picture of light discovered in the 19th century by James Clerk Maxwell. These researchers found that they could “quantize” classical field theory, restricting fields so that they could only oscillate in discrete amounts known as the “quanta” of the fields. In addition to &nbsp;photons — the quanta of light — Paul Dirac and others discovered that the idea could be extrapolated to electrons and everything else: According to quantum field theory, particles are excitations of quantum fields that fill all of space.</p>
<p>In positing the existence of these more fundamental fields, quantum field theory stripped particles of status, characterizing them as mere bits of energy that set fields sloshing. Yet despite the ontological baggage of omnipresent fields, quantum field theory became the lingua franca of particle physics because it allows researchers to calculate with extreme precision what happens when particles interact — particle interactions being, at base level, the way the world is put together.</p>

<p>As physicists discovered more of nature’s particles and their associated fields, a parallel perspective developed. The properties of these particles and fields appeared to follow numerical patterns. By extending these patterns, physicists were able to predict the existence of more particles. “Once you encode the patterns you observe into the mathematics, the mathematics is predictive; it tells you more things you might observe,” explained <a href="https://www.quantamagazine.org/roberto-peccei-and-helen-quinn-driving-around-stanford-in-a-clunky-jeep-20170615/">Helen Quinn</a>, an emeritus particle physicist at Stanford University.<br>
<a id="back3"></a><br>
The patterns also suggested a more abstract and potentially deeper perspective on what particles actually are.</p>
<h2><a href="#GlashowNeemanSternberg">A Particle Is an ‘Irreducible<br>
Representation of a Group’<sup>3</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Mark Van Raamsdonk remembers the beginning of the first class he took on quantum field theory as a Princeton University graduate student. The professor came in, looked out at the students, and asked, “What is a particle?”</p>
<p>“An irreducible representation of the Poincaré group,” a precocious classmate answered.</p>
<p>Taking the apparently correct definition to be general knowledge, the professor skipped any explanation and launched into an inscrutable series of lectures. “That entire semester I didn’t learn a single thing from the course,” said <a href="https://phas.ubc.ca/~mav/vanraamsdonk.html">Van Raamsdonk</a>, who’s now a respected theoretical physicist at the University of British Columbia.</p>
<p>It’s the standard deep answer of people in the know: Particles are “representations” of “symmetry groups,” which are sets of transformations that can be done to objects.</p>
<p>Take, for example, an equilateral triangle. Rotating it by 120 or 240 degrees, or reflecting it across the line from each corner to the midpoint of the opposite side, or doing nothing, all leave the triangle looking the same as before. These six symmetries form a group. The group can be expressed as a set of mathematical matrices — arrays of numbers that, when multiplied by coordinates of an equilateral triangle, return the same coordinates. Such a set of matrices is a “representation” of the symmetry group.</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_SYMMETRY.V3.svg" alt="" decoding="async" loading="lazy"><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_SYMMETRY-MOBILE.V2.svg" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Similarly, electrons, photons and other fundamental particles are objects that essentially stay the same when acted on by a certain group. Namely, particles are representations of the Poincaré group: the group of 10 ways of moving around in the space-time continuum. Objects can shift in three spatial directions or shift in time; they can also rotate in three directions or receive a boost in any of those directions. In 1939, the mathematical physicist Eugene Wigner <a href="https://www.jstor.org/stable/1968551?seq=1">identified particles</a> as the simplest possible objects that can be shifted, rotated and boosted.</p>
<p>For an object to transform nicely under these 10 Poincaré transformations, he realized, it must have a certain minimal set of properties, and particles have these properties. One is energy. Deep down, energy is simply the property that stays the same when the object shifts in time. Momentum is the property that stays the same as the object moves through space.</p>
<p>A third property is needed to specify how particles change under combinations of spatial rotations and boosts (which, together, are rotations in space-time). This key property is “spin.” At the time of Wigner’s work, physicists already knew particles have spin, a kind of intrinsic angular momentum that determines many aspects of particle behavior, including whether they act like matter (as electrons do) or as a force (like photons). Wigner showed that, deep down, “spin is just a label that particles have because the world has rotations,” said <a href="https://www.quantamagazine.org/nima-arkani-hamed-and-the-future-of-physics-20150922/">Nima Arkani-Hamed</a>, a particle physicist at the Institute for Advanced Study in Princeton, New Jersey.</p>
<p>Different representations of the Poincaré group are particles with different numbers of spin labels, or degrees of freedom that are affected by rotations. There are, for example, particles with three spin degrees of freedom. These particles rotate in the same way as familiar 3D objects. All matter particles, meanwhile, have two spin degrees of freedom, nicknamed “spin-up” and “spin-down,” which rotate differently. If you rotate an electron by 360 degrees, its state will be inverted, just as an arrow, when moved around a 2D Möbius strip, comes back around pointing the opposite way.</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_MOBIUS.V2.svg" alt="" decoding="async" loading="lazy"><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_MOBIUS-MOBILE.svg" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Elementary particles with one and five spin labels also appear in nature. Only a representation of the Poincaré group with four spin labels seems to be missing.</p>
<p>The correspondence between elementary particles and representations is so neat that some physicists — like Van Raamsdonk’s professor — equate them. Others see this as a conflation. “The representation is not the particle; the representation is a way of describing certain properties of the particle,” said <a href="http://physics.bu.edu/people/show/slg">Sheldon Glashow</a>, a Nobel Prize-winning particle <a id="back4"></a>theorist and professor emeritus at Harvard University and Boston University. “Let us not confuse the two.”</p>
<h2><a href="#Wen1">‘Particles Have So Many Layers’<sup>4</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Whether there’s a distinction or not, the relationship between particle physics and group theory grew both richer and more complicated over the course of the 20th century. The discoveries showed that elementary particles don’t just have the minimum set of labels needed to navigate space-time; they have extra, somewhat superfluous labels as well.</p>
<p>Particles with the same energy, momentum and spin behave identically under the 10 Poincaré transformations, but they can differ in other ways. For instance, they can carry different amounts of electric charge. As “the whole particle zoo” (as Quinn put it) was discovered in the mid-20th century, additional distinctions between particles were revealed, necessitating new labels dubbed “color” and “flavor.”</p>

<p>Just as particles are representations of the Poincaré group, theorists came to understand that their extra properties reflect additional ways they can be transformed. But instead of shifting objects in space-time, these new transformations are more abstract; they change particles’ “internal” states, for lack of a better word.</p>
<p>Take the property known as color: In the 1960s, physicists ascertained that quarks, the elementary constituents of atomic nuclei, exist in a probabilistic combination of three possible states, which they nicknamed “red,” “green” and “blue.” These states have nothing to do with actual color or any other perceivable property. It’s the number of labels that matters: Quarks, with their three labels, are representations of a group of transformations called SU(3) consisting of the infinitely many ways of mathematically mixing the three labels.</p>
<p>While particles with color are representations of the symmetry group SU(3), particles with the internal properties of flavor and electric charge are representations of the symmetry groups SU(2) and U(1), respectively. Thus, the <a href="https://www.quantamagazine.org/a-new-map-of-the-standard-model-of-particle-physics-20201022/">Standard Model of particle physics</a> — the quantum field theory of all known elementary particles and their interactions — is often said to represent the symmetry group SU(3) × SU(2) × U(1), consisting of all combinations of the symmetry operations in the three subgroups. (That particles also transform under the Poincaré group is apparently too obvious to even mention.)</p>

<p>The Standard Model reigns half a century after its development. Yet it’s an incomplete description of the universe. Crucially, it’s missing the force of gravity, which quantum field theory can’t fully handle. Albert Einstein’s general theory of relativity separately describes gravity as curves in the space-time fabric. Moreover, the Standard Model’s three-part SU(3) × SU(2) × U(1) structure raises questions. To wit: “Where the hell did all this come from?” as <a href="https://physics.tamu.edu/directory/dimitri-nanopoulos/">Dimitri Nanopoulos</a> put it. “OK, suppose it works,” continued Nanopoulos, a particle physicist at Texas A&amp;M University who was active during the Standard Model’s early days. “But what is this thing? It cannot <a id="back5"></a>be three groups there; I mean, ‘God’ is better than this — God in quotation marks.”</p>
<h2><a href="#Gaillard">Particles ‘Might Be Vibrating Strings’<sup>5</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>In the 1970s, Glashow, Nanopoulos and others tried fitting the SU(3), SU(2) and U(1) symmetries inside a single, larger group of transformations, the idea being that particles were representations of a single symmetry group at the beginning of the universe. (As symmetries broke, complications set in.) The most natural candidate for such a “grand unified theory” was a symmetry group called SU(5), but experiments soon ruled out that option. Other, less appealing possibilities <a href="https://www.quantamagazine.org/no-proton-decay-means-grand-unification-must-wait-20161215/">remain in play</a>.</p>
<p>Researchers placed even higher hopes in string theory: the idea that if you zoomed in enough on particles, you would see not points but one-dimensional vibrating strings. You would also see six extra spatial dimensions, which string theory says are curled up at every point in our familiar 4D space-time fabric. The geometry of the small dimensions determines the properties of strings and thus the macroscopic world. “Internal” symmetries of particles, like the SU(3) operations that transform quarks’ color, obtain physical meaning: These operations map, in the string picture, onto rotations in the small spatial dimensions, just as spin reflects rotations in the large dimensions. “Geometry gives you symmetry gives you particles, and all of this goes together,” Nanopoulos said.</p>
<p>However, if any strings or extra dimensions exist, they’re too small to be detected experimentally. In their absence, other ideas have blossomed. Over the past decade, two approaches in particular have attracted the brightest minds in contemporary fundamental physics.<a id="back6"></a> Both approaches refresh the picture of particles yet again.</p>
<h2><a href="#Wen2">A Particle Is a ‘Deformation of the Qubit Ocean’<sup>6</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The first of these research efforts goes by the slogan “it-from-qubit,” which expresses the hypothesis that everything in the universe — all particles, as well as the space-time fabric those particles stud like blueberries in a muffin — arises out of quantum bits of information, or qubits. Qubits are probabilistic combinations of two states, labeled 0 and 1. (Qubits can be stored in physical systems just as bits can be stored in transistors, but you can think of them more abstractly, as information itself.) When there are multiple qubits, their possible states can get tangled up, so that each one’s state depends on the states of all the others. Through these contingencies, a small number of entangled qubits can encode a huge amount of information.</p>
<p>In the it-from-qubit conception of the universe, if you want to understand what particles are, you first have to understand space-time. In 2010, Van Raamsdonk, a member of the it-from-qubit camp, wrote <a href="https://arxiv.org/abs/1005.3035">an influential essay</a> boldly declaring what various calculations suggested. He argued that entangled qubits might stitch together the space-time fabric.</p>
<p>Calculations, thought experiments and toy examples going back decades suggest that space-time has “holographic” properties: It’s possible to encode all information about a region of space-time in degrees of freedom in one fewer dimension — often on the region’s surface. “In the last 10 years, we’ve learned a lot more about how this encoding works,” Van Raamsdonk said.</p>
<p>What’s most surprising and fascinating to physicists about this holographic relationship is that space-time is bendy because it includes gravity. But the lower-dimensional system that encodes information about that bendy space-time is a purely quantum system that lacks any sense of curvature, gravity or even geometry. It can be thought of as a system of entangled qubits.</p>
<p>Under the it-from-qubit hypothesis, the properties of space-time — its robustness, its symmetries — essentially come from the way 0s and 1s are braided together. The long-standing quest for a quantum description of gravity becomes a matter of identifying the qubit entanglement pattern that encodes the particular kind of space-time fabric found in the actual universe.</p>

<p>So far, researchers know much more about how this all works in toy universes that have negatively curved, saddle-shaped space-time — mostly because they’re relatively easy to work with. Our universe, by contrast, is positively curved. But researchers have found, to their surprise, that anytime negatively curved space-time pops up like a hologram, particles come along for the ride. That is, whenever a system of qubits holographically encodes a region of space-time, there are always qubit entanglement patterns that correspond to localized bits of energy floating in the higher-dimensional world.</p>
<p>Importantly, algebraic operations on the qubits, when translated in terms of space-time, “behave just like rotations acting on the particles,” Van Raamsdonk said. “You realize there’s this picture being encoded by this nongravitational quantum system. And somehow in that code, if you can decode it, it’s telling you that there are particles in some other space.”</p>
<p>The fact that holographic space-time always has these particle states is “actually one of the most important things that&nbsp;distinguishes these holographic systems from other quantum systems,” he said. “I think nobody really understands the reason why holographic models have&nbsp;this property.”</p>
<p>It’s tempting to picture qubits having some sort of spatial arrangement that creates the holographic universe, just as familiar holograms project from spatial patterns. But in fact, the qubits’ relationships and interdependencies might be far more abstract, with no real physical arrangement at all. “You don’t need to talk about these 0s and 1s living in a particular space,” said <a href="https://web.mit.edu/physics/people/faculty/engelhardt_netta.html">Netta Engelhardt</a>, a physicist at MIT who recently <a href="https://breakthroughprize.org/News/60">won a New Horizons in Physics Prize</a> for <a href="https://www.quantamagazine.org/the-most-famous-paradox-in-physics-nears-its-end-20201029/">calculating the quantum information content of black holes</a>. “You can talk about the abstract existence of 0s and 1s, and how an operator might act on 0s and 1s, and these are all much more abstract mathematical relations.”</p>
<p>There’s clearly more to understand. But if the it-from-qubit picture is right, then particles are holograms, just like space-time. Their truest definition <a id="back7"></a>is in terms of qubits.</p>
<h2><a href="#ArkaniHamed">‘Particles Are What We Measure in Detectors’<sup>7</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Another camp of researchers who call themselves “amplitudeologists” seeks to return the spotlight to the particles themselves.</p>
<p>These researchers argue that quantum field theory, the current lingua franca of particle physics, tells far too convoluted a story. Physicists use quantum field theory to calculate essential formulas called scattering amplitudes, some of the most basic calculable features of reality. When particles collide, amplitudes indicate how the particles might morph or scatter. Particle interactions make the world, so the way physicists test their description of the world is to compare their scattering amplitude formulas to the outcomes of particle collisions in experiments such as Europe’s Large Hadron Collider.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Applied Mathematical Programming (123 pts)]]></title>
            <link>https://web.mit.edu/15.053/www/AMP.htm</link>
            <guid>41611571</guid>
            <pubDate>Sat, 21 Sep 2024 18:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.mit.edu/15.053/www/AMP.htm">https://web.mit.edu/15.053/www/AMP.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41611571">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[What 10k Hours of Coding Taught Me: Don't Ship Fast (106 pts)]]></title>
            <link>https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast</link>
            <guid>41610832</guid>
            <pubDate>Sat, 21 Sep 2024 16:13:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast">https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast</a>, See on <a href="https://news.ycombinator.com/item?id=41610832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-wrapper"><p>I’ve been an engineer for over 7 years now. I have worked on countless projects in backend, frontend, and DevOps. I don’t consider myself a great engineer; there are people out there who are not only smarter but also more experienced. Over the years, I have learned some tricks to help me climb the programming ladder, allowing me to build software that is reliable and easy to work with.</p>
<p>Being slow has made me code faster, ship more, and be more productive in general. This didn’t come only from years of coding but also from life lessons and my religion. As an Orthodox Christian, you have to always be slow and not rush your moves.</p>
<h2 id="heading-the-1-problem-with-software">The #1 Problem with Software</h2>
<p>Most people, when they start to code, think that great engineers are magicians who build applications in a unique way that no one can understand. That is very far from the truth. If you actually take a look at great engineers' code, you will find it very simple and easy to navigate and understand.</p>
<p>Your application doesn’t need to be fast, fancy, or use cutting-edge technology for you to be considered a good programmer. Managers also make that mistake. They hire people based on things that are far from the truth.</p>
<p>Giving coding tests where you have to build an application from scratch is a terrible way to judge someone's skills. Whiteboard interviews are actually better than coding challenges that give you 3 days to complete because at least they take a look at your IQ and your way of thinking.</p>
<p>Now, let's talk about the #1 problem that everyone should focus on but often overlooks:</p>
<p><strong>Developer Experience</strong></p>
<p>This is the most important thing in the entire project 99% of the time. Because everybody wants to ship fast to make money, but they end-up building 90% of the application in 1 month and the last 10% takes them 3 months to finish.</p>
<p>Developers are also hyped up for new projects so they try to take the quick dopamine to just have something to showcase as fast as possible and make there managers happy as well.</p>
<p>They end-up making there managers happy, yet in the long-run everybody is panicking and they are considering refactoring or even building the application from scratch after 4-5 years.</p>
<p>That’s why actually creating features becomes really hard and even harder to push them to production. This creates a snowball effect.  </p>
<p>Let’s take a look at 2 code examples. We have 2 controllers that get the trending users from our database and attach emojis to them. This is from one of my open-source projects <a target="_blank" href="http://eporanger.xyz/">reporanger.xyz</a>.</p>
<p>This is the controller that is being called from the routes. In there we have all the functionality as well as a try-catch block to check for any errors as well.</p>
<pre><code><span>// users.controller.ts</span>
<span>const</span> getTrendingUsers = <span>async</span> (_req: Request, res: Response, _next: NextFunction) =&gt; {
  <span>try</span> {
    <span>const</span> events = <span>await</span> GithubEvent.find({
      where: { event_date: MoreThan(<span>new</span> <span>Date</span>(<span>Date</span>.now() - <span>24</span> * <span>60</span> * <span>60</span> * <span>1000</span>)) },
      order: { event_size: <span>'DESC'</span> },
      take: <span>3</span>,
    });
    <span>const</span> users = <span>await</span> Username.find({ where: { id: In(events.map(<span>(<span>event</span>) =&gt;</span> event.username_id)) } });
    <span>const</span> topUsers = <span>await</span> getTopUsers(<span>3</span>);
    <span>const</span> trendingUsers = <span>await</span> <span>Promise</span>.all(
      users.map(<span>async</span> (user) =&gt; ({
        ...user,
        emoji: <span>await</span> emojiService.getEmoji(user.score, topUsers),
      })),
    );
    res.status(<span>200</span>).json({
      status: <span>200</span>,
      message: <span>'Trending users fetched successfully'</span>,
      data: trendingUsers,
      error: <span>''</span>,
      success: <span>true</span>,
    });
  } <span>catch</span> (error) {
    res.status(<span>500</span>).json({
      status: <span>500</span>,
      message: <span>'Error fetching trending users'</span>,
      data: <span>null</span>,
      error: error.message,
      success: <span>false</span>,
    });
  }
};
</code></pre>
<p>Here is the same controller but we’ve used one simple principle: <strong>Unique Responsibility</strong></p>
<p>We spitted our code in 4 smaller re-usable files:<br><code>user.controller.ts</code><br><code>user.service.ts</code><br><code>async.util.ts</code><br><code>response.util.ts</code></p>
<p>This help’s us in many more ways than we can understand.</p>
<ol>
<li><p>We can re-use the <code>user.service.ts</code> everywhere in our application we want. For example on a cron-job we can do <code>usernameService.getTrendingUsers();</code></p>
</li>
<li><p>We removed every try-catch block to make the code cleaner. We also log every error (<code>logger('error', error);</code>). This way, we can easily create an error service later that stores all errors in the database for future use-cases.</p>
</li>
<li><p>We have unified responses for all of our controller with the <code>resFn</code> <strong>,</strong> this is really important because we make sure that all of the request will return that same response by just using a simple generic as you can see below.</p>
</li>
<li><p>Developing a new controller is now 10X easier, because our coding architecture is seamless across our entire application. Even if another developer wrote code it wouldn’t make a difference on the coding style.</p>
</li>
</ol>
<pre><code><span>// user.controller.ts</span>
<span>const</span> getTrendingUsers = asyncFn(<span>async</span> (_req: Request, res: Response, _next: NextFunction) =&gt; {
  <span>const</span> trendingUsers = <span>await</span> usernameService.getTrendingUsers();
  resFn(res, {
    status: <span>200</span>,
    message: <span>'Trending users fetched successfully'</span>,
    data: trendingUsers,
    error: <span>''</span>,
    success: <span>true</span>,
  });
});

<span>// user.service.ts</span>
<span>const</span> getTrendingUsers = <span>async</span> () =&gt; {
  <span>const</span> events = <span>await</span> GithubEvent.find({
    where: { event_date: MoreThan(<span>new</span> <span>Date</span>(<span>Date</span>.now() - <span>24</span> * <span>60</span> * <span>60</span> * <span>1000</span>)) },
    order: { event_size: <span>'DESC'</span> },
    take: <span>3</span>,
  });
  <span>const</span> users = <span>await</span> Username.find({ where: { id: In(events.map(<span>(<span>event</span>) =&gt;</span> event.username_id)) } });
  <span>const</span> topUsers = <span>await</span> getTopUsers(<span>3</span>);
  <span>const</span> usersWithEmoji = <span>await</span> <span>Promise</span>.all(
    users.map(<span>async</span> (user) =&gt; ({
      ...user,
      emoji: <span>await</span> emojiService.getEmoji(user.score, topUsers),
    })),
  );
  <span>return</span> usersWithEmoji;
};

<span>// async.util.ts</span>
<span>export</span> <span>const</span> asyncFn = <span>(<span>fn: asyncPropsFunction</span>) =&gt;</span> <span>async</span> (req: Request, res: Response, next: NextFunction) =&gt; {
  <span>try</span> {
    <span>await</span> fn(req, res, next);
  } <span>catch</span> (error) {
    logger(<span>'error'</span>, error);
    next(error);
  }
};

<span>// response.util.ts</span>
<span>export</span> <span>const</span> resFn = <span>(<span>res: Response, { status, error, data, message, success }: IResponse&lt;<span>any</span>&gt;</span>) =&gt;</span> {
  <span>const</span> suc = success !== <span>undefined</span> ? success : <span>true</span>;

  res.status(status).json({
    error,
    data,
    message,
    success: suc,
    status,
  });
};

<span>// response.interface.ts</span>
<span>export</span> <span>interface</span> IResponse&lt;T&gt; {
  status: <span>number</span>;
  message: <span>string</span>;
  data: T | <span>any</span>;
  error: <span>string</span>;
  success: <span>boolean</span>;
}
</code></pre>
<p>Now imagine if we didn’t implement a good architecture from the beginning and wanted to change something small across the application in the future. Even if we just wanted to log our errors, we would have to go to all of our controllers and add <code>logger('error', error);</code>. Or if we wanted to add a sixth field to our response, for example, <code>metadata</code>. It would be a nightmare.</p>
<h2 id="heading-do-the-refactoring-first">Do the Refactoring First</h2>
<p>Refactoring should be done before you write your code. What I mean by this is that eventually, every application needs refactoring. Refactoring a relatively big software, for example, with over 70,000 lines of code, can take 30-40 hours and also create a lot of errors and bugs in the process.</p>
<p>You might end up breaking the application or spending 20 more hours testing it. Also, when you reach a size this large, the refactoring won’t be as good as if you did it in the beginning.</p>
<p>What I propose is to spend your first 40-50 hours planning and refactoring. Just create a few controllers, brainstorm how that would scale in the future, refactor, and then continue.</p>
<p>Yes, your manager might scream in the beginning because you spent 50 hours coding and have almost nothing to showcase except a good architecture that will scale that no-one understand. But if you have the option to do it, then do it. It will save a ton of headaches for not only you but future developers as well.</p>
<p>Unit testing is also really important. Don’t be crazy with it just have at least 60% coverage and you are good to go. It will save you tones of bugs in the future.</p>
<h2 id="heading-pre-commit-checks">Pre-commit Checks</h2>
<p>This is very important. For JavaScript/TypeScript projects, we have Husky, but there are many alternatives for every language or framework out there. Husky is a tool that runs some commands before you commit your code. If got throw an error, the commit won't pass. Here is an example <code>.husky</code> configuration from <a target="_blank" href="http://reporanger.xyz/">reporanger.xyz</a>.</p>
<ol>
<li><p>Lint Check</p>
</li>
<li><p>Run Tests</p>
</li>
<li><p>Prettify</p>
</li>
</ol>
<p>This 3 simple steps will make your codebase. 10X better.</p>
<pre><code><span>#!/bin/sh</span>
npx eslint --max-warnings=0 src api/src || {
  <span>echo</span> <span>"ESLint check failed. Commit aborted."</span>
  <span>exit</span> 1
}

<span>cd</span> ./api &amp;&amp; npx jest || {
  <span>echo</span> <span>"Tests failed. Commit aborted."</span>
  <span>exit</span> 1
}

<span>cd</span> .. &amp;&amp; npx prettier --write .
git update-index --again
</code></pre>
<h2 id="heading-in-a-nutshell">In a nutshell</h2>
<p>There are many things you could do to improve your code. But the things that I mentioned are not even hard to implement. Especially now with LLM’s the problem is that you are bored to do them not that you can’t.</p>
<p>Throw boredom out of the window and you will get many blessings. Start coding with love and not for money. If you do that, you will make more money, make your co-workers happy and your managers will thank you.</p>
<h3 id="heading-because-coding-is-not-writing-it-is-architecture"><em>Because Coding is not writing, it is Αrchitecture.</em></h3>
<p>Thanks for reading, and I hope you found this article helpful. If you have any questions, feel free to email me at <a target="_blank" href="mailto:x@sotergreco.com"><strong>x@sotergreco.com</strong></a><strong>, and I will respond.</strong></p>
<p>You can also keep up with my latest updates by checking out my X here: <a target="_blank" href="http://x.com/sotergreco"><strong>x.com/sotergreco</strong></a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omega-3 intake counteracts symptoms of anxiety and depression in mice (232 pts)]]></title>
            <link>https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</link>
            <guid>41610619</guid>
            <pubDate>Sat, 21 Sep 2024 15:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/">https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</a>, See on <a href="https://news.ycombinator.com/item?id=41610619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="psypo-463511331"><p><a href="https://news.google.com/publications/CAAqBwgKMLz2gwsw-5CAAw" aria-label="Follow PsyPost on Google News"><img decoding="async" src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" data-src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" alt="Follow PsyPost on Google News" data-srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w" data-sizes="(max-width: 510px) 100vw, 510px" width="250" height="85" srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w"></a></p></div><p>A study on mice found that adding omega-3 polyunsaturated fatty acids to their diets effectively counteracts depressive and anxiety-like behaviors induced by stress. Not only did the supplementation reduce these stress-induced symptoms, but it also lowered anxiety levels in mice that were not exposed to stress. These findings, published in <a href="https://www.sciencedirect.com/science/article/pii/S2352289524000420"><em>Neurobiology of Stress</em></a>, suggest that omega-3 fatty acids may have protective mental health benefits.</p><p>Omega-3 polyunsaturated fatty acids are essential fats that the body cannot produce, meaning they must be obtained through food. There are three main types of omega-3s: alpha-linolenic acid (ALA), found in plant oils, and eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), primarily found in fish and seafood. These fats play a key role in maintaining brain function, preserving the integrity of cell membranes, and reducing inflammation throughout the body.</p><p>Omega-3s are widely recognized for their cardiovascular benefits, such as lowering blood pressure and reducing the risk of heart disease. They are equally important for mental health. Research indicates that omega-3s may alleviate symptoms of depression and anxiety, likely due to their anti-inflammatory properties and their role in maintaining brain health.</p><p>Several recent rodent studies have shown that incorporating these fatty acids into the diet can help counteract some of the negative effects of chronic stress, particularly during critical developmental periods. Omega-3s are most abundant in fatty fish like salmon and tuna, as well as in plant sources such as flaxseeds, walnuts, and chia seeds.</p><p>Study author Tatyana Strekalova and her colleagues wanted to explore whether exposing young mice to prolonged stress would induce behaviors similar to anxiety and depression in humans, and if supplementing the diet with omega-3 fatty acids would help prevent the development of these symptoms. Chronic stress was induced through exposure to ultrasound frequencies, simulating emotional stress that could lead to depressive-like symptoms. This method is an established way to model stress-induced depression in animals, which is used to better understand how these conditions develop in humans.</p><p>The experiments were conducted using 40 C57BL/6 male mice, each one month old. This strain of mice is commonly used in research because of their genetic uniformity and their susceptibility to diet-related conditions, such as obesity and diabetes. They are frequently used in studies on neurobiology, immunology, and cancer, making them ideal for this experiment. The mice were housed individually, with unlimited access to food and water.</p><p>The researchers divided the mice into four groups of ten. One group served as a control and received a regular diet without exposure to stress. The second group was subjected to chronic stress in the form of unpredictable ultrasound frequencies for 21 days, without any dietary supplementation. The third group received omega-3 fatty acids in their diet but was not exposed to stress. The fourth group was both exposed to stress and given the omega-3 supplement. The supplement included 0.55 mg/kg/day each of EPA and DHA, matching the recommended dosage of omega-3s for humans, scaled appropriately for mice.</p><p>After the 21-day period of stress exposure, the mice underwent several behavioral tests designed to measure symptoms analogous to human depression and anxiety. These tests included the sucrose preference test, which assesses anhedonia (the loss of interest in pleasurable activities), the novel cage test, the dark-light box test, and the open field test, which measure anxiety and exploratory behaviors. Once the behavioral tests were completed, the mice were killed, and their blood and tissues were analyzed to assess the biological effects of stress and omega-3 supplementation.</p><p>Mice that were exposed to ultrasound stress but received no dietary supplements showed significant anxiety- and depression-like behaviors. They displayed reduced sucrose consumption, indicating anhedonia, and exhibited less exploratory behavior in the tests. Furthermore, their blood samples revealed elevated levels of corticosterone, a hormone linked to stress responses.</p><p>The researchers also detected increased expression of TNF and interleukin-1 beta (IL-1β) genes in the brain, both of which are markers of inflammation. Inflammation in the brain is associated with various neurological disorders and can exacerbate conditions like depression and anxiety. The enhanced gene expression suggests that chronic stress had triggered an inflammatory response in these mice, leading to changes in their brain function and behavior.</p><p>In contrast, the mice that were exposed to stress but received omega-3 supplementation did not show the same degree of behavioral and physiological changes. They continued to drink sucrose, indicating they were less affected by stress-induced anhedonia, and they explored their environment more freely during the tests. Their levels of corticosterone and inflammatory markers, including TNF and IL-1β, were also lower than those in the stressed mice without supplementation.</p><p>These findings suggest that omega-3 fatty acids may protect against the harmful effects of chronic stress by reducing inflammation in the brain. Interestingly, even the mice that were not exposed to stress but received omega-3 supplements showed fewer anxiety-like behaviors compared to the control group, highlighting the broad mental health benefits of these fatty acids.</p><p>“Chronic omega-3 intake counteracted depressive- and anxiety-like behaviors in a US model of juvenile depression in mice [mice exposed to chronic stress as juveniles using ultrasound]. These effects likely stem from the anti-inflammatory properties of the supplement, suggesting potential therapeutic applications in juvenile depression,” the study authors concluded.</p><p>The study demonstrates the protective effects of omega-3 fatty acid supplements in mice exposed to chronic stress. However, it should be emphasized that this study was done on mice, not on humans. While mice and humans share many physiological similarities, there are significant differences between the two species. The effects observed in this study may not necessarily translate directly to human patients, and further research is needed to confirm whether omega-3 supplements would have the same benefits in people.</p><p>The paper, “<a href="https://doi.org/10.1016/j.ynstr.2024.100646">Omega-3 alleviates behavioral and molecular changes in a mouse model of stress-induced juvenile depression,</a>” was authored by Tatyana Strekalova, Daniel Radford-Smith, Isobel K. Dunstan, Anna Gorlova, Evgeniy Svirin, Elisaveta Sheveleva, Alisa Burova, Sergey Morozov, Aleksey Lyundup, Gregor Berger, Daniel C. Anthony, and Susanne Walitza.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling up linear programming with PDLP (163 pts)]]></title>
            <link>https://research.google/blog/scaling-up-linear-programming-with-pdlp/</link>
            <guid>41609670</guid>
            <pubDate>Sat, 21 Sep 2024 12:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/scaling-up-linear-programming-with-pdlp/">https://research.google/blog/scaling-up-linear-programming-with-pdlp/</a>, See on <a href="https://news.ycombinator.com/item?id=41609670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20240920">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="vflng">Classic <a href="https://en.wikipedia.org/wiki/Linear_programming" target="_blank" rel="noopener noreferrer">linear programming</a> (LP) problems are one of the most foundational problems in computer science and operations research. With extensive applications across numerous sectors of the global economy, such as manufacturing, networking, and other fields, LP has been the cornerstone of mathematical programming and has significantly influenced the development of today’s sophisticated modeling and algorithmic frameworks for data-driven decision making. If there's something to optimize, there's a good chance LP is involved.</p><p data-block-key="c5c0o">Since the late 1940s, LP solving has evolved significantly, with the <a href="https://en.wikipedia.org/wiki/Simplex_algorithm" target="_blank" rel="noopener noreferrer">simplex method</a> by Dantzig and various <a href="https://en.wikipedia.org/wiki/Interior-point_method" target="_blank" rel="noopener noreferrer">interior-point methods</a> being the most prevalent techniques. Today's advanced commercial LP solvers utilize these methods but face challenges in scaling to very large instances due to computational demands. In response to this limitation, <a href="https://en.wikipedia.org/wiki/Category:First_order_methods" target="_blank" rel="noopener noreferrer">first-order methods</a> (FOMs) have gained traction for large-scale LP problems.</p><p data-block-key="3ip58">With the above in mind, we introduce our solver PDLP (<a href="https://link.springer.com/article/10.1007/s10851-010-0251-1" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> enhanced for LP), a new FOM–based LP solver that significantly scales up our LP solving capabilities. Utilizing <a href="https://en.wikipedia.org/wiki/Matrix_multiplication#Definitions" target="_blank" rel="noopener noreferrer">matrix-vector multiplication</a> rather than <a href="https://en.wikipedia.org/wiki/Matrix_decomposition" target="_blank" rel="noopener noreferrer">matrix factorization</a>, PDLP requires less memory and is more compatible with modern computational technologies like GPUs and distributed systems, offering a scalable alternative that mitigates the memory and computational inefficiencies of traditional LP methods. PDLP is open-sourced in Google’s <a href="https://github.com/google/or-tools" target="_blank" rel="noopener noreferrer">OR-Tools</a>. This project has been in development since 2018 [<a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://epubs.siam.org/doi/full/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">3</a>], and we are proud to announce that it was co-awarded the prestigious <a href="https://www.mathopt.org/?nav=boh" target="_blank" rel="noopener noreferrer">Beale — Orchard-Hays Prize</a> at the <a href="https://ismp2024.gerad.ca/" target="_blank" rel="noopener noreferrer">International Symposium of Mathematical Programming</a> in July 2024. This accolade is one of the highest honors in the field of computational optimization, awarded every three years by the <a href="https://www.mathopt.org/" target="_blank" rel="noopener noreferrer">Mathematical Optimization Society</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">LP and first-order methods for LP</h2><p data-block-key="covcv">Scaling the methods used in today’s state of the art LP solvers presents significant challenges. The primary computational limitations for both methods relate to matrix factorization required for solving linear equations, introducing two key challenges as problem sizes grow:</p><ol><li data-block-key="ekud4"><i>Memory overflows:</i> LP solvers that use the simplex method (such as Google's <a href="https://en.wikipedia.org/wiki/GLOP" target="_blank" rel="noopener noreferrer">GLOP</a>) employ <a href="https://en.wikipedia.org/wiki/LU_decomposition" target="_blank" rel="noopener noreferrer">LU factorization</a>, and solvers that use the interior point method use <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition" target="_blank" rel="noopener noreferrer">Cholesky factorization</a>. For both these methods the resulting factorization uses considerably more memory than the LP instance itself.</li><li data-block-key="3dv18"><i>Hardware-related challenges:</i> Both methods face difficulties leveraging modern computing architectures, such as GPUs or distributed systems, because the sparse matrix factorization step usually requires highly sequential operations.</li></ol><p data-block-key="3ac05">Given the above limitations associated with traditional LP methods, FOMs have emerged as a promising alternative for tackling large-scale LP problems. Unlike methods that rely on matrix factorization, FOMs utilize gradient information to iteratively update their solutions, with the primary computational requirement being matrix-vector multiplication. This distinction means that FOMs require only the storage of the LP instance itself, without needing additional memory to store factorized forms. Additionally, advances in FOMs for machine learning and deep learning have enhanced their scalability, <a href="https://arxiv.org/abs/1606.04838" target="_blank" rel="noopener noreferrer">making them highly efficient</a> on modern computing platforms such as GPUs and distributed computing. This scalability and reduced memory dependency make FOMs particularly suitable for large and complex LP tasks where traditional methods may falter.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">Restarted primal-dual hybrid gradient for LP</h2><p data-block-key="a2f41"><a href="https://optimization-online.org/2010/06/2646/" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> (PDHG) is widely recognized for its application in image processing. When applied to LP, PDHG's primary computational demand involves matrix-vector multiplication, eliminating the need for matrix factorizations. This makes PDHG particularly efficient for large-scale computational tasks, but it is not reliable in solving LP. For example, in a benchmark of 383 instances, PDHG can only solve <a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">113 instances to moderate accuracy</a>.</p><p data-block-key="4m87g">To enhance PDHG’s reliability in solving LP problems, we have developed a modified approach called <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">restarted PDHG</a>. This version uses a two-loop structure where PDHG is run until a restarting condition is triggered, after which the average of the PDHG iterations is computed. The algorithm then restarts from this average point. This approach is visualized below where the trajectory of the standard PDHG is depicted with a blue line, the average iteration with a red line, and the restarted PDHG with a green line. Notably, the restarted PDHG shows a quicker convergence to the optimal solution, marked by a star on the plot.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="qp0k3">The intuition behind this faster convergence is that by restarting from the computed average at the end of each spiral phase, the restarted PDHG effectively shortens the path to convergence. This strategy leverages the cyclical nature of the PDHG spirals to expedite the solution process.</p><p data-block-key="e8fdh">We show in <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">our research</a> that this restarting technique can significantly speed up the convergence behaviors of PDHG for LP both in theory and in practice. This establishes restarted PDHG as a highly efficient and theoretically sound method for tackling LP challenges, reinforcing its utility and effectiveness in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">PDLP</h2><p data-block-key="6ptml">We designed <a href="https://developers.google.com/optimization/lp/pdlp_math" target="_blank" rel="noopener noreferrer">PDLP</a> as a software package that can solve linear programming problems efficiently. The core algorithm of PDLP is based on the restarted PDHG, which we have enhanced significantly through five improvements:</p><ul><li data-block-key="336v2"><i>Presolving</i>: This process simplifies the LP problem before solving. It involves detecting inconsistent bounds, detecting duplicate rows, tightening bounds, etc. These steps reduce complexity and improve the efficiency of the solver.</li><li data-block-key="60lg4"><i>Preconditioning</i>: A preconditioner in PDLP rescales variables and constraints within the LP instance. This adjustment helps speed up the algorithm by optimizing the numerical condition of the problem, thereby enhancing convergence rates.</li><li data-block-key="fo387"><i>Infeasibility detection</i>: In real-world scenarios, LP problems may often be infeasible or unbounded. Our approach utilizes the iterates of PDHG, which encodes information about the problem's feasibility and boundedness, allowing for detection without extra computational effort. The theory of this method is detailed in <a href="https://epubs.siam.org/doi/abs/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">our SIAM Journal paper</a>.</li><li data-block-key="6ubbl"><i>Adaptive restarts</i>: This technique involves strategically deciding when to optimally restart the PDHG algorithm to enhance its efficiency, particularly speeding up the convergence to a high-accuracy solution.</li><li data-block-key="6u9l9"><i>Adaptive step-size</i>: We introduced an adaptive method for selecting the step-size in the PDHG, which significantly reduces the need for manual tuning. This approach adjusts the step-size dynamically based on the problem's characteristics and the algorithm's performance, promoting faster convergence.</li></ul><p data-block-key="8lct3">PDLP is open-sourced as part of Google’s <a href="https://developers.google.com/optimization" target="_blank" rel="noopener noreferrer">OR-Tools</a>, an open-source software suite for optimization. The solver is easy to use and it has interfaces in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" target="_blank" rel="noopener noreferrer">Python</a>, <a href="https://en.wikipedia.org/wiki/C%2B%2B" target="_blank" rel="noopener noreferrer">C++</a>, <a href="https://en.wikipedia.org/wiki/Java_(programming_language)" target="_blank" rel="noopener noreferrer">Java</a> and <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" target="_blank" rel="noopener noreferrer">C#</a>. More details and examples on how to use PDLP can be found in the <a href="https://developers.google.com/optimization/lp/lp_example" target="_blank" rel="noopener noreferrer">OR-Tools documentation</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Applications</h2><p data-block-key="56kp2">Scaling up and speeding up LP enables new applications — here, we briefly mention three:</p><ol><li data-block-key="6f59p"><i>Data center network traffic engineering (</i><a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network" target="_blank" rel="noopener noreferrer"><i>blog post</i></a><i>,</i> <a href="https://research.google/pubs/jupiter-evolving-transforming-googles-datacenter-network-via-optical-circuit-switches-and-software-defined-networking/"><i>paper</i></a><i>):</i> Google's data centers rely on dynamically optimized traffic engineering for high-performance efficiency. The challenge of optimizing network traffic routing is periodically addressed as a large-scale LP problem. Previously, solving this large problem fast enough was not possible, leading to the development of partition heuristics. These heuristics decomposed the problem into many smaller-scale LPs that could be solved concurrently, albeit at the cost of optimality. With the introduction of PDLP, we can now efficiently optimize traffic routing across an entire data center network, effectively saving a significant amount of machine resources across the network. This solution has been deployed in Google's production environment since May 2023.</li><li data-block-key="a199v"><i>Container shipping optimization (</i><a href="https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/"><i>blog post</i></a><i>):</i> The world's shipping supply chain relies on optimizing the order in which vessels visit ports and the placement of containers on those vessels. Due to the extreme scale of real-world instances, a direct solution often is intractable. Consequently, various heuristic approaches have been proposed to enhance efficiency and practicality in solving this complex optimization problem. The problem can be formulated as a type of optimization problem called a massive integer two-layer <a href="https://en.wikipedia.org/wiki/Multi-commodity_flow_problem" target="_blank" rel="noopener noreferrer">multi-commodity flow problem</a>. PDLP enables solving the linear relaxation of this formulation, quantifying the quality of the heuristics.</li><li data-block-key="bii5j"><i>Traveling salesman problem:</i> The <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem" target="_blank" rel="noopener noreferrer">traveling salesman problem</a> (TSP) poses a classic question: given a list of cities and their distances, what's the shortest route that visits every city once and returns to the starting point? This problem is notoriously challenging, holding significant importance in theoretical computer science and operations research. PDLP has <a href="https://research.google/blog/google-research-2022-beyond-algorithmic-advances/">demonstrated its power</a> by solving real-world TSP lower bound LP instances of immense scale, encompassing up to 12 billion non-zero entries in the constraint matrix. This capability far surpasses the capacity of even the most advanced commercial solvers available today, showcasing PDLP's potential for tackling large-scale LP challenges.</li></ol>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Broader impacts</h2><p data-block-key="947n">Since its initial release, PDLP has attracted significant interest, leading to further enhancements. Here are some notable developments: <a href="https://github.com/jinwen-yang/cuPDLP.jl" target="_blank" rel="noopener noreferrer">cuPDLP.jl</a> is an open-sourced GPU implementation of PDLP, written in <a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">Julia</a>. The commercial solver company, <a href="https://www.copt.de/" target="_blank" rel="noopener noreferrer">Cardinal Optimizer</a>, has incorporated PDLP into their software in <a href="https://github.com/COPT-Public/COPT-Release" target="_blank" rel="noopener noreferrer">Version 7.1</a> in January 2024. The open-source solver, <a href="https://highs.dev/" target="_blank" rel="noopener noreferrer">HiGHS</a>, has incorporated a version of PDLP in their software in <a href="https://conan.io/center/recipes/highs" target="_blank" rel="noopener noreferrer">V1.7.0</a> in March 2024. In addition, the academic community has continued to explore and expand upon the theoretical foundations of PDLP. Recent studies have focused on areas such as <a href="https://arxiv.org/pdf/2206.12061" target="_blank" rel="noopener noreferrer">new analysis on PDHG</a>, <a href="https://arxiv.org/pdf/2312.14774" target="_blank" rel="noopener noreferrer">condition number theory</a>, <a href="https://arxiv.org/pdf/2307.03664v2" target="_blank" rel="noopener noreferrer">trajectory-based analysis</a>, extensions to <a href="https://arxiv.org/pdf/2311.07710" target="_blank" rel="noopener noreferrer">quadratic programming</a> and <a href="https://arxiv.org/pdf/2402.00311" target="_blank" rel="noopener noreferrer">semi-definite programming</a>, etc. These efforts not only deepen the understanding of PDLP's underlying mechanics but also explore its potential applications to more complex problems. These developments reflect PDLP's significant impact on the field of optimization, bridging the gap between theoretical research and practical application. As PDLP continues to evolve, its influence is expected to grow, pushing the boundaries of what can be achieved in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Acknowledgments</h2><p data-block-key="e8dq7"><i>We are grateful to our co-authors Mateo Diaz, Oliver Hinder, Miles Lubin, and Warren Schudy for their exceptional support and contributions. We would also like to thank our managers, Vahab Mirrokni, Jon Orwant and Aaron Archer, and our collaborators in the Data Center Networking team, the Algorithm team and the Operations Research team.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Forget ChatGPT: why researchers now run small AIs on their laptops (506 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-02998-y</link>
            <guid>41609393</guid>
            <pubDate>Sat, 21 Sep 2024 11:52:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-02998-y">https://www.nature.com/articles/d41586-024-02998-y</a>, See on <a href="https://news.ycombinator.com/item?id=41609393">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>The website histo.fyi is a database of structures of immune-system proteins called major histocompatibility complex (MHC) molecules. It includes images, data tables and amino-acid sequences, and is run by bioinformatician Chris Thorpe, who uses artificial intelligence (AI) tools called large language models (LLMs) to convert those assets into readable summaries. But he doesn’t use ChatGPT, or any other web-based LLM. Instead, Thorpe runs the AI on his laptop.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02630-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27689164.jpg"><p>Chatbots in science: What can ChatGPT do for you?</p></a>
 </article><p>Over the past couple of years, chatbots based on LLMs have won praise for their ability to write poetry or engage in conversations. Some LLMs have hundreds of billions of parameters — the more parameters, the greater the complexity — and can be accessed only online. But two more recent trends have blossomed. First, organizations are making ‘open weights’ versions of LLMs, in which the weights and biases used to train a model are publicly available, so that users can download and run them locally, if they have the computing power. Second, technology firms are making scaled-down versions that can be run on consumer hardware — and that rival the performance of older, larger models.</p><p>Researchers might use such tools to save money, protect the confidentiality of patients or corporations, or ensure reproducibility. Thorpe, who’s based in Oxford, UK, and works at the European Molecular Biology Laboratory’s European Bioinformatics Institute in Hinxton, UK, is just one of many researchers exploring what the tools can do. That trend is likely to grow, Thorpe says. As computers get faster and models become more efficient, people will increasingly have AIs running on their laptops or mobile devices for all but the most intensive needs. Scientists will finally have AI assistants at their fingertips — but the actual algorithms, not just remote access to them.</p><h2><b>Big things in small packages</b></h2><p>Several large tech firms and research institutes have released small and open-weights models over the past few years, including Google DeepMind in London; Meta in Menlo Park, California; and the Allen Institute for Artificial Intelligence in Seattle, Washington (see ‘Some small open-weights models’). (‘Small’ is relative — these models can contain some 30 billion parameters, which is large by comparison with earlier models.)</p><p>Although the California tech firm OpenAI hasn’t open-weighted its current GPT models, its partner Microsoft in Redmond, Washington, has been on a spree, releasing the small language models Phi-1, Phi-1.5 and Phi-2 in 2023, then four versions of Phi-3 and three versions of Phi-3.5 this year. The Phi-3 and Phi-3.5 models have between 3.8 billion and 14 billion active parameters, and two models (Phi-3-vision and Phi-3.5-vision) handle images<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>. By some benchmarks, even the smallest Phi model outperforms OpenAI’s GPT-3.5 Turbo from 2023, rumoured to have 20 billion parameters.</p><p>Sébastien Bubeck, Microsoft’s vice-president for generative AI, attributes Phi-3’s performance to its training data set. LLMs initially train by predicting the next ‘token’ (iota of text) in long text strings. To predict the name of the killer at the end of a murder mystery, for instance, an AI needs to ‘understand’ everything that came before, but such consequential predictions are rare in most text. To get around this problem, Microsoft used LLMs to write millions of short stories and textbooks in which one thing builds on another. The result of training on this text, Bubeck says, is a model that fits on a mobile phone but has the power of the initial 2022 version of ChatGPT. “If you are able to craft a data set that is very rich in those reasoning tokens, then the signal will be much richer,” he says.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02386-6" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27484538.png"><p>ChatGPT for science: how to talk to your data</p></a>
 </article><p>Phi-3 can also help with routing — deciding whether a query should go to a larger model. “That’s a place where Phi-3 is going to shine,” Bubeck says. Small models can also help scientists in remote regions that have little cloud connectivity. “Here in the Pacific Northwest, we have amazing places to hike, and sometimes I just don’t have network,” he says. “And maybe I want to take a picture of some flower and ask my AI some information about it.”</p><p>Researchers can build on these tools to create custom applications. The Chinese e-commerce site Alibaba, for instance, has built models called Qwen with 500 million to 72 billion parameters. A biomedical scientist in New Hampshire fine-tuned the largest Qwen model using scientific data to create Turbcat-72b, which is available on the model-sharing site Hugging Face. (The researcher goes only by the name Kal’tsit on the Discord messaging platform, because AI-assisted work in science is still controversial.) Kal’tsit says she created the model to help researchers to brainstorm, proof manuscripts, prototype code and summarize published papers; the model has been downloaded thousands of times.</p><h2><b>Preserving privacy</b></h2><p>Beyond the ability to fine-tune open models for focused applications, Kal’tsit says, another advantage of local models is privacy. Sending personally identifiable data to a commercial service could run foul of data-protection regulations. “If an audit were to happen and you show them you’re using ChatGPT, the situation could become pretty nasty,” she says.</p><p>Cyril Zakka, a physician who leads the health team at Hugging Face, uses local models to generate training data for other models (which are sometimes local, too). In one project, he uses them to extract diagnoses from medical reports so that another model can learn to predict those diagnoses on the basis of echocardiograms, which are used to monitor heart disease. In another, he uses the models to generate questions and answers from medical textbooks to test other models. “We are paving the way towards fully autonomous surgery,” he explains. A robot trained to answer questions would be able to communicate better with doctors.</p><p>Zakka uses local models — he prefers Mistral 7B, released by the tech firm Mistral AI in Paris, or Meta’s Llama-3 70B — because they’re cheaper than subscription services such as ChatGPT Plus, and because he can fine-tune them. But privacy is also key, because he’s not allowed to send patients’ medical records to commercial AI services.</p><article data-label="Related">
  <a href="https://www.nature.com/articles/d41586-024-02185-z" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_27488412.jpg"><p>Inside the maths that drives AI</p></a>
 </article><p>Johnson Thomas, an endocrinologist at the health system Mercy in Springfield, Missouri, is likewise motivated by patient privacy. Clinicians rarely have time to transcribe and summarize patient interviews, but most commercial services that use AI to do so are either too expensive or not approved to handle private medical data. So, Thomas is developing an alternative. Based on Whisper — an open-weight speech-recognition model from OpenAI — and on Gemma 2 from Google DeepMind, the system will allow physicians to transcribe conversations and convert them to medical notes, and also summarize data from medical-research participants.</p><p>Privacy is also a consideration in industry. CELLama, developed at the South Korean pharmaceutical company Portrai in Seoul, exploits local LLMs such as Llama 3.1 to reduce information about a cell’s gene expression and other characteristics to a summary sentence<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. It then creates a numerical representation of this sentence, which can be used to cluster cells into types. The developers highlight privacy as one advantage on their GitHub page, noting that <a href="https://github.com/CelVoxes/ceLLama" data-track="click" data-label="https://github.com/CelVoxes/ceLLama" data-track-category="body text link">CELLama</a> “operates locally, ensuring no data leaks”.</p><h2><b>Putting models to good use</b></h2><p>As the LLM landscape evolves, scientists face a fast-changing menu of options. “I’m still at the tinkering, playing stage of using LLMs locally,” Thorpe says. He tried ChatGPT, but felt it was expensive, and the tone of its output wasn’t right. Now he uses Llama locally, with either 8 billion or 70 billion parameters, both of which can run on his Mac laptop.</p><p>Another benefit, Thorpe says, is that local models don’t change. Commercial developers, by contrast, can update their models at any moment, leading to different outputs and forcing Thorpe to alter his prompts or templates. “In most of science, you want things that are reproducible,” he explains. “And it’s always a worry if you’re not in control of the reproducibility of what you’re generating.”</p><p>For another project, Thorpe is writing code that aligns MHC molecules on the basis of their 3D structure. To develop and test his algorithms, he needs lots of diverse proteins — more than exist naturally. To design plausible new proteins, he uses <a href="https://huggingface.co/nferruz/ProtGPT2" data-track="click" data-label="https://huggingface.co/nferruz/ProtGPT2" data-track-category="body text link">ProtGPT2</a>, an open-weights model with 738 million parameters that was trained on about 50 million sequences<sup><a href="#ref-CR3" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">3</a></sup>.</p><p>Sometimes, however, a local app won’t do. For coding, Thorpe uses the cloud-based GitHub Copilot as a partner. “It kind of feels like my arm’s chopped off when for some reason I can’t actually use Copilot,” he says. Local LLM-based coding tools do exist (such as Google DeepMind’s <a href="https://huggingface.co/google/codegemma-7b" data-track="click" data-label="https://huggingface.co/google/codegemma-7b" data-track-category="body text link">CodeGemma</a> and one from California-based developers <a href="https://docs.continue.dev/intro" data-track="click" data-label="https://docs.continue.dev/intro" data-track-category="body text link">Continue</a>), but in his experience they can’t compete with Copilot.</p><h2><b>Access points</b></h2><p>So, how do you run a local LLM? Software called <a href="https://ollama.com/" data-track="click" data-label="https://ollama.com/" data-track-category="body text link">Ollama</a> (available for Mac, Windows and Linux operating systems) lets users download open models, including Llama 3.1, Phi-3, Mistral and Gemma 2, and access them through a command line. Other options include the cross-platform app <a href="https://www.nomic.ai/gpt4all" data-track="click" data-label="https://www.nomic.ai/gpt4all" data-track-category="body text link">GPT4All</a> and <a href="https://github.com/Mozilla-Ocho/llamafile" data-track="click" data-label="https://github.com/Mozilla-Ocho/llamafile" data-track-category="body text link">Llamafile</a>, which can transform LLMs into a single file that runs on any of six operating systems, with or without a graphics processing unit.</p><article data-label="Related">
  <a href="https://www.nature.com/collections/fxvqrpnlcq" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-02998-y/d41586-024-02998-y_16573690.jpg"><p>NatureTech hub</p></a>
 </article><p>Sharon Machlis, a former editor at the website InfoWorld, who lives in Framingham, Massachusetts, wrote <a href="https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html" data-track="click" data-label="https://www.infoworld.com/article/2338922/5-easy-ways-to-run-an-llm-locally.html" data-track-category="body text link">a guide to using LLMs locally</a>, covering a dozen options. “The first thing I would suggest,” she says, “is to have the software you choose fit your level of how much you want to fiddle.” Some people prefer the ease of apps, whereas others prefer the flexibility of the command line.</p><p>Whichever approach you choose, local LLMs should soon be good enough for most applications, says Stephen Hood, who heads open-source AI at the tech firm Mozilla in San Francisco. “The rate of progress on those over the past year has been astounding,” he says.</p><p>As for what those applications might be, that’s for users to decide. “Don’t be afraid to get your hands dirty,” Zakka says. “You might be pleasantly surprised by the results.”</p>
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Collapse of Self-Worth in the Digital Age (196 pts)]]></title>
            <link>https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/</link>
            <guid>41609099</guid>
            <pubDate>Sat, 21 Sep 2024 10:48:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/">https://thewalrus.ca/collapse-of-self-worth-in-the-digital-age/</a>, See on <a href="https://news.ycombinator.com/item?id=41609099">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-170627">

	
	
	
	<div>
		<!-- Ad-Auris -->
		
		<p><span>W</span><span>hen I was twelve,</span> I used to roller-skate in circles for hours. I was at another new school, the odd man out, bullied by my desk mate. My problems were too complex and modern to explain. So I skated across parking lots, breezeways, and sidewalks, I listened to the vibration of my wheels on brick, I learned the names of flowers, I put deserted paths to use. I decided for myself each curve I took, and by the time I rolled home, I felt lighter. One Saturday, a friend invited me to roller-skate in the park. I can still picture her in green protective knee pads, flying past. I couldn’t catch up, I had no technique. There existed another scale to evaluate roller skating, beyond joy, and as Rollerbladers and cyclists overtook me, it eclipsed my own. Soon after, I stopped skating. </p>

<p><span>Y</span><span>ears ago,</span> I worked in the backroom of a Tower Records. Every few hours, my face-pierced, gunk-haired co-workers would line up by my workstation, waiting to clock in or out. When we typed in our staff number at 8:59 p.m., we were off time, returned to ourselves, free like smoke.</p>
<p>There are no words to describe the opposite sensations of being at-our-job and being not-at-our-job even if we know the feeling of crossing that threshold by heart. But the most essential quality that makes a job a job is that when we are at work, we surrender the power to decide the worth of what we do. At-job is where our labour is appraised by an external meter: the market. At-job, our labour is never a means to itself but a means to money; its value can be expressed only as a number—relative, fluctuating, out of our control. At-job, because an outside eye measures us, the workplace is a place of surveillance. It’s painful to have your sense of worth extracted. For Marx, the poet of economics, when a person’s innate value is replaced with exchange value, it is as if we’ve been reduced to “a mere jelly.” </p>

<p>Not-job, or whatever name you prefer—“quitting time,” “off duty,” “downtime”—is where we restore ourselves from a mere jelly, precisely by using our internal meter to determine the criteria for success or failure. Find the best route home—not the one that optimizes cost per minute but the one that offers time enough to hear an album from start to finish. Plant a window garden, and if the plants are half dead, try again. My brother-in-law found a toy loom in his neighbour’s garbage, and nightly he weaves tiny technicolour rugs. We do these activities for the sake of doing them, and their value can’t be arrived at through an outside, top-down measure. It would be nonsensical to treat them as comparable and rank them from one to five. We can assess them only by privately and carefully attending to what they contain and, on our own, concluding their merit. </p>
<p>And so artmaking—the cultural industries—occupies the middle of an uneasy Venn diagram. First, the value of an artwork is internal—how well does it fulfill the vision that inspired it? Second, a piece of art is its own end. Third, a piece of art is, by definition, rare, one of a kind, nonfungible. </p>

<p>Yet the end point for the working artist is to create an object for sale. Once the art object enters the market, art’s intrinsic value is emptied out, compacted by the market’s logic of ranking, until there’s only relational worth, no interior worth. Two novelists I know publish essays one week apart; in a grim coincidence, each writer recounts their own version of the same traumatic life event. Which essay is better, a friend asks. I explain they’re different; different life circumstances likely shaped separate approaches. Yes, she says, but which one is <em>better</em>?</p>
<p><span>I</span><span>grew up</span> a Catholic, a faithful, an anachronism to my friends. I carried my faith until my twenties, when it finally broke. Once I couldn’t gain comfort from religion anymore, I got it from writing. Sitting and building stories, side by side with millions of other storytellers who have endeavoured since the dawn of existence to forge meaning even as reality proves endlessly senseless, is the nearest thing to what it felt like back when I was a believer.</p>
<p>I spent my thirties writing a novel and paying the bills as low-paid part-time faculty at three different colleges. I could’ve studied law or learned to code. Instead, I manufactured sentences. Looking back, it baffles me that I had the wherewithal to commit to a project with no guaranteed financial value, as if I was under an enchantment. Working on that novel was like visiting a little town every day for four years, a place so dear and sweet. Then I sold it.</p>
<p>As the publication date advanced, I was awash with extrinsic measures. Only twenty years ago, there was no public, complete data on book sales. Until the introduction of BookScan in the late ’90s, you just had to take an agent’s word for it. “The track record of an author was a contestable variable that was known to some, surmised by others, and always subject to exaggeration in the interests of inflating value,” says John B. Thompson in <em>Merchants of Culture</em>, his ethnography of contemporary publishing.</p>
<p>This is hard to imagine, now that we are inundated with cold, beautiful stats, some publicized by trade publications or broadcast by authors themselves on all socials. How many publishers bid? How big is the print run? How many stops on the tour? How many reviews on Goodreads? How many mentions on Bookstagram, BookTok? How many bloggers on the blog tour? How exponential is the growth in follower count? Preorders? How many printings? How many languages in translation? How many views on the unboxing? How many mentions on most-anticipated lists? I was glued to my numbers like a day trader.</p>

<p>I wanted to write my publicist to ask: Should I be worried my stats aren’t higher? The question blared constantly in my head: Did gambling years I could’ve been earning towards a house pay off? But I never did. I was too embarrassed. I had trained in the religion of art, and to pay mind to the reception of my work was to be a non-believer. During my fine arts degree, we heard again and again that <em>the only gauge for art is your own measure</em>, and when I started teaching writing, I’d preach the same thing. Ignore whatever publications or promotions friends gain; you’re on your own journey. It’s a purportedly anti-capitalist idea, but it repackages the artist’s concern for economic security as petty ego. My feelings—caring at all—broke code. Shame sublimated everything. </p>
<p>And when the reception started to roll in, I’d hear good news, but gratitude lasted moments before I wanted more. A starred review from <em>Publisher’s Weekly</em>, but I wasn’t in “Picks of the Week.” A mention from <em>Entertainment Weekly</em>, but last on a click-through list. Nothing was enough. Why? What had defined my adult existence was my ability to find worth within, to build to an internal schematic, which is what artists do. Now I was a stranger to myself. I tried to fix it with box breathing videos, podcasts, reading about <em>Anna Karenina</em>. My partner and I were trying for another baby, but cycles kept passing, my womb couldn’t grab the egg. A kind nurse at the walk-in said: <em>Sometimes your body is saying the time’s not right</em>. Mine was a bad place. </p>
<p>A few weeks after my book release, my friends and I and our little kids took a weekend vacation. They surprised me with a three-tiered cake matching my book cover, cradled on laps, from Toronto, through a five-hour traffic jam. In all the photos from that trip, I’m staring at my phone. I can hardly remember that summer.</p>
<p>My scale of worth had torn off, like a roof in a hurricane, replaced with an external one. An external scale is a relative scale; so of course, nothing’s enough. There is no top. </p>
<p>Then I was shortlisted for a major prize. It took me on a world tour, listed me alongside authors who are certifiable geniuses. I thought my endless accounting could stop, this had to be enough for me, I could get back to who I was. But I couldn’t. In London, I bought my two-year-old a bath toy, a little boat with a Beefeater. Today at bath time, the boat still gives me a sickly feeling, like it’s from the scene of a trauma. My centre was gone.</p>
<p><span>O</span><span>ne of at-job’s</span> defining qualities is how efficiently output is converted into a number. In 1994, Philip Agre described this as <a href="https://djp3.westmont.edu/classes/2017_01_CS195/readings/CaptureModelOfSurveillance.pdf" rel="noopener" target="_blank">the “capture model,”</a> or “the deliberate reorganization of industrial work activities to allow computers to track them in real time.” Gregory Sholette, the author of <em>Dark Matter: Art and Politics in the Age of Enterprise Culture</em>, describes how workers in a Pennsylvania factory spent their break covering a wall of the plant with “newspaper clippings, snapshots, spent soda cans, industrial debris, trashed food containers and similar bits and pieces.” They called it “Swampwall.” It reminds me of the sculpture on a high shelf in the back of a diner where I worked, composed of unusually shaped potatoes. Its form changed with each new tuber contributed by the cook on prep shift. </p>
<p>Such spontaneous projects are signs of life: physical evidence of the liberating fact that not all time at work can be measured or processed into productivity. Swampwall was inutile: a means to itself. It was allowed to flourish until the company was bought out by a global corporation, at which point the massive collaborative mural was “expunged.”</p>
<p>Thirty years after Agre coined the capture model, workforce management technology can track every moment at work as a production target. Amazon’s Units Per Hour score, Uber’s and Lyft’s (constantly shrivelling) base fares, and Domino’s Pizza Tracker have made it possible to time all time, even in the break room or toilet stall. These are extreme examples, but they’re echoed across the work world, with the datafication of parts of performance that used to be too baggy or obscure to crunch and so were ours to keep. “Wellness” apps provided as health benefits by corporate management that track fob swipes for office workers; case management software that counts advice by the piece for legal workers; shares, hover rate, and time on site that measure media workers; leaderboards for tech employees, ranking who worked longest. </p>
<p>There must exist professions that are free from capture, but I’m hard pressed to find them. Even non-remote jobs, where work cannot pursue the worker home, are dogged by digital tracking: a farmer says Instagram Story views directly correlate to farm subscriptions, a server tells me her manager won’t give her the Saturday-night money shift until she has more followers. Even religious guidance can be quantified by view counts for online church services, Yelp for spirituality. <a href="https://www.theguardian.com/world/2020/nov/10/ireland-catholic-priests-online-mass-reviews-causing-performance-anxiety" rel="noopener" target="_blank">One priest told the <em>Guardian</em></a>, “you have this thing about how many followers have you . . . it hits at your gut, at your heart.” </p>
<p>But we know all this. What we hardly talk about is how we’ve reorganized not just industrial activity but <em>any</em> activity to be capturable by computer, a radical expansion of what can be mined. Friendship is ground zero for the metrics of the inner world, the first unquantifiable shorn into data points: Friendster testimonials, the MySpace Top 8, friending. Likewise, the search for romance has been refigured by dating apps that sell paid-for rankings and paid access to “quality” matches. Or, if there’s an off-duty pursuit you love—giving tarot readings, polishing beach rocks—it’s a great compliment to say: “You should do that for money.” Join the passion economy, give the market final say on the value of your delights. Even engaging with art—say, encountering some uncanny reflection of yourself in a novel, or having a transformative epiphany from listening, on repeat, to the way that singer’s voice breaks over the bridge—can be spat out as a figure, on Goodreads or your Spotify year in review.  </p>

<p>And those ascetics who disavow all socials? They are still caught in the network. Acts of pure leisure—photographing a sidewalk cat with a camera app or watching a video on how to make a curry—are transmuted into data to grade how well the app or the creators’ deliverables are delivering. If we’re not being tallied, we affect the tally of others. We are all data workers.</p>
<p>Twenty years ago, anti-capitalist activists campaigned against ads posted in public bathroom stalls: too invasive, there needs to be a limit to capital’s reach. Now, ads by the toilet are quaint. Clocking out is obsolete when, in the deep quiet of our minds, we lack the pay grade to determine worth.</p>
<p><span>T</span><span>he internet</span> is designed to stop us from ever switching it off. It moves at the speed of light, with constantly changing metrics, fuelled by “‘ludic loops’ or repeated cycles of uncertainty, anticipation and feedback”—in other words, it works exactly like a Jackpot 6000 slot machine. (On a basic level, social media apps like Instagram operate like phone games. They’ve replaced classics like Snake or Candy Crush, except the game is your sense of self.)</p>
<p>The effect of gamification on artmaking has been dramatic. <a href="https://www.vox.com/culture/2024/2/1/24056883/tiktok-self-promotion-artist-career-how-to-build-following" rel="noopener" target="_blank">In Rebecca Jennings’s <em>Vox</em> long read</a> on the necessity of authorly self-promotion, she interviews William Deresiewicz, whose book <em>The Death of the Artist</em> breaks down the harsh conditions for artists seeking an income in the digital economy. Deresiewicz used to think “selling out”—using the most sacred parts of your life and values to shill for a brand—was “evil.” Yet this economy has made it so there’s “no choice” if you want a living. The very concept of selling out, he says, “has disappeared.” A few years ago, much was made of the fact that the novelist Sally Rooney had no Twitter account—this must explain her prolific output. But the logic is back to front: it’s only top-selling authors who can afford to forgo social media. Call it Deactivation Privilege. </p>
<p>It’s a privilege few of us can afford, if it’s the algorithm we need to impress rather than book reviewers of old. <a href="https://www.esquire.com/entertainment/books/a60924704/debut-fiction-challenges/" rel="noopener" target="_blank">In a nightmarish dispatch in <em>Esquire</em></a> on how hard it is for authors to find readers, Kate Dwyer argues that all authors must function like influencers now, which means a fire sale on your “private” life. As internet theorist Kyle Chayka puts it to Dwyer: “Influencers get attention by exposing parts of their life that have nothing to do with the production of culture.”</p>
<p>The self <em>is</em> the work, just ask Flaubert. But data collection’s ability to reduce the self to a figure—batted about by the fluctuations of its stock—is newly unbearable. There’s no way around it, and this self being sold alongside the work can be as painful for a writer of autofiction as it is for me, a writer of speculative fiction who invented an imaginary world. </p>
<p><span>I</span><span>tell you</span> all this not because I think we should all be very concerned about artists, but because what happens to artists is happening to all of us. As data collection technology hollows out our inner worlds, all of us experience the working artist’s plight: our lot is to numericize and monetize the most private and personal parts of our experience. </p>
<p>Certainly, smartphones could be too much technology for children, <a href="https://www.newyorker.com/news/the-new-yorker-interview/jonathan-haidt-wants-you-to-take-away-your-kids-phone" rel="noopener" target="_blank">as Jonathan Haidt argues</a>, and definitely, <a href="https://www.theguardian.com/books/2016/dec/26/the-attention-merchants-tim-wu-review" rel="noopener" target="_blank">as Tim Wu says</a>, attention is a commodity, but these ascendant theories of tech talk around the fact that something else deep inside, innermost, is being harvested too: our self-worth, or, rather, worthing. </p>
<p>We are not giving away our value, as a puritanical grandparent might scold; we are giving away our facility <em>to</em> value. We’ve been cored like apples, a dependency created, hooked on the public internet to tell us the worth. </p>
<p>Every notification ping holds the possibility we have merit. When we scroll, what are we looking for? </p>

<p><span>W</span><span>hen my eldest child</span> was in kindergarten, she loved to make art, but she detested the assignments that tried to make math fun by asking kids to draw. If I sat her down to complete one, she would stare rebelliously at her pencil or a strand of her hair rather than submit. Then one day, while drawing a group of five ants and a group of eight ants, my kindergartener started to sketch fast. She drew ants with bulbous limbs growing out of their bodies, like chains of sausages. “Bombombom!” she cried, flapping her arms up and down. “These are their muscles.” She continued to draw and mime pumping iron, giggling to herself, delighted to have planted something in her homework that couldn’t be accounted for in the metric of correct or incorrect. She had taken drawing back. </p>
<p><span>T</span><span>he ludic loop</span> of the internet has automated our inner worlds: we don’t have to choose what we like, or even if we like it; the algorithm chooses for us. Take Shein, the fast fashion leviathan. While other fast fashion brands wait for high-end houses to produce designs they can replicate cheaply, Shein has completely eclipsed the runway, using AI to trawl social media for cues on what to produce next. Shein’s site operates like a casino game, using “dark patterns”—a countdown clock puts a timer on an offer, pop-ups say there’s only one item left in stock, and the scroll of outfits never ends—so you buy now, ask if you want it later. </p>
<p>Shein’s model is dystopic: countless reports detail how it puts its workers in obscene poverty in order to sell a reprieve to consumers who are also moneyless—a saturated plush world lasting as long as the seams in one of their dresses. Yet the day to day of Shein’s target shopper is so bleak, we strain our moral character to cosplay a life of plenty. </p>
<p>Automation isn’t forced upon us: we crave it, oblivion, thanks to the tech itself. As the ascendant apparatus of the labour market, it’s squeezed already dire working conditions to a suffocation point, until all we desire is the sweet fugue of scroll, our decision maker set to “off.” </p>
<p><span>A</span><span>fter my novel</span> came out, whenever I met an author, I would ask, with increasing frenzy, how they managed the grisly experience of work going to market. I was comforted and horrified when everyone agreed it could be dispossessing. Then they all said the same thing: “I kept writing and I felt better.” That was the advice: keep writing. </p>
<p>The market is the only mechanism for a piece of art to reach a pair of loving eyes. Even at a museum or library, the market had a hand in homing the item there. I didn’t understand that seeking a reader for my story meant handing over my work in the same way I sold my car on Craigslist: it’s gone from me, fully, bodily, finally. Or, as Marx says, alienated. I hated that advice to keep writing, because if I wrote another book, I’d have to go through the cycle again: slap my self on the scale like a pair of pork chops again. Now, I realize the authors I met meant something else. Yes, sell this part of your inner life but then go back in there and reinflate what’s been emptied. It’s a renewable resource.  </p>
<p>When I grasp this, all of it becomes tolerable. It’s like letting out a line, then braiding more line. I can manage, because there’ll always be more line.  </p>
<p><span>I</span><span>will try to sell</span> this essay to a publication, and if successful, the publication will try to sell it to readers. If you are reading this, it’s a commodity now, fluctuating and fungible, like so much digital dust. </p>
<!-- AI CONTENT END 1 -->
		<div id="sexy_author_bio_widget-2"><p><a href="https://thewalrus.ca/author/thea-lim/" target="_top"><img alt="Thea Lim" src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%2070%2070'%3E%3C/svg%3E" data-src="https://secure.gravatar.com/avatar/a5dae45e6bea1e8e5104bdd5b15830f9?s=70&amp;d=mm&amp;r=pg" data-srcset="https://secure.gravatar.com/avatar/a5dae45e6bea1e8e5104bdd5b15830f9?s=140&amp;d=mm&amp;r=pg 2x" height="70" width="70"></a></p><p>Thea Lim is an author, a culture writer, and a creative writing teacher. Her most recent novel is <em>An Ocean of Minutes</em>.</p></div>	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

		
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ultra high-resolution image of The Night Watch (482 pts)]]></title>
            <link>https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch</link>
            <guid>41608648</guid>
            <pubDate>Sat, 21 Sep 2024 09:08:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch">https://www.rijksmuseum.nl/en/stories/operation-night-watch/story/ultra-high-resolution-image-of-the-night-watch</a>, See on <a href="https://news.ycombinator.com/item?id=41608648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div v-else="">


<gtm-scroll-tracker location="article_story" category="article" scroll-element-id="openPipModal" inline-template="">
  <div>
      

<div>
      
  <p>The new high-resolution image of The Night Watch represents a major advance in the state of the art for imaging paintings, setting records for both the resolution and the total size of the image. The sampling resolution is 5 µm (0.005 mm), meaning that each pixel covers an area of the painting that is smaller than a human red blood cell. Given the large size of The Night Watch, this results in a truly enormous image: it’s 925,000 by 775,000 pixels – 717 gigapixels – with a file size of 5.6 TB!</p>

    </div>

<div>
    <h2>Grid</h2>
<p>To create this huge image, the painting was photographed in a grid with 97 rows and 87 columns with our 100-megapixel Hasselblad H6D 400 MS camera. Each of these 8,439 separate photos was captured using a sophisticated laser-guided five-axis camera positioning system that can sense the precise location of the painting so that every photo is sharp – an error of even 1/8 mm in the placement of the camera would result in a useless image.</p>

  </div>

<div>
    <h2>New technology</h2>
<p>New technology allowed the previously-released 20 µm resolution image of The Night Watch to serve as the guide for  lining up these much higher-resolution images during the process of fusing the individual captures into a single monolithic image. The technology allows each of the other types of images collected during Operation Night Watch to be precisely aligned with each other, thereby allowing all of our data to be seen in context.</p>

  </div>

<div>
    <h2>Physical state of the painting</h2>
<p>Why create such an incredibly huge image? With this resolution, we can very clearly see the precise physical state of the painting. Lead soap protrusions, tiny cracks, the shapes of individual paint pigment particles, past retouches, and the beautiful details of Rembrandt’s painting technique are all extraordinarily clear. This enables researchers to understand the painting’s condition in order to make the best plan for future conservation treatments. It helps us to better understand how Rembrandt painted, and it creates an exquisite 'snapshot’ of The Night Watch at this moment in its history.</p>

  </div>
    </div>
</gtm-scroll-tracker>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kamal Proxy – A minimal HTTP proxy for zero-downtime deployments (205 pts)]]></title>
            <link>https://github.com/basecamp/kamal-proxy</link>
            <guid>41608350</guid>
            <pubDate>Sat, 21 Sep 2024 07:55:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/basecamp/kamal-proxy">https://github.com/basecamp/kamal-proxy</a>, See on <a href="https://news.ycombinator.com/item?id=41608350">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Kamal Proxy - A minimal HTTP proxy for zero-downtime deployments</h2><a id="user-content-kamal-proxy---a-minimal-http-proxy-for-zero-downtime-deployments" aria-label="Permalink: Kamal Proxy - A minimal HTTP proxy for zero-downtime deployments" href="#kamal-proxy---a-minimal-http-proxy-for-zero-downtime-deployments"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What it does</h2><a id="user-content-what-it-does" aria-label="Permalink: What it does" href="#what-it-does"></a></p>
<p dir="auto">Kamal Proxy is a tiny HTTP proxy, designed to make it easy to coordinate
zero-downtime deployments. By running your web applications behind Kamal Proxy,
you can deploy changes to them without interruping any of the traffic that's in
progress. No particular cooperation from an application is required for this to
work.</p>
<p dir="auto">Kamal Proxy is designed to work as part of <a href="https://kamal-deploy.org/" rel="nofollow">Kamal</a>,
which provides a complete deployment experience including container packaging
and provisioning. However, Kamal Proxy could also be used standalone or as part
of other deployment tooling.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A quick overview</h2><a id="user-content-a-quick-overview" aria-label="Permalink: A quick overview" href="#a-quick-overview"></a></p>
<p dir="auto">To run an instance of the proxy, use the <code>kamal-proxy run</code> command. There's no
configuration file, but there are some options you can specify if the defaults
aren't right for your application.</p>
<p dir="auto">For example, to run the proxy on a port other than 80 (the default) you could:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy run --http-port 8080"><pre><code>kamal-proxy run --http-port 8080
</code></pre></div>
<p dir="auto">Run <code>kamal-proxy help run</code> to see the full list of options.</p>
<p dir="auto">To route traffic through the proxy to a web application, you <code>deploy</code> instances
of the application to the proxy. Deploying an instance makes it available to the
proxy, and replaces the instance it was using before (if any).</p>
<p dir="auto">Use the format <code>hostname:port</code> when specifying the instance to deploy.</p>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000"><pre><code>kamal-proxy deploy service1 --target web-1:3000
</code></pre></div>
<p dir="auto">This will instruct the proxy to register <code>web-1:3000</code> to receive traffic under
the service name <code>service1</code>. It will immediately begin running HTTP health
checks to ensure it's reachable and working and, as soon as those health checks
succeed, will start routing traffic to it.</p>
<p dir="auto">If the instance fails to become healthy within a reasonable time, the <code>deploy</code>
command will stop the deployment and return a non-zero exit code, allowing
deployment scripts to handle the failure appropriately.</p>
<p dir="auto">Each deployment takes over all the traffic from the previously deployed
instance. As soon as Kamal Proxy determines that the new instance is healthy,
it will route all new traffic to that instance.</p>
<p dir="auto">The <code>deploy</code> command also waits for traffic to drain from the old instance before
returning. This means it's safe to remove the old instance as soon as <code>deploy</code>
returns successfully, without interrupting any in-flight requests.</p>
<p dir="auto">Because traffic is only routed to a new instance once it's healthy, and traffic
is drained completely from old instances before they are removed, deployments
take place with zero downtime.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Host-based routing</h3><a id="user-content-host-based-routing" aria-label="Permalink: Host-based routing" href="#host-based-routing"></a></p>
<p dir="auto">Host-based routing allows you to run multiple applications on the same server,
using a single instance of Kamal Proxy to route traffic to all of them.</p>
<p dir="auto">When deploying an instance, you can specify a host that it should serve traffic
for:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
</code></pre></div>
<p dir="auto">When deployed in this way, the instance will only receive traffic for the
specified host. By deploying multiple instances, each with their own host, you
can run multiple applications on the same server without port conflicts.</p>
<p dir="auto">Only one service at a time can route a specific host:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # returns &quot;Error: host is used by another service&quot;
kamal-proxy remove service1
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # suceeds"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # returns "Error: host is used by another service"
kamal-proxy remove service1
kamal-proxy deploy service2 --target web-2:3000 --host app1.example.com # suceeds
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic TLS</h3><a id="user-content-automatic-tls" aria-label="Permalink: Automatic TLS" href="#automatic-tls"></a></p>
<p dir="auto">Kamal Proxy can automatically obtain and renew TLS certificates for your
applications. To enable this, add the <code>--tls</code> flag when deploying an instance:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com --tls"><pre><code>kamal-proxy deploy service1 --target web-1:3000 --host app1.example.com --tls
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Specifying <code>run</code> options with environment variables</h2><a id="user-content-specifying-run-options-with-environment-variables" aria-label="Permalink: Specifying run options with environment variables" href="#specifying-run-options-with-environment-variables"></a></p>
<p dir="auto">In some environments, like when running a Docker container, it can be convenient
to specify <code>run</code> options using environment variables. This avoids having to
update the <code>CMD</code> in the Dockerfile to change the options. To support this,
<code>kamal-proxy run</code> will read each of its options from environment variables if they
are set. For example, setting the HTTP port can be done with either:</p>
<div data-snippet-clipboard-copy-content="kamal-proxy run --http-port 8080"><pre><code>kamal-proxy run --http-port 8080
</code></pre></div>
<p dir="auto">or:</p>
<div data-snippet-clipboard-copy-content="HTTP_PORT=8080 kamal-proxy run"><pre><code>HTTP_PORT=8080 kamal-proxy run
</code></pre></div>
<p dir="auto">If any of the environment variables conflict with something else in your
environment, you can prefix them with <code>KAMAL_PROXY_</code> to disambiguate them. For
example:</p>
<div data-snippet-clipboard-copy-content="KAMAL_PROXY_HTTP_PORT=8080 kamal-proxy run"><pre><code>KAMAL_PROXY_HTTP_PORT=8080 kamal-proxy run
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building</h2><a id="user-content-building" aria-label="Permalink: Building" href="#building"></a></p>
<p dir="auto">To build Kamal Proxy locally, if you have a working Go environment you can:</p>

<p dir="auto">Alternatively, build as a Docker container:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Trying it out</h2><a id="user-content-trying-it-out" aria-label="Permalink: Trying it out" href="#trying-it-out"></a></p>
<p dir="auto">See the <a href="https://github.com/basecamp/kamal-proxy/blob/main/example">example</a> folder for a Docker Compose setup that you can use
to try out the proxy commands.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FCC wants all phones unlocked in sixty days, AT&T and T-Mobile aren't so keen (212 pts)]]></title>
            <link>https://www.androidauthority.com/fcc-60-day-unlock-tmo-3483642/</link>
            <guid>41608025</guid>
            <pubDate>Sat, 21 Sep 2024 06:52:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.androidauthority.com/fcc-60-day-unlock-tmo-3483642/">https://www.androidauthority.com/fcc-60-day-unlock-tmo-3483642/</a>, See on <a href="https://news.ycombinator.com/item?id=41608025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><picture><source sizes="(min-width: 64rem) 51.25rem, 80vw" srcset="https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1.jpg.webp 1920w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1536w-864h.jpg.webp 1536w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-675w-380h.jpg.webp 675w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-64w-36h.jpg.webp 64w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1000w-563h.jpg.webp 1000w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-300w-170h.jpg.webp 300w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1280w-720h.jpg.webp 1280w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-840w-472h.jpg.webp 840w" type="image/webp"><img decoding="async" loading="eager" sizes="(min-width: 64rem) 51.25rem, 80vw" title="T Mobile logo on smartphone (1)" srcset="https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1.jpg 1920w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1536w-864h.jpg 1536w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-675w-380h.jpg 675w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-64w-36h.jpg 64w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1000w-563h.jpg 1000w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-300w-170h.jpg 300w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-1280w-720h.jpg 1280w, https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1-840w-472h.jpg 840w" alt="T Mobile logo on smartphone (1)" src="https://www.androidauthority.com/wp-content/uploads/2024/04/T-Mobile-logo-on-smartphone-1.jpg"></picture><div><p>Edgar Cervantes / Android Authority</p></div></div><div data-container-type="content"><p>TL;DR</p>
<ul>
<li>Newly proposed FCC rules would require carriers to unlock phones after 60 days, even if they are on payment plans that have unresolved balances.</li>
<li>AT&amp;T and T-Mobile have both pushed back on the effort, though T-Mobile has been even more vocal claiming the FCC doesn’t have the right to authorize this change and that it even implied this change could lead the uncarrier to abandon payment plans altogether.</li>
<li>Verizon supports the effort, though largely because it already activates its phones within 60 days due to a prior agreement with the FCC.</li>
</ul>
</div><p>Back in June, the <a href="https://www.androidauthority.com/fcc-mobile-unlocking-proposal-3455448/">FCC proposed a significant rule change</a> that would require carriers to unlock all phones within 60 days of activation. At the time, the FCC was seeking public comment on the proposal, with plans to vote on whether to pursue the issue in early July. Since then, the proposal has been unanimously approved by the five-member commission, and the plan marches forward. To be clear, this doesn’t mean a new unlock policy is happening anytime soon; it just means that the FCC will continue to actively pursue these regulatory changes. Unsurprisingly, <a href="https://www.androidauthority.com/att-plans-785600/">AT&amp;T</a> and <a href="https://www.androidauthority.com/best-t-mobile-plans-786372/">T-Mobile</a> have both spoken up against the change.</p><p>AT&amp;T has indicated that the rule changes could negatively affect its ability to offer affordable devices, though that’s about the extent of its opposition so far. T-Mobile has been considerably more vocal. The “Uncarrier” has not only made it clear that this change could negatively impact their device payment plans and other services, but it has also gone so far as to imply that the change might cause the carrier to give up on payment plans altogether (as first reported by B<a href="https://broadbandbreakfast.com/t-mobile-unlocking-phones-after-60-days-a-major-question/" target="_blank"><em>roadband Breakfast</em></a>). Furthermore, the carrier questions whether the FCC even has the authorization to pursue such a change.</p><p>As detailed by T-Mobile’s Michele Thomas<a href="https://www.fcc.gov/ecfs/document/10913111581487/1?ref=broadbandbreakfast.com" target="_blank"> in a letter to the FCC</a>: “The Commission fails to point to specific statutory authorization for an unlocking mandate and would have profound economic consequences, thus raising a major question that would require clear statutory authority from Congress.”</p><p>For those who don’t know, a 2022 decision by the high court requires explicit Congressional permission before agencies can decide on issues that have “vast political and economic significance.” T-Mobile argues that the change would qualify as a major economic burden for carriers like itself, which is something AT&amp;T likely agrees with based on its sentiments so far.</p><p>You might notice that I’ve yet to mention <a href="https://www.androidauthority.com/best-verizon-plans-1141575/">Verizon</a>, and that’s for good reason. Big Red is the only major carrier vocally in support of the change. As you likely guessed, the reason isn’t out of the kindness of their hearts.</p><p>Back in 2008, the FCC reached an agreement with Verizon regarding the use of the 700MHz spectrum, with the carrier agreeing to prompt device unlocks. In 2019, the FCC agreed to implement a 60-day unlocking window to help Verizon combat potential fraud around its payment plans and special deal pricing. In other words, Verizon is already abiding by this change, so it loses nothing by supporting it—in fact, it might even have something to gain.</p><p>Right now, many carriers, both prepaid and postpaid, offer free trials through eSIM. While AT&amp;T and T-Mobile limit these kinds of trials due to their current unlocking policies, it’s much easier to try out a different network while still keeping your Verizon phone and subscription. This means a Verizon customer has a greater chance to shop for other networks than those on another carrier, increasing their chances of being lured away by a competitor. If all carriers adhere to the same 60-day window, the playing field becomes level.</p><p><h2>What are the chances this unlock policy will be blocked?</h2></p><div><picture><source sizes="(min-width: 64rem) 51.25rem, 80vw" srcset="https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo.jpg.webp 1920w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1536w-864h.jpg.webp 1536w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-675w-380h.jpg.webp 675w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-64w-36h.jpg.webp 64w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1000w-563h.jpg.webp 1000w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-300w-170h.jpg.webp 300w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1280w-720h.jpg.webp 1280w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-840w-472h.jpg.webp 840w" type="image/webp"><img decoding="async" loading="lazy" sizes="(min-width: 64rem) 51.25rem, 80vw" title="Verizon Wireless logo on smartphone with colored background stock photo" srcset="https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo.jpg 1920w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1536w-864h.jpg 1536w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-675w-380h.jpg 675w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-64w-36h.jpg 64w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1000w-563h.jpg 1000w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-300w-170h.jpg 300w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-1280w-720h.jpg 1280w, https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo-840w-472h.jpg 840w" alt="Verizon Wireless logo on smartphone with colored background stock photo" src="https://www.androidauthority.com/wp-content/uploads/2024/06/Verizon-Wireless-logo-on-smartphone-with-colored-background-stock-photo.jpg"></picture><div><p>Edgar Cervantes / Android Authority</p></div></div><p>Right now, it’s hard to say how this will all play out, but it’s safe to assume a long fight lies ahead. T-Mobile and AT&amp;T will likely continue to use their resources to prevent the regulation from happening and to force congressional involvement, but it’s unclear whether Congress will engage.</p><p>Even if Congress does get involved, the FCC could argue that Verizon already follows this rule, and the purchase of Mint Mobile required T-Mobile to implement a similar rule for its new prepaid carrier. Despite these changes, Verizon still continues to offer payment plans without major issues. A quick look at Mint Mobile’s website also indicates that the T-Mobile-owned carrier hasn’t ditched payment plans yet, despite being forced to implement the same 60-day unlocking window that T-Mobile now opposes for its primary brand.</p><p>Ultimately, I’d say this change will happen eventually, but that’s just speculation on my part. It’s clear that the FCC wants to enforce 60-day unlocking policies by any means necessary, including through merger agreements and more. So even if they don’t win this immediate fight, it’s apparent that shorter unlocking windows are a priority for the FCC moving forward.</p><p><strong>Got a tip? Talk to us!</strong>&nbsp;Email our staff at <a href="mailto:news@androidauthority.com" rel="noopener noreferrer" data-stringify-link="mailto:tips@androidauthority.com" data-sk="tooltip_parent" aria-haspopup="menu">news@androidauthority.com</a>. You can stay anonymous or get credit for the info, it's your choice.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porsche's idea for a six-stroke internal combustion engine (164 pts)]]></title>
            <link>https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/</link>
            <guid>41607887</guid>
            <pubDate>Sat, 21 Sep 2024 06:15:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/">https://www.motor1.com/news/734156/porsche-six-stroke-combustion-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=41607887">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post_box"> <div> <p><span data-time="1726578000"></span><span>Sep 17, 2024</span><span> at</span> 1:00pm ET</p>  </div> <div>  <div> <ul> <li><strong>Porsche has patented a six-stroke internal combustion engine design.</strong></li> <li><strong>It uses a special crankshaft to create extra compression and power strokes per cycle.</strong></li> <li><strong>Nearly all combustion-powered vehicles use a four-stroke engine design.</strong></li> </ul> <hr> <p><a href="https://www.motor1.com/porsche/" data-inline-widget="internal-links" data-type-id="2" data-params="%7B%22alias%22%3A%22porsche%22%7D">Porsche</a>&nbsp;has revealed a strange (and possibly brilliant) idea for a six-stroke combustion engine. If you don't know the fundamentals of an internal combustion engine, we'll try to keep this simple. If you<em> do</em> know how engines work ... we'll still try and keep it simple.</p> <p>With very few exceptions every combustion-powered car uses a four-stroke engine: intake, compression, power, and exhaust. The intake stroke is where air and fuel come into the cylinder. Compression is when the piston pushes that mixture to the top of the cylinder. The mixture is ignited, shoving the piston back down for the power stroke. Exhaust is the final step, pushing the remaining gas out of the cylinder.</p> <section contenteditable="false" draggable="true" data-widget="image" data-border="" data-id="7893499"> <span> <svg> <use xlink:href="https://www.motor1.com/design/dist/critical/icons/sprite-common-4-aab71d103bb6c273cab9291678c627d9.svg#search"></use> </svg> </span> <picture> <source type="image/webp" srcset=" https://cdn.motor1.com/images/mgl/3W4vj6/s5/porsche-six-stroke-combustion-engine-patent.webp 213w, https://cdn.motor1.com/images/mgl/3W4vj6/s6/porsche-six-stroke-combustion-engine-patent.webp 445w, https://cdn.motor1.com/images/mgl/3W4vj6/s4/porsche-six-stroke-combustion-engine-patent.webp 889w, https://cdn.motor1.com/images/mgl/3W4vj6/s3/porsche-six-stroke-combustion-engine-patent.webp 1280w, https://cdn.motor1.com/images/mgl/3W4vj6/s2/porsche-six-stroke-combustion-engine-patent.webp 1440w, https://cdn.motor1.com/images/mgl/3W4vj6/s1/porsche-six-stroke-combustion-engine-patent.webp 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <source type="image/jpeg" srcset=" https://cdn.motor1.com/images/mgl/3W4vj6/s5/porsche-six-stroke-combustion-engine-patent.jpg 213w, https://cdn.motor1.com/images/mgl/3W4vj6/s6/porsche-six-stroke-combustion-engine-patent.jpg 445w, https://cdn.motor1.com/images/mgl/3W4vj6/s4/porsche-six-stroke-combustion-engine-patent.jpg 889w, https://cdn.motor1.com/images/mgl/3W4vj6/s3/porsche-six-stroke-combustion-engine-patent.jpg 1280w, https://cdn.motor1.com/images/mgl/3W4vj6/s2/porsche-six-stroke-combustion-engine-patent.jpg 1440w, https://cdn.motor1.com/images/mgl/3W4vj6/s1/porsche-six-stroke-combustion-engine-patent.jpg 1920w " sizes="(max-width: 767px) calc(100vw - 30px), (max-width: 1023px) calc(100vw - 50px), 649px"> <img src="https://cdn.motor1.com/images/static/16x9-tr.png" alt="Porsche Six-Stroke Combustion Engine Patent" width="16" height="9" loading="lazy"> </picture> <p>Porsche</p> </section> <p>Porsche designers reckon they can add another compression and power stroke to this process. Documents filed with the US Patent and Trademark Office specifically describe this as "six individual strokes that can be divided into two three-stroke sequences." The added steps would occur between the traditional power and exhaust stroke. The first sequence, then, would be intake-compression-power, followed by compression-power-exhaust.</p> <p>To do this, Porsche's patent shows a crankshaft spinning on a ring with two concentric circles—an annulus. This alternates the center point of rotation, effectively lowering the piston's travel (bottom dead center) slightly for the added strokes. That in turn changes the compression, since the piston isn't traveling as far up (top-dead-center) in the cylinder. And that also means this engine has <em>two</em> top and bottom dead centers.</p> <p>Why all the complexity? In short, this design has the potential to generate more power with better efficiency. In a typical engine, only one stroke in four actually makes power. This changes the formula to one stroke in three, and it also burns up the mixture more thoroughly. Of course, the downside is added complexity. Whether the gains are enough to justify the design remains to be seen.</p> <p>As with many patents, it's possible this could never see the light of day. It's certainly an interesting idea, but perhaps more importantly, it suggests Porsche is working very hard at <a href="https://www.motor1.com/news/714168/porsche-v8-continue-2030s/" data-inline-widget="internal-links" data-type-id="0" data-params="%7B%22article_edition_id%22%3A%22714168%22%2C%22section%22%3A%221%22%2C%22alias%22%3A%22porsche-v8-continue-2030s%22%7D">finding ways to keep combustion engines alive</a> amid the push for electric power.</p> <section contenteditable="false" draggable="true" data-widget="related-content" data-widget-size="content" data-params="%7B%22type_id%22%3A0%2C%22title_id%22%3A%22%22%2C%22items%22%3A%5B%7B%22article_edition_id%22%3A%22713952%22%2C%22title%22%3A%22Ferrari%20Wants%20to%20Build%20an%20Upside-Down%2C%20Hydrogen%2C%20Twin-Supercharged%20Inline-Six%22%2C%22alias%22%3A%22ferrari-hydrogen-hybrid-supercar-patent%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FwlZZzL%2Fs5%2Fferrari-hydrogen-hybrid-sports-car.jpg%22%7D%7D%2C%7B%22article_edition_id%22%3A%22667392%22%2C%22title%22%3A%22Mazda%20Patent%20Shows%20Another%20Rotary%20Sports%20Car%2C%20This%20Time%20A%20PHEV%20With%20AWD%22%2C%22alias%22%3A%22mazda-rotary-sports-car-patent%22%2C%22section%22%3A%221%22%2C%22is_video%22%3A%220%22%2C%22images%22%3A%7B%22s5%22%3A%22https%3A%2F%2Fcdn.motor1.com%2Fimages%2Fmgl%2FojBPol%2Fs5%2Fmazda-rotary-sports-car-new-patent.jpg%22%7D%7D%5D%7D"> <p>More Cool Patents:</p>  </section>  </div> <!-- new gallery place, attached gallery --> <p> Source: <span><span>US Patent and Trademark Office</span> via <a target="_blank" href="https://www.autoguide.com/auto/manufacturers/porsche/new-patent-shows-how-porsche-plans-to-keep-combustion-alive-44613226" rel="noopener">AutoGuide</a></span> </p> <!-- Author info bottom -->       </div> </div></div>]]></description>
        </item>
    </channel>
</rss>