<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 12 Jun 2024 19:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Swift compiler is slow due to how types are inferred (112 pts)]]></title>
            <link>https://danielchasehooper.com/posts/why-swift-is-slow/</link>
            <guid>40661001</guid>
            <pubDate>Wed, 12 Jun 2024 17:59:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielchasehooper.com/posts/why-swift-is-slow/">https://danielchasehooper.com/posts/why-swift-is-slow/</a>, See on <a href="https://news.ycombinator.com/item?id=40661001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Swift compiler is notoriously slow due to how types are inferred<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Every June I hope that Apple will announce that they fixed it; sadly this is not that year.</p><p>Here‚Äôs an explanation by the creator of Swift, Chris Lattner (From his <a href="https://www.youtube.com/watch?v=9ag0fPMmYPQ&amp;t=373s" target="_blank" rel="noopener">Mojo talk</a>):</p><blockquote><p>My experience with Swift is we tried to make a really fancy bi-directional Hindley-Milner type checker and it‚Äôs really great because you can have very beautiful minimal syntax but the problem is that A) compile times are really bad (particularly if you have complicated expressions) and B) the error messages are awful because now you have global constraint systems and when something goes wrong you have to infer what happened and the user can‚Äôt know that something over there made it so something over here can‚Äôt type check. In my experience it sounds great but it doesn‚Äôt work super well.</p></blockquote><p>Let me explain what he means with an example:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>enum</span> <span>ThreatLevel</span> <span>{</span>
</span></span><span><span>    <span>case</span> <span>red</span>
</span></span><span><span>    <span>case</span> <span>midnight</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>enum</span> <span>KeyTime</span> <span>{</span>
</span></span><span><span>    <span>case</span> <span>midnight</span>
</span></span><span><span>    <span>case</span> <span>midday</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>func</span> <span>setThreatLevel</span><span>(</span><span>_</span> <span>level</span><span>:</span> <span>ThreatLevel</span><span>)</span> <span>{...}</span>
</span></span><span><span>
</span></span><span><span><span>setThreatLevel</span><span>(.</span><span>midnight</span><span>)</span>
</span></span></code></pre></div><p>The <code>.midnight</code> on the last line could represent <code>ThreatLevel.midnight</code> or <code>KeyTime.midnight</code>. The Swift compiler has to use the surrounding context of <code>setThreatLevel()</code>, which has the type <code>(ThreatLevel)-&gt;Void</code>, to infer that we mean <code>ThreatLevel.midnight</code>. After the Swift compiler parses code into an abstract syntax tree, child nodes influence their parent‚Äôs type <em>and</em> parent nodes influence their children‚Äôs types (that‚Äôs what Chris means by ‚Äúbi-directional‚Äù). Compare this to the Zig language, in which types are determined without looking at the surrounding code.</p><p>This approach becomes a problem when expressions contain many elements that each need their types inferred, with each affecting the others. This often occurs due to Swift‚Äôs operator overloading, and the <a href="https://developer.apple.com/documentation/swift/initialization-with-literals" target="_blank" rel="noopener">ExpressibleBy protocols</a>. Every literal (string, number, boolean, dictionary, array) and every operator (* / + - etc) multiply the combinations the type checker must consider.</p><p>Here‚Äôs an example:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>let</span> <span>address</span> <span>=</span> <span>"127.0.0.1"</span>
</span></span><span><span><span>let</span> <span>username</span> <span>=</span> <span>"steve"</span>
</span></span><span><span><span>let</span> <span>password</span> <span>=</span> <span>"1234"</span>
</span></span><span><span><span>let</span> <span>channel</span> <span>=</span> <span>11</span>
</span></span><span><span>
</span></span><span><span><span>let</span> <span>url</span> <span>=</span> <span>"http://"</span> <span>+</span> <span>username</span> 
</span></span><span><span>            <span>+</span> <span>":"</span> <span>+</span> <span>password</span> 
</span></span><span><span>            <span>+</span> <span>"@"</span> <span>+</span> <span>address</span> 
</span></span><span><span>            <span>+</span> <span>"/api/"</span> <span>+</span> <span>channel</span> 
</span></span><span><span>            <span>+</span> <span>"/picture"</span>
</span></span><span><span>
</span></span><span><span><span>print</span><span>(</span><span>url</span><span>)</span>
</span></span></code></pre></div><p><code>swiftc</code> spends 42 seconds on these 12 lines on an M1 Pro<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, only to spit out the notorious <code>error: the compiler is unable to type-check this expression in reasonable time; try breaking up the expression into distinct sub-expressions</code>. In the same amount of time, clang can perform a clean build of my 59,000 line C project <em>38 times</em>.</p><p>The issue is caused by using the <code>+</code> operator with the <code>channel</code> Int and a String literal. Thanks to the standard library‚Äôs 17 overloads of <code>+</code> and 9 types adopting the <code>ExpressibleByStringLiteral</code> Protocol, the swift compiler can‚Äôt rule out that there <em>might</em> be a combination of types and operators that make the expression valid, so it has to try them all. Just considering that the five string literals could be one of the possible nine types results in 59,049 combinations, but I suspect that‚Äôs a lower bound, since it doesn‚Äôt consider the many overloads of <code>+</code>. It gives up before getting through them all.</p><p>You can fix the code by converting <code>channel</code> to String:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>let</span> <span>url</span> <span>=</span> <span>"http://"</span> <span>+</span> <span>username</span> 
</span></span><span><span>            <span>+</span> <span>":"</span> <span>+</span> <span>password</span> 
</span></span><span><span>            <span>+</span> <span>"@"</span> <span>+</span> <span>address</span> 
</span></span><span><span>            <span>+</span> <span>"/api/"</span> <span>+</span> <span>String</span><span>(</span><span>channel</span><span>)</span> 
</span></span><span><span>            <span>+</span> <span>"/picture"</span>
</span></span></code></pre></div><p>This now successfully compiles in 0.19 seconds!</p><p>Maybe you think strings are complicated or something, so here‚Äôs an example that is just math:</p><div><pre tabindex="0"><code data-lang="swift"><span><span><span>let</span> <span>offset</span><span>:</span> <span>Double</span> <span>=</span> <span>5.0</span><span>;</span>
</span></span><span><span><span>let</span> <span>index</span><span>:</span> <span>Int</span> <span>=</span> <span>10</span><span>;</span>
</span></span><span><span><span>let</span> <span>angle</span> <span>=</span> <span>(</span><span>180.0</span> <span>-</span> <span>offset</span> <span>+</span> <span>index</span> <span>*</span> <span>5.0</span><span>)</span> <span>*</span> <span>.</span><span>pi</span> <span>/</span> <span>180</span><span>;</span>
</span></span></code></pre></div><p>Again, we get <code>error: the compiler is unable to type-check this expression in reasonable time; try breaking up the expression into distinct sub-expressions</code>, this time after ‚Äúonly‚Äù 8 seconds. The problem is due to <code>index * 5.0</code>, i.e. an int multiplied by a double. Even <a href="https://youtu.be/-eCwBwTbjAI?si=rQ5tHNcBRkmaFV8-&amp;t=1000" target="_blank" rel="noopener">toy compilers</a> handle equivalent code quickly, thanks to a context-free type system.</p><p>Both examples are slow because they‚Äôre invalid swift and the type checker falls out of the fast path in order to confirm all possible type combinations are invalid. You might think it‚Äôs ok for invalid code to take a long time to compile. For me, 42 seconds to produce an ‚ÄúI give up‚Äù message is unacceptable. However, there are valid lines of swift that take a long time to compile too. Send me your slow lines (found using <code>-Xfrontend -debug-time-function-bodies</code>) and I‚Äôll add it to this post.</p><p>Swift has come a long way from version 1, but on its 10th birthday it can still be slow. Unfortunately this can‚Äôt be completely fixed by optimizing the current approach. It requires a different approach.</p><p>Here‚Äôs what I‚Äôd do:</p><ol><li>Add a flag to <code>swiftc</code> that makes it infer types using only an expression‚Äôs child AST nodes while ignoring the parent AST node. The flag would also disable the <code>ExpressibleBy</code> protocols, which by definition get their type from their context.</li><li>Make a feature that adds type annotations, casts, and enum names to existing code where necessary to compile with the new type checker</li><li>Update all sample code to compile with the flag</li></ol><p>This might be a reasonable stopping point: teams that care about compile times and good error messages could use the flag, and everyone else doesn‚Äôt have to. It could go further though:</p><ol start="4"><li>Enable the flag by default for new Xcode projects</li><li>Deprecate the old type inference approach</li></ol><p>With this new approach, you‚Äôd have to add type annotations in some places. I‚Äôm ok with that. As a result, we‚Äôd get faster compilation times and clearer error messages, but the extra verbosity might be too much for the swift community to swallow.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Restate ‚Äì Low-latency durable workflows for JavaScript/Java, in Rust (101 pts)]]></title>
            <link>https://restate.dev/</link>
            <guid>40659160</guid>
            <pubDate>Wed, 12 Jun 2024 15:25:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restate.dev/">https://restate.dev/</a>, See on <a href="https://news.ycombinator.com/item?id=40659160">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><a href="https://restate.dev/blog/announcing-restate-1.0-restate-cloud-and-our-seed-funding-round/"><p>üéâ&nbsp;&nbsp;Announcing Restate 1.0, Restate&nbsp;Cloud, and our Seed Funding Round &nbsp;&nbsp;<span>Read more</span></p></a></section><div data-animation="default" data-collapse="medium" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner"><p><a href="https://restate.dev/" aria-current="page"><img src="https://cdn.prod.website-files.com/663272930a67769123cdcf53/66552a0c5a6f4d528f1241de_Logo%20Refined.svg" loading="lazy" alt=""></a></p></div><div><div id="w-node-_909f3004-9317-0658-ea73-f830f9153f13-23cdcf59" data-w-id="909f3004-9317-0658-ea73-f830f9153f13"><p data-w-id="0e3c2fe2-55e6-bde5-39c2-cefd2408f0b6">As <strong>regular functions and services</strong>, in your existing infrastructure. On FaaS, K8s, servers, containers. Self-hosted or fully managed. Restate meets you where you are.</p></div><div id="w-node-_0a36f96d-1a2c-4e83-c438-e5e08296ce51-23cdcf59"><p><img src="https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background.png" loading="eager" sizes="(max-width: 479px) 261.75px, (max-width: 767px) 282.84375px, 554.75px" srcset="https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-500.png 500w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-800.png 800w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-1080.png 1080w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-1600.png 1600w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-2000.png 2000w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background-p-2600.png 2600w, https://cdn.prod.website-files.com/663272930a67769123cdcf53/665bd80206cc423e5a2edcf2_hero-background.png 2752w" alt=""></p></div></div><div data-w-id="c420d2f0-b483-a654-3cb5-e22ce4cf01f9"><h2 id="w-node-ebe6a069-89b1-fc5f-5813-61aed10405e5-23cdcf59">Easy solutions for common challenges</h2><div fs-cmstabs-element="list" role="list" id="w-node-_987cb84f-9b03-aa32-df41-957747709f42-23cdcf59"><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Workflows as code</p><h4>Workflows as code</h4><div><p>Durable Execution ensures code runs reliably to the end, even in the presence of failures.</p><p>‚Äç</p><ul role="list"><li>Failures and errors are automatically retried (unless labeled as terminal errors)</li><li>Functions can memoize the results of code blocks, and actions like RPC, in a journal. Completed steps are not re-executed during retries, but replayed from the journal.</li><li>Workflows are built with regular code and control flow, no custom DSLs needed.</li><li>Durable sleeps let code wait and suspend for up to months</li></ul><p>‚Äç</p></div><p><a href="https://github.com/restatedev/examples/blob/main/basics/basics-typescript/src/1_durable_execution.ts" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
export default restate.service({
  name: "roleUpdate",
  handlers: {
    applyRoleUpdate: async (ctx, update) =&gt; {
      const { userId, role, permissions } = update;
      const applied = await ctx.run("apply new role", () =&gt;
        applyUserRole(userId, role)
      );
      if (!applied) {
        return;
      }
      for (const permission of permissions) {
        await ctx.run("apply permission", () =&gt;
          applyPermission(userId, permission)
        );
      }
    }
  }
});
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@Service
public class RoleUpdateService {

    @Handler
    public void applyRoleUpdate(Context ctx, Update update) {

        boolean success = ctx.run("apply new role", BOOLEAN,
            () -&gt; applyUserRole(update.getUserId(), update.getRole()));

        if (!success) {
            return;
        }

        for (String permission : update.getPermissions()) {
            ctx.run("apply permission",
                () -&gt; applyPermission(update.getUserId(), permission));
        }
    }
}
</code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">API calls and webhooks</p><h4>API calls and webhooks</h4><div><p>Reliably join synchronous code and async events like webhooks</p><ul role="list"><li>Webhooks/events are persisted in Restate‚Äôs log and reliably delivered to services</li><li>Persistent Promises/Futures easily join synchronous and asynchronous code paths</li><li>Durable execution ensures reliable completion, whether webhooks come after milliseconds or months, and avoid re-execution of completed steps.</li></ul></div><p><a href="https://github.com/restatedev/examples/tree/website_snippets_java/patterns-use-cases/async-signals-payment" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
const paymentSvc = restate.service({
  name: "payments",
  handlers: {
    processPayment: async (ctx, request) =&gt; {
      const webhookPromise = ctx.awakeable();
      const paymentIntent = await ctx.run("stripe call", () =&gt;
        createPaymentIntent({
          request,
          metadata: { restate_callback_id: webhookPromise.id }
        })
      );
      if (paymentIntent.status === "processing") {
        // synchronous response inconclusive, await webhook response
        const paymentIntentFromWebhook = await webhookPromise.promise;
        return verifyPayment(paymentIntentFromWebhook);
      } else {
        return verifyPayment(paymentIntent);
      }
    },
    processWebhook: async (ctx) =&gt; {
      const paymentIntent = verifyAndParseEvent(ctx.request());
      const webhookPromiseId = paymentIntent.metadata.restate_callback_id;
      ctx.resolveAwakeable(webhookPromiseId, paymentIntent);
    }
  }
});
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@Service
public class PaymentService {
  @Handler
  public void processPayment(Context ctx, PaymentRequest request) {
    var webhookFuture = ctx.awakeable(SERDE);
    var payment = ctx.run("Stripe call", SERDE, () -&gt; submitPayment(
            request, Map.of("restate_callback_id", webhookFuture.id())
    ));
    if (payment.getStatus().equals("processing")) {
      // synchronous response inconclusive, await webhook response
      var updatedPayment = webhookFuture.await();
      verifyPayment(updatedPayment);
    } else {
      verifyPayment(payment);
    }
  }
  @Handler
  public void processWebhook(Context ctx) {
    var paymentEvent = verifyAndParseEvent(ctx.request());
    String callbackId = paymentEvent.getMetadata().get("restate_callback_id");
    ctx.awakeableHandle(callbackId).resolve(SERDE, paymentEvent);
  }
}
</code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Asynchronous Tasks</p><h4>Asynchronous Tasks</h4><div><p>All functions invoked through Restate are executed durably and asynchronous.</p><ul role="list"><li>Deploy async functions serverless or as containers or processes.</li><li>Call functions synchronously, async, or delayed. Re-attach and await from anywhere.</li><li>Build async patterns like fan-out, fan-in, task chains, and subtasks simply with function calls and Futures/Promises.</li><li>Use persistent timers to schedule tasks into the future.</li><li>Use fine-grained virtual queues (via virtual objects) to enforce strict task order and concurrency</li></ul></div><p><a href="https://github.com/restatedev/examples/tree/website_snippets_java/patterns-use-cases/async-tasks" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
// ------ service (= worker) ------
const asyncTaskService = restate.service({
    name: "taskWorker",
    handlers: { processPayment }
});
// ------ client ------
const rs = clients.connect({ url: process.env.RESTATE_URL });
const taskWorker = rs.serviceSendClient({ name: "taskWorker" });
// submit the payment task 
app.post('/charge/:paymentId', async (req, res) =&gt; {
    const taskHandle = await taskWorker.processPayment(
        { request: req.params },
        SendOpts.from({ idempotencyKey: req.params.paymentId })
    );
    res.json(taskHandle);
});
// await the payment task
app.get('/status', async (req,res) =&gt; {
        const taskHandle = req.body.json();
        const paymentResult = await restate.result(taskHandle); 
        res.join(paymentResult);
});
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
// --- start payment task ---
server.createContext("/charge", httpExchange -&gt; {
  PaymentRequest req = parsePaymentRequest(httpExchange);
  SendResponse handle = AsyncTaskServiceClient
      .fromIngress(RESTATE_URI)
      .send()
      .processPayment(req, idempotencyKey(req.getPaymentId()));

  respondJson(httpExchange, handle);
});
//  --- connect to payment result ---
server.createContext("/status", httpExchange -&gt; {
  String handle = parseToHandle(httpExchange);
  String response = IngressClient.defaultClient(RESTATE_URI)
      .invocationHandle(handle, STRING)
      .attach();
  respond(httpExchange, response);
});
</code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Stateful Event Processing</p><h4>Stateful Event Processing</h4><div><p>Process events (for example from Kafka) with durable functions as event handlers and get fine-grained retries and workflow-as-code semantics.</p><ul role="list"><li>No queue subscriptions, no manual offset management, scaling, or balancing</li><li>Deploy the event processing logic as serverless functions on FaaS</li><li>Keep exactly-once state, delay events, run multiple asynchronous steps or API calls.</li><li>Restate‚Äôs queue-per-key semantics mean no more head-of-the-line waiting effects</li></ul></div><p><a href="https://github.com/restatedev/examples/blob/main/basics/basics-typescript/src/5_events_processing.ts" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
const eventEnricher = restate.object({
  name: "eventEnricher",
  handlers: {
    userEvent: async (ctx, event) =&gt; {
      // remember event, time box 100 ms to collect features
      // before emitting result
      ctx.set("user", event);
      ctx.serviceSendClient(eventEnricher, { delay: 100 }).emit();
    },
    featureEvent: async (ctx, featureEvent) =&gt; {
      // merge feature into event
      const userEvent = (await ctx.get("user")) ?? {};
      (userEvent.features ??= []).push(featureEvent);
      ctx.set("user", userEvent)
    },
    emit: async (ctx) =&gt; {
      emit(ctx.key, await ctx.get("user"));
      ctx.clearAll();
    }
  }
})
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@VirtualObject
public class EventEnricher {
    static final StateKey<user> USER = StateKey.of("user", of(User.class));
    @Handler
    public void userEvent(ObjectContext ctx, User event) {
        ctx.set(USER, event);
        // time box 100 ms to collect features before emitting result
        EventEnricherClient.fromContext(ctx, ctx.key())
            .send(ofMillis(100)).emit();
    }
    @Handler
    public void featureEvent(ObjectContext ctx, Feature event) {
        User user = ctx.get(USER).orElse(new User());
        user.addFeature(event);
        ctx.set(USER, user);
    }
    @Handler
    public void emit(ObjectContext ctx) {
        send(ctx.key(), ctx.get(USER));
        ctx.clearAll();
    }
}
</user></code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Durable Signals</p><h4>Durable Signals</h4><div><p>Create workflows and event handlers that reliably handle external signals, events, human input.</p><p>‚Äç</p><ul role="list"><li>Use durable Promises/Futures to intuitively model signals and conditions</li><li>Create signals from RPCs, webhooks, or Kafka events</li><li>Signals and events are persisted by Restate, no need for a queue</li></ul></div><p><a href="https://github.com/restatedev/examples/blob/main/basics/basics-typescript/src/3_workflows.ts" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
export default workflow({
  name: "verify",
  handlers: {
    run: async (ctx, { email }) =&gt; {
      const secret = ctx.run("generate secret", () =&gt;
        crypto.randomUUID()
      );
      await ctx.run("send email", () =&gt; sendEmail({ email, secret }));

      const clickSecret = await ctx.promise("email.clicked");
      return clickSecret == secret;
    },
    click: (ctx, { secret }) =&gt; {
      ctx.promise("email.clicked").resolve(secret);
    },
  },
});



</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@Workflow
public class SecretVerifier {

    static final DurablePromiseKey<string> EMAIL_CLICKED =
            DurablePromiseKey.of("email_clicked", JsonSerdes.STRING);

    @Workflow
    public boolean run(WorkflowContext ctx, Email email) {
        String secret = ctx.random().nextUUID().toString();
        ctx.run("send email",
            () -&gt; sendEmailWithLink(email, secret));

        String clickSecret = ctx.promise(EMAIL_CLICKED).awaitable().await();
        return clickSecret.equals(secret);
    }

    @Handler
    public void click(SharedWorkflowContext ctx, String secret) {
        ctx.promiseHandle(EMAIL_CLICKED).resolve(secret);
    }
}
</string></code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Idempotency</p><h4>Idempotency</h4><div><p>Add idempotency to any RPC- or event handler.</p><p>‚Äç</p><ul role="list"><li>Every RPC- and event handler call accepts an idempotency key</li><li>Use idempotency keys to re-attach to an ongoing invocation</li><li>Calls from within a durable execution context are automatically idempotent</li></ul></div><p><a href="https://docs.restate.dev/concepts/invocations#idempotent-invocations" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
const rs = restate.connect({ url: process.env.RESTATE_URL });
app.get('/reserve/:product/:reservationId', async (req, res) =&gt; {
  const { product, reservationId } = req.params;
  const products = rs.serviceClient(ProductService);
  const reservation = await products.reserve(
    product,
    Opts.from({ idempotencyKey : reservationId })
  );
  res.json(reservation);
})
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
server.createContext("/reserve", httpExchange -&gt; {
      ReservationRequest req = parseRequest(httpExchange.getRequestBody());
      // derive an idempotency key from the parameters
      var idempotencyOps = CallRequestOptions.DEFAULT
          .withIdempotency(req.getReservationId());
      // add idempotency opts to the request to let the service automatically
      // fuse repeated requests
      Reservation reservation = ProductServiceClient
          .fromIngress(RESTATE_RUNTIME_ENDPOINT)
          .reserve(req.getProduct(), idempotencyOps);
      sendResponse(httpExchange, reservation);
    });
</code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">Sagas</p><h4>Sagas</h4><div><p>Implements robust sagas and compensation patterns: long-running transactions that undo previous actions when they need to abort and roll back.</p><p>‚Äç</p><ul role="list"><li>Reliably pick up after failures to trigger compensations</li><li>Ensure compensations happen even upon failures during the compensation phase</li><li>Use standard Exception/Error mechanisms and control flow rather than complex DSLs.</li></ul></div><p><a href="https://github.com/restatedev/examples/tree/main/patterns-use-cases/sagas" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
async function reservation(ctx, products) {
  const reservations = [];
  try {
    for (const product of products) {
      const reservation = await ctx.run(`reserve ${product}`,
          () =&gt; reserve(product));
      reservations.push(reservation);
    }
  } catch (error) {
    if (error instanceof TerminalError) {
      for (const reservation of reservations) {
        await ctx.run("undo reserve", () =&gt; 
            cancelReservation(reservation));
      }
    }
    throw error;
  }
}
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@Handler
public void reserveAllProducts(Context ctx, Product[] products) {
    final List<reservation> reservations = new ArrayList&lt;&gt;();
    try {
        for (Product product : products) {
            Reservation res = ctx.run("Reserve " + product.getId(),
                RESERVE_SERDE, () -&gt; reserve(product)
            );
            reservations.add(res);
        }
    } catch (TerminalException e) {
        reservations.forEach(res -&gt; {
            ctx.run("Undo reservation", () -&gt; cancelReservation(res));
        });
        throw e;
    }
}
</reservation></code>
</pre></div></div></div><div role="listitem"><div id="w-node-_13e0bcf1-d9ea-6e17-5d98-d31f688c70c6-23cdcf59"><p fs-cmstabs-element="tab-link">State machines</p><h4>State machines</h4><div><p>Create consistent and scalable State Machines without databases or transactions<br>‚Äç</p><ul role="list"><li>Run millions of State Machines that maintain state directly in the context of their handlers</li><li>State changes commit atomically with function execution, for rock-solid consistency</li><li>Single-writer semantics for a dead simple concurrency model. A virtual queue per state machine for efficiency and scalability.</li><li>State transition can be workflows with all the features from durable execution</li></ul></div><p><a href="https://github.com/restatedev/examples/tree/main/patterns-use-cases/payment-state-machine" target="_blank">&gt; Learn More</a></p></div><div data-current="Tab 1" data-easing="ease" data-duration-in="300" data-duration-out="100" id="w-node-e2a5a4fe-8235-9f45-0a19-48178634d8ac-23cdcf59"><div data-w-tab="Tab 1"><pre><code>
const paymentSvc = restate.object({
  name: "payments",
  handlers: {
    makePayment: async (ctx, payment) =&gt; {
      const paymentId = ctx.key;
      switch (await ctx.get("status")) {
        case "CANCELLED":
            return `${paymentId} was cancelled before`;
        case "SUCCESS":
            return `${paymentId} previously completed`;
      }
      wireFunds(payment);
      ctx.set("status", "SUCCESS");
      ctx.set("payment", payment);
    },
    cancelPayment: async (ctx) =&gt; {
      const status = await ctx.get("status");
      if (status === "SUCCESS") {
        const payment = await ctx.get("payment");
        refund(payment);
      }
      ctx.set("status", "CANCELLED");
    }
  }
});
</code>
</pre></div><div data-w-tab="Tab 2"><pre><code>
@VirtualObject
public class PaymentStateMachine {
  @Handler
  public String makePayment(ObjectContext ctx, PaymentRequest payment) {
    String paymentId = ctx.key();
    switch (ctx.get(STATE_STATUS).orElse(NEW)) {
      case CANCELLED: return paymentId + " was cancelled before";
      case SUCCESS:   return paymentId + " was previously completed";
    }
    wireFunds(payment);
    ctx.set(STATE_STATUS, SUCCESS);
    ctx.set(STATE_PAYMENT_REQUEST, payment);
    return paymentId + " was successfully processed";
  }
  @Handler
  public void cancelPayment(ObjectContext ctx) {
    Status status = ctx.get(STATE_STATUS).orElse(NEW);
    if (status == SUCCESS) {
      PaymentRequest payment = ctx.get(STATE_PAYMENT_REQUEST).get();
      refund(payment);
    }
    ctx.set(STATE_STATUS, CANCELLED);
  }
}
</code>
</pre></div></div></div></div></div><div><div id="w-node-_6c62185e-aeb0-0281-3106-2400ea849cab-23cdcf59"><h2>A simple and powerful programming model</h2><p>Restate provides distributed durable version of your everyday building blocks.</p><p><a href="https://restate.dev/programming-model">&gt; See how it works</a></p></div><div id="w-node-_6efa648f-2885-10fe-426b-0822434c8e3d-23cdcf59"><div data-w-id="1f98eac8-7392-f220-f431-d55dd9707ff8"><h4>Durable Execution</h4><p>Functions/Services that handle retries, recovery, asynchrony, idempotency.</p></div><div data-w-id="fada5290-d344-caa0-93a5-2dca955e7633"><h4>Virtual Objects</h4><p>Persistent state directly in your objects with a simple concurrency model.</p></div><div data-w-id="6f0d1405-b0e1-174a-5538-0a0fc0cd2f72"><h4>Durable Promises</h4><p>Transparent and fault-tolerant communication across services, processes, and time.</p></div></div></div><div><div id="w-node-_64f32bf9-9582-8528-1db5-e498d4a9d807-23cdcf59"><p><img src="https://cdn.prod.website-files.com/663272930a67769123cdcf53/664fdfb3d3abef98f35a8335_FeatureIcon1.svg" loading="lazy" alt=""></p><h2>Single binary, no dependencies, built in Rust.</h2><p>A system that runs locally and on-prem just as well as in the ‚Ä®cloud. Restate server comes as a single binary. Simple to run, ‚Ä®simple to operate.</p><p>Fully self-contained, resource-efficient, resilient, thanks to ‚Ä®Rust‚Äôs magic.</p></div><div id="w-node-d62c8e4f-b2e9-6271-8c4d-c77645e928de-23cdcf59"><p><img src="https://cdn.prod.website-files.com/663272930a67769123cdcf53/664fdfb4b4dde429290390db_FeatureIcon2.svg" loading="lazy" alt=""></p><h2>Stellar local dev-experience</h2><p>What‚Äôs better than a local dev server? </p><p>Running the real system on your laptop or in your CI pipeline. No subtle quirks and differences between dev- and prod setups.<br></p><p>Your Restate-powered code is just functions/services. Develop them with the tools you know and love.<br></p></div></div><div data-w-id="c21848fa-07c8-b134-6d13-aa60a989b3e8"><div><h2>Restate Cloud:&nbsp;The zero-infrastructure option</h2><p>Get a fully serverless Restate experience, managed by the developers of the system.‚Ä®<br>Sign in, generate keys, point your app, go!</p><p><a href="https://cloud.restate.dev/" target="_blank">&gt; Get Access</a></p></div><p><img src="https://cdn.prod.website-files.com/663272930a67769123cdcf53/66551349e3bd7f3d6a22e6a9_Clouds.svg" loading="lazy" alt=""></p></div><div id="w-node-df836a90-d340-351a-8bf6-bfbc18c0615f-23cdcf59"><p id="w-node-_27c261b3-325b-c04f-1f2f-fb69f494eaf8-23cdcf59"><h2>Ready to <br><span>get started?</span></h2></p></div><div><p>Copyright ¬© 2024 Restate. All rights reserved.</p></div>

<!-- üíô MEMBERSCRIPT #92 v0.1 üíô TURN ANYTHING INTO A LINK -->






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel is trucking a 916,000-pound 'Super Load' across Ohio to its new fab (203 pts)]]></title>
            <link>https://www.tomshardware.com/pc-components/cpus/intel-is-trucking-a-916000-pound-super-load-across-ohio-to-its-new-fab-spawning-road-closures-over-nine-days</link>
            <guid>40658095</guid>
            <pubDate>Wed, 12 Jun 2024 13:45:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tomshardware.com/pc-components/cpus/intel-is-trucking-a-916000-pound-super-load-across-ohio-to-its-new-fab-spawning-road-closures-over-nine-days">https://www.tomshardware.com/pc-components/cpus/intel-is-trucking-a-916000-pound-super-load-across-ohio-to-its-new-fab-spawning-road-closures-over-nine-days</a>, See on <a href="https://news.ycombinator.com/item?id=40658095">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-320-80.jpg" alt="Ohio Department of Transportation" srcset="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ.jpg"></picture>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/Uef74YhnJN4cS75qmWbgQZ.jpg">
<meta itemprop="height" content="600">
<meta itemprop="width" content="338">
<figcaption itemprop="caption description">
<span itemprop="copyrightHolder">(Image credit: Ohio Department of Transportation)</span>
</figcaption>
</div>

<div id="article-body">
<p>Ohio is seeing the effects of Intel's growth, but maybe not in the way state officials had hoped. Intel will put a 916,000-pound "super load" on the road in Ohio <a data-analytics-id="inline-link" href="https://www.dispatch.com/story/news/local/2024/06/11/intel-super-load-to-move-through-central-ohio-starting-sunday/74057074007/" data-url="https://www.dispatch.com/story/news/local/2024/06/11/intel-super-load-to-move-through-central-ohio-starting-sunday/74057074007/" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">on Wednesday</a>, for a trip that will cover approximately 150 miles in nine days and snarl traffic for over a week. The price of progress!</p><p>Intel's <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/intel-pushes-launch-date-of-ohio-fab-from-2025-to-2027-or-2028-state-politicians-remain-enthusiastic-about-progress" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/semiconductors/intel-pushes-launch-date-of-ohio-fab-from-2025-to-2027-or-2028-state-politicians-remain-enthusiastic-about-progress">new campus coming to New Albany, OH</a>, is in heavy construction, and around 20 super loads are being ferried across Ohio's roads by the Ohio Department of Transportation after arriving at a port of the Ohio River via barge. Four of these loads, including the one hitting the road now, weigh around 900,000 pounds ‚Äî that's 400 metric tons, or 76 elephants. The super loads were <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/semiconductors/delivery-of-equipment-to-intels-ohio-fab-delayed-for-several-weeks" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/semiconductors/delivery-of-equipment-to-intels-ohio-fab-delayed-for-several-weeks">first planned for February</a> but were delayed due to the immense planning workload. Large crowds are estimated to accumulate on the route, potentially slowing it even further.</p><p>Intel's 916,000-pound shipment is a "cold box," a self-standing air-processor structure that facilitates the cryogenic technology needed to fabricate semiconductors. The box is 23 feet tall, 20 feet wide, and 280 feet long, stretching longer than a football field. The immense scale of the cold box necessitates a transit process that moves at a "parade pace" of 5-10 miles per hour.</p><figure><blockquote><p>There's a lot of moving parts to it. It's not just jump in a truck and go</p><figcaption><cite>Matt Bruning, ODOT press secretary</cite></figcaption></blockquote></figure><p>Intel is taking over southern Ohio's roads for the next several weeks and months as it builds its new Ohio One Campus, a $28 billion project to create a 1,000-acre campus with two chip factories and room for more. Calling it the new "Silicon Heartland," the project will be the first leading-edge semiconductor fab in the American Midwest, and once operational, will get to work on the "Angstrom era" of Intel processes, <a data-analytics-id="inline-link" href="https://www.tomshardware.com/news/intel-displays-arrow-lake-wafer-with-20a-process-node-chips-arrive-in-2024" data-before-rewrite-localise="https://www.tomshardware.com/news/intel-displays-arrow-lake-wafer-with-20a-process-node-chips-arrive-in-2024">20A and beyond</a>. Beyond bringing jobs to the region, Intel seeks to make nice with Ohio by investing millions into local schools and universities to provide local students with the tools to grow up to work at the foundries.</p><p>The cold box and the other super loads to come after it required immense planning from ODOT. "There's a lot of moving parts to it. It's not just jump in a truck and go from point A to point B," said Matt Bruning, ODOT press secretary. "There's a lot of planning and coordination and analysis that goes with doing a move like that." The Department of Transportation has been planning the route for months, ensuring that bridges and roadways could handle the loads coming for them. Power lines were moved underground or extended so work crews could lift them over the loads.&nbsp;</p><p>The <a data-analytics-id="inline-link" href="https://www.transportation.ohio.gov/about-us/traffic-advisories/district-9/superload" data-url="https://www.transportation.ohio.gov/about-us/traffic-advisories/district-9/superload" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Ohio Department of Transportation has shared a timetable</a> for how long they will be dealing with the super loads. Bruning shared that other companies are piggybacking on the super load route plans now that accommodations have already been made. "It is kind of abnormal to see this many in this close succession. Usually, you have a couple, and you may not see another load like that for years," he said. The summer of road closures is here for Ohio, thanks to Intel.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-xE3TGq23Eyoz89kJDTMjrL"><section><p>Get Tom's Hardware's best news and in-depth reviews, straight to your inbox.</p></section></div>
</div>




<!-- Drop in a standard article here maybe? -->



</section>





<div id="slice-container-relatedArticles"><p><h5>Most Popular</h5></p></div>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Study shows N95 masks near-perfect at blocking escape of airborne Covid-19 (148 pts)]]></title>
            <link>https://sph.umd.edu/news/study-shows-n95-masks-near-perfect-blocking-escape-airborne-covid-19</link>
            <guid>40657307</guid>
            <pubDate>Wed, 12 Jun 2024 12:28:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sph.umd.edu/news/study-shows-n95-masks-near-perfect-blocking-escape-airborne-covid-19">https://sph.umd.edu/news/study-shows-n95-masks-near-perfect-blocking-escape-airborne-covid-19</a>, See on <a href="https://news.ycombinator.com/item?id=40657307">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>COLLEGE PARK, Md. ‚Äì&nbsp;In a head-to-head comparison of masks worn by people with active COVID-19, the inexpensive ‚Äúduckbill‚Äù N95 came out on top, stopping 98% of COVID-19 particles in the breath of infected people from escaping into the air. Led by researchers from the University of Maryland School of Public Health (SPH), results showed other masks also performed well, blocking at least 70% of viral particles from escaping from the source ‚Äì an infected person‚Äôs exhaled breath.</p><div id="umd_terp_paragraph--12679">
				<p>The study,&nbsp;<a href="https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(24)00192-0/fulltext">Relative efficacy of masks and respirators as source control for viral aerosol shedding from people infected with SARS-CoV-2</a>, published May 29 in eBioMedicine, a Lancet journal.</p>

<p>‚ÄúThe research shows that any mask is much better than no mask, and an N95 is significantly better than the other options. That‚Äôs the number one message,‚Äù says the study‚Äôs senior author,&nbsp;<a href="https://sph.umd.edu/people/donald-milton">Dr. Donald Milton</a>. Milton is a UMD SPH professor of environmental health and a global expert on how viruses spread through the air.</p>

<p>The study started in May 2020, shortly after the pandemic began, and compared breath samples from volunteers who had active COVID-19, testing the performance of four commonly-used masks. Even without giving participants fit tests or training on how to wear masks correctly, all masks significantly reduced the amount of virus escaping into the air. The study tested masks as a way to control the spread of the virus from the source, i.e. the infected person, and did not test masks as protection from COVID-19 in the surrounding air.</p>

<p>‚ÄúBecause COVID-19 is airborne, we focused on the extent to which wearing a mask reduces contamination of the air around you,‚Äù Milton says. This latest study is a continuation of investigations by UMD‚Äôs&nbsp;<a href="https://sites.google.com/umd.edu/phablabumd/home?authuser=0">Public Health AeroBiology Lab</a>&nbsp;(PHAB Lab) into how contagious respiratory viruses such as influenza contaminate the air.</p>

<p>Researchers asked volunteers with COVID-19 to breathe into a unique contraption known as the Gesundheit II Machine, developed by Milton and colleagues to measure viruses in exhaled breath. Participants, who breathed into the machine for 30 minutes at a time, were asked to do a&nbsp;variety of vocalizations such as repeating the alphabet, singing Happy Birthday, and even&nbsp;honoring&nbsp;<a href="https://umterps.com/sports/2018/6/7/school-mascot">UMD‚Äôs mascot</a>&nbsp;by repeatedly shouting ‚ÄúGo Terps!‚Äù</p>

<p>In each instance, researchers measured the amount of viral particles in the exhaled breath of volunteers, pairing each 30-minute session of breathing with a mask on with another 30-minute session with no mask.</p>

<p>‚ÄúData from our study suggests that a mildly symptomatic person with COVID-19 who is not wearing a mask exhales a little over two infectious doses per hour,‚Äù says first author Dr. Jianyu Lai, a postdoctoral researcher at the PHAB Lab. ‚ÄúBut when wearing an N95 mask, the risk goes down exponentially.‚Äù</p>

<p>The duckbill N95 blocked 99% of large particles and 98% of small particles from escaping out of a person‚Äôs mask. Milton says the design‚Äôs tight seal, a powerful filter, and large air space for breath to move around all contribute to the duckbill‚Äôs success.</p>

<p>Surprisingly, KN95 masks ‚Äì the disposable masks used widely ‚Äì were no more effective than cloth or surgical masks. The study found that a common brand of KN95 masks leak more air than duckbills or other studied masks, because they don‚Äôt conform to the face well. That flaw is compounded by a powerful filter with more flow resistance that pushes air out of the mask at the sides instead of through the filter, allowing more virus particles to escape into the surrounding air.</p>

<p>Cloth masks also outperformed both KN95 and surgical masks. Milton theorizes that cloth masks with greater coverage, wrap around the face and give a better seal than either KN95 or surgical masks. With cloth mask filters, flow resistance is also lower, allowing breath to pass through the filter and not leak out the sides of the mask.</p>

<p>Limiting the amount of viral particles in the air is a key way to control highly contagious respiratory viruses in general, Milton said. This is even more the case with the COVID-19 virus, given transmissibility has increased over time, with Omicron in particular breaking through the immunity people developed from vaccinations or prior infections.</p>

<p>‚ÄúOur research shows definitively why it‚Äôs so important to have non-pharmaceutical responses like wearing masks, and why we need studies like this to illuminate which masks are most effective,‚Äù says Milton.</p>

<p>Both Milton and Lai hope that their findings will inform health policies going forward, including when combatting potential outbreaks like bird flu or even the common flu.</p>

<p>‚ÄúDuckbill N95 masks should be the standard of care in high-risk situations, such as nursing homes and health care settings,‚Äù Lai says. ‚ÄúNow, when the next outbreak of a severe respiratory&nbsp;virus occurs, we know exactly how to help control the spread, with this simple and inexpensive&nbsp;solution.‚Äù</p>

<p>In addition to researchers from the UMD School of Public Health, collaborators include authors from the UMD A. James Clark School of Engineering and the World Health Organization Collaborating Centre for Infectious Disease Epidemiology and Control at the University of Hong Kong, China.</p>

<p>This research was supported by the Prometheus-UMD, sponsored by the Defence Advanced Research Projects Agency (agreement N66001-18-2-4015), the National Institute of Allergy and Infectious Diseases Centers of Excellence for Influenza Research and Surveillance (contract 12-HHSN272201400008C), and the Centers for Disease Control and Prevention (contract 200-2020-09528); by a grant from the Bill &amp; Melinda Gates Foundation; and by a gift from The Flu Lab.</p>



<p>##<br>
Media Contact &nbsp;- SPH Communications, sph-comm@umd.edu, 301-405-2438</p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Detectors Get It Wrong. Writers Are Being Fired Anyway (150 pts)]]></title>
            <link>https://gizmodo.com/ai-detectors-inaccurate-freelance-writers-fired-1851529820</link>
            <guid>40657238</guid>
            <pubDate>Wed, 12 Jun 2024 12:19:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gizmodo.com/ai-detectors-inaccurate-freelance-writers-fired-1851529820">https://gizmodo.com/ai-detectors-inaccurate-freelance-writers-fired-1851529820</a>, See on <a href="https://news.ycombinator.com/item?id=40657238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Kimberly Gasuras doesn‚Äôt use AI. ‚ÄúI don‚Äôt need it,‚Äù she said. ‚ÄúI‚Äôve been a news reporter for 24 years. How do you think I did all that work?‚Äù That logic wasn‚Äôt enough to save her job.<br></p><div data-video-id="195264" data-monetizable="true" data-position="sidebar" data-video-title="Why is Everyone Suing AI Companies? | Future Tech" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="290" data-playlist="195264,195603,196019" data-current="195264"><div><p>Why is Everyone Suing AI Companies? | Future Tech</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/195264/195264_240p.mp4" label="240p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_480p.mp4" label="480p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_720p.mp4" label="720p" type="video/mp4"><source data-src="https://vid.kinja.com/prod/195264/195264_1080p.mp4" label="1080p" type="video/mp4"><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/20725.vtt" srclang="en"></video><div><ul><li data-label="">Off</li><li data-label="English">English</li></ul></div></div><p>As a local journalist in Bucyrus, Ohio, Gasuras relies on side hustles to pay the bills. For a while, she made good money on a freelance writing platform called WritersAccess, where she wrote blogs and other content for small and midsize companies. But halfway through 2023, the income plummeted as some clients switched to ChatGPT for their writing needs. It was already a difficult time. Then the email came. </p><p>‚ÄúI only got one warning,‚Äù Gasuras said. ‚ÄúI got this message saying they‚Äôd flagged my work as AI using a tool called ‚ÄòOriginality.‚Äô‚Äù She was dumbfounded. Gasuras wrote back to defend her innocence, but she never got a response. Originality costs money, but Gasuras started running her work through other AI detectors before submitting to make sure she wasn‚Äôt getting dinged by mistake. A few months later, WritersAccess kicked her off the platform anyway. ‚ÄúThey said my account was suspended due to excessive use of AI. I couldn‚Äôt believe it,‚Äù Gasuras said. WritersAccess did not respond to a request for comment.</p><p>When ChatGPT set the world on fire a year and a half ago, it sparked a feverish search for ways to catch people trying to pass off AI text as their own writing. A host of startups launched to fill the void through AI detection tools, with names including Copyleaks, GPTZero, Originality.AI, and Winston AI. It makes for a tidy business in a landscape full of AI boogeymen. </p><p>These companies advertise peace of mind, a way to take back control through ‚Äúproof‚Äù and ‚Äúaccountability.‚Äù Some advertise accuracy rates as high as 99.98%. But a growing body of experts, studies, and industry insiders argue these tools are far less reliable than their makers promise. There‚Äôs no question that AI detectors make frequent mistakes, and innocent bystanders get caught in the crossfire. Countless <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.rollingstone.com/culture/culture-features/student-accused-ai-cheating-turnitin-1234747351/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.rollingstone.com/culture/culture-features/student-accused-ai-cheating-turnitin-1234747351/" target="_blank" rel="noopener noreferrer">students have been accused of AI plagiarism</a></span>, but a quieter epidemic is happening in the professional world. Some <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944&quot;,{&quot;metric25&quot;:1}]]" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4602944" target="_blank" rel="noopener noreferrer">writing gigs are drying up thanks to chatbots</a></span>. As people fight over the dwindling field of work, writers are losing jobs over false accusations from AI detectors.</p><p>‚ÄúThis technology doesn‚Äôt work the way people are advertising it,‚Äù said Bars Juhasz, co-founder of Undetectable AI, which makes tools to help people humanize AI text to sneak it past detection software. ‚ÄúWe have a lot of concerns around the reliability of the training process these AI detectors use. These guys are claiming they have 99% accuracy, and based on our work, I think that‚Äôs impossible. But even if it‚Äôs true, that still means for every 100 people there‚Äôs going to be one false flag. We‚Äôre talking about people‚Äôs livelihoods and their reputations.‚Äù</p><h4 id="h1203"><a id=""></a><strong>Safeguard, or snake oil?</strong></h4><p>In general, AI detectors work by spotting the hallmarks of AI penmanship, such as perfect grammar and punctuation. In fact, one of the easiest ways to get your work flagged is to use Grammarly, a tool that checks for spelling and grammatical errors. It even suggests ways to rewrite sentences for clarity using, you guessed it, artificial intelligence. Adding insult to injury, Gizmodo spoke to writers who said they were fired by platforms that required them to use Grammarly. (Gizmodo confirmed the details of these stories, but we are excluding the names of certain freelance platforms because writers signed non-disclosure agreements.)</p><p>Detectors look for more telling factors as well, such as ‚Äúburstiness.‚Äù Human writers are more likely to reuse certain words in clusters or bursts, while AI is more likely to distribute words evenly across a document. AI detectors can also assess ‚Äúperplexity,‚Äù which essentially asks an AI to measure the likelihood that it would have produced a piece of text given the model‚Äôs training data. Some companies, such as industry leader Originaility.AI, train their own AI language models specially made to detect the work of other AIs, which are meant to spot patterns that are too complex for the human mind. </p><p>However, none of these techniques are foolproof, and many major institutions have backed away from this class of tools. OpenAI released its own AI detector to quell fears about its products in 2023 but pulled the tool off the market just months later ‚Äúdue to its <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/open-ai-chatgpt-ai-text-detector-1850055005&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/open-ai-chatgpt-ai-text-detector-1850055005">low rate of accuracy</a></span>.‚Äù The academic world was first to adopt AI detectors, but false accusations pushed a long list of universities to <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://www.theregister.com/2023/09/23/turnitin_ai_detection/&quot;,{&quot;metric25&quot;:1}]]" href="https://www.theregister.com/2023/09/23/turnitin_ai_detection/" target="_blank" rel="noopener noreferrer">ban the use of AI detection software</a></span>,, including Vanderbilt, Michigan State, Northwestern, and the University of Texas at Austin.</p><p>AI detection companies ‚Äúare in the business of selling snake oil,‚Äù said Debora Weber-Wulff, a professor at the University of Applied Sciences for Engineering and Economics in Berlin, who co-authored a <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00146-z&quot;,{&quot;metric25&quot;:1}]]" href="https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00146-z" target="_blank" rel="noopener noreferrer">recent paper</a></span> about the effectiveness of AI detection. According to Weber-Wulff, research shows that AI detectors are inaccurate, unreliable, and easy to fool. ‚ÄúPeople want to believe that there can be some magic software that solves their problems,‚Äù she said. But ‚Äúcomputer software cannot solve social problems. We have to find other solutions.‚Äù</p><p>The companies that make AI detectors say they‚Äôre a necessary but imperfect tool in a world inundated by robot-generated text. There‚Äôs a significant demand for these services, whether or not they‚Äôre effective.</p><p>Alex Cui, chief technology officer for the AI detection company GPTZero, said detectors have meaningful shortcomings, but the benefits outweigh the drawbacks. ‚ÄúWe see a future where, if nothing is changed, the internet becomes more and more dictated by AI, whether it‚Äôs news, peer-reviewed articles, marketing. You don‚Äôt even know if the person you‚Äôre talking to on social media is real,‚Äù Cui said. ‚ÄúWe need a solution for confirming knowledge en masse, and determining whether content is high quality, authentic, and of legitimate authorship.‚Äù</p><h4 id="h1204"><a id=""></a><strong>A necessary evil?</strong></h4><p>Mark, another Ohio-based copywriter who asked that we withhold his name to avoid professional repercussions, said he had to take work doing maintenance at a local store after an AI detector cost him his job.</p><p>‚ÄúI got an email saying my most recent article had scored a 95% likelihood of AI generation,‚Äù Mark said. ‚ÄúI was in shock. It felt ridiculous that they‚Äôd accuse me after working together for three years, long before ChatGPT was available.‚Äù </p><p>He tried to push back. Mark sent his client a copy of the Google Doc where he drafted the article, which included timestamps that demonstrated he wrote the document by hand. It wasn‚Äôt enough. Mark‚Äôs relationship with the writing platform fell apart. He said losing the job cost him 90% of his income.</p><p>‚ÄúWe hear these stories more than we wish we did, and we understand the pain that false positives cause writers when the work they poured their heart and soul into gets falsely accused,‚Äù said Jonathan Gillham, CEO of Originality.AI. ‚ÄúWe feel like we feel like we‚Äôre building a tool to help writers, but we know that at times it does have some consequences.‚Äù</p><p>But according to Gillham, the problem is about more than helping writers or providing accountability.‚ÄúGoogle is aggressively going after AI spam,‚Äù he said. ‚ÄúWe‚Äôve heard from companies that had their entire site de-indexed by Google that said they didn‚Äôt even know their writers were using AI.‚Äù </p><p>It‚Äôs true that the internet is being flooded by <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/study-junk-news-sites-ad-systems-ai-generated-content-1850578259&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/study-junk-news-sites-ad-systems-ai-generated-content-1850578259">low-effort content farms</a></span> that pump out junky AI articles in an effort to game search results, get clicks, and make ad money from those eyeballs. <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;Internal link&quot;,&quot;https://gizmodo.com/google-search-updates-downrank-seo-ai-generated-content-1851309904&quot;,{&quot;metric25&quot;:1}]]" href="https://gizmodo.com/google-search-updates-downrank-seo-ai-generated-content-1851309904">Google is cracking down on these sites</a></span>, which leads some companies to believe that their websites will be down-ranked if Google detects any AI writing whatsoever. That‚Äôs a problem for web-based businesses, and increasingly the No. 1 selling point for AI detectors. Originality promotes itself as a way to ‚Äúfuture proof your site on Google‚Äù at the top of the list of benefits on its homepage.</p><p>A Google spokesperson said this completely misinterprets the company‚Äôs policies. Google, a company that provides AI, said it has no problem with AI content in and of itself. ‚ÄúIt‚Äôs inaccurate to say Google penalizes websites simply because they may use some AI-generated content,‚Äù the spokesperson said. ‚ÄúAs we‚Äôve clearly stated, low value content that‚Äôs created at scale to manipulate Search rankings is spam, however it is produced. Our automated systems determine what appears in top search results based on signals that indicate if content is helpful and high quality.‚Äù</p><h4 id="h1205"><a id=""></a><strong>Mixed messages</strong></h4><p>No one claims AI detectors are perfect, including the companies that make them. But Originality and other AI detectors send mixed messages about how their tools should be used. For example, Gillham said ‚Äúwe advise against the tool being used within academia, and strongly recommend against being used for disciplinary action.‚Äù He explained the risk of false positives is too high for students, because they submit a small number of essays throughout a school year, but the volume of work produced by a professional writer means the algorithm has more chances to get it right. However, on one of the company‚Äôs <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://originality.ai/blog/ai-content-detection-in-education&quot;,{&quot;metric25&quot;:1}]]" href="https://originality.ai/blog/ai-content-detection-in-education" target="_blank" rel="noopener noreferrer">blog posts</a></span>, Originality says AI detection is ‚Äúessential‚Äù in the classroom. </p><p>Then there are questions about how the results are presented. Many of the writers Gizmodo spoke to said their clients don‚Äôt understand the limitations of AI detectors or even what the results are actually saying. It‚Äôs easy to see how someone might be confused: I ran one of my own articles through Originality‚Äôs AI detector. The results were ‚Äú70% Original‚Äù and ‚Äú30% AI.‚Äù You might assume that means Originality determined that 30% of the article was written by a chatbot, especially because the tool highlights specific sentences it finds suspect. However, it‚Äôs actually a confidence score; Originality is 70% sure a human wrote the text. (I wrote the whole thing myself, but you‚Äôll just have to take my word for it.)</p><p>Then there‚Äôs the way the company describes its algorithm. According to Originality, the latest version of its tool has a 98.8% accuracy rate, but Originality also says its false positive rate is 2.8%. If you‚Äôve got your calculator handy, you‚Äôll notice that adds up to more than 100%. Gillham said that‚Äôs because these numbers come from two different tests.</p><p>In Originality‚Äôs defense, the company provides a detailed explanation of how you should interpret the information right below the results, along with links to more detailed writeups about how to use the tool. It seems that isn‚Äôt enough, though. Gizmodo spoke to multiple writers who said they had to argue with clients who misunderstood the Originality tool.</p><p>Originality has published numerous <span><a data-ga="[[&quot;Embedded Url&quot;,&quot;External link&quot;,&quot;https://originality.ai/blog/ai-content-detection-accuracy&quot;,{&quot;metric25&quot;:1}]]" href="https://originality.ai/blog/ai-content-detection-accuracy" target="_blank" rel="noopener noreferrer">blog posts</a></span> and studies about accuracy and other issues, including the dataset and methodology it used to develop and measure its own tools. However, Weber-Wulff at the University of Applied Sciences for Engineering and Economics in Berlin said the details about Originality‚Äôs methodology ‚Äúwere not that clear.‚Äù </p><p>A number of experts Gizmodo spoke to, such as Juhasz of Undetectable AI, said they had concerns about businesses across the AI detection industry inflating their accuracy rates and misleading their customers. Representatives for GPTZero and Originality AI said their companies are committed to openness and transparency. Both companies said they go out of their way to provide clear information about the limitations and shortcomings of their tools.</p><p>It might feel like being against AI detectors is being on the side of writers, but according to Gillham the opposite is true. ‚ÄúIf there are no detectors, then the competition for writing jobs increases and as a result the pay drops,‚Äù he said. ‚ÄúDetectors are the difference between a writer being able to do their work, submit content, and get compensated for it, and somebody being able to just copy and paste something from ChatGPT.‚Äù </p><p>On the other hand, all of the copywriters Gizmodo spoke to said the AI detectors are the problem. </p><p>‚ÄúAI is the future. There‚Äôs nothing we can do to stop it, but in my opinion that‚Äôs not the issue. I can see lots of ways AI can be useful,‚Äù Mark said. ‚ÄúIt‚Äôs these detectors. They are the ones that are saying with utmost certainty that they can detect AI writing, and they‚Äôre the ones who are making our clients on edge and paranoid and putting us out of jobs.‚Äù </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elixir 1.17 released: set-theoretic types in patterns, durations, OTP 27 (273 pts)]]></title>
            <link>https://elixir-lang.org/blog/2024/06/12/elixir-v1-17-0-released/</link>
            <guid>40656747</guid>
            <pubDate>Wed, 12 Jun 2024 11:13:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2024/06/12/elixir-v1-17-0-released/">https://elixir-lang.org/blog/2024/06/12/elixir-v1-17-0-released/</a>, See on <a href="https://news.ycombinator.com/item?id=40656747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p>Elixir v1.17 has just been released. üéâ</p>

<p>This release introduces set-theoretic types into a handful of language constructs. While there are still <a href="https://elixir-lang.org/blog/2023/06/22/type-system-updates-research-dev/">many steps ahead of us</a>, this important milestone already brings benefits to developers in the form of new warnings for common mistakes. This new version also adds support for <a href="https://www.erlang.org/downloads/27">Erlang/OTP 27</a>, the latest and greatest Erlang release. You‚Äôll also find a new calendar-related data type (<code>Duration</code>) and a <code>Date.shift/2</code> function.</p>

<p>Let‚Äôs dive in.</p>

<h2 id="warnings-from-gradual-set-theoretic-types">Warnings from gradual set-theoretic types</h2>

<p>This release introduces gradual set-theoretic types to infer types from patterns and use them to type check programs, enabling the Elixir compiler to find faults and bugs in codebases without requiring changes to existing software. The underlying principles, theory, and roadmap of our work have been outlined in <a href="https://arxiv.org/abs/2306.06391">‚ÄúThe Design Principles of the Elixir Type System‚Äù by Giuseppe Castagna, Guillaume Duboc, Jos√© Valim</a>.</p>

<p>At the moment, Elixir developers will interact with set-theoretic types only through <strong>warnings</strong> found by the type system. The current implementation models all data types in the language:</p>

<ul>
  <li>
    <p><code>binary()</code>, <code>integer()</code>, <code>float()</code>, <code>pid()</code>, <code>port()</code>, <code>reference()</code> - these
types are indivisible. This means both <code>1</code> and <code>13</code> get the same <code>integer()</code>
type.</p>
  </li>
  <li>
    <p><code>atom()</code> - it represents all atoms and it is divisible. For instance, the
atom <code>:foo</code> and <code>:hello_world</code> are also valid (distinct) types.</p>
  </li>
  <li>
    <p><code>map()</code> and structs - maps can be ‚Äúclosed‚Äù or ‚Äúopen‚Äù. Closed maps only allow
the specified keys, such as <code>%{key: atom(), value: integer()}</code>. Open maps
support any other keys in addition to the ones listed and their definition
starts with <code>...</code>, such as <code>%{..., key: atom(), value: integer()}</code>. Structs
are closed maps with the <code>__struct__</code> key.</p>
  </li>
  <li>
    <p><code>tuple()</code>, <code>list()</code>, and <code>function()</code> - currently they are modelled as
indivisible types. The next Elixir versions will also introduce fine-grained
support to them.</p>
  </li>
</ul>

<p>We focused on <em>atoms</em> and <em>maps</em> on this initial release as they are respectively the simplest and the most complex types representations, so we can stress the performance of the type system and quality of error messages. Modelling these types will also provide the most immediate benefits to Elixir developers. Assuming there is a variable named <code>user</code>, holding a <code>%User{}</code> struct with a <code>address</code> field, Elixir v1.17 will emit the following warnings at compile-time:</p>

<ul>
  <li>
    <p>Pattern matching against a map or a struct that does not have the given key,
such as <code>%{adress: ...} = user</code> (notice <code>address</code> vs <code>adress</code>).</p>
  </li>
  <li>
    <p>Accessing a key on a map or a struct that does not have the given key, such
as <code>user.adress</code>.</p>
  </li>
  <li>
    <p>Invoking a function on non-modules, such as <code>user.address()</code>.</p>
  </li>
  <li>
    <p>Capturing a function on non-modules, such as <code>&amp;user.address/0</code>.</p>
  </li>
  <li>
    <p>Attempting to call an anonymous function without an actual function, such as
<code>user.()</code>.</p>
  </li>
  <li>
    <p>Performing structural comparisons between structs, such as <code>my_date &lt;
~D[2010-04-17]</code>.</p>
  </li>
  <li>
    <p>Performing structural comparisons between non-overlapping types, such as
<code>integer &gt;= string</code>.</p>
  </li>
  <li>
    <p>Building and pattern matching on binaries without the relevant specifiers,
such as <code>&lt;&lt;name&gt;&gt;</code> (this warns because by default it expects an integer, it
should have been <code>&lt;&lt;name::binary&gt;&gt;</code> instead).</p>
  </li>
  <li>
    <p>Attempting to rescue an undefined exception or a struct that is not an
exception.</p>
  </li>
  <li>
    <p>Accessing a field that is not defined in a rescued exception.</p>
  </li>
</ul>

<p>Here‚Äôs an example of how the warning for accessing a misspelled field of a
struct looks like:</p>

<p><img src="https://elixir-lang.org/images/contents/type-warning-on-struct-field.png" alt="Example of a warning when accessing a mispelled struct field"></p>

<p>Another example, this time it‚Äôs a warning for structural comparison across two
<code>Date</code> structs:</p>

<p><img src="https://elixir-lang.org/images/contents/type-warning-on-date-comparison.png" alt="Example of a warning when comparing two structs with &quot;>&quot;"></p>

<p>These warnings also work natively in text editors, as they are standard Elixir
compiler warnings:</p>

<p><img src="https://elixir-lang.org/images/contents/type-warning-in-editor.png" alt="Example of a type warning inline in an editor"></p>

<p>These new warnings will help Elixir developers find bugs earlier and give more
confidence when refactoring code, especially around maps and structs. While
Elixir already emitted some of these warnings in the past, those were discovered
using syntax analysis. The new warnings are more reliable, precise, and with
better error messages. Keep in mind, however, that the Elixir typechecker only
infers types from patterns within the same function at the moment. Analysis from
guards and across function boundaries will be added in future releases. For more
details, see our new <a href="https://hexdocs.pm/elixir/gradual-set-theoretic-types.html">reference document on gradual set-theoretic
types</a>.</p>

<p>The type system was made possible thanks to a partnership between
<a href="https://www.cnrs.fr/">CNRS</a> and <a href="https://remote.com/">Remote</a>. The development
work is currently sponsored by <a href="https://www.fresha.com/">Fresha</a>
(<a href="https://www.fresha.com/careers/openings?department=engineering">they are hiring!</a>),
<a href="https://starfish.team/">Starfish*</a>, and <a href="https://dashbit.co/">Dashbit</a>.</p>



<p>This release adds support for Erlang/OTP 27 and drops support for Erlang/OTP 24.
We recommend Elixir developers to migrate to Erlang/OTP 26 or later, especially
on Windows. Support for WERL (a graphical user interface for the Erlang terminal
on Windows) will be removed in Elixir v1.18.</p>

<p>You can read more about Erlang/OTP 27 in <a href="https://www.erlang.org/downloads/27">their release
announcement</a>. The bits that are
particularly interesting for Elixir developers are the addition of a <a href="https://erlang.org/documentation/doc-15.0-rc3/lib/stdlib-6.0/doc/html/json.html"><code>json</code>
module</a>
and process labels (<code>proc_lib:set_label/1</code>). The latter will also be available
in this Elixir release as <code>Process.set_label/1</code>.</p>

<h2 id="new-duration-data-type-and-shifting-functions">New <code>Duration</code> data type and shifting functions</h2>

<p>This Elixir version introduces the <code>Duration</code> data type and APIs to shift dates,
times, and date times by a given duration, considering different calendars and
time zones.</p>

<div><pre><code><span>iex</span><span>&gt;</span> <span>Date</span><span>.</span><span>shift</span><span>(</span><span>~D[2016-01-31]</span><span>,</span> <span>month:</span> <span>2</span><span>)</span>
<span>~D[2016-03-31]</span>
</code></pre></div>

<p>We chose the name <em>‚Äúshift‚Äù</em> for this operation (instead of ‚Äúadd‚Äù) since working
with durations does not obey properties such as <strong>associativity</strong>. For instance,
adding one month and then one month does not give the same result as adding two
months:</p>

<div><pre><code><span>iex</span><span>&gt;</span> <span>~D[2016-01-31]</span> <span>|&gt;</span> <span>Date</span><span>.</span><span>shift</span><span>(</span><span>month:</span> <span>1</span><span>)</span> <span>|&gt;</span> <span>Date</span><span>.</span><span>shift</span><span>(</span><span>month:</span> <span>1</span><span>)</span>
<span>~D[2016-03-29]</span>
</code></pre></div>

<p>Still, durations are essential for building intervals, recurring events, and
modelling scheduling complexities found in the world around us. For <code>DateTime</code>s,
Elixir will correctly deal with time zone changes (such as Daylight Saving
Time). However, provisions are also available in case you want to surface
conflicts, such as shifting to a wall clock that does not exist, because the
clock has been moved forward by one hour. See <code>DateTime.shift/2</code> for examples.</p>

<p>Finally, we added a new <code>Kernel.to_timeout/1</code> function, which helps developers
normalize durations and integers to a timeout used by many APIs‚Äîlike <code>Process</code>,
<code>GenServer</code>, and more. For example, to send a message after one hour, you can
now write:</p>

<div><pre><code><span>Process</span><span>.</span><span>send_after</span><span>(</span><span>pid</span><span>,</span> <span>:wake_up</span><span>,</span> <span>to_timeout</span><span>(</span><span>hour:</span> <span>1</span><span>))</span>
</code></pre></div>

<h2 id="learn-more">Learn more</h2>

<p>Here are other notable changes in this release:</p>

<ul>
  <li>
    <p>There are new <code>Keyword.intersect/2,3</code> functions to mirror the equivalent in
the <code>Map</code> module.</p>
  </li>
  <li>
    <p>A new Mix profiler was added, <code>mix profile.tprof</code>, which lets you use the
new <a href="https://www.erlang.org/doc/apps/tools/tprof.html">tprof</a>
profiler released with Erlang/OTP 27. This profiler leads to the
soft-deprecation of <code>mix profile.cprof</code> and <code>mix profile.eprof</code>.</p>
  </li>
  <li>
    <p>We added <code>Kernel.is_non_struct_map/1</code>, a new guard to help with the common
pitfall of matching on <code>%{}</code>, which also successfully matches structs (as
they are maps underneath).</p>
  </li>
  <li>
    <p>Elixir‚Äôs Logger now formats
<a href="https://www.erlang.org/doc/apps/stdlib/gen_statem.html"><code>gen_statem</code></a>
reports and includes Erlang/OTP 27 <em>process labels</em> in logger events.</p>
  </li>
</ul>

<p>For a complete list of all changes, see the
<a href="https://github.com/elixir-lang/elixir/releases/tag/v1.17.0">full release notes</a>.</p>

<p>Check <a href="https://elixir-lang.org/install.html">the Install section</a> to get Elixir installed and
read our <a href="https://hexdocs.pm/elixir/introduction.html">Getting Started guide</a>
to learn more.</p>

<p>Happy learning!</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi is now a public company (154 pts)]]></title>
            <link>https://techcrunch.com/2024/06/11/raspberry-pi-is-now-a-public-company-as-its-shares-pops-after-ipo-pricing/</link>
            <guid>40656603</guid>
            <pubDate>Wed, 12 Jun 2024 10:48:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/06/11/raspberry-pi-is-now-a-public-company-as-its-shares-pops-after-ipo-pricing/">https://techcrunch.com/2024/06/11/raspberry-pi-is-now-a-public-company-as-its-shares-pops-after-ipo-pricing/</a>, See on <a href="https://news.ycombinator.com/item?id=40656603">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Who would have thought that Raspberry Pi, the maker of the tiny, cheap, single-board computers, would become a public company? Yet, this is exactly what‚Äôs <a href="https://www.raspberrypi.com/news/raspberry-pi-ipo/" target="_blank" rel="noreferrer noopener">happening</a>: Raspberry Pi <a href="https://investors.raspberrypi.com/" target="_blank" rel="noreferrer noopener">priced its IPO</a> on the London Stock Exchange on Tuesday morning at ¬£2.80 per share, valuing it at ¬£542 million, or $690 million at today‚Äôs exchange rate.</p>

<p>Shortly after that, the company‚Äôs <a href="https://www.ft.com/content/6419f805-01e8-4900-9da7-7e4fc8504a81" target="_blank" rel="noreferrer noopener">shares jumped a nice 32% to ¬£3.70</a>. It means that Raspberry Pi could end up raising more than $200 million during its IPO process.</p>

	
	


<p>Retail investors can‚Äôt buy Raspberry Pi shares just yet, as only certain institutional shareholders can trade the company‚Äôs shares right now. Retail investors will be able to buy and sell shares starting on Friday.</p>

	
	


<p>This listing is also a win for the London stock market. Deliveroo and Wise both trade in London, but many U.K. tech companies choose to go public in the U.S., as the stock markets there are more liquid.</p>

<p>Raspberry Pi is mostly known for its <a href="https://techcrunch.com/2023/09/27/raspberry-pi-5/">tiny computers</a> that can be programmed to perform all sorts of tasks without spending too much money and requiring too much power. These ARM-based computers became particularly popular among tech hobbyists who wanted to create media servers, retro game consoles, interactive dashboards, robotics projects and more.</p>

<p>More recently, many industrial companies have started integrating the Raspberry Pi in their devices and facilities. The company <a href="https://investors.raspberrypi.com/" target="_blank" rel="noreferrer noopener">reports</a> that the industrial and embedded segment represents 72% of its sales.</p>

<p>Raspberry Pi has sold 60 million units since its inception. In 2023 alone, Raspberry Pi generated $266 million in revenue and $66 million in gross profit.</p>

	
	



<p>Raspberry Pi Ltd, the public company, is the commercial subsidiary of the Raspberry Pi Foundation. The Foundation says it wants to make it easier for people to learn coding through a low-cost, programmable computer. It also remains the main shareholder of Raspberry Pi Ltd.</p>

	
	


<p>Other strategic shareholders in the company include ARM and Sony Semiconductor Solutions Corporation, a subsidiary of Sony that makes image sensors for smartphones and other components. ARM previously said it intended to increase its stake in Raspberry Pi via the public listing.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why SQLite Is Taking over with Brian Holt and Marco Bambini (150 pts)]]></title>
            <link>https://syntax.fm/show/779/why-sqlite-is-taking-over-with-brian-holt-and-marco-bambini</link>
            <guid>40654734</guid>
            <pubDate>Wed, 12 Jun 2024 05:07:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://syntax.fm/show/779/why-sqlite-is-taking-over-with-brian-holt-and-marco-bambini">https://syntax.fm/show/779/why-sqlite-is-taking-over-with-brian-holt-and-marco-bambini</a>, See on <a href="https://news.ycombinator.com/item?id=40654734">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><header><span title="Show #779">779</span> <p>June 7th, 2024
		√ó
		<span><span>#sqlite</span><span>#databases</span><span>#local-first</span></span></p>  <p><span>Discussion on why SQLite is gaining popularity, its advantages like efficiency, speed and stability, misconceptions about capabilities, and how SQLite Cloud enhances it by making it shareable and adding enterprise features.</span></p></header> <div> <div><figure><img src="https://github.com/wesbos.png" alt="Wes Bos"> <figcaption><p>Wes Bos <span>Host</span></p> </figcaption></figure> </div> <div><figure><img src="https://github.com/stolinski.png" alt="Scott Tolinski"> <figcaption><p>Scott Tolinski <span>Host</span></p> </figcaption></figure> </div> </div>        <div><div><!-- HTML_TAG_START --><p>Scott and CJ dive into the world of SQLite Cloud with special guests Brian Holt and Marco Bambini. They explore why SQLite is gaining traction, its unique features, and the misconceptions surrounding its use‚Äîlet's get into it!</p>
<h3 id="show-notes">Show Notes</h3>
<ul>
<li><strong><a href="#t=00:00">00:00</a></strong> Welcome to Syntax!</li>
<li><strong><a href="#t=01:20">01:20</a></strong> Who is Brian Holt?</li>
<li><strong><a href="#t=02:26">02:26</a></strong> Who is Marco Bambini?</li>
<li><strong><a href="#t=05:12">05:12</a></strong> Why are people starting to talk so much about SQLite now?</li>
<li><strong><a href="#t=08:47">08:47</a></strong> What makes SQLite special or interesting?</li>
<li><strong><a href="#t=09:46">09:46</a></strong> What is a big misconception about SQLite?</li>
<li><strong><a href="#t=11:13">11:13</a></strong> Installed by default in operating systems.</li>
<li><strong><a href="#t=12:03">12:03</a></strong> A perception that SQLite is intended for single users.</li>
<li><strong><a href="#t=13:36">13:36</a></strong> Convincing developers it's a full-featured solution.</li>
<li><strong><a href="#t=15:11">15:11</a></strong> What does SQLite do better than <a href="https://www.postgresql.org/">Postgres</a> or <a href="https://www.mysql.com/">MySQL</a>?</li>
<li><strong><a href="#t=17:30">17:30</a></strong> SQLite Cloud &amp; local first features.</li>
<li><strong><a href="#t=20:38">20:38</a></strong> Where does SQLite store the offline information?</li>
<li><strong><a href="#t=23:08">23:08</a></strong> Are you typically reaching for ORMs?</li>
<li><strong><a href="#t=25:00">25:00</a></strong> What is <a href="https://sqlitecloud.io/">SQLite Cloud</a>?</li>
<li><strong><a href="#t=27:29">27:29</a></strong> What makes for an approachable software?</li>
<li><strong><a href="#t=29:18">29:18</a></strong> What make SQLite cloud different from other hosted SQLite options?</li>
<li><strong><a href="#t=32:13">32:13</a></strong> Is SQLite still evolving?</li>
<li><strong><a href="#t=34:40">34:40</a></strong> What about branching?</li>
<li><strong><a href="#t=37:37">37:37</a></strong> What is the GA timeline?</li>
<li><strong><a href="#t=40:04">40:04</a></strong> How does SQLite actually work?</li>
<li><strong><a href="#t=41:19">41:19</a></strong> Questions about security.</li>
<li><strong><a href="#t=44:28">44:28</a></strong> But does it scale?</li>
<li><strong><a href="#t=45:52">45:52</a></strong> Sick Picks + Shameless Plugs.</li>
</ul>
<h3 id="sick-picks">Sick Picks</h3>
<p>Brian: <a href="https://www.trainerroad.com/">Trainer Road</a>
Marco: Tennis</p>
<h3 id="shameless-plugs">Shameless Plugs</h3>
<ul>
<li>Brian: <a href="https://sqlitecloud.io/">SQLite Cloud</a>, <a href="https://frontendmasters.com/courses/complete-intro-containers/">Frontend Masters - Containers</a>.</li>
</ul>

<p>Syntax: <a href="https://twitter.com/syntaxfm">X</a> <a href="https://www.instagram.com/syntax_fm/">Instagram</a> <a href="https://www.tiktok.com/@syntaxfm">Tiktok</a> <a href="https://www.linkedin.com/company/96077407/admin/feed/posts/">LinkedIn</a> <a href="https://www.threads.net/@syntax_fm">Threads</a></p>
<p>Wes: <a href="https://twitter.com/wesbos">X</a> <a href="https://www.instagram.com/wesbos/">Instagram</a> <a href="https://www.tiktok.com/@wesbos">Tiktok</a> <a href="https://www.linkedin.com/in/wesbos/">LinkedIn</a> <a href="https://www.threads.net/@wesbos">Threads</a></p>
<p>Scott:<a href="https://twitter.com/stolinski">X</a> <a href="https://www.instagram.com/stolinski/">Instagram</a> <a href="https://www.tiktok.com/@stolinski">Tiktok</a> <a href="https://www.linkedin.com/in/stolinski/">LinkedIn</a> <a href="https://www.threads.net/@stolinski">Threads</a></p>
<p>Randy: <a href="https://twitter.com/randyrektor">X</a> <a href="https://www.instagram.com/randyrektor/">Instagram</a> <a href="https://www.youtube.com/@randyrektor">YouTube</a> <a href="https://www.threads.net/@randyrektor">Threads</a></p><!-- HTML_TAG_END --></div> <nav> </nav></div> <dialog aria-labelledby="search-header"><h3 data-svelte-h="svelte-epihaf">Share</h3>  </dialog></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Silicon Valley's best kept secret: Founder liquidity (1420 pts)]]></title>
            <link>https://www.stefantheard.com/silicon-valleys-best-kept-secret-founder-liquidity/</link>
            <guid>40654190</guid>
            <pubDate>Wed, 12 Jun 2024 03:32:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stefantheard.com/silicon-valleys-best-kept-secret-founder-liquidity/">https://www.stefantheard.com/silicon-valleys-best-kept-secret-founder-liquidity/</a>, See on <a href="https://news.ycombinator.com/item?id=40654190">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>Ask most venture-backed founders why they get 10x more equity than employee #1, 100x more equity than employee #5, and 1000x more equity than employee #15, and you'll get the same answer: "I'M TAKING SO MUCH RISK, IT'S SO HARD TO START A COMPANY, I MADE A BIG MOVE!!!" And then you'll ask, "but why are you yelling?‚Äù</p><p>The narrative of the founder's risk is a cornerstone of Silicon Valley's mythology. Founders are celebrated for leaving stable jobs and pouring their lives into an ‚Äúuncertain‚Äù and ‚Äúhigh-risk‚Äù venture. This mythos justifies the enormous equity stakes founders hold compared to early employees who take very similar risks by joining an unproven startup.</p><p>However, there's a lesser-known aspect of the startup ecosystem that significantly shifts the risk landscape: <strong>founder liquidity</strong>.</p><h3 id="my-experience-in-early-stage-startups">My Experience in Early Stage Startups</h3><p>Being a software engineer who has a strong preference for creativity, problem-solving, and autonomy I realized during college that very big and slow companies were not for me. I joined a startup straight out of college as employee number 8 and immediately knew I made the right choice. My skills were improving week over week, I was responsible for shipping important features and was given a lot of responsibility right out of the gate.</p><p>I eventually got pretty good at choosing strong founders to join and building great products from zero to one which in turn spawned a cycle of joining a team early, finding success, the company gets too big, and then I leave to do it again elsewhere. I have been an early or first engineer at five different companies and have had three liquidity events in a 9-year career.</p><h3 id="the-reality-of-founder-risk-liquidity">The Reality of Founder Risk &amp; Liquidity</h3><p><strong>Founder liquidity</strong> refers to the practice where founders sell a portion of their shares during a new funding round. This allows them to "take chips off the table," securing personal financial stability while continuing to build the company with a fresh influx of venture capital. This practice is often kept under wraps, discussed in closed boardrooms, and only briefly mentioned in investor updates. You would really only know this happened if you were a founder, investor, or had direct access to the cap table.</p><p>Why is it a secret that founders get liquidity in many venture rounds? Because it undermines the narrative of the founder who is "all-in." The story of the founder who mortgaged their house and lived on ramen noodles for years is compelling. It garners admiration and sympathy, attracting top talent willing to work for lower salaries in exchange for a piece of the pie. If it were widely known that founders could de-risk their financial position while their employees remained all-in, it might change how startups are perceived and valued.</p><p>This is a graph of cash compensation over time modeled off of a real scenario that happened over 4 years. This level of founder liquidity is fairly common.</p><figure><img src="https://www.stefantheard.com/content/images/2024/06/founder-liquidity-chart-1.png" alt="" loading="lazy" width="1056" height="547" srcset="https://www.stefantheard.com/content/images/size/w600/2024/06/founder-liquidity-chart-1.png 600w, https://www.stefantheard.com/content/images/size/w1000/2024/06/founder-liquidity-chart-1.png 1000w, https://www.stefantheard.com/content/images/2024/06/founder-liquidity-chart-1.png 1056w" sizes="(min-width: 720px) 720px"></figure><p>The founder in this scenario was offered $400,000 of liquidity at Series A and $750,000 at Series B and encouraged to do so by their board of investors to de-risk their own life. Liquidity was not offered to any employees and the fact that this happened at all was only revealed to people on the cap table.</p><p>Another more well-known and extreme example was in the case of Adam Neumann the founder of WeWork - Neumann was able to cash out over 2B in secondary meanwhile not a single WeWork employee was able to capitalize on their equity stakes. They were told internally how much their shares were worth at each raise, and the hype surrounding each raise continued as WeWork sky-rocketed in valuation. Neumann was smart to de-risk his position by selling as much secondary as possible during the ascent but only attempted to structure a tender offer for non-founding employees in 2019 <strong><em>nine years</em></strong> after WeWork was created. That tender offer with SoftBank fell through and employees were left with absolutely nothing. (<a href="https://www.forbes.com/sites/samanthasharf/2020/04/13/wework-employees-feel-abandoned-and-angry-as-softbank-ditches-its-3-billion-buyout-offer?ref=stefantheard.com">source</a>)</p><p>The part about these stories that feels unfair is not that the founders are getting liquidity - it's that they are the <em>only ones</em> getting liquidity. There are other stories like <a href="https://techfundingnews.com/unravelling-virtual-dreams-the-rise-and-fall-of-hopin/?ref=stefantheard.com" rel="noreferrer">Hopin</a> where the founder takes tens or hundreds of millions in secondary just to later sell the company for less than the <a href="https://www.holloway.com/g/venture-capital/sections/liquidation-preference?ref=stefantheard.com" rel="noreferrer">liquidation preference</a> stack and leave the employees with a grand total of zero dollars for their equity.</p><h3 id="right-sizing-perception">Right-Sizing Perception</h3><p>There are a lot of odd perceptions surrounding founder liquidity:</p><ol><li>Investors and founders both tend to think that if employees knew founders were getting liquidity that that would negatively impact employee morale (<strong>it wouldn‚Äôt</strong>)</li><li>Founders often feel guilty that they are getting liquidity (<strong>they shouldn‚Äôt</strong>)</li><li>Investors think that the liquidity could taint the perception of future investors negatively (<strong>it doesn‚Äôt</strong>)</li><li>Investors, founders, and employees all believe that founders are taking more risk than early employees (<strong>this isn‚Äôt true once founders have exclusive access to liquidity</strong>)</li></ol><p>When I found out that my founders got access to liquidity during our series A my first thought was ‚ÄúThat is awesome, they deserve it‚Äù my second thought was ‚ÄúI wonder why employees didn‚Äôt get access to any liquidity?‚Äù and then my third thought was ‚ÄúIs this a secret? It seems like a secret. That‚Äôs weird‚Äù. I was the only employee who knew about it because I had incidental access to the cap table.</p><p>Once I found out I was curious if I was reading it correctly so I immediately went to one of the founders and asked ‚ÄúDid you get a bit of liquidity during the series A?‚Äù. His reaction went from surprise to confusion and then he said ‚ÄúYeah I did, a little bit‚Äù. I said ‚ÄúWow that is awesome, congrats! It has to be nice to be able to backfill some salary after grinding for a couple of years‚Äù and he said, ‚ÄúYeah, definitely.‚Äù. I could sense relief after chatting about it with him, almost like he felt better knowing that I knew about it. I never felt negative, had low morale, or anything of the sort, I trusted in my founding team and I was happy for them. If it were the case that I was lied to about it, then I would be upset and have low morale but that would be a result of being lied to - not liquidity access.</p><h3 id="balancing-the-scales">Balancing the Scales</h3><p>As of 4 months ago I left a very successful stealth startup (which grew to 40M in ARR in two years) to become a founder and that is when it clicked - I expected to feel stressed, pressured, and the weight of all of the risk I was taking. What actually happened is that I realized I could have been a founder 6 years ago and I would have been taking a similar amount of risk as I did then as the first employee at <a href="http://tackle.io/?ref=stefantheard.com">tackle.io</a>.</p><p>My intention now, as a founder, is to balance the risk for early employees by being transparent, more generous with equity, and only taking liquidity if I can also offer it to employees as well.</p><ul><li>Our employee option pool is 20% which is double the average</li><li>We have a 3-month equity cliff which is 9 months sooner than the average.</li><li>We allow employees to exercise options up to 10 years after they leave instead of 90 days.</li><li>Our equity packages vest over 3 years instead of the industry standard 4-year period.</li></ul><p>These changes are great, but nowhere near enough. In my view, every internal announcement of a new round at venture-backed companies should be accompanied by education and transparency around liquidity. Without transparency, none of the misperceptions have a chance of going away. The net result is that employees have a fundamentally misguided idea of the risk landscape as it shifts beneath their feet. </p><div><p>If you work at a venture-backed company the next time a round is announced ask if the founders took any liquidity. Do it anonymously if you have to. This question should become so common that founders and investors become transparent by default. If they say no, great - no change to risk profiles. If they say yes - great, employees are operating with the same information as the founders and investors. This levels the playing field and allows employees to assess if they are still in a lower risk bucket than the founders, or if they are now taking significantly more risk than the founders.</p><p>If employees realize they are taking more risk than the founders, maybe they'll ask for more compensation, maybe they'll congratulate the founders and move on with their day, maybe they'll start yelling: "I'M TAKING SO MUCH RISK, IT'S SO HARD TO BUILD A COMPANY, I DON'T EVEN HAVE ACCESS TO LIQUIDITY!!!". And maybe they're right.</p></div><p><em>(special thanks to anu, jessica, erika, laura, derek, and minh for reading drafts and giving  feedback on this)</em></p>
        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[T-Mobile users thought they had a lifetime price lock‚Äìguess what happened next (191 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/06/t-mobile-users-thought-they-had-a-lifetime-price-lock-guess-what-happened-next/</link>
            <guid>40653785</guid>
            <pubDate>Wed, 12 Jun 2024 02:09:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/06/t-mobile-users-thought-they-had-a-lifetime-price-lock-guess-what-happened-next/">https://arstechnica.com/tech-policy/2024/06/t-mobile-users-thought-they-had-a-lifetime-price-lock-guess-what-happened-next/</a>, See on <a href="https://news.ycombinator.com/item?id=40653785">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/06/t-mobile-logo-800x533.jpg" alt="A large T-Mobile logo above a conference hall.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/06/t-mobile-logo.jpg" data-height="1667" data-width="2500">Enlarge</a> <span>/</span> T-Mobile logo above the Deutsche Telekom pavilion at Mobile World Congress 2024 in Barcelona, Spain, on February 28, 2024. </p><p>Getty Images | NurPhoto </p></figcaption>  </figure>

  




<!-- cache hit 245:single/related:3bb49bf898878db2dc1931d956d3c958 --><!-- empty -->
<p>When T-Mobile <a href="https://arstechnica.com/tech-policy/2024/05/t-mobile-imposes-5-monthly-price-hike-on-customers-using-older-plans/">announced price hikes</a> of up to $5 per line on older smartphone plans last month, many customers were shocked because of T-Mobile's years-old promise that their price would never rise as long as they stuck with the same plan.</p>
<p>"New rule: Only YOU should have the power to change what you pay," T-Mobile said in a <a href="https://www.t-mobile.com/news/press/un-carrier-next">January 2017 announcement</a> of its "Un-contract" promise for T-Mobile One plans. "Now, T-Mobile One customers keep their price until THEY decide to change it. T-Mobile will never change the price you pay for your T-Mobile One plan."</p>
<p>Unfortunately, the promise wasn't as simple as T-Mobile claimed it to be in that press release. T-Mobile also published an FAQ that answered the question, "What happens if you do raise the price of my T-Mobile One service?" It explained that the only guarantee is T-Mobile will pay your final month's bill if the price goes up and you decide to cancel.</p>
<p>The FAQ stated, "The Un-contract is our commitment that only you can change what you pay and we mean it! To show just how serious we are we have committed to pay your final month's recurring service charges if we were to raise prices and you choose to leave. Just let us know within 60 days."</p>
<p>The FAQ link now just redirects to the T-Mobile home page but the Internet Archive has a <a href="https://web.archive.org/web/20180124073308/https://www.t-mobile.com/offers/tmo_one_faqs#uncontractpromise">capture</a> of the FAQ from January 2018. While we couldn't find an earlier capture of the page, a <a href="https://forums.androidcentral.com/threads/t-mobile-un-carrier-next.760027/#post-5636154">discussion</a> on an Android Central forum shows that the text mentioned above was noticed by some customers in January 2017.</p>
<p>The Un-contract was also previously <a href="https://www.t-mobile.com/news/press/uncontract-carrier-freedom">applied to T-Mobile Simple Choice plans</a> starting in March 2015. The 2015 announcement said the Un-contract would be enabled automatically with "no crazy strings, no hoops to jump through, no hidden fees, no BS."</p>                                            
                                                        
<p>The recent price increases <a href="https://tmo.report/2024/05/confirmed-t-mobile-is-raising-prices-on-some-legacy-plans/">reportedly</a> affect Simple Choice plans as well as other packages, but we haven't been able to find any language from 2015 that acknowledges an exception that lets T-Mobile raise prices on Simple Choice. We asked T-Mobile several questions today and will update this article if it provides more information.</p>
<h2>T-Mobile disputes complaint to FCC</h2>
<p>T-Mobile is pointing to the above caveat to defend itself against at least one complaint filed to the Federal Communications Commission after the recent price hike. Yesterday, a Reddit user and T-Mobile subscriber <a href="https://www.reddit.com/r/tmobile/comments/1dd1x5t/did_anyone_else_get_the_following_letter_from/">posted a letter</a> in which T-Mobile asked the FCC to close the complaint filed by the user.</p>
<p>T-Mobile's response to the FCC and the user who complained said:</p>
<blockquote><p>Regarding these changes, we are aware some customers have inquired about T-Mobile's <em>Un-contract</em> and <em>Price Lock</em>. With <em>Un-contract</em>, T-Mobile committed to its customers that if we were to increase prices and customers chose to leave as a result, T-Mobile would pay the customers' final month's recurring service charge, as long as we are notified within 60 days. Consistent with this commitment, customers who activated on an eligible rate plan between January 5, 2017 and April 27, 2022, can request to have their final month's qualifying service charge reimbursed if their rate plan increases and they choose to cancel service. Customers simply need to request reimbursement within 60 days of the price increase.</p></blockquote>
<p>The T-Mobile response goes on to describe the more recent "Price Lock" guarantee that was offered starting in April 2022 and discontinued in January 2024. The T-Mobile response said that customer lines covered by Price Lock are exempt from the recent price increases:</p>
<blockquote><p>As for customers with concerns about T-Mobile's <em>Price Lock</em> guarantee, it is important to note that customers with <em>Price Lock</em> are not impacted by the change. On April 28, 2022, T-Mobile began offering <em>Price Lock</em> on new account activations on qualifying rate plans. For customers who activated on a qualifying plan between April 28, 2022 and January 17, 2024, <em>Price Lock</em> guarantees that accounts activated with a qualifying rate plan, within the enrollment period, would not be subject to a price increase, so long as the account remained in good standing and the customer remained on the qualifying rate plan.</p></blockquote>
<p>T-Mobile's response to the complaint also said that customers who switch plans lose their Price Lock guarantee.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AES-GCM and breaking it on nonce reuse (127 pts)]]></title>
            <link>https://frereit.de/aes_gcm/</link>
            <guid>40653125</guid>
            <pubDate>Wed, 12 Jun 2024 00:09:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frereit.de/aes_gcm/">https://frereit.de/aes_gcm/</a>, See on <a href="https://news.ycombinator.com/item?id=40653125">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="an-overview-of-this-article-tldr">An overview of this article (TL;DR)</h2><p>TL;DR: AES-GCM is great, as long as every nonce (mnemonic: <strong>n</strong>umber used <strong>once</strong>) is truly unique. Once a nonce is reused, AES-GCM completely falls apart.</p><p>If you‚Äôve ever worked with AES-GCM, you may have heard that reusing a nonce can lead to catastrophic security failures. In this post, we will look at how exactly all security guarantees of AES-GCM can be broken when a nonce is reused even once.</p><p>First, we‚Äôll quickly go over AES, then explain AES-GCM in detail. We‚Äôll then derive some formulas for the AES-GCM authentication tags and see how we can authenticate any message we want as soon as a nonce is reused.</p><p>This post will be somewhat math heavy, especially as we get to the nonce reuse attack. I‚Äôll try my best to explain any concepts not covered by high-school math, and I‚Äôll skip over any details of the algorithms, as these are best understood by reading the original papers.</p><h2 id="aes">AES</h2><p>If you‚Äôre reading this, chances are you know what <abbr title="Advanced Encryption Standard">AES</abbr> is. It is the most widely used symmetric encryption algorithm and is almost always the symmetric cipher used when communicating over HTTPS.</p><p>AES is a block cipher, which means it encrypts and decrypts data in fixed-size blocks. The block size for AES is 128 bits, which is 16 bytes. This means that given a key, the AES algorithm can be used to transform a 128-bit block of data into another 128-bit block of data, and back again. We arbitrarily call this process encryption and decryption, respectively. There‚Äôs no intrinsic property of AES that assigns one direction to encryption and the other to decryption. It is important to understand that AES is a bijective function, meaning <em>any</em> 128-bit block of data can be encrypted into a 128-bit block of data, and that <em>any</em> 128-bit block of data is a valid ciphertext that can be decrypted again. This is a fundamental property of block ciphers and important to understand.</p><p>Because every single possible block of 128-bit data can be decrypted using AES, it is absolutely incorrect to assume that just because you <em>can</em> decrypt some ciphertext, that it was indeed encrypted using the key you have. Anyone ‚Äúin the middle‚Äù of a transmission can just replace the ciphertext, even if they don‚Äôt have the key, and AES won‚Äôt tell you that that‚Äôs happened.</p><p>There are three key sizes you can choose from when using AES: 128, 192, and 256. The key size changes some internal parameters of the algorithm, but the basic structure is the same. In this blog post, we will only be considering AES-128 but the same principles apply to the other key sizes as well, and for that matter, to any block cipher.</p><figure><img loading="lazy" src="https://frereit.de/img/aes/aes-block-cipher.svg" alt="AES is a bijective function parameterize by a key" data-ffwidth="51%" id="aes-block-cipher"><figcaption>AES is a bijective function parameterized by a key</figcaption></figure><p>It is important to understand that AES-128 is just that, a cipher that encrypts and decrypts a single 128-bit block of data. AES does not specify how to encrypt multiple blocks of data using a single key, nor does it authenticate the data. It is a simple bijective function parameterized by a key, nothing more, nothing less.</p><p>You can play with the following widget to see how AES-128 works. The widget allows you to encrypt and decrypt a single block of data using a key of your choice.</p><p>In summary, we can treat AES-128 as a simple black box that encrypts and decrypts 128-bit blocks of data using a key. It is a building block that can be used to build more complex cryptographic systems, but it is not a complete cryptographic system in itself.</p><h2 id="gcm">GCM</h2><p>When using a block cipher, we want to be able to encrypt arbitrary amounts of data, and we want to ensure that the encrypted data cannot be tampered with. This is where modes of operation come into play. A mode of operation is a way to use a block cipher to encrypt and authenticate data. There are many different modes of operation, but in this post, we will focus on the Galois/Counter Mode, or GCM for short.</p><p>GCM is a method for authenticated encryption with associated data (AEAD). ‚ÄúAuthenticated encryption‚Äù means that the mode of operation allows us to validate that a given ciphertext was indeed generated using the secret key, and that it has not been modified. This is called ‚Äúauthenticating‚Äù the ciphertext and is essential for secure communication. Without it, a bad actor could modify the ciphertext and the recipient would not be able to detect it, leading to garbled plaintext in the best case, and a huge security issue in the worst case.</p><p>The second part, ‚Äúwith associated data‚Äù, means that we can also authenticate additional data that is not encrypted. This is almost a byproduct of the way GCM works, but it is a very useful feature. For example, when sending a message, we might want to encrypt the message but keep the sender in plaintext. Think of a letter you‚Äôre mailing, where the contents are ‚Äúprotected‚Äù but the sender is plainly visible. By using AES-GCM, we are able to authenticate not only the ciphertext but also the sender so that the recipient can be sure that the message was indeed sent by the sender and that it is intended for them, even if the sender is not part of the ciphertext.</p><p>In this post, we‚Äôll look at the two parts of GCM (encryption and authentication) seperately. We‚Äôll start by seeing how encryption works with AES-GCM, where the nonce comes into play, and how the encryption breaks when a nonce is reused. After that, we‚Äôll dive into the authentication part and see how it can also be broken when a nonce is reused.</p><h3 id="gcm-encryption">GCM encryption</h3><p>GCM, like all modes of operation, provides a way to encrypt and decrypt arbitrary amounts of data using the underlying block cipher.</p><p>To do this, GCM uses the block cipher (in our case, AES-128) to generate a sequence of random-looking bits that are as long as the plaintext. This is called the keystream and it can be generated deterministically using the key (and a nonce, which we will get to in a bit), which means although it looks random, the recipient of a message in possesion of the key is able to calculate the same keystream. To encrypt the plaintext, we take the plaintext and XOR it with the keystream. XOR (‚äï) is a simple operation that takes any two bits and returns 1 if exactly one of the bits is 1, and 0 otherwise. It, conveniently, is its own inverse. This means that if we generate by XORing the plaintext and keystream (<code>ciphertext = plaintext ‚äï keystream</code>), we can decrypt the ciphertext, we generate the keystream used during the encryption and XOR it with the cipertext we received: <code>ciphertext ‚äï keystream = (plaintext ‚äï keystream) ‚äï keystream = plaintext</code>. So, technically, in GCM, we don‚Äôt actually encrypt the plaintext using the block cipher, we encrypt it using the keystream. The block cipher is only used to generate the keystream.</p><p>However, there‚Äôs a problem: Let‚Äôs assume for a moment that we have two plaintexts <code>p1</code> and <code>p2</code> and we want to encrypt them both using the same key. If the keystream was only generated using the key, then the keystream for <code>p1</code> would be the same as the keystream for <code>p2</code>. The ciphertexts would then be <code>c1 = p1 ‚äï keystream</code> and <code>c2 = p2 ‚äï keystream</code>. At first glance, this seems fine, but it is not. If an attacker knows the plaintext <code>p1</code> and the ciphertext <code>c1</code>, then they can compute the keystream by XORing <code>p1</code> and <code>c1</code> together (<code>keystream = p1 ‚äï c1</code>) and then decrypt <code>c2</code> by XORing <code>c2</code> with the keystream (<code>p2 = c2 ‚äï keystream = c2 ‚äï (p1 ‚äï c1)</code>). This is a huge security issue, as it allows an attacker to decrypt any ciphertext they have the plaintext for, without knowing the key. This is why we need to introduce a <strong>nonce</strong>.</p><p>A nonce is a random number transfered along with each ciphertext that may never be reused under the same key. We use the nonce as an additional input to the block cipher when generating the keystream so that for each ciphertext, the keystream is different. This means that even if an attacker knows the plaintext and ciphertext for one message, they cannot use that information to decrypt any other ciphertext. When a nonce is reused, however, the keystream is the same, and an attacker can use the same technique as above to decrypt any ciphertext that was encrypted using the same nonce.</p><p>Let‚Äôs take a look at an example! First, we choose a nonce and generate a keystream using the key from earlier and the chosen nonce:</p><p>Notice how <code>c2 ‚äï p1 ‚äï c1</code> is the same as <code>p2</code> as long as <code>p1</code> is long enough? This is the security issue we were talking about. If the nonce is reused, an attacker only needs a single pair of plaintext and ciphertext to decrypt any other ciphertext that was encrypted using the same key and nonce. Additionally, by obtaining the keystream, an attacker is able to create their own ciphertext for any plaintext they want, simply by XORing the plaintext with the recovered keystream. Therefore, encryption is trivially broken when a nonce is reused.</p><h4 id="keystream-generation">Keystream generation</h4><p>Although not necessary for understanding the security issue, let‚Äôs look at how the keystream is generated in GCM. In GCM, we start off with some initial block of 16 bytes called <code>Y</code><sub><code>0</code></sub> that is calculated from the given nonce. Incrementing this block means taking the last 4 bytes and interpreting them as a 32-bit big-endian integer and incrementing that integer by 1. We start off by incrementing the initial block and then encrypting it using AES-128. This will gives us 16 bytes of output, which we then use as the first 16 bytes of the keystream. We then increment the block again and encrypt it again to get the next 16 bytes of keystream, and so on. This process is repeated until the entire plaintext is encrypted. Note that if the plaintext falls short of a full 16 bytes, we simply only take as many bytes as we need from the keystream instead of the full 16 bytes. This process of ‚Äúcounting up‚Äù and encrypting the resulting block to get the keystream is the ‚ÄúCounter Mode‚Äù part of Galois/Counter Mode.</p><figure><img loading="lazy" src="https://frereit.de/img/aes/gcm-ctr.svg" alt="GCM uses a simple counter to generate consecutive keystream blocks" data-ffwidth="99%" id="gcm-ctr-mode"><figcaption>GCM uses a simple counter to generate consecutive keystream blocks</figcaption></figure><p>As you can see, the generated keystream only depends on <code>Y</code><sub><code>0</code></sub>, which in turn only depends on the nonce, and the key. This means that if the nonce is reused across different messages, the keystream will be the same for both messages, and an attacker can use the technique as above to decrypt any ciphertext that was encrypted using the same nonce.</p><h5 id="ysub0sub-calculation"><code>Y</code><sub><code>0</code></sub> calculation</h5><p>I told you before that <code>Y</code><sub><code>0</code></sub> is calculated from the nonce, but I didn‚Äôt tell you how. In the simple case, the supplied nonce is 12 bytes long (e.g. <code>deadbeefcafeaffebadbabe0</code>). In that case, <code>Y</code><sub><code>0</code></sub> is the nonce with a 4-byte big endian 1 appended to it, so <code>Y</code><sub><code>0</code></sub><code> = nonce || 0x00000001</code>. If the nonce is not exactly 12 bytes long, we generate <code>Y</code><sub><code>0</code></sub> by passing it through a kind-of hash function called <code>GHASH</code>. We‚Äôll look at <code>GHASH</code> in more detail later but for now, just imagine that <code>GHASH</code> takes a nonce of any length and spits out a 16-byte block that we can use as <code>Y</code><sub><code>0</code></sub>.</p><p>The generated <code>Y</code><sub><code>0</code></sub> is then used to generate the keystream as described above.</p><h4 id="recap">Recap</h4><p>We‚Äôve now seen how the encryption part of GCM works. We‚Äôve seen that the nonce is used together with the key to generate a keystream that is then used to encrypt the plaintext. We‚Äôve also seen that if the nonce is reused, an attacker can use a single known plaintext-ciphertext pair to decrypt any other ciphertext that was encrypted using the same nonce. Once an attacker has obtained the keystream, they can also use it to encrypt any plaintext they want, so there is no guarantee that the plaintext was indeed generated by the sender in possession of the key.</p><h3 id="gcm-authentication">GCM authentication</h3><p>The second and equally important part of GCM is the authentication. This means that we are able to validate that a given ciphertext was indeed generated using the secret key, and that it has not been modified. At the risk of repeating myself, remember that the encryption part of GCM only ensures that the ciphertext cannot be decrypted without the key, but it does not ensure that is has not been tampared with. The encryption operation is a simple XOR operation, so if an attacker changes a single bit in the ciphertext from a <code>0</code> to a <code>1</code>, the corresponding bit in the plaintext will also change. This means that even though the ciphertext cannot be decrypted without the key, an attacker can still modify the ciphertext and the recipient would not be able to detect it. With a single known plaintext-ciphertext pair, an attacker is even able to recover the entire keystream and thus encrypt any plaintext they want. Hence, we need to authenticate the ciphertext.</p><h4 id="galois-field-arithmetic">Galois field arithmetic</h4><p>A core part of the authentication in GCM is the use of Galois field arithmetic, the other part of Galois/Counter Mode. Galois field arithmetic is just a fancy name for a kind of maths where we don‚Äôt have infinite numbers like in the real numbers, but instead we have a finite number of elements. This is why sometimes Galois fields are also called ‚Äúfinite fields‚Äù.</p><h5 id="gf2"><code>GF(2)</code></h5><p>The simplest example of a Galois field is the field of integers modulo <code>2</code>. This means that we only have two elements, <code>0</code> and <code>1</code>. Forget all other numbers, only <code>0</code> and <code>1</code> exist when we‚Äôre talking about <code>GF(2)</code>. Because this is a new number system, we have to definie how mathematical operations work in it. If no other numbers exist, what is <code>1 + 1</code>?</p><p>We <em>define</em> addition of numbers in these fields to be the result of adding the numbers in the real numbers and then taking the result modulo <code>2</code>. The modulo operation simply takes the remainder of a whole number divison. For example, in the real numbers, <code>5 = 2 * 2 + 1</code>, so <code>5 = 1 (mod 2)</code>. Let‚Äôs look at how this looks in an addition table:</p><table><tbody><tr><th>+</th><th>0</th><th>1</th></tr><tr><th>0</th><td>0</td><td>1</td></tr><tr><th>1</th><td>1</td><td>0</td></tr></tbody></table><p>As you can see, <code>0 + 0 = 0</code>, <code>0 + 1 = 1</code>, <code>1 + 0 = 1</code>, and <code>1 + 1 = 0</code>. You might recognize this as the XOR operation that we used to encrypt the plaintext with the keystream. This is no coincidence, as the XOR operation is exactly the addition operation in the Galois field of integers modulo <code>2</code>. This means that when we XOR two numbers together, we can also think of it as adding them together in the Galois field of integers modulo <code>2</code>. To make it clear that we are working in a different number system, we don‚Äôt use the <code>+</code> symbol for addition in Galois fields, but instead use the <code>‚äï</code> symbol. You might have seen this symbol as the XOR operation, and now you know that it is exactly the same as addition in the Galois field of integers modulo <code>2</code>.</p><p>Now, let‚Äôs look at how we <em>define</em> multiplication in the Galois field of integers modulo <code>2</code>. We define it to be the result of multiplying the numbers in the real numbers and then taking the result modulo <code>2</code>. Let‚Äôs look at how this looks in a multiplication table:</p><table><tbody><tr><th>‚ãÖ</th><th>0</th><th>1</th></tr><tr><th>0</th><td>0</td><td>0</td></tr><tr><th>1</th><td>0</td><td>1</td></tr></tbody></table><p>Again, you might notice that this is exactly the same as the AND operation. The result of multiplying two numbers in <code>GF(2)</code> is <code>1</code> if and only if both numbers are <code>1</code>. This means that when we AND two numbers together, we can also think of it as multiplying them together in the Galois field of integers modulo <code>2</code>. Analogously to the addition operation, where we use the <code>‚äï</code> symbol, we use the <code>‚®Ç</code> symbol to represent multiplication in Galois fields.</p><h5 id="gf2sup128sup"><code>GF(2</code><sup><code>128</code></sup><code>)</code></h5><p>We can also define Galois fields with more than two elements. For example, we can define a Galois field with <code>2</code><sup><code>128</code></sup> elements. This means that we have <code>2</code><sup><code>128</code></sup> different numbers, which is just to say that we use 128 bits (16 bytes!) to represent each number. You might already notice that this is exactly the same as the block size of AES. As you‚Äôll see later, this is no coincidence, because we‚Äôll start interpreting the 128-bit blocks of data as elements represented by numbers in <code>GF(2</code><sup><code>128</code></sup><code>)</code>.</p><p>First, though, we need to define addition and multiplication in <code>GF(2</code><sup><code>128</code></sup><code>)</code> just like we did for <code>GF(2)</code>. One way to think of elements in <code>GF(2</code><sup><code>128</code></sup><code>)</code> is as polynomials with coefficients in <code>GF(2)</code>. This is just a definition, we have this set of <code>2</code><sup><code>128</code></sup> things, and we say that each of the things corresponds to some polynomial. This means that we can represent each element in <code>GF(2</code><sup><code>128</code></sup><code>)</code> as a polynomial of degree at most <code>127</code> with coefficients in <code>GF(2)</code>. So, some elements of <code>GF(2</code><sup><code>128</code></sup><code>)</code> can be represented like so:</p><ul><li><code>0 ‚ãÖ x</code><sup><code>0</code></sup><code> = 0</code>.</li><li><code>1 ‚ãÖ x</code><sup><code>0</code></sup><code> = 1</code>.</li><li><code>x</code><sup><code>4</code></sup><code> + x</code>.</li><li><code>x</code><sup><code>127</code></sup><code> + x</code><sup><code>126</code></sup><code> + x</code><sup><code>125</code></sup>.</li></ul><p>Because we‚Äôve defined the the coefficients to be in <code>GF(2)</code>, they are all either <code>0</code> or <code>1</code>. Another way to look at this is that <code>x</code><sup><code>i</code></sup> is either in the polynomial or it is not, for each <code>i</code> from <code>0</code> to <code>127</code>. This means that we can represent each element in <code>GF(2</code><sup><code>128</code></sup><code>)</code> as a 128-bit value, where each bit tells us if a certain power of <code>x</code> is in the polynomial or not. Different standards use different ways to assign the bits to the powers of <code>x</code> but the GCM standard uses a kind-of reversed order, so that the most significant bit of the 128-bit value corresponds to <code>x</code><sup><code>0</code></sup>, the next bit to <code>x</code><sup><code>1</code></sup>, and so on, up to the least significant bit corresponding to <code>x</code><sup><code>127</code></sup>. Let‚Äôs encode the previous polynomials in this way as hexadecimal values:</p><ul><li><code>0</code> is <code>00000000000000000000000000000000</code> because no powers of <code>x</code> are in the polynomial.</li><li><code>1</code> is <code>80000000000000000000000000000000</code> because <code>x</code><sup><code>0</code></sup> is in the polynomial, which is the most significant bit.</li><li><code>x</code><sup><code>4</code></sup><code> + x</code> is <code>48000000000000000000000000000000</code>.</li><li><code>x</code><sup><code>127</code></sup><code> + x</code><sup><code>126</code></sup><code> + x</code><sup><code>125</code></sup> is <code>00000000000000000000000000000007</code>.</li></ul><p>We now have a way of representing each of the <code>2</code><sup><code>128</code></sup> elements of <code>GF(2</code><sup><code>128</code></sup><code>)</code> as a polynomial. To define addition, we use the polynomial representation, which already has a well-defined addition operation. Remember, all coefficients are in <code>GF(2)</code>, so we add them together using the addition operation we defined earlier, for example <code>(x</code><sup><code>2</code></sup><code> + x) + (x</code><sup><code>4</code></sup><code> + x</code><sup><code>2</code></sup><code> + 1) = x</code><sup><code>4</code></sup><code> + x + 1</code>. The result is a polynomial of degree at most <code>127</code> with coefficients in <code>GF(2)</code>, so it is a valid element in <code>GF(2</code><sup><code>128</code></sup><code>)</code>. Note that if a power of <code>x</code> appears in both polynomials, it will be cancelled out, so for example <code>(x</code><sup><code>2</code></sup><code>) + (x</code><sup><code>2</code></sup><code>) = 0</code>. If it appears in exactly one of the polynomials, it will be in the result. This is exactly the same as the XOR operation, so we can again think of addition in <code>GF(2</code><sup><code>128</code></sup><code>)</code> as the XOR operation on the 128-bit values representing the polynomials.</p><p>You can try it out for yourself here. Enter two polynomials or their hexadecimal representations and see the result of adding them together:</p><p>Hopefully you‚Äôre able to convince yourself that adding these polynomials is exactly the same as XORing the 128-bit values representing them. This is the addition operation in <code>GF(2</code><sup><code>128</code></sup><code>)</code>.</p><p>Now, let‚Äôs take a look at multiplication. Multiplication, just like addition, works by interpreting the field elements as polynomials and then multiplying the polynomials together. For example, <code>(x</code><sup><code>2</code></sup><code> + x) ‚ãÖ (x</code><sup><code>4</code></sup><code> + 1) = x</code><sup><code>6</code></sup><code> + x</code><sup><code>5</code></sup><code> + x</code><sup><code>2</code></sup><code> + x</code>. We get this result by multiplying all the terms in the first polynomial with all the terms in the second polynomial and then adding the results together. In this case, the result is a polynomial with degree <code>6</code> and coefficients in <code>GF(2)</code>, so it is a valid element in <code>GF(2</code><sup><code>128</code></sup><code>)</code>. However, look at what happens when we multiply <code>x</code><sup><code>127</code></sup> by <code>x</code>: <code>x</code><sup><code>127</code></sup><code> ‚ãÖ x = x</code><sup><code>128</code></sup>. This poses a problem because we defined <code>GF(2</code><sup><code>128</code></sup><code>)</code> to have elements of degree at most <code>127</code> but this polynomial is of degree <code>128</code>. So <code>x</code><sup><code>128</code></sup> is not an element which we can represent as a 128-bit block of data.
Instead, we need to add another step to the multiplication operation:</p><p>After we multiply the polynomials together, we divide the result by a special polynomial called the ‚Äúreduction polynomial‚Äù and take the remainder as the result instead. The reduction polynomial must be defined along with the field. It is an irreducible polynomial, which means that it isn‚Äôt the product of any two non-trivial polynomials (like how prime numbers aren‚Äôt the product of any two other numbers, except one and itself) and has degree 128, so that the remainder of a division operation is always of degree at most 127. The GCM standard defines the reduction polynomial to be <code>x</code><sup><code>128</code></sup><code> + x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1</code> for the field <code>GF(2</code><sup><code>128</code></sup><code>)</code> used in GCM.</p><p>In this case, where we are trying to reduce <code>x</code><sup><code>128</code></sup>, it‚Äôs actually quite easy to see that dividing <code>x</code><sup><code>128</code></sup> by <code>x</code><sup><code>128</code></sup><code> + x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1</code> will result in a remainder of <code>x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1</code> because <code>x</code><sup><code>128</code></sup> fits exactly once into the reduction polynomial, leaving a remainder of <code>x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1</code>. Multiplying <code>x</code><sup><code>128</code></sup> by <code>1</code> and adding the remainder confirms this:</p><p><code>1 ‚ãÖ (x</code><sup><code>128</code></sup><code>) + (x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1) = x</code><sup><code>128</code></sup><code> + x</code><sup><code>7</code></sup><code> + x</code><sup><code>2</code></sup><code> + x + 1</code>.</p><p>For more complex cases, we need to use polynomial long division to divide the result by the reduction polynomial and take the remainder as the result. This is a bit more involved, but it is exactly the same as long division with real numbers, just with polynomials instead. I won‚Äôt go into the details here because we can just let the computer do the work for us, but if you‚Äôre interested, you can look up polynomial long division on the internet and try to apply it to coefficients in <code>GF(2)</code> instead of real numbers<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><p>If we look at the multiplication in <code>GF(2</code><sup><code>128</code></sup><code>)</code> from the perspective of the 128-bit blocks of data, instead of the polynomials, the operation is sometimes referred to as ‚ÄúCarry-less multiplication‚Äù, because it corresponds to the multiplication of the 128-bit blocks of data, where all carry values are discarded instead of propagated during the multiplication. In this post, we‚Äôll stick to the polynomial representation, but it‚Äôs good to know that the operation is also called ‚ÄúCarry-less multiplication‚Äù or ‚ÄúCLMUL‚Äù, especially if you‚Äôre looking at the AES-NI instruction set of modern CPUs. The symbol for multiplication in Galois fields is <code>‚®Ç</code>, so we‚Äôll use that in the following figures.</p><p>Let‚Äôs go through another example. Enter two polynomials and see the result of multiplying them together:</p><p>That covers the basics of Galois field arithmetic. We‚Äôve seen that we can add and multiply elements in <code>GF(2</code><sup><code>128</code></sup><code>)</code> just like we can add and multiply real numbers, but with the added step of reducing the result by a reduction polynomial. Importantly, we can also think of addition as the XOR operation, which is why it can also be represented by the <code>‚äï</code> symbol. Multiplication is represented by the <code>‚®Ç</code> symbol in the following figures.</p><h4 id="ghash">GHASH</h4><p>Now that we have the basics of Galois field arithmetic down, we can look at the <code>GHASH</code> function. <code>GHASH</code> is a function defined in the GCM standard that takes a key and arbitrary amounts of data and spits out a 128-bit block of data. This block of data is then used in the GCM standard to authenticate the ciphertext and the associated data.</p><p>To use <code>GHASH</code>, we first need to derive a 128-bit block that we can use as the <code>GHASH</code> key <code>H</code>. This is done by encrypting a block of 16 null bytes using AES and the AES key. This block is then interpreted as a polynomial and used as the <code>GHASH</code> key <code>H</code> for the rest of the <code>GHASH</code> computation:</p><figure><img loading="lazy" src="https://frereit.de/img/aes/h-key.svg" alt="The GHASH key H is derived by encrypting a block of 16 null bytes using AES-128 and the AES key" data-ffwidth="51%"><figcaption>The GHASH key H is derived by encrypting a block of 16 null bytes using AES-128 and the AES key</figcaption></figure><p>To compute <code>GHASH</code>, we first need to represent the data we want to authenticate as a sequence of 128-bit blocks. This is done by splitting the data into 128-bit blocks and then padding the last block with null bytes if it is not already 128 bits long. We do this separately for the associated data and the ciphertext, so for example if we wanted to authenticated the associated data <code>deadbeef</code> and the ciphertext <code>cafeaffe</code>, we‚Äôd use the blocks <code>deadbeef000000000000000000000000</code> and <code>cafeaffe000000000000000000000000</code> as the input to <code>GHASH</code>. To make sure the size of the data is not lost, we add one more block at the end that contains the length of the associated data in bits as a 64-bit big-endian integer and the length of the ciphertext in bits as a 64-bit big-endian integer concatenated together, so in this case <code>00000000000000200000000000000020</code> for the associated data <code>deadbeef</code> and the ciphertext <code>cafeaffe</code>.</p><p>To start the computation, we initialize a <code>GF(2</code><sup><code>128</code></sup><code>)</code> element <code>Q</code> to <code>0</code>. We then process the prepared blocks in sequence. The blocks from the associated data are processed first, followed by the blocks from the ciphertext. The length block is processed last. For each block, we interpret the block as a <code>GF(2</code><sup><code>128</code></sup><code>)</code> element and add it to <code>Q</code> using the addition operation in <code>GF(2</code><sup><code>128</code></sup><code>)</code> (which is just the XOR operation) and then multiply <code>Q</code> by the <code>GHASH</code> key <code>H</code> using the multiplication and reduction operation we defined earlier.</p><figure><img loading="lazy" src="https://frereit.de/img/aes/ghash.svg" alt="The GHASH function processes 128-bit blocks in order" data-ffwidth="99%"><figcaption>The GHASH function processes 128-bit blocks in order</figcaption></figure><p>The <code>result</code> of the <code>GHASH</code> function is the final value of <code>Y</code> after processing all the blocks. For security reasons that will hopefully become clear later, we cannot use the <code>result</code> directly as the authentication tag. Instead, we encrypt the <code>Y</code><sub><code>0</code></sub> block from earlier using the AES key and XOR the encrypted <code>Y</code><sub><code>0</code></sub> block with the <code>result</code> to get the final authentication tag. This is the value that is sent along with the ciphertext and the associated data to the recipient, who can then use the same key to compute the <code>GHASH</code> function and verify that the authentication tag is correct. An attacker who does not know the key cannot modify the ciphertext or the associated data without the recipient noticing, because they would not be able to compute the correct authentication tag, because they cannot derive <code>H</code> and the encrypted <code>Y</code><sub><code>0</code></sub> block.</p><h5 id="formula-for-ghash">Formula for GHASH</h5><p>We can also express the <code>GHASH</code> function as a formula. Let <code>H</code> be the <code>GHASH</code> key and <code>U</code><sub><code>i</code></sub> be the <code>i</code>-th prepared block. So, in the example above, <code>U</code><sub><code>0</code></sub> would be <code>deadbeef000000000000000000000000</code>, <code>U</code><sub><code>1</code></sub> would be <code>cafeaffe000000000000000000000000</code>, and <code>U</code><sub><code>2</code></sub> would be <code>00000000000000200000000000000020</code>.</p><p>We can build the formula for <code>GHASH</code> iteratively:</p><ol><li>First, we initialize <code>Q</code> to <code>0</code>: <code>Q ‚Üê 0</code>.</li><li>Then, for the first block, we add it to <code>Q</code>: <code>Q ‚Üê Q ‚äï U</code><sub><code>0</code></sub> (which is the same as <code>Q = U</code><sub><code>0</code></sub> because <code>Q</code> is <code>0</code>).</li><li>We then multiply <code>Q</code> by <code>H</code>: <code>Q ‚Üê Q ‚®Ç H = (U</code><sub><code>0</code></sub><code>) ‚®Ç H</code>.</li><li>For the second block, we add it to <code>Q</code>: <code>Q ‚Üê Q ‚äï U</code><sub><code>1</code></sub><code> = ((U</code><sub><code>0</code></sub><code>) ‚®Ç H) ‚äï U</code><sub><code>1</code></sub>.</li><li>Again, we multiply <code>Q</code> by <code>H</code>: <code>Q ‚Üê Q ‚®Ç H = (((U</code><sub><code>0</code></sub><code>) ‚®Ç H) ‚äï U</code><sub><code>1</code></sub><code>) ‚®Ç H</code>.</li><li>We can continue this process for all the blocks and the final result is the <code>GHASH</code> value. The formula for <code>GHASH</code> is then: <code>Q = (((((U</code><sub><code>0</code></sub><code> ‚®Ç H) ‚äï U</code><sub><code>1</code></sub><code>) ‚®Ç H) ‚äï U</code><sub><code>2</code></sub><code>) ‚®Ç H) ‚äï ...</code></li></ol><p>Take some time to look at the formula and see if you can convince yourself that it indeed the same as the graphical representation above.</p><p>Multiplication and addition in <code>GF(2</code><sup><code>128</code></sup><code>)</code> follows the usual laws of multiplication and addition, so we can distribute the multiplication of <code>H</code> over the additions. This means that <code>(((U</code><sub><code>0</code></sub><code>) ‚®Ç H) ‚äï U</code><sub><code>1</code></sub><code>) ‚®Ç H = (U</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U</code><sub><code>1</code></sub><code> ‚®Ç H)</code>.</p><p>We can apply this rule to the formula above to get a more compact formula for <code>GHASH</code>:</p><p><code>Q = (U</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>n+1</code></sup><code>) ‚äï (U</code><sub><code>1</code></sub><code> ‚®Ç H</code><sup><code>n</code></sup><code>) ‚äï ... ‚äï (U</code><sub><code>n-1</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U</code><sub><code>n</code></sub><code> ‚®Ç H)</code>.</p><p>Lastly, we have to XOR the result with the encrypted <code>Y</code><sub><code>0</code></sub> block to get the final authentication tag. We have to add the encrypted <code>Y</code><sub><code>0</code></sub> block to the result to get the final authentication tag <code>T</code>, because adding in <code>GF(2</code><sup><code>128</code></sup><code>)</code> is equal to the XOR operation:</p><p><code>T = Q ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>) = (U</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>n+1</code></sup><code>) ‚äï ... ‚äï (U</code><sub><code>n</code></sub><code> ‚®Ç H) ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code>.</p><p>Now that we have a formula for <code>GHASH</code>, we can use it to compute the authentication tag for the ciphertext and the associated data. Let‚Äôs take a look at an example! Enter some key, nonce, associated data, and ciphertext and see the authentication tag computed using the <code>GHASH</code> function:</p><p>Okay, that was a lot! We‚Äôve now seen how the <code>GHASH</code> function works and how it is used to authenticate the ciphertext and the associated data. We‚Äôve also seen that we can represent the <code>GHASH</code> function as a formula that we can use to compute the authentication tag in <code>GF(2</code><sup><code>128</code></sup><code>)</code>. To verify the authenticity of the ciphertext and the associated data, the recipient can compute the <code>GHASH</code> function using the same key and the same nonce and compare the result to the authentication tag. If the two values match, the recipient can be sure that the ciphertext and the associated data have not been tampered with and that they were indeed generated by the sender in possession of the key.</p><h3 id="recap-1">Recap</h3><p>We‚Äôve now seen how GCM works. It allows us to encrypt and authenticate data using a secret key, and detect if the encrypted data has been tampered with.</p><p>Enter any plaintext, key, and nonce and see the ciphertext and authentication tag computed using AES-GCM<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. This time, unlike in plain AES, when you change the ciphertext or authentication tag, the decryption will fail because the authentication tag will not match:</p><p>If you‚Äôve made it this far into the blog post, now may be a good time to take a break and let all the information sink in before we continue on to the attack on AES-GCM when a nonce is reused. If you have any questions, feel free to <a href="https://infosec.exchange/@fre">send me a toot</a>.</p><p><marquee scrollamount="3" scrolldelay="60" direction="right" behavior="alternate">‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï</marquee></p><p>Alright, let‚Äôs continue to the attack!</p><h2 id="nonce-reuse">Nonce Reuse</h2><p>We have now seen how AES-GCM works and how the authentication tag is computed. We have also seen that the nonce is used in the computation of the authentication tag. But what happens if the nonce is reused?</p><p>Let‚Äôs assume two authentication tags <code>T1</code> and <code>T2</code> are computed using the same key and nonce. For simplicitly, let‚Äôs assume the blocks used in the <code>GHASH</code> computation were <code>U1</code><sub><code>0</code></sub>, <code>U1</code><sub><code>1</code></sub> and <code>U1</code><sub><code>2</code></sub> for the first tag and <code>U2</code><sub><code>0</code></sub>, <code>U2</code><sub><code>1</code></sub> and <code>U2</code><sub><code>2</code></sub> for the second tag. In practice, the number of blocks used in the <code>GHASH</code> computation is (almost) irrelevant, but for this example, we‚Äôll stick to three blocks.</p><p>Let‚Äôs write out the formula for the first tag <code>T1</code>:</p><p><code>T1 = GHASH1 ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>) = (U1</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>3</code></sup><code>) ‚äï (U1</code><sub><code>1</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U1</code><sub><code>2</code></sub><code> ‚®Ç H) ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code>.</p><p>The formula for the second tag <code>T2</code> is similar:</p><p><code>T2 = GHASH2 ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>) = (U2</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>3</code></sup><code>) ‚äï (U2</code><sub><code>1</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U2</code><sub><code>2</code></sub><code> ‚®Ç H) ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code>.</p><p>Notice how in both formulas <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> appears. This is the crucial part. Remember that <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> is the encryption of the <code>Y</code><sub><code>0</code></sub> block using the AES key. The <code>Y</code><sub><code>0</code></sub> block is only dependant on the nonce, which we assume to have been the same in both messages, and of course we assume both messages were encrypted with the same key. This means that <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> is exactly the same value in both tags. This means that <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> can be cancelled out by adding the two equations together:</p><p><code>T1 ‚äï T2 = ((U1</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>3</code></sup><code>) ‚äï (U1</code><sub><code>1</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U1</code><sub><code>2</code></sub><code> ‚®Ç H) ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)) ‚äï ((U2</code><sub><code>0</code></sub><code> ‚®Ç H</code><sup><code>3</code></sup><code>) ‚äï (U2</code><sub><code>1</code></sub><code> ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï (U2</code><sub><code>2</code></sub><code> ‚®Ç H) ‚äï E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>))</code><br><code>= ((U1</code><sub><code>0</code></sub><code> ‚äï U2</code><sub><code>0</code></sub><code>) ‚®Ç H</code><sup><code>4</code></sup><code>) ‚äï ((U1</code><sub><code>1</code></sub><code> ‚äï U2</code><sub><code>1</code></sub><code>) ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï ((U1</code><sub><code>2</code></sub><code> ‚äï U2</code><sub><code>2</code></sub><code>) ‚®Ç H)</code>.</p><p>By adding the two equations together, we have completely eliminated <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code>. We‚Äôll now look at what‚Äôs left in this formula, and how we can use it to recover <code>H</code>.</p><p>Rearraning the formula by adding <code>T1 ‚äï T2</code> on both sides gives us a zero on one side of the equation:</p><p><code>0 = ((U1</code><sub><code>0</code></sub><code> ‚äï U2</code><sub><code>0</code></sub><code>) ‚®Ç H</code><sup><code>4</code></sup><code>) ‚äï ((U1</code><sub><code>1</code></sub><code> ‚äï U2</code><sub><code>1</code></sub><code>) ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï ((U1</code><sub><code>2</code></sub><code> ‚äï U2</code><sub><code>2</code></sub><code>) ‚®Ç H) ‚äï T1 ‚äï T2</code></p><p>Now, you might notice, this is <em>extremely</em> similar to a polynomial equation. In fact, it is a polynomial equation for <code>H</code>! Forget for a moment that <code>H</code> and all the <code>U</code> values are in <code>GF(2</code><sup><code>128</code></sup><code>)</code> and think of any other polynomial equation you might have seen, like <code>4x</code><sup><code>4</code></sup><code> + 2x</code><sup><code>3</code></sup><code> + 3x</code><sup><code>2</code></sup><code> + 7x + 1 = 0</code>. This is exactly the same, just with <code>H</code> instead of <code>x</code> and with coefficients the coefficients <code>U1</code><sub><code>i</code></sub><code> ‚äï U2</code><sub><code>i</code></sub> instead of a regular real number like <code>4</code>.</p><p>Note that attacker that has obtained both transmitted messages has knowledge of <code>T1</code>, <code>T2</code> as well as <code>U1</code> and <code>U2</code>, as the tag and ciphetext (with associated data) are the ‚Äúpublic‚Äù parts of the AES-GCM scheme. So, because an attacker has knowledge of <code>U1</code> and <code>U2</code>, we can treat this coefficient like any other constant coefficient in a polynomial equation. We‚Äôve already defined the addition and multiplication operations in <code>GF(2</code><sup><code>128</code></sup><code>)</code>, so hopefully it becomes clear that we can treat the formula we just derived like any other polynomial equation.</p><p>If we can find a solution for this polynomial equation, we can recover the <code>H</code> value. Why is this interesting? Remember that <code>H</code> is the <code>GHASH</code> key, which is derived from the AES key. If we can recover <code>H</code>, we can use it to compute the <code>GHASH</code> function for any data we want. This means that we can authenticate any data we want, even if we don‚Äôt know the AES key. Combined with the keystream recovery demonstrated early, this leads to a <strong><em>full break</em></strong> of the AES-GCM encryption scheme.</p><h3 id="solving-the-polynomial-equation">Solving the polynomial equation</h3><p>So, the question is, how do we solve this polynomial equation? This is where the Cantor-Zassenhaus algorithm comes in. The Cantor-Zassenhaus algorithm is an algorithm that can be used to factor polynomials specifically over finite fields. In our case, we want to factor the polynomial equation we derived earlier over <code>GF(2</code><sup><code>128</code></sup><code>)</code>. The Cantor-Zassenhaus algorithm is a probabilistic algorithm, which means that it might not always find a solution, but given enough attempts, it will find a solution with an arbitrarily high probability.</p><p>The Cantor-Zassenhaus algorithm cannot be applied to just any polynomial equation, there are a few requirements that must be ticked off before the algorithm can be used. Lukily, there exist other algorithms to ensure that these requirements are met for any given polynomial:</p><ol><li><p>The polynomial must be square-free, which means that it has no repeated roots. For example, let‚Äôs say we have a polynomial equation <code>H ‚äï 1 = 0</code>. Remember that addition in <code>GF(2</code><sup><code>128</code></sup><code>)</code> is the XOR operation, so if we set <code>H</code> to <code>1</code>, then <code>H ‚äï 1 = 1 ‚äï 1 = 0</code>. So the polynomial has a root at <code>H = 1</code>. If we now multiply this polynomial with itself, we get a new polynomial: <code>(H ‚äï 1) ‚®Ç (H ‚äï 1) = H</code><sup><code>2</code></sup><code> ‚äï 1</code>. This polynomial has a repeated root at <code>H = 1</code>, because <code>H ‚äï 1</code> appears twice in the factorization of the polynomial. You can also think of this as the polynomial having a factor <code>(H ‚äï 1)</code> squared. The Cantor-Zassenhaus algorithm cannot factor polynomials with repeated roots, so we need to make sure that the polynomial we derived earlier does not have any repeated roots, which is the case when it is ‚Äúsquare-free‚Äù. To achive this requirement, we will be constructing a new polynomial that contains all the factors of the original polynomial exactly once. Although this algorithm changes the ‚Äúform‚Äù of the polynomial, the values of the roots stay unchanged, only their multiplicity (how often they appear) is set to exactly one.</p></li><li><p>The polynomial must be the product of polynomials of equal degrees. For example, take the polynomial equation <code>H</code><sup><code>2</code></sup><code> ‚äï (x ‚®Ç H) ‚äï 1 = 0</code>. Here the <code>x</code> is the polynomial representation of the block value <code>40000000000000000000000000000000</code>, like we discussed earlier. This polynomial has degree <code>2</code> and is irreducible, which means that it cannot be factored into two polynomials of degree <code>1</code>. Any polynomial that has a root must have a factor of degree <code>1</code>, therefore any irreducible polynomial of degree <code>2</code> or higher cannot have any roots. If we multiply this by <code>H + 1</code>, we get <code>H</code><sup><code>3</code></sup><code> ‚äï ((x + 1) ‚®Ç H</code><sup><code>2</code></sup><code>) ‚äï ((x + 1) ‚®Ç H) ‚äï 1</code>, which is a polynomial of degree <code>3</code>. However, this polynomial cannot be factored using the Cantor-Zassenhaus algorithm because it is the product of one irreducible polynomial of degree <code>2</code> and one polynomial of degree <code>1</code>. We need to split the input polynomial its ‚Äúparts‚Äù, so into a list of polynomials that only have factors of the same degree. This is called ‚Äúdistinct-degree factorization‚Äù. It is the last step needed before we can then apply the Cantor-Zassenhaus algorithm to find the roots of each of the ‚Äúequal-degree‚Äù polynomials.</p></li></ol><p>The algorithms to make the polynomial square-free and to split it into polynomials of equal degrees are well-documented and there‚Äôs even pseudocode available on Wikipedia for <a href="https://en.wikipedia.org/wiki/Factorization_of_polynomials_over_finite_fields#Square-free_factorization">square-free factorization</a> and <a href="https://en.wikipedia.org/wiki/Factorization_of_polynomials_over_finite_fields#Distinct-degree_factorization">distinct-degree factorization</a> respectively.</p><p>Once we have a square-free polynomial that is the product of polynomials of equal degrees, we can use the Cantor-Zassenhaus algorithm to split the polynomial into two factors and do so repeatedly until we have found all the factors.</p><p>I‚Äôll outline the main idea of the Cantor-Zassenhaus algorithm here, but again, you can find <a href="https://en.wikipedia.org/wiki/Factorization_of_polynomials_over_finite_fields#Cantor%E2%80%93Zassenhaus_algorithm">pseudocode on Wikipedia</a><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. We want to factor a polynomial <code>f</code> into two factors. This assumes we already have a square-free polynomial and that it is the product of polynomials of equal degrees <code>d</code>. For polynomials in <code>GF(2</code><sup><code>128</code></sup><code>)</code>, the algorithm works as follows:</p><ol><li>Pick a random polynomial <code>h</code> of degree less than <code>f</code> and compute the greatest common divisor of <code>f</code> and <code>h</code>.</li><li>Set <code>M = ‚Öì(2</code><sup><code>d ‚ãÖ 128</code></sup><code> - 1)</code> and compute the greatest common denominator of <code>h</code><sup><code>M</code></sup><code> - 1</code> and <code>f</code>. We‚Äôll call this <code>g</code>.</li><li>If <code>g</code> is not <code>1</code> or <code>f</code> (which are both trivial factors that we don‚Äôt care about), we have found a non-trivial factor of <code>f</code>. We can then recursively factor <code>g</code> and <code>f / g</code> to find all the factors of <code>f</code>.</li><li>If <code>g</code> is <code>1</code> or <code>f</code>, we need to pick a new random polynomial <code>h</code> and try again.</li></ol><p>By just repeatedly picking a random polynomial, raising it to the power of <code>‚Öì ‚ãÖ (2</code><sup><code>d ‚ãÖ 128</code></sup><code> - 1)</code>, subtracting one, and computing the greatest common divisor with the polynomial we want to factor, we can find all the factors of the polynomial. But you might spot a problem: Raising a polynomial to the power of <code>‚Öì ‚ãÖ (2</code><sup><code>d ‚ãÖ 128</code></sup><code> - 1)</code> seems almost impossible, because that number is absolutely huge! But, of course, there‚Äôs a trick: Instead of raising the polynomial to the power of <code>‚Öì ‚ãÖ (2</code><sup><code>d ‚ãÖ 128</code></sup><code> - 1)</code>, and then computing the greatest common denominator immediately, we can reduce the polynomial by <code>f</code> before computing the greatest common denominator, without ‚Äúlosing‚Äù any factors. Calculating an almost arbitrarily large power with a given modulus is a well-known problem in computer algebra, and the square-and-multiply algorithm can be used to compute the result efficiently. Without this trick, the Cantor-Zassenhaus algorithm would be infeasible for polynomials of degree <code>128</code> in <code>GF(2</code><sup><code>128</code></sup><code>)</code> and it is one of the core reasons why the Cantor-Zassenhaus algorithm is so powerful.</p><p>Once we have found all the factors of the polynomial, we look at all the factors with degree <code>1</code>. These are the factors that are linear polynomials, so they are of the form <code>H + a</code> where <code>a</code> is a constant. We then know that when we set <code>H = a</code>, this linear polynomial will evaluate to zero, and is thus is a solution to the polynomial equation we derived earlier. Note that we might have multiple solutions for <code>H</code> if there are multiple roots to the polynomial but only one of them is the correct <code>H</code> used in the <code>GHASH</code> computation, which we will need to use if we want to authenticate other data. To do this, we need a third message that was authenticated using the same key and nonce. We can then use the recovered <code>H</code> to compute the <code>GHASH</code> function for the third message and check if the result of our computation matches the real authentication tag of the third message. If it does, we have successfully recovered the <code>H</code> value and can now authenticate any data we want.</p><h3 id="putting-it-all-together">Putting it all together</h3><p>We now have all the pieces we need to recover the <code>GHASH</code> key <code>H</code> if the nonce is reused. We can use the Cantor-Zassenhaus algorithm to factor the polynomial equation we derived earlier and recover the <code>H</code> value. We can then use the recovered <code>H</code> to compute the <code>GHASH</code> function for any data we want and authenticate it. Let‚Äôs see it all in action!</p><p>First, we need to simulate the nonce reuse. For simplicity, we‚Äôll ignore the associated data because it doesn‚Äôt affect the attack, it just means we have to take the associated data into account when constructing the polynomial equation. Enter a key, nonce and three plaintexts to compute the ciphertexts and the authentication tags<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>:</p><p>Now that we have the ciphertexts and the authentication tags for three messages that were encrypted using the same key and nonce, we can recover candidate <code>H</code> values by solving the polynomial equation we derived earlier and then verify the correct <code>H</code> value by computing the <code>GHASH</code> function for the third message if more than one <code>H</code> solves the equation.</p><p>We‚Äôll need to figure out the polynomial equation to solve. Let‚Äôs split up the first ciphertext into their respective blocks and XOR them together to get the coefficients of the polynomial equation:</p><p>Now, we can solve this equation to get candidate <code>H</code> values, one of which is the real <code>H</code> key used during AES-GCM authentication.</p><p>We have just used the Cantor-Zassenhaus algorithm to recover the <code>H</code> key and <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> value used during the AES-GCM authentication, which lets us authenticate <strong>any message we want</strong>.</p><h3 id="recap-2">Recap</h3><p>Although more complicated than the keystream recovery, when a nonce is reused, we can use polynomial factorization to figure out the <code>H</code> key, which ultimately let‚Äôs us authenticate any data we want. So, in total, the attack goes like this:</p><ol><li>Alice and Bob agree to a secret shared key. This key is unknown to the attacker.</li><li>Alice sends Bob a secret message, encrypted using AES-GCM. We assume that the attacker knows the plaintext that Alice sent, and records the nonce, ciphertext and tag transmitted by Alice to Bob.</li><li>Bob is able to use the nonce and tag to authenticate the ciphertext, and uses the shared key to decrypt the ciphertext.</li><li>Alice sends Bob two more messages, all encrypted using the <em>same nonce</em>. The attacker can use the first plaintext/ciphertext pair to recover the keystream, and thus recover the plaintext for these messages as well.</li><li>Bob, again, is able to use the nonce and tag to authenticate the ciphertext, and decrypt it using the shared key.</li><li>The attacker has recovered the keystream by XORing the first plaintext with the ciphertext.</li><li>The attacker uses the polynomial factorization to recover the <code>H</code> and <code>E</code><sub><code>k</code></sub><code>(y</code><sub><code>0</code></sub><code>)</code> values.</li><li>The attacker uses these values to construct a message and sends the message to Bob.</li><li>Bob successfully authenticates the ciphertext, even though the ciphertext wasn‚Äôt sent by Alice. Because the keystream is the same as well, Bob is also able to decrypt the ciphertext. This means that Bob has now received a message from the attacker that they think was sent by Alice.</li></ol><h2 id="conclusion">Conclusion</h2><p>Thank you for reading all the way through this huge post! I hope I was able to explain AES-GCM well enough and that you‚Äôve got a good feel for why resuing a nonce with AES-GCM is such a big deal.</p><p>If you‚Äôre interested, the code powering all the interactive widgets here is on GitHub. The factorization algorithms were implemented in <a href="https://github.com/frereit/frereit.github.io/tree/main/wasm/cantor-zassenhaus/src">Rust and built for WebAssembly</a> and all the DOM manipulation and reactiveness was done manually in a <a href="https://github.com/frereit/frereit.github.io/blob/main/static/js/aesgcm_widgets.js">1200 line JavaScript file üò≠</a>.</p><p>This blog post was an enormous amount of work, but I hope it was worth it. If you have any questions, comments, or feedback, please don‚Äôt hesitate to reach out to me on <a href="https://infosec.exchange/@fre">Mastodon</a>, I‚Äôd love to here from you! Also, if you‚Äôd like to send some donation my way, don‚Äôt. Instead send some feedback my way and some money to the <a href="https://supporters.eff.org/donate/">Electronic Frontier Foundation</a>, <a href="https://archive.org/donate">The Internet Archive</a> or anything, really, that you think is important.</p><p>Lastly, a huge thank you to <a href="https://johannes-bauer.com/">Prof. Dr. Johannes Bauer</a> who very kindly reviewed this blog post and provided me with some valuable feedback. I really appreciate it!</p><p>Thanks again for reading!</p><h2 id="addendum-using-sagemath-to-do-the-heavy-lifting">Addendum: Using SageMath to do the heavy lifting</h2><p>In this blog post, I‚Äôve shown how the square free factorization, the distinct degree factorization, and the Cantor-Zassenhaus algorithms can be used to break AES-GCM. To be able to show you the internals right in your browser, I‚Äôve implemented the algorithms from scratch in <a href="https://github.com/frereit/frereit.github.io/blob/main/wasm/cantor-zassenhaus/src/factorize.rs">Rust</a> but if you actually want to execute this attack in real life, you can use <a href="https://www.sagemath.org/">SageMath</a> to calculate the roots of the polynomial, instead of implementing the algorithms yourself.</p><p>First, setup the <code>GF(2</code><sup><code>128</code></sup><code>)</code> field:</p><pre tabindex="0"><code>&gt;&gt;&gt; F.&lt;a&gt; = GF(2)[]
&gt;&gt;&gt; F.&lt;x&gt; = GF(2^128, modulus=a^128 + a^7 + a^2 + a + 1)</code></pre><p>Then, construct a polynomial ring over this field:</p><pre tabindex="0"><code>&gt;&gt;&gt; R.&lt;H&gt; = PolynomialRing(F)</code></pre><p>If we now want to find the roots of the polynomial <code>H</code><sup><code>2</code></sup><code> + H + 1</code>, we can use the <code>.roots()</code> method:</p><pre tabindex="0"><code>&gt;&gt;&gt; (H^2 + H + 1).roots()
[(x^125 + x^123 + x^120 + x^118 + x^116 + x^115 + x^113 + x^111 + x^110 + x^103 + x^101 + x^100 + x^96 + x^95 + x^94 + x^93 + x^92 + x^90 + x^86 + x^85 + x^84 + x^81 + x^80 + x^76 + x^75 + x^73 + x^71 + x^70 + x^69 + x^68 + x^67 + x^64 + x^62 + x^61 + x^58 + x^57 + x^56 + x^54 + x^53 + x^51 + x^49 + x^47 + x^45 + x^43 + x^42 + x^39 + x^36 + x^35 + x^34 + x^33 + x^32 + x^31 + x^29 + x^26 + x^23 + x^21 + x^20 + x^17 + x^11 + x^9 + x^8 + x^3,
  1),
 (x^125 + x^123 + x^120 + x^118 + x^116 + x^115 + x^113 + x^111 + x^110 + x^103 + x^101 + x^100 + x^96 + x^95 + x^94 + x^93 + x^92 + x^90 + x^86 + x^85 + x^84 + x^81 + x^80 + x^76 + x^75 + x^73 + x^71 + x^70 + x^69 + x^68 + x^67 + x^64 + x^62 + x^61 + x^58 + x^57 + x^56 + x^54 + x^53 + x^51 + x^49 + x^47 + x^45 + x^43 + x^42 + x^39 + x^36 + x^35 + x^34 + x^33 + x^32 + x^31 + x^29 + x^26 + x^23 + x^21 + x^20 + x^17 + x^11 + x^9 + x^8 + x^3 + 1,
  1)]</code></pre><p>This immediately gives us the candidate values for <code>H</code>, no need to jump through any extra hoops. I‚Äôll leave implementing the whole attack in SageMath as an exercise to the reader ;).</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How much of a genius-level move was binary space partitioning in Doom? (2019) (189 pts)]]></title>
            <link>https://twobithistory.org/2019/11/06/doom-bsp.html</link>
            <guid>40652917</guid>
            <pubDate>Tue, 11 Jun 2024 23:38:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twobithistory.org/2019/11/06/doom-bsp.html">https://twobithistory.org/2019/11/06/doom-bsp.html</a>, See on <a href="https://news.ycombinator.com/item?id=40652917">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <p>In 1993, id Software released the first-person shooter <em>Doom</em>, which quickly
became a phenomenon. The game is now considered one of the most influential
games of all time.</p>

<p>A decade after <em>Doom</em>‚Äôs release, in 2003, journalist David Kushner published a
book about id Software called <em>Masters of Doom</em>, which has since become the
canonical account of <em>Doom</em>‚Äôs creation. I read <em>Masters of Doom</em> a few years
ago and don‚Äôt remember much of it now, but there was one story in the book
about lead programmer John Carmack that has stuck with me. This is a loose
gloss of the story (see below for the full details), but essentially, early in
the development of <em>Doom</em>, Carmack realized that the 3D renderer he had written
for the game slowed to a crawl when trying to render certain levels. This was
unacceptable, because <em>Doom</em> was supposed to be action-packed and frenetic. So
Carmack, realizing the problem with his renderer was fundamental enough that he
would need to find a better rendering algorithm, started reading research
papers. He eventually implemented a technique called ‚Äúbinary space
partitioning,‚Äù never before used in a video game, that dramatically sped up the
<em>Doom</em> engine.
<!--more--></p>

<p>That story about Carmack applying cutting-edge academic research to video games
has always impressed me. It is my explanation for why Carmack has become such a
legendary figure. He deserves to be known as the archetypal genius video game
programmer for all sorts of reasons, but this episode with the academic papers
and the binary space partitioning is the justification I think of first.</p>

<p>Obviously, the story is impressive because ‚Äúbinary space partitioning‚Äù sounds
like it would be a difficult thing to just read about and implement yourself.
I‚Äôve long assumed that what Carmack did was a clever intellectual leap, but
because I‚Äôve never understood what binary space partitioning is or how novel a
technique it was when Carmack decided to use it, I‚Äôve never known for sure. On
a spectrum from Homer Simpson to Albert Einstein, how much of a genius-level
move was it really for Carmack to add binary space partitioning to <em>Doom</em>?</p>

<p>I‚Äôve also wondered where binary space partitioning first came from and how the
idea found its way to Carmack. So this post is about John Carmack and <em>Doom</em>,
but it is also about the history of a data structure: the binary space
partitioning tree (or BSP tree). It turns out that the BSP tree, rather
interestingly, and like so many things in computer science, has its origins in
research conducted for the military.</p>

<p>That‚Äôs right: E1M1, the first level of <em>Doom</em>, was brought to you by the
US Air Force.</p>

<h2 id="the-vsd-problem">The VSD Problem</h2>
<p>The BSP tree is a solution to one of the thorniest problems in computer
graphics. In order to render a three-dimensional scene, a renderer has to
figure out, given a particular viewpoint, what can be seen and what cannot be
seen. This is not especially challenging if you have lots of time, but a
respectable real-time game engine needs to figure out what can be seen and what
cannot be seen at least 30 times a second.</p>

<p>This problem is sometimes called the problem of visible surface determination.
Michael Abrash, a programmer who worked with Carmack on <em>Quake</em> (id Software‚Äôs
follow-up to <em>Doom</em>), wrote about the VSD problem in his famous <em>Graphics
Programming Black Book</em>:</p>

<blockquote>
  <p>I want to talk about what is, in my opinion, the toughest 3-D problem of all:
visible surface determination (drawing the proper surface at each pixel), and
its close relative, culling (discarding non-visible polygons as quickly as
possible, a way of accelerating visible surface determination). In the
interests of brevity, I‚Äôll use the abbreviation VSD to mean both visible
surface determination and culling from now on.</p>
</blockquote>

<blockquote>
  <p>Why do I think VSD is the toughest 3-D challenge? Although rasterization
issues such as texture mapping are fascinating and important, they are tasks
of relatively finite scope, and are being moved into hardware as 3-D
accelerators appear; also, they only scale with increases in screen
resolution, which are relatively modest.</p>
</blockquote>

<blockquote>
  <p>In contrast, VSD is an open-ended problem, and there are dozens of approaches
currently in use. Even more significantly, the performance of VSD, done in an
unsophisticated fashion, scales directly with scene complexity, which tends
to increase as a square or cube function, so this very rapidly becomes the
limiting factor in rendering realistic worlds.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup></p>
</blockquote>

<p>Abrash was writing about the difficulty of the VSD problem in the late ‚Äô90s,
years after <em>Doom</em> had proved that regular people wanted to be able to play
graphically intensive games on their home computers. In the early ‚Äô90s, when id
Software first began publishing games, the games had to be programmed to run
efficiently on computers not designed to run them, computers meant for word
processing, spreadsheet applications, and little else. To make this work,
especially for the few 3D games that id Software published before <em>Doom</em>, id
Software had to be creative. In these games, the design of all the levels was
constrained in such a way that the VSD problem was easier to solve.</p>

<p>For example, in <em>Wolfenstein 3D</em>, the game id Software released just prior to
<em>Doom</em>, every level is made from walls that are axis-aligned. In other words,
in the Wolfenstein universe, you can have north-south walls or west-east walls,
but nothing else. Walls can also only be placed at fixed intervals on a
grid‚Äîall hallways are either one grid square wide, or two grid squares wide,
etc., but never 2.5 grid squares wide. Though this meant that the id Software
team could only design levels that all looked somewhat the same, it made
Carmack‚Äôs job of writing a renderer for <em>Wolfenstein</em> much simpler.</p>

<p>The <em>Wolfenstein</em> renderer solved the VSD problem by ‚Äúmarching‚Äù rays into the
virtual world from the screen. Usually a renderer that uses rays is a
‚Äúraycasting‚Äù renderer‚Äîthese renderers are often slow, because solving the VSD
problem in a raycaster involves finding the first intersection between a ray
and something in your world, which in the general case requires lots of number
crunching. But in <em>Wolfenstein</em>, because all the walls are aligned with the
grid, the only location a ray can possibly intersect a wall is at the grid
lines. So all the renderer needs to do is check each of those intersection
points. If the renderer starts by checking the intersection point nearest to
the player‚Äôs viewpoint, then checks the next nearest, and so on, and stops when
it encounters the first wall, the VSD problem has been solved in an almost
trivial way. A ray is just marched forward from each pixel until it hits
something, which works because the marching is so cheap in terms of CPU cycles.
And actually, since all walls are the same height, it is only necessary to
march a single ray for every <em>column</em> of pixels.</p>

<p>This rendering shortcut made <em>Wolfenstein</em> fast enough to run on underpowered
home PCs in the era before dedicated graphics cards. But this approach would
not work for <em>Doom</em>, since the id team had decided that their new game would
feature novel things like diagonal walls, stairs, and ceilings of different
heights. Ray marching was no longer viable, so Carmack wrote a different kind
of renderer. Whereas the <em>Wolfenstein</em> renderer, with its ray for every column
of pixels, is an ‚Äúimage-first‚Äù renderer, the <em>Doom</em> renderer is an
‚Äúobject-first‚Äù renderer. This means that rather than iterating through the
pixels on screen and figuring out what color they should be, the <em>Doom</em>
renderer iterates through the objects in a scene and projects each onto the
screen in turn.</p>

<p>In an object-first renderer, one easy way to solve the VSD problem is to use a
z-buffer. Each time you project an object onto the screen, for each pixel you
want to draw to, you do a check. If the part of the object you want to draw is
closer to the player than what was already drawn to the pixel, then you can
overwrite what is there. Otherwise you have to leave the pixel as is. This
approach is simple, but a z-buffer requires a lot of memory, and the renderer
may still expend a lot of CPU cycles projecting level geometry that is never
going to be seen by the player.</p>

<p>In the early 1990s, there was an additional drawback to the z-buffer approach:
On IBM-compatible PCs, which used a video adapter system called VGA,
writing to the output frame buffer was an expensive operation. So time
spent drawing pixels that would only get overwritten later tanked the
performance of your renderer.</p>

<p>Since writing to the frame buffer was so expensive, the ideal renderer was
one that started by drawing the objects closest to the player, then the objects
just beyond those objects, and so on, until every pixel on screen had been
written to. At that point the renderer would know to stop, saving all the time
it might have spent considering far-away objects that the player cannot see.
But ordering the objects in a scene this way, from closest to farthest, is
tantamount to solving the VSD problem. Once again, the question is: What can be
seen by the player?</p>

<p>Initially, Carmack tried to solve this problem by relying on the layout of
<em>Doom</em>‚Äôs levels. His renderer started by drawing the walls of the room
currently occupied by the player, then flooded out into neighboring rooms to
draw the walls in those rooms that could be seen from the current room.
Provided that every room was convex, this solved the VSD issue. Rooms that were
not convex could be split into convex ‚Äúsectors.‚Äù You can see how this rendering
technique might have looked if run at extra-slow speed <a href="https://youtu.be/HQYsFshbkYw?t=822">in this
video</a>, where YouTuber Bisqwit demonstrates
a renderer of his own that works according to the same general algorithm. This
algorithm was successfully used in Duke Nukem 3D, released three years after
<em>Doom</em>, when CPUs were more powerful. But, in 1993, running on the hardware
then available, the <em>Doom</em> renderer that used this algorithm struggled with
complicated levels‚Äîparticularly when sectors were nested inside of each other,
which was the only way to create something like a circular pit of stairs. A
circular pit of stairs led to lots of repeated recursive descents into a sector
that had already been drawn, strangling the game engine‚Äôs speed.</p>

<p>Around the time that the id team realized that the <em>Doom</em> game engine might be
too slow, id Software was asked to port <em>Wolfenstein 3D</em> to the Super Nintendo.
The Super Nintendo was even less powerful than the IBM-compatible PCs of the
day, and it turned out that the ray-marching <em>Wolfenstein</em> renderer, simple as
it was, didn‚Äôt run fast enough on the Super Nintendo hardware. So Carmack began
looking for a better algorithm. It was actually for the Super Nintendo
port of <em>Wolfenstein</em> that Carmack first researched and implemented binary
space partitioning. In <em>Wolfenstein</em>, this was relatively straightforward
because all the walls were axis-aligned; in <em>Doom</em>, it would be more complex.
But Carmack realized that BSP trees would solve <em>Doom</em>‚Äôs speed problems too.</p>


<p>Binary space partitioning makes the VSD problem easier to solve by splitting a
3D scene into parts ahead of time. For now, you just need to grasp why
splitting a scene is useful: If you draw a line (really a plane in 3D) across
your scene, and you know which side of the line the player or camera viewpoint
is on, then you also know that nothing on the other side of the line can
obstruct something on the viewpoint‚Äôs side of the line. If you repeat this
process many times, you end up with a 3D scene split into many sections, which
wouldn‚Äôt be an improvement on the original scene except now you know more about
how different parts of the scene can obstruct each other.</p>

<p>The first people to write about dividing a 3D scene like this were researchers
trying to establish for the US Air Force whether computer graphics were
sufficiently advanced to use in flight simulators. They released their
findings in a 1969 report called ‚ÄúStudy for Applying Computer-Generated Images
to Visual Simulation.‚Äù The report concluded that computer graphics could be
used to train pilots, but also warned that the implementation would be
complicated by the VSD problem:</p>

<blockquote>
  <p>One of the most significant problems that must be faced in the real-time
computation of images is the priority, or hidden-line, problem. In our
everyday visual perception of our surroundings, it is a problem that nature
solves with trivial ease; a point of an opaque object obscures all other
points that lie along the same line of sight and are more distant. In the
computer, the task is formidable. The computations required to resolve
priority in the general case grow exponentially with the complexity of the
environment, and soon they surpass the computing load associated with finding
the perspective images of the objects.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup></p>
</blockquote>

<p>One solution these researchers mention, which according to them was earlier
used in a project for NASA, is based on creating what I am going to call an
‚Äúocclusion matrix.‚Äù The researchers point out that a plane dividing a scene
in two can be used to resolve ‚Äúany priority conflict‚Äù between objects on
opposite sides of the plane. In general you might have to add these planes
explicitly to your scene, but with certain kinds of geometry you can just rely
on the faces of the objects you already have. They give the example in the
figure below, where \(p_1\), \(p_2\), and \(p_3\) are the separating planes. If
the camera viewpoint is on the forward or ‚Äútrue‚Äù side of one of these planes,
then \(p_i\) evaluates to 1. The matrix shows the relationships between the
three objects based on the three dividing planes and the location of the camera
viewpoint‚Äîif object \(a_i\) obscures object \(a_j\), then entry \(a_{ij}\) in
the matrix will be a 1.</p>

<p><img src="https://twobithistory.org/images/matrix_figure.png" alt=""></p>

<p>The researchers propose that this matrix could be implemented in hardware and
re-evaluated every frame. Basically the matrix would act as a big switch or a
kind of pre-built z-buffer. When drawing a given object, no video would be
output for the parts of the object when a 1 exists in the object‚Äôs column and
the corresponding row object is also being drawn.</p>

<p>The major drawback with this matrix approach is that to represent a scene with
\(n\) objects you need a matrix of size \(n^2\). So the researchers go on to
explore whether it would be feasible to represent the occlusion matrix as a
‚Äúpriority list‚Äù instead, which would only be of size \(n\) and would establish
an order in which objects should be drawn. They immediately note that for
certain scenes like the one in the figure above no ordering can be made (since
there is an occlusion cycle), so they spend a lot of time laying out the
mathematical distinction between ‚Äúproper‚Äù and ‚Äúimproper‚Äù scenes. Eventually
they conclude that, at least for ‚Äúproper‚Äù scenes‚Äîand it should be easy enough
for a scene designer to avoid ‚Äúimproper‚Äù cases‚Äîa priority list could be
generated. But they leave the list generation as an exercise for the reader. It
seems the primary contribution of this 1969 study was to point out that it
should be possible to use partitioning planes to order objects in a scene for
rendering, at least <em>in theory</em>.</p>

<p>It was not until 1980 that a paper, titled ‚ÄúOn Visible Surface Generation by A
Priori Tree Structures,‚Äù demonstrated a concrete algorithm to accomplish this.
The 1980 paper, written by Henry Fuchs, Zvi Kedem, and Bruce Naylor, introduced
the BSP tree. The authors say that their novel data structure is ‚Äúan
alternative solution to an approach first utilized a decade ago but due to a
few difficulties, not widely exploited‚Äù‚Äîhere referring to the approach taken in
the 1969 Air Force study.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> A BSP tree, once constructed, can easily be used
to provide a priority ordering for objects in the scene.</p>

<p>Fuchs, Kedem, and Naylor give a pretty readable explanation of how a BSP tree
works, but let me see if I can provide a less formal but more concise one.</p>

<p>You begin by picking one polygon in your scene and making the plane in which
the polygon lies your partitioning plane. That one polygon also ends up as the
root node in your tree. The remaining polygons in your scene will be on one
side or the other of your root partitioning plane. The polygons on the
‚Äúforward‚Äù side or in the ‚Äúforward‚Äù half-space of your plane end up in the
left subtree of your root node, while the polygons on the ‚Äúback‚Äù side or in the
‚Äúback‚Äù half-space of your plane end up in the right subtree. You then repeat
this process recursively, picking a polygon from your left and right subtrees
to be the new partitioning planes for their respective half-spaces, which
generates further half-spaces and further sub-trees. You stop when you run out
of polygons.</p>

<p>Say you want to render the geometry in your scene from back-to-front. (This is
known as the ‚Äúpainter‚Äôs algorithm,‚Äù since it means that polygons further from
the camera will get drawn over by polygons closer to the camera, producing a
correct rendering.) To achieve this, all you have to do is an in-order
traversal of the BSP tree, where the decision to render the left or right
subtree of any node first is determined by whether the camera viewpoint is in
either the forward or back half-space relative to the partitioning plane
associated with the node. So at each node in the tree, you render all the
polygons on the ‚Äúfar‚Äù side of the plane first, then the polygon in the
partitioning plane, then all the polygons on the ‚Äúnear‚Äù side of the plane‚Äî‚Äùfar‚Äù
and ‚Äúnear‚Äù being relative to the camera viewpoint. This solves the VSD problem
because, as we learned several paragraphs back, the polygons on the far side of
the partitioning plane cannot obstruct anything on the near side.</p>

<p>The following diagram shows the construction and traversal of a BSP tree
representing a simple 2D scene. In 2D, the partitioning planes are instead
partitioning lines, but the basic idea is the same in a more complicated 3D
scene.</p>

<p><img src="https://twobithistory.org/images/bsp.svg" alt="">
<em>Step One: The root partitioning line along wall D splits the remaining
geometry into two sets.</em></p>

<p><img src="https://twobithistory.org/images/bsp1.svg" alt="">
<em>Step Two: The half-spaces on either side of D are split again. Wall C is the
only wall in its half-space so no split is needed. Wall B forms the new
partitioning line in its half-space. Wall A must be split into two walls since
it crosses the partitioning line.</em></p>

<p><img src="https://twobithistory.org/images/bsp2.svg" alt="">
<em>A back-to-front ordering of the walls relative to the viewpoint in the
top-right corner, useful for implementing the painter‚Äôs algorithm. This is just
an in-order traversal of the tree.</em></p>

<p>The really neat thing about a BSP tree, which Fuchs, Kedem, and Naylor stress
several times, is that it only has to be constructed once. This is somewhat
surprising, but the same BSP tree can be used to render a scene no matter where
the camera viewpoint is. The BSP tree remains valid as long as the polygons in
the scene don‚Äôt move. This is why the BSP tree is so useful for real-time
rendering‚Äîall the hard work that goes into constructing the tree can be done
beforehand rather than during rendering.</p>

<p>One issue that Fuchs, Kedem, and Naylor say needs further exploration is the
question of what makes a ‚Äúgood‚Äù BSP tree. The quality of your BSP tree will
depend on which polygons you decide to use to establish your partitioning
planes. I skipped over this earlier, but if you partition using a plane that
intersects other polygons, then in order for the BSP algorithm to work, you
have to split the intersected polygons in two, so that one part can go in one
half-space and the other part in the other half-space. If this happens a lot,
then building a BSP tree will dramatically increase the number of polygons in
your scene.</p>

<p>Bruce Naylor, one of the authors of the 1980 paper, would later write about
this problem in his 1993 paper, ‚ÄúConstructing Good Partitioning Trees.‚Äù
According to John Romero, one of Carmack‚Äôs fellow id Software co-founders, this
paper was one of the papers that Carmack read when he was trying to implement
BSP trees in <em>Doom</em>.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup></p>

<h2 id="bsp-trees-in-doom">BSP Trees in Doom</h2>
<p>Remember that, in his first draft of the <em>Doom</em> renderer, Carmack had been
trying to establish a rendering order for level geometry by ‚Äúflooding‚Äù the
renderer out from the player‚Äôs current room into neighboring rooms. BSP trees
were a better way to establish this ordering because they avoided the issue
where the renderer found itself visiting the same room (or sector) multiple
times, wasting CPU cycles.</p>

<p>‚ÄúAdding BSP trees to <em>Doom</em>‚Äù meant, in practice, adding a BSP tree generator to
the <em>Doom</em> level editor. When a level in <em>Doom</em> was complete, a BSP tree was
generated from the level geometry. According to Fabien Sanglard, the generation
process could take as long as eight seconds for a single level and 11 minutes
for all the levels in the original <em>Doom</em>.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup> The generation process was
lengthy in part because Carmack‚Äôs BSP generation algorithm tries to search for
a ‚Äúgood‚Äù BSP tree using various heuristics. An eight-second delay would have
been unforgivable at runtime, but it was not long to wait when done offline,
especially considering the performance gains the BSP trees brought to the
renderer. The generated BSP tree for a single level would have then ended up as
part of the level data loaded into the game when it starts.</p>

<p>Carmack put a spin on the BSP tree algorithm outlined in the 1980 paper,
because once <em>Doom</em> is started and the BSP tree for the current level is read
into memory, the renderer uses the BSP tree to draw objects front-to-back
rather than back-to-front. In the 1980 paper, Fuchs, Kedem, and Naylor show how
a BSP tree can be used to implement the back-to-front painter‚Äôs algorithm, but
the painter‚Äôs algorithm involves a lot of over-drawing that would have been
expensive on an IBM-compatible PC. So the <em>Doom</em> renderer instead starts with
the geometry closer to the player, draws that first, then draws the geometry
farther away. This reverse ordering is easy to achieve using a BSP tree, since
you can just make the opposite traversal decision at each node in the tree. To
ensure that the farther-away geometry is not drawn over the closer geometry,
the <em>Doom</em> renderer uses a kind of implicit z-buffer that provides much of the
benefit of a z-buffer with a much smaller memory footprint. There is one array
that keeps track of occlusion in the horizontal dimension, and another two
arrays that keep track of occlusion in the vertical dimension from the top and
bottom of the screen. The <em>Doom</em> renderer can get away with not using an actual
z-buffer because <em>Doom</em> is not technically a fully 3D game. The cheaper data
structures work because certain things never appear in <em>Doom</em>: The horizontal
occlusion array works because there are no sloping walls, and the vertical
occlusion arrays work because no walls have, say, two windows, one above the
other.</p>

<p>The only other tricky issue left is how to incorporate <em>Doom</em>‚Äôs moving
characters into the static level geometry drawn with the aid of the BSP tree.
The enemies in <em>Doom</em> cannot be a part of the BSP tree because they move; the
BSP tree only works for geometry that never moves. So the <em>Doom</em> renderer draws
the static level geometry first, keeping track of the segments of the screen
that were drawn to (with yet another memory-efficient data structure). It then
draws the enemies in back-to-front order, clipping them against the segments of
the screen that occlude them. This process is not as optimal as rendering using
the BSP tree, but because there are usually fewer enemies visible than there is
level geometry in a level, speed isn‚Äôt as much of an issue here.</p>

<p>Using BSP trees in <em>Doom</em> was a major win. Obviously it is pretty neat that
Carmack was able to figure out that BSP trees were the perfect solution to his
problem. But was it a <em>genius</em>-level move?</p>

<p>In his excellent book about the <em>Doom</em> game engine, Fabien Sanglard quotes John
Romero saying that Bruce Naylor‚Äôs paper, ‚ÄúConstructing Good Partitioning
Trees,‚Äù was mostly about using BSP trees to cull backfaces from 3D models.<sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup>
According to Romero, Carmack thought the algorithm could still be useful for
<em>Doom</em>, so he went ahead and implemented it. This description is quite
flattering to Carmack‚Äîit implies he saw that BSP trees could be useful for
real-time video games when other people were still using the technique to
render static scenes. There is a similarly flattering story in <em>Masters of
Doom</em>: Kushner suggests that Carmack read Naylor‚Äôs paper and asked himself,
‚Äúwhat if you could use a BSP to create not just one 3D image but an entire
virtual world?‚Äù<sup id="fnref:7" role="doc-noteref"><a href="#fn:7">7</a></sup></p>

<p>This framing ignores the history of the BSP tree. When those US Air Force
researchers first realized that partitioning a scene might help speed up
rendering, they were interested in speeding up <em>real-time</em> rendering, because
they were, after all, trying to create a flight simulator. The flight simulator
example comes up again in the 1980 BSP paper. Fuchs, Kedem, and Naylor talk
about how a BSP tree would be useful in a flight simulator that pilots use to
practice landing at the same airport over and over again. Since the airport
geometry never changes, the BSP tree can be generated just once. Clearly
what they have in mind is a real-time simulation. In the introduction to their
paper, they even motivate their research by talking about how real-time
graphics systems must be able to create an image in at least 1/30th of a
second.</p>

<p>So Carmack was not the first person to think of using BSP trees in a real-time
graphics simulation. Of course, it‚Äôs one thing to anticipate that BSP trees
might be used this way and another thing to actually do it. But even in the
implementation Carmack may have had more guidance than is commonly assumed. The
<a href="https://en.wikipedia.org/wiki/Binary_space_partitioning">Wikipedia page about BSP
trees</a>, at least as of
this writing, suggests that Carmack consulted a 1991 paper by Chen and Gordon
as well as a 1990 textbook called <em>Computer Graphics: Principles and Practice</em>.
Though no citation is provided for this claim, it is probably true. The 1991
Chen and Gordon paper outlines a front-to-back rendering approach using BSP
trees that is basically the same approach taken by <em>Doom</em>, right down to what
I‚Äôve called the ‚Äúimplicit z-buffer‚Äù data structure that prevents farther
polygons being drawn over nearer polygons. The textbook provides a great
overview of BSP trees and some pseudocode both for building a tree and for
displaying one. (I‚Äôve been able to skim through the 1990 edition thanks to my
wonderful university library.) <em>Computer Graphics: Principles and Practice</em> is
a classic text in computer graphics, so Carmack might well have owned it.</p>

<p>Still, Carmack found himself faced with a novel problem‚Äî‚ÄùHow can we make a
first-person shooter run on a computer with a CPU that can‚Äôt even do
floating-point operations?‚Äù‚Äîdid his research, and proved that BSP trees are a
useful data structure for real-time video games. I still think that is an
impressive feat, even if the BSP tree had first been invented a decade prior
and was pretty well theorized by the time Carmack read about it. Perhaps
the accomplishment that we should really celebrate is the <em>Doom</em> game engine as
a whole, which is a seriously nifty piece of work. I‚Äôve mentioned it once
already, but Fabien Sanglard‚Äôs book about the <em>Doom</em> game engine (<em>Game Engine
Black Book: DOOM</em>) is an excellent overview of all the different clever
components of the game engine and how they fit together. We shouldn‚Äôt forget
that the VSD problem was just one of many problems that Carmack had to solve to
make the <em>Doom</em> engine work. That he was able, on top of everything else, to
read about and implement a complicated data structure unknown to most
programmers speaks volumes about his technical expertise and his drive to
perfect his craft.</p>

<p><em>
If you enjoyed this post, more like it come out every four weeks! Follow
<a href="https://twitter.com/TwoBitHistory">
  @TwoBitHistory
</a> on Twitter or subscribe to the
<a href="https://twobithistory.org/feed.xml">
  RSS feed
</a>
to make sure you know when a new post is out.
</em></p>

<p><em>Previously on TwoBitHistory‚Ä¶</em></p>

<blockquote><p lang="en" dir="ltr">I've wanted to learn more about GNU Readline for a while, so I thought I'd turn that into a new blog post. Includes a few fun facts from an email exchange with Chet Ramey, who maintains Readline (and Bash):<a href="https://t.co/wnXeuyjgMx">https://t.co/wnXeuyjgMx</a></p>‚Äî TwoBitHistory (@TwoBitHistory) <a href="https://twitter.com/TwoBitHistory/status/1164631020353859585?ref_src=twsrc%5Etfw">August 22, 2019</a></blockquote>




</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mistral AI raises $640M at $6B valuation (111 pts)]]></title>
            <link>https://www.generalcatalyst.com/perspectives/tripling-down-on-mistral-ai</link>
            <guid>40651298</guid>
            <pubDate>Tue, 11 Jun 2024 20:48:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.generalcatalyst.com/perspectives/tripling-down-on-mistral-ai">https://www.generalcatalyst.com/perspectives/tripling-down-on-mistral-ai</a>, See on <a href="https://news.ycombinator.com/item?id=40651298">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p>Intelligence Sans Fronti√®res </p></div><div><p><img src="https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B.jpg" loading="lazy" alt="Tripling Down on Mistral AI" sizes="(max-width: 479px) 88vw, (max-width: 767px) 93vw, (max-width: 991px) 86vw, (max-width: 1919px) 71vw, 1371px" srcset="https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-500.jpg 500w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-800.jpg 800w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-1080.jpg 1080w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-1600.jpg 1600w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-2000.jpg 2000w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-2600.jpg 2600w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B-p-3200.jpg 3200w, https://cdn.prod.website-files.com/633eca9ef5936405a2224b4d/66673ac2e7744e536b45634e_Mistral%20Series%20B.jpg 3582w"></p></div><div><div fs-readtime-element="contents" fs-richtext-element="rich-text"><p><strong>Today, we are excited to<em> triple down</em> on our partnership with </strong><a href="http://mistral.ai/"><strong>Mistral AI</strong></a><strong> by co-leading their ‚Ç¨600M Series B round. Mistral‚Äôs astounding impact on the global stage since its inception only a year ago is a true testament to the uniqueness and vitality of Europe in today‚Äôs global AI Renaissance. We believe Mistral will be one of the leading generational global technology companies to emerge from France‚Äôs vibrant AI ecosystem, and we are energized to help catalyze their Europe-led movement which is accelerating AI product innovation, driving industry transformation and bolstering resilience globally.</strong></p><p>Since partnering with Mistral at their inception a year ago, their open source approach to frontier AI has propelled them to the forefront of the world stage with remarkable force. At the heart of this meteoric ascent lies a foundation built upon exceptional European AI talent, a culture of humility, ambition and determination, and deep trust with the AI developer community. Today, Mistral‚Äôs industry-leading open models are not only setting the standard across the performance-cost frontier, but also catalyzing AI product innovation and cutting-edge AI safety research on a national, regional, and global scale. We see tremendous value from the rise of such a rich ecosystem already flourishing around Mistral and are eager to support their dream of making France and Europe the center of the global ‚ÄúRenAIssance‚Äù.</p><p>Now, Mistral is embarking on the next stage of their journey to drive economy-wide transformation. With <a href="https://console.mistral.ai/">La Plateforme</a> and <a href="https://chat.mistral.ai/chat">Le Chat</a> ‚Äî whose names exude the elegance emblematic of the company‚Äôs French roots ‚Äî Mistral is empowering enterprise leaders to reinvent their core businesses and enabling entrepreneurs to create entirely new markets. For Europe, we believe Mistral‚Äôs frontier AI presents a unique opportunity to leapfrog the traditional SaaS era and firmly capitalize on the continent‚Äôs vertical strength. We are fortunate to already partner with a number of AI-first industry platform companies including <a href="https://www.appliedintuition.com/">Applied Intuition</a>, <a href="https://www.generalcatalyst.com/perspectives/our-creation-of-crescendo">Crescendo</a>, <a href="https://www.generalcatalyst.com/perspectives/our-investment-in-helsing">Helsing</a>, <a href="https://www.generalcatalyst.com/perspectives/our-investment-in-hippocratic-ai">Hippocratic</a>, <a href="https://www.grammarly.com/">Grammarly</a>, <a href="https://www.physicsx.ai/">PhysicsX</a>, and <a href="http://www.shift-technology.com/">Shift</a>, and look forward to co-creating several more with Mistral in the near future.&nbsp;</p><p>Finally, Mistral‚Äôs open, portable platform is proving itself to be a fundamental building block to advancing resilience in AI ‚Äì for France, Europe, and beyond. At General Catalyst, we recently outlined our thesis for <a href="https://www.generalcatalyst.com/perspectives/building-globally-resilient-systems-for-a-new-world-order-investing-in-modern-defense-intelligence">Global Resilience</a>: in today‚Äôs new world order, defined by great power competition and re-globalization, we need to build more dynamic, resilient systems across the most critical industries for our economy and our society. We believe this is particularly true in frontier AI, and are thrilled to see Mistral create a leading technology platform that radically collaborates<em> </em>with local ecosystems and provides safety, stability and greater control for enterprise or sovereign benefit.</p><p>As investors, consumers, and citizens, it is our privilege to continue supporting Mistral on their mission to advance intelligence and help solve the world‚Äôs most complex and pressing problems. We are thrilled&nbsp; to be part of this daring and category-defining journey with Arthur, Guillaume, Tim, and their team, and invite everyone to build high trust, high integrity applications with Mistral.</p></div><div fs-readtime-element="contents" fs-richtext-element="rich-text" fs-toc-offsettop="143px" fs-toc-element="contents"><p><strong>Today, we are excited to<em> triple down</em> on our partnership with </strong><a href="http://mistral.ai/"><strong>Mistral AI</strong></a><strong> by co-leading their ‚Ç¨600M Series B round. Mistral‚Äôs astounding impact on the global stage since its inception only a year ago is a true testament to the uniqueness and vitality of Europe in today‚Äôs global AI Renaissance. We believe Mistral will be one of the leading generational global technology companies to emerge from France‚Äôs vibrant AI ecosystem, and we are energized to help catalyze their Europe-led movement which is accelerating AI product innovation, driving industry transformation and bolstering resilience globally.</strong></p><p>Since partnering with Mistral at their inception a year ago, their open source approach to frontier AI has propelled them to the forefront of the world stage with remarkable force. At the heart of this meteoric ascent lies a foundation built upon exceptional European AI talent, a culture of humility, ambition and determination, and deep trust with the AI developer community. Today, Mistral‚Äôs industry-leading open models are not only setting the standard across the performance-cost frontier, but also catalyzing AI product innovation and cutting-edge AI safety research on a national, regional, and global scale. We see tremendous value from the rise of such a rich ecosystem already flourishing around Mistral and are eager to support their dream of making France and Europe the center of the global ‚ÄúRenAIssance‚Äù.</p><p>Now, Mistral is embarking on the next stage of their journey to drive economy-wide transformation. With <a href="https://console.mistral.ai/">La Plateforme</a> and <a href="https://chat.mistral.ai/chat">Le Chat</a> ‚Äî whose names exude the elegance emblematic of the company‚Äôs French roots ‚Äî Mistral is empowering enterprise leaders to reinvent their core businesses and enabling entrepreneurs to create entirely new markets. For Europe, we believe Mistral‚Äôs frontier AI presents a unique opportunity to leapfrog the traditional SaaS era and firmly capitalize on the continent‚Äôs vertical strength. We are fortunate to already partner with a number of AI-first industry platform companies including <a href="https://www.appliedintuition.com/">Applied Intuition</a>, <a href="https://www.generalcatalyst.com/perspectives/our-creation-of-crescendo">Crescendo</a>, <a href="https://www.generalcatalyst.com/perspectives/our-investment-in-helsing">Helsing</a>, <a href="https://www.generalcatalyst.com/perspectives/our-investment-in-hippocratic-ai">Hippocratic</a>, <a href="https://www.grammarly.com/">Grammarly</a>, <a href="https://www.physicsx.ai/">PhysicsX</a>, and <a href="http://www.shift-technology.com/">Shift</a>, and look forward to co-creating several more with Mistral in the near future.&nbsp;</p><p>Finally, Mistral‚Äôs open, portable platform is proving itself to be a fundamental building block to advancing resilience in AI ‚Äì for France, Europe, and beyond. At General Catalyst, we recently outlined our thesis for <a href="https://www.generalcatalyst.com/perspectives/building-globally-resilient-systems-for-a-new-world-order-investing-in-modern-defense-intelligence">Global Resilience</a>: in today‚Äôs new world order, defined by great power competition and re-globalization, we need to build more dynamic, resilient systems across the most critical industries for our economy and our society. We believe this is particularly true in frontier AI, and are thrilled to see Mistral create a leading technology platform that radically collaborates<em> </em>with local ecosystems and provides safety, stability and greater control for enterprise or sovereign benefit.</p><p>As investors, consumers, and citizens, it is our privilege to continue supporting Mistral on their mission to advance intelligence and help solve the world‚Äôs most complex and pressing problems. We are thrilled&nbsp; to be part of this daring and category-defining journey with Arthur, Guillaume, Tim, and their team, and invite everyone to build high trust, high integrity applications with Mistral.</p></div></div></div><div><h2>Related Perspectives</h2></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Elon Musk drops suit against OpenAI and Sam Altman (201 pts)]]></title>
            <link>https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html</link>
            <guid>40651203</guid>
            <pubDate>Tue, 11 Jun 2024 20:38:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html">https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html</a>, See on <a href="https://news.ycombinator.com/item?id=40651203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107399197" data-test="InlineImage"><p>In this photo illustration, the logo of 'OpenAI' is displayed on a mobile phone screen in front of a computer screen displaying the photographs of Elon Musk and Sam Altman in Ankara, Turkiye on March 14, 2024.</p><p>Muhammed Selim Korkutata | Anadolu | Getty Images</p></div><div><p>Elon Musk on Tuesday withdrew his lawsuit against OpenAI and two of the company's co-founders, Sam Altman and Greg Brockman, in California state court. Musk's decision to file to dismiss the suit came just one day after he <a href="https://www.cnbc.com/2024/06/10/elon-musk-to-ban-apple-devices-from-his-companies-over-openai-deal.html">publicly criticized OpenAI</a> and its new partnership with Apple.</p><p>The case was dismissed without prejudice, according to a court filing obtained by CNBC.</p><p>In February, Musk had filed a lawsuit against OpenAI, Altman and Brockman ‚Äî the current CEO and president of OpenAI, respectively ‚Äî for breach of contract and fiduciary duty.</p><p>A hearing was scheduled for Wednesday in San Francisco, in which the judge was going to consider whether the case should be dismissed as requested by the defendants.</p><p>Experts <a href="https://www.cnbc.com/2024/03/05/read-the-complaint-in-elon-musk-v-sam-altman-greg-brockman-openai.html">told CNBC in March</a> that the case was built on a questionable legal foundation, because the contract at the heart of the suit was not a formal written agreement that was signed by all parties involved.</p><p>Rather, Musk had alleged that the early OpenAI team had set out to develop&nbsp;<a href="https://www.cnbc.com/2024/03/05/read-the-complaint-in-elon-musk-v-sam-altman-greg-brockman-openai.html">artificial general intelligence</a>, or AGI, "for the benefit of humanity," but that the project has been transformed into a for-profit entity that's largely controlled by principal shareholder&nbsp;<a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a>.</p><p>Musk had used much of the 35-page complaint (plus attached exhibits) he filed in March to remind the world of his position in the creation of a company that's since become one of the hottest startups on the planet, (OpenAI ranked first on CNBC's&nbsp;<a href="https://www.cnbc.com/2023/05/09/openai-disruptor-50.html">Disruptor 50 list</a>&nbsp;in 2023) thanks largely to the viral spread of ChatGPT.</p><p>"It's certainly a good advertisement for the benefit of Elon Musk," Kevin O'Brien, partner at Ford O'Brien Landy LLP and former assistant U.S. attorney, told CNBC at the time. "I'm not sure about the legal part though."</p><p>Last year, Musk debuted his own AI startup and OpenAI competitor, xAI, which last month <a href="https://x.ai/blog/series-b" target="_blank">announced</a> a $6 billion Series B funding round. Investors included Andreessen Horowitz, Sequoia Capital and Fidelity Management &amp; Research Company. </p><p>X.AI seeks to "understand the true nature of the universe," according to its website. Last year, X.AI released a chatbot called Grok, which the company says is modeled after "The Hitchhiker's Guide to the Galaxy." The chatbot debuted with two months of training and has real-time knowledge of the internet, the company claims.</p><p>Representatives for Musk and Altman did not immediately respond to a request for comment. </p><p>‚Äî<em>CNBC's Lora Kolodny contributed to this report.</em></p><p><em>Correction: The lawsuit was filed in February. An earlier version of this story misstated the month.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swift Static Linux SDK (243 pts)]]></title>
            <link>https://www.swift.org/documentation/articles/static-linux-getting-started.html</link>
            <guid>40651054</guid>
            <pubDate>Tue, 11 Jun 2024 20:25:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swift.org/documentation/articles/static-linux-getting-started.html">https://www.swift.org/documentation/articles/static-linux-getting-started.html</a>, See on <a href="https://news.ycombinator.com/item?id=40651054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
  <article class="page">
  
    
      <header>
        <h2>Getting Started with the Static Linux SDK</h2>
      </header>
    
  

  <p>It‚Äôs well known that Swift can be used to build software for Apple
platforms such as macOS or iOS, but Swift is also supported on other
platforms, including Linux and Windows.</p>

<p>Building for Linux is especially interesting because, historically,
Linux programs written in Swift needed to ensure that a copy of the
Swift runtime‚Äîand all of its dependencies‚Äîwas installed on the
target system.  Additionally, a program built for a particular
distribution, or even a particular major version of a particular
distribution, would not necessarily run on any other distribution or
in some cases even on a different major version of the same
distribution.</p>

<p>The Swift Static Linux SDK solves both of these problems by allowing
you to build your program as a <em>fully statically linked</em> executable,
with no external dependencies at all (not even the C library), which
means that it will run on <em>any</em> Linux distribution as the only thing
it depends on is the Linux system call interface.</p>

<p>Additionally, the Static Linux SDK can be used from any platform
supported by the Swift compiler and package manager; this means that
you can develop and test your program on macOS before building and
deploying it to a Linux-based server, whether running locally or
somewhere in the cloud.</p>



<p><em>Linking</em> is the process of taking different pieces of a computer
program and wiring up any references between those pieces.  For
<em>static</em> linking, generally speaking those pieces are <em>object files</em>,
or <em>static libraries</em> (which are really just collections of object
files).</p>

<p>For <em>dynamic</em> linking, the pieces are <em>executables</em> and <em>dynamic
libraries</em> (aka dylibs, shared objects, or DLLs).</p>

<p>There are two key differences between dynamic and static linking:</p>

<ul>
  <li>
    <p>The time at which linking takes place.  Static linking happens when
you build your program; dynamic linking happens at runtime.</p>
  </li>
  <li>
    <p>The fact that a static library (or <em>archive</em>) is really a collection
of individual object files, whereas a dynamic library is monolithic.</p>
  </li>
</ul>

<p>The latter is important because traditionally, the static linker will
include every object explicitly listed on its command line, but it
will <em>only</em> include an object from a static library if doing so lets
it resolve an unresolved symbolic reference.  If you statically link
against a library that you do not actually use, a traditional static
linker will completely discard that library and not include any code
from it in your final binary.</p>

<p>In practice, things can be more complicated‚Äîthe static linker may
actually work on the basis of individual <em>sections</em> or <em>atoms</em> from
your object files, so it may in fact be able to discard individual
functions or pieces of data rather than just whole objects.</p>

<h3 id="pros-and-cons-of-static-linking">Pros and Cons of Static Linking <a title="Permalink for Pros and Cons of Static Linking section" href="#pros-and-cons-of-static-linking">
            <!--?xml version="1.0" encoding="utf-8"?--> 
          </a></h3>

<p>Pros of static linking:</p>

<ul>
  <li>
    <p>No runtime overhead.</p>
  </li>
  <li>
    <p>Only include code from libraries that is actually needed.</p>
  </li>
  <li>
    <p>No need for separately installed dynamic libraries.</p>
  </li>
  <li>
    <p>No versioning issues at runtime.</p>
  </li>
</ul>

<p>Cons of static linking:</p>

<ul>
  <li>
    <p>Programs cannot share code (higher overall memory usage).</p>
  </li>
  <li>
    <p>No way to update dependencies without rebuilding program.</p>
  </li>
  <li>
    <p>Larger executables (though this can be offset by not having to
install separate dynamic libraries).</p>
  </li>
</ul>

<p>On Linux in particular, it‚Äôs also possible to use static linking to
completely eliminate dependencies on system libraries supplied by the
distribution, resulting in executables that work on any distribution
and can be installed by simply copying.</p>



<p>Before you start, it‚Äôs important to note:</p>

<ul>
  <li>
    <p>You will need to <a href="https://www.swift.org/install/">install an Open Source toolchain from
swift.org</a>.</p>
  </li>
  <li>
    <p>You cannot use the toolchain provided with Xcode to build programs
using the SDK.</p>
  </li>
  <li>
    <p>If you are using macOS, you will also need to ensure that you use
the Swift compiler from this toolchain by <a href="https://www.swift.org/install/macos/package_installer/">following the
instructions
here</a>.</p>
  </li>
  <li>
    <p>The toolchain must match the version of the Static Linux SDK that
you install.  The Static Linux SDK includes the corresponding Swift
version in its filename to help identify the correct version of the
SDK.</p>
  </li>
</ul>

<p>Once that is out of the way, actually installing the Static Linux SDK
is easy; at a prompt, enter</p>

<div><pre><code><span>$</span><span> </span>swift sdk <span>install</span> &lt;URL-or-filename-here&gt;
</code></pre></div>

<p>giving the URL or filename at which the SDK can be found.</p>

<p>For instance, assuming you have installed the
<code>swift-6.0-DEVELOPMENT-SNAPSHOT-2024-06-06-a</code> toolchain, you would
need to enter</p>

<div><pre><code><span>$</span><span> </span>swift sdk <span>install </span>https://download.swift.org/development/static-sdk/swift-DEVELOPMENT-SNAPSHOT-2024-06-06-a/swift-DEVELOPMENT-SNAPSHOT-2024-06-06-a_static-linux-0.0.1.artifactbundle.tar.gz
</code></pre></div>

<p>to install the corresponding Static Linux SDK.</p>

<p>Swift will download and install the SDK on your system.  You can get a
list of installed SDKs with</p>



<p>and it‚Äôs also possible to remove them using</p>

<div><pre><code><span>$</span><span> </span>swift sdk remove &lt;name-of-SDK&gt;
</code></pre></div>



<p>First, create a directory to hold your code:</p>



<p>Next, ask Swift to create a new program package for you:</p>

<div><pre><code><span>$</span><span> </span>swift package init <span>--type</span> executable
</code></pre></div>

<p>You can build and run this locally:</p>

<div><pre><code><span>$</span><span> </span>swift build
<span>Building for debugging...
[8/8] Applying hello
Build complete! (15.29s)
</span><span>$</span><span> </span>.build/debug/hello
<span>Hello, world!
</span></code></pre></div>

<p>But with the Static Linux SDK installed, you can also build Linux
binaries for x86-64 and ARM64 machines:</p>

<div><pre><code><span>$</span><span> </span>swift build <span>--sdk</span> x86_64-swift-linux-musl
<span>Building for debugging...
[8/8] Linking hello
Build complete! (2.04s)
</span><span>$</span><span> </span>file .build/x86_64-swift-linux-musl/debug/hello
<span>.build/x86_64-swift-linux-musl/debug/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped
</span></code></pre></div>

<div><pre><code><span>$</span><span> </span>swift build <span>--sdk</span> aarch64-swift-linux-musl
<span>Building for debugging...
[8/8] Linking hello
Build complete! (2.00s)
</span><span>$</span><span> </span>file .build/aarch64-swift-linux-musl/debug/hello
<span>.build/aarch64-swift-linux-musl/debug/hello: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, with debug_info, not stripped
</span></code></pre></div>

<p>These can be copied to an appropriate Linux-based system and executed:</p>

<div><pre><code><span>$</span><span> </span>scp .build/x86_64-swift-linux-musl/debug/hello linux:~/hello
<span>$</span><span> </span>ssh linux ~/hello
<span>Hello, world!
</span></code></pre></div>



<p>Swift packages that make use of Foundation or Swift NIO should just
work.  If you try to use a package that uses the C library, however,
you may have a little work to do.  Such packages often contain files
with code like the following:</p>

<div><pre><code><span>#if os(macOS) || os(iOS)</span>
<span>import</span> <span>Darwin</span>
<span>#elseif os(Linux)</span>
<span>import</span> <span>Glibc</span>
<span>#elseif os(Windows)</span>
<span>import</span> <span>ucrt</span>
<span>#else</span>
<span>#error(Unknown platform)</span>
<span>#endif</span>
</code></pre></div>

<p>The Static Linux SDK does not use Glibc; instead, it is built on top
of an alternative C library for Linux called
<a href="https://musl-libc.org/">Musl</a>.  We chose this approach for two
reasons:</p>

<ol>
  <li>
    <p>Musl has excellent support for static linking.</p>
  </li>
  <li>
    <p>Musl is permissively licensed, which makes it easy to distribute
executables statically linked with it.</p>
  </li>
</ol>

<p>If you are using such a dependency, you will therefore need to adjust
it to import the <code>Musl</code> module instead of the <code>Glibc</code> module:</p>

<div><pre><code><span>#if os(macOS) || os(iOS)</span>
<span>import</span> <span>Darwin</span>
<span>#elseif canImport(Glibc)</span>
<span>import</span> <span>Glibc</span>
<span>#elseif canImport(Musl)</span>
<span>import</span> <span>Musl</span>
<span>#elseif os(Windows)</span>
<span>import</span> <span>ucrt</span>
<span>#else</span>
<span>#error(Unknown platform)</span>
<span>#endif</span>
</code></pre></div>

<p>Occasionally there might be a difference between the way a C library
type gets imported between Musl and Glibc; this sometimes happens if
someone has added nullability annotations, or where a pointer type is
using a forward-declared <code>struct</code> for which no actual definition is
ever provided.  Usually the problem will be obvious‚Äîa function
argument or result will be <code>Optional</code> in one case and non-<code>Optional</code>
in another, or a pointer type will be imported as <code>OpaquePointer</code>
rather than <code>UnsafePointer&lt;FOO&gt;</code>.</p>

<p>If you do find yourself needing to make these kinds of adjustments,
you can make your local copy of the package dependency editable by
doing</p>

<div><pre><code><span>$</span><span> </span>swift package edit SomePackage
</code></pre></div>

<p>and then editing the files in the <code>Packages</code> directory that appears in
your program‚Äôs source directory.  You may wish to consider raising PRs
upstream with any fixes you may have.</p>


  
    
  
</article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flameshot ‚Äì Open-source screenshot software (343 pts)]]></title>
            <link>https://flameshot.org/</link>
            <guid>40650844</guid>
            <pubDate>Tue, 11 Jun 2024 20:03:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flameshot.org/">https://flameshot.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40650844">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pills-tabContent" role="tabpanel" aria-labelledby="pills-linux-tab">
            <h4>Get the latest Flameshot</h4>
            <h5><strong>Linux Downloads</strong></h5>
            <p>64-bit only, install via Appimage, your package manager, Snapcraft or Flathub</p>
            
            <p><a href="https://snapcraft.io/flameshot"><img src="https://flameshot.org/img/snapcraft.svg" title="Get it from the Snapcraft store" alt="get it from snapcraft store"></a>
              <a href="https://flathub.org/apps/details/org.flameshot.Flameshot"><img src="https://flameshot.org/img/flathub.svg" title="Get it from Flathub" alt="get it from flathub"></a>
            </p>
            <p><a href="https://github.com/flameshot-org/flameshot/releases">Looking for older releases?</a></p><div>
              <p>
                <h6>Install via Package Manager</h6>
              </p>
              
              <div>
                <p>Ubuntu 18.04+ and Debian 10+</p>
                <p><code>apt install flameshot</code></p>
              </div>
              <div>
                <p>openSUSE</p>
                <p><code>zypper install flameshot</code></p>
              </div>
              <div>
                <p>Void Linux</p>
                <p><code>xbps-install flameshot</code></p>
              </div>
              
              <div>
                <p>Fedora</p>
                <p><code>dnf install flameshot</code></p>
              </div>
              <div>
                <p>NixOs</p>
                <p><code>nix-env -iA nixos.flameshot</code></p>
              </div>
            </div>
          </div></div>]]></description>
        </item>
    </channel>
</rss>