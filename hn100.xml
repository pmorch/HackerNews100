<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 01 Feb 2026 04:30:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Swift is a more convenient Rust (248 pts)]]></title>
            <link>https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust</link>
            <guid>46841374</guid>
            <pubDate>Sat, 31 Jan 2026 22:05:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust">https://nmn.sh/blog/2023-10-02-swift-is-the-more-convenient-rust</a>, See on <a href="https://news.ycombinator.com/item?id=46841374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><a href="https://naman34.svbtle.com/swift-is-the-more-convenient-rust"></a>
<p><em>(originally published on my <a href="https://naman34.svbtle.com/swift-is-the-more-convenient-rust">old blog</a>)</em></p>
<p>I’ve been learning Rust lately.</p>
<p>Rust is one of the most loved languages out there, is fast, and has an amazing community. Rust invented the concept of ownership as a solution memory management issues without resorting to something slower like Garbage Collection or Reference Counting. But, when you don’t need to be quite as low level, it gives you utilities such as <code>Rc</code>, <code>Arc</code> and <code>Cow</code> to do reference counting and “clone-on-right” in your code. And, when you need to go lower-level still, you can use the <code>unsafe</code> system and access raw C pointers.</p>
<p>Rust also has a bunch of awesome features from functional languages like tagged enums, match expressions, first class functions and a powerful type system with generics.</p>
<p>Rust has an LLVM-based compiler which lets it compile to native code and WASM.</p>
<p>I’ve also been doing a bit of Swift programming for a couple of years now. And the more I learn Rust, the more I see a reflection of Swift. (I know that Swift stole a lot of ideas from Rust, I’m talking about my own perspective here).</p>
<p>Swift, too, has awesome features from functional languages like tagged enums, match expressions and first-class functions. It too has a very powerful type system with generics.</p>
<p>Swift too gives you complete type-safety without a garbage collector. By default, everything is a value type with “copy-on-write” semantics. But when you need extra speed you can opt into an ownership system and “move” values to avoid copying. And if you need to go even lower level, you can use the unsafe system and access raw C pointers.</p>
<p>Swift has an LLVM-based compiler which lets it compile to native code and WASM.</p>
<a id="deja-vu" href="#deja-vu"><h3><span>#</span>Deja Vu?</h3></a>
<p>You’re probably feeling like you just read the same paragraphs twice. This is no accident. Swift is extremely similar to Rust and has most of the same feature-set. But there is a very big difference is <em>perspective</em>. If you consider the default memory model, this will start to make a lot of sense.</p>
<a id="rust-is-bottom-up-swift-is-top-down" href="#rust-is-bottom-up-swift-is-top-down"><h3><span>#</span>Rust is bottom-up, Swift is top-down.</h3></a>
<p>Rust is a low-level systems language at heart, but it gives you the tools to go higher level. Swift starts at a high level and gives you the ability to go low-level.</p>
<p>The most obvious example of this is the memory management model. Swift use value-types by default with <code>copy-on-write</code> semantics. This is the equivalent of using <code>Cow&lt;&gt;</code> for all your values in Rust. But defaults matter. Rust makes it easy to use “moved” and “borrowed” values but requires extra ceremony to use <code>Cow&lt;&gt;</code> values as you need to “unwrap” them <code>.as_mutable()</code> to actually use the value within. Swift makes these Copy-on-Write values easy to use and instead requires extra ceremony to use borrowing and moving instead. Rust is faster by default, Swift is simpler and easier by default.</p>
<a id="swift-takes-rusts-ideas-and-hides-them-in-c-like-syntax" href="#swift-takes-rusts-ideas-and-hides-them-in-c-like-syntax"><h3><span>#</span>Swift takes Rust’s ideas and hides them in C-like syntax.</h3></a>
<p>Swift’s syntax is a masterclass in taking awesome functional language concepts and hiding them in C-like syntax to trick the developers into accepting them.</p>
<p>Consider <code>match</code> statements. This is what a match statement looks like in Rust:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    Penny</span><span>,</span><br></span></p><p><span><span>    Nickel</span><span>,</span><br></span></p><p><span><span>    Dime</span><span>,</span><br></span></p><p><span><span>    Quarter</span><span>,</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>fn </span><span>value_in_cents</span><span>(</span><span>coin</span><span>: </span><span>Coin</span><span>) -&gt; </span><span>u8</span><span> {</span><br></span></p><p><span><span>    match </span><span>coin</span><span> {</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Penny</span><span> =&gt; </span><span>1</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Nickel</span><span> =&gt; </span><span>5</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Dime</span><span> =&gt; </span><span>10</span><span>,</span><br></span></p><p><span><span>        Coin</span><span>::</span><span>Quarter</span><span> =&gt; </span><span>25</span><span>,</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Here’s how that same code would be written in Swift:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    case </span><span>penny</span><br></span></p><p><span><span>    case </span><span>nickel</span><br></span></p><p><span><span>    case </span><span>dime</span><br></span></p><p><span><span>    case </span><span>quarter</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>func </span><span>valueInCents</span><span>(</span><span>coin</span><span>: Coin) -&gt; </span><span>Int</span><span> {</span><br></span></p><p><span><span>    switch</span><span> coin {</span><br></span></p><p><span><span>    case</span><span> .</span><span>penny</span><span>: </span><span>1</span><br></span></p><p><span><span>    case</span><span> .</span><span>nickel</span><span>: </span><span>5</span><br></span></p><p><span><span>    case</span><span> .</span><span>dime</span><span>: </span><span>10</span><br></span></p><p><span><span>    case</span><span> .</span><span>quarter</span><span>: </span><span>25</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Swift doesn’t have a <code>match</code> statement or expression. It has a <code>switch</code> statement that developers are already familiar with. Except this <code>switch</code> statement is actually not a <code>switch</code> statement at all. It’s an expression. It doesn’t “fallthrough”. It does pattern matching. It’s just a <code>match</code> expression with a different name and syntax.</p>
<p>In fact, Swift treats <code>enums</code> as more than <em>just</em> types and lets you put methods directly on it:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>Coin</span><span> {</span><br></span></p><p><span><span>    case </span><span>penny</span><br></span></p><p><span><span>    case </span><span>nickel</span><br></span></p><p><span><span>    case </span><span>dime</span><br></span></p><p><span><span>    case </span><span>quarter</span><br></span></p><p><span><span>    func </span><span>valueInCents</span><span>() -&gt; </span><span>Int</span><span> {</span><br></span></p><p><span><span>        switch </span><span>self</span><span> {</span><br></span></p><p><span><span>        case</span><span> .</span><span>penny</span><span>: </span><span>1</span><br></span></p><p><span><span>        case</span><span> .</span><span>nickel</span><span>: </span><span>5</span><br></span></p><p><span><span>        case</span><span> .</span><span>dime</span><span>: </span><span>10</span><br></span></p><p><span><span>        case</span><span> .</span><span>quarter</span><span>: </span><span>25</span><br></span></p><p><span><span>        }</span><br></span></p><p><span><span>    }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<a id="optional-types" href="#optional-types"><h4><span>#</span>Optional Types</h4></a>
<p>Rust doesn’t have <code>null</code>, but it does have <code>None</code>. Swift has a <code>nil</code>, but it’s really just a <code>None</code> in hiding. Instead of an <code>Option&lt;T&gt;</code>, Swift let’s you use <code>T?</code>, but the compiler still forces you to check that the value is not <code>nil</code> before you can use it.</p>
<p>You get the same safety with more convenience since you can do this in Swift with an optional type:</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>let</span><span> val: T?</span><br></span></p><p><span><span>if </span><span>let</span><span> val {</span><br></span></p><p><span><span>  // val is now of type `T`.</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>Also, you’re not forced to wrap every value with a <code>Some(val)</code> before returning it. The Swift compiler takes care of that for you. A <code>T</code> will transparently be converted into a <code>T?</code> when needed.</p>
<a id="error-handling" href="#error-handling"><h4><span>#</span>Error Handling</h4></a>
<p>Rust doesn’t have <code>try-catch</code>. Instead it has a <code>Result</code> type which contains the success and error types.</p>
<p>Swift doesn’t have a <code>try-catch</code> either, but it does have <code>do-catch</code> and you have to use <code>try</code> before calling a function that could throw. Again, this is just deception for those developers coming from C-like languages. Swift’s error handling works exactly like Rust’s behind the scenes, but it is hidden in a clever, familiar syntax.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>func </span><span>usesErrorThrowingFunction</span><span>() </span><span>throws</span><span> {</span><br></span></p><p><span><span>  let</span><span> x = </span><span>try </span><span>thisFnCanThrow</span><span>()</span><br></span></p><p><span><span>}</span><br></span></p><p><span><span>func </span><span>handlesErrors</span><span>() {</span><br></span></p><p><span><span>  do</span><span> {</span><br></span></p><p><span><span>    let</span><span> x = </span><span>try </span><span>thisFnCanThrow</span><span>()</span><br></span></p><p><span><span>  } </span><span>catch </span><span>err</span><span> {</span><br></span></p><p><span><span>    // handle the `err` here.</span><br></span></p><p><span><span>  }</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>This is very similar to how Rust let’s you use <code>?</code> at the end of statements to automatically forward errors, but you don’t have to wrap your success values in <code>Ok()</code>.</p>
<a id="rusts-compiler-catches-problems-swifts-compiler-solves-some-of-them" href="#rusts-compiler-catches-problems-swifts-compiler-solves-some-of-them"><h3><span>#</span>Rust’s compiler catches problems. Swift’s compiler solves some of them</h3></a>
<p>There are many common problems that Rust’s compiler will catch at compile time and even suggest solutions for you. The example that portrays this well is self-referencing enums.</p>
<p>Consider an enum that represents a tree. Since, it is a recursive type, Rust will force you to use something like <code>Box&lt;&gt;</code> for referencing a type within itself.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>enum </span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt; {</span><br></span></p><p><span><span>    Leaf</span><span>(</span><span>T</span><span>),</span><br></span></p><p><span><span>    Branch</span><span>(</span><span>Vec</span><span>&lt;</span><span>Box</span><span>&lt;</span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt;&gt;&gt;),</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p>(You could also us <code>Box&lt;Vec&lt;TreeNode&lt;T&gt;&gt;&gt;</code> instead)</p>
<p>This makes the problem explicit and forces you to deal with it directly. Swift is a little more, <em>automatic</em>.</p>
<div data-bright-theme="dark-plus"><pre><code><p><span><span>indirect enum </span><span>TreeNode</span><span>&lt;</span><span>T</span><span>&gt; {</span><br></span></p><p><span><span>    case </span><span>leaf</span><span>(T)</span><br></span></p><p><span><span>    case </span><span>branch</span><span>([TreeNode&lt;T&gt;])</span><br></span></p><p><span><span>}</span><br></span></p></code></pre></div>
<p><strong>Note</strong>: that you still have to annotate this <code>enum</code> with the <code>indirect</code> keyword to indicate that it is recursive. But once you’ve done that, Swift’s compiler takes care of the rest. You don’t have to think about <code>Box&lt;&gt;</code> or <code>Rc&lt;&gt;</code>. The values just work normally.</p>
<a id="swift-is-less-pure" href="#swift-is-less-pure"><h3><span>#</span>Swift is less “pure”</h3></a>
<p>Swift was designed to replace Objective-C and needed to be able to interface with existing code. So, it has made a lot of pragmatic choices that makes it a much less “pure” and “minimalist” language. Swift is a pretty big language compared to Rust and has many more features built-in. However, Swift is designed with “progressive disclosure” in mind which means that just as soon as you think you’ve learned the language a little more of the iceberg pops out of the water.</p>
<p>Here are just <em>some</em> of the language features:</p>
<ul>
<li>Classes / Inhertence</li>
<li>async-await</li>
<li>async-sequences</li>
<li>actors</li>
<li>getters and setters</li>
<li>lazy properties</li>
<li>property wrappers</li>
<li>Result Builders (for building tree-like structures. e.g. HTML / SwiftUI)</li>
</ul>
<a id="convenience-has-its-costs" href="#convenience-has-its-costs"><h3><span>#</span>Convenience has its costs</h3></a>
<p>Swift is a far easier language to get started and productive with. The syntax is more familiar and a lot more is done for you automatically. But this really just makes Swift a higher-level language and it comes with the same tradeoffs.</p>
<p>By default, a Rust program is much faster than a Swift program. This is because Rust is fast by default, and <em>lets</em> you be slow, while Swift is easy by default and <em>lets</em> you be fast.</p>
<p>Based on this, I would say both languages have their uses. Rust is better for systems and embedded programming. It’s better for writing compilers and browser engines (Servo) and it’s better for writing entire operating systems.</p>
<p>Swift is better for writing UI and servers and some parts of compilers and operating systems. Over time I expect to see the overlap get bigger.</p>
<a id="the-cross-platform-problem" href="#the-cross-platform-problem"><h3><span>#</span>The “cross-platform” problem</h3></a>
<p>There is a perception that Swift is only a good language for Apple platforms. While this was once true, this is no longer the case and Swift is becoming increasingly a good cross-platform language. Hell, Swift even compiles to wasm, and the forks made by the swift-wasm team were merged back into Swift core earlier this year.</p>
<p>Swift on Windows is being used by The Browser Company to share code and bring the Arc browser to windows. Swift on Linux has long been supported by Apple themselves in order to push “Swift on Server”. Apple is directly sponsoring the Swift on Server conference.</p>
<p>This year Embedded Swift was also announced which is already being used on small devices like the Panic Playdate.</p>
<p>Swift website has been highlighting many of these projects:</p>
<ul>
<li><a href="https://www.swift.org/blog/swift-everywhere-windows-interop/">Swift on Windows</a></li>
<li><a href="https://www.swift.org/blog/embedded-swift-examples/">Embedded Swift</a></li>
<li><a href="https://www.swift.org/blog/adwaita-swift/">Gnome apps with Swift on Linux</a></li>
<li><a href="https://www.swift.org/blog/byte-sized-swift-tiny-games-playdate/">Swift on Playdate</a></li>
</ul>
<p>The browser company says that <a href="https://speakinginswift.substack.com/p/interoperability-swifts-super-power">Interoperability is Swift’s super power</a>.</p>
<p>And the Swift project has been trying make working with Swift a great experience outside of XCode with projects like an open source LSP and funding the the VSCode extension.</p>
<!-- -->
<!--$?--><template id="B:0"></template><!--/$-->
<a id="swift-is-not-a-perfect-language" href="#swift-is-not-a-perfect-language"><h3><span>#</span>Swift is not a perfect language.</h3></a>
<p>Compile times are (like Rust) quite bad. There is some amount of feature creep and the language is larger than it should be. Not all syntax feels familiar. The <a href="https://swiftpackageindex.com/">package ecosystem</a> isn’t nearly as rich as Rust.</p>
<p>But the “Swift is only for Apple platforms” is an old and tired cliche at this point. Swift is already a cross-platform, ABI-stable language with no GC, automatic Reference Counting and the option to opt into ownership for even more performance. Swift packages increasingly work on Linux. Foundation was ported to Swift, open sourced and made open source. It’s still early days for Swift as a good, more convenient, Rust alternative for cross-platform development, but it is here now. It’s no longer a future to wait for.</p><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Google Cloud suspended my account for 2 years, only automated replies (102 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=46839375</link>
            <guid>46839375</guid>
            <pubDate>Sat, 31 Jan 2026 18:41:36 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=46839375">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><tbody><tr id="46839742"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46839742" href="https://news.ycombinator.com/vote?id=46839742&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>I had my GCP quota algorithmically set to 0 after spending 6 months working with them to launch a startup.</p><p>I went through a ton of hoops to get approval for our quota. We sent them system diagrams, code samples, financial reports, growth predictions, etc. It was months of back and forth. I'll also add that it was very annoying because they auto-reject your quota request if you don't respond to their emails within 48 hours but their responses take 1-3 weeks. In any case, after 6 months, they eventually approved us for our quota, we launched, and they shut us down to 0 quota across all services the instant our production app got traffic.</p><p>We contacted them again asking for help. We never got any human response. We got a boiler plate template a few times, but that was it.</p><p>I will never ever ever again use a cloud service where I can't guarantee that I can get good customer service. Unfortunately for a small business that means no big clouds like AWS, GCP, etc.</p><p>Yes, I am bitter.</p></div></td></tr></tbody></table></td></tr><tr id="46840254"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840254" href="https://news.ycombinator.com/vote?id=46840254&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Has AWS support gone downhill in the last two years?  I've worked with them in the past - as both an individual and a couple startups - I always reached a human.  Issues weren't always resolved as quickly as I'd like but response times were short.</p></div></td></tr></tbody></table></td></tr><tr id="46840477"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46840477" href="https://news.ycombinator.com/vote?id=46840477&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Working in small and medium businesses I've observed the same thing, and I've been quite satisfied with it. So I don't think it's really gone downhill, so GP's comment doesn't really resonate for me, but that isn't to negate their experience. Otoh I keep hearing horror stories about GCP and now I'm reluctant to try it.</p></div></td></tr></tbody></table></td></tr><tr id="46840679"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46840679" href="https://news.ycombinator.com/vote?id=46840679&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Shitting on GCP is just popular on HN and always gets upvoted. AWS and Azure have royally fucked thousands of customers if you care to search for those writeups. My wild ass guess, considering posts like these have zero background details, is that they were careless with service account keys and their account got suspended for mining crypto or something. They also probably weren’t actually <i>paying</i> for support of any kind and that’s why no one is responding to them.</p></div></td></tr></tbody></table></td></tr><tr id="46842151"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46842151" href="https://news.ycombinator.com/vote?id=46842151&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Nope. We had been testing in our development and staging environments for months. We were deploying to production the exact same stack and we got our quota revoked within about an hour. We must have tripped some random thing. We have absolutely no idea what I could have been though.</p></div></td></tr></tbody></table></td></tr><tr id="46843483"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46843483" href="https://news.ycombinator.com/vote?id=46843483&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>I have the same question. I always got human response after 24-48hours or after one round of messages (with an automated human or machine, not sure). But so far, across 3 accounts and a dozens of correspondence, I always got a human.</p></div></td></tr></tbody></table></td></tr><tr id="46843270"><td></td></tr><tr id="46841359"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46841359" href="https://news.ycombinator.com/vote?id=46841359&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>It has!</p><p>In the 2010s I always got an AWS support team to help.</p><p>Now I get handed off to an external partner of AWS certified contractors.</p><p>They are often terrible. They have no backend systems access and just run through the AWS equivalent of "reboot it", "defrag your disk". Basically trying to find an issue in my pipeline. Which they never do because it's the same TF scripts used for years.</p><p>Only once we waste time going through the motions do I get passed up to someone who can actually correct the backend issue in the AWS stack itself.</p><p>Tbf though I rarely ever have to contact AWS support at this point. The few times I have in the last 2-3 was due to issues after they rolled out an update or with a newer service we wanted to use.</p><p>Never have issues with stable services like S3, ECS, EKS, or RDS.</p></div></td></tr></tbody></table></td></tr><tr id="46843284"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46843284" href="https://news.ycombinator.com/vote?id=46843284&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; They have no backend systems access and just run through the AWS equivalent of "reboot it", "defrag your disk"</p><p>To be fair I would bet money that the overwhelmingly vast majority of support tickets are exactly those kind of issues, and ones that refer to actual bugs on their end are, comparatively, extremely rare, and <i>should</i> have to be escalated through normal procedures to weed out common problems.</p></div></td></tr></tbody></table></td></tr><tr id="46840337"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840337" href="https://news.ycombinator.com/vote?id=46840337&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>if you want best support (while staying with big cloud) then Microsoft is the best .</p><p>Azure has its flaws but Microsoft puts a lot of people and effort behind it . We are not that large but there are so many instances where Microsoft reps will come in call with our customers or their people working with common customers will help out etc.</p><p>AWS has a done a decent job of taking enterprise business seriously last 10 years.  you can get human support but generally they will charge you , I.e if better support you want you have to pay for premium support plans .</p><p>They are constrained unlike MS they don’t have non-cloud large enterprise business relationships for decades M365 or AD etc that helps with building the enterprise DNA.</p><p>In all three clouds it works best if you don’t buy directly, buy through a partner reseller , who both have the relationships to the CSP and have the people to work with you .</p></div></td></tr></tbody></table></td></tr><tr id="46840911"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46840911" href="https://news.ycombinator.com/vote?id=46840911&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Sorry, no.</p><p>MS is the same network were even their lead engineers answer "well, uhh create a new account and hope you're not banned", when it comes to fixing a illegitimate ban issue.</p><p>None of the biggies are good. None of them.</p><p>You're better off building your own data enter. Can't believe I'm saying that, but I am. And it doesnt have to be acres and MW and water cooled. It can be a 42U rack.</p><p>Hell, I'm a homeowner and have 27U rack with 10U full, battery backup, solar, fiber and a backup internet connection, and stuff.</p><p>A small business could easy do this and own the hardware and software to their enterprise. In fact, they probably should. Helps prevent rug pulls!</p></div></td></tr></tbody></table></td></tr><tr id="46841144"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46841144" href="https://news.ycombinator.com/vote?id=46841144&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Now I am curious what is the realistic price a business would expect to put down for a full rack. Say UPS, switch, 4-8U storage, and the rest CPU compute. Without entertaining GPUs, I bet you can get very respectably speced 1-2U servers for $5k a pop. So few hundred thousand probably gets you just an unbelievable amount of horsepower.</p></div></td></tr></tbody></table></td></tr><tr id="46841140"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46841140" href="https://news.ycombinator.com/vote?id=46841140&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Having run a small business on one of the big clouds for almost 10 years now building your own data center is insane advice.</p><p>&gt;easy</p><p>Hell no</p></div></td></tr></tbody></table></td></tr><tr id="46840649"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840649" href="https://news.ycombinator.com/vote?id=46840649&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Quota for what? In my experience the GCP service quotas are pretty sensible and if you’re running up against them you’re either dealing with unusual levels of traffic or (more often) you’re just using that service incorrectly.</p></div></td></tr></tbody></table></td></tr><tr id="46841321"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46841321" href="https://news.ycombinator.com/vote?id=46841321&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>The quota we needed increased far beyond the usual was the YouTube API. The startup was a media editing and publishing tool, with a feature to upload videos to YouTube on your behalf. Uploading a video requires a ton of quota, which they gave us.</p><p>Regardless, dropping all quotas to 0 effectively killed our GCP account.</p></div></td></tr></tbody></table></td></tr><tr id="46842551"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46842551" href="https://news.ycombinator.com/vote?id=46842551&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Interesting. I guess we’ve learned an important lesson in not building businesses around APIs that don’t have an SLA…</p></div></td></tr></tbody></table></td></tr><tr id="46842767"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46842767" href="https://news.ycombinator.com/vote?id=46842767&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>How many services have meaningful SLAs for extreme downtime?</p><p>Github and (parts of) AWS will give you a small discount at 0.1% downtime, a bigger discount at 1% downtime, and AWS will refund the whole month for 5% downtime.  But beyond that they don't care.  If a particular customer gets no service at all then their entire $0 gets refunded and that's it.</p></div></td></tr></tbody></table></td></tr><tr id="46842724"><td></td></tr><tr id="46840716"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46840716" href="https://news.ycombinator.com/vote?id=46840716&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; Quota for what?</p><p>Sure, I'm interested too.</p><p>&gt; In my experience the GCP service quotas are pretty sensible and if you’re running up against them you’re either dealing with unusual levels of traffic or (more often) you’re just using that service incorrectly.</p><p>Well 0 is not sensible, and who cares if it's weird if they got detailed approval and they're paying for it.</p></div></td></tr></tbody></table></td></tr><tr id="46840923"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46840923" href="https://news.ycombinator.com/vote?id=46840923&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>"... and they're paying for it..." - that might be the exact issue. Google has no way to ensure that these small shops and startups will pay their bill, so quotas are used to prevent the company from running up a large bill they won't be able to pay.</p><p>I see a bunch of threads on reddit about startups accidentally going way over budget and then asking for credits back.</p><p>This doesn't at all mean the startups have bad intent, but things happen and Google doesn't want to deal with a huge collection issue.</p><p>If someone rolled up to your gas station and wanted to pump 10,000 gallons of gas but only pay you next month - would you allow it?</p></div></td></tr></tbody></table></td></tr><tr id="46841091"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46841091" href="https://news.ycombinator.com/vote?id=46841091&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Well that is kind of a problem of their own making. The clouds <i>refuse</i> to entertain the prospect of pre-paying for services/having some sort of hard spending limits because they know that over-allocation is probably driving a decent amount of revenue.</p></div></td></tr></tbody></table></td></tr><tr id="46841192"><td><table><tbody><tr><td indent="5"><img src="https://news.ycombinator.com/s.gif" height="1" width="200"></td><td><center><a id="up_46841192" href="https://news.ycombinator.com/vote?id=46841192&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>I dont really understand ops problem as I've been able to set monthly limits on expenditure. Seems trivial to setup.</p></div></td></tr></tbody></table></td></tr><tr id="46841335"><td><table><tbody><tr><td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td><center><a id="up_46841335" href="https://news.ycombinator.com/vote?id=46841335&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>That’s not how quotas work in GCP. Google sets quotas for certain APIs for interacting with GCP itself, like how many VMs you can create per second.    They’re not billable. Sometimes these quotas can be be increased if you need them to be. But the way op described it makes no sense.</p></div></td></tr></tbody></table></td></tr><tr id="46840781"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46840781" href="https://news.ycombinator.com/vote?id=46840781&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Sure, but the comment is so vague I’m skeptical the OP knew what they were doing in the first place, or it happened exactly as they wrote. Maybe a service quota was reset to the default? But just set to zero? Doesn’t pass the sniff test.</p></div></td></tr></tbody></table></td></tr><tr id="46842629"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46842629" href="https://news.ycombinator.com/vote?id=46842629&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>What did your account manager say about this. Getting this interaction right is the core of their job, enabling your business on the platform so you spend more money. With this bad an interaction I'd have asked for a new account manager.</p></div></td></tr></tbody></table></td></tr><tr id="46841552"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46841552" href="https://news.ycombinator.com/vote?id=46841552&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>A colleague had a similar quota issue. 4 times quota restoration request was rejected. Upon the final request he put “women owned startup helping underprivileged kids” and it was approved.</p><p>It can’t hurt.</p></div></td></tr></tbody></table></td></tr><tr id="46840925"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840925" href="https://news.ycombinator.com/vote?id=46840925&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; they auto-reject your quota request if you don't respond to their emails within 48 hours but their responses take 1-3 weeks</p><p>It boggles my mind anyone would base their business on their good will. By now it should be obvious that companies with a huge number of customers don't care about individual cases that much for obvious reasons. That's why they cut on customer support. You get much better support with smaller companies where you (as an individual or business) are much more important to them.</p></div></td></tr></tbody></table></td></tr><tr id="46840580"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46840580" href="https://news.ycombinator.com/vote?id=46840580&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; I am a CS researcher at UC Berkeley. This has seriously impacted my work.</p><p>I would try to get help from your department. Somewhere within CS and CS-adjacent departments at Berkeley there’s likely to be someone with an official or unofficial connection to Google that can get you in touch with a human to at least clarify the situation.</p></div></td></tr></tbody></table></td></tr><tr id="46841055"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46841055" href="https://news.ycombinator.com/vote?id=46841055&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>So much information is missing from this.</p><p>What Google account? Is it personal Gmail? Or your academic account? Are you using this for personal reasons or professional or commercial reasons? What kind of payment method is attached? What was your level of usage? Any idea why you were suspended initially?</p><p>Because it could be that Google is reviewing your appeal and simply shadow-denying it, and you haven't provided the right information to make it look legit. E.g. if they think you're a spammer or mining crypto or they think you're creating additional free accounts to use free credits, they're obviously not going to tell you what makes them think that.</p><p>But if this is for university-related work, and your university purchases IT+cloud services from Google (as they probably do), talk to your IT department so they can get you in touch with their institution-level support. Obviously, for the attached Google sales rep, the last thing they want is a CS researcher losing access to GCP.</p></div></td></tr></tbody></table></td></tr><tr id="46841161"><td></td></tr><tr id="46840320"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46840320" href="https://news.ycombinator.com/vote?id=46840320&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; I am a CS researcher at UC Berkeley. This has seriously impacted my work.</p><p>Can I suggest a topic for your next research? "Cloud exascalers and their negative impact on the society"</p></div></td></tr></tbody></table></td></tr><tr id="46840694"><td></td></tr><tr id="46840996"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46840996" href="https://news.ycombinator.com/vote?id=46840996&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>There are so many things with this statement I don't even know where to start. I hope you're being sarcastic.</p></div></td></tr></tbody></table></td></tr><tr id="46840508"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840508" href="https://news.ycombinator.com/vote?id=46840508&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Not sure why this is getting downvoted. This may be snark, but this is 100% needed in the world we live in today. It is a fact of today's world that individuals have no leverage over these companies. I can understand why big companies, who have leverage, buy their services. But I don't understand why individuals, who have no leverage, buy their services and build their profession and livelihood around them. Any day, they can cut you off from their services. You are being irresponsible to yourself if you put all your eggs in these big tech baskets.</p><p>We seriously do need this kind of research and compelling articles that argue why relying on these big tech cloud services is harmful for individuals.</p></div></td></tr></tbody></table></td></tr><tr id="46840248"><td></td></tr><tr id="46842633"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46842633" href="https://news.ycombinator.com/vote?id=46842633&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Our GCP account manager was always pretty good at solving these sorts of problems for us at my last company.</p></div></td></tr></tbody></table></td></tr><tr id="46841277"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46841277" href="https://news.ycombinator.com/vote?id=46841277&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>The role of GCP is to help enterprises negotiate better deals out of Azure/AWS.
Why would anyone actually use it is beyond me...</p></div></td></tr></tbody></table></td></tr><tr id="46840296"><td></td></tr><tr id="46839763"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46839763" href="https://news.ycombinator.com/vote?id=46839763&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>It's gone. No human will ever respond to you. That's how these companies operate. From here, you realistically have two options.</p><p>1. Forget the account and move on. You could create a new one, but nobody can tell how long it would take before that gets suspended as well.</p><p>2. If the suspension has a tangible negative impact on your profession, hire a lawyer and get proper legal advice.</p><p>Most important of all, let this be a lesson for you and your colleagues. It is a terrible idea to let any critical part of your life depend on unregulated industries that can wipe out someone's livelihood at the whim of machine learning systems. Learn this lesson and pass it on to everyone you know.</p><p>As an individual, you are nobody to Google and you have no leverage. It is reckless to build your livelihood or profession around their platforms. If you were a company, your team could speak to an account manager and negotiate. As an individual, your only real leverage is legal action.</p><p>Stories like this appear every month. I don't know how many more it will take before it becomes best practice not to depend on these utterly abominable rackets for anything critical.</p></div></td></tr></tbody></table></td></tr><tr id="46840373"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840373" href="https://news.ycombinator.com/vote?id=46840373&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; let this be a lesson for you and your colleagues.</p><p>Nah, big tech infiltrates everything, it’s 100% their fault. Why did everyone switch to  webmail? Why did we gravitate to web apps? Big tech persuaded us all to do it.</p><p>With big promises comes great responsibility, and the stuff in the fine print doesn’t count. It’s not ethical to invite dependency and randomly kneecap people; it shouldn’t be legal either.</p></div></td></tr></tbody></table></td></tr><tr id="46840466"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46840466" href="https://news.ycombinator.com/vote?id=46840466&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>100% agree with you. The big techs are definitely 100% at fault. But you know, fool me once, shame on me. Fool me twice...</p><p>I mean, we get these stories every month. Yes, 100% it is not ethical to randomly kneecap people. But let's be honest. Nobody is working on making these big tech companies accountable for the potentially devastating, algorithm-driven decisions they take. How many more times do they have to fool us before we all realize that it's time to move away from them?</p><p>All I ask from you, myself and all the tech folks here is to learn from these lessons and pass them on to everyone around you. With how things are today, it is reckless to depend on these big tech cloud services for your livelihood and profession. If you're working for a company where the company has leverage, all good. But as an individual, you should stay away from these big tech companies, because they can screw up your life any day, without warning and without recourse.</p></div></td></tr></tbody></table></td></tr><tr id="46840872"><td></td></tr><tr id="46841189"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46841189" href="https://news.ycombinator.com/vote?id=46841189&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>With email in particular, it's not like chocolate. If you self-host email, or use any other cloud host besides Microsoft or Google, then Microsoft and Google will randomly fail to deliver emails you send to their users, even though you have SPF, DKIM, DMARC, etc. set up exactly right.</p></div></td></tr></tbody></table></td></tr><tr id="46841375"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46841375" href="https://news.ycombinator.com/vote?id=46841375&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Seriously #2 is your only recourse.  Download the terms of service / your service contract , highlight their violations and send them a certified letter about breach of contract and that you intend legal recourse.</p></div></td></tr></tbody></table></td></tr><tr id="46840485"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46840485" href="https://news.ycombinator.com/vote?id=46840485&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Cloud lock-in is real and requires a lot of forethought to avoid or at least mitigate. on the LLM side I have pushed my last two companies to always have at least 3 vendors for hosting and a system to fail over instantly or even load balance based on different criteria. It has paid massive dividends. I wish that philosophy was easier to implement at the cloud level for all services.</p></div></td></tr></tbody></table></td></tr><tr id="46843006"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46843006" href="https://news.ycombinator.com/vote?id=46843006&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>anything that has to do with google avoid at major cost</p><p>or have an alternative ready</p><p>for serious work -- don't use google &amp; don't use google devices either</p></div></td></tr></tbody></table></td></tr><tr id="46840943"><td></td></tr><tr id="46841358"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46841358" href="https://news.ycombinator.com/vote?id=46841358&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>This is an asinine question. Even if you build agnostic solutions (like a docker image), you have storage resources, networks, configs, ACLs, snapshots and more all trapped inside GCP. we’re human — we forget to backup things, or push important commits .  And we know cloud solutions quickly develop lock-in – even a simple cloud DB instance locks you into the vendors config .</p><p>So there are at least a dozen perfectly good reasons this guy is panicking that his account was suddenly revoked without warning.</p></div></td></tr></tbody></table></td></tr><tr id="46841743"><td></td></tr><tr id="46842390"><td><table><tbody><tr><td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td><center><a id="up_46842390" href="https://news.ycombinator.com/vote?id=46842390&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Appeals take time. And it’s not an uncommon case . It doesn’t make his desire to recover the resources any less valid .</p></div></td></tr></tbody></table></td></tr><tr id="46840836"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46840836" href="https://news.ycombinator.com/vote?id=46840836&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>UC Berkeley gets much of its IT infrastructure from Google in a big and expensive contract.  Perhaps some of the campus staff could try to negotiate on your behalf?</p></div></td></tr></tbody></table></td></tr><tr id="46841327"><td></td></tr><tr id="46841898"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46841898" href="https://news.ycombinator.com/vote?id=46841898&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>I had a bad Cloudflare experience. So, my card on file got no balance one day (my bad, I  forgot to update to a new card), and they just turned off the services.</p><p>They somehow managed to charge partial amount (like 80% of the bill), but decided to turn off everything anyway, even the services that could be covered by those 80%. They turned off what they offer for free, and we were unable to change the setting, like instead of their CDN point traffic to an S3 bucket, etc.</p><p>When they do that they basically freeze your account. I mean you cannot provide a new card to pay the outstanding bill, or do anything at all actually. You're not welcomed here anymore. Locked out. That's is a terrible way to react to a payment failure after being a paying customer for a few years.</p><p>It was hard to reach the support, and it took multiple days until I found someone on Reddit who looked at our ticket and it eventually helped.</p><p>PS I had much worse experience with GCP after being a loyal customer of them for like 15 years, so Clouflare is good.</p></div></td></tr></tbody></table></td></tr><tr id="46843501"><td></td></tr><tr id="46842663"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46842663" href="https://news.ycombinator.com/vote?id=46842663&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Yeah, we were looking for image CDN services (with resizing etc). Asked CloudFlare and they said $200 a month, everyone else was saying $3-5k per month.</p><p>Had a sales call with CloudFlare, they said yes they do flat rate billing and it's only $200 a month for all we can eat image hosting.</p><p>We of course called bullshit and third time around (talking to human sales reps) we said, just to get it in writing, we can do X bandwidth/Y images for $200 a month?</p><p>...oh errr, no, that would be more like $7k.</p><p>Thankfully we smelled bullshit and didn't take sales word for it. We'd have built an integration and started paying only to be bitten a month or two later when they readjusted our pricing. They basically refuse to talk about real pricing until you're already paying $200/m and locked in.</p><p>We ended up hosting our own on GKE for $500-$1k/m.</p></div></td></tr></tbody></table></td></tr><tr id="46840318"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46840318" href="https://news.ycombinator.com/vote?id=46840318&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>This is such a repetitious issue that I wonder why there has been no class action suits so far?</p><p>I think documenting these cases somewhere, and targeting not just Alphabet but all the other "we're too big to support little people like you" companies would be a good idea. I don't think the pay out would be significant, but the punitive impact might change things.</p></div></td></tr></tbody></table></td></tr><tr id="46840444"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840444" href="https://news.ycombinator.com/vote?id=46840444&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>OP is not clear , but it looks like GCP suspension not Google one (I.e email android etc)</p><p>All clouds reject a lot of businesses for their services for variety of reasons and there are alternatives in the market unlike say a Google account suspension .</p><p>I don’t think class action is feasible for cloud computing suspension (unless of course they are discriminating against a protected class etc)</p></div></td></tr></tbody></table></td></tr><tr id="46843069"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46843069" href="https://news.ycombinator.com/vote?id=46843069&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>i was thinking more in terms of tort law or contract law. They probably have a disclaimer and Tos that addresses all that, but given enough plaintiffs and their market dominance, it might amount to possible deliberate/calculated financial harm. It might be enough to not get thrown out of court at least. They can reject business for any reason, but once someone relies on their services for their business, there is always a certain expectation of continued service, and in the event of service termination, they may not need to explain themselves, but they must accommodate reasonable requests to transfer data, customers,etc.. elsewhere. Otherwise it sounds like tortiuous interference.</p><p><a href="https://en.wikipedia.org/wiki/Tortious_interference" rel="nofollow">https://en.wikipedia.org/wiki/Tortious_interference</a></p><p>&gt; Tortious interference, also known as intentional interference with contractual relations, in the common law of torts, occurs when one person intentionally damages someone else's contractual or business relationships with a third party, causing economic harm.</p><p>In this case, people who use GCP have customers and other contractual relationships. Google's termination of service interfered with that. Google also doing this as a matter of standard business practice indicates that they are aware that their action will interfere with people's contractual obligations (well common sense should tell them that anyways).</p><p>You can't force someone to sign a contract with you that says "if I interfere with your future contracts with arbitrary third parties on purpose, you can't sue me". The deliberate part is crucial from what I understand. If their decision making couldn't have accounted for the interference, and the interference wasn't calculated as an acceptable risk, there is no issue. But the plaintiffs can claim that repeated social media posts and acknowledgements of said interference by Google over the years means it's enough grounds for a suit. and a suit will mean discovery, google will have go hand over internal documents, depose employees,etc...</p><p>In the end, this might be more costly to companies like Google than just giving customers a grace period to move elsewhere before termination.</p><p>Obligatory: IANAL, I'm just a guy using big words I barely understand.</p></div></td></tr></tbody></table></td></tr><tr id="46840756"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840756" href="https://news.ycombinator.com/vote?id=46840756&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Of all the posts like this I’ve seen the customers are always 1) extremely scant on details about what they were using GCP for or why they were suspended, and more importantly 2) never actually paying for support.</p><p>Having worked with a fair few academics, I’m guessing they lost track of their service account keys and the account got suspended for crypto mining.</p></div></td></tr></tbody></table></td></tr><tr id="46843079"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46843079" href="https://news.ycombinator.com/vote?id=46843079&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>There have been plenty of posts where the reason was apparent. One i recall was caused by a guy having malware on his phone, and he happened to use a work email on his phone, so the entire GWS organization was banned, shutting down the company's operations.</p></div></td></tr></tbody></table></td></tr><tr id="46840842"><td></td></tr><tr id="46840522"><td><table><tbody><tr><td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td><center><a id="up_46840522" href="https://news.ycombinator.com/vote?id=46840522&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>&gt; but the punitive impact might change things</p><p>Call me cynical but I have little to no hope that even class actions would solve anything. These companies have become so big that they can take one class action after another for years to come without making a dent in their financials and without bringing any change to their operating procedures.</p></div></td></tr></tbody></table></td></tr><tr id="46843083"><td><table><tbody><tr><td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td><center><a id="up_46843083" href="https://news.ycombinator.com/vote?id=46843083&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>I'm just expecting them to change their calculus. Right now it costs them nothing to randomly shut down accounts. If it had some cost, perhaps some minor notice, accommodation,etc.. however automated might be worth just the man hours spent on lawsuits.</p></div></td></tr></tbody></table></td></tr><tr id="46841003"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46841003" href="https://news.ycombinator.com/vote?id=46841003&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>One of the many reasons I continue to degoogle and remove that garbage from my life wherever I can. So many cases like this.</p></div></td></tr></tbody></table></td></tr><tr id="46840574"><td></td></tr><tr id="46841542"><td><table><tbody><tr><td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td><center><a id="up_46841542" href="https://news.ycombinator.com/vote?id=46841542&amp;how=up&amp;goto=item%3Fid%3D46839375"></a></center></td><td><br>
<div><p>Xbox &amp; Discord are the only 2 services I’ve seen handle bans with adequate transparency (yes there is still room to improve).  Both offer a ban status tab ranging from hand-slap to giga-banned , allowing you to have some level of warning before being booted.</p><p>Given how dependent we all are on these services: we run our businesses and our lives, it’s despicable that more due process and transparency is not offered for shadow and proper bans like this.</p></div></td></tr></tbody></table></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nintendo DS code editor and scriptable game engine (110 pts)]]></title>
            <link>https://crl.io/ds-game-engine/</link>
            <guid>46839215</guid>
            <pubDate>Sat, 31 Jan 2026 18:27:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crl.io/ds-game-engine/">https://crl.io/ds-game-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=46839215">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <header><p>2026</p></header> <br data-astro-cid-tkmlznkr=""> <section data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">TL;DR</p> <p data-astro-cid-tkmlznkr="">
I built a <strong data-astro-cid-tkmlznkr="">scriptable 3D game engine</strong> for the Nintendo DS so
      you can write and run games directly on the console itself. Written in <strong data-astro-cid-tkmlznkr="">C</strong> using
<strong data-astro-cid-tkmlznkr="">libnds</strong>, it compiles to a <strong data-astro-cid-tkmlznkr="">~100KB .nds ROM</strong>
that runs at <strong data-astro-cid-tkmlznkr="">60 FPS</strong>. Features a touch-based code editor
      on the bottom screen and real-time 3D rendering on the top screen. Ships
      with a working 3D pong game as the default script.
</p> </section> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr=""> <iframe src="https://www.youtube.com/embed/3NlipciOHcY?si=6oqYL7KYsNa2DzGI&amp;start=0" title="DS game engine video demo short clip" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" data-astro-cid-tkmlznkr=""></iframe> </p> </div> <h2 data-astro-cid-tkmlznkr="">What is it?</h2> <p data-astro-cid-tkmlznkr="">
I felt nostalgic for when I made my first games on an old TI-82 graphing
    calculator. So I tried bringing that whole experience to my Nintendo DS. A
    complete programming environment you can hold in your hands.
</p>  <p data-astro-cid-tkmlznkr="">
What you see is a <strong data-astro-cid-tkmlznkr="">scriptable game engine</strong> with a custom programming
    language featuring variables, loops, and conditionals. You write code using the
    bottom touchscreen, click play, and the game will execute in real-time on the
    top screen with full 3D rendering.
</p> <br data-astro-cid-tkmlznkr=""> <div> <figure data-astro-cid-tkmlznkr=""> <img src="https://crl.io/images/ds-game-engine-reddit.png" alt="" data-astro-cid-tkmlznkr=""> </figure> </div> <h2 data-astro-cid-tkmlznkr="">How it works</h2> <p data-astro-cid-tkmlznkr="">At a high level, the engine breaks down into three parts:</p> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">1. Top screen: 3D rendering (hardware accelerated)</h3> <p data-astro-cid-tkmlznkr="">
Uses the DS's 3D hardware to render colored cubes at 60 FPS. Each model has
    position (X, Y, Z), rotation angle, and color. The camera is fully
    controllable with position and yaw/pitch angles.
</p> <pre data-astro-cid-tkmlznkr="">// DS 3D rendering code (C + libnds)
glMatrixMode(GL_MODELVIEW);
glLoadIdentity();
gluLookAt(camX, camY, camZ,  // camera position
          camX + lookX, camY + lookY, camZ + lookZ,  // look target
          0, 1, 0);  // up vector</pre> <p data-astro-cid-tkmlznkr="">
Each model is drawn with a transform (position + Y-axis rotation), then the
    cube geometry: one color, six quads (24 vertices).
</p> <pre data-astro-cid-tkmlznkr="">// Per-model draw calls (from main.c)
for (i = 0; i &lt; MAX_MODELS; i++) {
    if (!modelActive[i]) continue;
    glPushMatrix();
    glTranslatef(modelX[i], modelY[i], modelZ[i]);
    glRotatef(modelAngle[i], 0, 1, 0);
    drawCube(CUBE_COLORS[modelColorIndex[i]]);
    drawWireframeCube();
    glPopMatrix(1);
}

// Cube geometry: RGB15 color -&gt; glColor3b, then 6 faces as GL_QUADS
glColor3b(r * 255/31, g * 255/31, b * 255/31);
glBegin(GL_QUADS);
    /* +Z face */
    glVertex3f(-1.0f,  1.0f,  1.0f);
    glVertex3f( 1.0f,  1.0f,  1.0f);
    glVertex3f( 1.0f, -1.0f,  1.0f);
    glVertex3f(-1.0f, -1.0f,  1.0f);
    /* -Z, +Y, -Y, +X, -X ... (24 vertices total) */
glEnd();</pre> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">2. Bottom screen: Script editor (software rendered)</h3> <p data-astro-cid-tkmlznkr="">
A touch-based code editor with a custom UI drawn pixel-by-pixel to a 256x192
    bitmap. Features include:
</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Token picker</strong>: tap to insert commands (SET, ADD, LOOP,
      IF_GT, etc.)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Numpad</strong>: edit number parameters for each command</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Register selector</strong>: choose which variable (A-Z) to use
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Play/Pause/Stop/Step</strong>: control script execution</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">6 script slots</strong>: save and load different programs</li> </ul> <pre data-astro-cid-tkmlznkr="">// Software rendering to bottom screen
u16 *subBuffer = (u16*)BG_BMP_RAM_SUB(0);  // 256x192 framebuffer
subBuffer[y * 256 + x] = RGB15(31, 31, 31);  // white pixel</pre> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">3. Script interpreter</h3> <p data-astro-cid-tkmlznkr="">
Executes one line of script per frame (~60 lines/sec). Scripts can use 26
    variables (A-Z) plus 9 read-only registers for input (D-pad, buttons) and
    system state (elapsed time, camera direction).
</p> <pre data-astro-cid-tkmlznkr="">// Script execution (simplified)
if (tokenEquals(script[scriptIP], "add")) {
    int r = scriptReg[scriptIP];  // which register (A-Z)
    registers[r] += getNumberParamValue(scriptIP, 0);
    scriptIP++;  // next line
}</pre> <h2 data-astro-cid-tkmlznkr="">The scripting language</h2> <p data-astro-cid-tkmlznkr="">
Scripts are built from <strong data-astro-cid-tkmlznkr="">tokens</strong> (commands) with numeric parameters.
    Each line executes instantly, with no parsing overhead, just a series of if-checks
    against token names.
</p> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Available commands</h3> <div data-astro-cid-tkmlznkr=""> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Variables &amp; Math</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SET A 5</code> — set register A to 5</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">ADD A 1</code> — add 1 to A</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SUBTRACT A 2</code> — subtract 2 from A</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">MULTIPLY B -1</code> — multiply B by -1</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Control Flow</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">LOOP</code> / <code data-astro-cid-tkmlznkr="">END_LOOP</code> — infinite loop</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_GT A 10</code> — if A &gt; 10</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_LT A 0</code> — if A &lt; 0</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">IF_TRUE kA</code> — if A button pressed</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">END_IF</code> — close conditional</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">3D Objects</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">MODEL 0</code> — create model at index 0</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">POSITION 0 X Y Z</code> — set position</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">ANGLE 0 45</code> — set rotation angle</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">NEXT_COLOR 0</code> — cycle color</li> </ul> </div> <div data-astro-cid-tkmlznkr=""> <p data-astro-cid-tkmlznkr="">Camera &amp; Rendering</p> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">CAM_POS X Y Z</code> — set camera position</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">CAM_ANGLE yaw pitch</code> — set look direction</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">BACKGROUND 2</code> — set bg color (0-3)</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">BEEP</code> — play 0.1s sound</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">SLEEP 0.016</code> — pause (60 FPS = 0.016s/frame)</li> </ul> </div> </div> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Read-only registers (input &amp; state)</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""> <code data-astro-cid-tkmlznkr="">LEFT, UP, RGT, DN</code>: D-pad (1.0 when held, 0.0 when released)
</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">KA, KB</code>: A and B buttons</li> <li data-astro-cid-tkmlznkr=""><code data-astro-cid-tkmlznkr="">TIME</code>: elapsed seconds since script started</li> <li data-astro-cid-tkmlznkr=""> <code data-astro-cid-tkmlznkr="">LOOKX, LOOKZ</code>: camera forward direction (normalized X and Z)
</li> </ul> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Example: 3D pong (default script)</h3> <p data-astro-cid-tkmlznkr="">
The engine ships with a playable pong game. Here's a simplified excerpt:
</p> <pre data-astro-cid-tkmlznkr="">MODEL 0           ; create ball
MODEL 1           ; create paddle
CAM_POS 0 8 18    ; position camera
SET A 0           ; ball X position
SET B 1           ; ball velocity
SET C 0           ; paddle Z position
LOOP
  ADD A B         ; move ball
  IF_GT A 10      ; hit right wall?
    MULTIPLY B -1 ; reverse velocity
  END_IF
  IF_TRUE Up      ; up button pressed?
    ADD C -0.5    ; move paddle up
  END_IF
  POSITION 0 A 0 0     ; update ball position
  POSITION 1 -13 0 C   ; update paddle position
  SLEEP 0.016          ; ~60 FPS
END_LOOP</pre>  <p data-astro-cid-tkmlznkr="">
The full script includes collision detection, game-over logic, and beep
    sounds on miss, all done with simple register math and conditionals.
</p> <h2 data-astro-cid-tkmlznkr="">Technical details</h2> <h3 data-astro-cid-tkmlznkr="">Language &amp; toolchain</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Language</strong>: C</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Library</strong>: <a href="https://github.com/devkitPro/libnds" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">libnds</a> (Nintendo DS development library)
</li> <li data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Toolchain</strong>: <a href="https://devkitpro.org/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">devkitPro</a> (ARM cross-compiler)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Source size</strong>: ~3,100 lines of C (main.c)</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Binary size</strong>: ~100 KB (.nds ROM)</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">Performance</strong>: 60 FPS on DS Lite (2006 hardware)</li> </ul> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Capabilities &amp; limitations</h3> <ul data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">Up to <strong data-astro-cid-tkmlznkr="">128 script lines</strong> per program</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">26 variables</strong> (A-Z) + 9 read-only registers</li> <li data-astro-cid-tkmlznkr="">
Up to <strong data-astro-cid-tkmlznkr="">16 3D models</strong> (simple cubes with color/position/rotation)
</li> <li data-astro-cid-tkmlznkr=""><strong data-astro-cid-tkmlznkr="">6 save slots</strong> for different scripts</li> <li data-astro-cid-tkmlznkr="">No dynamic memory allocation, all arrays are statically sized</li> <li data-astro-cid-tkmlznkr="">No string variables, numbers only (floats)</li> <li data-astro-cid-tkmlznkr="">No function calls or subroutines (yet!)</li> </ul> <h2 data-astro-cid-tkmlznkr="">How to build &amp; run</h2> <h3 data-astro-cid-tkmlznkr="">Compilation (on your computer)</h3> <ol data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">
Install <a href="https://devkitpro.org/wiki/Getting_Started" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">devkitPro</a> (includes devkitARM and libnds)
</li> <li data-astro-cid-tkmlznkr=""> <a href="https://crl.io/ds-game-engine.zip" download="" data-astro-cid-tkmlznkr="">Download the source code</a> (main.c
      + Makefile)
</li><li data-astro-cid-tkmlznkr="">
Run <code data-astro-cid-tkmlznkr="">make</code> in the project directory
</li> <li data-astro-cid-tkmlznkr="">
Output: <code data-astro-cid-tkmlznkr="">program.nds</code> (~100 KB ROM file)
</li> </ol> <br data-astro-cid-tkmlznkr=""> <h3 data-astro-cid-tkmlznkr="">Running on real hardware</h3> <p data-astro-cid-tkmlznkr="">
You need a <strong data-astro-cid-tkmlznkr="">flashcart</strong> (e.g. R4, DSTT, Acekard) with a microSD
    card:
</p> <ol data-astro-cid-tkmlznkr=""> <li data-astro-cid-tkmlznkr="">
Copy <code data-astro-cid-tkmlznkr="">program.nds</code> to the microSD card
</li> <li data-astro-cid-tkmlznkr="">Insert the microSD into the flashcart</li> <li data-astro-cid-tkmlznkr="">Insert the flashcart into your DS</li> <li data-astro-cid-tkmlznkr="">Boot the DS and select the ROM from the flashcart menu</li> </ol> <p data-astro-cid-tkmlznkr=""> <strong data-astro-cid-tkmlznkr="">Note</strong>: I got my R4 cart + SD card from a friend years ago,
    so I don't have detailed setup instructions for the cart itself. Most modern
    flashcarts just need you to copy their firmware to the SD root, then add
    ROMs in a folder.
</p> <h2 data-astro-cid-tkmlznkr="">Try it in your browser (Nintendo DS emulator)</h2> <p data-astro-cid-tkmlznkr="">
You can test the DS game engine build directly below. The emulator loads <code data-astro-cid-tkmlznkr="">ds-game-engine.nds</code>. Loads a more basic pong game than the one in the video.
</p>   <p data-astro-cid-tkmlznkr="">
Nintendo DS emulator (<a href="https://notan127.github.io/DS-Emulator-Web/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">Desmond</a>). If the game doesn’t start, ensure JavaScript is enabled and the page has
    finished loading.
</p> <h2 data-astro-cid-tkmlznkr="">Download</h2>  <p data-astro-cid-tkmlznkr=""> <a href="https://crl.io/dist/ds-game-engine.zip" data-astro-cid-tkmlznkr="">Source (ds-game-engine.zip)</a> </p>  <p data-astro-cid-tkmlznkr=""> <a href="https://crl.io/dist/ds-game-engine.nds" data-astro-cid-tkmlznkr="">Compiled ROM (ds-game-engine.nds)</a> </p> <h2 data-astro-cid-tkmlznkr="">Discussion</h2>  <p data-astro-cid-tkmlznkr="">
Feel free to ask or discuss in
<a href="https://www.reddit.com/r/NDSHacks/comments/1qrwost/ds_code_editor_making_3d_pong/" target="_blank" rel="noreferrer" data-astro-cid-tkmlznkr="">this Reddit thread</a> </p>      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Genode OS is a tool kit for building highly secure special-purpose OS (112 pts)]]></title>
            <link>https://genode.org/about/index</link>
            <guid>46838981</guid>
            <pubDate>Sat, 31 Jan 2026 18:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://genode.org/about/index">https://genode.org/about/index</a>, See on <a href="https://news.ycombinator.com/item?id=46838981">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="portal-column-content">

 <p>
  The Genode OS Framework is a tool kit for building highly secure
  special-purpose operating systems. It scales from embedded systems with as
  little as 4 MB of memory to highly dynamic general-purpose workloads.
 </p>
 <p>
  Genode is based on a recursive system structure. Each program runs in a
  dedicated sandbox and gets granted only those access rights and resources that
  are needed for its specific purpose. Programs can create and manage
  sub-sandboxes out of their own resources, thereby forming hierarchies where
  policies can be applied at each level. The framework provides mechanisms to
  let programs communicate with each other and trade their resources, but only
  in strictly-defined manners. Thanks to this rigid regime, the attack surface
  of security-critical functions can be reduced by orders of magnitude compared
  to contemporary operating systems.
 </p>
 <p>
  The framework aligns the construction principles of L4 with Unix philosophy.
  In line with Unix philosophy, Genode is a collection of small building blocks,
  out of which sophisticated systems can be composed. But unlike Unix, those
  building blocks include not only applications but also all classical OS
  functionalities including kernels, device drivers, file systems, and protocol
  stacks.
 </p>
 
 <ul>
  <li>
   <p>
    CPU architectures: x86 (32 and 64 bit), ARM (32 and 64 bit), RISC-V
   </p>
  </li>
  <li>
   <p>
    Kernels: most members of the L4 family
    (<a href="http://hypervisor.org/">NOVA</a>,
    <a href="https://sel4.systems/">seL4</a>,
    <a href="http://os.inf.tu-dresden.de/fiasco/">Fiasco.OC</a>,
    <a href="http://okl4.org/">OKL4 v2.1</a>,
    <a href="http://www.l4ka.org/65.php">L4ka::Pistachio</a>,
    <a href="http://os.inf.tu-dresden.de/fiasco/prev/">L4/Fiasco</a>),
    Linux, and a custom kernel.
   </p>
  </li>
  <li>
   <p>
    Virtualization: VirtualBox (on NOVA), a custom virtual machine monitor
    for ARM, and a custom runtime for Unix software
   </p>
  </li>
  <li>
   <p>
    Over 100 ready-to-use
    <a href="https://genode.org/documentation/components">components</a>
   </p>
  </li>
 </ul>
 <p>
  Genode is open source and commercially supported by
  <a href="http://www.genode-labs.com/">Genode Labs</a>.
 </p>
 <div><dl>
  <dt><a href="https://genode.org/about/road-map">Road map</a></dt>
  <dd>
   <p>
    The direction where the project is currently heading
   </p>
  </dd>
  <dt><a href="https://genode.org/about/challenges">Challenges</a></dt>
  <dd>
   <p>
    A collection of project ideas, giving a glimpse on possible future directions
   </p>
  </dd>
  <dt><a href="https://genode.org/about/publications">Publications</a></dt>
  <dd>
   <p>
    Publications related to Genode
   </p>
  </dd>
  <dt><a href="https://genode.org/about/licenses">Licensing</a></dt>
  <dd>
   <p>
    Open-Source and commercial licensing
   </p>
  </dd>
  <dt><a href="https://genode.org/about/screenshots">Screenshots</a></dt>
  <dd>
   <p>
    Screenshots of Genode-based system scenarios
   </p>
  </dd>
 </dl></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US has investigated claims WhatsApp chats aren't private (169 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private</link>
            <guid>46838635</guid>
            <pubDate>Sat, 31 Jan 2026 17:25:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private">https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private</a>, See on <a href="https://news.ycombinator.com/item?id=46838635">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Mobile carriers can get your GPS location (507 pts)]]></title>
            <link>https://an.dywa.ng/carrier-gnss.html</link>
            <guid>46838597</guid>
            <pubDate>Sat, 31 Jan 2026 17:21:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://an.dywa.ng/carrier-gnss.html">https://an.dywa.ng/carrier-gnss.html</a>, See on <a href="https://news.ycombinator.com/item?id=46838597">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  

  <p>
    <time datetime="2026-01-31 00:00:00 +0000">2026-01-31</time>
  </p>
  
  <p>In iOS 26.3, Apple introduced a new privacy feature which limits “precise location” data made available to cellular networks via cell towers. The feature is only available to devices with Apple’s in-house modem introduced in 2025. The announcement<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> says</p>

<blockquote>
  <p>Cellular networks can determine your location based on which cell towers your device connects to.</p>
</blockquote>

<p>This is well-known. I have served on a jury where the prosecution obtained location data from cell towers. Since cell towers are sparse (especially before 5G), the accuracy is in the range of tens to hundreds of metres<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>.</p>

<p><strong>But this is not the whole truth</strong>, because cellular standards have built-in protocols that make your device silently send GNSS (i.e. GPS, GLONASS, Galileo, BeiDou) location to the carrier. This would have the same precision as what you see in your Map apps, in single-digit metres.</p>

<p>In 2G and 3G this is called <a href="https://projects.osmocom.org/projects/security/wiki/RRLP">Radio Resources LCS Protocol (RRLP)</a></p>

<blockquote>
  <p>So the network simply asks “tell me your GPS coordinates if you know them” and the phone will respond<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>.</p>
</blockquote>

<p>In 4G and 5G this is called <a href="https://tech-academy.amarisoft.com/LTE_LPP.html">LTE Positioning Protocol (LPP)</a></p>

<blockquote>
  <p>RRLP, RRC, and LPP are natively control-plane positioning protocols. This means that they are transported in the inner workings of cellular networks and are practically invisible to end users<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup>.</p>
</blockquote>

<p>It’s worth noting that GNSS location is never <em>meant</em> to leave your device. GNSS coordinates are calculated entirely passively, your device doesn’t need to send a single bit of information. Using GNSS is like finding out where you are by reading a road sign: you don’t have to tell anyone else you read a road sign, anyone can read a road sign, and the people who put up road signs don’t know who read which road sign when.</p>

<p>These capabilities are not secrets but somehow they have mostly slid under the radar of the public consciousness. They have been used in the wild for a long time, such as by the DEA in the US in 2006<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup>:</p>

<blockquote>
  <p>[T]he DEA agents procured a court order (but not a search warrant) to obtain GPS coordinates from the courier’s phone via a ping, or signal requesting those coordinates, sent by the phone company to the phone.</p>
</blockquote>

<p>And by Shin Bet in Israel, which tracks everyone everywhere all the time<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup>:</p>

<blockquote>
  <p>The GSS Tool was based on centralized cellular tracking operated by Israel’s General Security Services (GSS). The technology was based on a framework that tracks all the cellular phones running in Israel through the cellular companies’ data centers. According to news sources, it routinely collects information from cellular companies and identifies the location of all phones through cellular antenna triangulation and GPS data<sup id="fnref:7:1" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup>.</p>
</blockquote>

<p>Notably, the Israeli government started using the data for contact tracing in March 2020<sup id="fnref:7:2" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup><sup id="fnref:8" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup>, only a few weeks after the first Israeli COVID-19 case. An individual would be sent an SMS message informing them of close contact with a COVID patient and required to quarantine. This is good evidence that the location data Israeli carriers are collecting are far more precise than what cell towers alone can achieve.</p>

<p>A major caveat is that I don’t know if RRLP and LPP are the exact techniques, and the only techniques, used by DEA, Shin Bet, and possibly others to collect GNSS data; there could be other protocols or backdoors we’re not privy to.</p>

<p>Another unknown is whether these protocols can be exploited remotely by a foreign carrier. Saudi Arabia has abused SS7 to spy on people in the US<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">9</a></sup>, but as far as I know this only locates a device to the coverage area of a Mobile Switching Center, which is less precise than cell tower data. Nonetheless, given the abysmal culture, competency, and integrity in the telecom industry, I would not be shocked if it’s possible for a state actor to obtain the precise GNSS coordinates of anyone on earth using a phone number/IMEI.</p>

<p>Apple made a good step in iOS 26.3 to limit at least one vector of mass surveillance, enabled by having full control of the modem silicon and firmware. They must now allow users to disable GNSS location responses to mobile carriers, and notify the user when such attempts are made to their device.</p>

<hr>


</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finland to end "uncontrolled human experiment" with ban on youth social media (535 pts)]]></title>
            <link>https://yle.fi/a/74-20207494</link>
            <guid>46838417</guid>
            <pubDate>Sat, 31 Jan 2026 17:06:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://yle.fi/a/74-20207494">https://yle.fi/a/74-20207494</a>, See on <a href="https://news.ycombinator.com/item?id=46838417">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><p>Lunch break at the Finnish International School of Tampere (FISTA) is a boisterous time.</p><p>The yard is filled with children — ranging from grades 1 to 9, or ages 6 to 16 — running around, shouting, playing football, shooting basketball hoops, doing what kids do.</p><p>And there's not a single screen in sight.</p><p>FISTA has taken advantage of the <a href="https://yle.fi/a/74-20103459" role="link">law change</a>, brought in last August, which allows schools to restrict or completely ban the use of mobile phones during school hours. At FISTA, this means no phones at all unless specifically used for learning in the classroom.</p><p>"We've seen that cutting down on the possibilities for students to use their phones, during the breaks for instance, has spurred a lot of creativity," FISTA vice principal <strong>Antti Koivisto</strong> notes.</p><p>"They're more active, doing more physical things like playing games outdoors or taking part in the organised break activities or just socialising with each other."</p><p>With the smartphone restriction in schools widely considered to have been a success, Finland's government has now set its sights on social media platforms.</p><p>Prime Minister <strong>Petteri Orpo</strong> (NCP) <a href="https://yle.fi/a/74-20204220" role="link">said earlier this month</a> that he supports banning the use of social media by children under the age of 15.</p><p>"I am deeply concerned about the lack of physical activity among children and young people, and the fact that it is increasing," Orpo said at the time.</p><p>And there is a growing groundswell of support for Finland introducing such a ban. Two-thirds of respondents to a survey published earlier this week <a href="https://yle.fi/a/74-20206519" role="link">said they back a ban</a> on social media for under-15s. This is a near 10 percentage point jump compared to a similar survey carried out just last summer.</p><h2>"Uncontrolled human experiment"</h2><p>The concerns over social media, and in particular the effects on children, have been well-documented — but Finnish researcher <strong>Silja Kosola</strong>'s <a href="https://yle.fi/a/74-20205877" role="link">recent description of the phenomenon</a> as an "uncontrolled human experiment" has grabbed people's attention once again.</p><p>Kosola, an associate professor in adolescent medicine, has researched the impact of social media on young people, and tells Yle News that the consequences are not very well understood.</p><p>"We see a rise in self-harm and especially eating disorders. We see a big separation in the values of young girls and boys, which is also a big problem in society," Kosola explains.</p><p><strong>In the video below, Silja Kosola explains the detrimental effects that excessive use of social media can have on young people.</strong></p><figure><figcaption><span>Silja Kosola speaking on the All Points North podcast.</span></figcaption></figure><p>She further notes that certain aspects of Finnish culture — such as the independence and freedom granted to children from a young age — have unwittingly exacerbated the ill effects of social media use.</p><p>"We have given smartphones to younger people more than anywhere else in the world. Just a couple of years ago, about 95 percent of first graders had their own smartphone, and that hasn't happened anywhere else," she says.</p><h2>All eyes on Australia</h2><p>Since 10 December last year, children under the age of 16 in Australia have been banned from using social media platforms such as TikTok, Snapchat, Facebook, Instagram and YouTube.</p><p>Prime Minister <strong>Anthony Albanese</strong> began drafting the legislation after he received a heartfelt letter from a grieving mother who lost her 12-year-old daughter to suicide.</p><p>Although Albanese has never revealed the details of the letter, <a href="https://www.abc.net.au/news/2025-12-13/how-australia-developed-social-media-ban-under-16s/106137700" role="link">he told public broadcaster</a> ABC that it was "obvious social media had played a key role" in the young girl's death.</p><p>The legislation aims to shift the burden away from parents and children and onto the social media companies, who face fines of up to 49.5 million Australian dollars (29 million euros) if they consistently fail to keep kids off their platforms.</p><p><strong>Clare Armstrong</strong>, ABC's chief digital political correspondent, told Yle News that the initial reaction to the roll-out has been some confusion but no little "relief".</p><p>"The government often talks about this law as being a tool to help parents and other institutions enforce and start conversations about tech and social media in ways that before, they couldn't," she says.</p><p>Although it is still early days, as the ban has only been in force for about six weeks, Armstrong adds that the early indicators have been good.</p><p><strong>ABC journalist Clare Armstrong explains in the video below how children in Australia have been spending their time since the social media ban was introduced.</strong></p><figure><figcaption><span>Clare Armstrong speaking on the All Points North podcast.</span></figcaption></figure><p>However, she adds a note of caution to any countries — such as Finland — looking to emulate the Australian model, noting that communication is key.</p><p>"Because you can write a very good law, but if the public doesn't understand it, and if it can't be enforced at that household level easily, then it's bound to fail," Armstrong says.</p><h2>Playing to Finland's strengths</h2><p><strong>Seona Candy,</strong> an Australian living in Helsinki for over eight years, has been keenly following the events in her homeland since the social media ban came into effect in December.</p><p>She has heard anecdotally that if kids find themselves blocked from one platform, they just set up an account on another, "ones that maybe their parents don't even know exist".</p><p>"And this is then much, much harder, because those platforms don't have parental controls, so they don't have those things already designed into them that the more mainstream platforms do," Candy says.</p><p>Because of this issue, and others she has heard about, she warns against Finland introducing like-for-like legislation based around Australia's "reactive, knee-jerk" law change.</p><p>"I think the Finnish government should really invest in digital education, and digital literacy, and teach kids about digital safety. Finland is world-famous for education, and for media literacy. Play to your strengths, right?"</p><p><em>The All Points North podcast asked if Finland should introduce a similar ban on social media as in Australia. You can listen to the episode via this embedded player, on</em> <a href="https://areena.yle.fi/podcastit/1-4355773" role="link"><em>Yle Areena</em></a><em>,</em> <em>via</em> <a href="https://podcasts.apple.com/us/podcast/all-points-north/id1678541537" role="link"><em>Apple</em></a>, <a href="https://open.spotify.com/show/11M4NJ3cfmNCo0qYiIXXU1" role="link"><em>Spotify</em></a> <em>or wherever you get your podcasts.</em></p><figure><div><div><p><strong>Should Finland ban kids from using social media?</strong></p><div><canvas></canvas><picture><source data-testid="source-for-S" media="(max-width: 767px)" srcset="https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_104,w_104/dpr_2.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 2x,https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_104,w_104/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 1x"><source data-testid="source-for-M" media="(min-width: 768px)" srcset="https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_135,w_135/dpr_2.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 2x,https://images.cdn.yle.fi/image/upload/ar_1.0,c_fill,g_faces,h_135,w_135/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917 1x"><img alt="" src="https://images.cdn.yle.fi/image/upload/ar_1.7777777777777777,c_fill,g_faces,h_75,w_135/dpr_1.0/q_auto:eco/f_auto/fl_lossy/13-1-4355773-1756384400917"></picture></div></div></div></figure></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Film students who can no longer sit through films (110 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/</link>
            <guid>46838026</guid>
            <pubDate>Sat, 31 Jan 2026 16:26:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/">https://www.theatlantic.com/ideas/2026/01/college-students-movies-attention-span/685812/</a>, See on <a href="https://news.ycombinator.com/item?id=46838026">Hacker News</a></p>
<div id="readability-page-1" class="page"><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">Everyone knows it’s hard to get college students to do the reading—remember books? But the attention-span crisis is not limited to the written word. Professors are now finding that they can’t even get film students—<em>film </em>students—to sit through movies. “I used to think, <em>If homework is watching a movie, that is the best homework ever</em>,” Craig Erpelding, a film professor at the University of Wisconsin at Madison, told me. “But students will not do it.”</p><p data-flatplan-paragraph="true">I heard similar observations from 20 film-studies professors around the country. They told me that over the past decade, and particularly since the pandemic, students have struggled to pay attention to feature-length films. Malcolm Turvey, the founding director of Tufts University’s Film and Media Studies Program, officially bans electronics during film screenings. Enforcing the ban is another matter: About half the class ends up looking furtively at their phones.</p><p data-flatplan-paragraph="true">A handful of professors told me they hadn’t noticed any change. Some students have always found old movies to be slow, Lynn Spigel, a professor of screen cultures at Northwestern University, told me. “But the ones who are really dedicated to learning film always were into it, and they still are.”</p><p data-flatplan-paragraph="true">Most of the instructors I spoke with, however, feel that something is different now. And the problem is not limited to large introductory courses. Akira Mizuta Lippit, a cinema and media-studies professor at the University of Southern California—home to perhaps the top film program in the country—said that his students remind him of nicotine addicts going through withdrawal during screenings: The longer they go without checking their phone, the more they fidget. Eventually, they give in. He recently screened the 1974 Francis Ford Coppola classic <em>The Conversation</em>. At the outset, he told students that even if they ignored parts of the film, they needed to watch the famously essential and prophetic final scene. Even that request proved too much for some of the class. When the scene played, Lippit noticed that several students were staring at their phones, he told me. “You do have to just pay attention at the very end, and I just can’t get everybody to do that,” he said.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/magazine/archive/2024/11/the-elite-college-students-who-cant-read-books/679945/">From the November 2024 issue: The elite college students who can’t read books</a></p><p data-flatplan-paragraph="true">Many students are resisting the idea of in-person screenings altogether. Given the ease of streaming assignments from their dorm rooms, they see gathering in a campus theater as an imposition. Professors whose syllabi require in-person screenings outside of class time might see their enrollment drop, Meredith Ward, director of the Program in Film and Media Studies at Johns Hopkins University, told me. Accordingly, many professors now allow students to stream movies on their own time.</p><p data-flatplan-paragraph="true">You can imagine how that turns out. At Indiana University, where Erpelding worked until 2024, professors could track whether students watched films on the campus’s internal streaming platform. Fewer than 50 percent would even start the movies, he said, and only about 20 percent made it to the end. (Recall that these are students who chose to take a film class.) Even when students stream the entire film, it’s not clear how closely they watch it. Some are surely folding laundry or scrolling Instagram, or both, while the movie plays.</p><p data-flatplan-paragraph="true">The students I spoke with admitted to their own inattentiveness. They even felt bad about it. But that wasn’t enough to make them sit through the assigned movies. Mridula Natarajan, a freshman at the University of Texas at Austin, took a world-cinema class this past fall. “There were some movies that were extremely slow-paced, and ironically, that was the point of the movie,” she told me. “But I guess impatience made me skip through stuff or watch it on two-times speed.”</p><p data-flatplan-paragraph="true">After watching movies distractedly—if they watch them at all—students unsurprisingly can’t answer basic questions about what they saw. In a multiple-choice question on a recent final exam, Jeff Smith, a film professor at UW Madison, asked what happens at the end of the Truffaut film <em>Jules and Jim</em>. More than half of the class picked one of the wrong options, saying that characters hide from the Nazis (the film takes place during World War I) or get drunk with Ernest Hemingway (who does not appear in the movie). Smith has administered similar exams for almost two decades; he had to grade his most recent exam on a curve to keep students’ marks within a normal range.</p><p data-flatplan-paragraph="true">The professors I spoke with didn’t blame students for their shortcomings; they focused instead on how media diets have changed. From 1997 to 2014, screen time for children under age 2 doubled. And the screen in question, once a television, is now more likely to be a tablet or a smartphone. Students arriving in college today have no memory of a world before the infinite scroll. As teenagers, they spent nearly five hours a day on social media, with much of that time used for flicking from one short-form video to the next. An <a data-event-element="inline link" href="https://www.apa.org/news/podcasts/speaking-of-psychology/attention-spans">analysis</a> of people’s attention while working on a computer found that they now switch between tabs or apps every 47 seconds, down from once every two and a half minutes in 2004. “I can imagine that if your body and your psychology are not trained for the duration of a feature-length film, it will just feel excruciatingly long,” USC’s Lippit said. (He also hypothesized that, because every movie is available on demand, students feel that they can always rewatch should they miss something—even if they rarely take advantage of that option.)</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/podcasts/archive/2024/03/smartphone-anxious-generation-mental-health/677817/">Listen: The smartphone kids are not all right</a></p><p data-flatplan-paragraph="true">Kyle Stine, a film and media-studies professor at Johns Hopkins, usually begins his course with an icebreaker: <em>What’s a movie you watched recently?</em> In the past few years, some students have struggled to name any film. Kristen Warner, a performing- and media-arts professor at Cornell University, has noticed a similar trend. Some of her students arrive having seen only Disney movies. Erpelding, at UW Madison, said he tries to find a movie that everyone in his class has seen, to serve as a shared reference point they can talk about. Lately, that’s become impossible. Even students who are interested in going into filmmaking don’t necessarily love watching films. “The disconnect is that 10 years ago, people who wanted to go study film and media creation were cinephiles themselves,” Erpelding told me. “Nowadays, they’re people that consume the same thing everyone else consumes, which is social media.”</p><p data-flatplan-paragraph="true">Of course, young people haven’t given up on movies altogether. But the feature films that they do watch now tend to be engineered to cater to their attentional deficit. In a recent appearance on <em>The Joe Rogan Experience</em>, Matt Damon, the star of many movies that college students may not have seen, said that Netflix has started encouraging filmmakers to put action sequences in the first five minutes of a film to get viewers hooked. And just because young people are streaming movies, it doesn’t mean they’re paying attention. When they sit down to watch, many are browsing social media on a second screen. Netflix has accordingly advised directors to have characters <a data-event-element="inline link" href="https://au.variety.com/2026/film/news/matt-damon-netflix-movies-restate-plot-viewers-on-phones-32039/">repeat the plot</a> three or four times so that multitasking audiences can keep up with what’s happening, Damon said.</p><p data-flatplan-paragraph="true">Some professors are treating wilting attention spans as a problem to be solved, not a reality to accept. Stine, at Johns Hopkins, is piloting a course on “slow cinema”—minimalist films with almost no narrative thrust—with the goal of helping students redevelop long modes of attention. Rick Warner, the director of film studies at the University of North Carolina, deliberately selects films with slow pacing and subtle details, such as Chantal Akerman’s <em>Jeanne Dielman, 23 quai du Commerce, 1080 Bruxelles</em>, a three-hour movie that mostly follows a woman doing chores in her apartment. “I try to teach films that put their habits of viewing under strain,” Warner told me. “I’m trying to sell them on the idea that a film watched properly can actually help them retrain their perception and can teach them how to concentrate again.” Once they get used to it, students enjoy the challenge, he said.</p><p data-flatplan-paragraph="true">But other professors, perhaps concluding that resistance is futile, are adjusting to the media their students grew up on. Some show shorter films or have students watch movies over multiple sittings. Erpelding, who primarily teaches filmmaking courses, has moved from teaching traditional production methods to explaining how to maximize audience engagement. He now asks students to make three- or four-minute films, similar to the social-media edits they see online. After all, that seems to be the only type of video many young people want to watch.</p><p data-flatplan-paragraph="true">By the way, the last scene of <em>The Conversation</em> has the paranoid Gene Hackman destroying his apartment in a desperate and futile search for listening devices. He eventually gives up, and mournfully plays the saxophone amid the wreckage. It’s a brilliant scene, and worth the wait.</p></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple Platform Security (Jan 2026) [pdf] (138 pts)]]></title>
            <link>https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf</link>
            <guid>46837814</guid>
            <pubDate>Sat, 31 Jan 2026 16:04:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf">https://help.apple.com/pdf/security/en_US/apple-platform-security-guide.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=46837814">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Nvidia's 10-year effort to make the Shield TV the most updated Android device (112 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/</link>
            <guid>46837346</guid>
            <pubDate>Sat, 31 Jan 2026 15:14:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/">https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/</a>, See on <a href="https://news.ycombinator.com/item?id=46837346">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2138185">
  
  <header>
  <div>
    

    

    <p>
      “Selfishly a little bit, we built Shield for ourselves.”
    </p>

          
    
    <div>
            <p><a data-pswp-width="1920" data-pswp-height="1080" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1.jpg" target="_blank">
              <img width="1920" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1.jpg" alt="Shield TV box" loading="eager" decoding="async" fetchpriority="high" srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-1-1440x810.jpg 1440w" sizes="(max-width: 1920px) 100vw, 1920px">
            </a></p><div id="caption-2138228">
    
    <p>
      The Shield TV has that classic Nvidia aesthetic. 

              <span>
          Credit:

          
          Ryan Whitwam

                  </span>
          </p>
  </div>
          </div>

    <div>
    
    <p>
      The Shield TV has that classic Nvidia aesthetic. 

              <span>
          Credit:

          
          Ryan Whitwam

                  </span>
          </p>
  </div>
  </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>It took Android devicemakers a very long time to commit to long-term update support. Samsung and Google have only recently decided to offer <a href="https://arstechnica.com/gadgets/2023/10/the-google-pixel-8-is-official-with-7-years-of-updates/">seven years of updates</a> for their flagship Android devices, but a decade ago, you were lucky to get more than one or two updates on even the most expensive Android phones and tablets. How is it, then, that an Android-powered set-top box from 2015 is still going strong?</p>
<p>Nvidia released the first <a href="https://arstechnica.com/gadgets/2015/10/nvidia-shield-android-tv-review-a-powerful-do-it-all-box-that-lacks-content/">Shield Android TV in 2015</a>, and according to the company’s senior VP of hardware engineering, Andrew Bell, supporting these devices has been a labor of love. And the team at Nvidia still loves the Shield. Bell assures us that Nvidia has never given up, even when it looked like support for the Shield was waning, and it doesn’t plan to stop any time soon.</p>
<h2>The soul of Shield</h2>
<p>Gaming has been central to Nvidia since its start, and that focus gave rise to the Shield. “Pretty much everybody who worked at Nvidia in the early days really wanted to make a game console,” said Bell, who has worked at the company for 25 years.</p>
<p>However, Nvidia didn’t have what it needed back then. Before gaming, crypto, and AI turned it into the multi-trillion-dollar powerhouse it is today, Nvidia had a startup mentality and the budget to match. When Shield devices began percolating in the company’s labs, it was seen as an important way to gain experience with “full-stack” systems and all the complications that arise when managing them.</p>
<p>“To build a game console was pretty complicated because, of course, you have to have a GPU, which we know how to make,” Bell explained. “But in addition to that, you need a CPU, an OS, games, and you need a UI.”</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>Through acquisitions and partnerships, the pieces of Nvidia’s fabled game console slowly fell into place. The purchase of PortalPlayer in 2007 brought the CPU technology that would become the Tegra Arm chips, and the company’s surging success in GPUs gave it the partnerships it needed to get games. But the UI was still missing—that didn’t change until Google expanded Android to the TV in 2014. The company’s first Android mobile efforts were already out there in the form of the Shield Portable and Shield Tablet, but the TV-connected box is what Nvidia really wanted.</p>
<p>“Selfishly, a little bit, we built Shield for ourselves,” Bell told Ars Technica. “We actually wanted a really good TV streamer that was high-quality and high-performance, and not necessarily in the Apple ecosystem. We built some prototypes, and we got so excited about it. [CEO Jensen Huang] was like, ‘Why don’t we bring it out and sell it to people?’”</p>
<p>The first Shield box in 2015 had a heavy gaming focus, with a raft of both local and cloud-based (<a href="https://arstechnica.com/gaming/2023/01/geforce-now-ultimate-first-impressions-streaming-has-come-a-real-long-way/">GeForce Now</a>) games. The base model included only a game controller, with the remote control sold separately. According to Bell, Nvidia eventually recognized that the gaming angle wasn’t as popular as it had hoped. The 2017 and 2019 Shield refreshes were more focused on the streaming experience.</p>
<p>“Eventually, we kind of said, ‘Maybe the soul is that it’s a streamer for gamers,’” said Bell. “We understand gamers from GeForce, and we understand they care about quality and performance. A lot of these third-party devices like tablets, they’re going cheap. Set-top boxes, they’re going cheap. But we were the only company that was like, ‘Let’s go after people who really want a premium experience.’”</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="1920" data-pswp-height="1080" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3.jpg" target="_blank">
              <img width="1920" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3.jpg" alt="Shield controller" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-3-1440x810.jpg 1440w" sizes="auto, (max-width: 1920px) 100vw, 1920px">
            </a></p><div id="caption-2138231"><p>
              Nvidia used to sell Shield-branded game controllers.
                              </p><p>
                  Credit:
                                      Ryan Whitwam
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Nvidia used to sell Shield-branded game controllers.

              <span>
          Credit:

          
          Ryan Whitwam

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>


<p>And premium it is, offering audio and video support far beyond what you find in other TV boxes, even years after release. The Shield TV started at $200 in 2015, and that’s <a href="https://marketplace.nvidia.com/en-us/consumer/streaming-media-devices/">still what you’ll pay for the Pro model</a> to this day. However, Bell notes that passion was the driving force behind bringing the Shield TV to market. The team didn’t know if it would make money, and indeed, the company lost money on every unit sold during the original production run. The 2017 and 2019 refreshes were about addressing that while also emphasizing the Shield’s streaming media chops.</p>
<h2>A passion for product support</h2>
<p>Update support for Internet-connected devices is vital—whether they’re phones, tablets, set-top boxes, or something else. When updates cease, gadgets fall out of sync with platform features, leading to new bugs (which will never be fixed) and security holes that can affect safety and functionality. The support guarantee attached to a device is basically its expiration date.</p>
<p>“We were all frustrated as buyers of phones and tablets that you buy a device, you get one or two updates, and that’s it!” said Bell. “Early on when we were building Shield TV, we decided we were going to make it for a long time. Jensen and I had a discussion, and it was, ‘How long do we want to support this thing?’ And Jensen said, ‘For as long as we shall live.’”</p>
<p>In 2025, Nvidia wrapped up its tenth year of supporting the Shield platform. Even those original 2015 boxes are still being maintained with bug fixes and the occasional new feature. They’ve gone all the way from Android 5.0 to Android 11 in that time. No Android device—not a single phone, tablet, watch, or streaming box—has gotten anywhere close to this level of support.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>The best example of Nvidia’s passion for support is, believe it or not, a two-year gap in updates.</p>
<p>Across the dozens of Shield TV updates, there have been a few times when fans feared Nvidia was done with the box. Most notably, there were no public updates for the Shield TV in 2023 or 2024, but over-the-air updates resumed in 2025.</p>
<p>“On the outside, it looked like we went quiet, but it’s actually one of our bigger development efforts,” explained Bell.</p>
<p>The origins of that effort, surprisingly, stretch back years to the launch of the Nintendo Switch. The Shield runs Nvidia’s custom Tegra X1 Arm chip, <a href="https://arstechnica.com/gaming/2016/12/nintendo-switch-nvidia-tegra-x1-specs-speed/">the same processor Nintendo chose</a> to power the original Switch in 2017. Soon after release, modders <a href="https://arstechnica.com/gaming/2018/04/the-unpatchable-exploit-that-makes-every-current-nintendo-switch-hackable/">discovered a chip flaw</a> that could bypass Nintendo’s security measures, enabling homebrew (and piracy). An updated Tegra X1 chip (also used in the 2019 Shield refresh) fixed that for Nintendo, but Nvidia’s 2015 and 2017 Shield boxes ran the same exploitable version.</p>
<p>Initially, Nvidia was able to roll out periodic patches to protect against the vulnerability, but by 2023, the Shield needed something more. Around that time, owners of 2015 and 2017 Shield boxes had noticed that DRM-protected 4K content often failed to play—that was thanks to the same bug that affected the Switch years earlier.</p>
<p>With a newer, non-vulnerable product on the market, many companies might have just accepted that the older product would lose functionality, but Nvidia’s passion for Shield remained. Bell consulted Huang, whom he calls Shield customer No. 1, about the meaning of his “as long as we shall live” pledge, and the team was approved to spend whatever time was needed to fix the vulnerability on the first two generations of Shield TV.</p>
<p>According to Bell, it took about 18 months to get there, requiring the creation of an entirely new security stack. He explains that Android updates aren’t actually that much work compared to DRM security, and some of its partners weren’t that keen on re-certifying older products. The Shield team fought for it because they felt, as they had throughout the product’s run, that they’d made a promise to customers who expected the box to have certain features.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>In February 2025, Nvidia released <a href="https://support-shield.nvidia.com/android-tv-release-notes/9.2/">Shield Patch 9.2</a>, the first wide release in two years. The changelog included an unassuming line reading, “Added security enhancement for 4K DRM playback.” That was the Tegra X1 bug finally being laid to rest on the 2015 and 2017 Shield boxes.</p>

<p>The refreshed Tegra X1+ in <a href="https://arstechnica.com/gadgets/2019/10/2019-nvidia-shield-tv-gets-a-compact-new-form-factor-new-remote/">the 2019 Shield TV</a> spared it from those DRM issues, and Nvidia still hasn’t stopped working on that chip. The Tegra X1 was blazing fast in 2015, and it’s still quite capable compared to your average smart TV today. The chip has actually outlasted several of the components needed to manufacture it. For example, when the Tegra chip’s memory was phased out, the team immediately began work on qualifying a new memory supplier. To this day, Nvidia is still iterating on the Tegra X1 platform, supporting the Shield’s continued updates.</p>
<p>“If operations calls me and says they just ran out of this component, I’ve got engineers on it tonight looking for a new component,” Bell said.</p>
<h2>The future of Shield</h2>
<p>Nvidia has put its money where its mouth is by supporting all versions of the Shield for so long. But it’s been over six years since we’ve seen new hardware. Surely the Shield has to be running out of steam, right?</p>
<p>Not so, says Bell. Nvidia still manufactures the 2019 Shield because people are still buying it. In fact, the sales volume has remained basically unchanged for the past 10 years. The Shield Pro is a spendy step-top box at $200, so Nvidia has experimented with pricing and promotion with little effect. The 2019 non-Pro Shield was one such effort. The base model was originally priced at $99, but the MSRP eventually landed at $150.</p>
<p>“No matter how much we dropped the price or how much we market or don’t market it, the same number of people come out of the woodwork every week to buy Shield,” Bell explained.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<figure>
    <div>
            <p><a data-pswp-width="1920" data-pswp-height="1080" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1440x810.jpg 1440w" data-cropped="false" href="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2.jpg" target="_blank">
              <img width="1920" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2.jpg" alt="Shield controller" decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2.jpg 1920w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1024x576.jpg 1024w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1536x864.jpg 1536w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2026/01/Shield-10-yrs-2-1440x810.jpg 1440w" sizes="auto, (max-width: 1920px) 100vw, 1920px">
            </a></p><div id="caption-2138234"><p>
              Nvidia had no choice but to put that giant Netflix button on the remote.
                              </p><p>
                  Credit:
                                      Ryan Whitwam
                                  </p>
                          </div>
          </div>
          <figcaption>
        <div>
    
    <p>
      Nvidia had no choice but to put that giant Netflix button on the remote.

              <span>
          Credit:

          
          Ryan Whitwam

                  </span>
          </p>
  </div>
      </figcaption>
      </figure>

<p>That kind of consistency isn’t lost on Nvidia. Bell says the company has no plans to stop production or updates for the Shield “any time soon.” It’s also still possible that Nvidia could release new Shield TV hardware in the future. Nvidia’s Shield devices came about as a result of engineers tinkering with new concepts in a lab setting, but most of those experiments never see the light of day. For example, Bell notes that the team produced several updated versions of the Shield Tablet and Shield Portable (some of which you can find floating around on eBay) that never got a retail release, and they continue to work on Shield TV.</p>
<p>“We’re always playing in the labs, trying to discover new things,” said Bell. “We’ve played with new concepts for Shield and we’ll continue to play, and if we find something we’re super-excited about, we’ll probably make a go of it.”</p>
<p>But what would that look like? Video technology has advanced since 2019, leaving the Shield unable to take full advantage of some newer formats. First up would be support for VP9 Profile 2 hardware decoding, which enables HDR video on YouTube. Bell says a refreshed Shield would also prioritize formats like AV1 and the HDR 10+ standard, as well as support for newer Dolby Vision profiles for people with backed-up media.</p>
<p>And then there’s the enormous, easy-to-press-by-accident Netflix button on the remote. While adding new video technologies would be job one, fixing the Netflix button is No. 2 for a theoretical new Shield. According to Bell, Nvidia doesn’t receive any money from Netflix for the giant button on its remote. It’s actually there as a requirement of Netflix’s certification program, which was “very strong” in 2019. In a refresh, he thinks Nvidia could get away with a smaller “N” button. We can only hope.</p>
<p>But does Bell think he’ll get a chance to build that new Shield TV, shrunken Netflix button and all? He stopped short of predicting the future, but there’s definitely interest.</p>
<p>“We talk about it all the time—I’d love to,” he said.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/ryanwhitwam/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/AV4.jpg" alt="Photo of Ryan Whitwam"></a></p>
  </div>

  <div>
    

    <p>
      Ryan Whitwam is a senior technology reporter at Ars Technica, covering the ways Google, AI, and mobile technology continue to change the world. Over his 20-year career, he's written for Android Police, ExtremeTech, Wirecutter, NY Times, and more. He has reviewed more phones than most people will ever own. You can <a href="https://bsky.app/profile/rwhitwam.bsky.social">follow him on Bluesky</a>, where you will see photos of his dozens of mechanical keyboards.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/gadgets/2026/01/inside-nvidias-10-year-effort-to-make-the-shield-tv-the-most-updated-android-device-ever/#comments" title="151 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    151 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/information-technology/2026/01/ai-agents-now-have-their-own-reddit-style-social-network-and-its-getting-weird-fast/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/moltbook-blue-v-red-768x432.jpg" alt="Listing image for first story in Most Read: AI agents now have their own Reddit-style social network, and it's getting weird fast" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US reportedly investigate claims that Meta can read encrypted WhatsApp messages (171 pts)]]></title>
            <link>https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages</link>
            <guid>46836487</guid>
            <pubDate>Sat, 31 Jan 2026 13:27:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages">https://www.theguardian.com/technology/2026/jan/31/us-authorities-reportedly-investigate-claims-that-meta-can-read-encrypted-whatsapp-messages</a>, See on <a href="https://news.ycombinator.com/item?id=46836487">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>US authorities have reportedly investigated claims that Meta can read users’ encrypted chats on the <a href="https://www.theguardian.com/technology/whatsapp" data-link-name="in body link" data-component="auto-linked-tag">WhatsApp</a> messaging platform, which it owns.</p><p>The reports follow a lawsuit filed last week, which claimed <a href="https://www.theguardian.com/technology/meta" data-link-name="in body link" data-component="auto-linked-tag">Meta</a> “can access virtually all of WhatsApp users’ purportedly ‘private’ communications”.</p><p>Meta has denied the allegation, reported by <a href="https://www.bloomberg.com/news/articles/2026-01-29/us-has-investigated-claims-that-whatsapp-chats-aren-t-private" data-link-name="in body link">Bloomberg</a>, calling the lawsuit’s claim “categorically false and absurd”. It suggested the claim was a <a href="https://x.com/andymstone/status/2016920479362171305" data-link-name="in body link">tactic</a> to support the NSO Group, an Israeli firm that develops spyware used against activists and journalists, and which recently lost a lawsuit brought by WhatsApp.</p><p>The firm that filed last week’s lawsuit against Meta, Quinn Emanuel Urquhart &amp; Sullivan, attributes the allegation to <a href="https://www.washingtonpost.com/technology/2026/01/29/whatsapp-lawsuit-read-messages-denied/" data-link-name="in body link">unnamed</a> “courageous” whistleblowers from Australia, Brazil, India, Mexico and South Africa.</p><p>Quinn Emanuel is, in a separate case, helping to represent the NSO Group in its appeal against a <a href="https://www.davispolk.com/experience/trial-victory-meta-and-whatsapp-spyware-case" data-link-name="in body link">judgment</a> from a US federal court last year, which ordered it to pay $167m to WhatsApp for violating its terms of service in its <a href="https://www.theguardian.com/news/series/pegasus-project" data-link-name="in body link">deployment</a> of Pegasus spyware against more than 1,400 users.</p><p>“We’re pursuing sanctions against Quinn Emanuel for filing a meritless lawsuit that was designed purely to grab headlines,” said Carl Woog, a Meta spokesperson, in a statement. “This is the same firm that is trying to help NSO overturn an injunction that barred their operations for targeting journalists and government officials with spyware.”</p><p>Adam Wolfson, a partner at Quinn Emanuel said: “Our colleagues’ defence of NSO on appeal has nothing to do with the facts disclosed to us and which form the basis of the lawsuit we brought for worldwide WhatsApp users.</p><p>“We look forward to moving forward with those claims and note WhatsApp’s denials have all been carefully worded in a way that stops short of denying the central allegation in the complaint – that Meta has the ability to read WhatsApp messages, regardless of its claims about end-to-end encryption.”</p><p>Steven Murdoch, professor of security engineering at UCL, said the lawsuit was “a bit strange”. “It seems to be going mostly on whistleblowers, and we don’t know much about them or their credibility,” he said. “I would be very surprised if what they are claiming is actually true.”</p><p>If WhatsApp were, indeed, reading users’ messages, this was likely to have been discovered by staff and would end the business, he said. “It’s very hard to keep secrets inside a company. If there was something as scandalous as this going on, I think it’s very likely that it would have leaked out from someone within WhatsApp.”</p><p>The Bloomberg article cites reports and interviews from officials within the US Department of Commerce in claiming that the US has investigated whether Meta could read WhatsApp messages. However, a spokesperson for the department called these assertions “unsubstantiated”.</p><p>WhatsApp <a href="https://faq.whatsapp.com/820124435853543" data-link-name="in body link">bills itself</a> as an end-to-end encrypted platform, which means that messages can be read only by their sender and recipient, and are not decoded by a server in the middle.</p><p>This contrasts with some other messaging apps, such as Telegram, which encrypt messages between a sender and its own servers, preventing third parties from reading the messages, but allowing them – in theory – to be decoded and read by Telegram itself.</p><p>A senior executive in the technology sector told the Guardian that WhatsApp’s vaunted privacy “leaves much to be desired”, given the platform’s willingness to collect metadata on its users, such as their profile information, their contact lists, and who they speak to and when.</p><p>However, the “idea that WhatsApp can selectively and retroactively access the content of [end-to-end encrypted] individual chats is a mathematical impossibility”, he said.</p><p>Woog, of Meta, said: “We’re pursuing sanctions against Quinn Emanuel for filing a meritless lawsuit that was designed purely to grab headlines. WhatsApp’s encryption remains secure and we’ll continue to stand up against those trying to deny people’s right to private communication.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guix System First Impressions as a Nix User (161 pts)]]></title>
            <link>https://nemin.hu/guix.html</link>
            <guid>46835612</guid>
            <pubDate>Sat, 31 Jan 2026 11:22:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nemin.hu/guix.html">https://nemin.hu/guix.html</a>, See on <a href="https://news.ycombinator.com/item?id=46835612">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div role="doc-toc" id="table-of-contents">
<h2>Table of Contents</h2>
<div role="doc-toc" id="text-table-of-contents">
<ul>
<li><a href="#my-journey-to-guix-system">1. My Journey to Guix System</a></li>
<li><a href="#installer-impressions">2. Installer Impressions</a></li>
<li><a href="#i-can-t-find-my-way-land">3. I Can't Find my Way-land</a></li>
<li><a href="#sympathy-for-the-devil">4. Sympathy for the Devil</a></li>
<li><a href="#goals">5. Goals</a></li>
<li><a href="#results">6. Results</a>
<ul>
<li><a href="#the-good">6.1. The Good</a></li>
<li><a href="#the-ambiguous">6.2. The Ambiguous</a></li>
<li><a href="#the-bad">6.3. The Bad</a></li>
</ul>
</li>
<li><a href="#overall">7. Overall</a></li>
<li><a href="#notes">8. Notes</a></li>
</ul>
</div>
</div>
<div id="outline-container-my-journey-to-guix-system">
<h2 id="my-journey-to-guix-system"><span>1.</span> My Journey to Guix System</h2>
<div id="text-1">
<p>
Feel free to skip this section if you don't really care about backstories. I just figured it makes sense to recap how and why one might start having an interest in declarative distros before tackling the main topic.
</p>

<p>
I've been a Linux-only<sup><a role="doc-backlink" id="fnr.1" href="#fn.1">1</a></sup> user for about ten years now and, like many others, I too embarked on the arduous journey of distro-hopping. I started with <a href="https://www.linuxmint.com/">Mint</a> and when that felt too slow, I switched to <a href="https://ubuntu.com/">Ubuntu</a>. When Ubuntu felt too handholdy<sup><a role="doc-backlink" id="fnr.2" href="#fn.2">2</a></sup>, I switched to <a href="https://archlinux.org/">Arch</a>, which proved to be my main driver for well over five or so years. And when I couldn't resist the Siren's call, I moved on to <a href="https://gentoo.org/">Gentoo</a>, thinking surely "harder is better". Which resulted in severe burnout in a few months, so I capitulated and switched to <a href="https://fedoraproject.org/">Fedora</a>, which was very stable and honestly an all around excellent system. But once more, my interest was piqued, and (before today's adventure) I finally switched to <a href="https://nixos.org/">NixOS</a>.
</p>

<p>
I've always had a passing interest towards Nix ever since I've first heard about it, but until fairly recently, I always dismissed it as a tool for DevOps guys. The syntax was <i>weird</i>, the need for reproducible environments seemingly irrelevant, and stuff like the oft-recommended <a href="https://nixos.org/guides/nix-pills/">Nix Pills</a> seemed anything but newbie-friendly.
</p>

<p>
So then why would someone like me, who's so adamant about not needing Nix eventually choose to go all-in? I guess it was at first less about Nix being better and just the rest being worse.
</p>

<p>
Of the two big reasons for the switch, one was that I realized that having per-directory environments for your projects is actually a very handy thing to do when you like to toy around with many technologies. I used to generate my <a href="https://oddwords.hu/">other blog</a> using <a href="https://jekyllrb.com/">Jekyll</a> and, no matter which distro I used, it was always a pain in the neck to have a good Ruby environment set up. <code>bundler install</code> didn't really want to work without privileges and I wasn't really a fan of unleashing <code>sudo</code> on it, but usually that was the only way I could get things to work.
</p>

<p>
With Nix, however, it was a matter of just describing a few packages in a shell and boom, Ruby in one folder, no Ruby (and thus no mess) everywhere else. <b>I was hooked!</b> I started adding <code>shell.nix</code> files to all my little projects, hell, I started planning projects by first adding a <code>shell.nix</code> with all the dependencies I would reasonably need.
</p>

<p>
The other reason, which ultimately cemented that I need to commit, was that I was getting tired of my installed packages slowly drifting out of control. Sure, every package manager has some method of listing what's installed, but these are usually cumbersome and completely ephemeral (in the sense that any listing becomes invalid the moment you change anything).
</p>

<p>
With NixOS, the equation is flipped on its head: No longer did I query the system to tell me what's installed and what's not, it was now the system that worked based on files that I edit. The difference sounds small on paper, but for me it was an extremely liberating feeling to know that I could edit my system configuration in a versionable, explicit, and centralized way.
</p>

<p>
But NixOS isn't the only declarative distro out there. In fact GNU forked Nix fairly early and made their own spin called <a href="https://guix.gnu.org/">Guix</a>, whose big innovation is that, instead of using the unwieldy Nix-language, it uses Scheme. Specifically <a href="https://www.gnu.org/software/guile/">Guile Scheme</a>, GNU's sanctioned configuration language. I've been following Guix for a bit, but it never felt quite ready to me with stuff like KDE being only barely supported and a lot of hardware not working out of the box.
</p>

<p>
However, now that (after three years) Guix announced its <a href="https://guix.gnu.org/en/blog/2026/gnu-guix-1.5.0-released/">1.5.0 release</a> with a lot of stuff stabilized and KDE finally a first-party citizen, I figured now is the best time to give it a fresh shot. This post captures my experiences from installation to the first 3-4 days.
</p>
</div>
</div>
<div id="outline-container-installer-impressions">
<h2 id="installer-impressions"><span>2.</span> Installer Impressions</h2>
<div id="text-2">
<p>
Plug your USB in, <code>dd</code> the file onto the drive, reboot, nothing unusual. If you've ever installed a Linux system, it's more of the same.
</p>

<p>
After selecting the pendrive in my BIOS settings, the monitor began to glow in a deep, radiant blue as the Guix System logo appeared on my screen… only to suddenly switch to a menacing red: My CPU's integrated GPU is not supported by free firmware. A helpful popup gave me a gentle nudge about picking free hardware next time (buddy, have you seen the PC part prices these days?) and off I went into the installer proper.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/installer_partitions.avif" alt="installer_partitions.avif">
</p>
<p><span>Figure 1: </span>Picture of the installer graciously borrowed from the Guix installer manual.</p>
</div>

<p>
The installer itself is refreshingly barebones and I mean this in a positive way. It asks all the necessary questions and provides a nice basic configuration file, all done in a retro <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Guided-Graphical-Installation.html">Ncurses-based TUI</a>. I was really happy to see that, unlike my last attempt at using Guix System in the early 2020-s, KDE Plasma is now a first-party choice during installation. I never really vibed too much with GNOME and the other options didn't appeal either, so the choice was obvious.
</p>

<p>
Now, I'm not sure if I just picked the worst possible time or if the Guix servers were facing unusual load or whatever may have happened, but after such a breeze of a setup, the moment I pressed install, my PC became unusable for the next 2.5 <b>hours.</b> Which is unacceptable for an installation process these days in my opinion. I am lucky enough to live in a household with fiber-optic internet, that merely shrugs at bandwidth of up to a gigabyte per second and yet nearly all packages downloaded with a whopping 50 <i>kilobytes</i> per second, meaning even small-ish 5-10 megabyte packages took long minutes to download.<sup><a role="doc-backlink" id="fnr.3" href="#fn.3">3</a></sup>
</p>

<p>
A reboot later my issues only got worse.
</p>
</div>
</div>
<div id="outline-container-i-can-t-find-my-way-land">
<h2 id="i-can-t-find-my-way-land"><span>3.</span> I Can't Find my Way-land</h2>
<div id="text-3">
<p>
I was assuming I'd get SDDM after having chosen KDE Plasma, but (what a later, <a href="https://guix.gnu.org/manual/devel/en/html_node/X-Window.html#:~:text=by%20default%20the%20GNOME%20Display%20Manager%20(GDM).">closer read</a> of the manual made me realize is the expected outcome for a default config) it was GDM that loaded in. I entered my name and password, and I was greeted with the familiar Plasma 6 spinner. The first hint that something might be off was that it loaded a bit longer than usual, but I was not going to get mad at waiting 10 seconds instead of 3. After all, I did just wait magnitudes longer to get here.
</p>

<p>
With practically nothing installed beyond the very basics, I clicked on Konsole, hoping to start prodding around my config and add some of my day to day apps. To my horror, it opened in the top left corner, without a titlebar and without any borders. What's more, no matter what I did, I couldn't move it. It also didn't show up on the menu bar, despite the application launcher still being completely usable. At this point I was fairly exhausted by these antics, but I figured,
</p>

<blockquote>
<p>
Well, it's a brand new release, perhaps this just snuck in. Let's give updating a shot and see if that helps.
</p>
</blockquote>

<p>
So I issued <code>guix pull</code>… The download whizzed by with speed quite unexpected after what I experienced with the installer… Only to crash into the brick wall that's indexing. Okay, whatever, another 10-12 minutes down the drain, at least now I have newest version.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/downloads.avif" alt="downloads.avif">
</p>
<p><span>Figure 2: </span>Better than before download speeds</p>
</div>

<p>
Except I didn't. Because, unlike Nix, the <code>guix</code> executable is not an omnipresent, unique thing that anyone and everyone uses on your PC. Not only does every user have their own instance, if you don't issue a certain set of commands, you won't start using the new version, despite updating it.
</p>

<p>
To Guix's credit, the CLI does scream at you to update your environment or else you'll keep using the old version, but I still find this system very disorientating compared to Nix. I'm certain experienced Guixheads are long past being tripped up by this sort of stuff and might even struggle to remember that there was a time they had to do these special steps too, but as a new user it felt a bit rough, especially consdering this is Guix System, i.e. the system whose whole purpose is to be integrate Guix as much as it can.
</p>

<p>
Back to our issue at hand. I issued <code>sudo -s</code> and <code>guix pull</code>-ed again. Once more 10-12 minutes passed indexing. But at least I could finally call <code>guix system reconfigure /etc/config.scm</code>. Interestingly things are much faster this time around, I saw speeds up to 30-50 Mbps. Before long the system was updated to the newest commit and I rebooted with high hopes.
</p>

<p>
High hopes, that were immediately dashed when Plasma loaded in the same messed up way. At this point I started to suspect this might be an issue with the GPU driver, so I enabled the LXQT desktop environment and rebooted once more. Thankfully that one worked like a charm and I was able to boot up both Emacs (editing Scheme with GNU Nano is a pain I do not wish on anyone) and <a href="https://librewolf.net/">LibreWolf</a> (Firefox's de-Mozilla-d variant).
</p>

<p>
Not having found anything too useful in the docs, I decided to make my problem someone else's so I fired up ERC<sup><a role="doc-backlink" id="fnr.4" href="#fn.4">4</a></sup> and connected to Libera.chat's <code>#guix</code> channel. After around half an hour of wait, a user by the name of Rutherther stepped up and offered me some help. We were able to figure it out that Nouveau wasn't able to drive my GPU (an RTX 5070), so his recommendation was that I should try booting with <code>nomodeset</code>. I did, but it sadly didn't help much either.
</p>
</div>
</div>
<div id="outline-container-sympathy-for-the-devil">
<h2 id="sympathy-for-the-devil"><span>4.</span> Sympathy for the Devil</h2>
<div id="text-4">
<p>
At this point I was out of ideas. Ideas of solving this using pure-Guix System, that is. There was still one option I wanted to avoid as long as I could, but alas, it seemed like the only option, that still had a realistic chance of working.
</p>




<p>
Enter <a href="https://gitlab.com/nonguix/nonguix">Nonguix</a>, the Mr. Hyde to Guix's Dr. Jekyll, the shady guy who offers you a hit and first time's for free, the… Erm, in a nutshell, it's the repository for non-free applications and drivers packages for Guix System, basically. Interestingly enough, by Guix's own findings <a href="https://guix.gnu.org/en/blog/2025/guix-user-and-contributor-survey-2024-the-results-part-2/">about 64% of users</a> utilize the Nonguix channel, which is perhaps not "literally everyone", but it does paint a picture that there is still stuff out there that you simply cannot replace with FOSS software yet.
</p>

<div>
<p><label><span>Listing 1: </span>At the time of writing, this is all one has to do to enable Nonguix.</label></p><pre><span> 1: </span>(cons* (channel
<span> 2: </span>      (name 'nonguix)
<span> 3: </span>      (url <span>"https://gitlab.com/nonguix/nonguix"</span>)
<span> 4: </span>            (introduction
<span> 6: </span>       (make-channel-introduction
<span> 7: </span>        <span>"897c1a470da759236cc11798f4e0a5f7d4d59fbc"</span>
<span> 8: </span>        (openpgp-fingerprint
<span> 9: </span>         <span>"2A39 3FFF 68F4 EF7A 3D29  12AF 6F51 20A0 22FB B2D5"</span>))))
<span>10: </span>     %default-channels)
</pre>
</div>

<p>
Enabling the repo wasn't exactly difficult. You just paste the short excerpt from above (also found in the README) into your <code>~/.config/guix/channels.scm</code> and <code>/etc/guix/channels.scm</code> files, <code>guix pull</code>, let it index to its heart's content again, and then you have access to all that is nasty (yet occasionally useful) in the world.
</p>

<p>
I figured perhaps if <a href="https://www.fsfla.org/ikiwiki/selibre/linux-libre/">Linux-libre</a> and its free firmware couldn't deal with my GPU, then surely Linux proper with its binary blobs could. Hell, for good measure I threw in the NVIDIA transform, which is supposed to automagically translate all dependencies to use the proprietary drivers.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/nvidia_first_shot_crash.avif" alt="nvidia_first_shot_crash.avif">
</p>
<p><span>Figure 4: </span>What haste and half-reading manuals gets you…</p>
</div>

<p>
Turns out my eagerness was a mistake. Not only did the process take yet another half an hour (if not more, I stopped counting), upon reboot all I was met with was a kernel panic about the driver not being able to cope with the GPU it found and a massive spew of FSCK logs.
</p>


<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/fsck.avif" alt="fsck.avif">
</p>
<p><span>Figure 5: </span>'FSCK' was indeed very close to the first words that came to my mind at this moment.</p>
</div>

<p>
With no better ideas in mind, I took out my pendrive again and burned Nonguix's own pre-built ISO on it using my partner's PC. While it ultimately did get me a working system, this version has three unfortunate hindrances:
</p>

<ol>
<li>It was built in 2022, far before Guix's <a href="https://guix.gnu.org/blog/2025/migrating-to-codeberg/">migration to Codeberg</a>, meaning it still attempts to pull content from the unfathomably slow <a href="https://savannah.gnu.org/">GNU Savannah</a> mirror. I had to manually override my <code>channels.scm</code> to point at the Codeberg repo instead, but with no easy means of finding its "<a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Channel-Authentication.html">channel introduction</a>"<sup><a role="doc-backlink" id="fnr.5" href="#fn.5">5</a></sup>, I had to pass in <code>--disable-authentication</code> to Guix when updating my system. A bit scary, but I trust the Codeberg repo.</li>
<li>Because of its age, I got a lot of somewhat intimidating errors about hardware not being recognized and other stuff I couldn't even decipher, but ultimately the system booted to the installer without issue.</li>
<li>For some reason while the installer itself does include Nonguix stuff, it actually does not include the repo in the resulting channels files, nor the substitution server for the project. The README has a warning about this, but if you happen to miss it, you could accidentally install a non-Nonguix Guix System (say that three times fast).</li>
</ol>

<p>
None of these were particularly hard to fix, however, and soon enough I was back where I started. That is to say, in a <code>nomodeset</code> X11 session, except this time running <a href="https://i3wm.org/">i3</a>, as LXQT wasn't an available option on an installer this old. There was certainly a bit of a hacker-ish vibe to messing with code files in an environment like that, but I was honestly much more looking forward to finally having a usable desktop.
</p>

<p>
Having learned from my hastiness, this time I was smarter. I only enabled the full kernel and firmware blobs, without going anywhere near the NVIDIA transform. I issued another <code>guix system reconfigure</code> and, after having time for another tea session, my update was finally finished.
</p>

<p>
I rebooted with tentative nervousness and… Success? Huh.
</p>
</div>
</div>
<div id="outline-container-goals">
<h2 id="goals"><span>5.</span> Goals</h2>
<div id="text-5">
<p>
Obviously there is little point in throwing Guix System on my PC and declaring success. I wanted to be able to at least reproduce the kind of workflow I'm used to using NixOS. For that, I need the following:
</p>

<ul>
<li><b>A browser:</b> preferably Firefox, as I'm not a huge fan of Chrome / Chromium,</li>
<li><b>An E-mail client:</b> preferably Thunderbird,</li>
<li><b>A basic office suite:</b> preferably LibreOffice,</li>
<li><b>Dev environments:</b> for Rust, Zig, Scheme, and TypeScript (with the option for more, if possible),</li>
<li><b>Emacs:</b> I do almost all my text editing in it these days, falling back to Neovim for quick tasks,</li>
<li><b>Discord:</b> for chatting with friends,</li>
<li><b>Telegram:</b> for chatting with family,</li>
<li><b>Steam:</b> for the very rare occasions I want to game,</li>
<li><b>NVIDIA drivers:</b> I prefer to offload day-to-day usage to my CPU's integrated GPU, as it cuts my energy usage in half.</li>
</ul>

<p>
Of these it was obvious that two would be relatively hard and one "outright impossible". The two being Steam and the drivers (as both are non-free and thus not in Guix's default repos) and the "impossible" one being Discord (which not even the non-free repo has packaged). But I was ready to compromise a little bit since I am requesting stuff that's explicitly against Guix's goals.
</p>
</div>
</div>
<div id="outline-container-results">
<h2 id="results"><span>6.</span> Results</h2>
<div id="text-6">

<div>
<p><img src="https://nemin.hu/assets/imgs/2026-01-26-guix/desktop.avif" alt="desktop.avif">
</p>
<p><span>Figure 6: </span>My desktop running Wezterm packaged by me and Emacs.</p>
</div>

<p>
While there has been occasional bumps and hitches along the ride, I must say I'm very impressed with Guix System so far. Let's go through this list in order:
</p>

<ul>
<li><b>Browser:</b> So far I'm really enjoying LibreWolf. It feels a lot snappier than Firefox and I'm really baffled how much speed I was apparently missing out on.</li>
<li><b>E-mails:</b> I installed Icedove, which is basically just Thunderbird without Mozilla branding. It works as expected.</li>
<li><b>Office suite:</b> LibreOffice is available as expected. Not much to say about it. I guess it's interesting that Guix isn't following the usual <code>-stale</code> / <code>-fresh</code> packaging schema, but I don't really mind not having cutting edge versions of an office suite :)</li>
<li><b>Dev environments:</b> I've only briefly toyed with development environments so far, but to me it seems like for simple use-cases it might be even easier to use than <code>shell.nix</code> (you don't need any sort of ceremony, just a <code>manifest.scm</code> file with a <code>(specifications-&gt;manifest &lt;list of packages&gt;)</code> form inside and you have a dev env ready to go.)</li>
<li><b>Emacs:</b> Installed just fine. I had to install <code>emacs-vterm</code> to make <a href="https://github.com/akermu/emacs-libvterm">Vterm</a> work, but all that took was the very simple process of adding the library to my home configuration and then referencing it in my Emacs config as per this <a href="https://reddit.com/r/GUIX/comments/11gzhyu/how_to_compile_the_vterm_module_from_emacs_and/">Reddit post</a>.</li>
<li><b>Discord:</b> I decided to just use Discord's browser version, which works just as fine (if not better). It's trading a tiny bit of convenience in return for not having to figure out how to manually add a package for it from some random third-party source. From what I've read elsewhere Flatpak is also an option, but I prefer having just one package manager at a time.</li>
<li><b>Steam:</b> Installed shockingly easily. I have to really give props to the Nonguix team. I tested Portal 2 with the Nouveau driver, it is a little disheartening to see a 15 years old game<sup><a role="doc-backlink" id="fnr.6" href="#fn.6">6</a></sup> lag, but I understand the people's hands are tied when it comes to the free drivers. After I managed to install the proprietary drivers, I was able to play even Portal RTX, which is something I never managed to get to work using NixOS.</li>
<li><b>NVIDIA drivers:</b> This time I actually read the docs properly and it didn't take long for me to realize the initial problem that caused my previous install to be unbootable was of course found between the chair and keyboard. This time, after making sure I enabled the open drivers and kernel mode-setting, I crossed my fingers, issued a reconfigure and it works beautifully!</li>
</ul>
</div>
<div id="outline-container-the-good">
<h3 id="the-good"><span>6.1.</span> The Good</h3>
<div id="text-6-1">
<ul>
<li><p>
<b>Helpful community:</b> While I do feel like Guix's community could be much larger (see below), the one that exists is very helpful and nice from my limited experience. In all places I've looked so far (Libera's <code>#guix</code>, /r/Guix, and the guix/guix Codeberg repository) I was met with genuinely kind and helpful people.
</p>

<p>
That is not to say I haven't seen some bad eggs, especially in posts from years ago, but I don't think there is any community without those, so I'm not going to cite this as a negative.
</p></li>
<li><b>Home configuration:</b> Having <code>guix home</code> be a built-in, first class citizen, instead of a community made "extension" is excellent. Instead of needing to consult a third-party resource like Home Manager's <a href="https://nix-community.github.io/home-manager/">documentation</a> you can simply use what you already know about Guix and, if you happen to hit a wall, you can just read the <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Home-Configuration.html">official handbook</a> which is guaranteed to always stay up to date with the rest of the system.</li>
<li><b>Package availability:</b> As long as you largely use FOSS stuff (which is much easier than one might think), the amount of choice is awesome. I could basically just copy over the list of packages from my Nix config and practically everything had an equivalent.</li>
<li><p>
<b>Scheme:</b> I'm not really a seasoned Schemer, but I have dabbled in the language previously and it feels so much better to me than Nix (the language) ever did. One great benefit of this is that it's a lot easier to start digging into package definitions to figure things out for yourself.
</p>

<p>
This is "<a href="https://www.gnu.org/philosophy/free-sw.html#make-changes">Freedom 1</a>" of GNU's Four Essential Freedoms in effect. Since the code is pretty much just Scheme and the different mechanisms available are fairly well documented (see caveat below), the barrier to entry is much lower than with Nix in my opinion.<sup><a role="doc-backlink" id="fnr.7" href="#fn.7">7</a></sup>
</p>

<p>
Another nice benefit of this is that you can use Emacs' extensive Scheme support to help your configuration. Tools like <a href="https://github.com/emacsmirror/geiser">Geiser</a> can plug right into Guix and help you find package and function names and, once you're experienced enough, debug your config/packages on the fly. I personally haven't yet achieved mastery of such level yet, but having the REPL confirm if I've entered names in correctly before running the code is already a boon.
</p></li>
<li><p>
<b>Ease of hacking:</b> In the "to tinker on" sense, rather than "being insecure". With Nix, merely pulling in Nixpkgs is an effort, due to the repository being massive. My otherwise beefy machine struggled to switch between branches and make commits, which doesn't exactly inspire confidence in contributing, even though it was otherwise something I was excited to do. Meanwhile, with Guix I was able to get a fully functioning development environment in 15 minutes tops, which includes cloning the repo, authenticating all commits, generating bytecode for the entire repository, and getting Emacs set up to work nice with the codebase.
</p>

<p>
Not to mention, at the time of writing <a href="https://github.com/NixOS/nixpkgs/pull/453219">my Nixpkgs PR of guile-colorized</a> is still not accepted, despite being open since October, 2025. Which is kind of disheartening, when the package is really trivial and has a very low blast-radius. With Guix I <a href="https://codeberg.org/guix/guix/pulls/5962">got an answer</a> to an extremely noobish question on my first PR in mere hours.
</p>

<p>
On a separate, but related note, I also found it a lot easier to test my package in a "live" environment as <code>guix pull</code> supports a parameter called <code>--url</code> which you can easily point to a folder on your own PC. So once I was confident my code should work, I could just "check out" my local repository clone and build it like I was an end user. This let me make sure it really does work.
</p></li>
</ul>
</div>
</div>
<div id="outline-container-the-ambiguous">
<h3 id="the-ambiguous"><span>6.2.</span> The Ambiguous</h3>
<div id="text-6-2">
<ul>
<li><p>
<b>Search:</b> <code>guix search</code> not taking an extra parameter like <code>nix search</code> is both very convenient and a bit of a bummer.
</p>

<p>
Its absence is not a deal breaker, but I really loved how with Nix, you could search in <i>anything</i>, that has a flake. Be that Nixpkgs, a repo you downloaded, a repo that's on a git forge, etc. I remember being awestruck that I could just do <code>nix search github:mozilla/nixpkgs-mozilla</code> and search for their builds of Firefox without having to manually check out anything.
</p></li>
<li><p>
<b>The documentation:</b> Oof, this one is a bit hard to pass definite judgment on.
</p>

<p>
On one hand I love the thoroughness of it all. You can get a fairly decent idea of what Guix, what it can do for your, how to use it, and how to extend it, just by reading the manual. It is evident that the Guix team and GNU in general takes its mission to educate using free software very seriously. Stuff like the <a href="https://guix.gnu.org/cookbook/en/html_node/Packaging-Tutorial.html">Packaging tutorial</a> make it very easy for complete beginners to hack together package definitions without needing to consult any other resource.
</p>

<p>
On the other hand, it really is just a manual, not a tutorial. What I mean by this is that concepts that could belong together aren't placed near each other. A simple example would be <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Services.html">services</a> and <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/Service-Reference.html#:~:text=modify-services%20services">customizing them</a>. Assuming, you're in one of the sub-pages of Services and you suddenly realize you want to replace/modify one of the services, you are left completely clueless how that works. You have to go to a completely different chapter and find one particular function's description and then apply what you learn there. The <a href="https://guix.gnu.org/cookbook/en/guix-cookbook.html">Guix Cookbook</a> has some examples, but you have to know about the cookbook in the first place.
</p>

<p>
And before anyone misunderstands me, I'm fine with RTFM, but in my opinion one of the preconditions of mass-appeal is having "pre-chewed" solutions for common problems, that don't require perusing multiple chapters.
</p></li>
</ul>
</div>
</div>
<div id="outline-container-the-bad">
<h3 id="the-bad"><span>6.3.</span> The Bad</h3>
<div id="text-6-3">
<ul>
<li><b>Substitute server stability:</b> I imagine this is an issue that only a massive bag of money could fix, but the CI/CD servers could definitely use some more processing power. It's really annoying when you're trying to test something and you're suddenly forced to wait 10-15 minutes because the server can only spare 50-100 kbps for you.</li>
<li><p>
<b>Content out there:</b> Clearly this isn't the Guix team's fault (and it's something I'm trying to lessen with this post, even if just a tiny bit), but it's really hard to find good quality material when it comes to Guix.
</p>

<p>
I mean, sure, there is the excellent <a href="https://systemcrafters.net/craft-your-system-with-guix/">System Crafters</a> tutorial series, and the odd gems like <a href="https://dthompson.us/posts/guix-for-development.html">DThompson's dev env tutorial</a>, but as a whole you're largely left to your own to trawl through the manual, IRC logs, Reddit threads, Codeberg and the previous issue tracker, etc. It's not an impossible task, especially if you're used to doing Linux things "the hard way", but it's certainly a far cry from such one-stop shops as <a href="https://nixos-and-flakes.thiscute.world/nixos-with-flakes/introduction-to-flakes">the Nix Flakes book</a> or <a href="https://mhwombat.codeberg.page/nix-book/">Wombat's Book of Nix</a>.
</p></li>
<li><b>Guix's own build speed:</b> Nix excels in speed, so I was hoping Guix would be the same. Yet stuff like <code>guix pull</code> really bog things down. Doubly so, if you want to update not just your own <code>guix</code> instance, but also root's.</li>
<li><b>Clarity of commands:</b> The fact that all concerns are lumped together (unlike Nix's many utilities) means that to the new user the many commands such as <code>guix pull</code>, <code>guix {system, home} reconfigure</code>, <code>guix update</code> can easily feel overwhelming and unclear what's updating/changing what. With time I'm sure you obtain a sort of mental muscle memory and you never think about it again, but starting out it's definitely a confusing part.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-overall">
<h2 id="overall"><span>7.</span> Overall</h2>
<div id="text-7">
<div>
<p><label><span>Listing 2: </span>My current, fairly barebones Guix home config.</label></p><pre><span> 1: </span>(<span>define-module</span> (<span>guix-home-config</span>)
<span> 2: </span>  <span>#:use-module</span> (nongnu packages)
<span> 3: </span>  <span>#:use-module</span> (gnu packages)
<span> 4: </span>  <span>#:use-module</span> (gnu home)
<span> 5: </span>  <span>#:use-module</span> (gnu home services)
<span> 6: </span>  <span>#:use-module</span> (gnu home services shells)
<span> 7: </span>  <span>#:use-module</span> (gnu services)
<span> 8: </span>  <span>#:use-module</span> (gnu system shadow)
<span> 9: </span>  <span>#:use-module</span> (guix gexp))
<span>10: </span>
<span>11: </span>(<span>define</span> <span>%packages</span>
<span>12: </span>  (list <span>"git"</span> <span>"openssh"</span> <span>"librewolf"</span> <span>"ripgrep"</span>
<span>13: </span>        <span>"bat"</span> <span>"eza"</span> <span>"fd"</span> <span>"zoxide"</span> <span>"bc"</span> <span>"gimp"</span>
<span>14: </span>        <span>"libreoffice"</span> <span>"jujutsu"</span> <span>"starship"</span> <span>"direnv"</span>
<span>15: </span>        <span>"okular"</span> <span>"gwenview"</span> <span>"bitwarden-desktop"</span>
<span>16: </span>        <span>"icedove-wayland"</span> <span>"telegram-desktop"</span>
<span>17: </span>        <span>"emacs-vterm"</span> <span>"ispell"</span> <span>"hunspell"</span> <span>"wezterm"</span>))
<span>18: </span>
<span>19: </span>(<span>define</span> <span>%nonfree-packages</span>
<span>20: </span>  (list <span>"steam-nvidia"</span>
<span>21: </span>        <span>"mpv-nvidia"</span>))
<span>22: </span>
<span>23: </span>(<span>define</span> <span>home-config</span>
<span>24: </span>  (home-environment
<span>25: </span>   (packages (specifications-&gt;packages (append %nonfree-packages %packages)))
<span>26: </span>   (services
<span>27: </span>    (append
<span>28: </span>     (list
<span>29: </span>      (service home-bash-service-type
<span>30: </span>               (home-bash-configuration
<span>31: </span>                 (aliases '((<span>"ls"</span> . <span>"eza"</span>)))
<span>32: </span>                 (bashrc (list (local-file <span>"./bashrc.sh"</span>)))))
<span>33: </span>
<span>34: </span>      (service home-files-service-type
<span>35: </span>               `((<span>".guile"</span> ,%default-dotguile)
<span>36: </span>                 (<span>".Xdefaults"</span> ,%default-xdefaults)))
<span>37: </span>
<span>38: </span>      (service home-xdg-configuration-files-service-type
<span>39: </span>               `((<span>"gdb/gdbinit"</span> ,%default-gdbinit)
<span>40: </span>                 (<span>"nano/nanorc"</span> ,%default-nanorc))))
<span>41: </span>
<span>42: </span>     %base-home-services))))
<span>43: </span>
<span>44: </span>home-config
</pre>
</div>

<p>
In a nutshell I'm very positively surprised by Guix System. After struggling so much with it years ago, this time everything just clicked after a much shorter battle. So much so that I'm happy to make it my daily driver for the foreseeable future. Beyond the slightly slower execution speed, I'm getting a comparable experience to NixOS, with all the usual pros a declarative environment brings and without having to put up with Nixlang.
</p>

<p>
My only recurring issues so far are the occasional slow download speeds and that I have to start my kernel in <code>nomodeset</code> because otherwise the graphical environment crashes without me being able to switch to a TTY. It's a bummer, but honestly, I'm not too bothered by it so far. I'm trusting a driver update will fix it soon enough and, if not, it's not exactly difficult to <a href="https://guix.gnu.org/manual/1.5.0/en/html_node/operating_002dsystem-Reference.html#:~:text=kernel-arguments">throw in a kernel parameter</a> into your config.
</p>

<p>
I'm hoping to do a followup post about packaging in Guix, because I've been dipping my toes into it by <a href="https://codeberg.org/guix/guix/pulls/6020">trying to package</a> Wezterm and the journey there was similarly arduous as installing the system itself.
</p>

<p>
Till then, thank you for reading and see you next time!
</p>
</div>
</div>
<div id="outline-container-notes">
<h2 id="notes"><span>8.</span> Notes</h2>
<div id="text-8">
<p>
The stuff you see below are all I managed to write down mid-process. Some of these I threw it into the file from Nano, some from half-broken X11 sessions. Because of this, it's not exactly well-edited, but I hope it might provide a glimpse into my mind at the time.
</p>

<blockquote>
<ul>
<li>The installer is decently simple
<ul>
<li>I appreciate the warning about incompatible hardware</li>
</ul></li>
<li>2.5 hours at least to install (mirrors throttle connection to 50kbps)</li>
<li>KDE is simply not working out of the box (titlebars are missing)
<ul>
<li>It seems to also default to X11, when I'm looking for Wayland</li>
</ul></li>
<li>The first <code>guix pull</code> is horrendously slow</li>
<li>Wayland continues to elude me, seems to be an Nvidia issue
<ul>
<li>IRC recommends <code>nomodeset</code>, doesn't help</li>
</ul></li>
<li>Try enabling Nonguix, system no longer boots</li>
<li>Try installing using the Nonguix ISO
<ul>
<li>Lots of errors, terribly old release</li>
<li>Having to <code>guix pull</code> myself to the present day again</li>
<li>Also I'm missing the introduction, so I have to run it using <code>--disable-authentication</code>, not great, but I trust the Codeberg repo</li>
<li>At least the download speed seems to have normalized</li>
</ul></li>
<li>It isn't entirely clear when you have to use <code>sudo</code></li>
<li>Running <code>i3</code> on a shitty low-res has a certain vibe to it, but I'd prefer a system working out of the box</li>
</ul>
</blockquote>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA["Giving up upstream-ing my patches & feel free to pick them up" (146 pts)]]></title>
            <link>https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html</link>
            <guid>46835454</guid>
            <pubDate>Sat, 31 Jan 2026 10:53:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html">https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118080.html</a>, See on <a href="https://news.ycombinator.com/item?id=46835454">Hacker News</a></p>
<div id="readability-page-1" class="page">
   
    <b>xtex</b> 
    <a href="mailto:hotspot-dev%40openjdk.org?Subject=Re%3A%20Giving%20up%20upstream-ing%20my%20patches%20%26%20feel%20free%20to%20pick%20them%20up&amp;In-Reply-To=%3C4555062.ejJDZkT8p0%40xtex1%3E" title="Giving up upstream-ing my patches &amp; feel free to pick them up">xtex at envs.net
       </a><br>
    <i>Sat Jan 31 09:51:36 UTC 2026</i>
    <ul>
        <li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118077.html">RFR: 8372942: AArch64: Set JVM flags for Neoverse V3AE core [v2]
</a></li>
        <li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118081.html">Giving up upstream-ing my patches &amp; feel free to pick them up
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/date.html#118080">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/thread.html#118080">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/subject.html#118080">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/author.html#118080">[ author ]</a>
         </li>
       </ul>
    <hr>  
<!--beginarticle-->
<pre>Hi,

About one year ago, in Jan. 2025, I began my adventure of the OpenJDK 
codebase. Later I attempted to make some patches into the repository.
I checked the documentation and learned that I have to sign an Oracle 
Contributor Agreement before submitting patches to OpenJDK. At that time, I 
dreamed that it was just a pretty normal CLA, like the ones I signed for other 
projects and shall just take at most several days.

A few days later, I received an email asking me to update some information in 
the agreement. I did. After that, I have sent 5 emails to 
<a href="https://mail.openjdk.org/mailman/listinfo/hotspot-dev">opensource_ww_grp at oracle.com</a> asking if there was anything wrong (once a month 
from January to May). For each of my emails, I got a reply, saying that they 
"sincerely apologize" and "@Dalibor Topic Can you please review...", with no 
actual progress being made. Now it has been (more than) one year since I 
submitted my first OCA submission. And I have been tired of "/touch"-ing my PR 
once a month.

I wonder if there is a reason for not reviewing my OCA submission. I do live 
in Chinese Mainland but I have no contractual or subordinate or teacher-
student relationship with any entities that are restricted by the US import/
export control laws (according to OpenSanctions). If you think that I have 
such a relationship or should be rejected for any other reasons, please simply 
reject my OCA submission, instead of hanging it for months.

As I no longer have enough interest and spare time to work on OpenJDK, I 
decided to give up upstreaming those patches.
If anyone is interested in them, please feel free to pick up and submit these 
patches, most of which are small but I believe they are useful.
As OCA requires that "each contribution that you submit is and shall be an 
original work of authorship", you may rewrite my patches from scratch so it is 
an original work, and you don't need to sign my name or ping me.

I would like to give a list of the patches that I wanted to upstream but 
failed:

- Checks if "llvm-config" is broken:
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
6a8b12b1ad700d994a2803de593ca06e698ef1a9
- Extend default thread stack size for zero:
This addresses the stack overflow exception in javac when building JDK 24 with 
zero variants.
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
4534fcaafc149f649105dc9914c7cf4aaf8c802c
<a href="https://www.mail-archive.com/build-dev@openjdk.org/msg14818.html">https://www.mail-archive.com/build-dev@openjdk.org/msg14818.html</a>

Some patches that are not for the upstream OpenJDK but Loongson's fork of JDK 
and were also blocked by OCA:
<a href="https://github.com/loongson/jdk/pull/134">https://github.com/loongson/jdk/pull/134</a>
<a href="https://github.com/loongson/jdk/pull/126">https://github.com/loongson/jdk/pull/126</a>
<a href="https://github.com/loongson/jdk/pull/125">https://github.com/loongson/jdk/pull/125</a>
<a href="https://github.com/loongson/jdk/pull/135">https://github.com/loongson/jdk/pull/135</a>
<a href="https://github.com/loongson/jdk/pull/136">https://github.com/loongson/jdk/pull/136</a>
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
913dcb2b2759437876ae3a40a1b074eeb1bfe09f
<a href="https://github.com/AOSC-Tracking/jdk/commit/">https://github.com/AOSC-Tracking/jdk/commit/</a>
caba8e6de73fd9ffa078d6c257d6be8500b9d16a

Best wishes,
Bye.
-- 
Bingwu Zhang (a.k.a. xtex) @ Sat, 31 Jan 2026 08:42:31 +0000



</pre>


<!--endarticle-->
    <hr>
    <ul>
        <!--threads-->
	<li>Previous message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118077.html">RFR: 8372942: AArch64: Set JVM flags for Neoverse V3AE core [v2]
</a></li>
	<li>Next message (by thread): <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/118081.html">Giving up upstream-ing my patches &amp; feel free to pick them up
</a></li>
         <li> <b>Messages sorted by:</b> 
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/date.html#118080">[ date ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/thread.html#118080">[ thread ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/subject.html#118080">[ subject ]</a>
              <a href="https://mail.openjdk.org/pipermail/hotspot-dev/2026-January/author.html#118080">[ author ]</a>
         </li>
       </ul>

<hr>
<a href="https://mail.openjdk.org/mailman/listinfo/hotspot-dev">More information about the hotspot-dev
mailing list</a><br>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Euro firms must ditch Uncle Sam's clouds and go EU-native (724 pts)]]></title>
            <link>https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/</link>
            <guid>46835336</guid>
            <pubDate>Sat, 31 Jan 2026 10:34:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/">https://www.theregister.com/2026/01/30/euro_firms_must_ditch_us/</a>, See on <a href="https://news.ycombinator.com/item?id=46835336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> I'm an eighth-generation American, and let me tell you, I wouldn't trust my data, secrets, or services to a US company these days for love or money. Under our current government, we're simply not trustworthy.</p>
<p>In the Trump‑redux era of 2026, European enterprises are finally taking data seriously, and that means packing up from Redmond-by-Seattle and moving their most sensitive workloads home. This isn't just compliance theater; it's a straight‑up national economic security play.</p>
<div><p><img src="https://regmedia.co.uk/2021/08/25/shutterstock_penguins.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="penguins"></p><h2 title="Freedom can be very contagious if it grows on its own terms. Europe of all places should know that">Open source's new mission: Rebuild a continent's tech stack</h2>
<p><a href="https://www.theregister.com/2026/01/19/open_sources_new_mission_rebuild/"><span>READ MORE</span></a></p></div>
<p>Europe's digital sovereignty paranoia, long waved off as regulatory chatter, is now feeding directly into procurement decisions. Gartner told <em>The Reg</em> last year that IT spending in Europe is set to grow by 11 percent in 2026, <a target="_blank" href="https://www.theregister.com/2025/11/14/it_spending_europe/">hitting $1.4 trillion</a>, with a big chunk rolling into "sovereign cloud" options and on‑prem/edge architectures.</p>
<p>The kicker? Fully <a target="_blank" href="https://www.theregister.com/2025/11/13/gartner_cio_cloud_sovereignty/">61 percent of European CIOs and tech leaders</a> say they want to increase their use of local cloud providers. More than half say geopolitics will prevent them from leaning further on US‑based hyperscalers.</p>
<p>The American hypercloud vendors have figured this out. <a target="_blank" href="https://www.theregister.com/2026/01/15/aws_european_sovereign_cloud/">AWS recently made its European Sovereign Cloud available</a>. This AWS cloud, Amazon claims, is "entirely located within the EU, and physically and logically separate from other AWS Regions." On top of that, EU residents will "independently operate it" and "be backed by strong technical controls, sovereign assurances, and legal protections designed to meet the needs of European governments and enterprises for sensitive data."</p>

    

<p>Many EU-based companies aren't pleased with this Euro-washing of American hypercloud services. The Cloud Infrastructure Service Providers in Europe (CISPE) trade association accuses the EU Cloud Sovereignty Framework of being <a target="_blank" href="https://www.theregister.com/2025/10/27/cispe_eu_sovereignty_framework/">set up to favor the incumbent</a> (American) hypercloud providers.</p>

        


        

<p>They're not wrong.</p>
<p>You don't need a DEA warrant or a Justice Department subpoena to see the trend: Europe's 90‑plus‑percent dependency on US cloud infrastructure, as former European Commission advisor <a target="_blank" href="https://www.theregister.com/2025/12/22/europe_gets_serious_about_cutting/">Cristina Caffarra put it, is a single‑shock‑event security nightmare</a> waiting to rupture the EU's digital stability.</p>

        

<p>Seriously. What will you do if Washington decides to unplug you? Say Trump gets up on the wrong side of the bed and decides to invade Greenland. There goes NATO, and in all the saber-rattling leading up to the 10th Mountain Division being shipped to Nuuk, he orders American companies to cut their services to all EU countries and the UK.</p>
<ul>

<li><a href="https://www.theregister.com/2026/01/26/cursor_opinion/">When AI 'builds a browser,' check the repo before believing the hype</a></li>

<li><a href="https://www.theregister.com/2026/01/16/linus_torvalds_vibe_coding/">Just because Linus Torvalds vibe codes doesn't mean it's a good idea</a></li>

<li><a href="https://www.theregister.com/2025/12/31/long_lived_tech/">The most durable tech is boring, old, and everywhere</a></li>

<li><a href="https://www.theregister.com/2025/12/22/what_linux_desktop_really_needs/">What the Linux desktop really needs to challenge Windows</a></li>
</ul>
<p>With the way things are going, they're not going to say no. I mean, CEOs Tim Cook of Apple, Eric Yuan of Zoom, Lisa Su of AMD, and – pay attention – Amazon's Andy Jassy all went obediently to watch a feature-length White House screening of Melania, the universally-loathed, 104‑minute Amazon‑produced documentary about First Lady Melania Trump.</p>
<div><p><img src="https://regmedia.co.uk/2016/05/20/shutterstock_plane.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="Plane. Image via shutterstock"></p><h2 title="Countries that banded together to challenge Boeing in the air try to do the same to AWS, Microsoft, and Google on the ground">Europe's cloud challenge: Building an Airbus for the digital age</h2>
<p><a href="https://www.theregister.com/2025/12/29/europes_cloud_challenge_building_an/"><span>READ MORE</span></a></p></div>
<p>Sure, that's a silly example, but for American companies to do business today, they're kowtowing to Trump. Or, take a far more serious example, when Minnesota company CEOs called for "de-escalation" in the state, there was not one word about ICE or the government's role in the bloodshed. It was the corporate equivalent of the mealy-mouthed "thoughts and prayers" American right-wingers always say after a US school shooting.</p>
<p>Some companies have already figured out which way the wind is blowing. Airbus, the European aerospace titan, has put out a €50 million, decade‑long tender to migrate its <a target="_blank" href="https://www.theregister.com/2025/12/19/airbus_sovereign_cloud/">mission‑critical applications to a "sovereign European cloud."</a> Airbus wants its whole stack – data at rest, data in transit, logging, IAM, and security‑monitoring infrastructure – all rooted in EU law and overseen by EU operators. As Catherine Jestin, Airbus's executive vice president of digital, told <em>The Register</em>: "We want to ensure this information remains under European control."</p>
<p>Who can blame them? Thanks to the American CLOUD Act and related US surveillance statutes, US‑headquartered providers must hand over European data regardless of where the bytes sit. Exhibit A is that <a target="_blank" href="https://www.theregister.com/2025/07/25/microsoft_admits_it_cannot_guarantee/">Microsoft has already conceded that it cannot guarantee data independence from US law enforcement</a>. Airbus is betting that "data residency on paper" from AWS‑styled "EU sections" is not enough. Real sovereignty demands EU‑owned and run operations with full contractual and legal firewalls. Sure, your data may live in Frankfurt, but your fate still rests in Seattle, Redmond, or Mountain View if an American company owns your cloud provider.</p>
<p>Besides, do you really want some Trump apparatchik getting their hands on your data? I mean, this is a government where Madhu Gottumukkala, the acting director of the US Cybersecurity and Infrastructure Security Agency, <a target="_blank" rel="nofollow" href="https://www.politico.com/news/2026/01/27/cisa-madhu-gottumukkala-chatgpt-00749361">uploaded sensitive data into ChatGPT</a>!</p>
<div><p><img src="https://regmedia.co.uk/2019/04/26/plug_shutterstock.jpg?x=174&amp;amp;y=115&amp;amp;crop=1" width="174" height="115" alt="plug"></p><h2 title="Campaigners say Britain's dependence on Big Tech leaves critical systems exposed to political pressure">UK urged to unplug from US tech giants as digital sovereignty fears grow</h2>
<p><a href="https://www.theregister.com/2026/01/06/uk_urged_to_unplug_from/"><span>READ MORE</span></a></p></div>
<p>In response, Brussels is pushing an <a target="_blank" href="https://www.theregister.com/2025/12/29/europes_cloud_challenge_building_an/">open source‑led exit from hyperscaler lock‑in</a>. Ministries are standardizing on Nextcloud‑style collaboration stacks instead of Microsoft 365 to fund Euro‑native clouds via the European Cloud Alliance. Some countries, like France, are already <a target="_blank" href="https://www.theregister.com/2026/01/27/france_videoconferencing_visio/?td=rt-3a">shoving Zoom, Teams, and other US videoconferencing platforms out the door</a> in favor of a local service.</p>
<p>If you're running an EU‑based firm in 2026, the takeaway isn't that AWS‑in‑Frankfurt is evil; it's that for certain workloads, especially national security, industrial IP, or high‑profile consumer data franchises, EU‑native cloud and services are no longer a nice‑to‑have but a business continuity plan requirement.</p>

        

<p>It's time to get serious about digital sovereignty. The clock is ticking, and there's no telling when Trump will go off. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Automatic Programming (205 pts)]]></title>
            <link>https://antirez.com/news/159</link>
            <guid>46835208</guid>
            <pubDate>Sat, 31 Jan 2026 10:11:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/159">https://antirez.com/news/159</a>, See on <a href="https://news.ycombinator.com/item?id=46835208">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<section id="newslist"><article data-news-id="159"><h2><a href="https://antirez.com/news/159">Automatic programming</a></h2></article></section><topcomment><article data-comment-id="159-" id="159-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 3 hours ago. 17855 views.  </span><pre>In my YouTube channel, for some time now I started to refer to the process of writing software using AI assistance (soon to become just "the process of writing software", I believe) with the term "Automatic Programming".

In case you didn't notice, automatic programming produces vastly different results with the same LLMs depending on the human that is guiding the process with their intuition, design, continuous steering and idea of software.

Please, stop saying "Claude vibe coded this software for me". Vibe coding is the process of generating software using AI without being part of the process at all. You describe what you want in very general terms, and the LLM will produce whatever happens to be the first idea/design/code it would spontaneously, given the training, the specific sampling that happened to dominate in that run, and so forth. The vibe coder will, at most, report things not working or not in line with what they expected.

When the process is actual software production where you know what is going on, remember: it is the software *you* are producing. Moreover remember that the pre-training data, while not the only part where the LLM learns (RL has its big weight) was produced by humans, so we are not appropriating something else. We can pretend AI generated code is "ours", we have the right to do so. Pre-training is, actually, our collective gift that allows many individuals to do things they could otherwise never do, like if we are now linked in a collective mind, in a certain way.

That said, if vibe coding is the process of producing software without much understanding of what is going on (which has a place, and democratizes software production, so it is totally ok with me), automatic programming is the process of producing software that attempts to be high quality and strictly following the producer's vision of the software (this vision is multi-level: can go from how to do, exactly, certain things, at a higher level, to stepping in and tell the AI how to write a certain function), with the help of AI assistance. Also a fundamental part of the process is, of course, *what* to do.

I'm a programmer, and I use automatic programming. The code I generate in this way is mine. My code, my output, my production. I, and you, can be proud.

If you are not completely convinced, think to Redis. In Redis there is not much technical novelty, especially at its start it was just a sum of basic data structures and networking code that every competent system programmer could write. So, why it became a very useful piece of software? Because of the ideas and visions it contained.

Programming is now automatic, vision is not (yet).</pre></article></topcomment>


<p><a href="https://disqus.com/">blog comments powered by <span>Disqus</span></a>

</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CERN accepts $1B in private cash towards Future Circular Collider (138 pts)]]></title>
            <link>https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/</link>
            <guid>46835124</guid>
            <pubDate>Sat, 31 Jan 2026 09:58:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/">https://physicsworld.com/a/cern-accepts-1bn-in-private-cash-towards-future-circular-collider/</a>, See on <a href="https://news.ycombinator.com/item?id=46835124">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-126061">
		<div>

				<!-- Issue information -->
				
				<!-- Standfirst -->
										<p>Mark Thomson takes the reins at the CERN particle-physics lab, which recently received $1bn in private donations for its next collider project, as <strong>Michael Banks </strong>reports</p>
				
				<!-- Thumbnail -->
												<figure>
										<a href="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg" data-fancybox="" data-src="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg" data-caption="igger and better: The Large Hadron Collider at CERN will shut down later this year to make way for a major upgrade – the High-Luminosity LHC (courtesy: CERN)
">
												<img src="https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026-635x423.jpg" srcset="
															https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026.jpg 1440w,
															https://physicsworld.com/wp-content/uploads/2026/01/cern-19-01-2026-635x423.jpg 635w" sizes="(max-width: 768px) 100vw, 635w" alt="The Large Hadron Collider" title="cern-19-01-2026" width="635" height="423">
										</a>
																						
																				<figcaption>Bigger and better: The Large Hadron Collider at CERN will shut down later this year to make way for a major upgrade – the High-Luminosity LHC (courtesy: CERN)
</figcaption>
								</figure>
								<p>The CERN particle-physics lab near Geneva <a href="https://home.cern/news/press-release/cern/private-donors-pledge-860-million-euros-cerns-future-circular-collider">has received $1bn</a> from private donors towards the construction of the <a href="https://home.cern/science/accelerators/future-circular-collider">Future Circular Collider</a> (FCC). The cash marks the first time in the lab’s 72-year history that individuals and philanthropic foundations have agreed to support a major CERN project. If built, the FCC would be the successor to the Large Hadron Collider (LHC), where the Higgs boson was discovered.</p>
<p>CERN originally released&nbsp;<a href="https://physicsworld.com/a/europe-unveils-successor-to-the-large-hadron-collider/">a four-volume conceptual design report</a>&nbsp;for the FCC in early 2019, with more detail included in a <a href="https://cds.cern.ch/record/2928193">three-volume feasibility study</a> that came out last year. It calls for a giant tunnel some 90.7 km in circumference – roughly three times as long as the LHC&nbsp; – that would be built about 200&nbsp;m underground on average.</p>
<p>The FCC has been recommended as the preferred option for the next flagship collider at CERN in the <a href="https://url.uk.m.mimecastprotect.com/s/xtPXC0Rv8tvN53FRhwF9G-Hn?domain=u7061146.ct.sendgrid.net">ongoing process to update the European Strategy for Particle Physics</a>, which will be passed over to the &nbsp;CERN Council in May 2026.If the plans are given the green light by CERN Council in 2028, construction on the FCC electron-positron machine, dubbed FCC-ee, would begin in 2030. It would start operations in 2047, a few years after the High Luminosity LHC (HL-LHC) closes down, and run for about 15 years until the early 2060s.</p>
<p>The FCC-ee would focus on creating a million Higgs particles in total to allow physicists to study its properties with an accuracy an order of magnitude better that possible with the LHC. The FCC feasibility study then calls for a hadron machine, dubbed FCC-hh, to replace the FCC-ee in the existing 91 km tunnel. It would be a “discovery machine”, smashing together protons at high energy – about 85 TeV – with the aim of creating new particles. If built, the FCC-hh will begin operation in 2073 and run to the end of the century.</p>
<p>The funding model for the FCC-ee, which is expected to have a price tag of about $18bn, is still a work in progress. But it is estimated that at least two-thirds of the construction costs will come from CERN’s 24 member states with the rest needing to be found elsewhere. One option to plug that gap is private donations and in late December CERN received a significant boost from several organizations including the Breakthrough Prize Foundation, the Eric and Wendy Schmidt Fund for Strategic Innovation, and the entrepreneurs John Elkann and Xavier Niel. Together, they pledged a total of $1bn towards the FCC-ee.</p>
<p>Costas Fountas, president of the CERN Council, says CERN is “extremely grateful” for the interest. “This once again demonstrates CERN’s relevance and positive impact on society, and the strong interest in CERN’s future that exists well beyond our own particle physics community,” he notes.</p>
<p>Eric Schmidt, who founded Google, claims that he and Wendy Schmidt were “inspired by the ambition&nbsp;of this project and by what it could mean for the future of humanity”. The FCC, he believes, is an instrument that “could push the boundaries of human knowledge and deepen our understanding of the fundamental laws of the Universe” and could lead to technologies that could benefit society “in profound ways” from medicine to computing to sustainable energy.</p>
<p>The cash promised has been welcomed by outgoing CERN director-general Fabiola Gianotti. “It’s the first time in history that private donors wish to partner with CERN to build an extraordinary research instrument that will allow humanity to take major steps forward in our understanding of fundamental physics and the universe,” she said. “I am profoundly grateful to them for their generosity, vision, and unwavering commitment to knowledge and exploration.”</p>
<h3>Further boost</h3>
<p>The cash comes a few months after the Circular Electron–Positron Collider (CEPC) – a rival collider to the FCC-ee that also involves building a huge 100 km tunnel to study the Higgs in unprecedented detail – was not considered for inclusion in China’s next five-year plan, which runs from 2026 to 2030. There has been much discussion in China about whether the CEPC is the right project for the country, with the collider facing criticism from particle physicist and Nobel laureate Chen-Ning Yang, before he died last year.</p>
<p>Wang Yifang of the Institute of High Energy Physics (IHEP) in Beijing says they will submit the CEPC for consideration again in 2030 unless FCC is officially approved before then. But for particle theorist John Ellis from Kings College London, China’s decision to effectively put the CEPC on the back burner &nbsp;“certainly simplifies the FCC discussion”. “However, an opportunity for growing the world particle physics community has been lost, or at least deferred [by the decision],” Ellis told <em>Physics World</em>.</p>
<p>Ellis adds, however, that he would welcome China’s participation in the FCC. “Their accelerator and detector [technical design reviews] show that they could bring a lot to the table, if the political obstacles can be overcome,” he says. </p><article>
			<a href="https://physicsworld.com/a/cern-releases-plans-for-the-most-extraordinary-instrument-ever-built/">
				<div>
					<p>Read more</p>
					<p><img decoding="async" width="129" height="90" src="https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-129x90.jpg" alt="Outline of the FCC near Geneva" srcset="https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-129x90.jpg 129w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-211x148.jpg 211w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-317x222.jpg 317w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-768x538.jpg 768w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-571x400.jpg 571w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-589x412.jpg 589w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-586x410.jpg 586w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-635x445.jpg 635w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-281x197.jpg 281w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-257x180.jpg 257w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-300x210.jpg 300w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN-128x90.jpg 128w, https://physicsworld.com/wp-content/uploads/2025/04/FCC-map-05-00000-CERN.jpg 1000w" sizes="(max-width: 129px) 100vw, 129px">
				</p></div>
				<h4><p>CERN releases plans for the ‘most extraordinary instrument ever built’</p>
</h4>
			</a>
		</article>
<p>However, if the FCC-ee goes ahead China could perhaps make significant “in-kind” contributions rather like those that occur with the ITER experimental fusion reactor, which is currently being built in France. In this case, instead of cash payments, the countries provide components, equipment and other materials.</p>
<p>Those considerations and more will now fall to the British physicist Mark Thomson, who took over from Gianotti as CERN director-general on 1 January for a five-year term. As well as working on funding requirements for the FCC-ee, top of his in-tray will actually be shutting down the LHC in June to make way for further work on the HL-LHC, which involves installing powerful new superconducting magnets and improving the detection.</p>
<p>About 90% of the 27 km LHC accelerator will be affected by the upgrade with a major part being to replace the magnets in the final focus systems of the two large experiments, ATLAS and CMS. These magnets will take the incoming beams and then focus them down to less than 10 µm in cross section. The upgrade includes the installation of brand new state-of-the-art niobium-tin (Nb<sub>3</sub>Sn) superconducting focusing magnets.</p>
<p>The HL-LHC will probably not turn on until 2030, at which time Thomson’s term will nearly be over, but that doesn’t deter him from leading the world’s foremost particle-physics lab. “It’s an incredibly exciting project,” Thomson <a href="https://www.theguardian.com/science/2025/dec/31/large-hadron-collider-head-of-cern-mark-thomson">told the <em>Guardian</em></a>. “It’s more interesting than just sitting here with the machine hammering away.”</p>




				

		</div><!-- .entry-content -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We have ipinfo at home or how to geolocate IPs in your CLI using latency (211 pts)]]></title>
            <link>https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/</link>
            <guid>46834953</guid>
            <pubDate>Sat, 31 Jan 2026 09:30:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/">https://blog.globalping.io/we-have-ipinfo-at-home-or-how-to-geolocate-ips-in-your-cli-using-latency/</a>, See on <a href="https://news.ycombinator.com/item?id=46834953">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
				<blockquote>
<p>TLDR: I made a CLI tool that can resolve an IP address to a country, US state and even a city. <a href="https://github.com/jimaek/geolocation-tool?ref=blog.globalping.io">https://github.com/jimaek/geolocation-tool</a><br>
It works well and confirms ipinfo's findings.</p>
</blockquote>
<p>Recently, I read how <a href="https://ipinfo.io/blog/vpn-location-mismatch-report?ref=blog.globalping.io">ipinfo finally proved</a> what most technical people assumed: VPN providers don't actually maintain a crazy amount of infrastructure in hundreds of countries. They simply fake the IP geolocation by intentionally providing wrong location data to ARIN, RIPE, and Geo DB providers via geofeeds.</p>
<p>They achieved their results using a novel approach compared to other geo IP providers. Based on their blog and HackerNews comments, they built a large probe network and used it to trace and ping every (or most) IP addresses on the internet.</p>
<p>This latency and hop data, most likely along with advanced algorithms and data cross-reference, provides a reliable way of correctly detecting the physical geolocation of an IP address, without relying on faked data available in public sources.</p>
<p>This is a very interesting approach that makes total sense, and I'm sure their clients appreciate it and heavily rely on it.</p>
<p>While I can't ping every single IP address on the internet from hundreds of locations just yet, I can do it to a limited subset using Globalping. So I decided to try it out and see if I can replicate their results and build a small tool to allow anyone to do the same.</p>
<p>Globalping is an open-source, community-powered project that allows users to self-host container-based probes. These probes then become part of our <a href="https://globalping.io/network?ref=blog.globalping.io">public network</a>, which allows anyone to use them to run network testing tools such as ping and traceroute.</p>
<p><img src="https://blog.globalping.io/content/images/2025/12/network-map-globalping.png" alt="network-map-globalping.png" loading="lazy"></p>
<p>At the moment, the network has more than 3000 probes, which in theory should be plenty to geolocate almost any IP address down to a country and even a US state level.</p>
<p>To automate and simplify this process, I made a little CLI tool using the <a href="https://github.com/jsdelivr/globalping-typescript?ref=blog.globalping.io">globalping-ts</a> library. My original idea was simple:</p>
<ol>
<li>Accept a single IP as input</li>
<li>Ping it a few times per continent to select the continent</li>
<li>Then ping the IP from many different probes on that continent</li>
<li>Group and sort the results; the country with the lowest latency should be the correct one</li>
<li>And as a bonus, repeat the same process for USA states if the winning country was the US</li>
</ol>
<p>Essentially, what I had to do was simply create a few measurements and pass the location I needed using Globalping’s magic field, which would automatically figure out what I was looking for and select a few pseudo-random probes that fit the location and limit.</p>
<p>Now initially, I used <code>ping</code> with 2 packets to run all measurements as quickly as possible, but I quickly realized it wasn’t a good idea as most networks block ICMP traffic. Next, I tried switching to TCP-based <code>ping</code>, which required trying a few popular ports to get it to work. I quickly realized this was too complicated and unreliable and switched to <code>traceroute</code>.</p>
<p>It worked perfectly. Even though <code>traceroute</code> uses ICMP by default, it did not matter to me if the target IP’s network allowed ICMP or not, I simply analyzed the latency of the last available hop. Even if you block ICMP, your upstream most likely allows it, and in most cases, it’s located in the same country.</p>
<p>Of course, this means the resulting data is not 100% perfect. A better approach would be to analyze each IP using different methods, including TCP and UDP-based <code>traceroute</code> on different ports, and expand to the last few hops instead of just one. Maybe even try to figure out the location of the registered ASNs and use a weights system in combination with public whois info in order to “vote” for the right location based on different inputs. Probably even mark low certainty IPs to be retested with a double amount of probes. (end of rant)</p>
<p>But that’s something for a commercial provider to figure out, which it seems they did.</p>
<p>For continent detection, I decided to use just 5 probes per continent; the results were extremely accurate. Although for IPs just on the "border" of continents it might be ineffective, a higher amount of probes would generate better results. For this use case, it was good enough.</p>
<p>My home IP in central Europe was too easy to detect:</p>
<pre><code>Phase 1: Detecting continent...
  North America: 137.18 ms
  Europe: 32.39 ms
  Asia: 174.54 ms
  South America: 215.08 ms
  Oceania: 244.15 ms
  Africa: 156.83 ms
</code></pre>
<p>In phase 2, all we need to do is run a single measurement with the winning continent as the location and a higher limit. Initially, I started with 250 probes with great accuracy.</p>
<p>Eventually, I decided to drop down to 50 as the default. Based on my tests, the results continued to look really good, and it would allow the tool to be run even without authentication, as the Globalping API allows 250 tests per hour per IP and 50 probes per measurement.</p>
<p>Although I recommend registering for a free account at <a href="https://dash.globalping.io/?ref=blog.globalping.io">https://dash.globalping.io/</a> and authenticating with a token to get up to 500 tests per hour and run more tests.</p>
<blockquote>
<p>Note: If you need more tests than that, you can either host a probe to generate passive credits to be used as tests, or donate via GitHub Sponsors. We will automatically detect it and credit your account.</p>
</blockquote>
<pre><code>Phase 2: Detecting country...
  Measuring from 50 probes...

  [████████████████████████████████████████] 100.0%   50/50 - Best: PL (7.29 ms)                    

Top 3 Locations:
─────────────────────────────────────────────────
  1.. Poland, EU                               7.29 ms
  2.. Germany, EU                              13.42 ms
  3.. Lithuania, EU                            17.65 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Poland, EU
  Minimum Latency: 7.29 ms
  Confidence: Medium
</code></pre>
<p>Great, now we have a basic IP-to-country resolver that only takes a few seconds to provide a response, and I didn’t even have to understand or write any complicated math. Although I’m sure someone smarter could use a formula to geolocate IPs with even fewer probes and higher accuracy.</p>
<p>For phase 3, we want to resolve the US to a specific state or territory, just like ipinfo did, and luckily they even provided a few sample IPs and locations to benchmark against during testing.</p>
<p>Again, this was as simple as creating a new measurement with the USA as the location. I used 50 probes as the default limit and tested the NordVPN IP advertised as Bahamas but resolved to Miami by ipinfo.</p>
<pre><code>Phase 3: Detecting US state...
  Measuring from 50 probes...

  [████████████████████████████████████████] 100.0%   50/50 - Best: FL (0.45 ms)                    

Top 3 Locations:
─────────────────────────────────────────────────
  1. Florida, USA                             0.45 ms
  2. South Carolina, USA                      12.23 ms
  3. Georgia, USA                             15.01 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Florida, United States
  Minimum Latency: 0.45 ms
  Confidence: Very High
═══════════════════════════════════════════════════
</code></pre>
<p>The tool agrees, Florida is the correct location. But how accurate can this system be? Can we expand it to show the city too?</p>
<p>Let's make a new phase, which again, will simply set the resulting country or state as the location and extract the city of the probe with the lowest latency. Here, since there are too many possible cities and towns per state and country, I expect the accuracy to be low and only point to the closest major hub. But in theory, this should be more than enough for use cases like routing or performance debugging.</p>
<p>And here we go, the same result ipinfo got</p>
<pre><code>Phase 4: Detecting city...
  Measuring from 36 probes...

  [████████████████████████████████████████] 100.0%   36/36 - Best: Miami (0.00 ms)                 

Top 3 Locations:
─────────────────────────────────────────────────
  1. Miami, Florida, USA                      0.00 ms
  2. West Palm Beach, Florida, USA            4.36 ms
  3. Tampa, Florida, USA                      5.85 ms

═══════════════════════════════════════════════════
                      SUMMARY
═══════════════════════════════════════════════════
  Location: Miami, Florida, United States
  Minimum Latency: 0.00 ms
  Confidence: Very High
═══════════════════════════════════════════════════
</code></pre>
<p>The current results are good but could be better. The main problem is with how the magic field works: when setting, for example, 'Europe' as the location, it tries to spread the tests across all European probes but does not guarantee that every single country is going to be included.</p>
<p>This results in inconsistencies where a probe in the same country as the target IP was not selected, and so the tool assumes the IP is located in a different neighbouring country.</p>
<p>To fix this and make the results more consistent, you would need to change the selection logic and manually set every country per continent and US state. By passing the full list of countries/states to the Globalping API, you ensure that at least one probe in that location is going to be selected. Additionally, you fully control the number of probes per location, which is very important to control the accuracy.</p>
<p>For example, North America technically contains 43 countries and territories. This means you can't just set a limit of one probe per country, it is not enough to properly understand the latency to the target IP from the disproportionately larger USA. A better limit would be around 200 probes for the USA, 20 for Canada, and 10 for Mexico.</p>
<p>But the goal of this tool was to use a minimum amount of probes to allow unauthenticated users to test it out. The current approach works great, it is simple to implement and it is very easy to control the accuracy by simply setting a higher limit of probes.</p>
<p>Overall, latency-based geolocation detection seems to be a great way to verify the location of any IP as long as you have enough vantage points. It will most likely fall apart in regions with minimal or no coverage.</p>
<p>The tool itself is open source and you can run it like this:</p>
<p><code>geolocate $IP</code></p>
<p>You can also use the –limit parameter to use more probes per phase. But be careful as it applies the set value to all phases and this will very quickly eat through your limit. Check the full docs in GitHub.</p>
<p>Pull requests with improvements are welcome!</p>
<p>Feel free to email me if you need some free credits to play around with <a href="mailto:d@globalping.io">d@globalping.io</a></p>
<p>And of course consider hosting a probe, it’s as simple as running a container <a href="https://github.com/jsdelivr/globalping-probe?ref=blog.globalping.io">https://github.com/jsdelivr/globalping-probe</a></p>

			</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[YouTube blocks background video playback on Brave and other Browsers (184 pts)]]></title>
            <link>https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/</link>
            <guid>46834441</guid>
            <pubDate>Sat, 31 Jan 2026 07:54:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/">https://piunikaweb.com/2026/01/28/youtube-background-play-samsung-internet-brave/</a>, See on <a href="https://news.ycombinator.com/item?id=46834441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              <p><strong>Update 30/01/26 – 12:50 pm (IST)</strong>: In a statement to the folks over at <a href="https://www.androidauthority.com/youtube-background-play-broken-3636179/" target="_blank" rel="noopener">Android Authority</a>, Google confirmed that they’ve tweaked the platform experience to prevent non-Premium users from accessing background playback when using browsers.</p>
<blockquote><p>Background playback is a feature intended to be exclusive for YouTube Premium members. While some non-Premium users may have previously been able to access this through mobile web browsers in certain scenarios, we have updated the experience to ensure consistency across all our platforms.</p></blockquote>
<hr>
<p><em><strong>Original article published on January 28, 2026, follows:</strong></em></p>
<p>It looks like YouTube has thrown a wrench into the works for a lot of mobile users who enjoy listening to videos with their screen off. Over the past few days, reports have been flooding in that the handy background video playback feature has suddenly stopped working on Samsung Internet.</p>
<p>Judging by the reports, it seems that the problem seems to have cropped up around a week ago and has since been impacting more users. While a majority of <a href="https://us.community.samsung.com/t5/Galaxy-S25/Background-Play-on-Samsung-Browser-stop-working/m-p/3467684#M50167" target="_blank" rel="nofollow ugc noopener">reports</a> are coming from Samsung Internet users, it’s not the only browser impacted. Users on <a href="https://us.community.samsung.com/t5/Samsung-Apps-and-Services/Background-Video-Play-Issue/td-p/3464259" target="_blank" rel="nofollow ugc noopener">Brave</a>, <a href="https://www.reddit.com/r/oneui/comments/1qni74a/background_audio_play_not_working_on_one_ui_8/" target="_blank" rel="nofollow ugc noopener">Vivaldi</a>, and even <a href="https://www.reddit.com/r/MicrosoftEdge/comments/1qmhv2n/background_playback_not_working/" target="_blank" rel="nofollow ugc noopener">Microsoft Edge</a> have complained about the issue.</p>
<p>What’s happening is pretty specific. When users try to minimize the browser or turn off their screen, the audio cuts out. On Samsung devices, some users <a href="https://www.reddit.com/r/oneui/comments/1qo2rp0/background_play_issue/" target="_blank" rel="nofollow ugc noopener">noticed</a> a fleeting notification that said “MediaOngoingActivity” right before the media controls vanished entirely.</p>
<p><a href="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp"><img fetchpriority="high" decoding="async" src="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp" alt="samsung-internet-youtube-background-play-not-working-complaint" width="600" height="339" srcset="https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint.webp 600w, https://piunikaweb.com/wp-content/uploads/2026/01/samsung-internet-youtube-background-play-not-working-complaint-300x170.webp 300w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>For years, people have relied on these mobile browser workarounds to get a free taste of what YouTube Premium offers: ad-free viewing and, crucially, background audio. This sudden, simultaneous failure across multiple browsers strongly suggests a targeted change by YouTube.</p>
<p>Samsung’s community forums and subs like r/oneui and r/youtube are becoming hubs to discuss the problem. Users have confirmed that basic troubleshooting tips, like ensuring that PiP mode and JavaScript are enabled, and also clearing the app’s cache, do not work.&nbsp;</p>
<p>Even the privacy-focused Brave browser has a new open issue on its <a href="https://github.com/brave/brave-browser/issues/52254" target="_blank" rel="nofollow ugc noopener">GitHub page</a>, confirming that the background play feature, which was working perfectly, has now failed. This widespread nature makes it hard to blame a single browser update or a simple bug.</p>
<p><a href="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp"><img decoding="async" src="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp" alt="brave-browser-youtube-background-playback-bug" width="600" height="1474" srcset="https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug.webp 600w, https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug-122x300.webp 122w, https://piunikaweb.com/wp-content/uploads/2026/01/brave-browser-youtube-background-playback-bug-417x1024.webp 417w" sizes="(max-width: 600px) 100vw, 600px"></a></p>
<p>That said, at least one Brave user <a href="https://www.reddit.com/r/MicrosoftEdge/comments/1qmhv2n/comment/o1zaa1q/" target="_blank" rel="noopener">claims</a> that this problem was fixed, and it now works fine. So I’d suggest Brave users keep an eye out for any new updates and try again (the same goes for other browsers too).</p>
<p>While YouTube hasn’t officially commented, the consensus among users is that the company has finally closed a popular loophole, effectively breaking the YouTube Premium workaround for millions. If you’re searching for why your YouTube background play is not working, or your Samsung Internet background video issue is suddenly a problem, you’re definitely not alone.</p>
<p>If this isn’t a random glitch, then the move is a clear push to convert more users to a paid subscription, leaving those who relied on the feature to either pay up or keep their screens on. We’ve already reported on YouTube’s fresh <a href="https://piunikaweb.com/2026/01/28/newpipe-content-unavailable-error-fix/" target="_blank" rel="noopener">crackdown on third-party clients like NewPipe</a>. So it won’t be a stretch to assume that YouTube is indeed patching such workarounds.</p>
<p>It’s a tough break for anyone who used this trick to listen to podcasts or music videos on the go.</p>
 
              
             </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sumerian Star Map Recorded the Impact of an Asteroid (2024) (138 pts)]]></title>
            <link>https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/</link>
            <guid>46834313</guid>
            <pubDate>Sat, 31 Jan 2026 07:32:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/">https://archaeologyworlds.com/5500-year-old-sumerian-star-map-recorded/</a>, See on <a href="https://news.ycombinator.com/item?id=46834313">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	




<p>For more than 150 years scientists have tried to solve the mystery of a notorious cuneiform clay tablet that reveals that in the past the impact case of so-called Köfel was detected. The circular stone-cast tablet was discovered in the late 1800s from the 650 BC King Ashurbanipal ‘s underground library in Nineveh, Iraq.</p>



<p>Data processing, which was long believed to be an Assyrian tablet, mirrored the sky over Mesopotamia in 3300 BC and proved to be much more <a href="https://archaeologyworlds.com/">ancient Sumerian origin</a>.</p>



<p>The tablet is the first astronomical instrument, the “Astrolabe.”&nbsp; It consists of a segmented, disk-shaped star chart with marked units of angle measure inscribed upon the rim.</p>



<p>Unfortunately considerable parts of the planisphere on this tablet are missing (approximately 40%), damage which dates to the sacking of Nineveh. The reverse of the tablet is not inscribed.</p>


<div>
<figure><img decoding="async" width="768" height="769" src="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min.jpg" alt="Sumerian Star Map Recorded " srcset="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min.jpg 768w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-300x300.jpg 300w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-150x150.jpg 150w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-1-768x769-min-96x96.jpg 96w" sizes="(max-width: 768px) 100vw, 768px"></figure>
</div>


<p>Still under study by modern scholars, the cuneiform tablet in the <a href="https://www.britishmuseum.org/" target="_blank" rel="noopener">British Museum</a> collection No K8538 (known as “the Planisphere”) provides extraordinary proof for the existence of sophisticated Sumerian astronomy.</p>



<p>In 2008 two authors, Alan Bond and Mark Hempsell published a book about the tablet called&nbsp;“A Sumerian Observation of the Kofels’ Impact Event”.</p>



<p>Raising a storm in archaeological circles, they re-translated the cuneiform text and asserted the tablet records an ancient asteroid strike, the Köfels’ Impact, which struck Austria sometime around 3100 BC.</p>



<p>The giant landslide centred at Köfels in Austria is 500m thick and five kilometres in diameter and has long been a mystery since geologists first looked at it in the 19th century.</p>



<p>The conclusion drawn by research in the middle 20th century was that it must be due to a very large meteor impact because of the evidence of crushing pressures and explosions. But this view lost favor as a much better understanding of impact sites developed in the late 20th century.</p>



<p>In the case of Köfels there is no crater, so to modern eyes it does not look as an impact site should look. However, the evidence that puzzled the earlier researchers remains unexplained by the view that it is just another landslide.</p>



<p>So what is the connection between the sophisticated Sumerian star chart discovered in the underground library in Nineveh and mysterious impact that took place in Austria?</p>



<p>Examination of the clay tablet reveals that it is an astronomical work as it has drawings of constellations on it and the text has known constellation names. It has attracted a lot of attention but in over a hundred years nobody has come up with a convincing explanation as to what it is.</p>



<p>With modern computer programs that can simulate trajectories and reconstruct the night sky thousands of years ago the researchers have established what the Planisphere tablet refers to. It is a copy of the night notebook of a Sumerian astronomer as he records the events in the sky before dawn on 29 June 3123 BC (Julian calendar).</p>



<p>Half the tablet records planet positions and cloud cover, the same as any other night, but the other half of the tablet records an object large enough for its shape to be noted even though it is still in space.</p>



<p>The astronomers made an accurate note of its trajectory relative to the stars, which to an error better than one degree is consistent with an impact at Köfels.</p>


<div>
<figure><img loading="lazy" decoding="async" width="600" height="467" src="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2.jpg" alt="Sumerian Star Map Recorded " srcset="https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2.jpg 600w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2-300x234.jpg 300w, https://archaeologyworlds.com/wp-content/uploads/2024/01/star-chart-2-150x117.jpg 150w" sizes="auto, (max-width: 600px) 100vw, 600px"></figure>
</div>


<p>The observation suggests the asteroid is over a kilometer in diameter and the original orbit about the Sun was an Aten type, a class of asteroids that orbit close to the Earth, that are resonant with the Earth’s orbit.</p>



<p>This trajectory explains why there is no crater at Köfels. The incoming angle was very low (six degrees) and means the asteroid clipped a mountain called Gamskogel above the town of Längenfeld, 11 kilometers from Köfels, and this caused the asteroid to explode before it reached its final impact point. As it traveled down the valley it became a fireball, around five kilometers in diameter (the size of the landslide).</p>



<p>When it hit Köfels it created enormous pressures that pulverized the rock and caused the landslide but because it was no longer a solid object it did not create a classic impact crater.</p>



<p>Mark Hempsell, discussing the Köfels event, said: “Another conclusion can be made from the trajectory. The back plume from the explosion (the mushroom cloud) would be bent over the Mediterranean Sea re-entering the atmosphere over the Levant, Sinai, and Northern Egypt.</p>



<p>“The ground heating though very short would be enough to ignite any flammable material – including human hair and clothes. It is probable more people died under the plume than in the Alps due to the impact blast.”</p>



<p>In other words, the remarkable ancient star map shows that the Sumerians made an observation of an Aten asteroid over a kilometer in diameter that impacted Köfels in Austria in the early morning of 29th June 3123 BC.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink updates privacy policy to allow consumer data to train (118 pts)]]></title>
            <link>https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html</link>
            <guid>46833847</guid>
            <pubDate>Sat, 31 Jan 2026 05:44:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html">https://finance.yahoo.com/news/musks-starlink-updates-privacy-policy-230853500.html</a>, See on <a href="https://news.ycombinator.com/item?id=46833847">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <p><!-- HTML_TAG_START -->By David Jeans and Joey Roulette<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->NEW YORK, Jan 30 (Reuters) - SpaceX (<a data-i13n="cpos:1;pos:1" href="https://finance.yahoo.com/quote/SPAX.PVT" data-ylk="slk:SPAX.PVT;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">SPAX.PVT</a>) revised its Starlink privacy policy to allow the use of customer data for AI training, a shift that ​could bolster Elon Musk's AI ambitions.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Ahead of a blockbuster IPO planned for later this year, ‌SpaceX is in talks to merge with Musk’s AI company, xAI (<a data-i13n="cpos:2;pos:1" href="https://finance.yahoo.com/quote/XAAI.PVT" data-ylk="slk:XAAI.PVT;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">XAAI.PVT</a>), a deal first reported by Reuters on Thursday. SpaceX, already the ‌world’s most valuable private company, could reach a value of more than $1 trillion after the IPO.<!-- HTML_TAG_END --></p>         <p><!-- HTML_TAG_START -->Starlink updated its Global Privacy Policy on January 15, according to the Starlink website. The policy includes new details stating that unless a user opts out, Starlink data may be used “to train our machine learning or <a href="https://tech.yahoo.com/ai/" data-ylk="slk:artificial intelligence;elm:context_link;itc:0;sec:content-canvas">artificial intelligence</a> ⁠models” and could be shared with ‌the company’s service providers and “third-party collaborators,” without providing further details.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->A previous version of the privacy policy, an archived version from November and reviewed by Reuters, did not ‍contain language about AI training on Starlink data.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->SpaceX did not respond to a request for comment.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Starlink collects vast amounts of user data, spanning location information, credit card information, contact information and user IP ​addresses. It also collects so-called communication data, which includes audio and visual information, data in shared ‌files, and “inferences we may make from other personal information we collect,” according to its global privacy policy.<!-- HTML_TAG_END --></p>      <p><!-- HTML_TAG_START -->The policy did not make clear exactly what data would be used to train AI. The move has raised concerns among privacy advocates and consumer rights groups, which argue that using personal data to train AI risks expanding surveillance and creates new avenues for misuse.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->“It certainly raises my eyebrow and would make ⁠me concerned if I was a Starlink user,” said Anupam ​Chander, a technology law professor at Georgetown University. “Often there's perfectly ​legitimate uses of your data, but it doesn’t have a clear limit to what kind of uses it will be put to.”<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->Musk's xAI, most recently valued at $230 billion ‍after a recent funding round, ⁠is currently developing its Grok LLM chatbot and also owns X, the social media platform.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->The potential merger with xAI would turbocharge the space company’s deployment of AI-powered services, while giving xAI ⁠vast new data sets to train its models on, including communication data. Starlink, a network of more than 9,000 satellites, ‌currently provides internet connection to more than 9 million users.<!-- HTML_TAG_END --></p>   <p><!-- HTML_TAG_START -->(Reporting by David Jeans and ‌Joey Roulette; Editing by Joe Brock and Lisa Shumaker)<!-- HTML_TAG_END --></p>   </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Phage Explorer (115 pts)]]></title>
            <link>https://phage-explorer.org/</link>
            <guid>46833754</guid>
            <pubDate>Sat, 31 Jan 2026 05:22:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phage-explorer.org/">https://phage-explorer.org/</a>, See on <a href="https://news.ycombinator.com/item?id=46833754">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
    </channel>
</rss>