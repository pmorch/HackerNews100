<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 28 Nov 2024 05:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Dell is posting unsigned updates to their website which fail to install (121 pts)]]></title>
            <link>https://infosec.exchange/@0xabad1dea/113543212666056329</link>
            <guid>42261707</guid>
            <pubDate>Thu, 28 Nov 2024 02:03:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://infosec.exchange/@0xabad1dea/113543212666056329">https://infosec.exchange/@0xabad1dea/113543212666056329</a>, See on <a href="https://news.ycombinator.com/item?id=42261707">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[London's 850-year-old food markets to close (104 pts)]]></title>
            <link>https://www.bbc.co.uk/news/articles/cje050wz22qo</link>
            <guid>42260027</guid>
            <pubDate>Wed, 27 Nov 2024 21:36:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.co.uk/news/articles/cje050wz22qo">https://www.bbc.co.uk/news/articles/cje050wz22qo</a>, See on <a href="https://news.ycombinator.com/item?id=42260027">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" data-testid="main-content"><article><header data-component="headline-block"><h2 id="main-heading" type="headline" tabindex="-1"><span role="text">London's 850-year-old food markets to close</span></h2></header><div data-component="image-block"><figure><p><span><picture><source srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg.webp 976w" type="image/webp"><img alt="A trader wearing a white overall holds to joints of meat - one of which in the air - while people stand around him in Smithfield meat market" loading="eager" src="https://ichef.bbci.co.uk/ace/standard/2048/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg" srcset="https://ichef.bbci.co.uk/ace/standard/240/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 240w, https://ichef.bbci.co.uk/ace/standard/320/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 320w, https://ichef.bbci.co.uk/ace/standard/480/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 480w, https://ichef.bbci.co.uk/ace/standard/624/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 624w, https://ichef.bbci.co.uk/ace/standard/800/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 800w, https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/9c33/live/d82fedb0-abfd-11ef-a4fe-a3e9a6c5d640.jpg 976w" width="2048" height="1152"></picture></span><span role="text"><span>Image source, </span>PA Media</span></p><figcaption><span>Image caption, </span><p>Smithfield is the largest wholesale meat market in the UK</p></figcaption></figure></div><div data-component="text-block"><p><b>The oldest meat and fish markets in London, which date back 850 years, are facing permanent closure from 2028.</b></p><p>Smithfield meat market, near St Paul's Cathedral, and Billingsgate fish market in Canary Wharf are to be closed after the City of London Corporation voted to withdraw support for them.</p><p>The Corporation said it would now work with traders to help them find alternative premises.</p><p>Traders, who have been offered compensation, have said the move means a London tradition will be lost, with one saying "it's all about the money now".</p></div><div data-component="image-block"><figure><p><span><span></span></span><span role="text"><span>Image source, </span>Getty Images</span></p><figcaption><span>Image caption, </span><p>Meat has been traded at its current site since the 1860s</p></figcaption></figure></div><div data-component="text-block"><p>Smithfield is the largest wholesale meat market in the UK and one of the biggest in Europe. The current iteration of the market has been trading at the site since the 1860s. Prior to that it was a livestock market, which dated back to the medieval period.</p><p>Work has already begun on turning this site into a new cultural and commercial hub,  which includes the new London Museum.</p><p>Billingsgate is the largest inland fish market in the UK, with an average of 25,000 tonnes of fish and fish products sold there every year. The original market first traded in Lower Thames Street in the City in 1327, before moving to its current site in Poplar, east London, in 1982.</p><p>It provides fish to businesses including fishmongers, fish-and-chip shops, delicatessens and restaurants.</p><p>This site has now been earmarked to provide thousands of new homes.</p></div><div data-component="image-block"><figure><figcaption><span>Image caption, </span><p>Billingsgate is currently based in Poplar, east London</p></figcaption></figure></div><div data-component="text-block"><p>Initially the Corporation had planned to move both markets as well as New Spitalfields in Leyton to a £1bn purpose-built site in Dagenham, however this was dropped earlier this month over cost concerns as the council had already spent £308m purchasing and remediating the site in Dagenham.</p><p>The decision to close the markets and offer traders compensation was made by the Corporation's Court of Common Council.</p><p>The Corporation will now have to file a Private Bill in Parliament as it seeks to absolve itself of the legal responsibility of running the markets. </p><p>It said traders would be able to continue their operations at the markets until at least 2028.</p></div><p data-component="subheadline-block"><h2 id="Do-my-best" tabindex="-1"><span role="text">'Do my best'</span></h2></p><div data-component="text-block"><p>Speaking to BBC London before the decision was announced, one trader - who did not want to give his name - said he had been forced to take the compensation offer or "leave with nothing".</p><p>The trader, whose family has sold fish at the site for 70 years, added: "For what we’ve been offered to vacate the premises, I can’t go and reinstate myself somewhere else. </p><p>"I’ve been told to do my best with what I can do. It’s not great at all."</p><p>On the wider impact, he said the closures would have a "massive knock-on effect".</p><p>"It means there’s no fish market for London, which would mean the populace of London would have to resort to using local fishmongers which obviously isn’t the end of the world, but where are the fishmongers going to get their fish? </p><p>"London will be without a fish supplier, so there does need to be another fish market. When and how that’s going to happen I don’t know."</p></div><div data-component="text-block"><p>Another trader said the demise of the market started when a decision was made to rid the <a href="https://www.bbc.co.uk/news/uk-england-london-10849882">fish porters of having to have a licence</a>. </p><p>"For the younger guys down here it’s not good because no-one’s ever mentioned about the workers - they’re only ever interested in the companies," he added.</p><p>Since then, Brexit and the pandemic have both brought down and led to the market's demise, one trader told BBC London.</p><p>"It's getting to the point where everything will be bought in a vac-pack," another trader added.</p></div><p data-component="subheadline-block"><h2 id="Transition-seamlessly" tabindex="-1"><span role="text">'Transition seamlessly'</span></h2></p><div data-component="text-block"><p>Chris Hayward, policy chairman of the City of London Corporation, said the decision represented a "positive new chapter" for the markets as it "empowers traders to build a sustainable future in premises that align with their long-term business goals".</p><p>He added: "By stepping back from direct market operations, we will help to create opportunities for these businesses to thrive independently.</p><p>"We've worked closely with the traders and thank them for their input and understanding.</p><p>"We're committed to making sure they have the financial support and guidance they need to transition seamlessly and successfully to new locations."</p><p>Dominic Twomey, leader of Barking and Dagenham Council, said although it was disappointing news, the council understood the "financial pressures that key investment projects" were facing.</p><p>He added they were committed to working with the Corporation to "unlock the huge potential" of the Dagenham Dock site. </p></div><div data-component="text-block"><p><i>Listen to the best of BBC Radio London on </i><a href="https://www.bbc.co.uk/sounds/curation/p0cjdwm5"><i>Sounds</i></a><i> and follow BBC London on </i><a href="https://www.facebook.com/BBCLondon"><i>Facebook</i><span>, <!-- -->external</span></a><i>, </i><a href="https://twitter.com/BBCLondonNews"><i>X</i><span>, <!-- -->external</span></a><i> and </i><a href="https://www.instagram.com/bbclondon/?hl=en"><i>Instagram</i><span>, <!-- -->external</span></a><i>. Send your story ideas to </i><a href="mailto:hello.bbclondon@bbc.co.uk"><i>hello.bbclondon@bbc.co.uk</i><span>, <!-- -->external</span></a></p></div><section data-component="links-block"><p><h2 type="normal">Related internet links</h2></p></section><section data-component="links-block"><p><h2 type="normal">More on this story</h2></p></section></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Malware can turn off webcam LED and record video, demonstrated on ThinkPad X230 (469 pts)]]></title>
            <link>https://github.com/xairy/lights-out</link>
            <guid>42259278</guid>
            <pubDate>Wed, 27 Nov 2024 20:10:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xairy/lights-out">https://github.com/xairy/lights-out</a>, See on <a href="https://news.ycombinator.com/item?id=42259278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Lights Out</h2><a id="user-content-lights-out" aria-label="Permalink: Lights Out" href="#lights-out"></a></p>
<p dir="auto">This repository contains tools that allow getting software control of the webcam LED on ThinkPad X230 <strong>without physical access to the laptop</strong>.
These were created as a practical demonstration that malware can record video through the webcam without the LED indication.</p>
<p dir="auto">This works via reflashing the webcam firmware over USB (the X230 webcam is connected over USB internally) to add a capability of arbitrarily controlling the LED.
This approach likely affects many other laptops, as connecting the webcam over USB and allowing to reflash its firmware is a common design pattern across laptop manufacturers.</p>
<p dir="auto">See the <a href="https://docs.google.com/presentation/d/1NSS2frdiyRVr-5vIjAU-2wf_agzpdiMR1DvVhz2eDwc/edit?usp=sharing" rel="nofollow">"Lights Out: Covertly turning off the ThinkPad webcam LED indicator"</a> talk (<a href="https://powerofcommunity.net/poc2024/Andrey%20Konovalov,%20Lights%20Out%20-%20Covertly%20turning%20off%20the%20ThinkPad%20webcam%20LED%20indicator.pdf" rel="nofollow">pdf</a>) I gave at <a href="https://powerofcommunity.net/" rel="nofollow">POC 2024</a> for the details: discovering a way to reflash the X230 webcam firmware, reverse engineering the firmware, adding an implant for LED control, and notes about the applicability of the approach to other laptops.</p>
<p dir="auto"><strong>Note: Reflashing the webcam firmware might brick the webcam, use these tools with caution</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">The webcam used on ThinkPad X230 (and a few other laptops from the same era) is based on the Ricoh R5U8710 USB camera controller.
This controller stores a part of its firmware, the SROM part, on the SPI flash chip located on the webcam board.
The controller also allows reflashing the contents of the SPI chip over USB.</p>
<p dir="auto">The LED on the X230 webcam board is connected to the GPIO B1 pin of the R5U8710 controller.
The GPIO B port is mapped to address <code>0x80</code> in the <code>XDATA</code> memory space of the 8051-based CPU inside R5U8710.
Thus, changing the value at that address changes the state of the LED.
This works regardless of whether the webcam is streaming video at the moment or not.</p>
<p dir="auto">The tools provided in this repository allow flashing custom firmware with a USB-controlled so-called "universal implant" onto the SPI chip on the webcam board.
This implant allows writing controlled data to arbitrary addesses (within the <code>XDATA</code> memory space) and calling arbitrary addresses (within the <code>CODE</code> memory space; aliased with <code>XDATA</code> starting from offset <code>0xb000</code>).</p>
<p dir="auto">The universal implant can be used for:</p>
<ul dir="auto">
<li>
<p dir="auto">Dynamically uploading a second-stage implant within the camera contoller memory and executing it (originally used for reverse engineering purposes);</p>
</li>
<li>
<p dir="auto">Directly controlling the webcam LED.</p>
</li>
</ul>
<p dir="auto">See the talk slides for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom.py">srom.py</a> — reads and writes the SROM part of the firmware of a Ricoh R5U8710–based webcam over USB.</p>
<p dir="auto">Note: The webcam only loads the SROM firmware during its boot.
Thus, you will need to power cycle the laptop (full shutdown, not just reboot) for the updated firmware to get loaded;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/patch_srom.py">patch_srom.py</a> — patches the SROM image from the FRU <code>63Y0248</code> webcam (not from the original X230 webcam) to add the universal implant.</p>
<p dir="auto">Note: This tool requires modification to work with the original X230 webcam SROM image.
However, the FRU <code>63Y0248</code> SROM image (optionally, with the implant added) can be flashed onto the original X230 webcam as well;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/fetch.py">fetch.py</a> — fetches the contents of the <code>IRAM</code>, <code>XDATA</code>, or <code>CODE</code> memory space over USB via a second-stage implant that gets dynamically uploaded via the universal implant;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/led.py">led.py</a> — turns the webcam LED on or off by overwriting the value at address <code>0x80</code> in <code>XDATA</code> via the universal implant.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory dumps</h2><a id="user-content-memory-dumps" aria-label="Permalink: Memory dumps" href="#memory-dumps"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom/x230.bin">srom/x230.bin</a> — SROM contents of the original X230 webcam module (FRU unknown; <code>19N1L1NVRA0H</code> marking on the board);</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom/63Y0248.bin">srom/63Y0248.bin</a> — SROM contents of the FRU <code>63Y0248</code> webcam module;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/code/63Y0248.bin">code/63Y0248.bin</a> — Contents of the <code>CODE</code> memory space leaked from the FRU <code>63Y0248</code> webcam module.</p>
<p dir="auto">Note: Boot ROM is below the offset <code>0xb000</code>, and it is identical to the Boot ROM on the original X230 webcam module.</p>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brain learning differs fundamentally from artificial intelligence systems (116 pts)]]></title>
            <link>https://www.nature.com/articles/s41593-023-01514-1</link>
            <guid>42259185</guid>
            <pubDate>Wed, 27 Nov 2024 20:00:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41593-023-01514-1">https://www.nature.com/articles/s41593-023-01514-1</a>, See on <a href="https://news.ycombinator.com/item?id=42259185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <div id="Sec1-section" data-title="Main"><h2 id="Sec1">Main</h2><div id="Sec1-content"><p>The credit assignment problem<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. Nat. Rev. Neurosci. 21, 335–346 (2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR1" id="ref-link-section-d46823651e584">1</a></sup> lies at the very heart of learning. Backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. Learning Internal Representations by Error Propagation (Univ. California, San Diego, Institute for Cognitive Science, 1985)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR2" id="ref-link-section-d46823651e588">2</a></sup>, as a simple yet effective credit assignment theory, has powered notable advances in artificial intelligence since its inception<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. ImageNet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bartlett, P. et al.) 1097–1105 (Curran Associates, 2012)." href="#ref-CR3" id="ref-link-section-d46823651e592">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="#ref-CR4" id="ref-link-section-d46823651e592_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Silver, D. et al. Mastering the game of go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR5" id="ref-link-section-d46823651e595">5</a></sup> and has also gained a predominant place in understanding learning in the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. Nat. Rev. Neurosci. 21, 335–346 (2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR1" id="ref-link-section-d46823651e599">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Richards, B. A. et al. A deep learning framework for neuroscience. Nat. Neurosci. 22, 1761–1770 (2019)." href="#ref-CR6" id="ref-link-section-d46823651e602">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Singer, Y. et al. Sensory cortex is optimized for prediction of future input. eLife 7, e31557 (2018)." href="#ref-CR7" id="ref-link-section-d46823651e602_1">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc. Natl Acad. Sci. USA 111, 8619–8624 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR8" id="ref-link-section-d46823651e605">8</a></sup>. Due to this success, much recent work has focused on understanding how biological neural networks could learn in a way similar to backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018)." href="#ref-CR9" id="ref-link-section-d46823651e609">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Guerguiev, J., Lillicrap, T. P. &amp; Richards, B. A. Towards deep learning with segregated dendrites. eLife 6, e22901 (2017)." href="#ref-CR10" id="ref-link-section-d46823651e609_1">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="#ref-CR11" id="ref-link-section-d46823651e609_2">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e612">12</a></sup>; although many proposed models do not implement backpropagation exactly, they nevertheless try to approximate backpropagation, and much emphasis is placed on how close this approximation is<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR9" id="ref-link-section-d46823651e617">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d46823651e620">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Whittington, J. C. R. &amp; Bogacz, R. Theories of error back-propagation in the brain. Trends Cogn. Sci. 23, 235–250 (2019)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR13" id="ref-link-section-d46823651e623">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e626">14</a></sup>. However, learning in the brain is superior to backpropagation in many critical aspects. For example, compared to the brain, backpropagation requires many more exposures to a stimulus to learn<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Tsividis, P. A., Pouncy, T., Xu, J. L., Tenenbaum, J. B. &amp; Gershman, S. J. Human learning in Atari. In 2017 AAAI Spring Symposium Series 643–646 (Association for the Advancement of Artificial Intelligence, 2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR15" id="ref-link-section-d46823651e630">15</a></sup> and suffers from catastrophic interference of newly and previously stored information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d46823651e634">16</a></sup>. This raises the question of whether using backpropagation to understand learning in the brain should be the main focus of the field.</p><p>Here, we propose that the brain instead solves credit assignment with a fundamentally different principle, which we call ‘prospective configuration’. In prospective configuration, before synaptic weights are modified, neural activity changes across the network so that output neurons better predict the target output; only then are the synaptic weights (hereafter termed ‘weights’) modified to consolidate this change in neural activity. By contrast, in backpropagation, the order is reversed; weight modification takes the lead, and the change in neural activity is the result that follows.</p><p>We identify prospective configuration as a principle that is implicitly followed by a well-established family of neural models with solid biological groundings, namely, energy-based networks. These networks include Hopfield networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl Acad. Sci. USA 79, 2554–2558 (1982)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR17" id="ref-link-section-d46823651e644">17</a></sup> and predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e648">18</a></sup>, which have been successfully used to describe information processing in the cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Friston, K. The free-energy principle: a unified brain theory? Nat. Rev. Neurosci. 11, 127–138 (2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR19" id="ref-link-section-d46823651e652">19</a></sup>. To support the theory of prospective configuration, we show that it can both yield efficient learning, which humans and animals are capable of, and reproduce data from experiments on human and animal learning. Thus, on the one hand, we demonstrate that prospective configuration performs more efficient and effective learning than backpropagation in various situations faced by biological systems, such as learning with deep structures, online learning, learning with a limited amount of training examples, learning in changing environments, continual learning with multiple tasks and reinforcement learning. On the other hand, we demonstrate that patterns of neural activity and behavior in diverse human and animal learning experiments, including sensorimotor learning, fear conditioning and reinforcement learning, can be naturally explained by prospective configuration but not by backpropagation.</p><p>Guided by the belief that backpropagation is the foundation of biological learning, previous work showed that energy-based networks can closely approximate backpropagation. However, to achieve it, the networks were set up in an unnatural way, such that the neural activity was prevented from substantially changing before weight modification by constraining the supervision signal to be infinitely small (for example, as in equilibrium propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d46823651e659">11</a></sup> and in previous studies using predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e663">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. Neural Comput. 34, 1329–1368 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR20" id="ref-link-section-d46823651e666">20</a></sup>) or last an infinitely short time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e670">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1510.02777
                  
                 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR21" id="ref-link-section-d46823651e673">21</a></sup>. By contrast, we reveal that energy-based networks without these unrealistic constraints follow the distinct principle of prospective configuration rather than backpropagation and are superior in both learning efficiency and accounting for data on biological learning.</p><p>Here, we introduce prospective configuration with an intuitive example, show how it originates from energy-based networks and describe its advantages and quantify them in a rich set of biologically relevant learning tasks. We show that prospective configuration naturally explains patterns of neural activity and behavior in diverse learning experiments.</p></div></div><div id="Sec2-section" data-title="Results"><h2 id="Sec2">Results</h2><div id="Sec2-content"><h3 id="Sec3">Prospective configuration: an intuitive example</h3><p>To optimally plan behavior, it is critical for the brain to predict future stimuli, for example, to predict sensations in some modalities on the basis of other modalities<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="O’Reilly, R. C. &amp; Munakata, Y. Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain (MIT Press Cambridge, 2000)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR22" id="ref-link-section-d46823651e693">22</a></sup>. If the observed outcome differs from the prediction, the weights in the whole network need to be updated so that predictions in the ‘output’ neurons are corrected. Backpropagation computes how the weights should be modified to minimize the error on the output, and this weight update results in a change in neural activity when the network next makes the prediction. By contrast, we propose that neural activity is first adjusted to a new configuration so that the output neurons better predict the observed outcome (target pattern); the weights are then modified to reinforce this configuration of neural activity. We call this configuration of neural activity ‘prospective’ because it is the neural activity that the network should produce to correctly predict the observed outcome. In agreement with the proposed mechanism of prospective configuration, it has indeed been widely observed in biological neurons that presenting the outcome of a prediction triggers changes in neural activity; for example, in tasks requiring animals to predict a juice delivery, the reward triggers rapid changes in activity not only in the gustatory cortex but also in multiple cortical regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Quilodran, R., Rothe, M. &amp; Procyk, E. Behavioral shifts and action valuation in the anterior cingulate cortex. Neuron 57, 314–325 (2008)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR23" id="ref-link-section-d46823651e697">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Wallis, J. D. &amp; Kennerley, S. W. Heterogeneous reward signals in prefrontal cortex. Curr. Opin. Neurobiol. 20, 191–198 (2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR24" id="ref-link-section-d46823651e700">24</a></sup>.</p><p>To highlight the difference between backpropagation and prospective configuration, consider a simple example (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1a</a>). Imagine a bear seeing a river. In the bear’s mind, the sight generates predictions of hearing water and smelling salmon. On that day, the bear indeed smelled the salmon but did not hear the water, perhaps due to an ear injury, and thus the bear needs to change its expectation related to the sound. Backpropagation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1b</a>) would proceed by backpropagating the negative error to reduce the weights on the path between the visual and auditory neurons. However, this also entails a reduction of the weights between visual and olfactory neurons that would compromise the expectation of smelling the salmon the next time the river is visited, even though the smell of salmon was present and correctly predicted. These undesired and unrealistic side effects of learning with backpropagation are closely related with the phenomenon of catastrophic interference, where learning a new association destroys previously learned memories<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d46823651e713">16</a></sup>. This example shows that, with backpropagation, even learning one new aspect of an association may interfere with the memory of other aspects of the same association.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Prospective configuration avoids interference during learning."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Prospective configuration avoids interference during learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig1_HTML.png?as=webp"><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="297"></picture></a></div><p><b>a</b>, Abstract (top) and concrete (bottom) examples of a task inducing interference during learning. One stimulus input (seeing the water) triggers two prediction outputs (hearing the water and smelling the salmon). One output is correct (smelling the salmon), whereas the other output is an error (not hearing the water). <b>b</b>,<b>c</b>, Backpropagation produces interference during learning; not hearing the water reduces the expectation of smelling the salmon (<b>b</b>), although the salmon was indeed smelled. Prospective configuration, on the other hand, avoids such interference (<b>c</b>). In backpropagation, negative error propagates from the error output to hidden neurons (<b>b</b>; left). This causes a weakening of some connections, which, on the next trial, improves the incorrect output but also reduces the prediction of the correct output, thus introducing interference (<b>b</b>; middle and right). In prospective configuration, neural activity settles into a new configuration (different intensities of purple) before weight modification (<b>c</b>; left). This configuration corresponds to the activity that should be produced after learning, that is, is ‘prospective’. Hence, it foresees the positive error on the correct output and modifies the connections to improve the incorrect output while maintaining the correct output (<b>c</b>; middle and right).</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>By contrast, prospective configuration assumes that learning starts with the neurons being configured to a new state, which corresponds to a pattern enabling the network to correctly predict the observed outcome. The weights are then modified to consolidate this state. This behavior can ‘foresee’ side effects of potential weight modifications and compensate for them dynamically (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1c</a>). To correct the negative error on the incorrect output, the hidden neurons settle to their prospective state of lower activity, and, as a result, a positive error is revealed and allocated to the correct output. Consequently, prospective configuration increases the weights connecting to the correct output, whereas backpropagation does not (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1b,c</a>). Hence, prospective configuration is able to correct the side effects of learning an association effectively and efficiently and with little interference.</p><h3 id="Sec4">Origin of prospective configuration: energy-based networks</h3><p>To show how prospective configuration naturally arises in energy-based networks, we introduce a physical machine analog, which provides an intuitive understanding of energy-based networks and how they produce the mechanism of prospective configuration.</p><p>Energy-based networks have been widely and successfully used in describing biological neural systems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl Acad. Sci. USA 79, 2554–2558 (1982)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR17" id="ref-link-section-d46823651e784">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Friston, K. A theory of cortical responses. Philos. Trans. R. Soc. Lond. B Biol. Sci. 360, 815–836 (2005)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR25" id="ref-link-section-d46823651e787">25</a></sup>. In these models, a neural circuit is described by a dynamical system driven by reducing an abstract ‘energy’, for example, reflecting errors made by neurons (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec10">Methods</a>). Neural activity and weights change to reduce this energy; hence, they can be considered ‘movable parts’ of the dynamical system. We show that energy-based networks are mathematically equivalent to a physical machine (we call it ‘energy machine’), where the energy function has an intuitive interpretation, and its dynamics are straightforward; the energy machine simply adjusts its movable parts to reduce energy.</p><p>The energy machine includes nodes sliding on vertical posts connected with each other via rods and springs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2a,b</a>). Translating from energy-based networks to the energy machine, neural activity maps to the vertical position of a solid node, a connection maps to a rod (blue arrow) pointing from one node to another (where the weight determines how the end position of the rod relates to the initial position), and the energy function maps to the elastic potential energy of springs with nodes attached on both ends (the natural length of the springs is 0). Different energy functions and network structures result in different energy-based networks, corresponding to energy machines with different configurations and combinations of nodes, rods and springs. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2</a>, we present the energy machine of predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e803">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e806">18</a></sup> because they are most accessible and are established to be closely related to backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e810">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e813">14</a></sup>.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="The energy machine reveals a new understanding of energy-based networks, the mechanism of prospective configuration and its theoretical advantages."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: The energy machine reveals a new understanding of energy-based networks, the mechanism of prospective configuration and its theoretical advantages.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig2_HTML.png?as=webp"><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="432"></picture></a></div><p>A subset of energy-based networks can be visualized as mechanical machines that perform equivalent computations. Here, we present the energy machine corresponding to predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e829">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e832">18</a></sup>. In the energy machine, the activity of a neuron corresponds to the height of a node (represented by a solid circle) sliding on a post. The input to the neuron is represented by a hollow node on the same post. A synaptic connection corresponds to a rod pointing from a solid node to a hollow node. The weight determines how the input to a postsynaptic neuron depends on the activity of a presynaptic neuron; hence, it influences the angle of the rod. In energy-based networks, relaxation (that is, neural dynamics) and weight modification (that is, weight dynamics) are both driven by minimizing the energy, which corresponds to relaxation of the energy machine by moving the nodes and tuning the rods, respectively. <b>a</b>,<b>b</b>, Predictions (<b>a</b>) and learning (<b>b</b>) in energy-based networks visualized by the energy machine. The pin indicates that neural activity is fixed to the input or target pattern. Here, it is revealed that relaxation infers prospective neural activity, toward which the weights are then modified, a mechanism that we call prospective configuration. <b>c</b>, Physical implementation (top) and connectivity of a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e852">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e855">18</a></sup> (bottom), which has dynamics mathematically equivalent to those of the energy machine in the middle (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec10">Methods</a> for details). <b>d</b>, The learning problem in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a> visualized by the energy machine, which learns to improve the incorrect output while not interfering with the correct output, thanks to the mechanism of prospective configuration.</p></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>The dynamics of energy-based networks, which are driven by minimizing the energy function, map to relaxation of the energy machine, which is driven by reducing the total elastic potential energy on the springs. A prediction with energy-based networks involves clamping the input neurons to the provided stimulus and updating the activity of the other neurons, which corresponds to fixing one side of the energy machine and letting the energy machine relax by moving nodes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2a</a>). Learning with energy-based networks involves clamping the input and output neurons to the corresponding stimulus, first letting the activities of the remaining neurons converge and then updating weights, which corresponds to fixing both sides of the energy machine and letting the energy machine relax first by moving nodes and then tuning rods (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2b</a>).</p><p>The energy machine reveals the essence of energy-based networks; relaxation before weight modification lets the network settle to a new configuration of neural activity corresponding to the neural activity that would have occurred after the error was corrected by the modification of weights, that is, prospective activity (thus, we call this mechanism prospective configuration). For example, the second-layer ‘neuron’ in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2b</a> increases its activity, and this increase in activity would also be caused by the subsequent weight modification (of the connection between the first and second neurons). In simple terms, relaxation in energy-based networks infers the prospective neural activity after learning, toward which the weights are then modified. This distinguishes it from backpropagation, where weight modification takes the lead, and the change in neural activity is the result that follows.</p><p>The bottom of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2c</a> shows the connectivity of a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e898">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e901">18</a></sup>, which has dynamics mathematically equivalent to those of the energy machine shown above it. Predictive coding networks include neurons (blue) corresponding to nodes on the posts and separate neurons encoding prediction errors (red) corresponding to springs. For details, see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec10">Methods</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">1</a>, where we list equations describing predictive coding networks and show how they map on the neural implementation and the proposed energy machine.</p><p>Using the energy machine, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2d</a> simulates the learning problem from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a>. Here, we can see that prospective configuration indeed foresees the result of learning and its side effects through relaxation. Hence, it corrects the side effects within one iteration, which would otherwise take multiple iterations for backpropagation.</p><h3 id="Sec5">Advantages of prospective configuration: reduced interference and faster learning</h3><p>Here, we quantify interference in the above scenario and demonstrate how reduced interference translates into an advantage in performance. In all simulations in the main text, prospective configuration is implemented in predictive coding networks (other energy-based models are considered in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.1). We also compare the performance of predictive coding networks against artificial neural networks (ANNs) trained with backpropagation because they are closely related, which makes the comparisons fair. In particular, although predictive coding networks include recurrent connections, they generate the same prediction for a given input (when inputs are constrained but outputs are not; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2a</a>) as standard feedforward ANNs if their weights are set to corresponding values<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e934">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e937">14</a></sup>. Therefore, loss is the same function of weights in both models, so direct minimization of loss with gradient descent in predictive coding networks (which is not their natural way of training) would produce the same weight changes as backpropagation in ANNs. Hence, comparing predictive coding networks and backpropagation enables isolation of the effects of the learning algorithm (prospective configuration versus direct minimization of loss as in backpropagation).</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3a</a>, we compare the activity of output neurons in the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a> between backpropagation and prospective configuration. Initially both output neurons are active (top right), and the output should change toward a target in which one of the neurons is inactive (red vector). Learning with prospective configuration results in changes on the output (purple solid vector) that are aligned better with the target than those for backpropagation (purple dotted vector).</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Learning with prospective configuration changes the activity of output neurons in a direction more aligned toward the target."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Learning with prospective configuration changes the activity of output neurons in a direction more aligned toward the target.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig3_HTML.png?as=webp"><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="308"></picture></a></div><div data-test="bottom-caption" id="figure-3-desc"><p><b>a</b>, Simulation of the network from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a> showing changes in the correct and incorrect output neurons during training (‘Iteration’) trained with both learning rules. Here, learning with prospective configuration (purple solid vector) aligns better with the target (red vector) than learning with backpropagation (purple dashed vector). <b>b</b>, Interference can be quantified by ‘target alignment’, the cosine similarity of the direction of the target (red vector) and the direction of learning (purple vector). <b>c</b>, Higher target alignment indicates less interference and vice versa. <b>d</b>, The same experiment as in <b>a</b> repeated with a learning rate ranging from 0.005 to 0.5 represented by the size of the markers, where it is shown that the choice of learning rate changes the trajectories for both methods slightly, but the conclusion holds irrespective of the learning rate. <b>e</b>, Target alignment of randomly generated networks trained with both learning rules as a function of depth of the network. Each symbol shows target alignment resulting from training on a single randomly generated pattern. <b>f</b>, Test error during training on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e986">60</a></sup> dataset containing images of clothing belonging to different categories for both learning rules with a deep neural network of 15 layers. Here, ‘test error’ refers to the ratio of incorrectly classified samples among all samples in the test set. <b>g</b>, Mean of the test error over training epochs (reflecting how fast test error drops) as a function of learning rate. Results in <b>f</b> and <b>h</b> are for the learning rates giving the minima of the corresponding curves in <b>g</b>. <b>h</b>, Mean of test error of other network depths. Each point is from a learning rate independently optimized for each learning rule in the corresponding setup of network depth. In <b>e</b>–<b>h</b>, prospective configuration demonstrates a notable advantage as the structure gets deeper. Each experiment in <b>f</b>–<b>h</b> was repeated with <i>n</i> = 3 random seeds. Error bars and bands represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>Following the first weight update, we simulate multiple iterations until the network is able to correctly predict the target. Here, ‘iteration’ refers to each time the agent is presented with stimuli and conducts one weight update because of the stimulus. Although the output from backpropagation can reach the target after multiple iterations, the output for the ‘correct neuron’ diverges from the target during learning and then comes back; this is a particularly undesired effect in biological learning, where networks can be ‘tested’ at any point during the learning process, because it may lead to incorrect decisions affecting chances for survival. By contrast, prospective configuration substantially reduces this effect.</p><p>Although backpropagation modifies weights to directly reduce cost in the space of weights (that is, performs gradient descent), surprisingly, and rather subversively, it does not push the resulting output activity directly toward the target. To illustrate this, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3a</a> visualizes the cost with contour lines. Changing the activity of output neurons according to the gradient of the cost would correspond to a change orthogonal to the contour lines, that is, that indicated by the red arrow. However, backpropagation changes the output in a different direction shown by a dashed arrow. Optimizing the weights independently, without considering the effect of updating other weights, leads to output activity not updating toward the target directly due to different weight updates to different layers interfering with each other. By contrast, prospective configuration considers the results of updating other weights by finding a desired configuration of neural activity first. Such a mechanism is missing in backpropagation but is natural in energy-based networks. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">2</a> shows a direct comparison of how these two models evolve in weight and output spaces during learning.</p><p>Interference can be quantified by the angle between the direction of the target (from current output to target) and learning (from current output to output after learning, both measured without the target provided), and we define ‘target alignment’ as the cosine of this angle (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3b</a>); hence, high interference corresponds to low target alignment (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3c</a>).</p><p>It is useful to highlight that target alignment is affected little by the learning rate (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3d</a>), demonstrating that the learning rate has little effect on the direction and trajectory that output neurons take. The difference in target alignment demonstrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3a</a> is also present for deeper and larger (randomly generated) networks (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3e</a>). When a network has no hidden layers, the target alignment is equal to 1 (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.4.1). The target alignment drops for backpropagation as the network gets deeper because changes in weights in one layer interfere with changes in other layers (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a>), and the backpropagated errors do not lead to appropriate modification of weights in hidden layers (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">2</a>). Because backpropagation modifies the weights in the direction reducing loss, it has positive target alignment for small learning rates but not necessarily close to 1. By contrast, prospective configuration maintains a much higher value along the way. This higher target alignment of prospective configuration can be theoretically explained by the following: (1) there exists a close link between prospective configuration and an algorithm called target propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1407.7906
                  
                 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR26" id="ref-link-section-d46823651e1078">26</a></sup> (shown in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">3</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.2), and (2) under certain conditions, target propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1407.7906
                  
                 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR26" id="ref-link-section-d46823651e1088">26</a></sup> has a target alignment of 1 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Meulemans, A., Carzaniga, F., Suykens, J., Sacramento, J. &amp; Grewe, B. F. A theoretical framework for target propagation. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochelle, H. et al.) 20024–20036 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR27" id="ref-link-section-d46823651e1092">27</a></sup>; demonstrated in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">4</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.4.2). Thus, the link with target propagation provides theoretical insight (with numerical verification) into why prospective configuration has a higher target alignment.</p><p>Higher target alignment directly translates to the efficiency of learning. Test error during training in a visual classification task with a deep neural network of 15 layers decreases faster for prospective configuration than for backpropagation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a>).</p><p>Throughout the data presented here, if learning rate is not presented in a plot, the plot corresponds to the best learning rate optimized independently for each rule under the setup via a grid search. The optimization target is either learning performance or similarity to experimental data (details can be found in the methods for each experiment). Thus, for example, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a> shows the test errors as training progress, with the learning rates optimized independently for each learning rule. The optimization target is the ‘mean of test error’ during training, reflecting how fast the test error decreases during training. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3g</a> plots this mean of test error for different learning rates for both learning rules, and the learning rates giving the minima of the curves were used in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a>. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3h</a> repeats the experiment on networks of other depths and shows the mean of the test error during training as a function of network depth. The mean error is higher for lower depths, as these networks are unable to learn the task, and for greater depths, as it takes longer to train deeper networks. Importantly, the gap between backpropagation and prospective configuration widens for deeper networks, paralleling the difference in target alignment. Efficient training with deeper networks is important for biological neural systems known to be deep, for example, the primate visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR28" id="ref-link-section-d46823651e1124">28</a></sup>.</p><p>In Section 2.3 of the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, we develop a formal theory of prospective configuration and provide further illustrations and analyses of its advantages. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">5</a> formally defines prospective configuration and demonstrates that it is indeed commonly observed in different energy-based networks. Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">6</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">7</a> empirically verify and generalize the advantages expected from the theory and show that prospective configuration yields more accurate error allocation and less erratic weight modification, respectively.</p><h3 id="Sec6">Advantages of prospective configuration: effective learning in biologically relevant scenarios</h3><p>Inspired by these advantages, we show empirically that prospective configuration indeed handles various learning problems that biological systems would face better than backpropagation. Because the field of machine learning has developed effective benchmarks for testing learning performance, we use variants of classic machine learning problems that share key features with learning in natural environments. Such problems include online learning, where weights must be updated after each experience (rather than a batch of training examples)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In Efficiency and Scalability Methods for Computational Intellect (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR29" id="ref-link-section-d46823651e1151">29</a></sup>, continual learning with multiple tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. Neuron 95, 245–258 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR30" id="ref-link-section-d46823651e1155">30</a></sup>, learning in changing environments<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d46823651e1159">31</a></sup>, learning with a limited amount of training examples and reinforcement learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d46823651e1163">4</a></sup>. In all aforementioned learning problems, prospective configuration demonstrates a notable superiority over backpropagation.</p><p>First, based on the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a>, we expect prospective configuration to require fewer episodes for learning than backpropagation. Before presenting the comparison, we describe how backpropagation is used to train ANNs. Typically, the weights are only modified after a batch of training examples based on the average of updates derived from individual examples (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4a</a>). In fact, backpropagation relies heavily on averaging over multiple experiences to reach human-level performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Puri, R., Kirby, R., Yakovenko, N. &amp; Catanzaro, B. Large scale language modeling: converging on 40 GB of text in four hours. In 2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD) 290–297 (IEEE, 2018)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR32" id="ref-link-section-d46823651e1176">32</a></sup>, as it needs to stabilize training<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proceedings of the International Conference on Machine Learning (ICML) (eds Bach, F. &amp; Blei, D.) 448–456 (PMLR, 2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR33" id="ref-link-section-d46823651e1180">33</a></sup>. By contrast, biological systems must update the weights after each experience, and we compare learning performance in such a setting. Sampling efficiency can be quantified by mean of test error during training, which is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4b</a> as a function of batch size (number of experiences that the updates are averaged over). Efficiency strongly depends on batch size for backpropagation because it requires batch training to average out erratic weight updates, whereas this dependence is weaker for prospective configuration, where weight changes are intrinsically less erratic and batch averaging is required less (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">7</a>). Importantly, prospective configuration learns faster with smaller batch sizes, as in biological settings. Additionally, final performance can be quantified by the minimum of the test error, which is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4c</a>, when trained with a batch size equal to 1. Here, prospective configuration also demonstrates a notable advantage over backpropagation.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Prospective configuration achieves a superior performance over backpropagation in various learning situations faced by biological systems."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Prospective configuration achieves a superior performance over backpropagation in various learning situations faced by biological systems.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig4_HTML.png?as=webp"><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="451"></picture></a></div><div data-test="bottom-caption" id="figure-4-desc"><p><b>a</b>–<b>k</b>, Learning situations include online learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In Efficiency and Scalability Methods for Computational Intellect (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR29" id="ref-link-section-d46823651e1211">29</a></sup> (<b>a</b>–<b>c</b>), continual learning of multiple tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. Neuron 95, 245–258 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR30" id="ref-link-section-d46823651e1221">30</a></sup> (<b>d</b>–<b>e</b>), learning in changing environments<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d46823651e1232">31</a></sup> (<b>f</b>–<b>g</b>), learning with a limited amount of training examples (<b>h</b>) and reinforcement learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d46823651e1246">4</a></sup> (<b>k</b>). Graphs corresponding to each situation are grouped together with the same background color. Simulations of each situation differ from the ‘default setup’ described in the <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec10">Methods</a> in a single aspect unique to this task. For example, the default setup involves training with minibatches, so the batch size was only set to 1 in <b>a</b>–<b>c</b> for investigating online learning, whereas it was set to a larger default value in rest of the groups. In supervised learning setups, fully connected networks (<b>a</b>–<b>h</b>) were evaluated on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e1269">60</a></sup> dataset, and convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d46823651e1273">35</a></sup> (<b>i</b> and <b>j</b>) were evaluated on the CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d46823651e1283">36</a></sup>) dataset. In the reinforcement learning setup (<b>k</b>), fully connected networks were evaluated on three classic control problems. If the learning rate was not presented, each point (a setup of an experiment) in the plot corresponds to the best learning rate optimized independently for each rule under that setup. <b>a</b>, Difference in training setup between computers that can average weight modifications for individual examples to get a ‘statistically good’ value and biological systems that must apply one modification before computing another. <b>b</b>, Mean of the test errors during training as a function of batch size. <b>c</b>, Minimum of test error during training as a function of learning rate. <b>d</b>, Test error during continual learning of two tasks. <b>e</b>, Mean of test error of both tasks during training as a function of learning rate. <b>f</b>, Test error during training when learning with concept drifting. <b>g</b>, Mean of test error during training with concept drifting as a function of learning rate. <b>h</b>, Minimum of test error during training with different amounts of training examples (data points per class). <b>i</b>, Minimum of test error during training of a convolutional neural network trained with prospective configuration and backpropagation on the CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d46823651e1319">36</a></sup>) dataset. <b>j</b>, Structure detail of the convolutional neural network used in <b>i</b>. <b>k</b>, Sum of rewards per episode during training on three classic reinforcement learning tasks (insets). An episode is a period from initialization of environment to reaching a terminate state. Each experiment in <b>a</b>–<b>h</b> was repeated with <i>n</i> = 10 random seeds. Each experiment in <b>i</b>–<b>k</b> was repeated with <i>n</i> = 3 random seeds because these experiments are more expensive. Error bars and bands represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>Second, biological organisms need to sequentially learn multiple tasks, while ANNs show catastrophic forgetting. When trained on a new task, performance on previously learned tasks is largely destroyed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d46823651e1367">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In Proc. 34th International Conference on Machine Learning (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR34" id="ref-link-section-d46823651e1370">34</a></sup>. The data in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4d</a> show performance when trained on two tasks alternately (task 1 is classifying five randomly selected classes in the FashionMNIST dataset, and task 2 is classifying the remaining five classes). Prospective configuration outperforms backpropagation both in terms of avoiding forgetting previous tasks and relearning current tasks. The results are summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4e</a>.</p><p>Third, biological systems often need to rapidly adapt to changing environments. A common way to simulate this is ‘concept drifting’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d46823651e1383">31</a></sup>, where a part of the mapping between the output neurons to the semantic meaning is shuffled regularly, each time a certain number of training iterations has passed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4f</a>). Test error during training with concept drifting is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4f</a>. Before epoch 0, both learning rules are initialized with the same pretrained model (trained with backpropagation); thus, epoch 0 is the first time the model experiences concept drift. The results are summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4g</a> and show that, for this task, there is a particularly large difference in mean error (for optimal learning rates). This large advantage of prospective configuration is related to it being able to optimally detect which weights to modify (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">6</a>) and to preserve existing knowledge while adapting to changes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a>). This ability to maintain important information while updating other information is critical for survival in natural environments that are bound to change, and prospective configuration has a very substantial advantage in this respect.</p><p>Furthermore, biological learning is also characterized by limited data availability. Prospective configuration outperforms backpropagation when the model is trained with fewer examples (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4h</a>).</p><p>To demonstrate that the advantage of prospective configuration also scales up to larger networks and problems, we evaluated convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d46823651e1413">35</a></sup> on CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d46823651e1417">36</a></sup>) trained with both learning rules (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4i</a>), where prospective configuration showed notable advantages over backpropagation. The detailed structure of the convolutional networks is provided in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4j</a>.</p><p>Another key challenge for biological systems is to decide which actions to take. Reinforcement learning theories (for example, <i>Q</i> learning) propose that it is solved by learning the expected reward resulting from different actions in different situations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Sutton, R. S. &amp; Barto, A. G. Introduction to Reinforcement Learning, Vol. 2 (MIT Press Cambridge, 1998)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR37" id="ref-link-section-d46823651e1433">37</a></sup>. Such prediction of rewards can be made by neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d46823651e1437">4</a></sup>, which can be trained with prospective configuration or backpropagation. The sum of rewards per episode during training on three classic reinforcement learning tasks is reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4k</a>, where prospective configuration demonstrates a notable advantage over backpropagation. This large advantage may arise because reinforcement learning is particularly sensitive to erratic changes in network weights (as the target output depends on reward predicted by the network itself for a new state; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec10">Methods</a>).</p><p>Based on the superior learning performance of prospective configuration, we may expect that this learning mechanism has been favored by evolution; thus, in the next sections, we investigate if it can account for neural activity and behavior during learning better than backpropagation.</p><h3 id="Sec7">Evidence for prospective configuration: inferring the latent state during learning</h3><p>Prospective configuration is related to theories proposing that before learning, the brain first infers a latent state of the environment from feedback<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="#ref-CR38" id="ref-link-section-d46823651e1459">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="#ref-CR39" id="ref-link-section-d46823651e1459_1">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Larsen, T., Leslie, D. S., Collins, E. J. &amp; Bogacz, R. Posterior weighted reinforcement learning with state uncertainty. Neural Comput. 22, 1149–1179 (2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR40" id="ref-link-section-d46823651e1462">40</a></sup>. Here, we propose that this inference can be achieved in neural circuits through prospective configuration, where, following feedback, neurons in ‘hidden layers’ converge to a prospective pattern of activity that encodes this latent state. We demonstrate that data from various previous studies, which involved the inference of a latent state, can be explained by prospective configuration. These data were previously explained by complex and abstract mechanisms, such as Bayesian models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e1466">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d46823651e1469">39</a></sup>, whereas here, we mechanistically show with prospective configuration how such inference can be performed by minimal networks encoding only the essential elements of the tasks.</p><p>The dynamical inference of a latent state from feedback has been recently proposed to take place during sensorimotor learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d46823651e1476">39</a></sup>. In this experiment, participants received different motor perturbations in different contexts and learned to compensate for these perturbations. Behavioral data suggest that, after receiving feedback, participants first used the feedback to infer context and then adapted the force for the inferred context. We demonstrate that prospective configuration is able to reproduce these behavioral data, whereas backpropagation cannot.</p><p>Specifically, in the task (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5a</a>), participants were asked to move a stick from a starting point to a target point while experiencing perturbations. The participants experienced a sequence of blocks of trials (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5c–e</a>), including training, washout and testing. During the training session, different directions of perturbations, positive (+) or negative (–), were applied in different contexts, blue (B) or red (R) backgrounds, respectively. We denote these trials as B+ and R–. These trials may be associated with latent states, which we denote [B] and [R]; for example, the latent state [B] may be associated with both background B and perturbation +. The next stage of the task was designed to investigate if the latent state [B] can be activated by perturbation + even if no background B is shown. Thus, participants experienced different trials including R+ (that is, perturbation + but no background B). Specifically, after a washout session (during which no perturbation was provided), in the testing session, participants experienced one of the four possible test trials: B+, R+, B– and R–. To evaluate learning on the test trials, motor adaptation (that is, the difference between the final and target stick positions) was measured before and after the test trial in two trials with the blue background (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5e</a>). Change in the adaptation between these two trials is a reflection of learning about blue context that occurred at the test trial. If participants only associated feedback with the background color (B), then the change in adaptation would only occur with test trials B+ and B–. However, experimental data (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5f</a>) show that there was also substantial adaptation change with R+ trials (which was even bigger than with B– trials).</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Prospective configuration explains contextual inference in human sensorimotor learning."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Prospective configuration explains contextual inference in human sensorimotor learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig5_HTML.png?as=webp"><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="297"></picture></a></div><div data-test="bottom-caption" id="figure-5-desc"><p><b>a</b>, Structure of an experimental trial where participants were asked to move a stick from the starting point to the target point while experiencing perturbations. <b>b</b>, The minimal network for the task, including six connections encoding the associations from the backgrounds (B and R) to the belief of contexts ([B] and [R]) and from the belief of contexts to the prediction of perturbations (+ and –). <b>c</b>–<b>e</b>, Sequence of sessions the participants experienced, including training (<b>c</b>), washout (<b>d</b>) and testing (<b>e</b>). Darker gray boxes show the expected network after the session, where thickness represents the strength of connections. In the testing session, the darker box explains how the two learning rules learn differently on the R+ trial, leading to the differences in <b>f</b>. <b>f</b>, Predictions of the two learning rules compared to behavioral data measured from human participants, where prospective configuration reproduces the key patterns of data, but backpropagation does not. Each experiment was repeated with <i>n</i> = 24 random seeds, as there were 24 participants in the behavioral experiment.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>To model learning in this task, we considered a neural network (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5b</a>) where input nodes encode the background color, and outputs encode movement compensations in the two directions. Importantly, this network also includes hidden neurons encoding belief of being in the contexts associated with the two backgrounds ([B] and [R]). Trained with the exact procedure of the experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d46823651e1555">39</a></sup> from randomly initialized weights, prospective configuration with this minimal network can reproduce the behavioral data, whereas backpropagation cannot (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5f</a>).</p><p>Prospective configuration can produce change in adaptation with the R+ test trial because after + feedback, it is able to also activate context [B] that was associated with this feedback during training and then learn compensation for this latent state. To shed light on how this inference takes place in the model, schematics in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5c,d</a> show evolution of the weights of the network over sessions (thickness represents the strength of connections). The schematic in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5e</a> shows the difference between the two learning rules after exposure to R+; although B is not perceived, prospective configuration infers a moderate excitation of the belief of blue context [B] because the positive connection from [B] to + was built during the training session. The activity of [B] enables the learning of weights from [B] to + and –, while backpropagation does not modify any weights originating from [B].</p><p>For simplicity of explanation, we presented simulations with minimal networks; however, Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">8</a> shows that networks with a general fully connected structure and more hidden neurons can replicate the above data when using prospective configuration but not when using backpropagation.</p><p>Studies of animal conditioning have also observed that feedback in learning tasks involving multiple stimuli may trigger learning about non-presented stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Kaufman, M. A. &amp; Bolles, R. C. A nonassociative aspect of overshadowing. Bull. Psychonomic Soc. 18, 318–320 (1981)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR41" id="ref-link-section-d46823651e1581">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Matzel, L. D., Schachtman, T. R. &amp; Miller, R. R. Recovery of an overshadowed association achieved by extinction of the overshadowing stimulus. Learn. Motiv. 16, 398–412 (1985)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR42" id="ref-link-section-d46823651e1584">42</a></sup>. One example is provided in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">9</a>, where we show that it can be explained by prospective configuration but not by backpropagation.</p><h3 id="Sec8">Evidence for prospective configuration: discovering task structure during learning</h3><p>Prospective configuration is also able to discover the underlying task structure in reinforcement learning. Specifically, we consider a task where reward probabilities of different options were not independent<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e1599">38</a></sup>. In this study, humans were choosing between two options where the reward probabilities were constrained such that one option had a higher reward probability than the other (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6a</a>). Occasionally the reward probabilities were swapped, so if one probability was increased, the other was decreased by the same amount. Remarkably, the recorded functional magnetic resonance imaging (fMRI) data suggested that participants learned that the values of the two options were negatively correlated and on each trial updated the value estimates of both options in opposite ways. This conclusion was drawn from analysis of the signal from the medial prefrontal cortex (mPFC), which encoded the expected value of reward. The data presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6c</a> compare this signal after making a choice on two consecutive trials: a trial in which the reward was not received (‘punish trial’) and the next trial. If the participant selected the same option on both trials (‘stay’), the signal decreased, indicating that the reward expected by the participant was reduced. Remarkably, if the participant selected the other option on the next trial (‘switch’), the signal increased, suggesting that negative feedback for one option increased the value estimate for the other. Such learning is not predicted by standard reinforcement learning models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e1609">38</a></sup>.</p><div data-test="figure" data-container-section="figure" id="figure-6" data-title="Prospective configuration can discover the underlying task structure during reinforcement learning."><figure><figcaption><b id="Fig6" data-test="figure-caption-text">Fig. 6: Prospective configuration can discover the underlying task structure during reinforcement learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig6_HTML.png?as=webp"><img aria-describedby="Fig6" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="110"></picture></a></div><div data-test="bottom-caption" id="figure-6-desc"><p><b>a</b>, Reinforcement learning task. Human participants were required to choose between two options, leading to either reward (gaining coins) or punishment (losing coins) with different probabilities. The probability of reward was occasionally reversed between the two options. <b>b</b>, The minimal network encoding the essential elements of the task. <b>c</b>, Activity of the output neuron corresponding to the selected option from networks trained with prospective configuration and backpropagation compared with fMRI data measured in human participants (that is, peak blood oxygenation level-dependent (%BOLD) signal in the mPFC). Prospective configuration reproduces the key finding that the expected value (encoded in %BOLD signal in the mPFC) increases if the next choice after a punishing trial is to switch to the other option. The number of trials is not mentioned in the original paper, so we simulated for <i>n</i> = 128 trials for both learning rules. Error bars represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><p><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="https://www.nature.com/articles/s41593-023-01514-1/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span></a></p></figure></div><p>This task can be conceptualized as having a latent state encoding which option is superior, and this latent state determines the reward probabilities for both options. Consequently, we consider a neural network reflecting this structure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6b</a>) that includes an input neuron encoding being in the task (equal to 1 in simulations), a hidden neuron encoding the latent state and two output neurons encoding the reward probabilities for the two options. Trained with the exact procedure of the experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e1654">38</a></sup> from randomly initialized weights, prospective configuration with this minimal network can reproduce the data, whereas backpropagation cannot (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6c</a>). In Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">10</a>, we show that prospective configuration reproduces these data because it can infer the rewarded choice by updating the activity of the hidden neuron based on feedback.</p><p>Taken together, the presented simulations illustrate that prospective configuration is a common principle that can explain a range of surprising learning effects in diverse tasks.</p></div></div><div id="Sec9-section" data-title="Discussion"><h2 id="Sec9">Discussion</h2><div id="Sec9-content"><p>Our paper identifies the principle of prospective configuration, according to which learning relies on neurons first optimizing their pattern of activity to match the correct output and then reinforcing these prospective activities through synaptic plasticity. Although it was known that in energy-based networks the activity of neurons shifts before weight update, it has been previously thought that this shift is a necessary cost of error propagation in biological networks, and several methods have been proposed to suppress it<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d46823651e1676">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e1679">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e1682">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. Neural Comput. 34, 1329–1368 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR20" id="ref-link-section-d46823651e1685">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1510.02777
                  
                 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR21" id="ref-link-section-d46823651e1688">21</a></sup> to approximate backpropagation more closely. By contrast, we demonstrate that this reconfiguration of neural activity is the key to achieving learning performance superior to that of backpropagation and to explaining experimental data from diverse learning tasks. Prospective configuration further offers a range of experimental predictions distinct from those of backpropagation (Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">11</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">12</a>). Together, we have demonstrated that prospective configuration enables more efficient learning than backpropagation by reducing interference, demonstrates superior performance in situations faced by biological organisms, requires only local computation and plasticity and matches experimental data across a wide range of tasks.</p><p>Our theory addresses a long-standing question of how the brain solves the plasticity-stability dilemma, for example, how it is possible that, despite adjustment of representation in the primary visual cortex during learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Poort, J. et al. Learning enhances sensory and multiple non-sensory representations in primary visual cortex. Neuron 86, 1478–1490 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR43" id="ref-link-section-d46823651e1701">43</a></sup>, we can still understand the meaning of visual stimuli we learned over our lifetime. According to prospective configuration, when some weights are modified, compensatory changes are made to other weights to ensure the stability of correctly predicted outputs. Thus, prospective configuration reduces interference between different weight modifications while learning a single association. Previous computational models have proposed mechanisms that reduce interference between new and previously acquired information while learning multiple associations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In Proc. 34th International Conference on Machine Learning (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR34" id="ref-link-section-d46823651e1705">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol. Rev. 102, 419–457 (1995)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR44" id="ref-link-section-d46823651e1708">44</a></sup>. It is highly likely that such mechanisms and prospective configuration operate in the brain in parallel to minimize both types of interference.</p><p>Prospective configuration is related to inference and learning procedures in statistical modeling. If the ‘energy’ in energy-based schemes is variational free energy, prospective configuration can be seen as an implementation of variational Bayes that subsumes inference and learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Dauwels, J. On variational message passing on factor graphs. In 2007 IEEE International Symposium on Information Theory, 2546–2550 (IEEE, 2007)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR45" id="ref-link-section-d46823651e1715">45</a></sup>. For example, dynamic expectation maximization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Anil Meera, A. &amp; Wisse, M. Dynamic expectation maximization algorithm for estimation of linear systems with colored noise. Entropy 23, 1306 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR46" id="ref-link-section-d46823651e1719">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Friston, K. Hierarchical models in the brain. PLoS Comput. Biol. 4, e1000211 (2008)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR47" id="ref-link-section-d46823651e1722">47</a></sup> can be regarded as a generalization of predictive coding networks in which the D-step optimizes representations of latent states (analogously to relaxation until convergence during inference) while the E-step optimizes model parameters (analogously to weight modification during learning).</p><p>Other recent work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Meulemans, A., Farinha, M. T., Cervera, M. R., Sacramento, J. &amp; Grewe, B. F. Minimizing control for credit assignment with strong feedback. In Proc. of Machine Learning Research (eds Chaudhuri, K. et al.) 15458–15483 (PMLR, 2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR48" id="ref-link-section-d46823651e1729">48</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. Adv. Neural Inf. Process. Syst. 35, 33603–33617 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR49" id="ref-link-section-d46823651e1732">49</a></sup> also noticed that the natural form of energy-based networks (‘strong control’ in their words) performs different learning than backpropagation. Their analysis concentrates on an architecture of deep feedback control, and they demonstrated that a particular form of their model is equivalent to predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. Adv. Neural Inf. Process. Syst. 35, 33603–33617 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR49" id="ref-link-section-d46823651e1736">49</a></sup>. The unique contribution of our paper is to show the benefits of such strong control and explain why they arise. The principle of prospective configuration is also present in other recent models. For example, Gilra and Gerstner<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Gilra, A. &amp; Gerstner, W. Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network. eLife 6, e28295 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR50" id="ref-link-section-d46823651e1740">50</a></sup> developed a spiking model in which feedback about the error on the output directly affects the activity of hidden neurons before plasticity takes place. Haider et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d46823651e1744">51</a></sup> developed a faster inference algorithm for energy-based models that computes a value to which the activity is likely to converge, termed latent equilibrium<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d46823651e1748">51</a></sup>. Iteratively setting each neuron’s output based on its latent equilibrium leads to much faster inference<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d46823651e1753">51</a></sup> and enables efficient computation of the prospective configuration.</p><p>Predictive coding networks require symmetric forward and backward weights between layers of neurons, so a question arises concerning how such symmetry may develop in the brain. If predictive coding networks are initialized with symmetric weights (as in our simulations), the symmetry will persist because the changes in weight between neurons A and B are the same as those for feedback weight (between neurons B and A). Even if the weights are not initialized symmetrically, the symmetry may develop if synaptic decay is included in the model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Akrout, M., Wilson, C., Humphreys, P., Lillicrap, T. &amp; Tweed, D. B. Deep learning without weight transport. In Advances in Neural Information Processing Systems (NeurIPS) (eds Wallach, H. et al.) (Curran Associates, 2019)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR52" id="ref-link-section-d46823651e1761">52</a></sup> because then the initial asymmetric values decay away, and weight values become more influenced by recent changes that are symmetric. Nevertheless, weight symmetry is not generally required for effective credit assignment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Lillicrap, T. P., Cownden, D., Tweed, D. B. &amp; Akerman, C. J. Random synaptic feedback weights support error backpropagation for deep learning. Nat. Commun. 7, 13276 (2016)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR53" id="ref-link-section-d46823651e1765">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Relaxing the constraints on predictive coding models. Preprint at 
                  https://doi.org/10.48550/arXiv.2010.01047
                  
                 (2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR54" id="ref-link-section-d46823651e1768">54</a></sup>.</p><p>Here, we assumed for simplicity that the convergence of neural activity to an equilibrium happens rapidly after the stimuli are provided so that the synaptic weight modification after convergence may take place while the stimuli are still present. Nevertheless, predictive coding networks can still work even if weight modification takes place while the neural activity is converging. Specifically, Song et al. demonstrated that if neural activities are only updated for the first few steps, the update of the weights is equivalent to that in backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e1775">14</a></sup>. As a reminder, we demonstrate here that if the neural activities are updated to equilibrium, the update of the weights follows the principle of prospective configuration and possesses the desirable demonstrated properties. Thus, a learning rule where neural activities and weights are updated in parallel will experience a weight update that is equivalent to backpropagation at the start and then move to prospective configuration as the system converges to equilibrium<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at 
                  https://doi.org/10.48550/arXiv.2212.00720
                  
                 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR55" id="ref-link-section-d46823651e1779">55</a></sup>. Furthermore, predictive coding networks have been extended to describe recurrent structures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Friston, K. J., Trujillo-Barreto, N. &amp; Daunizeau, J. Dem: a variational treatment of dynamic systems. NeuroImage 41, 849–885 (2008)." href="#ref-CR56" id="ref-link-section-d46823651e1783">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.05.15.540906
                  
                 (2023)." href="#ref-CR57" id="ref-link-section-d46823651e1783_1">57</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR58" id="ref-link-section-d46823651e1786">58</a></sup>, and it has been shown that such networks can learn to predict dynamically changing stimuli even if weights are modified before the activity converged for a given ‘frame’ of the stimulus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.05.15.540906
                  
                 (2023)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR57" id="ref-link-section-d46823651e1790">57</a></sup>.</p><p>The advantages of prospective configuration suggest that it may be profitably applied in machine learning to improve the efficiency and performance of deep neural networks. An obstacle for this is that the relaxation phase is computationally expensive. However, recent work demonstrated that by modifying weights after each step of relaxation, the model becomes comparably fast to backpropagation and easier for parallelization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at 
                  https://doi.org/10.48550/arXiv.2212.00720
                  
                 (2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR55" id="ref-link-section-d46823651e1797">55</a></sup>.</p><p>Most intriguingly, it has been demonstrated that the speed of energy-based networks can be greatly increased by implementing the relaxation on analog hardware<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Foroushani, A. N., Assaf, H., Noshahr, F. H., Savaria, Y. &amp; Sawan, M. Analog circuits to accelerate the relaxation process in the equilibrium propagation algorithm. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) 1–5 (IEEE, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR59" id="ref-link-section-d46823651e1804">59</a></sup>, potentially resulting in energy-based networks being faster than backpropagation. Therefore, we anticipate that our discoveries may change the blueprint of next-generation machine learning hardware, switching from the current digital tensor base to analog hardware and being closer to the brain and potentially far more efficient.</p></div></div><div id="Sec10-section" data-title="Methods"><h2 id="Sec10">Methods</h2><div id="Sec10-content"><p>This section provides the necessary details for replication of the results described in the main text.</p><h3 id="Sec11">Models</h3><p>Throughout this work, we compare the established theory of backpropagation to the proposed new principle of prospective configuration. As explained in the main text, backpropagation is used to train ANNs, where the activity of a neuron is fixed to a value based on its input, whereas prospective configuration occurs in energy-based networks, where the activity of a neuron is not fixed.</p><p>Because in ANNs the activity of neurons <b><i>x</i></b> is determined by their input, the output of the network can be obtained by propagating the inputs ‘forward’ through the computational graph. The output can then be compared to a target pattern to get a measure of difference known as a loss. Because the value of a node (activity of a neuron) in the computational graph is explicitly computed as a function of its input, the computational graph is usually differentiable. Thus, training ANNs with backpropagation modifies the weights <b><i>w</i></b> to take a step toward the negative gradient of loss <span>\({{{\mathcal{L}}}}\)</span>,</p><div id="Equ1"><p><span>$${{\Delta }}{{{\boldsymbol{w}}}}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{\boldsymbol{w}}}}},$$</span></p><p>
                    (1)
                </p></div><p>during which the activities of neurons <b><i>x</i></b> are fixed, and <i>α</i> is the learning rate. The weights <b><i>w</i></b> requiring modification might be many steps away from the output on the computational graph, where the loss <span>\({{{\mathcal{L}}}}\)</span> is computed; thus, <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{\boldsymbol{w}}}}}\)</span> is often obtained by applying the chain rule of computing a derivative through intermediate variables (activity of output and hidden neurons). For example, consider a network with four layers, and let <b><i>x</i></b><sup><i>l</i></sup> denote the activity of neurons in layer <i>l</i> and <b><i>w</i></b><sup><i>l</i></sup> denote the weights of connections between layers <i>l</i> and <i>l</i> + 1. The change in weights originating from the first layer is then computed: <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{w}}}}}^{1}}=\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{4}}\cdot \frac{\partial {{{{\boldsymbol{x}}}}}^{4}}{\partial {{{{\boldsymbol{x}}}}}^{3}}\ldots \frac{\partial {{{{\boldsymbol{x}}}}}^{2}}{\partial {{{{\boldsymbol{w}}}}}^{1}}\)</span>. This enables the loss to be backpropagated through the graph to provide a direction of update for all weights.</p><p>In contrast to ANNs, in energy-based networks, the activity of neurons <b><i>x</i></b> is not fixed to the input from a previous layer. Instead, an energy function <i>E</i> is defined as a function of the neural activity <b><i>x</i></b> and weights <b><i>w</i></b>. For networks organized in layers (considered in this paper), the energy can be decomposed into a sum of local energy terms <i>E</i><sup><i>l</i></sup>,</p><div id="Equ2"><p><span>$$E=\mathop{\sum}\limits_{l}{E}^{l}\left({{{{\boldsymbol{x}}}}}^{l},{{{{\boldsymbol{w}}}}}^{l-1},{{{{\boldsymbol{x}}}}}^{l-1}\right).$$</span></p><p>
                    (2)
                </p></div><p>Here, <i>E</i><sup><i>l</i></sup> is called local energy because it is a function of <b><i>x</i></b><sup><i>l</i></sup>, <b><i>x</i></b><sup><i>l</i> − 1</sup> and <b><i>w</i></b><sup><i>l</i> − 1</sup>, which are neighbors and connected to each other. This ensures that the optimization of energy <i>E</i> can be implemented by local circuits because the derivative of <i>E</i> with respect to any neural activity (or weights) results in an equation containing only the local activity (or weights) and the activity of adjacent neurons. Predictions with energy-based networks are computed by clamping the input neurons to an input pattern and then modifying the activity of all other neurons to decrease the energy:</p><div id="Equ3"><p><span>$${{\Delta }}{{{\boldsymbol{x}}}}=-\gamma \frac{\partial E}{\partial {{{\boldsymbol{x}}}}},$$</span></p><p>
                    (3)
                </p></div><p>where <i>γ</i> is the integration step of the neural dynamics. Because the terms in <i>E</i> can be divided into local energy terms, this results in an equation that can be implemented with local circuits. This process of modifying neural activity to decrease the energy is called relaxation, and we refer to the equation describing relaxation as neural dynamics because it describes the dynamics of the neural activity in energy-based networks. After convergence of relaxation, the activities of the output neurons are taken as the prediction made by the energy-based network. Different energy-based networks are trained in slightly different ways. For predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e2383">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e2386">18</a></sup>, training involves clamping the input and output neurons to input and target patterns, respectively. Then, relaxation is run until convergence (<span>\({{{\boldsymbol{x}}}}=\mathop{{{{\boldsymbol{x}}}}}\limits^{* }\)</span>), after which the weights are updated using the activity at convergence to further decrease the energy:</p><div id="Equ4"><p><span>$${\Delta }{\boldsymbol{w}}=-\alpha \frac{\partial E}{\partial {\boldsymbol{w}}}{\vert }_{{\boldsymbol{x}} = \mathop{\boldsymbol{x}}\limits^{*}}.$$</span></p><p>
                    (4)
                </p></div><p>This will also result in an equation that can be implemented with local plasticity because it is just a gradient descent on the local energy. We refer to such an equation as weight dynamics, because it describes the dynamics of the weights in energy-based networks.</p><p>Backpropagation and prospective configuration are not restricted to specific models. Depending on the structure of the network and the choice of the energy function, one can define different models that implement the principle of backpropagation or prospective configuration. In the main text and most of the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, we investigate the most standard layered network. In this case, both ANNs and energy-based networks include <i>L</i> layers of weights <b><i>w</i></b><sup>1</sup>, <b><i>w</i></b><sup>2</sup>, …, <b><i>w</i></b><sup><i>L</i></sup> and <i>L</i> + 1 layers of neurons <b><i>x</i></b><sup>1</sup>, <b><i>x</i></b><sup>2</sup>, …, <b><i>x</i></b><sup><i>L</i> + 1</sup>, where <b><i>x</i></b><sup>1</sup> and <b><i>x</i></b><sup><i>L</i> + 1</sup> are the input and output neurons, respectively. We consider the relationship between activities in adjacent layers for ANNs given by</p><div id="Equ5"><p><span>$${{{{\boldsymbol{x}}}}}^{l}={{{{\boldsymbol{w}}}}}^{l-1}f\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right),$$</span></p><p>
                    (5)
                </p></div><p>and the energy function for EBNs described by</p><div id="Equ6"><p><span>$${E}^{l}=\frac{1}{2}{\left({{{{\boldsymbol{x}}}}}^{l}-{{{{\boldsymbol{w}}}}}^{l-1}f\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\right)}^{2}.$$</span></p><p>
                    (6)
                </p></div><p>This defines the ANNs to be the standard multilayer perceptrons (MLPs) and the energy-based networks to be the predictive coding network. In Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ6">6</a>) and below, the square operator (<b><i>v</i></b>)<sup>2</sup> denotes the inner product of vector <b><i>v</i></b> with itself. The comparison between backpropagation and prospective configuration in the main text is thus between the above MLPs and predictive coding networks; this choice is justified as (1) they are the most standard models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Goodfellow, I., Bengio, Y. &amp; Courville, A. Deep Learning (MIT Press Cambridge, 2016)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR61" id="ref-link-section-d46823651e2788">61</a></sup> and (2) it is established that the two are closely related<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e2793">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d46823651e2796">14</a></sup> (that is, they make the same prediction with the same weights and input pattern), thus enabling a fair comparison. Nevertheless, we show that the theory (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">5</a>) and empirical comparison (Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">6</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">7</a>) between backpropagation and prospective configuration generalize to other choices of network structures and energy functions, that is, other energy-based networks and ANNs, such as GeneRec<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. Neural Comput. 8, 895–938 (1996)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR62" id="ref-link-section-d46823651e2809">62</a></sup> and Almeida–Pineda<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In Artificial Neural Networks: Concept Learning (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990)." href="#ref-CR63" id="ref-link-section-d46823651e2813">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (ed. Anderson, D.) 602–611 (Curran Associates, 1987)." href="#ref-CR64" id="ref-link-section-d46823651e2813_1">64</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Pineda, F. J. Dynamics and architecture for neural computation. J. Complex. 4, 216–245 (1988)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR65" id="ref-link-section-d46823651e2816">65</a></sup>.</p><p>Putting Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ5">5</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ6">6</a>) into the general framework, we can obtain the equations that describe MLPs and predictive coding networks, respectively. Assume that the input and target patterns are <b><i>s</i></b><sup>in</sup> and <b><i>s</i></b><sup>target</sup>, respectively. Prediction with MLPs is</p><div id="Equ7"><p><span>$${{{{\boldsymbol{x}}}}}^{1}={{{{\boldsymbol{s}}}}}^{{{{\rm{in}}}}}\,{{{\rm{and}}}}\,{{{{\boldsymbol{x}}}}}^{l}={{{{\boldsymbol{w}}}}}^{l-1}{f}\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right){{{\rm{for}}}}\,l &gt; 1,$$</span></p><p>
                    (7)
                </p></div><p>where <b><i>x</i></b><sup><i>L</i> + 1</sup> is the prediction. Training MLPs with backpropagation is described by</p><div id="Equ8"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{w}}}}}^{l}}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{L+1}}\cdot \frac{\partial {{{{\boldsymbol{x}}}}}^{L+1}}{\partial {{{{\boldsymbol{x}}}}}^{L}}\ldots \frac{\partial {{{{\boldsymbol{x}}}}}^{l+1}}{\partial {{{{\boldsymbol{w}}}}}^{l}}\,{{{\rm{where}}}}\,\,{{{\mathcal{L}}}}=\frac{1}{2}{\left({{{{\boldsymbol{s}}}}}^{{{{\rm{target}}}}}-{{{{\boldsymbol{x}}}}}^{L+1}\right)}^{2},$$</span></p><p>
                    (8)
                </p></div><p>which backpropagates the error <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{l}}\)</span> layer by layer from output neurons.</p><p>The neural dynamics of predictive coding networks can be obtained using Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ2">2</a>):</p><div id="Equ9"><p><span>$${{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma \frac{\partial E}{\partial {{{{\boldsymbol{x}}}}}^{l}}=-\gamma \frac{\partial ({E}^{l}+{E}^{l+1})}{\partial {{{{\boldsymbol{x}}}}}^{l}}.$$</span></p><p>
                    (9)
                </p></div><p>Similarly, the weight dynamics of predictive coding networks can be found,</p><div id="Equ10"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=-\alpha \frac{\partial E}{\partial {{{{\boldsymbol{w}}}}}^{l}}=-\alpha \frac{\partial {E}^{l+1}}{\partial {{{{\boldsymbol{w}}}}}^{l}}.$$</span></p><p>
                    (10)
                </p></div><p>To reveal the neural implementation of predictive coding networks, we define the prediction errors to be</p><div id="Equ11"><p><span>$${{{{\boldsymbol{\varepsilon }}}}}^{l}={{{{\boldsymbol{x}}}}}^{l}-{{{{\boldsymbol{w}}}}}^{l-1}{f}\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right).$$</span></p><p>
                    (11)
                </p></div><p>The neural and weight dynamics of predictive coding networks can be expressed (by evaluating derivatives in Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ9">9</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ10">10</a>)) as</p><div id="Equ12"><p><span>$${{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma {{{{\boldsymbol{\varepsilon }}}}}^{l}+{f}^{{\prime} }\left({{{{\boldsymbol{x}}}}}^{l}\right)\circ {\left({{{{\boldsymbol{w}}}}}^{l}\right)}^{T}{{{{\boldsymbol{\varepsilon }}}}}^{l+1}\,{\mathrm{and}}$$</span></p><p>
                    (12)
                </p></div><div id="Equ13"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=\alpha {{{{\boldsymbol{\varepsilon }}}}}^{l+1}{\left({f}\left({{{{\boldsymbol{x}}}}}^{l}\right)\right)}^{T},$$</span></p><p>
                    (13)
                </p></div><p>where the symbol <span>∘</span> denotes element-wise multiplication. Assuming that <b><i>ε</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup> are encoded in the activity of error and value neurons, respectively, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ11">11</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ12">12</a>) can be realized with the neural implementation in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2c</a>. In particular, error <b><i>ε</i></b> and value <b><i>x</i></b> neurons are represented by red and blue nodes, respectively; excitatory + and inhibitory − connections are represented by connections with solid and hollow nodes, respectively. Thus, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ11">11</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ12">12</a>) are implemented with red and blue connections, respectively. It should also be noted that the weight dynamics are also realized locally. The weight change described by Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ13">13</a>) corresponds to simple Hebbian plasticity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Hebb, D. O. The Organisation of Behaviour: A Neuropsychological Theory (Science Editions New York, 1949)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR66" id="ref-link-section-d46823651e3996">66</a></sup> in the neural implementation of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig2">2c</a>; that is, the change in a weight is proportional to the product of activity of presynaptic and postsynaptic neurons. Thus, a predictive coding network, as an energy-based network, can be implemented with local circuits only due to the local nature of energy terms (as argued earlier in this section). Note that when the network is expressive enough such that learning can reduce the energy <i>E</i> to 0, the loss <span>\({{{\mathcal{L}}}}\)</span> must also become 0 as <span>\({{{\mathcal{L}}}}\)</span> is one of the terms in energy <i>E</i>, that is <span>\({{{\mathcal{L}}}}={E}^{L+1}\)</span>, and, in this case, the predictive coding network is guaranteed to minimize the loss, just like backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Senn, W. et al. A neuronal least-action principle for real-time learning in cortical circuits. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.03.25.534198
                  
                 (2023)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR67" id="ref-link-section-d46823651e4087">67</a></sup>.</p><p>The full algorithm of the predictive coding network is summarized in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="https://www.nature.com/articles/s41593-023-01514-1#FPar1">1</a>. In all simulations in this paper (unless stated otherwise), the integration step of the neural dynamics (that is, relaxation) is set to <i>γ</i> = 0.1, and the relaxation is performed for 128 steps (<span>\({{{\mathcal{T}}}}\)</span> in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="https://www.nature.com/articles/s41593-023-01514-1#FPar1">1</a>). During relaxation, if the overall energy is not decreased from the last step, the integration step is reduced by 50%; if the integration step is reduced two times (that is, reaching 0.025), relaxation is terminated early. By monitoring the number of relaxation steps performed, we notice that in most of the tasks we performed, relaxation is terminated early at around 60 iterations.</p>
                  <h3 id="FPar1">Algorithm 1</h3>
                  <p>Learn with a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e4128">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e4131">18</a></sup> <img src="https://media.springernature.com/lw684/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Figa_HTML.png" alt=""></p>
                <p>In the Supplementary <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Information</a>, we also investigate other choices of network structures and energy functions, resulting in other ANNs and energy-based networks. Overall, the energy-based networks investigated include predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d46823651e4146">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d46823651e4149">18</a></sup>, target predictive coding networks and GeneRec<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. Neural Comput. 8, 895–938 (1996)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR62" id="ref-link-section-d46823651e4153">62</a></sup>, and the ANNs investigated include backpropagation and Almeida–Pineda<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In Artificial Neural Networks: Concept Learning (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990)." href="#ref-CR63" id="ref-link-section-d46823651e4157">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (ed. Anderson, D.) 602–611 (Curran Associates, 1987)." href="#ref-CR64" id="ref-link-section-d46823651e4157_1">64</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Pineda, F. J. Dynamics and architecture for neural computation. J. Complex. 4, 216–245 (1988)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR65" id="ref-link-section-d46823651e4160">65</a></sup>. Details of all the models can be found in corresponding previous work and are also given in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.1.</p><h3 id="Sec12">Interference and measuring interference (that is, target alignment)</h3><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3a</a>, because it simulates the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig1">1</a>, the network has one input neuron, one hidden neuron and two output neurons; weights were all initialized to 1, the input pattern was <span>\(\left[1\right]\)</span>, and the target pattern was <span>\(\left[0,1\right]\)</span>. Learning rates of both learning rules were 0.2, and the weights were updated for 24 iterations. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3d</a> repeated the same experiment as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3a</a> but with the learning rate searched from <span>\(\left(0.005,0.01,0.05,0.1\right)\)</span>, which is wide enough to cover essentially all learning rates used to train deep neural networks in practice.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3e</a>, there were 64 neurons in each layer (including input and output layers) for each network; weights were initialized via standard Xavier uniform initialization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proc. 13th International Conference on Artificial Intelligence and Statistics (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR68" id="ref-link-section-d46823651e4280">68</a></sup>. No activation function was used, that is, linear networks were investigated. Depths of networks (<i>L</i>) took values from <span>\(\left\{1,2,\ldots ,24,25\right\}\)</span>, as reported on the <i>x</i> axis. Input and target patterns were a pair of randomly generated patterns with a mean of 0 and standard deviation (s.d.) of 1. Learning rates of both learning rules were 0.001. Weights were updated for one iteration, and target alignment was measured. The whole experiment was repeated 27 times with each individual experiment reported as a point.</p><p>Simulations in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f–h</a> followed the experimental setup in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4a–h</a>; these are described at the end of <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec13">Biologically relevant tasks</a>.</p><h3 id="Sec13">Biologically relevant tasks</h3><p>In supervised learning simulations, fully connected networks in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4a–h</a> were trained and tested on FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e4353">60</a></sup>, and convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d46823651e4357">35</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4i,j</a>) were trained and tested on CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d46823651e4364">36</a></sup>). With FashionMNIST, models were trained to perform classification of gray-scaled fashion item images into ten categories, such as trousers, pullovers and dresses. FashionMNIST was chosen because it is of moderate and appropriate difficulty for multilayer non-linear deep neural networks so that the comparisons with energy-based networks are informative. Classification of the data in CIFAR-10 is more difficult, as it contains colored natural images belonging to categories such as cars, birds and cats and is thus only evaluated with convolutional neural networks. Both datasets consist of 60,000 training examples (that is, training set) and 10,000 test examples (that is, test set).</p><p>The experiments in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4a–h</a> followed the configurations described below, except for the parameters investigated in specific panels (such as batch size, size of the dataset and size of the architecture), which were adjusted as stated in the descriptions of the specific experiments. The neural network was composed of four layers and 32 hidden neurons in each hidden layer. Note that the state-of-the-art MLP models of FashionMNIST are all quite large<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Tolstikhin, I. O. et al. Mlp-mixer: an all-mlp architecture for vision. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 24261–24272 (Curran Associates, 2021)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR69" id="ref-link-section-d46823651e4374">69</a></sup>. However, they are highly overparameterized and thus are not suitable to base our comparison on because the accuracy reaches more than 95% regardless of the learning rule due to the overparameterization. Thus, there was no space for demonstrating any meaningful comparison in these state-of-the-art overparameterized models. Overall, the size of the model on FashionMNIST demonstrated in this paper was a reasonable choice, with baseline models reaching reasonable performance (~0.12 test error for the standard machine learning setup) while maintaining enough room for demonstrating performance differences for different learning rules. The size of the input layer was 28 × 28 for FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e4378">60</a></sup> gray scaled, and the size of the output layer was ten as the number of classes for both datasets. The weights were initialized from a normal distribution with a mean of 0 and s.d. of <span>\(\sqrt{\frac{2}{{n}^{l}+{n}^{l+1}}}\)</span>, where <i>n</i><sup><i>l</i></sup> and <i>n</i><sup><i>l</i> + 1</sup> are the numbers of neurons in the layer before and after the weight, respectively. This initialization is known as Xavier normal initialization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proc. 13th International Conference on Artificial Intelligence and Statistics (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR68" id="ref-link-section-d46823651e4460">68</a></sup>. The activation function <span>\({f}\,\left(\right)\)</span> is sigmoid. We defined one iteration as updating the weights for one step based on a minibatch. Each iteration contained (1) a numerical integration procedure of relaxation of energy-based networks, which captures its continuous process; and (2) one update of weights at the end of the above procedure. The number of examples in a minibatch, called the batch size, was by default 32. One epoch comprised presenting the entire training set split over multiple minibatches. At the end of each epoch, the model was tested on the test set, and the classification error was recorded as the ‘test error’ of the epoch. The neural network was trained for 64 epochs, thus yielding 64 test errors. The mean of the test error over epochs, that is, during training progress, is an indicator of how fast the model learns, and the minimum of the test errors over epochs is an indicator of how well the model can learn, ignoring the possibility of overfitting due to training for too long. Learning rates were optimized independently for each configuration and each model. Each experiment was repeated ten times (unless stated otherwise), and the error bars represent the 68% confidence interval computed using bootstrap.</p><p>We now describe settings specific to individual experiments. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4b</a>, different batch sizes were tested (as shown on the <i>x</i> axis). In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4c</a>, the batch size was set to 1. In continual learning of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4d</a>, training alternated between two tasks. Task 1 involved classifying five randomly selected classes in a dataset, and task 2 involved classifying the remaining five classes. The whole network was shared by the two tasks; thus, different from the network used in other panels, the network only had five output neurons. This better corresponds to continual learning with multiple tasks in nature, because, for example, if humans learn to perform two different tasks, they typically use one brain and one pair of hands (that is, the whole network is shared), as they do not have two different pairs of hands (that is, humans share the output layers across tasks). Task 1 was trained for four iterations, task 2 was trained for four iterations, and the training continued until a total of 84 iterations was reached. After each iteration, error on the test set of each task was measured as ‘test error’. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4e</a>, the mean of test error of both tasks during training of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4d</a> at different learning rates is reported. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4d–g</a> investigating concept drifting<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d46823651e4516">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Žliobaitė, I. Learning under concept drift: an overview. Preprint at 
                  https://doi.org/10.48550/arXiv.1010.4784
                  
                 (2010)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR70" id="ref-link-section-d46823651e4519">70</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 71" title="Tsymbal, A. The Problem of Concept Drift: Definitions and Related Work. Technical report, Computer Science Department, Trinity College Dublin (2004)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR71" id="ref-link-section-d46823651e4522">71</a></sup>, changes to class labels were made every 64 epochs, and the models were trained for 3,000 epochs in total. Thus, every 64 epochs, five of ten output neurons were selected, and the mapping from these five output neurons to the semantic meaning was pseudorandomly shuffled. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4h</a>, different numbers of data points per class (shown on the <i>x</i> axis) were included in the training set (subsets were randomly selected according to different seeds).</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4i</a>, we trained a convolutional network with prospective configuration and backpropagation, with the structure detailed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4j</a>. For each learning rule, we independently searched seven learning rates ranging from <span>\(\left\{0.0005,0.00025,0.0001,0.000075,0.00005,0.000025,0.00001\right\}\)</span>. Both learning rules were trained for 80 epochs, with a batch size of 200. Because training deep convolutional networks is more difficult and slower than training shallow fully connected networks, a few improvements were applied to both learning rules. Specifically, a weight decay of 0.01 and an Adam optimizer<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. 
                  https://doi.org/10.48550/arXiv.1412.6980
                  
                 (2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR72" id="ref-link-section-d46823651e4590">72</a></sup> were applied for both learning rules. To reduce running time, the weights were updated more frequently in predictive coding networks; that is, the weights were updated at all steps of inference instead of at the last step of inference. Inference was run for a fixed number of 16 iterations; thus, weights were updated 16 times for each batch of data. Thus, for fair comparison, backpropagation also updated weights 16 times on each batch of data. Training in each configuration (each learning rule and each learning rate) was repeated three times with different seeds.</p><p>To extend a predictive coding network to a convolutional neural network (or to any network with a layered structure<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR58" id="ref-link-section-d46823651e4598">58</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R. &amp; Xu, Z. Reverse differentiation via predictive coding. In Proc. 36th AAAI Conference on Artificial Intelligence (Salvatori, T., Song, Y., Xu, Z., Lukasiewicz, T. &amp; Bogacz, R.) 8150–8158 (Curran Associates, 2022)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR73" id="ref-link-section-d46823651e4601">73</a></sup>), we can define the forward function of a layer (that is, how the input of layer <i>l</i> + 1 is computed from the neural activity of layer <i>l</i>) with weights <b><i>w</i></b><sup><i>l</i></sup> to be <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span>. For example, for the MLPs described above, <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)={{{{\boldsymbol{w}}}}}^{l}{f}\,\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span>. For a convolutional network, <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> is a more complex function of <b><i>w</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup>, and also <b><i>w</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup> are not simple matrix and vector anymore (to be defined later). Defining an ANN with <span>\({\mathcal{F}}()\)</span> would be (that is, Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ5">5</a>) becomes) <span>\({{{{\boldsymbol{x}}}}}^{l}={{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l-1}}\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\)</span>. Defining an energy function of a predictive coding network with <span>\({\mathcal{F}}()\)</span> would be (that is, Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ6">6</a>) becomes) <span>\({E}^{l}=\frac{1}{2}{\left[{{{{\boldsymbol{x}}}}}^{l}-{{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l-1}}\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\right]}^{2}\)</span>. Thus, neural and weight dynamics would be (that is, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ12">12</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ13">13</a>) become) <span>\({{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma {{{{\boldsymbol{\varepsilon }}}}}^{l}+\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{x}}}}}^{l}}{{{{\boldsymbol{\varepsilon }}}}}^{l+1}\)</span> and <span>\({{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=\alpha {{{{\boldsymbol{\varepsilon }}}}}^{l+1}\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{w}}}}}^{l}},\)</span> respectively. As <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> is defined, <span>\(\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{x}}}}}^{l}}\)</span> and <span>\(\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{w}}}}}^{l}}\)</span> are obtained via auto differentiation in PyTorch (<a href="https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html">https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html</a>). Thus, training a convolutional predictive coding network is as simple as replacing lines 11 and 16 in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="https://www.nature.com/articles/s41593-023-01514-1#FPar1">1</a> with the above corresponding equations.</p><p>In the following, we define <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> for convolutional networks. First, <span>\({{{{\boldsymbol{x}}}}}^{l}\in {{\mathbb{R}}}^{{c}_{l}\times {h}_{l}\times {w}_{l}}\)</span>, where <i>c</i><sub><i>l</i></sub>, <i>h</i><sub><i>l</i></sub> and <i>w</i><sub><i>l</i></sub> are the number of features, height and width of the feature map, respectively. The numbers for each layer are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4j</a> in the format <i>c</i><sub><i>l</i></sub><i>@</i><i>h</i><sub><i>l</i></sub> × <i>w</i><sub><i>l</i></sub>. For example, for the first layer (input layer), the shape was 3<i>@</i>32 × 32 as it is 32 × 32 colored images, that is, with three feature maps representing red, green and blue. We denote kernel size, stride and padding of this layer as <i>k</i><sub><i>l</i></sub>, <i>s</i><sub><i>l</i></sub> and <i>p</i><sub><i>l</i></sub>, respectively. The numbers for each layer are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4j</a>. Thus, <span>\({{{{\boldsymbol{w}}}}}^{l}\in {{\mathbb{R}}}^{{c}_{l+1}\times {c}_{l}\times {k}_{l}\times {k}_{l}}\)</span>. Finally, <b><i>x</i></b><sup><i>l</i> + 1</sup> is obtained via</p><div id="Equ14"><p><span>$$\begin{array}{l}{{{{\boldsymbol{x}}}}}^{\;l+1}[c,x,y]={f}\,\left({{{{\boldsymbol{x}}}}}^{\;l}\left[:,x{s}_{l}-{p}_{l}:x{s}_{l}-{p}_{l}+{k}_{l},y{s}_{l}-{p}_{l}:y{s}_{l}-{p}_{l}+{k}_{l}\right]\right)\\\cdot {{{{\boldsymbol{w}}}}}^{l}\left[c,:,:,:\right],\end{array}$$</span></p><p>
                    (14)
                </p></div><p>where <span>\(\left[a,b,\ldots \right]\)</span> means indexing the tensor along each dimension, : means all indexes at that dimension, <i>a</i>: <i>b</i> means slice of that dimension from index <i>a</i> to <i>b</i> − 1, and <span>⋅</span> is dot product. In the above equation, if the slicing of <b><i>x</i></b><sup><i>l</i></sup> on the second and third dimensions, that is, <span>\({{{{\boldsymbol{x}}}}}^{l}\left[:,x{s}_{l}-{p}_{l}:x{s}_{l}-{p}_{l}+{k}_{l},y{s}_{l}-{p}_{l}:y{s}_{l}-{p}_{l}+{k}_{l}\right]\)</span>, is outside its defined range <span>\({{\mathbb{R}}}^{{c}_{l}\times {h}_{l}\times {w}_{l}}\)</span>, the entries outside range are considered to be 0, known as padding mode of zeros.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a>, networks of 15 layers were trained and tested on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e6681">60</a></sup> dataset. Learning rates in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a> were optimized independently by a grid search over (5.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005) for each learning rule, as shown Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3g</a>; that is, each learning rule in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a> used the learning rate that gave a minimal point in the corresponding curve in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3g</a>. The experiment in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3h</a> investigated other network depths (<span>\(\left\{1,2,4,6,8,10,12,14,15\right\}\)</span>) in the same setup. Similar to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig3">3f</a>, the learning rate for each learning rule and each ‘number of layers’ was the optimal value (in terms of mean of test error as the <i>y</i> axis of the figure) independently searched from (5.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005). Hidden layers were always of size 64 in the above experiments. In the above experiment, only a part of the training set was used (60 data points per class) so that the test error was evaluated more frequently to reflect the difference on efficiency of the investigated learning rules. The activation function <span>\({f}\,\left(\right)\)</span> used is LeakyReLU instead of the standard sigmoid because sigmoid results in difficulty in training deep neural networks. Other unmentioned details followed the defaults, as described above.</p><p>In the reinforcement learning experiments (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4k</a>), we evaluated performance on three classic reinforcement learning problems: Acrobot<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Sutton, R. S. Generalization in reinforcement learning: successful examples using sparse coarse coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Touretzky, D. et al.) 1038–1044 (NIPS, 1995)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR74" id="ref-link-section-d46823651e6797">74</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 75" title="Geramifard, A., Dann, C., Klein, R. H., Dabney, W. &amp; How, J. P. RLPy: a value-function-based reinforcement learning framework for education and research. J. Mach. Learn. Res. 16, 1573–1578 (2015)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR75" id="ref-link-section-d46823651e6800">75</a></sup>, MountainCar<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 76" title="Moore, A. Efficient memory-based learning for robot control. Technical report, Carnegie Mellon Univ. (1990)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR76" id="ref-link-section-d46823651e6804">76</a></sup> and CartPole<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Barto, A. G., Sutton, R. S. &amp; Anderson, C. W. Neuronlike adaptive elements that can solve difficult learning control problems. In IEEE Transactions on Systems, Man, and Cybernetics, 834–846 (1983)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR77" id="ref-link-section-d46823651e6808">77</a></sup>. We interacted with these environments via a unified interface by OpenAI Gym<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Brockman, G. et al. OpenAI Gym. Preprint at 
                  https://doi.org/10.48550/arXiv.1606.01540
                  
                 (2016)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR78" id="ref-link-section-d46823651e6812">78</a></sup>. The observations <i>s</i><sub><i>t</i></sub> of these environments are vectors describing the status of the system, such as velocities and positions of different moving parts (for details, refer to the original articles or documentation from OpenAI Gym). Each entry of the observation <i>s</i><sub><i>t</i></sub> is normalized to mean 0 and s.d. 1 via Welford’s online algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Welford, B. P. Note on a method for calculating corrected sums of squares and products. Technometrics 4, 419–420 (1962)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR79" id="ref-link-section-d46823651e6829">79</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Knuth, D. E. Art of Computer Programming, Vol. 2 (Addison-Wesley Professional, 2014)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR80" id="ref-link-section-d46823651e6832">80</a></sup>. The action space of these environments is discrete. Thus, we can have a network taking in observation <i>s</i><sub><i>t</i></sub> and predicting the value (<i>Q</i>) of each action <i>a</i><sub><i>t</i></sub> with different output neurons. Such a network is known as an action-value network, in short, a <i>Q</i> network. In our experiment, the <i>Q</i> network contained two hidden layers, each of which contained 64 neurons, initialized the same way as the network used for supervised learning, described before. One can acquire the value of an action <i>a</i><sub><i>t</i></sub> at a given observation <i>s</i><sub><i>t</i></sub> by feeding <i>s</i><sub><i>t</i></sub> into the <i>Q</i> network and reading out the prediction on the output neuron corresponding to the action <i>a</i><sub><i>t</i></sub>; such a value is denoted <span>\(Q\left({s}_{t},{a}_{t}\right)\)</span>. The training of <i>Q</i> is a simple regression problem to target <span>\({\hat{R}}_{t}\)</span>, obtained via <i>Q</i> learning with experience replay (summarized in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="https://www.nature.com/articles/s41593-023-01514-1#FPar2">2</a>). Considering <i>s</i><sub><i>t</i></sub> to be <b><i>s</i></b><sup>in</sup> and <span>\({\hat{R}}_{t}\)</span> to be <b><i>s</i></b><sup>target</sup>, the <i>Q</i> network can be trained with prospective configuration or backpropagation. Note that <span>\({\hat{R}}_{t}\)</span> is the target of the selected action <i>a</i><sub><i>t</i></sub> (that is, the target of one of the output neurons corresponds to the selected action <i>a</i><sub><i>t</i></sub>); thus, <span>\({\hat{R}}_{t}\)</span> is, in practice, considered to be <span>\({{{{\boldsymbol{s}}}}}^{{{{\rm{target}}}}}\left[{a}_{t}\right]\)</span>. For prospective configuration, it means that the rest of the output neurons except the one corresponding to <i>a</i><sub><i>t</i></sub> are freed; for backpropagation, it means that the error on these neurons is masked out.</p><p>A predictive coding network with slightly different settings from the defaults was used for prospective configuration. The integration step was fixed to be half of the default (<i>γ</i> = 0.05), and relaxation was performed for a fixed and smaller number of steps (<span>\({{{\mathcal{T}}}}=32\)</span>). This change was introduced because <i>Q</i> learning is more unstable (smaller integration step) and more expensive (smaller number of relaxation steps) than supervised learning tasks. To produce a smoother curve of ‘sum of rewards per episode’ in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4k</a> from <i>SumRewardPerEpisode</i> in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="https://www.nature.com/articles/s41593-023-01514-1#FPar2">2</a>, the <i>SumRewardPerEpisode</i> curve was averaged along <i>TrainingEpisode</i> with a sliding window with a length of 200. Each experiment was repeated with three random seeds, and the shadows represent 68% confidence interval across them. Learning rates were searched independently for each environment and each model from the range <span>\(\left\{0.05,0.01,0.005,0.001,0.0005,0.0001\right\}\)</span>. The results reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4k</a> are for the learning rates yielding the highest mean of ‘sum of rewards per episode’ over training episodes.</p>
                  <h3 id="FPar2">Algorithm 2</h3>
                  <p><i>Q</i> learning with experience replay <img src="https://media.springernature.com/lw684/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Figb_HTML.png" alt=""></p>
                <h3 id="Sec14">Simulation of motor learning</h3><p>As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5</a>, we trained a network that included two input neurons, two hidden neurons and two output neurons. The two input neurons were one-to-one connected to the two hidden neurons, and the two hidden neurons were fully connected to the two output neurons. The two input neurons were considered to encode presenting the blue and red background, respectively. The two output neurons were considered to encode the prediction of the perturbations toward positive and negative directions, respectively. Presenting and not presenting a background color were encoded 1 and 0, respectively; presenting and not presenting perturbations of a particular direction were encoded 1 and 0, respectively. The weights were initialized from a normal distribution with mean 0 and an s.d. fitted to the behavioral data (see below), simulating that the participants had not built any associations before the experiments. Learning rates were independent for the two layers, as we expected the connections from perception to belief and from belief to predictions to have different degrees of plasticity. The two learning rates were also fitted to the data (see below).</p><p>The number of participants and training and testing trials follow exactly as described for the human experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e7322">38</a></sup>. In particular, for each of the 24 simulated participants, the weights were initialized with a different seed of the random number generator. They each experienced two stages: training and testing. Note that the pretraining stage performed in the human experiment was not simulated here as its goal was to make human participants familiar with the setup and devices.</p><p>In the training stage, the model experienced 24 blocks of trials. In each block, the model was presented with the following sequence of trials, matching the original experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e7329">38</a></sup>:</p><ul>
                  <li>
                    <p>The model was trained with two trials without perturbation, B<sub>0</sub> and R<sub>0</sub>, with the order counterbalanced across consecutive blocks. Note that, in the human experiment, there were two trial types without perturbations (channel and washout trials), but they were simulated in the same way here as B<sub>0</sub> or R<sub>0</sub> trials because they both did not include any perturbations.</p>
                  </li>
                  <li>
                    <p>The model was trained with 32 trials with perturbations, where there were equal numbers of B+ and R– within each of the 8 trials in a pseudorandom order.</p>
                  </li>
                  <li>
                    <p>The model experienced two trials, B<sub>0</sub> and R<sub>0</sub>, with the order counterbalanced across consecutive blocks.</p>
                  </li>
                  <li>
                    <p>The model experienced <i>n</i> ← {14, 16, 18} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order), where <i>n</i> ← {<i>a</i>, <i>b</i>, <i>c</i>} denotes sampling without replacement from a set of values <i>a</i>, <i>b</i> and <i>c</i> and replenishing the set whenever it becomes empty.</p>
                  </li>
                  <li>
                    <p>The model experienced one triplet, where the exposure trial was either B+ or R–, counterbalanced across consecutive blocks. Here, a triplet consisted of three sequential trials: B<sub>0</sub>, the specified exposure trial and B<sub>0</sub> again.</p>
                  </li>
                  <li>
                    <p>The model experienced additional <i>n</i> ← {6, 8, 10} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order).</p>
                  </li>
                  <li>
                    <p>The model experienced one triplet again, where the exposure trial was either B+ or R–, whichever was not used on the previous triplet.</p>
                  </li>
                </ul><p>In the testing stage, the model then experienced eight repetitions of four blocks of trials. In each block, one of the combinations of B+, R+, B– and R– was tested. The order of the four blocks was shuffled in each of the eight repetitions. In each block, the model first experienced <i>n</i> ← {2, 4, 6} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order). The model then experienced a triplet of trials, where the exposure trial was the combination (B+, R+, B– or R–) tested in a given block to assess single-trial learning of this combination. The change in adaption in the model was computed as the absolute value of the difference in the predictions of perturbations on the two B<sub>0</sub> trials in the above triplet, where the prediction of perturbation was computed as the difference between the activities of the two output neurons. The predictions were averaged over participants and the above repetitions.</p><p>The parameters of each learning rule were chosen such that the model best reproduced the change in adaptation shown in Fig <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig5">5f</a>. In particular, we minimized the sum over set <i>C</i> of the four exposure trial types of the squared difference between average change in adaptation in experiment (<i>d</i><sub><i>c</i></sub>) and model (<i>x</i><sub><i>c</i></sub>):</p><div id="Equ15"><p><span>$$\mathop{\sum}\limits_{c\in C}{\left(a{x}_{c}-{d}_{c}\right)}^{2}.$$</span></p><p>
                    (15)
                </p></div><p>The model predictions were additionally scaled by a coefficient <i>a</i> fitted to the data because the behavioral data and model outputs had different scales. An exhaustive search was performed over model parameters. The s.d. of initial weights could take values from <span>\(\left\{0.01,0.05,0.1\right\}\)</span>, and two learning rates for two layers could take values from <span>\(\left\{0.00005,0.0001,0.0005,0.01,0.05\right\}\)</span>. For each learning rule and each combination of the above model parameters, the coefficient <i>a</i> was then resolved analytically (restricted to be positive) to minimize the sum of the squared errors of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ15">15</a>).</p><h3 id="Sec15">Simulation of human reinforcement learning</h3><p>As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6b</a>, we trained a network that included one input neuron, one hidden neuron and two output neurons. The input neuron was considered to encode being in the task, so it was set to 1 throughout the simulation. The two output neurons encoded the prediction of the value of the two choices. Reward and punishment were encoded as 1 and −1, respectively, because the participants were either winning or losing money. The model selected actions stochastically based on the predicted value of the two choices (encoded in the activity of two output neurons) according to the softmax rule (with a temperature of 1). The weights were initialized from a normal distribution of mean 0 and an s.d. fitted to experimental data (see below), simulating that the human participants had not built any associations before the experiments. The number of simulated participants (number of repetitions with different seeds) was set to 16, as in the human experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d46823651e7642">38</a></sup>. The number of trials was not mentioned in the original paper, so we simulated for 128 trials for both learning rules.</p><p>To compare the ability of the two learning rules to account for the pattern of signal from the mPFC, for each of the rules, we optimized the parameters describing how the model is set up and learns (the s.d. of initial weights and the learning rate). Namely, we searched for the values of these parameters for which the model produces the most similar pattern of its output activity to that in the experiment. In particular, we minimized the sum over set <i>C</i> of four trial types in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6c</a> of the squared difference between model predictions <i>x</i><sub><i>c</i></sub> and data <i>d</i><sub><i>c</i></sub> on mean mPFC signal:</p><div id="Equ16"><p><span>$$\mathop{\sum}\limits_{c\in C}{\left(a{x}_{c}+b-{d}_{c}\right)}^{2}.$$</span></p><p>
                    (16)
                </p></div><p>The model predictions were additionally scaled by a coefficient <i>a</i> and offset by a bias <i>b</i> because the fMRI signal had different units and baseline than the model. To compute the model prediction for a given trial type, the activity of the output neuron corresponding to the chosen option was averaged across all trials of this type in the entire simulation. The scaled average activity from the model is plotted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig6">6c</a>, where the error bars show the 68% confidence interval of the scaled activity. To fit the model to experimental data, the values of model parameters and the coefficient were found as described in the previous section. In particular, we used exhaustive grid search on the parameters. The models were simulated for all possible combinations of s.d. of initial weights and the learning rate from the following set: <span>\(\left\{0.01,0.05,0.1\right\}\)</span>. For each learning rule and each combination of the above model parameters, the coefficient <i>a</i> (restricted to be positive) and the bias <i>b</i> were then resolved analytically to minimize the sum of the squared error of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Equ16">16</a>).</p><h3 id="Sec16">Statistics and reproducibility</h3><p>The work in this paper involved computer simulations, but due to random initialization of weight parameters, the simulations were repeated multiple times. No statistical method was used to predetermine the number of repetitions, but for simulations corresponding to behavioral or neurophysiological experiments, the number of repetitions was matched to the number of participants in the given experiment. No data were excluded from the analyses. Because the order of execution has no effect on the results of the numeric experiments, they were not randomized. The investigators were not blinded to outcome assessment.</p><p>To visualize the variability of simulation results, we either presented individual data points or error bars showing confidence intervals or box plots. Confidence intervals were computed using bootstrap throughout the paper, and detailed descriptions of the implementation can be found at <a href="https://seaborn.pydata.org/tutorial/error_bars.html#confidence-interval-error-bars">https://seaborn.pydata.org/tutorial/error_bars.html#confidence-interval-error-bars</a>. The details of the methods used to produce the box plots are available at <a href="https://seaborn.pydata.org/generated/seaborn.boxplot.html">https://seaborn.pydata.org/generated/seaborn.boxplot.html</a>.</p><h3 id="Sec17">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41593-023-01514-1#MOESM2">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div>
                </div><div>
                <div id="data-availability-section" data-title="Data availability"><h2 id="data-availability">Data availability</h2><p>Learning tasks analyzed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4a–j</a> were built using the publicly available FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d46823651e7930">60</a></sup> and CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d46823651e7934">36</a></sup>) datasets. These datasets are incorporated in most machine learning libraries, and their original releases are available at <a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a> and <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a>, respectively. Reinforcement learning tasks analyzed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Fig4">4i</a> were built using the publicly available simulators by OpenAI Gym<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Brockman, G. et al. OpenAI Gym. Preprint at 
                  https://doi.org/10.48550/arXiv.1606.01540
                  
                 (2016)." href="https://www.nature.com/articles/s41593-023-01514-1#ref-CR78" id="ref-link-section-d46823651e7956">78</a></sup>. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41593-023-01514-1#Sec20">Source data</a> are provided with this paper.</p></div><div id="code-availability-section" data-title="Code availability"><h2 id="code-availability">Code availability</h2><div id="code-availability-content">
              
              <p>Complete code and full documentation reproducing all simulation results written in Python are publicly available at <a href="https://github.com/YuhangSong/Prospective-Configuration">https://github.com/YuhangSong/Prospective-Configuration</a> released under GNU General Public License v3.0 without any additional restrictions (for license details, see <a href="https://opensource.org/licenses/GPL-3.0">https://opensource.org/licenses/GPL-3.0</a> by the open source initiative).</p>
            </div></div><div id="MagazineFulltextArticleBodySuffix" aria-labelledby="Bib1" data-title="References"><h2 id="Bib1">References</h2><div data-container-section="references" id="Bib1-content"><ol data-track-component="outbound reference" data-track-context="references section"><li data-counter="1."><p id="ref-CR1">Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. <i>Nat. Rev. Neurosci.</i> <b>21</b>, 335–346 (2020).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41583-020-0277-3" data-track-item_id="10.1038/s41583-020-0277-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-020-0277-3" aria-label="Article reference 1" data-doi="10.1038/s41583-020-0277-3">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXnsVCksrk%3D" aria-label="CAS reference 1">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32303713" aria-label="PubMed reference 1">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Backpropagation%20and%20the%20brain&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-020-0277-3&amp;volume=21&amp;pages=335-346&amp;publication_year=2020&amp;author=Lillicrap%2CTP&amp;author=Santoro%2CA&amp;author=Marris%2CL&amp;author=Akerman%2CCJ&amp;author=Hinton%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. <i>Learning Internal Representations by Error Propagation</i> (Univ. California, San Diego, Institute for Cognitive Science, 1985).</p></li><li data-counter="3."><p id="ref-CR3">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. ImageNet classification with deep convolutional neural networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Bartlett, P. et al.) 1097–1105 (Curran Associates, 2012).</p></li><li data-counter="4."><p id="ref-CR4">Mnih, V. et al. Human-level control through deep reinforcement learning. <i>Nature</i> <b>518</b>, 529–533 (2015).</p></li><li data-counter="5."><p id="ref-CR5">Silver, D. et al. Mastering the game of go with deep neural networks and tree search. <i>Nature</i> <b>529</b>, 484–489 (2016).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/nature16961" data-track-item_id="10.1038/nature16961" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature16961" aria-label="Article reference 5" data-doi="10.1038/nature16961">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12is7w%3D" aria-label="CAS reference 5">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26819042" aria-label="PubMed reference 5">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search&amp;journal=Nature&amp;doi=10.1038%2Fnature16961&amp;volume=529&amp;pages=484-489&amp;publication_year=2016&amp;author=Silver%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="6."><p id="ref-CR6">Richards, B. A. et al. A deep learning framework for neuroscience. <i>Nat. Neurosci.</i> <b>22</b>, 1761–1770 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41593-019-0520-2" data-track-item_id="10.1038/s41593-019-0520-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-019-0520-2" aria-label="Article reference 6" data-doi="10.1038/s41593-019-0520-2">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXitVCksbrO" aria-label="CAS reference 6">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31659335" aria-label="PubMed reference 6">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115933" aria-label="PubMed Central reference 6">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20deep%20learning%20framework%20for%20neuroscience&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-019-0520-2&amp;volume=22&amp;pages=1761-1770&amp;publication_year=2019&amp;author=Richards%2CBA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="7."><p id="ref-CR7">Singer, Y. et al. Sensory cortex is optimized for prediction of future input. <i>eLife</i> <b>7</b>, e31557 (2018).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.31557" data-track-item_id="10.7554/eLife.31557" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.31557" aria-label="Article reference 7" data-doi="10.7554/eLife.31557">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29911971" aria-label="PubMed reference 7">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6108826" aria-label="PubMed Central reference 7">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensory%20cortex%20is%20optimized%20for%20prediction%20of%20future%20input&amp;journal=eLife&amp;doi=10.7554%2FeLife.31557&amp;volume=7&amp;publication_year=2018&amp;author=Singer%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="8."><p id="ref-CR8">Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, 8619–8624 (2014).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.1403112111" data-track-item_id="10.1073/pnas.1403112111" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1403112111" aria-label="Article reference 8" data-doi="10.1073/pnas.1403112111">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXnslWnsb4%3D" aria-label="CAS reference 8">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24812127" aria-label="PubMed reference 8">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4060707" aria-label="PubMed Central reference 8">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance-optimized%20hierarchical%20models%20predict%20neural%20responses%20in%20higher%20visual%20cortex&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1403112111&amp;volume=111&amp;pages=8619-8624&amp;publication_year=2014&amp;author=Yamins%2CDLK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="9."><p id="ref-CR9">Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018).</p></li><li data-counter="10."><p id="ref-CR10">Guerguiev, J., Lillicrap, T. P. &amp; Richards, B. A. Towards deep learning with segregated dendrites. <i>eLife</i> <b>6</b>, e22901 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.22901" data-track-item_id="10.7554/eLife.22901" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.22901" aria-label="Article reference 10" data-doi="10.7554/eLife.22901">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29205151" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5716677" aria-label="PubMed Central reference 10">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20deep%20learning%20with%20segregated%20dendrites&amp;journal=eLife&amp;doi=10.7554%2FeLife.22901&amp;volume=6&amp;publication_year=2017&amp;author=Guerguiev%2CJ&amp;author=Lillicrap%2CTP&amp;author=Richards%2CBA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. <i>Front. Comput. Neurosci.</i> <b>11</b>, 24 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3389/fncom.2017.00024" data-track-item_id="10.3389/fncom.2017.00024" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncom.2017.00024" aria-label="Article reference 11" data-doi="10.3389/fncom.2017.00024">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28522969" aria-label="PubMed reference 11">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5415673" aria-label="PubMed Central reference 11">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Equilibrium%20propagation%3A%20bridging%20the%20gap%20between%20energy-based%20models%20and%20backpropagation&amp;journal=Front.%20Comput.%20Neurosci.&amp;doi=10.3389%2Ffncom.2017.00024&amp;volume=11&amp;publication_year=2017&amp;author=Scellier%2CB&amp;author=Bengio%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. <i>Neural Comput.</i> <b>29</b>, 1229–1262 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/NECO_a_00949" data-track-item_id="10.1162/NECO_a_00949" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2FNECO_a_00949" aria-label="Article reference 12" data-doi="10.1162/NECO_a_00949">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28333583" aria-label="PubMed reference 12">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5467749" aria-label="PubMed Central reference 12">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20approximation%20of%20the%20error%20backpropagation%20algorithm%20in%20a%20predictive%20coding%20network%20with%20local%20hebbian%20synaptic%20plasticity&amp;journal=Neural%20Comput.&amp;doi=10.1162%2FNECO_a_00949&amp;volume=29&amp;pages=1229-1262&amp;publication_year=2017&amp;author=Whittington%2CJCR&amp;author=Bogacz%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="13."><p id="ref-CR13">Whittington, J. C. R. &amp; Bogacz, R. Theories of error back-propagation in the brain. <i>Trends Cogn. Sci.</i> <b>23</b>, 235–250 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.tics.2018.12.005" data-track-item_id="10.1016/j.tics.2018.12.005" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2018.12.005" aria-label="Article reference 13" data-doi="10.1016/j.tics.2018.12.005">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30704969" aria-label="PubMed reference 13">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6382460" aria-label="PubMed Central reference 13">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Theories%20of%20error%20back-propagation%20in%20the%20brain&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2018.12.005&amp;volume=23&amp;pages=235-250&amp;publication_year=2019&amp;author=Whittington%2CJCR&amp;author=Bogacz%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="14."><p id="ref-CR14">Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020).</p></li><li data-counter="15."><p id="ref-CR15">Tsividis, P. A., Pouncy, T., Xu, J. L., Tenenbaum, J. B. &amp; Gershman, S. J. Human learning in Atari. In <i>2017 AAAI Spring Symposium Series</i> 643–646 (Association for the Advancement of Artificial Intelligence, 2017).</p></li><li data-counter="16."><p id="ref-CR16">McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. <i>Psychol. Learn. Motiv.</i> <b>24</b>, 109–165 (1989).</p></li><li data-counter="17."><p id="ref-CR17">Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. <i>Proc. Natl Acad. Sci. USA</i> <b>79</b>, 2554–2558 (1982).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.79.8.2554" data-track-item_id="10.1073/pnas.79.8.2554" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.79.8.2554" aria-label="Article reference 17" data-doi="10.1073/pnas.79.8.2554">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL383it1WktQ%3D%3D" aria-label="CAS reference 17">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6953413" aria-label="PubMed reference 17">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238" aria-label="PubMed Central reference 17">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20networks%20and%20physical%20systems%20with%20emergent%20collective%20computational%20abilities&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.79.8.2554&amp;volume=79&amp;pages=2554-2558&amp;publication_year=1982&amp;author=Hopfield%2CJJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="18."><p id="ref-CR18">Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. <i>Nat. Neurosci.</i> <b>2</b>, 79–87 (1999).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/4580" data-track-item_id="10.1038/4580" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2F4580" aria-label="Article reference 18" data-doi="10.1038/4580">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK1MXhsl2ns7k%3D" aria-label="CAS reference 18">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10195184" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20in%20the%20visual%20cortex%3A%20a%20functional%20interpretation%20of%20some%20extra-classical%20receptive-field%20effects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F4580&amp;volume=2&amp;pages=79-87&amp;publication_year=1999&amp;author=Rao%2CRP&amp;author=Ballard%2CDH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Friston, K. The free-energy principle: a unified brain theory? <i>Nat. Rev. Neurosci.</i> <b>11</b>, 127–138 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/nrn2787" data-track-item_id="10.1038/nrn2787" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2787" aria-label="Article reference 19" data-doi="10.1038/nrn2787">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXksFGktw%3D%3D" aria-label="CAS reference 19">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20068583" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20free-energy%20principle%3A%20a%20unified%20brain%20theory%3F&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2787&amp;volume=11&amp;pages=127-138&amp;publication_year=2010&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. <i>Neural Comput.</i> <b>34</b>, 1329–1368 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco_a_01497" data-track-item_id="10.1162/neco_a_01497" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco_a_01497" aria-label="Article reference 20" data-doi="10.1162/neco_a_01497">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35534010" aria-label="PubMed reference 20">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20approximates%20backprop%20along%20arbitrary%20computation%20graphs&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco_a_01497&amp;volume=34&amp;pages=1329-1368&amp;publication_year=2022&amp;author=Millidge%2CB&amp;author=Tschantz%2CA&amp;author=Buckley%2CCL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="21."><p id="ref-CR21">Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at <a href="https://doi.org/10.48550/arXiv.1510.02777" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1510.02777">https://doi.org/10.48550/arXiv.1510.02777</a> (2015).</p></li><li data-counter="22."><p id="ref-CR22">O’Reilly, R. C. &amp; Munakata, Y. <i>Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain</i> (MIT Press Cambridge, 2000).</p></li><li data-counter="23."><p id="ref-CR23">Quilodran, R., Rothe, M. &amp; Procyk, E. Behavioral shifts and action valuation in the anterior cingulate cortex. <i>Neuron</i> <b>57</b>, 314–325 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2007.11.031" data-track-item_id="10.1016/j.neuron.2007.11.031" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2007.11.031" aria-label="Article reference 23" data-doi="10.1016/j.neuron.2007.11.031">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXhvVSrt7c%3D" aria-label="CAS reference 23">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18215627" aria-label="PubMed reference 23">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Behavioral%20shifts%20and%20action%20valuation%20in%20the%20anterior%20cingulate%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2007.11.031&amp;volume=57&amp;pages=314-325&amp;publication_year=2008&amp;author=Quilodran%2CR&amp;author=Rothe%2CM&amp;author=Procyk%2CE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Wallis, J. D. &amp; Kennerley, S. W. Heterogeneous reward signals in prefrontal cortex. <i>Curr. Opin. Neurobiol.</i> <b>20</b>, 191–198 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.conb.2010.02.009" data-track-item_id="10.1016/j.conb.2010.02.009" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2010.02.009" aria-label="Article reference 24" data-doi="10.1016/j.conb.2010.02.009">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXlsFCisrw%3D" aria-label="CAS reference 24">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20303739" aria-label="PubMed reference 24">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2862852" aria-label="PubMed Central reference 24">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Heterogeneous%20reward%20signals%20in%20prefrontal%20cortex&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2010.02.009&amp;volume=20&amp;pages=191-198&amp;publication_year=2010&amp;author=Wallis%2CJD&amp;author=Kennerley%2CSW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="25."><p id="ref-CR25">Friston, K. A theory of cortical responses. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>360</b>, 815–836 (2005).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1098/rstb.2005.1622" data-track-item_id="10.1098/rstb.2005.1622" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2005.1622" aria-label="Article reference 25" data-doi="10.1098/rstb.2005.1622">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15937014" aria-label="PubMed reference 25">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1569488" aria-label="PubMed Central reference 25">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20theory%20of%20cortical%20responses&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2005.1622&amp;volume=360&amp;pages=815-836&amp;publication_year=2005&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="26."><p id="ref-CR26">Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at <a href="https://doi.org/10.48550/arXiv.1407.7906" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1407.7906">https://doi.org/10.48550/arXiv.1407.7906</a> (2014).</p></li><li data-counter="27."><p id="ref-CR27">Meulemans, A., Carzaniga, F., Suykens, J., Sacramento, J. &amp; Grewe, B. F. A theoretical framework for target propagation. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Larochelle, H. et al.) 20024–20036 (Curran Associates, 2020).</p></li><li data-counter="28."><p id="ref-CR28">Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/cercor/1.1.1" data-track-item_id="10.1093/cercor/1.1.1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F1.1.1" aria-label="Article reference 28" data-doi="10.1093/cercor/1.1.1">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK38zltlGmsg%3D%3D" aria-label="CAS reference 28">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1822724" aria-label="PubMed reference 28">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F1.1.1&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Essen%2CDC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="29."><p id="ref-CR29">Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In <i>Efficiency and Scalability Methods for Computational Intellect</i> (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013).</p></li><li data-counter="30."><p id="ref-CR30">Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. <i>Neuron</i> <b>95</b>, 245–258 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2017.06.011" data-track-item_id="10.1016/j.neuron.2017.06.011" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2017.06.011" aria-label="Article reference 30" data-doi="10.1016/j.neuron.2017.06.011">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXht1Smtb%2FE" aria-label="CAS reference 30">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28728020" aria-label="PubMed reference 30">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuroscience-inspired%20artificial%20intelligence&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2017.06.011&amp;volume=95&amp;pages=245-258&amp;publication_year=2017&amp;author=Hassabis%2CD&amp;author=Kumaran%2CD&amp;author=Summerfield%2CC&amp;author=Botvinick%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="31."><p id="ref-CR31">Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. <i>ACM Comput. Surv.</i> <b>46</b>, 1–37 (2014).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1145/2523813" data-track-item_id="10.1145/2523813" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1145%2F2523813" aria-label="Article reference 31" data-doi="10.1145/2523813">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20on%20concept%20drift%20adaptation&amp;journal=ACM%20Comput.%20Surv.&amp;doi=10.1145%2F2523813&amp;volume=46&amp;pages=1-37&amp;publication_year=2014&amp;author=Gama%2CJ&amp;author=%C5%BDliobait%C4%97%2CI&amp;author=Bifet%2CA&amp;author=Pechenizkiy%2CM&amp;author=Bouchachia%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="32."><p id="ref-CR32">Puri, R., Kirby, R., Yakovenko, N. &amp; Catanzaro, B. Large scale language modeling: converging on 40 GB of text in four hours. In <i>2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)</i> 290–297 (IEEE, 2018).</p></li><li data-counter="33."><p id="ref-CR33">Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In <i>Proceedings of the International Conference on Machine Learning (ICML)</i> (eds Bach, F. &amp; Blei, D.) 448–456 (PMLR, 2015).</p></li><li data-counter="34."><p id="ref-CR34">Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In <i>Proc. 34th International Conference on Machine Learning</i> (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017).</p></li><li data-counter="35."><p id="ref-CR35">O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at <a href="https://doi.org/10.48550/arXiv.1511.08458" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1511.08458">https://doi.org/10.48550/arXiv.1511.08458</a> (2015).</p></li><li data-counter="36."><p id="ref-CR36">Krizhevsky, A. &amp; Hinton, G. <i>Learning Multiple Layers of Features from Tiny Images</i>. Master’s thesis, Univ. Toronto (2009).</p></li><li data-counter="37."><p id="ref-CR37">Sutton, R. S. &amp; Barto, A. G. <i>Introduction to Reinforcement Learning</i>, Vol. 2 (MIT Press Cambridge, 1998).</p></li><li data-counter="38."><p id="ref-CR38">Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. <i>J. Neurosci.</i> <b>26</b>, 8360–8367 (2006).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1010-06.2006" data-track-item_id="10.1523/JNEUROSCI.1010-06.2006" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1010-06.2006" aria-label="Article reference 38" data-doi="10.1523/JNEUROSCI.1010-06.2006">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD28Xos1Kju74%3D" aria-label="CAS reference 38">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16899731" aria-label="PubMed reference 38">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6673813" aria-label="PubMed Central reference 38">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20the%20ventromedial%20prefrontal%20cortex%20in%20abstract%20state-based%20inference%20during%20decision%20making%20in%20humans&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1010-06.2006&amp;volume=26&amp;pages=8360-8367&amp;publication_year=2006&amp;author=Hampton%2CAN&amp;author=Bossaerts%2CP&amp;author=O%E2%80%99Doherty%2CJP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="39."><p id="ref-CR39">Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. <i>Nature</i> <b>600</b>, 489–493 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-021-04129-3" data-track-item_id="10.1038/s41586-021-04129-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-021-04129-3" aria-label="Article reference 39" data-doi="10.1038/s41586-021-04129-3">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXisFyrsbfN" aria-label="CAS reference 39">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34819674" aria-label="PubMed reference 39">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8809113" aria-label="PubMed Central reference 39">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Contextual%20inference%20underlies%20the%20learning%20of%20sensorimotor%20repertoires&amp;journal=Nature&amp;doi=10.1038%2Fs41586-021-04129-3&amp;volume=600&amp;pages=489-493&amp;publication_year=2021&amp;author=Heald%2CJB&amp;author=Lengyel%2CM&amp;author=Wolpert%2CDM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="40."><p id="ref-CR40">Larsen, T., Leslie, D. S., Collins, E. J. &amp; Bogacz, R. Posterior weighted reinforcement learning with state uncertainty. <i>Neural Comput.</i> <b>22</b>, 1149–1179 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco.2010.01-09-948" data-track-item_id="10.1162/neco.2010.01-09-948" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.2010.01-09-948" aria-label="Article reference 40" data-doi="10.1162/neco.2010.01-09-948">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20100078" aria-label="PubMed reference 40">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Posterior%20weighted%20reinforcement%20learning%20with%20state%20uncertainty&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.2010.01-09-948&amp;volume=22&amp;pages=1149-1179&amp;publication_year=2010&amp;author=Larsen%2CT&amp;author=Leslie%2CDS&amp;author=Collins%2CEJ&amp;author=Bogacz%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="41."><p id="ref-CR41">Kaufman, M. A. &amp; Bolles, R. C. A nonassociative aspect of overshadowing. <i>Bull. Psychonomic Soc.</i> <b>18</b>, 318–320 (1981).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3758/BF03333639" data-track-item_id="10.3758/BF03333639" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03333639" aria-label="Article reference 41" data-doi="10.3758/BF03333639">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20nonassociative%20aspect%20of%20overshadowing&amp;journal=Bull.%20Psychonomic%20Soc.&amp;doi=10.3758%2FBF03333639&amp;volume=18&amp;pages=318-320&amp;publication_year=1981&amp;author=Kaufman%2CMA&amp;author=Bolles%2CRC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="42."><p id="ref-CR42">Matzel, L. D., Schachtman, T. R. &amp; Miller, R. R. Recovery of an overshadowed association achieved by extinction of the overshadowing stimulus. <i>Learn. Motiv.</i> <b>16</b>, 398–412 (1985).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0023-9690(85)90023-2" data-track-item_id="10.1016/0023-9690(85)90023-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0023-9690%2885%2990023-2" aria-label="Article reference 42" data-doi="10.1016/0023-9690(85)90023-2">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Recovery%20of%20an%20overshadowed%20association%20achieved%20by%20extinction%20of%20the%20overshadowing%20stimulus&amp;journal=Learn.%20Motiv.&amp;doi=10.1016%2F0023-9690%2885%2990023-2&amp;volume=16&amp;pages=398-412&amp;publication_year=1985&amp;author=Matzel%2CLD&amp;author=Schachtman%2CTR&amp;author=Miller%2CRR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="43."><p id="ref-CR43">Poort, J. et al. Learning enhances sensory and multiple non-sensory representations in primary visual cortex. <i>Neuron</i> <b>86</b>, 1478–1490 (2015).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2015.05.037" data-track-item_id="10.1016/j.neuron.2015.05.037" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2015.05.037" aria-label="Article reference 43" data-doi="10.1016/j.neuron.2015.05.037">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhtVSqt73M" aria-label="CAS reference 43">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26051421" aria-label="PubMed reference 43">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4503798" aria-label="PubMed Central reference 43">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20enhances%20sensory%20and%20multiple%20non-sensory%20representations%20in%20primary%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2015.05.037&amp;volume=86&amp;pages=1478-1490&amp;publication_year=2015&amp;author=Poort%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="44."><p id="ref-CR44">McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. <i>Psychol. Rev.</i> <b>102</b>, 419–457 (1995).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-295X.102.3.419" data-track-item_id="10.1037/0033-295X.102.3.419" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.102.3.419" aria-label="Article reference 44" data-doi="10.1037/0033-295X.102.3.419">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7624455" aria-label="PubMed reference 44">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20there%20are%20complementary%20learning%20systems%20in%20the%20hippocampus%20and%20neocortex%3A%20insights%20from%20the%20successes%20and%20failures%20of%20connectionist%20models%20of%20learning%20and%20memory&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.102.3.419&amp;volume=102&amp;pages=419-457&amp;publication_year=1995&amp;author=McClelland%2CJL&amp;author=McNaughton%2CBL&amp;author=O%E2%80%99Reilly%2CRC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="45."><p id="ref-CR45">Dauwels, J. On variational message passing on factor graphs. In <i>2007 IEEE International Symposium on Information Theory</i>, 2546–2550 (IEEE, 2007).</p></li><li data-counter="46."><p id="ref-CR46">Anil Meera, A. &amp; Wisse, M. Dynamic expectation maximization algorithm for estimation of linear systems with colored noise. <i>Entropy</i> <b>23</b>, 1306 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3390/e23101306" data-track-item_id="10.3390/e23101306" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3390%2Fe23101306" aria-label="Article reference 46" data-doi="10.3390/e23101306">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34682030" aria-label="PubMed reference 46">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534782" aria-label="PubMed Central reference 46">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20expectation%20maximization%20algorithm%20for%20estimation%20of%20linear%20systems%20with%20colored%20noise&amp;journal=Entropy&amp;doi=10.3390%2Fe23101306&amp;volume=23&amp;publication_year=2021&amp;author=Anil%20Meera%2CA&amp;author=Wisse%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="47."><p id="ref-CR47">Friston, K. Hierarchical models in the brain. <i>PLoS Comput. Biol.</i> <b>4</b>, e1000211 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1000211" data-track-item_id="10.1371/journal.pcbi.1000211" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1000211" aria-label="Article reference 47" data-doi="10.1371/journal.pcbi.1000211">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18989391" aria-label="PubMed reference 47">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570625" aria-label="PubMed Central reference 47">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchical%20models%20in%20the%20brain&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1000211&amp;volume=4&amp;publication_year=2008&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="48."><p id="ref-CR48">Meulemans, A., Farinha, M. T., Cervera, M. R., Sacramento, J. &amp; Grewe, B. F. Minimizing control for credit assignment with strong feedback. In <i>Proc. of Machine Learning Research</i> (eds Chaudhuri, K. et al.) 15458–15483 (PMLR, 2022).</p></li><li data-counter="49."><p id="ref-CR49">Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. <i>Adv. Neural Inf. Process. Syst.</i> <b>35</b>, 33603–33617 (2022).</p></li><li data-counter="50."><p id="ref-CR50">Gilra, A. &amp; Gerstner, W. Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network. <i>eLife</i> <b>6</b>, e28295 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.28295" data-track-item_id="10.7554/eLife.28295" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.28295" aria-label="Article reference 50" data-doi="10.7554/eLife.28295">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29173280" aria-label="PubMed reference 50">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5730383" aria-label="PubMed Central reference 50">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Predicting%20non-linear%20dynamics%20by%20stable%20local%20learning%20in%20a%20recurrent%20spiking%20neural%20network&amp;journal=eLife&amp;doi=10.7554%2FeLife.28295&amp;volume=6&amp;publication_year=2017&amp;author=Gilra%2CA&amp;author=Gerstner%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="51."><p id="ref-CR51">Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Ranzato, M. et al.) 17839–17851 (2021).</p></li><li data-counter="52."><p id="ref-CR52">Akrout, M., Wilson, C., Humphreys, P., Lillicrap, T. &amp; Tweed, D. B. Deep learning without weight transport. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Wallach, H. et al.) (Curran Associates, 2019).</p></li><li data-counter="53."><p id="ref-CR53">Lillicrap, T. P., Cownden, D., Tweed, D. B. &amp; Akerman, C. J. Random synaptic feedback weights support error backpropagation for deep learning. <i>Nat. Commun.</i> <b>7</b>, 13276 (2016).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/ncomms13276" data-track-item_id="10.1038/ncomms13276" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms13276" aria-label="Article reference 53" data-doi="10.1038/ncomms13276">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XhvVehtLrM" aria-label="CAS reference 53">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27824044" aria-label="PubMed reference 53">PubMed</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5105169" aria-label="PubMed Central reference 53">PubMed Central</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Random%20synaptic%20feedback%20weights%20support%20error%20backpropagation%20for%20deep%20learning&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms13276&amp;volume=7&amp;publication_year=2016&amp;author=Lillicrap%2CTP&amp;author=Cownden%2CD&amp;author=Tweed%2CDB&amp;author=Akerman%2CCJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="54."><p id="ref-CR54">Millidge, B., Tschantz, A. &amp; Buckley, C. L. Relaxing the constraints on predictive coding models. Preprint at <a href="https://doi.org/10.48550/arXiv.2010.01047" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.2010.01047">https://doi.org/10.48550/arXiv.2010.01047</a> (2020).</p></li><li data-counter="55."><p id="ref-CR55">Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at <a href="https://doi.org/10.48550/arXiv.2212.00720" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.2212.00720">https://doi.org/10.48550/arXiv.2212.00720</a> (2022).</p></li><li data-counter="56."><p id="ref-CR56">Friston, K. J., Trujillo-Barreto, N. &amp; Daunizeau, J. Dem: a variational treatment of dynamic systems. <i>NeuroImage</i> <b>41</b>, 849–885 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2008.02.054" data-track-item_id="10.1016/j.neuroimage.2008.02.054" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2008.02.054" aria-label="Article reference 56" data-doi="10.1016/j.neuroimage.2008.02.054">Article</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD1czkvFWqtg%3D%3D" aria-label="CAS reference 56">CAS</a>&nbsp;
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18434205" aria-label="PubMed reference 56">PubMed</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Dem%3A%20a%20variational%20treatment%20of%20dynamic%20systems&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2008.02.054&amp;volume=41&amp;pages=849-885&amp;publication_year=2008&amp;author=Friston%2CKJ&amp;author=Trujillo-Barreto%2CN&amp;author=Daunizeau%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="57."><p id="ref-CR57">Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2023.05.15.540906" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1101/2023.05.15.540906">https://doi.org/10.1101/2023.05.15.540906</a> (2023).</p></li><li data-counter="58."><p id="ref-CR58">Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022).</p></li><li data-counter="59."><p id="ref-CR59">Foroushani, A. N., Assaf, H., Noshahr, F. H., Savaria, Y. &amp; Sawan, M. Analog circuits to accelerate the relaxation process in the equilibrium propagation algorithm. In <i>2020 IEEE International Symposium on Circuits and Systems (ISCAS)</i> 1–5 (IEEE, 2020).</p></li><li data-counter="60."><p id="ref-CR60">Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at <a href="https://doi.org/10.48550/arXiv.1708.07747" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1708.07747">https://doi.org/10.48550/arXiv.1708.07747</a> (2017).</p></li><li data-counter="61."><p id="ref-CR61">Goodfellow, I., Bengio, Y. &amp; Courville, A. <i>Deep Learning</i> (MIT Press Cambridge, 2016).</p></li><li data-counter="62."><p id="ref-CR62">O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. <i>Neural Comput.</i> <b>8</b>, 895–938 (1996).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco.1996.8.5.895" data-track-item_id="10.1162/neco.1996.8.5.895" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.1996.8.5.895" aria-label="Article reference 62" data-doi="10.1162/neco.1996.8.5.895">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Biologically%20plausible%20error-driven%20learning%20using%20local%20activation%20differences%3A%20the%20generalized%20recirculation%20algorithm&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1996.8.5.895&amp;volume=8&amp;pages=895-938&amp;publication_year=1996&amp;author=O%E2%80%99Reilly%2CRC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="63."><p id="ref-CR63">Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In <i>Artificial Neural Networks: Concept Learning</i> (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990).</p></li><li data-counter="64."><p id="ref-CR64">Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (ed. Anderson, D.) 602–611 (Curran Associates, 1987).</p></li><li data-counter="65."><p id="ref-CR65">Pineda, F. J. Dynamics and architecture for neural computation. <i>J. Complex.</i> <b>4</b>, 216–245 (1988).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0885-064X(88)90021-0" data-track-item_id="10.1016/0885-064X(88)90021-0" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0885-064X%2888%2990021-0" aria-label="Article reference 65" data-doi="10.1016/0885-064X(88)90021-0">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamics%20and%20architecture%20for%20neural%20computation&amp;journal=J.%20Complex.&amp;doi=10.1016%2F0885-064X%2888%2990021-0&amp;volume=4&amp;pages=216-245&amp;publication_year=1988&amp;author=Pineda%2CFJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="66."><p id="ref-CR66">Hebb, D. O. <i>The Organisation of Behaviour: A Neuropsychological Theory</i> (Science Editions New York, 1949).</p></li><li data-counter="67."><p id="ref-CR67">Senn, W. et al. A neuronal least-action principle for real-time learning in cortical circuits. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2023.03.25.534198" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1101/2023.03.25.534198">https://doi.org/10.1101/2023.03.25.534198</a> (2023).</p></li><li data-counter="68."><p id="ref-CR68">Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In <i>Proc. 13th International Conference on Artificial Intelligence and Statistics</i> (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010).</p></li><li data-counter="69."><p id="ref-CR69">Tolstikhin, I. O. et al. Mlp-mixer: an all-mlp architecture for vision. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Ranzato, M. et al.) 24261–24272 (Curran Associates, 2021).</p></li><li data-counter="70."><p id="ref-CR70">Žliobaitė, I. Learning under concept drift: an overview. Preprint at <a href="https://doi.org/10.48550/arXiv.1010.4784" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1010.4784">https://doi.org/10.48550/arXiv.1010.4784</a> (2010).</p></li><li data-counter="71."><p id="ref-CR71">Tsymbal, A. <i>The Problem of Concept Drift: Definitions and Related Work</i>. Technical report, Computer Science Department, Trinity College Dublin (2004).</p></li><li data-counter="72."><p id="ref-CR72">Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. <a href="https://doi.org/10.48550/arXiv.1412.6980" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1412.6980">https://doi.org/10.48550/arXiv.1412.6980</a> (2014).</p></li><li data-counter="73."><p id="ref-CR73">Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R. &amp; Xu, Z. Reverse differentiation via predictive coding. In <i>Proc. 36th AAAI Conference on Artificial Intelligence</i> (Salvatori, T., Song, Y., Xu, Z., Lukasiewicz, T. &amp; Bogacz, R.) 8150–8158 (Curran Associates, 2022).</p></li><li data-counter="74."><p id="ref-CR74">Sutton, R. S. Generalization in reinforcement learning: successful examples using sparse coarse coding. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Touretzky, D. et al.) 1038–1044 (NIPS, 1995).</p></li><li data-counter="75."><p id="ref-CR75">Geramifard, A., Dann, C., Klein, R. H., Dabney, W. &amp; How, J. P. RLPy: a value-function-based reinforcement learning framework for education and research. <i>J. Mach. Learn. Res.</i> <b>16</b>, 1573–1578 (2015).</p><p><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=RLPy%3A%20a%20value-function-based%20reinforcement%20learning%20framework%20for%20education%20and%20research&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=16&amp;pages=1573-1578&amp;publication_year=2015&amp;author=Geramifard%2CA&amp;author=Dann%2CC&amp;author=Klein%2CRH&amp;author=Dabney%2CW&amp;author=How%2CJP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="76."><p id="ref-CR76">Moore, A. Efficient memory-based learning for robot control. Technical report, Carnegie Mellon Univ. (1990).</p></li><li data-counter="77."><p id="ref-CR77">Barto, A. G., Sutton, R. S. &amp; Anderson, C. W. Neuronlike adaptive elements that can solve difficult learning control problems. In <i>IEEE Transactions on Systems, Man, and Cybernetics</i>, 834–846 (1983).</p></li><li data-counter="78."><p id="ref-CR78">Brockman, G. et al. OpenAI Gym. Preprint at <a href="https://doi.org/10.48550/arXiv.1606.01540" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1606.01540">https://doi.org/10.48550/arXiv.1606.01540</a> (2016).</p></li><li data-counter="79."><p id="ref-CR79">Welford, B. P. Note on a method for calculating corrected sums of squares and products. <i>Technometrics</i> <b>4</b>, 419–420 (1962).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/00401706.1962.10490022" data-track-item_id="10.1080/00401706.1962.10490022" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F00401706.1962.10490022" aria-label="Article reference 79" data-doi="10.1080/00401706.1962.10490022">Article</a>&nbsp;
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=Note%20on%20a%20method%20for%20calculating%20corrected%20sums%20of%20squares%20and%20products&amp;journal=Technometrics&amp;doi=10.1080%2F00401706.1962.10490022&amp;volume=4&amp;pages=419-420&amp;publication_year=1962&amp;author=Welford%2CBP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="80."><p id="ref-CR80">Knuth, D. E. <i>Art of Computer Programming</i>, Vol. 2 (Addison-Wesley Professional, 2014).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01514-1?format=refman&amp;flavour=references">Download references</a></p></div></div><div id="Ack1-section" data-title="Acknowledgements"><h2 id="Ack1">Acknowledgements</h2><p>We thank T. Behrens for comments on the manuscript and A. Saxe and M. Witbrock for discussions. The presented research was supported by the following grants: China Scholarship Council under the State Scholarship Fund (Y.S.), JPMorgan AI Research Awards (Y.S.), Biotechnology and Biological Sciences Research Council grant BB/S006338/1 (R.B.), Medical Research Council grant MC_UU_00003/1 (R.B.), the Alan Turing Institute under the EPSRC grant EP/N510129/1 (T.L.), the AXA Research Fund (T.L.), National Natural Science Foundation of China grants 61906063 and 62276089 (Z.X.), Natural Science Foundation of Hebei Province, China, grant F2021202064 (Z.X.), Natural Science Foundation of Tianjin City, China, grant 19JCQNJC00400 (Z.X.), the ‘100 Talents Plan’ of Hebei Province, China, grant E2019050017 (Z.X.) and the Yuanguang Scholar Fund of Hebei University of Technology, China (Z.X.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. This research was also funded, in part, by JPMorgan Chase &amp; Co. Any views or opinions expressed herein are solely those of the authors listed and may differ from the views and opinions expressed by JPMorgan Chase &amp; Co. or its affiliates. This material is not a product of the Research Department of J.P. Morgan Securities, LLC. This material should not be construed as an individual recommendation for any particular client and is not intended as a recommendation of particular securities, financial instruments or strategies for a particular client. This material does not constitute a solicitation or offer in any jurisdiction.</p></div><div id="author-information-section" aria-labelledby="author-information" data-title="Author information"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Department of Computer Science, University of Oxford, Oxford, UK</p><p>Yuhang Song,&nbsp;Tommaso Salvatori,&nbsp;Thomas Lukasiewicz&nbsp;&amp;&nbsp;Zhenghua Xu</p></li><li id="Aff2"><p>Medical Research Council Brain Network Dynamics Unit, University of Oxford, Oxford, UK</p><p>Yuhang Song,&nbsp;Beren Millidge&nbsp;&amp;&nbsp;Rafal Bogacz</p></li><li id="Aff3"><p>Fractile, Ltd., London, UK</p><p>Yuhang Song</p></li><li id="Aff4"><p>Institute of Logic and Computation, Vienna University of Technology, Vienna, Austria</p><p>Tommaso Salvatori&nbsp;&amp;&nbsp;Thomas Lukasiewicz</p></li><li id="Aff5"><p>VERSES AI Research Lab, Los Angeles, CA, USA</p><p>Tommaso Salvatori</p></li><li id="Aff6"><p>State Key Laboratory of Reliability and Intelligence of Electrical Equipment, School of Health Sciences and Biomedical Engineering, Hebei University of Technology, Tianjin, China</p><p>Zhenghua Xu</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Yuhang-Song-Aff1-Aff2-Aff3"><span>Yuhang Song</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yuhang%20Song" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yuhang%20Song%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Beren-Millidge-Aff2"><span>Beren Millidge</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Beren%20Millidge" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Beren%20Millidge%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Tommaso-Salvatori-Aff1-Aff4-Aff5"><span>Tommaso Salvatori</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tommaso%20Salvatori" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tommaso%20Salvatori%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Thomas-Lukasiewicz-Aff1-Aff4"><span>Thomas Lukasiewicz</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Thomas%20Lukasiewicz" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thomas%20Lukasiewicz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Zhenghua-Xu-Aff1-Aff6"><span>Zhenghua Xu</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zhenghua%20Xu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zhenghua%20Xu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li><li id="auth-Rafal-Bogacz-Aff2"><span>Rafal Bogacz</span><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rafal%20Bogacz" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span>&nbsp;</span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rafal%20Bogacz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></li></ol></div><h3 id="contributions">Contributions</h3><p>Y.S. and R.B. conceived the project. Y.S., R.B., B.M. and T.S. contributed ideas for experiments and analysis. Y.S. and B.M. performed simulations. Y.S., B.M. and R.B. performed mathematical analyses. Y.S., T.L. and R.B. managed the project. T.L and Z.X. advised on the project. Y.S., R.B. and B.M. wrote the paper. T.S., T.L. and Z.X. provided revisions to the paper.</p><h3 id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:yuhang.song@bndu.ox.ac.uk">Yuhang Song</a>, <a id="corresp-c2" href="mailto:thomas.lukasiewicz@cs.ox.ac.uk">Thomas Lukasiewicz</a>, <a id="corresp-c3" href="mailto:zhenghua.xu@hebut.edu.cn">Zhenghua Xu</a> or <a id="corresp-c4" href="mailto:rafal.bogacz@ndcn.ox.ac.uk">Rafal Bogacz</a>.</p></div></div><div id="ethics-section" data-title="Ethics declarations"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar4">Competing interests</h3>
                <p>Y.S., B.M. and R.B. are shareholders in Fractile, Ltd., which designs artificial intelligence accelerator hardware. The remaining authors declare no competing interests.</p>
              
            </div></div><div id="peer-review-section" data-title="Peer review"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar3">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Karl Friston, Walter Senn, Friedemann Zenke and Joel Zylberberg for their contribution to the peer review of this work.</p>
              
            </div></div><div id="additional-information-section" data-title="Additional information"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div><div id="Sec19-section" data-title="Supplementary information"><h2 id="Sec19">Supplementary information</h2></div><div id="Sec20-section" data-title="Source data"><h2 id="Sec20">Source data</h2></div><div id="rightslink-section" data-title="Rights and permissions"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Inferring%20neural%20activity%20before%20plasticity%20as%20a%20foundation%20for%20learning%20beyond%20backpropagation&amp;author=Yuhang%20Song%20et%20al&amp;contentID=10.1038%2Fs41593-023-01514-1&amp;copyright=The%20Author%28s%29&amp;publication=1097-6256&amp;publicationDate=2024-01-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div><div id="article-info-section" aria-labelledby="article-info" data-title="About this article"><h2 id="article-info">About this article</h2><div id="article-info-content"><p><a data-crossmark="10.1038/s41593-023-01514-1" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-023-01514-1" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"></a></p><div><h3 id="citeas">Cite this article</h3><p>Song, Y., Millidge, B., Salvatori, T. <i>et al.</i> Inferring neural activity before plasticity as a foundation for learning beyond backpropagation.
                    <i>Nat Neurosci</i> <b>27</b>, 348–358 (2024). https://doi.org/10.1038/s41593-023-01514-1</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01514-1?format=refman&amp;flavour=citation">Download citation</a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-05-18">18 May 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2023-11-02">02 November 2023</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2024-01-03">03 January 2024</time></span></p></li><li><p>Issue Date<span>: </span><span><time datetime="2024-02">February 2024</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41593-023-01514-1</span></p></li></ul></div></div></div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[QwQ: Alibaba's O1 Like Reasoning LLM (172 pts)]]></title>
            <link>https://qwenlm.github.io/blog/qwq-32b-preview/</link>
            <guid>42259184</guid>
            <pubDate>Wed, 27 Nov 2024 20:00:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qwenlm.github.io/blog/qwq-32b-preview/">https://qwenlm.github.io/blog/qwq-32b-preview/</a>, See on <a href="https://news.ycombinator.com/item?id=42259184">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Please add a pair of parentheses to the incorrect equation: 1 + 2 * 3 + 4 * 5 + 6 * 7 + 8 * 9 = 479, to make the equation true.</p><div><p>Let’s tackle this problem step by step. The equation given is:</p><p>1 + 2 * 3 + 4 * 5 + 6 * 7 + 8 * 9 = 479</p><p>But it’s incorrect, and I need to add a pair of parentheses to make it true. Okay, first things first, I should understand what the current value of the left side is without any parentheses.</p><p>Let’s recall the order of operations: PEMDAS (Parentheses, Exponents, Multiplication and Division, Addition and Subtraction). So, multiplication comes before addition.</p><p>So, calculating step by step:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>Now, plugging these back into the equation:</p><p>1 + 6 + 20 + 42 + 72</p><p>Adding these up:</p><p>1 + 6 = 7</p><p>7 + 20 = 27</p><p>27 + 42 = 69</p><p>69 + 72 = 141</p><p>So, without any parentheses, the left side equals 141, but it should be 479. That’s quite a difference. So, I need to add a pair of parentheses to make it equal to 479.</p><p>I need to think about where to place the parentheses to alter the order of operations to achieve the desired result.</p><p>Let me consider different possibilities:</p><ol><li>Parenthesizing individual terms:</li></ol><p>For example, (1 + 2) * 3 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Calculate inside the parentheses first:</p><p>(1 + 2) = 3</p><p>Then, 3 * 3 = 9</p><p>Now, the equation becomes:</p><p>9 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 9 + 20 + 42 + 72 = 143</p><p>Still not 479.</p><ol start="2"><li>Parenthesizing more terms:</li></ol><p>What if I do (1 + 2 * 3) + 4 * 5 + 6 * 7 + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>1 + 2 * 3</p><p>Here, multiplication comes before addition, so 2 * 3 = 6, then 1 + 6 = 7</p><p>So, the equation becomes:</p><p>7 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Again, following order of operations:</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 7 + 20 + 42 + 72 = 141</p><p>Same as before.</p><ol start="3"><li>Let’s try (1 + 2) * (3 + 4) * 5 + 6 * 7 + 8 * 9</li></ol><p>First, calculate inside the parentheses:</p><p>(1 + 2) = 3</p><p>(3 + 4) = 7</p><p>So, 3 * 7 * 5 = 105</p><p>Now, the equation becomes:</p><p>105 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 105 + 42 + 72 = 219</p><p>Still not 479.</p><ol start="4"><li>Maybe trying to group more terms:</li></ol><p>(1 + 2 * 3 + 4) * 5 + 6 * 7 + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>1 + 2 * 3 + 4</p><p>Multiplication first: 2 * 3 = 6</p><p>Then, 1 + 6 + 4 = 11</p><p>So, 11 * 5 = 55</p><p>Now, the equation becomes:</p><p>55 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 55 + 42 + 72 = 169</p><p>Getting closer, but still not 479.</p><ol start="5"><li>Let’s try a different approach. Maybe grouping the additions together:</li></ol><p>1 + (2 * 3 + 4 * 5 + 6 * 7 + 8 * 9)</p><p>First, calculate inside the parentheses:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 6 + 20 + 42 + 72 = 140</p><p>Then, 1 + 140 = 141</p><p>Same as before.</p><ol start="6"><li>Perhaps grouping two multiplications together:</li></ol><p>1 + 2 * (3 + 4) * 5 + 6 * 7 + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>(3 + 4) = 7</p><p>So, 2 * 7 * 5 = 70</p><p>Now, the equation becomes:</p><p>1 + 70 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 1 + 70 + 42 + 72 = 185</p><p>Still not 479.</p><ol start="7"><li>Maybe grouping more multiplications:</li></ol><p>1 + 2 * 3 + 4 * (5 + 6) * 7 + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>(5 + 6) = 11</p><p>So, 4 * 11 * 7 = 308</p><p>Now, the equation becomes:</p><p>1 + 2 * 3 + 308 + 8 * 9</p><p>Following order of operations:</p><p>2 * 3 = 6</p><p>8 * 9 = 72</p><p>So, 1 + 6 + 308 + 72 = 387</p><p>Closer, but still not 479.</p><ol start="8"><li>Let’s try grouping the last terms:</li></ol><p>1 + 2 * 3 + 4 * 5 + 6 * (7 + 8) * 9</p><p>First, calculate inside the parentheses:</p><p>(7 + 8) = 15</p><p>So, 6 * 15 * 9 = 810</p><p>Now, the equation becomes:</p><p>1 + 2 * 3 + 4 * 5 + 810</p><p>Following order of operations:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>So, 1 + 6 + 20 + 810 = 837</p><p>Now that’s way over 479.</p><p>Maybe I need to group terms in a way that subtraction is implied, but since there are no subtractions in the original equation, perhaps I need to consider that.</p><p>Wait, maybe the problem allows for adding parentheses to change the operations indirectly.</p><p>Alternatively, perhaps the parentheses need to group additions in a specific way.</p><p>Let me try grouping the first few terms:</p><p>(1 + 2 * 3 + 4 * 5) + 6 * 7 + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>So, 1 + 6 + 20 = 27</p><p>Now, the equation becomes:</p><p>27 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 27 + 42 + 72 = 141</p><p>Same as before.</p><ol start="9"><li>Maybe grouping further:</li></ol><p>(1 + 2 * 3 + 4 * 5 + 6 * 7) + 8 * 9</p><p>First, calculate inside the parentheses:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>So, 1 + 6 + 20 + 42 = 69</p><p>Now, the equation becomes:</p><p>69 + 8 * 9</p><p>Following order of operations:</p><p>8 * 9 = 72</p><p>So, 69 + 72 = 141</p><p>Still not 479.</p><ol start="10"><li>Let’s try grouping differently:</li></ol><p>1 + 2 * (3 + 4 * 5 + 6 * 7 + 8 * 9)</p><p>First, calculate inside the parentheses:</p><p>3 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Following order of operations inside:</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 3 + 20 + 42 + 72 = 137</p><p>Now, 2 * 137 = 274</p><p>Then, the equation becomes:</p><p>1 + 274 = 275</p><p>Still not 479.</p><ol start="11"><li>Maybe trying to group the additions and multiplications in a different way:</li></ol><p>1 + (2 * 3 + 4 * 5 + 6 * 7 + 8 * 9)</p><p>Wait, I did this earlier and got 141.</p><p>Hmm.</p><p>Let me think differently. Maybe I need to group terms to create a larger multiplication.</p><p>For example:</p><p>1 + 2 * (3 + 4 * 5 + 6 * 7 + 8 * 9)</p><p>First, calculate inside the parentheses:</p><p>3 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 3 + 20 + 42 + 72 = 137</p><p>Now, 2 * 137 = 274</p><p>Then, 1 + 274 = 275</p><p>Still not 479.</p><ol start="12"><li>Let’s try another approach:</li></ol><p>(1 + 2) * (3 + 4) * (5 + 6) * (7 + 8) * 9</p><p>Wait, that’s adding multiple sets of parentheses, which is not allowed since I can only add one pair.</p><p>Back to the original problem: only one pair of parentheses can be added.</p><p>Maybe I need to group a subtraction or division, but those operations aren’t present in the original equation.</p><p>Wait, perhaps I need to consider that adding parentheses can create a negative term, but again, there are no subtractions in the original equation.</p><p>Alternatively, maybe the parentheses are meant to group additions in a specific way to create a larger number.</p><p>Let me try grouping more terms together:</p><p>1 + 2 * (3 + 4 * 5 + 6 * 7 + 8 * 9)</p><p>First, inside the parentheses:</p><p>3 + 4 * 5 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>4 * 5 = 20</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 3 + 20 + 42 + 72 = 137</p><p>Now, 2 * 137 = 274</p><p>Then, 1 + 274 = 275</p><p>Same as before.</p><ol start="13"><li>Maybe trying to group the last few terms:</li></ol><p>1 + 2 * 3 + 4 * 5 + 6 * (7 + 8 * 9)</p><p>First, inside the parentheses:</p><p>7 + 8 * 9</p><p>Following order of operations:</p><p>8 * 9 = 72</p><p>Then, 7 + 72 = 79</p><p>Now, 6 * 79 = 474</p><p>So, the equation becomes:</p><p>1 + 2 * 3 + 4 * 5 + 474</p><p>Following order of operations:</p><p>2 * 3 = 6</p><p>4 * 5 = 20</p><p>So, 1 + 6 + 20 + 474 = 501</p><p>Close to 479, but still not there.</p><ol start="14"><li>Maybe adjusting the grouping slightly:</li></ol><p>1 + 2 * 3 + 4 * (5 + 6 * 7 + 8 * 9)</p><p>First, inside the parentheses:</p><p>5 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 5 + 42 + 72 = 119</p><p>Now, 4 * 119 = 476</p><p>Then, the equation becomes:</p><p>1 + 2 * 3 + 476</p><p>Following order of operations:</p><p>2 * 3 = 6</p><p>So, 1 + 6 + 476 = 483</p><p>Still not 479.</p><ol start="15"><li>Let’s try grouping the first part differently:</li></ol><p>(1 + 2 * 3 + 4) * (5 + 6 * 7 + 8 * 9)</p><p>First, calculate inside the first set of parentheses:</p><p>1 + 2 * 3 + 4</p><p>Following order of operations:</p><p>2 * 3 = 6</p><p>Then, 1 + 6 + 4 = 11</p><p>Now, the second set of parentheses:</p><p>5 + 6 * 7 + 8 * 9</p><p>Following order of operations:</p><p>6 * 7 = 42</p><p>8 * 9 = 72</p><p>So, 5 + 42 + 72 = 119</p><p>Now, 11 * 119 = 1309</p><p>Way over 479.</p><ol start="16"><li>Maybe trying to group only two terms:</li></ol><p>1 + 2 * (3 + 4) * 5 + 6 * 7 + 8 * 9</p><p>Wait, I did this earlier and got 185.</p><p>Hmm.</p><p>Let me think differently. Maybe I need to group terms to create a division or subtraction, but since those operations aren’t present, perhaps I need to consider that the parentheses can be used to create a fraction or some other operation, but that might be reaching too far.</p><p>Alternatively, maybe the problem allows for adding a pair of parentheses around the entire equation, but that doesn’t make sense.</p><p>Wait, perhaps the parentheses are meant to group additions in a specific way to create a larger number.</p><p>Let me try grouping more terms together for multiplication.</p><p>For example:</p><p>1 + 2 * (3 + 4 * 5 + 6) * 7 + 8 * 9</p><p>First, inside the parentheses:</p><p>3 + 4 * 5 + 6</p><p>Following order of operations:</p><p>4 * 5 = 20</p><p>So, 3 + 20 + 6 = 29</p><p>Now, 2 * 29 * 7 = 406</p><p>Then, the equation becomes:</p><p>1 + 406 + 8 * 9</p><p>Following order of operations:</p><p>8 * 9 = 72</p><p>So, 1 + 406 + 72 = 479</p><p>Wait a minute, that’s exactly 479!</p><p>Let me double-check:</p><p>First, inside the parentheses: 3 + 4 * 5 + 6</p><p>4 * 5 = 20</p><p>Then, 3 + 20 + 6 = 29</p><p>Then, 2 * 29 * 7 = 2 * 203 = 406</p><p>Then, 1 + 406 = 407</p><p>Plus 8 * 9 = 72</p><p>So, 407 + 72 = 479</p><p>Perfect! So, by adding parentheses around (3 + 4 * 5 + 6), and multiplying that sum by 2 and 7, we get the desired result.</p><p>So, the corrected equation is:</p><p>1 + 2 * (3 + 4 * 5 + 6) * 7 + 8 * 9 = 479</p><p><strong>Final Answer</strong></p><p>$$ \boxed{1 + 2 \times (3 + 4 \times 5 + 6) \times 7 + 8 \times 9 = 479} $$</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The US copyright office has struck down a major effort for game preservation (135 pts)]]></title>
            <link>https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/</link>
            <guid>42259133</guid>
            <pubDate>Wed, 27 Nov 2024 19:54:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/">https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/</a>, See on <a href="https://news.ycombinator.com/item?id=42259133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>A three-year fight to help support game preservation has come to a sad end today. The US copyright office has denied a request for a DMCA exemption that would allow libraries to remotely share digital access to preserved video games.</p><p>"For the past three years, the Video Game History Foundation has been supporting with the Software Preservation Network (SPN) on a petition to allow libraries and archives to <a data-analytics-id="inline-link" href="https://www.copyright.gov/1201/2024/comments/Class%206(b)%20-%20Initial%20Comments%20-%20%20Software%20Preservation%20Network%20and%20Library%20Copyright%20Alliance.pdf" target="_blank" data-url="https://www.copyright.gov/1201/2024/comments/Class%206(b)%20-%20Initial%20Comments%20-%20%20Software%20Preservation%20Network%20and%20Library%20Copyright%20Alliance.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">remotely share digital access to out-of-print video games in their collections</a>," VGHF explains in its <a data-analytics-id="inline-link" href="https://gamehistory.org/dmca-2024-statement/" target="_blank" data-url="https://gamehistory.org/dmca-2024-statement/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">statement</a>. "Under the current anti-circumvention rules in Section 1201 of the DMCA, libraries and archives are unable to break copy protection on games in order to make them remotely accessible to researchers."</p><p>Essentially, this exemption would open up the possibility of a digital library where historians and researchers could 'check out' digital games that run through emulators. The VGHF argues that <a data-analytics-id="inline-link" href="https://gamehistory.org/87percent/" target="_blank" data-url="https://gamehistory.org/87percent/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">around 87% of all video games released in the US before 2010 are now out of print</a>, and the only legal way to access those games now is through the occasionally exorbitant prices and often failing hardware that defines the retro gaming market.</p><p>Still, the US copyright office has said no. "The Register concludes that proponents did not show that removing the single-user limitation for preserved computer programs or permitting off-premises access to video games are likely to be noninfringing," according to the <a data-analytics-id="inline-link" href="https://public-inspection.federalregister.gov/2024-24563.pdf" target="_blank" data-url="https://public-inspection.federalregister.gov/2024-24563.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">final ruling</a>. "She also notes the greater risk of market harm with removing the video game exemption’s premises limitation, given the market for legacy video games."</p><p>That ruling cites the belief of the Entertainment Software Association and other industry lobby groups that "there would be a significant risk that preserved video games would be used for recreational purposes." We cannot, of course, entertain the notion that researchers enjoy their subjects for even a moment. More importantly, this also ignores the fact that libraries <em>already</em> lend out digital versions of more traditional media like books and movies to everyday people for what can only be described as recreational purposes.</p><p>Members of the VGHF are naturally unhappy with the decision. "Unfortunately, lobbying efforts by rightsholder groups continue to hold back progress," the group says in its statement, noting the ESA's absolutist position that it would <a data-analytics-id="inline-link" href="https://www.gamesradar.com/games/the-esa-says-its-members-wont-support-the-one-form-of-game-preservation-that-might-actually-work/" data-before-rewrite-localise="https://www.gamesradar.com/games/the-esa-says-its-members-wont-support-the-one-form-of-game-preservation-that-might-actually-work/">not support a similar sort of copyright reform under any circumstances</a>.</p><p>"I'm proud of the work we and the orgs we partnered with did to try and change copyright law," VGHF founder and director Frank Cifaldi says on <a data-analytics-id="inline-link" href="https://x.com/frankcifaldi/status/1849869475782459704" target="_blank" data-url="https://x.com/frankcifaldi/status/1849869475782459704" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Twitter</a>. "We really gave it our all, I can't see what else we could have done. This fails the needs of citizens in favor of a weak sauce argument from the industry, and it's really disappointing."</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-fdSYVfdKPF5N2AbJW46cMW"><section><p>Weekly digests, tales from the communities you love, and more</p></section></div><p><em>Your legal access to the </em><a data-analytics-id="inline-link" href="https://www.gamesradar.com/best-games-of-all-time/" data-before-rewrite-localise="https://www.gamesradar.com/best-games-of-all-time/"><em>best games of all time</em></a><em> is not a guarantee.</em>&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Feels Like Paper (155 pts)]]></title>
            <link>https://www.lukasmoro.com/paper</link>
            <guid>42258540</guid>
            <pubDate>Wed, 27 Nov 2024 18:43:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lukasmoro.com/paper">https://www.lukasmoro.com/paper</a>, See on <a href="https://news.ycombinator.com/item?id=42258540">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[You can use C-Reduce for any language (297 pts)]]></title>
            <link>https://bernsteinbear.com/blog/creduce/</link>
            <guid>42258103</guid>
            <pubDate>Wed, 27 Nov 2024 17:56:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bernsteinbear.com/blog/creduce/">https://bernsteinbear.com/blog/creduce/</a>, See on <a href="https://news.ycombinator.com/item?id=42258103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        
        
        <p><i>November 15, 2024</i></p>
        
        
        <div>
            <p><a href="https://github.com/csmith-project/creduce">C-Reduce</a> is a tool by Regehr and
friends for minimizing C compiler bug reproducers. Imagine if you had a 10,000
line long C file that triggered a Clang bug. You don’t want to send a massive
blob to the compiler developers because that’s unhelpful, but you also don’t
want to cut it down to size by hand. The good news is that C-Reduce can do that
for you. The bad news is that everyone thinks it only works for C.</p>

<p>It’s pretty widely applicable. You only need:</p>

<ul>
  <li>A deterministic condition<sup id="fnref:loop" role="doc-noteref"><a href="#fn:loop" rel="footnote">1</a></sup></li>
  <li>A reasonably quick reproducer (it helps with the speed of the reduction)</li>
  <li>One or more mutable source files for C-Reduce to cut down</li>
</ul>

<p>I ran into a bug with <a href="https://github.com/RustPython/RustPython">RustPython</a>
running <a href="https://github.com/tekknolagi/scrapscript">scrapscript</a> and wanted to
report it. So I ran wrote a script <code>interesting.sh</code> to reproduce the bug:</p>

<div><pre><code><span>#!/bin/bash</span>
<span># No -o pipefail; we don't want rustpython failures to cause the script to fail</span>
<span>set</span> <span>-eu</span>

<span># Note the absolute path to the binary, which is not in $PATH</span>
/path/to/RustPython/target/release/rustpython scrapscript.py 2&gt;&amp;1 | <span>grep</span> <span>\</span>
    <span>"tried to push value onto stack but overflowed max_stackdepth"</span>
</code></pre></div>

<p>And then I ran C-Reduce. This all happened within a couple of seconds:</p>

<div><pre><code><span>$</span><span> </span>creduce <span>--not-c</span> interesting.sh scrapscript.py
<span>===&lt; 2263604 &gt;</span><span>===</span>
<span>running 4 interestingness tests in parallel
</span><span>===&lt; pass_blank :: 0 &gt;</span><span>===</span>
<span>(0.5 %, 200799 bytes)
(0.6 %, 200607 bytes)
</span><span>===&lt; pass_lines :: 0 &gt;</span><span>===</span>
<span>(9.2 %, 183225 bytes)
(18.1 %, 165228 bytes)
(26.5 %, 148382 bytes)
(29.3 %, 142674 bytes)
(34.6 %, 131961 bytes)
(38.1 %, 124960 bytes)
(40.6 %, 119872 bytes)
(42.3 %, 116504 bytes)
(44.4 %, 112161 bytes)
(46.4 %, 108180 bytes)
(47.5 %, 105950 bytes)
</span><span>...
</span></code></pre></div>

<p>What you see is C-Reduce cutting down the file by 50% nearly instantly… and I
don’t even have a very fast computer.</p>

<p>We use <code>--not-c</code> because otherwise C-Reduce uses a bunch of C-specific passes.
If we’re working on Python, it will likely just slow things down (but not
materially change the outcome).</p>

<p>There you have it. Fast and easy. As I finish typing these next couple of
sentences, we’re already at 96.9% reduced.</p>


        </div>
            
    <!-- Workaround for FB MITM -->
    <!-- Google tag (gtag.js) -->







    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparing AWS S3 with Cloudflare R2: Price, Performance and User Experience (189 pts)]]></title>
            <link>https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience</link>
            <guid>42256771</guid>
            <pubDate>Wed, 27 Nov 2024 15:26:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience">https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience</a>, See on <a href="https://news.ycombinator.com/item?id=42256771">Hacker News</a></p>
Couldn't get https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Redis Inc seeks control over future of Rust redis-rs client library (112 pts)]]></title>
            <link>https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/</link>
            <guid>42256594</guid>
            <pubDate>Wed, 27 Nov 2024 14:58:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/">https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/</a>, See on <a href="https://news.ycombinator.com/item?id=42256594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
                            <article>
        <div>
            <ul>
                                        <li><a href="https://devclass.com/category/databases/">Databases</a></li>
                                </ul>

            <header>
                <!-- title -->
                <h3>
                    <a href="https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/" rel="bookmark" title="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns">
                        Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns                    </a>
                </h3>

                
            </header>

            <div>
                <!-- image -->
                                        <p><img src="https://devclass.com/wp-content/uploads/2019/04/shutterstock_491993500-768x427.jpg" alt="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns" title="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns">
                                                    </p>
                				
                
<p>Redis inc, whose core product is the formerly open source Redis in-memory database, has prompted further unease in the community by approaching the maintainers of the most popular Rust client library for Redis with the intent either to control or to fork it.</p>



<p>Armin Ronacher, who controls the redis-rs entry on crates.io, the Rust package registry, <a href="https://github.com/redis-rs/redis-rs/issues/1419">posted</a> about an email from Redis product manager Mirko Ortensi, followed by a call, in which the company expressed its desire for a Rust client with official support. The proposal was to take over redis-rs in order to add “enterprise-grade features” but continuing with community contributions and compatibility with the official community edition of Redis.</p>



<p>Ronacher said he understood from the call that “the name of the library constitutes a trademark violation in their mind” and that the options were either to transfer the code to Redis, or to rename the crate. He said he did not wish to be in any kind of trademark dispute. He also expressed concern for those who use the library with Valkey, an open source alternative to Redis.</p>



<p>In March 2024 Redis <a href="https://www.theregister.com/2024/03/22/redis_changes_license/">changed the licensing</a> for its core code from the open source BSD-3 to the Redis Source Available License v2 or the Server Side Public License v1, restricting the use of that code. One of the consequences was the <a href="https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community">formation of Valkey</a>, based on Redis 7.2.4 and continuing with the BSD-3 license.</p>



<p>Ortensi posted to the thread, clarifying that while he had not called the name redis-rs a trademark violation, “companies do consider protecting their trademarks where their reputation is challenged.” He also said that the Redis crate should be for Redis and that Valkey could not guarantee compatibility with Redis long-term and should have its own crate.</p><!-- FALCON via Article Inline Ad -->
            



<p>Valkey maintainer Madelyn Olson said that her hope was “to support both Valkey and Redis [in rust-rs] because of the overlap between the products.”</p>



<p>Another rust-rs committer commented, asking why Redis could not simply contribute pull requests to the existing project for the required new features, as well as support for the forthcoming Redis 8, adding that “I would feel much better about yielding governance if I saw that Redis Inc was actively contributing.”</p>



<p>Apache Software Foundation member Xuanwo pitched in, stating that there are other Redis-compatible services which use the Redis protocol including Apache Kvrocks, as well as others such as DragonflyDB. “If this repository is transferred to Redis, Inc., I would be concerned that Redis, Inc. might introduce breaking changes to the protocol or client itself, preventing users from using this client to access other Redis-compatible services,” he said.</p>



<p>Redis creator Salvatore Sanfilippo, also known as antirez, offered to talk to the Redis company about authorization “so that open source client libraries can use the name ‘Redis’ without issues.”&nbsp;&nbsp;</p>



<p>It was Sanfilippo who made Redis open source in 2009, early in the life of the project, though he stepped down as maintainer in 2020. At the time, Redis <a href="https://redis.io/blog/thank-you-salvatore-sanfilippo/">said</a> that “the core of the open source Redis project will remain under the 3-Clause BSD license,” a promise that was kept only for a few more years.</p>



<div><p>Even if Sanfilippo mitigates the trademark issue, there remains the question of whether Redis Inc will still wish to acquire or fork redis-rs for its own purposes, further alienating the open source community.</p></div>
				
							<!-- QUIZ HERE -->
							
				<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->
            </div>
        </div>
    </article>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emacs arbitrary code execution and how to avoid it (130 pts)]]></title>
            <link>https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html</link>
            <guid>42256409</guid>
            <pubDate>Wed, 27 Nov 2024 14:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html">https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html</a>, See on <a href="https://news.ycombinator.com/item?id=42256409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<header>

<p role="doc-subtitle">Details and advice about a long standing arbitrary code execution vulnerability in Emacs</p>
</header><p>Created on <span><span>[2024-11-27]</span></span>, last updated <span><span>[2024-11-27]</span></span></p>


<p>
This is a security advisory about CVE-2024-53920, an Emacs
vulnerability that I (re-)discovered a few months ago.
</p>
<div id="outline-container-org049caf1">
<h2 id="org049caf1">TL;DR</h2>
<div id="text-org049caf1">
<p>
Viewing or editing Emacs Lisp code in Emacs can run arbitrary code.
The vulnerability stems from unsafe Lisp <i>macro-expansion</i>, which runs
unrestricted Emacs Lisp code.  Most common configurations are
vulnerable (see details below).  The best security measures are:
</p>

<ul>
<li>Avoid visiting untrusted <code>.el</code> files in Emacs</li>
<li>Disable automatic error checking (with Flymake or Flycheck) in
untrusted <code>.el</code> files</li>
<li>Disable auto-completion features in untrusted <code>.el</code> files</li>
</ul>

<p>
This is a long-standing vulnerability which has been known for several
years, but has not been addressed thus far.  Emacs maintainers are
working on countermeasures that will hopefully make their way into
future Emacs versions.  This advisory is intended to help users of
existing Emacs versions protect themselves.
</p>
</div>
</div>
<div id="outline-container-org33b9590">
<h2 id="org33b9590">Background</h2>
<div id="text-org33b9590">
<p>
<i>Macros</i> are a staple feature across Lisp dialects.  They are often
cited as one of the superpowers of Lisp.  They are essentially a
meta-programming facility: a macro is just a Lisp function that
outputs Lisp code.  Since Lisp is homoiconic (code and data are
represented using the same data structures), manipulating Lisp code in
Lisp is as simple as processing any other program input.  This makes
such meta-programming fun and easy, especially in comparison to the
experience of writing elaborate C preprocessor macros, for example,
which often feels a bit hackish.
</p>

<p>
However, as is often the case with great powers, Lisp macros are
double-edged swords—wielding them safely requires special care.
</p>

<p>
Normally, macros are executed, or “expanded”, during so-called
macro-expansion time: after parsing (“reading”) text into a Lisp form,
macro calls that occur in the form are expanded by executing the
macro, which produces new (sub-)forms.  The macro-free form obtained
by expanding all macro calls can then be compiled and executed.  Thus
macro-expansion time comes after “read time” and before compile time
and runtime.
</p>

<p>
<i>Emacs Lisp</i> is the programming language used implement most of
Emacs’s core features and extensions, as well to configure it.  It is
not the most powerful Lisp dialect out there, but it does boast a
full-blown meta-programming facility in the form of macros.  The
problem is that macros in Emacs Lisp come with no safety
measures—they can execute arbitrary, unrestricted, Emacs Lisp code.
The basic macro-expansion primitive in Emacs is the Lisp function
<code>macroexpand</code>, defined in C code in <code>src/eval.c</code> in the Emacs sources.
It repeatedly replaces macro names with their definitions as
functions, and applies those functions to the provided code:
</p>

<div>
<pre><span>while</span> <span>(</span>1<span>)</span>
  <span>{</span>
    

...
    <span>{</span>
      <span>Lisp_Object</span> <span>newform</span> = apply1 <span>(</span>expander, XCDR <span>(</span>form<span>)</span><span>)</span>;
      <span>if</span> <span>(</span>EQ <span>(</span>form, newform<span>)</span><span>)</span>
        <span>break</span>;
      <span>else</span>
        form = newform;
    <span>}</span>
  <span>}</span>
<span>return</span> form;
</pre>
</div>

<p>
That <code>apply1</code> call up there can do, well, literally anything,
depending on the <code>expander</code> function (the definition of the macro) and
the given input <code>form</code>.
</p>

<p>
The Emacs Lisp library <code>macroexp.el</code> provides higher-level routines on
top of this <code>macroexpand</code> primitive, such as <code>macroexpand-all</code> which
the Lisp byte-compiler in <code>bytecomp.el</code> uses to preprocess Lisp forms.
</p>

<p>
In addition, Emacs ships with several built-in macros that actually do
execute arbitrary code by <i>evaluating</i> some of their arguments, no
questions asked.  These macros are <code>static-if</code>, <code>rx</code>, <code>cl-eval-when</code>,
<code>eval-when-compile</code>, <code>eval-and-compile</code>, and perhaps others.
</p>

<p>
Therefore, if we can nudge Emacs to expand one of these macros, we get
arbitrary code execution.  That’s the crux of this vulnerability.
<i>Expanding macros in Emacs Lisp is unsafe by design</i>.
</p>
</div>
</div>
<div id="outline-container-org435223b">
<h2 id="org435223b">Exploitation</h2>
<div id="text-org435223b">
<p>
But could an attacker really coerce Emacs to expand macros without an
explicit user request?  When you open (or “visit”, in Emacs parlance)
an Emacs Lisp file, Emacs enables “ELisp mode”, a dedicated editor
mode defined in <code>elisp-mode.el</code>, which provides various useful
features for exploring and editing Emacs Lisp code.
</p>

<p>
One of the features that ELisp mode provides is code completion.
Completion is implemented in the function <code>elisp-completion-at-point</code>,
which tries to examine the code around your cursor and come up with
relevant completions.  Among other things, it invokes a subroutine
<code>elisp--local-variables</code> that looks for local variable names in the
current scope.  Since macros can completely change the meaning of the
code they apply to, <code>elisp--local-variables</code> expands macros in the
surrounding code to uncover local variables that may be created or
obscured by such macros.  Hence <i>invoking code completion runs
arbitrary code</i>.  In vanilla Emacs, by default, code completion is
only triggered when you issue a completion command.  However, since
macros run arbitrary code in a Turing complete language (Emacs Lisp),
there’s no way to know for sure whether invoking completion will get
you pwned.  More importantly, almost no one uses the default Emacs
configuration.  Emacs users tweak various knobs, and in many common
configurations folks enable auto-completion features which then
trigger code completion without an explicit completion command.  Such
auto-completion is performed by the popular Emacs packages Corfu and
Company, as well as the newly built-in <a href="https://eshelyaron.com/posts/2023-11-17-completion-preview-in-emacs.html">Completion Preview mode</a>.
</p>

<p>
But the most common flow that involves automatic macro-expansion is
probably <i>on-the-fly code diagnosis</i>.  There are two widespread Emacs
packages that check your code and warn about potential errors
automatically.  One is Flymake, which is built into Emacs, and the
other is a popular extension package called <a href="https://www.flycheck.org/en/latest/">Flycheck</a>.  Both of them,
when enabled in an ELisp mode buffer, check for code issues by
<i>byte-compiling</i> the code.  As mentioned earlier, this involves
macro-expansion, and thus arbitrary code execution.  For Flymake, this
byte-compilation happens in the function <code>elisp-flymake-byte-compile</code>.
Like auto-completion, on-the-fly diagnosis is not enabled by default
in vanilla Emacs, but it is extremely common for users to enable it.
In some Emacs “distributions”, such as the popular <a href="https://github.com/doomemacs/doomemacs">Doom Emacs</a> and
<a href="https://prelude.emacsredux.com/en/latest/">Prelude</a>, either Flymake or Flycheck are enabled by default in ELisp
mode.
</p>

<p>
So the idea is simple: to exploit this vulnerability, an attacker
crafts an Emacs Lisp file that includes a malicious macro invocation,
and sends that file to an unsuspecting Emacs user.  When that user
opens the file in Emacs, code diagnosis is triggered automatically,
which expands macros and executes arbitrary code.
</p>

<p>
Here’s the content of the POC “malicious” file that I shared with the
Emacs maintainers when reporting this vulnerability:
</p>

<div>
<pre><span>(</span><span>rx</span> <span>(</span>eval <span>(</span><span>call-process</span> <span>"touch"</span> nil nil nil <span>"/tmp/owned"</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
If you have Flymake or Flycheck hooked to ELisp mode (again, such a
setting is often the default in Emacs starter kits, and generally very
common among Emacs users), then just putting the above line of code
anywhere in a <code>.el</code> file and opening that file in Emacs will create a
new file <code>/tmp/owned</code> on your system.  Such a setup usually looks
something like the following in the Emacs initialization file,
<code>~/.emacs.d/init.el</code>:
</p>

<div>
<pre>
<span>(</span><span>add-hook</span> 'emacs-lisp-mode-hook #'<span>flymake-mode</span><span>)</span>
</pre>
</div>

<p>
This is reproducible at least since Emacs version from 26.1 and all
the way up to the development version of the upcoming Emacs 30.
</p>

<p>
So this is a long-standing vulnerability, and the gist of it is very
simple: macros are unsafe, and in common setups Emacs expands them
automatically.  I’ve come to discover this issue while working on an
enhancement for ELisp mode, which employed macro-expansion to provide
semantic code highlighting.  I quickly realized that doing so naively
is a security risk, and soon afterwards it hit me that Emacs suffered
from such a vulnerability already without my custom hacks.
</p>

<p>
The very same day, 17/08/2024, I reported my findings to the Emacs
maintainers via private email.  The maintainers informed me that
variants of this issue have been surfaced in the past, but the issue,
sadly, still stands.  AFAICT the earliest public discussion about the
security implications of Emacs Lisp macros started in August 2018,
when <a href="https://yhetil.org/emacs/CAFXAjY5f4YfHAtZur1RAqH34UbYU56_t6t2Er0YEh1Sb7-W=hg@mail.gmail.com/">Wilfred Hughes noted</a> that code completion can lead to arbitrary
code execution via macro-expansion.  In October 2019, <a href="https://yhetil.org/emacs/CAJw81da4=R1jMJ0enx6SbO7G1rzaL61K2kqbY+jxhe=AM-3vtQ@mail.gmail.com/">Adam Plaice
reported</a> that Flymake specifically can be used in a similar exploit.
Some solutions have been floated in the discussions following these
reports, but unfortunately, Emacs remains vulnerable to this very day.
</p>

<p>
Following my report, the maintainers requested 90 days to work on a
fix before public disclosure.  That non-disclosure period have since
expired, hence this advisory.  They continue to work on a fix, which I
hope will be available soon, and now we at least have a CVE to track
this vulnerability.  Until new guardrails are put in place to mitigate
this risk, it is important to realize that macro-expansion of
untrusted Emacs Lisp code is unsafe, and to be vigilant about <code>.el</code>
files that you open in Emacs.  Crucially, <b>do not enable
Flymake/Flycheck in ELisp mode automatically</b>.  Only allow automatic
macro-expansion in <code>.el</code> files that trust and you control, and protect
those files from tampering.
</p>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Art and Mathematics of Genji-Ko (107 pts)]]></title>
            <link>https://www.oranlooney.com/post/genji-ko/</link>
            <guid>42256394</guid>
            <pubDate>Wed, 27 Nov 2024 14:33:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.oranlooney.com/post/genji-ko/">https://www.oranlooney.com/post/genji-ko/</a>, See on <a href="https://news.ycombinator.com/item?id=42256394">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <img src="https://www.oranlooney.com/post/genji-ko_files/lead.jpg">
      
      
      
      <hr>
      <ul>
        
        <li><time>November 26, 2024</time></li>
        <li>
          <a href="https://www.oranlooney.com/tags/math/">
            <i></i>
            Math
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/visualization/">
            <i></i>
            Visualization
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/history/">
            <i></i>
            History
          </a>&nbsp;
        </li>
        <li>
          <a href="https://www.oranlooney.com/tags/python/">
            <i></i>
            Python
          </a>&nbsp;
        </li>
      </ul>
      

      

<p>You might think it’s unlikely for any interesting mathematics to arise from
incense appreciation, but that’s only because you’re unfamiliar with the
peculiar character of <a href="https://en.wikipedia.org/wiki/Muromachi_period">Muromachi (室町) era</a> Japanese nobles.</p>

<p>There has never been a group of people, in any time or place, who were so driven
to display their sophistication and refinement. It wouldn’t do to merely put
out a few sticks of incense; no, you would have to prove that your taste was
more exquisite, your judgment more refined, your etiquette more oblique. You
could of course merely invite some other nobles over for an incense
appreciation party, make a few cutting but plausibly deniable remarks about a
rival, maybe drop a few lines of poetry linking the incense to the current
season. But if you were really on the ball you’d be looking for a way to
simultaneously humiliate your rivals, flirt with your love interest, and
impress people in a position of power. They didn’t just perfect cultured
refinement: they weaponized it.</p>

<p>Only under such conditions could something like Genji-kō (源氏香) arise. It is
a parlor game played with incense—just one of many similar games inside the
broader umbrella of kōdō (香道), the traditional Japanese art of incense
appreciation.</p>

<p>What sets Genji-kō apart is its extreme difficulty - where another kōdō game
might have contestants write down their guesses for three separate incenses and
score a point for each correct guess, Genji-kō asks contestants to smell five
separate samples, then determine which of the five were the same scent. All
five might be the same, all five might be different, or (and this is where it
gets interesting) they might be in groups of two or three or four.</p>

<p>Contestants score a single point by correctly guessing all five incenses;
otherwise they score nothing. A typical game has five rounds over the course of
an evening, with an overall winner declared at the end.</p>

<p>Obviously contestants would need some kind of notation to submit their answers
in a concise and unambiguous way, and it is really about this notation (and
the art, mathematics, and culture connected to it) that this article is about.</p>

<h2 id="notation">Notation</h2>

<p>The solutions that Genji-kō players submit are called Genji-mon (源氏紋) and
are drawn with exactly five vertical lines, representing the five possible
incenses. To show that two or more incenses are part of the same group, you
draw a horizontal line connecting the top of every vertical line in that group.
To avoid confusion when there are two or more groups, you draw these horizontal
lines at different heights, shortening the vertical lines as needed:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/examples.png"></p>

<p>There are a few nuances worth mentioning. If two groups don’t overlap, there is
no need to draw them at different heights (top center.) Sometimes it is
impossible to avoid an intersection (bottom center) but it is clear that groups
are distinct because the horizontal connecting lines are at different heights;
nevertheless, we try to minimize such intersections.</p>

<p>Genji-kō features as a plot point in <a href="https://www.imdb.com/title/tt2076558/">episode 8 of the experimental horror
anime Mononoke</a>, where it is suggested that players used blocks to
record their solutions:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/blocks.png"></p>

<p>While this might be true - the episode’s description of Genji-Kō is otherwise
grounded and well-researched - I haven’t seen any other references to this;
everything else I’ve seen indicates the game was played with ink and paper. I
think it’s probably just a case of artistic license.</p>

<h2 id="etymology">Etymology</h2>

<p>Genji-kō, by the way, is named after the titular Genji of the Heian (平安) era
literary classic <a href="https://en.wikipedia.org/wiki/The_Tale_of_Genji"><em>The Tale of Genji</em></a>. (The fact that “Genji” is a proper
name is also why I capitalize Genji-kō and Genji-mon.)</p>

<p>There are two connections. First, in one chapter of the book Genji hosts an
incense appreciation party. Second, since there are 52 possible patterns and 54
chapters of the book, each Genji-mon is traditionally associated with—and
named after—a chapter, except for the first and last chapters, which are
omitted.</p>

<p>Every educated person of the Muromachi era would have been be intimately
familiar with <a href="https://en.wikipedia.org/wiki/The_Tale_of_Genji"><em>The Tale of Genji</em></a> and would know the themes, season, and
characters associated with each chapter by heart, giving each pattern a
literary resonance. A skillful kōdō practitioner hosting a game of Genji-kō
would choose a solution that referenced the current season or recent event,
adding both a additional layer of meaning to the game and a hint to skilled
players.</p>

<p>There are <a href="#names#">several different words</a> we could use to refer
to the patterns themselves, but I’ve chosen Genji-mon as it seems to be the
most common.</p>

<h2 id="cultural-influence">Cultural Influence</h2>

<p>Compared to other traditional arts from the same era such as tea ceremony or
flower arranging, kōdō is not particularly popular or well-known, even in
Japan; nevertheless it is <a href="https://www.youtube.com/watch?v=wpDb5LhvvSM">still played</a> even to this day.</p>

<p>However, its cultural influence extends beyond the few who actually play the
game - the patterns show up fairly often as motifs in contemporary Japanese
graphic design, and it’s especially popular on traditional goods such as
kimono:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/genjiko_colorful.jpg">
<img src="https://www.oranlooney.com/post/genji-ko_files/kimono.jpg">
</p>

<p>While
<a href="https://www.oranlooney.com/post/genji-ko_files/cheap_genjiko_kimono.jpg" target="_blank">cheaper fabrics</a>
simply print the same Genji-mon repeatedly, high-quality Genji-Kō textiles will
use a variety of Genji-mon so that the pattern seems to never quite repeat:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/fabric.jpg"></p>

<p>Naturally, Genji-mon are often found on goods related to incense in some way,
such as this kōdō set, incense box, or incense holder:</p>

<p><img "display:inline;="" padding:="" 0px;"="" src="https://www.oranlooney.com/post/genji-ko_files/incense_set.jpg">
<img src="https://www.oranlooney.com/post/genji-ko_files/incense_box.jpg">
<img src="https://www.oranlooney.com/post/genji-ko_files/incense_holder.jpg">
</p>

<p>In the 1840s <a href="https://en.wikipedia.org/wiki/Kunisada">Kunisada</a> painted a series of wall scrolls, one for each
chapter of <a href="https://en.wikipedia.org/wiki/The_Tale_of_Genji"><em>The Tale of Genji</em></a>, and included the associated Genji-mon on
each:</p>

<p><a href="https://www.oranlooney.com/post/genji-ko_files/minori_wall_scroll.png" target="_blank">
<img src="https://www.oranlooney.com/post/genji-ko_files/minori_wall_scroll.png">
</a></p>

<h2 id="drawing-genji-mon">Drawing Genji-Mon</h2>

<p>To draw Genji-Mon programmatically, we’ll use the standard recursive algorithm
to generate all possible partitions for a set of five elements:</p>

<pre><code>def partitions(s: Set[int]) -&gt; Iterator[List[Set[int]]]:
    """Yield all partitions of a set as they are generated."""
    if not s:
        yield []
        return
    first = next(iter(s))
    rest = s - {first}
    for partition in partitions(rest):
        yield [{first}] + partition
        for i in range(len(partition)):
            new_partition = (
                partition[:i] + 
                [partition[i] | {first}] + partition[i+1:]
            )
            yield new_partition
</code></pre>

<p id="maintext1">
However, the partition alone does not suffice to fully characterize a Genji-mon.
While we must draw overlapping groups at different heights to avoid ambiguity,
there is still a free choice about which groups we make taller. After studying
the chart of traditional Genji-mon, two rules became clear:
</p>

<ol>
<li>Groups should be as tall as possible.</li>
<li>Groups entirely inside<a href="#footnote1"><sup>†</sup></a> other
groups should be lower and appear to nest inside the outer group.</li>
</ol>

<p>I implemented this as a simple brute-force cost-based optimizer, because that
made it easy to experiment with different rules. (Even though in the end I
only used those two simple rules, I experimented with many others trying to
get rid of the remaining special cases, which I’ll discuss below.)</p>

<pre><code>def optimal_genjiko_for_partition(
    partition: List[Set[int]]
) -&gt; List[Tuple[float, Set[int]]]:
    """
    Given a partition, find the optimal Genji-kō layout by minimizing a cost
    function.
    """
    best_cost = math.inf
    best_genjiko = None
    HEIGHTS = [1.0, 0.8, 0.6]
    
    # Generate all possible combinations of heights
    for height_combo in itertools.product(HEIGHTS, repeat=len(partition)):
        genjiko_candidate = [
            (height, group) 
            for height, group 
            in zip(height_combo, partition)
        ]
        
        # Skip invalid configurations
        if not validate_genjiko(genjiko_candidate):
            continue
        
        # Encourage larger heights
        cost = -sum(height for height, _ in genjiko_candidate)  
        
        for height1, group1 in genjiko_candidate:
            for height2, group2 in genjiko_candidate:
                # Large penalty for higher inner group height
                if is_nested_within(group1, group2) and height1 &gt; height2:
                    cost += 1
        
        # keep track of the best solution so far
        if cost &lt; best_cost:
            best_cost = cost
            best_genjiko = genjiko_candidate

    return best_genjiko
</code></pre>

<p><a href="https://github.com/olooney/genjiko/blob/main/src/genjiko.py#L122">Drawing these using Pillow</a> or <a href="https://github.com/olooney/genjiko/blob/main/src/genjiko.py#L270">organizing them into a grid</a> is
straight-forward, so you can check the source code if you’re interested in
those details.</p>

<p>Here’s what we get if always use the algorithmically calculated “optimal”
layout and simply put them in the order returned by <code>partitions()</code>:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/algorithmic_genjiko.png"></p>

<p>Good, but not perfect. The order is only vaguely similar, and the four Genji-mon
rendered in red are the ones where our “optimal” layout has failed to reproduce
the traditional design.</p>

<h2 id="maintext2">Genji-mon Order</h2>

<p>In the introduction he wrote for a <a href="https://www.amazon.com/Combinatorics-Ancient-Modern-Robin-Wilson/dp/0198739052">book on ancient combinatorics</a>, Knuth
<a href="https://www.oranlooney.com/post/genji-ko_files/combanatorics_ancient_and_modern_page.png" target="_blank">mentions</a>
that the Genji-mon “were not arranged in any particularly logical order” and
I’m inclined to agree. I tried several variations of the above <code>partition()</code>
function hoping to find one where the traditional order would just fall out
naturally, but it never did. A close inspection of the traditional order makes
it clear that this was never going to happen: While there is an overall trend
from many to fewer groups, there are just too many cases where the order is
clearly arbitrary.</p>

<p>I found a several references that put them in a different order, and even some
that tried to stretch it to 54 using some kind of
<a target="_blank" href="https://www.oranlooney.com/post/genji-ko_files/dupes.gif">duplication</a>
or introducing
<a target="_blank" href="https://www.oranlooney.com/post/genji-ko_files/irregular.jpg">irregular</a>
patterns.<sup><a href="#footnote2">*</a></sup>
However, if we recall what the notation is designed to represent this is
clearly nonsense: simultaneously useless for playing Genji-kō, mathematically
impossible, and at odds with tradition.</p>

<p>However, the association between the 52 patterns and chapter titles for
chapters 2-53 of the <em>Tale of Genji</em> seems watertight and consistent for
centuries back. Also, the order of the chapters is mostly consistent across
sources (there is some disagreement about the order of the later chapters, and
one chapter which survives only as a title or perhaps was intentionally elided
as a delicate way to allude to a character’s death) so I’ve put my Genji-mon in
chapter order following Waley. You can find the full table in
<a href="#table">Appendix C</a>.</p>

<h2 id="special-cases">Special Cases</h2>

<p>I spent some time trying to find some elegant heuristic that would nudge
the layout algorithm to produce those four without breaking any of the others,
but the rules were more complex than simply listing the special cases (and
none of them correctly handled Yūgiri (夕霧), which I’ll discuss below.)</p>

<p>The four special cases are:</p>

<pre><code>    # Suma: {1, 3, 4} should be lower than {2, 5}
    df.at[10, "Layout"] = [ (0.8, {1, 3, 4}), (1.0, {2, 5}) ]
    
    # Hatsune: {1, 3} should be lower than {2, 4}
    df.at[21, "Layout"] = [ (0.8, {1, 3}), (1.0, {2, 4}), (1.0, {5}) ]
    
    # Yugiri: {1, 4} should be lower than {3, 5}, and {2} even lower.
    df.at[37, "Layout"] = [ (0.8, {1, 4}), (0.6, {2}), (1.0, {3, 5}) ]
    
    # Nioumiya: {1, 2, 4} should be lower than {3, 5}
    df.at[40, "Layout"] = [ (0.8, {1, 2, 4}), (1.0, {3, 5}) ]
</code></pre>

<p>With these corrections, and using the <em>Tale of Genji</em> chapter order:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/genjiko.png"></p>

<p>Of the four exceptions, two are obvious improvements (fixing the “hole” in Suma
and the “dent” in Hatsune), and one (Nioumiya) is a matter of indifference.
However, the fourth, Yūgiri, seems to actively violate the basic rules around
nesting and creates a three-level structure when two would have sufficed:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/yugiri_diff.png"></p>

<p>The cost-based optimizer would never have chosen that layout because its most
basic tenet is to make the groups as tall as possible. A heuristic, let me
remind you, that holds for the other 51 Genji-mon. However, all the examples
of Yūgiri I found online use the traditional design, such as this
<a href="https://www.oranlooney.com/post/genji-ko_files/yugiri_wall_scroll.png" target="_blank">wall scroll</a>
by <a href="https://en.wikipedia.org/wiki/Kunisada">Kunisada</a> or this woodblock print by <a href="https://en.wikipedia.org/wiki/Masao_Maeda">Masao Maeda</a>:</p>

<p><a href="https://www.oranlooney.com/post/genji-ko_files/yugiri_woodblock_print.png" target="_blank">
<img src="https://www.oranlooney.com/post/genji-ko_files/yugiri_woodblock_print.png">
</a></p>

<p>So I don’t think I have a leg to stand on unless I want to fly in the face of
hundreds of years of tradition; we’ll just have to hard-code Yūgiri as a
special case.</p>

<h2 id="counting-genji-mon">Counting Genji-Mon</h2>

<p>The connection between Genji-kō and mathematics becomes apparent if we ask
ourselves, “Why are there exactly 52 Genji-mon patterns? How can we be sure
there aren’t more?”</p>

<p>Like a lot of questions in mathematics, it helps to generalize things. Instead
of focusing on five incenses, let’s ask ourselves, how many unique ways are
there of grouping $n$ elements? This approach lets us ease into the problem,
starting with a simpler case and building complexity gradually.</p>

<p>For $n = 1$, there’s clearly only solution:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/counting_partitions1.png"></p>

<p>For $n = 2$, there are only two possible solutions. Either the first element is
in a group by itself, or it is in a group with another.</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/counting_partitions2.png"></p>

<p>For $n = 3$, things start to get more interesting. Let’s repeat the trick we
used for $n = 2$ and focus on the first element. It must either be in a group
by itself, in a pair with another, or in the same group as all others. That
gives us exactly three cases to consider:</p>

<ol>
<li>If the first element in a group by itself, then there are two elements left
over; We showed above that there are two ways to partition them.</li>
<li>If it’s in a pair, then we have a choice: we can either pair it with the
second or third element. In either case there will only be one element left
over.</li>
<li>And there is only one way to have all the elements be in the same
group.</li>
</ol>

<p>Here they all are, in Genji-kō notation:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/counting_partitions3.png"></p>

<p>Thus, we have $1 \times 2 + 2 \times 1 + 1 = 5$ ways to partition a set of
three elements.</p>

<p>This is starting to look like a repeatable strategy. We always start by
focusing on the first element. We then neatly divide the set of all possible
solutions by the size $k$ of the group containing this first element. For each
$k$ between $1$ and $n$, there are two questions to ask:</p>

<ol>
<li>How many ways are there of choosing the set that contains the first element?</li>
<li>How many ways are there of putting the remaining $n-k$ elements into groups?</li>
</ol>

<p>Let’s try that out for $n = 4$. The other cases are obvious, but let’s focus on
the case where $k = 2$ as there’s a new wrinkle there. We have to choose one
other element from three possible elements, so there are three ways of doing
that. We’ll always have two left over, and there are always two ways of
grouping those together. This these are two independent choices - choosing the
first group, then choosing how to partition the remaining elements, there are
$3 \times 2 = 6$ ways of doing that. This case teaches us that we have to
count both the ways of selecting a set of $k$ elements and the number of ways
to partition the remaining elements, and multiply them together.</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/counting_partitions4.png"></p>

<p>So, for $n = 4$, there are $1 \times 5 + 3 \times 2 + 3 \times 1 + 1 = 15$
possible solutions.</p>

<h2 id="mathematical-approach">Mathematical Approach</h2>

<p>For the case of $n = 5$, I’ve
<a href="https://www.oranlooney.com/post/genji-ko_files/counting_partitions5.png" target="_blank">generated the diagram</a>
showing how to use the same strategy to count all possible Genji-mon,
but I think it’s more useful to take the strategy we’ve learned and abstract it.</p>

<p>First, let’s use the right terminology. What we’ve so far called a “Genji-mon,”
mathematicians would call a <a href="https://en.wikipedia.org/wiki/Partition_of_a_set">partition</a>. In mathematical terms, the question
we’re asking is, “How many distinct partitions are there for a set of $n$
elements?” This number also has a name: the <a href="https://en.wikipedia.org/wiki/Bell_number">Bell number</a> denoted $B_n$.</p>

<p>Above, we calculated $B_1$ through $B_4$ using a mix of intuition and common
sense. To formalize the strategy we used in mathematical notation we’ll need a
concept you may or may not have seen before: “the number of ways to choose $k$
elements from $n$ distinct elements, ignoring order” is called “$n$ choose $k$”
or the <a href="https://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a> and is denoted $nCk$ or with this tall
bracket notation:</p>

<p>\[
    \binom{n}{k} = \frac{n!}{k! (n-k)!}
\]</p>

<p>There are many ways of deriving the equation in terms of factorials, but here’s
one I like: imagine we put all $n$ elements in order; there are $n!$ ways of
doing that. Then we always take the $k$ leftmost elements for our choice. However,
because order doesn’t matter, we divided by all the different ways of ordering
the $k$ chosen elements, which is $k!$, and the $n-k$ remaining elements, which
is $(n-k)!$.</p>

<p>With that tool in hand, we can define the Bell numbers recursively. The first
couple can be treated as special cases, since obviously there’s only one way to
partition a set of zero or one elements:</p>

<p>\[
    B_0 = 1,  B_1 = 1
\]</p>

<p>For $n &gt; 1$, we generalize the strategy we discovered above:</p>

<ol>
<li>Pick an arbitrary element to represent the “first element.”</li>
<li>We’ll call whichever set in the partition that contains this first element
the “first set.” Every element is in exactly one set of the partition, so this
uniquely picks out a particular set in the partition.</li>
<li>For each $k$ between $1$ and $n$, consider only partitions where the first
set is of size $k$. This divides the problem up into non-overlapping buckets:
if two partitions have different sized first set, they cannot
possibly be the same.</li>
<li>We have to make a choice about the other $k-1$ elements to include in the
first set, and there are $\binom{n-1}{k-1}$ ways of doing that.</li>
<li>Regardless of which elements we choose for the first set, there will always
be $n-k$ elements left over. They won’t always be the same elements,
but there will always be $n-k$ of them. Thankfully, we already know how many
ways there are to partition a set of $n-k$ elements: it’s $B_{n-k}$.</li>
<li>Since our choices for step 4 and step 5 are independent, we can <em>multiply</em>
the two counts together to get the total number of partitions where the
first set is of size $k$.</li>
<li>Finally, we just have to add up everything for $k$ from $1$ to $n$.</li>
</ol>

<p>In concise mathematical notation, this algorithm is:</p>

<p>\[
    B_{n} = \sum_{k=1}^{n} \binom{n-1}{k-1} B_{n-k}   \tag{1}
\]</p>

<p>We can make this a little neater if we run $k$ from $0$ to $n-1$ instead and
use the fact that $\binom{n}{r} = \binom{n}{n-r}$ to count down instead of up:</p>

<p>\[
    B_{n} = \sum_{k=0}^{n-1} \binom{n-1}{k} B_{k}     \tag{2}
\]</p>

<p>Substituting $n+1$ for $n$ we can put the recurrence relation in an even tidier
form, which is the canonical form you’ll find in textbooks:</p>

<p>\[
    B_{n+1} = \sum_{k=0}^n \binom{n}{k} B_k           \tag{3}
\]</p>

<p>Equation $(3)$ looks a little cleaner and easier to work with, and can be
understood intuitively if you reconceptualize $k$ not as the number of elements
in the first group, but as the number of elements <em>not</em> in the first group.
Shifting to calculating $B_{n+1}$ also allows us to get rid of the “minus
ones” in the original that made the expression seem messy. However, it’s a
little divorced from the intuition about pinning the size of the first set we
used to motivate $(1)$ although of course they’re completely equivalent
mathematically.</p>

<h2 id="computing-bell-numbers">Computing Bell Numbers</h2>

<p>Of these three equivalent equations, $(2)$ is the most natural fit for a Python
implementation because <code>range(n)</code> naturally runs from <code>0</code> to <code>n-1</code> and it makes
far more sense to implement a function for $B_n$ instead of $B_{n+1}$:</p>

<pre><code>def bell_number(n: int) -&gt; int:
    """Calculate the Bell number for any integer `n`."""
    if n &lt; 0:
        raise ValueError("The Bell number is not defined for n &lt; 0.")
    elif n &lt; 2:
        return 1
    else:
        return sum(
            comb(n-1, k) * bell_number(k)
            for k in range(n)
        )
</code></pre>

<p>(Optimizing this function is left as an exercise to the reader, who may find the
techniques described in my earlier article on writing <a href="https://www.oranlooney.com/post/fibonacci/">a fairly fast Fibonacci
function</a> helpful.)</p>

<p>We can use it to calculate the first 20 Bell numbers:</p>

<div id="bell-table">
    <table>
        <thead>
            <tr>
                <th>$n$</th>
                <th>$B_n$</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>0</td>
                <td>1</td>
            </tr>
            <tr>
                <td>1</td>
                <td>1</td>
            </tr>
            <tr>
                <td>2</td>
                <td>2</td>
            </tr>
            <tr>
                <td>3</td>
                <td>5</td>
            </tr>
            <tr>
                <td>4</td>
                <td>15</td>
            </tr>
            <tr>
                <td>5</td>
                <td>52</td>
            </tr>
            <tr>
                <td>6</td>
                <td>203</td>
            </tr>
            <tr>
                <td>7</td>
                <td>877</td>
            </tr>
            <tr>
                <td>8</td>
                <td>4,140</td>
            </tr>
            <tr>
                <td>9</td>
                <td>21,147</td>
            </tr>
            <tr>
                <td>10</td>
                <td>115,975</td>
            </tr>
            <tr>
                <td>11</td>
                <td>678,570</td>
            </tr>
            <tr>
                <td>12</td>
                <td>4,213,597</td>
            </tr>
            <tr>
                <td>13</td>
                <td>27,644,437</td>
            </tr>
            <tr>
                <td>14</td>
                <td>190,899,322</td>
            </tr>
            <tr>
                <td>15</td>
                <td>1,382,958,545</td>
            </tr>
            <tr>
                <td>16</td>
                <td>10,480,142,147</td>
            </tr>
            <tr>
                <td>17</td>
                <td>82,864,869,804</td>
            </tr>
            <tr>
                <td>18</td>
                <td>682,076,806,159</td>
            </tr>
            <tr>
                <td>19</td>
                <td>5,832,742,205,057</td>
            </tr>
            <tr>
                <td>20</td>
                <td>51,724,158,235,372</td>
            </tr>
        </tbody>
    </table>
</div>

<p>And there it is: $B_5 = 52$, confirming that there are exactly 52 Genji-mon,
no more and no fewer.</p>

<h2 id="conclusion">Conclusion</h2>

<p>It’s not too surprising that some of these ideas were worked out over seven
hundred years ago; combinatorics is an easy branch to stumble into when it
arises in connection to some practical problem. It does, however, feel slightly
surreal that it was a bunch of bored nobles playing an esoteric parlor game who
first noticed these patterns and used it to attach literary significance to
their activities. But I’m happy they did so, because they did something we mere
number crunchers would not have thought to do: they made them beautiful.</p>

<hr>

<h2 id="appendices">Appendices</h2>

<h3 id="appendix-a-source-code">Appendix A: Source Code</h3>

<p>The full <a href="https://github.com/olooney/genjiko">source code</a> use for this article is available on GitHub. The
main Python code is in <a href="https://github.com/olooney/genjiko/blob/main/src/genjiko.py">src/genjiko.py</a> and the <a href="https://github.com/olooney/genjiko/tree/main/notebooks">notebooks</a>
directory contains many examples of usage.</p>

<h3 id="appendix-b-alternative-genji-kō-chart-a-name-chart-a">Appendix B: Alternative Genji-Kō Chart<a name="chart"></a></h3>

<p>Genji-mon are often rendered with thick lines which achieves an interesting
effect with the negative space. By playing around with the parameters a little:</p>

<pre><code>genjiko_df = load_genjiko()
genjiko_df['Color'] = "black"
draw_annotated_genjiko_grid(
    genjiko_df,
    cell_size=82,
    grid_width=8,
    grid_height=7,
    line_width=14,
    padding=20,
    include_index_label=False,
    include_romaji_label=False,
    grid_indent=1,
)
</code></pre>

<p>We can achieve a very attractive result:</p>

<p><img src="https://www.oranlooney.com/post/genji-ko_files/genjiko_dense.png"></p>

<h3 id="table">Appendix C: Full Table</h3>

<p>Here is the full table in HTML format, so you can copy-and-paste the kanji and other
fields. The Genji-mon column uses the <a href="https://www.illllli.com/font/symbol/genjiko/">Genji-Kō TrueType font available from
illllli.com</a>.</p>

<p>You can also download this same table as a <a href="https://www.oranlooney.com/post/genji-ko_files/genjiko.csv">UTF-8 encoded CSV file</a>
or <a href="https://www.oranlooney.com/post/genji-ko_files/genjiko.xlsx">Excel spreadsheet</a>.</p>

<div>
    
    <table>
        <thead>
            <tr>
                <th>Chapter</th>
                <th>Kanji</th>
                <th>Romaji</th>
                <th>English</th>
                <th>Partition</th>
                <th>Genji-mon</th>
            </tr>
        </thead>
        <tbody>
            
            <tr>
                <td>2</td>
                <td>帚木</td>
                <td>Hōkigi</td>
                <td>The Broom Tree</td>
                <td>{1}, {2}, {3}, {4}, {5}</td>
                <td>B</td>
            </tr>
            
            <tr>
                <td>3</td>
                <td>空蝉</td>
                <td>Utsusemi</td>
                <td>Utsusemi</td>
                <td>{1}, {2}, {3}, {4, 5}</td>
                <td>C</td>
            </tr>
            
            <tr>
                <td>4</td>
                <td>夕顔</td>
                <td>Yūgao</td>
                <td>Yūgao</td>
                <td>{1}, {2}, {3, 4}, {5}</td>
                <td>D</td>
            </tr>
            
            <tr>
                <td>5</td>
                <td>若紫</td>
                <td>Wakamurasaki</td>
                <td>Young Murasaki</td>
                <td>{1}, {2, 3}, {4, 5}</td>
                <td>E</td>
            </tr>
            
            <tr>
                <td>6</td>
                <td>末摘花</td>
                <td>Suetsumuhana</td>
                <td>The Saffron Flower</td>
                <td>{1, 2, 3, 4}, {5}</td>
                <td>F</td>
            </tr>
            
            <tr>
                <td>7</td>
                <td>紅葉賀</td>
                <td>Momijinoga</td>
                <td>The Festival of Red Leaves</td>
                <td>{1}, {2, 3, 5}, {4}</td>
                <td>G</td>
            </tr>
            
            <tr>
                <td>8</td>
                <td>花宴</td>
                <td>Hana no En</td>
                <td>The Flower Feast</td>
                <td>{1}, {2}, {3, 5}, {4}</td>
                <td>H</td>
            </tr>
            
            <tr>
                <td>9</td>
                <td>葵</td>
                <td>Aoi</td>
                <td>Aoi</td>
                <td>{1, 2}, {3}, {4}, {5}</td>
                <td>I</td>
            </tr>
            
            <tr>
                <td>10</td>
                <td>賢木</td>
                <td>Sakaki</td>
                <td>The Sacred Tree</td>
                <td>{1, 2, 3}, {4, 5}</td>
                <td>J</td>
            </tr>
            
            <tr>
                <td>11</td>
                <td>花散里</td>
                <td>Hana Chiru Sato</td>
                <td>The Village of Falling Flowers</td>
                <td>{1}, {2, 4}, {3, 5}</td>
                <td>K</td>
            </tr>
            
            <tr>
                <td>12</td>
                <td>須磨</td>
                <td>Suma</td>
                <td>Exile at Suma</td>
                <td>{1, 3, 4}, {2, 5}</td>
                <td>L</td>
            </tr>
            
            <tr>
                <td>13</td>
                <td>明石</td>
                <td>Akashi</td>
                <td>Akashi</td>
                <td>{1}, {2, 3}, {4}, {5}</td>
                <td>M</td>
            </tr>
            
            <tr>
                <td>14</td>
                <td>澪標</td>
                <td>Miotsukushi</td>
                <td>The Flood Gauge</td>
                <td>{1}, {2, 4, 5}, {3}</td>
                <td>N</td>
            </tr>
            
            <tr>
                <td>15</td>
                <td>蓬生</td>
                <td>Yomogiu</td>
                <td>The Palace in the Tangled Woods</td>
                <td>{1, 2, 3}, {4}, {5}</td>
                <td>O</td>
            </tr>
            
            <tr>
                <td>16</td>
                <td>関屋</td>
                <td>Sekiya</td>
                <td>A Meeting at the Frontier</td>
                <td>{1}, {2, 3, 4}, {5}</td>
                <td>P</td>
            </tr>
            
            <tr>
                <td>17</td>
                <td>絵合</td>
                <td>Eawase</td>
                <td>The Picture Competition</td>
                <td>{1, 3}, {2, 5}, {4}</td>
                <td>Q</td>
            </tr>
            
            <tr>
                <td>18</td>
                <td>松風</td>
                <td>Matsukaze</td>
                <td>The Wind in the Pine Trees</td>
                <td>{1, 2}, {3, 4}, {5}</td>
                <td>R</td>
            </tr>
            
            <tr>
                <td>19</td>
                <td>薄雲</td>
                <td>Usugumo</td>
                <td>A Wreath of Cloud</td>
                <td>{1}, {2, 3, 4, 5}</td>
                <td>S</td>
            </tr>
            
            <tr>
                <td>20</td>
                <td>朝顔</td>
                <td>Asagao</td>
                <td>Asagao</td>
                <td>{1, 3, 4}, {2}, {5}</td>
                <td>T</td>
            </tr>
            
            <tr>
                <td>21</td>
                <td>乙女</td>
                <td>Otome</td>
                <td>The Maiden</td>
                <td>{1, 3}, {2}, {4}, {5}</td>
                <td>U</td>
            </tr>
            
            <tr>
                <td>22</td>
                <td>玉鬘</td>
                <td>Tamakazura</td>
                <td>Tamakatsura</td>
                <td>{1, 2}, {3, 4, 5}</td>
                <td>V</td>
            </tr>
            
            <tr>
                <td>23</td>
                <td>初音</td>
                <td>Hatsune</td>
                <td>The First Song of the Year</td>
                <td>{1, 3}, {2, 4}, {5}</td>
                <td>W</td>
            </tr>
            
            <tr>
                <td>24</td>
                <td>胡蝶</td>
                <td>Kochō</td>
                <td>The Butterflies</td>
                <td>{1, 4}, {2, 3, 5}</td>
                <td>X</td>
            </tr>
            
            <tr>
                <td>25</td>
                <td>蛍</td>
                <td>Hotaru</td>
                <td>The Glow-Worm</td>
                <td>{1, 2, 4}, {3}, {5}</td>
                <td>Y</td>
            </tr>
            
            <tr>
                <td>26</td>
                <td>常夏</td>
                <td>Tokonatsu</td>
                <td>A Bed of Carnations</td>
                <td>{1}, {2}, {3, 4, 5}</td>
                <td>Z</td>
            </tr>
            
            <tr>
                <td>27</td>
                <td>篝火</td>
                <td>Kagaribi</td>
                <td>The Flares</td>
                <td>{1}, {2, 4}, {3}, {5}</td>
                <td>a</td>
            </tr>
            
            <tr>
                <td>28</td>
                <td>野分</td>
                <td>Nowaki</td>
                <td>The Typhoon</td>
                <td>{1, 2}, {3}, {4, 5}</td>
                <td>b</td>
            </tr>
            
            <tr>
                <td>29</td>
                <td>御幸</td>
                <td>Miyuki</td>
                <td>The Royal Visit</td>
                <td>{1, 3}, {2, 4, 5}</td>
                <td>c</td>
            </tr>
            
            <tr>
                <td>30</td>
                <td>藤袴</td>
                <td>Fujibakama</td>
                <td>Blue Trousers</td>
                <td>{1, 4}, {2}, {3}, {5}</td>
                <td>d</td>
            </tr>
            
            <tr>
                <td>31</td>
                <td>真木柱</td>
                <td>Makibashira</td>
                <td>Makibashira</td>
                <td>{1, 5}, {2, 4}, {3}</td>
                <td>e</td>
            </tr>
            
            <tr>
                <td>32</td>
                <td>梅枝</td>
                <td>Umegae</td>
                <td>The Spray of Plum Blossom</td>
                <td>{1, 2, 3, 5}, {4}</td>
                <td>f</td>
            </tr>
            
            <tr>
                <td>33</td>
                <td>藤裏葉</td>
                <td>Fuji no Uraba</td>
                <td>Fuji no Uraba</td>
                <td>{1}, {2, 5}, {3, 4}</td>
                <td>g</td>
            </tr>
            
            <tr>
                <td>34</td>
                <td>若菜上</td>
                <td>Wakana Jō</td>
                <td>Wakana, Part I</td>
                <td>{1, 2, 5}, {3, 4}</td>
                <td>h</td>
            </tr>
            
            <tr>
                <td>35</td>
                <td>若菜下</td>
                <td>Wakana Ge</td>
                <td>Wakana, Part II</td>
                <td>{1, 3}, {2}, {4, 5}</td>
                <td>i</td>
            </tr>
            
            <tr>
                <td>36</td>
                <td>柏木</td>
                <td>Kashiwagi</td>
                <td>Kashiwagi</td>
                <td>{1, 3, 5}, {2}, {4}</td>
                <td>j</td>
            </tr>
            
            <tr>
                <td>37</td>
                <td>横笛</td>
                <td>Yokobue</td>
                <td>The Flute</td>
                <td>{1, 4, 5}, {2}, {3}</td>
                <td>k</td>
            </tr>
            
            <tr>
                <td>38</td>
                <td>鈴虫</td>
                <td>Suzumushi</td>
                <td>The Bell Cricket</td>
                <td>{1, 5}, {2}, {3, 4}</td>
                <td>l</td>
            </tr>
            
            <tr>
                <td>39</td>
                <td>夕霧</td>
                <td>Yūgiri</td>
                <td>Yūgiri</td>
                <td>{1, 4}, {2}, {3, 5}</td>
                <td>m</td>
            </tr>
            
            <tr>
                <td>40</td>
                <td>御法</td>
                <td>Minori</td>
                <td>The Law</td>
                <td>{1, 4}, {2, 5}, {3}</td>
                <td>n</td>
            </tr>
            
            <tr>
                <td>41</td>
                <td>幻</td>
                <td>Maboroshi</td>
                <td>Mirage</td>
                <td>{1, 5}, {2}, {3}, {4}</td>
                <td>o</td>
            </tr>
            
            <tr>
                <td>42</td>
                <td>匂宮</td>
                <td>Nioumiya</td>
                <td>Niou</td>
                <td>{1, 2, 4}, {3, 5}</td>
                <td>p</td>
            </tr>
            
            <tr>
                <td>43</td>
                <td>紅梅</td>
                <td>Kōbai</td>
                <td>Kōbai</td>
                <td>{1}, {2, 5}, {3}, {4}</td>
                <td>q</td>
            </tr>
            
            <tr>
                <td>44</td>
                <td>竹河</td>
                <td>Takekawa</td>
                <td>Bamboo River</td>
                <td>{1, 5}, {2, 3, 4}</td>
                <td>r</td>
            </tr>
            
            <tr>
                <td>45</td>
                <td>橋姫</td>
                <td>Hashihime</td>
                <td>The Bridge Maiden</td>
                <td>{1, 3, 4, 5}, {2}</td>
                <td>s</td>
            </tr>
            
            <tr>
                <td>46</td>
                <td>椎本</td>
                <td>Shiigamoto</td>
                <td>At the Foot of the Oak Tree</td>
                <td>{1, 4}, {2, 3}, {5}</td>
                <td>t</td>
            </tr>
            
            <tr>
                <td>47</td>
                <td>総角</td>
                <td>Agemaki</td>
                <td>Agemaki</td>
                <td>{1, 4, 5}, {2, 3}</td>
                <td>u</td>
            </tr>
            
            <tr>
                <td>48</td>
                <td>早蕨</td>
                <td>Sawarabi</td>
                <td>Fern Shoots</td>
                <td>{1, 2}, {3, 5}, {4}</td>
                <td>v</td>
            </tr>
            
            <tr>
                <td>49</td>
                <td>宿木</td>
                <td>Yadorigi</td>
                <td>The Mistletoe</td>
                <td>{1, 2, 4, 5}, {3}</td>
                <td>w</td>
            </tr>
            
            <tr>
                <td>50</td>
                <td>東屋</td>
                <td>Azumaya</td>
                <td>The Eastern House</td>
                <td>{1, 2, 5}, {3}, {4}</td>
                <td>x</td>
            </tr>
            
            <tr>
                <td>51</td>
                <td>浮舟</td>
                <td>Ukifune</td>
                <td>Ukifune</td>
                <td>{1, 5}, {2, 3}, {4}</td>
                <td>y</td>
            </tr>
            
            <tr>
                <td>52</td>
                <td>蜻蛉</td>
                <td>Kagerō</td>
                <td>The Gossamer Fly</td>
                <td>{1, 3, 5}, {2, 4}</td>
                <td>z</td>
            </tr>
            
            <tr>
                <td>53</td>
                <td>手習</td>
                <td>Tenarai</td>
                <td>Writing Practice</td>
                <td>{1, 2, 3, 4, 5}</td>
                <td>1</td>
            </tr>
            
        </tbody>
    </table>
</div>

<p>Note that whenever the English column has apparently been left untranslated,
this is because the chapter title is the proper name of one of the characters
from <a href="https://en.wikipedia.org/wiki/The_Tale_of_Genji"><em>The Tale of Genji</em></a>. Translating these would be as nonsensical as
translating “Jack Smith” to “Lifting Device Metal Worker.”</p>

<h3 id="appendix-d-names-for-genji-kō-pattern">Appendix D: Names for Genji-Kō Pattern</h3>

<p id="names">
This table is included merely to illustrate the variety of legitimate ways
to refer to the patterns used in Genji-kō, and to justify my choice to
standardize on Genji-mon. Click on any of the kanji to link directly to
the Google Image Search for that name.
</p>

<table>
  <thead>
    <tr>
      <th>Kanji</th>
      <th>Romaji</th>
      <th>English Translation</th>
      <th>Count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://www.google.com/search?tbm=isch&amp;q=%E6%BA%90%E6%B0%8F%E7%B4%8B" target="_blank">源氏紋</a></td>
      <td>Genji-mon</td>
      <td>Genji Crest</td>
      <td>844,000</td>
    </tr>
    <tr>
      <td><a href="https://www.google.com/search?tbm=isch&amp;q=%E6%BA%90%E6%B0%8F%E9%A6%99%E5%9B%B3" target="_blank">源氏香図</a></td>
      <td>Genji-kōzu</td>
      <td>Genji-kō Diagram</td>
      <td>686,000</td>
    </tr>
    <tr>
      <td><a href="https://www.google.com/search?tbm=isch&amp;q=%E6%BA%90%E6%B0%8F%E9%A6%99" target="_blank">源氏香の模様</a></td>
      <td>Genji-kō no Moyō</td>
      <td>Genji-kō Pattern</td>
      <td>400,000</td>
    </tr>
    <tr>
      <td><a href="https://www.google.com/search?tbm=isch&amp;q=%E6%BA%90%E6%B0%8F%E9%A6%99%E6%A8%A1%E6%A7%98" target="_blank">源氏香模様</a></td>
      <td>Genji-kō Moyō</td>
      <td>Genji-kō Design</td>
      <td>479,000</td>
    </tr>
    <tr>
      <td><a href="https://www.google.com/search?tbm=isch&amp;q=%E6%BA%90%E6%B0%8F%E9%A6%99%E6%96%87%E6%A7%98" target="_blank">源氏香文様</a></td>
      <td>Genji-kō Monyō</td>
      <td>Genji-kō Motif</td>
      <td>129,000</td>
    </tr>
  </tbody>
</table>

<h3 id="appendix-e-asymptotic-behavior">Appendix E: Asymptotic Behavior</h3>

<p>The Bell numbers grow very fast. The asymptotic growth is approximately:</p>

<p>\[
    B_n \sim \frac{1}{\sqrt{2 \pi n}} \left( \frac{n}{\ln n} \right)^n
\]</p>

<p>Which is just a tiny bit slower than factorials, as you can see if you compare
it to <a href="https://en.wikipedia.org/wiki/Stirling%27s_approximation">Stirling’s approximation</a>.</p>



<p id="footnote1">
    <sup><a href="#maintext1">†</a></sup>
    By "inside", I mean which respect to interval logic, not set containment. Obviously
    no group will be a subset of another, because no incense belongs to more than one
    group. But when the leftmost element of a group is to the left of the leftmost
    element of another, and likewise <i>mutatis mutandis</i> for the rightmost, then
    visually the second group is inside the first.
    <a href="#maintext1">Back</a>
</p>

<p id="footnote2">
  <sup><a href="#maintext2">*</a></sup>
  I know I should cite the creators of these misguided images, but I have not done so to spare any potential embarrassment.
  You can find the originals through a Google reverse image search if you're curious.
  <a href="#maintext2">Back</a>
</p>

    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: TeaTime – distributed book library powered by SQLite, IPFS and GitHub (122 pts)]]></title>
            <link>https://github.com/bjesus/teatime</link>
            <guid>42256104</guid>
            <pubDate>Wed, 27 Nov 2024 13:56:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/bjesus/teatime">https://github.com/bjesus/teatime</a>, See on <a href="https://news.ycombinator.com/item?id=42256104">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">
📚 TeaTime
</h2><a id="user-content--teatime" aria-label="Permalink: 
📚 TeaTime
" href="#-teatime"></a></p>
<p dir="auto">
TeaTime is a fully static distributed library system powered by IPFS, SQLite, and GitHub
</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/55081/382481806-caacdcde-8ad9-49af-915f-c93a52c7bf11.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzI3Njg1MDIsIm5iZiI6MTczMjc2ODIwMiwicGF0aCI6Ii81NTA4MS8zODI0ODE4MDYtY2FhY2RjZGUtOGFkOS00OWFmLTkxNWYtYzkzYTUyYzdiZjExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTI4VDA0MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFiODQ1YjY3NTlhNDg1NDYwMzhjNGI0ZDNjYmU4ZGRiZGQ2NjIxNzdmYzE5MzMxZjMxNmYyN2QxYmI2MDBlODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.WMCKc85qHCcaVcNyALvFxUBHl1QKtyxh4pIaNiu6FvQ"><img src="https://private-user-images.githubusercontent.com/55081/382481806-caacdcde-8ad9-49af-915f-c93a52c7bf11.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzI3Njg1MDIsIm5iZiI6MTczMjc2ODIwMiwicGF0aCI6Ii81NTA4MS8zODI0ODE4MDYtY2FhY2RjZGUtOGFkOS00OWFmLTkxNWYtYzkzYTUyYzdiZjExLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMjglMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTI4VDA0MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFiODQ1YjY3NTlhNDg1NDYwMzhjNGI0ZDNjYmU4ZGRiZGQ2NjIxNzdmYzE5MzMxZjMxNmYyN2QxYmI2MDBlODAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.WMCKc85qHCcaVcNyALvFxUBHl1QKtyxh4pIaNiu6FvQ" height="300"></a> <br>
Auto-updating instances are hosted on <a href="https://teatime-library.netlify.app/" rel="nofollow">Netlify</a> and <a href="https://bjesus.github.io/teatime/" rel="nofollow">GitHub Pages</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">A Distributed Library</h2><a id="user-content-a-distributed-library" aria-label="Permalink: A Distributed Library" href="#a-distributed-library"></a></p>
<p dir="auto">The TeaTime web application is completely decoupled from its databases and the files it fetches. The databases used in TeaTime are <a href="https://github.com/search?q=topic%3Ateatime-database&amp;type=repositories">GitHub repositories tagged with the teatime-database topic</a>, which are published on GitHub Pages. Each repository contains a <a href="https://github.com/bjesus/teatime-database/blob/main/config.json">config.json</a> file that points to an SQLite database. Before a user performs a search in TeaTime, they choose which database to use and then TeaTime queries the SQLite database using <a href="https://github.com/phiresky/sql.js-httpvfs">sql.js-httpvfs</a>. Each row in the SQLite database is an item in the library, and a file hash column is used for getting the item from IPFS.</p>
<p dir="auto">Since the web application is a static site, and the databases are comprised of static files, both can be easily forked, replicated, and deployed. Frontend instances are <a href="https://github.com/search?q=topic%3Ateatime-instance&amp;type=repositories">GitHub repositories tagged with the teatime-instance topic</a>. With the files being served off IPFS, this distributed architecture contributes to TeaTime's resilience.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Search by title, author, year or format</li>
<li>Maintain reading history, and return to page when re-opening file</li>
<li>Download files locally</li>
<li>Cache files in IndexedDB for fast loading</li>
<li>Drop files on TeaTime to render them</li>
<li>Dark mode and full screen mode</li>
<li>No cookies, no login</li>
<li><strong>...Completely distributed</strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Developing the Frontend</h2><a id="user-content-developing-the-frontend" aria-label="Permalink: Developing the Frontend" href="#developing-the-frontend"></a></p>
<p dir="auto">TeaTime is Nuxt.js application. You can easily run it locally by cloning the repository and following these steps:</p>
<ol dir="auto">
<li>Install the dependencies: <code>npm install</code></li>
<li>Run the server: <code>npm run dev</code></li>
<li>Navigate to <code>http://localhost:3000</code></li>
</ol>
<p dir="auto">Check out the <a href="https://nuxt.com/docs/getting-started" rel="nofollow">Nuxt documentation</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Creating a Database</h2><a id="user-content-creating-a-database" aria-label="Permalink: Creating a Database" href="#creating-a-database"></a></p>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">The easiest way to create your own database is by forking the <a href="https://github.com/bjesus/teatime-json-database/">JSON-based database repository</a> and adjusting the JSON files according to your needs. GitHub Actions will then generate an SQLite file and upload it to GitHub Pages.</p>
</div>
<p dir="auto">To manually generate an SQLite database that TeaTime can work with, follow the example on <a href="https://github.com/bjesus/teatime-database/">the database repository</a>.</p>
<p dir="auto">Each SQLite database contains a table with the below schema. Note that column names can be adjusted in the <code>config.json</code> file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE TABLE &quot;books&quot; (
 &quot;id&quot; INTEGER,
 &quot;title&quot; TEXT,
 &quot;author&quot; TEXT,
 &quot;year&quot; INTEGER,
 &quot;lang&quot; TEXT,
 &quot;size&quot; INTEGER,
 &quot;ext&quot; TEXT,
 &quot;ipfs_cid&quot; TEXT,
 PRIMARY KEY(&quot;id&quot; AUTOINCREMENT)
);"><pre><span>CREATE</span> <span>TABLE</span> "<span>books</span>" (
 <span><span>"</span>id<span>"</span></span> <span>INTEGER</span>,
 <span><span>"</span>title<span>"</span></span> <span>TEXT</span>,
 <span><span>"</span>author<span>"</span></span> <span>TEXT</span>,
 <span><span>"</span>year<span>"</span></span> <span>INTEGER</span>,
 <span><span>"</span>lang<span>"</span></span> <span>TEXT</span>,
 <span><span>"</span>size<span>"</span></span> <span>INTEGER</span>,
 <span><span>"</span>ext<span>"</span></span> <span>TEXT</span>,
 <span><span>"</span>ipfs_cid<span>"</span></span> <span>TEXT</span>,
 <span>PRIMARY KEY</span>(<span><span>"</span>id<span>"</span></span> AUTOINCREMENT)
);</pre></div>
<p dir="auto">The <code>dbConfig</code> section of <code>config.json</code> is identical to the output of the <a href="https://github.com/phiresky/sql.js-httpvfs/blob/master/create_db.sh">sql.js-httpvfs create_db.sh</a> script.</p>
<p dir="auto">If the SQLite file is too big, you can <a href="https://github.com/phiresky/sql.js-httpvfs?tab=readme-ov-file#usage">split it</a>. Note the information about optimizing your database. You will also want to <a href="https://github.com/bjesus/teatime-database/blob/main/create_indexes.sql">use FTS</a>. Then, publish your repository to GitHub Pages and assign the <code>teatime-database</code> topic to your repository.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Even if you cannot code, a great way to contribute is to simply fork this repository, as well as your favorite database repositories. If you fork the repository, it could be better to do it manually (<code>git clone</code> &amp;&amp; <code>git remote add your-origin ...</code> &amp;&amp; <code>git push your-origin main</code>) so that the repositories won't be directly linked.</p>
<p dir="auto">It's also a good practice to star the database repositories you find useful, as this determines their order in the TeaTime user interface, making it easier for other users to find the best databases.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Recommendation for a SWE looking to get up to speed with latest on AI (208 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42256093</link>
            <guid>42256093</guid>
            <pubDate>Wed, 27 Nov 2024 13:55:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42256093">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42256405"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256405" href="https://news.ycombinator.com/vote?id=42256405&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>The poster's looking for articles, so this recommendation's a bit off the mark. I learned more from participating in a few Kaggle competitions (<a href="https://www.kaggle.com/competitions" rel="nofollow">https://www.kaggle.com/competitions</a>) than I did from reading about AI. Many folks in the community shared their homework, and by learning how to follow their explanations I developed a much more intuitive understanding of the technology. The first competition had a steep learning curve. I felt it was worth it. The application of having a specific goal and the provided datasets made the problem space more tractable.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256720"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256720" href="https://news.ycombinator.com/vote?id=42256720&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Out of sheer curiosity, how much time did you spend on it on average? How much of this knowledge are you using now?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256785"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42256785" href="https://news.ycombinator.com/vote?id=42256785&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Not the poster you responded to but I learned quite a bit from kaggle too.</p><p>I started from scratch, spent 2-4 hrs per day for 6 months &amp; won a silver in a kaggle NLP competition.  Now I use some of it now but not all of it. More than that, I'm quite comfortable with models, understand the costs/benefits/implications etc. I started with Andrew Ng's intro courses, did a bit of fastai, did Karpathy's Zero to Hero fully, all of Kaggle's courses &amp; a few other such things. Kagglers share excellent notebooks and I found them v helpful. Overall I highly recommend this route of learning.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257032"><td></td></tr>
            <tr id="42256925"><td></td></tr>
                              <tr id="42256144"><td></td></tr>
                <tr id="42256502"><td></td></tr>
                  <tr id="42256403"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256403" href="https://news.ycombinator.com/vote?id=42256403&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>I don't think it's a good idea to kepp up to date at a daily/weekly cadence, unless you somehow directly get paid for it. It's like checking stocks daily, it doesn't lead to good investment decisions.</p><p>It's better to do it more batchy, like once every 6-12 months or so.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256452"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256452" href="https://news.ycombinator.com/vote?id=42256452&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>How do you do that? Once you're out of the loop for half a year, it becomes harder to know what's important and what's not, I think.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257829"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257829" href="https://news.ycombinator.com/vote?id=42257829&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Some ideas:</p><p>1. Buy O'reilly (and other tech) books as they come out. This will have a lag, but essentially somebody did this research &amp; summarization work, and wrote it up for you in chapters. Note that you don't have to read everything in a book. Also, $50 is a great investment if it saves you 10s of hours of time.</p><p>2. Talks on Youtube at conferences by industry leaders, like Yann LeCun, or maintainers of popular libraries, etc. Also, YT videos on the topic that are upvoted/linked.</p><p>3. If you're interested in hardcore research, look for review articles on arxiv.</p><p>4. Look at tutorials/examples in the documentation/repo of popular ML/AI libraries, like Pytorch.</p><p>5. Try to cover your blindspots. One way or another, you'll know how new AI is applied to SWE and related fields. But how is AI applied to perpendicular fields, like designing buildings, composing music, or balancing a budget? Trying to cover these areas will be tougher, because it will be more noisy, as most commenters will be non-experts compared to you. To get a feel for this, do something that feels unnatural, like watch TED talks that seem bullshity, read HBR articles intended for MBAs, and check out what Palantir is doing.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256624"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42256624" href="https://news.ycombinator.com/vote?id=42256624&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Every release is novel. Once something has been around for a while and is still being referenced, you know it’s worth learning.</p><p>Waiting 3-6 months to take a deep dive is a good pattern to prevent investing your time in dead-end routes.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257570"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42257570" href="https://news.ycombinator.com/vote?id=42257570&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Yes this is why I never buy the latest CPUs and try to never run the latest release of any software. Stay a (supported) release or two behind the bleeding edge, and you'll find stuff is more stable. Common bugs and other issues have been shaken out by the early adopters.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42257627"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257627" href="https://news.ycombinator.com/vote?id=42257627&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>For news-like content I follow accounts on X: @kimmonismus @apples_jimmy and the accounts of Antropic, Mistal, Gemini / DeepMind and OpenAI.
I think everyone who is really interested in the hot AI developments must also follow what comes from China. I follow <a href="https://chinai.substack.com/" rel="nofollow">https://chinai.substack.com/</a> but I am open to hear about other Chinese resources.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257607"><td></td></tr>
            <tr id="42257387"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257387" href="https://news.ycombinator.com/vote?id=42257387&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>I read about 30 LLM papers a couple months ago dated from 2018-2024. Mostly folks are publishing on the “how do we prompt better” problem, and you can kind of get the gist in about a day by reading a few blogs (RAG, fine tuning, tool use, etc). There is also more progress being made for model capabilities, like multi modality, and each company seems to be pushing in only slightly different directions, but essentially they are still black boxes.</p><p>It depends what you are looking for honestly “the latest things happening” is pretty vague. I’d say the place to look is probably just the blogs of OpenAI/Anthropic/Genini, since they are the only teams with inside information and novel findings to report. Everyone else is just using the tools we are given.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257629"><td></td></tr>
            <tr id="42256529"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256529" href="https://news.ycombinator.com/vote?id=42256529&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>The best place for the latest information isn't tech blogs in my opinion. It's the stable diffusion and local llama subreddits. If you are looking to learn about everything on a fundamental level you need to check out Andrej Karpathy on YouTube. There other some other notable mentions in other people's comments.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257251"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257251" href="https://news.ycombinator.com/vote?id=42257251&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>New short course on FreeCodeCamp YouTube channel looks good -</p><p>Ollama Course – Build AI Apps Locally
<a href="https://youtu.be/GWB9ApTPTv4?feature=shared" rel="nofollow">https://youtu.be/GWB9ApTPTv4?feature=shared</a></p><p>As an aside, does anyone have any ideas about this: there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs, in addition to ingesting docs, text and content in the normal RAG way. Then you could build AI chat-enabled knowledge resources around specific subjects. Autogenerated summaries and dashboards would provide useful overviews.</p><p>Perhaps this already exists?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257429" href="https://news.ycombinator.com/vote?id=42257429&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>&lt;&lt; there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs,</p><p>I am not aware if that exists yet, but the challenge I see with it is rather simple: you get overwhelmed with information really quickly. In other words, you would still need human somewhere in that process to review those scrapes and the quality of that varies widely. For example, even on HN it is not a given a link will be pure gold ( you still want to check if it fits your use case ).</p><p>That said, as ideas goes, it sounds like a fun weekend project.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42257174"><td></td></tr>
                <tr id="42257385"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257385" href="https://news.ycombinator.com/vote?id=42257385&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>My issue with YouTube channels that focus on AI news is that they’re heavily incentivized to give you a frequent stream of attention-grabbing news. Week-by-week updates aren’t that helpful. It’s easy to miss the bigger picture and there’s too much content to feel like a good use of time.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257668"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257668" href="https://news.ycombinator.com/vote?id=42257668&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>I agree with this statement, most YouTube channels are incentivized to keep repeating the same trivial information like how to compose prompts etc</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42257363"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257363" href="https://news.ycombinator.com/vote?id=42257363&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>First thing you need to do is change your LinkedIn to “AI evangelist” then go to your boss and say I want triple the pay. Then let the chips fall where they may. Oh also rename all your GitHub or personal projects to have AI in the name. You don’t actually have to do much else.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257076"><td></td></tr>
            <tr id="42257364"><td></td></tr>
            <tr id="42256542"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256542" href="https://news.ycombinator.com/vote?id=42256542&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Simon's blog is fragmented because it's, well, a blog. It would be hard to find a better source to "keep updated on things AI" though. He does do longer summary articles sometimes, but mostly he's keeping up with things in real time. The search and tagging systems on his blog work well, too. I suggest you stick his RSS feed in your feed reader, and follow along that way.</p><p>Swyx also has a lot of stuff keeping up to date at <a href="https://www.latent.space/" rel="nofollow">https://www.latent.space/</a>, including the Latent Space podcast, although tbh I haven't listened to more than one or two episodes.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257239"><td></td></tr>
                  <tr id="42256966"><td></td></tr>
            <tr id="42256621"><td></td></tr>
                <tr id="42257255"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257255" href="https://news.ycombinator.com/vote?id=42257255&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>daveshap quit ai right? got agi pilled/"oneshotted by ayahuasca" as the kids say</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257285"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257285" href="https://news.ycombinator.com/vote?id=42257285&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>He was only gone for a few days, IIRC. At any rate, he's back publishing AI related content again, and it looks like all (?) of his old content is back on his YT channel.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42257131"><td></td></tr>
            <tr id="42256497"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256497" href="https://news.ycombinator.com/vote?id=42256497&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>As I was building up my understanding/intuition for the internals of transformers + attention, I found 3Blue1Brown's series of videos (specifically on attention) to be super helpful.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256557"><td></td></tr>
                  <tr id="42256670"><td></td></tr>
                <tr id="42257544"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257544" href="https://news.ycombinator.com/vote?id=42257544&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Sadly, you'll have to include 4chan /g/'s local models general, which, unfortunately, seems to have top AI researchers posting there (anonymously)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42256540"><td></td></tr>
            <tr id="42256469"><td></td></tr>
            <tr id="42256628"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256628" href="https://news.ycombinator.com/vote?id=42256628&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Reproduce nanogpt.</p><p>Then find a small dataset and see if you can start getting close to some of the reported benchmark numbers with similar architectures.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256666"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256666" href="https://news.ycombinator.com/vote?id=42256666&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Build a tool on top of the LLM layer for a specific use case. That'll get you up to speed. You haven't missed much.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256810"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256810" href="https://news.ycombinator.com/vote?id=42256810&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Exactly. Avoid intentionally throw-away effort and instead attempt to build something specific and practical. Learn by doing.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42257393"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257393" href="https://news.ycombinator.com/vote?id=42257393&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Lots of good suggestions here already. I'd start by adding one quick note though. "AI" is more than just LLM's. Sure, the "current, trendy, fashionable" thing is all LLM's, but the field as a whole is still much larger. I'd encourage you to not myopically focus on LLM's to exclusion. Depending on your existing background knowledge, there's a lot to be said for going out and getting a copy of <i>Artificial Intelligence: A Modern Approach</i> and reading through it. Likewise for something like <i>Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow</i>.</p><p>Beyond that: there are some decent sub-reddits for keeping up with AI happenings, a lot of good Youtube channels (although a lot of the ones that talk about the "current, trendy" AI stuff tend to be a bit tabloid'ish), and even a couple of Facebook groups. You can also find good signal by choosing the right people to follow on Twitter/LinkedIn/Mastodon/Bluesky/etc.</p><p><a href="https://www.reddit.com/r/artificial/" rel="nofollow">https://www.reddit.com/r/artificial/</a></p><p><a href="https://reddit.com/r/machineLearning/" rel="nofollow">https://reddit.com/r/machineLearning/</a></p><p><a href="https://www.reddit.com/r/LLM/" rel="nofollow">https://www.reddit.com/r/LLM/</a></p><p><a href="https://www.reddit.com/r/agi" rel="nofollow">https://www.reddit.com/r/agi</a></p><p><a href="https://www.reddit.com/r/ollama/" rel="nofollow">https://www.reddit.com/r/ollama/</a></p><p><a href="https://www.youtube.com/@matthew_berman" rel="nofollow">https://www.youtube.com/@matthew_berman</a></p><p><a href="https://www.youtube.com/@TheAiGrid" rel="nofollow">https://www.youtube.com/@TheAiGrid</a></p><p><a href="https://www.youtube.com/@WesRoth" rel="nofollow">https://www.youtube.com/@WesRoth</a></p><p><a href="https://www.youtube.com/@DaveShap" rel="nofollow">https://www.youtube.com/@DaveShap</a></p><p><a href="https://www.youtube.com/c/MachineLearningStreetTalk" rel="nofollow">https://www.youtube.com/c/MachineLearningStreetTalk</a></p><p><a href="https://www.youtube.com/@twimlai" rel="nofollow">https://www.youtube.com/@twimlai</a></p><p><a href="https://www.youtube.com/@YannicKilcher" rel="nofollow">https://www.youtube.com/@YannicKilcher</a></p><p>And you can always go straight to "the source" and follow pre-prints showing up in arXiv.</p><p><a href="https://arxiv.org/corr" rel="nofollow">https://arxiv.org/corr</a></p><p>For tools to make it easier to track new releases, arXiv supports subscriptions to daily digest emails, and also has RSS feeds.</p><p><a href="https://info.arxiv.org/help/subscribe.html" rel="nofollow">https://info.arxiv.org/help/subscribe.html</a></p><p><a href="https://info.arxiv.org/help/rss.html" rel="nofollow">https://info.arxiv.org/help/rss.html</a></p><p>There are also some bots in the Fediverse that push out links to new arXiv papers.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256846"><td></td></tr>
            <tr id="42256354"><td></td></tr>
                <tr id="42256806"><td></td></tr>
                  <tr id="42256482"><td></td></tr>
            <tr id="42256774"><td></td></tr>
            <tr id="42256565"><td></td></tr>
            <tr id="42257064"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257064" href="https://news.ycombinator.com/vote?id=42257064&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Are you wanting to get into LLMs in particular or something else? I am a software engineer also trying to make headways into so-called "AI", but I have little interest in LLMs. For one, it's suffering from a major hype bubble right now. The second reason is that because of reason one, it has a huge amount of attention from people who study and work on this every day. It's not something I have the time commitment for to compete with that. Lastly, as mentioned, I have no interest in it and my understanding of them leads me to believe they have few interesting applications besides generating a huge amount of noise in society and dumping heat. The Internet, like blogs, articles, and even YouTube, are already being overrun by LLM-generated material that is effectively worthless. I'm not sure of the net positive for LLMs.</p><p>For me personally, I prefer to work backwards and then forwards. What I mean by that is that I want to understand the basics and fundamentals first. So, I'm, slowly, trying to bone up on my statistics, probability, and information theory and have targeted machine learning books that also take a fundamental approach. There's no end to books in this realm for neural networks, machine learning, etc., so it's hard to recommend beyond what I've just picked, and I'm just getting started anyway.</p><p>If you can get your employer to pay for it, MIT xPRO has courses on machine learning (<a href="https://xpro.mit.edu/programs/program-v1:xPRO+MLx/" rel="nofollow">https://xpro.mit.edu/programs/program-v1:xPRO+MLx/</a> and <a href="https://xpro.mit.edu/courses/course-v1:xPRO+GenAI/" rel="nofollow">https://xpro.mit.edu/courses/course-v1:xPRO+GenAI/</a>). These will likely give a pretty up to date overview of the technologies.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256640"><td></td></tr>
            <tr id="42256722"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ancient Sumerians created the first writing system (145 pts)]]></title>
            <link>https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/</link>
            <guid>42255829</guid>
            <pubDate>Wed, 27 Nov 2024 13:15:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/">https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/</a>, See on <a href="https://news.ycombinator.com/item?id=42255829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								        
										<p>“In Uruk he built walls, a great rampart, and the temple of blessed Eanna for the god of the firmament Anu, and for Ishtar the goddess of love. Look at it still today: the outer wall where the cornice runs, it shines with the brilliance of copper; and the inner wall, it has no equal. Touch the threshold, it is ancient.”<br>
–<em>The Epic of Gilgamesh</em>, ca. 1750 BC<br>
*</p><p><span>Article continues after advertisement</span></p>
<p>In the middle of the fourth millennium before Christ, men and women could feed themselves and their families, much of the time, but almost nobody else. They did not yet have the wheel. They could fight, but they did not have the capacity to make war. They could not read or write, for there was no writing. Without writing, there was no history. There were stories but no literature. Art was something that people might produce on their pottery, but never for a living. There were customs but no laws. There were chiefs but no kings, tribes but no nations. The city was unknown.</p>
<p>And then, around that time, civilization was born: urban life, based on nutritional surplus and social organization, characterized by complexity and material culture, much of it made possible by writing. This happened in a very particular part of the world: the flood-prone, drought-wracked, frequently pestilential plain of southern Iraq, where the rivers Tigris and Euphrates meet the Persian Gulf. The plain could be fertile, very fertile, but only when people worked together to irrigate it and control the floods with channels and earthworks; this necessity, most likely, accounts for much of the early surge in social complexity that distinguished the area. Later civilizations would arise independently in two great river valleys not so far away, the Indus and the Nile, but the original organized, literate, urban culture was produced by a far crueler and more challenging environment than either of those.</p>
<p><span>The need for a single script to serve a geography using two such dissimilar languages almost interchangeably was a great spur to the development of early Mesopotamian writing.</span></p><p>This first civilization came to be known as Sumer. By about the year 3000 BC, a city called Uruk near the mouth of the Euphrates River, just inland of the head of the Persian Gulf, had eighty thousand residents. A thousand years later Iraq, the land along the Euphrates and its sister stream, the Tigris, would be named for this early metropolis of Uruk. Sharing the land of Sumer, about the size of Belgium, with a dozen other city-states, Uruk was not always the foremost among its rivals in the land. But for most of its existence, spanning the two millennia of the Sumerian world, Uruk was the greatest city on earth.</p>
<p>The Sumerians invented kingship, priesthood, diplomacy, law, and war. They gave the West its founding stories: the opposition of darkness and light at the Beginning; the Flood, with its ark and dove and surviving patriarch; the tower of Babel; the distant ancestors of Odysseus and Hercules. The Sumerians established the outlines of our political, legal, and temporal structures too, with the first kings and assemblies, the first written laws, the first legal contracts, and the sexagesimal system of counting that regulates the hours and seconds of our days.</p><div><p><span>Article continues after advertisement</span></p></div>
<p>The Sumerians wrote the first epics and constructed the first monumental buildings. They invented the wheel, the sailing boat, the dome, and the arch. They were the first people to cast, rivet, and solder metals. They were the first to develop mathematics, calculating the hypotenuse of a right triangle two thousand years before Pythagoras and enabling extraordinary achievements in civil engineering. Compiling methodical lists of plants and animals, the Sumerians were the first people to apply rational order to our knowledge of the natural world.</p>
<p>The Sumerians wrote down almost everything they knew, much of it on disposable clay tablets that have survived the millennia. Some thirty-nine centuries after the last of the Sumerians died, another inventive and curious people, the Victorians of the nineteenth century AD, initiated a remarkable period of foreign exploration in Iraq. Thanks to this colorful and dramatic intellectual adventure, which began in the 1840s, today we can follow the course of Sumerian lawsuits, track Sumerian inventories, and study the terms of Sumerian marriages, wills, and loans. We read the overtures of Sumer’s diplomats. We follow in detail the provisioning of Sumer’s armies and the triumphs or disasters of their expeditions. We know intimately the pleadings of Sumerian students for more money from their fathers, and the pleadings of their fathers for more diligence from their sons. We track the transactions of Sumerian merchants in copper or onions. We admire the complex and perfect calculations of Sumerian engineers.</p>
<p>Human life on the alluvial plain of the two rivers at the birth of civilization five thousand years ago was precarious. Again and again, through the ancient stories and archaeological records that illuminate the dawn of history, plagues and pestilence swept the hot, low country. Terrifying floods killed and destroyed everything within reach of the raging waters that came every spring when the snow melted in the mountains five hundred miles and more to the north, in what is now Armenia and southeast Turkey. At Ur in Sumer’s far south, the great archaeologist Sir Leonard Woolley, digging in 1929, discovered a layer of “perfectly clean clay” more than eight feet thick separating the remains—pottery and much more—of two distinct cultures from some time before 3000 BC. A single flood, in other words, had created a temporary lake that deposited this eight-foot-thick layer. The catastrophic scale of such a deluge is almost beyond the powers of imagination. Woolley naturally surmised that it was the great flood of Genesis. Other floods have left similar records in southern Iraq. Most were smaller than Woolley’s Ur deluge. One left eleven feet of new flood soil.</p>
<p>Meanwhile neighbors from the higher, rougher country to the east, north, and west were greedy for the wealth of the settled plain, then as now. The invasions of barbarians from the Persian hill country, the Kurdish and Turkish mountains, and the Arabian steppe sometimes paused, but never ended. Within Sumer, Uruk and its neighboring city-states fought against each other almost constantly during the twenty-odd centuries of Sumerian civilization.</p>
<p>The soil of southern Iraq is a dusty, flinty accumulation of silt from the two shifting rivers that originate far to the north. In the areas where Iraq’s alluvial soil is not dry, it is marshy, especially in the south; it was more so in ancient times, when the Tigris and Euphrates were bigger. The ground is home to no minerals or ores, although bitumen seeps from the earth in places. The land contains no stones for building. Almost no tree, aside from the date palm, grows on it successfully. Trade with the far-off source-lands of raw materials—for tin and copper to alloy into bronze for weapons, for gold and silver to please the rich and the divine, for hardwood timbers for the roof beams of palaces and temples—required the pooling of resources. Organization and leadership were required to conduct commerce at scale with places as far afield as Anatolia for tin, Lebanon for cedar timbers, “Oman for copper, south-west Iran for carved stone bowls, eastern Iran for lapis lazuli, the Indus for carnelian.”</p><div><p><span>Article continues after advertisement</span></p></div>
<p>*</p>
<p>The water of the two great rivers irrigated the rainless plain. It also raged as a violent killer, to be restrained with dykes and channels. This required cooperation on a much larger scale than the individual village or town could offer. Better irrigation led to increasing harvests. As the land of Sumer became crowded with more and more people, food was another reason for increasingly sophisticated social arrangements. Each of these catalysts—trade, water, sustenance—also led to humanity’s first organized conflicts. War was born. Every Sumerian city had its own principal deity, and the many gods also sent men into their earliest battles there on the hot plain.</p>
<p>*</p>
<p>Late in the fourth millennium BC, a couple of thousand years after the advent of agriculture with the Neolithic revolution, Sumer was one of several distinct cultures around the world. In none of these cultures had true urban life and, with it, civilization yet developed. Then the Sumerian genius produced its greatest innovation: writing.</p>
<p>The eighty thousand people living in Uruk by 3000 BC sheltered behind walls that were forty feet high and six miles long. Archaeologists estimate these to have cost over five million man-hours to build. The fourth-millennium city occupied about 1.7 square miles, a little bit less than imperial Rome at its peak (2.1 square miles) and larger than classical Athens.</p><div><p><span>Article continues after advertisement</span></p></div>
<p>At the archaeological site of Uruk, the residential buildings, workshops, and barracks have not yet been excavated. Thus it is still the case that “very little about the actual conditions of life in the city is known.” Yet this is certain: Uruk was the world’s only major city of the fourth millennium BC, marked by public buildings that were “unprecedented and unrivaled at the time.”&nbsp; Most of the labor for such civic projects in Sumer came from free laborers requiring recompense for their work. Trade in livestock and agricultural produce fed them and the residents of nearby towns. The Sumerians needed a way to keep track of it all. This was the setting in which writing was born.</p>
<p>The earliest writing and the earliest direct precursors of writing, all from the second half of the fourth millennium, have been found at Uruk. Initially, clay tokens the size of a thimble would be formed to represent the sorts of things that a person might own and trade, such as sheep. For convenience, these tokens would then be put into a larger, hollow clay ball a little smaller than a grapefruit. These clay spheres, called “bullae,” served as something like sealed wallets or envelopes for the information within. On its exterior, the bulla would then be impressed with authenticating marks from cylindrical seals rolled upon the clay surface.</p>
<p>At Uruk some of these bullae have been found with additional marks impressed onto their surfaces. These marks indicated the number of tokens contained inside. It was an obvious step. The next step then suggested itself. With the contents marked on the exterior, there was no need for the little tokens rattling around inside. By 3300 BC, the information was instead simply scratched onto the surface of the spheres. The Sumerians had invented writing.</p>
<p>It is the only invention that has ever rivaled that of agriculture for its transformational effect upon human existence. Eventually flat clay tablets replaced the bullae.</p>
<p>At this stage writing was almost purely pictographic. Characters signified their objects through more or less recognizable images. Any given pictograph might mean several different things. “Mountain”—a right-side-up pyramid formed by three convex half circles—also meant “foreign lands,” for Sumer was completely flat. Consequently the same character also signified “conquest.” Shown together with the symbol for “woman,” a downward-pointing triangle with a notch at the bottom tip, the two symbols meant a woman captured from far away: “slave-woman.”</p><div><p><span>Article continues after advertisement</span></p></div>
<p>Pictographs were originally drawn on wet clay with a sharp-pointed object. Clay was an ideal medium for the Sumerians. It was cheap and abundant on the floodplain. Clay tablets were easy to make and prepare, although it is still not known how the larger ones were kept wet and impressionable. Sumerian scribes eventually wrote for the most part as we do, from left to right, top to bottom.</p>
<p>A typical tablet might be two to three inches high and half again as wide, with writing often going all the way to the margins. Incisions toward the bottom of archaic Iraq’s writing tablets tend to be visibly less deep and clear than those at the top of tablets, as the drying clay became harder to work. Once the inscribed clay had dried in southern Mesopotamia’s hot sun, it would endure for scores of centuries, and possibly forever, if left somewhere still and dry. Tablets made from such cheap and ubiquitous material were easily discarded once no longer needed. To the delight of archaeologists dozens of centuries later, they were thrown into heaps or used to fill the spaces beneath floors.</p>
<p>The original pictographs were for the most part recognizably indicative of something physical: a plow or a mountain, a head or a hand. But clay as a two-dimensional medium is ill-suited to both detail and curves. Around the year 2900, scribes discovered that impressing a sequence of lines with a straight-edged implement such as a cut reed was easier than tracing with a pointed implement. Reeds are flat, with a spine along one edge. Thus the mark made by each impression of the cut-off reed comprised a straight line with a wedge at its tip. By 2100, Sumerian scribes possessed a fast, well-developed script. Almost four thousand years later, in 1700 AD, cuneiform was named after the Latin word for wedge, <em>cuneus</em>, by the court interpreter of Eastern languages at the court of William III of England.</p>
<p>The rigid straight lines of the new technique pushed the characters away from the representational and toward the symbolic and the stylized. As centuries passed, the pictographs lost their illustrational quality. They were now “ideographs.” “Mountain,” for example, became three semicircles. By 2500 BC the recognizably representational had disappeared.</p>
<p><span>Here was the evolution from the ideographic to the phonetic. The impact was revolutionary. The boundaries of writing were now as infinite as those of speech.</span></p><p>A representational writing system has significant limitations. It is not practical to have a symbol for everything. The symbols must mean the same to all who use the writing. Users must memorize thousands of these symbols and must also be familiar with that which is being expressed. Tenses, cases, and voices are mostly impossible to depict. In the first centuries of writing, an image illustrating a foot meant “walk,” “stand up,” “ground,” “foundation,” and more besides simply “foot.” This made things difficult enough, but how would one say, “She will walk”? Or, worse, “Will she walk?” or “How will she have walked?” The ideographic method also had great limitations, as it connected writing not to words themselves, but rather to whatever it was that the words expressed. Ideographic writing bypassed spoken language, in other words. Restricted to known events and objects, unconnected to the spoken word, such a system can never cover all that language covers.</p>
<p>The next great innovation in the development of writing derived from puns. Early in the third millennium before Christ, Sumerian scribes perceived that homophones allowed them greatly to expand the verbal territory covered by the symbols they had mastered. For example, the Sumerians originally lacked a pictograph for their word sum, “to give.” To signify “give” in writing they used the pictograph for another word (“garlic”) that also was pronounced “sum.” In English such a visual pun is called a rebus. We might remember these from school. The picture of an eye next to that of a reed is one such, challenging us to remember dimly, the Sumerians with the sentence “I read.”</p>
<p>With this development, writing was now attached to sounds, to the “signifier” and not the “signified.” By the time of what is known as the Old Babylonian period, about 1500 BC, the Sumerian discovery of the power of paronomasia had helped the Uruk period’s written lexicon of two thousand characters halve in number, even as it covered more meaning. Writing was more accessible. During the Old Babylonian period even a king might be able to read, where hitherto that skill had been largely the province of scribes.</p>
<p>*</p>
<p>Shortly after the earliest development of writing, an ominous cloud appeared on Sumer’s northern horizon: a people called the Akkadians. In contrast to the native Sumerians, the Akkadians were Semitic pastoralists living in what came to be known as the Arabian Desert, the huge, dry steppe to the south and west of the Mesopotamian floodplain. By about 3000 BC, the Akkadians had moved eastward out of the desert. They settled north of Sumer in the part of Iraq that later came to be known as Babylonia.</p>
<p>The Sumerians and Akkadians lived next to each other for a thousand years. The two peoples mixed and fought constantly. There was a great degree of bilingualism, and all manner of sharing between the two languages over time. But the Sumerian and Akkadian tongues are entirely different. How, in such a setting, might a Sumerian scribe record the name of an Akkadian merchant? The need for a single script to serve a geography using two such dissimilar languages almost interchangeably was a great spur to the development of early Mesopotamian writing. Eventually the increasingly cosmopolitan quality of life on the Mesopotamian floodplain would force the script to make itself usable by people of different tongues.</p>
<p>The demands of the emerging southern Mesopotamian sprachbund required that the script deliver more and more of the nuances of speech. With writing no longer able to ignore spoken language, a crucial change happened. Most of writing’s symbols came to represent not meaning—an object, activity, or idea, for example—but rather sound. Here was the evolution from the ideographic to the phonetic. The impact was revolutionary. The boundaries of writing were now as infinite as those of speech. Once the Sumerian script became phonetic, the civilization that cuneiform defined would spread until it reached from Iran to the Mediterranean and from the Persian Gulf to Anatolia.</p>
<p>__________________________________</p>
<p><img fetchpriority="high" decoding="async" data-attachment-id="245872" data-permalink="https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/land-between-the-rivers/" data-orig-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg" data-orig-size="340,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="land between the rivers" data-image-description="" data-image-caption="" data-medium-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg" data-large-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg" src="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg" alt="" width="200" height="300" srcset="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg 200w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-40x60.jpg 40w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-33x50.jpg 33w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg 340w" sizes="(max-width: 200px) 100vw, 200px"></p>
<p><em>Excerpted from </em><a href="https://bookshop.org/a/132/9780802162502" target="_blank">Land Between the Rivers: A 5,000-Year History of Iraq</a> <em>by Bartle Bull. Copyright </em><em>© 2024 by Bartle Bull. Reprinted with the permission of the publisher, Atlantic Monthly Press, an imprint of Grove Atlantic, Inc. All rights reserved.</em></p>
										
																				
																		
										<div id="about_the_author">
												<p><a href="https://lithub.com/author/bartlebull/"><img src="https://s26162.pcdn.co/wp-content/uploads/2024/11/Bartle-Bull-100x100.jpeg" width="100" height="100" srcset="https://s26162.pcdn.co/wp-content/uploads/2024/11/Bartle-Bull.jpeg 2x" alt="Bartle Bull"></a></p>
												
											</div>

										
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi CM5 is a faster, drop-in upgrade (189 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly</link>
            <guid>42254379</guid>
            <pubDate>Wed, 27 Nov 2024 09:15:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly">https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly</a>, See on <a href="https://news.ycombinator.com/item?id=42254379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-angle.jpeg" alt="Raspberry Pi Compute Module 5"></p>

<p>The Raspberry Pi <a href="http://raspberrypi.com/products/compute-module-5/">Compute Module 5</a> is smaller than a credit card, and I already have it gaming in 4K with an eGPU, running a Kubernetes cluster, and I even upgraded my NEC Commercial display from a CM4 to CM5, just swapping the Compute Modules!</p>

<p>The Compute Module 4 was hard to get for <em>years</em>. It launched right after the COVID supply chain crisis, leading to insane scalper pricing.</p>

<p>It was so <em>useful</em>, though, that Raspberry Pi sold every unit they made, and they're inside <em>everything</em>: from <a href="https://youtu.be/cbm03jtWWL0?t=2851">commercial 3D printers</a>, to <a href="https://www.jeffgeerling.com/blog/2022/tv-thats-not-necs-pi-powered-55-display">TVs</a>, to <a href="https://pipci.jeffgeerling.com/boards_cm/blikvm-pci-express-card.html">IP KVM cards</a>.</p>

<p>After <a href="https://www.youtube.com/watch?v=Lky4FSfbc1E">pre-announcing the CM5</a> earlier this year, the biggest question was, is it a drop-in replacement?</p>

<p>Yes. <em>For the most part.</em></p>

<p>I've been testing it in <em>tons</em> of Compute Module boards, and it's been awesome seeing a 2-3x speedup just dropping in the new module.</p>

<p>It boots up in seconds, it has USB 3 instead of USB 2, and it's compatible with PCIe Gen 3 instead of Gen 2. The CPU is 2-3x faster, RAM is <em>3-4x</em> faster, <em>WiFi</em>'s faster, storage is faster... It's basically a Pi 5, but without the plugs. Most CM4 cases and accessories still work with it, just there's a LOT more bandwidth.</p>

<p>The big advantage to a Compute Module versus a Pi 5 is modularity. And I published a video today going over a ton of use cases enabled by various Compute Module carrier boards. All the ones I've tested were built for the CM4, but the CM5 is an instant drop-in upgrade:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/X4blR5Ua3S0" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>I won't cover the individual use cases in this blog post. Rather, I'll focus on CM5 benchmarking and my notes from using the hardware a few weeks.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/CM5-Pricing-Table.png" alt="CM5 Launch Pricing Table"></p>

<p>The second-most-asked question is how much it will cost. Put simply, the 8GB CM5 is roughly the same price as the 8GB CM4. The 4GB module is $5 more, and the 2GB module is $10 more. So the cheapest CM5 is now $45 instead of $35—they're dropping the 1GB option from the lineup this generation. For any specific pricing information, please consult the <a href="https://datasheets.raspberrypi.com/cm5/cm5-product-brief.pdf">CM5 Product Brief</a>.</p>

<h2>Performance</h2>

<p>Good news: you can expect almost all the same numbers as a Pi 5 with the same amount of RAM.</p>

<p>Raspberry Pi made some quality of life improvements for management, too:</p>

<ul>
<li>You can edit the EEPROM (e.g. to change the <code>BOOT_ORDER</code>) without needing another computer</li>
<li>Raspberry Pi maintains <a href="https://github.com/raspberrypi/pi-gen-micro">pi-gen-micro</a> to build smaller custom Pi OS installations</li>
</ul>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.001.boot_.png" alt="CM5 Benchmark - Boot time"></p>

<p>Right off the bat, the most refreshing difference is it boots up about 4 seconds faster.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.002.hpl_.png" alt="CM5 Benchmark - HPL Linpack FP64"></p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.003.hpl-efficiency.png" alt="CM5 Benchmark - HPL Efficiency"></p>

<p>Once it's running, the CPU is almost 3x faster. And it's also about 1.5x more efficient, according to my High Performance Linpack tests.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.004.linux_.png" alt="CM5 Benchmark - Linux compile"></p>

<p>And of course, I had to test recompiling the Linux kernel. The CM5 obliterates the CM4, it's more than 3x faster.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.005.x264-4k.png" alt="CM5 Benchmark - x264 4K Transcode"></p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.006.x264-1080p.png" alt="CM5 Benchmark - x264 1080p Transcode"></p>

<p>Video encoding is also about 3x faster. I tested x264 transcoding both at 4K and 1080p resolutions, using Phoronix. All these benchmarks are helped by the faster LPDDR4x RAM on the CM5, which I tested using tinymembench:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.007.ram_.png" alt="CM5 Benchmark - RAM speed"></p>

<p>But all these speedups consume more power, at least at full blast: the CM5 uses almost <em>twice</em> the power flat out. But at idle, the CM5 uses a tiny bit <em>less</em>: I measured 2.3 watts at the wall:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.008.power_.png" alt="CM5 Benchmark - Power consumption"></p>

<p>And if you're deciding on which CM5 to buy, more RAM is better, at least if you're looking for raw performance.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.009.hpl-cm5.png" alt="CM5 Benchmark - HPL on various RAM capacities"></p>

<p>You can save some money with less RAM, but don't expect the performance numbers on a 2 gig model to match the 8 gig model.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.010.igpu_.png" alt="CM5 Benchmark - iGPU GLMark2 V3D performance"></p>

<p>The built-in graphics are much faster, too. Just testing with GLMark I saw the score jump from about 750 to 1916. It's not nearly as fast as even an older graphics card, but any improvement is welcome, especially for things like 4K displays.</p>

<p>You might've noticed, there was a third module in most of these graphs, except that last one. That's <em>another</em> CM5, <a href="https://radxa.com/products/cm/cm5/">this one being made by Radxa</a>. It uses a Rockchip RK3588S2, which is a monster in its own right, beating the Pi on <em>almost</em> every benchmark, including efficiency.</p>

<p>The elephant in the room is all the Compute Module clones. Because of the Pi shortages, every SBC maker on the planet built their own Compute Module. Though... some work better than others. A lot are <em>faster</em> than the Pi, but pricing is fairly similar, when you compare RAM and relative performance.</p>

<p>The big difference between the Pi and all the others, though, is support. I've written how other SBCs <em>could</em> become Pi-killers—I mean the hardware is often there—but they lack <em>support</em>.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/compute-module-5-clones.jpg" alt="Compute Module 5 and Clones"></p>

<p>One big part of that is the breadth of options for the Pi, which may or may not work on other Compute Modules. And if you want to try, you can expect to debug hardware and OS issues yourself. Like I couldn't get a valid GLMark score for the Radxa, because I couldn't get an OS image to boot and use the built-in Mali GPU in time for this post! It's often a frustrating experience.</p>

<p>I regularly test other Compute Modules, though, and I post <em>all</em> my test data and experiences in my <a href="https://github.com/geerlingguy/sbc-reviews">sbc-reviews GitHub repo</a>.</p>

<h2>Hardware - CM5 IO Board</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-io-board.jpeg" alt="CM5 IO Board"></p>

<p>Along with the CM5, Raspberry Pi's selling an updated IO board, for $20, with a few helpful changes. First, a power button, with the same behavior as the Pi 5. This would've saved <em>so</em> much time debugging graphics cards on the CM4.</p>

<p>Then, there's a new tiny fan header, the same one on the Raspberry Pi 5. Companies like EDAtec already have active coolers for the CM5, and I'll test some cooling options on my my 2nd channel, Level2Jeff.</p>

<p>On the port side, they got rid of the 12 volt barrel jack for power, and now they just use USB-C. They dropped down to two multipurpose Camera/Display ports. Each one has 4 lanes of MIPI bandwidth, just like the Pi 5.</p>

<p>There are still two full-size HDMI ports, an Ethernet port, and two USB type-A ports, but these are upgraded to USB 3. There's a microSD card that only works on Lite Compute Modules without eMMC, and finally an M.2 slot, with a little LED that blinks when you're using an SSD.</p>

<p>This is nice, because probably 99% of people buying these things would plug in storage. On the CM4, you had to use an awkward adapter card, but that's not required anymore.</p>

<p>Maybe we could see this on the Pi 5 someday? Or if not, maybe we could hack it using the Compute Module! That's foreshadowing...</p>

<h2>Hardware - CM5</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-memory-emmc-silkscreen.jpeg" alt="CM5 Silkscreen - RAM and eMMC options"></p>

<p>The feature that'll make the biggest impact for <em>me</em>, since I use a lotta compute modules, is this new silkscreen up in the top corner. It has resistors for the RAM and storage sizes, so the specs are right up top.</p>

<p>The major changes from the CM4 include:</p>

<ul>
<li>BCM2712 D0 stepping SoC, with 4x Cortex A76 CPU cores at 2.4 GHz</li>
<li>RP1 chip for IO expansion (GPIO, MIPI Camera/Display, 2x USB 3.0 bus, Ethernet)</li>
<li>eMMC storage is moved to the bottom of the Compute Module</li>
<li>The Wireless chip has been raised up onto a short PCB mezzanine (I believe it can be had separately now, for system integrators, maybe?)</li>
<li>The RAM is now an LPDDR4x RAM module, sporting much higher speeds (and on-chip ECC)</li>
<li>The Pi 5 PMIC is included on the CM5 board, for USB-C PD negotation or direct 5V input like on the Pi 5</li>
</ul>

<p>Other things are familiar, like the switchable PCB antenna / u.fl connector, the 2x 200-pin hirose board to board connections, and the Broadcom BCM54210PE (which <a href="https://www.jeffgeerling.com/blog/2022/ptp-and-ieee-1588-hardware-timestamping-on-raspberry-pi-cm4">enables hardware PTP timestamping support</a>).</p>

<p>I've been testing the CM5 on various carrier boards, even with eGPUs and 10 Gbps NICs on the official IO Board, and all that testing can be seen in <a href="https://www.youtube.com/watch?v=l819Nnj5PNc">my YouTube video on the CM5</a>.</p>

<h2>Conclusion</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-compute-blade.jpeg" alt="CM5 in Compute Blade"></p>

<p>But tying up the CM5, Raspberry Pi kept the price the same for the 8 gig model; those start at $75 for the Lite version. For 4 gig, they're going up five bucks, and for 2 gig, it's up 10 bucks, from $35 to $45.</p>

<p>They're dropping the 1 gig model from the lineup, and in reality, a lotta applications choke with less than 2 gigs of RAM, so I'm not surprised.</p>

<p>When the Compute Module 4 came out, it changed <em>literally</em> everything about the Compute Module. Including the form factor. That meant everything built for the CM1 and CM3 had to be redesigned, and it made many hardware developers angry.</p>

<p>Luckily, this time they kept the form factor, meaning for <em>most</em> things, it's a drop-in upgrade, where you get 2-3x faster performance, and at least for the larger models, the same price.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: App that asks 'why?' every time you unlock your phone (662 pts)]]></title>
            <link>https://play.google.com/store/apps/details?id=com.actureunlock&amp;hl=en_US</link>
            <guid>42254156</guid>
            <pubDate>Wed, 27 Nov 2024 08:34:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play.google.com/store/apps/details?id=com.actureunlock&#x26;hl=en_US">https://play.google.com/store/apps/details?id=com.actureunlock&#x26;hl=en_US</a>, See on <a href="https://news.ycombinator.com/item?id=42254156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-g-id="description"><p>Intenty helps you build a healthier relationship with your phone through gentle awareness prompts that appear right when you need them – at unlock. No blockers, no limits, just mindful choices.</p><p>🎯 Thoughtful nudges<br>Choose from carefully crafted default nudges or create your own:</p><p>* Intention - Set clear purposes for each phone session<br>* Necessity - Question if you really need to use your phone now<br>* Grounding - Return to the present moment<br>* Posture - Remember your physical wellbeing<br>* Minimalism - Stay focused on what truly matters</p><p>✨ Smart customisation</p><p>* Create personal nudges with your own prompts<br>* Control how often nudges appear with intensity settings<br>* Set cooldown periods to prevent prompt fatigue<br>* Export your data for personal insights</p><p>🎨 Minimalist design</p><p>* Clean, distraction-free interface<br>* Full-screen prompts for maximum impact<br>* Thoughtfully crafted user experience</p><p>🛡️ Privacy first</p><p>* Works 100% locally<br>* No ads or tracking<br>* No metrics or analytics collection<br>* Your phone, your data, your control</p><p>💡 Why it works<br>Instead of blocking apps or setting arbitrary limits, Intenty helps you build awareness naturally. Each unlock becomes an opportunity to check in with yourself, making mindful decisions about your phone use throughout the day. Perfect for anyone looking to check their phone less and use their phone more mindfully.</p><p>🌟 Who it's for<br>Perfect for anyone who wants to:</p><p>* Reduce mindless phone-checking<br>* Stay present and focused<br>* Build better digital habits<br>* Maintain productivity without restrictive blocks</p><p>Would you be ready to transform your relationship with your phone? Download Intenty today and make every unlock count.</p><p>🔐 Note on Intenty permissions usage: </p><p>Intenty might use quite permissive Android capabilities such as Display over other apps, Battery optimization disablement, or Accessibility service. All permissions are used exclusively for features to work locally on your device.</p><p>Accessibility service is used exclusively to let you quickly turn off your phone's screen with a Lock button. The service is optional, disabled by default, and does not collect nor share any data.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Wrote "Janet for Mortals" (222 pts)]]></title>
            <link>https://ianthehenry.com/posts/janet-for-mortals/</link>
            <guid>42253241</guid>
            <pubDate>Wed, 27 Nov 2024 05:34:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ianthehenry.com/posts/janet-for-mortals/">https://ianthehenry.com/posts/janet-for-mortals/</a>, See on <a href="https://news.ycombinator.com/item?id=42253241">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<div><p>I wrote a book.</p>
<p>It’s called <a href="https://janet.guide/"><em>Janet for Mortals</em></a>, and it’s free, and it’s on the internet, and you can read it right now.</p>
<p>And you <em>should</em> read it right now, instead of reading this blog post, because this blog post is not very interesting if you haven’t read the book. Heck, this blog post is not very interesting even if you <em>have</em> read the book. This blog post is a thinly-veiled promotion for my book to slip into my newsletter and RSS feed, with just enough additional content to pad it out to the length of a real post.</p>
<p>The book is about <a href="https://janet-lang.org/">Janet</a>, a programming language that <a href="https://ianthehenry.com/posts/janet-game/">I have written about before</a>. I’ve been using Janet a lot lately, and I’ve been having a lot of fun with it, and I think that more people should know about it so that they can have fun with it too. People like you.</p>
<p>I’m not really going to talk much about <em>why</em> you should read the book, or even why you should care about Janet in the first place – that will come in a later post. Instead, this is going to be a short retrospective of what it was like to write my first technical book.</p>
<hr>
<p>We’ll start with some numbers.</p>
<p>It took me twenty weeks to write the book, working in my spare time. I had originally estimated twelve weeks, which turned out to be a really good guess for how long I spent <em>writing</em> the book, but I didn’t account for how much time I would spend working on book-adjacent coding side quests.</p>
<p>The final book is pretty short: 44k words of English prose, if you don’t count any of the code snippets. I tried to find an example of a famous book with a similar word count to put that number in perspective, and the best I can do is <em>The Great Gatsby</em>, which clocks in at 47k words. It’s right on the border between novella- and novel-length, but it’s less than half as long as <a href="https://ianthehenry.com/posts/how-to-learn-nix/">my series of posts about Nix</a>, which is sort of terrifying.</p>
<p>But writing English words was only a fraction of the work. Over the course of those five months, I also spent a lot of time on:</p>
<ul>
<li><a href="https://janet.guide/">the website itself</a></li>
<li><a href="https://github.com/ianthehenry/jimmy"><code>jimmy</code></a>, bindings to a C++ library of persistent data structures</li>
<li><a href="https://toodle.studio/">Toodle.Studio</a>, an interactive turtle graphics playground</li>
<li><a href="https://github.com/ianthehenry/cmd"><code>cmd</code></a>, a command-line argument parsing library</li>
<li><a href="https://github.com/ianthehenry/judge"><code>judge</code></a>, an inline snapshot testing framework</li>
<li><a href="https://github.com/ianthehenry/to-do"><code>to do</code></a>, a command-line todo list manager</li>
</ul>
<p>These things are not very interesting by themselves, but this blog post just exists to promote the book, so I’m going to reflect on them now. You are welcome to stop reading at any point and <a href="https://janet.guide/">go read the actual book instead</a>.</p>
<h2 id="the-website-2-weeks">The Website (2 weeks)</h2>
<p>The most interesting thing about <em>Janet for Mortals</em> is that it has a built-in repl. At any point you can press escape and pull it up, and it’s docked to the bottom of the page, just out of the way of the text. I’m sure that it’s not the first programming book to include a repl like this, but I’ve never actually seen it done before.</p>
<p>The editor portion of the repl is <a href="https://codemirror.net/">CodeMirror</a>, which I had used previously in <a href="https://ianthehenry.com/posts/janet-for-mortals/bauble.studio/">Bauble</a>. CodeMirror doesn’t know anything about Janet out of the box, but I had already implemented some basic <a href="https://ianthehenry.com/posts/janet-for-mortals/github.com/ianthehenry/codemirror-lang-janet">language support</a> when I wrote Bauble.</p>
<p>But I skipped a lot of the Janet language when I was writing the grammar for Bauble, like <code>``multi`backtick`quoted``</code> strings, because they didn’t really matter in Bauble’s constrained DSL. But they mattered for the book, so I had to spend time figuring out how to implement them.</p>
<p>But fleshing out the CodeMirror grammar (or more precisely, the <a href="https://lezer.codemirror.net/docs/guide/">Lezer</a> grammar that CodeMirror uses) had an unexpected side effect: it let me re-use the grammar to do syntax highlighting for the code snippets in the book itself.</p>
<p><em>Janet for Mortals</em> is just a static site, but no static site generators that I know of know how to highlight Janet code. For a long time the book was entirely black-and-white, which I don’t mind, but I knew I needed to add some color before I released it upon an unsuspecting public – I think Janet’s syntax is pretty unfamiliar to most people reading the book, and anything to make it look friendlier helps.</p>
<p>So I knew that I’d have to roll my own syntax highlighter of some kind, and I ended up just writing a simple static site generator in <a href="https://github.com/apenwarr/redo"><code>redo</code></a>, which was not a very good fit, but… well, least bad choice that I know of. The meat of the generator is written in JavaScript, so that I could plug in the Lezer grammar for free, but it’s all tied together by a fragile web of shell.</p>
<p>I used <a href="https://github.com/remarkjs/remark">Remark</a> to implement the parsing of the book’s source, and it was nice how much control I had over the generated output. I even added a simple extension to label code blocks, which was pretty easy.</p>
<p>I also re-used Remark in the client itself, as part of the repl. The docstrings in the Janet standard library are written in Markdown, and I’m actually parsing and rendering them to HTML on the fly as part of the repl autocomplete.</p>
<p>I spent a long time getting the repl autocomplete working well – because this book was written for newcomers to the Janet language, I thought that the help-as-you-type would be really useful for people trying to follow along in the repl.</p>
<p>Autocomplete works by dynamically querying the Janet environment via WebAssembly at repl startup. This means if you define a new symbol with a docstring, it won’t actually appear in the autocomplete output, but I think that’s… fine. I could re-generate the autocompletions after every command is run, but… I don’t think there’s much value in that.</p>
<p>The most interesting part of the repl is probably the <code>(report)</code> function, which takes a string and POSTs it to a simple web server that sticks it into a SQLite database for me to peruse later. It’s not really any different than a comment box, but I feel like there’s something fun about doing it from the repl. I’m really glad that I added it – it’s been fun reading people’s feedback, and I’ve fixed quite a few errors because of it. I’m sad that I didn’t implement any way to respond, though!</p>
<p>The backend for reports is <em>not</em> written in Janet; it’s a tiny Haskell application that just listens for POST requests and sticks them into a SQLite database.</p>
<p>There are people using Janet to make websites, but I am not one of them: the primary thing I want out of a web server is security, and I just don’t think Janet or its HTTP libraries are “battle-tested” enough for me to connect them to the internet.</p>
<p>I also just think the idea of using a dynamically-typed interpreted language to build a web service is crazy, when there are optimizing compilers <em>right there</em>, but that’s a whole other conversation.</p>
<h2 id="jimmy-1-week"><code>jimmy</code> (1 week)</h2>
<p>I spent a little bit of time writing bindings to <a href="https://github.com/arximboldi/immer">immer</a>, a library of persistent data structures. I never finished them, and probably won’t, at least not until I have a use for them. But as a demonstration of how to interop with C++ code from Janet, I think it was successful.</p>
<h2 id="httpstoodlestudio-2-weeks"><a href="https://toodle.studio/">https://toodle.studio</a> (2 weeks)</h2>
<p>Last year I wrote a little art playground called <a href="https://bauble.studio/">Bauble</a>. It was my first time embedding Janet in the browser, and I had a pretty tough time figuring out how to do that.</p>
<p>There weren’t a lot of resources back then about embedding Janet <em>period</em>, and doing it in the browser added an extra layer of difficulty. I’d never used WebAssembly or Emscripten before, or even TypeScript, and it turns out there are no tutorials on how to write TypeScript Emscripten WebAssembly Janet bindings, so I spent a while figuring out how all the pieces worked together.</p>
<p>And I’m glad I did, because I think the final product is really neat: it’s a website that is <em>not written in JavaScript</em>. I mean, a lot of it is. The UI is, still. But the actual application logic is all Janet.</p>
<p>I thought that that was a really useful superpower of Janet, and I wanted to make the technique more accessible. In fact this was a big motivation for writing this book about Janet – I wanted people to know that this was <em>possible</em> in the first place, and I wanted to make it easier to get started with it.</p>
<p>But <em>Janet for Mortals</em> doesn’t talk about Bauble at all. Bauble is actually not very interesting from an interop perspective: Bauble is completely stateless, and basically uses Janet to implement a pure function from strings to strings (they’re… pretty complicated strings; Bauble is a Janet-to-GLSL compiler, but they are strings nonetheless). I didn’t think it was a very good showcase for everything you can do with Janet, so I briefly considered talking about how I implemented the repl in the book, but I decided that that was far too boring. So I wrote <a href="https://toodle.studio/">Toodle.Studio</a> – an obvious fork of Bauble – instead.</p>
<p>Toodle.Studio <em>seems</em> a lot simpler than Bauble, but the interop with JavaScript is much more involved. Toodle.Studio has to execute long-running Janet programs asynchronously over time. It has to think about memory management, as the JavaScript code retains multiple references to the same Janet values. It has to pass complex nested data structures to and from Janet, going through C++ as an intermediary. It does a very simple version of all of these things, but it’s a pretty good showcase for the techniques.</p>
<p>But the most interesting part of Toodle.Studio isn’t the interop or the memory management. The most interesting part of Toodle.Studio is the logo.</p>
<p>I wasn’t really planning on making a logo – this is a demo project for a book, after all – but sadly I had no choice. When I was getting ready to release the website, I showed it to my partner, because it’s rare that I work on something comprehensible to normal human beings. I thought she’d like it, but she was <em>aghast</em>.</p>
<p>“You said you were working on turtle graphics,” she said. “Where are the turtles?”</p>
<p>I tried to explain that the turtles aren’t <em>really</em> turtles, that it’s like a flea circus, and the turtles are metaphors – but she was having none of it. The lack of turtles was a base betrayal, so I had to spend a day or so <a href="https://gist.github.com/ianthehenry/612c980f0db04ea3c2ccab2741475870">modeling a cute animated turtle in Bauble</a> to act as the logo. And making its eyes follow the mouse, of course.</p>
<p>Relationship repaired. The logo wound up being my favorite part of the site, and it was fun to get a chance to use Bauble to make something “real.”</p>
<h2 id="cmd-2-weeks"><code>cmd</code> (2 weeks)</h2>
<p>One of the things that I spent the most time on, oddly enough, was a command-line argument parsing library. The library itself only gets, like, three paragraphs of screen time in the book, but it was very important to me that it exist before the book came out, so that I could unambiguously claim that “Janet is an excellent scripting language.” Before <code>cmd</code>, that was still true, but the phrasing was more “Janet is a great choice for scripting and writing CLI tools, except that the argument parsing is kind of janky, sorry, but hey at least it’s better than Bash.”</p>
<p><code>cmd</code> was heavily inspired by <a href="https://ocaml.org/p/core/latest/doc/Core/Command/Param/index.html"><code>Core.Command</code></a>, which is the best command-line argument parsing library that I have ever used. I’m extremely spoiled by how easy it makes writing CLIs, and I wanted to replicate that experience in Janet. <code>cmd</code> is definitely not as good as <code>Core.Command</code> – types, my goodness, types make everything so much easier – but it has 95% of the features I care about, and the concise notation makes it more pleasant to use in ad-hoc scripts.</p>
<p>One thing that I miss, though, is that <code>Core.Command</code> autogenerates Bash completion functions. I want to add that to <code>cmd</code> one day – the API is designed so that that will be <em>possible</em> to do. But… so many projects, so little time.</p>
<h2 id="judge-1-week"><code>judge</code> (1 week)</h2>
<p><code>judge</code> was <a href="https://ianthehenry.com/posts/janet-game/judging-janet/">one of the first things that I wrote in Janet</a>, all the way back in 2021. I think that it worked pretty well considering that I didn’t know anything about Janet when I wrote it, but now I do, so I rewrote it from scratch. Not only is the API much nicer to use now, but the implementation is way simpler – and easier to make changes to.</p>
<p>The main differences between Judge v1 and Judge v2 are that tests can now appear inside regular source files, not just the <code>test/</code> directory, and I added the <code>test-macro</code> and <code>test-stdout</code> helpers, which are <em>extremely</em> useful. <a href="https://blog.janestreet.com/the-joy-of-expect-tests/">The OCaml equivalent of <code>test-stdout</code></a> is pretty much the only way that I write tests professionally, because OCaml doesn’t really have a way to embed arbitrary data in source code, so we turn everything into a string.</p>
<p>After publishing the book – which <a href="https://janet.guide/testing-and-debugging/">has a whole chapter on testing with Judge</a> – I had a chance to spend a little more time improving Judge, and I finally added an <code>--interactive</code> mode, which I’ve been wanting for a long time. And since I’m not spending all my time working on this book anymore, I’ve actually had a few opportunities to <em>use</em> the new Judge, and I gotta say: it’s nice. It’s really nice. I know I can’t impress upon you just how nice it is in this post – it really needs a demo, and I’m too lazy to record one right now – but I’m very happy with how it feels to use it to write Janet.</p>
<h2 id="to-do-2-hours"><code>to do</code> (2 hours)</h2>
<p>I picked this project to highlight for <a href="https://janet.guide/scripting/">the scripting chapter</a>, because it’s a non-trivial thing that I had done in Bash before, and actually found it pretty painful. Parsing multi-line text with Sed is not fun, and trying to do date manipulation with <code>date</code> in a way that works the same on macOS and Linux is… basically impossible, as far as I can tell. I quickly ran into the limits of my patience, and gave up on the idea some years ago.</p>
<p>It was really fun to return to this with the full power of PEGs and <a href="https://github.com/andrewchambers/janet-sh"><code>sh</code></a> and <a href="https://github.com/ianthehenry/cmd"><code>cmd</code></a> at my disposal. I immediately surpassed all of features of my original Bash todo list, and was able to add quite a few more (like <code>fzf</code> multi-select – good luck constructing null-terminated strings in Bash).</p>
<p>The book covers a very simplified version of the app – it can’t schedule tasks for the future, and there’s no concept of “skipping” tasks. Those features are important for <em>my</em> todo list workflow, but they are probably not important for <em>your</em> todo list workflow, so the book only discusses the core functionality of adding things to a list and crossing them off. I think that it makes a good starting point to run with and make your own – paired with <a href="https://github.com/ianthehenry/zsh-autoquoter"><code>zsh-autoquoter</code></a>, it’s actually a surprisingly useful app!</p>
<hr>
<p>If you put all of these projects together, I was writing code for almost half the time that I spent working on the book. Eight out of twenty weeks, plus some periods where I was doing both at once.</p>
<p>I didn’t really budget for that going into this. I thought that I’d improve Judge, and I thought that I’d write an argument parser. But I thought that writing an argument parser would be <em>way easier</em> than it actually was. And I thought that I’d just talk about Bauble – it never occurred to me that I’d write <em>another</em> art playground just because Bauble was <em>too easy</em>.</p>
<p>So that’s the story of writing the book. Or really, everything <em>but</em> writing the book. All the other things. The writing itself isn’t that interesting. I wrote it in Markdown, in Sublime Text, which is my favorite editor for writing long-form prose. I have nothing interesting to say about that part.</p>
<p>Two new versions of Janet came out while I was writing the book, and I did have to go back and update the chapters on debugging and native modules to keep up with changes to the language. I plan on keeping the book up to date with the latest Janet release – we’ll see how long I can keep that up.</p>
<hr>
<p>I haven’t done much to promote the book yet. I <a href="https://news.ycombinator.com/item?id=35386405">submitted it to Hacker News</a>, and I <a href="https://lobste.rs/s/duwkz7">submitted it to Lobsters</a>, and I wrote <a href="https://twitter.com/ianthehenry/status/1641797578739306499">a very half-hearted tweet about it</a>. The reception was pretty much as good as I could have hoped for: it was on the Hacker News front page all day, and even held the number one spot for a while.</p>
<p>What does that actually mean? Well, according my Nginx access logs, I got:</p>
<ul>
<li>30,025 unique visitors on Friday</li>
<li>9,568 unique visitors on Saturday</li>
<li>3,777 unique visitors on Sunday</li>
</ul>
<p>Those numbers don’t mean very much, though. Those are just people who clicked on a link – the number of people who actually <em>read</em> the book is much, much smaller.</p>
<p>I don’t actually know how much smaller exactly, because I don’t have any client-side behavior-tracking analytics on the site. But I can sort of try to guess, by looking at my access logs. It seems like retention is not great:</p>
<ul>
<li>Chapter One had 22% as many visitors as the home page.</li>
<li>Chapter Two had 20% as many visitors as Chapter One.</li>
<li>Chapter Three had 69% as many visitors as Chapter Two.</li>
<li>Chapters Four and Nine, “<a href="https://janet.guide/pegular-expressions/">Pegular Expressions</a>” and “<a href="https://janet.guide/xenofunctions/">Xenofunctions</a>,” had more visitors than Chapter Three.</li>
</ul>
<p>I’m guessing that last bit is because people clicked on those chapters to see what they were about, which just goes to show that unique visitor count is not a very dependable metric.</p>
<p>My best attempt at answering the question “how many people are actually reading the book” is 387, as of the end of the launch weekend. So far 387 unique IP addresses have loaded five or more distinct chapters, which is probably a decent proxy for the metric I care about.</p>
<p>I really had no expectations for what these numbers would be before I launched the book. It’s a big time commitment to read a weird book about a programming language you’ve barely heard of, and 387 seems simultaneously low (compared to, say, any blog post) and high (I don’t think <em>I’ve</em> ever read a book off a HN link). But it’s more than zero!</p>
<p>Alright, I think that’s enough. I’ll close with some fun facts:</p>
<ul>
<li>
<p>The Janet language is named after an immortal being in <a href="https://en.wikipedia.org/wiki/The_Good_Place"><em>The Good Place</em></a> who helps mortals navigate the afterlife, hence the title.</p>
</li>
<li>
<p>The chapter with the fewest visits is currently “Testing and Debugging,” despite being the third-to-last chapter. This does not surprise me at all, but I think it’s a shame: the last three chapters are by far the most interesting in the book, and the style of testing described in that chapter is one of the biggest productivity upgrades that I have personally experienced in my engineering career.</p>
</li>
<li>
<p>So far I’ve received 494 reports from the built-in repl reporting feature. Most of these were of the “hey nice book” or “testing” variety, but I’ve gotten several dozen typo reports, clarification requests, or otherwise useful comments through it as well.</p>
</li>
<li>
<p>The most interesting report was just “you should listen to this song: <a href="https://www.youtube.com/watch?v=46i3LbIbbhI">https://www.youtube.com/watch?v=46i3LbIbbhI</a>.” No context, no explanation, and I have no way to reply for clarification. But… thanks! It’s a good song. I’m into it.</p>
</li>
<li>
<p>A few people asked me questions without including any kind of contact info, so I have no way to answer them. I hope that they found peace, wherever they are. I’m not ignoring you. I just… I only implemented an extremely primitive one-way feedback function.</p>
</li>
<li>
<p>I’m going to plug the book one last time.</p>
</li>
</ul>
<p>With feeling: <em><a href="https://janet.guide/">Janet for Mortals</a>!</em> Out now! The first infinity visitors get their copy for free!</p></div>
</article></div>]]></description>
        </item>
    </channel>
</rss>