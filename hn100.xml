<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 22 Apr 2025 22:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Atuin Desktop: Runbooks That Run (122 pts)]]></title>
            <link>https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</link>
            <guid>43766200</guid>
            <pubDate>Tue, 22 Apr 2025 20:54:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</a>, See on <a href="https://news.ycombinator.com/item?id=43766200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://blog.atuin.sh/tag/news/">News</a>
            
                <p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p>

            <div>
                <p><a href="https://blog.atuin.sh/author/ellie/">
                                <img src="https://blog.atuin.sh/content/images/size/w160/2024/01/me2.jpg" alt="Ellie Huxtable">
                            </a>
                </p>
                
            </div>

            
        </header>

        <section>
            <figure data-kg-thumbnail="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final.mp4" poster="https://img.spacergif.org/v1/1852x1600/0a/spacer.png" width="1852" height="1600" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:27</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg"></figure><p>Most infrastructure is held together by five commands someone remembers when shit breaks. Docs are out of date, if they exist. The real answers? Buried in Slack threads, rotting in Notion, or trapped in someone's shell history.</p><p><a href="https://atuin.sh/?ref=blog.atuin.sh" rel="noreferrer">Atuin CLI</a> fixed part of this, with synced, searchable shell history. But teams need more than history. They need workflows that don't live in someone's head (or their shell).</p><p>Set up. SSH in. Export some variables. Run some commands. Hope nothing breaks. Stuff we do every day, but still have to piece together from fragments of the past, or copy paste from some document somewhere.</p><p>That's why we built the next step.</p><h2 id="introducing-atuin-desktop"><strong>Introducing Atuin Desktop</strong></h2><blockquote>A local-first, executable runbook editor for real terminal workflows</blockquote><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png" width="1581" height="1382" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.28.30.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1000w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1581w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png" width="1643" height="1386" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1643w" sizes="(min-width: 720px) 720px"></p></div></figure><p>Built to make workflows repeatable, shareable, and reliable.</p><p>Runbooks should run. Workflows shouldn't live in someone's head. Docs shouldn't rot the moment you write them.</p><p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p><ul><li><strong>Kill context switching: </strong>chain shell commands, database queries and HTTP requests</li><li><strong>Docs that don't rot: </strong>execute directly + stay relevant</li><li><strong>Reusable automation: </strong>dynamic runbooks with Jinja-style templating</li><li><strong>Instant recall: </strong>autocomplete from your real shell history</li><li><strong>Local-first, CRDT-powered: </strong>if it runs in your terminal, it runs in a runbook</li><li><strong>Sync and share with Atuin Hub: </strong>up to date, across devices and teams</li></ul><h3 id="how-we-use-it-today">How we use it today</h3><p>We‚Äôre already running real-world workflows in Atuin Desktop:</p><ul><li>Releasing Atuin CLI (no more checklist hell)</li><li>Migrating infra safely between environments</li><li>Spinning up staging or prod with confidence</li><li>Managing and collaborating on live database queries</li></ul><p>This is how we ship, manage infra, and collaborate.</p><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png" width="1693" height="1554" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1693w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png" width="1688" height="1494" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1688w" sizes="(min-width: 720px) 720px"></p></div></figure><h3 id="what%E2%80%99s-next">What‚Äôs next</h3><ul><li>Team accounts: true collaborative ops</li><li>Generate runbooks from your shell history. Workflows that write themselves</li></ul><h3 id="get-early-access">Get early access</h3><p>We're rolling out Atuin Desktop now. If you're done copy-pasting from Notion and Slack, or spelunking through shell history, join the <a href="https://wt.ls/atuin?ref=blog.atuin.sh" rel="noreferrer">early access list</a>!</p>
        </section>

    </article>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sapphire: Rust based package manager for macOS (Homebrew replacement) (184 pts)]]></title>
            <link>https://github.com/alexykn/sapphire</link>
            <guid>43765011</guid>
            <pubDate>Tue, 22 Apr 2025 18:39:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alexykn/sapphire">https://github.com/alexykn/sapphire</a>, See on <a href="https://news.ycombinator.com/item?id=43765011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sapphire</h2><a id="user-content-sapphire" aria-label="Permalink: Sapphire" href="#sapphire"></a></p>
<blockquote>
<p dir="auto"><strong>WARNING: ALPHA SOFTWARE</strong> &gt; Sapphire is experimental, under heavy development, and may be unstable. Use at your own risk!</p>
<p dir="auto">Uninstalling a cask with brew then reinstalling it with Sapphire will have it installed with slightly different paths, your user settings etc. will not be migrated automatically.</p>
</blockquote>
<p dir="auto">Sapphire is a next‚Äëgeneration, Rust‚Äëpowered package manager inspired by Homebrew. It installs and manages:</p>
<ul dir="auto">
<li><strong>Formulae:</strong> command‚Äëline tools, libraries, and languages</li>
<li><strong>Casks:</strong> desktop applications and related artifacts on macOS</li>
</ul>
<blockquote>
<p dir="auto"><em>ARM only for now, might add x86 support eventually</em></p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚öôÔ∏è Project Structure</h2><a id="user-content-Ô∏è-project-structure" aria-label="Permalink: ‚öôÔ∏è Project Structure" href="#Ô∏è-project-structure"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>sapphire‚Äëcore</strong> Core library: fetching, dependency resolution, archive extraction, artifact handling (apps, binaries, pkg installers, fonts, plugins, zap/preflight/uninstall stanzas, etc.)</p>
</li>
<li>
<p dir="auto"><strong>sapphire‚Äëcli</strong> Command‚Äëline interface: <code>sapphire</code> executable wrapping the core library.</p>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üöß Current Status</h2><a id="user-content--current-status" aria-label="Permalink: üöß Current Status" href="#-current-status"></a></p>
<ul dir="auto">
<li>Bottle installation and uninstallation</li>
<li>Cask installation and uninstallation</li>
<li>Parallel downloads and installs for speed</li>
<li>Automatic dependency resolution and installation</li>
<li>Building Formulae from source (very early impl)</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üöÄ Roadmap</h2><a id="user-content--roadmap" aria-label="Permalink: üöÄ Roadmap" href="#-roadmap"></a></p>
<ol dir="auto">
<li><strong>Upgrade</strong> command to update installed packages</li>
<li><strong>Cleanup</strong> old downloads, versions, caches</li>
<li><strong>Reinstall</strong> command for quick re‚Äëpours</li>
<li><strong>Prefix isolation:</strong> support <code>/opt/sapphire</code> as standalone layout</li>
<li><strong><code>sapphire init</code></strong> helper to bootstrap your environment</li>
<li><strong>Ongoing</strong> Bug fixes and stability improvements</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üì¶ Usage</h2><a id="user-content--usage" aria-label="Permalink: üì¶ Usage" href="#-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Print help
sapphire --help

# Update metadata
sapphire update

# Search for packages
sapphire search <formula/cask>

# Get package info
sapphire info <formula/cask>

# Install bottles or casks
sapphire install <formula/cask>

# Build and install a formula from source
sapphire install --build-from-source <formula>

# Uninstall
sapphire uninstall <formula/cask>

# (coming soon)
sapphire upgrade [--all] <name>
sapphire cleanup
sapphire init"><pre><span><span>#</span> Print help</span>
sapphire --help

<span><span>#</span> Update metadata</span>
sapphire update

<span><span>#</span> Search for packages</span>
sapphire search <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Get package info</span>
sapphire info <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Install bottles or casks</span>
sapphire install <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Build and install a formula from source</span>
sapphire install --build-from-source <span>&lt;</span>formula<span>&gt;</span>

<span><span>#</span> Uninstall</span>
sapphire uninstall <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> (coming soon)</span>
sapphire upgrade [--all] <span>&lt;</span>name<span>&gt;</span>
sapphire cleanup
sapphire init</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üèóÔ∏è Building from Source</h2><a id="user-content-Ô∏è-building-from-source" aria-label="Permalink: üèóÔ∏è Building from Source" href="#Ô∏è-building-from-source"></a></p>
<p dir="auto"><strong>Prerequisites:</strong> Rust toolchain (stable).</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone <repo-url>
cd sapphire
cargo build --release"><pre>git clone <span>&lt;</span>repo-url<span>&gt;</span>
<span>cd</span> sapphire
cargo build --release</pre></div>
<p dir="auto">The <code>sapphire</code> binary will be at <code>target/release/sapphire</code>. Add it to your <code>PATH</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">ü§ù Contributing</h2><a id="user-content--contributing" aria-label="Permalink: ü§ù Contributing" href="#-contributing"></a></p>
<p dir="auto">Sapphire lives and grows by your feedback and code! We‚Äôre particularly looking for:</p>
<ul dir="auto">
<li>Testing and bug reports for Cask &amp; Bottle installation + <code>--build-from-source</code></li>
<li>Test coverage for core and cask modules</li>
<li>CLI UI/UX improvements</li>
<li>See <a href="https://github.com/alexykn/sapphire/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></li>
</ul>
<p dir="auto">Feel free to open issues or PRs. Every contribution helps!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìÑ License</h2><a id="user-content--license" aria-label="Permalink: üìÑ License" href="#-license"></a></p>
<ul dir="auto">
<li><strong>Sapphire:</strong> BSD‚Äë3‚ÄëClause - see <a href="https://github.com/alexykn/sapphire/blob/main/LICENSE.md">LICENSE.md</a></li>
<li>Inspired by Homebrew BSD‚Äë2‚ÄëClause ‚Äî see <a href="https://www.google.com/search?q=NOTICE.md" rel="nofollow">NOTICE.md</a></li>
</ul>
<hr>
<blockquote>
<p dir="auto"><em>Alpha software. No guarantees. Use responsibly.</em></p>
</blockquote>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[œÄ0.5: A VLA with open-world generalization (101 pts)]]></title>
            <link>https://pi.website/blog/pi05</link>
            <guid>43764439</guid>
            <pubDate>Tue, 22 Apr 2025 17:29:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pi.website/blog/pi05">https://pi.website/blog/pi05</a>, See on <a href="https://news.ycombinator.com/item?id=43764439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Published</p><p>April 22, 2025</p><p>Email</p><p><span>research@physicalintelligence.company</span><span>Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili Yu, Ury Zhilinsky</span></p><p>Paper</p></div>

<div><p>Robots have come a long way over the past few years‚Äîthey can perform impressive acrobatic feats, dance on stage, follow language commands and, <a href="https://pi.website/blog/pi0">in some of our own results</a>, perform complex tasks like folding laundry or cleaning off a table. But the biggest challenge in robotics is not in performing feats of agility or dexterity, but generalization: the ability to figure out how to correctly perform even a simple task in a new setting or with new objects. Imagine a robot that needs to clean your home: every home is different, with different objects in different places. Generalization must occur at many levels. At the low level, the robot must understand how to pick up a spoon (by the handle) or plate (by the edge), even if it has not seen these specific spoons or plates before, and even if they are placed in a pile of dirty dishes. At a higher level, the robot must understand the semantics of each task‚Äîwhere to put clothes and shoes (ideally in the laundry hamper or closet, not on the bed), and what kind of tool is appropriate for wiping down a spill. This generalization requires both robust physical skills and a common-sense understanding of the environment, so that the robot can generalize at many levels at the same time, from physical, to visual, to semantic. This is made even harder by the limited availability of diverse data for such robotic systems.</p><p>This is why most commercial robots operate in tightly controlled environments like factories or warehouses: in a world where the robot never needs to venture outside of a single building and where the objects and their locations are predetermined, current robotic methods that provide for only weak generalization can be very successful. Even the impressive demonstrations of robotic agility and dexterity that have been shown in recent years are typically designed to work in a specific environment, often with data collected in the test scene or very similar settings. But if we want robots to be part of our everyday lives, working in our homes, grocery stores, offices, hospitals, and other "messy" environments, we need strong generalization.</p><p>We have been developing robotic foundation models that can generalize to such messy environments, building on our vision-language-action (VLA) model <span>œÄ<sub>0</sub></span>. While both <span>œÄ<sub>0</sub></span> and other recent VLAs are evaluated in environments that closely match training, we've developed a new model that we call <span>œÄ<sub>0.5</sub></span> that exhibits meaningful generalization to entirely new environments. We believe that this represents a significant step forward toward truly generalizable physical intelligence. Our current model is far from perfect: its goal is not to accomplish new skills or exhibit high dexterity, but to generalize to new settings, such as cleaning up a kitchen or bedroom in a new home that was not seen in the training data. In our experiments, <span>œÄ<sub>0.5</sub></span> can perform a variety of tasks in entirely new homes. It does not always succeed on the first try, but it often exhibits a hint of the flexibility and resourcefulness with which a person might approach a new challenge.</p><p>The individual tasks that <span>œÄ<sub>0.5</sub></span> performs vary in difficulty, from rearranging objects (e.g., to put dishes in the sink) to much more intricate behaviors, such as using a sponge to wipe down a spill. We show some of the more complex stages in these tasks below, and the videos of the long-horizon behaviors <a href="#long-horizon-videos">later in the post</a>.</p></div>

<div><h3 id="how-does-it-work">How does it work?</h3><p>The main principle behind <span>œÄ<sub>0.5</sub></span> is co-training on heterogeneous data: by training our VLA model on a variety of different data sources, we can teach it not only how to physically perform diverse skills, but also how to understand the semantic context of each skill (e.g., if the task is to clean the kitchen, what are appropriate objects to pick up and put away, and where to put them), infer the high-level structure of a task (e.g., the steps required to make a bed), and even transfer physical behaviors from other robots (e.g., simpler robots that have one arm or no mobile base, or data from robots in less diverse environments).</p><p>Co-training is conceptually straightforward: because VLAs are derived from general vision-language models (VLMs), they can be trained on examples that consist of any combination of actions, images, text, and other multimodal annotations such as bounding boxes. This includes general multimodal tasks, such as image captioning, visual question answering, or object detection, and robotic oriented tasks, such as robotic demonstrations with actions, and "high-level" robot examples, consisting of observations labeled with the appropriate semantic behavior (e.g., an observation of an unmade bed with the label "pick up the pillow"). We also include "verbal instruction" demonstrations, where a person coaches the robot through a complex task by telling it what to do step by step (with natural language). The model makes both high-level inferences about the next semantic step to perform, analogously to chain-of-thought inference, and low-level predictions to output motor commands to the robot's joints:</p></div>

<p>While the basic principles of co-training are not new, training a VLA that can generalize broadly requires the right mixture of co-training tasks. Just like a person needs an appropriate curriculum to teach them the conceptual and practical aspects of a new job, VLAs need a "curriculum" provided by the mixture of co-training tasks to enable generalization at all of the necessary levels of abstraction. In our experiments, we trained versions of the <span>œÄ<sub>0.5</sub></span> model that exclude different parts of the full training mixture: the "no WD" version excludes multimodal <strong>W</strong>eb <strong>D</strong>ata (question-answering, captioning, and object detection), the "no ME" version excludes <strong>M</strong>ultiple <strong>E</strong>nvironment data collected with non-mobile robots (e.g., static robots placed into many other homes), the "no CE" version excludes <strong>C</strong>ross <strong>E</strong>mbodiment data collect as part of the original <span>œÄ<sub>0</sub></span> training set, and the "no ME or CE" version excludes both sources of robot data, leaving only the mobile manipulation data collected with the same robots that we use in our experiments (about 400 hours).</p>
<div><div><div><p>In-distribution Follow Rate</p></div><div><p>In-distribution Success Rate</p></div></div><p>Evaluating the full <span>œÄ<sub>0.5</sub></span> training mixture compared to ablations that exclude various sources of data. Web data (WD) makes the biggest difference for generalizing to out-of-distribution objects, while data from other robots (ME and CE) is important across all evaluation conditions.</p></div>
<div><p>We evaluated two experimental conditions: full cleaning tasks, such as putting away dishes in the sink or cleaning up items off the floor of a bedroom, and an out-of-distribution (OOD) evaluation that tasks the robot to move specific objects indicated in the prompt into a drawer. For both evaluations, we measure the success rate, averaged over individual subtasks (e.g., the percentage of objects that were moved into their proper place), as well as the language following rate, which indicates the fraction of cases where the robot's behavior correctly accords with the user's prompt. We can see that in all cases, data from other robots (ME and CE) makes a big difference in terms of policy performance. In the OOD case, we also see a significant difference from including web data (WD), which greatly improves the robot's ability to correctly identify new object categories that were not in the data. More details on these experiments are included in the <a href="https://pi.website/download/pi05.pdf">accompanying paper</a>.</p><p>To better quantify just how much generalization <span>œÄ<sub>0.5</sub></span> can achieve, we conducted a scaling study where we vary the number of different environments seen in the training data. We also include a baseline model in these comparisons that was trained directly on data from the test environment in addition to all of the other data sources. This model (shown with a horizontal green line) provides a sense for how well a VLA could do in this scene if the challenge of generalizing to new environments is removed.</p></div>
<div><p>Evaluating how performance scales with the number of training environments, when co-training with the other datasets in our training mixture. When using all of the available training environments (rightmost point on the graph), our model (yellow) attains similar performance as a baseline that is trained directly on test environments (green).</p></div>
<div><p>These results not only show that the generalization performance of <span>œÄ<sub>0.5</sub></span> steadily increases with the number of distinct environments in the training set, but that after only about 100 training environments, it actually approaches the performance of the baseline model that was trained on test environment directly. This suggests that our recipe can attain effective generalization using relatively accessible amounts of mobile manipulation training data.</p><h3 id="training-and-inference">Training and inference</h3><p><span>œÄ<sub>0.5</sub></span> is based on the <span>œÄ<sub>0</sub></span> VLA, but because it is co-trained on tasks that require outputting a variety of label types, including actions and text, we can use the same model to control the robot at both the high and low level. When we run <span>œÄ<sub>0.5</sub></span>, we first ask it to output a "high level" action expressed in text, and then ask it to follow this high level action by choosing an appropriate robot motor command, in the form of a 50-step (1-second) "action chunk" of continuous low-level joint actions. This approach follows our recently developed <a href="https://pi.website/research/hirobot">Hi Robot</a> system, except that the same model is used for both the high-level decisions and low-level motor control in a kind of "chain of thought" process.</p><p>The model itself includes both discrete auto-regressive token decoding and continuous decoding via flow matching, as in <span>œÄ<sub>0</sub></span>. The discrete decoding pathway is used for inferring high-level actions, while the continuous flow-matching pathway is used for low-level motor commands, as illustrated in the diagram below.</p></div>

<div><h3 id="generalization-to-new-homes">Generalization to new homes</h3><p>We evaluated <span>œÄ<sub>0.5</sub></span> by asking it to control mobile manipulators to clean new homes that were never seen in the training data. This is an exceptionally difficult test for a VLA: while there have been impressive demonstrations of VLA generalization, such as following new semantic commands, interactively following human instructions, and chaining together distinct primitive skills, such demonstrations typically take place in the same or very similar environment as the training data. Our recent <a href="https://pi.website/research/fast"><span>œÄ<sub>0</sub></span>-FAST model</a> was able to generalize to new environments with the DROID setup, but for relatively simple skills like moving individual objects. Our experiments involved placing a robot equipped with <span>œÄ<sub>0.5</sub></span> into an entirely new home and asking it to put away dishes, make the bed, or clean up a bedroom floor. These are long tasks that require not only using complex behaviors (such as using a sponge to clean a spill), but also understanding the semantics of the task and breaking it down into individual parts, with each stage interacting with the correct object. We show example evaluations of <span>œÄ<sub>0.5</sub></span> in the videos below.</p></div>
<div id="long-horizon-videos"><div><p>Examples of our model completing long-horizon tasks in new kitchens and bedrooms.<!-- --> </p><p><strong>All experiments were done in homes that were not in the training data.</strong></p></div></div>
<p>The policies are reactive, and can handle both variability in the environment and perturbations. In the videos below, we test what happens when people interfere with the robot.</p>

<p>Lastly, the <span>œÄ<sub>0.5</sub></span> model can accept language commands at various levels of granularity, from high-level prompts like "put the dishes in the sink" to detailed individual commands instructing the model to pick up specific objects or move in specific directions. We show some examples of language following in the videos below.</p>
<div><div><p>Our model can follow language commands at various levels of granularity.<br><strong>Yes, you know it by now - all experiments were done in homes that were not in the training data.</strong></p></div><p>We include detailed videos from our rigorous empirical evaluation below, with examples of successful and failed episodes of our model. Importantly, as with all the videos on this page, none of the scenes in the videos below are from the training data. Complete results from all experiments can be found in the <a href="https://pi.website/download/pi05.pdf">full article</a>.</p><h3 id="where-do-we-go-from-here">Where do we go from here?</h3><p>We showed that VLAs can enable broad generalization even for complex and extended robotic skills, like cleaning a kitchen or bedroom. Our <span>œÄ<sub>0.5</sub></span> model can enable a robot to clean a new home that was never seen in the training data. <span>œÄ<sub>0.5</sub></span> is far from perfect, and it often makes mistakes both in terms of its high-level semantic deductions and motor commands. However, by allowing robots to learn from a variety of knowledge sources, we hope that the <span>œÄ<sub>0.5</sub></span> recipe will bring us closer to broadly generalizable and flexible physical intelligence. There is a lot left to do: while our robots can improve from verbal feedback, they could also in the future utilize their autonomous experience to get better with even less supervision, or they could explicitly request help or advice in unfamiliar situations. There is also a lot left to do to improve transfer of knowledge, both in the technical aspects of how the models are structured, and in the diversity of data sources that our models can employ.</p><p>If you are interested in collaborating, please <a href="mailto:collaborate@physicalintelligence.company" target="_blank" data-state="closed">reach out</a>. We are particularly excited to work with companies scaling up data collection with robots deployed for real-world applications, who are looking to collaborate on autonomy.</p><p>We are also hiring! If you'd be interested in <a href="https://pi.website/join-us">joining us</a> please get in touch.</p><p>For researchers interested in our work, collaborations, or other queries, please write to <a href="mailto:research@physicalintelligence.company" target="_blank" data-state="closed">research@physicalintelligence.company</a>.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are polynomial features the root of all evil? (2024) (110 pts)]]></title>
            <link>https://alexshtf.github.io/2024/01/21/Bernstein.html</link>
            <guid>43764101</guid>
            <pubDate>Tue, 22 Apr 2025 16:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexshtf.github.io/2024/01/21/Bernstein.html">https://alexshtf.github.io/2024/01/21/Bernstein.html</a>, See on <a href="https://news.ycombinator.com/item?id=43764101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="a-myth">A myth</h2>

<p>When fitting a non-linear model using linear regression, we typically generate new features using non-linear functions. We also know that any function, in theory, can be approximated by a sufficiently high degree polynomial. This result is known as <a href="https://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem">Weierstrass approximation theorem</a>. But many blogs, papers, and even books tell us that high polynomials should be avoided. They tend to oscilate and overfit, and regularization doesn‚Äôt help! They even scare us with images, such as the one below, when the polynomial fit using the data points (in red) is far away from the true function (in blue):
<img src="https://alexshtf.github.io/assets/poly_overfit.png" alt="Polynomial overfitting"></p>

<p>It turns out that it‚Äôs just a MYTH. There‚Äôs nothing inherently wrong with high degree polynomials, and in contrast to what is typically taught, high degree polynomials are easily controlled using standard ML tools, like regularization. The source of the myth stems mainly from two misconceptions about polynomials that we will explore here. In fact, not only they are great non-linear features, certain representations also provide us with powerful control over the shape of the function we wish to learn.</p>

<p>A colab notebook with the code for reproducing the above results is available <a href="https://github.com/alexshtf/alexshtf.github.io/blob/master/assets/polyfeatures.ipynb">here</a>.</p>

<h2 id="approximation-vs-estimation">Approximation vs estimation</h2>

<p>Vladimir Vapnik, in his famous book ‚ÄúThe Nature of Statistical Learning Theory‚Äù which is cited more than 100,000 times as of today, coined the approximation vs. estimation balance. The approximation power of a model is its ability to represent the ‚Äúreality‚Äù we would like to learn. Typically, approximation power increases with the complexity of the model - more parameters mean more power to represent any function to arbitrary precision. Polynomials are no different - higher degree polynomials can represent functions to higher accuracy. However, more parameters make it difficult to <em>estimate these parameters from the data</em>.</p>

<p>Indeed, higher degree polynomials have a higher capacity to approximate arbitrary functions. And since they have more coefficients, these coefficients are harder to estimate from data. But how does it differ from other non-linear features, such as the well-known <a href="https://en.wikipedia.org/wiki/Radial_basis_function">radial basis functions</a>? Why do polynomials have such a bad reputation? Are they truly hard to estimate from data?</p>

<p>It turns out that the primary source is the standard polynomial basis for n-degree polynomials \(\mathbb{E}_n = {1, x, x^2, ..., x^n}\). Indeed, any degree \(n\)  polynomial can be written as a linear combination of these functions:</p><p>

\[\alpha_0 \cdot 1 + \alpha_1 \cdot x + \alpha_2 \cdot x^2 + \cdots + \alpha_n x^n\]

</p><p>But the standard basis \(\mathbb{B}_n\) is <em>awful</em> for estimating polynomials from data. In this post we will explore other ways to represent polynomials that are appropriate for machine learning, and are readily available in standard Python packages. We note, that one advantage of polynomials over other non-linear feature bases is that the only hyperparameter is their <em>degree</em>. There is no ‚Äúkernel width‚Äù, like in radial basis functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>The second source of their bad reputation is misunderstanding of Weierstrass‚Äô approximation theorem. It‚Äôs usually cited as ‚Äúpolynomials can approximate arbitrary continuous functions‚Äù. But that‚Äôs not entrely true. They can approximate arbitrary continuous functions <strong>in an interval</strong>. This means that when using polynomial features, the data must be normalized to lie in an interval. It can be done using min-max scaling, computing empirical quantiles, or passing the feature through a sigmoid. But we should avoid the use of polynomials on raw un-normalized features.</p>

<h2 id="building-the-basics">Building the basics</h2>

<p>In this post we will demonstrate fitting the function</p><p>

\[f(x)=\sin(8 \pi x) / \exp(x)+x\]

</p><p>on the interval \([0, 1]\) by fitting to \(m=30\) samples corrupted by Gaussian noise. The following code implements the function and generates samples:</p>

<div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>true_func</span><span>(</span><span>x</span><span>):</span>
  <span>return</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>8</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>x</span><span>)</span> <span>/</span> <span>np</span><span>.</span><span>exp</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>x</span>

<span>m</span> <span>=</span> <span>30</span>
<span>sigma</span> <span>=</span> <span>0.1</span>

<span># generate features
</span><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>42</span><span>)</span>
<span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>m</span><span>)</span>
<span>y</span> <span>=</span> <span>true_func</span><span>(</span><span>X</span><span>)</span> <span>+</span> <span>sigma</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>m</span><span>)</span>
</code></pre></div>

<p>For function plotting, we will use uniformly-spaced points in \([0, 1]\). The following code plots the true function and the sample points:</p>

<div><pre><code><span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span>plt_xs</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1000</span><span>)</span>
<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>
<span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_func.png" alt="polyfit_func"></p>

<p>Now let‚Äôs fit a polynomial to the sampled points using the standard basis. Namely, we‚Äôre given the set of noisy points \(\{ (x_i, y_i) \}_{i=1}^m\), and we need to find the coefficients \(\alpha_0, \dots, \alpha_n\) that minimize:</p><p>

\[\sum_{i=1}^m (\alpha_0 + \alpha_1 x_i + \dots + \alpha_n x_i^n - y_i)^2\]

</p><p>As expected, this is readily accomplished by transforming each sample \(x_i\) to a vector of features \(1, x_i, \dots, x_i^n\), and fitting a linear regression model to the resulting features. Fortunately, NumPy has the <code>numpy.polynomial.polynomial.polyvander</code>function. It takes a vector containing \(x_1, \dots, x_m\) and produces the matrix</p><p>

\[\begin{pmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \dots &amp; x_1^n \\
1 &amp; x_2 &amp; x_2^2 &amp; \dots &amp; x_2^n \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_m &amp; x_m^2 &amp; \dots &amp; x_m^n \\
\end{pmatrix}\]

</p><p>The name of the function comes from the name of the matrix - the Vandermonde matrix. Let‚Äôs use it to fit a polynomial of degree \(n=50\).</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>LinearRegression</span>
<span>import</span> <span>numpy.polynomial.polynomial</span> <span>as</span> <span>poly</span>

<span>n</span> <span>=</span> <span>50</span>
<span>model</span> <span>=</span> <span>LinearRegression</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>
</code></pre></div>

<p>The reason we use <code>fit_intercept=False</code> is because the ‚Äòintercept‚Äô is provided by the first column of the Vandermonde matrix. Now we can plot the function we just fit:</p>

<div><pre><code><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>As expected, we got the ‚Äúscary‚Äù image from the beginning of this post. Indeed, the standard basis is awful for model fitting! We hope that regularization provides a remedy, but it does not. Maybe adding some L2 regularization helps? Let‚Äôs use the <code>Ridge</code> class from the <code>sklearn.linear_model</code>  package to fit an L2 regularized model:</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>Ridge</span>

<span>reg_coef</span> <span>=</span> <span>1e-7</span>
<span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>reg_coef</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_standard_ridge.png" alt="polyfit_standard_ridge"></p>

<p>The regularization coefficient coefficient of \(\alpha=10^{-7}\) is large enough to break the model in \([0,0.8]\) but not large enough to avoid over-fitting in \([0.8, 1]\). Increasing the coefficient clearly won‚Äôt help - the model will be broken even further in \([0, 0.8]\).</p>

<p>Since we will be trying several polynomial bases, it makes sense to write a more generic function for our experiments that will accept various ‚ÄúVandermonde‚Äù matrix functions of the basis of our choice, fit the polynomial using the <code>Ridge</code> class, and plot it with the original function and the sample points.</p>

<div><pre><code><span>def</span> <span>fit_and_plot</span><span>(</span><span>vander</span><span>,</span> <span>n</span><span>,</span> <span>alpha</span><span>):</span>
  <span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>alpha</span><span>)</span>
  <span>model</span><span>.</span><span>fit</span><span>(</span><span>vander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

  <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                           <span># plot the samples
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                 <span># plot the true function
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>vander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span>  <span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
  <span>plt</span><span>.</span><span>show</span><span>()</span>  
</code></pre></div>

<p>Now we can reproduce our latest experiment by invoking:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<h2 id="polynomial-bases">Polynomial bases</h2>

<p>It turns out that in our sister discipline, approximation theory, reseachers also encountered similar difficulties with the standard basis \(\mathbb{E}_n\), and developed a thoery for approximating functions by polynomials from different bases. Two prominent examples of bases of \(n\)-degree polynomials include, and their:</p>

<ol>
  <li>The <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> \(\mathbb{T}_n = \{ T_0, T_1, \dots, T_n \}\), implemented in the <code>numpy.polynomial.chebyshev</code> module.</li>
  <li>The <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomials</a> \(\mathbb{P}_n = \{ P_0, P_1, \dots, P_n \}\), implemented in the <code>numpy.polynomial.legendre</code> module.</li>
</ol>

<p>They are the computational workhorse of a large variety of numerical algorithms that are enabled by approximating a function using a polynomial, and are well-known for their advantages in approximating functions in the \([-1, 1]\) interval<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">2</a></sup>. In particular, the corresponding ‚ÄúVandermonde‚Äù matrices are provided by the <code>chebvander</code> and <code>legvander</code> functions in corresponding modules above. Each row in these matrices contains the value of the basis functions at each point, just like the standard Vandermonde matrix of the standard basis. For example, the Chebyshev Vandermonde matrix is:</p><p>

\[\begin{pmatrix}
T_0(x_1) &amp; T_1(x_1) &amp; \dots &amp; T_n(x_1) \\
T_0(x_2) &amp; T_1(x_2) &amp; \dots &amp; T_n(x_2) \\
\vdots &amp; \vdots  &amp; \ddots&amp; \vdots  \\
T_0(x_m) &amp; T_1(x_m) &amp; \dots &amp; T_n(x_m) \\
\end{pmatrix}\]

</p><p>I will not elaborate their formulas and properties here for a reason that will immediately be revealed. However, I highly recomment Prof. Nick Trefethen‚Äôs ‚ÄúApproximation theory and approximation practice‚Äù <a href="https://people.maths.ox.ac.uk/trefethen/atapvideos.html">online video course</a> to get familiar with their advantages. His book with the same name is an excellent introduction to the subject.</p>

<p>It might be tempting to try fitting a Chebyshev polynomial using our <code>fit_and_plot</code> method above directly:</p>

<div><pre><code><span>import</span> <span>numpy.polynomial.chebyshev</span> <span>as</span> <span>cheb</span>

<span>fit_and_plot</span><span>(</span><span>cheb</span><span>.</span><span>chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<p>However, that‚Äôs not the best thing to do. We aim to fit a function sampled from \([0, 1]\), but the Chebyshev basis ‚Äúlives‚Äù in \([-1, 1]\). Therefore, we will add the transformation \(x \to 2x-1\) before invoking the <code>chebvander</code> function:</p>

<div><pre><code><span>def</span> <span>scaled_chebvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
  <span>return</span> <span>cheb</span><span>.</span><span>chebvander</span><span>(</span><span>2</span> <span>*</span> <span>x</span> <span>-</span> <span>1</span><span>,</span> <span>deg</span><span>=</span><span>deg</span><span>)</span>

<span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1</span><span>)</span>
</code></pre></div>

<p>Note that a different basis requires a different regularization coefficient. We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg1.png" alt="polyfit_cheb_reg1"></p>

<p>Whoa! Seems even worse than the standard basis!. Maybe more regularization helps?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>10</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg10.png" alt="polyfit_cheb_reg10"></p>

<p>Appears that our polynomial is both a bad fit for the function, and extremely oscilatory. Even worse when the standard basis! Interested readers can repeat the experiment with Legendre polynomials and see a slightly better, but similar result. So what‚Äôs wrong? Is everything that approximation theory tries to teach us about polynomials wrong?</p>

<p>The answer stems from the fundamental difference between two tasks:</p>

<ul>
  <li><strong>Interpolation</strong> - finding a polynomial that agrees with the approximated function \(f(x)\) <em>exactly</em> at a set of <em>carefully chosen</em> points</li>
  <li><strong>Fitting</strong> - finding a polynomial that agrees <em>approximately</em> with a given <em>noisy</em> set of points, which are <em>out of our control</em>.</li>
</ul>

<p>The Chebyshev and Legendre bases perform extremely well at the the interpolation task, but not at the fitting task. It turns out that the polynomial \(T_k\) in the Chebyshev basis, and the polynomial \(P_k\) in the Legendre basis, are both \(k\)-degree polynomials. For example, \(T_1\) is a linear function, whereas \(T_{50}\) is a polynomial of degree 50. These two functions are radically different. Thus, the coefficient of \(T_1\) and \(T_{50}\) have ‚Äúdifferent units‚Äù. This property is shared with the standard basis as well. Thus, we have two issues:</p>

<ol>
  <li>A small change of the coefficient of a high degree basis function, say the coefficient \(\alpha_{50}\), has a huge effect on the shape of the polynomial. Thus, a small perturbation in the input data, be it from noise or a slighly different data point \(x_i\), has a <em>huge</em> effect of the fit model.</li>
  <li>L2 regularization makes no sense! For reasonable functions, the coefficient \(\alpha_{50}\) should be much smaller than the coefficient \(\alpha_1\). This is regardless of the choice of the basis!</li>
</ol>

<p>Both properties show that for the fitting, rather the interpolation tasks we need something else.</p>

<h2 id="the-bernstein-basis">The Bernstein basis</h2>

<p>A remedy is provided by the <a href="https://en.wikipedia.org/wiki/Bernstein_polynomial">Bernstein basis</a> \(\mathbb{B}_n = \{  b_{0,n}, \dots, b_{n, n} \}\). These are \(n\)-degree polynomials defined by on \([0, 1]\) by:</p><p>

\[b_{i,n}(x) = \binom{n}{i} x^i (1-x)^{n-i}\]

</p><p>These polynomials are widely used in computer graphics to approximate curves and surfaces, but it appears that they‚Äôre less known in the machine learning community. In fact, all the text you see on the screen when reading this post is rendered using Bernstein polynomials<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup>. We will study them more in depth in the next posts, but at this stage I would like to point out two simple properties that give an intuitive explanation of why they‚Äôre useful in machine learning.</p>

<p>First, note that each \(b_{i,n}\) is an \(n\)-degree polynomial. Thus, when representing a polynomial using</p><p>

\[p_n(x) = \alpha_0 b_{0,n}(x) + \alpha_1 b_{1,n}(x) + \dots + \alpha_n b_{n,n}(x),\]

</p><p>all the coefficients have the same ‚Äúunits‚Äù.</p>

<p>If the formula of \(b_{i,n}(x)\) seems familiar - you are correct. It is exactly the probability mass function of the binomial distribution for obtaining \(i\) successes in a sequence of trials whose success probability is \(x\). Therefore, \(b_{i,n}(x) \geq 0\),  and \(\sum_{i=0}^n b_{i,n}(x) = 1\) for any \(x \in [0, 1]\). Consequently, the polynomial \(p_n(x)\) is just a weighted average of the coefficients \(\alpha_0, \dots, \alpha_n\). So not only the coefficients have the same ‚Äúunits‚Äù, their ‚Äúunits‚Äù are also the same as the model‚Äôs labels. Thus, they‚Äôre much easier to regularize - they‚Äôre all on the same ‚Äúscale‚Äù.</p>

<p>Finally, due to the equivalence with the binomial distribution p.m.f, we can implement a ‚ÄúVandermonde‚Äù matrix in Python using the <code>scipy.stats.binom.pmf</code> function.</p>

<div><pre><code><span>from</span> <span>scipy.stats</span> <span>import</span> <span>binom</span>

<span>def</span> <span>bernvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
	<span>return</span> <span>binom</span><span>.</span><span>pmf</span><span>(</span><span>np</span><span>.</span><span>arange</span><span>(</span><span>1</span> <span>+</span> <span>deg</span><span>),</span> <span>deg</span><span>,</span> <span>x</span><span>.</span><span>reshape</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>1</span><span>))</span>
</code></pre></div>

<p>Let‚Äôs try and fit without regularization at all</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>0</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg0.png" alt="polyfit_bern_reg0"></p>

<p>We see our regular over-fitting. Now let‚Äôs see that they‚Äôre indeed easy to regularize. After trying several regularization coefficients, I came up with this:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>5e-7</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg5em4.png" alt="polyfit_bern_reg5em4"></p>

<p>Beautiful! This is a polynomial of degree 50! The fit is great, no oscillations, and the misfit near the right endpoint stems from the noise - I don‚Äôt believe there‚Äôs enough information in the data to convey the fact that it should ‚Äúcurve up‚Äù rather than ‚Äúcurve down‚Äù.</p>

<p>Let‚Äôs see what happens when we crank-up the degree. Can we produce a nice non-oscilating polynomial?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>100</span><span>,</span> <span>alpha</span><span>=</span><span>5e-4</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_100_reg5em4.png" alt="polyfit_bern_100_reg5em4"></p>

<p>This is a polynomial of degree 100, that does not overfit!</p>

<h2 id="summary">Summary</h2>

<p>The notorious reputation of high-degree polynomials in the machine learning community is primarily a myth. Despite it, papers, books, and blog posts are based on this premise as if it was an axiom. Bernstein polynomials are little known in the machine learning community, but there are a few papers<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> using them to represent polynomial features. Their main advantage is ease of use - we can use high degree polynomials to exploit their approximation power, and easily control model complexity with just one hyperparameter - the regularization coefficient.</p>

<p>In the following posts we will explore the Bernstein basis in more detail. We will use it to create polynomial features for real-world datasets and test it versus the standard basis. Moreover, we will see how to regularize the coefficients to control the shape of the function we aim to represent.. For example, what if we know that the function we‚Äôre aiming to fit is increasing? Stay tuned!</p>

<hr>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I should have loved biology too (137 pts)]]></title>
            <link>https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</link>
            <guid>43764076</guid>
            <pubDate>Tue, 22 Apr 2025 16:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too">https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</a>, See on <a href="https://news.ycombinator.com/item?id=43764076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>About a year ago, I came across James Somers‚Äô blog post, </span><em><a href="https://jsomers.net/i-should-have-loved-biology/" rel="">I should have loved biology</a></em><span>. I began reading it and every sentence struck a chord: ‚ÄúI should have loved biology but found it a lifeless recitation of names‚Äù; ‚ÄúIn textbooks, astonishing facts were presented without astonishment‚Äù; ‚ÄúIn biology class, biology wasn‚Äôt presented as a quest for the secrets of life. The textbooks wrung out the questing.‚Äù In fact, the chord was so neatly stuck that I stopped reading about a quarter of the way through, and found myself falling into a memory. I was sitting in my 7th grade biology class, completely disinterested. Every time our teacher would turn her back to us to write on the blackboard, my friends and I would sling paper pellets at each other across the room, barely paying attention as she narrated wearily about cell walls or chloroplasts or mitochondria being the powerhouse of the cell. I liked math and physics and economics and even chemistry, to some extent (much less pellet slinging), but biology, with its endless memorization of definitions and regurgitation of facts ‚Äì no, biology could go back under the soil it came from.</span></p><p>Now, I‚Äôm obsessed. I can‚Äôt get enough. I‚Äôve read about fifteen books in the last year or so, watched countless YouTube videos, and started a bioinformatics course. And my list keeps growing. The first quarter of Somers‚Äô post was so effective in making me consider my own disinterest-to-obsession journey ‚Äì (I didn‚Äôt even read the rest until months later) ‚Äì that I decided to look back and examine what caused this complete change of heart.</p><p><span>More than anything ‚Äì nature documentaries, science shows, museum visits ‚Äì it was great writing that allowed me to see the world of biology differently. My interest in biology, or rather the reversal of my disinterest in biology, began when I read </span><em>The Sixth Extinction</em><span> in 2016, during my second year of university. Elizabeth Kolbert‚Äôs gripping writing unveiled a completely different perspective of the subject, right alongside the scientists and researchers: driving through a Panamanian rainforest looking for golden frogs, searching a littered New Jersey creek for ammonites, scuba-diving in Castello Aragonese to inspect carbon dioxide rushing out of sea vents and in The Great Barrier Reef to look at octopi and coral reefs and blue starfish and leopard sharks and giant clams. Biology, suddenly, didn‚Äôt seem just a list of facts to memorize; it was an adventure.</span></p><p>I still remember how I felt after finishing her book: a strange mix of wonder and tragedy, awe and despair. That narrative structure ‚Äì vivid reporting and meticulous research built on a foundation of context and history ‚Äì changed how I saw science and scientists. No more dry paragraphs of definitions and explanations; every discovery had a story.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" width="1000" height="667" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:667,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1083159,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>The Great Barrier Reef, the world‚Äôs largest coral reef system. Elizabeth Kolbert occasionally reports about the impact of climate change there.</figcaption></figure></div><p><span>I wanted more books just like that, and luckily for me, several months later in an airport bookshop in Bangalore, I came across and picked up </span><em>The Gene</em><span>. I wasn‚Äôt aware of who Siddhartha Mukherjee was at the time (possibly the mention of Pulitzer Prize winner on the cover influenced me), and I had no prior interest in genetics, but that book would end up completely changing my worldview on biology and non-fiction writing. If Kolbert made a crack in the dam I had built around biology, Mukherjee would go on to smash the whole thing down to pieces.</span></p><p>One of the stories in the book, the discovery of the gene that caused Huntington‚Äôs disease, moved me tremendously when I first read it a few years ago. It‚Äôs the perfect example of the amount of effort that goes into a scientific discovery that then ends up as a single sentence in a textbook; in this case, that Huntington‚Äôs disease is a hereditary, neurodegenerative disorder caused by a mutation in a single gene.</p><p><span>The story of finding that mutation would make a thrilling movie: a young woman named Nancy Wexler, devastated by the news that her mother has been diagnosed with Huntignton‚Äôs and that she and her sister would have a 50-50 chance of getting it, decides to devote her life to solving this medical mystery. Her quest takes her from nursing homes in Los Angeles to interdisciplinary scientific workshops in Boston to stilt villages surrounding Lake Maracaibo in Venezuela. Her decade-long blood and skin sample collection efforts there would create the largest family tree with Huntington‚Äôs, leading to the first genetic test for the disease, followed by locating the precise genetic mutation that caused it</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-1-158089094" target="_self" rel="">1</a></span><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:231012,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Dr. Nancy Wexler in 1990, with a family tree that traced the path of Huntington‚Äôs. Acey Harper/The LIFE Collection, via Getty Images. Taken from the New York Times.</figcaption></figure></div><p><span>The gene sequence had a strange repeating structure, CAGCAGCAG‚Ä¶ continuing for 17 repeats on average (ranging between 10 to 35 normally), encoding a huge protein that‚Äôs found in neurons and testicular tissue (its exact function is still not well understood). The mutation that causes HD increases the number of repeats to more than forty ‚Äì a ‚Äúmolecular stutter‚Äù ‚Äì creating a longer huntingtin protein, which is believed to form abnormally sized clumps when enzymes in neural cells cut it. The more repeats there are, the sooner the symptoms occur and the higher the severity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-2-158089094" target="_self" rel="">2</a></span><span>.</span></p><p>Nancy herself opted not to take the genetic test she helped create. ‚ÄúIf the test showed I have the gene,‚Äù she wrote in 1991, ‚Äúwould I continue to feel the happiness, the passion, the occasional ecstasy I feel now? Is the chance of release from Huntington‚Äôs worth the risk of losing joy?‚Äù. In 2020, at the age of 74, she revealed that she had Huntington‚Äôs. The public acknowledgment was not a surprise for those close to her ‚Äì for the last decade, they noticed her gait slowly deteriorate, speech slur, and limbs jerk in random directions, the same characteristics she saw in her mother half a century ago, and in the hundreds of Venezuelan patients she tended to ever since.</p><p>There‚Äôs still no cure for Huntington‚Äôs disease, but every time I hear about progress on cures, I feel a rush of emotions, like I have a personal stake in its invention. I really wish to see one found within Nancy Wexler‚Äôs lifetime; this movie deserves a happy ending.</p><p>Pick a field in biology, or a slice of history, and you‚Äôll find countless stories just like this. Mischievous Watson and Crick figuring out the structure of DNA after getting a peek at Rosalind Franklin‚Äôs crisp x-ray crystallography photograph; Baruch Blumberg discovering hepatitis B after locating the antigen in the blood of an Australian Aboriginal, and beating NIH to its cure, the world‚Äôs first cancer vaccine; James Simpson systematically inhaling various vapors and recording its effects in the search for a better anesthetic, resulting in the discovery of chloroform; Andreas Vesalius taking prisoners‚Äô corpses hanging in the gallows in 16th century Paris and, along with painter Andrea Mategna, publishing nearly 700 incredibly detailed drawings of the human anatomy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" width="1200" height="1678" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1678,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:161518,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>An illustration from </span><em>De Humani Corporis Fabrica</em><span> (On the Fabric of the Human Body), published in 1543 by Andreas Vesalius and Andrea Mategna. The first edition included over 200 high-detail anatomical illustrations. I particularly like this one.</span></figcaption></figure></div><p>History and stories may not be immediately applicable, but when used as a key ingredient it makes the discoveries more majestic, more impactful. That‚Äôs what I love about Mukherjee‚Äôs writing: it‚Äôs a unique stew of history, biography, experimental methods and results, scientific findings and their significance, seasoned well with personal anecdotes, and presented with the candor of a physician and the artistry of a poet. The context creates a kind of multiplier when the mind-shattering discoveries are explained ‚Äì how a genotype gives rise to a phenotype, how cancer works, how a heart beats or a bone mends itself or a brain remembers a memory. Like the climax of a movie scene, the beauty and immensity of the discovery or the invention feels far more compelling after following the steps that got us there.</p><p><span>Every discovery might not have an entertaining backstory, but even when focusing on just the phenomenon, great technical writing has this striking ability to make you see the world differently. The same molecule or cell or organ, theory or experiment or discovery, suddenly seems monumental, like it‚Äôs the most important thing in the world. It makes you think: </span><em>why didn‚Äôt I learn about this before?</em></p><p><span>One of my favourites is the way Mukherjee describes how a neuron communicates in </span><em>The Song of the Cell</em><span>:</span></p><blockquote><p><em>Imagine the nerve, first, in its ‚Äúresting‚Äù state. At rest, the internal milieu of the neuron contains a high concentration of potassium ions and a minimal concentration of sodium ions. This exclusion of sodium from the neuron‚Äôs interior is critical; we might imagine these sodium ions as a throng outside the citadel, locked out of the castle‚Äôs walls and banging at the gates to get inside. Natural chemical equilibrium would drive the influx of sodium into the neuron. In its resting state, the cell actively excludes sodium from entry, using energy to drive the ions out‚Ä¶</em></p><p><em>[...] The dendrites are the site within the neuron where the ‚Äúinput‚Äù of the signal originates. When a stimulus‚Äîtypically a chemical called a ‚Äúneurotransmitter‚Äù‚Äîarrives at one of the dendrites, it binds to a cognate receptor on the membrane. And it is at this point that the cascade of nerve conduction begins.</em></p><p><em>The binding of the chemical to the receptor causes channels in the membrane to open. The citadel‚Äôs gates are thrown ajar, and sodium floods into the cell. As more ions swarm in, the neuron‚Äôs net charge changes: every influx of ions generates a small positive pulse. And as more and more transmitters bind, and more such channels open, the pulse increases in amplitude. A cumulative charge courses through the cell body.</em></p></blockquote><p><span>The mental picture of a </span><em>throng</em><span> of sodium ions </span><em>locked out of the castle walls</em><span> is so helpful and convincing. I can see, in my mind‚Äôs eye, these shadowy ions</span><em> banging at the gates to get inside</em><span>, like an invading army</span><em>.</em><span> Then, after the neurotransmitter binds to the cognate receptor, the sodium ions don‚Äôt just enter, they </span><em>flood</em><span> and </span><em>swarm</em><span> in; the membrane doesn‚Äôt just open, its </span><em>gates are thrown ajar</em><span>. The metaphor makes the chemical process relatable without leaving out the details; the vivid language romanticizes it, creating a mental picture that not only stays with you, but makes you want to learn more.</span></p><p>A little later in the chapter, Mukherjee writes about neural connection in the fetus:</p><blockquote><p><em>Neural connections between the eyes and the brain are formed long before birth, establishing the wiring and the circuitry that allow a child to begin visualizing the world the minute she emerges from the womb. Long before the eyelids open, during the early development of the visual system, waves of spontaneous activity ripple from the retina to the brain, like dancers practicing their moves before a performance‚Ä¶ This fetal warm-up act‚Äîthe soldering of neural connections before the eyes actually function‚Äîis crucial to the performance of the visual system. The world has to be dreamed before it is seen.</em></p></blockquote><p><span>There‚Äôs something about this evocative language that leaves a sweet, lingering imprint on my mind ‚Äî a new set of neural connections; my own </span><em>throng </em><span>of sodium ions </span><em>banging at the gates</em><span>, my own </span><em>ripples</em><span>. The details ‚Äì which ions, the name of the receptor ‚Äì might get murky after the passage of time, but the sweet feeling remains, like a memory of a heavenly meal; you may have forgotten the exact taste, but the feeling of satisfaction lingers, and occasionally, when it enters front and center, you might imagine visiting the restaurant (or home) once more. </span></p><p>That‚Äôs what I feel after reading books like this ‚Äì the belief that I‚Äôll revisit it, relive it, relearn it. It fills up a reservoir of curiosity, and every subsequent piece of stimulus ‚Äì a neurology article or academic paper shared on Twitter, a documentary or YouTube video, another book (even textbooks) ‚Äì opens the floodgates, and makes you want to explore a little more. I might not have the equipment to see this cell myself, but when written like this, this world too can be dreamed before it is seen.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" width="1456" height="2176" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2176,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1369914,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Santiago Ram√≥n y Cajal‚Äôs famous drawing of neurons, circa late 19th century. He would go on to create more than 2,900 drawings detailing the nervous system‚Äôs architecture. Image taken from Quanta Magazine</figcaption></figure></div><p><span>The more you explore, the more astonishing it gets. Suddenly, you‚Äôre surrounded by these facts that stop you in your tracks. Like the fact that there are 20-30 trillion red blood cells in our body, making up roughly 84% of all our cells, and 1.2 million are created in our bone marrow every second. Or the fact that our visual system is predictive, calculating where to move the hand to catch a ball before your visual system has fully registered its trajectory</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-3-158089094" target="_self" rel="">3</a></span><span>.</span></p><p><span>One of my favorite ‚Äòsentences that stopped me in my tracks‚Äô comes from Nick Lane‚Äôs book, </span><em>The Vital Question</em><span>. He starts with carefully explaining that all cells derive their energy from a single type of chemical reaction, the redox reaction, where electrons are transferred from one molecule to another. Rust is a redox reaction: iron donates electrons to oxygen, being </span><em>oxidized</em><span> in the process. Same with fire: oxygen (O</span><sub>2</sub><span>) is </span><em>reduced</em><span> to water after receiving two electrons (O</span><sup>2-</sup><span>) and then two protons (H</span><sub>2</sub><span>O), balancing the charges, and releasing heat in the process. Respiration ‚Äî the process that turns our food into energy ‚Äî does exactly this as well, except that it conserves </span><em>some</em><span> of the energy in the form of a molecule called adenosine triphosphate (ATP). Think of ATP as an energy currency, able to be stored or converted back into energy by splitting the molecule into ADP (adenosine diphosphate) and P</span><sub>i</sub><span> (phospate). And so, he writes, ‚Äú</span><strong>in the end respiration and burning are equivalent; the slight delay in the middle is what we know as life</strong><em>.‚Äù</em></p><p>Wait, what? The slight delay in the middle is what we know as life? I think when I first read that I might have skipped a heartbeat. I learned about mitochondria and ATP and redox reactions and aerobic respiration in high school, but I never pictured it as millions of molecular fires that keep us alive. Actually, not a million; it‚Äôs at least a quadrillion ‚Äì per second. </p><p>ATP is synthesized by the fabled mitochondria, but that‚Äôs not all they do. They also regulate metabolism, participate in cell growth and death, manage calcium levels, and are involved in detoxification, hormone production, and cellular signalling. They even have their own genetic code. In fact, your mitochondria come from your mother and your mother only; they‚Äôre not genetically recombined like the rest of you. They‚Äôre remarkably fascinating; even the universally memed ‚Äúpowerhouse‚Äù doesn‚Äôt quite cover its capabilities.</p><p>All of this is still merely scratching the surface of wonder. I‚Äôve only really described three examples in biology, all of which relate to human cells. But we‚Äôre just one of the millions of organisms on this planet. Bacteria, plants, fungi, insects, birds, reptiles, mammals, and everything in between, are all made up of cells. And every level ‚Äì ecological, species, organism, tissue, cellular, organelle, protein, genome ‚Äì has its own stories, each its own magic.</p><p><span>In his blog post, Somers advised to learn in small, deep slices. But I took a different approach: I went shallow and wide. Kolbert, Mukherjee, and Lane inspired exploring adjacent domains, and so I read about epidemiology, drug discovery, gene editing, molecular biology, systems and synthetic biology, immunotherapy, and memoirs from surgeons, cancer patients, and ‚Äúbiology watchers‚Äù. Even my fiction choices started to exhibit a biology tinge: </span><em>The Shell Collector</em><span>, </span><em>The Covenant of Water</em><span>, </span><em>The Overstory</em><span>. Eventually, I started seeing biology everywhere ‚Äî the roots of a sidewalk tree battling with concrete, a group of sparrows frolicking in a bush, a young woman in an air cast fiddling with her crutches ‚Äî as if it escaped the pages and began whispering its presence wherever I went.</span></p><p>Last summer, I went scuba diving for the first time in my life. I‚Äôve wanted to go since I was a teen, a desire amplified after reading Kolbert‚Äôs adventures and watching ocean documentaries. After years and years of postponing, I finally pulled the trigger and flew to Puerto Vallarta to get Open Water certified. I could fill an entire essay with just this certification experience ‚Äî the anxiety-inducing pre-dive coursework that essentially just lists the many ways you can get seriously injured or die; the silly awkwardness of training in a Mexican hotel pool surrounded by curious onlookers; the ear injury I sustained after my first ocean dive, where a rupture caused by improper depressurization caused middle ear fluid to flood my right ear canal, leaving me with partial hearing loss for a week (even PADI‚Äôs intimidating coursework could only do so much) ‚Äî but I will focus on just the experience of my second dive here.</p><p>It was a picture-perfect day in Puerto Vallarta: deep blue skies, fluffy cotton-candy clouds floating above, a momentary cool breeze tempering the unrelenting summer humidity. As our boat sped along to Playa Majahuitas, about a 40 minutes ride from the main pier, I watched the lush green hills roll by just behind the shore, the ocean shimmering as the sun flung silver disks across its surface. During the ride, I asked the couple sharing the boat about their scuba experiences, and, again, I got a common response I still couldn‚Äôt relate to: that it was meditative ‚Äî it was where your problems of land disappear, and you get to be a visitor in the home of sea-life, a polite guest just observing. </p><p>Our dive spot looked like a painting: water so clear you could see schools of fish just by peering over the edge of the boat. Just before we began, we got a surprise visit from a manta ray ‚Äì this enormous, ethereal creature silently gliding under the water, just flicking the tips of its wings above the surface, as if to say hello, and welcome us into its home.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2068990,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The dive spot in Playa Majahuitas, Mexico</figcaption></figure></div><p>After the dive that day, I understood what the couple meant. I felt a lot more comfortable with my equipment second time around, and so, no longer apprehensive about buoyancy or breathing rate or how deep I was, I finally felt free to fully take in my surroundings. I fell into a gentle rhythm: inhale, listen to the hiss of the regulator, exhale, watch the bubbles float away. You‚Äôre distinctly aware of each and every moment, mind blank and in awe of the world around you: a large school of Cortez wrasses passing by; a camouflaged octopus hiding under the seabed; a moray eel sticking its neck out of a little hole, an angry look on its face, as if you‚Äôve just disturbed its sleep; the vast, splendid diversity of corals ‚Äì you can see it living, with little, wavy hand-like appendages collecting bits of floating food to eat, with tiny fish swimming in and out and around, as if playing a game of tag. </p><p>It was truly marvelous. Colors, too, are more vibrant underwater, as if the gods enhanced saturation as a gift to those that dare venture below. The body of spotted boxfish are a glittery blue, and the yellow speckled top shines in contrast. The corals too are rich: deep oranges, yellows, greens and browns. Even ocean documentaries, with their film-grade color editing, don‚Äôt capture the true shades.</p><p>During the boat ride back, I had this incredibly calming bliss completely take over my body. (Maybe that‚Äôs also what people attribute to its meditative quality, although meditative isn‚Äôt exactly the right word). For me, the whole experience would mark the start of a gradual realization that I wanted my role in biology to be more than just reading. My favorite science writers ‚Äì Kolbert, Mukherjee, Lane, Lewis Thomas, Donald Kirsch ‚Äì all wrote from experience, and if I wanted to write, or create, like that, I‚Äôd have to experience the world too. I began piecing together the things that had been swimming in my mind: namely, how to combine my past passion, interactive learning, with my latest obsession, biology. </p><p><span>I have since restarted working on my website, </span><a href="https://www.newtinteractive.com/" rel="">Newt Interactive</a><span>, to make interactive articles and accessible simulators for topics in biology. I too, like Somers mentions at the end of his blog post, want to bring the three dimensional nature of biology to life. The subject is teeming with fascinating phenomena that remain hidden or inaccessible to those outside scientific and research communities. Occasionally, I‚Äôll come across something incredible ‚Äî like a video of a molecular motor in action ‚Äî but the sheer marvel of that just fundamentally doesn‚Äôt click unless you‚Äôre already well versed in the subject</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-4-158089094" target="_self" rel="">4</a></span><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" width="1456" height="851" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:851,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1749056,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>My interactive simulator of a coherent type-1 feed forward loop, a common gene circuit. My hope is that these kinds of playgrounds can make complex topics more accessible. </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">Try it out on Newt Interactive</a></figcaption></figure></div><p><span>I hope to bridge this gap and make some of biology's intricate mechanisms comprehensible and awe-inspiring for everyone. I‚Äôve started with an </span><a href="https://www.newtinteractive.com/series/systems-biology/transcription-network-basics-1" rel="">interactive series on systems biology</a><span> (and wrote about my idea and motivation behind it in a </span><a href="https://nehalslearnings.substack.com/p/a-new-interactive-series-for-systems" rel="">previous post</a><span>), as well as some standalone simulators for a few concepts: </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">coherent type-1 feed forward loops</a><span> and </span><a href="https://www.newtinteractive.com/blocks/circuit-evolution" rel="">genetic circuit evolution</a><span>, for two. My goal is to work my way up to more sophisticated simulations, tools, and interactive articles that will help illustrate, and importantly, allow you to play with, more advanced concepts. In addition, I‚Äôd like to generally write and draw more as well (also started with this by making </span><a href="https://press.asimov.com/articles/gene-circuit" rel="">my first science graphic and biological math model for Asimov Press</a><span>).</span></p><p>Stories of science can elicit all kinds of emotions: joy, sadness, enchantment, heartbreak, optimism, valiance, apprehension, intrigue. I find, however, that one theme seems to be consistent among the characters: curiosity. This shouldn‚Äôt come as a surprise, of course, but what I hadn‚Äôt anticipated was how infectious it could be. Just reading about these scientists ‚Äî their history, theories, efforts, mistakes and unwavering dedication to truth ‚Äî kindled an active curiosity in me. I don‚Äôt think I have the patience to do what the scientists I read about did, experimenting day after day, week and week, year after year, exploring a small sliver in the ‚Äúinfinite vastness of biology‚Äù. And, since my curiosity started and ended with books, I didn‚Äôt think there was a meaningful role I could play. I couldn‚Äôt hear the calling.</p><p>But now I‚Äôm not so sure. I have this recurring desire to look down a microscope, and see a cell live its life, see its components swimming, squirming, dividing. I want to see a sequencing machine take in an organism‚Äôs DNA and spit out all its nucleotide bases; to hold a test-tube with genetic material that I edited with CRISPR-Cas9; to roam around a laboratory and peek at each bench‚Äôs weird collection of tools and equipment and liquids, slide my feet across the polished laboratory floor, smell the lingering scent of disinfectant; to go on more dives and hikes and explore the breathtaking diversity of life. It‚Äôs not quite a calling, more like hearing a faint ringtone in a distant room. You‚Äôre not sure if your phone‚Äôs ringing or your mind‚Äôs making the sound up. Maybe this time it‚Äôs worth taking a look.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ClickHouse gets lazier (and faster): Introducing lazy materialization (189 pts)]]></title>
            <link>https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</link>
            <guid>43763688</guid>
            <pubDate>Tue, 22 Apr 2025 16:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</a>, See on <a href="https://news.ycombinator.com/item?id=43763688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine if you could skip packing your bags for a trip because you find out at the airport you‚Äôre not going. That‚Äôs what ClickHouse is doing with data now.</p>
<p>ClickHouse is one of the fastest analytical databases available, and much of that speed comes from avoiding unnecessary work. The less data it scans and processes, the faster queries run. Now it pushes this idea even further with a new optimization: lazy materialization, which delays reading column data until it‚Äôs actually needed.</p>
<p>This seemingly "lazy" behavior turns out to be extremely effective in real-world workloads, especially for <code>Top N</code> queries that sort large datasets and apply <code>LIMIT</code> clauses, a common pattern in observability and general analytics. In these scenarios, lazy materialization can dramatically accelerate performance, often by orders of magnitude.</p>
<blockquote>
<p><strong>Spoiler alert</strong>: We‚Äôll show you how a ClickHouse query went from 219 seconds to just 139 milliseconds‚Äî<strong>a 1,576√ó speedup</strong>‚Äîwithout changing a single line of SQL. Same query. Same table. Same machine. The only thing that changed? When ClickHouse reads the data.</p>
</blockquote>
<p>In this post, we‚Äôll walk through how lazy materialization works and how it fits into ClickHouse‚Äôs broader I/O optimization stack. To give a complete picture, we‚Äôll also briefly demonstrate the other key building blocks of I/O efficiency in ClickHouse, highlighting not just what lazy materialization does, but how it differs from and complements the techniques already in place.</p>
<p>We‚Äôll begin by describing the core I/O-saving techniques ClickHouse already uses, then run a real-world query through them, layer by layer, until lazy materialization kicks in and changes everything.</p>

<p>Over the years, ClickHouse has introduced a series of layered optimizations to aggressively reduce I/O. These techniques form the foundation of its speed and efficiency:</p>
<ul>
<li>
<p><strong><a href="https://clickhouse.com/docs/parts">Columnar storage</a></strong> allows skipping entire columns that aren‚Äôt needed for a query and also enables high compression by grouping similar values together, minimizing I/O during data loading.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/primary-indexes">Sparse primary indexes</a></strong>, <strong><a href="https://clickhouse.com/docs/optimize/skipping-indexes">secondary data-skipping indexes</a></strong>, and <strong><a href="https://clickhouse.com/docs/data-modeling/projections">projections</a></strong> prune irrelevant data by identifying which <strong>granules</strong> (row blocks) might match filters on <em>indexed columns</em>. These techniques operate at the granule level and can be used individually or in combination.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a></strong> checks matches also for filters on <em>non-indexed</em> columns to skip data early that would otherwise be loaded and discarded. It can work independently or refine the granules selected by indexes, complementing granule pruning by skipping rows that don‚Äôt match <em>all</em> column filters.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/blog/introducing-the-clickhouse-query-condition-cache">The query condition cache (deep dive)</a></strong> speeds up repeated queries by remembering which granules matched all filters last time. ClickHouse can then skip reading and filtering granules that didn‚Äôt match, even if the query shape changes. Since it simply caches the result of index and PREWHERE filtering, we won‚Äôt cover it further here.  <strong>We disabled it in all tests below to avoid skewing results.</strong></p>
</li>
</ul>
<blockquote>
<p>These techniques, including the lazy materialization introduced below, reduce I/O <em>during</em> query processing, which is the focus of this post. An orthogonal approach is to reduce table size (and query work) upfront by precomputing results with <a href="https://clickhouse.com/docs/materialized-view/incremental-materialized-view">incremental</a> or <a href="https://clickhouse.com/docs/materialized-view/refreshable-materialized-view">refreshable</a> <strong>materialized views</strong>, which we won‚Äôt cover here.</p>
</blockquote>

<p>While the aforementioned I/O optimizations can significantly reduce data read, they still assume that all columns for rows passing the <code>WHERE</code> clause must be loaded before running operations like sorting, aggregation, or <code>LIMIT</code>. But what if some columns aren‚Äôt needed until later, or some data, despite passing the <code>WHERE</code> clause, is never needed at all?</p>
<p>That‚Äôs where <strong>lazy materialization</strong> comes in. An orthogonal enhancement that completes the I/O optimization stack:</p>
<ul>
<li>
<p>Indexing, together with PREWHERE, ensures that only rows matching column filters in the <code>WHERE</code> clause are processed.</p>
</li>
<li>
<p>Lazy materialization builds on this by deferring column reads until they‚Äôre actually required by the query execution plan. Even after filtering, only the columns needed for the next operation‚Äîsuch as sorting‚Äîare loaded immediately. Others are postponed and, due to <code>LIMIT</code>, are often read only partially, just enough to produce the final result. This makes lazy materialization especially powerful for <em>Top N</em> queries, where the final result may only require a handful of rows from certain, often large, columns.</p>
</li>
</ul>
<blockquote>
<p>This kind of fine-grained column processing is only possible because ClickHouse stores each column independently. In <a href="https://clickhouse.com/engineering-resources/what-is-columnar-database#row-based-vs-column-based">row-oriented</a> databases, where all columns are read together, this level of deferred I/O simply isn‚Äôt feasible.</p>
</blockquote>
<p>To demonstrate its impact, we‚Äôll now walk through a real-world example and show how each layer of optimization plays a role.</p>

<p>We‚Äôll use the <a href="https://clickhouse.com/docs/getting-started/example-datasets/amazon-reviews">Amazon customer reviews</a> dataset, which has around 150 million product reviews from 1995 to 2015.</p>
<p>
We‚Äôre running ClickHouse 25.4 on an AWS <code>m6i.8xlarge</code> EC2 instance with:<br>
‚Ä¢ 32 vCPUs<br>
‚Ä¢ 128 GiB RAM<br>
‚Ä¢ 1 TiB gp3 SSD (with default settings: 3000 IOPS, 125 MiB/s max throughput üêå)<br>
‚Ä¢ Ubuntu Linux 24.04
</p>
<p>On that machine, we first created the Amazon reviews table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews
</span></span></span><span>(
<span></span></span><span><span>    `review_date` </span><span><span>Date</span><span> CODEC(ZSTD(</span><span>1</span><span>)),
</span></span></span><span><span>    `marketplace` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `customer_id` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_parent` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_title` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_category` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `star_rating` UInt8 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `helpful_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `total_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `vine` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `verified_purchase` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_headline` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_body` String CODEC(ZSTD(</span><span><span>1</span><span>))
</span></span></span><span>)
<span></span></span><span><span>ENGINE </span><span><span>=</span><span> MergeTree
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> (review_date, product_category);</span></span></span></code></pre></div></pre>
<p>And then loaded the dataset from Parquet files hosted in our public example datasets S3 bucket:</p>
<pre><div><pre><code><span><span>INSERT</span><span><span> </span><span>INTO</span><span>  amazon.amazon_reviews
</span></span></span><span><span></span><span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> s3Cluster(</span><span>'default'</span><span>, </span><span>'https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_*.snappy.parquet'</span><span>);</span></span></span></code></pre></div></pre>
<p>We check the table‚Äôs size after loading:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    formatReadableQuantity(</span><span><span>sum</span><span>(</span><span>rows</span><span>)) </span><span>AS</span><span> </span><span>rows</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.parts
</span></span></span><span><span></span><span><span>WHERE</span><span> active </span><span>AND</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>‚îå‚îÄrows‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄdata_size‚îÄ‚î¨‚îÄcompressed_size‚îÄ‚îê
</span><span></span></span><span>‚îÇ 150.96 million ‚îÇ 70.47 GiB ‚îÇ 30.05 GiB       ‚îÇ
<span></span></span><span>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò<span></span></span></code></pre></div></pre>
<p>After loading, the table contains ~150 million rows and:</p>
<ul>
<li>70 GiB uncompressed data</li>
<li>~30 GiB compressed on disk using ZSTD(1)</li>
</ul>

<p>150 million rows is hardly a challenge for ClickHouse. For example, this query sorts all 150 million values in the <code>helpful_votes</code> column (which isn‚Äôt part of the table‚Äôs sort key) and returns the top 3, in just 70 milliseconds cold (with the OS filesystem cache <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cleared</a> beforehand) and a processing throughput of 2.15 billion rows/s:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> helpful_votes
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>‚îå‚îÄhelpful_votes‚îÄ‚îê
</span><span></span></span><span>‚îÇ         47524 ‚îÇ
<span></span></span><span>‚îÇ         41393 ‚îÇ
<span></span></span><span>‚îÇ         41278 ‚îÇ
<span></span></span><span>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
<span></span></span><span>
<span></span></span><span>3 rows in set. Elapsed: 0.070 sec. Processed 150.96 million rows, 603.83 MB (2.15 billion rows/s., 8.61 GB/s.)
<span></span></span><span>Peak memory usage: 3.59 MiB.<span></span></span></code></pre></div></pre>
<p>Note that the query doesn‚Äôt benefit from indexing, PREWHERE, or other I/O reduction techniques, since it has no filters. But thanks to columnar storage, ClickHouse only reads the <code>helpful_votes</code> column and skips the rest.</p>
<p>Here‚Äôs another example query that simply selects (with cold filesystem cache) all data from a single <code>review_body</code> column:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> review_body
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Query id: b9566386-047d-427c-a5ec-e90bee027b02
</span><span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 176.640 sec. Processed 150.96 million rows, 56.02 GB (854.61 thousand rows/s., 317.13 MB/s.)
<span></span></span><span>Peak memory usage: 733.14 MiB.<span></span></span></code></pre></div></pre>
<p>üò± Almost 3 minutes! Despite reading just a single column.</p>
<p>But the bottleneck wasn‚Äôt ClickHouse, it was the disk‚Äôs throughput. This query scanned a much larger column, 56 GB vs. 600 MB in the previous example. On our test machine, which has a <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#test-setup-dataset-and-machine">relatively slow disk</a> and 32 CPU cores, ClickHouse used 32 <a href="https://clickhouse.com/docs/optimize/query-parallelism">parallel streams</a> to read the data. The <a href="https://clickhouse.com/docs/operations/system-tables/query_log">query log</a> confirms that the majority of the 3-minute runtime was spent <a href="https://github.com/ClickHouse/ClickHouse/blob/9d60aa01a83346648eae5dc9572530388271f7b0/src/Common/ProfileEvents.cpp#L101">waiting on the read syscall</a>:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> 
</span></span></span><span><span>  round(ProfileEvents[</span><span><span>'DiskReadElapsedMicroseconds'</span><span>] </span><span>/</span><span> </span><span>1e6</span><span>) </span><span>AS</span><span> disk_read_seconds,
</span></span></span><span><span>  ProfileEvents[</span><span><span>'ConcurrencyControlSlotsAcquired'</span><span>] </span><span>AS</span><span> parallel_streams,
</span></span></span><span><span>  formatReadableTimeDelta(round(disk_read_seconds </span><span><span>/</span><span> parallel_streams), </span><span>'seconds'</span><span>) </span><span>AS</span><span> time_per_stream
</span></span></span><span><span></span><span><span>FROM</span><span> system.query_log
</span></span></span><span><span></span><span><span>WHERE</span><span> query_id </span><span>=</span><span> </span><span>'b9566386-047d-427c-a5ec-e90bee027b02'</span><span> 
</span></span></span><span><span>  </span><span><span>AND</span><span> type </span><span>=</span><span> </span><span>'QueryFinish'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>‚îå‚îÄdisk_read_seconds‚îÄ‚î¨‚îÄparallel_streams‚îÄ‚î¨‚îÄtime_per_stream‚îÄ‚îê
</span><span></span></span><span>‚îÇ              5512 ‚îÇ               32 ‚îÇ 172 seconds     ‚îÇ
<span></span></span><span>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò<span></span></span></code></pre></div></pre>
<p>Clearly, brute-force scans aren‚Äôt ideal, especially with cold caches. Let‚Äôs give ClickHouse something to work with.</p>

<p>Despite the airport <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">drama</a>, I‚Äôm still set on that beach holiday, and that means loading my eReader with only the best. So I ask ClickHouse to help me find the most helpful 5-star verified reviews for digital ebook purchases since 2010, showing the number of helpful votes, book title, review headline, and the review itself:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical;<span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   6376
<span></span></span><span>product_title:   Wheat Belly: Lose the Wheat, Lose the Weight, and Find Your Path Back to Health
<span></span></span><span>review_headline: Overweight? Diabetic? Got High Blood Pressure, Arthritis? Get this Book!
<span></span></span><span>review_body:     I've been following Dr. Davis' heart scan blog for the past ...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   4149
<span></span></span><span>product_title:   The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing
<span></span></span><span>review_headline: Truly life changing
<span></span></span><span>review_body:     I rarely write reviews, but this book truly sparked somethin...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   2623
<span></span></span><span>product_title:   The Fast Metabolism Diet: Eat More Food and Lose More Weight
<span></span></span><span>review_headline: Fantastic Results **UPDATED 1/23/2015**
<span></span></span><span>review_body:     I have been on this program for 7 days so far.  I know it ma...<span></span></span></code></pre></div></pre>
<p>The query above selects four columns, including three (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) of the largest in the table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    name </span><span><span>as</span><span> </span><span>column</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.columns
</span></span></span><span><span></span><span><span>WHERE</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>
</span></span></span><span><span></span><span><span>GROUP</span><span> </span><span>BY</span><span> name
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>sum</span><span>(data_uncompressed_bytes) </span><span>DESC</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>‚îå‚îÄcolumn‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄdata_size‚îÄ‚îÄ‚î¨‚îÄcompressed_size‚îÄ‚îê
</span><span></span></span><span>‚îÇ review_body       ‚îÇ 51.13 GiB  ‚îÇ 21.60 GiB       ‚îÇ
<span></span></span><span>‚îÇ product_title     ‚îÇ 8.12 GiB   ‚îÇ 3.53 GiB        ‚îÇ
<span></span></span><span>‚îÇ review_headline   ‚îÇ 3.38 GiB   ‚îÇ 1.58 GiB        ‚îÇ
<span></span></span><span>‚îÇ review_id         ‚îÇ 2.07 GiB   ‚îÇ 1.35 GiB        ‚îÇ
<span></span></span><span>‚îÇ product_id        ‚îÇ 1.55 GiB   ‚îÇ 720.97 MiB      ‚îÇ
<span></span></span><span>‚îÇ customer_id       ‚îÇ 1.12 GiB   ‚îÇ 524.35 MiB      ‚îÇ
<span></span></span><span>‚îÇ product_parent    ‚îÇ 1.12 GiB   ‚îÇ 571.63 MiB      ‚îÇ
<span></span></span><span>‚îÇ helpful_votes     ‚îÇ 575.86 MiB ‚îÇ 72.11 MiB       ‚îÇ
<span></span></span><span>‚îÇ total_votes       ‚îÇ 575.86 MiB ‚îÇ 83.50 MiB       ‚îÇ
<span></span></span><span>‚îÇ review_date       ‚îÇ 287.93 MiB ‚îÇ 239.43 KiB      ‚îÇ
<span></span></span><span>‚îÇ marketplace       ‚îÇ 144.51 MiB ‚îÇ 414.92 KiB      ‚îÇ
<span></span></span><span>‚îÇ product_category  ‚îÇ 144.25 MiB ‚îÇ 838.96 KiB      ‚îÇ
<span></span></span><span>‚îÇ star_rating       ‚îÇ 143.96 MiB ‚îÇ 41.99 MiB       ‚îÇ
<span></span></span><span>‚îÇ verified_purchase ‚îÇ 143.96 MiB ‚îÇ 20.50 MiB       ‚îÇ
<span></span></span><span>‚îÇ vine              ‚îÇ 1.75 MiB   ‚îÇ 844.89 KiB      ‚îÇ
<span></span></span><span>‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò<span></span></span></code></pre></div></pre>
<p>The example query touches 60+ GiB of (uncompressed) data. As we showed earlier, even with 32 parallel streams, just reading that from the (relatively slow) disk would take 3+ minutes with a cold cache.</p>
<p>But the query includes filters on multiple columns (<code>review_date</code>, <code>product_category</code>, <code>verified_purchase</code>, and <code>star_rating</code>), plus a <code>LIMIT</code> applied after sorting by <code>helpful_votes</code>. This is the perfect setup for ClickHouse‚Äôs layered I/O optimizations:</p>
<ul>
<li>
<p><strong>Indexing</strong> prunes rows that don‚Äôt match filters on the primary/sorting key (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p><strong>PREWHERE</strong> pushes filtering deeper and prunes rows that don‚Äôt match <em>all</em> column filters.</p>
</li>
<li>
<p><strong>Lazy materialization</strong> delays loading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until they‚Äôre actually needed‚Äîafter sorting and applying <code>LIMIT</code>. Ideally, most of that large column data is never read at all.</p>
</li>
</ul>
<p>Each layer cuts down I/O further. Together, they reduce data read, memory use, and query time. Let‚Äôs see how much of a difference that makes, one layer at a time.</p>

<p>In the following sections, we clear the OS-level filesystem (page) cache before each query run using</p>
<p><code>echo 3 | sudo tee /proc/sys/vm/drop_caches &gt;/dev/null</code>.</p>
<p>on the Linux command line. This simulates the worst-case scenario and ensures the results reflect actual disk reads, not cached data.</p>
<!-- -->

<p>Before we bring in the optimizations, let‚Äôs see what happens when ClickHouse runs the query without any shortcuts‚Äîno indexing, no PREWHERE, no lazy materialization.</p>
<p>To do this, we run the example query on a version of the table without a sorting/primary key, meaning it won‚Äôt benefit from any index-based optimizations. The following command creates that baseline table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span>Engine </span><span><span>=</span><span> MergeTree 
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> ()
</span></span></span><span><span></span><span><span>AS</span><span> </span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> amazon.amazon_reviews;</span></span></span></code></pre></div></pre>
<p>Now we run the example query, with both PREWHERE and lazy materialization disabled, on the baseline table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>3 rows in set. Elapsed: 219.508 sec. Processed 150.96 million rows, 72.13 GB (687.71 thousand rows/s., 328.60 MB/s.)
</span><span></span></span><span>Peak memory usage: 953.25 MiB.<span></span></span></code></pre></div></pre>
<p>The ‚ë† query streamed all 150 million rows‚Äîorganized into <a href="https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#data-is-organized-into-granules-for-parallel-data-processing">granules</a> (the smallest processing units in ClickHouse, each covering 8,192 rows by default)‚Äîof ‚ë° the 8 required columns from disk to ‚ë¢ memory, processing 72 GB of data in 220 seconds and peaking at 953 MiB of memory usage:</p>

<blockquote>
<p>ClickHouse processes table data in a <a href="https://clickhouse.com/docs/optimize/query-parallelism">streaming fashion</a>, reading and operating on blocks of granules incrementally instead of loading all data into memory at once. That‚Äôs why, even for the query above which processed 72 GB of data, peak memory usage stayed under 1 GiB.</p>
</blockquote>
<p>With the baseline set, let‚Äôs see how the first layer of optimization improves things.</p>

<p>Obviously, scanning the entire dataset is far from optimal. Let‚Äôs start applying ClickHouse‚Äôs optimizations, beginning with the primary index. We run the example query, still with both PREWHERE and lazy materialization disabled, on the original table, which uses <code>(review_date, product_category)</code> as its compound sorting (primary) key:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>   optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>   query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 95.865 sec. Processed 53.01 million rows, 27.67 GB (552.98 thousand rows/s., 288.68 MB/s.)
</span><span></span></span><span>Peak memory usage: 629.00 MiB.<span></span></span></code></pre></div></pre>
<p>Because the query includes ‚ë† filters on the table‚Äôs compound sorting (primary) key, ClickHouse ‚ë° loads and evaluates the <a href="https://clickhouse.com/docs/primary-indexes">sparse primary index</a> to ‚ë¢ select only granules within the primary key columns that might contain matching rows. These potentially relevant granules are then ‚ë£ streamed into memory, along with positionally aligned granules from any other columns needed for the query. The remaining filters are applied after this step:</p>

<p>As a result, only 53 million rows from the eight required columns are streamed from disk to memory, processing 28 GB instead of 72 GB of data, and cutting runtime by more than half: 96 seconds vs. 220 seconds.</p>
<blockquote>
<p>The primary index prunes granules based on filters on the primary key columns.</p>
</blockquote>
<p>However, ClickHouse still loads all other column granules that are positionally aligned with the matching key column granules, even if filters on non-key columns exclude them later. That means unnecessary data is still being read and processed.</p>
<p>To fix that, we now enable PREWHERE.</p>

<p>We run the same query again, this time with <a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a> enabled (but still without lazy materialization). PREWHERE adds an additional layer of efficiency filtering out irrelevant data before reading non-filter columns from disk:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 61.148 sec. Processed 53.01 million rows, 16.28 GB (866.94 thousand rows/s., 266.24 MB/s.)
</span><span></span></span><span>Peak memory usage: 583.30 MiB.<span></span></span></code></pre></div></pre>
<p>With PREWHERE enabled, the query processed the same 53 million rows but read significantly less column data, 16.28 GB vs. 27.67 GB, and completed 36% faster (61 seconds vs. 96 seconds), while also slightly reducing peak memory usage.</p>
<p>To understand this improvement, let‚Äôs briefly walk through how PREWHERE changes the way ClickHouse processes the query.</p>
<p>Instead of streaming all selected column granules up front, ClickHouse begins PREWHERE processing by ‚ë† loading only the primary key column granules identified by the index analysis to check which ones actually contain matches. In this case, all selected granules do match, so ‚ë° the positionally aligned granules for the next filter column‚Äî<code>verified_purchase</code>‚Äîare selected to be loaded for further filtering:</p>

<p>Next, ClickHouse ‚ë† reads the selected <code>verified_purchase</code> column granules to evaluate the filter <code>verified_purchase</code> (which is a shortcut for <code>verified_purchase == True</code> ).</p>
<p>In this case, three out of four granules contain matching rows, so only ‚ë° their positionally aligned granules from the next filter column‚Äî<code>star_rating</code>‚Äîare selected for further processing:</p>

<p>Finally, ClickHouse reads the three selected granules from the <code>star_rating</code> column to evaluate the last filter <code>star_rating &gt; 4</code>.</p>
<p>Two of the three granules contain matching rows, so just the positionally aligned granules from the remaining columns‚Äî<code>helpful_votes</code>, <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code>‚Äîare selected to be loaded for further processing:</p>

<p>With that, PREWHERE processing is complete.</p>
<blockquote>
<p>Instead of loading all column granules selected by the primary index up front and then applying the remaining filters, PREWHERE pre-filters the selected data early‚Äîhence the name. ClickHouse evaluates filters one column at a time, using a <a href="https://clickhouse.com/docs/optimize/prewhere#prewhere-optimization-is-automatically-applied">cost-based approach</a>‚Äîtypically starting with the cheapest column to read‚Äîand loads data only for rows that pass each step. This progressively narrows the dataset, reducing I/O before the query runs the main operations like sorting, aggregation, <code>LIMIT</code>, and <code>SELECT</code>.</p>
</blockquote>
<p>Note that PREWHERE can also work independently of indexing. If a query has only filters on non-indexed columns, it still helps reduce I/O by skipping non-matching rows early.</p>

<p>After PREWHERE filtering, ClickHouse proceeds to ‚ë† load the selected data, ‚ë° sort it, and ‚ë¢ apply the LIMIT clause:</p>

<p>Each layer we‚Äôve added so far has chipped away at the query time, skipping unnecessary data, reducing I/O, and streamlining the work.</p>
<p>From a full scan that took 220 seconds, we‚Äôre already down to 61 seconds. But we‚Äôre not done yet. One last layer brings the biggest reduction yet.</p>

<p>Let‚Äôs see what happens when lazy materialization joins the stack. We run the query one last time, with all I/O optimizations enabled, including lazy materialization.</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 0.181 sec. Processed 53.01 million rows, 807.55 MB (292.95 million rows/s., 4.46 GB/s.)
</span><span></span></span><span>Peak memory usage: 3.88 MiB.<span></span></span></code></pre></div></pre>
<p>üòÆ From 61 seconds to 181 milliseconds, a 338√ó speedup.</p>
<p>ClickHouse processed the same 53 million rows but read 20√ó less column data, used 150√ó less memory, and finished before you could blink.</p>
<p>Let‚Äôs look under the hood to see how that happened.</p>
<p>The explanation is simple:</p>
<p>After PREWHERE filtering, ClickHouse doesn‚Äôt load all remaining columns <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#steps-after-prewhere-filtering">right away</a>.</p>
<p>Instead, it loads only what‚Äôs needed next. Since the next step is sorting by <code>helpful_votes</code> and applying the LIMIT, ClickHouse ‚ë† loads just the selected (and PREWHERE-filtered) <code>helpful_votes</code> granules, ‚ë° sorts their rows, ‚ë¢ applies the LIMIT, and only then ‚ë£ loads the corresponding rows from the <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#a-more-realistic-querywhere-optimizations-matter">large</a> <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code> columns:</p>

<p>And just like that, the final layer clicks into place, bringing execution time down from 220 seconds to just 181 milliseconds. Same query. Same table. Same machine. Same slow disk‚Ä¶just <strong>1,215√ó faster</strong>. All we changed was how and when data is read.</p>
<blockquote>
<p>In this example, lazy materialization delivers the biggest gain because the query selects large text columns, and thanks to lazy materialization, only 3 rows from them are needed in the end. But depending on the dataset and query shape, earlier optimizations like indexing or PREWHERE may yield greater savings. These techniques work together, each contributes to reducing I/O in a different way.</p>
</blockquote>
<p>Note: Lazy materialization is applied automatically for <code>LIMIT N</code> queries, but only up to a <code>N</code> threshold. This is controlled by the <a href="https://clickhouse.com/docs/operations/settings/settings#query_plan_max_limit_for_lazy_materialization">query_plan_max_limit_for_lazy_materialization</a> setting (default: 10). If set to 0, lazy materialization applies to all LIMIT values with no upper bound.</p>

<p>To benefit from indexing and PREWHERE, a query needs filters, on primary key columns for indexing, and on any columns for PREWHERE. As shown above, lazy materialization layers cleanly on top, but unlike the others, it can also speed up queries with no column filters at all.</p>
<p>To demonstrate this, we remove all filters from our example query to find the reviews with the highest number of helpful votes, regardless of date, product, rating, or verification status, returning the top 3 along with their title, headline, and full text.</p>
<p>We first run that query (with <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cold filesystem caches</a>) with lazy materialization disabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 219.071 sec. Processed 150.96 million rows, 71.38 GB (689.08 thousand rows/s., 325.81 MB/s.)
<span></span></span><span>Peak memory usage: 1.11 GiB.<span></span></span></code></pre></div></pre>
<p>Now we rerun the query (again with a cold filesystem cache), but this time with lazy materialization enabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 0.139 sec. Processed 150.96 million rows, 1.81 GB (1.09 billion rows/s., 13.06 GB/s.)
<span></span></span><span>Peak memory usage: 3.80 MiB.<span></span></span></code></pre></div></pre>
<p>Boom: a <strong>1,576√ó speedup</strong>‚Äîfrom 219 seconds to just 139 milliseconds‚Äîwith 40√ó less data read and 300√ó lower memory usage.</p>
<p>This example highlights what makes lazy materialization unique among ClickHouse‚Äôs I/O optimizations.</p>
<blockquote>
<p>Lazy materialization doesn‚Äôt need column filters to deliver speedups. While indexing and PREWHERE rely on query predicates to skip data, lazy materialization improves performance purely by deferring work, loading only what‚Äôs needed, when it‚Äôs needed.</p>
</blockquote>

<p>We can observe the lazy materialization for the previous query by inspecting the query‚Äôs logical execution plan using the <a href="https://clickhouse.com/docs/sql-reference/statements/explain#explain-plan">EXPLAIN</a> clause:</p>
<pre><div><pre><code><span><span>EXPLAIN actions </span><span><span>=</span><span> </span><span>1</span><span>
</span></span></span><span><span></span><span><span>SELECT</span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>...
</span><span></span></span><span>Lazily read columns: review_headline, review_body, product_title 
<span></span></span><span>  Limit                    
<span></span></span><span>    Sorting                             
<span></span></span><span>      ReadFromMergeTree<span></span></span></code></pre></div></pre>
<p>We can read the operator plan from bottom to top and observe that ClickHouse defers reading the three large String columns until after sorting and limiting.</p>

<p>This journey began with a full-table scan: 220 seconds, 72 GB read, and 1 GiB memory used. Through ClickHouse‚Äôs layered I/O optimizations, we chipped away at runtime, one technique at a time:</p>
<ul>
<li>
<p>‚ë† The <strong>primary index</strong> pruned granules that didn‚Äôt match filters on indexed columns (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p>‚ë°  <strong>PREWHERE</strong> filtered out granules early that passed the index but failed filters on non-indexed columns (<code>verified_purchase</code>, <code>star_rating</code>), reducing unnecessary reads.</p>
</li>
<li>
<p>‚ë¢  <strong>Lazy materialization</strong> deferred reading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until after sorting by <code>helpful_votes</code> and applying <code>LIMIT</code>.</p>
</li>
</ul>

<p>Each layer helped, but for our dataset and query shape lazy materialization changed the game.</p>
<p>The result?</p>
<ul>
<li>From 220s ‚Üí 0.18s = <strong>over 1,200√ó speedup</strong> on the filtered query</li>
<li>From 219s ‚Üí 0.139s = <strong>over 1,500√ó speedup</strong> on a full-table Top N query</li>
</ul>
<p><strong>Same table. Same machine. Same SQL code.</strong> The only thing we changed? How and <em>when</em> ClickHouse reads the data.</p>
<p>Lazy materialization doesn‚Äôt just make ClickHouse faster, it completes the I/O optimization stack.
And the laziest part? It (and PREWHERE) are on by default. You get the speed without lifting a finger.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Algebraic Semantics for Machine Knitting (159 pts)]]></title>
            <link>https://uwplse.org/2025/03/31/Algebraic-Knitting.html</link>
            <guid>43763614</guid>
            <pubDate>Tue, 22 Apr 2025 15:55:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uwplse.org/2025/03/31/Algebraic-Knitting.html">https://uwplse.org/2025/03/31/Algebraic-Knitting.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As programming languages researchers, we‚Äôre entitled to a certain level of mathematical
rigor behind the languages we write and analyze. Programming languages have <em>semantics</em>, which are
definitions of what statements in the language mean. We can use those semantics to do all
sorts of useful things, like error checking, compiling for efficiency, code transformation,
and so on.</p>

<p>This blog post is about a programming domain that doesn‚Äôt yet enjoy the same level of rigor
in its semantics: machine knitting. People write programs to control massive arrays of needles
that manipulate yarn into useful 3D objects. In this blog post, I‚Äôll run through the process
of finding ‚Äúthe right‚Äù semantics for machine knitting, touching on why we want semantics, connections
to traditional programming languages, and what we might use these semantics for in the future.
In our search, there are a surprising number of guest appearances by fields of study outside of programming languages:
algebraic topology, group theory, knot theory, category theory, and even quantum computing!</p>

<p>I‚Äôll motivate semantics with a toy problem: can two given statements commute with each other?
Here‚Äôs an example where they can:</p>

<p>By ‚Äúcommute‚Äù, I mean that if I swapped the order of the lines, the program would do the same
thing. The commuting problem is important: a compiler might move around the order of instructions
to optimize memory usage by batching related instructions together, an analyzer might want
to see if two programs are equivalent, and we might also want to know whether we can run two instructions
in parallel. In the above example, we know that the statements commute because of the implied <em>semantics</em>
of the statements ‚Äì they don‚Äôt have anything in common, so they shouldn‚Äôt affect each other!</p>

<p>Here are some more examples. These statements don‚Äôt commute because there‚Äôs a data dependency:</p>

<p>If we swapped those two statements, the statement assigning <code>x</code>‚Äôs value would use a potentially different
value for <code>y</code>.</p>

<p>Non-commuting statements might happen for reasons other than direct data dependencies. Imagine
we‚Äôre in C ‚Äì do these function calls commute?</p>
<div><pre><code><span>x</span> <span>=</span> <span>f</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
<span>y</span> <span>=</span> <span>f</span><span>(</span><span>c</span><span>,</span> <span>d</span><span>);</span>
</code></pre></div>
<p>We can‚Äôt be sure that they do ‚Äì perhaps the <code>f</code> function mutates some counter variable
every time it‚Äôs called.</p>

<p>Apart from explicit mutable state, there‚Äôs one more C-like thing that commonly prevents commuting:</p>
<div><pre><code><span>*</span><span>x</span> <span>=</span> <span>*</span><span>x</span> <span>+</span> <span>3</span><span>;</span>
<span>*</span><span>y</span> <span>=</span> <span>*</span><span>y</span> <span>*</span> <span>2</span><span>;</span>
</code></pre></div>
<p>If the <code>x</code> and <code>y</code> pointers are the same, these statements don‚Äôt commute.</p>

<p>It‚Äôs notable that in a <em>pure</em> language, there‚Äôs no hidden mutable state or pointer
aliasing. Haskell is a popular language that‚Äôs very close to being pure ‚Äì since
it supports IO operations like printing to the console and reading/writing files, it‚Äôs
not pure. In Haskell, these functions <em>do</em> commute, as long as there‚Äôs no IO monad malarkey:</p>


<p>The reason that Haskell‚Äôs commuting result is different than C is that its semantics are different ‚Äì any time we want to
prove a property of a language‚Äôs behavior, we‚Äôll have to turn to that language‚Äôs semantics. We know that proving properties
of machine knitting programs could be a powerful tool: <a href="https://doi.org/10.1145/3654777.3676405">a 2024 paper</a> showed massive
speedups using an optimizing compiler, using only a few program transformations that are <em>intuitively</em> correct. To scale that
result and prove the compiler‚Äôs accuracy, we‚Äôll need to develop semantics for machine knitting.</p>

<h2 id="machine-knitting-background">Machine knitting background</h2>

<p>This introduction is only for the details of machine knitting that are relevant
to this blog post. Unfortunately, the mechanisms behind a machine that automatically
creates useful objects from spools of yarn are pretty complicated! If you‚Äôd like to read
more about machine knitting, <a href="https://doi.org/10.1145/3592449">this paper</a> has a good
introduction.</p>

<p>Knitting machines have an array of hundreds of needles, called a bed. This is analogous
to the memory of a traditional computer ‚Äì registers hold values, and needles hold loops
of yarn. There are also <em>carrier strands</em> that move throughout the machine, winding through,
around, and past the loops of needles to create <em>stitches</em>, which I‚Äôll later compare to basic operations
in traditional programming languages. Here‚Äôs how a basic stitch is formed in knitting:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_pre.svg" alt="A cyan carrier strand to the left of a loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_no_box.svg" alt="The carrier strand has been pulled through the loop, creating a new cyan loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_post.svg" alt="A box has been drawn around part of the previous image; the stitch takes a cyan carrier strand and gold loop
  in and returns a cyan loop and a cyan carrier strand">
</p>

<p>A carrier strand (in cyan) is pulled through a loop (in gold) to create a new loop.
Note how the bottom gold loop is held in place as long as the top cyan loop and carrier strand
are held up. After the stitch, the knitting machine drops the bottom loop, but the bottom
loop stays connected and stable. This is like a value falling out of scope, but since some in-scope
value points to it, it‚Äôs not garbage-collected (gravity is the garbage collector of machine knitting!).</p>

<p>There are many variants of stitches, but they all follow the same
input-output pattern: loops and carrier strands in, loops and carrier strands 
out. In that way, they‚Äôre kind of like basic operations we‚Äôre used to in computer science,
like addition or bitwise AND: values in, values out. The third image above draws a box around the
stitch to show its inputs and outputs: carrier strand and loop in, loop and carrier strand out.</p>

<p>There‚Äôs one more technicality in machine knitting: in order to do a stitch
involving some values, those values must be all adjacent to each other.
In the example below, we can‚Äôt immediately knit the cyan carrier on the far left with
the gold loop on the far right ‚Äì instead, 
we have to move
the values next to each other before creating a stitch.</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_pre.svg" alt="A cyan carrier strand, red loop, and gold loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_post.svg" alt="The cyan carrier strand crosses over the red loop, and makes a stitch with the gold loop">
</p>

<p>This is also true for traditional computing ‚Äì to compute the
boolean AND of two bits, we need to connect those two bits to an AND gate,
getting them right next to each other. Computer architects use complicated
routing mechanisms like multiplexers to do this; when we code in traditional
programming languages, we don‚Äôt have to worry about those constraints
because the computer architects have generously handled it for us.</p>

<p>The languages used for machine knitting don‚Äôt include many of the traditional
programming language features that make code hard to analyze: no <code>if</code>
statements (branching) or <code>for</code> loops, and no functions. Machine
knitting code is just a series of operations that perform stitches and
move carrier strands and loops around. This should make analyzing machine knitting
easier: there‚Äôs far less complexity than traditional programming languages.
In fact, for our specific question of whether two operations commute, the
problem seems almost trivial: similar to pure functional programming
languages, there‚Äôs no global state or aliasing in
machine knitting. However, there‚Äôs something tricky hiding in
machine knitting that isn‚Äôt a worry in traditional computing contexts:
since knitting is done in 3 dimensions, when strands cross, one goes over and
the other goes under. This can cause operations to snag on each other, even if
no strand directly connects them. I‚Äôll illustrate this with some diagrams.</p>

<h2 id="diagrams">Diagrams</h2>

<p>Let‚Äôs start by carefully analyzing something core to traditional computing:
combinatorial boolean circuits. Here‚Äôs a simple example <code>myfunc</code> that maps
3 bits to 3 bits.</p>
<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span> <span>// split the wire in two</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>It‚Äôs usually easier to reason about circuits when they‚Äôre drawn (forgive my very strange choices when drawing
the diagram; all will be clear once we get to knitting):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_pre.svg" alt="Circuit diagram for the above code">
</p>

<p>I pose the same question: can the
<code>dup</code> and <code>and</code> operations commute? Here, the answer is a definite yes:
global state and aliasing aren‚Äôt present, and there‚Äôs no data dependency.
Here is the same function with the operations commuted:</p>

<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_post.svg" alt="Circuit diagram for the above code">
</p>

<p>Deciding whether two operations commute in a combinatorial circuit is easy
‚Äì they can commute if and only if there‚Äôs no directed path connecting them,
just like how two functions can commute in Haskell as long as there‚Äôs no data
dependency between them and no IO trickery.</p>

<h3 id="knitting-diagrams">Knitting diagrams</h3>

<p>Now, let‚Äôs try something similar for knitting. For simplicity, we‚Äôll work in a
made-up machine knitting language that hides some of the technicalities
that aren‚Äôt important for this post. Our knitting function takes three strands as input,
does two stitches, and returns three new strands. I‚Äôve taken the liberty to
simplify the diagrams by not drawing
the ‚Äúinternals‚Äù of the stitches (now they‚Äôre just boxes)
and I‚Äôm drawing both loops and carrier strands as single strands.</p>
<div><pre><code><span>fn</span> <span>myknit</span><span>(</span><span>s1</span><span>,</span> <span>s2</span><span>,</span> <span>s3</span><span>)</span> <span>{</span>
    <span>t1</span><span>,</span> <span>t2</span> <span>=</span> <span>stitch1</span><span>(</span><span>s2</span><span>);</span>
    <span>cross</span> <span>t1</span> <span>over</span> <span>s1</span><span>;</span>
    <span>cross</span> <span>s3</span> <span>over</span> <span>t2</span><span>;</span>
    <span>cross</span> <span>s1</span> <span>over</span> <span>s3</span><span>;</span>
    <span>t3</span> <span>=</span> <span>stitch2</span><span>(</span><span>s3</span><span>,</span> <span>s1</span><span>);</span>
    <span>cross</span> <span>t2</span> <span>over</span> <span>t3</span><span>;</span>

    <span>return</span> <span>t1</span><span>,</span> <span>t2</span><span>,</span> <span>t3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_knit.svg" alt="Diagram for the above knitting code. The stitch1 and stitch2 boxes aren't directly connected by a
  strand, but due to the way the strands have crossed, there is no way to move stitch2 below stitch1">
</p>

<p>Well, the diagram looks almost the same as the circuit diagram, but now every time two
strands cross, we have to specify which one goes on top of the other. This is extra noticeable
in the code: all crossings between strands are listed and annotated. We‚Äôre careful to record and
display these over/under crossings in machine knitting because they‚Äôre a feature of working in
a physical medium: the way strands cross affects how a knitted object looks and feels, and it can
drastically change the shape of the final object!</p>

<p>These over/under crossings are what make the commuting problem difficult for machine knitting.
In the above example, there‚Äôs no data dependency (i.e., no connecting strand) between the two
operations. However, because of how their strands are crossing, the operations ‚Äúsnag‚Äù on each other
so they can‚Äôt commute. It‚Äôs perhaps easy for humans to look at the above diagram and decide whether
two operations snag on each other, but how can we author an accurate algorithm to
apply automated analysis to these affairs? We need some way of formalizing these ideas so a computer
can reason about them‚Ä¶ ah yes, those semantics we mentioned earlier.</p>

<p>Now is a good time to mention that there actually ARE semantics for machine knitting:
<a href="https://doi.org/10.1145/3592449">a 2023 paper</a> set up rigorous mathematical semantics for all of machine
knitting. However, these semantics are defined in <em>tangles</em> from knot theory. This is a natural way to
define knitted objects ‚Äì they really are a tangle of strands in 3D space! However, the equivalences of
knot theory are defined by continuous deformations ‚Äì two knots are equivalent whenever we can stretch, move,
expand, and contract one knot into the other without tearing strands. Since the goal is to write computer
programs that analyze machine knitting, the proposed semantics aren‚Äôt directly useful to computers. Computers don‚Äôt have
any notion of what a ‚Äúcontinuous deformation‚Äù is, and they‚Äôre particularly bad at doing anything involving
continuous quantities. The semantics are useful for humans to do basic hand-written proofs and are a great
starting point, but we‚Äôd like to extend them so we can use computers to perform automatic analysis.</p>

<h3 id="aside-quantum-computing">Aside: quantum computing</h3>

<p>It should be noted that if we actually constructed the combinatorial circuit from earlier by
plugging wires into tangible logic gates, we would also have to make some decision for each
crossing as to which wire goes on top. However, this is simply not a concern for computer scientists:
it doesn‚Äôt matter which wire goes on top, because electrons don‚Äôt care whether they go above or below
other electrons ‚Äì it doesn‚Äôt change the resulting computation.</p>

<p>Models in quantum physics allow for particles that <em>do</em> remember how they pass over
and under each other. This could have big effects in quantum computing, where a so-called topological
quantum computer using these particles could be far more resistant to decoherence than
conventional quantum computing. A team at Microsoft has
<a href="https://doi.org/10.1038/s41586-024-08445-2">recently published some experimental results in topological quantum computing</a>
using a setup to braid quasiparticles together in 2+1 dimensions
of space and time respectively. The methods, setup, and goals are certainly different than machine
knitting, but it‚Äôs quite satisfying to see the two seemingly unrelated topics of machine knitting and
quantum computing bound by similar mathematical ideas.</p>

<h2 id="algebraicizing-our-topology">Algebraicizing our topology</h2>

<p>As I hinted earlier, we‚Äôd like to formalize the previous diagrams so we can study their properties, using
something more computer-friendly than knot theory. Really, this is an exercise in algebraic topology ‚Äì
representing a topology (like our deformations of 3D space) with algebra, which is a lot easier to work
with. The <em>braid group</em> is a great starter example of how mathematicians represent a topological object
with algebra.</p>

<h3 id="the-braid-group">The braid group</h3>

<p>For folks familiar with group theory, the braid group on \(n\) strands is</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2,\) and it represents the equivalence classes of \(n\) strands under ambient isotopy.
For the folks confused by this deluge of notation, read on!</p>

<p>A group is a set of elements \(G = \{x_1, x_2, \ldots \}\) with</p>

<ol>
  <li>Some way to <em>combine</em> or <em>compose</em> elements together, which I‚Äôll represent
using a semicolon. For any \(x, y \in G,\) we have \(x ; y \in G.\)</li>
  <li>Some identity element that represents ‚Äúnothing‚Äù. We‚Äôll call that element
\(\text{id}\in G,\) and it has the property \(\text{id} ; x = x = x ; \text{id}.\)</li>
  <li>Some way to <em>invert</em> elements: for any \(x \in G,\) there‚Äôs some \(x^{-1} \in G\)
where \(x;x^{-1} = \text{id} = x^{-1} ; x.\)</li>
</ol>

<p>One group we‚Äôre all familiar with is the integers under addition: the composition of integers is
addition, the identity is \(0,\) and inverting is negation.</p>

<p>For any natural number \(n\) (let‚Äôs say \(n=5\)), the <em>braid group on \(n\) strands</em> is one of
these groups. There are infinite elements in that group, and every element is 5 strands,
oriented bottom-to-top, passing over/under each other. It‚Äôs good to think of braids as
nailed or glued down at either end, and two braids are <em>equivalent</em> whenever one can be transformed
into the other by shifting around strands, keeping the nailed-down ends fixed.
Here are two examples of braids on 5 strands; I‚Äôll call the left one \(x\) and the right one \(y\):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-2.svg" alt="Braid y = sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>Next, we‚Äôll define what composition, the identity, and inverses are:</p>

<p>Composition is vertical concatenation, read bottom to top. So \(x ; y\) is \(x\) pasted
below \(y,\) with the strands connected in order:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>The identity in the braid group is just \(n\) strands going straight:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/ident-5.svg" alt="5 vertical strands, none of them crossing">
</p>

<p>With the definition of composition being vertical concatenation, hopefully we can agree that
pasting on the identity at either end doesn‚Äôt really change anything, so that braid is indeed the identity.
Finally, inverses are mirror images about the horizontal line through the middle of the braid ‚Äì below is \(x\) on the left and
\(x^{-1}\) on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv.svg" alt="Braid x^{-1} = sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>When we compose \(x ; x^{-1},\) we get a braid that untangles to be the identity:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>This is all well and good, but we need some way to write braids down so computers can use them.
We‚Äôll do this by listing their crossings in order, from bottom to top. We‚Äôll use \(\sigma_i\) to
refer to the \(i\)th strand from the left crossing over the \((i+1)\)th strand, and \(\sigma_i^{-1}\)
for under. Then we can write the braid \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_1 ; \sigma_3^{-1}.\)</p>

<p>There‚Äôs one more complication: there‚Äôs more than one way to write down braids. For example, we could
write \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_3^{-1} ; \sigma_1\) instead ‚Äì here‚Äôs the original \(x\)
diagram on the left and the new one on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-syn.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_3^{-1} ; sigma_1 in B_5">
</p>

<p>This diagram of \(x\) and the original are equivalent ‚Äì by shifting the crossings up/down, we transform
one into the other. So the braid group has extra relations to account for this:
\(\sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}\) and \(\sigma_i ; \sigma_j = \sigma_j ; \sigma_i.\)
Here are those relations drawn out, with the left and right sides being equal in each row:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-1.svg" alt="A red strand passes over a cyan and green strand, then the cyan passes over the green">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-2.svg" alt="Cyan passes over green, then red passes over green and cyan">
</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-1.svg" alt="Red over cyan, then green over purple">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-2.svg" alt="Green over purple, then red over cyan">
</p>

<p>Physics note: the first equation is called the <a href="https://en.wikipedia.org/wiki/Yang%E2%80%93Baxter_equation">Yang-Baxter equation</a>, and
it appears in many more places than just the braid group!</p>

<p>It should be noted that the relation \(\sigma_i ; \sigma_i^{-1} = \text{id}\) is implicit in all groups:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-1.svg" alt="A red strand passes over a cyan strand, then over the cyan strand from the other side">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-2.svg" alt="The red and cyan strands don't cross">
</p>

<p>Now, we should all be on the same page for the braid group: the notation</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2\)
tells us how to write braids down (with \(\sigma_1, \ldots, \sigma_{n-1}\)) and which words mean the same thing.</p>

<p>The braid group is well-studied and comes with some powerful algorithms. The presentation is canonicalizable in polynomial time,
meaning there are algorithms that we can run to efficiently tell whether two braids written down using \(\sigma_i\) are
equivalent. This is a great sign for our goal of computable semantics for machine knitting ‚Äì mathematicians have taken a topological object
with a lot of the structure we want in machine knitting, boiled it down to something computer-friendly, and even authored
some useful algorithms! However, the braid group can only represent the pieces of machine knitting programs without stitches.
Stitches operate like functions on strands, with input and output strands. The count of inputs can be different
than the count of outputs, changing the count of strands as we perform the stitch. The braid group is limited to some fixed \(n\) strands, so it can‚Äôt represent
stitches. To get the complete picture of machine knitting, we‚Äôll need to generalize our mathematical assumptions to include the boxes
that represent stitches.</p>

<h3 id="monoidal-categories-and-their-diagrams">Monoidal categories and their diagrams</h3>

<p>In programming languages research, category theory is best known for research in type theory.
I‚Äôve spent all my math allowance for this blog post explaining the braid group so I won‚Äôt get into the nitty-gritty
of what categories are ‚Äì in short, it‚Äôs an algebraic object, like a group, but more general: composition
doesn‚Äôt always have to be defined, and inverses don‚Äôt always have to exist.</p>

<p>Of particular note are the ideas of <a href="https://ncatlab.org/nlab/show/internal+logic">internal logics</a> and internal languages
of categories: correspondences between a category, some logic, and some theoretical programming language model. The
<a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard correspondence</a> describes the connection
between logic and programming languages, and these ideas add category theory to the party.</p>

<p>One such correspondence lies between <em>linear logic</em>, where values can only be used and must be used once, and
<em>symmetric monoidal categories</em>. All categories have composition, which I‚Äôm interpreting as vertical concatenation like in the braid
group; monoidal categories additionally have horizontal concatenation (like multiple values in scope, running two circuits in sequence,
or an array of needles holding loops). Symmetric monoidal categories
can be drawn as boxes connected by strands where the over/under-ness of
strand crossings isn‚Äôt recorded or drawn: exactly the diagrams we draw for combinatorial circuits! The symmetric
monoidal category gives notation and axioms for us to rigorously study those circuits, just like the braid group
gives notation and axioms for studying braids. <em>Symmetric</em> monoidal category is a great name because it‚Äôs closely
related to the symmetric group.</p>

<p>Following the same idea, <em>braided monoidal categories</em> generalize symmetric monoidal categories by recording
over/under crossings, and we draw our diagrams as such ‚Äì just like our diagram for machine knitting!
Back in 1991 when braided monoidal categories were still young,
<a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street</a> showed that the axioms of braided monoidal categories
correspond with the topology of the diagrams we use for them. Since our diagrams really do represent physical topological
objects, this means that braided monoidal categories are perfect for machine knitting!</p>

<h2 id="actually-using-these-semantics">Actually using these semantics</h2>
<p>Now that we‚Äôve identified an algebraic structure for machine knitting, we‚Äôd like to use that formalism to perform useful
analysis of machine knitting programs. One immediate goal is program equivalence: given two machine knitting programs, will
they produce the same object up to topological equivalence? We can reduce those programs to their braided monoidal category
representations and work with those. This is closely related to the braid group‚Äôs canonicalization I mentioned earlier ‚Äì can we
extend that to the braided monoidal category? I‚Äôve developed an algorithm that does just that in polynomial time, but it‚Äôs
too complicated to fit in a blog post. To borrow some language from Fermat, I‚Äôve
<a href="https://en.wikipedia.org/wiki/Fermat's_Last_Theorem#Fermat's_conjecture">discovered a truly marvelous algorithm and proof of correctness, which this blog post‚Äôs margin is too narrow to contain</a>.
The algorithm works by using some new ideas to canonicalize the positions and order of stitches, and then uses the braid group canonicalization to canonicalize
the crossings between stitches.</p>

<p>We could use the canonicalization algorithm to compile and optimize machine knitting programs. Normal forms are important to compilers because they can greatly
simplify the language to be compiled ‚Äì a canonical form builds on that by additionally providing a uniqueness guarantee. The axioms of braided monoidal categories
lay out exactly all the program transformations we should consider. Finally, I also have an interest in developing a user-facing programming language for machine knitting
that‚Äôs closer to the abstraction provided by category theory. The current machine knitting languages are closely tied to controlling knitting machines, so they require
the user to specify which needles on the machine hold strands (like how assembly requires users to specify which registers use values). On top of usability, a new programming
language might also come with features for performance, fabrication reliability, or modularity of programs.</p>

<p>Big thanks to my advisors at UW, Gilbert Bernstein and Adriana Schulz, for being flexible as a first-year PhD student learns category
theory and topology through the lens of machine knitting. This work is in part a collaboration with folks currently and previously at CMU,
including <a href="https://jlin98.github.io/">Jenny Lin</a>, <a href="https://t0mpr1c3.github.io/">Tom Price</a>, <a href="https://www.cs.cmu.edu/~jmccann/">Jim McCann</a>,
and <a href="https://www.cmu.edu/dietrich/philosophy/people/phd/hannah-fechtner.html">Hannah Fechtner</a>.</p>

<h2 id="further-reading">Further reading</h2>

<ol>
  <li><a href="https://doi.org/10.1145/3654777.3676405">KODA, the optimizing knitting compiler</a></li>
  <li><a href="https://doi.org/10.1145/3592449">Topological machine knitting semantics</a></li>
  <li><a href="https://doi.org/10.1038/s41586-024-08445-2">Microsoft‚Äôs experimental progress in topological quantum computing</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Braid_group">Wikipedia article for the braid group</a></li>
  <li><a href="https://ncatlab.org/nlab/show/internal+logic">nLab‚Äôs page on internal logics</a></li>
  <li><a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street‚Äôs paper connecting category theory diagrams and topology</a></li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Supabase raises $200M Series D at $2B valuation (259 pts)]]></title>
            <link>https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</link>
            <guid>43763225</guid>
            <pubDate>Tue, 22 Apr 2025 15:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html">https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><!-- HTML_TAG_START -->Paul Copplestone didn‚Äôt think things like this actually happened.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Then one day Accel‚Äôs Gonzalo Mocorrea asked for his New Zealand address‚Äîmore than 7,000 miles from Silicon Valley.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Mocorrea ‚Äúliterally showed up on my doorstep in WƒÅnaka, which is really not easy to get to,‚Äù said Copplestone, the CEO and cofounder of open source application development platform Supabase. ‚ÄúFor the next two days, he‚Äôd pop in and we‚Äôd chat for a couple hours.‚Äù<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->After a few days in WƒÅnaka‚Äîlocated on New Zealand's South Island and famous for its snow capped mountains overlooking a massive mirror of a lake‚ÄîAccel‚Äôs Mocorrea called in backup, texting partner Arun Mathew.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->‚ÄúArun said ‚Äòalright, I‚Äôm coming,‚Äô‚Äù said Copplestone. ‚ÄúAnd I said, ‚ÄòOh no, don‚Äôt come! We haven‚Äôt agreed to anything!‚Äô But yeah, he came, we had dinner in Queenstown, another beautiful place. We caught up the next morning, and they offered a term sheet.‚Äù<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Accel‚Äôs Mathew had traveled more than 24 hours, across two flights and multiple car rides, to make the trip as the firm weighed its first investment in Supabase.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->‚ÄúI needed to sit across the table, look him in the eye, and really believe he‚Äôs going to do something else,‚Äù Mathew told <em>Fortune</em>. ‚ÄúThat‚Äôs necessary, certainly at this valuation‚Ä¶We know what greatness looks like, we believe that‚Äîand I‚Äôm obviously betting with my career.‚Äù<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->That term sheet became Supabase‚Äôs latest funding round, a $200 million Series D valuing the company at $2 billion, <em>Fortune</em> can exclusively report. Coatue, Y Combinator, Craft Ventures, and Felicis participated in the round, as did big-name angels like OpenAI Chief Product Officer Kevin Weil, Vercel CEO Guillermo Rauch, and <a href="https://fortune.com/2024/09/05/laravel-raises-57-million-series-a-from-accel/" rel="nofollow noopener" target="_blank" data-ylk="slk:Laravel CEO Taylor Otwell;elm:context_link;itc:0;sec:content-canvas">Laravel CEO Taylor Otwell</a>.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->‚ÄúThe core thesis for us is that in every major platform shift, there's always value created at the database layer,‚Äù said Mathew. ‚ÄúIt's part of the reason that Larry Ellison and <a href="https://fortune.com/europe/2025/03/17/oracle-uk-ai-boom-5-billion-cloud-investment-larry-ellison-trump-starmer/" rel="nofollow noopener" target="_blank" data-ylk="slk:Oracle;elm:context_link;itc:0;sec:content-canvas">Oracle</a> have held the same power for 40-plus years. It's partially why MongoDB is one of the most interesting enterprise software companies out there‚Ä¶The database layer has a lot of dead bodies, but it also has a number of companies that have created exceptional enterprise value.‚Äù<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Supabase is currently used by two million developers who manage more than 3.5 million databases. The startup supports Postgres, the most popular developer database system that‚Äôs an alternative to Google‚Äôs Firebase. Supabase‚Äôs goal: To be a one-stop backend for developers and "vibe coders."<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->‚ÄúI see our community, over the next decade, as something that will grow with us, and it‚Äôs for everyone from developers, all the way up to enterprise,‚Äù said Copplestone. ‚ÄúIt‚Äôs more than just developers even now. Our sign-up rate just doubled in the past three months because of vibe coding‚ÄîBolt, Lovable, Cursor, all those.‚Äù<!-- HTML_TAG_END --></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I open-sourced my AI toy company that runs on ESP32 and OpenAI realtime (124 pts)]]></title>
            <link>https://github.com/akdeb/ElatoAI</link>
            <guid>43762409</guid>
            <pubDate>Tue, 22 Apr 2025 14:10:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/akdeb/ElatoAI">https://github.com/akdeb/ElatoAI</a>, See on <a href="https://news.ycombinator.com/item?id=43762409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">üöÄ ElatoAI: Realtime AI Speech for ESP32</h2><a id="user-content--elatoai-realtime-ai-speech-for-esp32" aria-label="Permalink: üöÄ ElatoAI: Realtime AI Speech for ESP32" href="#-elatoai-realtime-ai-speech-for-esp32"></a></p>
<p dir="auto">Realtime AI Speech powered by OpenAI Realtime API, ESP32, Secure WebSockets, and Deno Edge Functions for &gt;10-minute uninterrupted global conversations</p>
<p dir="auto"><a href="https://discord.gg/KJWxDPBRUj" rel="nofollow"><img src="https://camo.githubusercontent.com/a6bebe6b4fcd39437b9209e02e63af22ac414ffcfcf1bd0224924a924e113bd4/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f4b4a577844504252556a3f7374796c653d666c6174" alt="Discord Follow" data-canonical-src="https://dcbadge.vercel.app/api/server/KJWxDPBRUj?style=flat"></a>
<a href="https://www.gnu.org/licenses/gpl-3.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/bb4e5c0036a6a8cdbc59b38d44f09ad8f6dc722751dad34d3df5bf0ac61913c1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c7565" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/license-MIT-blue"></a>‚ÄÇ‚ÄÇ‚ÄÇ
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/da1334d6d7641a2f8b8a392848949968d3e2f74e04dd8f18e88b8274c5c288fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6f64652e6a732d32322e31332e302d79656c6c6f772e737667"><img src="https://camo.githubusercontent.com/da1334d6d7641a2f8b8a392848949968d3e2f74e04dd8f18e88b8274c5c288fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6f64652e6a732d32322e31332e302d79656c6c6f772e737667" alt="Node.js" data-canonical-src="https://img.shields.io/badge/Node.js-22.13.0-yellow.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6011eef04208dc40ad937a7deb0e3267a39aeef1231389e35deb305d09443039/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6578742e6a732d31342e322e372d627269676874677265656e2e737667"><img src="https://camo.githubusercontent.com/6011eef04208dc40ad937a7deb0e3267a39aeef1231389e35deb305d09443039/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6578742e6a732d31342e322e372d627269676874677265656e2e737667" alt="Next.js" data-canonical-src="https://img.shields.io/badge/Next.js-14.2.7-brightgreen.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e10edb68f4e033e521165fdd24d654e3ac2f1d43cbdab9a8cf9b76319e27106f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d31382e322e302d626c75652e737667"><img src="https://camo.githubusercontent.com/e10edb68f4e033e521165fdd24d654e3ac2f1d43cbdab9a8cf9b76319e27106f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d31382e322e302d626c75652e737667" alt="React" data-canonical-src="https://img.shields.io/badge/React-18.2.0-blue.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo Video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo Video" href="#demo-video"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description Elato.open-source.conversational.AI.device.mp4">Elato.open-source.conversational.AI.device.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/20175219/435005042-aa60e54c-5847-4a68-80b5-5d6b1a5b9328.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzNTA1MDMsIm5iZiI6MTc0NTM1MDIwMywicGF0aCI6Ii8yMDE3NTIxOS80MzUwMDUwNDItYWE2MGU1NGMtNTg0Ny00YTY4LTgwYjUtNWQ2YjFhNWI5MzI4Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIyVDE5MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNjZTRiYTdhNWJlZWMzZTVjM2VlZWE2MmFiNDJjYjkwYmNkY2YxOTU2Y2VkZDMzMTMwYTBlNGEwOWFiYWEwNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.o_7HQusgVlfhCHbV1IOlzhYl5pD9NiBvrQw61HOxMrg" data-canonical-src="https://private-user-images.githubusercontent.com/20175219/435005042-aa60e54c-5847-4a68-80b5-5d6b1a5b9328.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzNTA1MDMsIm5iZiI6MTc0NTM1MDIwMywicGF0aCI6Ii8yMDE3NTIxOS80MzUwMDUwNDItYWE2MGU1NGMtNTg0Ny00YTY4LTgwYjUtNWQ2YjFhNWI5MzI4Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIyVDE5MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNjZTRiYTdhNWJlZWMzZTVjM2VlZWE2MmFiNDJjYjkwYmNkY2YxOTU2Y2VkZDMzMTMwYTBlNGEwOWFiYWEwNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.o_7HQusgVlfhCHbV1IOlzhYl5pD9NiBvrQw61HOxMrg" controls="controls" muted="muted">

  </video>
</details>

<a href="https://www.youtube.com/watch?v=o1eIAwVll5I" rel="nofollow">
  <img src="https://camo.githubusercontent.com/c937f11455e973bb4d27d3cac0d9f79f64a49482daef0ead1c301e51844a16c7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f576174636825323044656d6f2d596f75547562652d7265643f7374796c653d666f722d7468652d6261646765266c6f676f3d796f7574756265" alt="Watch Demo on YouTube" data-canonical-src="https://img.shields.io/badge/Watch%20Demo-YouTube-red?style=for-the-badge&amp;logo=youtube">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">‚ö°Ô∏è Hardware Design</h2><a id="user-content-Ô∏è-hardware-design" aria-label="Permalink: ‚ö°Ô∏è Hardware Design" href="#Ô∏è-hardware-design"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/akdeb/ElatoAI/blob/main/pcb-design.png"><img src="https://github.com/akdeb/ElatoAI/raw/main/pcb-design.png" alt="Hardware Setup" width="100%"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<ol dir="auto">
<li>Install <a href="https://supabase.com/docs/guides/local-development/cli/getting-started" rel="nofollow">Supabase CLI</a> and set up your Local Supabase Backend. From the root directory, run:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="brew install supabase/tap/supabase
supabase start # Starts your local Supabase server with the default migrations and seed data."><pre>brew install supabase/tap/supabase
supabase start <span><span>#</span> Starts your local Supabase server with the default migrations and seed data.</span></pre></div>
<ol start="2" dir="auto">
<li>Set up your NextJS Frontend. (<a href="https://github.com/akdeb/ElatoAI/blob/main/frontend-nextjs/README.md">See the Frontend README</a>) From the <code>frontend-nextjs</code> directory, run the following commands. (<strong>Login creds:</strong> Email: <a href="mailto:admin@elatoai.com">admin@elatoai.com</a>, Password: admin)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="cd frontend-nextjs
npm install

# Set your environment variables
cp .env.example .env.local
# NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
# OPENAI_API_KEY=<your_openai_api_key>

# Run the development server
npm run dev"><pre><span>cd</span> frontend-nextjs
npm install

<span><span>#</span> Set your environment variables</span>
cp .env.example .env.local
<span><span>#</span> NEXT_PUBLIC_SUPABASE_ANON_KEY=&lt;your_supabase_anon_key&gt;</span>
<span><span>#</span> OPENAI_API_KEY=&lt;your_openai_api_key&gt;</span>

<span><span>#</span> Run the development server</span>
npm run dev</pre></div>
<ol start="3" dir="auto">
<li>
<p dir="auto">Add your ESP32-S3 Device MAC Address to the <a href="http://localhost:3000/home/settings" rel="nofollow">Settings page</a> in the NextJS Frontend. This links your device to your account.
To find your ESP32-S3 Device's MAC Address, build and upload <code>test/print_mac_address_test.cpp</code> using PlatformIO.</p>
</li>
<li>
<p dir="auto">Add your OpenAI API Key in the <code>server-deno/.env</code> and <code>frontend-nextjs/.env.local</code> file.</p>
</li>
</ol>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY=<your_openai_api_key>"><pre><code>OPENAI_API_KEY=&lt;your_openai_api_key&gt;
</code></pre></div>
<ol start="5" dir="auto">
<li>Start the Deno server. (<a href="https://github.com/akdeb/ElatoAI/blob/main/server-deno/README.md">See the Deno server README</a>)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to the server directory
cd server-deno

# Set your environment variables
cp .env.example .env
# NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
# OPENAI_API_KEY=<your_openai_api_key>

# Run the server at port 8000
deno run -A --env-file=.env main.ts"><pre><span><span>#</span> Navigate to the server directory</span>
<span>cd</span> server-deno

<span><span>#</span> Set your environment variables</span>
cp .env.example .env
<span><span>#</span> NEXT_PUBLIC_SUPABASE_ANON_KEY=&lt;your_supabase_anon_key&gt;</span>
<span><span>#</span> OPENAI_API_KEY=&lt;your_openai_api_key&gt;</span>

<span><span>#</span> Run the server at port 8000</span>
deno run -A --env-file=.env main.ts</pre></div>
<ol start="5" dir="auto">
<li>
<p dir="auto">Set up your ESP32 Arduino Client. (<a href="https://github.com/akdeb/ElatoAI/blob/main/firmware-arduino/README.md">See the ESP32 README</a>) On PlatformIO, first <code>Build</code> the project, then <code>Upload</code> the project to your ESP32.</p>
</li>
<li>
<p dir="auto">The ESP32 should open an AP <code>ELATO-DEVICE</code> to connect to Wifi. Connect to it and go to <code>http://192.168.4.1</code> to configure the device wifi.</p>
</li>
<li>
<p dir="auto">Once your Wifi is configured, turn the device off and on again and it should connect to your Wifi and the Deno edge server.</p>
</li>
<li>
<p dir="auto">Now you can talk to your AI Character!</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Architecture</h2><a id="user-content-project-architecture" aria-label="Permalink: Project Architecture" href="#project-architecture"></a></p>
<p dir="auto">ElatoAI consists of three main components:</p>
<ol dir="auto">
<li><strong>Frontend Client</strong> (<code>Next.js</code> hosted on Vercel) - to create and talk to your AI agents and 'send' it to your ESP32 device</li>
<li><strong>Edge Server Functions</strong> (<code>Deno</code> running on Deno/Supabase Edge) - to handle the websocket connections from the ESP32 device and the OpenAI API calls</li>
<li><strong>ESP32 IoT Client</strong> (<code>PlatformIO/Arduino</code>) - to receive the websocket connections from the Edge Server Functions and send audio to the OpenAI API via the Deno edge server.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">üåü Features</h2><a id="user-content--features" aria-label="Permalink: üåü Features" href="#-features"></a></p>
<ol dir="auto">
<li><strong>Realtime Speech-to-Speech</strong>: Instant speech conversion powered by OpenAI's Realtime APIs.</li>
<li><strong>Create Custom AI Agents</strong>: Create custom agents with different personalities and voices.</li>
<li><strong>Customizable Voices</strong>: Choose from a variety of voices and personalities.</li>
<li><strong>Secure WebSockets</strong>: Reliable, encrypted WebSocket communication.</li>
<li><strong>Server VAD Turn Detection</strong>: Intelligent conversation flow handling for smooth interactions.</li>
<li><strong>Opus Audio Compression</strong>: High-quality audio streaming with minimal bandwidth.</li>
<li><strong>Global Edge Performance</strong>: Low latency Deno Edge Functions ensuring seamless global conversations.</li>
<li><strong>ESP32 Arduino Framework</strong>: Optimized and easy-to-use hardware integration.</li>
<li><strong>Conversation History</strong>: View your conversation history.</li>
<li><strong>Device Management</strong>: Register and manage your devices.</li>
<li><strong>User Authentication</strong>: Secure user authentication and authorization.</li>
<li><strong>Conversations with WebRTC and Websockets</strong>: Talk to your AI with WebRTC on the NextJS webapp and with websockets on the ESP32.</li>
<li><strong>Volume Control</strong>: Control the volume of the ESP32 speaker from the NextJS webapp.</li>
<li><strong>Realtime Transcripts</strong>: The realtime transcripts of your conversations are stored in the Supabase DB.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">üõ† Tech Stack</h2><a id="user-content--tech-stack" aria-label="Permalink: üõ† Tech Stack" href="#-tech-stack"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Technology Used</th>
</tr>
</thead>
<tbody>
<tr>
<td>Frontend</td>
<td>Next.js, Vercel</td>
</tr>
<tr>
<td>Backend</td>
<td>Supabase DB</td>
</tr>
<tr>
<td>Edge Functions</td>
<td>Deno Edge Functions on Deno/Supabase</td>
</tr>
<tr>
<td>IoT Client</td>
<td>PlatformIO, Arduino Framework, ESP32-S3</td>
</tr>
<tr>
<td>Audio Codec</td>
<td>Opus</td>
</tr>
<tr>
<td>Communication</td>
<td>Secure WebSockets</td>
</tr>
<tr>
<td>Libraries</td>
<td>ArduinoJson, WebSockets, AsyncWebServer, ESP32_Button, Arduino Audio Tools, ArduinoLibOpus</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">üó∫Ô∏è High-Level Flow</h2><a id="user-content-Ô∏è-high-level-flow" aria-label="Permalink: üó∫Ô∏è High-Level Flow" href="#Ô∏è-high-level-flow"></a></p>
<section data-identity="65c7f3cf-ab78-4f32-9c40-23a254c1c485" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;flowchart TD\n  User[User Speech] --&amp;gt; ESP32\n  ESP32[ESP32 Device] --&amp;gt;|WebSocket| Edge[Deno Edge Function]\n  Edge --&amp;gt;|OpenAI API| OpenAI[OpenAI Realtime API]\n  OpenAI --&amp;gt; Edge\n  Edge --&amp;gt;|WebSocket| ESP32\n  ESP32 --&amp;gt; User[AI Generated Speech]\n&quot;}" data-plain="flowchart TD
  User[User Speech] --> ESP32
  ESP32[ESP32 Device] -->|WebSocket| Edge[Deno Edge Function]
  Edge -->|OpenAI API| OpenAI[OpenAI Realtime API]
  OpenAI --> Edge
  Edge -->|WebSocket| ESP32
  ESP32 --> User[AI Generated Speech]
">
      <pre lang="mermaid" aria-label="Raw mermaid code">flowchart TD
  User[User Speech] --&gt; ESP32
  ESP32[ESP32 Device] --&gt;|WebSocket| Edge[Deno Edge Function]
  Edge --&gt;|OpenAI API| OpenAI[OpenAI Realtime API]
  OpenAI --&gt; Edge
  Edge --&gt;|WebSocket| ESP32
  ESP32 --&gt; User[AI Generated Speech]
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<section data-identity="c2843843-c98d-4ca7-bdf2-6a2332934d9e" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;graph TD\n  repo[ElatoAI]\n  repo --&amp;gt; frontend[Frontend Vercel NextJS]\n  repo --&amp;gt; deno[Deno Edge Function]\n  repo --&amp;gt; esp32[ESP32 Arduino Client]\n  deno --&amp;gt; supabase[Supabase DB]\n\n  frontend --&amp;gt; supabase\n  esp32 --&amp;gt; websockets[Secure WebSockets]\n  esp32 --&amp;gt; opus[Opus Codec]\n  esp32 --&amp;gt; audio_tools[arduino-audio-tools]\n  esp32 --&amp;gt; libopus[arduino-libopus]\n  esp32 --&amp;gt; ESPAsyncWebServer[ESPAsyncWebServer]\n&quot;}" data-plain="graph TD
  repo[ElatoAI]
  repo --> frontend[Frontend Vercel NextJS]
  repo --> deno[Deno Edge Function]
  repo --> esp32[ESP32 Arduino Client]
  deno --> supabase[Supabase DB]

  frontend --> supabase
  esp32 --> websockets[Secure WebSockets]
  esp32 --> opus[Opus Codec]
  esp32 --> audio_tools[arduino-audio-tools]
  esp32 --> libopus[arduino-libopus]
  esp32 --> ESPAsyncWebServer[ESPAsyncWebServer]
">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph TD
  repo[ElatoAI]
  repo --&gt; frontend[Frontend Vercel NextJS]
  repo --&gt; deno[Deno Edge Function]
  repo --&gt; esp32[ESP32 Arduino Client]
  deno --&gt; supabase[Supabase DB]

  frontend --&gt; supabase
  esp32 --&gt; websockets[Secure WebSockets]
  esp32 --&gt; opus[Opus Codec]
  esp32 --&gt; audio_tools[arduino-audio-tools]
  esp32 --&gt; libopus[arduino-libopus]
  esp32 --&gt; ESPAsyncWebServer[ESPAsyncWebServer]
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">‚öôÔ∏è PlatformIO Configuration</h2><a id="user-content-Ô∏è-platformio-configuration" aria-label="Permalink: ‚öôÔ∏è PlatformIO Configuration" href="#Ô∏è-platformio-configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[env:esp32-s3-devkitc-1]
platform = espressif32 @ 6.10.0
board = esp32-s3-devkitc-1
framework = arduino
monitor_speed = 115200

lib_deps =
    bblanchon/ArduinoJson@^7.1.0
    links2004/WebSockets@^2.4.1
    ESP32Async/ESPAsyncWebServer@^3.7.6
    https://github.com/esp-arduino-libs/ESP32_Button.git#v0.0.1
    https://github.com/pschatzmann/arduino-audio-tools.git#v1.0.1
    https://github.com/pschatzmann/arduino-libopus.git#a1.1.0"><pre><span>[env:esp32-s3-devkitc-1]</span>
<span>platform</span> = espressif32 @ 6.10.0
<span>board</span> = esp32-s3-devkitc-1
<span>framework</span> = arduino
<span>monitor_speed</span> = 115200

<span>lib_deps</span> =
    bblanchon/ArduinoJson@^7.1.0
    links2004/WebSockets@^2.4.1
    ESP32Async/ESPAsyncWebServer@^3.7.6
    https://github.com/esp-arduino-libs/ESP32_Button.git<span><span>#</span>v0.0.1</span>
    https://github.com/pschatzmann/arduino-audio-tools.git<span><span>#</span>v1.0.1</span>
    https://github.com/pschatzmann/arduino-libopus.git<span><span>#</span>a1.1.0</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">üìä Important Stats</h2><a id="user-content--important-stats" aria-label="Permalink: üìä Important Stats" href="#-important-stats"></a></p>
<ul dir="auto">
<li>‚ö°Ô∏è <strong>Latency</strong>: &lt;1s round-trip globally</li>
<li>üéß <strong>Audio Quality</strong>: Opus codec at 24kbps (high clarity)</li>
<li>‚è≥ <strong>Uninterrupted Conversations</strong>: Up to 10 minutes continuous conversations</li>
<li>üåé <strong>Global Availability</strong>: Optimized with edge computing with Deno</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">üõ° Security</h2><a id="user-content--security" aria-label="Permalink: üõ° Security" href="#-security"></a></p>
<ul dir="auto">
<li>Secure WebSockets (WSS) for encrypted data transfers</li>
<li>Optional: API Key encryption with 256-bit AES</li>
<li>Supabase DB for secure authentication</li>
<li>Supabase RLS for all tables</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">üö´ Limitations</h2><a id="user-content--limitations" aria-label="Permalink: üö´ Limitations" href="#-limitations"></a></p>
<ul dir="auto">
<li>3-4s Cold start time while connecting to edge server</li>
<li>Limited to upto 10 minutes of uninterrupted conversations</li>
<li>Edge server stops when wall clock time is exceeded</li>
<li>No speech interruption detection on ESP32</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">ü§ù Contributing</h2><a id="user-content--contributing" aria-label="Permalink: ü§ù Contributing" href="#-contributing"></a></p>
<ol dir="auto">
<li>Looking for Speech Interruption detection on ESP32</li>
<li>Adding Arduino IDE support</li>
<li>Adding tool calling support on Deno Edge</li>
</ol>
<p dir="auto">We welcome contributions</p>
<ul dir="auto">
<li>Fork this repository.</li>
<li>Create your feature branch (<code>git checkout -b feature/EpicFeature</code>).</li>
<li>Commit your changes (<code>git commit -m 'Add EpicFeature'</code>).</li>
<li>Push to the branch (<code>git push origin feature/EpicFeature</code>).</li>
<li>Open a PR</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - see the <a href="https://github.com/akdeb/ElatoAI/blob/main/LICENSE">LICENSE</a> file for details.</p>
<hr>
<p dir="auto"><strong>If you find this project interesting or useful, drop a GitHub ‚≠êÔ∏è. It helps a lot!</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Abusing DuckDB-WASM by making SQL draw 3D graphics (Sort Of) (158 pts)]]></title>
            <link>https://www.hey.earth/posts/duckdb-doom</link>
            <guid>43761998</guid>
            <pubDate>Tue, 22 Apr 2025 13:35:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hey.earth/posts/duckdb-doom">https://www.hey.earth/posts/duckdb-doom</a>, See on <a href="https://news.ycombinator.com/item?id=43761998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><article dir="ltr"><h2>Abusing DuckDB-WASM by making SQL draw 3D graphics (Sort Of)</h2><h2>Building a SQL-Powered Doom Clone in the Browser<span id="building-a-sql-powered-doom-clone-in-the-browser"></span><a href="#building-a-sql-powered-doom-clone-in-the-browser" aria-label="Permalink for this section"></a></h2>
<p>I had this slightly crazy idea: Could I ditch most of the conventional JavaScript game loop and rendering logic and build a 3D game engine where <strong>SQL queries</strong> did the heavy lifting? Naturally, I decided to try building a primitive, text-based Doom clone to see how far I could push it using <strong>DuckDB-WASM</strong>.</p>
<p><img alt="A screenshot of the text-based Doom clone, showing the 3D view and minimap" loading="lazy" width="922" height="536" decoding="async" data-nimg="1" srcset="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1080&amp;q=75 1x, https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1920&amp;q=75 2x" src="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1920&amp;q=75"></p>
<p>Spoiler: It <em>kind of</em> works, it was often painful, but I learned a ton about the surprising power (and quirks) of running an analytical database engine in the browser for tasks it was definitely not designed for.</p>
<h2>The Setup: SQL Isn't Just for <code dir="ltr">SELECT *</code> Anymore<span id="the-setup-sql-isnt-just-for-select--anymore"></span><a href="#the-setup-sql-isnt-just-for-select--anymore" aria-label="Permalink for this section"></a></h2>
<p>Forget managing game state in JavaScript objects or drawing pixels with Canvas/WebGL. My approach looked like this:</p>
<ol>
<li>
<p><strong>The Database is the World:</strong> The 16x16 map, player coordinates (<code dir="ltr">x</code>, <code dir="ltr">y</code>, <code dir="ltr">dir</code>), enemy/bullet positions, game settings ‚Äì everything lives in DuckDB tables, right there in the browser tab.</p>

</li>
<li>
<p><strong>SQL Dictates Reality:</strong></p>
<ul>
<li>Want to move forward? <code dir="ltr">UPDATE player SET x = x + COS(dir)*step, y = y + SIN(dir)*step;</code></li>
<li>Bullet hits a wall? <code dir="ltr">DELETE FROM bullets WHERE EXISTS (SELECT 1 FROM map WHERE ...)</code></li>
<li>Enemy fragged? A <code dir="ltr">JOIN</code> between <code dir="ltr">bullets</code> and <code dir="ltr">enemies</code> followed by <code dir="ltr">DELETE</code> statements.</li>
</ul>

</li>
<li>
<p><strong>The Renderer is a SQL <code dir="ltr">VIEW</code>:</strong> This is where it gets wild. I defined a SQL <code dir="ltr">VIEW</code> named <code dir="ltr">render_3d_frame</code> that actually performs raycasting and renders the 3D scene. This beast uses recursive CTEs to cast rays for each screen column, calculates wall distances (with fish-eye correction!), determines the height of the wall slice for that column, and then uses <code dir="ltr">string_agg</code> to stitch together the characters (<code dir="ltr">' '</code>, <code dir="ltr">.</code>, <code dir="ltr">‚ñà</code>, <code dir="ltr">‚ñì</code>, <code dir="ltr">‚ñí</code>, <code dir="ltr">‚ñë</code>) for each row of the final text frame.</p>
<p>Here's the core of the raycasting algorithm in SQL:</p>

<p>Yes, SQL is calculating perspective and drawing characters. DuckDB's recursive CTE capabilities are unexpectedly powerful for this kind of work.</p>
</li>
<li>
<p><strong>JavaScript Glues It Together (and Handles Sprites):</strong> My JS code became the orchestrator. It handles keyboard input, runs the <code dir="ltr">setInterval</code> game loop, calls the SQL view to get the background frame, <em>then</em> fetches entity (bullet/enemy) positions and pre-calculated wall distances (from <em>another</em> SQL view!). It performs a quick Z-buffer check in JS to see if a sprite is closer than the wall at its projected screen column, draws it onto the background frame if it is, and finally outputs the resulting text onto a <code dir="ltr">&lt;pre&gt;</code> tag.</p>

</li>
</ol>
<p>Essentially, I took DuckDB-WASM ‚Äì designed for fast analytics ‚Äì and coerced it into acting like a state machine and a rudimentary rendering pipeline.</p>
<h2>The Gauntlet: My Battles with Bugs, Binders, and Browsers<span id="the-gauntlet-my-battles-with-bugs-binders-and-browsers"></span><a href="#the-gauntlet-my-battles-with-bugs-binders-and-browsers" aria-label="Permalink for this section"></a></h2>
<p>This wasn't exactly a smooth ride. Here's a log of some of the more... memorable... challenges and the fixes that eventually worked:</p>
<h3>1. The Initial Roadblock: DuckDB-WASM Just Wouldn't Load (404s)<span id="1-the-initial-roadblock-duckdb-wasm-just-wouldnt-load-404s"></span><a href="#1-the-initial-roadblock-duckdb-wasm-just-wouldnt-load-404s" aria-label="Permalink for this section"></a></h3>
<ul>
<li><strong>Pain Point:</strong> My first attempts using standard CDN links for the worker script just flat-out failed with <code dir="ltr">net::ERR_ABORTED 404</code>. Debugging WASM loading issues in the browser isn't always intuitive.</li>
<li><strong>The Fix:</strong> Digging into the DuckDB-WASM docs revealed the more robust initialization pattern: using their helper functions (<code dir="ltr">getJsDelivrBundles</code>) or explicitly selecting a bundle (<code dir="ltr">mvp</code> for max compatibility), creating the worker via <code dir="ltr">URL.createObjectURL(new Blob(...))</code>, and using the <code dir="ltr">+esm</code> CDN endpoint for the main module import.</li>
</ul>

<p>The lesson: When working with WASM libraries, always follow the recommended initialization patterns from the library authors.</p>
<h3>2. SQL Dialect Gotchas: <code dir="ltr">AUTOINCREMENT</code> vs. <code dir="ltr">SEQUENCE</code><span id="2-sql-dialect-gotchas-autoincrement-vs-sequence"></span><a href="#2-sql-dialect-gotchas-autoincrement-vs-sequence" aria-label="Permalink for this section"></a></h3>
<ul>
<li><strong>Pain Point:</strong> Muscle memory from SQLite/MySQL led me to use <code dir="ltr">AUTOINCREMENT</code> for the <code dir="ltr">bullets</code> table ID. DuckDB promptly slapped me with a <code dir="ltr">Parser Error: syntax error at or near "AUTOINCREMENT"</code>.</li>
<li><strong>The Fix:</strong> Remembering that DuckDB adheres more closely to standard SQL sequences. This meant <code dir="ltr">CREATE SEQUENCE my_seq;</code> and then <code dir="ltr">CREATE TABLE ... (id INTEGER PRIMARY KEY DEFAULT nextval('my_seq'), ...)</code>.</li>
</ul>

<p>This highlights an important point about DuckDB: it's not just SQLite in the browser. It has its own SQL dialect with nuances from PostgreSQL and standard SQL.</p>
<h3>3. Fighting the Query Planner (Binder Errors &amp; Table Functions)<span id="3-fighting-the-query-planner-binder-errors--table-functions"></span><a href="#3-fighting-the-query-planner-binder-errors--table-functions" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> This one drove me nuts for a while. I tried using <code dir="ltr">generate_series(0, settings.view_w - 1)</code> inside my rendering <code dir="ltr">VIEW</code>. The binder freaked out with errors like <code dir="ltr">Table function cannot contain subqueries</code> and even <code dir="ltr">Conversion Error: Could not convert string 's.view_w' to INT32</code>.</p>
</li>
<li>
<p><strong>The Fix:</strong> I had to restructure the view logic significantly. Instead of generating the exact range needed, I generated a <em>fixed, oversized</em> range (like 0-255) first, then added another CTE layer to <em>filter</em> that oversized range using the actual <code dir="ltr">view_w</code> from the settings CTE.</p>
</li>
</ul>

<p>I also initially forgot to alias the output of <code dir="ltr">generate_series</code>, leading to <code dir="ltr">Referenced column "value" not found</code> errors. Fixed with <code dir="ltr">generate_series(...) AS gs(col)</code>.</p>
<p>This approach satisfied the query planner, even though it's less elegant. It taught me that SQL query planners have strict rules about how and when references can be resolved, especially with table-generating functions.</p>
<h3>4. The Dreaded <code dir="ltr">async</code>/<code dir="ltr">setInterval</code> Race Condition<span id="4-the-dreaded-asyncsetinterval-race-condition"></span><a href="#4-the-dreaded-asyncsetinterval-race-condition" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> My game loop was simple: <code dir="ltr">setInterval(async () =&gt; { await tick(); await render(); }, 150)</code>. But because <code dir="ltr">tick()</code> and <code dir="ltr">render()</code> involved <code dir="ltr">async</code> database calls, sometimes a new interval would fire before the previous one finished. This was most obvious with the temporary <code dir="ltr">collisions</code> table used for bullet hits ‚Äì I'd get rapid-fire "table <code dir="ltr">collisions</code> does not exist!" followed by "table <code dir="ltr">collisions</code> already exists!" errors.</p>
</li>
<li>
<p><strong>The Fix:</strong> A classic solution: a simple boolean lock (<code dir="ltr">isProcessingTick</code>). The interval callback now checks this flag; if true, it bails immediately. If false, it sets the flag, runs the async work in a <code dir="ltr">try...finally</code>, and clears the flag in the <code dir="ltr">finally</code> block, ensuring it's always released.</p>
</li>
</ul>

<p>This was a classic reminder that asynchronous timing with recurring events needs careful handling, especially when database operations are involved.</p>
<h3>5. Sprites: Beyond the SQL Background (Z-Buffer Logic)<span id="5-sprites-beyond-the-sql-background-z-buffer-logic"></span><a href="#5-sprites-beyond-the-sql-background-z-buffer-logic" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> The SQL view rendered walls/floor/ceiling beautifully (well, beautifully for text mode). But enemies and bullets were just data. Drawing them required knowing <em>if they were hidden by a wall</em>.</p>
</li>
<li>
<p><strong>The Fix:</strong> A hybrid approach combining SQL and JavaScript. I created <em>another</em> SQL view (<code dir="ltr">column_distances</code>) specifically to output the distance to the nearest wall for each screen column:</p>
</li>
</ul>

<p>Then, in my JavaScript <code dir="ltr">render3d</code> function, I performed the Z-buffer check by comparing entity depth to wall depth for each screen column.</p>
<h2>Performance and Results<span id="performance-and-results"></span><a href="#performance-and-results" aria-label="Permalink for this section"></a></h2>
<p>How did it actually run? Surprisingly well, considering what we're asking SQL to do. On a modern laptop, I get about 6-7 FPS with the 150ms game loop interval. The most expensive operation is the SQL raycasting view, which takes about 80-100ms to execute. The sprite rendering in JavaScript is quite fast in comparison.</p>
<p><img alt="A GIF showing gameplay with player movement and shooting" loading="lazy" width="870" height="508" decoding="async" data-nimg="1" srcset="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1080&amp;q=75 1x, https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1920&amp;q=75 2x" src="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1920&amp;q=75"></p>
<p>Here's what the game looks like in action. The main view shows the 3D perspective with text-based graphics, while the smaller box in the corner shows a top-down minimap. You can see how the walls are rendered with different characters based on distance, giving a primitive 3D effect.</p>
<p>The movement feels responsive enough, and the SQL-based collision detection works well. There's something strangely satisfying about mowing down enemies with SQL <code dir="ltr">DELETE</code> statements.</p>
<h2>Pushing SQL to Its Limits: What I Learned<span id="pushing-sql-to-its-limits-what-i-learned"></span><a href="#pushing-sql-to-its-limits-what-i-learned" aria-label="Permalink for this section"></a></h2>
<p>This experiment taught me several important lessons about both SQL and browser-based development:</p>
<ol>
<li>
<p><strong>SQL is surprisingly powerful for non-traditional use cases.</strong> It's not just for data retrieval. The combination of recursive CTEs, window functions, and aggregate functions makes complex algorithms possible.</p>
</li>
<li>
<p><strong>DuckDB-WASM is impressively performant.</strong> Running an analytical database engine in the browser that can handle complex recursive queries 6-7 times per second is no small feat.</p>
</li>
<li>
<p><strong>The boundaries between languages can be blurred.</strong> This project combined SQL for game state and rendering fundamentals, with JavaScript for orchestration and sprite handling. Neither could have done the job alone.</p>
</li>
<li>
<p><strong>Debugging across language boundaries is challenging.</strong> When something went wrong, it wasn't always clear if the issue was in the JavaScript, the SQL, or at the interface between them. I added extensive logging to track the flow between components.</p>
</li>
<li>
<p><strong>Query planning is a complex art.</strong> I had to work around many limitations of how SQL planners work, especially around table function evaluation and CTEs.</p>
</li>
</ol>
<h2>Would I Recommend This Approach?<span id="would-i-recommend-this-approach"></span><a href="#would-i-recommend-this-approach" aria-label="Permalink for this section"></a></h2>
<p>For a production game? Absolutely not. It's a fun hack, but there are much better tools for game development.</p>
<p>But as a learning exercise? 100% yes. This project forced me to think deeply about:</p>
<ul>
<li>SQL query optimization and execution planning</li>
<li>Raycasting algorithms and 3D projection</li>
<li>Asynchronous JavaScript patterns</li>
<li>The capabilities and limitations of WASM in the browser</li>
</ul>
<h2>Try It Yourself!<span id="try-it-yourself"></span><a href="#try-it-yourself" aria-label="Permalink for this section"></a></h2>
<p>If you want to experiment with this SQL-powered monstrosity yourself, I've put the <a target="_blank" rel="noreferrer" href="https://github.com/patricktrainer/duckdb-doom">full source code on GitHub<span> (opens in a new tab)</span></a>. It's about 500 lines of code total, with roughly half being SQL and half JavaScript.</p>
<p>I'd love to see how far others can push this concept. Could you add textures? Implement a more complex game world? Add enemies that move and shoot back? The SQL rabbit hole goes deep!</p>
<h2>What's Next?<span id="whats-next"></span><a href="#whats-next" aria-label="Permalink for this section"></a></h2>
<p>This experiment has me wondering what other unconventional uses might exist for DuckDB-WASM in the browser. Physics simulations? Path finding algorithms? Full-text search engines?</p>
<p>Sometimes the most interesting projects come from using tools in ways they were never intended to be used. What weird DuckDB-WASM experiment would you like to see next?</p><small>not made by a ü§ñ</small></article><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Whistleblower: DOGE Siphoned NLRB Case Data (770 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/</link>
            <guid>43760801</guid>
            <pubDate>Tue, 22 Apr 2025 11:04:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/">https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/</a>, See on <a href="https://news.ycombinator.com/item?id=43760801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>A security architect with the <strong>National Labor Relations Board</strong> (NLRB) alleges that employees from <strong>Elon Musk</strong>‚Äòs <strong>Department of Government Efficiency</strong> (DOGE) transferred gigabytes of sensitive data from agency case files in early March, using short-lived accounts configured to leave few traces of network activity. The NLRB whistleblower said the unusual large data outflows coincided with multiple blocked login attempts from an Internet address in Russia that tried to use valid credentials for a newly-created DOGE user account.</p>
<div id="attachment_71048"><p><img aria-describedby="caption-attachment-71048" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint.png" alt="" width="749" height="823" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint.png 786w, https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint-768x844.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint-782x860.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p><p id="caption-attachment-71048">The cover letter from Berulis‚Äôs whistleblower statement, sent to the leaders of the Senate Select Committee on Intelligence.</p></div>
<p>The allegations came in an April 14 letter to the Senate Select Committee on Intelligence, signed by <strong>Daniel J. Berulis</strong>, a 38-year-old security architect at the NLRB.</p>
<p><strong>NPR</strong>, which was the <a href="https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security" target="_blank" rel="noopener">first to report</a> on Berulis‚Äôs whistleblower complaint, says NLRB is a small, independent federal agency that investigates and adjudicates complaints about unfair labor practices, and stores ‚Äúreams of potentially sensitive data, from confidential information about employees who want to form unions to proprietary business information.‚Äù</p>
<p>The complaint documents a one-month period beginning March 3, during which DOGE officials reportedly demanded the creation of all-powerful ‚Äútenant admin‚Äù accounts in NLRB systems that were to be exempted from network logging activity that would otherwise keep a detailed record of all actions taken by those accounts.</p>
<p>Berulis said the new DOGE accounts had unrestricted permission to read, copy, and alter information contained in NLRB databases. The new accounts also could restrict log visibility, delay retention, route logs elsewhere, or even remove them entirely ‚Äî top-tier user privileges that neither Berulis nor his boss possessed.</p>
<p>Berulis writes that on March 3, a black SUV accompanied by a police escort arrived at his building ‚Äî the NLRB headquarters in Southeast Washington, D.C. The DOGE staffers did not speak with Berulis or anyone else in NLRB‚Äôs IT staff, but instead met with the agency leadership.</p>
<p>‚ÄúOur acting chief information officer told us not to adhere to standard operating procedure with the DOGE account creation, and there was to be no logs or records made of the accounts created for DOGE employees, who required the highest level of access,‚Äù Berulis wrote of their instructions after that meeting.</p>
<p>‚ÄúWe have built in roles that auditors can use and have used extensively in the past but would not give the ability to make changes or access subsystems without approval,‚Äù he continued. ‚ÄúThe suggestion that they use these accounts was not open to discussion.‚Äù</p>
<p>Berulis found that on March 3 one of the DOGE accounts created an opaque, virtual environment known as a ‚Äúcontainer,‚Äù which can be used to build and run programs or scripts without revealing its activities to the rest of the world. Berulis said the container caught his attention because he polled his colleagues and found none of them had ever used containers within the NLRB network.</p>
<p>Berulis said he also noticed that early the next morning ‚Äî between approximately 3 a.m. and 4 a.m. EST on Tuesday, March 4&nbsp; ‚Äî there was a large increase in outgoing traffic from the agency. He said it took several days of investigating with his colleagues to determine that one of the new accounts had transferred approximately 10 gigabytes worth of data from the NLRB‚Äôs <strong>NxGen</strong> case management system.</p>
<p>Berulis said neither he nor his co-workers had the necessary network access rights to review which files were touched or transferred ‚Äî or even where they went. But his complaint notes the NxGen database contains sensitive information on unions, ongoing legal cases, and corporate secrets.</p>
<p>‚ÄúI also don‚Äôt know if the data was only 10gb in total or whether or not they were consolidated and compressed prior,‚Äù Berulis told the senators. ‚ÄúThis opens up the possibility that even more data was exfiltrated. Regardless, that kind of spike is extremely unusual because data almost never directly leaves NLRB‚Äôs databases.‚Äù</p>
<p>Berulis said he and his colleagues grew even more alarmed when they noticed nearly two dozen login attempts from a Russian Internet address (83.149.30,186) that presented valid login credentials for a DOGE employee account ‚Äî one that had been created just minutes earlier. Berulis said those attempts were all blocked thanks to rules in place that prohibit logins from non-U.S. locations.</p>
<p>‚ÄúWhoever was attempting to log in was using one of the newly created accounts that were used in the other DOGE related activities and it appeared they had the correct username and password due to the authentication flow only stopping them due to our no-out-of-country logins policy activating,‚Äù Berulis wrote. ‚ÄúThere were more than 20 such attempts, and what is particularly concerning is that many of these login attempts occurred within 15 minutes of the accounts being created by DOGE engineers.‚Äù</p>
<p>According to Berulis, the naming structure of one Microsoft user account connected to the suspicious activity suggested it had been created and later deleted for DOGE use in the NLRB‚Äôs cloud systems: ‚Äú<strong>DogeSA_2d5c3e0446f9@nlrb.microsoft.com</strong>.‚Äù He also found other new Microsoft cloud administrator accounts with nonstandard usernames, including ‚Äú<strong>Whitesox, Chicago M.</strong>‚Äù and ‚Äú<strong>Dancehall, Jamaica R</strong>.‚Äù</p>
<div id="attachment_71042"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71042" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png" alt="" width="749" height="556" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png 1072w, https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago-768x570.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago-782x581.png 782w" sizes="(max-width: 749px) 100vw, 749px"></a></p><p id="caption-attachment-71042">A screenshot shared by Berulis showing the suspicious user accounts.</p></div>
<p>On March 5, Berulis documented that a large section of logs for recently created network resources were missing, and a network watcher in <strong>Microsoft Azure</strong> was set to the ‚Äúoff‚Äù state, meaning it was no longer collecting and recording data like it should have.</p>
<p>Berulis said he discovered someone had downloaded three external code libraries from <strong>GitHub</strong> that neither NLRB nor its contractors ever use. A ‚Äúreadme‚Äù file in one of the code bundles explained it was created to rotate connections through a large pool of cloud Internet addresses that serve ‚Äúas a proxy to generate pseudo-infinite IPs for web scraping and brute forcing.‚Äù Brute force attacks involve automated login attempts that try many credential combinations in rapid sequence.</p>
<p>The complaint alleges that by March 17 it became clear the NLRB no longer had the resources or network access needed to fully investigate the odd activity from the DOGE accounts, and that on March 24, the agency‚Äôs associate chief information officer had agreed the matter should be reported to <strong>US-CERT</strong>. Operated by the Department of Homeland Security‚Äôs <strong>Cybersecurity and Infrastructure Security Agency</strong> (CISA), US-CERT provides on-site cyber incident response capabilities to federal and state agencies.</p>
<p>But Berulis said that between April 3 and 4, he and the associate CIO were informed that ‚Äúinstructions had come down to drop the US-CERT reporting and investigation and we were directed not to move forward or create an official report.‚Äù Berulis said it was at this point he decided to go public with his findings.<span id="more-71035"></span></p>
<div id="attachment_71050"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/berulis-mar4-spike.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71050" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/berulis-mar4-spike.png" alt="" width="685" height="908"></a></p><p id="caption-attachment-71050">An email from Daniel Berulis to his colleagues dated March 28, referencing the unexplained traffic spike earlier in the month and the unauthorized changing of security controls for user accounts.</p></div>
<p><strong>Tim Bearese</strong>, the NLRB‚Äôs acting press secretary, told NPR that DOGE neither requested nor received access to its systems, and that ‚Äúthe agency conducted an investigation after Berulis raised his concerns but ‚Äòdetermined that no breach of agency systems occurred.'‚Äù The NLRB did not respond to questions from KrebsOnSecurity.</p>
<p>Nevertheless, Berulis has shared a number of supporting screenshots showing agency email discussions about the unexplained account activity attributed to the DOGE accounts, as well as NLRB security alerts from Microsoft about network anomalies observed during the timeframes described.</p>
<p>As <strong>CNN</strong> <a href="https://www.cnn.com/2025/02/15/business/nlrb-trump-musk-workers/index.html#:~:text=Musk's%20SpaceX%20brought%20a%20case,it%20for%20firing%20some%20employees." target="_blank" rel="noopener">reported</a> last month, the NLRB has been effectively hobbled since <strong>President Trump</strong> fired three board members, leaving the agency without the quorum it needs to function.</p>
<p>‚ÄúDespite its limitations, the agency had become a thorn in the side of some of the richest and most powerful people in the nation ‚Äî notably Elon Musk, Trump‚Äôs key supporter both financially and arguably politically,‚Äù CNN wrote.</p>
<p>Both <strong>Amazon</strong> and Musk‚Äôs <strong>SpaceX</strong> have <a href="https://apnews.com/article/amazon-nlrb-unconstitutional-spacex-elon-musk-ab42977117d883e97110a7bf8e8b257f" target="_blank" rel="noopener">been suing</a> the NLRB over complaints the agency filed in disputes about workers‚Äô rights and union organizing, arguing that the NLRB‚Äôs very existence is unconstitutional. On March 5, a U.S. appeals court <a href="https://www.reuters.com/legal/government/musks-spacex-loses-early-legal-challenge-us-labor-boards-powers-2025-03-05/" target="_blank" rel="noopener">unanimously rejected</a> Musk‚Äôs claim that the NLRB‚Äôs structure somehow violates the Constitution.</p>
<p>Berulis shared screenshots with KrebsOnSecurity showing that on the day the NPR published its story about his claims (April 14), the deputy CIO at NLRB sent an email stating that administrative control had been removed from all employee accounts. Meaning, suddenly none of the IT employees at the agency could do their jobs properly anymore, Berulis said.</p>
<div id="attachment_71043"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71043" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png" alt="" width="750" height="377" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png 1046w, https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb-768x386.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb-782x393.png 782w" sizes="(max-width: 750px) 100vw, 750px"></a></p><p id="caption-attachment-71043">An email from the NLRB‚Äôs associate chief information officer Eric Marks, notifying employees they will lose security administrator privileges.</p></div>
<p>Berulis shared a screenshot of an agency-wide email dated April 16 from NLRB director <strong>Lasharn Hamilton</strong>&nbsp;saying DOGE officials had requested a meeting, and reiterating claims that the agency had no prior ‚Äúofficial‚Äù contact with any DOGE personnel. The message informed NLRB employees that two DOGE representatives would be detailed to the agency part-time for several months.</p>
<div id="attachment_71041"><p><img aria-describedby="caption-attachment-71041" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/nlrb-dir-emailapril14.png" alt="" width="551" height="568"></p><p id="caption-attachment-71041">An email from the NLRB Director Lasharn Hamilton on April 16, stating that the agency previously had no contact with DOGE personnel.</p></div>
<p>Berulis told KrebsOnSecurity he was in the process of filing a support ticket with Microsoft to request more information about the DOGE accounts when his network administrator access was restricted. Now, he‚Äôs hoping lawmakers will ask Microsoft to provide more information about what really happened with the accounts.</p>
<p>‚ÄúThat would give us way more insight,‚Äù he said. ‚ÄúMicrosoft has to be able to see the picture better than we can. That‚Äôs my goal, anyway.‚Äù</p>
<p>Berulis‚Äôs attorney told lawmakers that on April 7, while his client and legal team were preparing the whistleblower complaint, someone physically taped a threatening note to Mr. Berulis‚Äôs home door with photographs ‚Äî taken via drone ‚Äî of him walking in his neighborhood.</p>
<p>‚ÄúThe threatening note made clear reference to this very disclosure he was preparing for you, as the proper oversight authority,‚Äù reads a preface by Berulis‚Äôs attorney <strong>Andrew P. Bakaj</strong>. ‚ÄúWhile we do not know specifically who did this, we can only speculate that it involved someone with the ability to access NLRB systems.‚Äù</p>
<p>Berulis said the response from friends, colleagues and even the public has been largely supportive, and that he doesn‚Äôt regret his decision to come forward.</p>
<p>‚ÄúI didn‚Äôt expect the letter on my door or the pushback from [agency] leaders,‚Äù he said. ‚ÄúIf I had to do it over, would I do it again? Yes, because it wasn‚Äôt really even a choice the first time.‚Äù</p>
<p>For now, Mr. Berulis is taking some paid family leave from the NLRB. Which is just as well, he said, considering he was stripped of the tools needed to do his job at the agency.</p>
<p>‚ÄúThey came in and took full administrative control and locked everyone out, and said limited permission will be assigned on a need basis going forward‚Äù Berulis said of the DOGE employees. ‚ÄúWe can‚Äôt really do anything, so we‚Äôre literally getting paid to count ceiling tiles.‚Äù</p>
<p>Further reading: <a href="https://whistlebloweraid.org/wp-content/uploads/2025/04/2025_0414_Berulis-Disclosure-with-Exhibits.s.pdf" target="_blank" rel="noopener">Berulis‚Äôs complaint</a> (PDF).</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SerenityOS is a love letter to '90s user interfaces (170 pts)]]></title>
            <link>https://serenityos.org/</link>
            <guid>43760626</guid>
            <pubDate>Tue, 22 Apr 2025 10:24:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://serenityos.org/">https://serenityos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43760626">Hacker News</a></p>
<div id="readability-page-1" class="page">
<img src="https://serenityos.org/banner2.png" alt="SerenityOS">

<b>A graphical Unix-like operating system for desktop computers!</b>

<p>SerenityOS is a love letter to '90s user interfaces with a custom Unix-like core. It flatters with sincerity by stealing beautiful ideas from various other systems.</p>

<p>Roughly speaking, the goal is a marriage between the aesthetic of late-1990s productivity software and the power-user accessibility of late-2000s *nix.</p>

<p>This is a system by us, for us, based on the things we like.</p>

<p><b>Project:</b></p>
<ul>
    <li><a href="https://github.com/SerenityOS/serenity">SerenityOS on GitHub</a></li>
    <li><a href="https://discord.gg/serenityos">SerenityOS Discord Server</a> <span color="red">(join here to chat!)</span></li>
    <li><a href="https://man.serenityos.org/">SerenityOS man pages</a></li>
    <li><a href="https://serenityos.org/faq/">Frequently asked questions</a></li>
    <li><a href="https://serenityos.org/bounty/">Bug bounty program</a></li>
</ul>

<p><b>Birthday posts:</b></p>
<ul>
    <li><a href="https://serenityos.org/happy/5th/">Happy 5th birthday, SerenityOS!</a></li>
    <li><a href="https://serenityos.org/happy/4th/">Happy 4th birthday! The 4th year of SerenityOS</a></li>
    <li><a href="https://serenityos.org/happy/3rd/">Happy 3rd birthday! SerenityOS: Year 3 in review</a></li>
    <li><a href="https://serenityos.org/happy/2nd/">Happy 2nd birthday! SerenityOS: The second year</a></li>
    <li><a href="https://serenityos.org/happy/1st/">Happy 1st birthday! SerenityOS: From zero to HTML in a year</a></li>
</ul>

<p><b>Screenshot:</b></p>

<img src="https://serenityos.org/screenshot-b36968c.png">



</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attacking My Landlord's Boiler (340 pts)]]></title>
            <link>https://blog.videah.net/attacking-my-landlords-boiler/</link>
            <guid>43759073</guid>
            <pubDate>Tue, 22 Apr 2025 04:27:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.videah.net/attacking-my-landlords-boiler/">https://blog.videah.net/attacking-my-landlords-boiler/</a>, See on <a href="https://news.ycombinator.com/item?id=43759073">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><h2>Attacking My Landlord's Boiler</h2><p><label>Posted on <time datetime="2025-04-22T00:00:00+00:00">April 22, 2025</time> ‚Ä¢ 10 minute read</label></p></div><figure><div><picture><img alt="Very bright red photo of a Macbook plugged into a HackRF radio, with my thermostat sitting next to it" height="500px" src="https://blog.videah.net/processed_images/banner.929433b287ec442f.png"></picture></div></figure><div><p>Please do your due diligence and check local laws before attempting anything I do in this post. Transmitting radio signals can become legally problematic <em>very quickly</em>, and the band I specifically transmit on here (<code>868Mhz</code>) is <strong>illegal</strong> in the United States without a license. I'd rather you didn't have men in suits knocking on your door on my account. You've been warned!</p></div><p>A little while ago I moved into an apartment to live on my own for the first time. This has given me a decent amount of newfound freedom to sculpt my living environment to my liking, but not enough where I could start knocking down walls. I have a landlord (and a deposit!) to think about, after all. üôÇ</p><p>While it isn't near the level of knocking down walls, I was finding heating my apartment rather frustrating. The boiler's thermostat installed by my landlord is a single radio-controlled unit that uses a built-in temperature sensor to modulate the heating on and off to meet a target temperature. This presents a few first-world problems:</p><ul><li>The temperature sensor can only sample a single room in the apartment, which heats unevenly.</li><li>That room is dependent on the physical proximity of the thermostat's controls, which can be annoying to use if I might be in bed and the controls are in the living room or vice versa.</li><li>If I forget to turn the heating off before I leave the apartment, I'm wasting a lot of costly energy.</li></ul><p>I automate things around my apartment with <a href="https://www.home-assistant.io/">Home Assistant</a>, and I wanted to be able to do the same here. There are a lot of off-the-shelf solutions for this, obviously, but to get back to the knocking-down-walls comparison, they would require my landlord's cooperation and likely a visit from an electrician. I don't want that!</p><p>Instead, here's how I figured out how to control my apartment's heating in a way that leaves no trace using the existing thermostat already fitted by my landlord, and maybe learn a bit about radios along the way.</p><h2 id="where-do-we-start">Where Do We Start?</h2><p>I knew that the thermostat communicated with the boiler through some kind of radio protocol. We could try to reverse-engineer the protocol from scratch, but as I'll get into later, that turns out to be <em>very involved</em> and way beyond my minimal radio skills.</p><p>I eventually decided it was a lot easier to attempt something called a <a href="https://en.wikipedia.org/wiki/Replay_attack#Remote_keyless-entry_system_for_vehicles">Replay Attack</a>. This involves cloning the signals sent between the boiler and the thermostat, and then pretending <em>we</em> are the thermostat by re-broadcasting the signals. This way we don't need to understand the protocol, just replay it.</p><div><p>This approach requires some degree of luck and crossing your fingers. Replay attacks can be pretty easily thwarted by using an incrementing counter in the communications to nullify previous signals, ignoring signals with a counter value you've already seen. I was lucky the thermostat does not do this‚Äîyour mileage may vary!</p></div><h2 id="initial-reconnaissance">Initial Reconnaissance</h2><p>The first thing I did was check to see if there was any information online about my specific thermostat. I came across <a href="https://www.wolseley.co.uk/product/center-rf-wireless-programmable-boiler-thermostat">a listing for the exact model I had</a>, along with a datasheet in the attachments section. The section on <em>RF Communication</em> is exactly what I was looking for:</p><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/boiler_datasheet_rf.png"></picture></figure><p>From this, we know the thermostat communicates around the <code>868Mhz</code> range. The <code>Protocol: Encrypted</code> part was initially a bit concerning, but it turned out to not be a problem.</p><p>The first issue I'm running into here is that there are shockingly few resources on cloning a <code>868Mhz</code> signal online. Most beefy resources were about using LoRa/Meshtastic. I would come across a lot of Reddit posts of people trying to do the same thing as me for things like ceiling fans and garage doors, but nobody seemed to have any answers... üò≠</p><div><p>I <em>suspect</em> this is because unlicensed <code>868Mhz</code> transmission is illegal in the US and nobody cares about Europe, but who really knows. My life would be <em>so much</em> easier if it were <code>433Mhz</code> instead, as there is a plethora of consumer-facing tools for communicating on that band.</p></div><h2 id="seeing-signals">Seeing Signals</h2><p>So without much to go on, I thought the first thing to do would be to actually <em>see</em> the radio packets and inspect them. I'd read about <a href="https://en.wikipedia.org/wiki/Software-defined_radio">Software-Defined Radios</a> in the past and guessed it'd be my best bet. Most SDRs are <em>really</em> expensive, so I went with the budget <a href="https://www.aliexpress.com/item/1005005952566458.html?spm=a2g0o.order_list.order_list_main.165.295b1802ErX1lM">RTL-SDR V4</a> off of AliExpress. (This actually ended up being somewhat unnecessary for reasons we'll eventually get to!)</p><div><p>You might have heard of the infamous <a href="https://flipperzero.one/">Flipper Zero</a> and its ability to clone and replay signals. Maybe you're like me and consider using it in this situation, but be warned that the Flipper is <strong>NOT</strong> an SDR. The Flipper is very stingy about what frequencies it can operate on. I found this out the hard way when I borrowed one and assumed all was hopeless when it wouldn't work.</p></div><p>After it arrived, I hooked it up to my laptop with the <a href="https://www.sdrpp.org/">SDR++</a> software just to see if it worked and get an initial glimpse of my thermostat yapping. After pressing the thermostat's buttons a few times, I managed to see the waterfall light up!</p><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/sdr_plus_plus.png"></picture><figcaption>The "waterfall" at 868Mhz showing long horizontal blips.</figcaption></figure><div><p>Ignore the solid vertical line on the waterfall‚Äîthis is just a common byproduct of using a really cheap SDR, and for me it appears nearby to any frequency I'm inspecting.</p></div><p>This step isn't super important, but we can then try to use the <a href="https://github.com/merbanan/rtl_433">rtl_433</a> tool (it works on other frequencies despite the name) to see if the thermostat is speaking a known protocol. More obscure devices might not work here!</p><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/rtl_443_results.png"></picture></figure><p>It seems like this thermostat speaks the same protocol as another Honeywell one. The demand attribute sets whether the boiler is on (1) or off (0), and then the boiler responds with an acknowledgement (presumably so the thermostat can determine if it's out of range).</p><h2 id="trying-to-yell-back">Trying To Yell Back</h2><p>Now that we've actually seen the back-and-forth communication, we want to be able to send some packets ourselves and puppeteer the boiler as if we were the thermostat.</p><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/challenger.png"></picture><figcaption>Using a 868Mhz Challenger Dev Board, first failed attempt...</figcaption></figure><p>This was the step I got stuck on for <em>months</em>. I was trying the "smart" route of attempting to reverse-engineer and reconstruct the packets <em>by hand</em> using <a href="https://github.com/jopohl/urh">URH</a> and then broadcasting them with very cheap <code>868Mhz</code> microcontroller boards. I can safely say this was all wayyy outside of my skill set. None of the boards were really designed to talk to anything other than <em>the exact same board</em>, and going any further than that required poking at radio registers in ways I wasn't comfortable doing.</p><h2 id="the-hackrf">The HackRF</h2><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/hackrf-board.png"></picture><figcaption>The official HackRF One board, going on to spawn many AliExpress clones.</figcaption></figure><p>I decided to then go for the <strong>sledgehammer</strong> approach: use a full-blown SDR to just replay the exact same signal without a care for what the signal actually contains. But the cheap RTL-SDR I got earlier only supports receiving, not broadcasting. SDRs that can broadcast are usually <em>hundreds of dollars</em>.</p><p>I say <em>usuallyyy</em> because one of the most common broadcast-capable SDRs, the <code>HackRF One</code> (usually upwards of $400), had numerous clones available on AliExpress for a fraction of the price‚Äîjust $40.</p><div><p>And then I say <em>haddd</em> because, writing this months later, AliExpress has removed pretty much every listing you could find just searching "HackRF". From my understanding, they were getting nabbed at customs in a lot of countries that were getting pissy about importing a scawy hacking tool, so they just decided to nuke all the listings rather than deal with it. Newer clones can be bought from <a href="https://opensourcesdrlab.com/products/r10c-hrf-sdr-software-defined-1mhz-to-6ghz-mainboard-development-board-kit?VariantsId=10158">here</a>, but they aren't nearly as cheap as they used to be... üò≠</p></div><p>There are some obvious ethical (and probably a few technical) problems with cheap clones of what is meant to be open-source hardware, but I figured it'd be fine for my small use case. Please <a href="https://greatscottgadgets.com/hackrf/one">support the original hardware project</a> if it's within your means to!</p><div><p>As I kinda alluded to earlier, this makes the need for the RTL-SDR sort of redundant? But I guess it's always good to have another SDR just to confirm that we're not polluting other frequencies.</p></div><h2 id="actually-yelling-back">Actually Yelling Back</h2><p>With the HackRF in hand, we can use the <a href="https://manpages.debian.org/unstable/hackrf/hackrf_transfer.1.en.html">hackrf_transfer tool</a> to record signals and, most importantly, <em>replay</em> signals. I perform these commands and then press the appropriate controls on the thermostat to write the signals to individual files:</p><pre data-lang="shell"><code data-lang="shell"><span># We set the frequency to 868.3Mhz and the sample rate to 2000000.
</span><span>hackrf_transfer -r turn_off.raw -f 868300000 -s 2000000
</span><span>hackrf_transfer -r turn_on.raw -f 868300000 -s 2000000
</span></code></pre><p>And then we can try and turn the boiler off and on from CLI like this:</p><pre data-lang="shell"><code data-lang="shell"><span># We use -a to turn on the amplifier and -x to increase the gain a tad.
</span><span>hackrf_transfer -t turn_off.raw -f 868300000 -s 2000000 -a 1 -x 23
</span><span>hackrf_transfer -t turn_on.raw -f 868300000 -s 2000000 -a 1 -x 23
</span></code></pre><p>After doing this, I could hear the physical relay inside of my boiler turning on and off!</p><h2 id="automating-the-whole-thing">Automating The Whole Thing</h2><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/hackrf_horizontal.png"></picture><figcaption>My HackRF clone in a 3D printed case, plugged into the server.</figcaption></figure><p>I have the HackRF plugged into a powered USB hub connected to my Home Assistant server. I wrote a very basic web server that simply shells out to the transmit commands above in a Docker container.</p><p>Then with an <a href="https://github.com/Limych/ha-average">Average Sensor Plugin</a> and the config YAML below:</p><pre data-lang="yaml"><code data-lang="yaml"><span>command_line</span><span>:
</span><span>  - </span><span>switch</span><span>:
</span><span>    </span><span>name</span><span>: </span><span>Boiler
</span><span>    </span><span>command_on</span><span>: "</span><span>curl http://docker-vm:1111/api/on</span><span>"
</span><span>    </span><span>command_off</span><span>: "</span><span>curl http://docker-vm:1111/api/off</span><span>"
</span><span>
</span><span>sensor</span><span>:
</span><span>  - </span><span>platform</span><span>: </span><span>average
</span><span>    </span><span>name</span><span>: "</span><span>Average Temperature</span><span>"
</span><span>    </span><span>entities</span><span>:
</span><span>      - </span><span>sensor.bedroom_thermostat_temperature
</span><span>      - </span><span>sensor.kitchen_thermostat_temperature
</span><span>
</span><span>climate</span><span>:
</span><span>  - </span><span>platform</span><span>: </span><span>generic_thermostat
</span><span>  </span><span>name</span><span>: </span><span>Boiler Thermostat
</span><span>  </span><span>heater</span><span>: </span><span>switch.boiler
</span><span>  </span><span>target_sensor</span><span>: </span><span>sensor.average_temperature
</span></code></pre><p>We have a working controllable thermostat! ü§Ø</p><p>At this point I was just happy to have the thing <em>working</em> after so many months, so I'll be the first to admit this setup with Home Assistant is a bit slapdash and could use some cleanup. It'd be better to write a proper plugin and control the radio directly instead of shelling out to the CLI. Relying on <code>curl</code> to heat my apartment is maybe a bit cursed?</p><h2 id="was-it-worth-it">Was It Worth It?</h2><figure><picture><img decoding="async" loading="lazy" src="https://blog.videah.net/attacking-my-landlords-boiler/images/boiler_grafana.png"></picture><figcaption>Grafana graph showing the temperatures following the target one.</figcaption></figure><p>I've been using this setup to control the heating of my apartment since the beginning of December and haven't had any issues since! It's super convenient to dial in the temperature from my phone, and the automations I have make me feel like this project was really worth the work.</p><p>I have some basic automations like having the temperature go down when I'm sleeping and then up in the morning in time for me waking up, but I also have it so the heating turns off when I go into town and turns back on when I'm just a few train stops away so my place is nice and toasty for me getting home!</p><p>The only thing I'm not happy with is needing to use a very powerful and versatile radio like the HackRF for something as simple as a boiler on/off switch. But I'd rather use something overkill and have it work than spend ages trying to force smaller radios to do my bidding.</p><p>The important thing is I'm not as cold as I used to be! üê∫</p><hr><div><h3>There was a comment section here. It's gone now.</h3><p>As of March 16th, 2025 the United Kingdom's <a href="https://en.wikipedia.org/wiki/Online_Safety_Act_2023">Online Safety Act</a> has gone into full effect. The law presents a lot of challenges for hobbyist websites like this one to present any user-to-user content (like y'know, <i>blog comments</i>) and comes with some pretty serious repercussions for non-compliance.</p><p>The odds of Ofcom (the regulator who's job is to enforce this) kicking my door down over this blog are low if we are being honest with ourselves. But the odds are at least somewhere above zero and the punishment is a life ruining <strong>¬£18 million fine(!!)</strong> so it's just not worth the risk. taking the risk.</p><p>A kind lawyer has written up the <a href="https://onlinesafetyact.co.uk/ra_blog_with_comments/">implications of this law for self-run blogs like this one</a> and the only way to guarantee that I am not in-scope would be to manually review all comments made before being available to the public. Not to be a big baby about it all but I don't really want to do this! I liked my current setup!</p><p>So I guess as a little act of protest and to hedge against any risk I've removed the comment section entirely. Sorry about that!</p><p>If you want more information on this and how much this sucks for the hobbyist internet <a href="https://lobste.rs/s/ukosa1/uk_users_lobsters_needs_your_help_with#c_xevn8a">please read this writeup</a>.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prolog Adventure Game (153 pts)]]></title>
            <link>https://github.com/stefanrodrigues2/Prolog-Adventure-game</link>
            <guid>43757916</guid>
            <pubDate>Tue, 22 Apr 2025 00:25:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/stefanrodrigues2/Prolog-Adventure-game">https://github.com/stefanrodrigues2/Prolog-Adventure-game</a>, See on <a href="https://news.ycombinator.com/item?id=43757916">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-turbo-body="">
      



    <div>
      <p><a href="#start-of-content" data-skip-target-assigned="false">Skip to content</a>

      <span data-view-component="true">
    <span data-view-component="true"></span>
</span></p>

<react-partial partial-name="keyboard-shortcuts-dialog" data-ssr="false" data-attempted-ssr="false">
  
  
  
</react-partial>




      

          

              


<header role="banner" data-is-top="true" data-color-mode="light" data-light-theme="light" data-dark-theme="dark">
  <h2>Navigation Menu</h2>

  

  <div>
          <nav aria-label="Global">
            <ul>
                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_copilot&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_copilot_link_product_navbar&quot;}" href="https://github.com/features/copilot">
      
      <div>
        <p>GitHub Copilot</p><p>
        Write better code with AI
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_advanced_security&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_advanced_security_link_product_navbar&quot;}" href="https://github.com/security/advanced-security">
      
      <div>
        <p>GitHub Advanced Security</p><p>
        Find and fix vulnerabilities
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;actions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;actions_link_product_navbar&quot;}" href="https://github.com/features/actions">
      
      <div>
        <p>Actions</p><p>
        Automate any workflow
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;codespaces&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;codespaces_link_product_navbar&quot;}" href="https://github.com/features/codespaces">
      
      <div>
        <p>Codespaces</p><p>
        Instant dev environments
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;issues&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;issues_link_product_navbar&quot;}" href="https://github.com/features/issues">
      
      <div>
        <p>Issues</p><p>
        Plan and track work
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_review&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_review_link_product_navbar&quot;}" href="https://github.com/features/code-review">
      
      <div>
        <p>Code Review</p><p>
        Manage code changes
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;discussions&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;discussions_link_product_navbar&quot;}" href="https://github.com/features/discussions">
      
      <div>
        <p>Discussions</p><p>
        Collaborate outside of code
      </p></div>

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;code_search&quot;,&quot;context&quot;:&quot;product&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;code_search_link_product_navbar&quot;}" href="https://github.com/features/code-search">
      
      <div>
        <p>Code Search</p><p>
        Find more, search less
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      
</li>


                <li>
      
      <div>
                    <p><span id="resources-explore-heading">Explore</span></p><ul aria-labelledby="resources-explore-heading">
                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;learning_pathways&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;learning_pathways_link_resources_navbar&quot;}" href="https://resources.github.com/learn/pathways">
      Learning Pathways

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;events_amp_webinars&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;events_amp_webinars_link_resources_navbar&quot;}" href="https://resources.github.com/">
      Events &amp; Webinars

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;ebooks_amp_whitepapers&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;ebooks_amp_whitepapers_link_resources_navbar&quot;}" href="https://github.com/resources/whitepapers">
      Ebooks &amp; Whitepapers

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;customer_stories&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;customer_stories_link_resources_navbar&quot;}" href="https://github.com/customer-stories">
      Customer Stories

    
</a></li>

                    <li>
  <a target="_blank" data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;partners&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;partners_link_resources_navbar&quot;}" href="https://partner.github.com/">
      Partners

    
</a></li>

                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;executive_insights&quot;,&quot;context&quot;:&quot;resources&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;executive_insights_link_resources_navbar&quot;}" href="https://github.com/solutions/executive-insights">
      Executive Insights

    
</a></li>

                </ul>
              </div>
</li>


                <li>
      
      <div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;github_sponsors&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;github_sponsors_link_open_source_navbar&quot;}" href="https://github.com/sponsors">
      
      <div>
        <p>GitHub Sponsors</p><p>
        Fund open source developers
      </p></div>

    
</a></li>

                </ul>
              </div>
              <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;the_readme_project&quot;,&quot;context&quot;:&quot;open_source&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;the_readme_project_link_open_source_navbar&quot;}" href="https://github.com/readme">
      
      <div>
        <p>The ReadME Project</p><p>
        GitHub community articles
      </p></div>

    
</a></li>

                </ul>
              </div>
              
          </div>
</li>


                <li>
      
      <div>
                <ul>
                    <li>
  <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;enterprise_platform&quot;,&quot;context&quot;:&quot;enterprise&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;enterprise_platform_link_enterprise_navbar&quot;}" href="https://github.com/enterprise">
      
      <div>
        <p>Enterprise platform</p><p>
        AI-powered developer platform
      </p></div>

    
</a></li>

                </ul>
              </div>
</li>


                <li>
    <a data-analytics-event="{&quot;location&quot;:&quot;navbar&quot;,&quot;action&quot;:&quot;pricing&quot;,&quot;context&quot;:&quot;global&quot;,&quot;tag&quot;:&quot;link&quot;,&quot;label&quot;:&quot;pricing_link_global_navbar&quot;}" href="https://github.com/pricing">Pricing</a>
</li>

            </ul>
          </nav>

        <div>
                


<qbsearch-input data-scope="repo:stefanrodrigues2/Prolog-Adventure-game" data-custom-scopes-path="/search/custom_scopes" data-delete-custom-scopes-csrf="M4vuOji49guaighiHrSnS9--O-oFMi09HV2wYCAhD4N7BMxFYquC3d1bQxroHie4_cOQeZWpBnUJvUDD_wm6jQ" data-max-custom-scopes="10" data-header-redesign-enabled="false" data-initial-value="" data-blackbird-suggestions-path="/search/suggestions" data-jump-to-suggestions-path="/_graphql/GetSuggestedNavigationDestinations" data-current-repository="stefanrodrigues2/Prolog-Adventure-game" data-current-org="" data-current-owner="stefanrodrigues2" data-logged-in="false" data-copilot-chat-enabled="false" data-nl-search-enabled="false" data-retain-scroll-position="true">
  <div data-modal-dialog-overlay="" data-action="click:qbsearch-input#searchInputContainerClicked">
  <modal-dialog data-action="close:qbsearch-input#handleClose cancel:qbsearch-input#handleClose" data-target="qbsearch-input.searchSuggestionsDialog" role="dialog" id="search-suggestions-dialog" aria-modal="true" aria-labelledby="search-suggestions-dialog-header" data-view-component="true">
      <h2 id="search-suggestions-dialog-header">Search code, repositories, users, issues, pull requests...</h2>
    
</modal-dialog></div>
  
  <div>
    
<dialog-helper>
  <dialog data-target="qbsearch-input.feedbackDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="feedback-dialog" aria-modal="true" aria-labelledby="feedback-dialog-title" aria-describedby="feedback-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="feedback-dialog-title">
        Provide feedback
      </h2>
        
    </p>
    
  </div>
      <scrollable-region data-labelled-by="feedback-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>

    <custom-scopes data-target="qbsearch-input.customScopesManager">
    
<dialog-helper>
  <dialog data-target="custom-scopes.customScopesModalDialog" data-action="close:qbsearch-input#handleDialogClose cancel:qbsearch-input#handleDialogClose" id="custom-scopes-dialog" aria-modal="true" aria-labelledby="custom-scopes-dialog-title" aria-describedby="custom-scopes-dialog-description" data-view-component="true">
    <div data-view-component="true">
    <p>
      <h2 id="custom-scopes-dialog-title">
        Saved searches
      </h2>
        <h2 id="custom-scopes-dialog-description">Use saved searches to filter your results more quickly</h2>
    </p>
    
  </div>
      <scrollable-region data-labelled-by="custom-scopes-dialog-title">
        
      </scrollable-region>
      
</dialog></dialog-helper>
    </custom-scopes>
  </div>
</qbsearch-input>


            

              <p><a href="https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=stefanrodrigues2%2FProlog-Adventure-game" data-hydro-click="{&quot;event_type&quot;:&quot;authentication.click&quot;,&quot;payload&quot;:{&quot;location_in_page&quot;:&quot;site header menu&quot;,&quot;repository_id&quot;:null,&quot;auth_type&quot;:&quot;SIGN_UP&quot;,&quot;originating_url&quot;:&quot;https://github.com/stefanrodrigues2/Prolog-Adventure-game&quot;,&quot;user_id&quot;:null}}" data-hydro-click-hmac="47b5bb1e96ab2a5691eed9fb85bb5f1cadd34712d11c688d3d741b64a453840e" data-analytics-event="{&quot;category&quot;:&quot;Sign up&quot;,&quot;action&quot;:&quot;click to sign up for account&quot;,&quot;label&quot;:&quot;ref_page:/<user-name>/<repo-name>;ref_cta:Sign up;ref_loc:header logged out&quot;}">
                Sign up
              </a>

              
          
        </p></div>
      </div>
</header>

      
    </div>

  








    


    






  <div itemscope="" itemtype="http://schema.org/SoftwareSourceCode" data-commit-hovercards-enabled="" data-discussion-hovercards-enabled="" data-issue-and-pr-hovercards-enabled="" data-project-hovercards-enabled="">
    <main id="js-repo-pjax-container">
      
  





    






  
  

  



<turbo-frame id="repo-content-turbo-frame" target="_top" data-turbo-action="advance">
    <div data-view-component="true" id="repo-content-pjax-container">      










<react-partial partial-name="repos-overview" data-ssr="true" data-attempted-ssr="true">
  
  
  <div data-target="react-partial.reactRoot"><div itemscope="" itemtype="https://schema.org/abstract"><h2>Repository files navigation</h2><nav aria-label="Repository files"><ul role="list"><li><a href="#" aria-current="page"><span data-component="icon"></span><span data-component="text" data-content="README">README</span></a></li></ul></nav></div><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Prolog-Adventure-game</h2><a id="user-content-prolog-adventure-game" aria-label="Permalink: Prolog-Adventure-game" href="#prolog-adventure-game"></a></p>
<p dir="auto">Adventure game with prolog language. The player has to find the treasure hidden inside the castle to win the game. A total of 3 lives will be available. Implemented interactive gameplay mechanics such as locked doors, hidden objects, incomplete objects, limited resources, and inventory management.</p>
</article></div></div>
</react-partial>

      </div>

</turbo-frame>


    </main>
  </div>

          



    <ghcc-consent id="ghcc" data-initial-cookie-consent-allowed="" data-cookie-consent-required="true"></ghcc-consent>



  

    <template id="site-details-dialog">
  <details class="details-reset details-overlay details-overlay-dark lh-default color-fg-default hx_rsm" open="">
    <summary role="button" aria-label="Close dialog"></summary>
    <details-dialog class="Box Box--overlay d-flex flex-column anim-fade-in fast hx_rsm-dialog hx_rsm-modal">
      <button class="Box-btn-octicon m-0 btn-octicon position-absolute right-0 top-0" type="button" aria-label="Close dialog" data-close-dialog="">
        <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-x">
    <path d="M3.72 3.72a.75.75 0 0 1 1.06 0L8 6.94l3.22-3.22a.749.749 0 0 1 1.275.326.749.749 0 0 1-.215.734L9.06 8l3.22 3.22a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L8 9.06l-3.22 3.22a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042L6.94 8 3.72 4.78a.75.75 0 0 1 0-1.06Z"></path>
</svg>
      </button>
      <div class="octocat-spinner my-6 js-details-dialog-spinner"></div>
    </details-dialog>
  </details>
</template>

    

    <template id="snippet-clipboard-copy-button">
  <div class="zeroclipboard-container position-absolute right-0 top-0">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn js-clipboard-copy m-2 p-0" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon m-2">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none m-2">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>
<template id="snippet-clipboard-copy-button-unpositioned">
  <div class="zeroclipboard-container">
    <clipboard-copy aria-label="Copy" class="ClipboardButton btn btn-invisible js-clipboard-copy m-2 p-0 d-flex flex-justify-center flex-items-center" data-copy-feedback="Copied!" data-tooltip-direction="w">
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-copy js-clipboard-copy-icon">
    <path d="M0 6.75C0 5.784.784 5 1.75 5h1.5a.75.75 0 0 1 0 1.5h-1.5a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-1.5a.75.75 0 0 1 1.5 0v1.5A1.75 1.75 0 0 1 9.25 16h-7.5A1.75 1.75 0 0 1 0 14.25Z"></path><path d="M5 1.75C5 .784 5.784 0 6.75 0h7.5C15.216 0 16 .784 16 1.75v7.5A1.75 1.75 0 0 1 14.25 11h-7.5A1.75 1.75 0 0 1 5 9.25Zm1.75-.25a.25.25 0 0 0-.25.25v7.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-7.5a.25.25 0 0 0-.25-.25Z"></path>
</svg>
      <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true" class="octicon octicon-check js-clipboard-check-icon color-fg-success d-none">
    <path d="M13.78 4.22a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.22 9.28a.751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018L6 10.94l6.72-6.72a.75.75 0 0 1 1.06 0Z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[101 BASIC Computer Games (168 pts)]]></title>
            <link>https://github.com/maurymarkowitz/101-BASIC-Computer-Games</link>
            <guid>43757341</guid>
            <pubDate>Mon, 21 Apr 2025 22:47:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/maurymarkowitz/101-BASIC-Computer-Games">https://github.com/maurymarkowitz/101-BASIC-Computer-Games</a>, See on <a href="https://news.ycombinator.com/item?id=43757341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<tr>
<td>ACEYDU</td>
<td>Play acey-ducey with the computer</td>
<td>13</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>AMAZIN</td>
<td>Computer constructs a maze</td>
<td>15</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>ANIMAL</td>
<td>Computer guesses animals and learns new ones from you</td>
<td>17</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>AWARI</td>
<td>Ancient game of rotating beans in pits</td>
<td>19</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>BAGLES</td>
<td>Guess a mystery 3-digit number by logic</td>
<td>22</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>BANNER</td>
<td>Prints any message on a large banner</td>
<td>24</td>
<td>EduSystem 50</td>
</tr>
<tr>
<td>BASBAL</td>
<td>Baseball game</td>
<td>26</td>
<td>EduSystem 15/30/35, uses CHAIN</td>
</tr>
<tr>
<td>BASKET</td>
<td>Basketball game</td>
<td>29</td>
<td>Dartmouth?</td>
</tr>
<tr>
<td>BATNUM</td>
<td>Match wits in a battle of numbers vs. the computer</td>
<td>32</td>
<td>Dartmouth?</td>
</tr>
<tr>
<td>BATTLE</td>
<td>Decode a matrix to locate enemy battleship</td>
<td>34</td>
<td>HP?</td>
</tr>
<tr>
<td>BINGO</td>
<td>Computer prints your card and calls the numbers</td>
<td>36</td>
<td>DECsystem 10</td>
</tr>
<tr>
<td>BLKJAC</td>
<td>Blackjack (very comprehensive), Las Vegas rules</td>
<td>39</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>BLKJAK</td>
<td>Blackjack (standard game)</td>
<td>42</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>BOAT</td>
<td>Destroy a gunboat from your submarine</td>
<td>43</td>
<td></td>
</tr>
<tr>
<td>BOMBER</td>
<td>Fly World War II bombing missions</td>
<td>45</td>
<td>Unclear, supports ELSE</td>
</tr>
<tr>
<td>BOUNCE</td>
<td>Plot a bouncing ball</td>
<td>47</td>
<td>generic</td>
</tr>
<tr>
<td>BOWL</td>
<td>Bowling at the neighborhood lanes</td>
<td>48</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>BOXING</td>
<td>3-round Olympic boxing match</td>
<td>50</td>
<td>generic DEC</td>
</tr>
<tr>
<td>BUG</td>
<td>Roll dice vs. the computer to draw a bug</td>
<td>52</td>
<td>HP?</td>
</tr>
<tr>
<td>BULCOW</td>
<td>Guess a mystery 5-digit number vs. the computer</td>
<td>55</td>
<td>Dartmouth?</td>
</tr>
<tr>
<td>BULEYE</td>
<td>Throw darts</td>
<td>57</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>BULL</td>
<td>You're the matador in a championship bullfight</td>
<td>59</td>
<td>generic DEC</td>
</tr>
<tr>
<td>BUNNY</td>
<td>Computer drawing of the Playboy bunny</td>
<td>62</td>
<td>No code</td>
</tr>
<tr>
<td>BUZZWD</td>
<td>Compose your speeches with the latest buzzwords</td>
<td>63</td>
<td>EduSystem</td>
</tr>
<tr>
<td>CALNDR</td>
<td>Calendar for any year</td>
<td>65</td>
<td>EduSystem</td>
</tr>
<tr>
<td>CAN-AM</td>
<td>Drive a Group 7 car in a Can-Am road race</td>
<td>67</td>
<td>Dartmouth</td>
</tr>
<tr>
<td>CHANGE</td>
<td>Computer imitates a cashier</td>
<td>72</td>
<td>EduSystem</td>
</tr>
<tr>
<td>CHECKR</td>
<td>Game of checkers</td>
<td>73</td>
<td></td>
</tr>
<tr>
<td>CHEMST</td>
<td>Dilute kryptocyanic acid to make it harmless</td>
<td>76</td>
<td>generic</td>
</tr>
<tr>
<td>CHIEF</td>
<td>Silly arithmetic drill</td>
<td>77</td>
<td>EduSystem</td>
</tr>
<tr>
<td>CHOMP</td>
<td>Eat a cookie avoiding the poison piece (2 or more players)</td>
<td>78</td>
<td>generic</td>
</tr>
<tr>
<td>CIVILW</td>
<td>Fight the Civil War</td>
<td>80</td>
<td>generic</td>
</tr>
<tr>
<td>CRAPS</td>
<td>Play craps (dice), Las Vegas style</td>
<td>83</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>CUBE</td>
<td>Negotiate a 3-D cube avoiding hidden landmines</td>
<td>85</td>
<td>generic</td>
</tr>
<tr>
<td>DIAMND</td>
<td>Prints 1-page diamond patterns</td>
<td>87</td>
<td>BASIC-8/EduSystem</td>
</tr>
<tr>
<td>DICE</td>
<td>Summarizes dice rolls</td>
<td>89</td>
<td>BASIC-8/EduSystem</td>
</tr>
<tr>
<td>DIGITS</td>
<td>Computer tries to guess digits you select at random</td>
<td>91</td>
<td>BASIC-PLUS?</td>
</tr>
<tr>
<td>DOGS</td>
<td>Penny arcade dog race</td>
<td>93</td>
<td>EduSystem 50</td>
</tr>
<tr>
<td>EVEN</td>
<td>Take objects from a pile--try to end with an even number</td>
<td>96</td>
<td></td>
</tr>
<tr>
<td>EVEN1</td>
<td>Same as EVEN--computer improves its play</td>
<td>98</td>
<td></td>
</tr>
<tr>
<td>FIPFOP</td>
<td>Solitaire logic game--change a row of Xs to Os</td>
<td>99</td>
<td></td>
</tr>
<tr>
<td>FOOTBL</td>
<td>Professional football (very comprehensive)</td>
<td>101</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>FOOTBAL</td>
<td>High School football</td>
<td>104</td>
<td></td>
</tr>
<tr>
<td>FURS</td>
<td>Trade furs with the white man</td>
<td>106</td>
<td></td>
</tr>
<tr>
<td>GOLF</td>
<td>Golf game‚Äîchoose your clubs and swing</td>
<td>109</td>
<td></td>
</tr>
<tr>
<td>GOMOKO</td>
<td>Ancient board game of logic and strategy</td>
<td>110</td>
<td></td>
</tr>
<tr>
<td>GUESS</td>
<td>Guess a mystery number‚Äîcomputer gives you clues</td>
<td>113</td>
<td>EduSystem 20</td>
</tr>
<tr>
<td>GUNNER</td>
<td>Fire a cannon at a stationary target</td>
<td>115</td>
<td></td>
</tr>
<tr>
<td>GUNER1</td>
<td>Fire a cannon at a moving target</td>
<td>116</td>
<td>generic</td>
</tr>
<tr>
<td>HANG</td>
<td>Hangman word guessing game</td>
<td>118</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>HELLO</td>
<td>Computer becomes your friendly psychiatrist</td>
<td>120</td>
<td>EduSystem 25</td>
</tr>
<tr>
<td>HEX</td>
<td>Hexapawn game</td>
<td>122</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>HI-LO</td>
<td>Try to hit the mystery jackpot</td>
<td>124</td>
<td></td>
</tr>
<tr>
<td>HI-Q</td>
<td>Try to remove all the pegs from a board</td>
<td>126</td>
<td></td>
</tr>
<tr>
<td>HMRABI</td>
<td>Govern the ancient city-state of Sumeria</td>
<td>128</td>
<td>generic</td>
</tr>
<tr>
<td>HOCKEY</td>
<td>Ice hockey vs. Cornell</td>
<td>130</td>
<td></td>
</tr>
<tr>
<td>HORSES</td>
<td>Off-track betting on a horse race</td>
<td>133</td>
<td></td>
</tr>
<tr>
<td>HURKLE</td>
<td>Find the Hurkle hiding on a 10x10 grid</td>
<td>135</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>KINEMA</td>
<td>Drill in simple kinematics</td>
<td>137</td>
<td>generic</td>
</tr>
<tr>
<td>KING</td>
<td>Govern a modern island kingdom wisely</td>
<td>138</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>LETTER</td>
<td>Guess a mystery letter‚Äîcomputer gives you clues</td>
<td>141</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>LIFE</td>
<td>John Conway's Game of Life</td>
<td>143</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>LIFE-2</td>
<td>Competitive game of life (2 or more players)</td>
<td>146</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>LITQZ</td>
<td>Children's literature quiz</td>
<td>148</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>MATHD</td>
<td>Children's arithmetic drill using pictures of dice</td>
<td>151</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>MNOPLY</td>
<td>Monopoly for 2 players</td>
<td>153</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>MUGWMP</td>
<td>Locate 4 Mugwumps hiding on a 10x10 grid</td>
<td>156</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>NICOMA</td>
<td>Computer guesses number you think of</td>
<td>158</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>NIM</td>
<td>Chinese game of Nim</td>
<td>160</td>
<td>EduSystem 30?</td>
</tr>
<tr>
<td>NUMBER</td>
<td>Silly number matching game</td>
<td>162</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>1CHECK</td>
<td>Challenging game to remove checkers from a board</td>
<td>163</td>
<td>unknown, uses USING</td>
</tr>
<tr>
<td>ORBIT</td>
<td>Destroy an orbiting germ-laiden enemy spaceship</td>
<td>165</td>
<td>generic</td>
</tr>
<tr>
<td>PIZZA</td>
<td>Deliver pizzas successfully</td>
<td>167</td>
<td></td>
</tr>
<tr>
<td>POETRY</td>
<td>Computer composes poetry in 4-part harmony</td>
<td>169</td>
<td>generic</td>
</tr>
<tr>
<td>POET</td>
<td>Computer composes random poetry</td>
<td>171</td>
<td>EduSystem ?</td>
</tr>
<tr>
<td>POKER</td>
<td>Poker game</td>
<td>172</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>QUBIC</td>
<td>3-dimensional tic-tac-toe</td>
<td>174</td>
<td>generic</td>
</tr>
<tr>
<td>QUEEN</td>
<td>Move a single chess queen vs. the computer</td>
<td>178</td>
<td>unknown, line 99999</td>
</tr>
<tr>
<td>REVERSE</td>
<td>Order a series of numbers by reversing</td>
<td>178</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>ROCKET</td>
<td>Land an Apollo capsule on the moon</td>
<td>180</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>ROCKT1</td>
<td>Lunar landing from 500 feet (with plot)</td>
<td>183</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>ROCKT2</td>
<td>Very comprehensive lunar landing</td>
<td>185</td>
<td>generic</td>
</tr>
<tr>
<td>ROCKSP</td>
<td>Game of rock, scissors, paper</td>
<td>188</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>ROULET</td>
<td>European roulette table</td>
<td>189</td>
<td>generic</td>
</tr>
<tr>
<td>RUSROU</td>
<td>Russian roulette</td>
<td>192</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>SALVO</td>
<td>Destroy an enemy fleet of ships</td>
<td>193</td>
<td>generic</td>
</tr>
<tr>
<td>SALVO1</td>
<td>Destroy 4 enemy outposts</td>
<td>195</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>SLOTS</td>
<td>Slot machine (one-arm bandit)</td>
<td>196</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>SNOOPY</td>
<td>Pictures of Snoopy</td>
<td>208</td>
<td>No code</td>
</tr>
<tr>
<td>SPACWR</td>
<td>Comprehensive game of spacewar</td>
<td>210</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>SPLAT</td>
<td>Open a parachute at the last possible moment</td>
<td>205</td>
<td>EduSystem ?</td>
</tr>
<tr>
<td>STARS</td>
<td>Guess a mystery number‚Äîstars give you clues</td>
<td>207</td>
<td>generic</td>
</tr>
<tr>
<td>STOCK</td>
<td>Stock market simulation</td>
<td>209</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>SYNONM</td>
<td>Word synonym drill</td>
<td>212</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>TARGET</td>
<td>Destroy a target in 3-D space‚Äîvery tricky</td>
<td>214</td>
<td>EduSystem ?</td>
</tr>
<tr>
<td>3D PLOT</td>
<td>Plots families of curves‚Äîlooks 3-dimensional</td>
<td>216</td>
<td>generic</td>
</tr>
<tr>
<td>TICTAC</td>
<td>Tic-tac-toe</td>
<td>218</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>TOWER</td>
<td>Towers of Hanoi puzzle</td>
<td>221</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>TRAIN</td>
<td>Time-speed-distance quiz</td>
<td>223</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>TRAP</td>
<td>Trap a mystery number‚Äîcomputer gives you clues</td>
<td>224</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>23MTCH</td>
<td>Game of 23 matches‚Äîtry not to take the last one</td>
<td>226</td>
<td></td>
</tr>
<tr>
<td>UGLY</td>
<td>Silly profile plot of an ugly woman</td>
<td>228</td>
<td>BASIC-8</td>
</tr>
<tr>
<td>WAR</td>
<td>Card game of war</td>
<td>230</td>
<td>generic</td>
</tr>
<tr>
<td>WAR-2</td>
<td>Troop tactics in war</td>
<td>232</td>
<td>EduSystem 30</td>
</tr>
<tr>
<td>WEKDAY</td>
<td>Facts about your birthday</td>
<td>234</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>WORD</td>
<td>Word guessing game</td>
<td>236</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>YAHTZE</td>
<td>Dice game of Yahtzee</td>
<td>238</td>
<td>BASIC-PLUS</td>
</tr>
<tr>
<td>ZOOP</td>
<td>BASIC programmer's nightmare</td>
<td>243</td>
<td>EduSystem 15/30/35</td>
</tr>
</div></div>]]></description>
        </item>
    </channel>
</rss>