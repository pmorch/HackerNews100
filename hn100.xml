<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 11 Feb 2025 13:30:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Jeep Introduces Pop-Up Ads That Appear Every Time You Stop (244 pts)]]></title>
            <link>https://tech.slashdot.org/story/25/02/11/0016258/jeep-introduces-pop-up-ads-that-appear-every-time-you-stop</link>
            <guid>43009682</guid>
            <pubDate>Tue, 11 Feb 2025 06:34:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tech.slashdot.org/story/25/02/11/0016258/jeep-introduces-pop-up-ads-that-appear-every-time-you-stop">https://tech.slashdot.org/story/25/02/11/0016258/jeep-introduces-pop-up-ads-that-appear-every-time-you-stop</a>, See on <a href="https://news.ycombinator.com/item?id=43009682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="fhbody-176175319">
	
		
	

	
		
		<p>
			
		 	
				"<a href="https://techstory.in/stellantis-introduces-pop-up-ads-in-vehicles-sparking-outrage-among-owners/">In-dash advertising is here</a> and Stellantis, the parent company of Jeep, Dodge, Chrysler, and Ram, beat everyone to <a href="https://tech.slashdot.org/story/25/02/06/0454231/the-enshittification-hall-of-shame">further enshittification</a>," writes longtime Slashdot reader <a href="https://tech.slashdot.org/~sinij">sinij</a>. "Ads can be seen in <a href="https://www.youtube.com/watch?v=A31PkJaTZqU">this video</a>." From a report: <i> In a move that has left drivers both frustrated and bewildered, Stellantis has introduced full-screen pop-up ads on its infotainment systems. Specifically, Jeep owners have reported being bombarded with advertisements for Mopar's extended warranty service. The kicker? These ads appear every time the vehicle comes to a stop. Imagine pulling up to a red light, checking your GPS for directions, and suddenly, the entire screen is hijacked by an ad. That's the reality for some Stellantis owners. Instead of seamless functionality, drivers are now forced to manually close out of ads just to access basic vehicle functions.
<p> 
One Jeep 4xe owner recently shared their frustration on an online forum, detailing how these pop-ups disrupt the driving experience. Stellantis, responding through their "JeepCares" representative, confirmed that these ads are part of the contractual agreement with SiriusXM and suggested that users simply tap the "X" to dismiss them. While the company claims to be working on reducing the frequency of these interruptions, the damage to customer trust may already be done.</p></i><br>
		 	
		</p>

		

		

		
			
		
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta's Hyperscale Infrastructure: Overview and Insights (183 pts)]]></title>
            <link>https://cacm.acm.org/research/metas-hyperscale-infrastructure-overview-and-insights/</link>
            <guid>43008920</guid>
            <pubDate>Tue, 11 Feb 2025 04:19:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cacm.acm.org/research/metas-hyperscale-infrastructure-overview-and-insights/">https://cacm.acm.org/research/metas-hyperscale-infrastructure-overview-and-insights/</a>, See on <a href="https://news.ycombinator.com/item?id=43008920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div lang="en"><section id="sec1"><p id="p-1">Hyperscalers, such as Alibaba, Amazon, ByteDance, Google, Meta, Microsoft, and Tencent, have developed planetary-scale infrastructure to deliver cloud, Web, or mobile services to their global users. And though most practitioners may not directly build such hyperscale infrastructure, we believe it is beneficial to learn a bit about it. Historically, many widely used technologies have originated from advanced environments, including mainframes in the 1960s and hyperscale infrastructure in the past two decades. For instance, virtual memory had its origin in mainframes and is now common even in smartwatches. Similarly, Kubernetes and PyTorch originated in Google and Facebook, respectively, but have been adopted by organizations of all sizes. In addition to these specific technologies, the principles and lessons from hyperscale infrastructure may assist practitioners in building better systems in general.</p><p id="p-2">This article provides a high-level overview of Meta’s hyperscale infrastructure, focusing on key insights from its development, particularly in systems software. Where relevant, we highlight differences from public clouds, as varying constraints have led to distinct optimizations. While much of the knowledge presented here has been shared and practiced within the industry and research community, including insights from our past publications, the article’s primary contribution is to provide a holistic perspective that helps readers build a comprehensive mental model of hyperscale infrastructure end to end.</p><div><h2>Key Insights</h2><ul data-jats-list-type="bullet"><li><p id="p-3">Meta’s engineering culture emphasizes moving fast, technology openness, research in production, and shared infrastructure.</p></li><li><p id="p-4">To boost developer productivity, Meta has adopted continuous deployment universally and enabled more developers to write serverless functions rather than traditional service code.</p></li><li><p id="p-5">To reduce hardware costs, Meta utilizes hardware-software co-design at the datacenter scale and autonomously optimizes resource allocations, including workload migration, across global datacenters instead of limiting them to individual clusters.</p></li><li><p id="p-6">Meta’s AI strategy involves co-designing the entire stack, from PyTorch to AI accelerators, networks, and ML models such as Llama.</p></li></ul></div></section><section id="sec2"><h2>Engineering Culture</h2><p id="p-7">Before delving into the details of Meta’s infrastructure, we first highlight several aspects of the company’s engineering culture, because an organization’s culture heavily influences its technology.</p><section id="sec3"><p data-jats-content-type="inline-heading"><strong>Move fast.</strong>&nbsp; Since its inception, Facebook has ingrained and retained the “move-fast” culture, emphasizing agility and rapid iteration. This philosophy is evident in its strong commitment to continuous software deployment, which involves releasing the latest code into production as early as possible. Additionally, product engineers predominantly write code in stateless, serverless functions in PHP, Python, and Erlang for their benefits in simplicity, productivity, and iteration speed. Teams have the ability to quickly pivot their execution priorities without undergoing a lengthy replanning process, leaving ambiguous issues to be sorted out during iterative execution. This allows teams to quickly adapt and launch new products in response to evolving market conditions.</p></section><section id="sec4"><p data-jats-content-type="inline-heading"><strong>Technology openness.</strong>&nbsp; Meta champions technology openness, both internally and externally. Internally, we adopt the monorepo approach, storing the code for all projects in a single repository to facilitate code discovery and reuse, as well as cross-team contributions. While other organizations also use monorepos, they vary in the degree of openness. Some require designated owners for each project, with only these owners authorized to accept code changes, although others may propose changes. In contrast, with few exceptions, the vast majority of projects at Meta do not enforce such strict ownership rules. This openness encourages cross-team contributions and code reuse while discouraging the reinvention of similar technologies.</p><p id="p-10">At Meta, engineers directly commit code changes to the mainline of the monorepo, and software deployments are compiled from the mainline, that is, from the latest code, as opposed to some stable branches. For example, when a widely used library, such as the RPC library, is updated, the next release of every application dependent on this library will be automatically compiled with the latest version.</p><p id="p-11">Externally, Meta’s commitment to technology openness is demonstrated through its open-source hardware designs via the Open Compute Project<a href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a> and open-source software projects such as PyTorch, Llama, Presto, RocksDB, and Cassandra. Also, much of Meta’s infrastructure technology has been shared through research papers, with many examples in this article’s references.</p></section><section id="sec5"><p data-jats-content-type="inline-heading"><strong>Research in production.</strong>&nbsp; Meta’s hyperscale infrastructure requires continuous innovation, but unlike most hyperscalers, the company does not have a dedicated systems research lab. Instead, all of its systems research papers are authored by teams developing production systems. These teams advance the state of the art while tackling challenging production issues at scale, then reflect on these experiences to distill working solutions into research papers. This approach ensures that the addressed problems are real and the solutions work at scale, aligning well with key criteria for successful systems research.</p></section><section id="sec6"><p data-jats-content-type="inline-heading"><strong>Common infrastructure.</strong>&nbsp; While some organizations empower individual teams to make local decisions about their technology stack, Meta prioritizes standardization and global optimization. On the hardware side, servers supporting different products are all allocated from a shared server pool.<a href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> Moreover, for non-AI compute workloads, we offer only a single server type, equipped with one CPU and the same amount of DRAM (previously 64GB, now 256GB). Unlike public clouds, which must provide various server types to accommodate diverse customer applications, Meta can optimize its applications to suit the hardware, thereby avoiding the proliferation of server types.</p><p id="p-14">Standardization also prevails on the software side. For instance, different Meta products previously used Cassandra, HBase, and ZippyDB<a href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> for key-value stores, but now all have converged to ZippyDB. Further, each common capability—such as software deployment,<a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> configuration management,<a href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> service mesh,<a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> pre-production performance testing,<a href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a> in-production performance monitoring,<a href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a> and in-production load testing<a href="#B35" data-jats-ref-type="bibr" data-jats-rid="B35"><sup>35</sup></a>—is supported by a universally adopted tool.</p><p id="p-15">Besides standardization, a key principle in achieving common infrastructure is our preference for reusable components over monolithic solutions. A good example of this is the component-reuse chain in our distributed file system, Tectonic.<a href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a> Tectonic enhances scalability by using a distributed key-value store, ZippyDB,<a href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> to store its metadata. ZippyDB further employs a common sharding framework, Shard Manager, to manage its data shards; Shard Manager, in turn, depends on Meta’s mesh, ServiceRouter,<a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> for shard discovery and request routing. Finally, ServiceRouter stores the service discovery and configuration data of the entire infrastructure, which is critical for the site’s continuous operation, in the highly reliable, zero-dependency data store Delos.<a href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> Therefore, the component-reuse chain is Tectonic→ZippyDB→Shard Manager→ServiceRouter→Delos. All of these reusable components also serve many other use cases. In contrast, HDFS, a popular open-source distributed file system, is a monolithic system that implements all of these components internally.</p></section><section id="sec7"><p data-jats-content-type="inline-heading"><strong>Culture case study: The Threads app.</strong>&nbsp; The development of the Threads app,<a href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a> often compared to Twitter/X, exemplifies the aforementioned culture. Emphasizing moving fast, a small team developed Threads with just five months of technical work in a startup-like environment. Moreover, once it was developed, the infrastructure teams were given only two day’s notice to prepare for its production launch. Most large organizations would take longer than two days just to draft a project plan involving dozens of interdependent teams, let alone execute it. At Meta, however, we quickly established war rooms across distributed sites, bringing together both infrastructure and product teams to address issues in real-time. Despite the tight timeline, the app’s launch was highly successful, reaching 100 million users within just five days, making it the fastest-growing app in history.<a href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a></p><p id="p-17">Common infrastructure was crucial for enabling teams to swiftly implement Threads and scale it reliably. Threads reused Instagram’s Python backend as well as Meta’s shared infrastructure components, such as the social-graph database,<a href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> key-value store,<a href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a> serverless platform,<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a>&nbsp;machine-learning (ML) training and inference platforms,<a href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> and configuration-management framework for mobile apps.<a href="#B20" data-jats-ref-type="bibr" data-jats-rid="B20"><sup>20</sup></a></p><p id="p-18">Meta’s internal technology openness, using a monorepo, allowed Threads to reuse some Instagram application code to accelerate its development. In terms of external technology openness, Threads aims to integrate with ActivityPub, the open social networking protocol, for interoperability with other apps. We have also publicly shared our experiences of rapidly developing Threads.<a href="#B6" data-jats-ref-type="bibr" data-jats-rid="B6"><sup>6</sup></a></p></section></section><section id="sec8"><h2>End-to-End User Request Flow</h2><p id="p-20">We now dive into Meta’s infrastructure technology. Meta products are supported by a shared service infrastructure. To provide a holistic view of this infrastructure, we explain how a user request is processed end-to-end, detailing all the components involved.</p><section id="sec9"><p><strong>Request routing.</strong></p><section id="sec10"><p data-jats-content-type="inline-heading"><em>Dynamic DNS mapping.</em>&nbsp; When a user initiates a request to facebook.com, Meta’s DNS server dynamically returns an IP address that is mapped to a Meta-operated small edge datacenter, known as point of presence (PoP), as depicted in Figure <a href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>. This dynamic DNS mapping ensures that the chosen PoP is close to the user, while balancing load across PoPs. The user’s TCP connection is terminated at the PoP, which maintains separate, long-lived TCP connections with Meta’s datacenters. This split-TCP setup offers several advantages, including reduced TCP-establishment latency through the reuse of pre-established connections between PoPs and datacenters. A PoP typically has hundreds of servers but may have up to a few thousand. Hundreds of PoPs are positioned worldwide to ensure that most users have a PoP close to them, thereby ensuring short network latencies.</p><figure id="F1" data-jats-position="float"><p><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig01.jpg" data-type="image" data-caption="Figure 1. Meta’s global infrastructure." href="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig01.jpg">
				<img decoding="async" title="Figure 1. Meta’s global infrastructure." src="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig01.jpg" alt="Meta’s global infrastructure." data-image-id="F1" data-image-type="figure">
			</a>
		</p><figcaption><span>Figure 1.&nbsp;</span> <span>Meta’s global infrastructure.</span></figcaption></figure></section><section id="sec11"><p data-jats-content-type="inline-heading"><em>Static-content caching.&nbsp;</em> If the user request is for static content, such as images and videos, it can be directly served at the PoP if the content is already cached there. Additionally, static content may be cached by the content delivery network (CDN), as shown in Figure <a href="#F1" data-jats-ref-type="fig" data-jats-rid="F1">1</a>. When a significant volume of Meta product traffic originates from an Internet service provider’s (ISP’s) network, Meta seeks to establish a mutually beneficial partnership by providing Meta Network Appliances to be hosted in the ISP’s network to cache static content, thereby forming a CDN site. A CDN site typically has tens of servers, with some having over a hundred. Thousands of CDN sites across the globe form our CDN for distributing static content.</p><p id="p-23">Meta products use URL rewrites to redirect user requests to a nearby CDN site. When a Meta product provides a URL for a user to access static content, it rewrites the URL, for example, from <code>facebook.com/image.jpg</code> to <code>CDN109.meta.com/image.jpg.</code> If the image is not cached at CDN109 when the user requests it, CDN109 forwards the request to a nearby PoP. The PoP then forwards the request to the load balancer in a datacenter region, which retrieves the image from the storage system. On the return path, both the PoP and the CDN site cache the image for future use.</p></section><section id="sec12"><p data-jats-content-type="inline-heading"><em>Dynamic-content request routing.&nbsp;</em> If the user request is for dynamic content like a newsfeed, the PoP forwards it to a datacenter region. The selection of the target region is guided by a traffic-engineering tool<a href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a> that periodically computes the optimal distribution of global traffic from PoPs to datacenters, considering factors such as datacenter capacity and network latency.</p><p id="p-25">PoP-to-datacenter traffic travels through Meta’s private wide-area network (WAN),<a href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> which globally interconnects Meta’s PoPs and datacenters using optical fibers spanning tens of thousands of miles. Internal network traffic among our datacenters and PoPs significantly surpasses external-facing traffic between users and PoPs by several orders of magnitude, primarily due to data replication across datacenters and interactions among our microservices. The private WAN provides high bandwidth to serve this internal traffic.</p></section></section><section id="sec13"><p data-jats-content-type="inline-heading"><strong>Infrastructure topology.</strong>&nbsp; Table &nbsp;<a href="#T1" data-jats-ref-type="table" data-jats-rid="T1">1</a> &nbsp;summarizes the aforementioned infrastructure components. Globally, there are tens of datacenter regions, hundreds of edge datacenters (PoPs), and thousands of CDN sites. Each datacenter region has multiple datacenters located within the radius of a few miles. Each datacenter uses up to a dozen main switchboards (MSBs) for power distribution, which also act as the primary sub-datacenter fault domains. An MSB failure can render 10 to 20 thousand servers unavailable.</p><figure id="T1" data-jats-position="float"><div><p><span>Table 1.&nbsp;</span></p><p>Number and size of infrastructure components.</p></div><div><table data-jats-frame="hsides" data-jats-rules="rows"><colgroup> <col> <col> <col> </colgroup><thead><tr><th>Entity type</th><th>Entity count</th><th>Servers in each entity</th></tr></thead><tbody><tr><td>Region</td><td>O(10)</td><td>Up to one million</td></tr><tr><td>PoP</td><td>O(100)</td><td>Typically O(100) but up to O(1,000)</td></tr><tr><td>CDN site</td><td>O(1,000)</td><td>Typically O(10) but up to 100+</td></tr><tr><td>Datacenter</td><td>Multiple datacenters per region</td><td>O(100,000)</td></tr><tr><td>MSB</td><td>Up to a dozen MSBs per datacenter</td><td>Typically 10K to 20K</td></tr></tbody></table></div></figure><section id="sec14"><p data-jats-content-type="inline-heading"><em>Edge network.</em>&nbsp; A PoP is connected to multiple autonomous systems on the Internet and typically has multiple paths to reach a user network. When choosing a path between a PoP and a user, Border Gateway Protocol (BGP), by default, does not consider network capacity and performance. The PoP’s network, however, takes these factors into consideration and advertises its preferred route to a network prefix.<a href="#B32" data-jats-ref-type="bibr" data-jats-rid="B32"><sup>32</sup></a></p></section><section id="sec15"><p data-jats-content-type="inline-heading"><em>Datacenter network.&nbsp;</em> Servers in a datacenter are interconnected by a datacenter fabric,<a href="#B2" data-jats-ref-type="bibr" data-jats-rid="B2"><sup>2</sup></a> where network switches form a three-level Clos topology that can be scaled incrementally by adding more switches at the top level. With a sufficient number of top-level switches, the fabric can provide a non-blocking and non-oversubscribed network, enabling communication between any two servers at their full NIC bandwidth. We are moving toward eliminating network oversubscription within a datacenter.</p></section><section id="sec16"><p data-jats-content-type="inline-heading"><em>Regional network.&nbsp;</em> A fabric aggregator<a href="#B14" data-jats-ref-type="bibr" data-jats-rid="B14"><sup>14</sup></a> connects datacenters within a region and further connects them to our private WAN. The fabric aggregator employs a topology akin to the fat-tree, enabling the incremental addition of more switches to boost bandwidth. We aim to significantly reduce network oversubscription in a region so that cross-datacenter communication within a region is not a bottleneck. This allows most services, except for ML training, to be scattered across datacenters in a region without worrying about a significant performance penalty.</p></section></section><section id="sec17"><p><strong>Request processing.</strong></p><section id="sec18"><p data-jats-content-type="inline-heading"><em>Online processing.&nbsp;</em> When a user request reaches a datacenter region, it is processed along the path depicted in Figure&nbsp;<a href="#F2" data-jats-rid="F2" data-jats-ref-type="fig">2</a>. The load balancer spreads user requests across tens of thousands of servers that execute “frontend serverless functions.” To process a user request, a frontend serverless function may invoke many backend services, some of which may further call “ML inference,” for example, to retrieve recommendations for ads or newsfeed content.</p><figure id="F2" data-jats-position="float"><p><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig02.jpg" data-type="image" data-caption="Figure 2. High-level architecture of software components running in a datacenter region. This is a highly simplified diagram, as Meta internally has O(10,000) backend services that exhibit a complex call graph." href="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig02.jpg">
				<img decoding="async" title="Figure 2. High-level architecture of software components running in a datacenter region. This is a highly simplified diagram, as Meta internally has O(10,000) backend services that exhibit a complex call graph." src="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig02.jpg" alt="High-level architecture of software components running in a datacenter region. This is a highly simplified diagram, as Meta internally has O(10,000) backend services that exhibit a complex call graph." data-image-id="F2" data-image-type="figure">
			</a>
		</p><figcaption><span>Figure 2.&nbsp;</span><span>High-level architecture of software components running in a datacenter region. This is a highly simplified diagram, as Meta internally has O(10,000) backend services that exhibit a complex call graph.</span></figcaption></figure><p id="p-32">During its execution, a frontend serverless function can enqueue events in the “event queue” for “event-driven serverless functions”<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> to process asynchronously. One such event could be sending a confirmation email after the user performs an action on the site. While frontend serverless functions directly affect user-perceived response time and hence have a tight latency service-level objective (SLO), event-driven serverless functions work asynchronously without affecting user-perceived response time, and are optimized for throughput and hardware utilization instead of latency. The ratio of servers executing frontend serverless functions to event-driven serverless functions is approximately 5:1.</p></section><section id="sec19"><p data-jats-content-type="inline-heading"><em>Offline processing.&nbsp;</em> The components on the right side of Figure <a href="#F2" data-jats-rid="F2" data-jats-ref-type="fig">2</a> perform various offline processing to assist online processing on the left side. Decoupling online and offline processing enables independent optimization based on their respective workload characteristics. When handling user requests, frontend serverless functions and backend services log various types of data, such as ad-click-through or video-watch metrics, into the “data warehouse.” This data feeds various offline processing. For instance, “ML training”<a href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> uses the data to update ML models, while “stream processing” can use the data to update the most-discussed topics on the site and store them in “databases and caches,” which are then used during online user-request processing. Additionally, “batch analytics,” powered by Spark and Presto, can periodically perform operations such as updating friend recommendations in response to new activities on the site. Finally, data updates in the data warehouse serve as a primary event source that triggers the execution of event-driven serverless functions.<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a></p></section></section></section><section id="sec20"><h2>Boosting Developer Productivity</h2><p id="p-35">A main purpose of a shared infrastructure is to boost developer productivity. While it is widely recognized that continuous software deployment and serverless functions can help boost developer productivity, we have taken these approaches to the extreme.</p><section id="sec21"><p data-jats-content-type="inline-heading"><strong>Continuous deployment.</strong>&nbsp; Aligning with the move-fast culture, we take continuous deployment of both code and configuration to extreme speeds and scales. It enables developers to quickly release new features and bug fixes, receive immediate feedback, and iterate rapidly.</p><p id="p-37">For configuration changes, our configuration-management tool<a href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> deploys more than 100,000 live changes daily in production, spanning O(10,000) services and millions of servers. These changes facilitate a variety of tasks, including load balancing,<a href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a><sup>,</sup><a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> feature rollouts, A/B tests, and overload protection.<a href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> At Meta, nearly every engineer who writes code also makes live configuration changes in production. Following the configuration-as-code paradigm, manual configuration changes undergo peer code review before being committed to a code repository. Once committed, these changes immediately enter the continuous deployment pipeline. Within seconds, the updated configuration can be pushed to potentially millions of subscribed Linux processes, triggering an upcall notification. The processes can immediately adjust their runtime behavior without restarts. In addition to manual changes, automation tools also drive configuration changes, for example, for load balancing.<a href="#B9" data-jats-ref-type="bibr" data-jats-rid="B9"><sup>9</sup></a><sup>,</sup><a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a></p><p id="p-38">For code changes, our deployment tool<a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> manages more than 30,000 pipelines to deploy software upgrades. At Meta, 97% of services adopt fully automated software deployments without any manual intervention: 55% utilize continuous deployment, instantly deploying every code change to production after passing automated tests, while the remaining 42% are automatically deployed on a fixed schedule, mostly daily or weekly. Take the frontend serverless functions in Figure <a href="#F2" data-jats-rid="F2" data-jats-ref-type="fig">2</a> as an example. They run on more than half a million servers, with more than 10,000 product developers changing their code and thousands of code commits every workday. Despite this extremely dynamic environment, a new version of all serverless functions is released into production every three hours.</p><p id="p-39">Even our network software is designed like regular services and optimized for frequent updates. For example, our private WAN<a href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> divides its network topology into multiple parallel planes, each responsible for a portion of the traffic and equipped with its own controller. This enables frequent updates of the controller software. Developers can experiment with new control algorithms by diverting traffic from one plane and deploying the new algorithm exclusively within that plane, without affecting other planes. Similarly, our network switch software<a href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> undergoes frequent updates, just like standard services. Leveraging the switch ASIC’s “warm boot” feature, the data plane keeps forwarding traffic while the switch software undergoes an update.</p><p id="p-40">Frequent code and configuration updates enable agile software development but increase the risk of site outages. To address this risk, we invest heavily in testing, staged rollouts, and health checks during updates.<a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a><sup>,</sup><a href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> Previously, we launched a company-wide campaign to boost code-deployment automation, increasing the adoption of fully automated code deployment guarded by health checks from 12% to 97%. Similarly, we implemented another initiative to ensure that all configuration changes undergo automated canary tests to uphold configuration safety. Overall, we find these investments in continuous deployment worthwhile, as it significantly boosts developer productivity.</p></section><section id="sec22"><p data-jats-content-type="inline-heading"><strong>Serverless functions.</strong>&nbsp; The widespread use of serverless functions (also known as function-as-a-service or FaaS) is another key driver that boosts developer productivity. Unlike traditional backend services, which can exhibit arbitrary complexity, FaaS is stateless and implements a simple function interface.<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> Each FaaS invocation is managed independently, with no side effects on other concurrent invocations, except through states stored in external databases. Due to its stateless nature, FaaS relies heavily on external caching systems<a href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a><sup>,</sup><a href="#B27" data-jats-ref-type="bibr" data-jats-rid="B27"><sup>27</sup></a> to achieve good performance when accessing databases.</p><p id="p-43">Developers write FaaS code and leave it to the infrastructure to handle everything else through automation, including code deployment and auto-scaling in response to load changes. This simplicity allows Meta’s more than 10,000 product developers to focus solely on product logic without concern for infrastructure management. Moreover, it prevents hardware waste caused by product developers over-provisioning resources.</p><p id="p-44">Meta takes the usage of FaaS to the extreme to maximize developer productivity. Among O(10,000) engineers at Meta, the number of engineers writing FaaS code is about 50% greater than those writing code for regular services that they operate by themselves. This success is attributed not only to relieving product engineers of managing infrastructure but also to the usability of the integrated development environment (IDE) for FaaS. This IDE enables easy access to the social-graph database<a href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> and various backend systems through high-level language constructs. It also provides fast feedback through continuous integration tests.</p><p id="p-45">As shown in Figure <a href="#F2" data-jats-rid="F2" data-jats-ref-type="fig">2</a>, Meta operates two FaaS platforms: one for “frontend serverless functions” and another for “event-driven serverless functions.” We refer to them as <i>FrontFaaS</i> and <i>XFaaS,</i><a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> respectively. FrontFaaS functions are written in PHP (we also have FaaS platforms for Python, Erlang, and Haskell functions). To support the high load generated by billions of users, we maintain over half a million servers that keep the PHP runtime running at all times. When a user request arrives, it is routed to one of these servers for immediate processing, without experiencing cold start time. When the site’s load is low, we utilize auto-scaling to release some FrontFaaS servers for other services to use.</p><p id="p-46">XFaaS shares many similarities with FrontFaaS, the key difference being that it executes non-user-facing functions that do not require sub-second response times but exhibit a highly spiky load pattern.<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> To avoid overprovisioning resources for peak loads, XFaaS employs a combination of optimizations to spread out function execution, including deferring the execution of delay-tolerant functions to off-peak hours, globally load-balancing function calls across regions, and implementing throttling based on quotas.</p><p id="p-47">Product developers at Meta have been using FaaS as their primary coding paradigm since the late 2000s, even before the term <i>FaaS</i> became popular. Compared with serverless platforms in the industry, a unique aspect of our serverless platforms is that they allow multiple functions to execute concurrently in the same Linux process for higher hardware efficiency,<a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a> unlike public clouds that have to execute one function per virtual machine in order to ensure stronger isolation between different customers.</p></section></section><section id="sec23"><h2>Reducing Hardware Costs</h2><p id="p-49">Besides boosting developer productivity, another main purpose of a shared infrastructure is to lower the cost of hardware. In this section, we highlight several examples of how software solutions help reduce hardware costs.</p><section id="sec24"><p data-jats-content-type="inline-heading"><strong>All global datacenters as a computer.</strong>&nbsp; Most infrastructures place the burden of managing the complexities of geo-distributed datacenters on users, requiring them to manually determine the number of replicas for their services and select the regions for deployment, all while ensuring that service-level objectives are met. This complexity often leads to hardware wastage due to overprovisioning, uneven load distribution across regions, and insufficient cross-region migration to adapt to changes in workload demand and datacenter supply.</p><p id="p-51">In contrast, Meta is evolving from the practice of “the datacenter as a computer”<a href="#B4" data-jats-ref-type="bibr" data-jats-rid="B4"><sup>4</sup></a> (DaaC) to the vision of “all global datacenters as a computer” (Global-DaaC).<a href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> With Global-DaaC, users simply request the global deployment of a service, leaving the infrastructure to manage all the details: determining the optimal number of service replicas, placing these replicas across datacenter regions based on service-level objectives and available hardware, selecting the best-matching hardware type, optimizing traffic routing, and continuously adapting service placement in response to workload changes. Compared with public clouds, Meta can more easily realize Global-DaaC because it owns all its applications and can move them across regions as needed; public clouds lack this flexibility with their customers’ applications.</p><p id="p-52">To implement Global-DaaC, our tools seamlessly coordinate resource allocation across all levels: global, regional, and within individual servers. First, our global capacity-management tool<a href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a> uses RPC tracing to identify service dependencies and construct resource-consumption models, then employs mixed-integer programming to break down a service’s global capacity needs into regional quotas. Next, our regional capacity-management tool<a href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a> assigns server resources to these regional quotas to form virtual clusters. Unlike physical clusters, a virtual cluster can comprise servers from different datacenters in the same region, and its size may dynamically grow or shrink. During runtime, our container-management tool<a href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> allocates containers in these virtual clusters, often spreading a job’s containers across multiple datacenters in the same region for improved fault tolerance. Finally, at the server level, our kernel mechanisms<a href="#B21" data-jats-ref-type="bibr" data-jats-rid="B21"><sup>21</sup></a><sup>,</sup><a href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a> ensure proper sharing and isolation of memory and I/O resources allocated to individual containers.</p><p id="p-53">Stateful services, such as databases, benefit from Global-DaaC. These services are typically sharded, with each container hosting multiple data shards for efficiency. Our global service placer (GSP) uses constrained optimization to determine the optimal number of replicas for each data shard and their placement across regions. Then, our sharding framework<a href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> works within the constraints set by GSP to allocate shard replicas to containers and dynamically migrate them in response to load changes.</p><p id="p-54">Similarly, ML workloads benefit from Global-DaaC. For ML inference, models are managed similarly to data shards, with the number of model replicas and their locations determined by GSP. For ML training, it requires the collocation of training data and GPUs in the same datacenter region. Each team receives a global GPU capacity quota and submits training jobs to a global job queue. Our ML training scheduler<a href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a> automatically selects regions for data replication and GPU allocation to ensure the collocation of data and GPUs while maximizing GPU utilization.</p></section><section id="sec25"><p data-jats-content-type="inline-heading"><strong>Hardware and software co-design.</strong>&nbsp; While hardware and software co-design within a single server is common, we have elevated it to the global scale to use software solutions to overcome the limitations of lower-cost hardware.</p><section id="sec26"><p data-jats-content-type="inline-heading"><em>Low-cost fault tolerance.</em>&nbsp; Public clouds tend to provide hardware with higher availability because their customers’ applications might not be sufficiently fault tolerant. In contrast, since all our applications are under our control, we can ensure they are implemented in a fault-tolerant manner to run on cheaper hardware with lower availability guarantees. For example, a server rack in public clouds may use dual power supplies and dual top-of-rack (ToR) switches to ensure high availability and facilitate switch maintenance without disrupting running workloads. In contrast, our racks have neither dual power supplies nor dual ToR switches. Instead, hardware redundancies occur only at the much larger scope of the power main switchboards (MSBs), each covering about 10,000 to 20,000 servers. For every six MSBs, there is only one reserve MSB as a backup. Moreover, virtual machines (VMs) in public clouds often use network-attached block devices, which enable live VM migration. In contrast, our containers use low-cost, directly attached SSDs for root disks, which hinders live-container migration during datacenter maintenance operations.</p><p id="p-58">We use software solutions to overcome the limitations of lower-cost hardware. First, our resource-allocation tools<a href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a><sup>,</sup><a href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a><sup>,</sup><a href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a> ensure that a service’s containers and data shards are sufficiently spread across different sub-datacenter fault domains (MSBs) for better fault tolerance. Second, through a cooperative protocol that allows a service to weigh in on the lifecycle management of its containers,<a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a> we ensure that maintenance operations respect application-level constraints, such as avoiding simultaneous shut-downs of two replicas of the same data shard. Finally, Global-DaaC ensures that services are deployed to withstand the simultaneous loss of an entire datacenter region, one MSB in each region, and a certain percentage of random servers in each region. We routinely conduct tests in production to ensure that these properties hold so our services are fault tolerant.<a href="#B36" data-jats-ref-type="bibr" data-jats-rid="B36"><sup>36</sup></a></p><p id="p-59">While our infrastructure is designed to withstand the loss of an entire datacenter region without affecting users, the increasing number of regions has raised the possibility of two nearby regions being simultaneously affected by a large-scale natural disaster, such as a hurricane. Instead of over-provisioning capacity to tolerate the simultaneous loss of two regions, we employ a software-based approach<a href="#B25" data-jats-ref-type="bibr" data-jats-rid="B25"><sup>25</sup></a> that, in the event of losing multiple regions, deactivates less-critical product features and gracefully degrades service quality, such as delivering lower-quality videos, to reduce the load.</p></section><section id="sec27"><p data-jats-content-type="inline-heading"><em>Eliminating the costs of routing proxies.</em>&nbsp; Unlike traditional service meshes that predominantly use sidecar proxies to route RPC requests, Meta’s service mesh<a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> uses proxies to route only 1% of RPC requests across our fleet. The remaining 99% use a routing library linked into service executables for direct client-to-server routing, bypassing intermediate proxies. While this unconventional approach saves us O(100,000) servers needed for proxies, it introduces deployment challenges due to the library being compiled into around O(10,000) services, each with its own deployment schedule. Our software deployment and configuration-management tools<a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a><sup>,</sup><a href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a> help make these challenges manageable.</p></section><section id="sec28"><p data-jats-content-type="inline-heading"><em>Tiered storage and local SSDs.&nbsp;</em> Based on access frequency and latency tolerance, we categorize data as hot, warm, or cold, with each category using a different storage system to optimize cost-effectiveness. Hot databases and caches, such as the social graph database,<a href="#B5" data-jats-ref-type="bibr" data-jats-rid="B5"><sup>5</sup></a> store data in memory and solid state drives (SSDs).</p><p id="p-62">Warm data, including videos, images, and data in the data warehouse (for example, user activity logs), is stored in a distributed file system<a href="#B29" data-jats-ref-type="bibr" data-jats-rid="B29"><sup>29</sup></a> that utilizes hard disk drives (HDDs) to store data. Each storage server is equipped with one CPU, 36 HDDs, and two SSDs for metadata cache.</p><p id="p-63">For rarely accessed cold data, such as a decade-old high-resolution video, we archive them with high-density HDD servers, each with one CPU and 216 HDDs, which provides a good balance between total cost of ownership and data-restoration speed. These HDDs are powered off most of the time, as they are not in active use.</p><p id="p-64">Among workloads that store data on SSDs, some can tolerate longer-tail latencies and opt for SSD-based shared remote storage for better SSD utilization. However, workloads with strict latency requirements still use directly attached local SSDs. Compared with other hyperscale infrastructures, we more frequently employ local SSDs to reduce costs, despite the management complexities involved. For instance, imbalanced load distribution can lead to underutilization and stranding of local SSDs. Additionally, failure recovery is complicated by data becoming trapped in the SSDs of failed servers. To address these challenges, we use our common sharding framework<a href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> to implement stateful services with local SSDs, solving the issues once and reusing the solution across many services.</p></section></section><section id="sec29"><p data-jats-content-type="inline-heading"><strong>In-house hardware design.</strong>&nbsp; We design our own datacenters<a href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a> and hardware—servers, network switches, video accelerators, and AI chips<a href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a>—for better costs and power efficiency. In datacenters, power is the most constrained resource because it is fixed at the time of datacenter construction and hard to expand later during a datacenter’s 20-to-30-year lifespan. In contrast, the network and servers can be upgraded as needed. Power in a datacenter is often oversubscribed. To prevent over-drawing power when workloads surge, an automation tool<a href="#B38" data-jats-ref-type="bibr" data-jats-rid="B38"><sup>38</sup></a> coordinates power-capping actions across the power-delivery hierarchy.</p><p id="p-67">Our hardware designs often achieve cost and power savings through hardware/software co-design (for example, optimizing SRAM usage in our AI chip based on our workloads<a href="#B15" data-jats-ref-type="bibr" data-jats-rid="B15"><sup>15</sup></a>), and by removing components unnecessary to us (for example, eliminating compressor-cooled air conditioning<a href="#B17" data-jats-ref-type="bibr" data-jats-rid="B17"><sup>17</sup></a>). Additionally, in-house development of network switches and their companion software<a href="#B8" data-jats-ref-type="bibr" data-jats-rid="B8"><sup>8</sup></a> enables us to treat switch software like a regular service and deploy updates frequently. Most of our hardware designs are open source through the Open Compute Project.<a href="#B28" data-jats-ref-type="bibr" data-jats-rid="B28"><sup>28</sup></a></p></section></section><section id="sec30"><h2>Designing Scalable Systems</h2><p id="p-69">A recurring theme in hyperscale infrastructure is the design of scalable systems. Decentralized systems designed for the Internet environment, such as BGP, BitTorrent, and distributed hash tables (DHTs), are often lauded for their scalability. However, in a datacenter environment, which is less resource constrained and under the control of a single organization, our experiences indicate that centralized controllers not only achieve ample scalability but also are simpler and can make higher-quality decisions.</p><section id="sec31"><p data-jats-content-type="inline-heading"><strong>Deprecating decentralized controllers.</strong>&nbsp; In this section, we discuss several examples of the trade-off between centralized and decentralized controllers. For network switches in our datacenter fabric, although they still use BGP for compatibility, the fabric has a centralized controller capable of overriding routing paths during network congestion or link failures.<a href="#B1" data-jats-ref-type="bibr" data-jats-rid="B1"><sup>1</sup></a></p><p id="p-71">Except for BGP, we have migrated almost all decentralized controllers to centralized ones. For example, in our private WAN,<a href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> we transitioned from decentralized RSVP-TE to a centralized controller to compute preferred traffic paths and proactively establish backup paths for common failure scenarios. This has resulted in more efficient network resource usage and faster convergence during network failures.</p><p id="p-72">For key-value stores, DHTs use multi-hop routing to determine the server responsible for a given key, while Cassandra uses consistent hashing for this purpose. Both function without a central controller. In contrast, to achieve better load balance, our sharding framework<a href="#B23" data-jats-ref-type="bibr" data-jats-rid="B23"><sup>23</sup></a> uses a central controller to dynamically reassign key-encapsulating shards to servers.</p><p id="p-73">For bulk-data distribution, we transitioned from BitTorrent to Owl,<a href="#B16" data-jats-ref-type="bibr" data-jats-rid="B16"><sup>16</sup></a> which centralizes the decision of where a peer should fetch data, resulting in significantly faster download speeds. Note that both Owl and our private WAN<a href="#B12" data-jats-ref-type="bibr" data-jats-rid="B12"><sup>12</sup></a> centralize the control plane for better decision making but still use a decentralized data plane for actual data forwarding or downloading.</p><p id="p-74">For small-metadata distribution (further explained in Figure <a href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a>), we initially used a three-level distribution tree implemented in Java. The tree’s intermediate nodes were dedicated proxy servers, and its leaf nodes were application subscribers that could dynamically join and leave. When this implementation could not scale further, we transitioned to a peer-to-peer distribution tree, where intermediate nodes were also application subscribers that forwarded data to other subscribers. Among millions of application subscribers, however, a subset often experienced noisy performance issues due to their non-dedicated nature. Consequently, using them as intermediate nodes to forward traffic was less reliable, leading to frequent and time-consuming debugging. Eventually, after a few years of production use, we abandoned the peer-to-peer distribution tree and reverted to the original architecture that uses dedicated proxy servers. We replaced the original Java implementation with a more performant C++ implementation, which scaled well to tens of millions of subscribers.</p></section><section id="sec32"><p data-jats-content-type="inline-heading"><strong>Case study: Scalable service mesh.</strong>&nbsp; In this section, we use Meta’s service mesh, ServiceRouter,<a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a> as a case study to illustrate the design of scalable systems and demonstrate that centralized controllers combined with a decentralized data plane can scale well in a datacenter environment. ServiceRouter routes billions of RPCs per second across millions of layer-7 (L7, that is, application layer) routers.</p><p id="p-77">Figure <a href="#F3" data-jats-ref-type="fig" data-jats-rid="F3">3</a> depicts a commonly used service mesh in the industry, where each service process is accompanied by an L7 sidecar proxy that routes RPCs for the service. For example, when service A on server 1 sends requests to service B, the proxy on server 1 load balances them across servers 2, 3, and 4. While this solution is widely adopted, it is not scalable for hyperscale infrastructure because the central controller cannot scale to directly configure the routing tables of millions of sidecar proxies. The central controller has a dual function of generating global routing metadata and managing each L7 router. To scale out, we keep the former in the central controller but transfer the latter to L7 routers, making each L7 router self-configuring and self-managing.</p><figure id="F3" data-jats-position="float"><p><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig03.jpg" data-type="image" data-caption="Figure 3. Sidecar-proxy-based service mesh." href="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig03.jpg">
				<img decoding="async" title="Figure 3. Sidecar-proxy-based service mesh." src="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig03.jpg" alt="Sidecar-proxy-based service mesh." data-image-id="F3" data-image-type="figure">
			</a>
		</p><figcaption><span>Figure 3.&nbsp;</span> <span>Sidecar-proxy-based service mesh.</span></figcaption></figure><p id="p-78">Figure <a href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a> illustrates the scalable architecture of ServiceRouter. At the top, different controllers independently execute distinct functions such as registering services, updating measured network latencies, and computing a per-service cross-region routing table. Each controller independently updates the central routing information base (RIB) and is not concerned with configuring or managing individual L7 routers. The RIB is a Paxos-based database<a href="#B3" data-jats-ref-type="bibr" data-jats-rid="B3"><sup>3</sup></a> and can scale out through sharding. With the help of the RIB, the controllers become stateless and can easily scale out through sharding as well. For example, multiple controller instances can concurrently compute cross-region routing tables for different services.</p><figure id="F4" data-jats-position="float"><p><a data-fslightbox="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig04.jpg" data-type="image" data-caption="Figure 4. ServiceRouter’s scalable service-mesh architecture." href="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig04.jpg">
				<img decoding="async" title="Figure 4. ServiceRouter’s scalable service-mesh architecture." src="https://cacm.acm.org/wp-content/uploads/2024/12/3701296_fig04.jpg" alt="ServiceRouter’s scalable service-mesh architecture." data-image-id="F4" data-image-type="figure">
			</a>
		</p><figcaption><span>Figure 4.&nbsp;</span> <span>ServiceRouter’s scalable service-mesh architecture.</span></figcaption></figure><p id="p-79">In the middle of Figure&nbsp;<a href="#F4" data-jats-rid="F4" data-jats-ref-type="fig">4</a>, the distribution layer leverages thousands of RIB replicas to handle read traffic from millions of L7 routers. At the bottom, guided by the RIB, each L7 router self-configures without the direct involvement of the control plane. Heterogeneous L7 routers are supported, which can be load balancers, services with embedded routing libraries, or sidecar proxies.</p><p id="p-80">As ServiceRouter shows, we can achieve good scalability with centralized controllers through techniques like stateless controllers, controller sharding, and removing non-essential functions, such as managing individual L7 routers, from central controllers.</p></section></section><section id="sec33"><h2>Future Directions</h2><p id="p-81">Despite the complexity of Meta’s hyperscale infrastructure, here we provided a concise, high-level overview, emphasizing key insights from its development. To conclude, we share our thoughts on potential future trends for hyperscale infrastructure.</p><section id="sec34"><p data-jats-content-type="inline-heading"><strong>AI.</strong>&nbsp; AI workloads have become the single largest category of workload in datacenters. We anticipate that, before the end of this decade, more than half of the power in datacenters will be dedicated to AI workloads. Due to its distinct characteristics, such as being more resource-intensive and requiring higher-bandwidth networks, AI is expected to profoundly reshape every aspect of infrastructure. In the past two decades, hyperscale infrastructures have succeeded mostly by taking the <i>scaling-out</i> approach to utilize a large number of low-cost commodity servers. Future AI clusters, however, will more likely take the <i>scale-up</i> approach used by past supercomputers, such as using remote direct memory access (RDMA) over Ethernet to provide the high-bandwidth, low-latency network required for large-scale ML training.<a href="#B18" data-jats-ref-type="bibr" data-jats-rid="B18"><sup>18</sup></a> Meta’s approach to AI is distinguished by co-designing the full stack, from PyTorch to ML models, AI chips, networks, datacenters, servers, storage, power, and cooling.</p></section><section id="sec35"><p data-jats-content-type="inline-heading"><strong>Domain-specific hardware.</strong>&nbsp; Reversing the trend of diminishing hardware diversity in the 2000s, we anticipate a proliferation of custom and specialized hardware for various purposes, such as AI training and inference, virtualization, video encoding, encryption, compression, tiered memory, as well as in-network and in-storage processing. This is because economies of scale allow hyperscalers to design and deploy specialized hardware in large quantities to reduce costs. Consequently, this will pose challenges for the software stack in utilizing and managing a highly heterogeneous fleet.</p></section><section id="sec36"><p data-jats-content-type="inline-heading"><strong>Edge datacenters.</strong>&nbsp; We expect a substantial increase in metaverse and Internet of Things (IoT) applications. Cloud gaming, for instance, shifts graphics rendering from user devices to GPU servers in edge datacenters, necessitating less than 25ms network latency. The demand for real-time responsiveness will likely drive considerable growth in both the quantity and size of edge datacenters. As a result, the infrastructure control plane needs to adapt to managing a more dispersed fleet, ideally by enhancing Global-DaaC to shield application developers from the complexity of a dispersed infrastructure.</p></section><section id="sec37"><p data-jats-content-type="inline-heading"><strong>Developer productivity.</strong>&nbsp; Over the past two decades, automation tools have significantly boosted the productivity of system administrators, resulting in a considerably higher server-to-administrator ratio. In contrast, general software development remains labor-intensive, with comparatively slower productivity growth. In this decade, we anticipate a shift in this trend, with developer productivity increasing rapidly for two reasons: AI-powered code generation and debugging, and fully integrated serverless programming paradigms in vertical domains. Meta’s FrontFaaS is an example of the latter, and we anticipate the emergence of highly productive programming paradigms for more vertical domains.</p><p id="p-86">We anticipate that the rapid innovation in hyperscale infrastructure seen over the past two decades will continue into the next decade, driven especially by advancements in AI. We encourage hyperscalers to share their insights, enabling the community to collectively accelerate progress.</p></section></section><section id="sec38"><h2>Acknowledgments</h2><p id="p-87">This article summarizes the work done by thousands of Meta infrastructure engineers over a time span of more than a decade. While the author contributed to some systems described in this article,<a href="#B7" data-jats-ref-type="bibr" data-jats-rid="B7"><sup>7</sup></a><sup>,</sup><a href="#B10" data-jats-ref-type="bibr" data-jats-rid="B10"><sup>10</sup></a><sup>,</sup><a href="#B11" data-jats-ref-type="bibr" data-jats-rid="B11"><sup>11</sup></a><sup>,</sup><a href="#B13" data-jats-ref-type="bibr" data-jats-rid="B13"><sup>13</sup></a><sup>,</sup><a href="#B19" data-jats-ref-type="bibr" data-jats-rid="B19"><sup>19</sup></a><sup>–</sup><a href="#B24" data-jats-ref-type="bibr" data-jats-rid="B24"><sup>24</sup></a><sup>,</sup><a href="#B26" data-jats-ref-type="bibr" data-jats-rid="B26"><sup>26</sup></a><sup>,</sup><a href="#B30" data-jats-ref-type="bibr" data-jats-rid="B30"><sup>30</sup></a><sup>,</sup><a href="#B31" data-jats-ref-type="bibr" data-jats-rid="B31"><sup>31</sup></a><sup>,</sup><a href="#B33" data-jats-ref-type="bibr" data-jats-rid="B33"><sup>33</sup></a><sup>,</sup><a href="#B34" data-jats-ref-type="bibr" data-jats-rid="B34"><sup>34</sup></a><sup>,</sup><a href="#B37" data-jats-ref-type="bibr" data-jats-rid="B37"><sup>37</sup></a><sup>,</sup><a href="#B39" data-jats-ref-type="bibr" data-jats-rid="B39"><sup>39</sup></a><sup>,</sup><a href="#B40" data-jats-ref-type="bibr" data-jats-rid="B40"><sup>40</sup></a> there are also many systems that the author did not work on directly.</p></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Make Your Own Website: A beginner's guide (171 pts)]]></title>
            <link>https://web.pixelshannon.com/make/</link>
            <guid>43008315</guid>
            <pubDate>Tue, 11 Feb 2025 02:37:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.pixelshannon.com/make/">https://web.pixelshannon.com/make/</a>, See on <a href="https://news.ycombinator.com/item?id=43008315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <h2>Getting Started</h2>
        <p>This is not a complete <a href="https://developer.mozilla.org/en-US/docs/Web/HTML">HTML</a>/<a href="https://developer.mozilla.org/en-US/docs/Web/CSS">CSS</a> tutorial, but will attempt to guide you through making your first page using HTML and CSS. If you have questions or comments, you can <a href="mailto:reply25@pixelshannon.com?subject=%5Breply%20to%5D%20Make%20Your%20Own%20Website%22">reply by email</a>, <a href="https://bookstodon.com/@shannonkay/113981703308638892">reply on Mastodon</a>, or <a href="https://bsky.app/profile/shannonkay.com/post/3lhu5ebhrvk2l">reply on Bluesky</a>.</p>
    <blockquote>
        <strong>Personal note:</strong> I originally wrote this guide for my daughter, then 12 years old, to learn how to make a website for a class project. For that reason, I included a mix of things I thought she needed to know and things I thought she would want to use. She created her website at school, without my direct assistance. <a href="https://web.pixelshannon.com/make/ballet/index.html">Here's a copy of the website that she made using this guide</a>.
    </blockquote>
<nav id="web">
    <a href="#software">Software</a> 
    <a href="#make-a-folder">Make a Folder</a> 
    <a href="#html-page-structure">HTML Page Structure</a> 
    <a href="#page-content-in-html">Page Content in HTML</a> 
    <a href="#sections">Sections</a> 
    <a href="#linking">Linking</a> 
    <a href="#images">Images</a> 
    <a href="#create-a-stylesheet-with-css">Create a Stylesheet With CSS</a> 
    <a href="#link-your-stylesheet">Link Your Stylesheet</a>
    <a href="#stylish-bonus">Stylish Bonus</a> 
    <a href="#more-style">More Style</a>
    <a href="#more-pages">More Pages</a>
    <a href="#lists">Lists</a>
    <a href="#ids-and-classes">IDs and Classes</a>
    <a href="#styling-boxes-and-borders">Styling Boxes and Borders</a>
    <a href="#photos">Photos</a>
    <a href="#using-emoji">Using Emoji</a> 
    <a href="#examples">Examples</a> 
    <a href="#host-and-publish-your-website-on-the-internet">Publish</a>
    <a href="#more-resources">More Resources</a>

</nav>

<section id="example">
<figure><a href="https://web.pixelshannon.com/make/lesson/index.html"><img src="https://web.pixelshannon.com/make/examplepage.png" alt="A screenshot of the example website. The title of the website is I Love Cats and it has a light pink background with hot pink text and a photo of a cat"></a>
<figcaption><a href="https://web.pixelshannon.com/make/lesson/index.html">Here's an example website</a> that you can make with this guide.</figcaption>
</figure>
</section>

        <h3 id="software">Software</h3>
        <p>You will need a plain text or code editor. I use <a href="https://vscodium.com/">VSCodium</a> or <a href="https://code.visualstudio.com/">Visual Studio Code</a>(it also has a <a href="https://vscode.dev/">web-based version</a>). Another option is <a href="https://phcode.io/">Phoenix Code</a>(also has a desktop and web version). You can also use a plain text editor like Notepad or <a href="https://support.apple.com/guide/textedit/work-with-html-documents-txted0b6cd61/mac">TextEdit</a>.</p>
        <hr>
        <h3 id="make-a-folder">Make a Folder</h3>
        <p>On your computer, create a folder that you will put all the files for this website into. I like to have a "Websites" folder with subfolders for each of my different sites. You can name the folder whatever you want, like "homepage" or "cats".</p>
        <p><strong>Open the folder in your code editor, or open your text editor. Create a new file(or save your text document) and name it <em>index.html</em></strong></p>
        
        <details>
        <summary>Why is the file named "index.html"?</summary>
        In websites, the "index" page is the default page that will be shown if someone browses to the root of a website address or folder, so whatever you want people to see first should be called "index". If you want to make a page with an address like shannonkay.com/books without having to see a "page.html" file name, you need to make an "index" page inside the "books" folder. Our file has a .html ending because we're putting html code in it. 
        </details>
        
    <hr>
    <h3 id="html-page-structure">HTML Page Structure</h3>
    <p>Most HTML tags have an opening and a closing tag. The first one we need is the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/html"><code>&lt;html&gt;</code></a> tag. All the rest of our HTML will go between these opening and closing tags.</p>
    <pre><code>
    &lt;html&gt;
    &lt;/html&gt;</code></pre>

    <p>There's one more thing we need to put before our opening <code>&lt;html&gt;</code> tag, and it's the <a href="https://developer.mozilla.org/en-US/docs/Glossary/Doctype"><code>!DOCTYPE</code></a> declaration. It tells the browser what type of document to expect. This is the !DOCTYPE declaration for HTML 5.</p>
    <pre><code>
    &lt;!DOCTYPE html&gt;
        &lt;html&gt;
        &lt;/html&gt;</code></pre>

    <p>After the <code>&lt;html&gt;</code> tag, there are two important tags that further divide our HTML document, <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/head"><code>&lt;head&gt;</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/body"><code>&lt;body&gt;</code></a>. The <code>&lt;head&gt;</code> tag contains important information that doesn't show on the page. The <code>&lt;body&gt;</code> tag contains all the content of the page.</p>
    
    <pre><code>
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    
        &lt;head&gt;&lt;/head&gt;
        &lt;body&gt;&lt;/body&gt;
    
    &lt;/html&gt;</code></pre>

    <p id="head-section"><a href="#head-section">In the head section</a>, we will put the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/title"><code>&lt;title&gt;</code></a> tag. The title that goes in this tag will not show up on the page, but it will show up in the browser tab and be the title for bookmarks, sharing, etc. Don't add any other HTML tags in the title.</p>
    <pre><code>
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    
        &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;/head&gt;
    
    &lt;body&gt;&lt;/body&gt;
    
    &lt;/html&gt;</code></pre>

    <p id="viewport-meta">For now, we'll just add one more thing to the head section. In these modern times, people view websites on a wide variety of device sizes, including smart phones. <a href="#viewport-meta">The</a> <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Viewport_meta_tag"><code>viewport &lt;meta&gt; tag</code></a> will help it resize properly on those devices. </p>
    <pre><code>
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    
        &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
        &lt;/head&gt;
    
    &lt;body&gt;&lt;/body&gt;
    
    &lt;/html&gt;</code></pre>
<hr>
    <h3 id="page-content-in-html">Page Content in HTML</h3>
    <p>Let's start adding content to the body section of the page with a header. We'll start with a <a href="https://developer.mozilla.org/en-US/docs/Glossary/Semantics#semantic_elements">semantic</a> <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/header"><code>&lt;header&gt;</code></a> tag, and our page title will go inside it. I'm going to use the same text as my title for this page, <em>I Love Cats</em>. Put the header text between <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/Heading_Elements"><code>&lt;h1&gt;</code></a> tags. The <code>&lt;h1&gt;</code> tag means that this is the top-level header, usually what's at the very top of the page. </p>
    <pre><code>
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
    
        &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
        &lt;/head&gt;
    
    &lt;body&gt;
        &lt;header&gt;&lt;h1&gt;I Love Cats&lt;/h1&gt;&lt;/header&gt;
    &lt;/body&gt;
    
    &lt;/html&gt;</code></pre>

    <p>Let's use another semantic tag, <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/main"><code>&lt;main&gt;</code></a>, and put whatever we want to be the main content of this page. I'm going to use <code>&lt;h2&gt;</code> for a header that's smaller than and "below" the <code>&lt;h1&gt;</code> at the top of the page, and I'll use the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/p"><code>&lt;p&gt;</code></a>(paragraph) tag for my text.</p>
    <pre><code>
    &lt;body&gt;
        &lt;header&gt;&lt;h1&gt;I Love Cats&lt;/h1&gt;&lt;/header&gt;
    
        &lt;main&gt;
            &lt;h2&gt;Favorite Cats&lt;/h2&gt;
            &lt;p&gt;I love tabby cats, bengal cats, and siamese cats!&lt;/p&gt;
        &lt;/main&gt;
    &lt;/body&gt;</code></pre>

    <p>We can also add a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/footer"><code>&lt;footer&gt;</code></a> for some extra information at the bottom of the page, like telling everyone who made this website.</p>
    <pre><code>
    &lt;body&gt;
        &lt;header&gt;&lt;h1&gt;I Love Cats&lt;/h1&gt;&lt;/header&gt;
    
        &lt;main&gt;
            &lt;h2&gt;Favorite Cats&lt;/h2&gt;
            &lt;p&gt;I love tabby cats, bengal cats, and siamese cats!&lt;/p&gt;
        &lt;/main&gt;
    
        &lt;footer&gt;This website was made by Shannon&lt;/footer&gt;
    &lt;/body&gt;</code></pre>
<hr>
    <h3 id="sections">Sections</h3>
    <p>Let's make some <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/section">sections</a> to divide our page's content. We'll keep our sections within the main tags, and remember that everything that will be shown on your page should stay within the body tags.</p>
    <p>I'll make the My Favorite Cats header and paragraph my first section by putting <code>&lt;section&gt;</code> tags around it.</p>
    <pre><code>
    &lt;main&gt;
        &lt;section&gt;
            &lt;h2&gt;Favorite Cats&lt;/h2&gt;
            &lt;p&gt;I love tabby cats, bengal cats, and siamese cats!&lt;/p&gt;
        &lt;/section&gt;
    &lt;/main&gt;</code></pre>

    <p>Let's add more sections. You can make as many sections as you want.</p>
    <pre><code>
    &lt;main&gt;
        &lt;section&gt;
            &lt;h2&gt;Favorite Cats&lt;/h2&gt;
            &lt;p&gt;I love tabby cats, bengal cats, and siamese cats!&lt;/p&gt;
        &lt;/section&gt;
    
        &lt;section&gt;
            &lt;h2&gt;Tabby Cats&lt;/h2&gt;
            &lt;p&gt;Tabby cats have a striped pattern and are usually brown or grey.&lt;/p&gt;
        &lt;/section&gt;
    
        &lt;section&gt;
            &lt;h2&gt;Great Names for Cats&lt;/h2&gt;
            &lt;p&gt;Some people like to name their cats with names like 
            Fluffy, Frisky, or Patches.&lt;/p&gt;
        &lt;/section&gt;
    &lt;/main&gt;</code></pre>
<hr>
    <h3 id="linking">Linking</h3>
    <p>Linking pages and websites together is what makes the internet a network. The HTML for creating links is an <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/a"><code>&lt;a&gt;</code></a>(anchor) tag with an attribute called <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/a#href"><code>href</code></a>. </p>
    <p>Writing a link in HTML looks like this.</p>
    <pre><code>&lt;a href="about.html"&gt;About&lt;/a&gt;</code></pre>
    <p>The a tag has an opening and closing, just like the other tags we've been using. The text between the tags is what will show on the page for users to click(or tap) to follow the link. In this example, I'm linking to a file called "about.html" and my link's text will say "About". The file needs to be in the same folder as the page I'm putting the link on for it to work with just the file name like this. If the file is in a subfolder, include the path like this.</p>
    <pre><code>&lt;a href="about/index.html"&gt;About&lt;/a&gt;</code></pre>
    <p>And when you're linking to different website, be sure to include the full <a href="https://developer.mozilla.org/en-US/docs/Glossary/URL">url</a> like this.</p>
    <pre><code>&lt;a href="https://web.pixelshannon.com"&gt;Make Your Own Website&lt;/a&gt;</code></pre>
<hr>
<h3 id="images">Images</h3>
    <p>To embed images in your page, use the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/img"><code>&lt;img&gt;</code></a> tag. Put the filename of your image in the src attribute. I put my cat pixel images in a subfolder called "cats", so I included that path just like with the links. Many people like to have a subfolder for all of their images, named something like "img" or "images".</p>
    <pre><code>&lt;img src="cats/cat1.gif" /&gt;</code></pre>
    <p><img src="https://web.pixelshannon.com/make/lesson/cats/cat1.gif" alt="Pixel drawing of a black and white cat"></p>
    <p>For accessibility, you should always add alt text to your images. This helps people who use screen readers. To do this, put the alt attribute in your <code>&lt;img&gt;</code> tag. Write a short description of the image. Even a word or two will help!</p>
    <pre><code>&lt;img src="cats/cat1.gif" alt="Pixel drawing of a black and white cat" /&gt;</code></pre>
<hr>
<h3 id="create-a-stylesheet-with-css">Create a Stylesheet With CSS</h3>
    <p>Now you have a basic HTML page that you can open and view in the browser. If you open your index.html file, it will look very plain. The CSS used for a website is called the stylesheet. </p>
    <p>CSS looks like this. The selector describes what in the HTML is being selected to be styled. </p>
    <pre><code>selector {
        property: value;
    }</code></pre>
    <p>Create a new file called style.css and save it in the same folder as your index file. Unlike the index HTML file, you can name the CSS file for your stylesheet anything you want. </p>
    <p>Let's start simply by adding a background color. I'm using hexadecimal color values. There are some named colors that you can use, but unless it's white or black, I find it's easier to get the color you want with a color's hex code. I'm using a light pink for the background, <a href="https://www.color-hex.com/color/f9dee1">#f9dee1</a>. </p>
    <p>The selector is "body" because we're selecting the <code>&lt;body&gt;</code> tag in our HTML. Remember how everything visible on the page goes inside the <code>&lt;body&gt;</code> tags? That means that styles applied to "<code>body</code>" in our CSS will affect the whole page.</p>
    <pre><code>body {
    
        background-color: #f9dee1;
    
    }</code></pre>

    <hr>

    <h3 id="link-your-stylesheet">Link Your Stylesheet</h3>
    <p>Now that you've begun a stylesheet, add it to your HTML page to see the CSS applied to the page.</p>
    <p>Back at the index page, CSS goes within the <code>&lt;head&gt;</code> element, like the <code>&lt;title&gt;</code> does. We're going to <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/link">link</a> to the stylesheet like this.</p>
    <pre><code>
    &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
        &lt;link rel="stylesheet" href="style.css"&gt;
    &lt;/head&gt;</code></pre>
    <p>You could also put your CSS directly on the page, and it would still go within the <code>&lt;head&gt;</code> tags, and between <code>&lt;style&gt;</code> tags, like this. </p>
    <pre><code>
    &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;style&gt;
        body {
    
        background-color: #f9dee1;
    
        }
        &lt;/style&gt;
    &lt;/head&gt;
</code></pre>
    <p>Using an external stylesheet, like the one we linked in our header is usually preferred. It's more flexible, and you can link to the same stylesheet on multiple pages so you don't have to make changes multiple times.</p>
<hr>
<h3 id="stylish-bonus">Stylish Bonus</h3>
    <p>In case someone views your website on a mobile device, you can set a background color for the top of the screen to match your website's background color. It's not CSS, and you would have to change it in every page if you change your background color, but it's a nice detail that I like to add.</p>
    <p>All you need to do this is a <code>&lt;meta&gt;</code> tag with the <code>theme-color</code> attribute. Put this in the <code>&lt;head&gt;</code> section of your page. Add your color in the <code>content</code> attribute. I chose the same color I used for the <code>&lt;body&gt;</code> background color.</p>
    <pre><code>
    &lt;head&gt;
        &lt;title&gt;I Love Cats&lt;/title&gt;
        &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
        &lt;meta name="theme-color" content="#f9dee1"&gt;
        &lt;link rel="stylesheet" href="style.css"&gt;
    &lt;/head&gt;
</code></pre>

<hr>

<h3 id="more-style">More Style</h3>
    <p>Let's go back to the stylesheet to add more style to our page. I've added to the style for <code>body</code> with the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/font-family"><code>font-family</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/color"><code>color</code></a> properties. This will change the font and color of the text. </p>
    <p>I've styled centered the header by styling <code>h1</code> with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/text-align"><code>text-align: center</code></a> and added <code>color</code> to <code>h1</code> and <code>h2</code>. </p>
    <p>I've also added rules to the <code>footer</code>, centering the text with <code>text-align</code>, adding a <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/text-align"><code>border</code></a> to the top of the footer with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/border-top"><code>border-top</code></a>, and adding <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/border-top"><code>padding</code></a>.</p>
    <pre><code>
    body {
        background-color: #f9dee1;
        font-family: Verdana, Geneva, Tahoma, sans-serif;
        color: #282A36;
    }
    
    h1 {
        color: #FF1493;
        text-align: center;
    }
    
    h2 {
        color: #FF69B4;
    }
    
    footer {
        text-align: center;
        border-top: 2pt solid #fcc9ce;
        padding: 5pt;
    }</code></pre>
    <p>CSS is very extensive, and this is barely scratching the surface of what you can do. Check out a full <a href="#more-resources">CSS tutorial</a> when you're ready to do more. You can also <a href="https://web.pixelshannon.com/make/home.css">check out the stylesheet</a> for this page.</p>
 <hr>
    <h3 id="more-pages">More Pages</h3>
    <p>You might want your website to have more than one page. Linking your pages together from the index page creates a multipage website.</p>
    <p>Now that you know the basics that every web page needs, you can make additional pages. Create a new html file and use your index page as a template for any other pages you want to make. You'll want to change the title and header, and most likely put most of the new page's content within the <code>&lt;main&gt;</code> tags. Additional pages can be named whatever you want, but the files should have a <code>.html</code> ending and have no spaces in the name.</p>
    <pre><code>
    &lt;!DOCTYPE html&gt;
    &lt;html&gt;
        &lt;head&gt;
            &lt;title&gt;I Love Cats&lt;/title&gt;
            &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
            &lt;meta name="theme-color" content="#f9dee1"&gt;
            &lt;link rel="stylesheet" href="style.css"&gt;
        &lt;/head&gt;
        &lt;body&gt;  
            &lt;header&gt;&lt;h1&gt;I Love Cats&lt;/h1&gt;&lt;/header&gt;
    
                &lt;main&gt;
                &lt;/main&gt;
    
            &lt;footer&gt;This website was made by Shannon&lt;/footer&gt;
        &lt;/body&gt;
    &lt;/html&gt;</code></pre>

<hr>

<h3 id="lists">Lists</h3>
    <p>Creating a list in HTML can be very useful. use <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/ol"><code>&lt;ol&gt;</code></a> for an ordered list(usually a numbered list) or <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/ul"><code>&lt;ul&gt;</code></a> for an unordered list. Each item in your list should be wrapped in <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/li"><code>&lt;li&gt;</code></a> tags, for "list item".</p>
    <pre><code>
    &lt;section&gt;
        &lt;h2&gt;Great Names for Cats&lt;/h2&gt;
        &lt;ul&gt;
        &lt;li&gt;Fluffy&lt;/li&gt;
        &lt;li&gt;Frisky&lt;/li&gt;
        &lt;li&gt;Patches&lt;/li&gt;
        &lt;/ul&gt;
    &lt;/section&gt;
</code></pre>

<hr>

    <h3 id="ids-and-classes">IDs and Classes</h3>
    <p>Adding classes and IDs to the HTML can help us to create more specific styles, and organize the page more.<br>
    Use an <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/id"><code>id</code></a> attribute when there's only one on the page, and a <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Global_attributes/class"><code>class</code></a> attribute when you might use it multiple times. You can also link to an ID to create a link to a different page section. You can put the ID in pretty much any tag, but the h2/h3 tag of a header, or the section tag are the most common.</p>
    <p>Here's an example</p>
    <pre><code>
    &lt;section class="box"&gt;
        &lt;h2 id="tabbycats"&gt;Tabby Cats&lt;/h2&gt;
        &lt;p&gt;Tabby cats have a striped pattern and are usually brown or grey.&lt;/p&gt;
    &lt;/section&gt;</code></pre>

    <p>Link to an ID on the same page like this<br>
    <code>&lt;a href="#tabbycats"&gt;Tabby Cats&lt;/a&gt;</code></p>

<hr>

<h3 id="styling-boxes-and-borders">Styling Boxes and Borders</h3>
    <p>To style my sections, I can use CSS to select all <code>&lt;section&gt;</code> tags, or I can use a class or ID. Since I added the class "box" to all of my sections in the middle, I can use the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Class_selectors">class selector</a> to style only the sections with the "box" class. </p>
    <p>I can do things like add a <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/border">border</a>, a different background color, font color, font sizes, etc. </p>
    <pre><code>
    .box {
        border-style: solid;
        border-color: white;
        border-width: 1pt;
    }</code></pre>
    <p>This will apply the style to all elements with the class "box". I can also select only <code>&lt;section&gt;</code> elements with the class "box" using <code>element.class</code> like this.</p>
    <pre><code>
    section.box {
        border: solid white 2pt;
        padding: 5pt;
        margin-bottom: 5pt;
    }</code></pre>
    <p>There are several options to choose from with <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/border-style"><code>border-style</code></a>, including dotted, dashed, and double. </p>
    <p>You can make a rounded border with the <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/border-radius"><code>border-radius</code></a> property.</p>
    <pre><code>
    section.box { 
        border-radius: 10%;
    }</code></pre>
    <p>You can select an ID as well, using an <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/ID_selectors">ID selector</a> like <code>#id</code></p>
    <pre><code>
    #tabbycats {
        color: #c095e4;
    }</code></pre>
    <p>In this example, the <code>&lt;h2&gt;</code> with the id attribute <code>tabbycats</code> will be styled with a different text color. </p>

<hr>

<h3 id="photos">Photos</h3>
    <p>I exported my photo with a max-width of 1024px from my photo manager and put it in a subfolder named "photos". The <code>&lt;img&gt;</code> code is the same as before, with a different source and alt text, and I've added a class called <code>photo</code></p>
    <pre><code>&lt;img src="photos/kittenbaby.jpg" alt="A grey and white cat" class="photo" /&gt;</code></pre>
    <p>Now I can style my photo, and any other photos that I give the <code>photo</code> class to, in my stylesheet. I'm giving it a white border, resizing it, and giving it slightly rounded corners.</p>
    <pre><code>
    .photo {
        border: solid white 2pt;
        width: 400px;
        max-width: 100%;
        height: auto;
        border-radius: 10px;
    }</code></pre>

    <p>You might want to link to the full sized photo, using the resized embedded photo as a thumbnail. The HTML for this is just like a regular link, but instead of text for the reader to click on, the <code>&lt;img&gt;</code> code goes there.</p>
    <pre><code>
        &lt;a href="photos/kittenbaby.jpg"&gt;&lt;img src="photos/kittenbaby.jpg" 
        alt="A grey and white cat" class="photo" /&gt;&lt;/a&gt;</code></pre>
    <p>If you want to have a photo with a caption attached, you can keep them all together with the <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/figure"><code>&lt;figure&gt;</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/figcaption"><code>&lt;figcaption&gt;</code></a> tags. Put your <code>&lt;img&gt;</code> after the opening <code>&lt;figure&gt;</code> tag, and write a caption between the <code>&lt;figcaption&gt;</code> tags.</p>
    <pre><code>
    &lt;figure&gt;
    &lt;a href="photos/kittenbaby.jpg"&gt;&lt;img src="photos/kittenbaby.jpg" 
    alt="A grey and white cat" class="photo" /&gt;&lt;/a&gt;
    &lt;figcaption&gt;A cat named Kitten Baby.&lt;/figcaption&gt;
    &lt;/figure&gt;</code></pre>
    <p>We can style these too, if we want.</p>
    <pre><code>
    figure {
        margin: 0;
    }
    
    figcaption {
        color: #FF69B4;
    }</code></pre>

<hr>

<h3 id="using-emoji">Using Emoji</h3>
    <p>All special characters used in HTML documents need a special code to show up properly. Every special character is part of the <a href="https://developer.mozilla.org/en-US/docs/Glossary/Unicode">Unicode</a> character set, and that includes emoji. To get the code for your chosen emoji, you can use a website like <a href="https://emojiguide.org/">EmojiGuide.com</a>. I searched "<a href="https://emojiguide.org/cat">cat</a>" on <a href="https://emojiguide.org/">Emoji Guide</a>, and copied the HTML code, which is this: <code>&amp;#128008;</code> </p>
    <p>Just pasting that code into the HTML as if it were a word made the emoji appear. You can also style your emoji by wrapping it in a tag such as <code>&lt;span&gt;</code> and adding a class such as <code>emoji</code> to it.</p>
    <pre><code>&lt;span class="emoji"&gt;&amp;#128008;&lt;/span&gt;</code></pre>
    <p>Then style the class. I want my emoji to be a little bigger than the rest of my text.</p>
    <pre><code>.emoji {
        font-size: 2rem;
    }</code></pre>

    <hr>

    <h3 id="example">View Examples</h3>
    <p><a href="https://web.pixelshannon.com/make/lesson/index.html">View the example page</a> and the <a href="https://web.pixelshannon.com/make/lesson/style.css">example CSS stylesheet</a></p>
    <p><a href="https://web.pixelshannon.com/make/ballet/index.html">Ballet Website</a> - This is a copy of the website my daughter made using this guide, at age 12, for a school project.</p>
    <p>If you have questions or comments, you can <a href="mailto:reply25@pixelshannon.com?subject=%5Breply%20to%5D%20Make%20Your%20Own%20Website%22">reply by email</a>, <a href="https://bookstodon.com/@shannonkay/113981703308638892">reply on Mastodon</a>, or <a href="https://bsky.app/profile/shannonkay.com/post/3lhu5ebhrvk2l">reply on Bluesky</a>.</p>

<hr>

    <h3 id="host-and-publish-your-website-on-the-internet">Host and Publish Your Website on the Internet</h3>
    <p>To publish your website on the internet, you need to upload your files to a web host. You will need to upload your index.html file as well as any other files your website is using, including your stylesheet css file, images used, and any other html pages.</p>
    <p>If you can, I suggest registering your own domain name (I recommend <a href="https://porkbun.com/">porkbun.com</a> for domain registration). With a domain name, you don't have to change your website address if you change your hosting provider. You simply point the domain name at whichever host you want.</p>
    <h4 id="where-can-i-publish-my-website-for-free">Where can I publish my website for free?</h4>
    <p>Check out my <a href="https://web.pixelshannon.com/freehosts/index.html">Test of Free Web Hosts</a> for more details about using these and even more free hosting options.</p>
    <ul>
    <li><a href="https://yay.boo/">Yay.boo</a> - Super fast and easy to use, just drag and drop your website files into the uploader. They offer free websites up to 10mb(<em>for reference, my example site from this lesson is less than 0.5mb</em>) for free on the yay.boo subdomain, and there's a little ghost icon in the corner of the site. You can subscribe to support the site starting at $25/year to use your own domain names, upload sites up to 25mb, and remove the ghost mascot.</li>
    <li><a href="https://neocities.org/">Neocities</a> - A fun place for creative websites made by individuals. You get a subdomain web address on the free plan. Use their browser-based dashboard to upload your website. Their low cost <a href="https://neocities.org/supporter">supporter plan</a> supports custom domain names and some other extra features.</li>
    <li><a href="https://nekoweb.org/">Nekoweb</a> - Free website community similar to Neocities. Upload or edit your website in the browser. Their <a href="https://nekoweb.org/donate">donator tier</a> offers custom domain support, more space and some other perks.</li>
    <li><a href="https://codeberg.page/">Codeberg Pages</a> - Register an account at <a href="https://codeberg.org/">Codeberg</a> to use this option. They support custom domain names for free. </li>
    <li><a href="https://www.netlify.com/">Netlify</a> - Netlify has a generous free tier and support for <a href="https://docs.netlify.com/domains-https/custom-domains/configure-external-dns/#app">custom domain names</a>. You can use their <a href="https://docs.netlify.com/site-deploys/create-deploys/#drag-and-drop">drag and drop uploader</a>, or deploy with git.</li>
    <li><a href="https://glitch.com/">Glitch</a> - A nice choice if you want to write your website code all in the browser. You get a glitch.me subdomain. Support for custom domains, but you have to <a href="https://help.glitch.com/hc/en-us/articles/16287558909965-Adding-a-Custom-Domain">use fastly to set it up</a>.</li>
    </ul>
    <h4 id="paid-hosting">Paid Hosting</h4>
    <ul>
    <li><a href="https://www.dreamhost.com/hosting/shared/">DreamHost</a> - If you want more advanced web hosting, DreamHost is a reliable hosting provider that's been around for a long time. Their shared hosting plans are good for most people.</li>
    <li><a href="https://neocities.org/supporter">Neocities supporter plan</a> - Get custom domain name support, more space and bandwidth, and some other things, while supporting the Neocities community.</li>
    <li><a href="https://nekoweb.org/donate">Nekoweb donator tier</a> - Support through patreon to get more space, extra sites, and other benefits. Donators help support the whole website.</li>
    <li><a href="https://home.omg.lol/">omg.lol</a> - For $20/yr you get a yourname.omg.lol domain, profile page, webpage, blog, and a bunch of other things like a Mastodon instance. </li>
    <li><a href="https://www.nearlyfreespeech.net/">NearlyFreeSpeech</a> - Pay only for what you use web hosting.</li>
    </ul>

    <hr>
<section id="links">

    <h3 id="more-resources">More Resources</h3>
    <ul>
    <li><a href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web">Getting Started With the Web</a></li>
    <li><a href="https://32bit.cafe/cyowebsite/">32-Bit Cafe: Creating Your Own Website</a></li>
    <li><a href="https://htmlforpeople.com/">HTML For People</a> - This fantastic web book is another take on the beginner's guide to making a first website.</li>  
    <li><a href="https://stefanbohacek.com/blog/resources-for-keeping-the-web-free-open-and-poetic/">Resources for keeping the web free, open, and poetic</a></li>
    <li><a href="https://nowebwithoutwomen.com/">No Web Without Women</a> - A collection of innovations by women in the fields of computer science and technology.</li>
    </ul>
    <h4 id="html-and-css">HTML and CSS</h4>
    <ul>
    
    <li><a href="https://html.com/#tutorial">HTML Tutorial at HTML.com</a></li>
    <li><a href="https://www.w3schools.com/html/">HTML Tutorial at W3 Schools</a></li>
    <li><a href="https://www.w3schools.com/css/css_intro.asp">CSS Tutorial at W3 Schools</a></li>
    <li><a href="https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/CSS_basics">CSS Basics at mdn</a></li>
    <li><a href="https://girlswhocode.com/programs/code-at-home">Girls Who Code Activities</a> </li>
    <li><a href="https://cssreference.io/">CSS Reference</a> - A free visual guide to CSS</li>
    <li><a href="https://flexboxfroggy.com/">Flexbox Froggy</a> - A game for learning CSS flexbox</li>
    <li><a href="http://cssgridgarden.com/">Grid Garden</a> - A game for learning CSS grid layout</li>
    <li><a href="https://developer.mozilla.org/en-US/docs/Web">mdn web docs References</a></li>
    </ul>
    <h4 id="design">Design</h4>
    <ul>
    <li><a href="https://www.color-hex.com/">Color Hex</a> - color hex codes</li>
    <li><a href="https://colorkit.co/">Color Kit</a></li>
    <li><a href="https://girlswhocode.com/assets/images/craft-prod/images/Build-your-best-wireframe-2.pdf">Create a Website Wireframe in Google Slides (Girls Who Code)</a></li>
    </ul>
    <p><a href="https://raindrop.io/shannonkay/resources-34220799/search/sort=-sort&amp;perpage=30&amp;page=0&amp;search=%22%23Make+Your+Own+Website%22">More Resource Links</a></p>
</section>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We replaced our React front end with Go and WebAssembly (230 pts)]]></title>
            <link>https://dagger.io/blog/replaced-react-with-go</link>
            <guid>43008190</guid>
            <pubDate>Tue, 11 Feb 2025 02:13:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dagger.io/blog/replaced-react-with-go">https://dagger.io/blog/replaced-react-with-go</a>, See on <a href="https://news.ycombinator.com/item?id=43008190">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Post" name="Post"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>A few weeks ago, we <!--$--><a href="https://dagger.io/blog/dagger-cloud-v3" rel="noopener">launched Dagger Cloud v3</a><!--/$-->, a completely new user interface for <!--$--><a href="https://dagger.cloud/" rel="noopener">Dagger Cloud</a><!--/$-->. One of the main differences between v3 and its v2 predecessor is that the new UI is written in <!--$--><a href="https://en.wikipedia.org/wiki/WebAssembly" rel="noopener">WebAssembly (WASM)</a><!--/$--> using Go. At first glance, this might seem an odd choice - Go typically isn't the first language you think of when deciding to program a Web UI - but we had good reasons. In this blog post, I'll explain why we chose WebAssembly, some of our implementation challenges (and how we worked around them), and the results.</p><h4>Two Codebases = More Work, Fewer Features</h4><p>Dagger works by building up a DAG of operations and evaluating them, often in parallel. By nature, this is a difficult thing to display. To help users make sense of it, we offer <!--$--><a href="https://docs.dagger.io/features/visualization" rel="noopener">two real-time visualization interfaces</a><!--/$-->: the Dagger terminal UI (TUI), included in the Dagger CLI, and Dagger Cloud, an online Web dashboard. The Dagger TUI is implemented in Go, and Dagger Cloud (pre-v3) was written in React.</p><p>Obviously, we want both user interfaces to be as close to each other as possible. But the actual act of interpreting Dagger's event stream in real-time and producing a UI is pretty involved. Some of the more complex event streams we've seen have hundreds of thousands of OpenTelemetry spans, and managing the data structures around them gets very complicated, very quickly. The Web UI often couldn't keep up with the huge volume of data it had to process and it would become laggy and slow; to fix this performance bottleneck, we were forced into a different implementation model for the React application.</p><p>So, we ended up with two interfaces trying to accomplish the same thing, one of them in one language and ecosystem (TypeScript/React), the other in a totally different language and ecosystem (Go), and we couldn't easily share business logic between them. As a small team, we need to ship fast. Having to re-implement every feature twice was just a massive tax on our velocity.</p><p>We started thinking about a new approach to Dagger Cloud, with two main goals:</p><ul><li data-preset-tag="p"><p>Unify the codebases, to eliminate duplication and make it more efficient to ship new features</p></li><li data-preset-tag="p"><p>Deliver on the promise of a crisp, snappy Web UI, matching the speed and performance of the terminal UI</p></li></ul><h4>Choosing Go + WebAssembly</h4><p>Our starting goal was to be able to reuse one codebase for both Dagger Cloud and the TUI. We decided fairly early to make it a Go codebase. Technically, we could have gone the other way and used TypeScript for the TUI. But we're primarily a team of Go engineers, so selecting Go made it easier for others in the team to contribute, to add a feature or drop in for a few hours to help debug an issue. In addition to standardizing on a single language, it gave us flexibility and broke down silos in our team.</p><p>Once we decided to run Go code directly in the browser, WebAssembly was the logical next step. But there were still a couple of challenges:</p><ul><li data-preset-tag="p"><p>The Go + WebAssembly combination is still not as mature as React and other JavaScript frameworks. There are no ready-made component libraries to pull from, the developer tooling isn't as rich, and so on. We knew that we would need to build most of our UI components from scratch.</p></li><li data-preset-tag="p"><p>There is a hard 2 GB memory limit for WebAssembly applications in most browsers. We expected this to be a problem when viewing large traces, and we knew we would have to do a lot of optimization to minimize memory usage and keep the UI stable. This wasn't entirely bad though; the silver lining here was that any memory usage improvements made to the WebAssembly UI would also benefit TUI users, since it was now a shared codebase.</p></li></ul><h4>De-Risking the Project</h4><p>Once we'd made the decision, the next question was, "how do we build this?" We decided to build the new WebAssembly-based UI in the <!--$--><a href="https://go-app.dev/" rel="noopener">Go-app framework</a><!--/$-->. Go-app is a high-level framework specifically for <!--$--><a href="https://en.wikipedia.org/wiki/Progressive_web_app" rel="noopener">Progressive Web Apps (PWAs)</a><!--/$--> in WebAssembly. It offers key Go benefits, like fast compilation and native static typing, and it also follows a component-based UI model, like React, which made the transition easier.</p><p>Since the Go + WebAssembly combination isn't mainstream, there was some healthy skepticism within the Dagger team about its feasibility. For example, there was no real ecosystem for Go-app UI components and we knew we’d have to write our own, but we weren’t sure how easy or difficult this would be. We also had concerns over integrations with other services (Tailwind, Auth0, Intercom, PostHog), and about rendering many hundreds of live-updating components at the same time.&nbsp;</p><p>To answer these questions and de-risk the project, I spent almost a month prototyping, with the goal of re-implementing as much of the existing UI as possible in Go-app. As it turned out, there weren't many blockers: WebAssembly is already a <!--$--><a href="https://webassembly.org/specs/" rel="noopener">well-documented open standard</a><!--/$--> and most other questions were answered in <!--$--><a href="https://go-app.dev/reference" rel="noopener">Go-app’s own documentation</a><!--/$-->. The biggest challenge, as expected, was the memory usage limit, which required careful design and optimization.</p><h4>From Prototype to Production</h4><p>Once we had a working proof of concept, the team's comfort level increased significantly and we kicked off project "awesome wasm" to deliver a production implementation. Here are a few notes from the journey:</p><ul><li data-preset-tag="p"><p>Memory usage was easily the most existential threat to the project’s success. I spent a lot of time figuring out how to render 200k+ lines of log output without crashing. This led to optimizations deep in our <!--$--><a href="https://github.com/vito/midterm" rel="noopener">virtual terminal rendering library</a><!--/$-->, which dramatically reduced TUI memory usage at the same time (as mentioned already, sharing codebases means that important optimizations in one interface become "free" in the other!)</p></li><li data-preset-tag="p"><p>Go WASM is slow at parsing large amounts of JSON, which led to dramatic architecture changes and the creation of a “smart backend” for incremental data loading over WebSockets, using Go's rarely-used <!--$--><a href="https://pkg.go.dev/encoding/gob" rel="noopener">encoding/gob format</a><!--/$-->.</p></li><li data-preset-tag="p"><p>Initially, the WASM file was around 32 MB. By applying <!--$--><a href="https://github.com/google/brotli" rel="noopener">Brotli compression</a><!--/$-->, we were able to bring it down to around 4.6 MB. We tried to perform Brotli compression on-the-fly in our CDN but the file was too large, so eventually we just included the compression step into our build process.</p></li><li data-preset-tag="p"><p>Apart from the memory challenges, most of our other initial worries turned out unfounded. The UI components weren’t very hard to write, integrations with other services were straightforward, and I found good techniques for handling component updates in real-time.</p></li><li data-preset-tag="p"><p>There were a number of useful NPM packages I found, so I wondered if I could use them with Go. WebAssembly has a straightforward interface to both Go and JavaScript, so I built a <!--$--><a href="https://daggerverse.dev/mod/github.com/vito/daggerverse/browserify@d368836636284116d090e271742904fea369cf72" rel="noopener">Dagger module that uses Browserify to load an NPM package</a><!--/$-->. This module allows us to generate a JavaScript file that can be included in a Go application. This means that we can work primarily in Go and then, if needed, we have a way to load helpers that are implemented in native JavaScript.</p></li><li data-preset-tag="p"><p>Disclaimer: I'm not a React professional so with that in mind...it seemed to me that React had a very rigid way of implementing components, while Go-app was much more flexible. In Go-app, you can have any component update whenever you like, which gives you many more degrees of freedom for optimization. For example, I needed to optimize a component rendering 150,000+ lines of output. Just having the ability to try different approaches and then pick the one that worked best, made the entire exercise much easier!</p></li><li data-preset-tag="p"><p>Even though Go-app doesn't have React-like developer tools built into the browser, I was able to use Go's own tools (pprof) plus the default profiler built into the browser for profiling and debugging. This was very useful to inspect functions calls, track CPU and memory usage, and evaluate the effectiveness of different approaches for optimizing memory usage.</p></li><li data-preset-tag="p"><p>I discovered a side benefit of using Go-app: since Dagger Cloud is built as a PWA, it can be installed as a desktop or a mobile application. This makes it possible to launch Dagger Cloud like a native application and get a full-screen experience without needing to open a browser first, or just have a dedicated icon in your desktop taskbar/dock.</p></li></ul><p>We soft-launched Dagger Cloud v3 to our <!--$--><a href="https://dagger.io/commanders" rel="noopener">Dagger Commanders</a><!--/$--> a few weeks ago to collect feedback and made it available to everyone shortly thereafter.</p><h4>Benefits</h4><p>Our switch from React to WASM has resulted in a more consistent user experience across all Dagger interfaces, and better overall performance and lower memory usage, especially when rendering large and complex traces.</p><p>From an engineering perspective too, the benefits to our team are significant. Optimizations very often involve just as much, if not more, work than actually implementing features. So it's great to not have to spend time optimizing the Web UI, and then more time optimizing the TUI, and instead actually focus on delivering new features.</p><h4>Should You Do This?</h4><p>Dagger Cloud v3 has the Dagger community buzzing and one of the more common questions we've been fielding recently is: who should consider doing this and who shouldn't?</p><p>We want to be clear that we're not generally recommending making front-ends in Go. We had some very good reasons to do it: a team of strong Go engineers; a complex UI that TypeScript/React didn't scale well for; a requirement for standardization and reuse between two codebases; and a company-wide mandate to increase our velocity. That's a fairly specific set of circumstances. If you're in similar circumstances, this is certainly an option worth evaluating; if not, there are other tools and standards that you should consider first.</p><p>Dagger Cloud v3 is still in beta and we're excited for you to <!--$--><a href="https://v3.dagger.cloud/" rel="noopener">try it out</a><!--/$-->. If you'd like to know more about our implementation or simply have feedback to share on the new UI, join our Discord and <!--$--><a href="https://discord.com/invite/dagger-io" rel="noopener">let us know</a><!--/$--> what you think!</p></div><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>A few weeks ago, we <!--$--><a href="https://dagger.io/blog/dagger-cloud-v3" rel="noopener">launched Dagger Cloud v3</a><!--/$-->, a completely new user interface for <!--$--><a href="https://dagger.cloud/" rel="noopener">Dagger Cloud</a><!--/$-->. One of the main differences between v3 and its v2 predecessor is that the new UI is written in <!--$--><a href="https://en.wikipedia.org/wiki/WebAssembly" rel="noopener">WebAssembly (WASM)</a><!--/$--> using Go. At first glance, this might seem an odd choice - Go typically isn't the first language you think of when deciding to program a Web UI - but we had good reasons. In this blog post, I'll explain why we chose WebAssembly, some of our implementation challenges (and how we worked around them), and the results.</p><h4>Two Codebases = More Work, Fewer Features</h4><p>Dagger works by building up a DAG of operations and evaluating them, often in parallel. By nature, this is a difficult thing to display. To help users make sense of it, we offer <!--$--><a href="https://docs.dagger.io/features/visualization" rel="noopener">two real-time visualization interfaces</a><!--/$-->: the Dagger terminal UI (TUI), included in the Dagger CLI, and Dagger Cloud, an online Web dashboard. The Dagger TUI is implemented in Go, and Dagger Cloud (pre-v3) was written in React.</p><p>Obviously, we want both user interfaces to be as close to each other as possible. But the actual act of interpreting Dagger's event stream in real-time and producing a UI is pretty involved. Some of the more complex event streams we've seen have hundreds of thousands of OpenTelemetry spans, and managing the data structures around them gets very complicated, very quickly. The Web UI often couldn't keep up with the huge volume of data it had to process and it would become laggy and slow; to fix this performance bottleneck, we were forced into a different implementation model for the React application.</p><p>So, we ended up with two interfaces trying to accomplish the same thing, one of them in one language and ecosystem (TypeScript/React), the other in a totally different language and ecosystem (Go), and we couldn't easily share business logic between them. As a small team, we need to ship fast. Having to re-implement every feature twice was just a massive tax on our velocity.</p><p>We started thinking about a new approach to Dagger Cloud, with two main goals:</p><ul><li data-preset-tag="p"><p>Unify the codebases, to eliminate duplication and make it more efficient to ship new features</p></li><li data-preset-tag="p"><p>Deliver on the promise of a crisp, snappy Web UI, matching the speed and performance of the terminal UI</p></li></ul><h4>Choosing Go + WebAssembly</h4><p>Our starting goal was to be able to reuse one codebase for both Dagger Cloud and the TUI. We decided fairly early to make it a Go codebase. Technically, we could have gone the other way and used TypeScript for the TUI. But we're primarily a team of Go engineers, so selecting Go made it easier for others in the team to contribute, to add a feature or drop in for a few hours to help debug an issue. In addition to standardizing on a single language, it gave us flexibility and broke down silos in our team.</p><p>Once we decided to run Go code directly in the browser, WebAssembly was the logical next step. But there were still a couple of challenges:</p><ul><li data-preset-tag="p"><p>The Go + WebAssembly combination is still not as mature as React and other JavaScript frameworks. There are no ready-made component libraries to pull from, the developer tooling isn't as rich, and so on. We knew that we would need to build most of our UI components from scratch.</p></li><li data-preset-tag="p"><p>There is a hard 2 GB memory limit for WebAssembly applications in most browsers. We expected this to be a problem when viewing large traces, and we knew we would have to do a lot of optimization to minimize memory usage and keep the UI stable. This wasn't entirely bad though; the silver lining here was that any memory usage improvements made to the WebAssembly UI would also benefit TUI users, since it was now a shared codebase.</p></li></ul><h4>De-Risking the Project</h4><p>Once we'd made the decision, the next question was, "how do we build this?" We decided to build the new WebAssembly-based UI in the <!--$--><a href="https://go-app.dev/" rel="noopener">Go-app framework</a><!--/$-->. Go-app is a high-level framework specifically for <!--$--><a href="https://en.wikipedia.org/wiki/Progressive_web_app" rel="noopener">Progressive Web Apps (PWAs)</a><!--/$--> in WebAssembly. It offers key Go benefits, like fast compilation and native static typing, and it also follows a component-based UI model, like React, which made the transition easier.</p><p>Since the Go + WebAssembly combination isn't mainstream, there was some healthy skepticism within the Dagger team about its feasibility. For example, there was no real ecosystem for Go-app UI components and we knew we’d have to write our own, but we weren’t sure how easy or difficult this would be. We also had concerns over integrations with other services (Tailwind, Auth0, Intercom, PostHog), and about rendering many hundreds of live-updating components at the same time.&nbsp;</p><p>To answer these questions and de-risk the project, I spent almost a month prototyping, with the goal of re-implementing as much of the existing UI as possible in Go-app. As it turned out, there weren't many blockers: WebAssembly is already a <!--$--><a href="https://webassembly.org/specs/" rel="noopener">well-documented open standard</a><!--/$--> and most other questions were answered in <!--$--><a href="https://go-app.dev/reference" rel="noopener">Go-app’s own documentation</a><!--/$-->. The biggest challenge, as expected, was the memory usage limit, which required careful design and optimization.</p><h4>From Prototype to Production</h4><p>Once we had a working proof of concept, the team's comfort level increased significantly and we kicked off project "awesome wasm" to deliver a production implementation. Here are a few notes from the journey:</p><ul><li data-preset-tag="p"><p>Memory usage was easily the most existential threat to the project’s success. I spent a lot of time figuring out how to render 200k+ lines of log output without crashing. This led to optimizations deep in our <!--$--><a href="https://github.com/vito/midterm" rel="noopener">virtual terminal rendering library</a><!--/$-->, which dramatically reduced TUI memory usage at the same time (as mentioned already, sharing codebases means that important optimizations in one interface become "free" in the other!)</p></li><li data-preset-tag="p"><p>Go WASM is slow at parsing large amounts of JSON, which led to dramatic architecture changes and the creation of a “smart backend” for incremental data loading over WebSockets, using Go's rarely-used <!--$--><a href="https://pkg.go.dev/encoding/gob" rel="noopener">encoding/gob format</a><!--/$-->.</p></li><li data-preset-tag="p"><p>Initially, the WASM file was around 32 MB. By applying <!--$--><a href="https://github.com/google/brotli" rel="noopener">Brotli compression</a><!--/$-->, we were able to bring it down to around 4.6 MB. We tried to perform Brotli compression on-the-fly in our CDN but the file was too large, so eventually we just included the compression step into our build process.</p></li><li data-preset-tag="p"><p>Apart from the memory challenges, most of our other initial worries turned out unfounded. The UI components weren’t very hard to write, integrations with other services were straightforward, and I found good techniques for handling component updates in real-time.</p></li><li data-preset-tag="p"><p>There were a number of useful NPM packages I found, so I wondered if I could use them with Go. WebAssembly has a straightforward interface to both Go and JavaScript, so I built a <!--$--><a href="https://daggerverse.dev/mod/github.com/vito/daggerverse/browserify@d368836636284116d090e271742904fea369cf72" rel="noopener">Dagger module that uses Browserify to load an NPM package</a><!--/$-->. This module allows us to generate a JavaScript file that can be included in a Go application. This means that we can work primarily in Go and then, if needed, we have a way to load helpers that are implemented in native JavaScript.</p></li><li data-preset-tag="p"><p>Disclaimer: I'm not a React professional so with that in mind...it seemed to me that React had a very rigid way of implementing components, while Go-app was much more flexible. In Go-app, you can have any component update whenever you like, which gives you many more degrees of freedom for optimization. For example, I needed to optimize a component rendering 150,000+ lines of output. Just having the ability to try different approaches and then pick the one that worked best, made the entire exercise much easier!</p></li><li data-preset-tag="p"><p>Even though Go-app doesn't have React-like developer tools built into the browser, I was able to use Go's own tools (pprof) plus the default profiler built into the browser for profiling and debugging. This was very useful to inspect functions calls, track CPU and memory usage, and evaluate the effectiveness of different approaches for optimizing memory usage.</p></li><li data-preset-tag="p"><p>I discovered a side benefit of using Go-app: since Dagger Cloud is built as a PWA, it can be installed as a desktop or a mobile application. This makes it possible to launch Dagger Cloud like a native application and get a full-screen experience without needing to open a browser first, or just have a dedicated icon in your desktop taskbar/dock.</p></li></ul><p>We soft-launched Dagger Cloud v3 to our <!--$--><a href="https://dagger.io/commanders" rel="noopener">Dagger Commanders</a><!--/$--> a few weeks ago to collect feedback and made it available to everyone shortly thereafter.</p><h4>Benefits</h4><p>Our switch from React to WASM has resulted in a more consistent user experience across all Dagger interfaces, and better overall performance and lower memory usage, especially when rendering large and complex traces.</p><p>From an engineering perspective too, the benefits to our team are significant. Optimizations very often involve just as much, if not more, work than actually implementing features. So it's great to not have to spend time optimizing the Web UI, and then more time optimizing the TUI, and instead actually focus on delivering new features.</p><h4>Should You Do This?</h4><p>Dagger Cloud v3 has the Dagger community buzzing and one of the more common questions we've been fielding recently is: who should consider doing this and who shouldn't?</p><p>We want to be clear that we're not generally recommending making front-ends in Go. We had some very good reasons to do it: a team of strong Go engineers; a complex UI that TypeScript/React didn't scale well for; a requirement for standardization and reuse between two codebases; and a company-wide mandate to increase our velocity. That's a fairly specific set of circumstances. If you're in similar circumstances, this is certainly an option worth evaluating; if not, there are other tools and standards that you should consider first.</p><p>Dagger Cloud v3 is still in beta and we're excited for you to <!--$--><a href="https://v3.dagger.cloud/" rel="noopener">try it out</a><!--/$-->. If you'd like to know more about our implementation or simply have feedback to share on the new UI, join our Discord and <!--$--><a href="https://discord.com/invite/dagger-io" rel="noopener">let us know</a><!--/$--> what you think!</p></div><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>A few weeks ago, we <!--$--><a href="https://dagger.io/blog/dagger-cloud-v3" rel="noopener">launched Dagger Cloud v3</a><!--/$-->, a completely new user interface for <!--$--><a href="https://dagger.cloud/" rel="noopener">Dagger Cloud</a><!--/$-->. One of the main differences between v3 and its v2 predecessor is that the new UI is written in <!--$--><a href="https://en.wikipedia.org/wiki/WebAssembly" rel="noopener">WebAssembly (WASM)</a><!--/$--> using Go. At first glance, this might seem an odd choice - Go typically isn't the first language you think of when deciding to program a Web UI - but we had good reasons. In this blog post, I'll explain why we chose WebAssembly, some of our implementation challenges (and how we worked around them), and the results.</p><h4>Two Codebases = More Work, Fewer Features</h4><p>Dagger works by building up a DAG of operations and evaluating them, often in parallel. By nature, this is a difficult thing to display. To help users make sense of it, we offer <!--$--><a href="https://docs.dagger.io/features/visualization" rel="noopener">two real-time visualization interfaces</a><!--/$-->: the Dagger terminal UI (TUI), included in the Dagger CLI, and Dagger Cloud, an online Web dashboard. The Dagger TUI is implemented in Go, and Dagger Cloud (pre-v3) was written in React.</p><p>Obviously, we want both user interfaces to be as close to each other as possible. But the actual act of interpreting Dagger's event stream in real-time and producing a UI is pretty involved. Some of the more complex event streams we've seen have hundreds of thousands of OpenTelemetry spans, and managing the data structures around them gets very complicated, very quickly. The Web UI often couldn't keep up with the huge volume of data it had to process and it would become laggy and slow; to fix this performance bottleneck, we were forced into a different implementation model for the React application.</p><p>So, we ended up with two interfaces trying to accomplish the same thing, one of them in one language and ecosystem (TypeScript/React), the other in a totally different language and ecosystem (Go), and we couldn't easily share business logic between them. As a small team, we need to ship fast. Having to re-implement every feature twice was just a massive tax on our velocity.</p><p>We started thinking about a new approach to Dagger Cloud, with two main goals:</p><ul><li data-preset-tag="p"><p>Unify the codebases, to eliminate duplication and make it more efficient to ship new features</p></li><li data-preset-tag="p"><p>Deliver on the promise of a crisp, snappy Web UI, matching the speed and performance of the terminal UI</p></li></ul><h4>Choosing Go + WebAssembly</h4><p>Our starting goal was to be able to reuse one codebase for both Dagger Cloud and the TUI. We decided fairly early to make it a Go codebase. Technically, we could have gone the other way and used TypeScript for the TUI. But we're primarily a team of Go engineers, so selecting Go made it easier for others in the team to contribute, to add a feature or drop in for a few hours to help debug an issue. In addition to standardizing on a single language, it gave us flexibility and broke down silos in our team.</p><p>Once we decided to run Go code directly in the browser, WebAssembly was the logical next step. But there were still a couple of challenges:</p><ul><li data-preset-tag="p"><p>The Go + WebAssembly combination is still not as mature as React and other JavaScript frameworks. There are no ready-made component libraries to pull from, the developer tooling isn't as rich, and so on. We knew that we would need to build most of our UI components from scratch.</p></li><li data-preset-tag="p"><p>There is a hard 2 GB memory limit for WebAssembly applications in most browsers. We expected this to be a problem when viewing large traces, and we knew we would have to do a lot of optimization to minimize memory usage and keep the UI stable. This wasn't entirely bad though; the silver lining here was that any memory usage improvements made to the WebAssembly UI would also benefit TUI users, since it was now a shared codebase.</p></li></ul><h4>De-Risking the Project</h4><p>Once we'd made the decision, the next question was, "how do we build this?" We decided to build the new WebAssembly-based UI in the <!--$--><a href="https://go-app.dev/" rel="noopener">Go-app framework</a><!--/$-->. Go-app is a high-level framework specifically for <!--$--><a href="https://en.wikipedia.org/wiki/Progressive_web_app" rel="noopener">Progressive Web Apps (PWAs)</a><!--/$--> in WebAssembly. It offers key Go benefits, like fast compilation and native static typing, and it also follows a component-based UI model, like React, which made the transition easier.</p><p>Since the Go + WebAssembly combination isn't mainstream, there was some healthy skepticism within the Dagger team about its feasibility. For example, there was no real ecosystem for Go-app UI components and we knew we’d have to write our own, but we weren’t sure how easy or difficult this would be. We also had concerns over integrations with other services (Tailwind, Auth0, Intercom, PostHog), and about rendering many hundreds of live-updating components at the same time.&nbsp;</p><p>To answer these questions and de-risk the project, I spent almost a month prototyping, with the goal of re-implementing as much of the existing UI as possible in Go-app. As it turned out, there weren't many blockers: WebAssembly is already a <!--$--><a href="https://webassembly.org/specs/" rel="noopener">well-documented open standard</a><!--/$--> and most other questions were answered in <!--$--><a href="https://go-app.dev/reference" rel="noopener">Go-app’s own documentation</a><!--/$-->. The biggest challenge, as expected, was the memory usage limit, which required careful design and optimization.</p><h4>From Prototype to Production</h4><p>Once we had a working proof of concept, the team's comfort level increased significantly and we kicked off project "awesome wasm" to deliver a production implementation. Here are a few notes from the journey:</p><ul><li data-preset-tag="p"><p>Memory usage was easily the most existential threat to the project’s success. I spent a lot of time figuring out how to render 200k+ lines of log output without crashing. This led to optimizations deep in our <!--$--><a href="https://github.com/vito/midterm" rel="noopener">virtual terminal rendering library</a><!--/$-->, which dramatically reduced TUI memory usage at the same time (as mentioned already, sharing codebases means that important optimizations in one interface become "free" in the other!)</p></li><li data-preset-tag="p"><p>Go WASM is slow at parsing large amounts of JSON, which led to dramatic architecture changes and the creation of a “smart backend” for incremental data loading over WebSockets, using Go's rarely-used <!--$--><a href="https://pkg.go.dev/encoding/gob" rel="noopener">encoding/gob format</a><!--/$-->.</p></li><li data-preset-tag="p"><p>Initially, the WASM file was around 32 MB. By applying <!--$--><a href="https://github.com/google/brotli" rel="noopener">Brotli compression</a><!--/$-->, we were able to bring it down to around 4.6 MB. We tried to perform Brotli compression on-the-fly in our CDN but the file was too large, so eventually we just included the compression step into our build process.</p></li><li data-preset-tag="p"><p>Apart from the memory challenges, most of our other initial worries turned out unfounded. The UI components weren’t very hard to write, integrations with other services were straightforward, and I found good techniques for handling component updates in real-time.</p></li><li data-preset-tag="p"><p>There were a number of useful NPM packages I found, so I wondered if I could use them with Go. WebAssembly has a straightforward interface to both Go and JavaScript, so I built a <!--$--><a href="https://daggerverse.dev/mod/github.com/vito/daggerverse/browserify@d368836636284116d090e271742904fea369cf72" rel="noopener">Dagger module that uses Browserify to load an NPM package</a><!--/$-->. This module allows us to generate a JavaScript file that can be included in a Go application. This means that we can work primarily in Go and then, if needed, we have a way to load helpers that are implemented in native JavaScript.</p></li><li data-preset-tag="p"><p>Disclaimer: I'm not a React professional so with that in mind...it seemed to me that React had a very rigid way of implementing components, while Go-app was much more flexible. In Go-app, you can have any component update whenever you like, which gives you many more degrees of freedom for optimization. For example, I needed to optimize a component rendering 150,000+ lines of output. Just having the ability to try different approaches and then pick the one that worked best, made the entire exercise much easier!</p></li><li data-preset-tag="p"><p>Even though Go-app doesn't have React-like developer tools built into the browser, I was able to use Go's own tools (pprof) plus the default profiler built into the browser for profiling and debugging. This was very useful to inspect functions calls, track CPU and memory usage, and evaluate the effectiveness of different approaches for optimizing memory usage.</p></li><li data-preset-tag="p"><p>I discovered a side benefit of using Go-app: since Dagger Cloud is built as a PWA, it can be installed as a desktop or a mobile application. This makes it possible to launch Dagger Cloud like a native application and get a full-screen experience without needing to open a browser first, or just have a dedicated icon in your desktop taskbar/dock.</p></li></ul><p>We soft-launched Dagger Cloud v3 to our <!--$--><a href="https://dagger.io/commanders" rel="noopener">Dagger Commanders</a><!--/$--> a few weeks ago to collect feedback and made it available to everyone shortly thereafter.</p><h4>Benefits</h4><p>Our switch from React to WASM has resulted in a more consistent user experience across all Dagger interfaces, and better overall performance and lower memory usage, especially when rendering large and complex traces.</p><p>From an engineering perspective too, the benefits to our team are significant. Optimizations very often involve just as much, if not more, work than actually implementing features. So it's great to not have to spend time optimizing the Web UI, and then more time optimizing the TUI, and instead actually focus on delivering new features.</p><h4>Should You Do This?</h4><p>Dagger Cloud v3 has the Dagger community buzzing and one of the more common questions we've been fielding recently is: who should consider doing this and who shouldn't?</p><p>We want to be clear that we're not generally recommending making front-ends in Go. We had some very good reasons to do it: a team of strong Go engineers; a complex UI that TypeScript/React didn't scale well for; a requirement for standardization and reuse between two codebases; and a company-wide mandate to increase our velocity. That's a fairly specific set of circumstances. If you're in similar circumstances, this is certainly an option worth evaluating; if not, there are other tools and standards that you should consider first.</p><p>Dagger Cloud v3 is still in beta and we're excited for you to <!--$--><a href="https://v3.dagger.cloud/" rel="noopener">try it out</a><!--/$-->. If you'd like to know more about our implementation or simply have feedback to share on the new UI, join our Discord and <!--$--><a href="https://discord.com/invite/dagger-io" rel="noopener">let us know</a><!--/$--> what you think!</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Copyover MUD Servers Worked (163 pts)]]></title>
            <link>http://jackkelly.name/blog/archives/2025/02/06/how_copyover_mud_servers_worked/</link>
            <guid>43007769</guid>
            <pubDate>Tue, 11 Feb 2025 01:19:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://jackkelly.name/blog/archives/2025/02/06/how_copyover_mud_servers_worked/">http://jackkelly.name/blog/archives/2025/02/06/how_copyover_mud_servers_worked/</a>, See on <a href="https://news.ycombinator.com/item?id=43007769">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <div><p>
  Posted on February  6, 2025
  
    by Jack Kelly
  

  
    </p>
  
</div>

  <p>When I was younger, I played a lot of MUDs (“<a href="https://mudconnect.com/mudfaq/mudfaq-p1.html#q1">Multi-User
Dungeons</a>” — the text-only predecessors of modern MMORPGs, often
played over <a href="https://en.wikipedia.org/wiki/Telnet">Telnet</a>).
They were great fun, particularly during high school: a lightweight
multiplayer game with no client state meant you could log in from any
machine in any lab, even Windows shipped a Telnet client in those days,
the Telnet protocol was light enough to run on my school’s slow PCs and
limited internet connection, and the lack of flashy graphics meant it
was easy to hide the window from a passing teacher or librarian.</p>
<p>At some point, building and tinkering with MUDs became more
interesting than playing them. In those days, MUD builders and wizards
(admins) were often recruited from each game’s playerbase, and many MUDs
let builders edit the world through in-game commands. This was
incredibly cool at the time — even through a clumsy line-oriented (<a href="https://www.gnu.org/software/ed/"><code>ed</code>-style</a>)
editor, there was something magical about summoning blank rooms from the
void, writing rich descriptions to turn them into “real” spaces, and
adding items and “mobs” (Mobile OBJects — NPCs) to make them come to
life. A few of my friends and I signed up to a “builder academy” MUD,
where everyone got a zone to mess around in, and we tried our hand at
crafting our own areas. Most of these projects didn’t get very far, and
all of them have been lost to time.</p>
<p>There’s only so much you can do with builder rights on someone else’s
MUD. To really change the game, you needed to be able to code, and most
MUDs were written “real languages” like C. We’d managed to get a copy of
Visual C++ 6 and the <a href="https://www.circlemud.org/">CircleMUD</a>
source code, and started messing about. But the development cycle was
pretty frustrating — for every change, you had to recompile the server,
shut it down (dropping everyone’s connections), bring it back up, and
wait for everyone to log back in.</p>
<p>Some MUDs used a very cool trick to avoid this, called “copyover” or
“hotboot”. It’s an idiom that lets a stateful server replace itself
while retaining its PID and open connections. It seemed like magic back
then: you recompiled the server, sent the right command, everything
froze for a few seconds, and (if you were lucky) it came back to life
running the latest code. The trick is simple but I can’t find a detailed
write-up, so I wanted to write it out while I thought of it.</p>
<!--more-->
<p>The copyover method I’m most familiar with works like this:</p>
<ol type="1">
<li><p>The copyover command is invoked by a MUD admin.</p></li>
<li><p>The server calls <a href="https://www.man7.org/linux/man-pages/man2/pipe.2.html"><code>pipe(2)</code></a>
to create a “pipe”. This is the data channel that the new version of the
server will read from, and the old version of the server will write
to.</p></li>
<li><p>The server calls <a href="https://www.man7.org/linux/man-pages/man2/fork.2.html"><code>fork(2)</code></a>,
creating a copy of itself with the same state. We now have a
<strong>parent</strong> and a <strong>child</strong> process.</p></li>
<li><p>The <strong>child</strong> closes the read end of the pipe,
writes the game state into the pipe, and then exits.</p></li>
<li><p>(In parallel with №3) The <strong>parent</strong> closes the
write end of the pipe and calls an <a href="https://man7.org/linux/man-pages/man3/exec.3.html"><code>exec(3)</code></a>
function to replace itself with the new binary. This <code>exec</code>
usually includes a specific “copyover” flag on the command line as well
as the FD for the read end of the pipe. File descriptors, including open
sockets, will remain open across the <code>exec()</code> call.</p></li>
<li><p>(In parallel with №3) The <strong>parent</strong>, now running
the new code, reads the game state through the pipe and then closes
it.</p></li>
<li><p>The <strong>parent</strong> calls <a href="https://man7.org/linux/man-pages/man2/wait.2.html"><code>wait(2)</code></a>
to clear away the zombie <strong>child</strong> process.</p></li>
</ol>
<p>At this point, we’ve achieved all of our goals. The server is running
the new code with the old state under the old PID. The biggest weakness
I see with this scheme is that if the new server fails to come up,
you’ve got no way to abort the copyover and you lose all your state. If
you give up maintaining a constant PID, I can imagine more elaborate and
robust schemes; for example, swapping out the pipe for something more
sophisticated allows the new server to report that it’s ready to take
over. It’s also possible to be smarter about how file descriptors are
handled: A server could split network connection handling off into a
separate process from the game logic (and have them communicate over
Unix domain sockets), pass sockets to the replacing server using <a href="https://www.man7.org/linux/man-pages/man7/unix.7.html#:~:text=SCM_RIGHTS"><code>SCM_RIGHTS</code></a>,
store copyover state in a <a href="https://man7.org/linux/man-pages/man2/memfd_create.2.html">memfd</a>,
or use <a href="https://systemd.io/FILE_DESCRIPTOR_STORE/">systemd’s
file descriptor store</a> to hold your memfds and socket fds while
systemd replaces your process. I don’t know what the most modern idioms
are, I just wanted to document how it used to work.</p>
<p>A simple copyover server uses well-known Unix primitives — pipes,
<code>fork(2)</code>, and file descriptor persistence across
<code>exec(3)</code> — but it doesn’t take much to prove that
sufficiently clever use of Unix is <a href="https://archive.org/details/unix-magic-poster-gary-overcare-1">indistinguishable
from magic</a>. (Other examples: <a href="https://factorio.com/blog/post/fff-408#:~:text=Asynchronous%20saving">Factorio
using <code>fork(2)</code> to implement asynchronous saving on macOS and
GNU/Linux</a>; <a href="https://blog.cloudflare.com/know-your-scm_rights/">Cloudflare
using <code>SCM_RIGHTS</code> to send TLS 1.3 connections to a separate
process</a>.) Much of the apparent magic comes not from Unix itself
being magical, but because many of its primitives now lie hidden beneath
cross-language runtimes or platform abstraction libraries, or are even
forgotten outright. I’d started this post just looking to document the
old way of copying over a stateful server, but the things I’ve found
along the way make me want to dig further. What else have I missed? Is
Stevens’ <em>Advanced Programming in the UNIX Environment</em> still the
canonical reference?</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Floppotron 3.0 (2022) (124 pts)]]></title>
            <link>https://silent.org.pl/home/2022/06/13/the-floppotron-3-0/</link>
            <guid>43007628</guid>
            <pubDate>Tue, 11 Feb 2025 01:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://silent.org.pl/home/2022/06/13/the-floppotron-3-0/">https://silent.org.pl/home/2022/06/13/the-floppotron-3-0/</a>, See on <a href="https://news.ycombinator.com/item?id=43007628">Hacker News</a></p>
Couldn't get https://silent.org.pl/home/2022/06/13/the-floppotron-3-0/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Fun with C++26 reflection: Keyword Arguments (114 pts)]]></title>
            <link>https://pydong.org/posts/KwArgs/</link>
            <guid>43006536</guid>
            <pubDate>Mon, 10 Feb 2025 23:16:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pydong.org/posts/KwArgs/">https://pydong.org/posts/KwArgs/</a>, See on <a href="https://news.ycombinator.com/item?id=43006536">Hacker News</a></p>
Couldn't get https://pydong.org/posts/KwArgs/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Hedge Funds Are Pocketing Much of Their Clients' Gains with 'No Limit' Fees (144 pts)]]></title>
            <link>https://www.bloomberg.com/graphics/2025-hedge-fund-investment-fees/</link>
            <guid>43006390</guid>
            <pubDate>Mon, 10 Feb 2025 22:57:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/graphics/2025-hedge-fund-investment-fees/">https://www.bloomberg.com/graphics/2025-hedge-fund-investment-fees/</a>, See on <a href="https://news.ycombinator.com/item?id=43006390">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/graphics/2025-hedge-fund-investment-fees/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Elon Musk-Led Group Makes $97.4B Bid for Control of OpenAI (649 pts)]]></title>
            <link>https://www.wsj.com/tech/elon-musk-openai-bid-4af12827</link>
            <guid>43004889</guid>
            <pubDate>Mon, 10 Feb 2025 20:42:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/elon-musk-openai-bid-4af12827">https://www.wsj.com/tech/elon-musk-openai-bid-4af12827</a>, See on <a href="https://news.ycombinator.com/item?id=43004889">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/elon-musk-openai-bid-4af12827: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling up test-time compute with latent reasoning: A recurrent depth approach (130 pts)]]></title>
            <link>https://arxiv.org/abs/2502.05171</link>
            <guid>43004416</guid>
            <pubDate>Mon, 10 Feb 2025 19:50:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2502.05171">https://arxiv.org/abs/2502.05171</a>, See on <a href="https://news.ycombinator.com/item?id=43004416">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2502.05171">View PDF</a>
    <a href="https://arxiv.org/html/2502.05171v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We study a novel language model architecture that is capable of scaling test-time computation by implicitly reasoning in latent space. Our model works by iterating a recurrent block, thereby unrolling to arbitrary depth at test-time. This stands in contrast to mainstream reasoning models that scale up compute by producing more tokens. Unlike approaches based on chain-of-thought, our approach does not require any specialized training data, can work with small context windows, and can capture types of reasoning that are not easily represented in words. We scale a proof-of-concept model to 3.5 billion parameters and 800 billion tokens. We show that the resulting model can improve its performance on reasoning benchmarks, sometimes dramatically, up to a computation load equivalent to 50 billion parameters.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Jonas Geiping [<a href="https://arxiv.org/show-email/0bfd09c7/2502.05171" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 7 Feb 2025 18:55:02 UTC (12,678 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Patterns for Building Realtime Features (132 pts)]]></title>
            <link>https://zknill.io/posts/patterns-for-building-realtime/</link>
            <guid>43004334</guid>
            <pubDate>Mon, 10 Feb 2025 19:42:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zknill.io/posts/patterns-for-building-realtime/">https://zknill.io/posts/patterns-for-building-realtime/</a>, See on <a href="https://news.ycombinator.com/item?id=43004334">Hacker News</a></p>
Couldn't get https://zknill.io/posts/patterns-for-building-realtime/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Kaspersky finds hardware backdoor in 5 generations of Apple Silicon (2024) (147 pts)]]></title>
            <link>https://www.xstore.co.za/stuff/2024/01/kaspersky-finds-hardware-backdoor-in-5-generations-of-apple-silicon/</link>
            <guid>43003230</guid>
            <pubDate>Mon, 10 Feb 2025 18:07:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.xstore.co.za/stuff/2024/01/kaspersky-finds-hardware-backdoor-in-5-generations-of-apple-silicon/">https://www.xstore.co.za/stuff/2024/01/kaspersky-finds-hardware-backdoor-in-5-generations-of-apple-silicon/</a>, See on <a href="https://news.ycombinator.com/item?id=43003230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Audio transcript</p>



<figure><audio controls="" src="https://www.xstore.co.za/stuff/wp-content/uploads/2024/01/triangulation1.mp3"></audio></figure>



<p>There are some readers here who will understand the import of the statement above and not believe it, and there are others who are not in a position to understand it all. For both camps, I’ll attempt to explain the details around what is (confirmed and corroborated by others) arguably one of the most critical security events to happen in the last decade of IT security.</p>



<p>What’s completely astonishing is the almost complete lack of media coverage (ARS Technica alone did a great piece) of this issue since its announcement by Kaspersky on the 27th of Dec 2023. Is this due to the holiday period (news of the original Meltdown and Spectre vulnerabilities was also released during the Dec/Jan holidays and seemed to have had a much greater reception in the media) or the fact that it’s Kaspersky (supposedly Russian-backed) that found and announced the issue?</p>



<p>No matter your thoughts on Kaspersky and its alleged ties to the Russian government, their research has been confirmed by others.</p>



<p>I reference information in this blog post from @sggrc’s <a href="https://www.grc.com/sn/SN-955-Notes.pdf">Security Now 955 show</a> as well as publicly available information from <a href="https://www.kaspersky.com/about/press-releases/2023_kaspersky-discloses-iphone-hardware-feature-vital-in-operation-triangulation-case">Kaspersky themselves</a> and other 3rd parties/media.</p>



<p><strong>Problem Statement</strong></p>



<p>Kaspersky has found a hardware/silicon-based backdoor in 5 generations of Apple mobile silicon, starting with the A12 CPU (iPhone X) and continuing to the A16 CPU (iPhone 14/15). These CPUs have been used in other Apple products like the iPad, Watch and TV, so the iPhone is not the only affected product.</p>



<p><em>This backdoor allows complete remote access to, and control of, the affected devices</em> … let that statement stew for a few minutes. And then understand that this allows a 3rd party to see and control anything on your Apple-based phone.</p>



<p><strong>History</strong></p>



<p>The issue now commonly referred to as CVE-2023-38606, was announced by Kasperky on Dec 27 2023. It refers to a hardware backdoor that was found in Apple CPUs designed and manufactured over a 5 year period. They state the following in their announcement:</p>



<blockquote>
<p>The discovered vulnerability is a hardware feature, possibly based on the principle of <em>“</em>security through obscurity,” and may have been intended for testing or debugging. Following the initial 0-click iMessage attack and subsequent privilege escalation, the attackers leveraged this hardware feature to bypass hardware-based security protections and manipulate the contents of protected memory regions. This step was crucial for obtaining full control over the device. Apple addressed the issue, identified as <a href="https://nvd.nist.gov/vuln/detail/CVE-2023-38606">CVE-2023-38606</a>.</p>
<cite>ARS Technica</cite></blockquote>



<p>Like Steve Gibson on the SN podcast, I take issue with Kaspersky’s characterisation of this being a vulnerability, which infers a bug as a result of a mistake in coding or design. To be very clear here, this backdoor was NO mistake – it was intentionally designed into the CPU.</p>



<p>Nonetheless, it does not diminish the severity of the issue.</p>



<p>So how did Kaspersky find this issue?</p>



<p>They had been following the propagation of Operation Triangulation, an APT (<span>a</span>dvanced <span>p</span>ersistent <span>t</span>hreat or complex malware that involves multiple stages of infection and attack using a variety of methods) which targets iOS devices through zero-click exploits distributed through iMessage. In other words, no action needs to be taken by the victim – they simply need to receive the attack message to be compromised. And this attack effects any Bionic CPU-based product from iPhones all the way to Apple Watches.</p>



<p>In the process of tracking the Triangulation malware (<a href="https://securelist.com/operation-triangulation/109842/">more details here</a>), Kaspersky found that the method for the initial attack vector sourced from an <em>undocumented</em> hardware feature that few, if anyone, outside of Apple and chip suppliers such as ARM Holdings knew of.</p>



<p>There are 2 aspects of Triangulation to consider:</p>



<ul>
<li>how did the hardware backdoor come about?</li>



<li>how did the attackers know about the backdoor and come to use it in their malware?</li>
</ul>



<p><em>On the first question</em>, It’s quite impossible for Apple to not have known about the backdoor in a CPU that their own engineers designed. Or might one suggest the even more ludicrous possibility that there are chip designers within Apple that have ulterior motives and that have slipped a backdoor past development, design, QA and all the other steps required to bring a CPU to market?</p>



<p><em>On the 2nd point</em>, the task of finding the backdoor at all is made almost impossible by the complexity of the design of the backdoor (Apple are generally regarded as good and efficient at designing secure systems) – Steve Gibson goes through some aspects of the backdoor in SN 955, and specifically why it’s close to impossible to discover it without prior knowledge. So we can quite validly assume that the attackers did not discover or identify the backdoor themselves. We may never know then how they come to access the backdoor ….</p>



<p>Kaspersky says:</p>



<blockquote>
<p>The exploit’s sophistication and the feature’s obscurity suggest the attackers had advanced technical capabilities,” Kaspersky researcher Boris Larin wrote in an email. “Our analysis hasn’t revealed how they became aware of this feature, but we’re exploring all possibilities, including accidental disclosure in past firmware or source code releases. They may also have stumbled upon it through hardware reverse engineering.</p>
<cite>Kasperskey</cite></blockquote>



<p>But at minimum, it could be posited that Apple was required by some agency to create the backdoor for “purposes”. Lateral thinking commence …</p>



<p><strong>Overview of the attack</strong></p>



<p>Details disclosed by Kaspersky on Wednesday Dec 27th, said that “Triangulation”—the name Kaspersky gave to both the malware and the campaign that installed it—exploited four critical zero-day vulnerabilities, meaning serious programming flaws that were known to the attackers before they were known to Apple. These include:</p>



<ul>
<li><a href="https://support.apple.com/en-us/103837">CVE-2023-32434</a></li>



<li><a href="https://support.apple.com/en-us/HT213676">CVE-2023-32435</a></li>



<li><a href="https://support.apple.com/en-us/HT213841">CVE-2023-38606</a></li>



<li><a href="https://support.apple.com/en-us/HT213842">CVE-2023-41990</a></li>
</ul>



<p>Besides affecting iPhones, these critical zero-days and the secret hardware function resided in Macs, iPods, iPads, Apple TVs, and Apple Watches. What’s more, the exploits Kaspersky recovered were intentionally developed to work on those devices as well. Apple has patched those platforms as well. Apple declined to comment for this article.</p>



<ul>
<li>Kaspersky initially became aware of issue due to finding Triangulation malware on their own staff devices</li>



<li>Kaspersky’s researchers affirmatively and without question found a deliberately concealed, never documented, deliberately locked but unlockable with a secret hash, hardware backdoor which was designed into all Apple devices starting with the A12, A13, A14, A15 and A16</li>



<li>Triangulation attackers used the aforementioned 4 CVEs in an attack chain, along with the hardware backdoor capability under discussion here, to implement their zero-day 0-click malware</li>
</ul>



<p><strong>The technical details</strong> (gloss over or skip this if you’re not a programmer)</p>



<p>IANAP (I am not a programmer), but I’ll relay some of the technical details as described by @sggrc in SN 955.</p>



<ul>
<li>Attackers send a malicious iMessage attachment, which the application processes without showing any signs to the user</li>



<li>This attachment exploits the remote code execution vulnerability CVE-2023-41990 in the undocumented, Apple-only ADJUST TrueType font instruction. This instruction had existed since the early 90’s until a patch removed it.</li>



<li>It uses return/jump oriented programming and multiple stages written in the NSExpression/NSPredicate query language, patching the JavaScriptCore library environment to execute a privilege escalation exploit written in JavaScript</li>



<li>This JavaScript exploit is obfuscated to make it completely unreadable and to minimize its size. Still, it has around 11,000 lines of code, which are mainly dedicated to JavaScriptCore and kernel memory parsing and manipulation.</li>



<li>It exploits the JavaScriptCore debugging feature DollarVM ($vm) to gain the ability to manipulate JavaScriptCore’s memory from the script and execute native API functions</li>



<li>It was designed to support both old and new iPhones and included a Pointer Authentication Code (PAC) bypass for exploitation of recent models</li>



<li>It uses the integer overflow vulnerability CVE-2023-32434 in XNU’s memory mapping syscalls to obtain read/write access to the entire physical memory of the device</li>



<li>It uses hardware memory-mapped I/O (MMIO) registers to bypass the Page Protection Layer (PPL). This was mitigated as CVE-2023-38606</li>



<li>After exploiting all the vulnerabilities, the JavaScript exploit can do whatever it wants to the device including running spyware. But the attackers chose to:</li>



<li>(a) launch the IMAgent process and inject a payload that clears the exploitation artifacts from the device;</li>



<li>(b) run a Safari process in invisible mode and forward it to a web page with the next stage.</li>



<li>The web page has a script that verifies the victim and, if the checks pass, receives the next stage: the Safari exploit.</li>



<li>The Safari exploit uses CVE-2023-32435 to execute a shellcode.</li>



<li>The shellcode executes another kernel exploit in the form of a Mach object file. The shellcode reuses the previously used vulnerabilities: CVE-2023-32434, CVE-2023-38606. It is also massive in terms of size and functionality, but completely different from the kernel exploit written in JavaScript. Certain parts related to exploitation of the above- mentioned vulnerabilities are all that the two share. Still, most of its code is also dedicated to parsing and manipulation of the kernel memory. It contains various post-exploitation utilities, which are mostly unused</li>



<li>The exploit obtains root privileges and proceeds to execute other stages, which load spyware</li>
</ul>



<blockquote>
<p>So the view we have from 10,000 feet is of an extremely potent and powerful attack chain which, unbeknownst to any targeted iPhone user, arranges to load, in sequence, a pair of extremely powerful and flexible attack kits. The first of the kits works to immediately remove all artifacts of its presence to erase any trace of what it is and how it got there. It also triggers the execution of the second extensive attack kit which obtains root privileges on the device and then loads whatever subsequent spyware the attackers have selected</p>
<cite>@sggrc</cite></blockquote>



<p>What the above demonstrates is an attack group that has stunning programming and technical code capabilities. And to be clear, Kaspersky did not discover the Apple CPU backdoor themselves, they only found out about it due its use by the Triangulation malware.</p>



<p>Kaspersky further says:</p>



<blockquote>
<p>What we want to discuss is related to the vulnerability that has been mitigated as CVE-2023-38606. Recent iPhone models have additional hardware-based security protection for sensitive regions of the kernel memory. This protection prevents attackers from obtaining full control over the device if they can read and write kernel memory, as achieved in this attack by exploiting CVE-2023-32434. We discovered that to bypass this hardware-based security protection, the attackers used another hardware feature of Apple-designed SoCs (systems on chip).</p>



<p>If we try to describe this feature and how the attackers took advantage of it, it all comes down to this: they are able to write data to a certain physical address while bypassing the hardware-based memory protection by writing the data, destination address, and data hash to unknown hardware registers of the chip unused by the firmware.</p>



<p>Our guess is that this unknown hardware feature was most likely intended to be used for debugging or testing purposes by Apple engineers or the factory, or that it was included by mistake. Because this feature is not used by the firmware, we have no idea how attackers would know how to use it.</p>
<cite>Kaspersky</cite></blockquote>



<p>Steve Gibson puts things plainly here:</p>



<blockquote>
<p>So let’s get this very clear because it’s an important point: There is nothing whatsoever obscure about this. The use of this backdoor required a priori knowledge — explicit knowledge in advance of its use. And that knowledge had to come from whatever entity implemented this. Period.</p>
<cite>@sggrc</cite></blockquote>



<p>Steve is saying that the knowledge of the backdoor had to have come from Apple (assuming they implemented the backdoor, which again is the only logical conclusion). Whether knowledge of the backdoor was a leak, or intentional, is unknown. </p>



<p>Kaspersky has done a brilliant job of disassembling the Triangulation malware, however the source of, and reason for, the backdoor used for the initial attack vector in the malware, remains a mystery.</p>



<p>It’s unlikely (as Kaspersky opines) that this backdoor was left in by mistake. There are too many checks and balances, in the design and manufacturing process of silicon, for deliberate functions like this to go unnoticed.</p>



<p>Bugs can happen yes, but not a deliberate design, which this clearly and unequivocally is.</p>



<p><strong>Conclusion</strong></p>



<p>Some points to wrap up</p>



<ul>
<li>unless Apple fesses, we may never know the source of, and reason for, this backdoor in their CPUs</li>



<li>we don’t know how the Triangulation malware attackers came to be in possession of the details of the backdoor, we do know however with reasonable surety that they would not have been able to find it themselves</li>



<li>the backdoor was not accessible from firmware and was undocumented but people within Apple knew of this backdoor. They knew that this backdoor was present and they knew how to access it. And somehow that secret escaped from Apple’s control</li>



<li>Apple have since patched all relevant CVEs so affected devices <em>should</em> now be secure from this issue</li>



<li>there is nothing to stop Apple from implementing similar backdoors in future silicon as long as they can keep it a secret</li>



<li>are ARM (who design/make some of the related silicon) involved?</li>



<li>do other silicon manufacturers have anything similar in play?</li>
</ul>



<p>The impact of the backdoor on Triangulation’s ability to propagate their malware can not be overstated. The backdoor was pivotal in allowing Triangulation’s malware to spawn without requiring action on an iOS user’s part. And the malware’s capabilities were impressive to put it bluntly, allowing complete compromise of iOS devices.</p>



<p>Kaspersky, no matter their reputation or allegiances, have done some stellar work in uncovering this issue, no matter its source or reasoning. But them finding out about the hardware backdoor may not be the obviously good thing it appears to be – involved parties now know that they need to take additional care when designing potential new backdoors; and these may never be found.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[1% Equity for Founding Engineers Is BS (171 pts)]]></title>
            <link>https://fetchfox.ai/a/founding-engineer-compensation</link>
            <guid>43002999</guid>
            <pubDate>Mon, 10 Feb 2025 17:47:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fetchfox.ai/a/founding-engineer-compensation">https://fetchfox.ai/a/founding-engineer-compensation</a>, See on <a href="https://news.ycombinator.com/item?id=43002999">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><main><div><p>Feb 2025</p><p>The status quo for Founding Engineer compensation is broken. It’s unfair, outdated, and doesn’t work for founders or engineers.</p><p>A startup starts with the founders doing all the work. The founders write all the code and they talk to all the customers. If the startup is doing well, there is more coding and talking to do than the hours in the day, and you need to hire some help. This help will almost always be a technical hire.</p><p>The job title “Founding Engineer” was<!-- --> <a href="https://trends.google.com/trends/explore?date=all&amp;q=founding%20engineer&amp;hl=en">invented</a> to describe this role. It is kinda-sorta like a founder, but not a founder. You do similar work to a founder, but a little bit less. You take on similar risk to the founder, but a little bit less.</p><p>This is all fine, except for one part. These roles offer similar compensation to the founders, except it’s a<!-- --> <i>whole lot less</i>.</p><h2>Similar risk for 50x less reward?</h2><p>The exact numbers vary, but the typical equity grants for founding engineers are in the range of 0.5% to 2%. You can get a sense for it if you scan<!-- --> <a href="https://www.workatastartup.com/jobs/l/software-engineer">YC’s job board</a>. Getting 1% is typical, and it comes with a one year cliff and a four year vest. These grants are given to the first one or two engineering hires, and many of these companies have YC as their first and only investor.</p><p>Assuming two founders and a 7% stake by YC, the founders retain 48.5% equity. That means their stake is anywhere from 25x to 80x larger than the Founding Engineer’s stake.</p><p>To illustrate this in dollar terms, consider an acquihire exit. At 1% of $10 million, the acquihire nets the Founding Engineer around $100,000, enough to buy a nice Tesla. Meanwhile, the founders net $4.8 million, enough to buy a<!-- --> <a href="https://www.zillow.com/homedetails/3247-Murray-Way-Palo-Alto-CA-94303/19499495_zpid/">house in Palo Alto</a>, a <a href="https://www.yachtworld.com/boats-for-sale/make-princess/model-v40/">small yacht</a>, and two nice Teslas.</p><p>The founders certainly took on more risk, but not 80 times more. The risk reward ratio is completely out of proportion, and it's profoundly unfair to the Founding Engineer.</p><p><img src="https://fetchfox.ai/equity.png"></p><h2>When liquidity?</h2><p>Even if you ignore the reward proportions, there’s another problem with startup equity: liquidity.</p><p>Most startups put a one year cliff on your vesting, which means if you work there for 11 months and 29 days, you don’t get any equity at all.</p><p>But even once you start vesting, there’s another problem: you can’t sell your equity. There are no market makers for a typical startup's equity, which means there are no buyers and no sellers. You could try a second market deal, but even for Series A startups those markets are slow. Good luck trying to sell pre-seed shares.</p><p>Even mature startups have thin liquidity. When I worked at 23andMe, we had a once a year liquidity event, and you had to sell a large number of shares with high fees. If you missed the event, you had to wait a whole year before you could sell again.</p><p>Many VCs will tell you this is for “long term alignment” and to “maintain incentives.” It’s all shenanigans. These are the <a href="https://a16zcrypto.com/">exact</a> <a href="https://www.sequoiacap.com/">same</a> <a href="https://visionfund.com/">VCs</a> that happily<!-- --> <a href="https://www.cnbc.com/2022/11/10/sequoia-capital-marks-down-its-ftx-investment-to-0.html">jumped</a> <a href="https://techcrunch.com/2022/11/14/softbank-ftx-crypto/">into</a> failed crypto projects for short term gains (or cashed out successful crypto pumps by<!-- --> <a href="https://www.benzinga.com/markets/cryptocurrency/21/07/22126163/polychain-a16z-face-unregistered-security-lawsuit-over-internet-computer-token-sale">dumping on retail</a>). Don’t believe their lies. With VCs, it’s “long term alignment” for you, and “cash now” for them.</p><h2>Who this works for</h2><p>This equity model works in some situations. It works in when the founders are bringing 50x more value than the Founding Engineer, for example:</p><ul><li><b>Famous founder.</b> If your startup has a famous founder like Sam Altman or Elon Musk, the equity is instantly valuable. A Sam Altman type brings so much weight to a startup that the absolute worst failure case is a $100 million exit. The best case for normal founders is the worst case for a famous founder.</li><li><b>Brand name investors.</b> If your startup has brand name investors like YC or a16z, it puts a floor on the exit value of your startup. If you fail, you are very likely to get acquired for a decent amount by virtue of your connections. Additionally, these brand names bring a little bit of guaranteed success, especially for B2B startups.</li><li><b>Proven hypergrowth.</b> If your startup is experiencing hypergrowth, like growing revenue by 2x monthly, then it has been de-risked substantially. At this point, you’re no longer an early stage startup, you are hiring regular engineers, not “Founding Engineers.”</li></ul><p>If one of these applies to your startup, then you are justified in offering 50x lower equity to founding engineers. But if you are in the vast majority of startups that do not fall in these buckets, your equity offering is out of line with the risk-reward for a Founding Engineer.</p><h2>Who this doesn’t work for</h2><p>This equity model does not work for tiny, no-name startups, like FetchFox.</p><p>Here at FetchFox, we very much want to hire<!-- --> <a href="https://steve-yegge.blogspot.com/2008/06/done-and-gets-things-smart.html">great</a> <a href="https://www.joelonsoftware.com/2005/07/25/hitting-the-high-notes/">engineers</a>. Our goal is to build a super reliable, easy to use system on top of two super unreliable, flakey systems: LLMs and proxies. This is hard. We run into subtle errors and difficult to reproduce bugs. We are competing against larger teams with more funding and huge incumbents. We need engineers who can frame problems well, figure out leveraged solutions, make good tradeoffs, apply both intuition and empiricism, and quickly write high quality code.</p><p>The great engineers we want to hire are always in demand, and they are super rare. They have the option to work at FetchFox, or they have the option to work at OpenAI for the same salary. When they see a 1% equity offer,<!-- --> <a href="https://www.google.com/search?q=site%3Anews.ycombinator.com+startup+equity+lottery">conventional wisdom</a> <!-- -->tells them to discount it down to zero after accounting for risk and time horizon. Meanwhile, the 0.005% equity offer from OpenAI will buy them a nice house in Palo Alto.</p><p>There are intangible benefits to working at an early stage startup like FetchFox: perhaps you want to own an entire component of the project, perhaps you enjoy the early stage startup experience, or perhaps you just like the vibe of the team. But these intangible benefits are stacked against the very tangible realities of cash compensation and exit liquidity.</p><h2>A 10x better model for Founding Engineer compensation</h2><p>FetchFox is inventing a new model for Founding Engineer compensation. Our goal is to solve the problems with the current model from above: disproportionate stake, and improbable liquidity.</p><p>First, we are dramatically increasing the stake that Founding Engineers receive. Generally we offer between 5% stake on the low end to 25% or more on the high end to the first few engineering hires. There is some tradeoff here with cash compensation. We believe this is a much more fair range that accounts for the risk and expected contribution for Founding Engineers.</p><p>Second, we are changing the vesting structure. We do have a vesting system, but you begin vesting your stake almost immediately upon joining the company. We do not have a one year cliff, and your stake does not expire if you leave the company.</p><p>Third, and most significant, we do not offer equity stakes using conventional instruments. We do not offer stock or options or equity in the<!-- --> <a href="https://github.com/jlevy/og-equity-compensation">traditional sense</a>. Instead, we offer a crypto token. This is a utility token that will be deployed under the ERC-20 standard, and live on the Ethereum blockchain. It will be set up so that if the product does well, the price of the token goes up, and if the product does badly, the price of the token goes down. You can read more about the<!-- --> <a href="https://docs.google.com/document/u/0/d/1VvxEQBRexuFJT5qCr9MCeZRVkzJUVSAFJ_hxa5yEDAg/edit">details of the token in a sister article</a>.</p><p>Finally, the founders and employees get exactly the same crypto token. Only difference is that the founders get a larger allocation of that token. In my case, I am taking $0 salary at FetchFox and my entire upside and compensation is through the token that me and Founding Engineers are getting.</p><p>As far as I know, very very few, if any, startups outside the crypto space use tokens for employee compensation. I believe this is out of habit, not rational analysis, and I predict that in the future, many many startups outside the crypto space will use tokens for employee compensation.</p><p>Using a crypto token gives our employees a very important,<!-- --> <a href="https://ortutay.substack.com/p/10x-better-10x-worse">10x improvement</a> over traditional stock grants. A crypto token enables continuous, 24/7 liquidity within the first months of the startup's life. No more waiting for a liquidity event that is contingent on the founders needs: you can sell anytime from day one.</p><p>Due to the unique structure of crypto AMM’s, any crypto token has infinite depth. Yes, infinite depth. A crypto AMM can absorb a token sale of any size, any time, zero sweat. It might not be at a price you like, but the option is there. If you haven’t read about them, I highly recommend learning about the<!-- --> <a href="http://ortutay.cc/articles/amm.html">math and intuition behind crypto AMM curves</a>.</p><p>What crypto AMM’s offer is better than the liquidity you get at a brand name startup (it comes a few times a year at best), better than you get on second markets (which have high fees and takes weeks to close), and even better than the gold standard of an IPO (these are closed on weekends, and have nasty employee lockout periods).</p><h2>Tradeoffs mean it's also 10x worse</h2><p>While I strongly believe that a crypto token is a 10x better model for early stage startups, there are downsides. Any innovation that is 10x better in some dimension is<!-- --> <a href="https://ortutay.substack.com/p/10x-better-10x-worse">10x worse</a> in another. Let's consider some of the downsides of the crypto token model.</p><p>First, granting a large amount of equity creates a signalling problem. If all the other startups are giving 1%, and FetchFox is giving up to 25%, does that mean FetchFox is a worthless company? It doesn’t, but many people will conclude it is.</p><p>Second, early stage startups are very volatile, and small cap crypto tokens are also volatile. Combine these two and you get volatility squared. This may create upset employees who could see their token grant values go up or down an order of magnitude overnight.</p><p>Finally, there is still a reputation risk associated with crypto. Mentioning crypto will set off alarm bells for some people, and it will often derail conversations because of its association with all manner of scammers.</p><p>Fortunately, these downsides are a necessary and worthwhile tradeoff. They are mostly related to perceptions (or misperceptions), and much of the impact can be mitigated by managing expectations. And remember that a startup should make<!-- --> <a href="https://kk.org/thetechnium/1000-true-fans/">a small group of people very happy</a>. It should not make everyone mildly ok.</p><h2>It’s not for everyone, but maybe it's for you</h2><p>I recently told the CEO of a recruiting agency about this compensation model. She told me that if you even mention crypto, more than half your engineering candidates will immediately say “no” to your company. The word triggers people, and many will wonder if you’re trying to pull some kind of get rich quick scheme. Even rational people will decide the risk model is not for them, or they don’t want to be guinea pigs on a new compensation model.</p><p>However, we don’t need to hire lots of people here at FetchFox. We just need a handful of<!-- --> <a href="https://steve-yegge.blogspot.com/2008/06/done-and-gets-things-smart.html">really great engineers</a>. I am betting there is a niche group of great engineers who will view this compensation as a huge big positive, and be excited to join us.</p><p>If that describes you, please email <a href="mailto:marcell@fetchfoxai.com">marcell@fetchfoxai.com</a> to chat about joining the team.</p><p>— Marcell Ortutay, Founder/CEO, FetchFox</p></div></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Work at the Mill Or, the Story of Digital Equipment Corporation (137 pts)]]></title>
            <link>https://www.abortretry.fail/p/work-at-the-mill</link>
            <guid>43002906</guid>
            <pubDate>Mon, 10 Feb 2025 17:39:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abortretry.fail/p/work-at-the-mill">https://www.abortretry.fail/p/work-at-the-mill</a>, See on <a href="https://news.ycombinator.com/item?id=43002906">Hacker News</a></p>
Couldn't get https://www.abortretry.fail/p/work-at-the-mill: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Undergraduate Upends a 40-Year-Old Data Science Conjecture (1024 pts)]]></title>
            <link>https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/</link>
            <guid>43002511</guid>
            <pubDate>Mon, 10 Feb 2025 17:05:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/">https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/</a>, See on <a href="https://news.ycombinator.com/item?id=43002511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>
            A young computer scientist and two colleagues show that searches within data structures called hash tables can be much faster than previously deemed possible.        </p>
        
    </div><div>
            <h2>Introduction</h2>
            <div data-role="selectable">
    <p>Sometime in the fall of 2021, Andrew Krapivin, an undergraduate at Rutgers University, encountered a paper that would change his life. At the time, Krapivin didn’t give it much thought. But two years later, when he finally set aside time to go through the paper (“just for fun,” as he put it), his efforts would lead to a rethinking of a widely used tool in computer science.</p>
<p>The paper’s title, “<a href="https://arxiv.org/abs/2111.12800">Tiny Pointers</a>,” referred to arrowlike entities that can direct you to a piece of information, or element, in a computer’s memory. Krapivin soon came up with a potential way to further miniaturize the pointers so they consumed less memory. However, to achieve that, he needed a better way of organizing the data that the pointers would point to.</p>
<p>He turned to a common approach for storing data known as a hash table. But in the midst of his tinkering, Krapivin realized that he had invented a new kind of hash table, one that worked faster than expected — taking less time and fewer steps to find specific elements.</p>
<p><a href="https://engineering.nyu.edu/faculty/martin-farach-colton">Martín Farach-Colton</a>, a co-author of the “Tiny Pointers” paper and Krapivin’s former professor at Rutgers, was initially skeptical of Krapivin’s new design. Hash tables are among the most thoroughly studied data structures in all of computer science; the advance sounded too good to be true. &nbsp;But just to be sure, he asked a frequent collaborator (and a “Tiny Pointers” co-author), <a href="https://csd.cmu.edu/people/faculty/william-kuszmaul">William Kuszmaul</a> of Carnegie Mellon University, to check out his student’s invention. Kuszmaul had a different reaction. “You didn’t just come up with a cool hash table,” he remembers telling Krapivin. “You’ve actually completely wiped out a 40-year-old conjecture!”</p>
</div>
    </div><div data-role="selectable">
    <p>Together, Krapivin (now a graduate student at the University of Cambridge), Farach-Colton (now at New York University) and Kuszmaul demonstrated in a <a href="https://arxiv.org/abs/2501.02305">January 2025 paper</a> that this new hash table can indeed find elements faster than was considered possible. ln so doing, they had disproved a conjecture long held to be true.</p>
<p>“It’s an important paper,” said <a href="https://ajhconway.com/">Alex Conway</a> of Cornell Tech in New York City. “Hash tables are among the oldest data structures we have. And they’re still one of the most efficient ways to store data.” Yet open questions remain about how they work, he said. “This paper answers a couple of them in surprising ways.”</p>
<p>Hash tables have become ubiquitous in computing, partly because of their simplicity and ease of use. They’re designed to allow users to do exactly three things: “query” (search for) an element, delete an element, or insert one into an empty slot. The first hash tables date back to the early 1950s, and computer scientists have studied and used them ever since. Among other things, researchers wanted to figure out the speed limits for some of these operations. How fast, for example, could a new search or insertion possibly be?</p>

<p>The answer generally depends on the amount of time it takes to find an empty spot in a hash table. This, in turn, typically depends on how full the hash table is. Fullness can be described in terms of an overall percentage — this table is 50% full, that one’s 90% — but researchers often deal with much fuller tables. So instead, they may use a whole number, denoted by <em>x</em>, to specify how close the hash table is to 100% full. If <em>x</em> is 100, then the table is 99% full. If <em>x</em> is 1,000, the table is 99.9% full. This measure of fullness offers a convenient way to evaluate how long it should take to perform actions like queries or insertions.<strong>&nbsp;</strong></p>
<p>Researchers have long known that for certain common hash tables, the expected time required to make the worst possible insertion — putting an item into, say, the last remaining open spot — is proportional to <em>x</em>. “If your hash table is 99% full,” Kuszmaul said, “it makes sense that you would have to look at around 100 different positions to find a free slot.”</p>
<p>In a <a href="https://dl.acm.org/doi/10.1145/3828.3836">1985 paper</a>, the computer scientist <a href="https://amturing.acm.org/award_winners/yao_1611524.cfm">Andrew Yao</a>, who would go on to win the A.M. Turing Award, asserted that among hash tables with a specific set of properties, the best way to find an individual element or an empty spot is to just go through potential spots randomly — an approach known as uniform probing. He also stated that, in the worst-case scenario, where you’re searching for the last remaining open spot, you can never do better than <em>x</em>. for 40 years, most computer scientists assumed that Yao’s conjecture was true.</p>
<p>Krapivin was not held back by the conventional wisdom for the simple reason that he was unaware of it. “I did this without knowing about Yao’s conjecture,” &nbsp;he said. His explorations with tiny pointers led to a new kind of hash table — one that did not rely on uniform probing. And for this new hash table, the time required for worst-case queries and insertions is proportional to (log <em>x</em>)<sup>2</sup> — far faster than <em>x</em>. This result directly contradicted Yao’s conjecture. Farach-Colton and Kuszmaul helped Krapivin show that (log <em>x</em>)<sup>2</sup> is the optimal, unbeatable bound for the popular class of hash tables Yao had written about.</p>
<p>“This result is beautiful in that it addresses and solves such a classic problem,” said <a href="http://www.cs.cmu.edu/~guyb/">Guy Blelloch</a> of Carnegie Mellon.</p>
<p>“It’s not just that they disproved [Yao’s conjecture], they also found the best possible answer to his question,” said <a href="https://cs.uwaterloo.ca/about/people/sassadi">Sepehr Assadi</a> of the University of Waterloo. &nbsp;“We could have gone another 40 years before we knew the right answer.”</p>
</div><div data-role="selectable">
    <p>In addition to refuting Yao’s conjecture, the new paper also contains what many consider an even more astonishing result. It pertains to a related, though slightly different, situation: In 1985, Yao looked not only at the worst-case times for queries, but also at the average time taken across all possible queries. He proved that hash tables with certain properties — including those that are labeled “greedy,” which means that new elements must be placed in the first available spot — could never achieve an average time better than log <em>x</em>.</p>
        
        
<p>Farach-Colton, Krapivin and Kuszmaul wanted to see if that same limit also applied to non-greedy hash tables. They showed that it did not by providing a counterexample, a non-greedy hash table with an average query time that’s much, much better than log <em>x</em>. In fact, it doesn’t depend on <em>x</em> at all. “You get a number,” Farach-Colton said, “something that is just a constant and doesn’t depend on how full the hash table is.” The fact that you can achieve a constant average query time, regardless of the hash table’s fullness, was wholly unexpected — even to the authors themselves.</p>
<p>The team’s results may not lead to any immediate applications, but that’s not all that matters, Conway said. “It’s important to understand these kinds of data structures better. You don’t know when a result like this will unlock something that lets you do better in practice.”</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CAPTCHAs: 'a tracking cookie farm for profit masquerading as a security service' (175 pts)]]></title>
            <link>https://www.pcgamer.com/gaming-industry/a-2023-study-concluded-captchas-are-a-tracking-cookie-farm-for-profit-masquerading-as-a-security-service-that-made-us-spend-819-billion-hours-clicking-on-traffic-lights-to-generate-nearly-usd1-trillion-for-google/</link>
            <guid>43002440</guid>
            <pubDate>Mon, 10 Feb 2025 16:59:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pcgamer.com/gaming-industry/a-2023-study-concluded-captchas-are-a-tracking-cookie-farm-for-profit-masquerading-as-a-security-service-that-made-us-spend-819-billion-hours-clicking-on-traffic-lights-to-generate-nearly-usd1-trillion-for-google/">https://www.pcgamer.com/gaming-industry/a-2023-study-concluded-captchas-are-a-tracking-cookie-farm-for-profit-masquerading-as-a-security-service-that-made-us-spend-819-billion-hours-clicking-on-traffic-lights-to-generate-nearly-usd1-trillion-for-google/</a>, See on <a href="https://news.ycombinator.com/item?id=43002440">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">

<section>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1920-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)">
<img src="https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1200-80.jpg" alt="Mature professional business man suffering from a headache while working online on computer checking emails alone at work. One male manager feeling overworked, stressed and tired due to a deadline - stock photo" srcset="https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1920-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/hpd4LbGpm6MBXYawDj9vwf.jpg" data-pin-nopin="true" fetchpriority="high">
</picture>
</div>
<figcaption>
<span>(Image credit: DMP via Getty Images)</span>
</figcaption>
</div>

<div id="article-body">
<p>As reported by <a data-analytics-id="inline-link" href="https://boingboing.net/2025/02/07/recaptcha-819-million-hours-of-wasted-human-time-and-billions-of-dollars-google-profit.html" target="_blank" data-url="https://boingboing.net/2025/02/07/recaptcha-819-million-hours-of-wasted-human-time-and-billions-of-dollars-google-profit.html" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Boing Boing</a>, a 2023 study out of UC Irvine, "<a data-analytics-id="inline-link" href="https://arxiv.org/abs/2311.10911" target="_blank" data-url="https://arxiv.org/abs/2311.10911" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Dazed and Confused: A Large-Scale Real-World User Study of reCAPTCHAv2</a>" concluded that not only are CAPTCHAs ineffective at actually preventing bot traffic, they introduce privacy concerns through tracking cookies, have wasted millions of hours of our collective time, and generated nearly a trillion dollars worth of data for Google, which acquired the ubiquitous reCAPTCHA utility back in 2009.</p><p>The study focuses on the two most common forms of CAPTCHAs you'll find out in the wild through Google's reCAPTCHAv2: "Invisible" or behavior-based CAPTCHAs which analyze your inputs as you check that "not a robot" box or even surreptitiously as you browse a website, and image-based CAPTCHAs, where you select all the motorcycles, traffic lights, or what have you in images sourced from Google Street View. Both are valuable to Google, with the tracking cookies generated by the former potentially contributing to ad targeting, and data from the latter being applied toward AI model training, either internally at Google or sold to another company.</p><figure data-bordeaux-image-check=""><div><p><picture><source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-320-80.jpeg.webp 320w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-480-80.jpeg.webp 480w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-650-80.jpeg.webp 650w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-970-80.jpeg.webp 970w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-1024-80.jpeg.webp 1024w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-1200-80.jpeg.webp 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"><img src="https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-320-80.jpeg" alt="CAPTCHA bikes" srcset="https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-320-80.jpeg 320w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-480-80.jpeg 480w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-650-80.jpeg 650w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-970-80.jpeg 970w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-1024-80.jpeg 1024w, https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW-1200-80.jpeg 1200w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-original-mos="https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW.jpeg" data-pin-media="https://cdn.mos.cms.futurecdn.net/C6AqADWX2K4VKqGiYmbhvW.jpeg"></picture></p></div><figcaption itemprop="caption description"><span>1200 human lifetimes of these moments lost to time like tears in rain. </span><span itemprop="copyrightHolder">(Image credit: Google)</span></figcaption></figure><p>This experiment did not inform its subjects, and instead added Google's reCAPTCHAv2 to the account creation and password recovery functions of an internal student account system at the university, with the researchers both measuring time to complete the CAPTCHAs and surveying a subset of the 13-month study's 3,600 users about their experience. Predictably, they took more time and surveyed negatively when it came to the more involved image detection CAPTCHAs. The study also noted variations in completion time across education disciplines, experience level, and for whether they were creating or recovering an account.</p><p>The researchers took the average completion time of 3.53 seconds across both image and behavior CAPTCHAs and multiplied that against a low-end estimate of 512 billion v1 and v2 reCAPTCHAs completed across the internet between 2010 and 2023, resulting in the following estimations of their impact on our lives:</p><ul><li><strong>819 million hours</strong> spent solving CAPTCHAs.</li><li><strong>$6.1 billion </strong>worth of our time at the US federal minimum wage.</li><li><strong>134 Petabytes</strong> of internet bandwidth.</li><li>consuming <strong>7.5 million kWhs</strong> of energy.</li><li>which produced <strong>7.5 million pounds</strong> of CO2 pollution.</li><li>This one's from me: putting the 819 million hours against the average human lifespan of 79 years, that's <strong>1,182.7 lifetimes</strong> spent solving CAPTCHAs.</li></ul><p>Comparing the new study's time and accuracy rates to bots, while also looking at <a data-analytics-id="inline-link" href="https://www.pcgamer.com/new-research-shows-bots-beat-people-at-convincing-computers-theyre-not-bots/" target="_blank" data-before-rewrite-localise="https://www.pcgamer.com/new-research-shows-bots-beat-people-at-convincing-computers-theyre-not-bots/">previous studies</a> on the increasing capability of automated processes to solve CAPTCHAs, the researchers concluded that bots are now faster than humans at completing reCAPTCHAv2's checkboxes, while they take more time, but are more accurate when it comes to image detection. The researchers also argued that the tracking cookies in fact introduce a new security and privacy risk. Looking at Google's stated value for collections of labeled image detection data and the lifetime value of an individual tracking cookie multiplied by the estimated lifetime amount of reCAPTCHAv2s completed, the researchers came up with the following values for Google:</p><ul><li><strong>$8.75-$32.3 billion</strong> for its full reCAPTCHAv2 dataset, which could theoretically be sold multiple times to different vendors.</li><li>A lifetime value of <strong>$888 billion </strong>for all of reCAPTCHAv2's tracking cookies produced between 2010 and 2023.</li></ul><p>"It can be concluded that the true purpose of reCAPTCHAv2 is as a tracking cookie farm for profit masquerading as a security service," the researchers stated in the final portion of the study, arguing that reCAPTCHA should be deprecated for its lack of genuine contribution to the internet's safety or functionality. Two years on from this study, there's no sign of that happening any time soon.</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-ZozyXgBL8hiqEj59pzDaW"><section><p>Keep up to date with the most important stories and the best deals, as picked by the PC Gamer team.</p></section></div>
</div>

<div id="slice-container-authorBio-ZozyXgBL8hiqEj59pzDaW"><p>Ted has been thinking about PC games and bothering anyone who would listen with his thoughts on them ever since he booted up his sister's copy of Neverwinter Nights on the family computer. He is obsessed with all things CRPG and CRPG-adjacent, but has also covered esports, modding, and rare game collecting. When he's not playing or writing about games, you can find Ted lifting weights on his back porch.</p></div>
</section>


<div data-test-id="more-about">
<p>More about gaming industry</p>


</div>

<div id="slice-container-relatedArticles"><p><h3>Most Popular</h3></p></div>







</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open Source Security & Compliance: Introducing Opencomply (107 pts)]]></title>
            <link>https://opencomply.io</link>
            <guid>43001826</guid>
            <pubDate>Mon, 10 Feb 2025 16:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opencomply.io">https://opencomply.io</a>, See on <a href="https://news.ycombinator.com/item?id=43001826">Hacker News</a></p>
Couldn't get https://opencomply.io: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Global 3D topography explorer (103 pts)]]></title>
            <link>https://topography.jessekv.com</link>
            <guid>43001688</guid>
            <pubDate>Mon, 10 Feb 2025 15:54:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://topography.jessekv.com">https://topography.jessekv.com</a>, See on <a href="https://news.ycombinator.com/item?id=43001688">Hacker News</a></p>
Couldn't get https://topography.jessekv.com: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Bank CEO: Retract your debanking piece? Me: No (264 pts)]]></title>
            <link>https://www.kalzumeus.com/2025/02/10/retraction-request-denied/</link>
            <guid>43001441</guid>
            <pubDate>Mon, 10 Feb 2025 15:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.kalzumeus.com/2025/02/10/retraction-request-denied/">https://www.kalzumeus.com/2025/02/10/retraction-request-denied/</a>, See on <a href="https://news.ycombinator.com/item?id=43001441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>In December 2024, in response to the press/advocacy campaign by Marc Andreessen and other crypto advocates regarding a phenomenon they call <a href="https://a16zcrypto.com/posts/article/debanking-explained/">debanking</a>, I wrote <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/">Debanking (and Debunking?)</a> in Bits about Money.</p>

<p>That piece is the definitive explanation of the issue. It examines many angles including:</p>

<ul>
  <li>the constraints on banks and their incentive structures</li>
  <li>how AML regulation sometimes hurts innocent entrepreneurs</li>
  <li>a detailed history of Operation Choke Point</li>
  <li>a detailed analysis of why two crypto-affiliated banks closed</li>
  <li>what the crypto industry hopes to win through the press/advocacy campaign.</li>
</ul>

<p><em>Debanking (and Debunking?)</em> won wide acclaim for being accurate, incisive, and balanced. Experts who publicly praised it include the crypto VC who coined the phrase “Choke Point 2.0” (<a href="https://x.com/nic__carter/status/1866308123742683279">“… the best and fairest treatment of the issue [I] could expect from a skeptic…”</a>) and a former federal banking regulator (<a href="https://x.com/bpetershome/status/1866973869979922650">“This is a tour-de-force. This is absolutely excellent. Anyone interested in this issue should read this piece.”</a>).</p>

<p>I am notoriously a crypto skeptic, but I do believe advocates have some points which are <em>just true</em> about debanking, a phenomenon which is much larger than crypto. They also have some arguments which deserve a fair hearing. They also say some things which are untrue and will not get more true simply by being strategically convenient.</p>

<h2 id="you-cant-please-everyone">You can’t please everyone</h2>

<p>In many years of writing for the Internet, I’ve gotten my fair share of negative comments. It happens; oh well. Sometimes randos use cliches like “Delete this post.” These are easy to ignore.</p>

<p>I recently received a <a href="https://x.com/nathanmccauley/status/1887635974064382198">request for retraction from a bank CEO</a>. (<a href="https://media.kalzumeus.com/bam-retraction-request/mccauley-thread-1-of-4.png">Tweets</a> <a href="https://media.kalzumeus.com/bam-retraction-request/mccauley-thread-2-of-4.png">sometimes</a> <a href="https://media.kalzumeus.com/bam-retraction-request/mccauley-thread-3-of-4.png">become</a> <a href="https://media.kalzumeus.com/bam-retraction-request/mccauley-thread-4-of-4.png">unavailable</a>.) <em>That</em> is a first, and it deserves careful attention.</p>

<p>Bits about Money is a <a href="https://www.bitsaboutmoney.com/memberships/">reader-supported</a> professional journal about the intersection of finance and technology. It has been my primary professional output and source of income for the last two years. It generally takes pains to avoid antagonizing specific banks, in part because banks can be <em>prickly</em> about their reputations. But there was always a risk, in writing candidly about banking, that a bank or banker could react with severe displeasure.</p>

<p>Bits about Money is, like most of my professional writing, published by Kalzumeus Software, LLC. The following is in the voice of the company.</p>

<blockquote>
Nathan McCauley, the CEO of <a href="https://anchorage.com/">Anchorage Labs, Inc.</a> d/b/a Anchorage Digital, and a board member (and, on faith and belief, CEO) of a federally chartered bank, has requested a retraction of the piece <em>Debanking (and Debunking?)</em>. He alleges inaccuracies, misleading statements, omission of key facts, and other improprieties.

<p>

This is a serious allegation, and we treated it seriously. We have undertaken a review of McCauley's points. This review included requesting input from Anchorage Digital's PR team, reviewing the text of the published essay, and consulting with our external advisors.

</p><p>

<strong>We find McCauley's allegations to lack merit.</strong> We therefore decline to retract the essay.
</p></blockquote>

<h3 id="the-bar-for-a-retraction-is-high">The bar for a retraction is high</h3>

<p>Retractions are, in the standard practice of journalism, research and other professional writing, extremely rare. They are reserved for the worst offenses: plagiarizing, fabricating quotations or data, committing libel, and the like.</p>

<p>I publish analytical essays about complex systems, and mostly do not break news. One is welcome to one’s opinion as to whether that counts as journalism.</p>

<p>I have a high regard for the truth. If I ever wander into error about the thing readers pay me to be an expert about, I try to correct the record. My preference is strongly towards corrections rather than retractions, as I have never unpublished a piece, but I <em>would do it</em> if warranted.</p>

<p>I have considered, and asked external advisors, whether it is possible that the CEO of a tech startup valued at <a href="https://www.anchorage.com/insights/anchorage-digital-raises-350-million-series-d-funding-led-by-kkr">over $3 billion</a> might be unaware of what the word “retraction” means or that asking for one is a serious act. We unanimously concluded that I am entitled to assume the professionalism and competence of a founder of a tech unicorn or a bank CEO. McCauley is both.</p>

<p>Because the specific allegations made do not show the professionalism and competence of the speaker in a positive light, I reached out to Anchorage Digital in advance of publication, via their <a href="https://www.anchorage.com/in-the-news">PR department’s published email address</a>. I asked, among other things, if they had reason to believe their CEO’s Twitter account was compromised. There is always a risk that someone <a href="https://www.loweringthebar.net/wp-content/uploads/2011/03/browns_letter_1974.pdf">is signing one’s name to stupid letters</a> without authorization.</p>

<p>Anchorage Digital’s PR team did not reply to my request for comment, despite receiving three emails and a clearly communicated timeline which was longer than one business day. As Anchorage Digital itself <a href="https://x.com/Anchorage/status/1887162623516725627">tagged</a> McCauley’s account the day prior on the occasion of <a href="https://www.banking.senate.gov/hearings/investigating-the-real-impacts-of-debanking-in-america">his testimony in front of the U.S. Senate Banking Committee</a>, and did not identify his account as compromised, I treat the authenticity of his messages as a settled question.</p>

<p>I will take the <em>charitable</em> perspective that a tech founder and bank CEO does not necessarily speak for the startup and/or bank themselves. Anchorage Digital knows my email address if they would like to clarify this or any other point.</p>

<h2 id="our-review-of-the-retraction-request">Our review of the retraction request</h2>

<p>On receiving the request for retraction we <a href="https://x.com/patio11/status/1887694095239217388">reached out</a> to McCauley to ask what specifically he believed was inaccurate in the piece. This was also an opportunity for McCauley to recharacterize his request as, for example, an indelicately phrased expression of personal opinion.</p>

<p>McCauley did not respond by walking back the request for retraction. Instead, he replied with what he seems to believe constitutes a litany of improprieties. As he has numbered his subpoints, we will address them in turn.</p>

<p>McCauley:</p>

<blockquote>
  <p>A few areas were incorrect and misleading, lots of omission of key facts, and missing the point about what we mean by debanking.</p>

  <p>In order:</p>
</blockquote>

<h3 id="1-a-few-areas-were-incorrect-and-misleading">1. “A few areas were incorrect and misleading”</h3>

<p>McCauley:</p>

<blockquote>
  <p>Silvergate was trivially solvent based on their call reports. Anyone assessing their liquidity position saw this (we were doing so).  Your implication that they were doomed due to BSA findings doesn’t comport with any regulatory practice—banks don’t get closed for this.</p>
</blockquote>

<p><strong>Our response regarding solvency:</strong> Had we stated or implied that Silvergate was insolvent, that would have been very improper. Insolvency of a financial institution is a serious charge. We assume McCauley believes we must have made it, because no bank CEO could possibly believe that solvency is <em>the only</em> obligation of a financial institution.</p>

<p>We did not make this accusation.</p>

<p>We reviewed the 4,300 words written about Silvergate specifically, and cannot identify any statement which can be reasonably read as alleging insolvency. A reader who wanted to quickly verify this might use Ctrl-F “solv” (three hits in the piece, none about Silvergate, and one expanding to “solving”). One could also run the piece by an expert in banking practice, who might point out the following is persuasive evidence of solvency.</p>

<p><em>Debanking (and Debunking?):</em></p>

<blockquote>
  <p>Silvergate voluntarily liquidated in the wake of the FTX implosion. Limited props for them here: they managed to do this in a mostly orderly fashion, as opposed to Signature, which had substantially less crypto exposure but blew up.</p>
</blockquote>

<p>If one’s bank does not employ an individual who understands the above paragraph to mean that Silvergate was solvent, <a href="https://anthropic.com/">Anthropic</a> will sell you artificial cognition for $20 a month. Claude 3.5 Sonnet demonstrates sufficient reading comprehension to analyze complex technical documents to the standards of an early-career employee in financial services. We would recommend supervising Claude with management at least as competent as it.</p>

<p><strong>Our response regarding Bank Secrecy Act (BSA) findings:</strong></p>

<p>We have reviewed our writings with respect to Silvergate’s broadly deficient BSA compliance regime, including the anti-moneylaundering (AML) errors it made. We stand by the entire analysis, most particularly the conclusion, which we did not articulate lightly.</p>

<blockquote>
  <p>Silvergate was not a competently run institution.</p>
</blockquote>

<p>We charitably assume that Anchorage Digital has mandatory training regarding BSA/AML compliance. This is required of all banks. McCauley has even more reason to be familiar with this requirement than the typical bank CEO.</p>

<p>McCauley and Anchorage Digital Bank, National Association are signatories to <a href="https://www.occ.gov/static/enforcement-actions/ea2022-010.pdf">a 2022 consent order with the Office of the Comptroller of the Currency (OCC)</a>.</p>

<p>That consent order stems from the OCC’s finding that, quoting the order:</p>

<blockquote>
  <p>As of 2021, the Bank failed to adopt and implement a compliance program that
adequately covers the required BSA/AML program elements, including, in particular, internal controls for customer due diligence and procedures for monitoring suspicious activity, BSA officer and staff, and training.</p>
</blockquote>

<p>We have no particularized knowledge as to what Anchorage Digital’s internal training instructs employees regarding the range of sanctions available for non-compliant behavior. If that training does not rhyme with every other training in the financial industry, we suggest Anchorage Digital might consider updating it.</p>

<p>(We gave McCauley and Anchorage Digital’s press team days of advance notice of our intention to mention the consent order. We gave them the opportunity to provide a comment regarding it. Neither offered a comment.)</p>

<p><em>Debanking</em> characterizes the standard training thusly:</p>

<blockquote>
  <p>If you’ve worked in the financial industry in any capacity, you went to mandatory Compliance training. Attendance is taken and you likely had a refresher annually. And there were smirks, and jokes. And your trainer said, very seriously, “Pay attention. This is important. If we eff this up, they can do anything to us, most likely large fines but up to and including closing this firm. You, personally, could go to jail.”</p>
</blockquote>

<p>Banks are, of course, welcome to their own risk analyses, and may consider the risk of being closed for AML/BSA compliance violations to be very low. This point of view appears common among crypto bankers. Silvergate executives have professed to share it.</p>

<p>As mentioned in <em>Debanking</em>, closing a bank is an extraordinary remedy, but it is on the table.</p>

<p>Case studies which might enliven one’s next training include:</p>

<ul>
  <li>Farmington State Bank d/b/a Moonstone Bank (2023): closed by the <a href="https://www.federalreserve.gov/newsevents/pressreleases/files/enf20230817a1.pdf">Federal Reserve</a> because it was puppeted by a coalition of Tether’s bankers, who are as-yet unindicted professional money launderers, and Sam Bankman-Fried et al, who are now-<a href="https://www.justice.gov/archives/opa/pr/samuel-bankman-fried-sentenced-25-years-his-orchestration-multiple-fraudulent-schemes">convicted</a> professional money launderers.</li>
  <li>ABLV Bank (2018): designated <a href="https://www.fincen.gov/news/news-releases/fincen-names-ablv-bank-latvia-institution-primary-money-laundering-concern-and">an Institution of Primary Money Laundering Concern</a> and forbidden from using dollar clearing, resulting in the European Central Bank <a href="https://www.bankingsupervision.europa.eu/press/pr/date/2018/html/ssm.pr180219.en.html">effectively directing</a> Latvia to close it, which <a href="https://www.bank.lv/en/operational-areas/supervision/monitoring-of-ablv-bank-voluntary-liquidation-process">Latvia did</a>.</li>
  <li>Washington Federal Bank for Savings (2017): closed <a href="https://www.occ.gov/news-issuances/news-releases/2017/nr-occ-2017-150.html">by the OCC</a> for a control fraud, BSA violations, and other malfeasance. The senior executives and directors were <a href="https://www.occ.gov/news-issuances/news-releases/2022/nr-occ-2022-140.html">sanctioned individually</a> and several <a href="https://chicago.suntimes.com/the-watchdogs/2024/08/13/bridgeport-bank-scandal-washington-federal-bank-for-savings-robert-kowalski-sentencing-john-gembara">went to prison</a>.</li>
  <li>FBME Bank (2017): designated <a href="https://www.fincen.gov/resources/statutes-regulations/federal-register-notices/imposition-special-measure-against-fbme">a Financial Institution of Primary Money Laundering Concern</a> by FinCEN. It was liquidated as a direct and intended consequence.</li>
  <li>Banca Privada d’Andorra (2015): designated <a href="https://www.fincen.gov/news/news-releases/fincen-names-banca-privada-dandorra-foreign-financial-institution-primary-money">a Foreign Financial Institution of Primary Money Laundering Concern</a> by FinCEN. It collapsed as a direct and intended consequence.</li>
</ul>

<p><strong>Summary:</strong> McCauley fails to identify an incorrect allegation of fact made by <em>Debanking</em>. Viewing his statements in a light most favorable to him, he disagrees with <em>our analysis</em>. He is welcome to articulate his point of view in his own spaces, the bank’s spaces, or the halls of the Senate. He is not entitled to a retraction.</p>

<p>To the extent McCauley believes that <em>any respectable publication</em> would retract over this, he is greatly miscalibrated. We could end the inquiry here, because his next two bullet points do not even purport to allege inaccuracies, but we will continue.</p>

<h3 id="2-lots-of-omission-of-key-facts">2. “lots of omission of key facts”</h3>

<p>McCauley:</p>

<blockquote>
  <p>You completely fail to mention the exhaustive set of communications publicly coming from the regulators indicating clear guidance that crypto businesses are to be viewed as, quoting, “highly unlikely to be compatible with safe and sound banking practices”. Particularly joint letter of Jan 2023, OCC IL 1179, and the rescinding of the Fair Access to Financial Services rule. Credit for the fdic letter mention but the sum total of these moves had a clear chilling effect, that caused most large banks the country to 180 about face in crypto. You also dismiss sab121 as boring accounting (it is) without acknowledging the meta message of it to banks.</p>
</blockquote>

<p>We concur that the Joint Statement on Crypto-Asset Risks to Banking Organizations (of the Federal Reserve, FDIC, and OCC, in January 2023) was an important milestone. Which is why <strong>we cited it as such</strong>. It was linked in the following discussion.</p>

<p><em>Debanking</em>:</p>

<blockquote>
  <p>Banking regulators get to weigh in on proposed banking products. That is the absolute core of the job. That will extremely routinely result in saying something which rounds, like many of the letters do, to “We are going to have a considered think about this and get back to you, but in the meanwhile, please don’t roll this out widely.” (The think was had; the results <a href="https://www.fdic.gov/news/financial-institution-letters/2023/fil23001.html">were published</a>. Many crypto advocates do not like those results, and are asserting procedural irregularities because of that.)</p>
</blockquote>

<p>The piece extensively argues that, contra the claims of crypto advocates generally (and McCauley in <a href="https://www.banking.senate.gov/imo/media/doc/nathan_mccauley__anchorage_digital_testimony_2-5-25.pdf">his testimony before the Senate</a> after the piece was published), the publication of extensive written guidance (<em>which we linked to</em>) militates against concerns that these actions are, quoting McCauley’s testimony, “opaque [and] unfair.”</p>

<p><em>Debanking</em>:</p>

<blockquote>
  <p>Conversely, when the government is capable of publishing extensively researched position papers and extensively footnoted indictments, that should give you more confidence that it is less likely to be engaged in lawless, arbitrary behavior. Not <em>limitless</em> confidence, certainly, but it is evidence in a direction.</p>
</blockquote>

<p><strong>Our response regarding <a href="https://www.sec.gov/rules-regulations/staff-guidance/staff-accounting-bulletins/staff-accounting-bulletin-121">SAB121</a>:</strong> McCauley is the CEO of a technology company with a custody business and a foothold within the regulated financial perimeter. We are extremely aware of why he has a particular interest in SAB121.</p>

<p>While this accounting arcana is material to his firms’ business interests, we judged it of only tangential interest to most readers. We only gestured at it to (<em><strong>accurately and fairly</strong></em>) identify changing SAB121 as a policy goal of the crypto industry. It has since <a href="https://www.duanemorris.com/alerts/sab_121_undone_will_bank_regulations_crypto_follow_0125.html">been rescinded</a>.</p>

<p>McCauley’s apparent dissatisfaction with the discussion of SAB121 asserts no inaccuracy and is accordingly not a reasonable grounds for retraction.</p>

<h3 id="3-missing-the-point-about-what-we-mean-by-debanking">3. “missing the point about what we mean by debanking”</h3>

<p>McCauley:</p>

<blockquote>
  <p>Debanking wasn’t just about losing access to settlement services like SEN/signet. It was about comprehensively being unable to get bank accounts after those banks were closed. It was about banks we’d been working with for years kicking us out of the blue - and this happening across the whole industry.</p>
</blockquote>

<p>Far from “missing the point” of what crypto advocates mean by “debanking”, <em>Debanking</em> points out that crypto advocates are engaged in strategic conflation of different issues. We could not have, at the time of publishing the following, known that McCauley would request a retraction using this <a href="https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/">strategic conflation</a>, <em>pretending</em> (a word we do not choose lightly) that advocates do not really care about bank supervision, and only want business checking accounts.</p>

<p><em>Debanking</em>:</p>

<blockquote>
  <p>Advocates often invoke a user-centric perspective of debanking, focusing on the impact on individuals/firms. Then, they conflate it with regulators’ decisions regarding bank supervision, in ways which are facially not about direct user impact.</p>
</blockquote>

<p>Crypto advocates routinely exaggerate the universality of banks’ treatment of crypto. As <em>Debanking</em> discusses extensively, we absolutely agree with advocates that crypto companies <em>have, at times, routinely</em> experienced banking friction. If one is demanding a retraction, though, it <em>pays to be precise</em> and not use words like “comprehensively” to mean “not comprehensively.”</p>

<p>For example, as McCauley admitted in his testimony to the Senate Banking Committee, Anchorage Digital <em>did find a banking partner</em>.</p>

<p><em>Debanking</em>, (following a discussion of our own two debanking incidents):</p>

<blockquote>
  <p>That is the typical end to a debanking story. “And then, I opened a new account.”</p>
</blockquote>

<p>McCauley asserts, in his testimony, his belief that “over forty banks” would not have rejected Anchorage Digital but for regulators pressuring banks to cut off services to the crypto industry.</p>

<p>We have no specific knowledge about Anchorage Digital’s relationship with its former bank or more than forty prospective banks, and will let the common factor in those discussions describe them.</p>

<p>Quoting McCauley’s testimony to the Senate:</p>

<blockquote>
  <p>One day in June 2023, we received an urgent email from the bank informing us
that they needed to speak with us that day. On the call, we were told that our account
would be closed in thirty days because they were not comfortable with our crypto
clients’ transactions. We attempted to explain the source of all payments from our
crypto clients were fully documented as a part of our robust KYC, AML, sanctions
compliance, and other internal transaction monitoring and attribution processes, and
that we would be willing to provide more information to their risk management team.
They were uninterested. They refused to engage in further discussions, provide any
additional explanation, or offer any chance to appeal the decision.</p>

  <p>Alongside this experience, we found ourselves shut out of the banking system at
other touchpoints. After the closure of some of the few banks that were willing to serve crypto clients in March of 2023, we were forced to find a new banks [sic] to hold clients’ cash funds in custody for trading purposes, as well as an account to hold segregated regulatory capital, both required to be held at an FDIC-insured bank under the terms of our bank charter. Again, we should have been a desirable, low-risk client for a bank. Yet over the course of a seven month period we spoke to over forty banks and were rejected by all of them. Many did not even cite a reason; others just vaguely told us it was not within their risk appetite to work with crypto clients.</p>
</blockquote>

<p><strong>Our response:</strong></p>

<p>We trust McCauley’s representation that this happened.</p>

<p>We also believe <em>Debanking</em> adequately explains to a non-involved individual <em>why</em> it happened. See the section <a href="https://www.bitsaboutmoney.com/archive/debanking-and-debunking/#debanking-specifically-for-aml-risk">Debanking specifically for AML risk</a>. Indeed, a reader of <em>Debanking</em> would have, months before McCauley’s testimony, been able to predict elements like the 30 day notice period, the disinterest in further negotiations, and the lack of appeals process.</p>

<p>McCauley, like many crypto advocates, professes to believe that a legitimate crypto company is a low-risk bank client. His testimony discusses the desire of Anchorage Digital to have demand deposit accounts, on its own behalf and on behalf of customers.</p>

<p>We empathized in <em>Debanking</em> with crypto entrepreneurs who are not banking experts. Some might not understand how a legitimate, legal business could be anything other than a low-risk bank client. We explained how. At substantial length.</p>

<p>Crypto advocates love a bit of risk, and love even more when somebody else has to buy them out of the downside, while they keep the upside. The demand that banks <em>just give them deposit accounts</em> is a demand that bank shareholders backstop their credit (and other) risk. Crypto advocates mostly do not intend to give their banks equity for this risk.</p>

<p>One can understand how a crypto founder who is raising their seed round might not yet be a banking expert.</p>

<p>Members of a bank board of directors, on the other hand, are charged with managing a variety of risks to their bank. They <em>must be able to articulate</em> how a legitimate business could pose credit (and other) risk to a bank with only demand deposit accounts.</p>

<p>This topic is discussed extensively in <em>Debanking</em>, including a worked example from the experience of Metropolitan Commercial Bank. Metropolitan primarily provided “low-risk” cash management services to Voyager Digital, a cryptocurrency platform/exchange. Voyager was a legitimate business, publicly traded, and believed to be well-capitalized. It represented to its bank, investors, and regulators that it had best-in-class risk and compliance programs in place.</p>

<p>Voyager blew up, due to its best-in-class risk program seeing <a href="https://www.wsj.com/articles/crypto-broker-voyager-digital-says-three-arrows-capital-hasnt-repaid-666-million-in-loans-11655915660">single-name exposure to $666 million</a> representing <a href="https://www.coppolacomment.com/2022/07/the-sinking-of-voyager.html">60% of loan book / 30% of all assets</a> and leaping at the opportunity. When it collapsed, customers who had sent Voyager money, but not received crypto in return, began to initiate reversals of those transfers. Metropolitan was faced with a credit loss large enough to imperil their entire crypto banking practice, which was approximately a quarter of deposits prior to the collapse. Metropolitan was dragged into Voyager’s contentious bankruptcy. It was sued over its conduct and alleged lapses.</p>

<p>One wonders whether Metropolitan, in clarity of hindsight, considers providing cash management services to an upstanding cryptocurrency platform to be “low-risk.”</p>

<p>Metropolitan attributes “the strategic assessment of the business case”, along with the regulatory environment, for deciding to fully exit crypto banking, which they claim they had pivoted from beginning in 2017.</p>

<p>McCauley’s assertion that <em>Debanking</em> ignores a constellation of regulatory activity which caused the banking industry to update negatively on its view of crypto is unsupported and unsupportable. We analyzed it extensively, along with <em>the other</em> reasons the banking industry negatively updated on crypto.</p>



<p>McCauley:</p>

<blockquote>
  <p>Broadly, the meta thesis of your piece is “nothing to see here regulators gonna regulate and banks gonna bank” which is just not what happened. Sprinkle in some non sequiturs about FTX and your humorous crypto skepticism and you have an entertainingly written piece that sadly misses the point. The biggest problem with it is how well it’s written! A passive observer unfamiliar with the details probably reads it and agrees with you and feels they are smarter.</p>
</blockquote>

<p>McCauley misinterprets the thesis of the piece, which is hinted at in the usual place and in the usual manner: stating it explicitly, very near the top.</p>

<p><em>Debanking:</em></p>

<blockquote>
  <p>“It’s not a conspiracy theory if people really are out to get you.” sums up part of my reaction to [the claims of crypto advocates], but only part. There exists some amount of conflation between what private actors are doing, what state actors have de facto or de jure commanded that they do, and which particular state and political actors have their fingers on the keyboard. These create a complex system; the threads are not entirely divorced from each other.</p>
</blockquote>

<p>We concur with McCauley that many readers might, after reading <em>Debanking</em>, feel that they are better informed about debanking than if they simply trust the representations of crypto advocates. Kalzumeus Software does not consider this a bug and WONTFIX.</p>

<p>We disagree with McCauley’s characterization of readers moved by the piece as “passive observer[s] unfamiliar with the details.” Many of our readers are extremely professionally invested in these topics, perhaps by dint of working in finance, financial technology, bank supervision, policy roles in the U.S. federal government, or the cryptocurrency industry.</p>

<p>McCauley has failed to identify a single fact alleged in <em>Debanking</em> which is incorrect, or any other malfeasance. Differences of opinion or different preferences in emphasis are, of course, not a reasonable basis for retraction. We accordingly reject his request for a retraction.</p>

<h2 id="bank-ceos-do-not-often-ask-writers-for-retractions">Bank CEOs do not often ask writers for retractions</h2>

<p>I need to promote an important subtext to text.</p>

<p>It is <em>exceedingly rare</em> for bank CEOs, who are chosen for probity, sound judgement, and professionalism, to demand retractions. It is rare enough for <em>banks</em> to do it, and when they do, it usually follows quiet outreach by e.g. PR or Legal teams.</p>

<p>Some might mismodel writers as being thrilled by unprofessional behavior.</p>

<p>The incorrect model is that the writer immediately enjoys the opportunity to embarrass someone, and probably gets paid to do it. There is an old saw about “Never pick a fight with someone who buys ink by the barrel”; a more modern articulation might mention the <a href="https://en.wikipedia.org/wiki/Streisand_effect">Streisand Effect</a>. (Wow, more than 20 years old now?! There are <em>bank employees</em> too young for that reference. Yeet it into an LLM if you need to.)</p>

<p>These bits of folk wisdom do not match how serious professionals perceive the incentives and power dynamics at play here. Banks are, as a class, much better resourced than writers (and almost all publications).</p>

<p>I am a very atypical writer vis the financial industry.</p>

<ul>
  <li>I have substantial experience and expertise in the topics I write about.</li>
  <li>I have substantial resources and independent decisionmaking authority.</li>
  <li>I would take perverse joy in being sued by a crypto company.</li>
</ul>

<p>Most writers work for an institution, and that is a Faustian bargain. On the one hand, working for an institution means that <em>when a bank sues for libel</em>, they will sue your employer, and not you. On the other hand, one’s Legal department, being <em>very sensitive to the expense and annoyance of being sued for libel</em>, will tread very lightly around prickly institutions and individuals. This includes exercising prior restraint of reasonable reporting and commentary.</p>

<p>A demand for a retraction by the CEO of a well-resourced financial institution is reasonably read by most outlets as being backstopped by potential legal consequences if they do not comply. Well-calibrated professionals understand retractions will only happen in the event of serious malfeasance. Accordingly, a request for a retraction is a statement that one believes one has suffered serious malfeasance.</p>

<p>Not all CEOs are well-calibrated. But publishers have to take certain genres of statements from certain genres of business owners much more seriously than other people might take them.</p>

<p>This includes when those statements are communicated via the Internet. <strong>The Internet is real life.</strong> A statement made by a bank using the Internet is <em>a statement by a bank</em>. Of course it wasn’t transmitted by telegraph, stagecoach, or carrier pigeon! A statement made by a bank CEO, etc etc.</p>

<p>And thus the recital above that e.g. Kalzumeus Software, LLC was and is the publisher of <em>Debanking</em> (and this piece), and thus the serious discussions with professional advisors. While I sometimes feel like I am LARPing at running a business, the great state of Nevada, the bank holding my mortgage, the IRS, and my insurance company are unanimous that <em>I do in fact run a business</em>. I am obliged to operate it in a competent fashion, including taking my legal responsibilities seriously, and managing risk to the business and other stakeholders.</p>

<p>Perhaps some bank CEOs feel like they’re just LARPing sometimes. I can empathize. But, to quote U.S. District Court Judge Ana Reyes (in <a href="https://assets.ctfassets.net/sygt3q11s4a9/22j1EXHivrIHXgCM9EmyAZ/d9b5fb93c5f862052f7b16f3aecbe716/HA_v._FDIC_1.22.25_Hearing_Transcript.pdf">a hearing on FDIC’s recent tussle with Coinbase</a>), “welcome to the NFL.”</p>

<p>I speak only for myself and, as I’ve said for years, I work for the Internet. The Internet is humanity’s crowning achievement. It is also <em>a community</em> and <em>that community has norms.</em> One of those norms is that it fights attempts at censorship. As a Internet-native independent writer who is better resourced than almost all writers who will ever get a saber rattled at them by a bank or banker, I will say what they cannot.</p>

<p>This conduct is unwarranted, unprofessional, and dishonorable. It should cease.</p>

<p>The <em>opinions</em>, on the other hand, are merely wrong. One is welcome to publish one’s opinions to the Internet in a manner of one’s choosing. (One may have stricter obligations with respect to representations made to one’s regulators or e.g. Congress. Ask one’s lawyers.)</p>

<h2 id="some-context-regarding-custodial-banks">Some context regarding custodial banks</h2>

<p>Many readers might wonder why a bank needs a bank. Indeed, McCauley’s verbal statement to Congress has a <a href="https://x.com/Anchorage/status/1887162623516725627">mic drop moment</a> where he expresses incredulity that a federally chartered bank could be debanked. It’s great theatre.</p>

<p>A fun bit of banking Compliance trivia: there exist <em>banks</em> which one cannot <em>bank</em> at.</p>

<p>Anchorage Digital Bank, National Association is one such bank.</p>

<p>Quoting Anchorage Digital’s home page’s fine print:</p>

<blockquote>
  <p>“Anchorage Digital” refers to services that are offered through the wholly-owned subsidiaries of Anchor Labs, Inc., a Delaware corporation.</p>
</blockquote>

<p>Anchorage Labs, Inc. is a tech company, and not a bank. That tech company has a <em>relationship with</em> Anchorage Digital Bank, National Association. That relationship involves receiving fees from the bank for services. As to whether it is an <em>ownership</em> relationship, well, I’d bet their lawyers can tell you a <em>scintillating</em> and true story about bank holding companies.</p>

<p>Anchorage Digital Bank, National Association makes much of the fact that they are a federally chartered bank, operating under the auspices of an agreement with the OCC.</p>

<p>Quoting Article V of their <a href="https://www.occ.gov/news-issuances/news-releases/2021/nr-occ-2021-6b.pdf">operating agreement with the OCC</a>:</p>

<blockquote>
  <p>The Bank shall limit its business to the operations of a trust company and
activities related or incidental thereto. The Bank shall not engage in activities that would cause it to be a “bank” as defined in section 2(c) of the Bank Holding Company Act.</p>
</blockquote>

<p>Those activities? Taking deposits and making loans, the traditional business of banking.</p>

<p>Anchorage Digital was previously a trust company in South Dakota prior to getting the OCC charter.</p>

<p>Trust companies, a type of regulated financial institution, can run custody businesses. A custodian maintains legal and operational control of an asset, but does not <em>own</em> it. The owner pays them because keeping that asset safe and useful increases the value of the asset by more than the cost of custody. You are yourself, reader, very likely a beneficial owner of assets held at a custodian. This is especially likely if you hold financial assets which are not cryptocurrency tokens. You have probably not paid an invoice for these professional services directly. Another entity, such as e.g. your brokerage or a fund you are invested in, paid for them as a prerequisite to offering you a bundle of services, of which custody is one necessary component.</p>

<p>A custody business might have other modern products such as e.g. a real-time settlement API. That is one of Anchorage Digital’s marquis <a href="https://www.anchorage.com/platform/settlement">products</a>. For a fuller discussion of real-time settlement APIs and why the crypto industry considers them structurally important, see <em>Debanking</em>’s discussion of the Silvergate Exchange Network.</p>

<p>Speaking of crypto trust companies, remember Prime Trust? It was a Nevada chartered trust company, which also had a custody business. Prime Trust <a href="https://www.prnewswire.com/news-releases/financial-infrastructure-innovator-prime-trust-raises-64m-in-new-funding-as-annual-revenue-run-rate-crossed-100m-mark-301343163.html">purported</a> to be the adults-in-the-room bilingual-in-TradFi eagerly-complying-with-regulations crypto custody company. They were going to clean up the cowboy behavior in the industry. This is a familiar sales pitch, also made by FTX, Voyager, BlockFi, Genesis, and probably some firms which are still with us, too.</p>

<p>Prime Trust lost a portion of the assets they were custodying due to technical incompetence (they wrote seed phrases allowing recovery of private keys on a piece of metal… then lost the metal). They then misappropriated other customer assets to buy substitute assets to fund withdrawals. This, per <a href="https://storage.courtlistener.com/recap/gov.uscourts.deb.190581/gov.uscourts.deb.190581.14.0.pdf">their bankruptcy filing</a>, resulted in insolvency which they concealed from their regulators and customers through intentional fraud.</p>

<p>When this came to light, they were closed by their regulators. This was in June of 2023. By coincidence, that is the same month that Anchorage Digital lost their banking partner.</p>

<p>This loud and notorious collapse of a major competitor to Anchorage Digital, happening as a result of incompetence and malfeasance, despite that competitor having said all the right things, as <em>part of a pattern</em>, seems relevant to the interests of banks in the summer of 2023. One might choose to recount it in describing those banks’ reticence to do business with one’s industry. Perhaps one might acknowledge that one’s prospective banks might have had legitimate concerns. (Washington professionally appreciates a well-executed limited hangout.) Having done so, one might tease out the nuance that those concerns <em>might have been surmountable</em> but for excessive regulatory pressure.</p>

<p>Time is precious in front of elected officials, though, and Anchorage eschewed that and stuck to simpler messaging.</p>

<p>Anchorage Digital mentioned its strong commitment to seeking (direct quote) “the highest level of regulatory scrutiny and certainty”, and its determination to meet the obligations it has signed up for. This was repeated multiple times for emphasis.</p>

<p>At approximately <a href="https://www.banking.senate.gov/hearings/investigating-the-real-impacts-of-debanking-in-america">1:08:30 in the recording of the Senate hearing</a>, CEO McCauley stated “That’s right. I’m a bit of a square, and like following rules, and so we always followed all the rules and regulations.”</p>

<p>I am also a bit of a square. I have never signed a consent order with the OCC regarding deficiencies in my bank’s BSA/AML program, however.</p>

<h3 id="my-business-cards-do-say-wire-transfer-compliance-influencer">My business cards do say “wire transfer compliance influencer”</h3>

<p>McCauley’s testimony that Anchorage lacks the ability to facilitate customer wires to third parties, “a basic banking service that we previously had access to”, may have surprised some listeners.</p>

<p>Readers of <em>Debanking</em> might be able to predict what point of view a <a href="https://www.anchorage.com/insights/anchorage-digital-initial-partner-in-global-dollar-network">sub-custodian bank</a> might have regarding AML risk of third-party wires for crypto clientele. The sub-custodian might not be moved by a valued customer’s complaints their customers are simply crypto-native and traditional institutions requesting wires to crypto-native counterparties.</p>

<p>Why not?</p>

<p>For example, readers might remember the statement (quoted in <em>Debanking</em>, on the basis of <a href="https://www.piratewires.com/p/inside-biden-admin-plot-to-destroy-silvergate-and-debank-crypto-for-good-nic-carter?f=author">reporting by Nic Carter</a>): <em>Where we were not as buttoned up as we should have been was in regards to the FTX/Alameda clients. That was a function of the bank growing incredibly quickly[.] … Probably we could have figured out FTX was brokering deposits via Alameda. In retrospect I think we could have pieced this together and figured it out.</em></p>

<p>Readers are welcome to their estimate of whether the quoted Silvergate executive, who Carter granted anonymity to, will work in banking again. Executives at many other banks do not relish the possibility of waking up to news that a crypto company was, once again, <em>not as buttoned up as it should have been.</em></p>

<h2 id="returning-to-our-regularly-scheduled-programming">Returning to our regularly scheduled programming</h2>

<p>As I point out in <em>Debanking</em> and elsewhere, crypto advocates would prefer to be judged on their potential rather than their track record. As a sometimes resident of Washington put it memorably: “What can be, unburdened by what has been.”</p>

<p>Optimism about future potential is highly prized in the startup community. It does not require unpublishing true claims about track records.</p>

<p>I continue to agree with crypto advocates on many of their claims. I will continue writing about the reality, warts and all, of the financial system. I will explain how history, humans, policy decisions, and technology have come together to deliver it. I will cover upgrades we’re collectively trying to build for it.</p>

<p>When those systems confound our expectations, or when their regulators <a href="https://x.com/patio11/status/1887567967392538641">are disregulated</a>, interested readers will find facts and fearlessness in <a href="https://www.bitsaboutmoney.com/">Bits about Money</a>.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Anthropic Economic Index (525 pts)]]></title>
            <link>https://www.anthropic.com/news/the-anthropic-economic-index</link>
            <guid>43000529</guid>
            <pubDate>Mon, 10 Feb 2025 14:14:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.anthropic.com/news/the-anthropic-economic-index">https://www.anthropic.com/news/the-anthropic-economic-index</a>, See on <a href="https://news.ycombinator.com/item?id=43000529">Hacker News</a></p>
Couldn't get https://www.anthropic.com/news/the-anthropic-economic-index: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Surnames from nicknames nobody has any more (894 pts)]]></title>
            <link>https://blog.plover.com/lang/etym/nickname-names.html</link>
            <guid>43000316</guid>
            <pubDate>Mon, 10 Feb 2025 13:54:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.plover.com/lang/etym/nickname-names.html">https://blog.plover.com/lang/etym/nickname-names.html</a>, See on <a href="https://news.ycombinator.com/item?id=43000316">Hacker News</a></p>
Couldn't get https://blog.plover.com/lang/etym/nickname-names.html: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HTML visualization of a PDF file's internal structure (396 pts)]]></title>
            <link>https://github.com/desgeeko/pdfsyntax/blob/main/docs/browse.md</link>
            <guid>43000303</guid>
            <pubDate>Mon, 10 Feb 2025 13:52:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/desgeeko/pdfsyntax/blob/main/docs/browse.md">https://github.com/desgeeko/pdfsyntax/blob/main/docs/browse.md</a>, See on <a href="https://news.ycombinator.com/item?id=43000303">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text">
<p dir="auto"><h3 tabindex="-1" dir="auto">Introduction</h3><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Inspecting the internal structure of a PDF file involves a lot of things (decompression, parsing, xref indexing, etc...) in order to make sense of the raw bytes.</p>
<p dir="auto">PDFSyntax takes care of the processing and proposes a visualization approach that consists in adding information and hyperlinks on top of a text that is a mostly a pretty-print of the PDF data once uncompressed. It respects the physical flow of the file while offering a logical navigation between revisions (incremental updates) and between objects.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Architecture</h3><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<p dir="auto">PDFSyntax is a self-contained Python package - without any dependency - and is principally a low-level PDF library.
The <code>browse</code> command is its highest and most visible part. It produces static HTML content that offers sufficient interactivity: JavaScript may be disabled.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Demo</h3><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto">Please try the <a href="https://pdfsyntax.dev/simple_text_string.html" rel="nofollow"><strong>LIVE DEMO</strong></a> of a full static HTML output that you can browse, at <a href="https://pdfsyntax.dev/simple_text_string.html" rel="nofollow">https://pdfsyntax.dev/simple_text_string.html</a> (hosted on GitHub Pages).</p>
<p dir="auto">Here is the same example, as a partial screenshot:
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/desgeeko/pdfsyntax/main/docs/screenshot.png"><img src="https://raw.githubusercontent.com/desgeeko/pdfsyntax/main/docs/screenshot.png" alt="PDFSyntax screenshot"></a></p>
<p dir="auto">NB: this is the output produced for the <a href="https://github.com/desgeeko/pdfsyntax/raw/main/samples/simple_text_string.pdf"><em>Simple Text String</em></a> example file from the PDF Specification.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">PDFSyntax can be installed from the GitHub repo (no dependency) or from PyPI:</p>

<p dir="auto">Redirect the standard output to a file that you can open in your browser:</p>
<div data-snippet-clipboard-copy-content="python3 -m pdfsyntax browse file.pdf > inspection_file.html"><pre><code>python3 -m pdfsyntax browse file.pdf &gt; inspection_file.html
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Features</h3><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">The generated HTML "looks" like an augmented raw PDF file with the following additional work:</p>
<ul dir="auto">
<li>Add a reverse index: links to where an object is used</li>
<li>Add a page index in a navigation menu</li>
<li>Add a physical minimap in a navigation menu</li>
<li>Indent to pretty-print dictionary objects</li>
<li>Extract objects contained in object streams and insert them in the flow like regular objects</li>
<li>Decompress streams and display a small part of it</li>
<li>Turn indirect object references into hyperlinks</li>
<li>Turn offset references (for example a /Prev entry) into hyperlinks</li>
<li>Display file offsets of objects in a left margin</li>
<li>Put some color on important names (for example /Type)</li>
<li>Put some color on warnings (for example the presence of /JS)</li>
<li>Light &amp; dark modes</li>
</ul>
<blockquote>
<p dir="auto">WARNING: Encrypted files are not supported yet</p>
</blockquote>
<blockquote>
<p dir="auto">WORK IN PROGRESS: New features are on the roadmap</p>
</blockquote>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why hasn't commercial air travel gotten any faster since the 1960s? (2009) (107 pts)]]></title>
            <link>https://engineering.mit.edu/engage/ask-an-engineer/why-hasnt-commercial-air-travel-gotten-any-faster-since-the-1960s/</link>
            <guid>43000275</guid>
            <pubDate>Mon, 10 Feb 2025 13:50:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://engineering.mit.edu/engage/ask-an-engineer/why-hasnt-commercial-air-travel-gotten-any-faster-since-the-1960s/">https://engineering.mit.edu/engage/ask-an-engineer/why-hasnt-commercial-air-travel-gotten-any-faster-since-the-1960s/</a>, See on <a href="https://news.ycombinator.com/item?id=43000275">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
                <p><img src="https://engineering.mit.edu/wp-content/uploads/2017/01/square_transportation.jpg" alt="Why hasn’t commercial air travel gotten any faster since the 1960s?">
        </p>

        <!--<div class="link-box">
          <a class="question-box" href="#">Submit a Question</a>
        </div>-->

        <div>
          <h6>Related Questions</h6>
                        <ul>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/why-cant-cars-run-on-water-instead-of-gasoline/" title="">Why can’t cars run on water instead of gasoline?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/are-santas-reindeer-used-for-propulsion-or-navigation/" title="">Are Santa’s reindeer used for propulsion or navigation?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/can-i-make-my-car-fly/" title="">Can I make my car fly?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/is-there-a-way-to-detect-my-cars-keyless-remote-if-i-dont-know-where-it-is/" title="">Is there a way to detect my car’s keyless remote if I don’t know where it is?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/would-it-be-feasible-to-dump-nuclear-waste-on-the-moon/" title="">Would it be feasible to dump nuclear waste on the Moon?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/why-dont-spacecraft-burn-up-or-veer-off-course-during-reentry-from-space/" title="">Why don’t spacecraft burn up or veer off course during reentry from space?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/why-does-traffic-bottleneck-on-freeways-for-no-apparent-reason/" title="">Why does traffic bottleneck on freeways for no apparent reason?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/can-robotic-submarines-collect-specimens-at-any-ocean-depth/" title="">Can robotic submarines collect specimens at any ocean depth?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/can-i-start-my-car-with-a-voice-command/" title="">Can I start my car with a voice command?</a>
                  </li>
                                  <li>
                    <a href="https://engineering.mit.edu/engage/ask-an-engineer/how-can-a-person-ride-a-motorcycle-100-mph-but-not-stand-up-in-a-100-mph-wind/" title="">How can a person ride a motorcycle 100 mph but not stand up in a 100 mph wind?</a>
                  </li>
                              </ul>
              
          <p><a href="https://engineering.mit.edu/engage/ask-an-engineer/">Browse all
            questions</a>

        </p></div>

      </div><!-- .left-area -->

      <div>

                          <h3>Why hasn’t commercial air travel gotten any faster since the 1960s?</h3>
          <p>In an era when everything else is accelerating, airplanes are actually flying at slower speeds than they used to…</p>
          <p><em>By Peter Dunn</em></p><p>Specified cruising speeds for commercial airliners today range between about 480 and 510 knots, compared to 525 knots for the Boeing 707, a mainstay of 1960s jet travel. Why? “The main issue is fuel economy,” says aeronautics and astronautics professor Mark Drela. “Going faster eats more fuel per passenger-mile. This is especially true with the newer ‘high-bypass’ jet engines with their large-diameter front fans.”</p>
<p>Observant fliers can easily spot these engines, with air intakes nearly 10 feet across, especially on newer long-range two-engine jetliners. Older engines had intakes that were less than half as wide and moved less air at higher speeds; high-bypass engines achieve the same thrust with more air at lower speed by routing most of the air (up to 93 percent in the newest designs) around the engine’s turbine instead of through it. “Their efficiency peaks are at lower speeds, which causes airplane builders to favor a somewhat slower aircraft,” says Drela. “A slower airplane can also have less wing sweep, which makes it smaller, lighter and hence less expensive.” The 707’s wing sweep was 35 degrees, while the current 777’s is 31.6 degrees.</p>
<p>There was, of course, one big exception: the Concorde flew primarily trans-Atlantic passenger routes at just over twice the speed of sound from 1976 until 2003. Product of a treaty between the British and French governments, the Concorde served a small high-end market and was severely constrained in where it could fly. An aircraft surpassing the speed of sound generates a shock wave that produces a loud booming sound as it passes overhead; fine, perhaps, over the Atlantic Ocean, but many countries banned supersonic flights over their land. The sonic-boom problem “was pretty much a show-stopper for supersonic transports,” says Drela.</p>
<p>Some hope for future supersonic travel remains, at least for those able to afford private aircraft. Several companies are currently developing supersonic business jets. Their smaller size and creative new “boom-shaping” designs could reduce or eliminate the noise, and Drela notes that supersonic flight’s higher fuel burn per passenger-mile will be less of an issue for private operators than airlines. “But whether they are politically feasible is another question,” he notes.</p>
<p>For now, it seems, travelers will have to appreciate the virtues of high-bypass engines, and perhaps bring along a good book.</p>
<p>Posted: February 19, 2009</p>
            
          
      </div><!-- .right-area -->
    </div><div id="pop_up_mit">
        <p>
          [contact-form-7 id="442" title="Submit Question"]        </p>
      </div></div>]]></description>
        </item>
    </channel>
</rss>