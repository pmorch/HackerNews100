<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 24 Apr 2025 07:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Shortest-possible walking tour to 81,998 bars in South Korea (252 pts)]]></title>
            <link>https://www.math.uwaterloo.ca/tsp/korea/index.html</link>
            <guid>43778105</guid>
            <pubDate>Thu, 24 Apr 2025 00:20:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.math.uwaterloo.ca/tsp/korea/index.html">https://www.math.uwaterloo.ca/tsp/korea/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=43778105">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> 

<p>
We have solved a traveling salesman problem (TSP) to walk to 81,998 bars in South Korea.
The problem was created using the <a href="https://project-osrm.org/">Open Source Routing Machine</a> (OSRM) to build a table of the 3,361,795,003 point-to-point travel times, one for each pair of bar locations.
Our computation produced a tour together with a proof that it is a shortest-possible route to visit all 81,998 stops when measured with the OSRM times.
</p>

<p>
It would be a very long pub crawl.
The total walking time for the round trip is 15,386,177 seconds, or 178 days, 1 hour, 56 minutes, and 17 seconds.
You will need to stop for plenty of drinks along the way (better stick with water, tea, or Diet Coke if you want to finish the route in only a few years), so it's  not likely you would count every second on such a journey.
But the level of precision makes the point that this not just a good route, it is an optimal solution to the 81,998-stop TSP.
It is not possible to rearrange the order of stops to save even a single second of the OSRM-estimated walking time.
</p>


<p>
This is the largest road-map instance of the TSP that has been solved to provable optimality, exceeding the <a href="https://www.math.uwaterloo.ca/tsp/nl/index.html">57,912-stop tour through the Netherlands</a> solved in February 2021.
The computations were carried out between December 2024 and March 2025 at <a href="https://ruc.dk/en">Roskilde University</a> and at the <a href="https://uwaterloo.ca/">University of Waterloo</a>.
Details of the computing work can be found on the <a href="https://www.math.uwaterloo.ca/tsp/korea/computation.html">Computation</a> page.
</p>


<p>
  <h2>Interactive map</h2>
</p>


<p>       
The figure below is a screen shot of an interactive map of the korea81998 tour.
The menu on the left-hand-side lets you select one of seven regions to view.
At the top right-hand-side you can choose to have either a colored street map or a grayscale map without street labels.
Just below this menu you can select whether or not to display the stop markers, or to display the tour edges, or to display both.
You can view the map by clicking on the image.
</p><figure>
  <a href="https://www.math.uwaterloo.ca/tsp/korea/korea81998_lite.html"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/korea_map.jpg" width="100%" alt="Screenshot of the interactive map"></a>
</figure>





<p>
  <h2>Snapshots of the Tour</h2>
</p>

<p>
If you have trouble viewing the interactive map, you can click on the drawings below to see high-resolution images of the tour.
For close-up views of city regions, please see the <a href="https://www.math.uwaterloo.ca/tsp/korea/cities.html">Cities</a> page.
</p>

<div>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap1.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap1_1000.jpg" alt="Tour snapshot 1"></a>
   </p>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap2.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap2_1000.jpg" alt="Tour snapshot 2"></a>
   </p>
</div> 

<div>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap3.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap3_1000.jpg" alt="Tour snapshot 3"></a>
   </p>
   <p><a href="https://www.math.uwaterloo.ca/tsp/korea/img/snap4.jpg"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/snap4_1000.jpg" alt="Tour snapshot 4"></a>
   </p>
</div> 




<p>
  <h2>Optimality</h2>
</p>

<p>
Newspapers, popular journals, blogs, and scientific press releases regularly report that solving even tiny instances of the TSP is impossible with the current generation of computers.
A typical example is the following quote from the Washington Post.
</p>

<figure>
<blockquote>
<p>
"It would take a laptop computer 1,000 years to compute the most efficient route between 22 cities, for example."
</p>
</blockquote>
  
</figure>

<!--
<figure>
<blockquote class="blockquote">
<p>
"... used a special quantum chip to solve a 22-stop traveling salesman problem that would have taken a supercomputer more than a thousand years to solve."
</p>
</blockquote>
  <figcaption class="blockquote-footer">
     Alles auf Quantencomputer!: Warum es lohnt, auf die Schluesseltechnologie zu setzen, <cite title="Source Title">Der Tagesspiegel</cite>, November 25, 2021.
  </figcaption>
</figure>

<figure>
<blockquote class="blockquote">
<p>
"With 50 landmarks to put in order . . . . computing this problem on your home computer right now, you'd find the optimal route in about 9.64 x 10<sup>52</sup> years."
</p>
</blockquote>
  <figcaption class="blockquote-footer">
     The ultimate American road trip revealed: Data scientist uses algorithms to plot the best route across the United States, <cite title="Source Title">Daily Mail</cite>, March 14, 2015.
  </figcaption>
</figure>
-->


<p>
Statements such as this assume the only way to solve the TSP is to check each possible tour, one-by-one.
That clearly cannot work for any of the large instances of the TSP we have solved.
The number of tours in the korea81998 case is roughly <a href="http://www.wolframalpha.com/input/?i=81997!">2 followed by 367308 zeroes</a>.
</p>

<p>
This huge number of possible solutions is frightening, but it doesn't mean we can't solve this large example of the TSP.
Our approach combines the <a href="http://webhotel4.ruc.dk/~keld/research/LKH/">LKH</a> code for computing extremely good TSP solutions and the <a href="https://www.math.uwaterloo.ca/tsp/concorde.html">Concorde</a> code for applying what is known as the "cutting-plane method" for producing quality guarantees.
You can see a short discussion of how we apply these tools on the <a href="https://www.math.uwaterloo.ca/tsp/korea/computation.html">Computation</a> page.
</p>

<p>
For a quick glimpse of the cutting-plane method, here is how I describe the process in a <a href="http://www.scientificamerican.com/article/case-traveling-salesman-unsolvable-limits-computation/">short piece in Scientific American</a>
</p>
<figure>
<blockquote>
<p>
"The idea is to follow Yogi Berra's advice `When you come to a fork in the road, take it.' A tool called linear programming allows us to do just this, assigning fractions to roads joining pairs of cities, rather than deciding immediately whether to use a road or not. It is perfectly fine, in this model, to send half a salesman along both branches of the fork."
</p>

<p>
"The process begins with the requirement that, for every city, the fractions assigned to the arriving and departing roads each sum to one. Then, step-by-step, further restrictions are added, each involving sums of fractions assigned to roads. Linear programming eventually points us to the best decision for each road, and thus the shortest possible route."
</p>
</blockquote>
<!--
  <figcaption class="blockquote-footer text-bg-light p-1 border border-dark-subtle border-top-0">
    Traveling Salesman: A Seemingly Unsolvable Problem Offers a Glimpse of the Limits of Computation, <cite title="Source Title">Scientific America</cite>, June 2012.
  </figcaption>
-->
</figure>


<p>
If you have a few minutes, you can check out the video of the talk <a href="https://www.youtube.com/watch?v=tChnXG6ulyE">Optimal Tours</a> given at the <a href="https://momath.org/civicrm/?page=CiviCRM&amp;q=civicrm%2Fevent%2Finfo&amp;reset=1&amp;id=6601">National Museum of Mathematics</a>, where the method is described in detail. 
Or, keeping with the Korean theme, please have a look at video of the talk <a href="https://www.youtube.com/watch?v=W0XnU1uvIwo">Amazon Deliveries, Pub Walks, and Astro Tours</a>, given at <a href="https://www.kaist.ac.kr/en/">KAIST</a> in March 2024.

</p><div>
   <p><a href="https://www.youtube.com/watch?v=tChnXG6ulyE"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/momath_title.jpg" alt="Tour snapshot 1"></a>
   </p>
   <p><a href="https://www.youtube.com/watch?v=W0XnU1uvIwo"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/korea2024_title.jpg" alt="Tour snapshot 2"></a>
   </p>
</div> 




<p>
  <h2>P vs NP</h2>
</p>

<p>
A great discussion of the P and NP complexity classes, including connections to the TSP, can be found in Lance Fortnow's article <a href="https://dl.acm.org/doi/pdf/10.1145/3460351">Fifty Years of P vs. NP and the Possibility of the Impossible</a>.
</p>

<figure> 
  <img src="https://www.math.uwaterloo.ca/tsp/korea/img/optiland.jpg" width="50%" alt="Optiland">
  <figcaption>Credit: https://cacm.acm.org/research/fifty-years-of-p-vs-np-and-the-possibility-of-the-impossible/</figcaption>
</figure>


<p>
  <h2>The Big Picture</h2>
</p>

<p>
We use large examples of the traveling salesman problem as a means for developing and testing general-purpose optimization methods.
The world has limited resources and the aim of the applied mathematics fields of <a href="https://en.wikipedia.org/wiki/Mathematical_optimization">mathematical optimization</a> and <a href="https://en.wikipedia.org/wiki/Operations_research">operations research</a> is to create tools to help us to use these resources as efficiently as possible.
</p>

<p>
For general information on mathematical modeling and its impact on industry, commerce, medicine, and the environment, we point you to a number of societies that support mathematics research and education:
<a href="http://www.ams.org/home/page">American Mathematical Society</a>,
<a href="http://www.maa.org/">Mathematical Association of America</a>,
<a href="http://www.mathopt.org/">Mathematical Optimization Society</a>,
<a href="https://www.informs.org/">INFORMS</a> (operations research), 
and <a href="http://www.siam.org/">SIAM</a> (applied mathematics).
</p>


<p>
  <h2>Research Team</h2>
</p>

<p>
  <a href="http://www.math.uwaterloo.ca/~bico/">William Cook</a>, Combinatorics and Optimization, University of Waterloo, Canada<br>
  <a href="https://scholar.google.com/citations?user=7KSvWuQAAAAJ&amp;hl=en">Daniel Espinoza</a>, Alicanto Labs, Chile<br> 
  <a href="http://mgoycool.uai.cl/">Marcos Goycoolea</a>, School of Business, Universidad Adolfo Ibanez, Chile<br>
  <a href="http://www.akira.ruc.dk/~keld/">Keld Helsgaun</a>, Computer Science, Roskilde University, Denmark
</p>


<p>
  <h2>Acknowledgements</h2>
</p>

<p>
The huge number of linear-programming models that arose in the computation were solved with the <a href="https://www-01.ibm.com/software/commerce/optimization/cplex-optimizer/">IBM CPLEX Optimizer</a>.
Many thanks to IBM for making their great software <a href="https://community.ibm.com/community/user/datascience/blogs/xavier-nodet1/2020/07/09/cplex-free-for-students">freely available for academic research</a>.
</p>

<p>
The map drawings of the tour were created with the <a href="https://leafletjs.com/">Leaflet</a> open-source JavaScript library for mobile-friendly interactive maps and make use of map tiles built by <a href="https://www.openstreetmap.org/">OpenStreetMap</a>, by <a href="https://carto.com/basemaps">Carto Basemaps</a> and by <a href="https://stadiamaps.com/products/map-tiles/">Stadia Maps</a>.
</p>

<p>
We thank <a href="https://dimag.ibs.re.kr/home/sangil/">Dr. Sang-il Oum</a>, Chief Investigator of the <a href="https://dimag.ibs.re.kr/">Discrete Mathematics Group</a> at the <a href="https://www.ibs.re.kr/eng.do">Institute for Basic Science (IBS)</a> for obtaining the locations of the bars in Korea.
The locations were downloaded from a <a href="https://www.bigdata-policing.kr/product/view?product_id=PRDT_360">database</a> maintained by the Korean National Police Agency.
</p>

<p>
The table of point-to-point walking times was created with the <a href="https://project-osrm.org/">Open Source Routing Machine</a> (OSRM).
</p>



<p>
  <h2>Other Road Trips</h2>
</p>

<div> 
  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/japan/index.html" data-ua-action="hp-news" title="Image of Japan tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/japan_270.jpg" alt="Konbini"></a></p><p>40,426 Japanese Konbini.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/uk/index.html" data-ua-action="hp-news" title="UK49687 Tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/uk49_270.png" alt="UK"></a></p><p>49,687 pubs in the UK.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/us/index.html" data-ua-action="hp-news" title="Screen shot of US50K"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/us50k_full_270.png" alt="US50K"></a></p><p>49,603 US historic places.</p>
  </div>

  <div>
    <p><a href="http://www.math.uwaterloo.ca/tsp/nl/index.html" data-ua-action="hp-news" title="NL Tour"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/nl_270.jpg" alt="UK"></a></p><p>57,912 Dutch monuments.</p>
  </div>
</div>


<p>
  <h2>Further Reading</h2>
</p>

<div "=""> 
  <div>
    <p><a href="http://press.princeton.edu/titles/9531.html" data-ua-action="hp-news" title="In Pursuit of the Traveling Salesman"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/pursuit.jpg" alt="Pursuit"></a></p><p>An introduction to the TSP, including its history, applications, and solution techniques.</p>
  </div>

  <div>
    <p><a href="http://press.princeton.edu/titles/8451.html" title="Traveling Salesman Problem"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/tspcomp.jpg" alt="TSP"></a></p><p>Detailed computational study of the cutting-plane method for the TSP.</p>
  </div>

  <div>
    <p><a href="http://press.princeton.edu/titles/9937.html" data-ua-action="hp-news" title="The Golden Ticket"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/golden.jpg" alt="The Golden Ticket"></a></p><p>Gentle introduction to the P vs NP problem and its ramifications.</p>
  </div>

  <div>
    <p><a href="https://press.princeton.edu/books/hardcover/9780691164069/opt-art" data-ua-action="hp-news" title="Opt Art"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/optart.jpg" alt="Opt Art"></a></p><p>See how the TSP is used to create pretty images with a single line.</p>
  </div>

  <div>
    <p><a href="https://www.or.uni-bonn.de/tspbook/tsp_book.html" data-ua-action="hp-news" title="Approximation Algorithms for the TSP"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/approx.jpg" alt="Approximation Algorithms"></a></p><p>Latest research on the theory of approximation algorithms for the TSP.</p>
  </div>

  <div>
    <p><a href="https://link.springer.com/book/10.1007/3-540-48661-5" data-ua-action="hp-news" title="Computational Solutions for TSP Applications"><img src="https://www.math.uwaterloo.ca/tsp/korea/img/reinelt.jpg" alt="Reinelt TSP"></a></p><p>Applications of the TSP are given in this 1994 book, now available as a free download.</p>
  </div>



<!--
  <div class="col col-md-2">
    <a href="https://www.alexbellos.com/numberland" class="su-link" data-ua-action="hp-news" title="Numberland"><img src="./img/bellos.jpg" class="img-fluid" alt="Alex Bellos"></a>
    <p>Fantastic math book! Not directly about the TSP, but reading get you in the mood for math research.</p>
  </div>

  <div class="col col-md-2">
    <a href="https://dimag.ibs.re.kr" class="su-link" data-ua-action="hp-news" title="AFSA"><img src="./img/ibs.jpg" class="img-fluid" alt="IBS"></a>
    <p>In Korea, there is one of the world's leading research groups focusing on discrete mathematics.
-->

</div>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: My from-scratch OS kernel that runs DOOM (168 pts)]]></title>
            <link>https://github.com/UnmappedStack/TacOS</link>
            <guid>43778081</guid>
            <pubDate>Thu, 24 Apr 2025 00:15:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/UnmappedStack/TacOS">https://github.com/UnmappedStack/TacOS</a>, See on <a href="https://news.ycombinator.com/item?id=43778081">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TacOS</h2><a id="user-content-tacos" aria-label="Permalink: TacOS" href="#tacos"></a></p>
<p dir="auto">My from-scratch OS with it's own kernel written in C and assembly</p>
<p dir="auto">TacOS is a UNIX-like kernel which is able to run DOOM, among various other smaller userspace programs. It has things like a VFS, scheduler, TempFS, devices, context switching, virtual memory management, physical page frame allocation, and a port of Doom. It runs both on real hardware (tested on my laptop) and in the Qemu emulator.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/UnmappedStack/TacOS/blob/main/screenshots/screenshot1.webp"><img src="https://github.com/UnmappedStack/TacOS/raw/main/screenshots/screenshot1.webp" alt="A screenshot of TacOS's shell"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/UnmappedStack/TacOS/blob/main/screenshots/screenshot2.webp"><img src="https://github.com/UnmappedStack/TacOS/raw/main/screenshots/screenshot2.webp" alt="A screenshot of TacOS running DOOM"></a></p>
<p dir="auto">Please note that TacOS is a hobby toy OS and is not complete enough for real usage. It has multiple known bugs.</p>
<p dir="auto">I have a Discord server for PotatOS where I will share most updates, and you can also get help with your own OSDev project or just have a chat. You can join <a href="https://discord.gg/hPg9S2F2nD" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">To build and run TacOS, simply run in your shell:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/UnmappedStack/TacOS
cd TacOS
git clone https://github.com/limine-bootloader/limine
cd limine
git checkout v9.x-binary
make"><pre><code>git clone https://github.com/UnmappedStack/TacOS
cd TacOS
git clone https://github.com/limine-bootloader/limine
cd limine
git checkout v9.x-binary
make
</code></pre></div>
<p dir="auto">You'll need to have Qemu, NASM, and Clang installed. It will automatically run in the Qemu emulator.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">TacOS is under the Mozilla Public License 2.0. See <code>LICENSE</code> for more information.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CubeCL: GPU Kernels in Rust for CUDA, ROCm, and WGPU (122 pts)]]></title>
            <link>https://github.com/tracel-ai/cubecl</link>
            <guid>43777731</guid>
            <pubDate>Wed, 23 Apr 2025 23:19:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/tracel-ai/cubecl">https://github.com/tracel-ai/cubecl</a>, See on <a href="https://news.ycombinator.com/item?id=43777731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">TL;DR</h2><a id="user-content-tldr" aria-label="Permalink: TL;DR" href="#tldr"></a></p>
<p dir="auto">With CubeCL, you can program your GPU using Rust, taking advantage of zero-cost abstractions to develop maintainable, flexible, and efficient compute kernels.
CubeCL currently fully supports functions, generics, and structs, with partial support for traits, methods and type inference.
As the project evolves, we anticipate even broader support for Rust language primitives, all while maintaining optimal performance.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Example</h3><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<p dir="auto">Simply annotate functions with the <code>cube</code> attribute to indicate that they should run on the GPU.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use cubecl::prelude::*;

#[cube(launch_unchecked)]
/// A [Line] represents a contiguous series of elements where SIMD operations may be available.
/// The runtime will automatically use SIMD instructions when possible for improved performance.
fn gelu_array<F: Float>(input: &amp;Array<Line<F>>, output: &amp;mut Array<Line<F>>) {
    if ABSOLUTE_POS < input.len() {
        output[ABSOLUTE_POS] = gelu_scalar(input[ABSOLUTE_POS]);
    }
}

#[cube]
fn gelu_scalar<F: Float>(x: Line<F>) -> Line<F> {
    // Execute the sqrt function at comptime.
    let sqrt2 = F::new(comptime!(2.0f32.sqrt()));
    let tmp = x / Line::new(sqrt2);

    x * (Line::erf(tmp) + 1.0) / 2.0
}"><pre><span>use</span> cubecl<span>::</span>prelude<span>::</span><span>*</span><span>;</span>

<span>#<span>[</span>cube<span>(</span>launch_unchecked<span>)</span><span>]</span></span>
<span>/// A [Line] represents a contiguous series of elements where SIMD operations may be available.</span>
<span></span><span>/// The runtime will automatically use SIMD instructions when possible for improved performance.</span>
<span></span><span>fn</span> <span>gelu_array</span><span>&lt;</span><span>F</span><span>:</span> <span>Float</span><span>&gt;</span><span>(</span><span>input</span><span>:</span> <span>&amp;</span><span>Array</span><span>&lt;</span><span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>&gt;</span><span>,</span> <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Array</span><span>&lt;</span><span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>&gt;</span><span>)</span> <span>{</span>
    <span>if</span> <span>ABSOLUTE_POS</span> &lt; input<span>.</span><span>len</span><span>(</span><span>)</span> <span>{</span>
        output<span>[</span><span>ABSOLUTE_POS</span><span>]</span> = <span>gelu_scalar</span><span>(</span>input<span>[</span><span>ABSOLUTE_POS</span><span>]</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span>

<span>#<span>[</span>cube<span>]</span></span>
<span>fn</span> <span>gelu_scalar</span><span>&lt;</span><span>F</span><span>:</span> <span>Float</span><span>&gt;</span><span>(</span><span>x</span><span>:</span> <span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span><span>)</span> -&gt; <span>Line</span><span>&lt;</span><span>F</span><span>&gt;</span> <span>{</span>
    <span>// Execute the sqrt function at comptime.</span>
    <span>let</span> sqrt2 = <span>F</span><span>::</span><span>new</span><span>(</span><span>comptime</span><span>!</span><span>(</span><span>2.0f32</span><span>.</span>sqrt<span>(</span><span>)</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> tmp = x / <span>Line</span><span>::</span><span>new</span><span>(</span>sqrt2<span>)</span><span>;</span>

    x <span>*</span> <span>(</span><span>Line</span><span>::</span><span>erf</span><span>(</span>tmp<span>)</span> + <span>1.0</span><span>)</span> / <span>2.0</span>
<span>}</span></pre></div>
<p dir="auto">You can then launch the kernel using the autogenerated <code>gelu_array::launch_unchecked</code> function.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pub fn launch<R: Runtime>(device: &amp;R::Device) {
    let client = R::client(device);
    let input = &amp;[-1., 0., 1., 5.];
    let vectorization = 4;
    let output_handle = client.empty(input.len() * core::mem::size_of::<f32>());
    let input_handle = client.create(f32::as_bytes(input));

    unsafe {
        gelu_array::launch_unchecked::<f32, R>(
            &amp;client,
            CubeCount::Static(1, 1, 1),
            CubeDim::new(input.len() as u32 / vectorization, 1, 1),
            ArrayArg::from_raw_parts::<f32>(&amp;input_handle, input.len(), vectorization as u8),
            ArrayArg::from_raw_parts::<f32>(&amp;output_handle, input.len(), vectorization as u8),
        )
    };

    let bytes = client.read_one(output_handle.binding());
    let output = f32::from_bytes(&amp;bytes);

    // Should be [-0.1587,  0.0000,  0.8413,  5.0000]
    println!(&quot;Executed gelu with runtime {:?} => {output:?}&quot;, R::name());
}"><pre><span>pub</span> <span>fn</span> <span>launch</span><span>&lt;</span><span>R</span><span>:</span> <span>Runtime</span><span>&gt;</span><span>(</span><span>device</span><span>:</span> <span>&amp;</span><span>R</span><span>::</span><span>Device</span><span>)</span> <span>{</span>
    <span>let</span> client = <span>R</span><span>::</span><span>client</span><span>(</span>device<span>)</span><span>;</span>
    <span>let</span> input = <span>&amp;</span><span>[</span>-<span>1.</span><span>,</span> <span>0.</span><span>,</span> <span>1.</span><span>,</span> <span>5.</span><span>]</span><span>;</span>
    <span>let</span> vectorization = <span>4</span><span>;</span>
    <span>let</span> output_handle = client<span>.</span><span>empty</span><span>(</span>input<span>.</span><span>len</span><span>(</span><span>)</span> <span>*</span> core<span>::</span>mem<span>::</span><span>size_of</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> input_handle = client<span>.</span><span>create</span><span>(</span>f32<span>::</span><span>as_bytes</span><span>(</span>input<span>)</span><span>)</span><span>;</span>

    <span>unsafe</span> <span>{</span>
        gelu_array<span>::</span><span>launch_unchecked</span><span>::</span><span>&lt;</span><span>f32</span><span>,</span> <span>R</span><span>&gt;</span><span>(</span>
            <span>&amp;</span>client<span>,</span>
            <span>CubeCount</span><span>::</span><span>Static</span><span>(</span><span>1</span><span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>,</span>
            <span>CubeDim</span><span>::</span><span>new</span><span>(</span>input<span>.</span><span>len</span><span>(</span><span>)</span> <span>as</span> <span>u32</span> / vectorization<span>,</span> <span>1</span><span>,</span> <span>1</span><span>)</span><span>,</span>
            <span>ArrayArg</span><span>::</span><span>from_raw_parts</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>&amp;</span>input_handle<span>,</span> input<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> vectorization <span>as</span> <span>u8</span><span>)</span><span>,</span>
            <span>ArrayArg</span><span>::</span><span>from_raw_parts</span><span>::</span><span>&lt;</span><span>f32</span><span>&gt;</span><span>(</span><span>&amp;</span>output_handle<span>,</span> input<span>.</span><span>len</span><span>(</span><span>)</span><span>,</span> vectorization <span>as</span> <span>u8</span><span>)</span><span>,</span>
        <span>)</span>
    <span>}</span><span>;</span>

    <span>let</span> bytes = client<span>.</span><span>read_one</span><span>(</span>output_handle<span>.</span><span>binding</span><span>(</span><span>)</span><span>)</span><span>;</span>
    <span>let</span> output = f32<span>::</span><span>from_bytes</span><span>(</span><span>&amp;</span>bytes<span>)</span><span>;</span>

    <span>// Should be [-0.1587,  0.0000,  0.8413,  5.0000]</span>
    <span>println</span><span>!</span><span>(</span><span>"Executed gelu with runtime {:?} =&gt; {output:?}"</span><span>,</span> <span>R</span><span>::</span>name<span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">To see it in action, run the working GELU example with the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cargo run --example gelu --features cuda # cuda runtime
cargo run --example gelu --features wgpu # wgpu runtime"><pre>cargo run --example gelu --features cuda <span><span>#</span> cuda runtime</span>
cargo run --example gelu --features wgpu <span><span>#</span> wgpu runtime</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Runtime</h2><a id="user-content-runtime" aria-label="Permalink: Runtime" href="#runtime"></a></p>
<p dir="auto">We support the following GPU runtimes:</p>
<ul dir="auto">
<li><a href="https://github.com/gfx-rs/wgpu">WGPU</a> for cross-platform GPU support (Vulkan, Metal, DirectX, WebGPU)</li>
<li><a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow">CUDA</a> for NVIDIA GPU support</li>
<li><a href="https://www.amd.com/en/products/software/rocm.html" rel="nofollow">ROCm/HIP</a> for AMD GPU support (WIP)</li>
</ul>
<p dir="auto">We also plan to develop an optimized JIT CPU runtime with SIMD instructions, leveraging <a href="https://cranelift.dev/" rel="nofollow">Cranelift</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">The goal of CubeCL is to ease the pain of writing highly optimized compute kernels that are portable across hardware.
There is currently no adequate solution when you want optimal performance while still being multi-platform.
You either have to write custom kernels for different hardware, often with different languages such as CUDA, Metal, or ROCm.
To fix this, we created a Just-in-Time compiler with three core features: <strong>automatic vectorization</strong>, <strong>comptime</strong>, and <strong>autotune</strong>!</p>
<p dir="auto">These features are extremely useful for anyone writing high-performance kernels, even when portability is not a concern.
They improve code composability, reusability, testability, and maintainability, all while staying optimal.
CubeCL also ships with a memory management strategy optimized for throughput with heavy buffer reuse to avoid allocations.</p>
<p dir="auto">Our goal extends beyond providing an optimized compute language; we aim to develop an ecosystem of high-performance and scientific computing in Rust.
To achieve this, we're developing linear algebra components that you can integrate into your own kernels.
We currently have an highly optimized matrix multiplication module, leveraging Tensor Cores on NVIDIA hardware where available, while gracefully falling back to basic instructions on other platforms.
While there's room for improvement, particularly in using custom instructions from newer NVIDIA GPUs, our implementation already delivers impressive performance.</p>
<p dir="auto">This is just the beginning.
We plan to include more utilities such as convolutions, random number generation, fast Fourier transforms, and other essential algorithms.
We are a small team also building <a href="https://burn.dev/" rel="nofollow">Burn</a>, so don't hesitate to contribute and port algorithms; it can help more than you would imagine!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it works" href="#how-it-works"></a></p>
<p dir="auto">CubeCL leverages Rust's proc macro system in a unique two-step process:</p>
<ol dir="auto">
<li>Parsing: The proc macro parses the GPU kernel code using the syn crate.</li>
<li>Expansion: Instead of immediately generating an Intermediate Representation (IR), the macro generates a new Rust function.</li>
</ol>
<p dir="auto">The generated function, semantically similar to the original, is responsible for creating the IR when called.
This approach differs from traditional compilers, which typically generate IR directly after parsing.
Our method enables several key features:</p>
<ul dir="auto">
<li><strong>Comptime</strong>: By not transforming the original code, it becomes remarkably easy to integrate compile-time optimizations.</li>
<li><strong>Automatic Vectorization</strong>: By simply vectorizing the inputs of a CubeCL function, we can determine the vectorization factor of each intermediate variable during the expansion.</li>
<li><strong>Rust Integration</strong>: The generated code remains valid Rust code, allowing it to be bundled without any dependency on the specific runtime.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design</h2><a id="user-content-design" aria-label="Permalink: Design" href="#design"></a></p>
<p dir="auto">CubeCL is designed around - you guessed it - Cubes! More specifically, it's based on cuboids, because not all axes are the same size.
Since all compute APIs need to map to the hardware, which are tiles that can be accessed using a 3D representation, our topology can easily be mapped to concepts from other APIs.</p>
<div dir="auto">
<p dir="auto"><h3 tabindex="-1" dir="auto">CubeCL - Topology</h3><a id="user-content-cubecl---topology" aria-label="Permalink: CubeCL - Topology" href="#cubecl---topology"></a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/tracel-ai/cubecl/blob/main/assets/cubecl.drawio.svg"><img src="https://github.com/tracel-ai/cubecl/raw/main/assets/cubecl.drawio.svg" width="100%"></a>
<br>
</p></div>

<p dir="auto"><em>A cube is composed of units, so a 3x3x3 cube has 27 units that can be accessed by their positions along the x, y, and z axes.
Similarly, a hyper-cube is composed of cubes, just as a cube is composed of units.
Each cube in the hyper-cube can be accessed by its position relative to the hyper-cube along the x, y, and z axes.
Hence, a hyper-cube of 3x3x3 will have 27 cubes.
In this example, the total number of working units would be 27 x 27 = 729.</em></p>
<details>
<summary>Topology Equivalence 👇</summary>

<p dir="auto">Since all topology variables are constant within the kernel entry point, we chose to use the Rust constant syntax with capital letters.
Often when creating kernels, we don't always care about the relative position of a unit within a cube along each axis, but often we only care about its position in general.
Therefore, each kind of variable also has its own axis-independent variable, which is often not present in other languages.</p>
<br>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>CubeCL</th>
<th>CUDA</th>
<th>WebGPU</th>
<th>Metal</th>
</tr>
</thead>
<tbody>
<tr>
<td>CUBE_COUNT</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_COUNT_X</td>
<td>gridDim.x</td>
<td>num_workgroups.x</td>
<td>threadgroups_per_grid.x</td>
</tr>
<tr>
<td>CUBE_COUNT_Y</td>
<td>gridDim.y</td>
<td>num_workgroups.y</td>
<td>threadgroups_per_grid.y</td>
</tr>
<tr>
<td>CUBE_COUNT_Z</td>
<td>gridDim.z</td>
<td>num_workgroups.z</td>
<td>threadgroups_per_grid.z</td>
</tr>
<tr>
<td>CUBE_POS</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_POS_X</td>
<td>blockIdx.x</td>
<td>workgroup_id.x</td>
<td>threadgroup_position_in_grid.x</td>
</tr>
<tr>
<td>CUBE_POS_Y</td>
<td>blockIdx.y</td>
<td>workgroup_id.y</td>
<td>threadgroup_position_in_grid.y</td>
</tr>
<tr>
<td>CUBE_POS_Z</td>
<td>blockIdx.z</td>
<td>workgroup_id.z</td>
<td>threadgroup_position_in_grid.z</td>
</tr>
<tr>
<td>CUBE_DIM</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>CUBE_DIM_X</td>
<td>blockDim.x</td>
<td>workgroup_size.x</td>
<td>threads_per_threadgroup.x</td>
</tr>
<tr>
<td>CUBE_DIM_Y</td>
<td>blockDim.y</td>
<td>workgroup_size.y</td>
<td>threads_per_threadgroup.y</td>
</tr>
<tr>
<td>CUBE_DIM_Z</td>
<td>blockDim.z</td>
<td>workgroup_size.z</td>
<td>threads_per_threadgroup.z</td>
</tr>
<tr>
<td>UNIT_POS</td>
<td>N/A</td>
<td>local_invocation_index</td>
<td>thread_index_in_threadgroup</td>
</tr>
<tr>
<td>UNIT_POS_X</td>
<td>threadIdx.x</td>
<td>local_invocation_id.x</td>
<td>thread_position_in_threadgroup.x</td>
</tr>
<tr>
<td>UNIT_POS_Y</td>
<td>threadIdx.y</td>
<td>local_invocation_id.y</td>
<td>thread_position_in_threadgroup.y</td>
</tr>
<tr>
<td>UNIT_POS_Z</td>
<td>threadIdx.z</td>
<td>local_invocation_id.z</td>
<td>thread_position_in_threadgroup.z</td>
</tr>
<tr>
<td>PLANE_POS</td>
<td>N/A</td>
<td>subgroup_id</td>
<td>simdgroup_index_in_threadgroup</td>
</tr>
<tr>
<td>PLANE_DIM</td>
<td>warpSize</td>
<td>subgroup_size</td>
<td>threads_per_simdgroup</td>
</tr>
<tr>
<td>UNIT_POS_PLANE</td>
<td>N/A</td>
<td>subgroup_invocation_id</td>
<td>thread_index_in_simdgroup</td>
</tr>
<tr>
<td>ABSOLUTE_POS</td>
<td>N/A</td>
<td>N/A</td>
<td>N/A</td>
</tr>
<tr>
<td>ABSOLUTE_POS_X</td>
<td>N/A</td>
<td>global_id.x</td>
<td>thread_position_in_grid.x</td>
</tr>
<tr>
<td>ABSOLUTE_POS_Y</td>
<td>N/A</td>
<td>global_id.y</td>
<td>thread_position_in_grid.y</td>
</tr>
<tr>
<td>ABSOLUTE_POS_Z</td>
<td>N/A</td>
<td>global_id.z</td>
<td>thread_position_in_grid.z</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Special Features</h2><a id="user-content-special-features" aria-label="Permalink: Special Features" href="#special-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Automatic Vectorization</h3><a id="user-content-automatic-vectorization" aria-label="Permalink: Automatic Vectorization" href="#automatic-vectorization"></a></p>
<p dir="auto">High-performance kernels should rely on SIMD instructions whenever possible, but doing so can quickly get pretty complicated!
With CubeCL, you can specify the vectorization factor of each input variable when launching a kernel.
Inside the kernel code, you still use only one type, which is dynamically vectorized and supports automatic broadcasting.
The runtimes are able to compile kernels and have all the necessary information to use the best instruction!
However, since the algorithmic behavior may depend on the vectorization factor, CubeCL allows you to access it directly in the kernel when needed, without any performance loss, using the comptime system!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Comptime</h3><a id="user-content-comptime" aria-label="Permalink: Comptime" href="#comptime"></a></p>
<p dir="auto">CubeCL isn't just a new compute language: though it feels like you are writing GPU kernels, you are, in fact, writing compiler plugins that you can fully customize!
Comptime is a way to modify the compiler IR at runtime when compiling a kernel for the first time.</p>
<p dir="auto">This enables lots of optimizations and flexibility without having to write many separate variants of the same kernels to ensure maximal performance.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Instruction Specialization</strong></td>
<td>Not all instructions are available on all hardware, but when a specialized one exists, it should be enabled with a simple if statement.</td>
</tr>
<tr>
<td><strong>Automatic Vectorization</strong></td>
<td>When you can use SIMD instructions, you should! But since not all hardware supports the same vectorization factors, it can be injected at runtime!</td>
</tr>
<tr>
<td><strong>Loop Unrolling</strong></td>
<td>You may want multiple flavors of the same kernel, with loop unrolling for only a certain range of values. This can be configured easily with Comptime.</td>
</tr>
<tr>
<td><strong>Shape Specialization</strong></td>
<td>For deep learning kernels, it's often crucial to rely on different kernels for different input sizes; you can do it by passing the shape information as Comptime values.</td>
</tr>
<tr>
<td><strong>Compile Time Calculation</strong></td>
<td>In general, you can calculate a constant using Rust runtime properties and inject it into a kernel during its compilation, to avoid recalculating it during each execution.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Autotuning</h3><a id="user-content-autotuning" aria-label="Permalink: Autotuning" href="#autotuning"></a></p>
<p dir="auto">Autotuning drastically simplifies kernel selection by running small benchmarks at runtime to figure out the best kernels with the best configurations to run on the current hardware; an essential feature for portability.
This feature combines gracefully with comptime to test the effect of different comptime values on performance; sometimes it can be surprising!</p>
<p dir="auto">Even if the benchmarks may add some overhead when running the application for the first time, the information gets cached on the device and will be reused.
It is usually a no-brainer trade-off for throughput-oriented programs such as deep learning models.
You can even ship the autotune cache with your program, reducing cold start time when you have more control over the deployment target.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resource</h2><a id="user-content-resource" aria-label="Permalink: Resource" href="#resource"></a></p>
<p dir="auto">For now we don't have a lot of resources to learn, but you can look at the <a href="https://github.com/tracel-ai/cubecl/blob/main/crates/cubecl-linalg/README.md">linear algebra library</a> to see how CubeCL can be used.
If you have any questions or want to contribute, don't hesitate to join the <a href="https://discord.gg/KSBSPhAUCc" rel="nofollow">Discord</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer &amp; History</h2><a id="user-content-disclaimer--history" aria-label="Permalink: Disclaimer &amp; History" href="#disclaimer--history"></a></p>
<p dir="auto">CubeCL is currently in <strong>alpha</strong>.</p>
<p dir="auto">While CubeCL is used in <a href="https://burn.dev/" rel="nofollow">Burn</a>, there are still a lot of rough edges; it isn't refined yet.
The project started as a WebGPU-only backend for Burn.
As we optimized it, we realized that we needed an intermediate representation (IR) that could be optimized then compiled to WGSL.
Having an IR made it easy to support another compilation target, so we made a CUDA runtime.
However, writing kernels directly in that IR wasn't easy, so we created a Rust frontend using the <a href="https://github.com/dtolnay/syn">syn</a> crate.
Navigating the differences between CUDA and WebGPU, while leveraging both platforms, forced us to come up with general concepts that worked everywhere.
Hence, CubeCL was born!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yagri: You are gonna read it (176 pts)]]></title>
            <link>https://www.scottantipa.com/yagri</link>
            <guid>43776967</guid>
            <pubDate>Wed, 23 Apr 2025 21:47:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scottantipa.com/yagri">https://www.scottantipa.com/yagri</a>, See on <a href="https://news.ycombinator.com/item?id=43776967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        
        <p><b>April, 2025</b></p>

        <p>
            YAGNI, or, <a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it">You aren't gonna need it</a>,
            is a standard piece of advice that warns against over engineering
            and building too many features too early. I think its great and saves you from wasting time, which
            can kill a project.
        </p>

        <p>
            However, there's an exception that I call YAGRI, or, "You are gonna read it". It means that you shouldn't just store
            the minimum
            data required to satisfy the current product spec. You should also store data that you'll highly likely use (read),
            such as timestamps and contextual metadata.
        </p>

        <p>
            This problem tends to happen when a UI design shows that you only need to display a few specific bits of data to the
            user,
            so you only store those exact fields in the database. You've satisfied the design and ship it. Then later you realize
            you're missing valuable information to help debug an issue, do internal analytics, etc.
        </p>

        <p>
            As an example, this commonly occurs when implementing a feature to let users delete something. The easy way
            is to just
            delete the row from the database, and maybe that's all that the current UI design call for.
            In this situation, regardless of the requested feature set, as engineers we should maintain good data standards
            and store:
        </p>
        <ul>
            <li>who deleted it</li>
            <li>how they deleted it (with what permission)</li>
            <li>when</li>
            <li>why (surrounding context, if possible)</li>
        </ul>

        <p>
            In general, these are some useful fields to store on almost any table:
        </p>
        <ul>
            <li>created_at</li>
            <li>updated_at</li>
            <li>deleted_at (soft deletes)</li>
            <li>created_by etc</li>
            <li>permission used during CRUD</li>
        </ul>

        <p>
            This practice will pay off with just a single instance of your boss popping into a meeting and going "wait
            do we know why that thing was deleted, the customer is worried...".
            
        </p>
        <p>
            However, not every one of these fields that you store will end up serving a purpose. But maybe just a single
            field on a single table will save you one day, and that makes up for the costs of implementing a dozen others.
            Most of the apps we build, at the end of the day, are about storing data to keep track of facts.            
            It's quite possibly your most important job as an engineer to steward and maintain this data.
        </p>

        <p>
            Of course you can go too far in the other direction. You shouldnt just log everything.
            But I've never heard someone complain about a table having too many timestamps.
        </p>
                
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google blocked Motorola use of Perplexity AI, witness says (158 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant</link>
            <guid>43776512</guid>
            <pubDate>Wed, 23 Apr 2025 20:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant">https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=43776512">Hacker News</a></p>
Couldn't get https://www.bloomberg.com/news/articles/2025-04-23/perplexity-executive-says-google-blocked-motorola-s-use-of-ai-assistant: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Doge Worker's Code Supports NLRB Whistleblower (802 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/</link>
            <guid>43776476</guid>
            <pubDate>Wed, 23 Apr 2025 20:48:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/">https://krebsonsecurity.com/2025/04/doge-workers-code-supports-nlrb-whistleblower/</a>, See on <a href="https://news.ycombinator.com/item?id=43776476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>A whistleblower at the <strong>National Labor Relations Board</strong> (NLRB) alleged last week that denizens of Elon Musk’s <strong>Department of Government Efficiency</strong> (DOGE) siphoned gigabytes of data from the agency’s sensitive case files in early March. The whistleblower said accounts created for DOGE at the NLRB downloaded three code repositories from <strong>GitHub</strong>. Further investigation into one of those code bundles shows it is remarkably similar to a program published in January 2025 by <strong>Marko Elez</strong>, a 25-year-old DOGE employee who has worked at a number of Musk’s companies.</p>
<div id="attachment_71090"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71090" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png" alt="" width="748" height="323" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds.png 1287w, https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds-768x331.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/db-powershellcmds-782x337.png 782w" sizes="(max-width: 748px) 100vw, 748px"></a></p><p id="caption-attachment-71090">A screenshot shared by NLRB whistleblower Daniel Berulis shows three downloads from GitHub.</p></div>
<p>According to <a href="https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/" target="_blank" rel="noopener">a whistleblower complaint</a> filed last week by&nbsp;<strong>Daniel J. Berulis</strong>, a 38-year-old security architect at the NLRB, officials from DOGE met with NLRB leaders on March 3 and demanded the creation of several&nbsp;all-powerful “tenant admin” accounts that were to be exempted from network logging activity that would otherwise keep a detailed record of all actions taken by those accounts.</p>
<p>Berulis said the new DOGE accounts had unrestricted permission to read, copy, and alter information contained in NLRB databases. The new accounts also could restrict log visibility, delay retention, route logs elsewhere, or even remove them entirely — top-tier user privileges that neither Berulis nor his boss possessed.</p>
<p>Berulis said he discovered one of the DOGE accounts had downloaded three external code libraries from <strong>GitHub</strong> that neither NLRB nor its contractors ever used. A “readme” file in one of the code bundles explained it was created to rotate connections through a large pool of cloud Internet addresses that serve “<em>as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing</em>.” Brute force attacks involve automated login attempts that try many credential combinations in rapid sequence.</p>
<p>A search on that description in Google brings up a code repository at GitHub for a user with the account name “<strong>Ge0rg3</strong>” who published a program roughly four years ago called “<a href="https://github.com/Ge0rg3/requests-ip-rotator" target="_blank" rel="noopener">requests-ip-rotator</a>,” described as a library that will allow the user “to bypass IP-based rate-limits for sites and services.”</p>
<div id="attachment_71091"><p><img aria-describedby="caption-attachment-71091" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh.png" alt="" width="749" height="543" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh.png 1171w, https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh-768x557.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/ge0rge-gh-782x568.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p><p id="caption-attachment-71091">The README file from the GitHub user Ge0rg3’s page for requests-ip-rotator includes the exact wording of a program the whistleblower said was downloaded by one of the DOGE users. Marko Elez created an offshoot of this program in January 2025.</p></div>
<p>“A Python library to utilize AWS API Gateway’s large IP pool as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing,” the description reads.</p>
<p>Ge0rg3’s code is “open source,” in that anyone can copy it and reuse it non-commercially. As it happens, there is a newer version of this project that was derived or “forked” from Ge0rg3’s code — called “<a href="https://github.com/markoelez/async-ip-rotator/blob/master/README.md" target="_blank" rel="noopener">async-ip-rotator</a>” — and it was committed to GitHub in January 2025 by DOGE captain <a href="https://github.com/markoelez" target="_blank" rel="noopener">Marko Elez</a>.</p>
<div id="attachment_71085"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71085" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png" alt="" width="750" height="492" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh.png 1150w, https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh-768x504.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/melez-gh-782x513.png 782w" sizes="(max-width: 750px) 100vw, 750px"></a></p><p id="caption-attachment-71085">The whistleblower stated that one of the GitHub files downloaded by the DOGE employees who transferred sensitive files from an NLRB case database was an archive whose README file read: “Python library to utilize AWS API Gateway’s large IP pool as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing.” Elez’s code pictured here was forked in January 2025 from a code library that shares the same description.</p></div>
<p>A key DOGE staff member who gained access to the Treasury Department’s central payments system, Elez has worked for a number of Musk companies, including <strong>X</strong>, <strong>SpaceX</strong>, and <strong>xAI</strong>. Elez was among the first DOGE employees to face public scrutiny, after <strong>The Wall Street Journal</strong> <a href="https://www.wsj.com/tech/doge-staffer-resigns-over-racist-posts-d9f11a93" target="_blank" rel="noopener">linked him to social media posts</a> that advocated racism and eugenics.</p>
<p>Elez resigned after that brief scandal, but was rehired after President Donald Trump and Vice President JD Vance expressed support for him. <strong>Politico</strong> <a href="https://www.politico.com/news/2025/03/29/doge-marco-elez-software-engineer-us-payroll-00259303" target="_blank" rel="noopener">reports</a> Elez is now a <strong>Labor Department</strong> aide detailed to multiple agencies, including the <strong>Department of Health and Human Services</strong>.</p>
<p>“During Elez’s initial stint at Treasury, he violated the agency’s information security policies by sending a spreadsheet containing names and payments information to officials at the General Services Administration,” Politico wrote, citing court filings.</p>
<p>KrebsOnSecurity sought comment from both the NLRB and DOGE, and will update this story if either responds.<span id="more-71075"></span></p>
<p>The NLRB has been effectively hobbled since <strong>President Trump</strong> fired three board members, leaving the agency without the quorum it needs to function. Both&nbsp;<strong>Amazon</strong>&nbsp;and Musk’s&nbsp;<strong>SpaceX</strong>&nbsp;have&nbsp;<a href="https://apnews.com/article/amazon-nlrb-unconstitutional-spacex-elon-musk-ab42977117d883e97110a7bf8e8b257f" target="_blank" rel="noopener">been suing</a>&nbsp;the NLRB over complaints the agency filed in disputes about workers’ rights and union organizing, arguing that the NLRB’s very existence is unconstitutional. On March 5, a U.S. appeals court&nbsp;<a href="https://www.reuters.com/legal/government/musks-spacex-loses-early-legal-challenge-us-labor-boards-powers-2025-03-05/" target="_blank" rel="noopener">unanimously rejected</a>&nbsp;Musk’s claim that the NLRB’s structure somehow violates the Constitution.</p>
<p>Berulis’s complaint alleges the DOGE accounts at NLRB downloaded more than 10 gigabytes of data from the agency’s case files, a database that includes reams of sensitive records including information about employees who want to form unions and proprietary business documents. Berulis said he went public after higher-ups at the agency told him not to report the matter to the US-CERT, as they’d previously agreed.</p>
<p>Berulis told KrebsOnSecurity he worried the unauthorized data transfer by DOGE could unfairly advantage defendants in a number of ongoing labor disputes before the agency.</p>
<p>“If any company got the case data that would be an unfair advantage,” Berulis said. “They could identify and fire employees and union organizers without saying why.”</p>
<div id="attachment_71106"><p><img aria-describedby="caption-attachment-71106" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/markoelez.png" alt="" width="444" height="515"></p><p id="caption-attachment-71106">Marko Elez, in a photo from a social media profile.</p></div>
<p>Berulis said the other two GitHub archives that DOGE employees downloaded to NLRB systems included <strong>Integuru</strong>, a software framework designed to reverse engineer application programming interfaces (APIs) that websites use to fetch data; and a “headless” browser called <strong>Browserless</strong>, which is made for automating web-based tasks that require a pool of browsers, such as web scraping and automated testing.</p>
<p>On February 6, someone <a href="https://github.com/markoelez/async-ip-rotator/issues/1" target="_blank" rel="noopener">posted a lengthy and detailed critique</a> of Elez’s code on the GitHub “issues” page for async-ip-rotator, calling it “insecure, unscalable and a fundamental engineering failure.”</p>
<p>“If this were a side project, it would just be bad code,” the reviewer wrote. “But if this is representative of how you build production systems, then there are much larger concerns. This implementation is fundamentally broken, and if anything similar to this is deployed in an environment handling sensitive data, it should be audited immediately.”</p>
<p>Further reading:&nbsp;<a href="https://whistlebloweraid.org/wp-content/uploads/2025/04/2025_0414_Berulis-Disclosure-with-Exhibits.s.pdf" target="_blank" rel="noopener">Berulis’s complaint</a>&nbsp;(PDF).</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You Wouldn't Steal a Font (884 pts)]]></title>
            <link>https://fedi.rib.gay/notes/a6xqityngfubsz0f</link>
            <guid>43775926</guid>
            <pubDate>Wed, 23 Apr 2025 19:42:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fedi.rib.gay/notes/a6xqityngfubsz0f">https://fedi.rib.gay/notes/a6xqityngfubsz0f</a>, See on <a href="https://news.ycombinator.com/item?id=43775926">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="splash"><p><img id="splashIcon" src="https://fedi.rib.gay/static-assets/splash.png?1745440201643"><span id="splashText">Loading...</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[First Successful Lightning Triggering and Guiding Using a Drone (110 pts)]]></title>
            <link>https://group.ntt/en/newsrelease/2025/04/18/250418a.html</link>
            <guid>43775766</guid>
            <pubDate>Wed, 23 Apr 2025 19:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://group.ntt/en/newsrelease/2025/04/18/250418a.html">https://group.ntt/en/newsrelease/2025/04/18/250418a.html</a>, See on <a href="https://news.ycombinator.com/item?id=43775766">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                
                <p>News Highlights:</p>
<!-- [/c-txt-2] -->

<div>
<ol>
    <li><span>◆</span>We have achieved the world's first successful lightning triggering and guiding using a drone by harnessing electric field fluctuations.</li>
    <li><span>◆</span>We developed and validated a lightning protection cage design that prevents malfunction or damage even when the drone is struck directly by lightning. This design can also be implemented on commercial drones.</li>
    <li><span>◆</span>In the future, we aim to protect cities and infrastructure with "lightning drones," working toward a society free from lightning-related damage.</li>
</ol>
</div>
<!-- [/c-txt-list-1] -->

<p><span>TOKYO - April 18, 2025 - </span>NTT Corporation (Headquarters: Chiyoda, Tokyo; President and CEO: Akira Shimada; hereinafter "NTT") has become the first in the world to successfully trigger and guide lightning using a drone. This experiment also demonstrated, under natural lightning conditions, the effectiveness of both the drone's lightning protection technology and the electric field-based lightning triggering method. These results are expected to contribute to further research on the still-mysterious mechanisms of lightning and to help reduce lightning-related damage to cities and people.</p>
<!-- [/c-box-1] -->

<h3>Background</h3>
<!-- [/c-ttl-2] -->

<p>Lightning strikes are one of the most destructive natural phenomena affecting human society. While the NTT Group has implemented various lightning protection measures for critical infrastructure—including telecommunications facilities—lightning-related damage remains a persistent issue. In Japan alone, the estimated annual cost of lightning damage ranges from 100 to 200 billion yen<sup>1</sup>. Building on its long-standing expertise in protecting communications equipment from lightning, NTT is now working to advance this technology further, with the aim of eliminating lightning strikes on infrastructure and urban areas altogether.<br>
　Traditionally, lightning protection has relied heavily on lightning rods. However, their protective range is limited, and in some cases—such as wind turbines or outdoor event venues—it may not be feasible to install them. At NTT, we are exploring the use of rapidly advancing drone technology to create a new approach: "drone-triggered lightning"<sup>2</sup>. This method involves flying drones into optimal positions beneath thunderclouds to actively trigger lightning strikes, and then guiding the discharge safely away from vulnerable areas.</p>
<!-- [/c-txt-1] -->

<h3>Overview and Key Findings of the Experiment</h3>
<!-- [/c-ttl-2] -->

<p>From December 2024 to January 2025, a lightning-triggering experiment using drones was conducted at an elevation of 900 meters in a mountainous area of Hamada City, Shimane Prefecture. In this experiment, a device called a field mill<sup>3</sup> was used to monitor the electric field at ground level. When the electric field strength increased due to the approach of a thundercloud, a drone equipped with a custom-designed lightning protection cage was launched to attempt lightning triggering (Figure 1).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418aa.jpg" alt="Figure 1 Lightning Protection Drone">
    <span><span><span>Figure 1 </span><span>Lightning Protection Drone</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>On December 13, 2024, during the approach of a thundercloud, the electric field strength observed by the field mill increased. At that moment, a drone equipped with a conductive wire was flown to an altitude of 300 meters. The drone was then electrically connected to the ground via a switch installed on the ground (Figure 2). As a result, a large current was observed flowing through the wire, accompanied by a significant change in the surrounding electric field strength (Figure 3).<br>
　Just before the lightning strike, it was confirmed that a voltage of over 2000 volts had developed between the wire and the ground. This rapid increase in local electric field strength triggered a lightning strike directed at the drone. This marks the first successful case in the world of triggering lightning using a drone.<br>
　At the moment of the strike, a loud cracking sound was heard, a flash was observed at the winch, and partial melting occurred in the drone's lightning protection cage (Figure 4). However, the drone equipped with the protective cage continued to fly stably even after the lightning strike.</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ab.jpg" alt="Figure 2 Experimental Setup for Drone-Based Lightning Triggering">
    <span><span><span>Figure 2 </span><span>Experimental Setup for Drone-Based Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ac.jpg" alt="Figure 3 Observed Waveforms During Lightning Triggering">
    <span><span><span>Figure 3 </span><span>Observed Waveforms During Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ad.jpg" alt="Figure 4 Flash Emission from the Winch During Lightning Triggering">
    <span><span><span>Figure 4 </span><span>Flash Emission from the Winch During Lightning Triggering</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>Technical Highlights</h3>
<!-- [/c-ttl-2] -->

<p>To successfully trigger lightning using a drone, the drone must remain operational even after being struck. Moreover, simply flying a drone under a thundercloud is not sufficient to attract lightning; an active triggering method is required. To address these challenges, we proposed and demonstrated the following two key technologies:</p>
<!-- [/c-txt-1] -->

<h4>(1) Lightning Protection Technology for Drones</h4>
<!-- [/c-ttl-3] -->

<p>We developed a lightning protection cage design that prevents malfunction or damage even if the drone is directly struck by lightning. This cage, which can be mounted on commercially available drones, is made of conductive metal and functions as a shield. It redirects the high current from the lightning strike away from the drone's internal components, preventing it from flowing through the drone itself. Additionally, the cage is designed to distribute the lightning current radially, which cancels out the strong magnetic fields generated by the current and minimizes electromagnetic interference with the drone (Figure 5).<br>
　Furthermore, we conducted artificial lightning tests on drones equipped with the lightning protection cage. The results showed that the system withstood artificial strikes of up to 150 kA—five times greater than the average natural lightning strike—without any malfunction or damage, covering over 98% of naturally occurring lightning conditions.</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ae.jpg" alt="Figure 5 Lightning Protection Design for High Current and Strong Magnetic Fields">
    <span><span><span>Figure 5 </span><span>Lightning Protection Design for High Current and Strong Magnetic Fields</span></span></span>
</p>
<!-- [/c-img-4] -->

<h4>(2) Electric Field–Based Lightning Triggering Technology</h4>
<!-- [/c-ttl-3] -->

<p>To actively trigger lightning, we devised a method in which a conductive wire connects the drone to the ground, with a high-voltage switch installed on the ground side. By operating this switch at the optimal moment, we can rapidly change the electric field around the drone. This sharp increase in local electric field strength encourages a lightning discharge to occur toward the drone (Figure 6).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418af.jpg" alt="Figure 6 Principle of Electric Field–Based Lightning Triggering Technology">
    <span><span><span>Figure 6 </span><span>Principle of Electric Field–Based Lightning Triggering Technology</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>Outlook</h3>
<!-- [/c-ttl-2] -->

<p>NTT aims to protect cities and people from lightning damage by flying drones—designed to withstand direct lightning strikes—to accurately predict lightning-prone locations, actively trigger strikes, and safely guide them away. To improve the success rate of drone-based lightning triggering, we will continue to advance research and development in two key areas: high-precision lightning location prediction and a deeper understanding of lightning mechanisms. In addition, we aim to not only trigger and control lightning, but also to harness its energy. Future efforts will focus on developing technologies for capturing and storing lightning energy for potential use (Figure 7).</p>
<!-- [/c-txt-1] -->

<p>
    <img src="https://group.ntt/en/newsrelease/2025/04/18/img/250418ag.jpg" alt="Figure 7 NTT's Vision: Protecting Cities from Lightning and Harnessing Its Energy Using Drones">
    <span><span><span>Figure 7 </span><span>NTT's Vision: Protecting Cities from Lightning and Harnessing Its Energy Using Drones</span></span></span>
</p>
<!-- [/c-img-4] -->

<h3>[Glossary]</h3>
<!-- [/c-ttl-2] -->

<p><sup>1</sup><span>The Institute of Electrical Engineers of Japan, Technical Report No. 902, 2002.</span></p>
<!-- [/c-txt-9] -->

<p><sup>2</sup><span>Lightning triggering: The active process of "initiating" lightning and "guiding" it safely to a target location.</span></p>
<!-- [/c-txt-9] -->

<p><sup>3</sup><span>Field mill: A device used to measure atmospheric electric fields.</span></p>
<!-- [/c-txt-9] -->

<h3>About NTT</h3>
<!-- [/c-ttl-2] -->

<p>NTT contributes to a sustainable society through the power of innovation. We are a leading global technology company providing services to consumers and businesses as a mobile operator, infrastructure, networks, applications, and consulting provider. Our offerings include digital business consulting, managed application services, workplace and cloud solutions, data center and edge computing, all supported by our deep global industry expertise. We are over $92B in revenue and 330,000 employees, with $3.6B in annual R&amp;D investments. Our operations span across 80+ countries and regions, allowing us to serve clients in over 190 of them. We serve over 75% of Fortune Global 100 companies, thousands of other enterprise and government clients and millions of consumers.</p>
<!-- [/c-txt-2] -->

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sail-Trim Simulator (107 pts)]]></title>
            <link>https://simulator.atterwind.info/</link>
            <guid>43775283</guid>
            <pubDate>Wed, 23 Apr 2025 18:36:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simulator.atterwind.info/">https://simulator.atterwind.info/</a>, See on <a href="https://news.ycombinator.com/item?id=43775283">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Wind-Basics" target="_blank"><h2>Wind Basics</h2></a><p>
            Learn and get a better mental model about wind-gradient, apparent-wind, sail-twist at changing speeds and course
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Simulation" target="_blank"><h2>Simulator and Sail Trim</h2></a><p>
            Improve trimming through boat acceleration, especially in apparent wind high-performance sailing
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Real-world-comparison" target="_blank"><h2>Real world comparison</h2></a><p>
            Comparison with real-world A-Class foiling catamaran DNA F1x trim settings
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki/Usage" target="_blank"><h2>Simulator Usage</h2></a><p>
            Mouse, keyboard, touch and Weblink sharing
            </p><a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki"><h2>More info</h2></a><p>
            Source code and documentation on <a href="https://github.com/flyinggorilla/simulator.atterwind.info/wiki" target="_blank">Github</a>
        </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Teaching LLMs how to solid model (234 pts)]]></title>
            <link>https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html</link>
            <guid>43774990</guid>
            <pubDate>Wed, 23 Apr 2025 18:13:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html">https://willpatrick.xyz/technology/2025/04/23/teaching-llms-how-to-solid-model.html</a>, See on <a href="https://news.ycombinator.com/item?id=43774990">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>It turns out that LLMs can make CAD models for simple 3D mechanical parts. And, I think they’ll be extremely good at it soon.</p>

<h2 id="an-ai-mechanical-engineer">An AI Mechanical Engineer</h2>

<p>Code generation is the first breakthrough application for LLMs. What would an AI agent look like for mechanical engineering? Material selection, design for manufacturing, computer-aided manufacturing (CAM), and off-the-shelf part comparison would all be important features of an AI mechanical engineer. Perhaps, most importantly, an AI mechanical engineer would design and improve CAD models. Mechanical engineers typically design CAD using point-and-click software (e.g. Fusion 360, Solidworks, and Onshape). How could AI generate these solid models instead?</p>

<h2 id="code-generation-meets-cad">Code generation meets CAD</h2>

<p>One promising direction is training a generative model on millions of existing CAD files. This approach is being actively researched by <a href="https://damassets.autodesk.net/content/dam/autodesk/www/pdfs/brepgen.pdf">multiple</a> <a href="https://arxiv.org/pdf/2105.09492">teams</a> who are investigating both diffusion and transformer architectures. In particular, I like <a href="https://www.youtube.com/watch?v=5r1qQ5DOsUI">Autodesk Research</a>’s approach to encode the parametric primitives (points, curves, shapes, extrusions, etc) into a transformer architecture. However, as far as I understand, the models in these projects cannot yet take an arbitrary input command and generate a desired shape.</p>

<p>Then a few weeks ago, I was inspired by the <a href="https://github.com/ahujasid/blender-mcp">recent use of LLMs to drive Blender</a>, the open source modeling tool widely used for animation. Given that LLMs are incredibly good at generating code, perhaps programmatic interfaces for CAD modeling could be used to generate solid models in a similar way. I immediately thought of <a href="https://openscad.org/">OpenSCAD</a>, an open-source programmatic CAD tool that’s been developed for more than 15 years. Instead of using point-and-click software to create a solid model, the user writes a software script, which is then rendered into the solid CAD model.</p>

<h2 id="llms-rock-at-writing-openscad">LLMs rock at writing OpenSCAD</h2>

<p>To test it out, I created a simple project in Cursor, made a blank OpenSCAD script (Cursor.scad), and added some Cursor rules:</p>

<div><pre><code># Your rule content

- We're creating files to model things in open scad. 
- All the OpenScad files you create will be in Cursor.scad. I've set up this file such that if you edit it, it will automatically be read by OpenScad (it's the open file in the program). 
- If I want to save what you've done, I'll tell you and you should create a new file and put it in the Saved folder. 
- That's it! Overtime, if needed, we could create documentation about how to use OpenScad. 
- If I'm asking you to create a new design, you should delete the current contents of cursor.scad and add the new design into it.
- When I make requests you should always first develop a step by step plan. Then tell me the step by step plan. And then I'll tell you to start modeling. 
- When you're going through the step by step plans, only execute one step at a time. 
- When you've executed a step, ask the user if its right.
</code></pre></div>

<p>Then, I started using Cursor to create solid models.</p>

<p>Here’s an example:  “Create an iPhone case”.</p>

<p><img src="https://willpatrick.xyz/assets/images/blog/iphone.gif" alt="iPhone GIF"></p>

<p>It didn’t nail it on the first try, but with a couple of iterations (including giving it screenshots) we created a basic case.</p>

<p>You can also leverage OpenSCAD libraries (there are many public ones). Here, I use a library to make a thread for a flange.</p>

<p><img src="https://willpatrick.xyz/assets/images/blog/flange.gif" alt="Flange GIF"></p>

<p>One thing that’s pretty neat is that the LLM can use its general knowledge of mechanical engineering. For example, above, Cursor created holes in the pipe for M6 bolts and it correctly made the diameter slightly bigger than 6 mm, so the bolts could pass through.</p>

<pre><code>bolt_hole_d = 6.5; // Diameter for M6 bolts
</code></pre>

<p>Of course, one of the really nice things about this approach is that the files are editable and Cursor defaults to parameterizing all the key elements of the design. In the above example, I asked it to add holes for mounting bolts, which it did, and then I edited the number of holes manually to 3 from 4.</p>

<pre><code>// Flange parameter
flange_OD = 50; // Outer diameter of the flange in mm 
flange_thickness = 10; // Thickness of the flange in mm
pipe_size = 1/2; // NPT Pipe Size

// Bolt hole parameters
num_bolts = 3;
bolt_hold_d = 6.5; // Diameter for M6 bolts
bold_hole_circle = 35; // Diameter for the bolt circle
</code></pre>

<h2 id="building-an-eval-for-llm---openscad---stl">Building an eval for LLM -&gt; OpenSCAD -&gt; STL</h2>

<p>I was impressed by these initial results but I wanted to learn more. For example, did the model’s reasoning ability help it think through the steps of creating a part? So, I decided to develop an evaluation to test the performance of various LLMs at generating solid models via OpenSCAD.</p>

<p>One of the challenges with creating an eval for CAD design is that most tasks have many correct answers. For example, a task such as “make a m3 screw that’s 10mm long” could have many correct answers because the length, diameter, and style of the head are not defined in the task. To account for this, I decided to write the tasks in my eval such that there was only a single, correct interpretation of the geometry.</p>

<p>For example, here is one of the tasks in the eval:</p>

<blockquote>
  <p>This is a 3mm thickness rectangular plate with two holes.</p>

  <ol>
    <li>
      <p>The plate is 18mm x 32mm in dimension.</p>
    </li>
    <li>
      <p>When looking down at the plate, it has two holes that are drilled through it. In the bottom left of the plate, there’s a hole with a centerpoint that is 3mm from the short (18mm) side and 3 mm from the long (32mm) side. This hole has a diameter of 2mm.</p>
    </li>
    <li>
      <p>In roughly the top left corner of plate, there’s a hole of diameter 3mm. Its center point is 8mm from the short side (18mm side) and 6mm away from the long (32mm) side.</p>
    </li>
  </ol>
</blockquote>

<p>The benefit of this approach is that we can score each task as a Pass or Fail and we can do this in an automated way. I wrote 25 total CAD tasks which ranged in difficulty from a single operation (“A 50mm long pipe that has a 10mm outer diameter and 2mm wall thickness”) to 5 sequential operations. For each task, I designed a reference CAD model using Autodesk Fusion 360 and then exported a STL mesh file.</p>

<p>Then, I set about programming the automated eval pipeline (of course, <a href="https://willpatrick.xyz/software/2025/03/17/software-with-a-market-of-one.html">I didn’t actually write much code</a>).</p>

<p>Here is how the eval pipeline works:</p>

<ol>
  <li>For each task and model, the eval sends the text prompt (along with a system prompt) to the LLM via API.</li>
  <li>The LLM sends back the openSCAD code.</li>
  <li>The openSCAD code is rendered into a STL</li>
  <li>The generated STL is automatically checked against the reference STL</li>
  <li>The task “passes” if it passes a number of geometric checks.</li>
  <li>The results are then outputted in a dashboard.</li>
</ol>

<p>
graph LR
    A[Start Eval For each Task &amp; Model] --&gt; B{Send System + Task Prompt to LLM};
    B --&gt; C[LLM Returns OpenSCAD];
    C --&gt; D{Render OpenSCAD to STL};
    D --&gt; E{Compare Generated STL to Reference STL};
    E --&gt; I[Output Eval Results to Dashboard];
</p>

<p>[Note: The eval runs multiple replicates per task x model combo. And the eval is executed in parallel, because there can be 1000+ tasks when running the full evaluation.]</p>

<p>Here’s how the geometric check works:</p>

<ul>
  <li>The generated STL and reference STL are aligned using the iterative closest point (ICP) algorithm.</li>
  <li>The aligned meshes are then compared by:
    <ul>
      <li>Their volumes (pass = &lt;2% diff)</li>
      <li>Their bounding boxes (pass = &lt;1 mm)</li>
      <li>The average chamfer distance between the parts (pass = &lt;1 mm)</li>
      <li>The Hausdorff distance (95% percentile) (pass = &lt;1 mm)</li>
    </ul>
  </li>
  <li>To “pass” the eval, all of the geometric checks must be passed.</li>
</ul>

<p>There are a few areas where the eval pipeline could be improved. In particular, false negatives are common (est: ~5%). I’ve also noticed that occasionally, small features that are incorrect (like a small radius fillet) are not caught by the automated geometry check. Nevertheless, the eval pipeline is still good enough to see interesting results and compare the performance of the various LLMs.</p>

<p>If you’d like to learn more about the eval, use it, or check out the tasks, please check out the <a href="https://github.com/wgpatrick/cadeval">GitHub repo</a>.</p>

<p>Finally, there are a number of ways to improve the evaluation. Here are a few things that I’d like to do next:</p>

<ul>
  <li>More tasks with greater coverage</li>
  <li>Optimize system prompts, in particular by adding OpenSCAD documentation and code snippets</li>
  <li>Create an eval variation that uses sketches and drawings as input</li>
  <li>Add another variation that tests the ability of the LLM to add operations to existing OpenSCAD script and STL</li>
  <li>Evaluate the ability of the LLM to fix mistakes in an existing STL / OpenSCAD code</li>
</ul>

<h2 id="rapid-improvement-of-frontier-models">Rapid improvement of frontier models</h2>

<p>Here are the results from an eval run executed on April 22, 2025. In the eval run, 15 different models were tested on the 25 tasks with 2 replicates were task. All of the results and configuration details from the run are available <a href="https://willpatrick.xyz/cadevalresults_20250422_095709/">here</a>.</p>

<p>The results show that LLMs only became good at OpenSCAD solid modeling recently.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/overall_result2.png" alt="Results from CadEval">
  <figcaption>Results from CadEval. In this run, each model attempted to complete 25 tasks (2 replicates per task). "Success" means they passed a number of geometric checks that compared to a reference geometry.</figcaption>
</figure>

<p>The top 3 models were all launched while I was working on the project and the top 7 models are all reasoning models. These models offer large performance increases compared to their predecessor, non-reasoning counterparts. Sonnet 3.5 is the best non-reasoning model and Sonnet 3.7 is only slightly better performing in the eval (for Sonnet 3.7, thinking was used with a budget of 2500 tokens).</p>

<p>Digging into the results offers some interesting insights. First, the LLMs are quite good at generating OpenSCAD code that compiles correctly and can be rendered into a STL. In other words, only a small portion of the failures are coming from things like OpenSCAD syntax errors. Anthropic’s Sonnet models are the best at this.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/stl_render_success.png" alt="Rendering Success Rate">
  <figcaption>For the same eval run as above, the % of tasks for each model where a STL was rendered (and the geometry was checked).</figcaption>
</figure>

<p>Additionally, we can look at the success rate for tasks where a STL was rendered. The o3-mini is quite strong, with nearly the same sucess rate as the full-size o3 model, while Sonnet 3.7 appears to be a step behind the leading Gemini 2.5 Pro and o1, o3, o4-mini, and o3-mini models.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/success_rate_for_only_tasks_with_rendered_stl.png" alt="Success Rate if STL Rendered">
  <figcaption>Of tasks where a STL was generated, the % of tasks that successfully passed all geometric checks.</figcaption>
</figure>

<p>Finally, to be expected, Gemini 2.5 and o4-mini are substantially cheaper and slightly faster to run than the full o3 and o1 models.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/average_estimated_cost.png" alt="Average cost per task for various models">
  <figcaption>The estimated cost per task for each model.</figcaption>
</figure>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/average_estimated_time.png" alt="Average time per task for various models">
  <figcaption>The average total time per task to generate OpenSCAD and then render a STL. The time to make the API call and receive the OpenSCAD is much, much greater than the time to render the STL, which is  less than 1 second. </figcaption>
</figure>

<p>As expected, some tasks were easy and some tasks were hard to complete.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/task_success_rate.png" alt="Pass rate for each of the 25 tasks">
  <figcaption>Overall success rate task by task.</figcaption>
</figure>

<p>Generally, speaking tasks with more operations we’re more challenging.</p>

<figure>
  <img src="https://willpatrick.xyz/assets/images/blog/part_complexity.png" alt="Pass rate by part complexity">
  <figcaption>Each task required 1 to 5 operations to complete manually in Fusion360. Within the eval, there were 5 tasks that required a single operation, 5 required two, and so forth. </figcaption>
</figure>

<p>Tasks 2, Task 3, and Task 6 were the easiest tasks with over 80% correct across models. Here’s what these tasks looked like with example successes.</p>



<p>Only 2 tasks had 0% success, task 11 and task 15. Here are the prompts for those two tasks and representative failures.</p>



<p>These failures are both interesting and quite different. Task 11 is a good example of poor spatial reasoning. In the specific failure highlighted in the image, the model extrudes the shank of the eyebolt  orthogonally to the torus (instead of in the same plane). Task 15 is a different failure mode. It’s hard to see in the attached image, but if you zoom in closely, it’s clear that the generated shape is slightly larger than the reference shape (which makes sense, because the generated STL failed the volume check). From looking at the OpenSCAD code for this example, it appears that the failure is due to using OpenSCAD’s <a href="https://www.openscad.info/index.php/2020/10/18/hull/">hull operation</a>, which is not precisely the same as a loft operation. OpenSCAD does not have a loft operation built-in.</p>

<p>Tasks 20-24 all required 5 sequential operations and the average success rate for these tasks ranged from 3.3% to 30%. Here are the prompts for those 5 tasks with representative successes and failures.</p>

<p>The failures can be tricky to spot. The green areas of the failed images should have geometry in the generated STL, but do not (the reference point cloud is plotted in green). Likewise, the red areas have geometry in the generated STL, but they shouldn’t.</p>



<h2 id="start-ups">Start-ups</h2>

<p>In the past few months, two different start-ups launched text-to-CAD products, AdamCad and Zoo.dev. Zoo.dev offers an API to use their text-to-CAD model. Zoo’s demos of their API and text-to-CAD product are very cool and look quite similar to the Cursor -&gt; OpenSCAD demo I have above.</p>

<blockquote><div lang="en" dir="ltr"><p>We're excited to announce the launch of Zoo.dev, a text-to-CAD API that lets you generate 3D models from text descriptions.</p><p>We've been working on this for the past year, and we're finally ready to share it with the world.</p><p>Here's a thread on what we've built 🧵 <a href="https://t.co/Yd9Yd9Ixqm">pic.twitter.com/Yd9Yd9Ixqm</a></p></div>— Abhishek (@abhi1thakur) <a href="https://twitter.com/abhi1thakur/status/1881766438383337573?ref_src=twsrc%5Etfw">July 21, 2024</a></blockquote>


<p>I added Zoo into the eval pipeline to compare against LLM -&gt; OpenSCAD -&gt; STL. Instead of generating OpenSCAD, the Zoo.dev API shoots back a STL directly. Zoo says they use <a href="https://zoo.dev/machine-learning-api">a proprietary dataset and machine learning model</a>. To my surprise, Zoo’s API didn’t perform particularly well in comparison to LLMs generating STLs by creating OpenSCAD. Despite that, I’m excited to see the development of Zoo.dev and I will be eager to see how future model launches from Zoo.dev compare to LLMs creating OpenSCAD.</p>

<h2 id="whats-next">What’s next?</h2>

<p>I think these initial results are promising. Cursor (or another coding agent) + OpenSCAD offers a solution for producing solid models in an automated way.</p>

<p>However, I don’t think this approach is about to take off and spread rapidly through the CAD design ecosystem. The current set-up is seriously clunky and I think substantial product improvements are needed to make this work better. Similar to how Cursor, Windsurf, and other tools have developed specific UX and LLM workflows for code generation, I imagine there will be substantial work required to develop workflows and UX that make sense for CAD generation. Here are a few ideas that I think could be worth pursuing in this direction:</p>

<ul>
  <li>Tools that bring in console logs and viewport images to Cursor from OpenSCAD for iterative improvement and debugging.</li>
  <li>A UI to highlight (and measure) certain faces, lines, or aspects of a part, which are fed to the LLM for additional context.</li>
  <li>Drawing or sketch-input, so the user can quickly visually communicate their ideas.</li>
  <li>A UI with sliders to adjust parameters instead of editing the code.</li>
</ul>

<p>Additionally, I expect that further model advances will continue to unlock this application. In particular, improving spatial reasoning is an <a href="https://arxiv.org/pdf/2504.05786">active area of research</a>. I imagine that improved spatial reasoning could greatly improve models’ ability to design parts step by step.</p>

<p>So when does text-to-CAD become a commonly used tool for mechanical engineers? With start-ups actively building products and the rapid improvement of frontier models, my guess would be something like 6-24 months.</p>

<h2 id="where-does-this-go">Where does this go?</h2>

<p>In the medium to long term (2-10 years), I imagine that most parts will be created with a form of GenCAD. Allow me to speculate.</p>

<ul>
  <li>Initially, GenCAD will be used to create parts that fit within existing assemblies. For example, you might say: “I need a bracket that fits here.”  And, the GenCAD tool will create a bracket that perfectly joins with the existing assembly components. Want to analyze three variants with FEA? Ask for them. I expect mainstream CAD suites (Autodesk, Solidworks, Onshape) to add these capabilities directly into their product suite.</li>
  <li>Longer term, I imagine GenCAD will reach every aspect of a CAD suite: sketches, mates, assemblies, exploded views, CAM tool-pathing, rendering visualizations, and CAE. Imagine a design review where you highlight a subassembly and say “replace these rivets with M6 countersunk screws and regenerate the BOM.” The model, drawings, and purchasing spreadsheet all update in seconds.</li>
</ul>

<p>We’re watching CAD begin to exit the manual-input era. I, for one, am quite excited about that.</p>

<!-- Carousel CSS and JS -->





  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Graphics livecoding in Common Lisp (154 pts)]]></title>
            <link>https://kevingal.com/blog/cl-livecoding.html</link>
            <guid>43774726</guid>
            <pubDate>Wed, 23 Apr 2025 17:48:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kevingal.com/blog/cl-livecoding.html">https://kevingal.com/blog/cl-livecoding.html</a>, See on <a href="https://news.ycombinator.com/item?id=43774726">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <header>
        <p data-nosnippet="">
        <nav>
        <a href="https://kevingal.com/index.html">about</a>
        • <a href="https://kevingal.com/blog.html">blog</a>
        • <a href="https://kevingal.com/projects.html">projects</a>
        • <a href="https://kevingal.com/feed.xml">rss</a>
        </nav>
        </p>
    </header>


<h3>2025-04-23</h3>
<h3>Developing a Boids program from scratch without restarting it.</h3>
<p>Tags: <a href="https://kevingal.com/blog/tag/lisp.html">lisp</a> <a href="https://kevingal.com/blog/tag/programming.html">programming</a> <a href="https://kevingal.com/blog/tag/artsy.html">artsy</a> </p>
<a href="https://kevingal.com/blog/chess-detective.html">&lt;&lt; previous</a>
<hr>
<p>Some Lisps, like Common Lisp, have a powerful feature that tends to go underappreciated amidst all the talk about macros: the ability to recompile your program while it's running, without restarting it. For the purposes of this post, and because it sounds cool, let's call this ability <em>livecoding</em><sup id="fnref:livecod"><a href="#fn:livecod">1</a></sup>.</p>
<p>Entering this strange land where the programs never stop, we'll first take a brief tour of Common Lisp and one of its graphics frameworks, Sketch, before walking through a livecoded implementation of the <a href="https://en.wikipedia.org/wiki/Boids">Boids algorithm</a>.</p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/img/cl-livecoding/boids-sample.mp4" type="video/mp4">
</video> 
<figcaption>Boids!</figcaption>
</figure>

<h3 id="wait-what-exactly-is-this-livecoding-thing">"Wait, what exactly is this livecoding thing?"</h3>
<p>Consider the typical workflow needed to modify a running application, like a videogame.</p>
<ol>
<li>Stop the application.</li>
<li>Change the code.</li>
<li>(If a compiled language) Wait N time units for a full recompilation.</li>
<li>Start the application again.</li>
<li>Fiddle with the application to get it back to its previous state.</li>
<li>Carry on.</li>
</ol>
<p>In a livecoding environment, the application is never stopped, which eliminates steps 1, 4 and 5. Instead, small code changes (which can be as granular as recompiling a single function) are immediately reflected in the running program. Step 3 is often instantaneous because only the changed parts of the program must be recompiled. In theory, then, you can develop an entire application while it continuously runs in the background, without ever waiting for code to recompile. This makes the development process more fluid and interactive, with minimal downtime.</p>
<p>In Common Lisp, the workflow might look something like this:</p>
<ol>
<li>Make a small change to a single function.</li>
<li>Recompile the function (instantaneous).</li>
<li>Carry on.</li>
</ol>
<p>For an example of this workflow in action, check out Common Lisp and Emacs being used as an environment for <a href="https://www.youtube.com/watch?v=EkYUU0UoB_0">live musical performance</a>. You can hear about a Lisp program being debugged remotely while running in <a href="https://corecursive.com/lisp-in-space-with-ron-garret/">deep space</a>. Livecoding (or hot reloading, or whatever you like to call it) is also available in other languages, like Smalltalk and Erlang.</p>
<h3 id="a-rough-sketch-of-sketch">A rough sketch of Sketch</h3>
<p>Before jumping into Boids, let's take a brief look at <a href="https://github.com/vydd/sketch">Sketch</a>, our Common Lisp graphics framework of choice. We'll be more concerned with big ideas than with code minutiae, but if you're unfamiliar with Common Lisp and want to understand the code samples, then please take a detour through <a href="https://learnxinyminutes.com/common-lisp/">Learn Common Lisp in Y Minutes</a>.</p>
<p>So, Sketch. The Sketch API is heavily based on that of <a href="https://processing.org/">Processing</a>. Its primary entry point is the <code>defsketch</code> macro. The code below defines a "sketch" called <code>my-sketch</code>.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>my-sketch</span>
    <span>((</span><span>width</span> <span>200</span><span>)</span>
     <span>(</span><span>height</span> <span>200</span><span>)</span>
     <span>(</span><span>n</span> <span>5</span><span>))</span>
  <span>;; ...drawing code here...</span>
  <span>)</span>
</code></pre></div>

<p>After the name of the sketch comes a list of bindings that define its state and configuration. Here, the window properties <code>width</code> and <code>height</code> are set to <code>200</code>, while <code>n</code> is an attribute we've added for our own use.</p>
<p>Then comes the drawing code. This gets run in a loop while the sketch is running, once per frame. The following snippet draws 5 red circles on a black background, each of radius 10 and in random positions.</p>
<div><pre><span></span><code><span>(</span><span>background</span> <span>+black+</span><span>)</span>
<span>(</span><span>loop</span> <span>repeat</span> <span>n</span>
      <span>do</span> <span>(</span><span>with-pen</span> <span>(</span><span>make-pen</span> <span>:fill</span> <span>+red+</span><span>)</span>
           <span>(</span><span>circle</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)</span> <span>10</span><span>)))</span>
</code></pre></div>

<p>After painting the background black, the all-powerful <code>loop</code> macro is used to draw <code>n</code> circles. The <code>with-pen</code> macro (defined by Sketch) configures drawing properties like fill colour, stroke width and stroke colour. It takes a "pen" object as an argument.</p>
<p>Here's all the code together:</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>my-sketch</span>
    <span>((</span><span>width</span> <span>200</span><span>)</span>
     <span>(</span><span>height</span> <span>200</span><span>)</span>
     <span>(</span><span>n</span> <span>5</span><span>))</span>
  <span>(</span><span>background</span> <span>+black+</span><span>)</span>
  <span>(</span><span>loop</span> <span>repeat</span> <span>n</span>
        <span>do</span> <span>(</span><span>with-pen</span> <span>(</span><span>make-pen</span> <span>:fill</span> <span>+red+</span><span>)</span>
             <span>(</span><span>circle</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)</span> <span>10</span><span>))))</span>
</code></pre></div>

<p>Finally, to run the sketch, we compile our code and execute <code>(run-sketch 'my-sketch)</code> from the REPL, resulting in...</p>
<figure>
<img src="https://kevingal.com/static/img/cl-livecoding/sketch-sample.gif" alt="The result: red circles flashing on a black background.">
<figcaption>...art.</figcaption>
</figure>

<p>That's all we need to know about Sketch for now!</p>
<h3 id="livecoding-boids">Livecoding Boids</h3>
<p><a href="https://en.wikipedia.org/wiki/Boids">Boids</a> is an algorithm from 1986 for simulating flocks of birds. In its essence, it consists of applying 3 forces to the simulated birds. Quoting Wikipedia<sup id="fnref:boidsref"><a href="#fn:boidsref">2</a></sup>, these forces are:</p>
<blockquote>
<ul>
<li>separation: steer to avoid crowding local flockmates</li>
<li>cohesion: steer to move towards the average position (center of mass) of local flockmates</li>
<li>alignment: steer towards the average heading of local flockmates</li>
</ul>
</blockquote>
<p>How can we implement this ourselves? First, we need a canvas to draw on!</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>))</span>
  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
</code></pre></div>

<p>The only mysterious thing in this code is the <code>restart-on-change</code> parameter, which is available in my <a href="https://github.com/Kevinpgalligan/sketch">fork</a> of Sketch. When its value is <code>nil</code> (false), the sketch's state - like the boid positions - won't be reset when we recompile our code.</p>
<p>Compiling the defsketch form in Emacs (with the Ctrl-C Ctrl-C shortcut) and executing <code>(run-sketch 'boids)</code> at the REPL gives us... 🥁... a gray background. Wonderful.</p>
<figure>
<img src="https://kevingal.com/static/img/cl-livecoding/boids-1-canvas.png" alt="A light-gray background.">
</figure>

<p>(Note: all going well, this modest window will run continuously throughout the entire development lifecycle).</p>
<p>Now let's create some boids to populate our world. We add a <code>boid</code> class to store their position and velocity, as well as a convenience function <code>make-boid</code> to create a boid from x &amp; y co-ordinates. These rely on a hopefully self-explanatory implementation of 2d vectors, which are created using the <code>vec2</code> function.</p>
<div><pre><span></span><code><span>(</span><span>defclass</span> <span>boid</span> <span>()</span>
  <span>((</span><span>pos</span> <span>:initarg</span> <span>:pos</span> <span>:accessor</span> <span>pos</span><span>)</span>
   <span>(</span><span>velocity</span> <span>:initarg</span> <span>:velocity</span>
             <span>:initform</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)</span>
             <span>:accessor</span> <span>velocity</span><span>)))</span>

<span>(</span><span>defun</span> <span>make-boid</span> <span>(</span><span>x</span> <span>y</span><span>)</span>
  <span>(</span><span>make-instance</span> <span>'boid</span> <span>:pos</span> <span>(</span><span>vec2</span> <span>x</span> <span>y</span><span>)))</span>
</code></pre></div>

<p>To the sketch itself, we add 20 boids in random positions, and pass them to the <code>draw-boids</code> function in the drawing loop.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
<span>     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
</span><span>                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span> <span>(</span><span>random</span> <span>height</span><span>)))))</span>
</span>  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
<span>  <span>(</span><span>draw-boids</span> <span>boids</span><span>))</span>
</span></code></pre></div>

<p>If we then recompile defsketch (with Ctrl-C Ctrl-C)... </p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-2-missing-draw-compile.mp4" type="video/mp4">
</video>

<p>...we get an error! Woops. </p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-2-missing-draw.mp4" type="video/mp4">
</video> 
<figcaption>Before: gray canvas. After: red error screen.</figcaption>
</figure>

<p>But of course! We forgot to define <code>draw-boids</code>. The program doesn't crash, however, and we'll soon be able to recover from this setback.</p>
<p>Here's an implementation of <code>draw-boids</code>. We don't need to get into the weeds of how it works. For each boid, it does some unwieldy vector math to figure out which direction the boid is facing and draws a triangle pointing in that direction.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>draw-boids</span> <span>(</span><span>boids</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>boid-width</span> <span>10</span><span>)</span>
        <span>(</span><span>boid-length</span> <span>20</span><span>))</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>with-slots</span> <span>(</span><span>pos</span> <span>velocity</span><span>)</span> <span>boid</span>
               <span>(</span><span>with-pen</span> <span>(</span><span>:fill</span> <span>+black+</span><span>)</span>
                 <span>(</span><span>let*</span> <span>((</span><span>dir</span> <span>(</span><span>if</span> <span>(</span><span>zerop</span> <span>(</span><span>v-length</span> <span>velocity</span><span>))</span>
                                 <span>(</span><span>vec2</span> <span>0</span> <span>-1</span><span>)</span>
                                 <span>(</span><span>v-normalise</span> <span>velocity</span><span>)))</span>
                        <span>(</span><span>p1</span> <span>(</span><span>v+</span> <span>pos</span> <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>)</span> <span>dir</span><span>)))</span>
                        <span>(</span><span>p2</span> <span>(</span><span>v+</span> <span>pos</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>-</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>))</span> <span>dir</span><span>)</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-width</span> <span>2</span><span>)</span>
                                           <span>(</span><span>perpendicular-anticlockwise</span> <span>dir</span><span>))))</span>
                        <span>(</span><span>p3</span> <span>(</span><span>v+</span> <span>pos</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>-</span> <span>(</span><span>/</span> <span>boid-length</span> <span>2</span><span>))</span> <span>dir</span><span>)</span>
                                <span>(</span><span>v-rescale</span> <span>(</span><span>/</span> <span>boid-width</span> <span>2</span><span>)</span>
                                           <span>(</span><span>perpendicular-clockwise</span> <span>dir</span><span>)))))</span>
                   <span>(</span><span>polygon</span> <span>(</span><span>vx</span> <span>p1</span><span>)</span> <span>(</span><span>vy</span> <span>p1</span><span>)</span>
                            <span>(</span><span>vx</span> <span>p2</span><span>)</span> <span>(</span><span>vy</span> <span>p2</span><span>)</span>
                            <span>(</span><span>vx</span> <span>p3</span><span>)</span> <span>(</span><span>vy</span> <span>p3</span><span>))))))))</span>
</code></pre></div>

<p>As soon as we compile <code>draw-boids</code>, the error screen disappears and our lovely boids are drawn into place. And we didn't have to restart the program to fix it!</p>
<figure>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-3-define-draw.mp4" type="video/mp4">
</video> 
<figcaption>Before: red error screen. After: boids are drawn.</figcaption>
</figure>

<p>There are two Common Lisp features that enable us to fix errors on-the-fly like we've done here:</p>
<ol>
<li>Newly compiled code, and recompiled code, is immediately loaded (sometimes called "hot reloading") into the running program. This opens up possibilities such as optimising a program as it runs, tweaking parameters like gravitational force and background colour, and iteratively developing a GUI.</li>
<li>The condition system! This is somewhat like exception handling in other languages, but more powerful. Not only can we signal exceptional situations ("conditions"), but we can also define "restarts" for recovering from those situations. When a running Common Lisp program encounters an unhandled condition, control passes to the debugger, and the user is presented with a selection of restarts. Perhaps they want to recompile the offending function and continue execution from the previous stack frame. Or perhaps the error was a division by zero, and the offending function provides a restart that swaps in a value of 1 for the divisor. Suddenly, there are a lot more possibilities than just crashing the program.</li>
</ol>
<p>Anyway, a worthy discussion of the condition system would take up a full blog post of its own. Back to Boids!</p>
<p>Now that our boids are drawn correctly, we want them to move around and do boid things. First, we implement an <code>update-positions</code> function, which basically adds the velocity of each boid to its position (so that the boid moves), and applies the 3 Boidian forces to update the boid's velocity. For now, the functions implementing these forces are stubbed out.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>update-positions</span> <span>(</span><span>boids</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>max-velocity</span> <span>10</span><span>))</span>
    <span>;; Update boid positions.</span>
    <span>(</span><span>map</span> <span>nil</span>
         <span>(</span><span>lambda</span> <span>(</span><span>boid</span><span>)</span>
           <span>(</span><span>setf</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>v+</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>velocity</span> <span>boid</span><span>))))</span>
         <span>boids</span><span>)</span>

    <span>;; Update boid velocities.</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>setf</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                   <span>(</span><span>v-clamp</span> <span>max-velocity</span>
                            <span>(</span><span>v+</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                                <span>(</span><span>rule1</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule2</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule3</span> <span>boid</span> <span>boids</span><span>)))))))</span>

<span>;; Stubs! (For now).</span>
<span>(</span><span>defun</span> <span>rule1</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>

<span>(</span><span>defun</span> <span>rule2</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>

<span>(</span><span>defun</span> <span>rule3</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
  <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>))</span>
</code></pre></div>

<p>We then have to modify the drawing loop to call <code>update-positions</code>.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span>
                                     <span>(</span><span>random</span> <span>height</span><span>)))))</span>
  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
  <span>(</span><span>draw-boids</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>update-positions</span> <span>boids</span><span>))</span>
</span></code></pre></div>

<p>So far, these changes haven't affected the boid behaviour, so let's circle back and implement <code>rule-1</code>, which can be summarised as "stay away from other boids". When a boid is less than 10 pixels from another boid, we push them away from each other to avoid crowding.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule1</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>v-sum</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>   <span>(</span><span>loop</span> <span>for</span> <span>boid2</span> <span>in</span> <span>boids</span>
</span><span>         <span>for</span> <span>offset</span> <span>=</span> <span>(</span><span>v-</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>pos</span> <span>boid2</span><span>))</span>
</span><span>         <span>for</span> <span>dist</span> <span>=</span> <span>(</span><span>v-length</span> <span>offset</span><span>)</span>
</span><span>         <span>when</span> <span>(</span><span>and</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span> <span>(</span><span>&lt;</span> <span>dist</span> <span>10</span><span>))</span>
</span><span>           <span>do</span> <span>(</span><span>v+!</span> <span>v-sum</span> <span>offset</span><span>))</span>
</span><span>   <span>v-sum</span><span>))</span>
</span></code></pre></div>

<p>(Note: the vector functions ending in <code>!</code>, like <code>v+!</code>, follow the convention of storing the result in the vector passed as the first argument).</p>
<p>When we recompile this function...</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-4-first-rule.mp4" type="video/mp4">
</video>

<p>...a pair of boids that happen to be too close to each other are sent flying off into the void. There's no counterforce to bring them back, just yet.</p>
<p>Next, we implement <code>rule-2</code>: boids should fly towards the average position of other boids. Our implementation could be more efficient by summing the boid positions just once, rather than doing it for every single boid, but I can't be bothered.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule2</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>center</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>    <span>(</span><span>map</span> <span>nil</span>
</span><span>         <span>(</span><span>lambda</span> <span>(</span><span>boid2</span><span>)</span>
</span><span>           <span>(</span><span>when</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span>
</span><span>             <span>(</span><span>v+!</span> <span>center</span> <span>(</span><span>pos</span> <span>boid2</span><span>))))</span>
</span><span>         <span>boids</span><span>)</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>(</span><span>1-</span> <span>(</span><span>length</span> <span>boids</span><span>)))</span> <span>center</span><span>)</span>
</span><span>    <span>(</span><span>v-!</span> <span>center</span> <span>(</span><span>pos</span> <span>boid</span><span>))</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>200</span><span>)</span> <span>center</span><span>)</span>
</span><span>    <span>center</span><span>))</span>
</span></code></pre></div>

<p>Recompiling <code>rule-2</code>, we get...</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-5-second-rule.mp4" type="video/mp4">
</video>

<p>Yes! This is starting to look vaguely like Boids. Let's add the final rule, <code>rule-3</code>: boids should match their velocity to all the other boids. Implementation note: we probably shouldn't update the velocities until all the new velocities have been calculated, but this doesn't seem to matter too much.</p>
<div><pre><span></span><code><span>(</span><span>defun</span> <span>rule3</span> <span>(</span><span>boid</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>let</span> <span>((</span><span>result</span> <span>(</span><span>vec2</span> <span>0</span> <span>0</span><span>)))</span>
</span><span>    <span>(</span><span>map</span> <span>nil</span>
</span><span>         <span>(</span><span>lambda</span> <span>(</span><span>boid2</span><span>)</span>
</span><span>           <span>(</span><span>when</span> <span>(</span><span>not</span> <span>(</span><span>eq</span> <span>boid</span> <span>boid2</span><span>))</span>
</span><span>             <span>(</span><span>v+!</span> <span>result</span> <span>(</span><span>velocity</span> <span>boid2</span><span>))))</span>
</span><span>         <span>boids</span><span>)</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>(</span><span>1-</span> <span>(</span><span>length</span> <span>boids</span><span>)))</span> <span>result</span><span>)</span>
</span><span>    <span>(</span><span>v-!</span> <span>result</span> <span>(</span><span>velocity</span> <span>boid</span><span>))</span>
</span><span>    <span>(</span><span>v-scale!</span> <span>(</span><span>/</span> <span>8</span><span>)</span> <span>result</span><span>)</span>
</span><span>    <span>result</span><span>))</span>
</span></code></pre></div>

<p>Recompiling, we see the Boids calm down a little bit.</p>
<video loop="" autoplay="" muted="">
  <source src="https://kevingal.com/static/video/cl-livecoding/boids-6-third-rule.mp4" type="video/mp4">
</video>

<p>Since it's not very bird-like to fly around in a vortex of death, we could also give the boids a purpose by making them follow the mouse position. The result of these changes can be seen at the top of the post.</p>
<div><pre><span></span><code><span>(</span><span>defsketch</span> <span>boids</span>
    <span>((</span><span>width</span> <span>400</span><span>)</span>
     <span>(</span><span>height</span> <span>400</span><span>)</span>
     <span>(</span><span>restart-on-change</span> <span>nil</span><span>)</span>
     <span>(</span><span>boids</span> <span>(</span><span>loop</span> <span>repeat</span> <span>20</span>
                  <span>collect</span> <span>(</span><span>make-boid</span> <span>(</span><span>random</span> <span>width</span><span>)</span>
                                     <span>(</span><span>random</span> <span>height</span><span>))))</span>
<span>     <span>(</span><span>mouse-pos</span> <span>(</span><span>vec2</span> <span>200</span> <span>200</span><span>)))</span>
</span>  <span>(</span><span>background</span> <span>(</span><span>gray-255</span> <span>230</span><span>))</span>
  <span>(</span><span>draw-boids</span> <span>boids</span><span>)</span>
<span>  <span>(</span><span>update-positions</span> <span>boids</span> <span>mouse-pos</span><span>))</span>
</span>
<span><span>(</span><span>defmethod</span> <span>on-hover</span> <span>((</span><span>instance</span> <span>boids</span><span>)</span> <span>x</span> <span>y</span><span>)</span>
</span><span>  <span>(</span><span>setf</span> <span>(</span><span>boids-mouse-pos</span> <span>instance</span><span>)</span> <span>(</span><span>vec2</span> <span>x</span> <span>y</span><span>)))</span>
</span>
<span>(</span><span>defun</span> <span>update-positions</span> <span>(</span><span>boids</span> <span>mouse-pos</span><span>)</span>
  <span>(</span><span>let</span> <span>((</span><span>max-velocity</span> <span>10</span><span>))</span>
    <span>(</span><span>map</span> <span>nil</span>
         <span>(</span><span>lambda</span> <span>(</span><span>boid</span><span>)</span>
           <span>(</span><span>setf</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>v+</span> <span>(</span><span>pos</span> <span>boid</span><span>)</span> <span>(</span><span>velocity</span> <span>boid</span><span>))))</span>
         <span>boids</span><span>)</span>
    <span>(</span><span>loop</span> <span>for</span> <span>boid</span> <span>in</span> <span>boids</span>
          <span>do</span> <span>(</span><span>setf</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                   <span>(</span><span>v-clamp</span> <span>max-velocity</span>
                            <span>(</span><span>v+</span> <span>(</span><span>velocity</span> <span>boid</span><span>)</span>
                                <span>(</span><span>rule1</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule2</span> <span>boid</span> <span>boids</span><span>)</span>
                                <span>(</span><span>rule3</span> <span>boid</span> <span>boids</span><span>)</span>
<span>                                <span>(</span><span>v-rescale</span> <span>0.1</span> <span>(</span><span>v-</span> <span>mouse-pos</span> <span>(</span><span>pos</span> <span>boid</span><span>)))))))))</span>
</span></code></pre></div>

<p>And with that, we have a complete implementation of Boids! At the risk of beating a dead horse, I'll re-emphasise that we did the whole thing without once restarting our program or waiting a perceivable amount of time for code to compile.</p>
<h3 id="closing-thoughts">Closing thoughts</h3>
<p>I hope, in this brief demonstration of livecoding, I've given you a taste of how useful and fun this feature can be, whether you're developing a graphics application or mundane accounting software. Like I've said, it's not unique to Common Lisp, as at least Smalltalk and Erlang have similar capabilities. It's also possible to bridge the gap in less interactive languages by making applications automatically restart themselves when a code change is detected, or by bolting on a scripting language. Just do me a favour and ask yourself, the next time you're waiting the requisite time units for your code to recompile: <em>How can I make this workflow more interactive? How can I make it more... like Common Lisp?</em></p>
<!-- Just in case, here's the ffmpeg command I used to trim the screen recordings:
ffmpeg -i input.mp4 -ss 2 -to 4 -async 1 cut.mp4 -->


<hr>
<a href="https://kevingal.com/blog/chess-detective.html">&lt;&lt; previous</a>
<ul>
<li><a href="https://kevingal.com/blog.html">Back to blog</a></li>
<li><a href="https://kevingal.com/feed.xml">RSS feed</a></li>
</ul>
<p>I'd be happy to hear from you at <i>galligankevinp@gmail.com</i>.</p>


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Future of MCPs (137 pts)]]></title>
            <link>https://iamcharliegraham.substack.com/publish/post/161906169</link>
            <guid>43774327</guid>
            <pubDate>Wed, 23 Apr 2025 17:12:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iamcharliegraham.substack.com/publish/post/161906169">https://iamcharliegraham.substack.com/publish/post/161906169</a>, See on <a href="https://news.ycombinator.com/item?id=43774327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:3341558,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://iamcharliegraham.substack.com/i/161906169?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a2e03d7-6d31-4677-a9ce-7fbf2c5288b1_1536x1024.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><em><span>This was originally posted at </span><a href="https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/" rel="nofollow ugc noopener">https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/</a></em><a href="https://www.iamcharliegraham.com/mcps-gatekeepers-and-the-future-of-ai/" rel="nofollow ugc noopener"><br></a><br><span>Lately, there’s been significant buzz and genuine excitement around MCPs—Model Context Protocols. If you've been following AI development circles, you've likely heard optimistic claims such as "this will change everything."</span></p><p>Curious about the possibilities, I went deep into MCPs, building two experimental MCP servers myself, and thoroughly exploring their potential and current limitations. Here's what I discovered.</p><p><em><strong>Note:</strong><span> This post is more technical and detailed than most of my previous posts.</span></em></p><p>Think of MCPs as standardized APIs—connectors between external data sources or applications and large language models (LLMs) like ChatGPT or Claude. They let the model contact a travel site to fetch real-time prices, read and manage your calendar, or even rename files on your computer.</p><p>While tools like Claude, Cursor, and OpenAI already use custom integrations under the hood, MCPs aim to offer a universal, standardized format for all such interactions.</p><p>MCPs have two main parts: clients (like ChatGPT) and servers (external services like a flight scheduling site). When used together, they give LLMs “superpowers”—letting them access real-time data, take action on the web, and act more like agents than static chatbots.</p><p>Today, two main types of MCP Servers are emerging. One set is developer-focused—tools like Cursor or Claude Code that integrate with your laptop to manage files, and/or run scripts. The other is web and action-oriented, built around real-world tasks like searching for products, registering domains, booking events, or sending emails.</p><p>To explore what’s actually possible, I built one of each MCP server. The first was a developer server called GPT Learner - a tool that lets you instruct Cursor to remember what went wrong and avoid repeating mistakes. If Claude or Cursor rewrote your code incorrectly, after you have it fixed you can say “record learnings,” and it will store what to do and not do in its rules for the future.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png" width="1129" height="608" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:608,&quot;width&quot;:1129,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff29e6f6a-2324-4b49-b61f-c0a6e9872fe2_1129x608.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>The second project was more ambitious: a prediction market MCP that connects an LLM to</span><a href="https://betsee.xyz/?ref=iamcharliegraham.com" rel="nofollow ugc noopener"> betsee.xyz</a><span>, a site I built that aggregates live prediction markets. When you ask Claude something like, “Trump just paused tariffs—what are the second-order effects, and what are people betting on?” the MCP returns relevant markets from Polymarket or Kalshi, along with live odds.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png" data-component-name="Image2ToDOM" rel="nofollow ugc noopener"><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png" width="1296" height="1604" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1604,&quot;width&quot;:1296,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" title="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F358c8dea-1c33-4b60-8229-b4238295ee09_1296x1604.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Building these things made a few things clear. First, MCPs aren’t ready for broad adoption.</p><p>The user experience is rough. Most chat clients like ChatGPT don’t yet support MCP servers. The few that do require manual JSON editing to install them—not exactly user-friendly. Clients like Cursor and Claude currently prompt users for every request and often return incomplete info or raw JSON outputs. It's clunky and frustrating.</p><p>When I used Claude Desktop to query my prediction market MCP, it often didn’t send links or prices unless I explicitly asked. Sometimes it didn’t call the server at all. And every time it made a call to my MCP, it prompted me to approve - which quickly became annoying. Eventually, MCP installation will be seamless (e.g., “click to add from a catalog”), and responses will be meaningful. But we’re not there yet.</p><p>Security is another glaring issue. Because MCPs enable external actions and access to live systems, they introduce a wide new surface area for abuse. Prompt injection, malicious tool installs, unauthorized access, and Trojan-horse-style exploits are all very real risks today. There's no sandboxing, no validation layer, and no mature security ecosystem to handle these edge cases.</p><p>We’re clearly still in the experimental stage.</p><p>While building these servers, I had one more important learning: while MCP servers provide the data and actions, the clients control the future.</p><p>Whoever controls the LLM interface— Claude, ChatGPT, Cursor, etc...—controls what tools users see, which ones get triggered, and what responses actually get surfaced. You can build the world’s most useful MCP server, but the client may not call it, or only show half of its output. You may not even be allowed to install it</p><p>Given that MCP clients hold all the power, it’s easy to see how MCPs will end up governed by a framework resembling a combination of the two dominant monopolies of the last two decades: search and mobile app stores. Major LLM providers—OpenAI, Anthropic, and others—will emerge as the new monopoly gatekeepers, managing MCP selection and monetizing that control through preferred placements and curated inclusion.</p><p>Since its founding in the late 1990s, Google has controlled which products users see when they have purchase intent—building an incredibly lucrative business. Now, GPT chats (the MCP clients) are entering that space, replacing the "10 blue links" by curating responses to people’s requests: deciding what content is included, what’s excluded, and how it's formatted. MCP servers will become the new SEM/SEO layer—paying fees to reach users via these AI intermediaries.</p><p>Installation, meanwhile, will resemble the mobile app store model. Just as Apple and Google shaped the mobile ecosystem by determining which apps were featured, preinstalled, or approved at all, LLM clients will decide which MCP servers get surfaced, promoted, or even allowed. Companies will compete—and likely pay significant sums—for premium visibility in these ecosystems, turning MCP directories into high-stakes distribution platforms.</p><p>Users will be able to install MCPs—or “chat apps”—from large, curated directories. Tools like Gmail, HubSpot, Uber, and Kayak will add MCP endpoints, integrating directly into chat-based workflows. While installation is technically possible, most users won’t bother to choose their own tools. Instead, they’ll rely on the defaults provided by the client (like ChatGPT). These defaults won’t be arbitrary—they’ll be the result of lucrative partnerships. Large companies will pay to become the preselected option for categories like shopping, travel, domain name search, or services search . Being the default means embedding into the daily flow of millions of users—bringing massive exposure, data, and commercial value.</p><p>Some client-side MCP App Stores (MAS) will offer looser, more open directories, allowing broader experimentation and community-developed MCPs. Others will be tightly gated, favoring quality, security, and monetization with strict approval processes. In either case, the client sets the terms of participation—and the rules for success.</p><p>MCP clients like OpenAI and Claude will become the new iOS and Android. MCP servers will play the role of apps—modular tools delivering rich, structured, interactive responses tailored to the user’s needs. But instead of screens and taps, interaction happens through language. The app is invoked not by icon, but by intent.</p><p>Over time, we’ll also see specialized clients emerge, tailored to specific industries or domains. Imagine a Travel Planner Chat Client that integrates seamlessly with airlines, hotel chains, and tour operators, offering users a complete trip-planning experience inside a single conversational flow. Or an HR-focused MCP client that unifies access to legal data, employee records, and organizational tools—transforming how businesses manage people and policy.</p><p>And while most users will stick with mainstream clients backed by billion-dollar UX budgets, some open-source GPT interfaces will likely emerge as well. These will appeal to power users who want full control over the MCPs they install—without gatekeepers. But just like Linux on the desktop, these open clients will remain niche: influential, dedicated, and small in number compared to the dominant platforms.</p><p>If this world unfolds, here are some of the businesses and tools I expect to emerge—and why they matter:</p><p><strong>MCP Wrapper and Server Packs</strong><span> These will simplify setup by bundling multiple related MCPs into a single installable unit. Imagine installing a “Startup Stack” that includes MCPs for calendar, email, CRM, and file storage—ready to go, no configuration required. These packs will streamline onboarding and become especially useful in vertical clients and may include packaged tooling ("set a calendar and send an email").</span></p><p><strong>MCP Affiliate Shopping Engines</strong><span> Some MCP servers will act like AI-powered comparison engines, returning real-time prices and product listings across vendors. They’ll monetize through affiliate links—earning referral fees from purchases. This echoes the early days of SEO and affiliate marketing, now reimagined for AI agents.</span></p><p><strong>MCP-First Content Apps</strong><span> Instead of designing websites for humans, these services will optimize content delivery for LLMs via MCP servers. Think rich, structured data, semantic labeling, and pricing hooks—all returned via MCP calls. Revenue will come from subscriptions or embedded sponsorships and product placements, not page views.</span></p><p><strong>API-to-MCP Providers</strong><span> Many existing APIs will want to participate in this new ecosystem but won’t have the resources to rebuild everything. Middleware tools will emerge that automatically translate traditional REST APIs into compliant, discoverable MCP servers, making onboarding turnkey for SaaS platforms.</span></p><p><strong>Cloudflare for MCPs</strong><span> Security will become a major issue, and someone will step in to handle it. These tools will sit between clients and servers, sanitizing inputs, logging requests, blocking attacks, and monitoring for anomalies. Just as Cloudflare made the modern web safer, a similar role will exist for MCP ecosystems.</span></p><p><strong>Enterprise “Private” MCP Solutions</strong><span> Large companies will start to wire up their own internal services into private MCP servers—exposing data from HR systems, legal tools, analytics dashboards, and more. Paired with open-source LLM clients, these internal setups will unlock AI workflows behind the firewall, with enterprise-level control.</span></p><p><strong>Verticalized MCP Clients</strong><span> Generic chat interfaces will only get you so far. Some domains—like babysitting marketplaces, industrial procurement, or compliance workflows—require specific UIs and business logic. Vertically focused MCP clients will emerge to serve these needs with tailored actions, language, and layouts.</span></p><p>If you’re working on this space—building MCP clients, servers, or something even better —I’d love to hear from you: charlie@iamcharliegraham.com</p><p>We’re still early. MCPs today are messy, brittle, and mostly in the hands of developers. But the direction is clear.</p><p>These protocols have the potential to transform LLMs from chat-based search engines into powerful, agent-like tools that can take action on your behalf—securely, intelligently, and in real time.</p><p><span>But the real story isn’t just about what MCP servers </span><em>can</em><span> do. It’s about who gets to decide </span><em>what they’re allowed to do</em><span>. And in that story, it’s the clients-the ChatGPTs and Claudes of the world—that will write the rules, set the defaults, and shape the future.</span></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I won't be vibe coding anymore: a noob's perspective (129 pts)]]></title>
            <link>https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/</link>
            <guid>43773977</guid>
            <pubDate>Wed, 23 Apr 2025 16:41:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/">https://varunraghu.com/why-i-wont-be-vibe-coding-anymore/</a>, See on <a href="https://news.ycombinator.com/item?id=43773977">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <header>
    <a href="https://varunraghu.com/">
      <h2>
        Varun Raghu
      </h2>
    </a>
    <nav>
      <p><a href="https://varunraghu.com/blog/">Blog</a></p>

    </nav>
  </header>
  <main>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2025-04-22T19:40Z">
                    22 Apr, 2025
                </time>
            </i>
        </p>
    

    <p>i’m breaking up with vibe coding. here’s why.</p>
<p>when i first started learning to code, i built apps/websites that would be considered poor in the traditional sense. it also took me an embarassing amout of time to figure out basic stuff. it was frustratingly difficult. the ‘finished’ product wasn’t even polished.</p>
<p>but atleast i built it. i wasn’t begging an ai agent to fix my bugs. no matter how poor, the code had my blood, sweat and tears in it. no one could take that away from me.</p>
<p>as i was lying in bed on a sleepless night. i realized i hadn’t learnt a new concept in weeks. i had built a few useful apps with ai, but a nagging question kept me awake - what was the point of it all if i didn’t learn a thing?</p>
<p>that’s when it struck me. coding isn’t about the finished product. its a lot like writing. its about the process. its about how you approach a problem. its critical thinking.</p>
<p>and i don’t think i’m ready to let ai take these away from me. i’m going back to writing shitty code, slowly and deliberately.</p>


    

    
        

        
            


        
    


  </main>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI Horseless Carriages (577 pts)]]></title>
            <link>https://koomen.dev/essays/horseless-carriages/</link>
            <guid>43773813</guid>
            <pubDate>Wed, 23 Apr 2025 16:19:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://koomen.dev/essays/horseless-carriages/">https://koomen.dev/essays/horseless-carriages/</a>, See on <a href="https://news.ycombinator.com/item?id=43773813">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[More Everything Forever (122 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html</link>
            <guid>43773746</guid>
            <pubDate>Wed, 23 Apr 2025 16:13:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html">https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html</a>, See on <a href="https://news.ycombinator.com/item?id=43773746">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/23/books/review/more-everything-forever-adam-becker.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[They made computers behave like annoying salesmen (277 pts)]]></title>
            <link>https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen</link>
            <guid>43773710</guid>
            <pubDate>Wed, 23 Apr 2025 16:10:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen">https://rakhim.exotext.com/they-made-computers-behave-like-annoying-salesmen</a>, See on <a href="https://news.ycombinator.com/item?id=43773710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <p>Computers are precise machines. You can give a computer a precise command using an inhumane language, and it should perfome the command. It's not a human, and there is no point of treating it as one. The goal of humanizing user experience isn't to create an illusion of human interaction - it's to make these mechanical commands more accessible while preserving their precise, deterministic nature. </p>
<p>UX designers and product managers of tech companies did a lot of damange to people's understanding of computers by making the software behave like a human; or to be more precise, behave like an annoying salesman. </p>
<p><img src="https://img.exotext.com/1/Mam8J5UIOOGzSAR80SsCi.png" alt=""></p>
<p><em>(Image from "<a href="https://blog.prototypr.io/not-now-a91c75ad35b6">Not Now. Not later either</a>" by Chris Oliver)</em></p>
<p>We're all familiar with this type. After receiving a clear "no thanks" they deploy increasingly manipulative tactics to meet their "always-be-closing" quotas: "Would this Wednesday work better?" "What would change your mind?" This behavior is frustrating enough from actual salespeople - it's even worse when programmed into our software.</p>
<p>(<a href="https://www.youtube.com/watch?v=GrhSLf0I-HM">Corporate LLM training session circa 2025</a>)</p>
<p>Personally, I can tolerate but deeply dislike software that pretends to have ulterior motives. Take YouTube, for instance. When I explicitly say "Not interested" to their damned shorts feature, I get this response:</p>
<p><img src="https://img.exotext.com/1/BRKRAYhSqywqHunBgXt0P.png" alt="youtube web page with a message saying 'shelf will be hidden for 30 days'"></p>
<p>I understand that it's not the "YouTube program" having its own agency and making this decision - it's the team behind it, driven by engagement metrics and growth targets. But does the average user understand this distinction?</p>
<p>The population (especially the younger generation, who never seen a different kind of technology at all) is being conditioned by the tech industry to accept that software should behave like an unreliable, manipulative human rather than a precise, predictable machine. They're learning that you can't simply tell a computer "I'm not interested" and expect it to respect that choice. Instead, you must engage in a perpetual dance of "not now, please" - only to face the same prompts again and again.</p>

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Cua (YC X25) – Open-Source Docker Container for Computer-Use Agents (127 pts)]]></title>
            <link>https://github.com/trycua/cua</link>
            <guid>43773563</guid>
            <pubDate>Wed, 23 Apr 2025 15:55:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/trycua/cua">https://github.com/trycua/cua</a>, See on <a href="https://news.ycombinator.com/item?id=43773563">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>TL;DR</strong>: <strong>c/ua</strong> (pronounced "koo-ah", short for Computer-Use Agent) is a framework that enables AI agents to control full operating systems within high-performance, lightweight virtual containers. It delivers up to 97% native speed on Apple Silicon and works with any vision language models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is c/ua?</h2><a id="user-content-what-is-cua" aria-label="Permalink: What is c/ua?" href="#what-is-cua"></a></p>
<p dir="auto"><strong>c/ua</strong> offers two primary capabilities in a single integrated framework:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>High-Performance Virtualization</strong> - Create and run macOS/Linux virtual machines on Apple Silicon with near-native performance (up to 97% of native speed) using the <strong>Lume CLI</strong> with <code>Apple's Virtualization.Framework</code>.</p>
</li>
<li>
<p dir="auto"><strong>Computer-Use Interface &amp; Agent</strong> - A framework that allows AI systems to observe and control these virtual environments - interacting with applications, browsing the web, writing code, and performing complex workflows.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Use c/ua?</h2><a id="user-content-why-use-cua" aria-label="Permalink: Why Use c/ua?" href="#why-use-cua"></a></p>
<ul dir="auto">
<li><strong>Security &amp; Isolation</strong>: Run AI agents in fully isolated virtual environments instead of giving them access to your main system</li>
<li><strong>Performance</strong>: <a href="https://browser.geekbench.com/v6/cpu/compare/11283746?baseline=11102709" rel="nofollow">Near-native performance</a> on Apple Silicon</li>
<li><strong>Flexibility</strong>: Run macOS or Linux environments with the same framework</li>
<li><strong>Reproducibility</strong>: Create consistent, deterministic environments for AI agent workflows</li>
<li><strong>LLM Integration</strong>: Built-in support for connecting to various LLM providers</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">System Requirements</h2><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<ul dir="auto">
<li>Mac with Apple Silicon (M1/M2/M3/M4 series)</li>
<li>macOS 15 (Sequoia) or newer</li>
<li>Python 3.10+ (required for the Computer, Agent, and MCP libraries). We recommend using Conda (or Anaconda) to create an ad hoc Python environment.</li>
<li>Disk space for VM images (30GB+ recommended)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Lume CLI Only (VM Management)</h3><a id="user-content-option-1-lume-cli-only-vm-management" aria-label="Permalink: Option 1: Lume CLI Only (VM Management)" href="#option-1-lume-cli-only-vm-management"></a></p>
<p dir="auto">If you only need the virtualization capabilities:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;"><pre>sudo /bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh<span>)</span></span><span>"</span></span></pre></div>
<p dir="auto">For Lume usage instructions, refer to the <a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md">Lume documentation</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Full Computer-Use Agent Capabilities</h3><a id="user-content-option-2-full-computer-use-agent-capabilities" aria-label="Permalink: Option 2: Full Computer-Use Agent Capabilities" href="#option-2-full-computer-use-agent-capabilities"></a></p>
<p dir="auto">If you want to use AI agents with virtualized environments:</p>
<ol dir="auto">
<li>
<p dir="auto">Install the Lume CLI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo /bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;"><pre>sudo /bin/bash -c <span><span>"</span><span><span>$(</span>curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh<span>)</span></span><span>"</span></span></pre></div>
</li>
<li>
<p dir="auto">Pull the latest macOS CUA image:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lume pull macos-sequoia-cua:latest"><pre>lume pull macos-sequoia-cua:latest</pre></div>
</li>
<li>
<p dir="auto">Start Lume daemon service:</p>

</li>
<li>
<p dir="auto">Install the Python libraries:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install cua-computer cua-agent[all]"><pre>pip install cua-computer cua-agent[all]</pre></div>
</li>
<li>
<p dir="auto">Use the libraries in your Python code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from computer import Computer
from agent import ComputerAgent, LLM, AgentLoop, LLMProvider

async with Computer(verbosity=logging.DEBUG) as macos_computer:
  agent = ComputerAgent(
      computer=macos_computer,
      loop=AgentLoop.OPENAI, # or AgentLoop.ANTHROPIC, or AgentLoop.OMNI
      model=LLM(provider=LLMProvider.OPENAI) # or LLM(provider=LLMProvider.ANTHROPIC)
  )

  tasks = [
      &quot;Look for a repository named trycua/cua on GitHub.&quot;,
  ]

  for task in tasks:
    async for result in agent.run(task):
      print(result)"><pre><span>from</span> <span>computer</span> <span>import</span> <span>Computer</span>
<span>from</span> <span>agent</span> <span>import</span> <span>ComputerAgent</span>, <span>LLM</span>, <span>AgentLoop</span>, <span>LLMProvider</span>

<span>async</span> <span>with</span> <span>Computer</span>(<span>verbosity</span><span>=</span><span>logging</span>.<span>DEBUG</span>) <span>as</span> <span>macos_computer</span>:
  <span>agent</span> <span>=</span> <span>ComputerAgent</span>(
      <span>computer</span><span>=</span><span>macos_computer</span>,
      <span>loop</span><span>=</span><span>AgentLoop</span>.<span>OPENAI</span>, <span># or AgentLoop.ANTHROPIC, or AgentLoop.OMNI</span>
      <span>model</span><span>=</span><span>LLM</span>(<span>provider</span><span>=</span><span>LLMProvider</span>.<span>OPENAI</span>) <span># or LLM(provider=LLMProvider.ANTHROPIC)</span>
  )

  <span>tasks</span> <span>=</span> [
      <span>"Look for a repository named trycua/cua on GitHub."</span>,
  ]

  <span>for</span> <span>task</span> <span>in</span> <span>tasks</span>:
    <span>async</span> <span>for</span> <span>result</span> <span>in</span> <span>agent</span>.<span>run</span>(<span>task</span>):
      <span>print</span>(<span>result</span>)</pre></div>
<p dir="auto">Explore the <a href="https://github.com/trycua/cua/blob/main/notebooks">Agent Notebook</a> for a ready-to-run example.</p>
</li>
<li>
<p dir="auto">Optionally, you can use the Agent with a Gradio UI:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from utils import load_dotenv_files
load_dotenv_files()
 
from agent.ui.gradio.app import create_gradio_ui

app = create_gradio_ui()
app.launch(share=False)"><pre><span>from</span> <span>utils</span> <span>import</span> <span>load_dotenv_files</span>
<span>load_dotenv_files</span>()
 
<span>from</span> <span>agent</span>.<span>ui</span>.<span>gradio</span>.<span>app</span> <span>import</span> <span>create_gradio_ui</span>

<span>app</span> <span>=</span> <span>create_gradio_ui</span>()
<span>app</span>.<span>launch</span>(<span>share</span><span>=</span><span>False</span>)</pre></div>
</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Build from Source (Nightly)</h3><a id="user-content-option-3-build-from-source-nightly" aria-label="Permalink: Option 3: Build from Source (Nightly)" href="#option-3-build-from-source-nightly"></a></p>
<p dir="auto">If you want to contribute to the project or need the latest nightly features:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone https://github.com/trycua/cua.git
cd cua

# Open the project in VSCode
code ./vscode/py.code-workspace

# Build the project
./scripts/build.sh"><pre><span><span>#</span> Clone the repository</span>
git clone https://github.com/trycua/cua.git
<span>cd</span> cua

<span><span>#</span> Open the project in VSCode</span>
code ./vscode/py.code-workspace

<span><span>#</span> Build the project</span>
./scripts/build.sh</pre></div>
<p dir="auto">See our <a href="https://github.com/trycua/cua/blob/main/docs/Developer-Guide.md">Developer-Guide</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Monorepo Libraries</h2><a id="user-content-monorepo-libraries" aria-label="Permalink: Monorepo Libraries" href="#monorepo-libraries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Description</th>
<th>Installation</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md"><strong>Lume</strong></a></td>
<td>CLI for running macOS/Linux VMs with near-native performance using Apple's <code>Virtualization.Framework</code>.</td>
<td><a href="https://github.com/trycua/cua/releases/latest/download/lume.pkg.tar.gz"><img src="https://camo.githubusercontent.com/bfc757e594c3881d25b9fe5be133b6f423c97d586a6be5a8981f598a3795644e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f776e6c6f61642d3333333333333f7374796c653d666f722d7468652d6261646765266c6f676f3d676974687562266c6f676f436f6c6f723d7768697465" alt="Download" data-canonical-src="https://img.shields.io/badge/Download-333333?style=for-the-badge&amp;logo=github&amp;logoColor=white"></a></td>
<td><a href="https://github.com/trycua/cua/releases"><img src="https://camo.githubusercontent.com/28582a8533a2f40c7c0012fa1f85d228b014c5e9f903e956953952ed05bc2575/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f7472796375612f6375613f636f6c6f723d333333333333" alt="GitHub release" data-canonical-src="https://img.shields.io/github/v/release/trycua/cua?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md"><strong>Computer</strong></a></td>
<td>Computer-Use Interface (CUI) framework for interacting with macOS/Linux sandboxes</td>
<td><code>pip install cua-computer</code></td>
<td><a href="https://pypi.org/project/cua-computer/" rel="nofollow"><img src="https://camo.githubusercontent.com/677fa2657fc6a5c02156848fb989e054d665eb63f96b173757fb0c643608ffb6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f6d70757465723f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-computer?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md"><strong>Agent</strong></a></td>
<td>Computer-Use Agent (CUA) framework for running agentic workflows in macOS/Linux dedicated sandboxes</td>
<td><code>pip install cua-agent</code></td>
<td><a href="https://pypi.org/project/cua-agent/" rel="nofollow"><img src="https://camo.githubusercontent.com/7544ebe8fe2cb215318bf3bb083a45506c1a9d11e8bfe36ffd0ac8a22e662081/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d6167656e743f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-agent?color=333333"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docs</h2><a id="user-content-docs" aria-label="Permalink: Docs" href="#docs"></a></p>
<p dir="auto">For the best onboarding experience with the packages in this monorepo, we recommend starting with the <a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md">Computer</a> documentation to cover the core functionality of the Computer sandbox, then exploring the <a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md">Agent</a> documentation to understand Cua's AI agent capabilities, and finally working through the Notebook examples.</p>
<ul dir="auto">
<li><a href="https://github.com/trycua/cua/blob/main/libs/lume/README.md">Lume</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/libs/computer/README.md">Computer</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/libs/agent/README.md">Agent</a></li>
<li><a href="https://github.com/trycua/cua/blob/main/notebooks">Notebooks</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demos</h2><a id="user-content-demos" aria-label="Permalink: Demos" href="#demos"></a></p>
<p dir="auto">Demos of the Computer-Use Agent in action. Share your most impressive demos in Cua's <a href="https://discord.com/invite/mVnXXpdE85" rel="nofollow">Discord community</a>!</p>
<details open="">
<summary><b>MCP Server: Work with Claude Desktop and Tableau </b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description mcp-claude-tableau.mp4">mcp-claude-tableau.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/432513160-9f573547-5149-493e-9a72-396f3cff29df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDMyNTEzMTYwLTlmNTczNTQ3LTUxNDktNDkzZS05YTcyLTM5NmYzY2ZmMjlkZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTg2OGQ1M2FjNjM3ZmQxZjk1NWE4Y2QzMGVkYTljMmY2NWYwOTk0YjczOTNkYjBmMjE1YmMzMWJkODE5MTFkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Dh-OsskAGXJ92uyHEfKr92XExG-IVZ86N6I5eH4I1wU" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/432513160-9f573547-5149-493e-9a72-396f3cff29df.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDMyNTEzMTYwLTlmNTczNTQ3LTUxNDktNDkzZS05YTcyLTM5NmYzY2ZmMjlkZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YTg2OGQ1M2FjNjM3ZmQxZjk1NWE4Y2QzMGVkYTljMmY2NWYwOTk0YjczOTNkYjBmMjE1YmMzMWJkODE5MTFkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.Dh-OsskAGXJ92uyHEfKr92XExG-IVZ86N6I5eH4I1wU" controls="controls" muted="muted">

  </video>
</details>

</p>
<details open="">
<summary><b>AI-Gradio: multi-app workflow requiring browser, VS Code and terminal access</b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description ai-gradio-clone.mp4">ai-gradio-clone.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/423690370-723a115d-1a07-4c8e-b517-88fbdf53ed0f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzNjkwMzcwLTcyM2ExMTVkLTFhMDctNGM4ZS1iNTE3LTg4ZmJkZjUzZWQwZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZjBmNzNkMDE0OTgyMDZmZGZjMGRjNDZkNGJlMzU2NmU2YjcyMGM4YTU2N2M5MTIxMjE4OTk2NjM1YjdjNDcyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.iiuC-O-Lrj2Y_e4SK75ZDJIifv7v5QlPzdo9T43CqP0" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/423690370-723a115d-1a07-4c8e-b517-88fbdf53ed0f.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzNjkwMzcwLTcyM2ExMTVkLTFhMDctNGM4ZS1iNTE3LTg4ZmJkZjUzZWQwZi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03ZjBmNzNkMDE0OTgyMDZmZGZjMGRjNDZkNGJlMzU2NmU2YjcyMGM4YTU2N2M5MTIxMjE4OTk2NjM1YjdjNDcyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.iiuC-O-Lrj2Y_e4SK75ZDJIifv7v5QlPzdo9T43CqP0" controls="controls" muted="muted">

  </video>
</details>

</p>
</details>
<details open="">
<summary><b>Notebook: Fix GitHub issue in Cursor</b></summary>

<p dir="auto">
    <details open="">
  <summary>
    
    <span aria-label="Video description notebook-github-cursor.mp4">notebook-github-cursor.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/195596869/423227709-f67f0107-a1e1-46dc-aa9f-0146eb077077.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzMjI3NzA5LWY2N2YwMTA3LWExZTEtNDZkYy1hYTlmLTAxNDZlYjA3NzA3Ny5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NGIxNDZhZmM1YjIxN2ZlMzdjMjg3YjljZjdiOWIxNjE2NWRmZGVjY2NkZWJkNzgzODA4YWJjMGU0MjQwZGVmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.GyYBYPMvfGNKj3S0TXUOpcNTinf195RFQjMD110-XLM" data-canonical-src="https://private-user-images.githubusercontent.com/195596869/423227709-f67f0107-a1e1-46dc-aa9f-0146eb077077.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDU0NTg1MDIsIm5iZiI6MTc0NTQ1ODIwMiwicGF0aCI6Ii8xOTU1OTY4NjkvNDIzMjI3NzA5LWY2N2YwMTA3LWExZTEtNDZkYy1hYTlmLTAxNDZlYjA3NzA3Ny5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNDI0JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDQyNFQwMTMwMDJaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT05NGIxNDZhZmM1YjIxN2ZlMzdjMjg3YjljZjdiOWIxNjE2NWRmZGVjY2NkZWJkNzgzODA4YWJjMGU0MjQwZGVmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.GyYBYPMvfGNKj3S0TXUOpcNTinf195RFQjMD110-XLM" controls="controls" muted="muted">

  </video>
</details>

</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Accessory Libraries</h2><a id="user-content-accessory-libraries" aria-label="Permalink: Accessory Libraries" href="#accessory-libraries"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Description</th>
<th>Installation</th>
<th>Version</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/core/README.md"><strong>Core</strong></a></td>
<td>Core functionality and utilities used by other Cua packages</td>
<td><code>pip install cua-core</code></td>
<td><a href="https://pypi.org/project/cua-core/" rel="nofollow"><img src="https://camo.githubusercontent.com/78e19e4d4807aff22db19c4a99319d0cf4173d57bd12aeabf4f8875d2ffa6e11/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f72653f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-core?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/pylume/README.md"><strong>PyLume</strong></a></td>
<td>Python bindings for Lume</td>
<td><code>pip install pylume</code></td>
<td><a href="https://pypi.org/project/pylume/" rel="nofollow"><img src="https://camo.githubusercontent.com/dc81f8cd99d66b602c71a01fa76382a22ca11ab56e576a8e3f46543306d1fea3/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f70796c756d653f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/pylume?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/computer-server/README.md"><strong>Computer Server</strong></a></td>
<td>Server component for the Computer-Use Interface (CUI) framework</td>
<td><code>pip install cua-computer-server</code></td>
<td><a href="https://pypi.org/project/cua-computer-server/" rel="nofollow"><img src="https://camo.githubusercontent.com/99568cb5aaf982926609b01d71d3fec021d82afebb220076e360fd2cec3fb08a/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d636f6d70757465722d7365727665723f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-computer-server?color=333333"></a></td>
</tr>
<tr>
<td><a href="https://github.com/trycua/cua/blob/main/libs/som/README.md"><strong>SOM</strong></a></td>
<td>Self-of-Mark library for Agent</td>
<td><code>pip install cua-som</code></td>
<td><a href="https://pypi.org/project/cua-som/" rel="nofollow"><img src="https://camo.githubusercontent.com/c49bae7797b2df0a453cf939a349436b9a8733afa3621322efa1a5eb56017e8c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6375612d736f6d3f636f6c6f723d333333333333" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/cua-som?color=333333"></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome and greatly appreciate contributions to Cua! Whether you're improving documentation, adding new features, fixing bugs, or adding new VM images, your efforts help make lume better for everyone. For detailed instructions on how to contribute, please refer to our <a href="https://github.com/trycua/cua/blob/main/CONTRIBUTING.md">Contributing Guidelines</a>.</p>
<p dir="auto">Join our <a href="https://discord.com/invite/mVnXXpdE85" rel="nofollow">Discord community</a> to discuss ideas or get assistance.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Cua is open-sourced under the MIT License - see the <a href="https://github.com/trycua/cua/blob/main/LICENSE">LICENSE</a> file for details.</p>
<p dir="auto">Microsoft's OmniParser, which is used in this project, is licensed under the Creative Commons Attribution 4.0 International License (CC-BY-4.0) - see the <a href="https://github.com/microsoft/OmniParser/blob/master/LICENSE">OmniParser LICENSE</a> file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Trademarks</h2><a id="user-content-trademarks" aria-label="Permalink: Trademarks" href="#trademarks"></a></p>
<p dir="auto">Apple, macOS, and Apple Silicon are trademarks of Apple Inc. Ubuntu and Canonical are registered trademarks of Canonical Ltd. Microsoft is a registered trademark of Microsoft Corporation. This project is not affiliated with, endorsed by, or sponsored by Apple Inc., Canonical Ltd., or Microsoft Corporation.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Stargazers over time</h2><a id="user-content-stargazers-over-time" aria-label="Permalink: Stargazers over time" href="#stargazers-over-time"></a></p>
<p dir="auto"><a href="https://starchart.cc/trycua/cua" rel="nofollow"><img src="https://camo.githubusercontent.com/0803bde0e4d80af5fd0b5651fd66e8f3929f576b783654b91e338d2b4ffd3aa4/68747470733a2f2f7374617263686172742e63632f7472796375612f6375612e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/trycua/cua.svg?variant=adaptive"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>



<markdown-accessiblity-table><table>
  <tbody>
    <tr>
      <td><a href="https://github.com/f-trycua"><img src="https://avatars.githubusercontent.com/u/195596869?v=4?s=100" width="100px;" alt="f-trycua"><br><sub><b>f-trycua</b></sub></a><br><a href="#code-f-trycua" title="Code">💻</a></td>
      <td><a href="http://pepicrft.me/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/663605?v=4?s=100" width="100px;" alt="Pedro Piñera Buendía"><br><sub><b>Pedro Piñera Buendía</b></sub></a><br><a href="#code-pepicrft" title="Code">💻</a></td>
      <td><a href="https://iamit.in/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/5647941?v=4?s=100" width="100px;" alt="Amit Kumar"><br><sub><b>Amit Kumar</b></sub></a><br><a href="#code-aktech" title="Code">💻</a></td>
      <td><a href="https://productsway.com/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/870029?v=4?s=100" width="100px;" alt="Dung Duc Huynh (Kaka)"><br><sub><b>Dung Duc Huynh (Kaka)</b></sub></a><br><a href="#code-jellydn" title="Code">💻</a></td>
      <td><a href="http://zaydkrunz.com/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/70227235?v=4?s=100" width="100px;" alt="Zayd Krunz"><br><sub><b>Zayd Krunz</b></sub></a><br><a href="#code-ShrootBuck" title="Code">💻</a></td>
      <td><a href="https://github.com/PrashantRaj18198"><img src="https://avatars.githubusercontent.com/u/23168997?v=4?s=100" width="100px;" alt="Prashant Raj"><br><sub><b>Prashant Raj</b></sub></a><br><a href="#code-PrashantRaj18198" title="Code">💻</a></td>
      <td><a href="https://www.mobile.dev/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/847683?v=4?s=100" width="100px;" alt="Leland Takamine"><br><sub><b>Leland Takamine</b></sub></a><br><a href="#code-Leland-Takamine" title="Code">💻</a></td>
    </tr>
    <tr>
      <td><a href="https://github.com/ddupont808"><img src="https://avatars.githubusercontent.com/u/3820588?v=4?s=100" width="100px;" alt="ddupont"><br><sub><b>ddupont</b></sub></a><br><a href="#code-ddupont808" title="Code">💻</a></td>
      <td><a href="https://github.com/Lizzard1123"><img src="https://avatars.githubusercontent.com/u/46036335?v=4?s=100" width="100px;" alt="Ethan Gutierrez"><br><sub><b>Ethan Gutierrez</b></sub></a><br><a href="#code-Lizzard1123" title="Code">💻</a></td>
      <td><a href="https://ricterz.me/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/5282759?v=4?s=100" width="100px;" alt="Ricter Zheng"><br><sub><b>Ricter Zheng</b></sub></a><br><a href="#code-RicterZ" title="Code">💻</a></td>
      <td><a href="https://www.trytruffle.ai/" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/50844303?v=4?s=100" width="100px;" alt="Rahul Karajgikar"><br><sub><b>Rahul Karajgikar</b></sub></a><br><a href="#code-rahulkarajgikar" title="Code">💻</a></td>
      <td><a href="https://github.com/trospix"><img src="https://avatars.githubusercontent.com/u/81363696?v=4?s=100" width="100px;" alt="trospix"><br><sub><b>trospix</b></sub></a><br><a href="#code-trospix" title="Code">💻</a></td>
      <td><a href="https://wavee.world/invitation/b96d00e6-b802-4a1b-8a66-2e3854a01ffd" rel="nofollow"><img src="https://avatars.githubusercontent.com/u/22633385?v=4?s=100" width="100px;" alt="Ikko Eltociear Ashimine"><br><sub><b>Ikko Eltociear Ashimine</b></sub></a><br><a href="#code-eltociear" title="Code">💻</a></td>
    </tr>
  </tbody>
</table></markdown-accessiblity-table>



</details></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a 20 year old bug in GTA San Andreas surfaced in Windows 11 24H2 (1066 pts)]]></title>
            <link>https://cookieplmonster.github.io/2025/04/23/gta-san-andreas-win11-24h2-bug/</link>
            <guid>43772311</guid>
            <pubDate>Wed, 23 Apr 2025 14:00:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cookieplmonster.github.io/2025/04/23/gta-san-andreas-win11-24h2-bug/">https://cookieplmonster.github.io/2025/04/23/gta-san-andreas-win11-24h2-bug/</a>, See on <a href="https://news.ycombinator.com/item?id=43772311">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
  <header id="main">
    <div>
      
      <p>April 23, 2025</p>
      <p>14 min. to read</p>
    </div>
  </header>
  <section>
    
      <ul id="markdown-toc">
  <li><a href="#introduction" id="markdown-toc-introduction">Introduction</a></li>
  <li><a href="#investigating-the-bug" id="markdown-toc-investigating-the-bug">Investigating the bug</a>    <ul>
      <li><a href="#what-is-broken" id="markdown-toc-what-is-broken">What is broken?</a></li>
      <li><a href="#but-why-and-how" id="markdown-toc-but-why-and-how">But why and how?</a></li>
    </ul>
  </li>
  <li><a href="#here-be-dragons--the-true-root-cause" id="markdown-toc-here-be-dragons--the-true-root-cause">Here be dragons – the true root cause</a>    <ul>
      <li><a href="#diving-deeper" id="markdown-toc-diving-deeper">Diving deeper</a></li>
      <li><a href="#whose-stack-is-it-anyway" id="markdown-toc-whose-stack-is-it-anyway">Whose Stack Is It Anyway?</a></li>
      <li><a href="#what-are-the-odds-this-only-broke-now-darn-windows-11" id="markdown-toc-what-are-the-odds-this-only-broke-now-darn-windows-11">What are the odds this only broke now? Darn Windows 11!</a></li>
    </ul>
  </li>
  <li><a href="#i-want-this-fixed-in-my-game" id="markdown-toc-i-want-this-fixed-in-my-game">I want this fixed in my game!</a></li>
  <li><a href="#final-word" id="markdown-toc-final-word">Final word</a></li>
</ul>
<h2 id="introduction">
  
  
    Introduction <a href="#introduction"></a>
  
  
</h2>
    

<p>On the <a href="https://github.com/CookiePLMonster/SilentPatch/issues/172" target="_blank">SilentPatch GitHub issue tracker</a>,
I received a rather specific bug report:</p>

<blockquote>
<h3 id="skimmer-airplane-doesnt-exist-in-windows-11-24h2">
  
  
    Skimmer airplane doesn’t exist in Windows 11 24H2
  
  
</h3>
    

  <p>When I upgraded my windows to version 24H2, the Skimmer plane disappear completely from the game.
It can’t be spawn using trainer nor it can’t be found anywhere on it’s normal spawn points.
I’m using both my modded copy (which is before the update, is completely fine) and vanilla copy with only silentpatch
(I tried the 2018, 2020 and the most recent version of silentpatch) and the plane still won’t exist.</p>
</blockquote>

<p>If this was the first time I had heard about it, I’d likely consider it dubious and suspect there are more things at play,
and it’s not specifically Windows 11 24H2. However, on GTAForums, I’ve been receiving comments about this exact issue since November last year.
Some of them said SilentPatch causes this issue, others however stated the same happens on a completely unmodded game:</p>

<blockquote>
  <p>Apparently the skimmer cant spawn when playing on Windows 11 24h2 update, hope this bug gets fixed.</p>

  <p>EDIT: So I think I confirmed it, I set up a VM with Windows 11 23h2 and the damn plane spawns fine,
and updating that same VM to 24h2 breaks the skimmer, why would a small feature update in 2024 break a random plane in a 2005 game is anyone’s guess.</p>
</blockquote>

<blockquote>
  <p>After the latest Silent patch update there is no Skimmer in the game and when I try to spawn it with RZL-Trainer or Cheat Menu by Grinch,
the game freezes and I have to close it via Task Manager.</p>
</blockquote>

<blockquote>
  <p>[…] I was forced to update to 24H2, and now after the update, I have the same problem with the Skimmer in GTA SA as others.
This means that mods or anything else are not causing the issue, the problem appeared after the latest Windows update.</p>
</blockquote><hr>

<p>My home PC is still on Windows 10 22H2, while my work machine is on Windows 11 23H2, and, to no surprise, neither machine reproduced the issue – Skimmer spawned
on the water just fine, creating one via script and putting CJ in a driver’s seat worked too.</p>

<p>That said, I also asked a few people who upgraded to 24H2 to test this on their machines and they <strong>all</strong> hit this bug. Attempts to debug “remotely”
by giving instructions over the chat didn’t go anywhere, so I set up a 24H2 virtual machine on my own. I copied the game over to the machine, set it up for remote
debugging from the host OS, headed to the usual place the Skimmer spawns, and sure enough, it wasn’t there. All other planes and boats still spawned fine,
only this one vehicle did not:</p>

<figure>
<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_SqUlKDKCRs.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_SqUlKDKCRs.jpg" alt="" width="1024" height="576"></a><figcaption>Skimmer is gone.</figcaption></figure>

<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_qnldPBAKRl.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_qnldPBAKRl.jpg" alt="" width="1024" height="576"></a><figcaption>Other planes are still here, though.</figcaption></figure>

</figure>

<p>I then used the script to spawn a Skimmer and put CJ inside it, just to be launched
<code>1.0287648030984853e+0031</code> = <strong>10.3 nonillion meters</strong>, or <strong>10.3 octillion kilometers</strong>, or <strong>1.087 quadrillion light-years</strong> up in the sky 😆</p>

<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_5KOLUPPHLe.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_5KOLUPPHLe.jpg" alt="" width="1024" height="576"></a><figcaption>Scientists claim to have discovered a ‘new color’ no one has seen before.</figcaption></figure>

<p>With SilentPatch installed, the game freezes shortly after launching the player up, as the game code gets stuck in a loop.
Without SilentPatch, the game doesn’t freeze, but instead, it succumbs to a famous “burn-in effect” known to occur when the camera gets launched into infinity or close to it.
Funny enough, you can still kind of make out the shape of the plane even though the animations give up completely to the inaccuracies of the floating point values:</p>

<figure>
<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_GXULFRni6Y.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_GXULFRni6Y.jpg" alt="" width="1024" height="576"></a></figure>

<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_qQUqnmyhV6.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_qQUqnmyhV6.jpg" alt="" width="1024" height="576"></a></figure>

</figure>
<h2 id="investigating-the-bug">
  
  
    Investigating the bug <a href="#investigating-the-bug"></a>
  
  
</h2>
    
<h2 id="what-is-broken">
  
  
    What is broken? <a href="#what-is-broken"></a>
  
  
</h2>
    

<p>But, enough messing around; now I knew it was a real bug and I needed to figure out the root cause. At this point it wasn’t possible to say
whether the game was at fault, or if I was really dealing with an API bug introduced in 24H2, as looking at how many games have issues with this OS version,
it could go either way.</p>

<p>I didn’t have much to go with, but the fact the game froze with SilentPatch installed provided me with a good starting point. Upon entering the seaplane,
the game froze in a very small loop in <code>CPlane::PreRender</code>, attempting to normalize the rotor blade angle to the 0-360 degree range:</p>

<div><pre><code><span>this</span><span>-&gt;</span><span>m_fBladeAngle</span> <span>=</span> <span>CTimer</span><span>::</span><span>ms_fTimeStep</span> <span>*</span> <span>this</span><span>-&gt;</span><span>m_fBladeSpeed</span> <span>+</span> <span>this</span><span>-&gt;</span><span>m_fBladeAngle</span><span>;</span>
<span>while</span> <span>(</span><span>v12</span> <span>&gt;</span> <span>6.2831855</span><span>)</span>
<span>{</span>
  <span>this</span><span>-&gt;</span><span>m_fBladeAngle</span> <span>=</span> <span>this</span><span>-&gt;</span><span>m_fBladeAngle</span> <span>-</span> <span>6.2831855</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>In the debugged session, <code>this-&gt;m_fBladeSpeed</code> was <code>3.73340132e+29</code>. This value is obviously enormous, big enough to make decrementing the value by <code>6.2831855</code>
entirely ineffective due to the difference in floating point exponents of these two values.<sup id="fnref:fp-explanation" role="doc-noteref"><a href="#fn:fp-explanation" rel="footnote">1</a></sup> But why is the blade speed so ridiculously high?
The blade speed is derived from the following formula:</p>
<div><pre><code><span>this</span><span>-&gt;</span><span>m_fBladeSpeed</span> <span>=</span> <span>(</span><span>v34</span> <span>-</span> <span>this</span><span>-&gt;</span><span>m_fBladeSpeed</span><span>)</span> <span>*</span> <span>CTimer</span><span>::</span><span>ms_fTimeStep</span> <span>/</span> <span>100.0</span> <span>+</span> <span>this</span><span>-&gt;</span><span>m_fBladeSpeed</span><span>;</span>
</code></pre></div>

<p>where <code>v34</code> is <strong>proportional to the plane’s altitude</strong>. This matches the initial findings – as mentioned earlier, the “burn-in effect” traditionally happens
when the camera is very far away from the map center, or at a great height.</p>

<p>What caused the plane to shoot so high up? There are two possibilities:</p>
<ol>
  <li>The plane spawns high up in the sky already.</li>
  <li>The plane spawns at ground level and then shoots up in the next frame.</li>
</ol>

<p>As for this test, I was spawning the Skimmer myself with a test script, so I could start from the function used in the game’s SCM (script) interpreter,
named <code>CCarCtrl::CreateCarForScript</code>. This function spawns a vehicle with a specified ID at the provided coordinates, and those come from my test script,
so I know they are correct. However, this function transforms the supplied Z coordinate slightly:</p>

<div><pre><code><span>if</span> <span>(</span><span>posZ</span> <span>&lt;=</span> <span>100.0</span><span>)</span>
<span>{</span>
  <span>posZ</span> <span>=</span> <span>CWorld</span><span>::</span><span>FindGroundZForCoord</span><span>(</span><span>posX</span><span>,</span> <span>posY</span><span>);</span>
<span>}</span>
<span>posZ</span> <span>+=</span> <span>newVehicle</span><span>-&gt;</span><span>GetDistanceFromCentreOfMassToBaseOfModel</span><span>();</span>
</code></pre></div>

<p><code>CEntity::GetDistanceFromCentreOfMassToBaseOfModel</code> contains multiple code paths, but the one used in this case simply gets the negated maximum Z value
of the model’s bounding box:</p>
<div><pre><code><span>return</span> <span>-</span><span>CModelInfo</span><span>::</span><span>ms_modelInfoPtrs</span><span>[</span><span>this</span><span>-&gt;</span><span>m_wModelIndex</span><span>]</span><span>-&gt;</span><span>pColModel</span><span>-&gt;</span><span>bbox</span><span>.</span><span>sup</span><span>.</span><span>z</span><span>;</span>
</code></pre></div>

<p>At this point, I expected this value to be incorrect, so I peeked into Skimmer’s bounding box values just to find out that the maximum Z value is indeed corrupted:</p>

<div><pre><code>- *(RwBBox**)0x00B2AC48	RwBBox *
  - sup	RwV3d
      x	-5.39924574	float
      y	-6.77431822	float
      z	-4.30747210e+33	float
  - inf	RwV3d
      x	5.42313004	float
      y	4.02343750	float
      z	1.87021971	float
</code></pre></div>

<p>If all the components of the bounding box were corrupted, I would have suspected some memory corruption, like another code writing past boundaries and overwriting
these values, but it’s specifically <code>sup.z</code> that is corrupted that is neither the first nor the last field in the bounding box. Once again, two possibilities came to my mind:</p>
<ol>
  <li>The collision file is read incorrectly and some fields remain uninitialized, or read unrelated data instead of the bounding box? Highly unlikely, but not impossible given that
  this issue could potentially have been an OS bug.</li>
  <li>The bounding box is read correctly, but then it’s updated with an outrageously incorrect value.</li>
</ol>

<p>A data breakpoint set up at <code>pColModel</code> reveals that at the time of the initial setup, the bounding box is correct, and the value of the Z coordinate is completely reasonable:</p>
<div><pre><code>- *(RwBBox**)0x00B2AC48	RwBBox *
  - sup	RwV3d
    x	-5.39924574	float
    y	-6.77431822	float
    z	-2.21952772	float
  - inf	RwV3d
    x	5.42313004	float
    y	4.02343750	float
    z	1.87021971	float
</code></pre></div>

<p>Turns out, the first time a vehicle with a specific model is spawned, the game sets up the suspension in a function <code>SetupSuspensionLines</code>, and updates the Z coordinate
of the bounding box to reflect the car’s natural suspension height:</p>
<div><pre><code><span>if</span> <span>(</span><span>pSuspensionLines</span><span>[</span><span>0</span><span>].</span><span>p1</span><span>.</span><span>z</span> <span>&lt;</span> <span>colModel</span><span>-&gt;</span><span>bbox</span><span>.</span><span>sup</span><span>.</span><span>z</span><span>)</span>
<span>{</span>
  <span>colModel</span><span>-&gt;</span><span>bbox</span><span>.</span><span>sup</span><span>.</span><span>z</span> <span>=</span> <span>pSuspensionLines</span><span>[</span><span>0</span><span>].</span><span>p1</span><span>.</span><span>z</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>This is where things went wrong first. The suspension lines are computed using a combination of values from <code>handling.cfg</code> and the wheel scale parameter
coming from <code>vehicles.ide</code>:</p>
<div><pre><code><span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>4</span><span>;</span> <span>i</span><span>++</span><span>)</span>
<span>{</span>
  <span>CVector</span> <span>posn</span><span>;</span>
  <span>modelInfo</span><span>-&gt;</span><span>GetWheelPosn</span><span>(</span><span>i</span><span>,</span> <span>posn</span><span>);</span>

  <span>posn</span><span>.</span><span>z</span> <span>+=</span> <span>pHandling</span><span>-&gt;</span><span>fSuspensionUpperLimit</span><span>;</span>
  <span>colModel</span><span>-&gt;</span><span>lines</span><span>[</span><span>i</span><span>].</span><span>p0</span> <span>=</span> <span>posn</span><span>;</span>

  <span>float</span> <span>wheelScale</span> <span>=</span> <span>i</span> <span>!=</span> <span>0</span> <span>&amp;&amp;</span> <span>i</span> <span>!=</span> <span>2</span> <span>?</span> <span>modelInfo</span><span>-&gt;</span><span>m_frontWheelScale</span> <span>:</span> <span>modelInfo</span><span>-&gt;</span><span>m_rearWheelScale</span><span>;</span>

  <span>posn</span><span>.</span><span>z</span> <span>+=</span> <span>pHandling</span><span>-&gt;</span><span>fSuspensionLowerLimit</span> <span>-</span> <span>pHandling</span><span>-&gt;</span><span>fSuspensionUpperLimit</span><span>;</span>
  <span>posn</span><span>.</span><span>z</span> <span>-=</span> <span>wheelScale</span> <span>/</span> <span>2.0</span><span>;</span>
  <span>colModel</span><span>-&gt;</span><span>lines</span><span>[</span><span>i</span><span>].</span><span>p1</span> <span>=</span> <span>posn</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>Since I knew <code>colModel-&gt;lines[0].p1</code> is corrupted, this meant either <code>pHandling-&gt;fSuspensionLowerLimit</code>, <code>pHandling-&gt;fSuspensionUpperLimit</code>, or <code>wheelScale</code> were bogus.
Skimmer’s <code>handling.cfg</code> values didn’t seem any different to any other plane in the game, but then I spotted something interesting in <code>vehicles.ide</code>. Skimmer’s line looks like this:</p>
<div><pre><code>460, 	skimmer,	skimmer, 	plane,		SEAPLANE,	SKIMMER,	null,	ignore,		5,	0,	0
</code></pre></div>

<p>Compare this line to any other plane in the game, in this example Rustler:</p>
<div><pre><code>476, 	rustler, 	rustler, 	plane, 		RUSTLER, 	RUSTLER,	rustler, ignore,		10,	0,	0,		-1, 0.6, 0.3,		-1
</code></pre></div>

<p>The line is shorter and it’s missing the last four parameters, moreover, <strong>two of the missing parameters are the front and rear wheel scale!</strong>
This is normal for boats, but Skimmer is <strong>the only</strong> plane to omit these parameters.</p>

<p>Does re-adding those parameters fix the seaplane? Unsurprisingly, it does!</p>

<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/gta_sa_3hbE1KfRUe.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/screens/thumb/gta_sa_3hbE1KfRUe.jpg" alt="" width="1024" height="576"></a></figure>
<h2 id="but-why-and-how">
  
  
    But why and how? <a href="#but-why-and-how"></a>
  
  
</h2>
    

<p>I have a likely explanation for why Rockstar made this specific mistake in the data to begin with – in Vice City, Skimmer was defined as a <strong>boat</strong>,
and therefore did not have those values defined by design!
When in San Andreas they changed Skimmer’s vehicle type to a <strong>plane</strong>, someone forgot to add those now-required extra parameters.
Since this game seldom verifies the completeness of its data, this mistake simply slipped under the radar.</p>

<p>Problem solved? Not quite yet, as for SilentPatch, I need to fix it from the code. A peek into the pseudocode of <code>CFileLoader::LoadVehicleObject</code>
reveals the true nature of this bug: the game assumes all parameters are always present in the definition line and it doesn’t default any but two parameters,
nor it checks the return value of <code>sscanf</code>, and so in the case of all boats and Skimmer, those parameters remained uninitialized:</p>
<div><pre><code><span>void</span> <span>CFileLoader</span><span>::</span><span>LoadVehicleObject</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>line</span><span>)</span>
<span>{</span>
  <span>int</span> <span>objID</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
  <span>char</span> <span>modelName</span><span>[</span><span>24</span><span>];</span>
  <span>char</span> <span>texName</span><span>[</span><span>24</span><span>];</span>
  <span>char</span> <span>type</span><span>[</span><span>8</span><span>];</span>
  <span>char</span> <span>handlingID</span><span>[</span><span>16</span><span>];</span>
  <span>char</span> <span>gameName</span><span>[</span><span>32</span><span>];</span>
  <span>char</span> <span>anims</span><span>[</span><span>16</span><span>];</span>
  <span>char</span> <span>vehClass</span><span>[</span><span>16</span><span>];</span>
  <span>int</span> <span>frq</span><span>;</span>
  <span>int</span> <span>flags</span><span>;</span>
  <span>int</span> <span>comprules</span><span>;</span>
  <span>int</span> <span>wheelModelID</span><span>;</span> <span>// Uninitialized!</span>
  <span>float</span> <span>frontWheelScale</span><span>,</span> <span>rearWheelScale</span><span>;</span> <span>// Uninitialized!</span>
  <span>int</span> <span>wheelUpgradeClass</span> <span>=</span> <span>-</span><span>1</span><span>;</span> <span>// Funny enough, this one IS initialized</span>

  <span>int</span> <span>TxdSlot</span> <span>=</span> <span>CTxdStore</span><span>::</span><span>FindTxdSlot</span><span>(</span><span>"vehicle"</span><span>);</span>
  <span>if</span> <span>(</span><span>TxdSlot</span> <span>==</span> <span>-</span><span>1</span><span>)</span>
  <span>{</span>
    <span>TxdSlot</span> <span>=</span> <span>CTxdStore</span><span>::</span><span>AddTxdSlot</span><span>(</span><span>"vehicle"</span><span>);</span>
  <span>}</span>
  <span>sscanf</span><span>(</span><span>line</span><span>,</span> <span>"%d %s %s %s %s %s %s %s %d %d %x %d %f %f %d"</span><span>,</span> <span>&amp;</span><span>objID</span><span>,</span> <span>modelName</span><span>,</span> <span>texName</span><span>,</span> <span>type</span><span>,</span> <span>handlingID</span><span>,</span>
        <span>gameName</span><span>,</span> <span>anims</span><span>,</span> <span>vehClass</span><span>,</span> <span>&amp;</span><span>frq</span><span>,</span> <span>&amp;</span><span>flags</span><span>,</span> <span>&amp;</span><span>comprules</span><span>,</span> <span>&amp;</span><span>wheelModelID</span><span>,</span> <span>&amp;</span><span>frontWheelScale</span><span>,</span> <span>&amp;</span><span>rearWheelScale</span><span>,</span>
        <span>&amp;</span><span>wheelUpgradeClass</span><span>);</span>

  <span>// More processing here...</span>
<span>}</span>
</code></pre></div>

<p>Given the symptoms, those uninitialized values must have evaluated to small, valid floating point values all the way until now,
whereas with Windows 11 24H2 they got out of hand and tripped the bounding box calculations.</p>

<p>In SilentPatch, the fix is easy – I wrap this call to <code>sscanf</code> and provide reasonable defaults for the final four parameters:</p>
<div><pre><code><span>static</span> <span>int</span> <span>(</span><span>*</span><span>orgSscanf</span><span>)(</span><span>const</span> <span>char</span><span>*</span> <span>s</span><span>,</span> <span>const</span> <span>char</span><span>*</span> <span>format</span><span>,</span> <span>...);</span>
<span>static</span> <span>int</span> <span>sscanf_Defaults</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>s</span><span>,</span> <span>const</span> <span>char</span><span>*</span> <span>format</span><span>,</span> <span>int</span><span>*</span> <span>objID</span><span>,</span> <span>char</span><span>*</span> <span>modelName</span><span>,</span> <span>char</span><span>*</span> <span>texName</span><span>,</span> <span>char</span><span>*</span> <span>type</span><span>,</span>
      <span>char</span><span>*</span> <span>handlingID</span><span>,</span> <span>char</span><span>*</span> <span>gameName</span><span>,</span> <span>char</span><span>*</span> <span>anims</span><span>,</span> <span>char</span><span>*</span> <span>vehClass</span><span>,</span> <span>int</span><span>*</span> <span>frequency</span><span>,</span> <span>int</span><span>*</span> <span>flags</span><span>,</span> <span>int</span><span>*</span> <span>comprules</span><span>,</span>
      <span>int</span><span>*</span> <span>wheelModelID</span><span>,</span> <span>float</span><span>*</span> <span>frontWheelSize</span><span>,</span> <span>float</span><span>*</span> <span>rearWheelSize</span><span>,</span> <span>int</span><span>*</span> <span>wheelUpgradeClass</span><span>)</span>
<span>{</span>
  <span>*</span><span>wheelModelID</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
  <span>// Why 0.7 and not 1.0, I'll explain later</span>
  <span>*</span><span>frontWheelSize</span> <span>=</span> <span>0.7</span><span>;</span>
  <span>*</span><span>rearWheelSize</span> <span>=</span> <span>0.7</span><span>;</span>
  <span>*</span><span>wheelUpgradeClass</span> <span>=</span> <span>-</span><span>1</span><span>;</span>

  <span>return</span> <span>orgSscanf</span><span>(</span><span>s</span><span>,</span> <span>format</span><span>,</span> <span>objID</span><span>,</span> <span>modelName</span><span>,</span> <span>texName</span><span>,</span> <span>type</span><span>,</span> <span>handlingID</span><span>,</span> <span>gameName</span><span>,</span> <span>anims</span><span>,</span> <span>vehClass</span><span>,</span>
                  <span>frequency</span><span>,</span> <span>flags</span><span>,</span> <span>comprules</span><span>,</span> <span>wheelModelID</span><span>,</span> <span>frontWheelSize</span><span>,</span> <span>rearWheelSize</span><span>,</span> <span>wheelUpgradeClass</span><span>);</span>
<span>}</span>
</code></pre></div>

<p><a href="https://github.com/CookiePLMonster/SilentPatch/commit/881aded7237067202025934796cc2313104cba8c" target="_blank">Fixed!</a>
Another compatibility win for the patch.</p><hr>

<p>If this was a regular bug, I would’ve ended the post right here. However, in the case of this rabbit hole, the discovery of this fix only
raised more questions – why did this break only now? What made the game work fine despite of this issue for over twenty years,
before a new update to Windows 11 suddenly challenged this status quo?</p>

<p><strong>Finally, is this somehow caused by a problem in Windows 11 24H2, or is this just an unfortunate coincidence, stars aligning just right?</strong></p>
<h2 id="here-be-dragons--the-true-root-cause">
  
  
    Here be dragons – the true root cause <a href="#here-be-dragons--the-true-root-cause"></a>
  
  
</h2>
    
<h2 id="diving-deeper">
  
  
    Diving deeper <a href="#diving-deeper"></a>
  
  
</h2>
    

<p>At this point, the working theory was that the uninitialized local variables in <code>CFileLoader::LoadVehicleObject</code>
happened to have reasonable values until <em>something</em> changed in Windows 11 24H2, and those values became “unreasonable”.
What I knew could <strong>not</strong> be the cause was the CRT (and thus, the <code>sscanf</code> call) – San Andreas uses a statically compiled CRT,
and therefore any OS-level hotfixes wouldn’t apply to it.
However, considering the plethora of security enhancements in Windows 11, I couldn’t rule out that one of those enhancements,
for example, <strong>Kernel-mode Hardware-enforced Stack Protection</strong>, ends up scrambling the stack in a way the game’s bugged function doesn’t like.</p>

<p>I set up an experiment where I broke into a debugger before a <code>sscanf</code> call when parsing Skimmer’s line (vehicle ID 460) specifically,
and the observed variable values supported that claim. On my Windows 10 machine, they happened to be both <code>0.7</code>:</p>
<div><pre><code>frontWheelSize  0x01779f14 {0.699999988}
rearWheelSize   0x01779f10 {0.699999988}
</code></pre></div>
<p>while on the Win11 24H2 VM, they are huge, similar in order of magnitude to the wrong values observed in the bounding box earlier.
The stack pointer has also shifted by 4 bytes for some reason, but that is unlikely to be related – and it’s likely caused by some changes
to the thread startup boilerplate inside <code>kernel32.dll</code>:</p>
<div><pre><code>frontWheelSize  0x01779f18 {7.84421263e+33}
rearWheelSize   0x01779f14 {4.54809690e-38}
</code></pre></div>

<p>This got me curious - <code>0.7</code> is a bit “too good” of a value to be a result of interpreting random garbage from the stack as a floating point;
what’s more likely is that it’s an actual floating point value that was sitting on the stack in exactly the right spot.
I then inspected <code>vehicles.ide</code> for TopFun – the vehicle defined directly before Skimmer. Sure enough, its wheel scale is <code>0.7</code>!</p>
<div><pre><code>459,	topfun,		topfun,		car,		TOPFUN,		TOPFUN,		van,	ignore,		1,	0,	0,		-1, 0.7, 0.7,		-1
</code></pre></div>

<p><code>vehicles.ide</code> is parsed in order, in a function working similarly to this (pseudocode):</p>
<div><pre><code><span>void</span> <span>CFileLoader</span><span>::</span><span>LoadObjectTypes</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>filename</span><span>)</span>
<span>{</span>
  <span>// Open the file...</span>

  <span>while</span> <span>((</span><span>line</span> <span>=</span> <span>fgets</span><span>(</span><span>file</span><span>))</span> <span>!=</span> <span>NULL</span><span>)</span>
  <span>{</span>
    <span>// Parse the section indicators...</span>
    <span>switch</span> <span>(</span><span>section</span><span>)</span>
    <span>{</span>
      <span>// Different sections...</span>
    <span>case</span> <span>SECTION_CARS</span><span>:</span>
      <span>LoadVehicleObject</span><span>(</span><span>line</span><span>);</span>
      <span>break</span><span>;</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div>

<p>Seems like the code somehow persisted the stale wheel scale values, so Skimmer ends up getting the same wheel scales as Topfun.
I set up another experiment to verify this claim:</p>
<ol>
  <li>Set up a breakpoint before <code>sscanf</code> again, but this time before Topfun’s line (vehicle ID 459) gets parsed.</li>
  <li>Set up write breakpoints on <code>frontWheelScale</code> and <code>rearWheelScale</code>.</li>
  <li>Resume execution until the game gets to parsing the next vehicle definition.</li>
</ol>

<p>Windows 10 verified my claim – <strong>nothing wrote to these two stack values between the calls to <code>CFileLoader::LoadVehicleObject</code>,
so the function’s effective behavior was to preserve (albeit, unintentionally) the wheel scale values between the consecutive calls!</strong></p>

<p>Repeating the same exercise on Windows 11 24H2 triggered the write breakpoint! However, it wasn’t anywhere close to any security feature:
the stack values were overwritten by… <code>LeaveCriticalSection</code> inside <code>fgets</code>:</p>
<div><pre><code>&gt;	ntdll.dll!_RtlpAbFindLockEntry@4()	Unknown
 	ntdll.dll!_RtlAbPostRelease@8()	Unknown
 	ntdll.dll!_RtlLeaveCriticalSection@4()	Unknown
 	gta_sa.exe!fgets()	Unknown
</code></pre></div>

<p>Seems like a change in Windows 11 24H2 modified the way <a href="https://learn.microsoft.com/en-us/windows/win32/sync/critical-section-objects" target="_blank">Critical Section Objects</a>
work internally, and the new code unlocking the critical section uses more stack space than the old one.
I ran one more experiment, comparing the changes to the stack space that happened after <code>sscanf</code> inside <code>LoadVehicleObject</code>, until the next invocation of this function.
Changed values are highlighted in red:</p>

<figure>
<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/stack-win10.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/stack-win10.jpg" alt="" width="1190" height="611"></a><figcaption>On Windows 10, the stack values didn’t change much between the calls.
        In fact, you can spot the two values of <code>0x3F449BA6</code> = <code>0.768</code> (highlighted on the screenshot).
        They correspond to Landstalker’s wheel scales.</figcaption></figure>

<figure><a href="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/stack-win11.jpg" target="_blank"><img src="https://cookieplmonster.github.io/assets/img/posts/sa-win11-24h2-bug/stack-win11.jpg" alt="" width="1190" height="611"></a><figcaption>On Windows 11 24H2, more stack space was modified by a new implementation of Critical Sections.
                The wheel scales are nowhere to be found, as they were overwritten!</figcaption></figure>

</figure>

<p>This is the exact proof I needed – notice that in the Windows 10 run, some of the local variables are even still visible to the human eye (like the <code>normal</code> vehicle class),
while in Windows 11, they are completely gone. It’s also worth pointing out that even in Windows 10, <strong>the very next local variable</strong> after the wheel scales has been overwritten
by <code>LeaveCriticalSection</code>, which means the game was <strong>4 bytes away</strong> from hitting this exact bug years earlier! The luck at display here is insane.</p>
<h2 id="whose-stack-is-it-anyway">
  
  
    Whose Stack Is It Anyway? <a href="#whose-stack-is-it-anyway"></a>
  
  
</h2>
    

<p>To illustrate why the game got away with this bug for so long, I need to show how the stack changes across calls.
Let’s say the stack looks like this after the call to <code>LoadVehicleObject</code>. <strong>Emphasis</strong> on the local variables we’re interested in:</p>

<table>
  <tbody>
    <tr>
      <td>return address from <code>LoadObjectTypes</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LoadObjectTypes</code>…</td>
    </tr>
    <tr>
      <td>return address from <code>LoadVehicleObject</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LoadVehicleObject</code>…</td>
    </tr>
    <tr>
      <td><strong>frontWheelScale</strong></td>
    </tr>
    <tr>
      <td><strong>rearWheelScale</strong></td>
    </tr>
    <tr>
      <td>more local variables…</td>
    </tr>
  </tbody>
</table>

<p>The call to <code>fgets</code>, and consequently <code>LeaveCriticalSection</code>, that follows the call to <code>LoadVehicleObject</code>, reuses the stack space previously occupied by that function,
as the lifetime of the function stack is limited to the duration of the function itself and once the function is done, this space is up for grabs again.
On Windows 10, the stack looked like this once <code>fgets</code> and <code>LeaveCriticalSection</code> returned:</p>

<table>
  <tbody>
    <tr>
      <td>return address from <code>LoadObjectTypes</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LoadObjectTypes</code>…</td>
    </tr>
    <tr>
      <td>return address from <code>fgets</code></td>
    </tr>
    <tr>
      <td>local variables of <code>fgets</code>…</td>
    </tr>
    <tr>
      <td>return address from <code>LeaveCriticalSection</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LeaveCriticalSection</code>…</td>
    </tr>
    <tr>
      <td><strong>frontWheelScale</strong></td>
    </tr>
    <tr>
      <td><strong>rearWheelScale</strong></td>
    </tr>
    <tr>
      <td>more local variables…</td>
    </tr>
  </tbody>
</table>

<p><span>Highlighted parts</span> overwrite what used to be the stack space of <code>LoadVehicleObject</code>,
but notice how it doesn’t reach the area of the stack where the wheel scales resided.
In Windows 11 24H2, <code>LeaveCriticalSection</code> uses more stack space, so the stack space instead looks more like this:</p>

<table>
  <tbody>
    <tr>
      <td>return address from <code>LoadObjectTypes</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LoadObjectTypes</code>…</td>
    </tr>
    <tr>
      <td>return address from <code>fgets</code></td>
    </tr>
    <tr>
      <td>local variables of <code>fgets</code>…</td>
    </tr>
    <tr>
      <td>return address from <code>LeaveCriticalSection</code></td>
    </tr>
    <tr>
      <td>local variables of <code>LeaveCriticalSection</code>…</td>
    </tr>
    <tr>
      <td><strong>frontWheelScale is overwritten!</strong></td>
    </tr>
    <tr>
      <td><strong>rearWheelScale is overwritten!</strong></td>
    </tr>
    <tr>
      <td>more local variables…</td>
    </tr>
  </tbody>
</table>

<p>Parts of the stack <span>highlighted in red</span> are now also scrambled
when in the past they were left intact; those parts include the wheel scales read by the previous call to <code>LoadVehicleObject</code>!
This in turn exposes the bug caused by those variables being uninitialized, and since <code>sscanf</code> can’t read those values from Skimmer’s <code>vehicles.ide</code> definition,
they are kept as-is in garbage form, and propagate further to the vehicle’s data.</p>
<h2 id="what-are-the-odds-this-only-broke-now-darn-windows-11">
  
  
    What are the odds this only broke now? Darn Windows 11! <a href="#what-are-the-odds-this-only-broke-now-darn-windows-11"></a>
  
  
</h2>
    

<p>I want to make it clear: <strong>all these findings prove that the bug is NOT an issue with Windows 11 24H2,
as things like the way the stack is used by internal WinAPI functions are not contractual and they may change at any time, with no prior notice</strong>.
The real issue here is the game relying on undefined behavior (uninitialized local variables), and to be honest,
I’m shocked that the game didn’t hit this bug on so many OS versions, although as I pointed out earlier, it was extremely close.
San Andreas still supported Windows 98, which means it got away with this bug in <strong>at least</strong> a dozen different Windows versions <strong>and</strong> many more releases of Wine!</p>

<p>…or, did it? I found it hard to believe that the game would never hit this issue on any of the many, many platforms it released on,
so I looked into the binary files of some other releases. While this bug was <strong>not</strong> fixed in the official 1.01 PC patch, it <strong>was</strong> fixed in the original Xbox release,
where a “reasonable default” of <code>1.0</code> was added to the code, much like in my fix. This fix was then “inherited” by many future versions of San Andreas, including:</p>
<ul>
  <li>Steam 3.0, newsteam, and RGL, as they were all based on the Xbox branch of the code.</li>
  <li>Any releases from War Drum Studios, including Android, X360, and PS3.</li>
  <li>The Definitive Edition.</li>
</ul>

<p>However, unlike Rockstar, I decided to use the wheel scale of <code>0.7</code> instead of <code>1.0</code> as a default, for multiple reasons:</p>
<ol>
  <li>This is the effective wheel scale Skimmer had on PC (and possibly PS2) until now since that’s the wheel scale of Topfun.</li>
  <li>Two other non-boat vehicles that float on water, Sea Sparrow and Vortex, both have a wheel scale of <code>0.7</code>.</li>
  <li>Many cars in the game have a wheel scale of <code>0.7</code>.</li>
</ol>
<h2 id="i-want-this-fixed-in-my-game">
  
  
    I want this fixed in my game! <a href="#i-want-this-fixed-in-my-game"></a>
  
  
</h2>
    

<p>The code fix will be included in <a href="https://github.com/CookiePLMonster/SilentPatch/milestone/3" target="_blank">the next SilentPatch hotfix</a>,
but for now, you may easily fix it yourself by editing <code>vehicles.ide</code>:</p>
<ol>
  <li>In your San Andreas directory, open <code>data\vehicles.ide</code> with Notepad.</li>
  <li>Scroll down to Skimmer’s line beginning with <code>460, 	skimmer</code>.</li>
  <li>Replace the original line with:
    <div><pre><code>460, 	skimmer,	skimmer, 	plane,		SEAPLANE,	SKIMMER,	null,	ignore,		5,	0,	0,		-1, 0.7, 0.7,		-1
</code></pre></div>
  </li>
  <li>Save the file.</li>
</ol>
<h2 id="final-word">
  
  
    Final word <a href="#final-word"></a>
  
  
</h2>
    

<p>This was the most interesting bug I’ve encountered for a while. I initially had a hard time believing that a bug like this would directly tie to a specific OS release,
but I was proven completely wrong. At the end of the day, it was a simple bug in San Andreas and this function should have never worked right,
and yet, at least on PC it hid itself for two decades.</p>

<p>This is an interesting lesson in compatibility: even changes to the stack layout of the internal implementations can have compatibility implications if an application
is bugged and unintentionally relies on a specific behavior. This is also not the first time I encountered issues like this: regular visitors might remember
<a href="https://cookieplmonster.github.io/mods/bully/">Bully: Scholarship Edition</a> which famously broke on Windows 10, for very similar reasons. Just like in this case,
Bully should have never worked properly to begin with, but instead, it got away with making incorrect assumptions for years, before changes in Windows 10 finally
made it run out of luck.</p>

<p>Yet again, we are reminded to:</p>
<ul>
  <li><strong>Validate your input data</strong> – San Andreas was notoriously bad at this, and ultimately this was the main reason why an incomplete config line remained unnoticed.</li>
  <li><strong>Not ignore the compilation warnings</strong> – this code most likely threw a warning in the original code that was either ignored or disabled!</li>
</ul>

<p>In the end, the GTA players are lucky: in many other games, issues like this would’ve remained unfixed and they’d become a folk legend.
Thankfully, GTAs are moddable and well understood, so we can act upon problems like this and ensure the game stays functional for many more years to come.</p><hr>


    
  </section>


  

  
  

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I Blog with Obsidian, Hugo, GitHub, and Cloudflare – Zero Cost, Fully Owned (275 pts)]]></title>
            <link>https://ingau.me/blog/how-i-write-my-blogs-in-obsidian-and-publish-instantly/</link>
            <guid>43771645</guid>
            <pubDate>Wed, 23 Apr 2025 13:00:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ingau.me/blog/how-i-write-my-blogs-in-obsidian-and-publish-instantly/">https://ingau.me/blog/how-i-write-my-blogs-in-obsidian-and-publish-instantly/</a>, See on <a href="https://news.ycombinator.com/item?id=43771645">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>I’ve been using Obsidian for all my writing lately, and it’s been a game changer. The local-first model means everything lives as plain text on my machine, and with the Minimal theme, the interface stays clean and distraction-free.</p>
<p>My vault lives in iCloud (Dropbox or Google Drive work too), so notes sync seamlessly across devices - I often start drafts on my phone and finish them later on my laptop.</p>
<p>For publishing, I use Hugo with the Bear Blog theme (fast, minimal), and deploy via GitHub and Cloudflare Pages. This stack gives me full control: no subscriptions, no vendor lock-in, and no risk of platforms disappearing or changing policies.</p>
<p>If you:</p>
<ul>
<li>Use (or want to try) Obsidian</li>
<li>Don’t mind a bit of technical setup</li>
<li>Prefer writing in plain text with Git-based version control</li>
<li>Want a fast, cost-free, portable publishing flow</li>
</ul>
<p>Then this setup might be exactly what you’re looking for. Once set up, publishing is as simple as toggling a draft flag and pushing to GitHub.</p>
<p><img src="https://ingau.me/images/obsidian-publish.png" alt="Screenshot of my Obsidian vault"></p>
<h2 id="setting-up-your-system">Setting Up Your System</h2>
<p>This post is a <strong>high-level outline</strong> of how it all fits together. It’s not a tutorial, but if you’re familiar with basic dev tools, it should be easy to follow. And if anything’s unclear, LLMs like ChatGPT or Claude are great for filling in the gaps.</p>
<h3 id="1-install-and-set-up-hugo">1. Install and Set Up Hugo</h3>
<p>First, you’ll need to <a href="https://gohugo.io/installation/">install Hugo</a> on your machine. Once installed, create a new site:</p>
<pre tabindex="0"><code>hugo new site myblog
cd myblog
</code></pre><p>Then add the Bear Blog theme (or your preferred theme):</p>
<pre tabindex="0"><code>git init
git submodule add https://github.com/janraasch/hugo-bearblog.git themes/hugo-bearblog
</code></pre><p>Update your <code>config.toml</code> file to use the theme. See the <a href="https://github.com/janraasch/hugo-bearblog">Bear Blog theme documentation</a> for configuration options.</p>
<h3 id="2-connect-obsidian-to-hugo">2. Connect Obsidian to Hugo</h3>
<p>This is the key part. Hugo has a specific folder structure, and you want to write your posts in the <code>content</code> folder. Inside that folder, I created a <code>blog</code> subfolder for all my posts.</p>
<p>So my folder structure looks like this:</p>
<pre tabindex="0"><code>myblog/
  ├── content/
  │   ├── blog/   &lt;- This is where I write my posts
  │   └── ...
  └── ...
</code></pre><p>To set up Obsidian:</p>
<ol>
<li>Open Obsidian</li>
<li>Click “Open folder as vault”</li>
<li>Navigate to your Hugo site’s blog folder (myblog/content/blog)</li>
<li>Select this folder</li>
</ol>
<p>This way, everything you write in Obsidian goes directly into the right folder for Hugo to process.</p>
<h3 id="3-set-up-front-matter-template">3. Set Up Front Matter Template</h3>
<p>In Obsidian, make sure that your posts includes the necessary Hugo front matter:</p>
<pre tabindex="0"><code>+++
title= "Your Post Title"
date= YYYY-MM-DD
tags= ["post"]
draft= true
+++
</code></pre><p>The <code>draft: true</code> tag is crucial - this is what you’ll toggle to <code>false</code> when you’re ready to publish.</p>
<h3 id="4-preview-posts-locally">4. Preview Posts Locally</h3>
<p>While writing, I use Hugo’s local server with draft visibility:</p>
<p><code>hugo server -D</code></p>
<p>This lets me see how everything looks in-browser before pushing live.</p>
<h3 id="5-connect-to-github">5. Connect to GitHub</h3>
<p>Create a new GitHub repository for your blog, then connect your local Hugo site:</p>
<pre tabindex="0"><code>git remote add origin https://github.com/yourusername/yourblog.git
git add .
git commit -m "Initial commit"
git push -u origin main
</code></pre><p>There are plenty of <a href="https://docs.github.com/en/get-started/quickstart/hello-world">GitHub tutorials</a> if you need help with this step.</p>
<h3 id="6-set-up-cloudflare-pages">6. Set Up Cloudflare Pages</h3>
<ol>
<li>Sign up for a <a href="https://dash.cloudflare.com/sign-up">Cloudflare account</a> if you don’t have one</li>
<li>Go to the Pages section and create a new project</li>
<li>Connect to your GitHub account and select your blog repository</li>
<li>For build settings:
<ul>
<li>Build command: <code>hugo --minify</code></li>
<li>Build output directory: <code>public</code></li>
</ul>
</li>
</ol>
<p>Cloudflare’s <a href="https://developers.cloudflare.com/pages/framework-guides/deploy-a-hugo-site/">own documentation</a> covers this process well.</p>
<h2 id="the-publishing-workflow">The Publishing Workflow</h2>
<p>Once everything is set up, publishing is simple:</p>
<ol>
<li>Write your post in Obsidian</li>
<li>When ready to publish, change <code>draft: true</code> to <code>draft: false</code> in the front matter</li>
<li>Commit and push to GitHub:</li>
</ol>
<pre tabindex="0"><code>git add .
git commit -m "Publish new post"
git push
</code></pre><p>Cloudflare Pages will automatically detect the change and rebuild your site, typically within a minute or two.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>This setup takes a bit of initial work, but the payoff is enormous. Once it’s all set up, this workflow fades into the background - I just write, commit, and publish. No friction, no fees, and everything stays in my hands. If you’re looking for a lightweight, sustainable way to blog, this might be worth trying.</p>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Show HN: Node.js video tutorials where you can edit and run the code (207 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=43771365</link>
            <guid>43771365</guid>
            <pubDate>Wed, 23 Apr 2025 12:35:49 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=43771365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="43771365">
      <td><span></span></td>      <td><center><a id="up_43771365" href="https://news.ycombinator.com/vote?id=43771365&amp;how=up&amp;goto=item%3Fid%3D43771365"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=43771365">Show HN: Node.js video tutorials where you can edit and run the code</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_43771365">104 points</span> by <a href="https://news.ycombinator.com/user?id=somebee">somebee</a> <span title="2025-04-23T12:35:49 1745411749"><a href="https://news.ycombinator.com/item?id=43771365">3 hours ago</a></span> <span id="unv_43771365"></span> | <a href="https://news.ycombinator.com/hide?id=43771365&amp;goto=item%3Fid%3D43771365">hide</a> | <a href="https://hn.algolia.com/?query=Show%20HN%3A%20Node.js%20video%20tutorials%20where%20you%20can%20edit%20and%20run%20the%20code&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=43771365&amp;auth=f2fed84ff1e053cd2fd7c67a4f2106ff939b6f87">favorite</a> | <a href="https://news.ycombinator.com/item?id=43771365">35&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hey HN,</p><p>I'm Sindre, CTO of Scrimba (YC S20). We originally launched Scrimba to make video learning more interactive for aspiring frontend developers. So instead of passively watching videos, you can jump in an experiment with the code directly inside the video player. Since launch, almost two million people have used Scrimba to grow their skills.</p><p>However, one limitation is that we've only supported frontend code, as our interactive videos run in the browser, whereas most of our learners want to go fullstack—building APIs, handling auth, working with databases, and so forth.</p><p>To fix this, we spent the last 6 months integrating StackBlitz WebContainers into Scrimba. This enables a full Node.js environment—including a terminal, shell, npm access, and a virtual file system—directly inside our video player. Everything runs in the browser.</p><p>Here is a 2-minute recorded demo: <a href="https://scrimba.com/s08dpq3nom">https://scrimba.com/s08dpq3nom</a></p><p>If you want to see more, feel free to enroll into any of the seven fullstack courses we've launched so far, on subject like Node, Next, Express, SQL, Vite, and more. We've opened them up for Hacker News today so that you don't even need to create an account to watch the content:</p><p><a href="https://scrimba.com/fullstack">https://scrimba.com/fullstack</a></p><p><i>Other notable highlights about our "IDE videos":</i></p><p>- Based on events (code edits, cursor moves, etc) instead of pixels</p><p>- Roughly 100x smaller than traditional videos</p><p>- Recording is simple: just talk while you code</p><p>- Can be embedded in blogs, docs, or courses, like MDN does here: <a href="https://developer.mozilla.org/en-US/curriculum/core/css-fundamentals/" rel="nofollow">https://developer.mozilla.org/en-US/curriculum/core/css-fund...</a></p><p>- Entirely built in Imba, a language I created myself: <a href="https://news.ycombinator.com/item?id=28207662">https://news.ycombinator.com/item?id=28207662</a></p><p>We think this format could be useful for open-source maintainers and API-focused teams looking to create interactive docs or walkthroughs. Our videos are already embedded by MDN, LangChain, and Coursera.</p><p>If you maintain a library or SDK and want an interactive video about it, let us know—happy to record one for free that you can use however you like.</p><p>Would love to answer any questions or hear people's feedback!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geocoding APIs compared: Pricing, free tiers and terms of use (128 pts)]]></title>
            <link>https://www.bitoff.org/geocoding-apis-comparison/</link>
            <guid>43770446</guid>
            <pubDate>Wed, 23 Apr 2025 10:21:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitoff.org/geocoding-apis-comparison/">https://www.bitoff.org/geocoding-apis-comparison/</a>, See on <a href="https://news.ycombinator.com/item?id=43770446">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <div role="note">
<p role="heading" aria-level="2"><strong>Author's note</strong></p>
<p>This article was originally <a href="https://web.archive.org/web/20230810062017/https://superface.ai/blog/geocoding-apis-comparison-1">published</a> on <a href="https://superface.ai/">Superface</a> blog before the pivot to agentic tooling platform and is republished here with company's permission.</p>
<p>I am no longer working with geocoding APIs and the content of this article may be outdated.</p>
</div>
<p>Geocoding is the process of converting an address to geolocation coordinates (latitude and longitude). <em>Reverse</em> geocoding is the opposite: assigning a street address to the given coordinates. Examples of geocoding include:</p>
<ul>
<li>Obvious ones, like finding a location on a map or displaying an address of a selected location.</li>
<li>Visualization of customer data.</li>
<li>Working with coordinates stored in photos.</li>
<li>Local search, such as displaying events or restaurants in the user’s proximity or within a city radius.</li>
</ul>
<p>How do you build this feature? The easiest way is to use a geocoding API, which often includes reverse geocoding and address data cleaning functions as well.</p>
<p>The good news is that there isn’t a shortage of geocoding API providers to choose from. The bad news is that you have to pick one. Which is why we’re here: to help you decide on the most suitable geocoding API for your project.</p>
<h2 id="comparison-criteria" tabindex="-1">Comparison criteria</h2>
<p>In this article, we will look at the pricing model, and terms of use:</p>
<ul>
<li><strong>Pricing:</strong> Most geocoding API providers have a volume-based pricing. So, we will look at pricing tiers and price per API request.</li>
<li><strong>Free tier:</strong> Typically there is a free or trial tier with a limited number of requests or limited functionality. This can be useful for testing the API or even keeping your costs low for personal or low-budget projects.</li>
<li><strong>Data terms of use:</strong> It’s essential to know if there are any limitations about the data usage: Does the provider require displaying an attribution? Is it even okay to use the data for commercial use?</li>
</ul>
<p>In the follow-up articles, we will also explore additional criteria:</p>
<ul>
<li><strong>Accuracy:</strong> It doesn’t matter whether the API is cheap if the results are useless. So, we will do a head-to-head comparison of various queries and compare the results.</li>
<li><strong>Performance:</strong> If your project requires displaying the geocoding results in real-time, then every millisecond matters.</li>
</ul>
<h2 id="what's-superface-and-why-is-this-comparison-neutral" tabindex="-1">What’s Superface and why is this comparison neutral</h2>
<p>At Superface we don’t provide a geocoding API. Instead, we are building a universal API client which lets you connect to any API and any provider – directly from your application without passing the data through our servers. You can even use multiple providers behind a single interface without the need to study the documentation for each or keep up with the API changes.</p>
<p>Geocoding is particularly one domain where your project can benefit from using multiple API providers. Whether it’s for accuracy, cost management, or legal reasons. Our goal is to provide you with accurate and impartial information about geocoding APIs, and we will show you how you can use them immediately with OneSDK, our API client.</p>
<p>Oh, and one more thing: OneSDK is free and <a href="https://github.com/superfaceai/one-sdk-js">open-source</a>, it doesn’t matter whether you will use it for geocoding twice or a billion times. Our business is built around providing the connectors to the APIs and their long-term support, but not around the usage volume.</p>

<table>
<thead>
<tr>
<th>Provider</th>
<th>Free Requests</th>
<th>Rate Limit (requests per second)</th>
<th>Pricing (per 1,000 requests)</th>
<th>Additional Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>HERE</td>
<td>30,000/month</td>
<td>5</td>
<td>$0.83 up to 5M<br>$0.66 up to 10M</td>
<td></td>
</tr>
<tr>
<td>Google Maps</td>
<td>40,000/month ($200 credit)</td>
<td>50</td>
<td>$5 up to 100,000<br>$4 up to 500,000</td>
<td>Attribution &amp; Google Maps required</td>
</tr>
<tr>
<td>Azure Maps</td>
<td>5,000/month</td>
<td>500 (geocoding)<br>250 (reverse geocoding)</td>
<td>$4.50</td>
<td></td>
</tr>
<tr>
<td>OpenCage</td>
<td>2,500/day</td>
<td>1 (free)<br>15 (X-Small)<br>up to 40 (Large)</td>
<td>$0.17 (10,000 per day)<br>$0.11 (300,000 per day)<sup><a href="#fn1" id="fnref1">[1]</a></sup></td>
<td>Free trial for testing only<br>Monthly fixed pricing</td>
</tr>
<tr>
<td>TomTom Maps</td>
<td>2,500/day</td>
<td>5</td>
<td>$0.54</td>
<td></td>
</tr>
<tr>
<td>LocationIQ</td>
<td>5,000/day</td>
<td>2</td>
<td>$0.16 (10,000 per day)<br>$0.03 (1M per day)<sup><a href="#fn1" id="fnref1:1">[1:1]</a></sup></td>
<td>Free plan requires attribution<br>Monthly fixed pricing</td>
</tr>
<tr>
<td>Nominatim</td>
<td>n/a</td>
<td>1</td>
<td>n/a</td>
<td>Low-volume, noncommercial use only<br>Attribution required</td>
</tr>
</tbody>
</table>
<h3 id="here" tabindex="-1">HERE</h3>
<p><a href="https://www.here.com/get-started/pricing">HERE’s pricing</a> starts with the Limited Plan, which provides you with <strong>1,000 free requests per day</strong>, with a rate limit of <strong>5 requests per second</strong>.</p>
<p>If you provide payment information, you are upgraded to the Base Plan. The Base Plan removes the rate limit and sets you up for <strong>30,000 free requests per&nbsp;month</strong>. Above that, requests up to 5&nbsp;million are <strong>$0.830 per 1,000</strong>, and <strong>$0.660 per 1,000</strong> requests between 5 and 10&nbsp;million per&nbsp;month.</p>
<h3 id="google-maps-platform" tabindex="-1">Google Maps Platform</h3>
<p>Google Maps Platform requires you to provide billing details to use the Geocoding API, and provides you with <strong>$200 of free credit per month</strong>, which is good for <strong>40,000 free geocoding API requests</strong> (check the <a href="https://developers.google.com/maps/documentation/geocoding/usage-and-billing">Geocoding API Usage and Billing</a>).</p>
<p>If that’s not enough, the pricing starts at <strong>$5 per 1,000 requests</strong> up to 100,000 requests per month. Above that, the price gets lower to <strong>$4 per 1,000</strong> requests up to 500,000 requests.</p>
<p>Regardless of usage, there’s a rate limit of 50 requests per second. Google also <a href="https://developers.google.com/maps/documentation/geocoding/policies#map">prohibits displaying of geocoding results</a> on another map than Google Maps, and <a href="https://developers.google.com/maps/documentation/geocoding/policies#logo">requires displaying Google logo</a> for attribution.</p>
<h3 id="azure-maps" tabindex="-1">Azure Maps</h3>
<p>Azure Maps provides <strong>5,000 free requests per month</strong> (see the <a href="https://azure.microsoft.com/en-us/pricing/details/azure-maps/">pricing for Azure Maps Search</a>), and the <strong>price per 1,000 requests above that is $4.50</strong> (up to 500,000 requests).</p>
<p><a href="https://learn.microsoft.com/en-us/azure/azure-maps/azure-maps-qps-rate-limits">Queries are rate limited</a> to 500 per second for geocoding, and 250 per second for reverse geocoding.</p>
<h3 id="opencage" tabindex="-1">OpenCage</h3>
<p><a href="https://opencagedata.com/pricing">OpenCage pricing</a> is richer than for other services. You have a choice of purchasing a one-time requests package (valid up to one year), or subscribing to different usage tiers on a monthly or annual basis.</p>
<p>The free tier is intended only for testing and development and provides you with <strong>2,500 requests per day</strong>, rate limited to 1 request per second. The cheapest package costs <strong>$50 per month</strong> and comes with <strong>10,000 requests per day</strong> (about $0.17 per 1,000 requests) and a rate limit of 15 requests per second. The biggest pre-Enterprise package costs <strong>$1,000 per month</strong>, with <strong>300,000 requests per day</strong> and a rate limit of 40 requests per second (which is approx $0.11 per 1,000 requests).</p>
<p>One nice thing is that the daily request limit is “soft” – if you occasionally cross the limit, the service won’t be blocked, and you won’t be charged anything extra. Only if you repeatedly pass the limit OpenCage asks you to upgrade your plan for the next month.</p>
<h3 id="locationiq" tabindex="-1">LocationIQ</h3>
<p><a href="https://locationiq.com/pricing">LocationIQ pricing</a> is very similar to OpenCage's. You have a choice of plans paid on a monthly and annual basis, but no option to purchase a one-time requests package.</p>
<p>The free tier does allow commercial usage as long as you include a link in your application to LocationIQ. Furthermore, the free tier limit is doubled compared to OpenCage, with <strong>5,000 free requests</strong> allowed per day and a rate limit of 2 requests per second. The smallest package is basically the same as OpenCage's: it costs <strong>$49 per month</strong> and comes with <strong>10,000 requests per day</strong> (about $0.16 per 1,000 requests) and a rate limit of 15 requests per second. However, the biggest package includes <strong>1 million requests per day</strong> for <strong>$950 per month</strong> (about $0.03 per 1,000 requests).</p>
<p>Similar to OpenCage, LocationIQ has a “soft” limit for daily requests, allowing requests “upto an additional 100% of your daily limit”. For example, on the smallest package, you can occasionally perform 20,000 requests per day before getting an error.</p>
<h3 id="tomtom-maps-api" tabindex="-1">TomTom Maps API</h3>
<p>TomTom provides a generous free tier with <strong>2,500 requests per day</strong> available for commercial applications as well. Above that, <strong>1,000 requests cost €0.50 ($0.54)</strong>.</p>
<h3 id="nominatim" tabindex="-1">Nominatim</h3>
<p><a href="https://nominatim.org/">Nominatim</a> is a bit different from the other services on this list. It’s primarily an open-source project that uses data from <a href="https://www.openstreetmap.org/">OpenStreetMap</a>. And conversely, OpenStreetMap’s search is powered by Nominatim. You can (and should) run Nominatim <a href="https://nominatim.org/release-docs/latest/admin/Installation/">on your server</a>, but if you just want to try the API or have a low-volume hobby project, you’re welcome to use the Nominatim instance provided by OpenStreetMap.</p>
<p>However, pay close attention to its <a href="https://operations.osmfoundation.org/policies/nominatim/">usage policy</a>, in particular:</p>
<ul>
<li>Maximum of 1 request per second.</li>
<li>Identify your application using User-Agent or HTTP Referer headers.</li>
<li>Display <a href="https://wiki.osmfoundation.org/wiki/Licence/Attribution_Guidelines">attribution</a>.</li>
<li>Don’t resell the data.</li>
</ul>
<p>Nominatim is also used by some <a href="https://wiki.openstreetmap.org/wiki/Nominatim#Alternatives_/_Third-party_providers">commercial providers</a>, including OpenCage and LocationIQ.</p>
<h2 id="pricing-comparison" tabindex="-1">Pricing comparison</h2>
<p>While each service has different pricing tiers, we can compare the price based on the number of requests made. We’ve omitted Nominatim in this comparison, since it’s always free, but isn’t intended for commercial projects.</p>
<h3 id="small-usage-(up-to-30000-requests-month)" tabindex="-1">Small usage (up to 30,000 requests / month)</h3>
<ul>
<li>HERE: free</li>
<li>Google Maps Platform: free (with credit)</li>
<li>Azure Maps: $112.5/month</li>
<li>OpenCage: free or $50/month (X-Small)</li>
<li>TomTom Maps: free</li>
<li>LocationIQ: free or $49/month (Geocoding Lite)</li>
</ul>
<h3 id="medium-usage-(100000-requestsmonth-or-3333day)" tabindex="-1">Medium usage (100,000 requests/month or 3,333/day)</h3>
<ul>
<li>HERE: $58.1</li>
<li>Google Maps Platform: $300 (with credit)</li>
<li>Azure Maps: $427.5</li>
<li>OpenCage: $50 (X-Small)</li>
<li>TomTom Maps: $16.2 ($0.54/day)</li>
<li>LocationIQ: free or $49/month (Geocoding Lite)</li>
</ul>
<h3 id="high-usage-(300000-requestsmonth-or-10000day)" tabindex="-1">High usage (300,000 requests/month or 10,000/day)</h3>
<ul>
<li>HERE: $224.1</li>
<li>Google Maps Platform: $1,100 (with credit)</li>
<li>Azure Maps: $1327.5</li>
<li>OpenCage: $50 (X-Small) or $125 (Small)</li>
<li>TomTom Maps: $121.5 ($4.05/day)</li>
<li>LocationIQ: $49/month (Geocoding Lite) or $99 (Developer)</li>
</ul>
<h2 id="conclusion:-what's-the-best-geocoding-api-deal" tabindex="-1">Conclusion: What’s the best geocoding API deal?</h2>
<p>Based purely on pricing, we can draw a conclusion about each provider.</p>
<p><strong>Azure Maps</strong> is, for higher volume scenarios, the most expensive option, with low free tier and fixed price per request. Similar to Google Maps, Azure Maps’ price per 1,000 requests is almost ten times higher compared to other providers.</p>
<p><strong>Google Maps Platform</strong> is similarly expensive, but also the most restrictive provider, with requirements for attribution and displaying data using their embedded maps. This can introduce additional costs, as Google Maps with JavaScript API is also paid per usage.</p>
<p><strong>OpenCage</strong> and <strong>LocationIQ</strong> both provide monthly plans with a fixed price. OpenCage also provides the possibility to purchase one-off usage credits and handles billing in multiple currencies automatically. LocationIQ, on the other hand, provides more generous free tier, and their monthly plans are cheaper, especially for higher volume usage. The “Business Plus” plan in particular allows for 1 million requests per day, allowing for a whopping 30 million requests per month without negotiating custom pricing. A monthly subscription probably makes the most sense if your usage volume of the geocoding API is consistent throughout the month.</p>
<p>On the other hand, <strong>TomTom Maps</strong> may be preferable if your usage is uneven. The price per 1,000 calls is among the lowest, and you have a large amount of free requests per day. And unlike OpenCage and LocationIQ, you don't need to pay a monthly subscription. The commercial-friendly free tier is also a great option for smaller and low-budget projects.</p>
<p><strong>HERE</strong> is a viable option for high-volume usage. While most providers require you to upgrade to the (presumably expensive) Enterprise plan once you use around 500,000 requests/month, HERE will ask you only once you reach 10 million monthly requests. (However, LocationIQ allows for 1 million requests <em>per day</em> with their biggest package.)</p>
<p>Finally, <strong>Nominatim</strong> is a special option. Great for small projects, but not intended for commercial usage. Still, if you use the service, consider <a href="https://nominatim.org/funding/">supporting the project</a>.</p>
<h2 id="resources" tabindex="-1">Resources</h2>
<ul>
<li>OpenCage has a <a href="https://opencagedata.com/guides/how-to-compare-and-test-geocoding-services">detailed guide on comparing and testing geocoding providers</a>; rather than comparing individual providers, it explains what criteria you should consider.</li>
<li>On GIS Stack Exchange, you can find a sheet with a <a href="https://gis.stackexchange.com/a/62389/27909">comprehensive comparison of providers’ accuracy</a>; the last update was in 2021.</li>
<li>You can find additional comparisons by <a href="https://www.smarty.com/articles/geocoding-api-comparison">Smarty</a> (formerly SmartyStreets), <a href="https://www.geoapify.com/top-geocoding-services-comparison">Geoapify</a>, and <a href="https://www.geocod.io/compare/">Geocodio</a>, however some information about pricing may be outdated and the comparisons are obviously biased.</li>
</ul>
<h2 id="updates" tabindex="-1">Updates</h2>
<p>The article was updated on June 26, 2023, to include LocationIQ per the provider's request.</p>
<section>
<h2>Footnotes</h2>
<ol>
<li id="fn1"><p>For services with monthly subscription (OpenCage and LocationIQ) the price per 1,000 requests is based on daily limit per 30 days for the lowest and the highest plans paid monthly. <a href="#fnref1">↩︎</a> <a href="#fnref1:1">↩︎</a></p>
</li>
</ol>
</section>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[MinC Is Not Cygwin (264 pts)]]></title>
            <link>https://minc.commandlinerevolution.nl/english/home.html</link>
            <guid>43770445</guid>
            <pubDate>Wed, 23 Apr 2025 10:21:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minc.commandlinerevolution.nl/english/home.html">https://minc.commandlinerevolution.nl/english/home.html</a>, See on <a href="https://news.ycombinator.com/item?id=43770445">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section>
<article>
<p>Welcome to the MinC home page. MinC is a Unix emulator for Windows, based on the OpenBSD operating system.
MinC was written to help children at vocational education learn Linux without the hassle of virtualization. 
It runs on all versions of Windows, except Win95 and Win98.
</p>
<p>MinC is a tiny kernel which runs on Windows. The rest of the software was 
taken verbatim from OpenBSD, version 6.1. This means that by installing MinC, 
you run OpenBSD on your Windows machine at native speed.
</p>
</article>
<article>
<img src="https://minc.commandlinerevolution.nl/_images/ppuf1000X907_small.png" width="96" alt="Puffy, the OpenBSD mascotte" title="Puffy"></article>
</section>

<section>

<article>
<h2>Install</h2>
<p>To install MinC you no longer have to copy it "by hand". You can now use the new installation
wizard. Download the current version by clicking the link:
<a href="https://minc.commandlinerevolution.nl/minc-6.1.exe">minc-6.1.exe</a> (20Mb).
</p>
<img src="https://minc.commandlinerevolution.nl/_images/Installer-1.0_10.png" width="288"><p>After installation you will see a new icon called <b>Console</b> on your Desktop.
This starts the MinC terminal.
</p>
</article>

<article>
<h2>Use</h2>
<p>The current MinC realease contains the following functions:
</p>
<ul>
<li>All Unix standard commands, like: ls, du, ps, df, find, grep, awk, mkdir, chmod, 
chown, wc, top, diff, etc.
</li><li>Editing: less, vi, nano, hexedit
</li><li>Compression: unzip, gzip, bzip2, xz
</li><li>Networking: route, ifconfig, ping, ftp, ssh, scp, telnet, wget, curl, lynx, mutt, BitchX
</li><li>Development: vim, git, ImageMagick
</li></ul>
<p>Services and daemons, like Apache (httpd), Sendmail and sshd are not yet available, 
but will be released as soon as possible.
</p>
<p>If you like to compile code for MinC, you can install the toolchain: 
<a href="https://minc.commandlinerevolution.nl/buildtools-6.1.exe">buildtools-6.1.exe</a> The package contains BSD libc, GNU 
binutils, GNU cc, GNU make, vim and git.
</p>
</article>

<article>
<h2>Donate</h2>
<p>Writing the kernel took a lot of time. To help me finish MinC, you can make a donation
via PayPal. Any amount is welcome.
</p>

<p>Let me know if you wish to have a particular software included in the next release.
Send an e-mail to dboland@xs4all.nl.
</p>
</article>

<article>
<h2>Antivirus</h2>
<p>MinC works well with antivirus software, such as the built-in
<b>Windows Defender</b> or <b>Kaspersky</b>.
</p>
<p>In some cases you need to temporarily disable antivirus before downloading and 
installing (<a target="_blank" href="https://support.kaspersky.com/KIS/21.2/en-US/70886.htm" title="How to pause and resume computer protection">Kaspersky</a>). After that, MinC works fine.
</p>
<p>In other cases, MinC installs well, but the antivirus does not let you 
run its programs. You need to exclude the MinC root directory from scanning 
(<a target="_blank" href="https://help.f-secure.com/product.html#home/total-windows/latest/en/allow_program_on_sys_control_blocklist_to_run-latest-en" title="Allowing blocked applications">f-secure</a>).
</p>
</article>

<article>
<h2>Visual Studio</h2>
<p>MinC can be integrated into <b>MS Visual Studio Code</b> as a terminal.
Put following snippet in your personal settings.json file:
</p>
<pre>"terminal.integrated.profiles.windows": {
   "MinC": {
      "path": "<u>C:\\MinC</u>\\sbin\\bsd.exe"
   }
}
</pre>
<p>If you installed MinC at another location, make sure 
the underlined part is correct.
</p>
</article>

</section>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EU fines Apple €500M and Meta €200M (130 pts)]]></title>
            <link>https://www.politico.eu/article/eu-fines-apple-meta-breaking-europe-digital-markets-act-dma/</link>
            <guid>43770396</guid>
            <pubDate>Wed, 23 Apr 2025 10:12:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.politico.eu/article/eu-fines-apple-meta-breaking-europe-digital-markets-act-dma/">https://www.politico.eu/article/eu-fines-apple-meta-breaking-europe-digital-markets-act-dma/</a>, See on <a href="https://news.ycombinator.com/item?id=43770396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-count="4" data-remainder="0" data-block-attributes="[]" data-page="0">
					
<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/13/GettyImages-2112143030-1.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="Big Tech fines just got political, whether the Commission likes it or not" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/big-tech-fines-digital-markets-act-political-european-commission-meta-apple-donald-trump-tariffs/">
						Big Tech fines just got political, whether the Commission likes it or not					</a>
				</h2>
			
			
							<p>By delaying expected announcements on fining Apple and Meta, the bloc’s Digital Markets Act is being dragged into the global trade war.</p>
			
			<p><span>
			Apr 14		</span>
	
	
	
<span>
	<span>5 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=242,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/08/GettyImages-1090864832-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="Top EU official downplays expectations over Apple, Meta digital fines" width="380" height="242" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/apple-meta-top-eu-official-downplays-expectations-over-apple-meta-digital-fines/">
						Top EU official downplays expectations over Apple, Meta digital fines					</a>
				</h2>
			
			
							<p>The bloc’s Digital Markets Act is about compliance, not fines, says Olivier Guersent.</p>
			
			<p><span>
			Apr 8		</span>
	
	
	
<span>
	<span>2 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=259,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/04/02/GettyImages-2204511832-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="EU fines big carmakers €458M for green cartel" width="380" height="259" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/eu-fines-big-carmakers-e458m-for-green-cartel/">
						EU fines big carmakers €458M for green cartel					</a>
				</h2>
			
			
							<p>European groups received some of the biggest fines.</p>
			
			<p><span>
			Apr 1		</span>
	
	
	
<span>
	<span>1 min read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>

<div>
			<p><img src="https://www.politico.eu/cdn-cgi/image/width=380,height=253,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg" srcset="https://www.politico.eu/cdn-cgi/image/width=480,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 480w, https://www.politico.eu/cdn-cgi/image/width=768,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 768w, https://www.politico.eu/cdn-cgi/image/width=1024,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 1024w, https://www.politico.eu/cdn-cgi/image/width=1280,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 1280w, https://www.politico.eu/cdn-cgi/image/width=1440,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 1440w, https://www.politico.eu/cdn-cgi/image/width=1920,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 1920w, https://www.politico.eu/cdn-cgi/image/width=2640,quality=80,onerror=redirect,format=auto/wp-content/uploads/2025/03/28/1742468554355_20250320_EP-182433A_PB9_227-scaled.jpg 2640w" sizes="(max-width: 380px) 100vw, 380px" alt="EU set to fine Apple and Meta amid escalating trade war" width="380" height="253" role="" loading="lazy" decoding="async">

					</p>
	
	
		
		<div>

			
			
			
			
			
							<h2>
										<a href="https://www.politico.eu/article/eu-set-fine-apple-meta-amid-escalating-trade-war/">
						EU set to fine Apple and Meta amid escalating trade war					</a>
				</h2>
			
			
							<p>The Commission’s first fines under its Digital Markets Act are expected this week.</p>
			
			<p><span>
			Mar 31		</span>
	
	
	
<span>
	<span>4 mins read</span>
</span>
</p>

			
			
			
			
					</div>

			</div>
				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[America's cyber defenses are being dismantled from the inside (329 pts)]]></title>
            <link>https://www.theregister.com/2025/04/23/trump_us_security/</link>
            <guid>43770382</guid>
            <pubDate>Wed, 23 Apr 2025 10:10:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/04/23/trump_us_security/">https://www.theregister.com/2025/04/23/trump_us_security/</a>, See on <a href="https://news.ycombinator.com/item?id=43770382">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p><span>Opinion</span> We almost lost the Common Vulnerabilities and Exposures (CVE) database system, but that's only the tip of the iceberg of what President Trump and company are doing to US cybersecurity efforts.</p>
<p>When it comes to technology security, let's face it. We're lame and we're lazy. But we don't normally go out of our way to make it worse. Until now. Until President Donald Trump and his cohort of tech minions, better known as Elon Musk's Department of Government Efficiency (DOGE), took over.</p>
<p>You might think, if you're outside the US, who cares? Unfortunately, whether you like it or not, the US has long taken the lead in technical security.</p>

    

<p>Take, for example, the fact that we <a target="_blank" href="https://www.theregister.com/2025/04/16/homeland_security_funding_for_cve/">almost lost the Common Vulnerabilities and Exposures (CVE) database</a>. Anyone familiar with cybersecurity will have heard of the CVE. It's the master list of essentially all security holes for the last 25 years.</p>

        


        

<p>As Jen Easterly, former director of the Cybersecurity and Infrastructure Security Agency (CISA), explained on LinkedIn: "It's the global catalog that helps everyone – security teams, software vendors, researchers, governments – organize and talk about vulnerabilities using the same reference system."</p>
<p>Without it, everyone is using a different catalog or no catalog at all, no one knows if they're talking about the same problem, and defenders waste precious time figuring out what's wrong. Worst of all, threat actors take advantage of the confusion.</p>

        

<p>How could such an important project go under? Easily. It wasn't funded. The group that oversees the CVE, CISA, had been targeted for staff cuts of over a third of its employees. In addition, CISA employees were given until midnight Monday to choose between <a target="_blank" rel="nofollow" href="https://www.govinfosecurity.com/cisa-braces-for-major-workforce-cuts-amid-security-fears-a-27996">staying on the job or resigning</a>. So it was that the decision to <a target="_blank" href="https://www.theregister.com/2025/04/16/cve_program_funding_save/?td=rt-3a">extend the MITRE CVE contract didn't come until literally the 11th hour</a>.</p>
<p>That contract will still run out in March 2026. Who knows if Trump et al will extend it again? Once upon a time, this kind of decision would be a no-brainer. I mean, all technology security, for better or worse, depends on the CVE system. Now? Your guess is as good as mine.</p>
<p>You can't depend on guesses when it comes to security.</p>

        

<p>The Trump administration's tenure, though, has already been marked by significant setbacks to US federal government technology security efforts, over and over again.</p>
<p>For example, General Timothy D. Haugh, the head of the National Security Agency (NSA) and US Cyber Command, was <a target="_blank" href="https://www.theregister.com/2025/04/04/nsa_boss_deputy_fired/">fired in early April</a>. General Haugh was a pivotal figure in defending the nation's cyber infrastructure, especially noted for countering Russian interference dating back to the 2016 election. His dismissal, along with the removal of other senior cyber officials, has significantly weakened the country's cyber defense. Why? What was his offense? Laura Loomer, a far-right conspiracy theorist and Trump buddy, disliked him.</p>
<p>The administration has also systematically dismantled critical cybersecurity advisory bodies. Notably, the Cyber Safety Review Board (CSRB), established under the previous Biden administration to investigate major cyber incidents, was effectively disbanded by terminating all its members. This <a target="_blank" href="https://www.theregister.com/2025/01/22/dhs_axes_cyber_advisory_boards/">move halted</a> investigations into significant cyberattacks, including the Chinese "Salt Typhoon" hacks.</p>
<p>Mind you, the Salt Typhoon attacks were also aimed at Trump and VP JD Vance, but for some reason, don't ask me why, they don't care. We already know that Trump is buddy-buddy with Russia, but China? The country he's having a major trade war with? This makes no sense to me.</p>
<p>So, who should be in charge of protecting the US's cyber resources? The state and local governments, would you believe?</p>
<p>According to Trump's <a target="_blank" rel="nofollow" href="https://www.whitehouse.gov/presidential-actions/2025/03/test/">Achieving Efficiency Through State and Local Preparedness</a> executive order: "Preparedness is most effectively owned and managed at the State, local, and even individual levels, supported by a competent, accessible, and efficient Federal Government. Citizens are the immediate beneficiaries of sound local decisions and investments designed to address risks, including cyberattacks, wildfires, hurricanes, and space weather."</p>
<ul>

<li><a href="https://www.theregister.com/2025/04/14/miyazaki_ai_and_intellectual_property/">It's fun making Studio Ghibli-style images with ChatGPT – but intellectual property is no laughing matter</a></li>

<li><a href="https://www.theregister.com/2025/02/07/opinion_column_musk/">Musk's move fast and break things mantra won't work in US.gov</a></li>

<li><a href="https://www.theregister.com/2025/01/28/windows_10_demise_linux/">Windows 10's demise nears, but Linux is forever</a></li>

<li><a href="https://www.theregister.com/2025/01/11/opinion_column_us_moves/">Is it really the plan to take over Greenland and the Panama Canal? It's been a weird week</a></li>
</ul>
<p>Part of that clearly sets the stage for getting rid of the Federal Emergency Management Administration (FEMA), but space weather!? Cyberattacks!!? Do you know how few real IT security experts are out there? Do you think all 50 states can hire enough? I don't. Oh, and let us not forget, cyberattacks aren't only made against, say, North Carolina and West Virginia, they hit everyone, everywhere. Fifty different groups trying to cope with state-sponsored elite hacking teams is too stupid for words.</p>
<p>Oh, and did I mention? Earlier in his tenure, <a target="_blank" rel="nofollow" href="https://cyberscoop.com/trump-pause-grants-aid-federal-cyber-programs/">Trump had cut funding for cybersecurity-specific federal grant programs</a>. So, good luck hiring top-flight security mavens to protect your home state.</p>
<p>Let's also not forget the enemy inside. DOGE has access to sensitive federal systems. These include the Treasury Department's payment systems and the Social Security System. It appears that this data had been copied to God alone knows where and can now be accessed by people without the right to see or use it.</p>
<p>So not only has America's external cyber defenses been dismantled, but the data is out there for the greatest security attacks ever on individual citizens. <a target="_blank" href="https://www.theregister.com/2025/04/15/landmark_admin_data_loss/?td=rt-3a">1.6 million people had their Social Security information stolen from an insurance company</a>? That's so penny-ante.</p>
<p>The US will suffer the most from these self-inflicted security wounds, but the entire world will feel the pain. "Buckle up, we're in for a bumpy ride." ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Apple and Meta fined millions for breaching EU law (355 pts)]]></title>
            <link>https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html</link>
            <guid>43770337</guid>
            <pubDate>Wed, 23 Apr 2025 10:01:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html">https://ca.finance.yahoo.com/news/apple-fined-570-million-meta-094701712.html</a>, See on <a href="https://news.ycombinator.com/item?id=43770337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><!-- HTML_TAG_START -->By Foo Yun Chee and Jan Strupczewski<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->BRUSSELS (Reuters) -Apple was fined 500 million euros ($570 million) on Wednesday and Meta 200 million euros, as European Union antitrust regulators handed out the first sanctions under landmark legislation aimed at curbing the power of Big Tech.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU fines could stoke tensions with U.S. President Donald Trump who has threatened to levy tariffs against countries that penalise U.S. companies.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->They follow a year-long investigation by the European Commission, the EU executive, into whether the companies comply with the Digital Markets Act (DMA) that seeks to allow smaller rivals into markets dominated by the biggest companies.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The fines signal that the EU is sticking to its guns in enforcing the new rules, which were introduced in 2023. That is despite Trump citing the DMA while vowing in February to "defend American companies and innovators from overseas extortion".<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Alphabet's Google and Elon Musk's X are also facing potential fines from European regulators.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU will be encouraged by a U.S. court judgment earlier this month which found that Google illegally dominates two markets for online advertising technology, Commission sources say. That ruling could pave the way for U.S. antitrust prosecutors to seek a breakup of its ad products.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Apple said it would challenge the EU fine.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"Today's announcements are yet another example of the European Commission unfairly targeting Apple in a series of decisions that are bad for the privacy and security of our users, bad for products, and force us to give away our technology for free," Apple said in an emailed statement.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->Meta also criticised the EU decision.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"The European Commission is attempting to handicap successful American businesses while allowing Chinese and European companies to operate under different standards," its Chief Global Affairs Officer Joel Kaplan said in an emailed statement.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->"This isn't just about a fine; the Commission forcing us to change our business model effectively imposes a multi-billion-dollar tariff on Meta while requiring us to offer an inferior service."<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The fines are modest compared to the penalties meted out by the previous EU antitrust chief Margrethe Vestager during her term. Sources, speaking on condition of anonymity, have said this is due to the short period of the breaches, a focus on compliance rather than sanctions, and a desire to avoid possible retaliation from Trump.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->PAY-OR-CONSENT MODEL<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->The EU competition watchdog said Apple must remove technical and commercial restrictions that prevent app developers from steering users to cheaper deals outside the App Store.<!-- HTML_TAG_END --></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI wants to buy Chrome and make it an "AI-first" experience (144 pts)]]></title>
            <link>https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/</link>
            <guid>43770312</guid>
            <pubDate>Wed, 23 Apr 2025 09:55:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/">https://arstechnica.com/ai/2025/04/chatgpt-head-tells-court-openai-is-interested-in-buying-chrome/</a>, See on <a href="https://news.ycombinator.com/item?id=43770312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>According to Turley, OpenAI would throw its proverbial hat in the ring if Google had to sell. When asked if OpenAI would want Chrome, he was unequivocal. "Yes, we would, as would many other parties," <a href="https://www.theinformation.com/articles/openai-buy-chrome-executive-testifies">Turley said</a>.</p>
<p>OpenAI has reportedly considered building its own Chromium-based browser to compete with Chrome. Several months ago, the company hired former Google developers Ben Goodger and Darin Fisher, both of whom worked to bring Chrome to market.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg">
    <p><img width="1000" height="665" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg" alt="Close-up of Google Chrome Web Browser web page on the web browser. Chrome is widely used web browser developed by Google." decoding="async" loading="lazy" srcset="https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser.jpg 1000w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-640x426.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-768x511.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2025/01/google-chrome-browser-980x652.jpg 980w" sizes="auto, (max-width: 1000px) 100vw, 1000px">
                  </p>
          <figcaption>
        <div>
    
    <p><span>
          Credit:

          
          Getty Images

                  </span>
          </p>
  </div>
      </figcaption>
      </a></figure>
<p>It's not hard to see why OpenAI might want a browser, particularly Chrome with its 4 billion users and 67 percent market share. Chrome would instantly give OpenAI a massive install base of users who have been incentivized to use Google services. If OpenAI were running the show, you can bet ChatGPT would be integrated throughout the experience—Turley said as much, predicting an "AI-first" experience. The user data flowing to the owner of Chrome could also be invaluable in training <a href="https://arstechnica.com/ai/2025/01/openai-launches-operator-an-ai-agent-that-can-operate-your-computer/">agentic AI models</a> that can operate browsers on the user's behalf.</p>
<p>Interestingly, there's so much discussion about who should buy Chrome, but relatively little about spinning off Chrome into an independent company. Google has contended that Chrome can't survive on its own. However, the existence of Google's multibillion-dollar search placement deals, which the DOJ wants to end, suggests otherwise. Regardless, if Google has to sell, and OpenAI has the cash, we might get the proposed "AI-first" browsing experience.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Gruen Transfer is consuming the internet (260 pts)]]></title>
            <link>https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet</link>
            <guid>43769936</guid>
            <pubDate>Wed, 23 Apr 2025 08:49:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet">https://sebs.website/blog/the%20gruen-transfer-is-consuming-the-internet</a>, See on <a href="https://news.ycombinator.com/item?id=43769936">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Have you ever walked into a supermarket, pharmacy, or department store looking to buy a specific item, only to find the layout confusing? Perhaps you ended up aimlessly strolling around, purchasing other items? This is deliberate, and known as the Gruen Transfer.  </p>
<p>The 'Transfer' part is the moment that you, as a consumer surrounded by a deliberately confusing layout, lose track of your original intentions.  </p>
<p>We've all experienced it, and now it's starting to consume the internet. It first appeared on Facebook, with the introduction of the feed. Originally intended as a way to simplify updates from your friends, and hold your attention captive for longer. However somewhere along the line, the feed became more than that. Facebook now feels more confusing than my local department store, and my original reason for visiting (keeping up to date with friends &amp; family) is quickly forgotten. The last time I checked Facebook, maybe 10% of my feed was updates from friends. The rest was a combination of ads, memes, and influencer marketing videos, leaving me doom scrolling endlessly.    </p>
<p>This isn't relegated to Facebook though, or even social media. So many websites are now designed to disorient you upon visiting, so that you start acting impulsively. This can even happen in a relatively benign way - who hasn't looked up something on Wikipedia and fell down a rabbit hole that ended looking at a <a href="https://en.wikipedia.org/wiki/List_of_animals_awarded_human_credentials">list of animals awarded human credentials</a>?  </p>
<p>It pops up in other areas as well, closely associated with several UX dark patterns. If you've tried to permanently delete your account from any major social network, you’ll know what I mean. It is utterly confusing to find and navigate to the page you need, and the site will desperately conjole you into doing something other than deleting your account. It's the same for trying to alter your insurance policy, cancel subscriptions, spend frequent flyer miles, and so on...  </p>
<p>I wonder where all this will end? There must be a point at which the friction generated by needless complexity has a detrimental effect. A kind of <a href="https://en.wikipedia.org/wiki/Laffer_curve#:~:text=In%20economics%2C%20the%20Laffer%20curve,of%20the%20government's%20tax%20revenue.">Laffer Curve</a> of web design.  </p>
<p>In the EU, it is a legal requirement to allow your customers the same method, with the same number of steps and complexity, for canceling as for subscribing. So if it takes 10 seconds to fill in a form online to get subscribed, they need to offer the same ease of use for canceling.  </p>
<p>I like this idea of ‘complexity’ as a measure for legislation. Now if only they could apply the same thing to my local Boots when I'm trying to buy toothpaste.  </p>
                  </div><p>If you've made it this far I owe you a beer the next time I see you 🍺. Want to get in touch? <a href="http://twitter.com/sebs_tweets">Follow me on Twitter(X)</a>.</p></div>]]></description>
        </item>
    </channel>
</rss>