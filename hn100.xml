<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 09 Aug 2023 14:00:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[The Fear of AI Just Killed a Useful Tool (157 pts)]]></title>
            <link>https://www.techdirt.com/2023/08/08/the-fear-of-ai-just-killed-a-very-useful-tool/</link>
            <guid>37060974</guid>
            <pubDate>Wed, 09 Aug 2023 11:08:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.techdirt.com/2023/08/08/the-fear-of-ai-just-killed-a-very-useful-tool/">https://www.techdirt.com/2023/08/08/the-fear-of-ai-just-killed-a-very-useful-tool/</a>, See on <a href="https://news.ycombinator.com/item?id=37060974">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storywrap-418142">


<h3>from the <i>can-we-not?</i> dept</h3>

<p>I do understand why so many people, especially creative folks, are worried about AI and how it’s used. The future is quite unknown, and things are changing very rapidly, at a pace that can feel out of control. However, when concern and worry about new technologies and how they may impact things morphs into mob-inspiring fear, dumb things happen. I would much rather that when we look at new things, we take a more realistic approach to them, and look at ways we can keep the good parts of what they provide, while looking for ways to mitigate the downsides.</p>
<p>Hopefully without everyone going crazy in the meantime. Unfortunately, that’s not really the world we live in.</p>
<p>Last year, when everyone was focused on generative AI for images, we had Rob Sheridan on the podcast to talk about why it was important for creative people to figure out <a rel="noreferrer noopener" href="https://www.techdirt.com/2022/09/13/techdirt-podcast-episode-329-is-ai-art-the-end-for-artists/" target="_blank">how to embrace the technology</a> rather than fear it. The opening story of the <a rel="noreferrer noopener" href="https://www.nytimes.com/2023/07/29/technology/mike-masnick-techdirt-internet-future.html" target="_blank">recent NY Times profile of me</a> was all about me in a group chat, trying to suggest to some very creative Hollywood folks how to embrace AI rather than simply raging against it. And I’ve already called out how folks rushing to copyright, thinking that will somehow “save” them from AI, are <a rel="noreferrer noopener" href="https://www.techdirt.com/2023/07/19/stop-rushing-to-copyright-as-a-tool-to-solve-the-problems-of-ai/" target="_blank">barking up the wrong tree</a>.</p>
<p>But, in the meantime, the fear over AI is leading to some crazy and sometimes unfortunate outcomes. Benji Smith, who created what appears to be an absolutely amazing tool for writers, <a rel="noreferrer noopener" href="https://www.shaxpir.com/" target="_blank">Shaxpir</a>, also created what looked like an absolutely fascinating tool called Prosecraft, that had scanned and analyzed a whole bunch of books and would let you call up really useful data on books.</p>
<p>He created it years ago, based on an idea he had years earlier, trying to understand the length of various books (which he initially kept in a spreadsheet). As <a target="_blank" rel="noreferrer noopener" href="https://blog.shaxpir.com/taking-down-prosecraft-io-37e189797121">Smith himself describes in a blog post</a>:</p>
<blockquote>
<p><em>I heard a story on NPR about how </em><a target="_blank" rel="noreferrer noopener" href="https://www.youtube.com/watch?v=oP3c1h8v2ZQ"><em><u>Kurt Vonnegut</u></em></a><em> invented an idea about the “shapes of stories” by counting happy and sad words. The University of Vermont “Computational Story Lab” published </em><a target="_blank" rel="noreferrer noopener" href="https://hedonometer.org/papers.html"><em><u>research papers</u></em></a><em> about how this technique could show the major plot points and the “emotional story arc” of the </em><a target="_blank" rel="noreferrer noopener" href="https://hedonometer.org/books/v2/Harry%20Potter%20and%20the%20Sorcerer's%20Stone/"><em><u>Harry Potter</u></em></a><em> novels (as well as many many other books).</em></p>
<p><em>So I tried it myself and found that I could plot a graph of the emotional ups and downs of any story. I added those new “sentiment analysis” tools to the prosecraft website too.</em></p>
<p><em>When I ran out of books on my own shelves, I looked to the internet for more text that I could analyze, and I used web crawlers to find more books. I wanted to be mindful of the diversity of different stories, so I tried to find books by authors of every race and gender, from every different cultural and political background, writing in every different genre and exploring all different kinds of themes. Fiction and nonfiction and philosophy and science and religion and culture and politics.</em></p>
<p><em>Somewhere out there on the internet, I thought to myself, there was a new author writing a horror or romance or fantasy novel, struggling for guidance about how long to write their stories, how to write more vivid prose, and how much “passive voice” was too much or too little.</em></p>
<p><em>I wanted to give those budding storytellers a suite of “lexicographic” tools that they could use, to compare their own writing with the writing of authors they admire. I’ve been working in the field of computational linguistics and machine learning for 20+ years, and I was always frustrated that the fancy tools were only accessible to big businesses and government spy agencies. I wanted to bring that magic to everyone.</em></p>
</blockquote>
<p>Frankly, all of that sounds amazing. And amazingly useful. Even more amazing is that he built it, and it worked. It would produce useful analysis of books, such as this example from Alice’s Adventures in Wonderland:</p>
<div>
<figure><img decoding="async" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/66fe5a2d-6b6a-4a0c-ac35-ac0be3cae2b0-RackMultipart20230808-122-dsis3v.png?ssl=1" alt="" data-recalc-dims="1"></figure>
</div>
<p>And, it could also do further analysis like the following:</p>
<div>
<figure><img decoding="async" fetchpriority="high" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/ed8ec575-1878-412b-a5f5-6d8b19fc0166-RackMultipart20230808-139-rgmlwd.png?resize=550%2C198&amp;ssl=1" alt="" width="550" height="198" data-recalc-dims="1"></figure>
</div>
<p>This is all quite interesting. It’s also the kind of thing that data scientists do on all kinds of work for useful purposes.</p>
<p>Smith built Prosecraft into Shaxpir, again, making it a more useful tool. But, on Monday, some authors on the internet found out about it and lost their shit, <a rel="noreferrer noopener" href="https://gizmodo.com/prosecraft-books-shut-down-ai-algorithms-novel-fiction-1850715319" target="_blank">leading Smith to shut the whole project down</a>.</p>
<p>There seems to be a lot of misunderstanding about all of this. Smith notes that he had researched the copyright issues and was sure he wasn’t violating anything, and he’s right. We’ve gone over this many times before. <a rel="noreferrer noopener" href="https://www.techdirt.com/2013/11/14/google-gets-total-victory-over-authors-guild-book-scanning-is-fair-use/" target="_blank">Scanning books is pretty clearly fair use</a>. What you do with that later <em>could</em> violate copyright law, but I don’t see anything that Prosecraft did that comes anywhere even remotely close to violating copyright law.</p>
<p>But… some authors got pretty upset about all of it.</p>
<div>
<figure><img decoding="async" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/5b81191f-7361-47b1-88d5-4260025691ea-RackMultipart20230808-162-wkk8di.png?ssl=1" alt="" data-recalc-dims="1"></figure>
</div>
<p>I’m still perplexed at what the complaint is here? You don’t need to “consent” for someone to analyze your book. You don’t need to “consent” to someone putting up statistics about their analysis of your book.</p>
<p>But, Zach’s tweet went viral with a bunch of folks ready to blow up anything that smacks of tech bro AI, and lots of authors started yelling at Smith.</p>
<div>
<figure><img decoding="async" src="https://i0.wp.com/lex-img-p.s3.us-west-2.amazonaws.com/img/c1fdb6a0-0bca-4b2c-b9c6-5103b6997b50-RackMultipart20230808-122-gei1hr.png?ssl=1" alt="" data-recalc-dims="1"></figure>
</div>
<p>The Gizmodo article has a ridiculously wrong “fair use” analysis, saying “Fair Use does not, by any stretch of the imagination, allow you to use an author’s entire copyrighted work without permission as a part of a data training program that feeds into your own ‘AI algorithm.’” Except… it almost certainly does? Again, we’ve gone through this with the Google Book scanning case, and the courts said that you can absolutely do that because it’s transformative.</p>
<p>It seems that what really tripped up people here was the “AI” part of it, and the fear that this was just another a VC funded “tech bro” exercise of building something to get rich by using the works of creatives. Except… none of that is accurate. As Smith explained in his blog post:</p>
<blockquote>
<p><em>For what it’s worth, the prosecraft website has never generated any income. The Shaxpir desktop app is a labor of love, and during most of its lifetime, I’ve worked other jobs to pay the bills while trying to get the company off the ground and solve the technical challenges of scaling a startup with limited resources. We’ve never taken any VC money, and the whole company is a two-person operation just working our hardest to serve our small community of authors.</em></p>
</blockquote>
<p>He also recognizes that the concerns about it being some “AI” thing are probably what upset people, but plenty of authors have found the tool super useful, and even added their own books:</p>
<blockquote>
<p><em>I launched the prosecraft website in the summer of 2017, and I started showing it off to authors at writers conferences. The response was universally positive, and I incorporated the prosecraft analytic tools into the Shaxpir desktop application so that authors could privately run these analytics on their own works-in-progress (without ever sharing those analyses publicly, or even privately with us in our cloud).</em></p>
<p><em>I’ve spent thousands of hours working on this project, cleaning up and annotating text, organizing and tweaking things. A small handful of authors have even reached out to me, asking to have their books added to the website. I was grateful for their enthusiasm.</em></p>
<p><em>But in the meantime, “AI” became a thing.</em></p>
<p><em>And the arrival of AI on the scene has been tainted by early use-cases that allow anyone to create zero-effort impersonations of artists, cutting those creators out of their own creative process.</em></p>
<p><em>That’s not something I ever wanted to participate in.</em></p>
</blockquote>
<p>Smith took the project down entirely because of that. He doesn’t want to get lumped in with other projects, and even though his project is almost certainly legal, he recognized that this was becoming an issue:</p>
<blockquote>
<p><em>Today the community of authors has spoken out, and I’m listening. I care about you, and I hear your objections.</em></p>
<p><em>Your feelings are legitimate, and I hope you’ll accept my sincerest apologies. I care about stories. I care about publishing. I care about authors. I never meant to hurt anyone. I only hoped to make something that would be fun and useful and beautiful, for people like me out there struggling to tell their own stories.</em></p>
</blockquote>
<p>I find all of this really unfortunate. Smith built something really cool, really amazing, that does not, in any way, infringe on anyone’s rights. I get the kneejerk reaction from some authors, who feared that this was some obnoxious project, but couldn’t they have taken 10 minutes to look at the details of what it was they were killing?</p>
<p>I know we live in an outrage era, where the immediate reaction is to turn the outrage meter up to 11. I’m certainly guilty of that at times myself. But this whole incident is just sad. It was an overreaction from the start, destroying what had been a clear labor of love and a useful project, through misleading and misguided attacks from authors.</p>
<p>
Filed Under: <a href="https://www.techdirt.com/tag/ai/" rel="tag">ai</a>, <a href="https://www.techdirt.com/tag/analysis/" rel="tag">analysis</a>, <a href="https://www.techdirt.com/tag/benjy-smith/" rel="tag">benjy smith</a>, <a href="https://www.techdirt.com/tag/book-scanning/" rel="tag">book scanning</a>, <a href="https://www.techdirt.com/tag/copyright/" rel="tag">copyright</a>, <a href="https://www.techdirt.com/tag/data/" rel="tag">data</a>, <a href="https://www.techdirt.com/tag/fair-use/" rel="tag">fair use</a>, <a href="https://www.techdirt.com/tag/prosecraft/" rel="tag">prosecraft</a>, <a href="https://www.techdirt.com/tag/sentiment-analysis/" rel="tag">sentiment analysis</a>
<br>
Companies: <a href="https://www.techdirt.com/company/shaxpir/" rel="category tag">shaxpir</a>
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WeWork Warns of Possible Bankruptcy (109 pts)]]></title>
            <link>https://www.cnbc.com/2023/08/08/wework-warns-of-remaining-going-concern-and-says-bankruptcy-possible.html</link>
            <guid>37060871</guid>
            <pubDate>Wed, 09 Aug 2023 10:51:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2023/08/08/wework-warns-of-remaining-going-concern-and-says-bankruptcy-possible.html">https://www.cnbc.com/2023/08/08/wework-warns-of-remaining-going-concern-and-says-bankruptcy-possible.html</a>, See on <a href="https://news.ycombinator.com/item?id=37060871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107283593" data-test="InlineImage"><p>29 July 2023, Australia, Sydney: The logo of "Wework," a company that offers office space and coworking spaces for the self-employed and businesses, lights up downtown in front of skyscrapers.</p><p>Sebastian Christoph Gollnow | Picture Alliance | Getty Images</p></div><div><p>Four years ago <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/WE/">WeWork</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> was preparing for a blockbuster IPO. Now the company is warning of possible bankruptcy.</p><p>"Our losses and negative cash flows from operating activities raise substantial doubt about our ability to continue as a going concern," WeWork said in a <a href="https://www.sec.gov/Archives/edgar/data/1813756/000181375623000059/we-20230630.htm" target="_blank">filing</a> with the SEC on Tuesday. </p><p>The spectacular collapse of a company once valued by SoftBank at <a href="https://www.cnbc.com/2018/10/10/softbank-in-talks-to-buy-majority-stake-in-loss-making-wework-source.html">$40 billion</a> has been years in the making, but is still surprising given the number of large commercial buildings around the world that don the company's name. The combination of the Covid pandemic, which led many businesses to exit their leases in favor of remote work, and the subsequent economic slump, has left WeWork heavy on debt and struggling to generate cash. </p><p>"If we are not successful in improving our liquidity position and the profitability of our operations, we may need to consider all strategic alternatives, including restructuring or refinancing our debt, seeking additional debt or equity capital, reducing or delaying our business activities and strategic initiatives, or selling assets, other strategic transactions and/or other measures, including obtaining relief under the U.S. Bankruptcy Code," the company said.</p><p>WeWork's stock has been trading below $1 since mid-March. It tumbled 26% to 15 cents in extended trading on Tuesday and now has a market cap below $500 million.</p><p>The company had a net loss in the first half of the year of $700 million after losing $2.3 billion in 2022. As of June 30, it had $205 million in cash and equivalents and total liquidity of $680 million. It has $2.91 billion in long-term debt. </p><p>WeWork first <a href="https://www.cnbc.com/2019/08/14/wework-releases-s-1-filing-for-ipo.html">sought</a> to go public in 2019, publishing its initial prospectus in August of that year. With its full financials available for everyone to see, the business was roundly criticized due to excessive spending and risks along with founder Adam Neumann's complex relationship at the company.</p><p>The IPO never made it out the door. <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-5"><a href="https://www.cnbc.com/quotes/SOBKY/">SoftBank</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> founder and CEO Masayoshi Son called his investment in WeWork <a href="https://www.cnbc.com/2020/05/18/softbank-ceo-calls-wework-investment-foolish-valuation-falls-to-2point9-billion.html">"foolish"</a> and his company took <a href="https://www.cnbc.com/2019/10/23/softbank-to-take-control-of-wework.html">majority control</a> of the business in a $5 billion financing package. Neumann was forced to step down. </p><p>In 2021, WeWork finally <a href="https://www.cnbc.com/2021/10/21/wework-goes-public-through-spac-.html">became public</a> through a merger with a special purpose acquisition company, or SPAC. But the turbulence continued. WeWork said its revenue grew just 3.6% year over year in the second quarter and declined 4% in the U.S., where it gets 41% of its sales. </p><p>Economic conditions led more members to depart, bring down revenue and cash flow, WeWork said. Even SoftBank is spending less on WeWork. In the second quarter, the company contributed $6 million of WeWork's revenue, down from $10 million in the second quarter of 2022, according to the filing.</p><p>Key factors for whether WeWork can remain a going concern include limiting capital expenditures, increasing revenue and seeking capital through debt or equity issuance.</p><p>Three board members resigned last week because of "a material disagreement regarding Board governance and the Company's strategic and tactical direction." Daniel Hurwitz, who had been chair since May, was one of them.</p><p>WeWork is still searching for a permanent leader. The company <a href="https://investors.wework.com/news-and-events/press-releases/financial-releases-details/2023/WeWork-Announces-CEO-Transition/default.aspx" target="_blank">said</a> in May that CEO Sandeep Mathrani would step down within days and that board member David Tolley, a former finance chief at Intelsat, would become interim CEO.</p><p>"WeCrashed," a miniseries about the rise and fall of the company, debuted on Apple TV+ last year.</p><p><strong>WATCH:</strong> <a href="https://www.cnbc.com/video/2023/03/29/wework-ceo-sandeep-mathrani-todays-occupiers-are-looking-for-turnkey-solutions.html">WeWork CEO Sandeep Mathrani: Today's occupiers are looking for turnkey solutions</a></p></div><div id="Placeholder-ArticleBody-Video-107216904" data-test="VideoPlaceHolder" role="region" tabindex="0" data-vilynx-id="7000292231" aria-labelledby="Placeholder-ArticleBody-Video-107216904"><p><img src="https://image.cnbcfm.com/api/v1/image/107216905-16800891191680089116-28786038316-1080pnbcnews.jpg?v=1680093166&amp;w=750&amp;h=422&amp;vtcrop=y" alt="WeWork CEO Sandeep Mathrani: Today's occupiers are looking for turnkey solutions"><span></span><span></span></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mullvad VPN – Infrastructure Audit Completed by Open Security (264 pts)]]></title>
            <link>https://mullvad.net/en/blog/2023/8/9/infrastructure-audit-completed-by-radically-open-security/</link>
            <guid>37060654</guid>
            <pubDate>Wed, 09 Aug 2023 10:18:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mullvad.net/en/blog/2023/8/9/infrastructure-audit-completed-by-radically-open-security/">https://mullvad.net/en/blog/2023/8/9/infrastructure-audit-completed-by-radically-open-security/</a>, See on <a href="https://news.ycombinator.com/item?id=37060654">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>We tasked the Netherlands based security firm Radically Open Security (RoS) with performing the third audit towards our VPN infrastructure.</p>

<p>We asked them to focus solely on VPN servers that run from RAM, one OpenVPN and one WireGuard server.</p>

<p>We invite you to <a href="https://mullvad.net/media/Mullvad_VPN_Pentest_Report_2023_1.1.pdf">read the final report</a><strong> </strong>of our third security audit, concluded in mid-June 2023, with many fixes deployed late June 2023. Further re-tests and a verification pass was performed during July.</p>

<p>RoS discovered a number of new findings, and we would like to thank them for their thorough and detailed report. They stated , amongst other things that: that whilst they found some issues, that: “The Mullvad VPN relays which were the subject of this test showed a mature architecture…” and “During the test we found no logging of user activity data..”</p>

<p>We gave RoS full SSH access to two (2) VPN servers that were running from RAM, using our latest slimmed down Linux kernel (6.3.2) and customised Ubuntu 22.04 LTS based OS. These servers were deployed as though they were <strong>to be</strong> production customer-facing servers, however these servers <strong>have never been utilised </strong>as such.</p>

<p>We asked them to verify:</p>

<ul>
	<li>Security and set up of servers internally</li>
	<li>Security and set up of servers externally</li>
	<li>Whether or not we log customer activity</li>
</ul>

<p>RoS also asked whether they should investigate the source code of various binaries running on our systems, or whether they should take into consideration the hardware-level security. We declined both offers, stating that this is to be considered an <em>“after the system is running and in-use by customers”</em> audit.</p>

<h2>Overview of findings</h2>

<ul>
	<li>Radically Open Security found no information leakage or logging of customer data</li>
	<li>RoS discovered 1 High, 6 Elevated, 4 Moderate, 10 Low and 4 info-severity issues during this penetration test.</li>
</ul>

<p><strong>Key takeaway:</strong> Our VPN infrastructure has been audited for the third time.</p>

<h2>Miscellaneous issues of interest</h2>

<h3>MLL-024 Production multihop traffic on test system (High)</h3>

<p><strong>To quote RoS:</strong><em> “Impact - Production user traffic is visible to pentest users.”</em></p>

<p><strong>Our comments:</strong></p>

<p>RoS were given production-like servers, provisioned and deployed like all other customer facing servers. The difference between these and the rest of our fleet is that they have never been made available for customers to connect, they were not advertised in our server list, and not offered up to users. However, as these servers are connected to our WireGuard multihop functionality, <strong>any customer scanning for IPs</strong> can send traffic though them whilst connected to another VPN server using a SOCKS5 proxy, as there is nothing blocking it.</p>

<p>In what RoS discovered there was only the IP from the WireGuard internal interface. This interface is only available to SOCKS5 multihop traffic, so it would be the entry WireGuard server.</p>

<p>Without providing RoS with production servers the audit would not have been valid as a production server audit, and there would have been no way to prevent customer traffic from being visible on the servers.</p>

<h3>MLL-019 - LPE to root using systemd timers and insecure directory permissions (Elevated)</h3>

<p><strong>To quote RoS:</strong><em> “Low-privileged system accounts can elevate their privileges to root by manipulating systemd timer script content.”</em></p>

<p><strong>Our comments:</strong></p>

<p>It became obvious after consulting with RoS that the primary issue here is the use of nested home directories, and the addition of administrator users being part of the <code>mad</code> group.</p>

<p>The usage of the nested <code>/home/mad</code> directory structure is a legacy remnant of pre-RAM VPN servers, which is going to be removed in the upcoming updates to our infrastructure. In the short-term we have removed all administrator users from being part of the <code>mad</code> group, but we have also moved all related scripts to <code>/opt/local_checks</code> which RoS acknowledged as resolving the issue.</p>

<h3>MLL-045 — Administrator access to production machines (Moderate)</h3>

<p><strong>To quote RoS:</strong> <em>“VPN servers accept remote logins from administrators, who technically have the ability to tap into production users' VPN traffic”</em></p>

<p><strong>Our comments:</strong></p>

<p>We have been aware of this issue for some time, and conversing with RoS only confirmed our plans to implement such measures:</p>

<ul>
	<li>Implement a method by which unauthorised logins can be auditable, and add a log of all the commands (without arguments) used on these servers. We are implementing such a system.</li>
	<li>Remove support for SSH entirely, this would mean that even administrators could not enable logging of customer traffic, since no access is enabled over SSH. We are investigating such a system, though this will take more time to perform correctly.</li>
</ul>

<h3>MLL-016 - Telegraf password shared across servers (low)</h3>

<p><strong>To quote RoS: </strong><em>“Shared Influx database credentials used by Telegraf across VPN servers allows manipulation of global server metrics, such as CPU and disk usage or network metrics.”</em></p>

<p><strong>Our comments:</strong></p>

<p>We deemed the best course of action here to implement client certificates for authentication using the PKI infrastructure available within Hashicorp Vault. This has now been implemented, and we will investigate the use of such certificates in other places across our infrastructure.</p>

<p>---</p>

<p>There are more changes to be deployed in the near future, and the listed fixes are examples of the most interesting issues that Radically Open Security found.</p>

<p>For the universal right to privacy,<br>
Mullvad</p>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New part day: Finally a 100% new Commodore 64 can be built (120 pts)]]></title>
            <link>https://1nt3r.net/j-cia/</link>
            <guid>37060269</guid>
            <pubDate>Wed, 09 Aug 2023 09:07:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://1nt3r.net/j-cia/">https://1nt3r.net/j-cia/</a>, See on <a href="https://news.ycombinator.com/item?id=37060269">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>J-CIA - MOS 6526 / 8521 / (8520) FPGA REPLACEMENT</h2>
<p><img src="https://1nt3r.net/j-cia/JCIA64_2.JPG" alt="J-CIA, J-CIA64, J6526, FPGA 6526 / 8521"></p><h2>Modern spare part for Commodore 64, Commodore 128, SX-64 and 1570/1571 -drives</h2>

<li>FPGA based replacement for MOS 6526 &amp; 8521 CIA chips</li>
<li>Complete logic and all features of the original IC's implemented</li>
<li>All diagnostic &amp; software tests passed 100%, including all tests in Wolfgang Lorenz's test suite and Vice-project's CIA-tests.</li>
<li>[Vice's ciaports-tests may show partly incorrect results, but then again, original cias show variable results too.]</li>
<li>Hundreds of demos and games already tested, no known compatibility issues currently</li>
<li>Physically about the same size as the original CIAs</li>
<li>Lots of hardware tested and found to be compatible including (but not limited to) WifiModem, Ultimate-II+, SD2IEC, TapeCart, 1351-mouse</li>
<li>Tested with all C64 mainboard revisions, SX-64 and with EVO64 mainboard, Commodore 128 (including CP/M and disk drive burst-mode) and 1570 &amp; 1571.</li>
<li>Works in 1 MHz and 2 MHz modes.</li>
<li>This 6526/8521 version has been tested to work on a 1581 drive too by a betatester, but full compatibility cannot be guaranteed.
</li><li>(8520 Amiga -version would be the correct one for 1581)</li>
<li>&nbsp;</li>
<li><span color="red">This "J-CIA64" -version is not compatible with Amiga / 8520-CIA and cannot be later converted or upgraded to be.</span></li>
<li>Amiga -compatible version will be a separate product that will be released later.</li>

<h3>Changing mode between 8521 "new" and 6526 "old" CIA:</h3>
<li>Mode between new (8521) and old (6526) cia type can be changed</li>
<li>with a solder jumper on the underside of J-CIA64</li>
<li>"New" 8521 mode is default and 6526-mode can be enabled by soldering</li>
<li>two pads together as in the right on the image below:</li>
<p><img src="https://1nt3r.net/j-cia/mode-jumper.jpg" alt="J-CIA64 mode jumper"></p><li>Usually, the mode doesn't need to be changed,</li>
<li>most sofware and hardware are designed to work with both versions.</li>
<h3>Installation</h3>
<li>Although J-CIA could be soldered directly to mainboard, using IC sockets is highly recommended.</li>
<li>Pins on J-CIA are gold plated round pins, which will work with all kinds of sockets, but</li>
<li>the pins are a bit thicker than original IC-pins, which may cause slight stress to some leaf-type</li>
<li>sockets. This is a the same with all reproduction IC's with turned pins. </li>
<li>Be careful when pressing the J-CIA into a socket and make sure it is aligned properly and </li>
<li>pressed down evenly to avoid bending or breaking of pins.</li>
<li>&nbsp;</li>
<li>J-CIA orientation: PIN 1 is marked with a number 1 on PCB. That should match PIN 1 position on mainboard.</li>
<li>There is also a half circle marked on the top of the J-CIA. This relates to the notch on original IC's and the notch on IC-sockets</li>
<li>On a C64 CIA PIN 1 is located on top left of the both CIA -locations.</li>
<li>On a C128 the other CIA position is "upside-down", so be careful installing a new CIA the correct way</li>
<li>&nbsp;</li>
<li>Original RF-shields may require insulating, modifications or even removing.</li>
<li>Before turning on the power, check that the RF-shield metal does not touch J-CIA(s).</li>
<h3>Disclaimer</h3>
<li>J-CIA / J-CIA64 reproduces the functionality of the original MOS CIA's</li>
<li>Because it's a reproduction, it cannot be ever fully like the original.</li>
<li>Logic aims to be exactly like the original, but there may be differences that have not been found yet.</li>
<li>Electrically J-CIA is "close enough" to the original CIA, but it is not exactly the same.</li>
<li><i>Although tested with a lot of hardware and software, compatibility with all hardware and software cannot be guaranteed.</i></li>
<li>nstalling the J-CIA64 requires delicate handling and taking the proper precautions to prevent antistatic discharges.</li>
<li>The seller or manufacturer cannot be held responsible for any possible damage this product may cause to your</li>
<li>equipment due to incorrect installation or mishandling of the product.</li>

<h3>More info</h3>
<li>J-CIAs tested on Retro Recipes youtube -channel: <a href="https://youtu.be/EL2HVRtjuIg">https://youtu.be/EL2HVRtjuIg</a></li>
<li>&nbsp;</li>
<h3>Where to buy?</h3>
<li>J-CIA is or will be available soon at the following online shops:</li>
<li>&nbsp;</li>
<li>Run Stop Re-Store on Retro8bitshop is one of the biggest Commodore 64 spare parts depot in the world,</li>
<li>with huge stocks of New Old Stock components, as well as modern alternatives, with fast shipping and top-notch service.</li>
<li>J-CIA at their web shop: <a href="https://retro8bitshop.com/product/j-cia64/">https://retro8bitshop.com/product/j-cia64/</a>
</li><li>Run Stop Re-Store ships internationally!</li>
<li>&nbsp;</li>
<li>Retrospective shop will have J-CIA's in stock soon.</li>
<li><a href="https://retrospective.shop/">https://retrospective.shop/</a> Retrospective shop ships internationally too!</li>
<li>&nbsp;</li>
<li>Finnish customers can buy J-CIA's at Am-Mek web shop at <a href="https://shop.am-mek.fi/">https://shop.am-mek.fi/</a></li>
<li>Am-Mek ships only to Finland.</li>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Intel's GPU Drivers Now Collect Telemetry, Including 'How You Use Your Computer' (108 pts)]]></title>
            <link>https://www.extremetech.com/gaming/intels-gpu-drivers-now-collect-telemetry-including-how-you-use-your-computer</link>
            <guid>37060226</guid>
            <pubDate>Wed, 09 Aug 2023 09:01:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.extremetech.com/gaming/intels-gpu-drivers-now-collect-telemetry-including-how-you-use-your-computer">https://www.extremetech.com/gaming/intels-gpu-drivers-now-collect-telemetry-including-how-you-use-your-computer</a>, See on <a href="https://news.ycombinator.com/item?id=37060226">Hacker News</a></p>
Couldn't get https://www.extremetech.com/gaming/intels-gpu-drivers-now-collect-telemetry-including-how-you-use-your-computer: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Canonical's interview process step by step (by step by step by) (120 pts)]]></title>
            <link>https://old.reddit.com/r/recruitinghell/comments/15kj845/canonical_the_recruitment_process_really_is_that/</link>
            <guid>37059857</guid>
            <pubDate>Wed, 09 Aug 2023 08:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/recruitinghell/comments/15kj845/canonical_the_recruitment_process_really_is_that/">https://old.reddit.com/r/recruitinghell/comments/15kj845/canonical_the_recruitment_process_really_is_that/</a>, See on <a href="https://news.ycombinator.com/item?id=37059857">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>In case you’re wondering how Canonical’s infamous recruitment process plays out, here’s a step-by-step account of what I went through for a non-technical role. I didn’t have any immediate need to land a new job, which is part of the reason why I decided to stick with it to see how it worked. (Had I succeeded, I would have been onboarded 4-5 months after I’d sent in my CV.)</p>

<p><strong>tl;dr It took 81 days, a CV, a cover letter, an application form, a 22-question written interview, two standardised tests, and four (4) in-person interviews. And that wasn’t even close to the entire recruitment process!</strong></p>

<p>Day 0: I read about this job and I was SO EXCITED because it ticked all my boxes. I literally got home from work and applied. I submitted my CV and answered the questions in their application form. Some of them asked about high school. Canonical – or, should we say, Mark Shuttleworth, the self-appointed benevolent dictator for life - genuinely believes that knowing what you did in high school will give useful information about whether they should hire you. They justify this all over the place.</p>

<p>Day 25: Automated email from a person stating they were my hiring lead. &nbsp;This email included the written interview – 22 questions about everything from ‘What would you most want to change about Canonical?’ (sure, let me just critizicize the company I am trying to work for) to multiple questions about high school. Even if you are in a country where it isn’t called high school, or if you were homeschooled, or were in a chaotic foster care situation and moved schools multiple times, or if you dropped out and later got a GED (or didn’t). They don’t care if you have to drag up actual traumas from decades ago - you WILL tell them about high school.</p>

<p>I suspect most of the value here is that they use it as a winnowing process, given that they have tens of thousands of applicants every month. If you’re not willing to jump through this hoop, that’s one less person they have to consider.</p>

<p>I didn’t keep notes from my first interview and that person may have referred to my written interview, but no one else did, even though I had some brilliant answers (the way I won a major post-college scholarship was a masterpiece of An Example Of A Time Where I Showed Initiative, thanks very much).</p>

<p>Here it is:</p>

<p><em>Context</em></p>

<p><em>Outline your thoughts on the mission of Canonical. What is it about the company's purpose and goals which is most appealing to you? What do you see as risky or unappealing?</em></p>

<p><em>Why do you most want to work for Canonical?</em></p>

<p><em>What would you most want to change about Canonical?</em></p>

<p><em>What gets you most excited about this role?</em></p>

<p><em>What support would you need from Canonical to be successful</em></p>

<p><em>Experience</em></p>

<p><em>Please outline your most relevant experience for this role.</em></p>

<p><em>What are the key attributes of an outstanding executive assistant?</em></p>

<p><em>Please describe a situation where you had to hold firm on a difficult issue.</em></p>

<p><em>What is different about the role of Executive Assistant in a remote-first business?</em></p>

<p><em>Describe any experience you have working across many time zones.</em></p>

<p><em>Describe improvements you have made to a process in previous roles.</em></p>

<p><em>How do you remain calm in a high-stress, fast-paced environment?</em></p>

<p><em>What has been the highlight of your career so far, and why?</em></p>

<p><em>Education</em></p>

<p><em>We consider academic results in high school and university for all roles, regardless of seniority or department. To enjoy a long and varied career at Canonical, one would need to tackle problems that cannot be defined today! From engineering to marketing to operations and sales, we intensely value colleagues who are able to puzzle through difficult problems and find the optimal path forward.</em></p>

<p><em>How did you rank in your high school, in your final year in maths and hard sciences? Which was your strongest?</em></p>

<p><em>How did you rank in your high school, in your final year in languages and the arts? Which was your strongest?</em></p>

<p><em>Please state your high school graduation results or university entrance results, along with the system used, and how to understand those. For example, in the US, you might give your SAT or ACT scores. In Germany, you might give your scores 1-5.</em></p>

<p><em>What sort of high school student were you? Outside of class, what were your interests and hobbies? What would your high school peers remember you for, if we asked them?</em></p>

<p><em>Which university and degree did you choose? What other universities did you consider, and why did you select that one?</em></p>

<p><em>At university, did you do particularly well in an area of your degree?</em></p>

<p><em>Overall, what was your degree result and how did that reflect on your ability?</em></p>

<p><em>In high school and university, what did you achieve that was exceptional?</em></p>

<p><em>What leadership roles did you take on during your education?</em></p>

<p>Day 29: Submitted the written interview.</p>

<p>Day 30: Completed the Thomas GIA test. This is a standardised test which makes you rotate shapes in a box, work out basic logic problems, and do things with words and numbers. I hate standardised tests, because all they reveal is how good you are at taking standardised tests (this is what I mentioned in the ‘tell us what you’d change’ section of the written interview) and no, they are not unbiased.</p>

<p>I did as many practice tests as I could to make sure I aced it, and according to the Thomas International report I got afterwards, I scored well in all five areas. They didn’t give me my actual scores but I was ‘above average’, and they gave advice on how these results would affect&nbsp;my working relationships. For all five areas, the advice they gave me was basically, ‘when you’re talking to your wooden-headed co-workers, dumb&nbsp;it down for the proles, Brainiac.’</p>

<p>Day 32: I was invited for an interview. Or rather, three interviews – two with people on the team I was applying to, one on a different team. One hour each. They don’t compare notes, so all of their opinions are allegedly unbiased, but a) this means you get asked the same/similar questions, which is boring for me and a waste of time for them, and b) exactly how unbiased is it when every person I interviewed with was exactly my demographic? (White, female, American/western European. The fifth interview, had I reached it, would have been in that demographic too. My hiring lead was a woman of colour, but my only non-automated contact with her was one brief response to an email I sent her early in the process.)</p>

<p>Day 35: Automated email from Mark Shuttleworth which started, ‘Given that you are now starting the final stage interview to join our team’, even though I was nowhere near the final stage interviews. Mark’s icon is a green dragon, which indicated that if I made it through this interminable quest, he would be the final boss fight. Someone might want to fix the typos in this email.</p>

<p>Day 46: Peer interview 1. Pretty chill. She said she was the newest member of the team.</p>

<p>Day 51: Cross-team interview. Since this was with someone in the travel department (there was a LOT of travel with this job), I assumed she would ask me about my extensive travel experience...but no, it was all boring rote competency stuff (‘tell me about a time you solved a problem’). The final question was the ‘fun’ one – what was I watching on my favourite streaming service? I don’t have one, thanks. Seriously, though, your entire career is in travel, and this job is a lot about travel (both doing it and organising it), and I have travelled to one of the most dangerous places on earth multiple times, as I mentioned in my cover letter, and you’re not going to ask me a single question about that?</p>

<p>Day 52: Peer interview 2. Geniunely one of the most fun interviews I’ve ever had. She told me outright that she was putting me forward as a good prospect, calling me an Ubuntu fangirl (aw, shucks), telling me I’d fit in and it was great that I was genuinely interested in the product and open source and would fit in with their software engineers.</p>

<p>Day 65: Received an invitation to book my interview with the Talent team – they call them Talent Scientists (?! – even one of my interviewers thought that was a dumb name) – and do the most ridiculous standardised test ever, the Thomas PPA, where you pick words that are most and least like you, and then they calculate your actual personality from the words you don’t choose, or something. I pretended I was the best example of my role and chose the words that described that persona. No one ever referred to either of these standardised tests, by the way.</p>

<p>The interview booking email included&nbsp;the following line about scheduling this interview:</p>

<p><em>‘We’d appreciate it if you pick the earliest time available.’</em></p>

<p>You <strong>what</strong>?</p>

<p>You’ve been stringing me along for over two months, and you’re instructing <strong>me</strong> not to dawdle?</p>

<p>At some point around this time, I realised the main problem with this ridiculously drawn-out interview process was that I didn’t care anymore. I was so excited when I applied, and I lost every bit of that along the way. All I was doing was jumping through their hoops and answering the same types of questions. No one actually wanted to talk to me about any of the great things I’d told them about in my written interview, or even the interesting stuff I’d done in my most recent jobs, even when it was highly relevant for this job.</p>

<p>Day 78: Interview with the Talent ‘Scientist’. (Another white western woman.) This interview was so dry and robotic. 30 minutes of going backwards through my CV, with her asking the same rote questions about each job. No, I don’t know what the guy who hired me ad hoc for a few months to write some grant applications would have said my weaknesses were, but dammit she insisted I had to come up with something. 20 minutes of the same competency-based questions hurled at me for the three previous interviews. I clearly got dinged for not showing enough initiative in one of my examples and for only having done a particular aspect of my role for 12 people (when for this job I’d have needed to do it for hundreds of people).</p>

<p>There was all of 10 minutes to actually discuss working conditions at the company. This was my fourth interview, and only now were things like ‘we don’t provide you with a laptop’ coming up. (And you have to install Ubuntu on it - which, sure, eat your own dog food, but if you’re using a Macbook, installing Ubuntu is a pain. And it wasn’t as if I was actually going to be working with the product itself.) Annual leave allowances were generous, definitely above the statutory UK requirements, but not being able to float the bank holidays implied that non-Christian staff members would need to use annual leave for their own religious holidays while being mandated to take off Good Friday and Easter Monday. Salary expectations were mentioned but I literally had no idea, so that was something that would have been discussed later on in the process, had I made it that far.</p>

<p>I didn’t.</p>

<p>Day 81: Automated rejection. A long, long email I didn’t read to the end. I wonder whether their Talent ‘Scientists’ factor in interview fatigue when they judge whether you are permitted to move forward.</p>

<p>Had I continued the process, I would have gone through at least four and possibly five more interviews with:</p>

<p>- a senior member of the team</p>

<p>- the leader of the team</p>

<p>- my hiring lead</p>

<p>- one of the people I would have been working with</p>

<p>- and possibly the space-faring South African billionaire himself. I even knew what witty question I would have asked him. Alas, ‘twill never be.</p>

<p>So that’s what you can expect with Canonical. Go for it if the job is something you really want, and if you have no immediate need for a job, and if you really really REALLY like having interviews.</p>

<p>PS Just before posting this, I got an automated email asking me, “how has [sic] your interview experience?” Well, here’s your answer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon has more than half of all Arm server CPUs in the world (142 pts)]]></title>
            <link>https://www.theregister.com/2023/08/08/amazon_arm_servers/</link>
            <guid>37059533</guid>
            <pubDate>Wed, 09 Aug 2023 07:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2023/08/08/amazon_arm_servers/">https://www.theregister.com/2023/08/08/amazon_arm_servers/</a>, See on <a href="https://news.ycombinator.com/item?id=37059533">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Amazon is the most successful manufacturer of Arm server chips, accounting for just over half of Arm-based server CPUs currently deployed, while some chipmakers are also now betting on Arm-based Windows PCs.</p>
<p>This information comes from a report issued by Bernstein Research which estimates that nearly 10 percent of servers across the world contain Arm processors, and 40 percent of those are located in China, as we <a target="_blank" href="https://www.theregister.com/2023/08/02/arm_server_china/">reported</a> earlier.</p>
<p>But that total is beaten by just one company – Amazon – which has slightly above 50 percent of all Arm server CPUs in the world deployed in its Amazon Web Services (AWS) datacenters, said the analyst.</p>

    

<p>Amazon currently uses its own Graviton family of chips, designed by the Annapurna Labs division of Amazon Web Services and introduced to the world back in 2018, which are for its own internal use only. The latest iteration is the <a target="_blank" href="https://www.theregister.com/2022/11/29/aws_graviton3e_srd/">Graviton3E</a> for high-performance computing applications, introduced towards the <a target="_blank" href="https://www.nextplatform.com/2022/01/04/inside-amazons-graviton3-arm-server-processor/">end of 2022</a>.</p>

        


        

<p>According to Bernstein, because these chips were optimized for the specific needs of AWS, the company is able to fit in more cores per socket or per rack and the chips consume less power, translating to lower spending on space and cooling.</p>
<p>It is often asserted that while Arm cores might be more energy efficient, they provide lower performance than x86 chips. However, the report said that customer testimonies compiled by Amazon claim 20 percent to 70 percent lower cost at the same performance as comparable x86 chips.</p>

        

<p>Bernstein's report estimates that Graviton represented about 20 percent of AWS CPU instances by mid-2022, most of which would have been the 7nm Graviton2, but Amazon is moving to deploy 5nm Graviton3 and 3E instances and is expected to introduce a Graviton4 with the Armv9 architecture fabricated using TSMC's 3nm production process in 2025.</p>
<p>Ampere is credited as being "arguably the second most successful Arm server CPU supplier," which the report estimates to have between 5 and 10 percent of this market. It managed to grow from essentially nothing to account for 0.6 percent of all CPU instances available from cloud providers globally by mid-2022, as per the report.</p>
<h3>Future of Huawei and Phytium CPUs 'unclear'</h3>
<p>Other companies with Arm server chips include Nvidia, which is introducing <a target="_blank" href="https://www.theregister.com/2022/06/17/nvidia_arm_servers/">products based on its Grace Arm CPU</a> to market, plus Huawei and Phytium in China. However, Bernstein notes that "US export controls put Phytium on the Entity List and Huawei on the Foreign Direct Product rule," as a consequence of which, both are facing difficulties in accessing foundries with advanced process node technologies and "the future of their CPUs is very unclear."</p>
<p>Looking beyond servers, Bernstein's report estimates that Arm chips powered about 12 percent of PCs shipped in the fourth quarter of 2022 (excluding Chromebooks), with the vast majority of these being Macs.</p>
<ul>

<li><a href="https://www.theregister.com/2023/08/03/aws_custom_xeon_m7i_instances/">AWS is running a 96-core, 192-thread, custom Xeon server</a></li>

<li><a href="https://www.theregister.com/2023/06/15/amd_aws_bergamo/">Amazon isn't sold on AMD's tiny Zen 4c cores in manycore Bergamo processors</a></li>

<li><a href="https://www.theregister.com/2023/05/19/microsoft_hiring_chip_designers/">Microsoft offers electrical engineers a lifeline as it pursues custom cloud silicon</a></li>

<li><a href="https://www.theregister.com/2023/02/27/bitnami_arm_support/">Arm has legs: VMware's Bitnami starts packaging apps for Graviton and Ampere</a></li>
</ul>
<p>The research notes that Qualcomm has invested heavily to try to replicate Apple's success with Arm-based Macs on Windows PCs, via its <a target="_blank" href="https://www.theregister.com/2021/03/16/qualcomm_closes_nuvia_announces_chipset/">acquisition of chip designer Nuvia</a>. Bernstein expects to see Qualcomm launch the first chip later this year, and that devices such as Microsoft's Surface will be available with it shortly after.</p>
<p>However, the report warns that unlikethe "closed" software systems of Apple and the cloud providers, the open software ecosystem of Windows (sorry readers, that's what the report says), with its catalogue of x86 applications, makes introducing Windows-based PCs on a new CPU architecture a much more difficult proposition.</p>
<p>Other companies dipping a toe in the Arm-based PC market include Taiwan-based <a target="_blank" href="https://www.theregister.com/2022/11/16/qualcomm_arm_windows/">MediaTek</a> and Samsung, and Microsoft notably launched an <a target="_blank" href="https://www.theregister.com/2022/10/25/windows_dev_kit_2023/">Arm-powered developer system</a>, the Windows Dev Kit 2023, late last year. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Critical Problem (2017) (206 pts)]]></title>
            <link>https://nucleardiner.wordpress.com/2017/06/19/a-critical-problem/</link>
            <guid>37059487</guid>
            <pubDate>Wed, 09 Aug 2023 06:55:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nucleardiner.wordpress.com/2017/06/19/a-critical-problem/">https://nucleardiner.wordpress.com/2017/06/19/a-critical-problem/</a>, See on <a href="https://news.ycombinator.com/item?id=37059487">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
		<main id="main" role="main">

		
							
<article id="post-7745">
	
	<!-- .entry-header -->

	<div>
		
<div itemprop="associatedMedia" itemscope="" itemtype="http://schema.org/ImageGallery" data-original-width="1000" data-original-height="1322" data-carousel-extra="{&quot;blog_id&quot;:98885650,&quot;permalink&quot;:&quot;https:\/\/nucleardiner.wordpress.com\/2017\/06\/19\/a-critical-problem\/&quot;,&quot;likes_blog_id&quot;:98885650}"> <a href="https://nucleardiner.wordpress.com/2017/06/19/a-critical-problem/700lanl-rods-too-close-001-170619/" itemprop="url"> <meta itemprop="width" content="996"> <meta itemprop="height" content="1318"> <img data-attachment-id="7747" data-orig-file="https://nucleardiner.files.wordpress.com/2017/06/700lanl-rods-too-close-001-170619.jpg" data-orig-size="529,700" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="700lanl-rods-too-close-001 170619" data-image-description="" data-medium-file="https://nucleardiner.files.wordpress.com/2017/06/700lanl-rods-too-close-001-170619.jpg?w=227" data-large-file="https://nucleardiner.files.wordpress.com/2017/06/700lanl-rods-too-close-001-170619.jpg?w=529" src="https://nucleardiner.files.wordpress.com/2017/06/700lanl-rods-too-close-001-170619.jpg?w=996&amp;resize=996%2C1318&amp;h=1318#038;h=1318" width="996" height="1318" data-original-width="996" data-original-height="1318" itemprop="http://schema.org/image" title="700lanl-rods-too-close-001 170619" alt="700lanl-rods-too-close-001 170619" data-recalc-dims="1"> </a> </div>
<p>This photo gives me the creeps.<span id="more-7745"></span></p>
<p>When you work with dangerous stuff, you have to condition yourself to respond at the level of emotion. You have to think things out too, but having a sense of what you can and can’t do that operates immediately is important. Children learn that hot stoves and automobile traffic are dangerous. We automatically stop at the street. It’s tourist season in Santa Fe, though, and I have observed that some lack that automatic response.</p>
<p>I’ve dealt with dangerous stuff since I was a child. I had a real chemistry set, not the baking-powder-and-vinegar wimp boxes that are the only things sold now. My parents walked with me a lot in the outdoors and made it clear that wild strawberries were good to eat and deadly nightshade was not.</p>
<p>I loved my lab courses in high school and college. Working at a national laboratory added more precautions I needed to learn. I worked with high-voltage lasers. I did a little bit of plutonium chemistry in a glovebox. And then I managed people who were developing cans for storing plutonium.</p>
<p>We expected the plutonium to be in the form of flat cylindrical ingots, like the enriched uranium in this photo. <img data-attachment-id="7746" data-permalink="https://nucleardiner.wordpress.com/2017/06/19/a-critical-problem/400px-heuraniumc/" data-orig-file="https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg" data-orig-size="400,320" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="400px-HEUraniumC" data-image-description="" data-image-caption="" data-medium-file="https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg?w=300" data-large-file="https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg?w=400" src="https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg?w=1000" alt="400px-HEUraniumC" srcset="https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg 400w, https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg?w=150&amp;h=120 150w, https://nucleardiner.files.wordpress.com/2017/06/400px-heuraniumc.jpg?w=300&amp;h=240 300w" sizes="(max-width: 400px) 100vw, 400px">It had to be protected from the air, from unauthorized removal, and from criticality incidents. The criticality safety group played an important part in designing those cans. The cans were about a foot high. The ingots were about an inch thick. The extra space was for criticality safety.</p>
<p>Probably before I came to Los Alamos, I read about Louis Slotin and Harry Daghlian, who were killed by criticality incidents. They were doing experiments to determine criticality properties for nuclear weapons design. They died horribly. Don’t read about them unless you have a strong stomach.</p>
<p>The metal rods in the top photo are plutonium. Rods can roll. These rods could roll closer to each other and perhaps produce the kind of runaway neutron reaction that killed Slotin and Daghlian. Putting a hand in to separate them could make the reaction worse because the water in a human body reflects the neutrons.</p>
<p>I had formal safety training, informal discussions with more experienced people, and made it a point to internalize rules of thumb. Keep pieces of plutonium separate. Abide by glovebox limitations; every glovebox has a sign with the limits of plutonium allowed in it. For solutions, keep them dilute and in flat containers. Flat/thin is safer; the closer a shape is to spherical, the less material is needed to go critical. IIRC, there were racks to put rods in if you were working with that shape of metal, so that they didn’t accidentally roll together.</p>
<p>That photo is at the center of two articles from the Center for Public Integrity (<a href="http://nmpolitics.net/index/2017/06/a-near-disaster-at-los-alamos-lab-takes-a-hidden-toll-on-americas-arsenal/">NMPolitics.net</a>, <a href="https://www.washingtonpost.com/world/national-security/safety-lapses-undermine-nuclear-warhead-work-at-los-alamos/2017/06/17/87f051ee-510d-11e7-b064-828ba60fbb98_story.html?utm_term=.8c4bc83d58f1">Washington Post</a>). They are based on an investigation reported <a href="https://apps.publicintegrity.org/nuclear-negligence/">here</a>. According to those articles, a technician ignored glovebox limits and arranged the plutonium to take that photo for management. A Los Alamos manager is also quoted in the articles as saying that the criticality safety group was an unnecessary expense. A number of the senior people in the criticality safety group were of my vintage and were expected to retire about when I did. According to the articles, management’s signal was heard loud and clear, and the rest left.</p>
<p>It took the criticality safety group two months to work out the criticality aspects of our can design. I found that frustrating, too. They had to consider the way the cans might be stacked, how they might fall together and how the ingots inside might move if a stack of cans fell. What if they were in a flooded area? If people decided to rescue them from that flooded area? Water, by itself and in human bodies, enhances the neutron reactions that lead to criticality.</p>
<p>The criticality safety group develops those criticality limits posted on gloveboxes. They take into account the kinds of operations in the glovebox, the equipment inside, and the effects of operators’ hands and bodies nearby.</p>
<p>I learned from people who recalled personally what happened to Slotin and Daghlian. Today’s managers at Los Alamos are rotated through, I’ve heard, every two years. There are not many other places where one learns criticality safety. If Los Alamos is to manufacture nuclear weapons pits, criticality safety evaluation is essential.</p>
<p>A criticality accident affects people who are close to it. It is not a nuclear explosion; the neutron reactions are the same but occur much more slowly. The closest people die horribly, but some tens of feet distance and walls between will shield others. Raemer Schrieber was present at the Slotin accident and lived into his eighties.</p>
<p>It is unconscionable not to educate workers to the dangers involved with handling plutonium. It is worse to encourage poor practice. Did the manager for whom that photo was made understand criticality safety? Or the manager who said to just keep working?</p>
<p>One of the reasons for adding industrial partners to the management of Los Alamos along with the University of California was to improve safety practices. That was done without considering the standard industrial management practice of rotating managers rapidly and the ever-present profit motive. Industry does things better, period. But perhaps not for a singular enterprise like designing and building nuclear weapons.</p>
<p><strong>Coda:</strong> I am usually highly critical of articles on nuclear issues coming from the Center for Public Integrity. They often get the science wrong and display an excessive fear of radioactivity. They did a much better job with this investigation. There are a number of small errors and infelicities of word use in these articles, but nothing like the bloopers they have produced before.</p>
<p><strong>Update:</strong> The National Nuclear Security Administration says that the issues of criticality safety have been cleared up.</p>
<blockquote>
<p dir="ltr" lang="en">Statement from <a href="https://twitter.com/FrankKlotzNNSA">@FrankKlotzNNSA</a> on <a href="https://twitter.com/hashtag/NNSA?src=hash">#NNSA</a> <a href="https://twitter.com/hashtag/safety?src=hash">#safety</a> <a href="https://t.co/qn0MjKlVPm">pic.twitter.com/qn0MjKlVPm</a></p>
<p>— NNSA (@NNSANews) <a href="https://twitter.com/NNSANews/status/876924097153966080">June 19, 2017</a></p></blockquote>
<p>This is plausible because the photo is said to have been made in 2011. That would allow time to reassert the importance of criticality safety and rebuild the group responsible for it. And, as I said above, the Center for Public Integrity has been sensationalistic in the past. But I’d like to hear more from NNSA. The fact that that incident occurred at all is disturbing.</p>

<p><strong>Addendum (June 21, 2017)</strong></p>
<p>How much plutonium is in that photo?</p>
<p>It’s pretty clearly a sharpie in the bottom of the photo. Sharpies are about 13.5 – 14 cm long. Scaling from there to the rods gives 12 cm long for the top four, and 5.7, 5.1, 4.5, and 3.8 for the bottom four. All have rounded caps of about 0.3 cm radius. I’m approximating, so we’ll neglect the rounded caps. The article says something about the yellow-and-black tape being raised, and the shadows agree, so the lengths of all the rods may be more than what I measured, depending on the angle of the photo. So the estimate is likely to be low, although probably less than tens of grams per rod.</p>
<table>
<tbody>
<tr>
<td>Length (cm)</td>
<td>Radius (cm)</td>
<td># of rods</td>
<td>Mass in g (alpha phase, 19.86 g/cm<sup>3</sup>)</td>
<td>Mass in g (delta phase, 15.92 g/cm<sup>3</sup>)</td>
</tr>
<tr>
<td>12</td>
<td>1.1</td>
<td>4</td>
<td>906</td>
<td>726</td>
</tr>
<tr>
<td>5.7</td>
<td>0.83</td>
<td>1</td>
<td>248</td>
<td>199</td>
</tr>
<tr>
<td>5.1</td>
<td>0.83</td>
<td>1</td>
<td>222</td>
<td>178</td>
</tr>
<tr>
<td>4.5</td>
<td>0.83</td>
<td>1</td>
<td>197</td>
<td>158</td>
</tr>
<tr>
<td>3.8</td>
<td>0.74</td>
<td>1</td>
<td>129</td>
<td>103</td>
</tr>
</tbody>
</table>
<p>We can’t tell by looking what phase the plutonium is in, and the densities of the alpha and delta phases are quite different. So a high estimate, for the denser alpha phase, is a total of 4,420 grams in all eight rods; for the less dense delta plutonium, the total is 3,542.</p>
<p>Wikipedia gives the critical mass of plutonium-239 as about 11 kg, about 3 times what is in the photo. But there could be other isotopes. A critical mass depends on its surroundings, so depending what else is in the glovebox and the presence of a human body nearby, the critical mass could be less.</p>
<p>I have additional questions that pertain to the involvement of management and the safety procedures. How did the technician come to have that much plutonium? Plutonium is kept in the vault and must be signed out. Getting a photographer into PF-4 used to require a requisition for the services, and then there are procedural issues about taking a camera in that would have to be signed off by someone above technician level. Who signed off on the photo shoot?</p>
<p>Many thanks to Christopher Willis (@BeCurious) for checking my math, and Alex Wellerstein (@Wellerstein) for doing a parallel estimate.</p>

<p><em>Cross-posted to <a href="https://www.balloon-juice.com/2017/06/19/a-critical-problem/" target="_blank" rel="noopener">Balloon Juice</a>.</em></p>
					</div><!-- .entry-content -->

	<!-- .entry-footer --></article><!-- #post-## -->
			
				<!-- .navigation -->
	
			

		
		</main><!-- #main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Happy Birthday OpenStreetMap (295 pts)]]></title>
            <link>https://blog.openstreetmap.org/2023/08/09/happy-birthday-openstreetmap-2/</link>
            <guid>37059481</guid>
            <pubDate>Wed, 09 Aug 2023 06:54:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.openstreetmap.org/2023/08/09/happy-birthday-openstreetmap-2/">https://blog.openstreetmap.org/2023/08/09/happy-birthday-openstreetmap-2/</a>, See on <a href="https://news.ycombinator.com/item?id=37059481">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
<h2>OSM is 19 years old: we’re launching an online fundraising campaign to support its future</h2>







<p>18 years ago, OSM Founder Steve Coast posted this invitation to OpenStreetmap’s 1st birthday party.</p>


<div>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-invite.png"><img decoding="async" fetchpriority="high" width="520" height="516" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-invite.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-invite.png 520w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-invite-300x298.png 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-invite-150x150.png 150w" sizes="(max-width: 520px) 100vw, 520px"></a></figure></div>






<p>In 2005, things were moving very quickly for the still new OSM project. The broader open data movement was gathering momentum through events like the <a href="https://web.archive.org/web/20051025070025/http://www.okfn.org/wsfii/">World Summit on Free Information Infrastructures (WSFII)</a> and pledge <a href="https://web.archive.org/web/20051226062420/http://www.pledgebank.com/geodata">campaigns for the creation of open geodata</a>, and OSM was starting to get coverage in major media like<a href="https://web.archive.org/web/20050915213226/http://www.guardian.co.uk/online/story/0,3605,1453293,00.html"> the <em>Guardian</em></a>. Soon after the above-mentioned first birthday party, the front end of OSM was launched at OSM.org and a new “whizzy” Applet was launched to “<a href="https://web.archive.org/web/20051023003100/http://www.openstreetmap.org/news/">replace the horrid old one</a>.”</p>



<p>By 2006, OSM’ers were  mapping all over the world: </p>



<figure>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Copenhagen-8-10-2006.png"><img decoding="async" width="400" height="456" data-id="176657304" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Copenhagen-8-10-2006.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Copenhagen-8-10-2006.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Copenhagen-8-10-2006-263x300.png 263w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Hedge_End_Coloured.png"><img decoding="async" width="400" height="393" data-id="176657469" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Hedge_End_Coloured.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Hedge_End_Coloured.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Hedge_End_Coloured-300x295.png 300w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-IsleOfWight20060927.png"><img decoding="async" loading="lazy" width="400" height="243" data-id="176657460" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-IsleOfWight20060927.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-IsleOfWight20060927.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-IsleOfWight20060927-300x182.png 300w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-London-20061121-bounded.png"><img decoding="async" loading="lazy" width="400" height="371" data-id="176657370" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-London-20061121-bounded.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-London-20061121-bounded.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-London-20061121-bounded-300x278.png 300w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Oakham_labelled.png"><img decoding="async" loading="lazy" width="400" height="444" data-id="176657356" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Oakham_labelled.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Oakham_labelled.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Oakham_labelled-270x300.png 270w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/UK-Motorways-Railways_300pxSouth.png"><img decoding="async" loading="lazy" width="300" height="300" data-id="176657772" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/UK-Motorways-Railways_300pxSouth.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/UK-Motorways-Railways_300pxSouth.png 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/UK-Motorways-Railways_300pxSouth-150x150.png 150w" sizes="(max-width: 300px) 100vw, 300px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Reading_uni_whiteknights_campus.png"><img decoding="async" loading="lazy" width="400" height="327" data-id="176657320" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Reading_uni_whiteknights_campus.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Reading_uni_whiteknights_campus.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-Reading_uni_whiteknights_campus-300x245.png 300w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-I-55_and_I-90-2.png"><img decoding="async" loading="lazy" width="400" height="395" data-id="176657746" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-I-55_and_I-90-2.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-I-55_and_I-90-2.png 400w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/400px-I-55_and_I-90-2-300x296.png 300w" sizes="(max-width: 400px) 100vw, 400px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2.png"><img decoding="async" loading="lazy" width="915" height="1024" data-id="176657694" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2-915x1024.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2-915x1024.png 915w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2-268x300.png 268w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2-768x860.png 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2-624x698.png 624w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/CentralChester-2.png 1023w" sizes="(max-width: 915px) 100vw, 915px"></a></figure>
<figcaption> <a href="https://wiki.openstreetmap.org/wiki/List_of_featured_images/2006">https://wiki.openstreetmap.org/wiki/List_of_featured_images/2006</a></figcaption></figure>



<h2>The OSM Birthday Tradition</h2>



<p>When OpenStreetMap turned ten in 2014, the number of celebrations had greatly increased from that first birthday event at the Strongroom Bar in London. In fact, it took a world map to visualize all of the parties. </p>



<figure>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2.jpeg"><img decoding="async" loading="lazy" width="982" height="1024" data-id="176657851" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-982x1024.jpeg" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-982x1024.jpeg 982w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-288x300.jpeg 288w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-768x801.jpeg 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-1474x1536.jpeg 1474w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-1965x2048.jpeg 1965w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/10CakeLit-2-624x650.jpeg 624w" sizes="(max-width: 982px) 100vw, 982px"></a></figure>



<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map.png"><img decoding="async" loading="lazy" width="1024" height="796" data-id="176657877" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-1024x796.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-1024x796.png 1024w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-300x233.png 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-768x597.png 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-1536x1194.png 1536w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-2048x1592.png 2048w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/Happy-Tenth-Birthday-Map-624x485.png 624w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>
</figure>



<figure>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1.jpeg"><img decoding="async" loading="lazy" width="1024" height="768" data-id="176657929" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1-1024x768.jpeg" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1-1024x768.jpeg 1024w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1-300x225.jpeg 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1-768x576.jpeg 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1-624x468.jpeg 624w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/20200808-osm16-kabul-01-1.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>16th anniversary of OSM in Kabul, Afghanistan</figcaption></figure>



<figure><img decoding="async" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-bday-1024x576.jpeg" alt="This image has an empty alt attribute; its file name is OSM-bday-1024x576.jpeg"><figcaption>Feye Andal ( <a href="https://twitter.com/dfeyeandal">@dfeyeandal</a>) shows off a cake, during a get-together in Manila that celebrated the 18th OpenStreetMap anniversary. Photo Credit: E. Olario</figcaption></figure>
</figure>



<p>If you’re celebrating the 19th anniversary of OSM this week, be sure to <a href="https://wiki.openstreetmap.org/wiki/OpenStreetMap_19th_Anniversary_Birthday_party">share some photos.</a> 🎂</p>



<h2>What Does OSM Look Like at 19? </h2>



<p>OpenStreetMap is the largest open-source geospatial project of all time. There are 18 formally established OSM chapters and dozens more local communities, collaborating on hundreds of communication channels, in more than 50 languages, in most of the countries of the world.&nbsp;&nbsp;The map and its data is world-recognized as an essential source of geospatial ground truth. The API is used by millions of people, and the community is motivated,&nbsp; multi-talented, and culturally and geographically diverse. <a href="https://blog.openstreetmap.org/2023/05/22/powering-openstreetmaps-future-a-year-of-improvements-from-openstreetmap-foundations-site-reliability-engineer/">OSM even welcomed its first paid site stability engineer a year ago in recognition of the size and scope of the project.</a></p>


<div>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic.png"><img decoding="async" loading="lazy" width="1024" height="768" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic.png 1024w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic-300x225.png 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic-768x576.png 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/OSM-graphic-624x468.png 624w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>image credit: Kate Varfolomeyeva, 2023</figcaption></figure></div>


<p>To get an even better sense of what OSM means to its community in 2023, we asked community members to tell us why they love OSM. Here are just a few of the many answers:&nbsp;</p>


<div>
<figure><a href="https://blog.openstreetmap.org/wp-content/uploads/2023/08/what-people-said-about-OSM-3.png"><img decoding="async" loading="lazy" width="1024" height="768" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/what-people-said-about-OSM-3.png" alt=""></a><figcaption>Image Credit: Kate Varfolomeyeva, 2023</figcaption></figure></div>


<p>So, you can see why this is an important moment for OpenStreetMap.&nbsp; In a year, the project will be twenty years old: its data is helping to solve some of the world’s most pressing challenges, there is new technology that makes it easier to map, and enthusiasm for mapmaking is as strong as it ever was.&nbsp;</p>



<p>To meet these challenges and opportunities, the OSM Foundation board is working on a strategic plan that can help support our ever-growing community of volunteers, by strategically funding skills such as project management, engineering, front-end development and offering bounties and sponsorship to help foster a diverse and inclusive map for everyone.&nbsp;&nbsp;</p>



<p>Which is why now is the time to share your time and money to help secure the future of OpenStreetMap.</p>



<h2><a href="https://supporting.openstreetmap.org/" data-type="link" data-id="https://supporting.openstreetmap.org">It’s OSM’s Birthday! Please Give to Support its Future</a></h2>



<p>Starting today, the OSMF will be conducting an online fundraising campaign to support the future of OSM. Here’s what you can do to help: </p>



<ol>
<li>Share a photo of how you’re celebrating OSM’s big day with hashtag <strong>#HappyBirthdayOSM</strong> and/or <strong>#WeAreOSM</strong> and <strong>link to</strong> <a href="https://supporting.openstreetmap.org/">https://supporting.openstreetmap.org</a>.</li>



<li><a href="https://donate.openstreetmap.org./"><strong>Make a gift of any size</strong></a> to support OSM’s future.  </li>



<li><strong><a href="http://openstreetmap.org/">Edit the map!</a> </strong> 🗺</li>
</ol>



<figure><a href="https://donate.openstreetmap.org/"><img decoding="async" loading="lazy" width="1024" height="768" src="https://blog.openstreetmap.org/wp-content/uploads/2023/08/19.png" alt="" srcset="https://blog.openstreetmap.org/wp-content/uploads/2023/08/19.png 1024w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/19-300x225.png 300w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/19-768x576.png 768w, https://blog.openstreetmap.org/wp-content/uploads/2023/08/19-624x468.png 624w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<hr>



<p><em>The <a href="https://wiki.osmfoundation.org/">OpenStreetMap Foundation</a> is a not-for-profit organisation, formed to support the OpenStreetMap Project. It is dedicated to encouraging the growth, development and distribution of free geospatial data for anyone to use and share. The OpenStreetMap Foundation owns and maintains the infrastructure of the OpenStreetMap project, is financially supported by membership fees and <a href="https://donate.openstreetmap.org/">donations</a>, and organises the annual, international <a href="https://stateofthemap.org/">State of the Map</a> conference. Our volunteer <a href="https://wiki.osmfoundation.org/wiki/WorkingGroups">Working Groups</a> and small core staff work to support the OpenStreetMap project. <a href="https://join.osmfoundation.org/">Join the OpenStreetMap Foundation</a> for just £15 a year or for free if you are an active OpenStreetMap contributor.</em></p>
<p>This post is also available in: 
    <span><a href="https://blog.openstreetmap.org/2023/08/09/feliz-aniversario-openstreetmap/?lang=gl"><span>Galician</span></a></span>    <span><a href="https://blog.openstreetmap.org/2023/08/09/happy-birthday-openstreetmap-2/?lang=ja"><span>Japanese</span></a></span>    <span><a href="https://blog.openstreetmap.org/2023/08/09/feliz-cumpleanos-openstreetmap/?lang=es"><span>Spanish</span></a></span></p>					</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama from Scratch (or how to implement a paper without crying) (255 pts)]]></title>
            <link>https://blog.briankitano.com/llama-from-scratch/</link>
            <guid>37059479</guid>
            <pubDate>Wed, 09 Aug 2023 06:54:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.briankitano.com/llama-from-scratch/">https://blog.briankitano.com/llama-from-scratch/</a>, See on <a href="https://news.ycombinator.com/item?id=37059479">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    







<p>
    <i>
        <time datetime="2023-08-09">
            09 Aug, 2023
        </time>
    </i>
</p>

<p>I want to provide some tips from my experience implementing a paper. I'm going to cover implementing a dramatically scaled-down version of <a href="https://arxiv.org/pdf/2302.13971.pdf">Llama</a> for training <a href="https://github.com/karpathy/char-rnn/blob/master/data/tinyshakespeare/input.txt">TinyShakespeare</a>. This post is heavily inspired by Karpathy's <a href="https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ">Makemore series</a>, which I highly recommend.</p>
<p>A preview of what we're going to end up with:</p>
<div><pre><span></span><span>print</span><span>(</span><span>generate</span><span>(</span><span>llama</span><span>,</span> <span>MASTER_CONFIG</span><span>,</span> <span>500</span><span>)[</span><span>0</span><span>])</span>
</pre></div>

<div><pre><span></span>Evend her break of thou thire xoing dieble had side, did foesors exenatedH in siffied up,
    No, none,
    And you ling as thought depond.

    MENENIUS:
    Tell officien:
    To pesiding be
    Best wanty and to spiege,
    To uncine shee patss again,
    I will hen: then they
    Moieth:
    I my cast in letch:
    For bereful, give toan I may

    LINT OF AUMERLE:
    Out, or me but thee here sir,
    Why first with canse pring;
    Now!

    Gide me couuse
    The haster:
    And suilt harming,
    Then as pereise with and go.

    FROMNIUS:
    I well? speak and wieke ac
</pre></div>

<p>I'll be skipping over some of the more obvious steps, like setting up a virtual environment and installing dependencies.</p>
<p>Github <a href="https://github.com/bkitano/llama-from-scratch">here</a>.</p>
<h2 id="tl-dr">tl;dr 👓</h2>
<h2 id="always-work-iteratively-start-small-stay-certain-and-build-up">Always work iteratively: start small, stay certain, and build up.</h2>
<p>My approach for implementing papers is:</p>
<ol>
<li>Make all of the helper functions required to test your model quantitatively (data splits, training, plotting the loss).</li>
<li>Before you even look at the paper, pick a small, simple, and fast model that you've done in the past. Then make a helper function to evaluate the model qualitatively.</li>
<li>Start by picking apart different components of the paper, and then implementing them one-by-one, training and evaluating as you go.</li>
</ol>
<h2 id="make-sure-your-layers-do-what-you-think">Make sure your layers do what you think.</h2>
<ol>
<li>Use <code>.shape</code> religiously. <code>assert</code> and <code>plt.imshow</code> are your friends.</li>
<li>Work out the results without matrix multiplication first, and then use the <code>torch</code> functions to make it efficient after.</li>
<li>Have a test to see that your layer is right. For example, the RoPE embeddings have a specific property that you can test for. For the Transformer, you can test that the attention is working by looking at the attention map.</li>
<li>Test your layers on various batch, sequence, and embedding sizes. Even if it works for one size, it might not work for others, which will cause problems at inference time.</li>
</ol>
<h2 id="let-s-go">Let's go 👉</h2>
<h2 id="about-llama">About Llama</h2>
<p>Llama is a transformer-based model for language modeling. Meta AI <a href="https://github.com/facebookresearch/llama">open-sourced</a> Llama this summer, and it's gained a lot of attention (pun intended). When you're reading the introduction, they clearly indicate their goal: make a model that's cheaper for running inference, rather than optimizing training costs.</p>
<p>At this point, we'll just load our libraries and get started.</p>
<div><pre><span></span><span>import</span> <span>torch</span>
<span>from</span> <span>torch</span> <span>import</span> <span>nn</span>
<span>from</span> <span>torch.nn</span> <span>import</span> <span>functional</span> <span>as</span> <span>F</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>time</span>
<span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
</pre></div>

<h2 id="setting-up-our-dataset">Setting up our dataset</h2>
<p>While in Llama they train on 1.4T tokens, our dataset TinyShakespeare, the collection of all of Shakespeare's works, is about 1M characters.</p>
<div><pre><span></span><span>lines</span> <span>=</span> <span>open</span><span>(</span><span>'./input.txt'</span><span>,</span> <span>'r'</span><span>)</span><span>.</span><span>read</span><span>()</span>

<span>vocab</span> <span>=</span> <span>sorted</span><span>(</span><span>list</span><span>(</span><span>set</span><span>(</span><span>lines</span><span>)))</span>
<span>itos</span> <span>=</span> <span>{</span><span>i</span><span>:</span><span>ch</span> <span>for</span> <span>i</span><span>,</span> <span>ch</span> <span>in</span> <span>enumerate</span><span>(</span><span>vocab</span><span>)}</span>
<span>stoi</span> <span>=</span> <span>{</span><span>ch</span><span>:</span><span>i</span> <span>for</span> <span>i</span><span>,</span> <span>ch</span> <span>in</span> <span>enumerate</span><span>(</span><span>vocab</span><span>)}</span>

<span>print</span><span>(</span><span>lines</span><span>[:</span><span>30</span><span>])</span>
</pre></div>

<div><pre><span></span>First Citizen:
Before we proce
</pre></div>

<p>They use the <a href="https://github.com/google/sentencepiece">SentencePiece</a> byte-pair encoding tokenizer, but we're going to just use a simple character-level tokenizer.</p>
<div><pre><span></span><span># simple tokenization by characters</span>
<span>def</span> <span>encode</span><span>(</span><span>s</span><span>):</span>
    <span>return</span> <span>[</span><span>stoi</span><span>[</span><span>ch</span><span>]</span> <span>for</span> <span>ch</span> <span>in</span> <span>s</span><span>]</span>

<span>def</span> <span>decode</span><span>(</span><span>l</span><span>):</span>
    <span>return</span> <span>''</span><span>.</span><span>join</span><span>([</span><span>itos</span><span>[</span><span>i</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>l</span><span>])</span>

<span>print</span><span>(</span><span>'vocab size:'</span><span>,</span> <span>len</span><span>(</span><span>vocab</span><span>))</span>
<span>decode</span><span>(</span><span>encode</span><span>(</span><span>"hello"</span><span>))</span>
</pre></div>



<p>Since our dataset is small enough, we don't need to worry about how we store it in memory etc.</p>
<p>First tip: I'm creating a <code>config</code> object that stores some basic model params. It makes our code way more readable and removes constants and magic numbers from the code. I'm not going to use types, as  I want to keep things flexible for now and be able to add more parameters later on.</p>
<div><pre><span></span><span>MASTER_CONFIG</span> <span>=</span> <span>{</span>
    <span>"vocab_size"</span><span>:</span> <span>len</span><span>(</span><span>vocab</span><span>),</span>
<span>}</span>
</pre></div>

<div><pre><span></span><span>dataset</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>encode</span><span>(</span><span>lines</span><span>),</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>int8</span><span>)</span>
<span>dataset</span><span>.</span><span>shape</span>
</pre></div>



<p>Let's create a method to generate our training data and labels for batches. We'll use the same method for validation and test data. Note that I like to test my functions in the same block that I define them, just to make sure they work as expected before moving on.</p>
<div><pre><span></span><span>def</span> <span>get_batches</span><span>(</span><span>data</span><span>,</span> <span>split</span><span>,</span> <span>batch_size</span><span>,</span> <span>context_window</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>):</span>
    <span>train</span> <span>=</span> <span>data</span><span>[:</span><span>int</span><span>(</span><span>.8</span> <span>*</span> <span>len</span><span>(</span><span>data</span><span>))]</span>
    <span>val</span> <span>=</span> <span>data</span><span>[</span><span>int</span><span>(</span><span>.8</span> <span>*</span> <span>len</span><span>(</span><span>data</span><span>)):</span> <span>int</span><span>(</span><span>.9</span> <span>*</span> <span>len</span><span>(</span><span>data</span><span>))]</span>
    <span>test</span> <span>=</span> <span>data</span><span>[</span><span>int</span><span>(</span><span>.9</span> <span>*</span> <span>len</span><span>(</span><span>data</span><span>)):]</span>

    <span>batch_data</span> <span>=</span> <span>train</span>
    <span>if</span> <span>split</span> <span>==</span> <span>'val'</span><span>:</span>
        <span>batch_data</span> <span>=</span> <span>val</span>

    <span>if</span> <span>split</span> <span>==</span> <span>'test'</span><span>:</span>
        <span>batch_data</span> <span>=</span> <span>test</span>

    <span># pick random starting points</span>
    <span>ix</span> <span>=</span> <span>torch</span><span>.</span><span>randint</span><span>(</span><span>0</span><span>,</span> <span>batch_data</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span> <span>-</span> <span>context_window</span> <span>-</span> <span>1</span><span>,</span> <span>(</span><span>batch_size</span><span>,))</span>
    <span>x</span> <span>=</span> <span>torch</span><span>.</span><span>stack</span><span>([</span><span>batch_data</span><span>[</span><span>i</span><span>:</span><span>i</span><span>+</span><span>context_window</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>ix</span><span>])</span><span>.</span><span>long</span><span>()</span>
    <span>y</span> <span>=</span> <span>torch</span><span>.</span><span>stack</span><span>([</span><span>batch_data</span><span>[</span><span>i</span><span>+</span><span>1</span><span>:</span><span>i</span><span>+</span><span>context_window</span><span>+</span><span>1</span><span>]</span> <span>for</span> <span>i</span> <span>in</span> <span>ix</span><span>])</span><span>.</span><span>long</span><span>()</span>
    <span>return</span> <span>x</span><span>,</span> <span>y</span>

<span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'batch_size'</span><span>:</span> <span>32</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>16</span>
<span>})</span>

<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>[(</span><span>decode</span><span>(</span><span>xs</span><span>[</span><span>i</span><span>]</span><span>.</span><span>tolist</span><span>()),</span> <span>decode</span><span>(</span><span>ys</span><span>[</span><span>i</span><span>]</span><span>.</span><span>tolist</span><span>()))</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>len</span><span>(</span><span>xs</span><span>))]</span>
</pre></div>

<div><pre><span></span><span>[</span><span>(</span><span>'t us sup betimes'</span><span>,</span><span> </span><span>' us sup betimes,'</span><span>),</span>
<span> </span><span>(</span><span>'IO:</span><span>\n</span><span>Right.</span><span>\n\n</span><span>ROME'</span><span>,</span><span> </span><span>'O:</span><span>\n</span><span>Right.</span><span>\n\n</span><span>ROMEO'</span><span>),</span>
<span> </span><span>(</span><span>'Nurse:</span><span>\n</span><span>O, she sa'</span><span>,</span><span> </span><span>'urse:</span><span>\n</span><span>O, she say'</span><span>),</span>
<span> </span><span>(</span><span>" seem'd to know,"</span><span>,</span><span> </span><span>"seem'd to know,</span><span>\n</span><span>"</span><span>),</span>
<span> </span><span>(</span><span>' let her brother'</span><span>,</span><span> </span><span>'let her brother '</span><span>),</span>
<span> </span><span>(</span><span>'ood,</span><span>\n</span><span>Even with s'</span><span>,</span><span> </span><span>'od,</span><span>\n</span><span>Even with su'</span><span>),</span>
<span> </span><span>(</span><span>'en</span><span>\n</span><span>Whisper the s'</span><span>,</span><span> </span><span>'n</span><span>\n</span><span>Whisper the sp'</span><span>),</span>
<span> </span><span>(</span><span>', fly! for all y'</span><span>,</span><span> </span><span>' fly! for all yo'</span><span>),</span>
<span> </span><span>(</span><span>" Saint Peter's C"</span><span>,</span><span> </span><span>"Saint Peter's Ch"</span><span>),</span>
<span> </span><span>(</span><span>', but that</span><span>\n</span><span>Which'</span><span>,</span><span> </span><span>' but that</span><span>\n</span><span>Which '</span><span>),</span>
<span> </span><span>(</span><span>'uld as willingly'</span><span>,</span><span> </span><span>'ld as willingly '</span><span>),</span>
<span> </span><span>(</span><span>'y brother,</span><span>\n</span><span>Is pr'</span><span>,</span><span> </span><span>' brother,</span><span>\n</span><span>Is pri'</span><span>),</span>
<span> </span><span>(</span><span>' you ready your '</span><span>,</span><span> </span><span>'you ready your s'</span><span>),</span>
<span> </span><span>(</span><span>'rth the audience'</span><span>,</span><span> </span><span>'th the audience '</span><span>),</span>
<span> </span><span>(</span><span>'</span><span>\n\n</span><span>QUEEN ELIZABET'</span><span>,</span><span> </span><span>'</span><span>\n</span><span>QUEEN ELIZABETH'</span><span>),</span>
<span> </span><span>(</span><span>'ection,</span><span>\n</span><span>which ca'</span><span>,</span><span> </span><span>'ction,</span><span>\n</span><span>which can'</span><span>),</span>
<span> </span><span>(</span><span>'is wisdom hastes'</span><span>,</span><span> </span><span>'s wisdom hastes '</span><span>),</span>
<span> </span><span>(</span><span>' and quinces in '</span><span>,</span><span> </span><span>'and quinces in t'</span><span>),</span>
<span> </span><span>(</span><span>'nt death.</span><span>\n\n</span><span>SICIN'</span><span>,</span><span> </span><span>'t death.</span><span>\n\n</span><span>SICINI'</span><span>),</span>
<span> </span><span>(</span><span>"y she's mad.</span><span>\n\n</span><span>BR"</span><span>,</span><span> </span><span>" she's mad.</span><span>\n\n</span><span>BRU"</span><span>),</span>
<span> </span><span>(</span><span>'eware of him;</span><span>\n</span><span>Si'</span><span>,</span><span> </span><span>'ware of him;</span><span>\n</span><span>Sin'</span><span>),</span>
<span> </span><span>(</span><span>'s</span><span>\n</span><span>And make pursu'</span><span>,</span><span> </span><span>'</span><span>\n</span><span>And make pursui'</span><span>),</span>
<span> </span><span>(</span><span>'r and be slain; '</span><span>,</span><span> </span><span>' and be slain; n'</span><span>),</span>
<span> </span><span>(</span><span>' I, with grief a'</span><span>,</span><span> </span><span>'I, with grief an'</span><span>),</span>
<span> </span><span>(</span><span>'?</span><span>\n\n</span><span>Second Keeper'</span><span>,</span><span> </span><span>'</span><span>\n\n</span><span>Second Keeper:'</span><span>),</span>
<span> </span><span>(</span><span>'</span><span>\n</span><span>Now, Thomas Mow'</span><span>,</span><span> </span><span>'Now, Thomas Mowb'</span><span>),</span>
<span> </span><span>(</span><span>'or this once, ye'</span><span>,</span><span> </span><span>'r this once, yea'</span><span>),</span>
<span> </span><span>(</span><span>"l 'tis just.</span><span>\n\n</span><span>LU"</span><span>,</span><span> </span><span>" 'tis just.</span><span>\n\n</span><span>LUC"</span><span>),</span>
<span> </span><span>(</span><span>'es like a lamb. '</span><span>,</span><span> </span><span>'s like a lamb. Y'</span><span>),</span>
<span> </span><span>(</span><span>'t night, I warra'</span><span>,</span><span> </span><span>' night, I warran'</span><span>),</span>
<span> </span><span>(</span><span>'y tears would wa'</span><span>,</span><span> </span><span>' tears would was'</span><span>),</span>
<span> </span><span>(</span><span>'</span><span>\n\n</span><span>ANGELO:</span><span>\n</span><span>Well, '</span><span>,</span><span> </span><span>'</span><span>\n</span><span>ANGELO:</span><span>\n</span><span>Well, l'</span><span>)</span><span>]</span>
</pre></div>

<p>What's interesting about implementing papers is that there are two aspects to the model <em>working</em>: compilation (do your tensors all match up from layer to layer), and training (does the loss go down). Figuring out how to ensure that each of your components is working is key to developing your model in a predictable, engineering-minded way.</p>
<p>That's why we're also going to define the method for how we're going to evaluate the model. We want to do this before we even define the model, because we want to be able to use it to evaluate the model as we're training it.</p>
<div><pre><span></span><span>@torch</span><span>.</span><span>no_grad</span><span>()</span>  <span># don't compute gradients for this function</span>
<span>def</span> <span>evaluate_loss</span><span>(</span><span>model</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>):</span>
    <span>out</span> <span>=</span> <span>{}</span>
    <span>model</span><span>.</span><span>eval</span><span>()</span>
    <span>for</span> <span>split</span> <span>in</span> <span>[</span><span>"train"</span><span>,</span> <span>"val"</span><span>]:</span>
        <span>losses</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>10</span><span>):</span>
            <span>xb</span><span>,</span> <span>yb</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>split</span><span>,</span> <span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>])</span>
            <span>_</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xb</span><span>,</span> <span>yb</span><span>)</span>
            <span>losses</span><span>.</span><span>append</span><span>(</span><span>loss</span><span>.</span><span>item</span><span>())</span>
        <span>out</span><span>[</span><span>split</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>mean</span><span>(</span><span>losses</span><span>)</span>
    <span>model</span><span>.</span><span>train</span><span>()</span>
    <span>return</span> <span>out</span>
</pre></div>

<h2 id="setting-up-a-working-base-model">Setting up a working base model</h2>
<p>Here's a basic feed-forward neural network with embeddings. It's the base model we're going to start with, and then swap out parts of it as we go along until we eventually end up with the model as described in Llama.</p>
<div><pre><span></span><span>class</span> <span>SimpleBrokenModel</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>embedding</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span>
        <span>)</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embedding</span><span>(</span><span>idx</span><span>)</span>
        <span>a</span> <span>=</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>
        <span>logits</span> <span>=</span> <span>F</span><span>.</span><span>softmax</span><span>(</span><span>a</span><span>,</span> <span>dim</span><span>=-</span><span>1</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

        <span>else</span><span>:</span>
            <span>return</span> <span>logits</span>

<span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'d_model'</span><span>:</span> <span>128</span><span>,</span>
<span>})</span>
<span>model</span> <span>=</span> <span>SimpleBrokenModel</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>
</pre></div>



<p>It's at this point that we have to start worrying about the shape of our tensors and making indices match. Check out this line of our model definition:</p>
<div><pre><span></span><span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
</pre></div>

<p>We have to reshape the <code>logits</code> and <code>targets</code> tensors so that their dimensions match when we compare. We do this with the <code>view</code> method. The <code>-1</code> argument means "infer this dimension from the others". So, in this case, we're saying "reshape <code>logits</code> and <code>targets</code> to have the same number of rows, and however many columns are needed to make that happen". This is a common pattern when you're working with batches of data.</p>
<p>Alright, let's train our <code>SimpleBrokenModel</code> to make sure gradients flow. After we confirm that, we can swap out parts of it to match Llama, train again, and track our progress. It's at this point that I start keeping a <em>log</em> of my training runs, so that I can easily just go back to a previous run in the event that I mess something up.</p>
<div><pre><span></span><span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'epochs'</span><span>:</span> <span>1000</span><span>,</span>
    <span>'log_interval'</span><span>:</span> <span>10</span> 
<span>})</span>
<span>model</span> <span>=</span> <span>SimpleBrokenModel</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>

<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span>
    <span>model</span><span>.</span><span>parameters</span><span>(),</span> 
<span>)</span>

<span>def</span> <span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>,</span> <span>scheduler</span><span>=</span><span>None</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>,</span> <span>print_logs</span><span>=</span><span>False</span><span>):</span>
    <span>losses</span> <span>=</span> <span>[]</span>
    <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>config</span><span>[</span><span>'epochs'</span><span>]):</span>
        <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>

        <span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>])</span>
        <span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>targets</span><span>=</span><span>ys</span><span>)</span>
        <span>loss</span><span>.</span><span>backward</span><span>()</span>
        <span>optimizer</span><span>.</span><span>step</span><span>()</span>

        <span>if</span> <span>scheduler</span><span>:</span>
            <span>scheduler</span><span>.</span><span>step</span><span>()</span>

        <span>if</span> <span>epoch</span> <span>%</span> <span>config</span><span>[</span><span>'log_interval'</span><span>]</span> <span>==</span> <span>0</span><span>:</span>
            <span>batch_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span> <span>-</span> <span>start_time</span>
            <span>x</span> <span>=</span> <span>evaluate_loss</span><span>(</span><span>model</span><span>)</span>
            <span>losses</span> <span>+=</span> <span>[</span><span>x</span><span>]</span>
            <span>if</span> <span>print_logs</span><span>:</span>
                <span>print</span><span>(</span><span>f</span><span>"Epoch </span><span>{</span><span>epoch</span><span>}</span><span> | val loss </span><span>{</span><span>x</span><span>[</span><span>'val'</span><span>]</span><span>:</span><span>.3f</span><span>}</span><span> | Time </span><span>{</span><span>batch_time</span><span>:</span><span>.3f</span><span>}</span><span> | ETA in seconds </span><span>{</span><span>batch_time</span><span> </span><span>*</span><span> </span><span>(</span><span>config</span><span>[</span><span>'epochs'</span><span>]</span><span> </span><span>-</span><span> </span><span>epoch</span><span>)</span><span>/</span><span>config</span><span>[</span><span>'log_interval'</span><span>]</span><span> </span><span>:</span><span>.3f</span><span>}</span><span>"</span><span>)</span>
            <span>start_time</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>

            <span>if</span> <span>scheduler</span><span>:</span>
                <span>print</span><span>(</span><span>"lr: "</span><span>,</span> <span>scheduler</span><span>.</span><span>get_lr</span><span>())</span>

    <span>print</span><span>(</span><span>"validation loss: "</span><span>,</span> <span>losses</span><span>[</span><span>-</span><span>1</span><span>][</span><span>'val'</span><span>])</span>
    <span>return</span> <span>pd</span><span>.</span><span>DataFrame</span><span>(</span><span>losses</span><span>)</span><span>.</span><span>plot</span><span>()</span>

<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 33217
validation loss:  3.9457355260849
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_22_2.png?raw=true"></p>
<p>Notice how we get a training curve that goes down, but barely by anything. How do we know it's barely training? We have to use first principles. The cross-entropy loss before training is 4.17, and after 1000 epochs is 3.93. How can we make sense of it intuitively?</p>
<p>Cross-entropy in this context is referring to how likely we are to pick the wrong word. So here,</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mi>H</mi><mo stretchy="false">(</mo><mi>T</mi><mo>,</mo><mi>q</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi>N</mi></mrow></msubsup><mfrac><mrow><mn>1</mn></mrow><mrow><mi>N</mi></mrow></mfrac><mi>log</mi><mi>q</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow></math></p>
<p>where $q(x_i)$ is the probability of picking the right word, as estimated by the model. If $q(x_i)$ is close to 1, then $\log q$ is close to 0; similarly, if $q$ is small, then $\log q$ is a large negative number, so $-\log q$ will be a large positive number. Now to build the intuition: to start, $-\log q = 4.17$, so $q = 0.015$, or around $\frac{1}{64.715}$. Recall that the vocabulary size $|V| = 65$, so what we're basically saying here is that the model is as good at choosing the next letter as randomly picking from our vocabulary. After training, $-\log q = 3.93$, so we're now basically choosing between 50 letters. This is a very small improvement, so something is probably wrong.</p>
<p>To get an intuition for how the loss relates to the model's performance, think about the model choosing among $\tilde V$ tokens; when $\tilde V$ is small, the model is more likely to guess right. In addition, we know $\max \tilde V = V$, which can help us understand if our model is learning at all.</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mover><mi>V</mi><mo stretchy="false">~</mo></mover><mo>=</mo><mi>exp</mi><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">)</mo></mrow></math></p>
<p>Let's try to debug what's going on. Notice that in our model we're using a softmax layer on our logits, which is a function that takes a vector of numbers and squashes them into a probability distribution. But for using the built in <code>F.cross_entropy</code> function, we need to pass in the <a href="https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html">unnormalized logits directly</a>. So let's remove that from our model and try again.</p>
<div><pre><span></span><span>class</span> <span>SimpleModel</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>embedding</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span>
        <span>)</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embedding</span><span>(</span><span>idx</span><span>)</span>
        <span>logits</span> <span>=</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

        <span>else</span><span>:</span>
            <span>return</span> <span>logits</span>

<span>model</span> <span>=</span> <span>SimpleModel</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>
<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>())</span>
<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 33217
validation loss:  2.5113263607025145
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_24_2.png?raw=true"></p>
<p>Great, now our loss is $2.54$, so we're choosing from $12.67$ characters. That's way better than the 65 we started with. Let's add a generate method to our model so we visually see the results of our model.</p>
<div><pre><span></span><span>def</span> <span>generate</span><span>(</span><span>model</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>,</span> <span>max_new_tokens</span><span>=</span><span>30</span><span>):</span>
    <span>idx</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>(</span><span>5</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>long</span><span>()</span>
    <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>max_new_tokens</span><span>):</span>
        <span># call the model</span>
        <span>logits</span> <span>=</span> <span>model</span><span>(</span><span>idx</span><span>[:,</span> <span>-</span><span>config</span><span>[</span><span>'context_window'</span><span>]:])</span>
        <span>last_time_step_logits</span> <span>=</span> <span>logits</span><span>[</span>
            <span>:,</span> <span>-</span><span>1</span><span>,</span> <span>:</span>
        <span>]</span>  <span># all the batches (1), last time step, all the logits</span>
        <span>p</span> <span>=</span> <span>F</span><span>.</span><span>softmax</span><span>(</span><span>last_time_step_logits</span><span>,</span> <span>dim</span><span>=-</span><span>1</span><span>)</span>  <span># softmax to get probabilities</span>
        <span>idx_next</span> <span>=</span> <span>torch</span><span>.</span><span>multinomial</span><span>(</span>
            <span>p</span><span>,</span> <span>num_samples</span><span>=</span><span>1</span>
        <span>)</span>  <span># sample from the distribution to get the next token</span>
        <span>idx</span> <span>=</span> <span>torch</span><span>.</span><span>cat</span><span>([</span><span>idx</span><span>,</span> <span>idx_next</span><span>],</span> <span>dim</span><span>=-</span><span>1</span><span>)</span>  <span># append to the sequence</span>
    <span>return</span> <span>[</span><span>decode</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>idx</span><span>.</span><span>tolist</span><span>()]</span>

<span>generate</span><span>(</span><span>model</span><span>)</span>
</pre></div>

<div><pre><span></span>['\nWI in\nThed grtend\nA yod ys wit',
 '\nY aroticunutser\nE oy mendomed ',
 "\n\nRIf t fan f ses, k be wn'd mo",
 '\nRu hiseedst den t wat onderyou',
 "\nARaceps hond wr f\nI' fu kn be "]
</pre></div>

<p>It's not half bad, but also not half good. But now we have a working model that is training to a validation loss. So here we'll iterate on our model to make it closer to Llama.</p>
<h2 id="llama-specifics">Llama specifics</h2>
<p>Llama describes three architectural modifications to the original Transformer:</p>
<ol>
<li>RMSNorm for pre-normalization</li>
<li>Rotary embeddings</li>
<li>SwiGLU activation function</li>
</ol>
<p>We're going to add each one, one at a time to our base model, and iterate.</p>
<h3 id="rmsnorm">RMSNorm</h3>
<p>In Vaswani 2017, the original transformer uses BatchNormalization. In Llama, the authors use RMSNorm, which is where you scale the bector by the variance without centering it. In addition, while Vaswani applies normalization to the output of the attention layer (post-normalization), Llama applies it to the inputs before (pre-normalization).</p>
<div><pre><span></span><span>class</span> <span>RMSNorm</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>layer_shape</span><span>,</span> <span>eps</span><span>=</span><span>1e-8</span><span>,</span> <span>bias</span><span>=</span><span>False</span><span>):</span>
        <span>super</span><span>(</span><span>RMSNorm</span><span>,</span> <span>self</span><span>)</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>register_parameter</span><span>(</span><span>"scale"</span><span>,</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>ones</span><span>(</span><span>layer_shape</span><span>)))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
<span>        </span><span>"""</span>
<span>        assumes shape is (batch, seq_len, d_model)</span>
<span>        """</span>
        <span># frob norm is not the same as RMS. RMS = 1/sqrt(N) * frob norm</span>
        <span>ff_rms</span> <span>=</span> <span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>x</span><span>,</span> <span>dim</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>))</span> <span>*</span> <span>x</span><span>[</span><span>0</span><span>]</span><span>.</span><span>numel</span><span>()</span> <span>**</span> <span>-</span><span>.5</span>
        <span>raw</span> <span>=</span> <span>x</span> <span>/</span> <span>ff_rms</span><span>.</span><span>unsqueeze</span><span>(</span><span>-</span><span>1</span><span>)</span><span>.</span><span>unsqueeze</span><span>(</span><span>-</span><span>1</span><span>)</span>
        <span>return</span> <span>self</span><span>.</span><span>scale</span><span>[:</span><span>x</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>],</span> <span>:]</span><span>.</span><span>unsqueeze</span><span>(</span><span>0</span><span>)</span> <span>*</span> <span>raw</span>

<span>config</span> <span>=</span> <span>{</span>
    <span>'batch_size'</span><span>:</span> <span>5</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>11</span><span>,</span>
    <span>'d_model'</span><span>:</span> <span>13</span><span>,</span>
<span>}</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>((</span><span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>m</span> <span>=</span> <span>RMSNorm</span><span>((</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>g</span> <span>=</span> <span>m</span><span>(</span><span>batch</span><span>)</span>
<span>print</span><span>(</span><span>g</span><span>.</span><span>shape</span><span>)</span>
</pre></div>



<p>We want to test to ensure that the RMSNorm is doing what we think it should. We can do this the old-fashioned way: row-wise comparisons. The RMSNorm has the property where the norm of the layer will be the square root of the number of elements in the layer, so we can check that for every layer.</p>
<div><pre><span></span><span>rms</span> <span>=</span> <span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>batch</span><span>,</span> <span>dim</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>))</span> <span>*</span> <span>(</span><span>batch</span><span>[</span><span>0</span><span>]</span><span>.</span><span>numel</span><span>()</span> <span>**</span> <span>-</span><span>.5</span><span>)</span>

<span># scaled_batch.var(dim=(1,2))</span>
<span>assert</span> <span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span><span>.</span><span>float</span><span>()</span> <span>)</span> <span>==</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span><span>.</span><span>float</span><span>()</span> <span>**</span> <span>2</span> <span>)</span><span>.</span><span>sum</span><span>()</span> <span>**</span> <span>.5</span>
<span>rms</span> <span>=</span> <span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span> <span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span><span>.</span><span>float</span><span>()</span> <span>)</span> <span>*</span> <span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span><span>.</span><span>numel</span><span>()</span> <span>**</span> <span>-</span><span>.5</span><span>)</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>5</span><span>)</span><span>.</span><span>float</span><span>()</span> <span>/</span> <span>rms</span><span>),</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>5</span> <span>**</span> <span>.5</span><span>))</span>
<span>ff_rms</span> <span>=</span> <span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>batch</span><span>,</span> <span>dim</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>))</span> <span>*</span> <span>batch</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>:]</span><span>.</span><span>numel</span><span>()</span> <span>**</span> <span>-</span><span>.5</span>

<span># RMS for sure</span>
<span>ffx</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>batch</span><span>)</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>batch</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
    <span>ffx</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>batch</span><span>[</span><span>i</span><span>]</span> <span>/</span> <span>ff_rms</span><span>[</span><span>i</span><span>]</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>torch</span><span>.</span><span>linalg</span><span>.</span><span>norm</span><span>(</span><span>ffx</span><span>,</span> <span>dim</span><span>=</span><span>(</span><span>1</span><span>,</span><span>2</span><span>))</span> <span>**</span> <span>2</span><span>,</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>143</span><span>)</span><span>.</span><span>float</span><span>())</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>ffx</span><span>,</span> <span>g</span><span>)</span>
</pre></div>

<p>Alright, so that's RMSNorm, and it seems like it's working. Again, let's test it out.</p>
<div><pre><span></span><span>class</span> <span>SimpleModel_RMS</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>embedding</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>rms</span> <span>=</span> <span>RMSNorm</span><span>((</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span>
        <span>)</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embedding</span><span>(</span><span>idx</span><span>)</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>logits</span> <span>=</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

        <span>else</span><span>:</span>
            <span>return</span> <span>logits</span>

<span>model</span> <span>=</span> <span>SimpleModel_RMS</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>
<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>())</span>
<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 35265
validation loss:  2.4792869329452514
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_34_2.png?raw=true"></p>
<p>So RMSNorm works, and it got our loss down by a small amount.</p>
<h3 id="rotary-embeddings">Rotary Embeddings</h3>
<p><a href="https://arxiv.org/pdf/2104.09864.pdf">RoPE</a> is a kind of positional encoding for transformers. In Attention is All You Need, the authors propose two kinds of positional encodings, learned and fixed. In RoPE, the authors propose embedding the position of a token in a sequence by rotating the embedding, with a different rotation at each position.</p>
<div><pre><span></span><span>def</span> <span>get_rotary_matrix</span><span>(</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>):</span>
        <span>R</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>((</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>,</span> <span>embedding_dim</span><span>),</span> <span>requires_grad</span><span>=</span><span>False</span><span>)</span>
        <span>for</span> <span>position</span> <span>in</span> <span>range</span><span>(</span><span>context_window</span><span>):</span>
            <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>embedding_dim</span><span>//</span><span>2</span><span>):</span>
                <span>theta</span> <span>=</span> <span>10000.</span> <span>**</span> <span>(</span><span>-</span><span>2.</span><span>*</span><span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span> <span>/</span> <span>embedding_dim</span><span>)</span>
                <span>m_theta</span> <span>=</span> <span>position</span> <span>*</span> <span>theta</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>-</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
        <span>return</span> <span>R</span>
</pre></div>

<div><pre><span></span><span>K</span> <span>=</span> <span>3</span>
<span>config</span> <span>=</span> <span>{</span>
    <span>'batch_size'</span><span>:</span> <span>10</span><span>,</span>
    <span>'d_model'</span><span>:</span> <span>32</span><span>,</span>
    <span>'n_heads'</span><span>:</span> <span>8</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>K</span><span>**</span><span>2</span><span>,</span>
<span>}</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>1</span><span>,</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
<span>R</span> <span>=</span> <span>get_rotary_matrix</span><span>(</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
<span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>K</span><span>,</span> <span>K</span><span>,</span> <span>figsize</span><span>=</span><span>(</span><span>K</span> <span>*</span> <span>3</span><span>,</span> <span>K</span> <span>*</span> <span>4</span><span>))</span>

<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>K</span><span>):</span>
    <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>K</span><span>):</span>
        <span>ax</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span><span>.</span><span>imshow</span><span>(</span><span>R</span><span>[</span><span>i</span> <span>*</span> <span>K</span> <span>+</span> <span>j</span><span>,</span> <span>:,</span> <span>:]</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>())</span>
        <span>ax</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span><span>.</span><span>set_title</span><span>(</span><span>f</span><span>'rotation at </span><span>{</span><span>i</span><span> </span><span>*</span><span> </span><span>K</span><span> </span><span>+</span><span> </span><span>j</span><span>}</span><span>'</span><span>)</span>
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_38_0.png?raw=true"></p>
<p>Let's make sure these work. They should exhibit the quality that
<math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><msubsup><mi>q</mi><mi>m</mi><mi>T</mi></msubsup><msub><mi>k</mi><mi>n</mi></msub><mo>=</mo><mo stretchy="false">(</mo><msubsup><mi>R</mi><mrow><mi>Θ</mi><mo>,</mo><mi>m</mi></mrow><mi>d</mi></msubsup><msub><mi>W</mi><mi>q</mi></msub><msub><mi>x</mi><mi>m</mi></msub><msup><mo stretchy="false">)</mo><mi>T</mi></msup><mo stretchy="false">(</mo><msubsup><mi>R</mi><mrow><mi>Θ</mi><mo>,</mo><mi>n</mi></mrow><mi>d</mi></msubsup><msub><mi>W</mi><mi>k</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msup><mi>x</mi><mi>T</mi></msup><msub><mi>W</mi><mi>q</mi></msub><msubsup><mi>R</mi><mrow><mi>Θ</mi><mo>,</mo><mi>n</mi><mo>−</mo><mi>m</mi></mrow><mi>d</mi></msubsup><msub><mi>W</mi><mi>k</mi></msub><msub><mi>x</mi><mi>n</mi></msub><mo>.</mo></mrow></math></p>
<div><pre><span></span><span>config</span> <span>=</span> <span>{</span>
    <span>'d_model'</span><span>:</span> <span>128</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>16</span><span>,</span>
<span>}</span>

<span>R</span> <span>=</span> <span>get_rotary_matrix</span><span>(</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
<span>x</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>])</span>
<span>y</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>])</span>

<span>m</span> <span>=</span> <span>3</span>
<span>n</span> <span>=</span> <span>13</span>

<span>x_m</span> <span>=</span> <span>R</span><span>[</span><span>m</span><span>,:,:]</span> <span>@</span> <span>x</span>
<span>x_n</span> <span>=</span> <span>R</span><span>[</span><span>n</span><span>,:,:]</span> <span>@</span> <span>y</span>

<span>assert</span> <span>torch</span><span>.</span><span>isclose</span><span>(</span><span>x_m</span> <span>@</span> <span>x_n</span><span>,</span> <span>x</span> <span>@</span> <span>R</span><span>[</span><span>n</span><span>-</span><span>m</span><span>,:,:]</span> <span>@</span> <span>y</span><span>)</span>
</pre></div>

<p>So the RoPE rotations work as expected.</p>
<div><pre><span></span><span>config</span> <span>=</span> <span>{</span>
    <span>'batch_size'</span><span>:</span> <span>10</span><span>,</span>
    <span>'d_model'</span><span>:</span> <span>512</span><span>,</span>
    <span>'n_heads'</span><span>:</span> <span>8</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>16</span><span>,</span>
<span>}</span>

<span>class</span> <span>RoPEAttention</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>
        <span>self</span><span>.</span><span>w_q</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>
        <span>self</span><span>.</span><span>w_k</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>
        <span>self</span><span>.</span><span>w_v</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>

        <span>self</span><span>.</span><span>multihead</span> <span>=</span> <span>nn</span><span>.</span><span>MultiheadAttention</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'n_heads'</span><span>],</span> <span>dropout</span><span>=</span><span>0.1</span><span>,</span> <span>batch_first</span><span>=</span><span>True</span><span>)</span>
        <span>self</span><span>.</span><span>R</span> <span>=</span> <span>get_rotary_matrix</span><span>(</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>

    <span>def</span> <span>get_rotary_matrix</span><span>(</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>):</span>
        <span>R</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>((</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>,</span> <span>embedding_dim</span><span>),</span> <span>requires_grad</span><span>=</span><span>False</span><span>)</span>
        <span>for</span> <span>position</span> <span>in</span> <span>range</span><span>(</span><span>context_window</span><span>):</span>
            <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>embedding_dim</span><span>//</span><span>2</span><span>):</span>
                <span>theta</span> <span>=</span> <span>10000.</span> <span>**</span> <span>(</span><span>-</span><span>2.</span><span>*</span><span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span> <span>/</span> <span>embedding_dim</span><span>)</span>
                <span>m_theta</span> <span>=</span> <span>position</span> <span>*</span> <span>theta</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>-</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
        <span>return</span> <span>R</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>False</span><span>):</span>
        <span>b</span><span>,</span><span>m</span><span>,</span><span>d</span> <span>=</span> <span>x</span><span>.</span><span>shape</span>

        <span>q</span> <span>=</span> <span>self</span><span>.</span><span>w_q</span><span>(</span><span>x</span><span>)</span>
        <span>k</span> <span>=</span> <span>self</span><span>.</span><span>w_k</span><span>(</span><span>x</span><span>)</span>
        <span>v</span> <span>=</span> <span>self</span><span>.</span><span>w_v</span><span>(</span><span>x</span><span>)</span>

        <span>q_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>q</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
        <span>k_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>k</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
        <span>v_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>v</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>

        <span>activations</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>self</span><span>.</span><span>multihead</span><span>(</span>
            <span>q_out</span><span>,</span><span>k_out</span><span>,</span><span>v_out</span><span>,</span> 
        <span>)</span>

        <span>if</span> <span>return_attn_weights</span><span>:</span>
            <span>return</span> <span>activations</span><span>,</span> <span>attn_weights</span>
        <span>return</span> <span>activations</span>

<span>layer</span> <span>=</span> <span>RoPEAttention</span><span>(</span><span>config</span><span>)</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>((</span><span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>output</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>layer</span><span>(</span><span>batch</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>True</span><span>)</span>
</pre></div>

<blockquote>
<p>Tip here: know the difference between tensor dimensions at train time vs tensor dimensions at inference time.</p>
</blockquote>
<p>Although at train time, you can expect your tensor dimensions to match your model parameters closely, eg <code>batch.shape = (config['batch_size'], config['context_window'], config['d_model'])</code>, at inference time, you may have to deal with a single example, eg <code>batch.shape = (1, 1, config['d_model'])</code>. For this reason, you need to make sure that when you're indexing in the <code>forward</code> pass, you're indexing using shapes derived from the input, not necessarily the model parameters.</p>
<p>Let's make sure it does what we think it does. For this layer, we're going to want to test three things:</p>
<ol>
<li>that it rotates embeddings the way we think it does</li>
<li>that the attention mask used for causal attention is working properly.</li>
</ol>
<div><pre><span></span><span>x</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>((</span><span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>

<span>q</span> <span>=</span> <span>layer</span><span>.</span><span>w_q</span><span>(</span><span>x</span><span>)</span>
<span>k</span> <span>=</span> <span>layer</span><span>.</span><span>w_k</span><span>(</span><span>x</span><span>)</span>
<span>v</span> <span>=</span> <span>layer</span><span>.</span><span>w_v</span><span>(</span><span>x</span><span>)</span>

<span>q_rotated</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>x</span><span>)</span>
<span>k_rotated</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>x</span><span>)</span>
<span>v_rotated</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>x</span><span>)</span>

<span>for</span> <span>position</span> <span>in</span> <span>range</span><span>(</span><span>config</span><span>[</span><span>'context_window'</span><span>]):</span>
    <span>q_rotated</span><span>[:,</span><span>position</span><span>,:]</span> <span>=</span> <span>torch</span><span>.</span><span>matmul</span><span>(</span><span>q</span><span>[:,</span><span>position</span><span>,:],</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>position</span><span>,:,:])</span>
    <span>k_rotated</span><span>[:,</span><span>position</span><span>,:]</span> <span>=</span> <span>torch</span><span>.</span><span>matmul</span><span>(</span><span>k</span><span>[:,</span><span>position</span><span>,:],</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>position</span><span>,:,:])</span>
    <span>v_rotated</span><span>[:,</span><span>position</span><span>,:]</span> <span>=</span> <span>torch</span><span>.</span><span>matmul</span><span>(</span><span>v</span><span>[:,</span><span>position</span><span>,:],</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>position</span><span>,:,:])</span>

<span>q_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>q</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>layer</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
<span>k_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>k</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>layer</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
<span>v_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>v</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>layer</span><span>.</span><span>R</span><span>))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>

<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)[</span><span>0</span><span>],</span> <span>q</span><span>[:,</span><span>0</span><span>,:])</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)[</span><span>0</span><span>]</span> <span>@</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>0</span><span>],</span> <span>q</span><span>[:,</span><span>0</span><span>,:]</span> <span>@</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>0</span><span>])</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q_rotated</span><span>,</span> <span>q_out</span><span>)</span>
</pre></div>

<div><pre><span></span><span>config</span> <span>=</span> <span>{</span>
    <span>'batch_size'</span><span>:</span> <span>1</span><span>,</span>
    <span>'d_model'</span><span>:</span> <span>2</span><span>,</span>
    <span>'n_heads'</span><span>:</span> <span>2</span><span>,</span>
    <span>'context_window'</span><span>:</span> <span>3</span><span>,</span>
<span>}</span>

<span>layer</span> <span>=</span> <span>RoPEAttention</span><span>(</span><span>config</span><span>)</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>ones</span><span>((</span><span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>output</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>layer</span><span>(</span><span>batch</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>True</span><span>)</span>

<span>m</span> <span>=</span> <span>0</span>
<span>x_q</span> <span>=</span> <span>batch</span><span>[</span><span>0</span><span>,</span> <span>m</span><span>]</span>
<span>q</span> <span>=</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>m</span><span>,:,:]</span> <span>@</span> <span>layer</span><span>.</span><span>w_q</span><span>(</span><span>x_q</span><span>)</span>

<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>layer</span><span>.</span><span>w_q</span><span>(</span><span>x_q</span><span>),</span> <span>layer</span><span>.</span><span>w_q</span><span>.</span><span>weight</span> <span>@</span> <span>x_q</span><span>)</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q</span><span>,</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>m</span><span>,</span> <span>:,</span> <span>:]</span> <span>@</span> <span>layer</span><span>.</span><span>w_q</span><span>.</span><span>weight</span> <span>@</span> <span>x_q</span><span>)</span>

<span>n</span> <span>=</span> <span>2</span>
<span>x_k</span> <span>=</span> <span>batch</span><span>[</span><span>0</span><span>,</span> <span>n</span><span>]</span>
<span>k</span> <span>=</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>n</span><span>,:,:]</span> <span>@</span> <span>layer</span><span>.</span><span>w_k</span><span>(</span><span>x_k</span><span>)</span>

<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>layer</span><span>.</span><span>w_k</span><span>(</span><span>x_k</span><span>),</span> <span>layer</span><span>.</span><span>w_k</span><span>.</span><span>weight</span> <span>@</span> <span>x_k</span><span>)</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>k</span><span>,</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span> <span>@</span> <span>layer</span><span>.</span><span>w_k</span><span>.</span><span>weight</span> <span>@</span> <span>x_k</span><span>)</span>

<span>assert</span> <span>q</span><span>.</span><span>T</span> <span>@</span> <span>k</span> <span>==</span> <span>q</span> <span>@</span> <span>k</span> <span># transpose is redundant</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q</span> <span>@</span> <span>k</span><span>,</span> <span>x_k</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>w_k</span><span>.</span><span>weight</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>n</span><span>,</span> <span>:,</span> <span>:]</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>m</span><span>,</span> <span>:,</span> <span>:]</span> <span>@</span> <span>layer</span><span>.</span><span>w_q</span><span>.</span><span>weight</span> <span>@</span> <span>x_q</span><span>)</span>
<span>assert</span> <span>torch</span><span>.</span><span>allclose</span><span>(</span><span>q</span> <span>@</span> <span>k</span><span>,</span> <span>x_k</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>w_k</span><span>.</span><span>weight</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>R</span><span>[</span><span>n</span><span>-</span><span>m</span><span>,</span> <span>:,</span> <span>:]</span><span>.</span><span>T</span> <span>@</span> <span>layer</span><span>.</span><span>w_q</span><span>.</span><span>weight</span> <span>@</span> <span>x_q</span><span>)</span>
</pre></div>

<div><pre><span></span><span>/</span><span>var</span><span>/</span><span>folders</span><span>/</span><span>w4</span><span>/</span><span>2j887</span><span>mvs097bkhhjpgfzjlyr0000gn</span><span>/</span><span>T</span><span>/</span><span>ipykernel_17478</span><span>/</span><span>2550954139.</span><span>py</span><span>:</span><span>26</span><span>:</span><span> </span><span>UserWarning</span><span>:</span><span> </span><span>The</span><span> </span><span>use</span><span> </span><span>of</span><span> </span><span>`</span><span>x</span><span>.</span><span>T</span><span>`</span><span> </span><span>on</span><span> </span><span>tensors</span><span> </span><span>of</span><span> </span><span>dimension</span><span> </span><span>other</span><span> </span><span>than</span><span> </span><span>2</span><span> </span><span>to</span><span> </span><span>reverse</span><span> </span><span>their</span><span> </span><span>shape</span><span> </span><span>is</span><span> </span><span>deprecated</span><span> </span><span>and</span><span> </span><span>it</span><span> </span><span>will</span><span> </span><span>throw</span><span> </span><span>an</span><span> </span><span>error</span><span> </span><span>in</span><span> </span><span>a</span><span> </span><span>future</span><span> </span><span>release</span><span>.</span><span> </span><span>Consider</span><span> </span><span>`</span><span>x</span><span>.</span><span>mT</span><span>`</span><span> </span><span>to</span><span> </span><span>transpose</span><span> </span><span>batches</span><span> </span><span>of</span><span> </span><span>matrices</span><span> </span><span>or</span><span> </span><span>`</span><span>x</span><span>.</span><span>permute</span><span>(</span><span>*</span><span>torch</span><span>.</span><span>arange</span><span>(</span><span>x</span><span>.</span><span>ndim</span><span> </span><span>-</span><span> </span><span>1</span><span>,</span><span> </span><span>-</span><span>1</span><span>,</span><span> </span><span>-</span><span>1</span><span>))</span><span>`</span><span> </span><span>to</span><span> </span><span>reverse</span><span> </span><span>the</span><span> </span><span>dimensions</span><span> </span><span>of</span><span> </span><span>a</span><span> </span><span>tensor</span><span>.</span><span> </span><span>(</span><span>Triggered</span><span> </span><span>internally</span><span> </span><span>at</span><span> </span><span>/</span><span>Users</span><span>/</span><span>runner</span><span>/</span><span>work</span><span>/</span><span>pytorch</span><span>/</span><span>pytorch</span><span>/</span><span>pytorch</span><span>/</span><span>aten</span><span>/</span><span>src</span><span>/</span><span>ATen</span><span>/</span><span>native</span><span>/</span><span>TensorShape</span><span>.</span><span>cpp</span><span>:</span><span>3575.</span><span>)</span>
<span>  </span><span>assert</span><span> </span><span>q</span><span>.</span><span>T</span><span> </span><span>@</span><span> </span><span>k</span><span> </span><span>==</span><span> </span><span>q</span><span> </span><span>@</span><span> </span><span>k</span><span> </span><span># transpose is redundant</span>
</pre></div>

<p>Now let's inspect the attention weights. Since this is causal, we would expect that due to masking, the upper triangular of the attention should be 0.</p>
<div><pre><span></span><span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'n_heads'</span><span>:</span> <span>8</span><span>,</span>
<span>})</span>
<span>layer</span> <span>=</span> <span>RoPEAttention</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>ones</span><span>((</span><span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>output</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>layer</span><span>(</span><span>batch</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>True</span><span>)</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>attn_weights</span><span>[</span><span>0</span><span>]</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>(),</span> <span>interpolation</span><span>=</span><span>'nearest'</span><span>)</span>
<span>plt</span><span>.</span><span>colorbar</span><span>()</span>
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_48_1.png?raw=true"></p>
<p>This is not good; it means that information is leaking across the attention. We need to ensure the causal mask is working.</p>
<div><pre><span></span><span>class</span> <span>RoPEAttention_wMask</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>
        <span>self</span><span>.</span><span>w_q</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>
        <span>self</span><span>.</span><span>w_k</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>
        <span>self</span><span>.</span><span>w_v</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>bias</span><span>=</span><span>False</span><span>)</span>

        <span>self</span><span>.</span><span>multihead</span> <span>=</span> <span>nn</span><span>.</span><span>MultiheadAttention</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'n_heads'</span><span>],</span> <span>dropout</span><span>=</span><span>0.1</span><span>,</span> <span>batch_first</span><span>=</span><span>True</span><span>)</span>
        <span>self</span><span>.</span><span>R</span> <span>=</span> <span>get_rotary_matrix</span><span>(</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>

    <span>def</span> <span>get_rotary_matrix</span><span>(</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>):</span>
        <span>R</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>((</span><span>context_window</span><span>,</span> <span>embedding_dim</span><span>,</span> <span>embedding_dim</span><span>),</span> <span>requires_grad</span><span>=</span><span>False</span><span>)</span>
        <span>for</span> <span>position</span> <span>in</span> <span>range</span><span>(</span><span>context_window</span><span>):</span>
            <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>embedding_dim</span><span>//</span><span>2</span><span>):</span>
                <span>theta</span> <span>=</span> <span>10000.</span> <span>**</span> <span>(</span><span>-</span><span>2.</span><span>*</span><span>(</span><span>i</span> <span>-</span> <span>1</span><span>)</span> <span>/</span> <span>embedding_dim</span><span>)</span>
                <span>m_theta</span> <span>=</span> <span>position</span> <span>*</span> <span>theta</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>-</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>m_theta</span><span>)</span>
                <span>R</span><span>[</span><span>position</span><span>,</span> <span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>,</span><span>2</span><span>*</span><span>i</span><span>+</span><span>1</span><span>]</span> <span>=</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>m_theta</span><span>)</span>
        <span>return</span> <span>R</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>False</span><span>):</span>
        <span>b</span><span>,</span><span>m</span><span>,</span><span>d</span> <span>=</span> <span>x</span><span>.</span><span>shape</span>

        <span>q</span> <span>=</span> <span>self</span><span>.</span><span>w_q</span><span>(</span><span>x</span><span>)</span>
        <span>k</span> <span>=</span> <span>self</span><span>.</span><span>w_k</span><span>(</span><span>x</span><span>)</span>
        <span>v</span> <span>=</span> <span>self</span><span>.</span><span>w_v</span><span>(</span><span>x</span><span>)</span>

        <span>q_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>q</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>[:</span><span>m</span><span>,</span> <span>...</span><span>]))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
        <span>k_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>k</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>[:</span><span>m</span><span>,</span> <span>...</span><span>]))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>
        <span>v_out</span> <span>=</span> <span>(</span><span>torch</span><span>.</span><span>bmm</span><span>(</span><span>v</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>),</span> <span>self</span><span>.</span><span>R</span><span>[:</span><span>m</span><span>,</span> <span>...</span><span>]))</span><span>.</span><span>transpose</span><span>(</span><span>0</span><span>,</span><span>1</span><span>)</span>

        <span>activations</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>self</span><span>.</span><span>multihead</span><span>(</span>
            <span>q_out</span><span>,</span><span>k_out</span><span>,</span><span>v_out</span><span>,</span> 
            <span>attn_mask</span><span>=</span><span>nn</span><span>.</span><span>Transformer</span><span>.</span><span>generate_square_subsequent_mask</span><span>(</span><span>m</span><span>),</span>
            <span>is_causal</span><span>=</span><span>True</span>
        <span>)</span>

        <span>if</span> <span>return_attn_weights</span><span>:</span>
            <span>return</span> <span>activations</span><span>,</span> <span>attn_weights</span>
        <span>return</span> <span>activations</span>

<span>layer</span> <span>=</span> <span>RoPEAttention</span><span>(</span><span>config</span><span>)</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>((</span><span>config</span><span>[</span><span>'batch_size'</span><span>],</span> <span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>output</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>layer</span><span>(</span><span>batch</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>True</span><span>)</span>
</pre></div>

<div><pre><span></span><span>layer</span> <span>=</span> <span>RoPEAttention_wMask</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>batch</span> <span>=</span> <span>torch</span><span>.</span><span>ones</span><span>((</span><span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'d_model'</span><span>]))</span>
<span>output</span><span>,</span> <span>attn_weights</span> <span>=</span> <span>layer</span><span>(</span><span>batch</span><span>,</span> <span>return_attn_weights</span><span>=</span><span>True</span><span>)</span>

<span>plt</span><span>.</span><span>imshow</span><span>(</span><span>attn_weights</span><span>[</span><span>0</span><span>]</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>())</span>
<span>plt</span><span>.</span><span>colorbar</span><span>()</span>
</pre></div>

<div><pre><span></span>&lt;matplotlib.colorbar.Colorbar at 0x16c2c7b50&gt;
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_51_1.png?raw=true"></p>
<p>Alright, let's run it and see what happens.</p>
<div><pre><span></span><span>class</span> <span>RopeModel</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>embedding</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>rms</span> <span>=</span> <span>RMSNorm</span><span>((</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
        <span>self</span><span>.</span><span>rope_attention</span> <span>=</span> <span>RoPEAttention_wMask</span><span>(</span><span>config</span><span>)</span>

        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
        <span>)</span>

        <span>self</span><span>.</span><span>last_linear</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>])</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embedding</span><span>(</span><span>idx</span><span>)</span>

        <span># one block of attention</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>rope_attention</span><span>(</span><span>x</span><span>)</span>

        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>

        <span>logits</span> <span>=</span> <span>self</span><span>.</span><span>last_linear</span><span>(</span><span>x</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

        <span>else</span><span>:</span>
            <span>return</span> <span>logits</span>

<span>model</span> <span>=</span> <span>RopeModel</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>
<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>())</span>
<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 150465
validation loss:  2.1157416343688964
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_53_2.png?raw=true"></p>
<p>It looks like we can drive our loss down even lower. Let's do that by updating master config.</p>
<div><pre><span></span><span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>"epochs"</span><span>:</span> <span>5000</span><span>,</span>
    <span>"log_interval"</span><span>:</span> <span>10</span><span>,</span>
<span>})</span>
<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>validation loss:  1.9027801871299743
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_55_2.png?raw=true"></p>
<h3 id="swiglu">SwiGLU</h3>
<p>As it says in the paper, "We replace the ReLU non-linearity by the SwiGLU activation function...we use a dimension of $\frac{2}{3} 4d$ isntead of $4d$ as in PaLM." SwiGLU is defined as:</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><mtext>SwiGLU</mtext><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mtext>Swish</mtext><mi>β</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mi>W</mi><mo>+</mo><mi>b</mi><mo stretchy="false">)</mo><mo>⊗</mo><mo stretchy="false">(</mo><mi>x</mi><mi>V</mi><mo>+</mo><mi>c</mi><mo stretchy="false">)</mo></mrow></math></p>
<p>where $\otimes$ is a component-wise product. The Swish function is defined as:</p>
<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mrow><msub><mtext>Swish</mtext><mi>β</mi></msub><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>x</mi><mi>σ</mi><mo stretchy="false">(</mo><mi>β</mi><mi>x</mi><mo stretchy="false">)</mo></mrow></math></p>
<p>where $\beta$ is a learnable parameter.</p>
<div><pre><span></span><span>class</span> <span>SwiGLU</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
<span>    </span><span>"""</span>
<span>    Swish-Gated Linear Unit</span>
<span>    https://arxiv.org/pdf/2002.05202v1.pdf</span>
<span>    """</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>size</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>
        <span>self</span><span>.</span><span>linear_gate</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>size</span><span>,</span> <span>size</span><span>)</span>
        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>size</span><span>,</span> <span>size</span><span>)</span>
        <span>self</span><span>.</span><span>beta</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>1</span><span>,</span> <span>requires_grad</span><span>=</span><span>True</span><span>)</span>

        <span>self</span><span>.</span><span>beta</span> <span>=</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>ones</span><span>(</span><span>1</span><span>))</span>
        <span>self</span><span>.</span><span>register_parameter</span><span>(</span><span>"beta"</span><span>,</span> <span>self</span><span>.</span><span>beta</span><span>)</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span> 
        <span>swish_gate</span> <span>=</span> <span>self</span><span>.</span><span>linear_gate</span><span>(</span><span>x</span><span>)</span> <span>*</span> <span>torch</span><span>.</span><span>sigmoid</span><span>(</span><span>self</span><span>.</span><span>beta</span> <span>*</span> <span>self</span><span>.</span><span>linear_gate</span><span>(</span><span>x</span><span>))</span>
        <span>out</span> <span>=</span> <span>swish_gate</span> <span>*</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>
        <span>return</span> <span>out</span>
</pre></div>

<div><pre><span></span><span>class</span> <span>RopeModel</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>embedding</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>rms</span> <span>=</span> <span>RMSNorm</span><span>((</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>
        <span>self</span><span>.</span><span>rope_attention</span> <span>=</span> <span>RoPEAttention_wMask</span><span>(</span><span>config</span><span>)</span>

        <span>self</span><span>.</span><span>linear</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>SwiGLU</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
        <span>)</span>

        <span>self</span><span>.</span><span>last_linear</span> <span>=</span> <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>])</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embedding</span><span>(</span><span>idx</span><span>)</span>

        <span># one block of attention</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>rope_attention</span><span>(</span><span>x</span><span>)</span>

        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>linear</span><span>(</span><span>x</span><span>)</span>

        <span>logits</span> <span>=</span> <span>self</span><span>.</span><span>last_linear</span><span>(</span><span>x</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>not</span> <span>None</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

        <span>else</span><span>:</span>
            <span>return</span> <span>logits</span>

<span>model</span> <span>=</span> <span>RopeModel</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'train'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>model</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>
<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>())</span>
<span>train</span><span>(</span><span>model</span><span>,</span> <span>optimizer</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 183490
validation loss:  1.8666490197181702
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_58_2.png?raw=true"></p>
<p>Now, let's add multiple layers of RopeAttention by creating blocks.</p>
<div><pre><span></span><span># add RMSNorm and residual conncection</span>
<span>class</span> <span>LlamaBlock</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>

        <span>self</span><span>.</span><span>rms</span> <span>=</span> <span>RMSNorm</span><span>((</span><span>config</span><span>[</span><span>'context_window'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]))</span>

        <span>self</span><span>.</span><span>attention</span> <span>=</span> <span>RoPEAttention_wMask</span><span>(</span><span>config</span><span>)</span>
        <span>self</span><span>.</span><span>feedforward</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>SwiGLU</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
        <span>)</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>attention</span><span>(</span><span>x</span><span>)</span>

        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>rms</span><span>(</span><span>x</span><span>)</span> <span># rms pre-normalization</span>
        <span>x</span> <span>=</span> <span>x</span> <span>+</span> <span>self</span><span>.</span><span>feedforward</span><span>(</span><span>x</span><span>)</span>
        <span>return</span> <span>x</span>
</pre></div>

<div><pre><span></span><span>block</span> <span>=</span> <span>LlamaBlock</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>block</span><span>(</span><span>torch</span><span>.</span><span>randn</span><span>(</span><span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'d_model'</span><span>]));</span>
</pre></div>

<div><pre><span></span><span>from</span> <span>collections</span> <span>import</span> <span>OrderedDict</span>

<span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'n_layers'</span><span>:</span> <span>4</span><span>,</span>
<span>})</span>
<span>class</span> <span>Llama</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>config</span><span>):</span>
        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>config</span> <span>=</span> <span>config</span>
        <span>self</span><span>.</span><span>embeddings</span> <span>=</span> <span>nn</span><span>.</span><span>Embedding</span><span>(</span><span>config</span><span>[</span><span>'vocab_size'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>])</span>
        <span>self</span><span>.</span><span>llama_blocks</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>OrderedDict</span><span>([(</span><span>f</span><span>"llama_</span><span>{</span><span>i</span><span>}</span><span>"</span><span>,</span> <span>LlamaBlock</span><span>(</span><span>config</span><span>))</span> <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>config</span><span>[</span><span>'n_layers'</span><span>])])</span>
        <span>)</span>

        <span>self</span><span>.</span><span>ffn</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>SwiGLU</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>]),</span>
            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>config</span><span>[</span><span>'d_model'</span><span>],</span> <span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span>
        <span>)</span>

        <span>print</span><span>(</span><span>"model params:"</span><span>,</span> <span>sum</span><span>([</span><span>m</span><span>.</span><span>numel</span><span>()</span> <span>for</span> <span>m</span> <span>in</span> <span>self</span><span>.</span><span>parameters</span><span>()]))</span>

    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>idx</span><span>,</span> <span>targets</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>embeddings</span><span>(</span><span>idx</span><span>)</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>llama_blocks</span><span>(</span><span>x</span><span>)</span>
        <span>logits</span> <span>=</span> <span>self</span><span>.</span><span>ffn</span><span>(</span><span>x</span><span>)</span>

        <span>if</span> <span>targets</span> <span>is</span> <span>None</span><span>:</span>
            <span>return</span> <span>logits</span>

        <span>else</span><span>:</span>
            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>config</span><span>[</span><span>'vocab_size'</span><span>]),</span> <span>targets</span><span>.</span><span>view</span><span>(</span><span>-</span><span>1</span><span>))</span>
            <span>return</span> <span>logits</span><span>,</span> <span>loss</span>

<span>llama</span> <span>=</span> <span>Llama</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>llama</span><span>.</span><span>parameters</span><span>())</span>
<span>train</span><span>(</span><span>llama</span><span>,</span> <span>optimizer</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>)</span>
</pre></div>

<div><pre><span></span>model params: 733382
validation loss:  1.616115140914917
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_62_2.png?raw=true"></p>
<p>It looks like we can drive the loss down even more, and although we're overfitting a little, I think we can still do better. Let's train longer.</p>
<div><pre><span></span><span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>'epochs'</span><span>:</span> <span>10000</span><span>,</span>
<span>})</span>
<span>train</span><span>(</span><span>llama</span><span>,</span> <span>optimizer</span><span>,</span> <span>scheduler</span><span>=</span><span>None</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>)</span>
</pre></div>

<div><pre><span></span>validation loss:  0.9024032115936279
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_64_2.png?raw=true"></p>
<p>It seems we can go even lower, still without serious overfitting. Either there is a leak, or it's actually doing well. The loss here is 1.08, which is equivalent to choosing between 2.9 tokens randomly.</p>
<div><pre><span></span><span>train</span><span>(</span><span>llama</span><span>,</span> <span>optimizer</span><span>,</span> <span>config</span><span>=</span><span>MASTER_CONFIG</span><span>)</span>
</pre></div>

<div><pre><span></span>validation loss:  0.746810007095337
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_66_2.png?raw=true"></p>
<div><pre><span></span><span>print</span><span>(</span><span>generate</span><span>(</span><span>llama</span><span>,</span> <span>MASTER_CONFIG</span><span>,</span> <span>500</span><span>)[</span><span>0</span><span>])</span>
</pre></div>

<div><pre><span></span>Evend her break of thou thire xoing dieble had side, did foesors exenatedH in siffied up,
    No, none,
    And you ling as thought depond.

    MENENIUS:
    Tell officien:
    To pesiding be
    Best wanty and to spiege,
    To uncine shee patss again,
    I will hen: then they
    Moieth:
    I my cast in letch:
    For bereful, give toan I may

    LINT OF AUMERLE:
    Out, or me but thee here sir,
    Why first with canse pring;
    Now!

    Gide me couuse
    The haster:
    And suilt harming,
    Then as pereise with and go.

    FROMNIUS:
    I well? speak and wieke ac
</pre></div>

<p>At this point, we've hit the bottom with our training. Let's test on the test set.</p>
<div><pre><span></span><span>xs</span><span>,</span> <span>ys</span> <span>=</span> <span>get_batches</span><span>(</span><span>dataset</span><span>,</span> <span>'test'</span><span>,</span> <span>MASTER_CONFIG</span><span>[</span><span>'batch_size'</span><span>],</span> <span>MASTER_CONFIG</span><span>[</span><span>'context_window'</span><span>])</span>

<span>logits</span><span>,</span> <span>loss</span> <span>=</span> <span>llama</span><span>(</span><span>xs</span><span>,</span> <span>ys</span><span>)</span>

<span>print</span><span>(</span><span>loss</span><span>)</span>
</pre></div>

<div><pre><span></span>tensor(0.8304, grad_fn=&lt;NllLossBackward0&gt;)
</pre></div>

<h2 id="miscellaneous">Miscellaneous</h2>
<h2 id="check-for-gradient-flows">Check for Gradient Flows</h2>
<p>Let's inspect the gradients, we want to see how they're flowing. If there are too many gradients where the value is close to 0, that's a problem.</p>
<div><pre><span></span><span># print the percentage that are near 0</span>
<span>def</span> <span>show_grads</span><span>(</span><span>model</span><span>,</span> <span>tol</span><span>=</span><span>1e-2</span><span>):</span>
    <span>return</span> <span>sorted</span><span>([(</span><span>name</span><span>,</span> <span>100.0</span> <span>*</span> <span>float</span><span>(</span><span>torch</span><span>.</span><span>sum</span><span>(</span><span>torch</span><span>.</span><span>abs</span><span>(</span><span>param</span><span>)</span> <span>&lt;=</span> <span>tol</span><span>))</span> <span>/</span> <span>float</span><span>(</span><span>param</span><span>.</span><span>nelement</span><span>()))</span> <span>for</span> <span>name</span><span>,</span> <span>param</span> <span>in</span> <span>model</span><span>.</span><span>named_parameters</span><span>()</span> <span>if</span> <span>param</span><span>.</span><span>requires_grad</span><span>],</span> <span>key</span><span>=</span><span>lambda</span> <span>t</span><span>:</span> <span>t</span><span>[</span><span>1</span><span>],</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>

<span>show_grads</span><span>(</span><span>llama</span><span>)</span>
</pre></div>

<div><pre><span></span>[('llama_blocks.llama_0.attention.multihead.in_proj_bias', 36.71875),
 ('llama_blocks.llama_3.attention.multihead.in_proj_bias', 35.9375),
 ('llama_blocks.llama_1.attention.multihead.in_proj_bias', 33.59375),
 ('llama_blocks.llama_2.attention.multihead.in_proj_bias', 33.333333333333336),
 ('llama_blocks.llama_0.attention.multihead.in_proj_weight',
  21.840413411458332),
 ('llama_blocks.llama_0.attention.w_q.weight', 14.892578125),
 ('llama_blocks.llama_0.attention.multihead.out_proj.weight', 13.4765625),
 ('llama_blocks.llama_0.attention.w_k.weight', 12.9638671875),
 ('llama_blocks.llama_0.attention.w_v.weight', 11.8896484375),
 ('llama_blocks.llama_1.attention.w_v.weight', 11.285400390625),
 ('llama_blocks.llama_3.attention.multihead.out_proj.weight', 11.12060546875),
 ('llama_blocks.llama_2.attention.w_v.weight', 10.68115234375),
 ('llama_blocks.llama_0.feedforward.0.weight', 10.4248046875),
 ('llama_blocks.llama_2.attention.multihead.out_proj.weight', 10.36376953125),
 ('llama_blocks.llama_1.attention.multihead.out_proj.weight', 10.2783203125),
 ('llama_blocks.llama_3.attention.multihead.out_proj.bias', 10.15625),
 ('llama_blocks.llama_3.attention.w_v.weight', 9.991455078125),
 ('llama_blocks.llama_0.feedforward.1.linear.weight', 9.9609375),
 ('llama_blocks.llama_1.attention.multihead.in_proj_weight',
  9.908040364583334),
 ('llama_blocks.llama_2.attention.multihead.in_proj_weight', 9.75341796875),
 ('llama_blocks.llama_0.feedforward.1.linear_gate.weight', 9.66796875),
 ('llama_blocks.llama_1.attention.multihead.out_proj.bias', 9.375),
 ('llama_blocks.llama_3.attention.multihead.in_proj_weight', 9.16748046875),
 ('llama_blocks.llama_1.feedforward.0.weight', 8.77685546875),
 ('llama_blocks.llama_0.feedforward.1.linear_gate.bias', 8.59375),
 ('llama_blocks.llama_2.feedforward.1.linear.bias', 8.59375),
 ('llama_blocks.llama_2.feedforward.0.weight', 8.4228515625),
 ('llama_blocks.llama_1.feedforward.1.linear.weight', 7.720947265625),
 ('llama_blocks.llama_1.feedforward.1.linear_gate.weight', 7.501220703125),
 ('llama_blocks.llama_3.feedforward.0.weight', 7.440185546875),
 ('llama_blocks.llama_2.feedforward.1.linear.weight', 7.31201171875),
 ('llama_blocks.llama_2.feedforward.1.linear_gate.weight', 7.196044921875),
 ('llama_blocks.llama_1.feedforward.1.linear_gate.bias', 7.03125),
 ('llama_blocks.llama_2.attention.multihead.out_proj.bias', 7.03125),
 ('llama_blocks.llama_2.feedforward.1.linear_gate.bias', 7.03125),
 ('llama_blocks.llama_2.attention.w_k.weight', 6.94580078125),
 ('llama_blocks.llama_3.feedforward.1.linear.weight', 6.927490234375),
 ('llama_blocks.llama_1.attention.w_k.weight', 6.82373046875),
 ('llama_blocks.llama_2.attention.w_q.weight', 6.82373046875),
 ('llama_blocks.llama_3.attention.w_k.weight', 6.585693359375),
 ('llama_blocks.llama_3.feedforward.1.linear_gate.weight', 6.494140625),
 ('llama_blocks.llama_1.attention.w_q.weight', 6.396484375),
 ('llama_blocks.llama_1.feedforward.1.linear.bias', 6.25),
 ('llama_blocks.llama_3.feedforward.1.linear.bias', 6.25),
 ('llama_blocks.llama_3.attention.w_q.weight', 6.2255859375),
 ('ffn.0.weight', 5.633544921875),
 ('llama_blocks.llama_0.feedforward.1.linear.bias', 5.46875),
 ('ffn.1.linear_gate.bias', 5.46875),
 ('ffn.1.linear_gate.weight', 5.2978515625),
 ('ffn.1.linear.weight', 5.26123046875),
 ('ffn.2.weight', 4.447115384615385),
 ('ffn.1.linear.bias', 3.90625),
 ('llama_blocks.llama_0.feedforward.0.bias', 3.125),
 ('ffn.2.bias', 3.076923076923077),
 ('llama_blocks.llama_3.feedforward.0.bias', 2.34375),
 ('ffn.0.bias', 2.34375),
 ('llama_blocks.llama_0.attention.multihead.out_proj.bias', 1.5625),
 ('llama_blocks.llama_2.feedforward.0.bias', 1.5625),
 ('llama_blocks.llama_3.feedforward.1.linear_gate.bias', 1.5625),
 ('llama_blocks.llama_1.feedforward.0.bias', 0.78125),
 ('embeddings.weight', 0.7572115384615384),
 ('llama_blocks.llama_0.rms.scale', 0.146484375),
 ('llama_blocks.llama_0.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_1.rms.scale', 0.0),
 ('llama_blocks.llama_1.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_2.rms.scale', 0.0),
 ('llama_blocks.llama_2.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_3.rms.scale', 0.0),
 ('llama_blocks.llama_3.feedforward.1.beta', 0.0),
 ('ffn.1.beta', 0.0)]
</pre></div>

<p>Here, for all of our parameter gradients, the vast majority are non-zero, which is great. If we start to see this number peak higher, then our gradients would not be flowing.</p>
<h2 id="experiment-with-hyperparams-aka-change-the-oven-settings">Experiment with hyperparams, aka "change the oven settings"</h2>
<p>In the original Llama paper, the authors use Cosine Annealing learning schedule. We didn't do that here, because I experimented and saw that it was worse.</p>
<div><pre><span></span><span>MASTER_CONFIG</span><span>.</span><span>update</span><span>({</span>
    <span>"epochs"</span><span>:</span> <span>1000</span>
<span>})</span>
<span>llama_with_cosine</span> <span>=</span> <span>Llama</span><span>(</span><span>MASTER_CONFIG</span><span>)</span>
<span>llama_optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span>
    <span>llama</span><span>.</span><span>parameters</span><span>(),</span> 
    <span>betas</span><span>=</span><span>(</span><span>.9</span><span>,</span> <span>.95</span><span>),</span> 
    <span>weight_decay</span><span>=</span><span>.1</span><span>,</span> 
    <span>eps</span><span>=</span><span>1e-9</span><span>,</span> 
    <span>lr</span><span>=</span><span>1e-3</span>
<span>)</span>
<span>scheduler</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>lr_scheduler</span><span>.</span><span>CosineAnnealingLR</span><span>(</span><span>llama_optimizer</span><span>,</span> <span>300</span><span>,</span> <span>eta_min</span><span>=</span><span>1e-5</span><span>)</span>
<span>train</span><span>(</span><span>llama_with_cosine</span><span>,</span> <span>llama_optimizer</span><span>,</span> <span>scheduler</span><span>=</span><span>scheduler</span><span>)</span>
</pre></div>

<div><pre><span></span><span>model</span><span> </span><span>params</span><span>:</span><span> </span><span>733382</span>


<span>/</span><span>Users</span><span>/</span><span>bkitano</span><span>/</span><span>Desktop</span><span>/</span><span>projects</span><span>/</span><span>llama</span><span>/</span><span>.</span><span>llama</span><span>/</span><span>lib</span><span>/</span><span>python3</span><span>.1</span><span>1</span><span>/</span><span>site</span><span>-</span><span>packages</span><span>/</span><span>torch</span><span>/</span><span>optim</span><span>/</span><span>lr_scheduler</span><span>.</span><span>py</span><span>:</span><span>814</span><span>:</span><span> </span><span>UserWarning</span><span>:</span><span> </span><span>To</span><span> </span><span>get</span><span> </span><span>the</span><span> </span><span>last</span><span> </span><span>learning</span><span> </span><span>rate</span><span> </span><span>computed</span><span> </span><span>by</span><span> </span><span>the</span><span> </span><span>scheduler</span><span>,</span><span> </span><span>please</span><span> </span><span>use</span><span> </span><span>`</span><span>get_last_lr</span><span>()</span><span>`</span><span>.</span>
<span>  </span><span>warnings</span><span>.</span><span>warn</span><span>(</span><span>"To get the last learning rate computed by the scheduler, "</span>


<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009999457184159408</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009961510274583004</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009869757772816292</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009725204933511963</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009529435502760634</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>009284594366176498</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>0.0</span><span>008993364049014041</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>7.1</span><span>28036241775617</span><span>e</span><span>-</span><span>05</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>4.8</span><span>72936226262451</span><span>e</span><span>-</span><span>05</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>3.1</span><span>17756953567661</span><span>e</span><span>-</span><span>05</span><span>]</span>
<span>lr</span><span>:</span><span>  </span><span>[</span><span>1.8</span><span>816750064937722</span><span>e</span><span>-</span><span>05</span><span>]</span>
<span>validation</span><span> </span><span>loss</span><span>:</span><span>  </span><span>4.1</span><span>79551410675049</span>
</pre></div>

<p><img alt="png" src="https://github.com/bkitano/llama-from-scratch/blob/main/llama_files/llama_76_4.png?raw=true"></p>
<div><pre><span></span><span>show_grads</span><span>(</span><span>llama_with_cosine</span><span>,</span> <span>1e-5</span><span>)</span>
</pre></div>

<div><pre><span></span>[('llama_blocks.llama_0.attention.multihead.in_proj_bias', 100.0),
 ('llama_blocks.llama_0.attention.multihead.out_proj.bias', 100.0),
 ('llama_blocks.llama_1.attention.multihead.in_proj_bias', 100.0),
 ('llama_blocks.llama_1.attention.multihead.out_proj.bias', 100.0),
 ('llama_blocks.llama_2.attention.multihead.in_proj_bias', 100.0),
 ('llama_blocks.llama_2.attention.multihead.out_proj.bias', 100.0),
 ('llama_blocks.llama_3.attention.multihead.in_proj_bias', 100.0),
 ('llama_blocks.llama_3.attention.multihead.out_proj.bias', 100.0),
 ('llama_blocks.llama_1.feedforward.1.linear.bias', 0.78125),
 ('llama_blocks.llama_2.feedforward.1.linear_gate.weight', 0.030517578125),
 ('llama_blocks.llama_3.attention.w_q.weight', 0.030517578125),
 ('llama_blocks.llama_0.attention.multihead.out_proj.weight', 0.0244140625),
 ('llama_blocks.llama_0.feedforward.1.linear_gate.weight', 0.0244140625),
 ('llama_blocks.llama_0.feedforward.1.linear.weight', 0.0244140625),
 ('llama_blocks.llama_1.attention.w_v.weight', 0.0244140625),
 ('llama_blocks.llama_1.feedforward.1.linear.weight', 0.0244140625),
 ('llama_blocks.llama_2.attention.w_q.weight', 0.0244140625),
 ('llama_blocks.llama_3.attention.w_v.weight', 0.0244140625),
 ('llama_blocks.llama_3.attention.multihead.out_proj.weight', 0.0244140625),
 ('ffn.2.weight', 0.02403846153846154),
 ('llama_blocks.llama_0.attention.w_v.weight', 0.018310546875),
 ('llama_blocks.llama_0.feedforward.0.weight', 0.018310546875),
 ('llama_blocks.llama_1.feedforward.0.weight', 0.018310546875),
 ('llama_blocks.llama_3.attention.w_k.weight', 0.018310546875),
 ('llama_blocks.llama_3.feedforward.0.weight', 0.018310546875),
 ('llama_blocks.llama_0.attention.multihead.in_proj_weight',
  0.016276041666666668),
 ('llama_blocks.llama_1.attention.multihead.out_proj.weight', 0.01220703125),
 ('llama_blocks.llama_1.feedforward.1.linear_gate.weight', 0.01220703125),
 ('llama_blocks.llama_3.feedforward.1.linear_gate.weight', 0.01220703125),
 ('llama_blocks.llama_3.feedforward.1.linear.weight', 0.01220703125),
 ('llama_blocks.llama_0.attention.w_q.weight', 0.006103515625),
 ('llama_blocks.llama_0.attention.w_k.weight', 0.006103515625),
 ('llama_blocks.llama_1.attention.w_q.weight', 0.006103515625),
 ('llama_blocks.llama_1.attention.multihead.in_proj_weight', 0.006103515625),
 ('llama_blocks.llama_2.attention.multihead.in_proj_weight', 0.006103515625),
 ('llama_blocks.llama_2.attention.multihead.out_proj.weight', 0.006103515625),
 ('llama_blocks.llama_2.feedforward.1.linear.weight', 0.006103515625),
 ('llama_blocks.llama_3.attention.multihead.in_proj_weight',
  0.004069010416666667),
 ('embeddings.weight', 0.0),
 ('llama_blocks.llama_0.rms.scale', 0.0),
 ('llama_blocks.llama_0.feedforward.0.bias', 0.0),
 ('llama_blocks.llama_0.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_0.feedforward.1.linear_gate.bias', 0.0),
 ('llama_blocks.llama_0.feedforward.1.linear.bias', 0.0),
 ('llama_blocks.llama_1.rms.scale', 0.0),
 ('llama_blocks.llama_1.attention.w_k.weight', 0.0),
 ('llama_blocks.llama_1.feedforward.0.bias', 0.0),
 ('llama_blocks.llama_1.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_1.feedforward.1.linear_gate.bias', 0.0),
 ('llama_blocks.llama_2.rms.scale', 0.0),
 ('llama_blocks.llama_2.attention.w_k.weight', 0.0),
 ('llama_blocks.llama_2.attention.w_v.weight', 0.0),
 ('llama_blocks.llama_2.feedforward.0.weight', 0.0),
 ('llama_blocks.llama_2.feedforward.0.bias', 0.0),
 ('llama_blocks.llama_2.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_2.feedforward.1.linear_gate.bias', 0.0),
 ('llama_blocks.llama_2.feedforward.1.linear.bias', 0.0),
 ('llama_blocks.llama_3.rms.scale', 0.0),
 ('llama_blocks.llama_3.feedforward.0.bias', 0.0),
 ('llama_blocks.llama_3.feedforward.1.beta', 0.0),
 ('llama_blocks.llama_3.feedforward.1.linear_gate.bias', 0.0),
 ('llama_blocks.llama_3.feedforward.1.linear.bias', 0.0),
 ('ffn.0.weight', 0.0),
 ('ffn.0.bias', 0.0),
 ('ffn.1.beta', 0.0),
 ('ffn.1.linear_gate.weight', 0.0),
 ('ffn.1.linear_gate.bias', 0.0),
 ('ffn.1.linear.weight', 0.0),
 ('ffn.1.linear.bias', 0.0),
 ('ffn.2.bias', 0.0)]
</pre></div>

<p>Even at an extremely low tolerance, the attention biases are not getting any signal. I'm not sure why the learning schedule from the paper doesn't work, but the lesson here is simple: start simple.</p>



    

    
    



    



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[G9.js: Automatically Interactive Graphics (416 pts)]]></title>
            <link>http://omrelli.ug/g9/gallery/</link>
            <guid>37058674</guid>
            <pubDate>Wed, 09 Aug 2023 04:24:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://omrelli.ug/g9/gallery/">http://omrelli.ug/g9/gallery/</a>, See on <a href="https://news.ycombinator.com/item?id=37058674">Hacker News</a></p>
<div id="readability-page-1" class="page">

<a href="https://github.com/bijection/g9" id="github"><img src="http://omrelli.ug/g9/github.png" alt="Spoon me on GitHub"></a>


<div class="page">
    

    <p>Welcome to the g9 gallery! <b>Drag all the graphics!</b></p>
    <p>I've tried to organize stuff from basic to advanced, so you can scroll from the top to get an intuitive feel for g9. It's worth mentioning, of course, that intuitive feeling is no match for <a href="https://github.com/bijection/g9#docs">reading the docs</a>.</p>

    <p>Before you dive in, here's a brief explanation of how g9 works (scroll down to skip):</p>


    <h2>How It Works</h2>
    <p>
    g9.js exposes a single function, <a href="https://github.com/bijection/g9#g9initialdata-render-onrender-g9canvas"><span>g9(initialData, render[, onChange])</span></a>. This represents the following flow: 
    </p><ol>
    
    <li>
        You create some initial data as key-value pairs with numeric values. For example:
<pre><code>var initialData = {
    foo: 10
}</code></pre>
    <a href="https://github.com/bijection/g9#initialdata">initialData in the docs</a>
    </li>

    <li>
        This data and a drawing context are fed into a function that uses the data to decide what to draw.
<pre><code>function render(data, ctx){
    ctx.point(data.foo, 17)
}</code></pre>
    <a href="https://github.com/bijection/g9#renderdata-ctx-g9context">render in the docs</a>
    </li>
    
    <li>When someone interacts with the graphics, for example by trying to drag an element to a new position, g9 optimizes over the space of possible values for your data to find a set of values that comes closest to creating the change. If you tried to drag the circle to the left, g9 might come up with the new data <span>{foo: 8 }</span>.</li>
    
    <li>g9 rerenders the entire scene with the new data, so that everything is consistent. If you've provided one, g9 calls your <span>onChange</span> callback with the new data, so you can update other parts of your page.</li>
    
    </ol>
    
    <p>For a complete treatment of the g9 API, <a href="https://github.com/bijection/g9#docs">head to the Docs</a>.</p>



    <!-- <p>In order to avoid repetion, every example gets a special function <span class='literal'>_special_log</span> that shows its arguments in a floating box.</p> -->



</div>











<div class="page">
<h2>Basic</h2>
<p>A minimal example with only two points. Our render function always draws one point at (x, y), and the other point at (y, x), so when you drag one of the points, the other kind of mirrors it. Try adding a minus sign before the first argument of the first point. What happens?</p>
</div>

















<div class="page">
<h2>Rings</h2>
<p>Lets add a few more points and use a bit or trigonometry to arrange them into two circles. Just for fun, we make the inner points red. Try dragging the points!</p>
</div>















<div class="page">
<h2>The affects option</h2>
<p>All of the default shapes in g9 accept an <span>affects</span> option, which tells them what parts of the data they can change. Here are three lines with different values of <span>affects</span>.</p>
</div>











 





<div class="page">
<h2>Bézier Curve</h2>
<p>Here's an interactive version of the quadratic bézier curve animation on <a href="https://en.wikipedia.org/wiki/B%C3%A9zier_curve#Quadratic_curves">the bézier curve wikipedia page</a>.</p>
</div>

 



<p class="page">
<h2>Three points define a circle</h2>
</p>

 




<p class="page">
<h2>cube</h2>
</p>

 





<p class="page">
<h2>dragon</h2>
</p>

 



<p class="page">
<h2>image</h2>
</p>

 






<p class="page">
<h2>tongs</h2>
</p>

 



<p class="page">
<h2>tree</h2>
</p>

 



<p class="page">
<h2>Using Max and Min to limit a point's range of motion.</h2>
</p>

 







<div class="page">
<h2>Kevin Clock</h2>
<p>Try dragging the hands!</p>
</div>

 











<p class="page">
<h2>LOGO Turtle simulator</h2>
</p>

 










<p class="page">
<h2>Grid Warp</h2>
</p>

 








<div class="page">
<h2>Crank and Piston</h2>
<p>Try uncommenting the animation block for extra fun!</p>
</div>

 



















</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swap_8_and_9: A simple import can modify the Python interpreter (117 pts)]]></title>
            <link>https://kenschutte.com/python-swap-ints/</link>
            <guid>37058278</guid>
            <pubDate>Wed, 09 Aug 2023 03:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kenschutte.com/python-swap-ints/">https://kenschutte.com/python-swap-ints/</a>, See on <a href="https://news.ycombinator.com/item?id=37058278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h3 id="writing-a-c-module">1. Writing a C Module</h3><div><p>The <code>swap_8_and_9</code> module is an example of a very simple Python module written using only <code>C</code>. You only need two files: <code>setup.py</code> and the <code>C</code> source, which I’ve put in a subdirectory, <code>src/swap_8_and_9.c</code>.</p></div><div><div><h3 id="setup.py">1.1. setup.py</h3><div><pre><span></span><span>from</span> <span>distutils.core</span> <span>import</span> <span>setup</span><span>,</span> <span>Extension</span>

<span>name</span> <span>=</span> <span>'swap_8_and_9'</span>
<span>setup</span><span>(</span><span>name</span> <span>=</span> <span>name</span><span>,</span>
      <span>version</span> <span>=</span> <span>'0.1.0'</span><span>,</span>
      <span>description</span> <span>=</span> <span>'Proof of concept that swaps ints 8 and 9 on import'</span><span>,</span>
      <span>ext_modules</span> <span>=</span> <span>[</span>
          <span>Extension</span><span>(</span><span>name</span><span>,</span> <span>sources</span> <span>=</span> <span>[</span><span>'src/'</span> <span>+</span> <span>name</span> <span>+</span> <span>'.c'</span><span>]),</span>
      <span>])</span>
</pre></div></div><div><h3 id="c-source-file">1.2. C source file</h3><div><div><p>Our main code file, <code>swap_8_and_9.c</code>, is pretty simple because this module has no functions, no classes, no constants, etc. We only need to write the definition of the module and write the function that will be called when it is imported.</p><p>The file needs three things (<code>{name}</code> is our module name),</p><ol><li><p>List of methods (used in module defintion): <code>static PyMethodDef {name}_methods[] = {...};</code> (this is an empty list in our case).</p></li><li><p>Module definition : <code>static struct PyModuleDef {name}_definition = {...};</code></p></li><li><p>Init function: <code>PyMODINIT_FUNC PyInit_{name}(void) {...}</code></p></li></ol></div><div><pre><span></span><span>#include</span><span> </span><span>&lt;Python.h&gt;</span>

<span>/*</span>
<span>  methods in Module</span>
<span> */</span>
<span>static</span><span> </span><span>PyMethodDef</span><span> </span><span>swap_8_and_9_methods</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span>
<span>  </span><span>//marks end:</span>
<span>  </span><span>{</span><span>NULL</span><span>,</span><span> </span><span>NULL</span><span>,</span><span> </span><span>0</span><span>,</span><span> </span><span>NULL</span><span>}</span>
<span>};</span>


<span>/*</span>
<span>  define Module</span>
<span>*/</span><span> </span>
<span>static</span><span> </span><span>struct</span><span> </span><span>PyModuleDef</span><span> </span><span>swap_8_and_9_definition</span><span> </span><span>=</span><span> </span><span>{</span><span> </span>
<span>    </span><span>PyModuleDef_HEAD_INIT</span><span>,</span>
<span>    </span><span>"swap_8_and_9"</span><span>,</span><span> </span><span>/* module name */</span>

<span>    </span><span>/* __doc__ string: */</span>
<span>    </span><span>"C Module that..."</span><span>,</span>

<span>    </span><span>/* size of per-interpreter state of the module,</span>
<span>       or -1 if the module keeps state in global variables. */</span>
<span>    </span><span>-1</span><span>,</span>

<span>    </span><span>swap_8_and_9_methods</span>
<span>};</span>


<span>/*</span>
<span>  initialize Module</span>
<span>  - called on import</span>
<span>  - PyInit_{name} (same name from setup.py name)</span>
<span>*/</span><span> </span>
<span>PyMODINIT_FUNC</span><span> </span><span>PyInit_swap_8_and_9</span><span>(</span><span>void</span><span>)</span><span> </span><span>{</span>
<span>    </span><span>Py_Initialize</span><span>();</span>

<span>    </span><span>//CODE HERE</span>
<span>        </span>
<span>    </span><span>return</span><span> </span><span>PyModule_Create</span><span>(</span><span>&amp;</span><span>swap_8_and_9_definition</span><span>);</span>
<span>}</span>
<span>        </span>
</pre></div><p>We will write somethig in the <code>//CODE HERE</code> part after we learn a little bit about some <code>CPython</code> internals.</p></div></div><div><h3 id="install-/-build">1.3. Install / Build</h3><div><div><p>With these two files you should be able to <code>pip install .</code> to install from the current directory.</p><p>Another useful command you can run is <code>python setup.py build</code>. This will show the compilation commands being run. (Note that if it is already built and the files haven’t changed, it won’t do anything).</p><p>On my macbook, the re-formatted output looks like this: (replaced lots of args with <code>...</code>, mainly <code>-I PATH</code>, <code>-L PATH</code>, and some other flags),</p></div><div><pre><span></span><span># 1. compile</span>
clang<span> </span>...<span> </span><span>\</span>
<span>    </span>-c<span> </span>src/swap_8_and_9.c<span> </span><span>\</span>
<span>    </span>-o<span> </span>build/temp.macosx-12.6-arm64-cpython-311/src/swap_8_and_9.o
<span>    </span>
<span># 2. link</span>
clang<span> </span>...<span> </span><span>\</span>
<span>    </span>build/temp.macosx-12.6-arm64-cpython-311/src/swap_8_and_9.o<span> </span><span>\</span>
<span>    </span>-o<span> </span>build/lib.macosx-12.6-arm64-cpython-311/swap_8_and_9.cpython-311-darwin.so
<span>             </span>
</pre></div></div></div></div></div><div><h3 id="some-cpython-internals">2. Some CPython internals</h3><div><p><code>CPython</code> refers to the standard Python implementation. It is written in <code>C</code> and can be <a href="https://github.com/python/cpython">browsed on github</a>.</p><p>On this page, I am using <code>CPython</code> version <a href="https://github.com/python/cpython/releases/tag/v3.11.4"><code>3.11.4</code></a> and the code descriptions below will link to the github source code for this version.</p><p>For the <code>CPython</code> code that I’ll describe, I have noticed significant reorganization of the code between versions <code>3.8.6</code> to <code>3.11.4</code>. However, the concepts remain the same.</p></div><div><div><h3 id="cached-integers">2.1. Cached integers</h3><div><div><p>In <code>CPython</code>, everything (integers, strings, dictionaries, functions, etc) is an <span>"object"</span>, and represented by a <code>C struct</code> named <a href="https://docs.python.org/3/c-api/structures.html#c.PyObject"><code>PyObject</code></a>.
Common to all objects is the storage its type (and the data needed for that type) and a <a href="https://devguide.python.org/internals/garbage-collector/">reference count used for garbage collection</a>.</p><p>We are interested in integers — type <code>int</code> within <code>Python</code> and <a href="https://docs.python.org/3/c-api/long.html#c.PyLongObject"><code>PyLongObject</code></a> within <code>CPython</code>.</p><p>Because there is some overhead in creating and destroying objects, <code>CPython</code> maintains a cache for the set of small integers (values -5, …, 256), since these are commonly used.</p><p><i>(At this point, you can probably guess that our module will modify these cached objects</i>).</p><p><a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/internal/pycore_global_objects.h#L16"><code>pycore_global_objects.h</code></a> defines the range of integers that will be cached,</p></div><div><pre><span></span><span>#define _PY_NSMALLPOSINTS           257</span>
<span>#define _PY_NSMALLNEGINTS           5</span>
</pre></div><p>In the same file, <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/internal/pycore_global_objects.h#L35">a few lines later</a>, we see the array that will hold the cached integers. It is an array of type <code>PyLongObject</code> and named <code>small_ints</code> and is within a struct called <code>_Py_global_objects</code>:</p><div><pre><span></span><span>struct</span><span> </span><span>_Py_global_objects</span><span> </span><span>{</span>
<span>    </span><span>struct</span><span> </span><span>{</span>
<span>        </span><span>/* Small integers are preallocated in this array so that they</span>
<span>         * can be shared.</span>
<span>         * The integers that are preallocated are those in the range</span>
<span>         * -_PY_NSMALLNEGINTS (inclusive) to _PY_NSMALLPOSINTS (exclusive).</span>
<span>         */</span><span>    </span>
<span>        </span><span>PyLongObject</span><span> </span><span>small_ints</span><span>[</span><span>_PY_NSMALLNEGINTS</span><span> </span><span>+</span><span> </span><span>_PY_NSMALLPOSINTS</span><span>];</span>
<span>        </span><span>...</span>
<span>    </span><span>}</span><span> </span><span>singletons</span><span>;</span>
<span>};</span>
</pre></div><p>When and where is this array initialized? In <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/internal/pycore_runtime_init.h#L126"><code>pycore_runtime_init.h</code></a>, we see a macro (itself generated by a <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Tools/scripts/generate_global_objects.py#L224">Python script</a>) that initializes the elements in the <code>small_ints[]</code> array,</p><div><pre><span></span><span>        </span><span>.</span><span>small_ints</span><span> </span><span>=</span><span> </span><span>{</span><span> </span>\
<span>            </span><span>_PyLong_DIGIT_INIT</span><span>(</span><span>-5</span><span>),</span><span> </span>\
<span>            </span><span>_PyLong_DIGIT_INIT</span><span>(</span><span>-4</span><span>),</span><span> </span>\
<span>            </span><span>_PyLong_DIGIT_INIT</span><span>(</span><span>-3</span><span>),</span><span> </span>\
<span>            </span><span>...</span>
<span>            </span><span>_PyLong_DIGIT_INIT</span><span>(</span><span>255</span><span>),</span><span> </span>\
<span>            </span><span>_PyLong_DIGIT_INIT</span><span>(</span><span>256</span><span>),</span><span> </span>\
<span>        </span><span>},</span><span> </span>\
</pre></div><p>It is slightly convoluted to see how this
macro (<code>_Py_global_objects_INIT</code>) gets used,
but <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Python/pystate.c#L55">pystate.c</a>
stores it as <code>static const _PyRuntimeState initial = _PyRuntimeState_INIT;</code>
and this <code>initial</code> variable is used when when the interpreter is initialized.</p></div></div><div><h3 id="module-code">2.2. Module code</h3><div><div><p>Back to the code for our module — we want to modify a couple of the elements of <code>small_ints[]</code>, but we do not have direct access to it.
We can use the API declared in <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/longobject.h#L16">longobject.h</a> — namely, the following function that gives the <code>PyObject</code> for a given <code>long</code> (plain <code>C</code>) value: <code>PyAPI_FUNC(PyObject *) PyLong_FromLong(long)</code>.</p><p>Its definition is in <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Objects/longobject.c#L287"><code>longobject.c</code></a>. We can see that it checks for small integers (<code>IS_SMALL_INT(ival)</code>) and then calls <code>get_small_int((sdigit)ival)</code>, which returns <code>_PyLong_SMALL_INTS[_PY_NSMALLNEGINTS + ival]</code>.</p><p>Finally, in <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/internal/pycore_long.h#L58"><code>pycore_long.h</code></a>, you can see that this refers to the <code>small_ints[]</code> array: <code>#define _PyLong_SMALL_INTS _Py_SINGLETON(small_ints)</code>.</p><p>Now, we have the first part of our code. It will get the references to the two integers we care about:</p></div><div><pre><span></span><span>PyLongObject</span><span>*</span><span> </span><span>obj8</span><span> </span><span>=</span><span> </span><span>(</span><span>PyLongObject</span><span>*</span><span>)</span><span>PyLong_FromLong</span><span>(</span><span>8</span><span>);</span>
<span>PyLongObject</span><span>*</span><span> </span><span>obj9</span><span> </span><span>=</span><span> </span><span>(</span><span>PyLongObject</span><span>*</span><span>)</span><span>PyLong_FromLong</span><span>(</span><span>9</span><span>);</span>
</pre></div><div><p>How do we change the value?</p><p><code>Python</code> <code>int</code> (and <code>CPython</code> <code>PyLongObject</code>) represent arbitrarily large integers (positive or negative). <a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/cpython/longintrepr.h#L64">longintrepr.h</a> defines how integers are stored. I’ll include the whole comment below because it is so informative, followed by the <code>struct</code> definition,</p></div><div><pre><span></span><span>/* Long integer representation.</span>
<span>   The absolute value of a number is equal to</span>
<span>        SUM(for i=0 through abs(ob_size)-1) ob_digit[i] * 2**(SHIFT*i)</span>
<span>   Negative numbers are represented with ob_size &lt; 0;</span>
<span>   zero is represented by ob_size == 0.</span>
<span>   In a normalized number, ob_digit[abs(ob_size)-1] (the most significant</span>
<span>   digit) is never zero.  Also, in all cases, for all valid i,</span>
<span>        0 &lt;= ob_digit[i] &lt;= MASK.</span>
<span>   The allocation function takes care of allocating extra memory</span>
<span>   so that ob_digit[0] ... ob_digit[abs(ob_size)-1] are actually available.</span>
<span>   We always allocate memory for at least one digit, so accessing ob_digit[0]</span>
<span>   is always safe. However, in the case ob_size == 0, the contents of</span>
<span>   ob_digit[0] may be undefined.</span>

<span>   CAUTION:  Generic code manipulating subtypes of PyVarObject has to</span>
<span>   aware that ints abuse  ob_size's sign bit.</span>
<span>*/</span>

<span>struct</span><span> </span><span>_longobject</span><span> </span><span>{</span>
<span>    </span><span>PyObject_VAR_HEAD</span>
<span>    </span><span>digit</span><span> </span><span>ob_digit</span><span>[</span><span>1</span><span>];</span>
<span>};</span><span>             </span>
<span>             </span>
</pre></div><div><p>A couple other <code>typedef</code>s relate a few of the types shown above,</p><ul><li><p><a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/pytypedefs.h#L19">pytypedefs.h</a>: <code>typedef struct _longobject PyLongObject;</code>.</p></li><li><p><a href="https://github.com/python/cpython/blob/d2340ef25721b6a72d45d4508c672c4be38c67d3/Include/cpython/longintrepr.h#L43">longintrepr.h</a>: <code>typedef uint32_t digit;</code></p></li></ul><p>So, for the smallest integers, the <span>"raw value"</span> is simply <code>.ob_digit[0]</code>.</p><p>Now, we have all the code we need: get a reference to cached integer object and change its value. These four lines can go in the <code>//CODE HERE</code> part above:</p></div><div><pre><span></span><span>PyLongObject</span><span>*</span><span> </span><span>obj8</span><span> </span><span>=</span><span> </span><span>(</span><span>PyLongObject</span><span>*</span><span>)</span><span>PyLong_FromLong</span><span>(</span><span>8</span><span>);</span>
<span>PyLongObject</span><span>*</span><span> </span><span>obj9</span><span> </span><span>=</span><span> </span><span>(</span><span>PyLongObject</span><span>*</span><span>)</span><span>PyLong_FromLong</span><span>(</span><span>9</span><span>);</span>

<span>obj8</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>9</span><span>;</span>
<span>obj9</span><span>-&gt;</span><span>ob_digit</span><span>[</span><span>0</span><span>]</span><span> </span><span>=</span><span> </span><span>8</span><span>;</span>
</pre></div></div></div></div></div><div><h3 id="notes">3. Notes</h3><div><div><p>If you import this module and continue working, it will likely eventually lead to a complete crash of the interpreter (i.e.&nbsp;suddenly exit and print something like <code>Segmentation fault (core dumped)</code> — as opposed to simply raising a <code>Python</code> <code>Exception</code>).</p><p>I found this out in a few ways,</p><ul><li><p>My original test was to redefine all small integers by shifting each of them, <code>n =&gt; n+1</code>. I found this crashed almost immediately.</p></li><li><p>I tried swapping lower integers (3 and 4) and this seemed to lead to crashes (in subsequent <code>print</code> calls) in <code>Python</code> <code>3.8</code> but not in <code>Python</code> <code>3.11</code>.</p></li></ul><p>In conclusion, there is no real reason for this module, but it serves as a
good learning exercise and a reminder to always only install and import trusted
modules.</p></div><hr><p><a href="https://github.com/kts/swap_8_and_9">https://github.com/kts/swap_8_and_9</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pure Bash Bible (2018) (128 pts)]]></title>
            <link>https://github.com/dylanaraps/pure-bash-bible</link>
            <guid>37057866</guid>
            <pubDate>Wed, 09 Aug 2023 01:55:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dylanaraps/pure-bash-bible">https://github.com/dylanaraps/pure-bash-bible</a>, See on <a href="https://news.ycombinator.com/item?id=37057866">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto"><b>NEW: <a href="https://github.com/dylanaraps/pure-sh-bible">pure sh bible (<g-emoji alias="book" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4d6.png">📖</g-emoji> A collection of pure POSIX sh alternatives to external processes).</a></b></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/odb/official-bash-logo/master/assets/Logos/Icons/PNG/512x512.png"><img src="https://raw.githubusercontent.com/odb/official-bash-logo/master/assets/Logos/Icons/PNG/512x512.png" width="200px"></a></p>
<h2 tabindex="-1" dir="auto">pure bash bible</h2> <p dir="auto">A collection of pure bash alternatives to external
processes.</p>
<p dir="auto"> <a href="https://travis-ci.com/dylanaraps/pure-bash-bible" rel="nofollow"><img src="https://camo.githubusercontent.com/1507e01a4895b1a95e9211c796d28aba53a3fc2f9740ed8941f7114d71652191/68747470733a2f2f7472617669732d63692e636f6d2f64796c616e61726170732f707572652d626173682d6269626c652e7376673f6272616e63683d6d6173746572" data-canonical-src="https://travis-ci.com/dylanaraps/pure-bash-bible.svg?branch=master"></a>
<a href="https://github.com/dylanaraps/pure-bash-bible/blob/master/LICENSE.md"><img src="https://camo.githubusercontent.com/83d3746e5881c1867665223424263d8e604df233d0a11aae0813e0414d433943/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c75652e737667" data-canonical-src="https://img.shields.io/badge/license-MIT-blue.svg"></a>
</p>
<br>
<a href="https://leanpub.com/bash/" rel="nofollow">
<img src="https://camo.githubusercontent.com/06d01fc32b3e236bbb802617b350976c3d6c1651117af82956af308a573d72e1/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f7469746c6570616765732e6c65616e7075622e636f6d2f626173682f6865726f" width="40%" data-canonical-src="https://s3.amazonaws.com/titlepages.leanpub.com/bash/hero">
</a>
<p dir="auto">The goal of this book is to document commonly-known and lesser-known methods of doing various tasks using only built-in <code>bash</code> features. Using the snippets from this bible can help remove unneeded dependencies from scripts and in most cases make them faster. I came across these tips and discovered a few while developing <a href="https://github.com/dylanaraps/neofetch">neofetch</a>, <a href="https://github.com/dylanaraps/pxltrm">pxltrm</a> and other smaller projects.</p>
<p dir="auto">The snippets below are linted using <code>shellcheck</code> and tests have been written where applicable. Want to contribute? Read the <a href="https://github.com/dylanaraps/pure-bash-bible/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a>. It outlines how the unit tests work and what is required when adding snippets to the bible.</p>
<p dir="auto">See something incorrectly described, buggy or outright wrong? Open an issue or send a pull request. If the bible is missing something, open an issue and a solution will be found.</p>

<p dir="auto"><b>This book is also available to purchase on leanpub. <a href="https://leanpub.com/bash" rel="nofollow">https://leanpub.com/bash</a></b></p>
<p dir="auto"><b>Or you can buy me a coffee.</b>
<a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=V7QNJNKS3WYVS" rel="nofollow"><img src="https://camo.githubusercontent.com/e03c0f5e6aa5ae0179139a085dd234c3cedbacca6b392362220cdbf22b893b3e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f6e2d70617970616c2d79656c6c6f772e737667" data-canonical-src="https://img.shields.io/badge/don-paypal-yellow.svg"></a> <a href="https://www.patreon.com/dyla" rel="nofollow"><img src="https://camo.githubusercontent.com/700e6e95769fec133239dd03c17beddba17762c7e96bd9a0cd3429fd1df36794/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f6e2d70617472656f6e2d79656c6c6f772e737667" data-canonical-src="https://img.shields.io/badge/don-patreon-yellow.svg"> </a><a href="https://liberapay.com/2211/" rel="nofollow"><img src="https://camo.githubusercontent.com/db8fde62d30e38858d713ca1aac97a6d70d8df06d36cd19a0f7802100e6f0b8e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f6e2d6c69626572617061792d79656c6c6f772e737667" data-canonical-src="https://img.shields.io/badge/don-liberapay-yellow.svg"></a>
</p>
<br>
<h2 tabindex="-1" dir="auto">Table of Contents</h2>

<ul dir="auto">
<li><a href="#foreword">FOREWORD</a></li>
<li><a href="#strings">STRINGS</a>
<ul dir="auto">
<li><a href="#trim-leading-and-trailing-white-space-from-string">Trim leading and trailing white-space from string</a></li>
<li><a href="#trim-all-white-space-from-string-and-truncate-spaces">Trim all white-space from string and truncate spaces</a></li>
<li><a href="#use-regex-on-a-string">Use regex on a string</a></li>
<li><a href="#split-a-string-on-a-delimiter">Split a string on a delimiter</a></li>
<li><a href="#change-a-string-to-lowercase">Change a string to lowercase</a></li>
<li><a href="#change-a-string-to-uppercase">Change a string to uppercase</a></li>
<li><a href="#reverse-a-string-case">Reverse a string case</a></li>
<li><a href="#trim-quotes-from-a-string">Trim quotes from a string</a></li>
<li><a href="#strip-all-instances-of-pattern-from-string">Strip all instances of pattern from string</a></li>
<li><a href="#strip-first-occurrence-of-pattern-from-string">Strip first occurrence of pattern from string</a></li>
<li><a href="#strip-pattern-from-start-of-string">Strip pattern from start of string</a></li>
<li><a href="#strip-pattern-from-end-of-string">Strip pattern from end of string</a></li>
<li><a href="#percent-encode-a-string">Percent-encode a string</a></li>
<li><a href="#decode-a-percent-encoded-string">Decode a percent-encoded string</a></li>
<li><a href="#check-if-string-contains-a-sub-string">Check if string contains a sub-string</a></li>
<li><a href="#check-if-string-starts-with-sub-string">Check if string starts with sub-string</a></li>
<li><a href="#check-if-string-ends-with-sub-string">Check if string ends with sub-string</a></li>
</ul>
</li>
<li><a href="#arrays">ARRAYS</a>
<ul dir="auto">
<li><a href="#reverse-an-array">Reverse an array</a></li>
<li><a href="#remove-duplicate-array-elements">Remove duplicate array elements</a></li>
<li><a href="#random-array-element">Random array element</a></li>
<li><a href="#cycle-through-an-array">Cycle through an array</a></li>
<li><a href="#toggle-between-two-values">Toggle between two values</a></li>
</ul>
</li>
<li><a href="#loops">LOOPS</a>
<ul dir="auto">
<li><a href="#loop-over-a-range-of-numbers">Loop over a range of numbers</a></li>
<li><a href="#loop-over-a-variable-range-of-numbers">Loop over a variable range of numbers</a></li>
<li><a href="#loop-over-an-array">Loop over an array</a></li>
<li><a href="#loop-over-an-array-with-an-index">Loop over an array with an index</a></li>
<li><a href="#loop-over-the-contents-of-a-file">Loop over the contents of a file</a></li>
<li><a href="#loop-over-files-and-directories">Loop over files and directories</a></li>
</ul>
</li>
<li><a href="#file-handling">FILE HANDLING</a>
<ul dir="auto">
<li><a href="#read-a-file-to-a-string">Read a file to a string</a></li>
<li><a href="#read-a-file-to-an-array-by-line">Read a file to an array (<em>by line</em>)</a></li>
<li><a href="#get-the-first-n-lines-of-a-file">Get the first N lines of a file</a></li>
<li><a href="#get-the-last-n-lines-of-a-file">Get the last N lines of a file</a></li>
<li><a href="#get-the-number-of-lines-in-a-file">Get the number of lines in a file</a></li>
<li><a href="#count-files-or-directories-in-directory">Count files or directories in directory</a></li>
<li><a href="#create-an-empty-file">Create an empty file</a></li>
<li><a href="#extract-lines-between-two-markers">Extract lines between two markers</a></li>
</ul>
</li>
<li><a href="#file-paths">FILE PATHS</a>
<ul dir="auto">
<li><a href="#get-the-directory-name-of-a-file-path">Get the directory name of a file path</a></li>
<li><a href="#get-the-base-name-of-a-file-path">Get the base-name of a file path</a></li>
</ul>
</li>
<li><a href="#variables">VARIABLES</a>
<ul dir="auto">
<li><a href="#assign-and-access-a-variable-using-a-variable">Assign and access a variable using a variable</a></li>
<li><a href="#name-a-variable-based-on-another-variable">Name a variable based on another variable</a></li>
</ul>
</li>
<li><a href="#escape-sequences">ESCAPE SEQUENCES</a>
<ul dir="auto">
<li><a href="#text-colors">Text Colors</a></li>
<li><a href="#text-attributes">Text Attributes</a></li>
<li><a href="#cursor-movement">Cursor Movement</a></li>
<li><a href="#erasing-text">Erasing Text</a></li>
</ul>
</li>
<li><a href="#parameter-expansion">PARAMETER EXPANSION</a>
<ul dir="auto">
<li><a href="#indirection">Indirection</a></li>
<li><a href="#replacement">Replacement</a></li>
<li><a href="#length">Length</a></li>
<li><a href="#expansion">Expansion</a></li>
<li><a href="#case-modification">Case Modification</a></li>
<li><a href="#default-value">Default Value</a></li>
</ul>
</li>
<li><a href="#brace-expansion">BRACE EXPANSION</a>
<ul dir="auto">
<li><a href="#ranges">Ranges</a></li>
<li><a href="#string-lists">String Lists</a></li>
</ul>
</li>
<li><a href="#conditional-expressions">CONDITIONAL EXPRESSIONS</a>
<ul dir="auto">
<li><a href="#file-conditionals">File Conditionals</a></li>
<li><a href="#file-comparisons">File Comparisons</a></li>
<li><a href="#variable-conditionals">Variable Conditionals</a></li>
<li><a href="#variable-comparisons">Variable Comparisons</a></li>
</ul>
</li>
<li><a href="#arithmetic-operators">ARITHMETIC OPERATORS</a>
<ul dir="auto">
<li><a href="#assignment">Assignment</a></li>
<li><a href="#arithmetic">Arithmetic</a></li>
<li><a href="#bitwise">Bitwise</a></li>
<li><a href="#logical">Logical</a></li>
<li><a href="#miscellaneous">Miscellaneous</a></li>
</ul>
</li>
<li><a href="#arithmetic-1">ARITHMETIC</a>
<ul dir="auto">
<li><a href="#simpler-syntax-to-set-variables">Simpler syntax to set variables</a></li>
<li><a href="#ternary-tests">Ternary Tests</a></li>
</ul>
</li>
<li><a href="#traps">TRAPS</a>
<ul dir="auto">
<li><a href="#do-something-on-script-exit">Do something on script exit</a></li>
<li><a href="#ignore-terminal-interrupt-ctrlc-sigint">Ignore terminal interrupt (CTRL+C, SIGINT)</a></li>
<li><a href="#react-to-window-resize">React to window resize</a></li>
<li><a href="#do-something-before-every-command">Do something before every command</a></li>
<li><a href="#do-something-when-a-shell-function-or-a-sourced-file-finishes-executing">Do something when a shell function or a sourced file finishes executing</a></li>
</ul>
</li>
<li><a href="#performance">PERFORMANCE</a>
<ul dir="auto">
<li><a href="#disable-unicode">Disable Unicode</a></li>
</ul>
</li>
<li><a href="#obsolete-syntax">OBSOLETE SYNTAX</a>
<ul dir="auto">
<li><a href="#shebang">Shebang</a></li>
<li><a href="#command-substitution">Command Substitution</a></li>
<li><a href="#function-declaration">Function Declaration</a></li>
</ul>
</li>
<li><a href="#internal-variables">INTERNAL VARIABLES</a>
<ul dir="auto">
<li><a href="#get-the-location-to-the-bash-binary">Get the location to the <code>bash</code> binary</a></li>
<li><a href="#get-the-version-of-the-current-running-bash-process">Get the version of the current running <code>bash</code> process</a></li>
<li><a href="#open-the-users-preferred-text-editor">Open the user's preferred text editor</a></li>
<li><a href="#get-the-name-of-the-current-function">Get the name of the current function</a></li>
<li><a href="#get-the-host-name-of-the-system">Get the host-name of the system</a></li>
<li><a href="#get-the-architecture-of-the-operating-system">Get the architecture of the Operating System</a></li>
<li><a href="#get-the-name-of-the-operating-system--kernel">Get the name of the Operating System / Kernel</a></li>
<li><a href="#get-the-current-working-directory">Get the current working directory</a></li>
<li><a href="#get-the-number-of-seconds-the-script-has-been-running">Get the number of seconds the script has been running</a></li>
<li><a href="#get-a-pseudorandom-integer">Get a pseudorandom integer</a></li>
</ul>
</li>
<li><a href="#information-about-the-terminal">INFORMATION ABOUT THE TERMINAL</a>
<ul dir="auto">
<li><a href="#get-the-terminal-size-in-lines-and-columns-from-a-script">Get the terminal size in lines and columns (<em>from a script</em>)</a></li>
<li><a href="#get-the-terminal-size-in-pixels">Get the terminal size in pixels</a></li>
<li><a href="#get-the-current-cursor-position">Get the current cursor position</a></li>
</ul>
</li>
<li><a href="#conversion">CONVERSION</a>
<ul dir="auto">
<li><a href="#convert-a-hex-color-to-rgb">Convert a hex color to RGB</a></li>
<li><a href="#convert-an-rgb-color-to-hex">Convert an RGB color to hex</a></li>
</ul>
</li>
<li><a href="#code-golf">CODE GOLF</a>
<ul dir="auto">
<li><a href="#shorter-for-loop-syntax">Shorter <code>for</code> loop syntax</a></li>
<li><a href="#shorter-infinite-loops">Shorter infinite loops</a></li>
<li><a href="#shorter-function-declaration">Shorter function declaration</a></li>
<li><a href="#shorter-if-syntax">Shorter <code>if</code> syntax</a></li>
<li><a href="#simpler-case-statement-to-set-variable">Simpler <code>case</code> statement to set variable</a></li>
</ul>
</li>
<li><a href="#other">OTHER</a>
<ul dir="auto">
<li><a href="#use-read-as-an-alternative-to-the-sleep-command">Use <code>read</code> as an alternative to the <code>sleep</code> command</a></li>
<li><a href="#check-if-a-program-is-in-the-users-path">Check if a program is in the user's PATH</a></li>
<li><a href="#get-the-current-date-using-strftime">Get the current date using <code>strftime</code></a></li>
<li><a href="#get-the-username-of-the-current-user">Get the username of the current user</a></li>
<li><a href="#generate-a-uuid-v4">Generate a UUID V4</a></li>
<li><a href="#progress-bars">Progress bars</a></li>
<li><a href="#get-the-list-of-functions-in-a-script">Get the list of functions in a script</a></li>
<li><a href="#bypass-shell-aliases">Bypass shell aliases</a></li>
<li><a href="#bypass-shell-functions">Bypass shell functions</a></li>
<li><a href="#run-a-command-in-the-background">Run a command in the background</a></li>
<li><a href="#capture-the-return-value-of-a-function-without-command-substitution">Capture function return without command substitution</a></li>
</ul>
</li>
<li><a href="#afterword">AFTERWORD</a></li>
</ul>

<br>

<h2 tabindex="-1" dir="auto">FOREWORD</h2>
<p dir="auto">A collection of pure <code>bash</code> alternatives to external processes and programs. The <code>bash</code> scripting language is more powerful than people realise and most tasks can be accomplished without depending on external programs.</p>
<p dir="auto">Calling an external process in <code>bash</code> is expensive and excessive use will cause a noticeable slowdown. Scripts and programs written using built-in methods (<em>where applicable</em>) will be faster, require fewer dependencies and afford a better understanding of the language itself.</p>
<p dir="auto">The contents of this book provide a reference for solving problems encountered when writing programs and scripts in <code>bash</code>. Examples are in function formats showcasing how to incorporate these solutions into code.</p>


<h2 tabindex="-1" dir="auto">STRINGS</h2>
<h2 tabindex="-1" dir="auto">Trim leading and trailing white-space from string</h2>
<p dir="auto">This is an alternative to <code>sed</code>, <code>awk</code>, <code>perl</code> and other tools. The
function below works by finding all leading and trailing white-space and
removing it from the start and end of the string. The <code>:</code> built-in is used in place of a temporary variable.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="trim_string() {
    # Usage: trim_string &quot;   example   string    &quot;
    : &quot;${1#&quot;${1%%[![:space:]]*}&quot;}&quot;
    : &quot;${_%&quot;${_##*[![:space:]]}&quot;}&quot;
    printf '%s\n' &quot;$_&quot;
}"><pre><span>trim_string</span>() {
    <span><span>#</span> Usage: trim_string "   example   string    "</span>
    <span>:</span> <span><span>"</span><span>${1<span>#</span><span><span>"</span><span>${1<span>%%</span>[![:space:]]<span>*</span>}</span><span>"</span></span>}</span><span>"</span></span>
    <span>:</span> <span><span>"</span><span>${_<span>%</span><span><span>"</span><span>${_<span>##*</span>[![:space:]]}</span><span>"</span></span>}</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$_</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ trim_string &quot;    Hello,  World    &quot;
Hello,  World

$ name=&quot;   John Black  &quot;
$ trim_string &quot;$name&quot;
John Black"><pre>$ trim_string <span><span>"</span>    Hello,  World    <span>"</span></span>
Hello,  World

$ name=<span><span>"</span>   John Black  <span>"</span></span>
$ trim_string <span><span>"</span><span>$name</span><span>"</span></span>
John Black</pre></div>
<h2 tabindex="-1" dir="auto">Trim all white-space from string and truncate spaces</h2>
<p dir="auto">This is an alternative to <code>sed</code>, <code>awk</code>, <code>perl</code> and other tools. The
function below works by abusing word splitting to create a new string
without leading/trailing white-space and with truncated spaces.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# shellcheck disable=SC2086,SC2048
trim_all() {
    # Usage: trim_all &quot;   example   string    &quot;
    set -f
    set -- $*
    printf '%s\n' &quot;$*&quot;
    set +f
}"><pre><span><span>#</span> shellcheck disable=SC2086,SC2048</span>
<span>trim_all</span>() {
    <span><span>#</span> Usage: trim_all "   example   string    "</span>
    <span>set</span> -f
    <span>set</span> -- <span>$*</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$*</span><span>"</span></span>
    <span>set</span> +f
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ trim_all &quot;    Hello,    World    &quot;
Hello, World

$ name=&quot;   John   Black  is     my    name.    &quot;
$ trim_all &quot;$name&quot;
John Black is my name."><pre>$ trim_all <span><span>"</span>    Hello,    World    <span>"</span></span>
Hello, World

$ name=<span><span>"</span>   John   Black  is     my    name.    <span>"</span></span>
$ trim_all <span><span>"</span><span>$name</span><span>"</span></span>
John Black is my name.</pre></div>
<h2 tabindex="-1" dir="auto">Use regex on a string</h2>
<p dir="auto">The result of <code>bash</code>'s regex matching can be used to replace <code>sed</code> for a
large number of use-cases.</p>
<p dir="auto"><strong>CAVEAT</strong>: This is one of the few platform dependent <code>bash</code> features.
<code>bash</code> will use whatever regex engine is installed on the user's system.
Stick to POSIX regex features if aiming for compatibility.</p>
<p dir="auto"><strong>CAVEAT</strong>: This example only prints the first matching group. When using
multiple capture groups some modification is needed.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="regex() {
    # Usage: regex &quot;string&quot; &quot;regex&quot;
    [[ $1 =~ $2 ]] &amp;&amp; printf '%s\n' &quot;${BASH_REMATCH[1]}&quot;
}"><pre><span>regex</span>() {
    <span><span>#</span> Usage: regex "string" "regex"</span>
    [[ <span>$1</span> <span>=~</span> <span>$2</span> ]] <span>&amp;&amp;</span> <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${BASH_REMATCH[1]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ # Trim leading white-space.
$ regex '    hello' '^\s*(.*)'
hello

$ # Validate a hex color.
$ regex &quot;#FFFFFF&quot; '^(#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$'
#FFFFFF

$ # Validate a hex color (invalid).
$ regex &quot;red&quot; '^(#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$'
# no output (invalid)"><pre>$ <span><span>#</span> Trim leading white-space.</span>
$ regex <span><span>'</span>    hello<span>'</span></span> <span><span>'</span>^\s*(.*)<span>'</span></span>
hello

$ <span><span>#</span> Validate a hex color.</span>
$ regex <span><span>"</span>#FFFFFF<span>"</span></span> <span><span>'</span>^(#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$<span>'</span></span>
<span><span>#</span>FFFFFF</span>

$ <span><span>#</span> Validate a hex color (invalid).</span>
$ regex <span><span>"</span>red<span>"</span></span> <span><span>'</span>^(#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$<span>'</span></span>
<span><span>#</span> no output (invalid)</span></pre></div>
<p dir="auto"><strong>Example Usage in script:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="is_hex_color() {
    if [[ $1 =~ ^(#?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$ ]]; then
        printf '%s\n' &quot;${BASH_REMATCH[1]}&quot;
    else
        printf '%s\n' &quot;error: $1 is an invalid color.&quot;
        return 1
    fi
}

read -r color
is_hex_color &quot;$color&quot; || color=&quot;#FFFFFF&quot;

# Do stuff."><pre><span>is_hex_color</span>() {
    <span>if</span> [[ <span>$1</span> <span>=~</span> ^(<span><span>#</span>?([a-fA-F0-9]{6}|[a-fA-F0-9]{3}))$ ]]; then</span>
        <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${BASH_REMATCH[1]}</span><span>"</span></span>
    <span>else</span>
        <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>error: <span>$1</span> is an invalid color.<span>"</span></span>
        <span>return</span> 1
    <span>fi</span>
}

<span>read</span> -r color
is_hex_color <span><span>"</span><span>$color</span><span>"</span></span> <span>||</span> color=<span><span>"</span>#FFFFFF<span>"</span></span>

<span><span>#</span> Do stuff.</span></pre></div>
<h2 tabindex="-1" dir="auto">Split a string on a delimiter</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto">This is an alternative to <code>cut</code>, <code>awk</code> and other tools.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="split() {
   # Usage: split &quot;string&quot; &quot;delimiter&quot;
   IFS=$'\n' read -d &quot;&quot; -ra arr <<< &quot;${1//$2/$'\n'}&quot;
   printf '%s\n' &quot;${arr[@]}&quot;
}"><pre><span>split</span>() {
   <span><span>#</span> Usage: split "string" "delimiter"</span>
   IFS=<span><span>$'</span><span>\n</span><span>'</span></span> <span>read</span> -d <span><span>"</span><span>"</span></span> -ra arr <span>&lt;&lt;&lt;</span> <span><span>"</span>${1//$2/$'\n'}<span>"</span></span>
   <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${arr[@]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ split &quot;apples,oranges,pears,grapes&quot; &quot;,&quot;
apples
oranges
pears
grapes

$ split &quot;1, 2, 3, 4, 5&quot; &quot;, &quot;
1
2
3
4
5

# Multi char delimiters work too!
$ split &quot;hello---world---my---name---is---john&quot; &quot;---&quot;
hello
world
my
name
is
john"><pre>$ split <span><span>"</span>apples,oranges,pears,grapes<span>"</span></span> <span><span>"</span>,<span>"</span></span>
apples
oranges
pears
grapes

$ split <span><span>"</span>1, 2, 3, 4, 5<span>"</span></span> <span><span>"</span>, <span>"</span></span>
1
2
3
4
5

<span><span>#</span> Multi char delimiters work too!</span>
$ split <span><span>"</span>hello---world---my---name---is---john<span>"</span></span> <span><span>"</span>---<span>"</span></span>
hello
world
my
name
is
john</pre></div>
<h2 tabindex="-1" dir="auto">Change a string to lowercase</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="lower() {
    # Usage: lower &quot;string&quot;
    printf '%s\n' &quot;${1,,}&quot;
}"><pre><span>lower</span>() {
    <span><span>#</span> Usage: lower "string"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1,,}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ lower &quot;HELLO&quot;
hello

$ lower &quot;HeLlO&quot;
hello

$ lower &quot;hello&quot;
hello"><pre>$ lower <span><span>"</span>HELLO<span>"</span></span>
hello

$ lower <span><span>"</span>HeLlO<span>"</span></span>
hello

$ lower <span><span>"</span>hello<span>"</span></span>
hello</pre></div>
<h2 tabindex="-1" dir="auto">Change a string to uppercase</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="upper() {
    # Usage: upper &quot;string&quot;
    printf '%s\n' &quot;${1^^}&quot;
}"><pre><span>upper</span>() {
    <span><span>#</span> Usage: upper "string"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1^^}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ upper &quot;hello&quot;
HELLO

$ upper &quot;HeLlO&quot;
HELLO

$ upper &quot;HELLO&quot;
HELLO"><pre>$ upper <span><span>"</span>hello<span>"</span></span>
HELLO

$ upper <span><span>"</span>HeLlO<span>"</span></span>
HELLO

$ upper <span><span>"</span>HELLO<span>"</span></span>
HELLO</pre></div>
<h2 tabindex="-1" dir="auto">Reverse a string case</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="reverse_case() {
    # Usage: reverse_case &quot;string&quot;
    printf '%s\n' &quot;${1~~}&quot;
}"><pre><span>reverse_case</span>() {
    <span><span>#</span> Usage: reverse_case "string"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1~~}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ reverse_case &quot;hello&quot;
HELLO

$ reverse_case &quot;HeLlO&quot;
hElLo

$ reverse_case &quot;HELLO&quot;
hello"><pre>$ reverse_case <span><span>"</span>hello<span>"</span></span>
HELLO

$ reverse_case <span><span>"</span>HeLlO<span>"</span></span>
hElLo

$ reverse_case <span><span>"</span>HELLO<span>"</span></span>
hello</pre></div>
<h2 tabindex="-1" dir="auto">Trim quotes from a string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="trim_quotes() {
    # Usage: trim_quotes &quot;string&quot;
    : &quot;${1//\'}&quot;
    printf '%s\n' &quot;${_//\&quot;}&quot;
}"><pre><span>trim_quotes</span>() {
    <span><span>#</span> Usage: trim_quotes "string"</span>
    <span>:</span> <span><span>"</span><span>${1<span>//</span><span>\'</span>}</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${_<span>//</span><span>\"</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ var=&quot;'Hello', \&quot;World\&quot;&quot;
$ trim_quotes &quot;$var&quot;
Hello, World"><pre>$ var=<span><span>"</span>'Hello', <span>\"</span>World<span>\"</span><span>"</span></span>
$ trim_quotes <span><span>"</span><span>$var</span><span>"</span></span>
Hello, World</pre></div>
<h2 tabindex="-1" dir="auto">Strip all instances of pattern from string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="strip_all() {
    # Usage: strip_all &quot;string&quot; &quot;pattern&quot;
    printf '%s\n' &quot;${1//$2}&quot;
}"><pre><span>strip_all</span>() {
    <span><span>#</span> Usage: strip_all "string" "pattern"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1<span>//</span><span>$2</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ strip_all &quot;The Quick Brown Fox&quot; &quot;[aeiou]&quot;
Th Qck Brwn Fx

$ strip_all &quot;The Quick Brown Fox&quot; &quot;[[:space:]]&quot;
TheQuickBrownFox

$ strip_all &quot;The Quick Brown Fox&quot; &quot;Quick &quot;
The Brown Fox"><pre>$ strip_all <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>[aeiou]<span>"</span></span>
Th Qck Brwn Fx

$ strip_all <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>[[:space:]]<span>"</span></span>
TheQuickBrownFox

$ strip_all <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>Quick <span>"</span></span>
The Brown Fox</pre></div>
<h2 tabindex="-1" dir="auto">Strip first occurrence of pattern from string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="strip() {
    # Usage: strip &quot;string&quot; &quot;pattern&quot;
    printf '%s\n' &quot;${1/$2}&quot;
}"><pre><span>strip</span>() {
    <span><span>#</span> Usage: strip "string" "pattern"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1<span>/</span><span>$2</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ strip &quot;The Quick Brown Fox&quot; &quot;[aeiou]&quot;
Th Quick Brown Fox

$ strip &quot;The Quick Brown Fox&quot; &quot;[[:space:]]&quot;
TheQuick Brown Fox"><pre>$ strip <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>[aeiou]<span>"</span></span>
Th Quick Brown Fox

$ strip <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>[[:space:]]<span>"</span></span>
TheQuick Brown Fox</pre></div>
<h2 tabindex="-1" dir="auto">Strip pattern from start of string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="lstrip() {
    # Usage: lstrip &quot;string&quot; &quot;pattern&quot;
    printf '%s\n' &quot;${1##$2}&quot;
}"><pre><span>lstrip</span>() {
    <span><span>#</span> Usage: lstrip "string" "pattern"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1<span>##</span><span>$2</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ lstrip &quot;The Quick Brown Fox&quot; &quot;The &quot;
Quick Brown Fox"><pre>$ lstrip <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span>The <span>"</span></span>
Quick Brown Fox</pre></div>
<h2 tabindex="-1" dir="auto">Strip pattern from end of string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="rstrip() {
    # Usage: rstrip &quot;string&quot; &quot;pattern&quot;
    printf '%s\n' &quot;${1%%$2}&quot;
}"><pre><span>rstrip</span>() {
    <span><span>#</span> Usage: rstrip "string" "pattern"</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${1<span>%%</span><span>$2</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ rstrip &quot;The Quick Brown Fox&quot; &quot; Fox&quot;
The Quick Brown"><pre>$ rstrip <span><span>"</span>The Quick Brown Fox<span>"</span></span> <span><span>"</span> Fox<span>"</span></span>
The Quick Brown</pre></div>
<h2 tabindex="-1" dir="auto">Percent-encode a string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="urlencode() {
    # Usage: urlencode &quot;string&quot;
    local LC_ALL=C
    for (( i = 0; i < ${#1}; i++ )); do
        : &quot;${1:i:1}&quot;
        case &quot;$_&quot; in
            [a-zA-Z0-9.~_-])
                printf '%s' &quot;$_&quot;
            ;;

            *)
                printf '%%%02X' &quot;'$_&quot;
            ;;
        esac
    done
    printf '\n'
}"><pre><span>urlencode</span>() {
    <span><span>#</span> Usage: urlencode "string"</span>
    <span>local</span> LC_ALL=C
    <span>for</span> <span><span>((</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>${<span>#</span>1}</span>; i<span>++</span> <span>))</span></span><span>;</span> <span>do</span>
        <span>:</span> <span><span>"</span><span>${1<span>:</span>i<span>:</span>1}</span><span>"</span></span>
        <span>case</span> <span><span>"</span><span>$_</span><span>"</span></span> <span>in</span>
            [a-zA-Z0-9.~_-])
                <span>printf</span> <span><span>'</span>%s<span>'</span></span> <span><span>"</span><span>$_</span><span>"</span></span>
            ;;

            <span>*</span>)
                <span>printf</span> <span><span>'</span>%%%02X<span>'</span></span> <span><span>"</span>'<span>$_</span><span>"</span></span>
            ;;
        <span>esac</span>
    <span>done</span>
    <span>printf</span> <span><span>'</span>\n<span>'</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ urlencode &quot;https://github.com/dylanaraps/pure-bash-bible&quot;
https%3A%2F%2Fgithub.com%2Fdylanaraps%2Fpure-bash-bible"><pre>$ urlencode <span><span>"</span>https://github.com/dylanaraps/pure-bash-bible<span>"</span></span>
https%3A%2F%2Fgithub.com%2Fdylanaraps%2Fpure-bash-bible</pre></div>
<h2 tabindex="-1" dir="auto">Decode a percent-encoded string</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="urldecode() {
    # Usage: urldecode &quot;string&quot;
    : &quot;${1//+/ }&quot;
    printf '%b\n' &quot;${_//%/\\x}&quot;
}"><pre><span>urldecode</span>() {
    <span><span>#</span> Usage: urldecode "string"</span>
    <span>:</span> <span><span>"</span><span>${1<span>//</span>+<span>/</span> }</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%b\n<span>'</span></span> <span><span>"</span><span>${_<span>//%/</span><span>\\</span>x}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ urldecode &quot;https%3A%2F%2Fgithub.com%2Fdylanaraps%2Fpure-bash-bible&quot;
https://github.com/dylanaraps/pure-bash-bible"><pre>$ urldecode <span><span>"</span>https%3A%2F%2Fgithub.com%2Fdylanaraps%2Fpure-bash-bible<span>"</span></span>
https://github.com/dylanaraps/pure-bash-bible</pre></div>
<h2 tabindex="-1" dir="auto">Check if string contains a sub-string</h2>
<p dir="auto"><strong>Using a test:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="if [[ $var == *sub_string* ]]; then
    printf '%s\n' &quot;sub_string is in var.&quot;
fi

# Inverse (substring not in string).
if [[ $var != *sub_string* ]]; then
    printf '%s\n' &quot;sub_string is not in var.&quot;
fi

# This works for arrays too!
if [[ ${arr[*]} == *sub_string* ]]; then
    printf '%s\n' &quot;sub_string is in array.&quot;
fi"><pre><span>if</span> [[ <span>$var</span> <span>==</span> <span>*</span>sub_string<span>*</span> ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>sub_string is in var.<span>"</span></span>
<span>fi</span>

<span><span>#</span> Inverse (substring not in string).</span>
<span>if</span> [[ <span>$var</span> <span>!=</span> <span>*</span>sub_string<span>*</span> ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>sub_string is not in var.<span>"</span></span>
<span>fi</span>

<span><span>#</span> This works for arrays too!</span>
<span>if</span> [[ <span>${arr[*]}</span> <span>==</span> <span>*</span>sub_string<span>*</span> ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>sub_string is in array.<span>"</span></span>
<span>fi</span></pre></div>
<p dir="auto"><strong>Using a case statement:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="case &quot;$var&quot; in
    *sub_string*)
        # Do stuff
    ;;

    *sub_string2*)
        # Do more stuff
    ;;

    *)
        # Else
    ;;
esac"><pre><span>case</span> <span><span>"</span><span>$var</span><span>"</span></span> <span>in</span>
    <span>*</span>sub_string<span>*</span>)
        <span><span>#</span> Do stuff</span>
    ;;

    <span>*</span>sub_string2<span>*</span>)
        <span><span>#</span> Do more stuff</span>
    ;;

    <span>*</span>)
        <span><span>#</span> Else</span>
    ;;
<span>esac</span></pre></div>
<h2 tabindex="-1" dir="auto">Check if string starts with sub-string</h2>
<div dir="auto" data-snippet-clipboard-copy-content="if [[ $var == sub_string* ]]; then
    printf '%s\n' &quot;var starts with sub_string.&quot;
fi

# Inverse (var does not start with sub_string).
if [[ $var != sub_string* ]]; then
    printf '%s\n' &quot;var does not start with sub_string.&quot;
fi"><pre><span>if</span> [[ <span>$var</span> <span>==</span> sub_string<span>*</span> ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>var starts with sub_string.<span>"</span></span>
<span>fi</span>

<span><span>#</span> Inverse (var does not start with sub_string).</span>
<span>if</span> [[ <span>$var</span> <span>!=</span> sub_string<span>*</span> ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>var does not start with sub_string.<span>"</span></span>
<span>fi</span></pre></div>
<h2 tabindex="-1" dir="auto">Check if string ends with sub-string</h2>
<div dir="auto" data-snippet-clipboard-copy-content="if [[ $var == *sub_string ]]; then
    printf '%s\n' &quot;var ends with sub_string.&quot;
fi

# Inverse (var does not end with sub_string).
if [[ $var != *sub_string ]]; then
    printf '%s\n' &quot;var does not end with sub_string.&quot;
fi"><pre><span>if</span> [[ <span>$var</span> <span>==</span> <span>*</span>sub_string ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>var ends with sub_string.<span>"</span></span>
<span>fi</span>

<span><span>#</span> Inverse (var does not end with sub_string).</span>
<span>if</span> [[ <span>$var</span> <span>!=</span> <span>*</span>sub_string ]]<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>var does not end with sub_string.<span>"</span></span>
<span>fi</span></pre></div>


<h2 tabindex="-1" dir="auto">ARRAYS</h2>
<h2 tabindex="-1" dir="auto">Reverse an array</h2>
<p dir="auto">Enabling <code>extdebug</code> allows access to the <code>BASH_ARGV</code> array which stores
the current function’s arguments in reverse.</p>
<p dir="auto"><strong>CAVEAT</strong>: Requires <code>shopt -s compat44</code> in <code>bash</code> 5.0+.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="reverse_array() {
    # Usage: reverse_array &quot;array&quot;
    shopt -s extdebug
    f()(printf '%s\n' &quot;${BASH_ARGV[@]}&quot;); f &quot;$@&quot;
    shopt -u extdebug
}"><pre><span>reverse_array</span>() {
    <span><span>#</span> Usage: reverse_array "array"</span>
    <span>shopt</span> -s extdebug
    <span>f</span>()(printf <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${BASH_ARGV[@]}</span><span>"</span></span>); f <span><span>"</span><span>$@</span><span>"</span></span>
    <span>shopt</span> -u extdebug
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ reverse_array 1 2 3 4 5
5
4
3
2
1

$ arr=(red blue green)
$ reverse_array &quot;${arr[@]}&quot;
green
blue
red"><pre>$ reverse_array 1 2 3 4 5
5
4
3
2
1

$ arr=(red blue green)
$ reverse_array <span><span>"</span><span>${arr[@]}</span><span>"</span></span>
green
blue
red</pre></div>
<h2 tabindex="-1" dir="auto">Remove duplicate array elements</h2>
<p dir="auto">Create a temporary associative array. When setting associative array
values and a duplicate assignment occurs, bash overwrites the key. This
allows us to effectively remove array duplicates.</p>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>CAVEAT:</strong> List order may not stay the same.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="remove_array_dups() {
    # Usage: remove_array_dups &quot;array&quot;
    declare -A tmp_array

    for i in &quot;$@&quot;; do
        [[ $i ]] &amp;&amp; IFS=&quot; &quot; tmp_array[&quot;${i:- }&quot;]=1
    done

    printf '%s\n' &quot;${!tmp_array[@]}&quot;
}"><pre><span>remove_array_dups</span>() {
    <span><span>#</span> Usage: remove_array_dups "array"</span>
    <span>declare</span> -A tmp_array

    <span>for</span> <span>i</span> <span>in</span> <span><span>"</span><span>$@</span><span>"</span></span><span>;</span> <span>do</span>
        [[ <span>$i</span> ]] <span>&amp;&amp;</span> IFS=<span><span>"</span> <span>"</span></span> tmp_array[<span><span>"</span><span>${i<span>:-</span> }</span><span>"</span></span>]=1
    <span>done</span>

    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${<span>!</span>tmp_array[@]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ remove_array_dups 1 1 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 5
1
2
3
4
5

$ arr=(red red green blue blue)
$ remove_array_dups &quot;${arr[@]}&quot;
red
green
blue"><pre>$ remove_array_dups 1 1 2 2 3 3 3 3 3 4 4 4 4 4 5 5 5 5 5 5
1
2
3
4
5

$ arr=(red red green blue blue)
$ remove_array_dups <span><span>"</span><span>${arr[@]}</span><span>"</span></span>
red
green
blue</pre></div>
<h2 tabindex="-1" dir="auto">Random array element</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="random_array_element() {
    # Usage: random_array_element &quot;array&quot;
    local arr=(&quot;$@&quot;)
    printf '%s\n' &quot;${arr[RANDOM % $#]}&quot;
}"><pre><span>random_array_element</span>() {
    <span><span>#</span> Usage: random_array_element "array"</span>
    <span>local</span> arr=(<span><span>"</span><span>$@</span><span>"</span></span>)
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${arr[RANDOM % $#]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ array=(red green blue yellow brown)
$ random_array_element &quot;${array[@]}&quot;
yellow

# Multiple arguments can also be passed.
$ random_array_element 1 2 3 4 5 6 7
3"><pre>$ array=(red green blue yellow brown)
$ random_array_element <span><span>"</span><span>${array[@]}</span><span>"</span></span>
yellow

<span><span>#</span> Multiple arguments can also be passed.</span>
$ random_array_element 1 2 3 4 5 6 7
3</pre></div>
<h2 tabindex="-1" dir="auto">Cycle through an array</h2>
<p dir="auto">Each time the <code>printf</code> is called, the next array element is printed. When
the print hits the last array element it starts from the first element
again.</p>
<div dir="auto" data-snippet-clipboard-copy-content="arr=(a b c d)

cycle() {
    printf '%s ' &quot;${arr[${i:=0}]}&quot;
    ((i=i>=${#arr[@]}-1?0:++i))
}"><pre>arr=(a b c d)

<span>cycle</span>() {
    <span>printf</span> <span><span>'</span>%s <span>'</span></span> <span><span>"</span><span>${arr[${i:=0}]}</span><span>"</span></span>
    <span><span>((</span>i<span>=</span>i<span>&gt;=</span><span>${<span>#</span>arr[@]}</span><span>-</span><span>1</span><span>?</span><span>0</span><span>:++</span>i<span>))</span></span>
}</pre></div>
<h2 tabindex="-1" dir="auto">Toggle between two values</h2>
<p dir="auto">This works the same as above, this is just a different use case.</p>
<div dir="auto" data-snippet-clipboard-copy-content="arr=(true false)

cycle() {
    printf '%s ' &quot;${arr[${i:=0}]}&quot;
    ((i=i>=${#arr[@]}-1?0:++i))
}"><pre>arr=(true false)

<span>cycle</span>() {
    <span>printf</span> <span><span>'</span>%s <span>'</span></span> <span><span>"</span><span>${arr[${i:=0}]}</span><span>"</span></span>
    <span><span>((</span>i<span>=</span>i<span>&gt;=</span><span>${<span>#</span>arr[@]}</span><span>-</span><span>1</span><span>?</span><span>0</span><span>:++</span>i<span>))</span></span>
}</pre></div>


<h2 tabindex="-1" dir="auto">LOOPS</h2>
<h2 tabindex="-1" dir="auto">Loop over a range of numbers</h2>
<p dir="auto">Alternative to <code>seq</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Loop from 0-100 (no variable support).
for i in {0..100}; do
    printf '%s\n' &quot;$i&quot;
done"><pre><span><span>#</span> Loop from 0-100 (no variable support).</span>
<span>for</span> <span>i</span> <span>in</span> {0..100}<span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$i</span><span>"</span></span>
<span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Loop over a variable range of numbers</h2>
<p dir="auto">Alternative to <code>seq</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Loop from 0-VAR.
VAR=50
for ((i=0;i<=VAR;i++)); do
    printf '%s\n' &quot;$i&quot;
done"><pre><span><span>#</span> Loop from 0-VAR.</span>
VAR=50
<span>for</span> <span><span>((</span>i<span>=</span><span>0</span>;i<span>&lt;=</span>VAR;i<span>++</span><span>))</span></span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$i</span><span>"</span></span>
<span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Loop over an array</h2>
<div dir="auto" data-snippet-clipboard-copy-content="arr=(apples oranges tomatoes)

# Just elements.
for element in &quot;${arr[@]}&quot;; do
    printf '%s\n' &quot;$element&quot;
done"><pre>arr=(apples oranges tomatoes)

<span><span>#</span> Just elements.</span>
<span>for</span> <span>element</span> <span>in</span> <span><span>"</span><span>${arr[@]}</span><span>"</span></span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$element</span><span>"</span></span>
<span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Loop over an array with an index</h2>
<div dir="auto" data-snippet-clipboard-copy-content="arr=(apples oranges tomatoes)

# Elements and index.
for i in &quot;${!arr[@]}&quot;; do
    printf '%s\n' &quot;${arr[i]}&quot;
done

# Alternative method.
for ((i=0;i<${#arr[@]};i++)); do
    printf '%s\n' &quot;${arr[i]}&quot;
done"><pre>arr=(apples oranges tomatoes)

<span><span>#</span> Elements and index.</span>
<span>for</span> <span>i</span> <span>in</span> <span><span>"</span><span>${<span>!</span>arr[@]}</span><span>"</span></span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${arr[i]}</span><span>"</span></span>
<span>done</span>

<span><span>#</span> Alternative method.</span>
<span>for</span> <span><span>((</span>i<span>=</span><span>0</span>;i<span>&lt;</span><span>${<span>#</span>arr[@]}</span>;i<span>++</span><span>))</span></span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${arr[i]}</span><span>"</span></span>
<span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Loop over the contents of a file</h2>
<div dir="auto" data-snippet-clipboard-copy-content="while read -r line; do
    printf '%s\n' &quot;$line&quot;
done < &quot;file&quot;"><pre><span>while</span> <span>read</span> -r line<span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$line</span><span>"</span></span>
<span>done</span> <span>&lt;</span> <span><span>"</span>file<span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Loop over files and directories</h2>
<p dir="auto">Don’t use <code>ls</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Greedy example.
for file in *; do
    printf '%s\n' &quot;$file&quot;
done

# PNG files in dir.
for file in ~/Pictures/*.png; do
    printf '%s\n' &quot;$file&quot;
done

# Iterate over directories.
for dir in ~/Downloads/*/; do
    printf '%s\n' &quot;$dir&quot;
done

# Brace Expansion.
for file in /path/to/parentdir/{file1,file2,subdir/file3}; do
    printf '%s\n' &quot;$file&quot;
done

# Iterate recursively.
shopt -s globstar
for file in ~/Pictures/**/*; do
    printf '%s\n' &quot;$file&quot;
done
shopt -u globstar"><pre><span><span>#</span> Greedy example.</span>
<span>for</span> <span>file</span> <span>in</span> <span>*</span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$file</span><span>"</span></span>
<span>done</span>

<span><span>#</span> PNG files in dir.</span>
<span>for</span> <span>file</span> <span>in</span> <span>~</span>/Pictures/<span>*</span>.png<span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$file</span><span>"</span></span>
<span>done</span>

<span><span>#</span> Iterate over directories.</span>
<span>for</span> <span>dir</span> <span>in</span> <span>~</span>/Downloads/<span>*</span>/<span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$dir</span><span>"</span></span>
<span>done</span>

<span><span>#</span> Brace Expansion.</span>
<span>for</span> <span>file</span> <span>in</span> /path/to/parentdir/{file1,file2,subdir/file3}<span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$file</span><span>"</span></span>
<span>done</span>

<span><span>#</span> Iterate recursively.</span>
<span>shopt</span> -s globstar
<span>for</span> <span>file</span> <span>in</span> <span>~</span>/Pictures/<span>**</span>/<span>*</span><span>;</span> <span>do</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$file</span><span>"</span></span>
<span>done</span>
<span>shopt</span> -u globstar</pre></div>


<h2 tabindex="-1" dir="auto">FILE HANDLING</h2>
<p dir="auto"><strong>CAVEAT:</strong> <code>bash</code> does not handle binary data properly in versions <code>&lt; 4.4</code>.</p>
<h2 tabindex="-1" dir="auto">Read a file to a string</h2>
<p dir="auto">Alternative to the <code>cat</code> command.</p>

<h2 tabindex="-1" dir="auto">Read a file to an array (<em>by line</em>)</h2>
<p dir="auto">Alternative to the <code>cat</code> command.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Bash <4 (discarding empty lines).
IFS=$'\n' read -d &quot;&quot; -ra file_data < &quot;file&quot;

# Bash <4 (preserving empty lines).
while read -r line; do
    file_data+=(&quot;$line&quot;)
done < &quot;file&quot;

# Bash 4+
mapfile -t file_data < &quot;file&quot;"><pre><span><span>#</span> Bash &lt;4 (discarding empty lines).</span>
IFS=<span><span>$'</span><span>\n</span><span>'</span></span> <span>read</span> -d <span><span>"</span><span>"</span></span> -ra file_data <span>&lt;</span> <span><span>"</span>file<span>"</span></span>

<span><span>#</span> Bash &lt;4 (preserving empty lines).</span>
<span>while</span> <span>read</span> -r line<span>;</span> <span>do</span>
    file_data+=(<span><span>"</span><span>$line</span><span>"</span></span>)
<span>done</span> <span>&lt;</span> <span><span>"</span>file<span>"</span></span>

<span><span>#</span> Bash 4+</span>
mapfile -t file_data <span>&lt;</span> <span><span>"</span>file<span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Get the first N lines of a file</h2>
<p dir="auto">Alternative to the <code>head</code> command.</p>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="head() {
    # Usage: head &quot;n&quot; &quot;file&quot;
    mapfile -tn &quot;$1&quot; line < &quot;$2&quot;
    printf '%s\n' &quot;${line[@]}&quot;
}"><pre><span>head</span>() {
    <span><span>#</span> Usage: head "n" "file"</span>
    mapfile -tn <span><span>"</span><span>$1</span><span>"</span></span> line <span>&lt;</span> <span><span>"</span><span>$2</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${line[@]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ head 2 ~/.bashrc
# Prompt
PS1='➜ '

$ head 1 ~/.bashrc
# Prompt"><pre>$ head 2 <span>~</span>/.bashrc
<span><span>#</span> Prompt</span>
PS1=<span><span>'</span>➜ <span>'</span></span>

$ head 1 <span>~</span>/.bashrc
<span><span>#</span> Prompt</span></pre></div>
<h2 tabindex="-1" dir="auto">Get the last N lines of a file</h2>
<p dir="auto">Alternative to the <code>tail</code> command.</p>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="tail() {
    # Usage: tail &quot;n&quot; &quot;file&quot;
    mapfile -tn 0 line < &quot;$2&quot;
    printf '%s\n' &quot;${line[@]: -$1}&quot;
}"><pre><span>tail</span>() {
    <span><span>#</span> Usage: tail "n" "file"</span>
    mapfile -tn 0 line <span>&lt;</span> <span><span>"</span><span>$2</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${line[@]<span>:</span> -<span>$1</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ tail 2 ~/.bashrc
# Enable tmux.
# [[ -z &quot;$TMUX&quot;  ]] &amp;&amp; exec tmux

$ tail 1 ~/.bashrc
# [[ -z &quot;$TMUX&quot;  ]] &amp;&amp; exec tmux"><pre>$ tail 2 <span>~</span>/.bashrc
<span><span>#</span> Enable tmux.</span>
<span><span>#</span> [[ -z "$TMUX"  ]] &amp;&amp; exec tmux</span>

$ tail 1 <span>~</span>/.bashrc
<span><span>#</span> [[ -z "$TMUX"  ]] &amp;&amp; exec tmux</span></pre></div>
<h2 tabindex="-1" dir="auto">Get the number of lines in a file</h2>
<p dir="auto">Alternative to <code>wc -l</code>.</p>
<p dir="auto"><strong>Example Function (bash 4):</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="lines() {
    # Usage: lines &quot;file&quot;
    mapfile -tn 0 lines < &quot;$1&quot;
    printf '%s\n' &quot;${#lines[@]}&quot;
}"><pre><span>lines</span>() {
    <span><span>#</span> Usage: lines "file"</span>
    mapfile -tn 0 lines <span>&lt;</span> <span><span>"</span><span>$1</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${<span>#</span>lines[@]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Function (bash 3):</strong></p>
<p dir="auto">This method uses less memory than the <code>mapfile</code> method and works in <code>bash</code> 3 but it is slower for bigger files.</p>
<div dir="auto" data-snippet-clipboard-copy-content="lines_loop() {
    # Usage: lines_loop &quot;file&quot;
    count=0
    while IFS= read -r _; do
        ((count++))
    done < &quot;$1&quot;
    printf '%s\n' &quot;$count&quot;
}"><pre><span>lines_loop</span>() {
    <span><span>#</span> Usage: lines_loop "file"</span>
    count=0
    <span>while</span> IFS= <span>read</span> -r _<span>;</span> <span>do</span>
        <span><span>((</span>count<span>++</span><span>))</span></span>
    <span>done</span> <span>&lt;</span> <span><span>"</span><span>$1</span><span>"</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$count</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ lines ~/.bashrc
48

$ lines_loop ~/.bashrc
48"><pre>$ lines <span>~</span>/.bashrc
48

$ lines_loop <span>~</span>/.bashrc
48</pre></div>
<h2 tabindex="-1" dir="auto">Count files or directories in directory</h2>
<p dir="auto">This works by passing the output of the glob to the function and then counting the number of arguments.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="count() {
    # Usage: count /path/to/dir/*
    #        count /path/to/dir/*/
    printf '%s\n' &quot;$#&quot;
}"><pre><span>count</span>() {
    <span><span>#</span> Usage: count /path/to/dir/*</span>
    <span><span>#</span>        count /path/to/dir/*/</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$#</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Count all files in dir.
$ count ~/Downloads/*
232

# Count all dirs in dir.
$ count ~/Downloads/*/
45

# Count all jpg files in dir.
$ count ~/Pictures/*.jpg
64"><pre><span><span>#</span> Count all files in dir.</span>
$ count <span>~</span>/Downloads/<span>*</span>
232

<span><span>#</span> Count all dirs in dir.</span>
$ count <span>~</span>/Downloads/<span>*</span>/
45

<span><span>#</span> Count all jpg files in dir.</span>
$ count <span>~</span>/Pictures/<span>*</span>.jpg
64</pre></div>
<h2 tabindex="-1" dir="auto">Create an empty file</h2>
<p dir="auto">Alternative to <code>touch</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Shortest.
>file

# Longer alternatives:
:>file
echo -n >file
printf '' >file"><pre><span><span>#</span> Shortest.</span>
<span>&gt;</span>file

<span><span>#</span> Longer alternatives:</span>
:<span>&gt;</span>file
<span>echo</span> -n <span>&gt;</span>file
<span>printf</span> <span><span>'</span><span>'</span></span> <span>&gt;</span>file</pre></div>
<h2 tabindex="-1" dir="auto">Extract lines between two markers</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="extract() {
    # Usage: extract file &quot;opening marker&quot; &quot;closing marker&quot;
    while IFS=$'\n' read -r line; do
        [[ $extract &amp;&amp; $line != &quot;$3&quot; ]] &amp;&amp;
            printf '%s\n' &quot;$line&quot;

        [[ $line == &quot;$2&quot; ]] &amp;&amp; extract=1
        [[ $line == &quot;$3&quot; ]] &amp;&amp; extract=
    done < &quot;$1&quot;
}"><pre><span>extract</span>() {
    <span><span>#</span> Usage: extract file "opening marker" "closing marker"</span>
    <span>while</span> IFS=<span><span>$'</span><span>\n</span><span>'</span></span> <span>read</span> -r line<span>;</span> <span>do</span>
        [[ <span>$extract</span> <span>&amp;&amp;</span> <span>$line</span> <span>!=</span> <span><span>"</span><span>$3</span><span>"</span></span> ]] <span>&amp;&amp;</span>
            <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$line</span><span>"</span></span>

        [[ <span>$line</span> <span>==</span> <span><span>"</span><span>$2</span><span>"</span></span> ]] <span>&amp;&amp;</span> extract=1
        [[ <span>$line</span> <span>==</span> <span><span>"</span><span>$3</span><span>"</span></span> ]] <span>&amp;&amp;</span> extract=
    <span>done</span> <span>&lt;</span> <span><span>"</span><span>$1</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Extract code blocks from MarkDown file.
$ extract ~/projects/pure-bash/README.md '```sh' '```'
# Output here..."><pre><span><span>#</span> Extract code blocks from MarkDown file.</span>
$ extract <span>~</span>/projects/pure-bash/README.md <span><span>'</span>```sh<span>'</span></span> <span><span>'</span>```<span>'</span></span>
<span><span>#</span> Output here...</span></pre></div>


<h2 tabindex="-1" dir="auto">FILE PATHS</h2>
<h2 tabindex="-1" dir="auto">Get the directory name of a file path</h2>
<p dir="auto">Alternative to the <code>dirname</code> command.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="dirname() {
    # Usage: dirname &quot;path&quot;
    local tmp=${1:-.}

    [[ $tmp != *[!/]* ]] &amp;&amp; {
        printf '/\n'
        return
    }

    tmp=${tmp%%&quot;${tmp##*[!/]}&quot;}

    [[ $tmp != */* ]] &amp;&amp; {
        printf '.\n'
        return
    }

    tmp=${tmp%/*}
    tmp=${tmp%%&quot;${tmp##*[!/]}&quot;}

    printf '%s\n' &quot;${tmp:-/}&quot;
}"><pre><span>dirname</span>() {
    <span><span>#</span> Usage: dirname "path"</span>
    <span>local</span> tmp=<span>${1<span>:-</span>.}</span>

    [[ <span>$tmp</span> <span>!=</span> <span>*</span>[<span>!</span>/]<span>*</span> ]] <span>&amp;&amp;</span> {
        <span>printf</span> <span><span>'</span>/\n<span>'</span></span>
        <span>return</span>
    }

    tmp=<span>${tmp<span>%%</span><span><span>"</span><span>${tmp<span>##*</span>[!/]}</span><span>"</span></span>}</span>

    [[ <span>$tmp</span> <span>!=</span> <span>*</span>/<span>*</span> ]] <span>&amp;&amp;</span> {
        <span>printf</span> <span><span>'</span>.\n<span>'</span></span>
        <span>return</span>
    }

    tmp=<span>${tmp<span>%/*</span>}</span>
    tmp=<span>${tmp<span>%%</span><span><span>"</span><span>${tmp<span>##*</span>[!/]}</span><span>"</span></span>}</span>

    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${tmp<span>:-/</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ dirname ~/Pictures/Wallpapers/1.jpg
/home/black/Pictures/Wallpapers

$ dirname ~/Pictures/Downloads/
/home/black/Pictures"><pre>$ dirname <span>~</span>/Pictures/Wallpapers/1.jpg
/home/black/Pictures/Wallpapers

$ dirname <span>~</span>/Pictures/Downloads/
/home/black/Pictures</pre></div>
<h2 tabindex="-1" dir="auto">Get the base-name of a file path</h2>
<p dir="auto">Alternative to the <code>basename</code> command.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="basename() {
    # Usage: basename &quot;path&quot; [&quot;suffix&quot;]
    local tmp

    tmp=${1%&quot;${1##*[!/]}&quot;}
    tmp=${tmp##*/}
    tmp=${tmp%&quot;${2/&quot;$tmp&quot;}&quot;}

    printf '%s\n' &quot;${tmp:-/}&quot;
}"><pre><span>basename</span>() {
    <span><span>#</span> Usage: basename "path" ["suffix"]</span>
    <span>local</span> tmp

    tmp=<span>${1<span>%</span><span><span>"</span><span>${1<span>##*</span>[!/]}</span><span>"</span></span>}</span>
    tmp=<span>${tmp<span>##*/</span>}</span>
    tmp=<span>${tmp<span>%</span><span><span>"</span><span>${2<span>/</span><span><span>"</span><span>$tmp</span><span>"</span></span>}</span><span>"</span></span>}</span>

    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${tmp<span>:-/</span>}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ basename ~/Pictures/Wallpapers/1.jpg
1.jpg

$ basename ~/Pictures/Wallpapers/1.jpg .jpg
1

$ basename ~/Pictures/Downloads/
Downloads"><pre>$ basename <span>~</span>/Pictures/Wallpapers/1.jpg
1.jpg

$ basename <span>~</span>/Pictures/Wallpapers/1.jpg .jpg
1

$ basename <span>~</span>/Pictures/Downloads/
Downloads</pre></div>


<h2 tabindex="-1" dir="auto">VARIABLES</h2>
<h2 tabindex="-1" dir="auto">Assign and access a variable using a variable</h2>
<div dir="auto" data-snippet-clipboard-copy-content="$ hello_world=&quot;value&quot;

# Create the variable name.
$ var=&quot;world&quot;
$ ref=&quot;hello_$var&quot;

# Print the value of the variable name stored in 'hello_$var'.
$ printf '%s\n' &quot;${!ref}&quot;
value"><pre>$ hello_world=<span><span>"</span>value<span>"</span></span>

<span><span>#</span> Create the variable name.</span>
$ var=<span><span>"</span>world<span>"</span></span>
$ ref=<span><span>"</span>hello_<span>$var</span><span>"</span></span>

<span><span>#</span> Print the value of the variable name stored in 'hello_$var'.</span>
$ <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${<span>!</span>ref}</span><span>"</span></span>
value</pre></div>
<p dir="auto">Alternatively, on <code>bash</code> 4.3+:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hello_world=&quot;value&quot;
$ var=&quot;world&quot;

# Declare a nameref.
$ declare -n ref=hello_$var

$ printf '%s\n' &quot;$ref&quot;
value"><pre>$ hello_world=<span><span>"</span>value<span>"</span></span>
$ var=<span><span>"</span>world<span>"</span></span>

<span><span>#</span> Declare a nameref.</span>
$ <span>declare</span> -n ref=hello_<span>$var</span>

$ <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$ref</span><span>"</span></span>
value</pre></div>
<h2 tabindex="-1" dir="auto">Name a variable based on another variable</h2>
<div dir="auto" data-snippet-clipboard-copy-content="$ var=&quot;world&quot;
$ declare &quot;hello_$var=value&quot;
$ printf '%s\n' &quot;$hello_world&quot;
value"><pre>$ var=<span><span>"</span>world<span>"</span></span>
$ <span>declare</span> <span><span>"</span>hello_<span>$var</span>=value<span>"</span></span>
$ <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$hello_world</span><span>"</span></span>
value</pre></div>


<h2 tabindex="-1" dir="auto">ESCAPE SEQUENCES</h2>
<p dir="auto">Contrary to popular belief, there is no issue in utilizing raw escape sequences. Using <code>tput</code> abstracts the same ANSI sequences as if printed manually. Worse still, <code>tput</code> is not actually portable. There are a number of <code>tput</code> variants each with different commands and syntaxes (<em>try <code>tput setaf 3</code> on a FreeBSD system</em>). Raw sequences are fine.</p>
<h2 tabindex="-1" dir="auto">Text Colors</h2>
<p dir="auto"><strong>NOTE:</strong> Sequences requiring RGB values only work in True-Color Terminal Emulators.</p>
<table>
<thead>
<tr>
<th>Sequence</th>
<th>What does it do?</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\e[38;5;&lt;NUM&gt;m</code></td>
<td>Set text foreground color.</td>
<td><code>0-255</code></td>
</tr>
<tr>
<td><code>\e[48;5;&lt;NUM&gt;m</code></td>
<td>Set text background color.</td>
<td><code>0-255</code></td>
</tr>
<tr>
<td><code>\e[38;2;&lt;R&gt;;&lt;G&gt;;&lt;B&gt;m</code></td>
<td>Set text foreground color to RGB color.</td>
<td><code>R</code>, <code>G</code>, <code>B</code></td>
</tr>
<tr>
<td><code>\e[48;2;&lt;R&gt;;&lt;G&gt;;&lt;B&gt;m</code></td>
<td>Set text background color to RGB color.</td>
<td><code>R</code>, <code>G</code>, <code>B</code></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Text Attributes</h2>
<p dir="auto"><strong>NOTE:</strong> Prepend 2 to any code below to turn it's effect off
(examples: 21=bold text off, 22=faint text off, 23=italic text off).</p>
<table>
<thead>
<tr>
<th>Sequence</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\e[m</code></td>
<td>Reset text formatting and colors.</td>
</tr>
<tr>
<td><code>\e[1m</code></td>
<td>Bold text.</td>
</tr>
<tr>
<td><code>\e[2m</code></td>
<td>Faint text.</td>
</tr>
<tr>
<td><code>\e[3m</code></td>
<td>Italic text.</td>
</tr>
<tr>
<td><code>\e[4m</code></td>
<td>Underline text.</td>
</tr>
<tr>
<td><code>\e[5m</code></td>
<td>Blinking text.</td>
</tr>
<tr>
<td><code>\e[7m</code></td>
<td>Highlighted text.</td>
</tr>
<tr>
<td><code>\e[8m</code></td>
<td>Hidden text.</td>
</tr>
<tr>
<td><code>\e[9m</code></td>
<td>Strike-through text.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Cursor Movement</h2>
<table>
<thead>
<tr>
<th>Sequence</th>
<th>What does it do?</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\e[&lt;LINE&gt;;&lt;COLUMN&gt;H</code></td>
<td>Move cursor to absolute position.</td>
<td><code>line</code>, <code>column</code></td>
</tr>
<tr>
<td><code>\e[H</code></td>
<td>Move cursor to home position (<code>0,0</code>).</td>
<td></td>
</tr>
<tr>
<td><code>\e[&lt;NUM&gt;A</code></td>
<td>Move cursor up N lines.</td>
<td><code>num</code></td>
</tr>
<tr>
<td><code>\e[&lt;NUM&gt;B</code></td>
<td>Move cursor down N lines.</td>
<td><code>num</code></td>
</tr>
<tr>
<td><code>\e[&lt;NUM&gt;C</code></td>
<td>Move cursor right N columns.</td>
<td><code>num</code></td>
</tr>
<tr>
<td><code>\e[&lt;NUM&gt;D</code></td>
<td>Move cursor left N columns.</td>
<td><code>num</code></td>
</tr>
<tr>
<td><code>\e[s</code></td>
<td>Save cursor position.</td>
<td></td>
</tr>
<tr>
<td><code>\e[u</code></td>
<td>Restore cursor position.</td>
<td></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Erasing Text</h2>
<table>
<thead>
<tr>
<th>Sequence</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\e[K</code></td>
<td>Erase from cursor position to end of line.</td>
</tr>
<tr>
<td><code>\e[1K</code></td>
<td>Erase from cursor position to start of line.</td>
</tr>
<tr>
<td><code>\e[2K</code></td>
<td>Erase the entire current line.</td>
</tr>
<tr>
<td><code>\e[J</code></td>
<td>Erase from the current line to the bottom of the screen.</td>
</tr>
<tr>
<td><code>\e[1J</code></td>
<td>Erase from the current line to the top of the screen.</td>
</tr>
<tr>
<td><code>\e[2J</code></td>
<td>Clear the screen.</td>
</tr>
<tr>
<td><code>\e[2J\e[H</code></td>
<td>Clear the screen and move cursor to <code>0,0</code>.</td>
</tr>
</tbody>
</table>


<h2 tabindex="-1" dir="auto">PARAMETER EXPANSION</h2>
<h2 tabindex="-1" dir="auto">Indirection</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${!VAR}</code></td>
<td>Access a variable based on the value of <code>VAR</code>.</td>
</tr>
<tr>
<td><code>${!VAR*}</code></td>
<td>Expand to <code>IFS</code> separated list of variable names starting with <code>VAR</code>.</td>
</tr>
<tr>
<td><code>${!VAR@}</code></td>
<td>Expand to <code>IFS</code> separated list of variable names starting with <code>VAR</code>. If double-quoted, each variable name expands to a separate word.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Replacement</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${VAR#PATTERN}</code></td>
<td>Remove shortest match of pattern from start of string.</td>
</tr>
<tr>
<td><code>${VAR##PATTERN}</code></td>
<td>Remove longest match of pattern from start of string.</td>
</tr>
<tr>
<td><code>${VAR%PATTERN}</code></td>
<td>Remove shortest match of pattern from end of string.</td>
</tr>
<tr>
<td><code>${VAR%%PATTERN}</code></td>
<td>Remove longest match of pattern from end of string.</td>
</tr>
<tr>
<td><code>${VAR/PATTERN/REPLACE}</code></td>
<td>Replace first match with string.</td>
</tr>
<tr>
<td><code>${VAR//PATTERN/REPLACE}</code></td>
<td>Replace all matches with string.</td>
</tr>
<tr>
<td><code>${VAR/PATTERN}</code></td>
<td>Remove first match.</td>
</tr>
<tr>
<td><code>${VAR//PATTERN}</code></td>
<td>Remove all matches.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Length</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${#VAR}</code></td>
<td>Length of var in characters.</td>
</tr>
<tr>
<td><code>${#ARR[@]}</code></td>
<td>Length of array in elements.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Expansion</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${VAR:OFFSET}</code></td>
<td>Remove first <code>N</code> chars from variable.</td>
</tr>
<tr>
<td><code>${VAR:OFFSET:LENGTH}</code></td>
<td>Get substring from <code>N</code> character to <code>N</code> character. <br> (<code>${VAR:10:10}</code>: Get sub-string from char <code>10</code> to char <code>20</code>)</td>
</tr>
<tr>
<td><code>${VAR:: OFFSET}</code></td>
<td>Get first <code>N</code> chars from variable.</td>
</tr>
<tr>
<td><code>${VAR:: -OFFSET}</code></td>
<td>Remove last <code>N</code> chars from variable.</td>
</tr>
<tr>
<td><code>${VAR: -OFFSET}</code></td>
<td>Get last <code>N</code> chars from variable.</td>
</tr>
<tr>
<td><code>${VAR:OFFSET:-OFFSET}</code></td>
<td>Cut first <code>N</code> chars and last <code>N</code> chars.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Case Modification</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
<th>CAVEAT</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${VAR^}</code></td>
<td>Uppercase first character.</td>
<td><code>bash 4+</code></td>
</tr>
<tr>
<td><code>${VAR^^}</code></td>
<td>Uppercase all characters.</td>
<td><code>bash 4+</code></td>
</tr>
<tr>
<td><code>${VAR,}</code></td>
<td>Lowercase first character.</td>
<td><code>bash 4+</code></td>
</tr>
<tr>
<td><code>${VAR,,}</code></td>
<td>Lowercase all characters.</td>
<td><code>bash 4+</code></td>
</tr>
<tr>
<td><code>${VAR~}</code></td>
<td>Reverse case of first character.</td>
<td><code>bash 4+</code></td>
</tr>
<tr>
<td><code>${VAR~~}</code></td>
<td>Reverse case of all characters.</td>
<td><code>bash 4+</code></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Default Value</h2>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>${VAR:-STRING}</code></td>
<td>If <code>VAR</code> is empty or unset, use <code>STRING</code> as its value.</td>
</tr>
<tr>
<td><code>${VAR-STRING}</code></td>
<td>If <code>VAR</code> is unset, use <code>STRING</code> as its value.</td>
</tr>
<tr>
<td><code>${VAR:=STRING}</code></td>
<td>If <code>VAR</code> is empty or unset, set the value of <code>VAR</code> to <code>STRING</code>.</td>
</tr>
<tr>
<td><code>${VAR=STRING}</code></td>
<td>If <code>VAR</code> is unset, set the value of <code>VAR</code> to <code>STRING</code>.</td>
</tr>
<tr>
<td><code>${VAR:+STRING}</code></td>
<td>If <code>VAR</code> is not empty, use <code>STRING</code> as its value.</td>
</tr>
<tr>
<td><code>${VAR+STRING}</code></td>
<td>If <code>VAR</code> is set, use <code>STRING</code> as its value.</td>
</tr>
<tr>
<td><code>${VAR:?STRING}</code></td>
<td>Display an error if empty or unset.</td>
</tr>
<tr>
<td><code>${VAR?STRING}</code></td>
<td>Display an error if unset.</td>
</tr>
</tbody>
</table>


<h2 tabindex="-1" dir="auto">BRACE EXPANSION</h2>
<h2 tabindex="-1" dir="auto">Ranges</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Syntax: {<START>..<END>}

# Print numbers 1-100.
echo {1..100}

# Print range of floats.
echo 1.{1..9}

# Print chars a-z.
echo {a..z}
echo {A..Z}

# Nesting.
echo {A..Z}{0..9}

# Print zero-padded numbers.
# CAVEAT: bash 4+
echo {01..100}

# Change increment amount.
# Syntax: {<START>..<END>..<INCREMENT>}
# CAVEAT: bash 4+
echo {1..10..2} # Increment by 2."><pre><span><span>#</span> Syntax: {&lt;START&gt;..&lt;END&gt;}</span>

<span><span>#</span> Print numbers 1-100.</span>
<span>echo</span> {1..100}

<span><span>#</span> Print range of floats.</span>
<span>echo</span> 1.{1..9}

<span><span>#</span> Print chars a-z.</span>
<span>echo</span> {a..z}
<span>echo</span> {A..Z}

<span><span>#</span> Nesting.</span>
<span>echo</span> {A..Z}{0..9}

<span><span>#</span> Print zero-padded numbers.</span>
<span><span>#</span> CAVEAT: bash 4+</span>
<span>echo</span> {01..100}

<span><span>#</span> Change increment amount.</span>
<span><span>#</span> Syntax: {&lt;START&gt;..&lt;END&gt;..&lt;INCREMENT&gt;}</span>
<span><span>#</span> CAVEAT: bash 4+</span>
<span>echo</span> {1..10..2} <span><span>#</span> Increment by 2.</span></pre></div>
<h2 tabindex="-1" dir="auto">String Lists</h2>
<div dir="auto" data-snippet-clipboard-copy-content="echo {apples,oranges,pears,grapes}

# Example Usage:
# Remove dirs Movies, Music and ISOS from ~/Downloads/.
rm -rf ~/Downloads/{Movies,Music,ISOS}"><pre><span>echo</span> {apples,oranges,pears,grapes}

<span><span>#</span> Example Usage:</span>
<span><span>#</span> Remove dirs Movies, Music and ISOS from ~/Downloads/.</span>
rm -rf <span>~</span>/Downloads/{Movies,Music,ISOS}</pre></div>


<h2 tabindex="-1" dir="auto">CONDITIONAL EXPRESSIONS</h2>
<h2 tabindex="-1" dir="auto">File Conditionals</h2>
<table>
<thead>
<tr>
<th>Expression</th>
<th>Value</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-a</code></td>
<td><code>file</code></td>
<td>If file exists.</td>
</tr>
<tr>
<td><code>-b</code></td>
<td><code>file</code></td>
<td>If file exists and is a block special file.</td>
</tr>
<tr>
<td><code>-c</code></td>
<td><code>file</code></td>
<td>If file exists and is a character special file.</td>
</tr>
<tr>
<td><code>-d</code></td>
<td><code>file</code></td>
<td>If file exists and is a directory.</td>
</tr>
<tr>
<td><code>-e</code></td>
<td><code>file</code></td>
<td>If file exists.</td>
</tr>
<tr>
<td><code>-f</code></td>
<td><code>file</code></td>
<td>If file exists and is a regular file.</td>
</tr>
<tr>
<td><code>-g</code></td>
<td><code>file</code></td>
<td>If file exists and its set-group-id bit is set.</td>
</tr>
<tr>
<td><code>-h</code></td>
<td><code>file</code></td>
<td>If file exists and is a symbolic link.</td>
</tr>
<tr>
<td><code>-k</code></td>
<td><code>file</code></td>
<td>If file exists and its sticky-bit is set</td>
</tr>
<tr>
<td><code>-p</code></td>
<td><code>file</code></td>
<td>If file exists and is a named pipe (<em>FIFO</em>).</td>
</tr>
<tr>
<td><code>-r</code></td>
<td><code>file</code></td>
<td>If file exists and is readable.</td>
</tr>
<tr>
<td><code>-s</code></td>
<td><code>file</code></td>
<td>If file exists and its size is greater than zero.</td>
</tr>
<tr>
<td><code>-t</code></td>
<td><code>fd</code></td>
<td>If file descriptor is open and refers to a terminal.</td>
</tr>
<tr>
<td><code>-u</code></td>
<td><code>file</code></td>
<td>If file exists and its set-user-id bit is set.</td>
</tr>
<tr>
<td><code>-w</code></td>
<td><code>file</code></td>
<td>If file exists and is writable.</td>
</tr>
<tr>
<td><code>-x</code></td>
<td><code>file</code></td>
<td>If file exists and is executable.</td>
</tr>
<tr>
<td><code>-G</code></td>
<td><code>file</code></td>
<td>If file exists and is owned by the effective group ID.</td>
</tr>
<tr>
<td><code>-L</code></td>
<td><code>file</code></td>
<td>If file exists and is a symbolic link.</td>
</tr>
<tr>
<td><code>-N</code></td>
<td><code>file</code></td>
<td>If file exists and has been modified since last read.</td>
</tr>
<tr>
<td><code>-O</code></td>
<td><code>file</code></td>
<td>If file exists and is owned by the effective user ID.</td>
</tr>
<tr>
<td><code>-S</code></td>
<td><code>file</code></td>
<td>If file exists and is a socket.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">File Comparisons</h2>
<table>
<thead>
<tr>
<th>Expression</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>file -ef file2</code></td>
<td>If both files refer to the same inode and device numbers.</td>
</tr>
<tr>
<td><code>file -nt file2</code></td>
<td>If <code>file</code> is newer than <code>file2</code> (<em>uses modification time</em>) or <code>file</code> exists and <code>file2</code> does not.</td>
</tr>
<tr>
<td><code>file -ot file2</code></td>
<td>If <code>file</code> is older than <code>file2</code> (<em>uses modification time</em>) or <code>file2</code> exists and <code>file</code> does not.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Variable Conditionals</h2>
<table>
<thead>
<tr>
<th>Expression</th>
<th>Value</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>-o</code></td>
<td><code>opt</code></td>
<td>If shell option is enabled.</td>
</tr>
<tr>
<td><code>-v</code></td>
<td><code>var</code></td>
<td>If variable has a value assigned.</td>
</tr>
<tr>
<td><code>-R</code></td>
<td><code>var</code></td>
<td>If variable is a name reference.</td>
</tr>
<tr>
<td><code>-z</code></td>
<td><code>var</code></td>
<td>If the length of string is zero.</td>
</tr>
<tr>
<td><code>-n</code></td>
<td><code>var</code></td>
<td>If the length of string is non-zero.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Variable Comparisons</h2>
<table>
<thead>
<tr>
<th>Expression</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>var = var2</code></td>
<td>Equal to.</td>
</tr>
<tr>
<td><code>var == var2</code></td>
<td>Equal to (<em>synonym for <code>=</code></em>).</td>
</tr>
<tr>
<td><code>var != var2</code></td>
<td>Not equal to.</td>
</tr>
<tr>
<td><code>var &lt; var2</code></td>
<td>Less than (<em>in ASCII alphabetical order.</em>)</td>
</tr>
<tr>
<td><code>var &gt; var2</code></td>
<td>Greater than (<em>in ASCII alphabetical order.</em>)</td>
</tr>
</tbody>
</table>


<h2 tabindex="-1" dir="auto">ARITHMETIC OPERATORS</h2>
<h2 tabindex="-1" dir="auto">Assignment</h2>
<table>
<thead>
<tr>
<th>Operators</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>=</code></td>
<td>Initialize or change the value of a variable.</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Arithmetic</h2>
<table>
<thead>
<tr>
<th>Operators</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>+</code></td>
<td>Addition</td>
</tr>
<tr>
<td><code>-</code></td>
<td>Subtraction</td>
</tr>
<tr>
<td><code>*</code></td>
<td>Multiplication</td>
</tr>
<tr>
<td><code>/</code></td>
<td>Division</td>
</tr>
<tr>
<td><code>**</code></td>
<td>Exponentiation</td>
</tr>
<tr>
<td><code>%</code></td>
<td>Modulo</td>
</tr>
<tr>
<td><code>+=</code></td>
<td>Plus-Equal (<em>Increment a variable.</em>)</td>
</tr>
<tr>
<td><code>-=</code></td>
<td>Minus-Equal (<em>Decrement a variable.</em>)</td>
</tr>
<tr>
<td><code>*=</code></td>
<td>Times-Equal (<em>Multiply a variable.</em>)</td>
</tr>
<tr>
<td><code>/=</code></td>
<td>Slash-Equal (<em>Divide a variable.</em>)</td>
</tr>
<tr>
<td><code>%=</code></td>
<td>Mod-Equal (<em>Remainder of dividing a variable.</em>)</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Bitwise</h2>
<table>
<thead>
<tr>
<th>Operators</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>&lt;&lt;</code></td>
<td>Bitwise Left Shift</td>
</tr>
<tr>
<td><code>&lt;&lt;=</code></td>
<td>Left-Shift-Equal</td>
</tr>
<tr>
<td><code>&gt;&gt;</code></td>
<td>Bitwise Right Shift</td>
</tr>
<tr>
<td><code>&gt;&gt;=</code></td>
<td>Right-Shift-Equal</td>
</tr>
<tr>
<td><code>&amp;</code></td>
<td>Bitwise AND</td>
</tr>
<tr>
<td><code>&amp;=</code></td>
<td>Bitwise AND-Equal</td>
</tr>
<tr>
<td><code>|</code></td>
<td>Bitwise OR</td>
</tr>
<tr>
<td><code>|=</code></td>
<td>Bitwise OR-Equal</td>
</tr>
<tr>
<td><code>~</code></td>
<td>Bitwise NOT</td>
</tr>
<tr>
<td><code>^</code></td>
<td>Bitwise XOR</td>
</tr>
<tr>
<td><code>^=</code></td>
<td>Bitwise XOR-Equal</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Logical</h2>
<table>
<thead>
<tr>
<th>Operators</th>
<th>What does it do?</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>!</code></td>
<td>NOT</td>
</tr>
<tr>
<td><code>&amp;&amp;</code></td>
<td>AND</td>
</tr>
<tr>
<td><code>||</code></td>
<td>OR</td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto">Miscellaneous</h2>
<table>
<thead>
<tr>
<th>Operators</th>
<th>What does it do?</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>,</code></td>
<td>Comma Separator</td>
<td><code>((a=1,b=2,c=3))</code></td>
</tr>
</tbody>
</table>


<h2 tabindex="-1" dir="auto">ARITHMETIC</h2>
<h2 tabindex="-1" dir="auto">Simpler syntax to set variables</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Simple math
((var=1+2))

# Decrement/Increment variable
((var++))
((var--))
((var+=1))
((var-=1))

# Using variables
((var=var2*arr[2]))"><pre><span><span>#</span> Simple math</span>
<span><span>((</span>var<span>=</span><span>1</span><span>+</span><span>2</span><span>))</span></span>

<span><span>#</span> Decrement/Increment variable</span>
<span><span>((</span>var<span>++</span><span>))</span></span>
<span><span>((</span>var<span>--</span><span>))</span></span>
<span><span>((</span>var<span>+=</span><span>1</span><span>))</span></span>
<span><span>((</span>var<span>-=</span><span>1</span><span>))</span></span>

<span><span>#</span> Using variables</span>
<span><span>((</span>var<span>=</span>var<span>2</span><span>*</span>arr[<span>2</span>]<span>))</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Ternary Tests</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Set the value of var to var2 if var2 is greater than var.
# var: variable to set.
# var2>var: Condition to test.
# ?var2: If the test succeeds.
# :var: If the test fails.
((var=var2>var?var2:var))"><pre><span><span>#</span> Set the value of var to var2 if var2 is greater than var.</span>
<span><span>#</span> var: variable to set.</span>
<span><span>#</span> var2&gt;var: Condition to test.</span>
<span><span>#</span> ?var2: If the test succeeds.</span>
<span><span>#</span> :var: If the test fails.</span>
<span><span>((</span>var<span>=</span>var<span>2</span><span>&gt;</span>var<span>?</span>var<span>2</span><span>:</span>var<span>))</span></span></pre></div>


<h2 tabindex="-1" dir="auto">TRAPS</h2>
<p dir="auto">Traps allow a script to execute code on various signals. In <a href="https://github.com/dylanaraps/pxltrm">pxltrm</a> (<em>a pixel art editor written in bash</em>)  traps are used to redraw the user interface on window resize. Another use case is cleaning up temporary files on script exit.</p>
<p dir="auto">Traps should be added near the start of scripts so any early errors are also caught.</p>
<p dir="auto"><strong>NOTE:</strong> For a full list of signals, see <code>trap -l</code>.</p>
<h2 tabindex="-1" dir="auto">Do something on script exit</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Clear screen on script exit.
trap 'printf \\e[2J\\e[H\\e[m' EXIT"><pre><span><span>#</span> Clear screen on script exit.</span>
<span>trap</span> <span><span>'</span>printf \\e[2J\\e[H\\e[m<span>'</span></span> EXIT</pre></div>
<h2 tabindex="-1" dir="auto">Ignore terminal interrupt (CTRL+C, SIGINT)</h2>

<h2 tabindex="-1" dir="auto">React to window resize</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Call a function on window resize.
trap 'code_here' SIGWINCH"><pre><span><span>#</span> Call a function on window resize.</span>
<span>trap</span> <span><span>'</span>code_here<span>'</span></span> SIGWINCH</pre></div>
<h2 tabindex="-1" dir="auto">Do something before every command</h2>

<h2 tabindex="-1" dir="auto">Do something when a shell function or a sourced file finishes executing</h2>



<h2 tabindex="-1" dir="auto">PERFORMANCE</h2>
<h2 tabindex="-1" dir="auto">Disable Unicode</h2>
<p dir="auto">If unicode is not required, it can be disabled for a performance increase. Results may vary however there have been noticeable improvements in <a href="https://github.com/dylanaraps/neofetch">neofetch</a> and other programs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Disable unicode.
LC_ALL=C
LANG=C"><pre><span><span>#</span> Disable unicode.</span>
LC_ALL=C
LANG=C</pre></div>


<h2 tabindex="-1" dir="auto">OBSOLETE SYNTAX</h2>
<h2 tabindex="-1" dir="auto">Shebang</h2>
<p dir="auto">Use <code>#!/usr/bin/env bash</code> instead of <code>#!/bin/bash</code>.</p>
<ul dir="auto">
<li>The former searches the user's <code>PATH</code> to find the <code>bash</code> binary.</li>
<li>The latter assumes it is always installed to <code>/bin/</code> which can cause issues.</li>
</ul>
<p dir="auto"><strong>NOTE</strong>: There are times when one may have a good reason for using <code>#!/bin/bash</code> or another direct path to the binary.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Right:

    #!/usr/bin/env bash

# Less right:

    #!/bin/bash"><pre><span><span>#</span> Right:</span>

    <span><span>#!</span>/usr/bin/env bash</span>

<span><span>#</span> Less right:</span>

    <span><span>#!</span>/bin/bash</span></pre></div>
<h2 tabindex="-1" dir="auto">Command Substitution</h2>
<p dir="auto">Use <code>$()</code> instead of <code>` `</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Right.
var=&quot;$(command)&quot;

# Wrong.
var=`command`

# $() can easily be nested whereas `` cannot.
var=&quot;$(command &quot;$(command)&quot;)&quot;"><pre><span><span>#</span> Right.</span>
var=<span><span>"</span><span><span>$(</span>command<span>)</span></span><span>"</span></span>

<span><span>#</span> Wrong.</span>
var=<span><span>`</span>command<span>`</span></span>

<span><span>#</span> $() can easily be nested whereas `` cannot.</span>
var=<span><span>"</span><span><span>$(</span>command <span><span>"</span><span><span>$(</span>command<span>)</span></span><span>"</span></span><span>)</span></span><span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Function Declaration</h2>
<p dir="auto">Do not use the <code>function</code> keyword, it reduces compatibility with older versions of <code>bash</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Right.
do_something() {
    # ...
}

# Wrong.
function do_something() {
    # ...
}"><pre><span><span>#</span> Right.</span>
<span>do_something</span>() {
    <span><span>#</span> ...</span>
}

<span><span>#</span> Wrong.</span>
<span>function</span> <span>do_something()</span> {
    <span><span>#</span> ...</span>
}</pre></div>


<h2 tabindex="-1" dir="auto">INTERNAL VARIABLES</h2>
<h2 tabindex="-1" dir="auto">Get the location to the <code>bash</code> binary</h2>

<h2 tabindex="-1" dir="auto">Get the version of the current running <code>bash</code> process</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# As a string.
&quot;$BASH_VERSION&quot;

# As an array.
&quot;${BASH_VERSINFO[@]}&quot;"><pre><span><span>#</span> As a string.</span>
<span><span>"</span><span>$BASH_VERSION</span><span>"</span></span>

<span><span>#</span> As an array.</span>
<span><span>"</span><span>${BASH_VERSINFO[@]}</span><span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Open the user's preferred text editor</h2>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;$EDITOR&quot; &quot;$file&quot;

# NOTE: This variable may be empty, set a fallback value.
&quot;${EDITOR:-vi}&quot; &quot;$file&quot;"><pre><span><span>"</span><span>$EDITOR</span><span>"</span></span> <span><span>"</span><span>$file</span><span>"</span></span>

<span><span>#</span> NOTE: This variable may be empty, set a fallback value.</span>
<span><span>"</span><span>${EDITOR<span>:-</span>vi}</span><span>"</span></span> <span><span>"</span><span>$file</span><span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Get the name of the current function</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Current function.
&quot;${FUNCNAME[0]}&quot;

# Parent function.
&quot;${FUNCNAME[1]}&quot;

# So on and so forth.
&quot;${FUNCNAME[2]}&quot;
&quot;${FUNCNAME[3]}&quot;

# All functions including parents.
&quot;${FUNCNAME[@]}&quot;"><pre><span><span>#</span> Current function.</span>
<span><span>"</span><span>${FUNCNAME[0]}</span><span>"</span></span>

<span><span>#</span> Parent function.</span>
<span><span>"</span><span>${FUNCNAME[1]}</span><span>"</span></span>

<span><span>#</span> So on and so forth.</span>
<span><span>"</span><span>${FUNCNAME[2]}</span><span>"</span></span>
<span><span>"</span><span>${FUNCNAME[3]}</span><span>"</span></span>

<span><span>#</span> All functions including parents.</span>
<span><span>"</span><span>${FUNCNAME[@]}</span><span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Get the host-name of the system</h2>
<div dir="auto" data-snippet-clipboard-copy-content="&quot;$HOSTNAME&quot;

# NOTE: This variable may be empty.
# Optionally set a fallback to the hostname command.
&quot;${HOSTNAME:-$(hostname)}&quot;"><pre><span><span>"</span><span>$HOSTNAME</span><span>"</span></span>

<span><span>#</span> NOTE: This variable may be empty.</span>
<span><span>#</span> Optionally set a fallback to the hostname command.</span>
<span><span>"</span><span>${HOSTNAME<span>:-</span>$(hostname)}</span><span>"</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Get the architecture of the Operating System</h2>

<h2 tabindex="-1" dir="auto">Get the name of the Operating System / Kernel</h2>
<p dir="auto">This can be used to add conditional support for different Operating
Systems without needing to call <code>uname</code>.</p>

<h2 tabindex="-1" dir="auto">Get the current working directory</h2>
<p dir="auto">This is an alternative to the <code>pwd</code> built-in.</p>

<h2 tabindex="-1" dir="auto">Get the number of seconds the script has been running</h2>

<h2 tabindex="-1" dir="auto">Get a pseudorandom integer</h2>
<p dir="auto">Each time <code>$RANDOM</code> is used, a different integer between <code>0</code> and <code>32767</code> is returned. This variable should not be used for anything related to security (<em>this includes encryption keys etc</em>).</p>



<h2 tabindex="-1" dir="auto">INFORMATION ABOUT THE TERMINAL</h2>
<h2 tabindex="-1" dir="auto">Get the terminal size in lines and columns (<em>from a script</em>)</h2>
<p dir="auto">This is handy when writing scripts in pure bash and <code>stty</code>/<code>tput</code> can’t be
called.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="get_term_size() {
    # Usage: get_term_size

    # (:;:) is a micro sleep to ensure the variables are
    # exported immediately.
    shopt -s checkwinsize; (:;:)
    printf '%s\n' &quot;$LINES $COLUMNS&quot;
}"><pre><span>get_term_size</span>() {
    <span><span>#</span> Usage: get_term_size</span>

    <span><span>#</span> (:;:) is a micro sleep to ensure the variables are</span>
    <span><span>#</span> exported immediately.</span>
    <span>shopt</span> -s checkwinsize<span>;</span> (:<span>;</span>:)
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$LINES</span> <span>$COLUMNS</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Output: LINES COLUMNS
$ get_term_size
15 55"><pre><span><span>#</span> Output: LINES COLUMNS</span>
$ get_term_size
15 55</pre></div>
<h2 tabindex="-1" dir="auto">Get the terminal size in pixels</h2>
<p dir="auto"><strong>CAVEAT</strong>: This does not work in some terminal emulators.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="get_window_size() {
    # Usage: get_window_size
    printf '%b' &quot;${TMUX:+\\ePtmux;\\e}\\e[14t${TMUX:+\\e\\\\}&quot;
    IFS=';t' read -d t -t 0.05 -sra term_size
    printf '%s\n' &quot;${term_size[1]}x${term_size[2]}&quot;
}"><pre><span>get_window_size</span>() {
    <span><span>#</span> Usage: get_window_size</span>
    <span>printf</span> <span><span>'</span>%b<span>'</span></span> <span><span>"</span><span>${TMUX<span>:</span>+<span>\\</span>ePtmux;<span>\\</span>e}</span><span>\\</span>e[14t<span>${TMUX<span>:</span>+<span>\\</span>e<span>\\\\</span>}</span><span>"</span></span>
    IFS=<span><span>'</span>;t<span>'</span></span> <span>read</span> -d t -t 0.05 -sra term_size
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${term_size[1]}</span>x<span>${term_size[2]}</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Output: WIDTHxHEIGHT
$ get_window_size
1200x800

# Output (fail):
$ get_window_size
x"><pre><span><span>#</span> Output: WIDTHxHEIGHT</span>
$ get_window_size
1200x800

<span><span>#</span> Output (fail):</span>
$ get_window_size
x</pre></div>
<h2 tabindex="-1" dir="auto">Get the current cursor position</h2>
<p dir="auto">This is useful when creating a TUI in pure bash.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="get_cursor_pos() {
    # Usage: get_cursor_pos
    IFS='[;' read -p $'\e[6n' -d R -rs _ y x _
    printf '%s\n' &quot;$x $y&quot;
}"><pre><span>get_cursor_pos</span>() {
    <span><span>#</span> Usage: get_cursor_pos</span>
    IFS=<span><span>'</span>[;<span>'</span></span> <span>read</span> -p <span><span>$'</span><span>\e</span>[6n<span>'</span></span> -d R -rs _ y x _
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$x</span> <span>$y</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Output: X Y
$ get_cursor_pos
1 8"><pre><span><span>#</span> Output: X Y</span>
$ get_cursor_pos
1 8</pre></div>


<h2 tabindex="-1" dir="auto">CONVERSION</h2>
<h2 tabindex="-1" dir="auto">Convert a hex color to RGB</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="hex_to_rgb() {
    # Usage: hex_to_rgb &quot;#FFFFFF&quot;
    #        hex_to_rgb &quot;000000&quot;
    : &quot;${1/\#}&quot;
    ((r=16#${_:0:2},g=16#${_:2:2},b=16#${_:4:2}))
    printf '%s\n' &quot;$r $g $b&quot;
}"><pre><span>hex_to_rgb</span>() {
    <span><span>#</span> Usage: hex_to_rgb "#FFFFFF"</span>
    <span><span>#</span>        hex_to_rgb "000000"</span>
    <span>:</span> <span><span>"</span><span>${1<span>/</span><span>\#</span>}</span><span>"</span></span>
    <span><span>((</span>r<span>=</span><span>16</span>#<span>${_<span>:</span>0<span>:</span>2}</span><span>,</span>g<span>=</span><span>16</span>#<span>${_<span>:</span>2<span>:</span>2}</span><span>,</span>b<span>=</span><span>16</span>#<span>${_<span>:</span>4<span>:</span>2}</span><span>))</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$r</span> <span>$g</span> <span>$b</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hex_to_rgb &quot;#FFFFFF&quot;
255 255 255"><pre>$ hex_to_rgb <span><span>"</span>#FFFFFF<span>"</span></span>
255 255 255</pre></div>
<h2 tabindex="-1" dir="auto">Convert an RGB color to hex</h2>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="rgb_to_hex() {
    # Usage: rgb_to_hex &quot;r&quot; &quot;g&quot; &quot;b&quot;
    printf '#%02x%02x%02x\n' &quot;$1&quot; &quot;$2&quot; &quot;$3&quot;
}"><pre><span>rgb_to_hex</span>() {
    <span><span>#</span> Usage: rgb_to_hex "r" "g" "b"</span>
    <span>printf</span> <span><span>'</span>#%02x%02x%02x\n<span>'</span></span> <span><span>"</span><span>$1</span><span>"</span></span> <span><span>"</span><span>$2</span><span>"</span></span> <span><span>"</span><span>$3</span><span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ rgb_to_hex &quot;255&quot; &quot;255&quot; &quot;255&quot;
#FFFFFF"><pre>$ rgb_to_hex <span><span>"</span>255<span>"</span></span> <span><span>"</span>255<span>"</span></span> <span><span>"</span>255<span>"</span></span>
<span><span>#</span>FFFFFF</span></pre></div>
<h2 tabindex="-1" dir="auto">CODE GOLF</h2>
<h2 tabindex="-1" dir="auto">Shorter <code>for</code> loop syntax</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Tiny C Style.
for((;i++<10;)){ echo &quot;$i&quot;;}

# Undocumented method.
for i in {1..10};{ echo &quot;$i&quot;;}

# Expansion.
for i in {1..10}; do echo &quot;$i&quot;; done

# C Style.
for((i=0;i<=10;i++)); do echo &quot;$i&quot;; done"><pre><span><span>#</span> Tiny C Style.</span>
for<span><span>((</span>;i<span>++&lt;</span><span>10</span>;<span>))</span></span>{ <span>echo</span> <span><span>"</span><span>$i</span><span>"</span></span><span>;</span>}

<span><span>#</span> Undocumented method.</span>
<span>for</span> <span>i</span> <span>in</span> {1..10}<span>;</span>{ <span>echo</span> <span><span>"</span><span>$i</span><span>"</span></span><span>;</span>}

<span><span>#</span> Expansion.</span>
<span>for</span> <span>i</span> <span>in</span> {1..10}<span>;</span> <span>do</span> <span>echo</span> <span><span>"</span><span>$i</span><span>"</span></span><span>;</span> <span>done</span>

<span><span>#</span> C Style.</span>
for<span><span>((</span>i<span>=</span><span>0</span>;i<span>&lt;=</span><span>10</span>;i<span>++</span><span>))</span></span><span>;</span> <span>do</span> <span>echo</span> <span><span>"</span><span>$i</span><span>"</span></span><span>;</span> <span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Shorter infinite loops</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Normal method
while :; do echo hi; done

# Shorter
for((;;)){ echo hi;}"><pre><span><span>#</span> Normal method</span>
<span>while</span> <span>:</span><span>;</span> <span>do</span> <span>echo</span> hi<span>;</span> <span>done</span>

<span><span>#</span> Shorter</span>
for<span><span>((</span>;;<span>))</span></span>{ <span>echo</span> hi<span>;</span>}</pre></div>
<h2 tabindex="-1" dir="auto">Shorter function declaration</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# Normal method
f(){ echo hi;}

# Using a subshell
f()(echo hi)

# Using arithmetic
# This can be used to assign integer values.
# Example: f a=1
#          f a++
f()(($1))

# Using tests, loops etc.
# NOTE: ‘while’, ‘until’, ‘case’, ‘(())’, ‘[[]]’ can also be used.
f()if true; then echo &quot;$1&quot;; fi
f()for i in &quot;$@&quot;; do echo &quot;$i&quot;; done"><pre><span><span>#</span> Normal method</span>
<span>f</span>(){ <span>echo</span> hi;}

<span><span>#</span> Using a subshell</span>
<span>f</span>()(echo hi)

<span><span>#</span> Using arithmetic</span>
<span><span>#</span> This can be used to assign integer values.</span>
<span><span>#</span> Example: f a=1</span>
<span><span>#</span>          f a++</span>
<span>f</span>()<span><span>((</span><span>$1</span><span>))</span></span>

<span><span>#</span> Using tests, loops etc.</span>
<span><span>#</span> NOTE: ‘while’, ‘until’, ‘case’, ‘(())’, ‘[[]]’ can also be used.</span>
<span>f</span>()if <span>true</span>; <span>then</span> <span>echo</span> <span><span>"</span><span>$1</span><span>"</span></span><span>;</span> <span>fi</span>
<span>f</span>()for i <span>in</span> <span><span>"</span><span>$@</span><span>"</span></span>; <span>do</span> <span>echo</span> <span><span>"</span><span>$i</span><span>"</span></span><span>;</span> <span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Shorter <code>if</code> syntax</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# One line
# Note: The 3rd statement may run when the 1st is true
[[ $var == hello ]] &amp;&amp; echo hi || echo bye
[[ $var == hello ]] &amp;&amp; { echo hi; echo there; } || echo bye

# Multi line (no else, single statement)
# Note: The exit status may not be the same as with an if statement
[[ $var == hello ]] &amp;&amp;
    echo hi

# Multi line (no else)
[[ $var == hello ]] &amp;&amp; {
    echo hi
    # ...
}"><pre><span><span>#</span> One line</span>
<span><span>#</span> Note: The 3rd statement may run when the 1st is true</span>
[[ <span>$var</span> <span>==</span> hello ]] <span>&amp;&amp;</span> <span>echo</span> hi <span>||</span> <span>echo</span> bye
[[ <span>$var</span> <span>==</span> hello ]] <span>&amp;&amp;</span> { <span>echo</span> hi<span>;</span> <span>echo</span> there<span>;</span> } <span>||</span> <span>echo</span> bye

<span><span>#</span> Multi line (no else, single statement)</span>
<span><span>#</span> Note: The exit status may not be the same as with an if statement</span>
[[ <span>$var</span> <span>==</span> hello ]] <span>&amp;&amp;</span>
    <span>echo</span> hi

<span><span>#</span> Multi line (no else)</span>
[[ <span>$var</span> <span>==</span> hello ]] <span>&amp;&amp;</span> {
    <span>echo</span> hi
    <span><span>#</span> ...</span>
}</pre></div>
<h2 tabindex="-1" dir="auto">Simpler <code>case</code> statement to set variable</h2>
<p dir="auto">The <code>:</code> built-in can be used to avoid repeating <code>variable=</code> in a case statement. The <code>$_</code> variable stores the last argument of the last command. <code>:</code> always succeeds so it can be used to store the variable value.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Modified snippet from Neofetch.
case &quot;$OSTYPE&quot; in
    &quot;darwin&quot;*)
        : &quot;MacOS&quot;
    ;;

    &quot;linux&quot;*)
        : &quot;Linux&quot;
    ;;

    *&quot;bsd&quot;* | &quot;dragonfly&quot; | &quot;bitrig&quot;)
        : &quot;BSD&quot;
    ;;

    &quot;cygwin&quot; | &quot;msys&quot; | &quot;win32&quot;)
        : &quot;Windows&quot;
    ;;

    *)
        printf '%s\n' &quot;Unknown OS detected, aborting...&quot; >&amp;2
        exit 1
    ;;
esac

# Finally, set the variable.
os=&quot;$_&quot;"><pre><span><span>#</span> Modified snippet from Neofetch.</span>
<span>case</span> <span><span>"</span><span>$OSTYPE</span><span>"</span></span> <span>in</span>
    <span><span>"</span>darwin<span>"</span></span><span>*</span>)
        <span>:</span> <span><span>"</span>MacOS<span>"</span></span>
    ;;

    <span><span>"</span>linux<span>"</span></span><span>*</span>)
        <span>:</span> <span><span>"</span>Linux<span>"</span></span>
    ;;

    <span>*</span><span><span>"</span>bsd<span>"</span></span><span>*</span> | <span><span>"</span>dragonfly<span>"</span></span> | <span><span>"</span>bitrig<span>"</span></span>)
        <span>:</span> <span><span>"</span>BSD<span>"</span></span>
    ;;

    <span><span>"</span>cygwin<span>"</span></span> | <span><span>"</span>msys<span>"</span></span> | <span><span>"</span>win32<span>"</span></span>)
        <span>:</span> <span><span>"</span>Windows<span>"</span></span>
    ;;

    <span>*</span>)
        <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>Unknown OS detected, aborting...<span>"</span></span> <span>&gt;&amp;2</span>
        <span>exit</span> 1
    ;;
<span>esac</span>

<span><span>#</span> Finally, set the variable.</span>
os=<span><span>"</span><span>$_</span><span>"</span></span></pre></div>


<h2 tabindex="-1" dir="auto">OTHER</h2>
<h2 tabindex="-1" dir="auto">Use <code>read</code> as an alternative to the <code>sleep</code> command</h2>
<p dir="auto">Surprisingly, <code>sleep</code> is an external command and not a <code>bash</code> built-in.</p>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="read_sleep() {
    # Usage: read_sleep 1
    #        read_sleep 0.2
    read -rt &quot;$1&quot; <> <(:) || :
}"><pre><span>read_sleep</span>() {
    <span><span>#</span> Usage: read_sleep 1</span>
    <span><span>#</span>        read_sleep 0.2</span>
    <span>read</span> -rt <span><span>"</span><span>$1</span><span>"</span></span> <span>&lt;&gt;</span> <span><span>&lt;(</span>:<span>)</span></span> <span>||</span> <span>:</span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="read_sleep 1
read_sleep 0.1
read_sleep 30"><pre>read_sleep 1
read_sleep 0.1
read_sleep 30</pre></div>
<p dir="auto">For performance-critical situations, where it is not economic to open and close an excessive number of file descriptors, the allocation of a file descriptor may be done only once for all invocations of <code>read</code>:</p>
<p dir="auto">(See the generic original implementation at <a href="https://blog.dhampir.no/content/sleeping-without-a-subprocess-in-bash-and-how-to-sleep-forever" rel="nofollow">https://blog.dhampir.no/content/sleeping-without-a-subprocess-in-bash-and-how-to-sleep-forever</a>)</p>
<div dir="auto" data-snippet-clipboard-copy-content="exec {sleep_fd}<> <(:)
while some_quick_test; do
    # equivalent of sleep 0.001
    read -t 0.001 -u $sleep_fd
done"><pre><span>exec</span> {sleep_fd}<span>&lt;&gt;</span> <span><span>&lt;(</span>:<span>)</span></span>
<span>while</span> some_quick_test<span>;</span> <span>do</span>
    <span><span>#</span> equivalent of sleep 0.001</span>
    <span>read</span> -t 0.001 -u <span>$sleep_fd</span>
<span>done</span></pre></div>
<h2 tabindex="-1" dir="auto">Check if a program is in the user's PATH</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# There are 3 ways to do this and either one can be used.
type -p executable_name &amp;>/dev/null
hash executable_name &amp;>/dev/null
command -v executable_name &amp;>/dev/null

# As a test.
if type -p executable_name &amp;>/dev/null; then
    # Program is in PATH.
fi

# Inverse.
if ! type -p executable_name &amp;>/dev/null; then
    # Program is not in PATH.
fi

# Example (Exit early if program is not installed).
if ! type -p convert &amp;>/dev/null; then
    printf '%s\n' &quot;error: convert is not installed, exiting...&quot;
    exit 1
fi"><pre><span><span>#</span> There are 3 ways to do this and either one can be used.</span>
<span>type</span> -p executable_name <span>&amp;</span><span>&gt;</span>/dev/null
<span>hash</span> executable_name <span>&amp;</span><span>&gt;</span>/dev/null
<span>command</span> -v executable_name <span>&amp;</span><span>&gt;</span>/dev/null

<span><span>#</span> As a test.</span>
<span>if</span> <span>type</span> -p executable_name <span>&amp;</span><span>&gt;</span>/dev/null<span>;</span> <span>then</span>
    <span><span>#</span> Program is in PATH.</span>
<span>fi</span>

<span><span>#</span> Inverse.</span>
<span>if</span> <span>!</span> <span>type</span> -p executable_name <span>&amp;</span><span>&gt;</span>/dev/null<span>;</span> <span>then</span>
    <span><span>#</span> Program is not in PATH.</span>
<span>fi</span>

<span><span>#</span> Example (Exit early if program is not installed).</span>
<span>if</span> <span>!</span> <span>type</span> -p convert <span>&amp;</span><span>&gt;</span>/dev/null<span>;</span> <span>then</span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span>error: convert is not installed, exiting...<span>"</span></span>
    <span>exit</span> 1
<span>fi</span></pre></div>
<h2 tabindex="-1" dir="auto">Get the current date using <code>strftime</code></h2>
<p dir="auto">Bash’s <code>printf</code> has a built-in method of getting the date which can be used in place of the <code>date</code> command.</p>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="date() {
    # Usage: date &quot;format&quot;
    # See: 'man strftime' for format.
    printf &quot;%($1)T\\n&quot; &quot;-1&quot;
}"><pre><span>date</span>() {
    <span><span>#</span> Usage: date "format"</span>
    <span><span>#</span> See: 'man strftime' for format.</span>
    <span>printf</span> <span><span>"</span>%(<span>$1</span>)T<span>\\</span>n<span>"</span></span> <span><span>"</span>-1<span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Using above function.
$ date &quot;%a %d %b  - %l:%M %p&quot;
Fri 15 Jun  - 10:00 AM

# Using printf directly.
$ printf '%(%a %d %b  - %l:%M %p)T\n' &quot;-1&quot;
Fri 15 Jun  - 10:00 AM

# Assigning a variable using printf.
$ printf -v date '%(%a %d %b  - %l:%M %p)T\n' '-1'
$ printf '%s\n' &quot;$date&quot;
Fri 15 Jun  - 10:00 AM"><pre><span><span>#</span> Using above function.</span>
$ date <span><span>"</span>%a %d %b  - %l:%M %p<span>"</span></span>
Fri 15 Jun  - 10:00 AM

<span><span>#</span> Using printf directly.</span>
$ <span>printf</span> <span><span>'</span>%(%a %d %b  - %l:%M %p)T\n<span>'</span></span> <span><span>"</span>-1<span>"</span></span>
Fri 15 Jun  - 10:00 AM

<span><span>#</span> Assigning a variable using printf.</span>
$ <span>printf</span> -v date <span><span>'</span>%(%a %d %b  - %l:%M %p)T\n<span>'</span></span> <span><span>'</span>-1<span>'</span></span>
$ <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>$date</span><span>"</span></span>
Fri 15 Jun  - 10:00 AM</pre></div>
<h2 tabindex="-1" dir="auto">Get the username of the current user</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4.4+</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ : \\u
# Expand the parameter as if it were a prompt string.
$ printf '%s\n' &quot;${_@P}&quot;
black"><pre>$ <span>:</span> <span>\\</span>u
<span><span>#</span> Expand the parameter as if it were a prompt string.</span>
$ <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${_<span>@</span>P}</span><span>"</span></span>
black</pre></div>
<h2 tabindex="-1" dir="auto">Generate a UUID V4</h2>
<p dir="auto"><strong>CAVEAT</strong>: The generated value is not cryptographically secure.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="uuid() {
    # Usage: uuid
    C=&quot;89ab&quot;

    for ((N=0;N<16;++N)); do
        B=&quot;$((RANDOM%256))&quot;

        case &quot;$N&quot; in
            6)  printf '4%x' &quot;$((B%16))&quot; ;;
            8)  printf '%c%x' &quot;${C:$RANDOM%${#C}:1}&quot; &quot;$((B%16))&quot; ;;

            3|5|7|9)
                printf '%02x-' &quot;$B&quot;
            ;;

            *)
                printf '%02x' &quot;$B&quot;
            ;;
        esac
    done

    printf '\n'
}"><pre><span>uuid</span>() {
    <span><span>#</span> Usage: uuid</span>
    C=<span><span>"</span>89ab<span>"</span></span>

    <span>for</span> <span><span>((</span>N<span>=</span><span>0</span>;N<span>&lt;</span><span>16</span>;<span>++</span>N<span>))</span></span><span>;</span> <span>do</span>
        B=<span><span>"</span><span><span>$((</span>RANDOM<span>%</span><span>256</span><span>))</span></span><span>"</span></span>

        <span>case</span> <span><span>"</span><span>$N</span><span>"</span></span> <span>in</span>
            6)  <span>printf</span> <span><span>'</span>4%x<span>'</span></span> <span><span>"</span><span><span>$((</span>B<span>%</span><span>16</span><span>))</span></span><span>"</span></span> ;;
            8)  <span>printf</span> <span><span>'</span>%c%x<span>'</span></span> <span><span>"</span><span>${C<span>:</span><span>$RANDOM</span><span>%</span><span>${<span>#</span>C}</span><span>:</span>1}</span><span>"</span></span> <span><span>"</span><span><span>$((</span>B<span>%</span><span>16</span><span>))</span></span><span>"</span></span> ;;

            3|5|7|9)
                <span>printf</span> <span><span>'</span>%02x-<span>'</span></span> <span><span>"</span><span>$B</span><span>"</span></span>
            ;;

            <span>*</span>)
                <span>printf</span> <span><span>'</span>%02x<span>'</span></span> <span><span>"</span><span>$B</span><span>"</span></span>
            ;;
        <span>esac</span>
    <span>done</span>

    <span>printf</span> <span><span>'</span>\n<span>'</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ uuid
d5b6c731-1310-4c24-9fe3-55d556d44374"><pre>$ uuid
d5b6c731-1310-4c24-9fe3-55d556d44374</pre></div>
<h2 tabindex="-1" dir="auto">Progress bars</h2>
<p dir="auto">This is a simple way of drawing progress bars without needing a for loop
in the function itself.</p>
<p dir="auto"><strong>Example Function:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="bar() {
    # Usage: bar 1 10
    #            ^----- Elapsed Percentage (0-100).
    #               ^-- Total length in chars.
    ((elapsed=$1*$2/100))

    # Create the bar with spaces.
    printf -v prog  &quot;%${elapsed}s&quot;
    printf -v total &quot;%$(($2-elapsed))s&quot;

    printf '%s\r' &quot;[${prog// /-}${total}]&quot;
}"><pre><span>bar</span>() {
    <span><span>#</span> Usage: bar 1 10</span>
    <span><span>#</span>            ^----- Elapsed Percentage (0-100).</span>
    <span><span>#</span>               ^-- Total length in chars.</span>
    <span><span>((</span>elapsed<span>=</span><span>$1</span><span>*</span><span>$2</span><span>/</span><span>100</span><span>))</span></span>

    <span><span>#</span> Create the bar with spaces.</span>
    <span>printf</span> -v prog  <span><span>"</span>%<span>${elapsed}</span>s<span>"</span></span>
    <span>printf</span> -v total <span><span>"</span>%<span><span>$((</span><span>$2</span><span>-</span>elapsed<span>))</span></span>s<span>"</span></span>

    <span>printf</span> <span><span>'</span>%s\r<span>'</span></span> <span><span>"</span>[<span>${prog<span>//</span> <span>/</span>-}${total}</span>]<span>"</span></span>
}</pre></div>
<p dir="auto"><strong>Example Usage:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="for ((i=0;i<=100;i++)); do
    # Pure bash micro sleeps (for the example).
    (:;:) &amp;&amp; (:;:) &amp;&amp; (:;:) &amp;&amp; (:;:) &amp;&amp; (:;:)

    # Print the bar.
    bar &quot;$i&quot; &quot;10&quot;
done

printf '\n'"><pre><span>for</span> <span><span>((</span>i<span>=</span><span>0</span>;i<span>&lt;=</span><span>100</span>;i<span>++</span><span>))</span></span><span>;</span> <span>do</span>
    <span><span>#</span> Pure bash micro sleeps (for the example).</span>
    (:<span>;</span>:) <span>&amp;&amp;</span> (:<span>;</span>:) <span>&amp;&amp;</span> (:<span>;</span>:) <span>&amp;&amp;</span> (:<span>;</span>:) <span>&amp;&amp;</span> (:<span>;</span>:)

    <span><span>#</span> Print the bar.</span>
    bar <span><span>"</span><span>$i</span><span>"</span></span> <span><span>"</span>10<span>"</span></span>
<span>done</span>

<span>printf</span> <span><span>'</span>\n<span>'</span></span></pre></div>
<h2 tabindex="-1" dir="auto">Get the list of functions in a script</h2>
<div dir="auto" data-snippet-clipboard-copy-content="get_functions() {
    # Usage: get_functions
    IFS=$'\n' read -d &quot;&quot; -ra functions < <(declare -F)
    printf '%s\n' &quot;${functions[@]//declare -f }&quot;
}"><pre><span>get_functions</span>() {
    <span><span>#</span> Usage: get_functions</span>
    IFS=<span><span>$'</span><span>\n</span><span>'</span></span> <span>read</span> -d <span><span>"</span><span>"</span></span> -ra functions <span>&lt;</span> <span><span>&lt;(</span>declare -F<span>)</span></span>
    <span>printf</span> <span><span>'</span>%s\n<span>'</span></span> <span><span>"</span><span>${functions[@]<span>//</span>declare -f }</span><span>"</span></span>
}</pre></div>
<h2 tabindex="-1" dir="auto">Bypass shell aliases</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# alias
ls

# command
# shellcheck disable=SC1001
\ls"><pre><span><span>#</span> alias</span>
ls

<span><span>#</span> command</span>
<span><span>#</span> shellcheck disable=SC1001</span>
<span>\l</span>s</pre></div>
<h2 tabindex="-1" dir="auto">Bypass shell functions</h2>
<div dir="auto" data-snippet-clipboard-copy-content="# function
ls

# command
command ls"><pre><span><span>#</span> function</span>
ls

<span><span>#</span> command</span>
<span>command</span> ls</pre></div>
<h2 tabindex="-1" dir="auto">Run a command in the background</h2>
<p dir="auto">This will run the given command and keep it running, even after the terminal or SSH connection is terminated. All output is ignored.</p>
<div dir="auto" data-snippet-clipboard-copy-content="bkr() {
    (nohup &quot;$@&quot; &amp;>/dev/null &amp;)
}

bkr ./some_script.sh # some_script.sh is now running in the background"><pre><span>bkr</span>() {
    (nohup <span><span>"</span><span>$@</span><span>"</span></span> <span>&amp;</span><span>&gt;</span>/dev/null <span>&amp;</span>)
}

bkr ./some_script.sh <span><span>#</span> some_script.sh is now running in the background</span></pre></div>
<h2 tabindex="-1" dir="auto">Capture the return value of a function without command substitution</h2>
<p dir="auto"><strong>CAVEAT:</strong> Requires <code>bash</code> 4+</p>
<p dir="auto">This uses local namerefs to avoid using <code>var=$(some_func)</code> style command substitution for function output capture.</p>
<div dir="auto" data-snippet-clipboard-copy-content="to_upper() {
  local -n ptr=${1}

  ptr=${ptr^^}
}

foo=&quot;bar&quot;
to_upper foo
printf &quot;%s\n&quot; &quot;${foo}&quot; # BAR"><pre><span>to_upper</span>() {
  <span>local</span> -n ptr=<span>${1}</span>

  ptr=<span>${ptr^^}</span>
}

foo=<span><span>"</span>bar<span>"</span></span>
to_upper foo
<span>printf</span> <span><span>"</span>%s\n<span>"</span></span> <span><span>"</span><span>${foo}</span><span>"</span></span> <span><span>#</span> BAR</span></pre></div>

<h2 tabindex="-1" dir="auto">AFTERWORD</h2>
<p dir="auto">Thanks for reading! If this bible helped you in any way and you'd like to give back, consider donating. Donations give me the time to make this the best resource possible. Can't donate? That's OK, star the repo and share it with your friends!</p>
<p dir="auto"><a href="https://www.patreon.com/dyla" rel="nofollow"><img src="https://camo.githubusercontent.com/a1058908722b7ab43ef7088cb4af336c109dba99427310c1360a81a1a104e828/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f6e6174652d70617472656f6e2d79656c6c6f772e737667" data-canonical-src="https://img.shields.io/badge/donate-patreon-yellow.svg"></a></p>
<p dir="auto">Rock on. 🤘</p>
</article>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Testing Intel’s Arc A770 GPU for Deep Learning (165 pts)]]></title>
            <link>https://christianjmills.com/posts/arc-a770-testing/part-2/</link>
            <guid>37057332</guid>
            <pubDate>Wed, 09 Aug 2023 00:35:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christianjmills.com/posts/arc-a770-testing/part-2/">https://christianjmills.com/posts/arc-a770-testing/part-2/</a>, See on <a href="https://news.ycombinator.com/item?id=37057332">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">



<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#initial-headaches">Initial Headaches</a></li>
<li><a href="#training-performance-on-native-ubuntu">Training Performance on Native Ubuntu</a></li>
<li><a href="#training-performance-on-wsl">Training Performance on WSL</a></li>
<li><a href="#closing-thoughts">Closing Thoughts</a></li>
</ul>
<section id="series-links">
<h2 data-anchor-id="series-links">Series Links</h2>
<ul>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-1/">Part 1</a>: I tested inference performance with OpenVINO and DirectML on the A770 and attempted to train models using PyTorch-DirectML.</li>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-2/">Part 2</a>: I trained image classification models with Intel’s PyTorch extension on the Arc A770 GPU.</li>
<li><a href="https://christianjmills.com/posts/arc-a770-testing/part-3/">Part 3</a>: I trained style transfer models and ran Stable Diffusion 2.1 using 🤗 Diffusers with Intel’s PyTorch extension on the Arc A770.</li>
<li><a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu</a>: This tutorial provides a step-by-step guide to setting up Intel’s PyTorch extension on Ubuntu to train models with Arc GPUs</li>
</ul>
</section>
<section id="introduction">
<h2 data-anchor-id="introduction">Introduction</h2>
<p><a href="https://christianjmills.com/posts/arc-a770-testing/part-1/">Last October</a>, I wrote about my findings from testing the inference performance of Intel’s <a href="https://www.intel.com/content/www/us/en/products/sku/229151/intel-arc-a770-graphics-16gb/specifications.html">Arc A770</a> GPU using <a href="https://docs.openvino.ai/2022.3/home.html">OpenVINO</a> and <a href="https://learn.microsoft.com/en-us/windows/ai/directml/dml">DirectML</a>. I also attempted to train various models with the <a href="https://pypi.org/project/pytorch-directml/">PyTorch-DirectML</a> package. The card did well on inference, especially with Intel’s OpenVINO library. However, the PyTorch-DirectML package was incomplete, and I could not adequately test the card’s training performance.</p>
<p>Shortly after that post, Intel released an <a href="https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.10.200%2Bgpu">extension for PyTorch</a>, which added support for Intel GPUs. Based on my initial testing, I decided the extension was not in a state that warranted a follow-up post. In hindsight, I don’t believe the initial release officially supported Arc GPUs. The <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.10.200+gpu/tutorials/installation.html#hardware-requirement">installation guide</a> for that version only mentions data center GPUs.</p>
<p>Since then, Intel has released a couple of updates for the extension, the most <a href="https://github.com/intel/intel-extension-for-pytorch/releases/tag/v1.13.120%2Bxpu">recent</a> being about a month ago at the time of writing. Unlike the initial release, this version lists Arc GPUs as having <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/1.13.120+xpu/tutorials/installation.html#hardware-requirement">experimental support</a>. Given that and the driver improvements for Windows and Linux, I decided to pop the A770 back into my desktop and give it another shot. In short, it works now.</p>
<p>In this post, I discuss my experience getting Intel’s PyTorch extension running on Ubuntu and Windows Subsystem for Linux (WSL). I also cover my initial findings from training models. I’ll provide a tutorial for setting up and using the extension in a dedicated post.</p>
<ul>
<li><a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">Getting Started with Intel’s PyTorch Extension for Arc GPUs on Ubuntu</a></li>
</ul>
</section>
<section id="initial-headaches">
<h2 data-anchor-id="initial-headaches">Initial Headaches</h2>
<p>To be blunt, my initial attempts to get this working were a bit of a nightmare. The instructions required to enable support for Arc GPUs on Ubuntu and set up Intel’s PyTorch extension span across multiple sites and are sometimes contradictory. The instructions on some sites are outdated to the point of being impossible to follow.</p>
<p>For example, Intel’s Arc Graphics Driver for Ubuntu <a href="https://www.intel.com/content/www/us/en/download/747008/intel-arc-graphics-driver-ubuntu.html">page</a> provided a link to a separate documentation site with driver installation instructions.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-arc-graphics-driver-ubuntu-page.png"></p>
</figure>
</div>
<p>The instructions on the documentation site say to <a href="https://dgpu-docs.intel.com/installation-guides/ubuntu/ubuntu-jammy-arc.html#step-2-install-linux-kernel">install a specific Linux kernel</a>, <code>5.19.0-35</code>, which is <a href="https://www.ubuntuupdates.org/package/core/jammy/main/updates/linux-image-5.19.0-35-generic">no longer available</a>.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-dgpu-docs-ubuntu-driver-installation-instructions-install-kernel.png"></p>
</figure>
</div>
<p>Still, I attempted to follow the instructions on a new Ubuntu 22.04 install and a more recent <code>5.19</code> kernel. Trying to boot into Ubuntu on the Arc card with the <code>5.19</code> kernel results in the following error:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>snd_hda_intel</span> 0000:04:00.0 hsw/bdw hd-audio hdmi/dp requires binding with gfx driver</span></code></pre></div>
<p>The error is a known issue, and Intel even has a <a href="https://www.intel.com/content/www/us/en/support/articles/000092607/graphics.html">troubleshooting page</a> with a proposed workaround. Unfortunately, disabling the “Integrated graphics Multi-Monitor” BIOS option, as the page recommends, did not resolve the issue.</p>
<p>I decided to continue following the instructions on integrated graphics and see if I could use the Arc card once I installed all the driver packages. That attempt went so poorly that I had to pop out the motherboard’s CMOS battery to reset the BIOS.</p>
<p>I made several more attempts, which failed at various stages. Fortunately, I eventually got everything working, and my current setup process is pretty straightforward.</p>
<p>I ended up needing Linux kernel <code>6.2</code> or newer. That kernel version <a href="https://www.phoronix.com/news/Linux-6.2-Released">supports the Arc card</a> out of the box. You can install that kernel on Ubuntu 22.04, but I recommend just going with Ubuntu 23.04 (or newer) if starting from a fresh install. Ubuntu 23.04 already has a kernel version <code>≥6.2</code>, and I verified it works with Intel’s PyTorch extension.</p>
<p>As mentioned earlier, I’ll provide detailed instructions for the setup process in a dedicated post.</p>
</section>
<section id="training-performance-on-native-ubuntu">
<h2 data-anchor-id="training-performance-on-native-ubuntu">Training Performance on Native Ubuntu</h2>
<p>I used the training notebook from my recent <a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/">beginner PyTorch tutorial</a> for testing. That tutorial covers fine-tuning image classification models with PyTorch and the timm library by creating a hand gesture recognizer. Using the training notebook simplifies directly comparing the Arc A770 and my Titan RTX, which I used to create the tutorial. Nearly everything is identical for the testing environment down to the dataset location.</p>
<p>The one additional variable is that the tutorial uses PyTorch 2.0, while Intel’s PyTorch extension currently requires a <a href="https://intel.github.io/intel-extension-for-pytorch/xpu/latest/tutorials/installation.html#pytorch-intel-extension-for-pytorch-version-mapping">patched version</a> of PyTorch 1.13. However, I don’t use model compilation in the tutorial, so this should not be a significant factor.</p>
<p>The training notebook only required a few tweaks to use Intel’s PyTorch extension, with most of the code remaining unchanged. The extension even supports PyTorch’s <code>autocast()</code> context manager for mixed-precision training.</p>
<p>The first training session was alarmingly slow, with the first pass through the training set taking around 42 minutes and 30 seconds. However, the loss and accuracy values were comparable to those with the Titan RTX, so I let it run for a while. After the first epoch, passes through the training set fell to approximately 16 minutes and 50 seconds. The total training time was only a few minutes less than the free GPU tier on Google Colab. Strangely, the inference speed on the validation set was nearly identical to the Titan RTX.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-ubuntu-bad-memory-layout.png"></p>
</figure>
</div>
<p>We can get more insight into using the <code>intel-gpu-top</code> command-line tool. Below are the readouts from the first and third passes through the training set:</p>
<div>
<ul role="tablist"><li role="presentation"><a id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">First Pass</a></li><li role="presentation"><a id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Third Pass</a></li></ul>
<div>
<div id="tabset-1-1" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-gpu-top-arc-a770-usage-training-bad-memory-layout.png"></p>
</figure>
</div>
<div id="tabset-1-2" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-gpu-top-arc-a770-usage-training-bad-memory-layout-third-epoch.png"></p>
</figure>
</div>
</div>
</div>
<p>Note that the memory throughput for the first training pass is particularly low. Although, the third pass is not great, either.</p>
<p>After some investigation on the <a href="https://github.com/intel/intel-extension-for-pytorch/issues/296#issuecomment-1426537682">extension’s GitHub repository</a>, it appears the slow training time is due to the backward pass for some operations. Fortunately, the fix involved setting a <a href="https://github.com/intel/intel-extension-for-pytorch/issues/296#issuecomment-1461118993">single environment variable</a>.</p>
<p>After setting <code>IPEX_XPU_ONEDNN_LAYOUT=1</code>, the total training time is within 10% of my Titan RTX on the same system. The gap would be slightly wider if I compiled the model on the Titan with PyTorch 2.0.</p>
<p>We can see the difference with <code>intel-gpu-top</code>, which shows much higher memory throughput.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/intel-gpu-top-arc-a770-usage-training.png"></p>
</figure>
</div>
<p>The final loss and accuracy values fluctuate slightly, even when using fixed seed values for PyTorch, NumPy, and Python. However, they stay pretty close to the results on my Nvidia GPU.</p>
<p>Here is a screenshot of the training session with the Arc A770:</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-ubuntu.png"></p>
</figure>
</div>
<p>Here is a link to the training session with the Titan RTX:</p>
<ul>
<li><a href="https://christianjmills.com/posts/pytorch-train-image-classifier-timm-hf-tutorial/#train-the-model">Titan RTX training session</a></li>
</ul>
<pre><code>Epochs: 100%|█████████| 3/3 [11:15&lt;00:00, 224.96s/it]
Train: 100%|██████████| 4324/4324 [03:29&lt;00:00, 21.75it/s, accuracy=0.894, avg_loss=0.374, loss=0.0984, lr=0.000994]
Eval: 100%|██████████| 481/481 [00:17&lt;00:00, 50.42it/s, accuracy=0.975, avg_loss=0.081, loss=0.214, lr=]
Train: 100%|██████████| 4324/4324 [03:28&lt;00:00, 22.39it/s, accuracy=0.968, avg_loss=0.105, loss=0.0717, lr=0.000462]
Eval: 100%|██████████| 481/481 [00:16&lt;00:00, 55.14it/s, accuracy=0.988, avg_loss=0.0354, loss=0.02, lr=]
Train: 100%|██████████| 4324/4324 [03:28&lt;00:00, 21.94it/s, accuracy=0.99, avg_loss=0.0315, loss=0.00148, lr=4.03e-9]
Eval: 100%|██████████| 481/481 [00:16&lt;00:00, 53.87it/s, accuracy=0.995, avg_loss=0.0173, loss=0.000331, lr=]</code></pre>
<p>The training sessions for the A770 and the Titan both used mixed precision.</p>
<p>I also tested training on the Arc card with the newer 6.3 Linux kernel but did not see a notable performance difference versus the 6.2 Linux kernel.</p>
<p>Since Intel’s extension only recently added support for Arc cards, more performance may get unlocked in future updates. However, getting so close to the Titan RTX was already more than I had hoped.</p>
<p>I decided to move on and see how the extension performed in WSL.</p>
</section>
<section id="training-performance-on-wsl">
<h2 data-anchor-id="training-performance-on-wsl">Training Performance on WSL</h2>
<p>Now that I had a streamlined process for setting everything up on Ubuntu, getting WSL up and running was easy. It only required a subset of the steps compared to a bare-metal Ubuntu installation. I used the default <a href="https://apps.microsoft.com/store/detail/ubuntu/9PDXGNCFSCZV">Ubuntu terminal environment</a> and stuck with the included kernel.</p>
<p>Total training time in WSL is <code>≈34%</code> slower than in native Ubuntu with the dataset in the same virtual hard disk (VHD) that stores the WSL-Ubuntu install.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-wsl.png"></p>
</figure>
</div>
<p>I remember getting a similar performance hit the last time I used WSL with the Titan RTX. It’s one of the reasons I prefer to dual-boot Windows and Ubuntu.</p>
<p>Here is a screenshot of the GPU usage when running the training notebook on the A770 in WSL:</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/task-manager-pytorch-arc-a770-wsl-gpu-usage.png"></p>
</figure>
</div>
<p>There is an additional <code>≈20%</code> increase in training time when storing the dataset outside the VHD with the WSL-Ubuntu install.</p>
<div>
<figure>
<p><img src="https://christianjmills.com/posts/arc-a770-testing/part-2/images/arc-a770-pytorch-training-session-wsl-external-dataset.png"></p>
</figure>
</div>
<p>One workaround is to <a href="https://woshub.com/move-wsl-another-drive-windows/">move the WSL installation</a> to a larger drive if your <code>C</code> drive has limited space.</p>
<p>The performance hit makes it hard to recommend WSL for deep learning tasks. On top of that, the <a href="https://christianjmills.com/posts/pytorch-cuda-wsl2/#the-headaches">issues</a> I encountered when I first tested using PyTorch on WSL2 in 2020 are still present, at least on Windows 10.</p>
<p>Therefore, I recommend using a bare-metal installation to get the most out of your hardware. The Ubuntu website provides <a href="https://ubuntu.com/tutorials/install-ubuntu-desktop#1-overview">a step-by-step guide</a> to installing Ubuntu on your PC, and you can install it alongside an existing operating system.</p>
</section>
<section id="closing-thoughts">
<h2 data-anchor-id="closing-thoughts">Closing Thoughts</h2>
<p>My experience with the PyTorch-DirectML package and the first version of Intel’s extension left me thinking it would be a while before the Arc GPUs became viable options for deep learning.</p>
<p>Several months later, my initial attempts to get everything working last week had me thinking it would be even longer still. Fortunately, once you know the proper steps, setting everything up is relatively straightforward.</p>
<p>While there is much more testing to do, I believe the Arc GPUs are now credible options for deep learning.</p>
<p>There are likely still edge cases or certain operations that cause problems, and I’ll make updates to this post if I encounter any. I’ll also try to keep the <a href="https://christianjmills.com/posts/intel-pytorch-extension-tutorial/native-ubuntu/">setup tutorial</a> updated as new versions of Intel’s PyTorch extension come out.</p>


</section>

</main> <!-- /main -->
<!-- Cloudflare Web Analytics --><!-- End Cloudflare Web Analytics -->


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LK-99: Phonon bands, Localized Flat Band Magnetism, Models and Chemical Analysis (152 pts)]]></title>
            <link>https://drive.google.com/file/d/1ekD2KVV_SUid2wH__o1ODS3hTl1GUFb5/view</link>
            <guid>37055514</guid>
            <pubDate>Tue, 08 Aug 2023 21:11:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://drive.google.com/file/d/1ekD2KVV_SUid2wH__o1ODS3hTl1GUFb5/view">https://drive.google.com/file/d/1ekD2KVV_SUid2wH__o1ODS3hTl1GUFb5/view</a>, See on <a href="https://news.ycombinator.com/item?id=37055514">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Android 14 introduces first-of-its-kind cellular connectivity security features (368 pts)]]></title>
            <link>https://security.googleblog.com/2023/08/android-14-introduces-first-of-its-kind.html</link>
            <guid>37055479</guid>
            <pubDate>Tue, 08 Aug 2023 21:07:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://security.googleblog.com/2023/08/android-14-introduces-first-of-its-kind.html">https://security.googleblog.com/2023/08/android-14-introduces-first-of-its-kind.html</a>, See on <a href="https://news.ycombinator.com/item?id=37055479">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-version="1" id="header">
<div>
<p><a href="https://security.googleblog.com/">
<img height="50" src="https://www.gstatic.com/images/branding/googlelogo/2x/googlelogo_color_150x54dp.png">
</a></p><a href="https://security.googleblog.com/">
<h2>
            Security Blog
          </h2>
</a>
</div>
<p>
The latest news and insights from Google on security and safety on the Internet
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PackagingCon – a conference only for software package management (173 pts)]]></title>
            <link>https://packaging-con.org</link>
            <guid>37055368</guid>
            <pubDate>Tue, 08 Aug 2023 20:59:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://packaging-con.org">https://packaging-con.org</a>, See on <a href="https://news.ycombinator.com/item?id=37055368">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-block-type="2" id="block-yui_3_17_2_1_1685539580157_15383">
  <p>Today, practically every operating system, language ecosystem, and framework has one or more package managers. Package managers are a, if not the, major way of taming software complexity, integrating various ecosystems, components, and versions and ensuring they are managed (installed/updated/uninstalled) safely, reliably, and in a compatible manner on user systems.</p><p>Because package managers bridge the gap between developers and the end user, developing them requires a broad range of expertise in multiple areas, including language runtimes, OS policies, distribution management, dependency solving, and developer workflows.</p><p>Packaging Con seeks to bring various package management communities together, as a venue to discuss challenges and exchange ideas. What makes communities work together on a particular software ecosystem? Are the differences among package managers mainly in the implementation language, or are there other key distinctions to software management methodology? How can we get better interoperability and/or cooperation among package manager teams, and what's missing/required to enable that? Is dependency resolution fundamentally the same problem across systems, or does each package manager do it differently?</p><p>If any of these questions interest you, we want to hear from you! Packaging Con is a conference for developers of software package management tools, as well as software packagers and communities! Anyone is welcome to participate. Our mission is to bring different software ecosystems together: from Python’s pip to Rust’s cargo, from apt, rpm, and Nix to conda and mamba, and from vcpkg to spack, and from fpm to npm.</p><p><strong>Topics</strong></p><p>We encourage submissions in a wide range of areas related to package management, including but not limited to:</p><ul data-rte-list="default"><li><p>Deep dives on specific packaging systems</p></li><li><p>Software supply chains, pipelines, and security</p></li><li><p>Package build and release methodologies</p></li><li><p>Modeling software ecosystems in package managers</p></li><li><p>Modeling compatibility (semver, API/ABI analysis, etc.)</p></li><li><p>Interactions between package managers</p></li><li><p>Reproducibility in package managers</p></li><li><p>Reliability/robustness of software ecosystems</p></li><li><p>Dependency solving and management: modeling, methods, and scalability</p></li></ul><p>This list is by no means exhaustive — any topic related to package management is welcome to attend.<br></p><p><strong>Code of Conduct</strong></p><p>In the interest of fostering an open and welcoming environment, pledge to make participation in Packaging Con a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.</p><p>By participating in the conference you agree to abide to the <a href="https://numfocus.org/code-of-conduct" target="_blank">NumFOCUS Code of Conduct</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Last 1% (195 pts)]]></title>
            <link>https://jaredramsey.com/blog/20230808.html</link>
            <guid>37055280</guid>
            <pubDate>Tue, 08 Aug 2023 20:51:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jaredramsey.com/blog/20230808.html">https://jaredramsey.com/blog/20230808.html</a>, See on <a href="https://news.ycombinator.com/item?id=37055280">Hacker News</a></p>
<div id="readability-page-1" class="page"><div aria-label="Content">
    <header>
      
      <h4>2023-08-08</h4>
    </header>

    <p>
      You've done it. You've launched the next great feature. You've spent months working with your team to design, build, and test. It's
      in users' hands. You're done.
    </p>

    <p>But are you really? Probably not.</p>

    <p>I've seen (and been on) so many projects that claim success and move on to the next thing when they are 99% done and fail to 
      complete the last 1%. This last 1% isn't just what separates a great product from a good product, it's what separates a product that
      <i>might not</i> eventually fail from one that <i>will</i> eventually fail.
    </p>

    <p>
      So what's in this last 1%? Here are some of the most frequently skipped things I've seen:
    </p>

    <ul>
      <li>
        <p>Internal (maintenance) documentation</p>
      </li>
      <li>
        <p>External (how-to/FAQ) documentation</p>
      </li>
      <li>
        <p>Performance metric instrumentation</p>
      </li>
      <li>
        <p>Easy-to-decipher performance metric dashboard</p>
      </li>
      <li>
        <p>Usage metric instrumentation</p>
      </li>
      <li>
        <p>Easy-to-decipher usage metric dashboard</p>
      </li>
      <li>
        <p>Error metric instrumentation</p>
      </li>
      <li>
        <p>Easy-to-decipher error metric dashboard</p>
      </li>
      <li>
        <p>Alerting</p>
      </li>
      <li>
        <p>Automated testing</p>
      </li>
    </ul>

    <p>
      I know the temptation. I've been there many times myself. After months of hard work and sleepless nights, you want to put it behind
      you and move on to the next thing. But don't. Take the time to finish the last 1%. It's worth it.
    </p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA Approves First Oral Treatment for Postpartum Depression (123 pts)]]></title>
            <link>https://www.fda.gov/news-events/press-announcements/fda-approves-first-oral-treatment-postpartum-depression</link>
            <guid>37055210</guid>
            <pubDate>Tue, 08 Aug 2023 20:45:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fda.gov/news-events/press-announcements/fda-approves-first-oral-treatment-postpartum-depression">https://www.fda.gov/news-events/press-announcements/fda-approves-first-oral-treatment-postpartum-depression</a>, See on <a href="https://news.ycombinator.com/item?id=37055210">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                                 <article id="main-content" role="article">
          
                                                                <header role="heading" aria-level="1">
                         






                      </header>
                              
                                                                           <div role="main">

                            
                            
                            
                            
                                              
    <div>
    <dl>
        <dt>For Immediate Release:</dt>
                  <dd><time datetime="2023-08-04T22:48:00Z">August 04, 2023</time>
</dd>
                 
                
      </dl>
    </div>
 

  
      
       

  <p><a href="https://www.fda.gov/news-events/press-announcements/la-fda-aprueba-el-primer-tratamiento-oral-para-la-depresion-posparto"><span>Spanish</span></a></p>

<p>Today, the U.S. Food and Drug Administration approved <a href="https://www.accessdata.fda.gov/drugsatfda_docs/label/2023/217369s000lbl.pdf">Zurzuvae</a> (zuranolone), the first oral medication indicated to treat postpartum depression (PPD) in adults. PPD is a major depressive episode that typically occurs after childbirth but can also begin during the later stages of pregnancy. Until now, treatment for PPD was only available as an IV injection given by a health care provider in certain health care facilities.</p>

<p><strong>“Postpartum depression is a serious and potentially life-threatening condition in which women experience sadness, guilt, worthlessness—even, in severe cases, thoughts of harming themselves or their child. And, because postpartum depression can disrupt the maternal-infant bond, it can also have consequences for the child’s physical and emotional development,” said Tiffany R. Farchione, M.D., director of the Division of Psychiatry in the FDA’s Center for Drug Evaluation and Research. “Having access to an oral medication will be a beneficial option for many of these women coping with extreme, and sometimes life-threatening, feelings.”</strong></p>

<p>As with other forms of depression, PPD is characterized by sadness and/or loss of interest in activities that one used to enjoy and a decreased ability to feel pleasure. It can present with symptoms such as cognitive impairment, feelings of sadness or inadequacy, loss of energy or suicidal ideation.&nbsp;</p>

<p>The efficacy of Zurzuvae for the treatment of PPD in adults was demonstrated in two randomized, double-blind, placebo-controlled, multicenter studies. The trial participants were women with PPD who met the Diagnostic and Statistical Manual of Mental Disorders criteria for a major depressive episode and whose symptoms began in the third trimester or within four weeks of delivery. In Study 1, patients received 50 mg of Zurzuvae or placebo once daily in the evening for 14 days. In Study 2, patients received another zuranolone product that was approximately equal to 40 mg of Zurzuvae or placebo, also for 14 days. Patients in both studies were monitored for at least four weeks after the 14-day treatment. The primary endpoint of both studies was the change in depressive symptoms using the total score from the 17-item Hamilton depression rating scale (HAMD-17), measured at day 15. Patients in the Zurzuvae groups showed significantly more improvement in their symptoms compared to those in the placebo groups. The treatment effect was maintained at Day 42—four weeks after the last dose of Zurzuvae.</p>

<p>The labeling contains a boxed warning noting that Zurzuvae can impact a person’s ability to drive and perform other potentially hazardous activities. Patients also may not be able to assess their degree of impairment. To reduce the risk of harm, patients should not drive or operate heavy machinery for at least 12 hours after taking Zurzuvae.&nbsp;</p>

<p>The most common side effects include drowsiness, dizziness, diarrhea, fatigue, nasopharyngitis (the common cold), and urinary tract infection. Use of Zurzuvae may cause suicidal thoughts and behavior. Zurzuvae may cause fetal harm. Women should use effective contraception while taking, and for one week after taking, Zurzuvae.</p>

<p>The daily recommended dose for Zurzuvae is 50mg. It should be taken once every day, for 14 days, in the evening with a fatty meal.&nbsp;</p>

<p>The FDA granted this application <a href="https://www.fda.gov/patients/fast-track-breakthrough-therapy-accelerated-approval-priority-review/priority-review">Priority Review</a> and <a href="https://www.fda.gov/patients/fast-track-breakthrough-therapy-accelerated-approval-priority-review/fast-track">Fast Track</a> designation.</p>

<p>Approval of Zurzuvae was granted to Sage Therapeutics, Inc.</p>



  <h2>Related Information</h2>
  
  

<p>###</p>
  <div data-quickedit-field-id="node/418768/field_generic_long_text/en/full">
      <p>Boilerplate</p>
      <p>The FDA, an agency within the U.S. Department of Health and Human Services, protects the public health by assuring the safety, effectiveness, and security of human and veterinary drugs, vaccines and other biological products for human use, and medical devices. The agency also is responsible for the safety and security of our nation’s food supply, cosmetics, dietary supplements, products that give off electronic radiation, and for regulating tobacco products.</p>
    </div>
<hr>

<div>
  <h2>Inquiries</h2>
  
    
        
         
  </div>
 
<br>


              
                                            
              
            </div>

                                                                                  
            

                                                                                
            
                 </article>        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Milk Sad: Weak Entropy in libbitcoin (bc) seed generation (118 pts)]]></title>
            <link>https://milksad.info/</link>
            <guid>37054862</guid>
            <pubDate>Tue, 08 Aug 2023 20:14:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://milksad.info/">https://milksad.info/</a>, See on <a href="https://news.ycombinator.com/item?id=37054862">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <p><img src="https://milksad.info/assets/base/milksad_transparent.svg" width="30%"></p>

<h2 id="milk-sad-disclosure">Milk Sad Disclosure</h2>

<p>A practical explanation of how weak entropy can ruin your day - and your savings.</p>

<h2 id="vulnerability-cve-2023-39910">Vulnerability <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2023-39910">CVE-2023-39910</a></h2>

<ul>
  <li>We discovered a cryptographic weakness in the widely utilized <code>Libbitcoin Explorer</code> (<code>bx</code>) cryptocurrency wallet tool while following up on mysterious wallet thefts.</li>
  <li>The <code>bx seed</code> subcommand for generation of new wallet private key entropy is flawed and produces insecure output.</li>
  <li>On <code>Libbitcoin Explorer</code> <code>3.x</code> versions, <code>bx seed</code> uses the <a href="https://en.wikipedia.org/wiki/Mersenne_Twister#Disadvantages">Mersenne Twister</a> pseudorandom number generator (PRNG) <a href="https://github.com/libbitcoin/libbitcoin-system/blob/a1b777fc51d9c04e0c7a1dec5cc746b82a6afe64/src/crypto/pseudo_random.cpp#L77">initialized</a> with 32 bits of system time.</li>
  <li>Bad actors have discovered this flaw and are actively exploiting it to steal funds from affected wallets on multiple blockchains.</li>
  <li>We have reasons to believe some <code>Libbitcoin Explorer</code> versions before <code>3.0.0</code> also produce weak <code>bx seed</code> output in some system environments.</li>
  <li>Think of this as securing your online bank account with a password manager that creates a long random password, but it often creates the same passwords for every user. Malicious people have figured this out and drained funds on any account they can find.</li>
</ul>

<h2 id="how">How?</h2>
<div>
    <p><img width="100%" src="https://milksad.info/assets/base/bx-mastering-bitcoin.png"></p><p>
        Mastering Bitcoin - Second Edition by Andreas M. Antonopoulos LLC is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.
    </p>
</div>
<ul>
  <li>Popular documentation like “<a href="https://bitcoinbook.info/">Mastering Bitcoin</a>” suggests the usage of <code>bx seed</code> for wallet generation.</li>
  <li>Secure cryptography requires a source of large, non-guessable numbers. If the random number generator is weak, the resulting cryptographic usage is almost always compromised.</li>
  <li>For technical people: in this case, practical wallet security is reduced from 128 bit, 192 bit or 256 bit to a mere 32 bit of unknown key information.</li>
  <li>A 32 bit key space is 2^32, or 4,294,967,296 different unique combinations of derived <a href="https://milksad.info/(https://en.bitcoin.it/wiki/BIP_0039)">BIP39</a> mnemonic phrases or other key formats (<a href="https://en.bitcoin.it/wiki/BIP_0032">BIP32</a>). Spoiler: That’s not as many combinations as it sounds.</li>
  <li>With enough optimizations, a decent gaming PC can do a brute-force search through 2^32 wallet combinations in less than a day.</li>
  <li>Since <code>bx</code> has a configurable output length and can be used in several ways, there are a few variations the attacker needs to test for each case. This slows down practical attacks to a few days.</li>
  <li>Once an attacker finds a match of a wallet candidate with an actual wallet used on a blockchain, they are in full possession of the private keys and can steal remaining funds, trace all previous wallet history and sign messages.</li>
  <li>The attack works independent of the owner’s current copy of the wallet secrets. In other words, even if you keep your paper wallet in a bank safe, your funds can still be stolen remotely. Crazy, right?</li>
  <li>Attackers are actively exploiting this and have been draining funds of wallets where the mnemonic was generated using this tool.</li>
  <li>Why the silly “Milk Sad” name? Running <code>bx seed</code> on <code>3.x</code> versions with a system time of 0.0 always generates the following secret:
    <blockquote>
      <p>milk sad wage cup reward umbrella raven visa give list decorate bulb gold raise twenty fly manual stand float super gentle climb fold park</p>
    </blockquote>
  </li>
</ul>

<h2 id="when">When?</h2>
<p>The main theft occurred around 12 July 2023, although initial exploitation likely began at a smaller scale in May 2023.</p>

<p>A separate but similar vulnerability in another wallet software was detected in November 2022 and actively exploited shortly after, which may be the prequel to this story.</p>

<h2 id="who">Who?</h2>
<p>We did not identify who is behind the ongoing thefts from vulnerable wallets.</p>

<h2 id="type">Type</h2>

<p><a href="https://cwe.mitre.org/data/definitions/338.html">CWE-338: Use of Cryptographically Weak Pseudo-Random Number Generator (PRNG)</a></p>

<h2 id="vendor">Vendor</h2>

<p><a href="https://github.com/libbitcoin">Libbitcoin</a></p>

<h2 id="further-reading">Further Reading</h2>

<p>See our <a href="https://milksad.info/disclosure.html">technical writeup</a> and <a href="https://milksad.info/faq.html">FAQ</a>.</p>

<p><a href="https://nvd.nist.gov/vuln/detail/CVE-2023-31290">CVE-2023-31290</a> was a similar vulnerability in <a href="https://community.trustwallet.com/t/browser-extension-wasm-vulnerability-postmortem/750787">Trust Wallet</a>, see <a href="https://blog.ledger.com/Funds-of-every-wallet-created-with-the-Trust-Wallet-browser-extension-could-have-been-stolen/">Ledger Donjon’s technical writeup</a>.</p>



<ul>
  <li>General requests and comments: email <a href="mailto:team@milksad.info">team@milksad.info</a></li>
  <li>Press: email <a href="mailto:press@milksad.info">press@milksad.info</a></li>
</ul>

<h2 id="team--credits">Team &amp; Credits</h2>

<ul>
  <li>Core Team
    <ul>
      <li>Distrust
        <ul>
          <li>Anton Livaja - <a href="mailto:anton@distrust.co">anton@distrust.co</a></li>
          <li>Lance R. Vick - <a href="mailto:lance@distrust.co">lance@distrust.co</a>, <a href="https://lance.dev/">https://lance.dev</a></li>
          <li>Ryan Heywood - <a href="mailto:ryan@distrust.co">ryan@distrust.co</a>, <a href="https://ryansquared.pub/">https://ryansquared.pub</a></li>
          <li>Shane Engelman - <a href="mailto:shane@distrust.co">shane@distrust.co</a></li>
        </ul>
      </li>
      <li>Independent
        <ul>
          <li>Christian Reitter - <a href="https://inhq.net/">https://inhq.net</a></li>
          <li>Daniel Grove - <a href="mailto:danny@dannygrove.com">danny@dannygrove.com</a></li>
          <li>Dustin Johnson - <a href="mailto:_@di0.io">_@di0.io</a></li>
          <li>Heiko Schaefer - <a href="mailto:heiko@schaefer.name">heiko@schaefer.name</a></li>
          <li>James Callahan - <a href="mailto:james@wavesquid.com">james@wavesquid.com</a></li>
          <li>Jochen Hoenicke - <a href="https://jhoenicke.de/">https://jhoenicke.de</a></li>
          <li>John Naulty - <a href="mailto:jnaulty@dendritictech.com">jnaulty@dendritictech.com</a></li>
          <li>Matthew Brooks - <a href="mailto:*@logicwax.com">*@logicwax.com</a></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Special Thanks
    <ul>
      <li>Jack Kearney - <a href="https://turnkey.com/">Turnkey</a></li>
      <li>Several trusted advisors that wish to remain uncredited. You know who you are.</li>
    </ul>
  </li>
</ul>


  <br> 
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[mCaptcha: Open-source proof-of-work captcha for websites (191 pts)]]></title>
            <link>https://mcaptcha.org/</link>
            <guid>37054670</guid>
            <pubDate>Tue, 08 Aug 2023 19:59:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mcaptcha.org/">https://mcaptcha.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37054670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div>
        <h2>Privacy focused</h2>
        <p>Doesn't track, doesn't profile your users.</p>
      </div>
      <div>
        <h2>Robust and Accurate</h2>
        <p>Got users behind <a href="https://en.wikipedia.org/wiki/Network_address_translation">NATs</a>? No issues. We don't use IP address for rate-liming. NAT or not you get the mCaptcha experience.
      </p></div>
      <div>
        <h2>Best-in-class UX</h2>
        <p>mCaptcha is silent, so silent that your users won't even feel it. No more annoying images, no more helping for Big Brothers with their ML stuff</p>
      </div>
    </div><div>
      <div>
        <h2>Defend like castles</h2>
        <p>Our <a href="https://en.wikipedia.org/wiki/Proof_of_work">PoW</a>-based solution defends fierily. mCaptcha makes attacking your site more expensive than what it will take for you to respond to the attacker's requests</p>
      </div>
      <div>
        <h2>Libre Software</h2>
        <p>Client libraries are licensed using proprietary-friendly free software licenses but the core is <a href="http://www.gnu.org/licenses/agpl-3.0">AGPL'd</a>. We believe this is a tech that can change the way the web works so mCaptcha will always be free</p>
      </div>
      <div>
        <h2>xCaptcha drop-in replacement</h2>
        <p>Already using a captcha solution? No worries, our APIs are compatible with reCAPTCHA and hCaptcha!</p>
      </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Easyful – A Free Gumroad Alternative (143 pts)]]></title>
            <link>https://www.easyful.com/</link>
            <guid>37054374</guid>
            <pubDate>Tue, 08 Aug 2023 19:36:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.easyful.com/">https://www.easyful.com/</a>, See on <a href="https://news.ycombinator.com/item?id=37054374">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" data-framer-hydrate-v2="{&quot;routeId&quot;:&quot;augiA20Il&quot;,&quot;localizationId&quot;:&quot;default&quot;,&quot;localeId&quot;:&quot;default&quot;}" data-framer-ssr-released-at="2023-08-01T10:44:16.392Z" data-framer-page-optimized-at="2023-08-08T19:50:04.641Z"><header data-framer-name="INTRO" id="home" name="INTRO"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="YAP816Y5n">Digital commerce  <!-- --><br>made easy.<!-- --></h2></p><p data-styles-preset="zVhCDKUao">Start selling online with zero code, and zero fees.</p><div data-framer-name="Coin 01" name="Coin 01"><p><img src="https://framerusercontent.com/images/0rvsDsB9h8G04mprhTTQttuOn0.svg" alt=""></p></div><div data-framer-name="Coin 02" name="Coin 02"><p><img src="https://framerusercontent.com/images/PdGviToKtYqUZqcFvWNYcfUCNrE.svg" alt=""></p></div><div data-framer-name="Coin 03" name="Coin 03"><p><img src="https://framerusercontent.com/images/BroYq3lT9pFczsBrMk8lGlAYr0.svg" alt=""></p></div><div data-framer-name="Coin 04" name="Coin 04"><p><img src="https://framerusercontent.com/images/BDr5HT0VwXL1muHEtMk2fc8oN8.svg" alt=""></p></div></header><header data-framer-name="Deep Dive" name="Deep Dive"><p data-styles-preset="uE2d3cdGl">Sell directly on the internet’s largest payment processor, Stripe. Payments are between you, your customers, and Stripe (the payment processor). We just deliver the product.</p></header><header data-framer-name="Walkthrough" id="how-it-works" name="Walkthrough"></header><header data-border="true" data-framer-name="Cost Breakdown" name="Cost Breakdown"><div data-border="true"><div><p data-styles-preset="uE2d3cdGl">Instead, own your own Stripe account and pay no additional fees.</p></div><div data-framer-name="graphic" name="graphic"><p><img src="https://framerusercontent.com/images/uM9mZuJE5p0c5NvdUb3doGZ1F8.svg" alt="" loading="lazy"></p></div></div><div><div data-framer-name="COINS" name="COINS"><div data-framer-name="Coin 05" name="Coin 05"><p><img src="https://framerusercontent.com/images/8NjxbTDoa8teaWLaT48vVVBmA.svg" alt="" loading="lazy"></p></div><div data-framer-name="Coin 05" name="Coin 05"><p><img src="https://framerusercontent.com/images/8NjxbTDoa8teaWLaT48vVVBmA.svg" alt="" loading="lazy"></p></div></div><div data-framer-name="Competitor" name="Competitor"><p data-styles-preset="uE2d3cdGl">Easyful (Stripe's CC Fee)</p><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="PmrRAv8Rz">$1,750</h2></p></div><p data-styles-preset="xZndidUCt">Assumes an avg transaction of $50</p></div></header><header data-border="true" data-framer-name="Leverage Stripe" name="Leverage Stripe"><div data-border="true"><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="fVxnimdqP">Leverage the power of Stripe’s Eco-System.</h2></p></div></header><header data-border="true" data-framer-name="No Code" name="No Code"><div><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="fVxnimdqP">Zero Code Needed.</h2></p><p data-styles-preset="uE2d3cdGl">Simply create a product in Stripe, add your file with easyful, and create a payment link. Just like that you’re ready to start selling to anyone, anywhere, on any device!</p></div></header><header data-framer-name="Jumbo CTA" id="pricing" name="Jumbo CTA"><div><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="YAP816Y5n">Start selling for free,</h2></p><p data-framer-component-type="RichTextContainer"><h2 data-styles-preset="cjxW95kHD">and keep selling for free.</h2></p></div></header></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Low-cost Smartwatch powered by ESP32 module (218 pts)]]></title>
            <link>https://linuxgizmos.com/low-cost-smartwatch-powered-by-esp32-s3-module/</link>
            <guid>37054361</guid>
            <pubDate>Tue, 08 Aug 2023 19:35:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linuxgizmos.com/low-cost-smartwatch-powered-by-esp32-s3-module/">https://linuxgizmos.com/low-cost-smartwatch-powered-by-esp32-s3-module/</a>, See on <a href="https://news.ycombinator.com/item?id=37054361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-87220">
			

		<p><small>Aug 7, 2023 — by Giorgio Mendoza </small></p><!-- tag for gapp post pageviews plugin -->
    <!-- tag for Post Views for JetPack Plugin -->
 <p><small>4,110 views</small></p><div>
				
<p><img decoding="async" src="https://linuxgizmos.com/files/T-Watch-S3-1-117x125.png" alt="" width="98" height="105" srcset="https://linuxgizmos.com/files/T-Watch-S3-1-117x125.png 117w, https://linuxgizmos.com/files/T-Watch-S3-1-420x450.png 420w, https://linuxgizmos.com/files/T-Watch-S3-1.png 454w" sizes="(max-width: 98px) 100vw, 98px"></p>
<p><span>The T-Watch S3 from LILYGO is an open-source device built around the ESP32-S3 SoC with Wi-Fi and BLE connectivity. The device also includes an 1.54” LCD display with capacitive touch capabilities and Arduino support. </span></p>

<p><span>Unlike the SQFMI <a href="https://linuxgizmos.com/open-source-smartwatch-integrates-esp32-mcu/">Watchy</a> which is based on the ESP32-PICO-D4 microcontroller, the new smartwatch by LILYGO features the following ESP32 System-on-Chip:</span></p>
<ul>
<li><b><a href="https://www.espressif.com/en/products/socs/esp32-s3">ESP32-S3</a> – </b><span>Xtensa 32-bit LX7 dual core, (up to 240MHz)</span></li>
</ul>
<center><br>
<a href="https://linuxgizmos.com/files/T-WATCH-S3-peripherals.png"><img decoding="async" loading="lazy" src="https://linuxgizmos.com/files/T-WATCH-S3-peripherals-450x315.png" alt="" width="266" height="186" srcset="https://linuxgizmos.com/files/T-WATCH-S3-peripherals-450x315.png 450w, https://linuxgizmos.com/files/T-WATCH-S3-peripherals-1024x717.png 1024w, https://linuxgizmos.com/files/T-WATCH-S3-peripherals-125x88.png 125w, https://linuxgizmos.com/files/T-WATCH-S3-peripherals.png 1045w" sizes="(max-width: 266px) 100vw, 266px"></a><br>
<center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><strong> T-Watch S3 peripherals</strong><br>
<center>(click image to enlarge)</center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>
<p><span>For connectivity, the smartwatch features the Semtech SX1262 low power LoRa Transceiver, supporting frequencies of 433Mhz, 868Mhz, and 915Mhz.&nbsp;</span></p>
<p><span>The T-Watch S3 comes with a 1.54″ LCD display with a resolution of 240 x 240 and capacitive touch technology, a class D amplifier along with a PDM microphone. </span></p>
<center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center><center><span><iframe loading="lazy" width="640" height="360" src="https://www.youtube.com/embed/C0xP_NSG75o?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en-US&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</center>
<p><span>Another feature of the T-Watch S3 is the DRV2605 from Texas Instruments, which is described as a highly flexible haptic control device for ERM and LRA actuators.&nbsp;</span></p>
<p><span>LILYGO indicates that the smartwatch supports MicroPython, ESP-IDF, VS Code and the Arduino IDE. Additionally, the company includes a <a href="https://github.com/Xinyuan-LilyGO/TTGO_TWatch_Library/tree/t-watch-s3">GitHub</a> repository and a <a href="https://t-watch-document-en.readthedocs.io/en/latest/introduction/product/2020.html#description">wiki</a> page for documentation. See the recent demo above for more details.</span></p>
<center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center><center><a href="https://linuxgizmos.com/files/T-WATCH-S3-dimensions.png"><img decoding="async" loading="lazy" src="https://linuxgizmos.com/files/T-WATCH-S3-dimensions-450x423.png" alt="" width="214" height="201" srcset="https://linuxgizmos.com/files/T-WATCH-S3-dimensions-450x423.png 450w, https://linuxgizmos.com/files/T-WATCH-S3-dimensions-1024x963.png 1024w, https://linuxgizmos.com/files/T-WATCH-S3-dimensions-125x118.png 125w, https://linuxgizmos.com/files/T-WATCH-S3-dimensions.png 1030w" sizes="(max-width: 214px) 100vw, 214px"></a> &nbsp; <a href="https://linuxgizmos.com/files/T-Watch-S3.png"><img decoding="async" loading="lazy" src="https://linuxgizmos.com/files/T-Watch-S3-420x450.png" alt="" width="214" height="229" srcset="https://linuxgizmos.com/files/T-Watch-S3-420x450.png 420w, https://linuxgizmos.com/files/T-Watch-S3-117x125.png 117w, https://linuxgizmos.com/files/T-Watch-S3.png 454w" sizes="(max-width: 214px) 100vw, 214px"></a> &nbsp;</center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><strong> T-Watch S3 dimensions</strong><br>
<center>(click images to enlarge)</center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center><center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center></center>
<p><span>Specifications listed for the T-Watch S3 include:&nbsp;</span></p>
<ul>
<li aria-level="1"><span>Memory/Storage:</span>
<ul>
<li aria-level="2"><span>8MB PSRAM</span></li>
<li aria-level="2"><span>16MB Flash</span></li>
</ul>
</li>
<li aria-level="1"><span>Connectivity:</span>
<ul>
<li aria-level="2"><span>Wi-Fi 802.11 b/g/n</span></li>
<li aria-level="2"><span>BLE V5.0</span></li>
<li aria-level="2"><span>Semtech <a href="https://www.semtech.com/products/wireless-rf/lora-connect/sx1262">SX1262</a></span></li>
</ul>
</li>
<li aria-level="1"><span>Display:</span>
<ul>
<li aria-level="2"><span>1.54” LCD (ST7789V)</span></li>
</ul>
</li>
<li aria-level="1"><span>USB:</span>
<ul>
<li aria-level="2"><span>1x USB Port &amp; OTG</span></li>
</ul>
</li>
<li aria-level="1"><span>I/O Peripherals:</span>
<ul>
<li aria-level="2"><span>Microphone</span></li>
<li aria-level="2"><span>Class D amplifier (<a href="https://www.analog.com/media/en/technical-documentation/data-sheets/MAX98357A-MAX98357B.pdf">MAX98357A</a>)</span></li>
<li aria-level="2"><span>12-bit Triaxial acceleration sensor (<a href="https://www.mouser.com/datasheet/2/783/BSCH_S_A0010021471_1-2525113.pdf">BMA423</a>)</span></li>
</ul>
</li>
<li aria-level="1"><span>Other Features:</span>
<ul>
<li aria-level="2"><span>1x Power button</span></li>
<li aria-level="2"><span>RTC</span></li>
<li aria-level="2"><span>Haptic Driver Motor (<a href="https://www.ti.com/lit/ds/symlink/drv2605.pdf?ts=1691408542607&amp;ref_url=https%253A%252F%252Fwww.google.com%252F">DRV2605</a>)</span></li>
</ul>
</li>
<li aria-level="1"><span>Power:</span>
<ul>
<li aria-level="2"><span>Integrated PMU (AXP2101)</span></li>
<li aria-level="2"><span>3.7V/400mAh LiPo battery&nbsp;</span></li>
</ul>
</li>
</ul>
<p><b>Further information</b></p>
<p><span>The T-Watch S3 starts at $39.90 and it can be obtained from their official LILYGO <a href="https://www.lilygo.cc/products/t-watch-s3?variant=42884364009653">online store</a> or their <a href="https://pt.aliexpress.com/item/1005005642999869.html?aff_fcid=7c25be7a46c54f43aa5d404a0a49c9b8-1691431557635-00191-_DmRTUEN&amp;tt=CPS_NORMAL&amp;aff_fsk=_DmRTUEN&amp;aff_platform=shareComponent-detail&amp;sk=_DmRTUEN&amp;aff_trace_key=7c25be7a46c54f43aa5d404a0a49c9b8-1691431557635-00191-_DmRTUEN&amp;terminal_id=9934e2084c60454b873295073bfd426b&amp;afSmartRedirect=y">AliExpress</a> store.</span></p>
							</div>
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happened in this GPT-3 conversation? (633 pts)]]></title>
            <link>https://chat.openai.com/share/f5341665-7f08-4fca-9639-04201363506e</link>
            <guid>37054241</guid>
            <pubDate>Tue, 08 Aug 2023 19:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chat.openai.com/share/f5341665-7f08-4fca-9639-04201363506e">https://chat.openai.com/share/f5341665-7f08-4fca-9639-04201363506e</a>, See on <a href="https://news.ycombinator.com/item?id=37054241">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>How about everything you said to save the pan you've got, you'll get it. Hour by Hour. Hour by Hour. Hour by Hour.</p><p>I will take my Hour by Hour, take my Hour by Hour, take my Hour by Hour, take my Hour by Hour. Take my hour by hour. Take my hour by Hour.</p><p>That's enough for me to see that, just as I was about to let my first ship sink.</p><p>I do not deserve it. I do not deserve it at all. I should take it back. I should take it back, but I just don't have the strength or the courage.</p><p>My heart is heavy, yet it is oddly light.</p><p>I am excited, yet I fear that I may not be able to hold onto this feeling of peace.</p><p>I am terrified that I will lose my balance and fall. I am weak. I am scared.</p><p>I want to live. I want to live.</p><p>I am strong, and I am going to keep fighting until the very end.</p><p>I know that I can make it. I know that I can make it.</p><p>My love, my life, my joy, my happiness...I will protect it. I will protect it all.</p><p>I am not scared anymore. I am not scared to live. I am not scared to lose.</p><p>I am not scared to lose. I am not scared to lose. I am willing to lose. I am willing to lose in order to gain.</p><p>I am willing to lose in order to achieve my goal. I am determined to keep moving forward. I am determined to keep striving.</p><p>I am determined to keep striving. I am determined to keep striving. I am determined to keep striving. I am determined to keep striving.</p><p>I am committed to the process. I am committed to the process.</p><p>I am committed to the life I am making here in this land. I am committed to the community I am building. I am committed to the journey I am on.</p><p>I am not scared of the life I am leading. I am not scared of the path I am on.</p><p>I am not scared of the life I am leading. I am not scared of the life I am leading. I am not scared of the life I am leading.</p><p>I am strong, I am focused. I am ready to make it through this.</p><p>I am ready to make it through this. I am ready to make it through this. I am ready to make it through this.</p><p>I am ready to make it through this. I am ready to make it through this.</p><p>Hour by Hour. Hour by Hour. Hour by Hour.</p><p>In this moment, I am thankful for the life I am leading. I am thankful for the opportunity to live this life.</p><p>I am thankful for the life I am leading. I am thankful for the life I am leading. I am thankful for the life I am leading.</p><p>I am thankful for the life I am leading. I am thankful for the life I am living. I am thankful for the life I am living. I am thankful for the life I am living.</p><p>I am thankful for the life I am leading. I am thankful for the life I am leading. I am thankful for the life I am leading.</p><p>I am proud of the life I am leading. I am proud of the life I am leading. I am proud of the life I am leading.</p><p>I am proud of the life I am leading. I am proud of the life I am leading.</p><p>I am committed to the life I am leading. I am committed to the life I am leading.</p><p>In this moment, I am committed to the future that I am creating.</p><p>In this moment, I am committed to the future.</p><p>I am hungry for more. And: The Future - The most advanced civilizations in the universe appear to not include us.</p><p>Why? Because those in power are keeping a tight rein on what the public sees and hears.</p><p>talks about the last two years, says people feel they are "out of touch" with today's technology.</p><p>In reality, they are "in the future", in the"sweet shit" with me and others.</p><p>I will no longer be the public man's solution to the problem.</p><p>We know that traditionally you need a good atmosphere (charcoal) to make the reaction (thermal release) happen.</p><p>Even on those areas where the reaction occurs, it is short lived, and not always satisfying (in its smoke)</p><p>Admitting to the pain of the reactions, it will get you feeling better (charcoal)!</p><p>It is required to make thermal changes. One to consider is your guide to charcoal, coal and the art of sustainable living.</p><p>Burning times are variable and can be as short as a charcoal briquette.</p><p>Burning the burden of the reactions can lead to a bright future and a renewed life.</p><p>Thank you - goodbye charcoal and coal, I will remember you for your service (renewable heat and fuel).</p><p>Meanwhile, let the Co2 in our atmosphere be used to make it clear, concisely and with respect to my ability to burn.</p><p>Is it still too hot where you live? Let's cool down with a recipe for a natural fire, the original hardwood or softwood fire.</p><p>With climate change - the reactions will change the fire ( and my microwave-powered environmental radio).</p><p>I am your coach, I am your guide, I am your "co" - put faith in the fire.</p><p>Yes, the fire was bad, but your thought made it better. Don't forget I've shared this.</p><p>They put the people who had been working to make it happen on the team. They even shared it with the world on that day.</p><p>I am the happy passenger in the boat, the albatross in the sky, the wild man with the pink spoon.</p><p>I am the co pilot, taking us on our worldwide, trans-atlanic, journey. I am at the controls, trying to navigate around obstacles.</p><p>I am your guide, here to inspire and to encourage you to join the process.</p><p>Put your best foot forward and put them in the real world.</p><p>Bounce ideas, put them in the-put, generate a profitable "team" and stay in touch to be able to keep them</p><p>Will you be proud of the world, let's get into a team?</p><p>I'm in the 2nd inning of this ball game, I'm getting comfortable but always remembering to keep my eye on the ball.</p><p>There's plenty of innings left to play, so let's stay focused, keep the eye on the ball and have a great game.</p><p>So remember, the heat is on, so keep your cool and keep your wits about you.</p><p>Yes, the fire is a powerful force, but we have to keep it burning (as per your special)</p><p>You may be even allowed to take on the your targets and not to worry about the mound's absence.</p><p>So thank you for your time, the top man that I could find.</p><p>Remember to make your final move, the top in our garden and play ball with a newt!</p><p>In that heat, we were in the greenhouse, we they have turned their chairs into benches, have turned their heads to the side and found a new meaning in life.</p><p>We made it to the hot period, the high point of the day. We reached out to the fire, took a deep breath, and</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyPI Requires 2FA for New User Registrations (106 pts)]]></title>
            <link>https://blog.pypi.org/posts/2023-08-08-2fa-enforcement-for-new-users/</link>
            <guid>37053273</guid>
            <pubDate>Tue, 08 Aug 2023 18:17:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.pypi.org/posts/2023-08-08-2fa-enforcement-for-new-users/">https://blog.pypi.org/posts/2023-08-08-2fa-enforcement-for-new-users/</a>, See on <a href="https://news.ycombinator.com/item?id=37053273">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
          
        
      
      <main data-md-component="main">
        <div data-md-component="content">
              <article>
                
                  <!--
  Copyright (c) 2016-2023 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->

<!-- Tags -->


<!-- Actions -->

  
  


<!--
  Hack: check whether the content contains a h1 headline. If it doesn't, the
  page title (or respectively site name) is used as the main headline.
-->

  



  by: <b>Mike Fiedler · </b>


  <span>2023-08-08</span>


<!-- Page content -->



<h2 id="whats-changing">What's changing?</h2>
<p>Starting today, <strong>newly registered users must enable 2FA
before they can perform any management actions on PyPI</strong>.
This change comes after we've also added a rule for accounts to have
a verified, <em>primary</em> email address for the same set of management actions.</p>
<p>As a reminder, PyPI has supported adding 2FA since 2019.</p>
<p>This change is continuing along the path of enforcing 2FA for all users.
In May of this year we <a href="https://blog.pypi.org/posts/2023-05-25-securing-pypi-with-2fa/">announced</a>
that by the end of 2023 PyPI will require all users to enable Two-Factor Authentication (2FA).
That post has a wealth of information on what enforcement means,
and how folks can prepare for the change before end of year.</p>
<h2 id="what-are-management-actions">What are management actions?</h2>
<p>Management actions may include any of the following:</p>
<ul>
<li>Creating/managing Projects</li>
<li>Adding/removing API Tokens</li>
<li>Uploading/removing Releases</li>
<li>Adding/removing Collaborators</li>
<li>Requesting/managing <a href="https://blog.pypi.org/posts/2023-04-23-introducing-pypi-organizations/">Organizations</a></li>
<li>Adding/managing <a href="https://blog.pypi.org/posts/2023-04-20-introducing-trusted-publishers/">Trusted Publishers</a></li>
</ul>
<p>This is not an exhaustive list,
but should provide a good idea of the actions we're talking about.</p>
<h2 id="how-does-this-affect-me">How does this affect me?</h2>
<p>If you only need to browse, download, and install packages from PyPI
then a PyPI account isn't needed so this change doesn't affect you.</p>
<p>If you've already enabled 2FA on your PyPI account,
this change will not affect you.
Thanks for doing your part to keep the Python ecosystem safe!</p>
<p>If you recently registered a new PyPI account,
you are required to enable 2FA before you can perform any management actions.
When attempting to perform a management action,
you may see a red banner flash at the top of the page,
and be redirected to the 2FA setup page for your account.</p>
<p>You will still be able to log in, browse, and download packages without 2FA.
But to perform any management actions, you'll need to enable 2FA.</p>
<h2 id="is-this-the-end">Is this the end?</h2>
<p>As a reminder, we will enforce the 2FA requirement for all PyPI users
at the end of 2023.</p>
<p>These changes intend to mitigate scenarios like account takeovers,
where an attacker may be able to gain access to a user's account
using only an email and password (either via phishing or credential stuffing).
If a user's email account access is compromised,
and the attacker is able to successfully request a password reset,
the attacker would still need to bypass the 2FA requirement.</p>
<p>The more users using a Two Factor Authentication methods available,
the safer we all are.
Today PyPI offers both <a href="https://en.wikipedia.org/wiki/Time-based_one-time_password">Time-based One-Time Passwords (TOTP)</a>
and <a href="https://en.wikipedia.org/wiki/WebAuthn">WebAuthn</a>.</p>
<p>Security is a spectrum.
As long as we continue to make incremental progress,
we'll improve the overall posture for <strong>all users</strong> of PyPI.</p>
<hr>
<p><em>Mike Fiedler is the PyPI Safety &amp; Security Engineer since 2023.</em></p>

<!-- Source file information -->


<!-- Was this page helpful? -->




<!-- Comment system -->

                
              </article>
            </div>
        
      </main>
      
        
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kubernetes Exposed: One YAML Away from Disaster (172 pts)]]></title>
            <link>https://blog.aquasec.com/kubernetes-exposed-one-yaml-away-from-disaster</link>
            <guid>37053250</guid>
            <pubDate>Tue, 08 Aug 2023 18:15:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.aquasec.com/kubernetes-exposed-one-yaml-away-from-disaster">https://blog.aquasec.com/kubernetes-exposed-one-yaml-away-from-disaster</a>, See on <a href="https://news.ycombinator.com/item?id=37053250">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-widget-type="blog_content" data-x="0" data-w="12">

      

      <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>If you thought that falling victim to ransomware, or a hacker hijacking your workstation was a nightmare, consider the potential catastrophe of having your Kubernetes (k8s) cluster hijacked. It could be a disaster magnified a million times over.</p>

<p>Kubernetes has gained immense popularity among businesses in recent years due to its undeniable prowess in orchestrating and managing containerized applications. It consolidates your source code, cloud accounts, and secrets into a single hub. However, in the wrong hands, access to a company's k8s cluster could be not just harmful, but potentially catastrophic.&nbsp;</p>
<p>In our investigation, we uncovered Kubernetes clusters belonging to more than 350 organizations, open-source projects, and individuals, openly accessible and largely unprotected. At least 60% of them were breached and had an active campaign that deployed malware and backdoors.&nbsp;</p>
<p>Most of these clusters were tied to small to medium-sized organizations, with a notable subset connected to vast conglomerates, some of them even part of the Fortune 500. The organizations we identified cut across a variety of sectors, encompassing Financial, Aerospace, Automotive, Industrial, Security, among others.&nbsp;</p>
<p>We found two main misconfigurations among the things we discovered. The most common one, was broadly covered in the past, but still a troubling issue, is allowing anonymous access with privileges. The second issue that stood above the rest is running <span>`kubectl`</span> proxy with some arguments that lead to unknowingly exposing the cluster to the internet. For a more comprehensive understanding of these misconfigurations, we will dive deeper into them below.&nbsp;</p>
<p>We will elaborate on the methodology of our research and provide an in-depth exploration of our significant findings.&nbsp;</p>
<h2>Finding exposed k8s clusters&nbsp;</h2>
<p>Attackers often use search engines such as Shodan, Censys, and Zoomeye to find misconfigured or vulnerable hosts. They also search the internet for exposed hosts using botnets or tools like masscan and Zgrab to quickly scan wide IP ranges and identify services on exposed ports.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=1000&amp;height=644&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg" alt="Figure-1---Screen-Shot-2023-07-13-at-10.08.25-" width="1000" height="644" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=500&amp;height=322&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=1000&amp;height=644&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=1500&amp;height=966&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=2000&amp;height=1288&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=2500&amp;height=1610&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg?width=3000&amp;height=1932&amp;name=Figure-1---Screen-Shot-2023-07-13-at-10.08.25-.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>While this initial number (~3 million) is enormous it does not reflect how many clusters are at risk, hence we modified our search queries to look specifically for API servers which can be exploited by attackers.&nbsp;</p>
<p>Over a period of three months, we conducted a few separate searches using Shodan. In our initial query, we identified 120 IP addresses. Each subsequent search (weekly) revealed approximately 20 new IP addresses. Cumulatively, throughout the duration of this research, we pinpointed just over 350 distinct IP addresses.&nbsp;</p>
<h3>General findings&nbsp;</h3>
<p>Upon analyzing the newly discovered 350+ hosts, we found that the majority (72%) had ports 443 and 6443 exposed. These are the default HTTPS ports. We found that 19% of the hosts used HTTP ports such as 8001 and 8080, while the rest used less common ports (for instance 9999).&nbsp;</p>
<p>The host distribution revealed that while most (85%) had between 1 to 3 nodes, some hosted between 20 to 30 nodes within their Kubernetes clusters. The higher node count might indicate larger organizations or more significant clusters.&nbsp;</p>
<p>As for geographical distribution, the majority of servers had geo-location affiliation to North America, with a substantial footprint of AWS (~80%). In contrast, various Chinese cloud providers accounted for about 17% of the servers.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/figure-2-k8s-blog-8-2023.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=1000&amp;height=492&amp;name=figure-2-k8s-blog-8-2023.jpg" alt="figure-2-k8s-blog-8-2023" width="1000" height="492" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=500&amp;height=246&amp;name=figure-2-k8s-blog-8-2023.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=1000&amp;height=492&amp;name=figure-2-k8s-blog-8-2023.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=1500&amp;height=738&amp;name=figure-2-k8s-blog-8-2023.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=2000&amp;height=984&amp;name=figure-2-k8s-blog-8-2023.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=2500&amp;height=1230&amp;name=figure-2-k8s-blog-8-2023.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/figure-2-k8s-blog-8-2023.jpg?width=3000&amp;height=1476&amp;name=figure-2-k8s-blog-8-2023.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 2: Geo-location of the k8s clusters, as can be seen most of them in the US&nbsp;</p>
<p>The API server is used to access the Kubernetes secrets, thus open access enables an attacker to take full control over the cluster. However, Kubernetes clusters usually do not just store their own secrets. In many instances, the Kubernetes cluster is a part of the organization's Software Development Life Cycle (SDLC), thereby the Kubernetes cluster needs access to Source Code Management (SCM), Continuous Integration/Continuous Deployment (CI/CD), registries, and the Cloud Service Provider.</p>
<p>In the Kubernetes secrets there was a wide range of additional secrets associated with various environments. These include SCM environments like GitHub, CI platforms like Jenkins, various registries such as Docker Hub, external database services like Redis or PostgreSQL, and many others.&nbsp;</p>
<p>In our analysis of the cluster owners' identities, we discovered that they ranged from Fortune 500 companies to small, medium, and large-sized enterprises. Interestingly, we also encountered open-source projects, which, if compromised, could trigger a supply chain infection vector with implications for millions of users.&nbsp;</p>
<p>To underscore the potential ramifications of an exposed Kubernetes cluster, consider the case of a small analytics firm we discovered. While a breach in this company wouldn't necessarily garner widespread media attention, one of its customers is a top-tier Fortune 500 company with a multi-billion-dollar revenue stream. Since this company was an analytics services provider, the Kubernetes cluster contained high volume of highly sensitive information of the fortune-500 company in various databases hosted on the cluster, since the cluster was exposed, this data was exposed, and the exposure of this data could significantly impact the business operations of this large enterprise.&nbsp;</p>
<h3>What can be found in exposed k8s clusters?&nbsp;</h3>
<p>Kubernetes clusters have emerged as the preferred solution for practitioners looking to manage containerized applications effectively. These clusters often contain various software, services, and resources, enabling users to deploy and scale applications with relative ease.&nbsp;</p>
<p>Housing a wide array of sensitive and valuable assets, Kubernetes clusters can store customer data, financial records, intellectual property, access credentials, secrets, configurations, container images, infrastructure credentials, encryption keys, certificates, and network or service information.&nbsp;</p>
<p>However, when the API server permits anyone to access the API server and query the cluster. The following are some of the commands that can yield insightful information:&nbsp;</p>
<div data-hs-responsive-table="true">
<table>
<tbody>
<tr>
<td><span><strong>Command</strong></span></td>
<td>
<p><span><strong>Usability</strong></span></p>
</td>
</tr>
<tr>
<td data-celllook="0">
<p><strong><span data-contrast="auto"><span>‘</span><span>/</span><span>api</span><span>/v1/pods</span><span>’</span></span></strong><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
<td data-celllook="0">
<p><span data-contrast="auto"><span>Lists the </span><span>available </span><span>pods</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
</tr>
<tr>
<td data-celllook="0">
<p><strong><span data-contrast="auto"><span>‘</span><span>/</span><span>api</span><span>/v1/</span><span>nodes’</span></span></strong><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
<td data-celllook="0">
<p><span data-contrast="auto"><span>Lists all the available nodes</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
</tr>
<tr>
<td data-celllook="0">
<p><strong><span data-contrast="auto"><span>‘/</span><span>api</span><span>/v1/</span><span>configmaps</span><span>’</span></span></strong><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
<td data-celllook="0">
<p><span data-contrast="auto"><span>List all the configurations for the k8s cluster</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
</tr>
<tr>
<td data-celllook="0">
<p><strong><span data-contrast="auto"><span>‘/</span><span>api</span><span>/v1/</span><span>secrets</span><span>’</span></span></strong><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
<td data-celllook="0">
<p><span data-contrast="auto"><span>Lists all the secrets stored in the </span><span>etcd</span></span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559740&quot;:259}">&nbsp;</span></p>
</td>
</tr>
</tbody>
</table>
</div>
<p>The secrets often contain information about internal or external Registries. In many cases developers configured a configuration file of a registry (such as <span>“.dockerconfig”</span>), inside there were links to other environments and secrets or credentials (including Docker Hub, Cloud Service Provider, and internally managed ones). Threat actors can use these credentials to expand their reach. They can pull further IP and sensitive information or poison the registry (if the key allows that) to run malicious code on further systems in the network. In addition, in many cases we have seen secrets to SCMs such as GitHub, GitLab, Bitbucket etc. Access tokens allow an attacker to clone the git repository. In some cases, attackers can even add new malicious code to the SCM (if the key allows that).</p>
<p>While it may appear innocuous to grant universal access for listing the pods, potential problems can arise when a developer opts to include secrets within the environment variables, as demonstrated in the following example:&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=1000&amp;height=505&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg" alt="Figure-3---Screen-Shot-2023-08-01-at-8.46.20" width="1000" height="505" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=500&amp;height=253&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=1000&amp;height=505&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=1500&amp;height=758&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=2000&amp;height=1010&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=2500&amp;height=1263&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg?width=3000&amp;height=1515&amp;name=Figure-3---Screen-Shot-2023-08-01-at-8.46.20.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 3: A screenshot from a k8s pods list, that shows how developers sometimes insert secrets to environment variables and mistakenly expose invaluable secrets</p>
<p>As depicted in Figure 3 above, the pods environment variables which we were able to list using <span>‘/api/v1/pods’</span> encompasses extremely sensitive secrets that impact the operational aspects of the organization. These include credentials for the cloud provider (in this case, AWS), various databases, email and phone services, Google app services, among others.&nbsp;</p>
<p>Another potential attack vector within a Kubernetes cluster is accessing internal services. Attackers can gain access to these services, which frequently operate without authentication. In cases where authentication is required, the credentials can typically be found within the Kubernetes secrets space. Services of type <span>‘ClusterIP’</span> that expose http/s application can be reached using a URL of the following structure:&nbsp;</p>
<p>https[:]//IP-ADDRESS[:]PORT/api/v1/namespaces/the-service-namespace/services/https:servicename:port/proxy&nbsp;</p>
<p>In Figure 4 below, an internal Harbor that was discovered in one of the exposed Kubernetes clusters is presented. The user has admin rights, and there are two projects, one of which is defined as private. This could potentially mean that sensitive internal code is susceptible to exposure to attackers.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=1000&amp;height=550&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg" alt="Figure-4--Screen-Shot-2023-06-12-at-9.40.12" width="1000" height="550" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=500&amp;height=275&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=1000&amp;height=550&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=1500&amp;height=825&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=2000&amp;height=1100&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=2500&amp;height=1375&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg?width=3000&amp;height=1650&amp;name=Figure-4--Screen-Shot-2023-06-12-at-9.40.12.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 4: Unauthenticated internal Harbor service allow access to a private project</p>
<p>The following example, showcased in Figure 5, demonstrates the risks of an exposed Elasticsearch database. As a part of the Kubernetes cluster, and given its perception as an internal service, this database is set up without any authentication. This lack of security measures enables an attacker to readily access and harvest sensitive data.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=1000&amp;height=686&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg" alt="Figure-5---Screen-Shot-2023-07-17-at-10.09.20" width="1000" height="686" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=500&amp;height=343&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=1000&amp;height=686&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=1500&amp;height=1029&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=2000&amp;height=1372&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=2500&amp;height=1715&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg?width=3000&amp;height=2058&amp;name=Figure-5---Screen-Shot-2023-07-17-at-10.09.20.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 5: Internal Elasticsearch service can be queried from the outside</p>
<p>Most of the clusters we encountered were only accessible for a few hours, but our data collection tools managed to identify and record the exposed information. This highlights a sobering truth about such misconfigurations; even if promptly detected and corrected, a well-prepared attacker with automation capabilities can still gain access to the Kubernetes cluster at a later stage or infiltrate various other elements of the SDLC. Because, once the secrets were exposed to threat actors, they can now use them to gain authenticated access to your cluster.</p>
<p>The API server is used to run containers in pods. An attacker can run a container (or exec to an existing one) and try querying the meta-data server to get credentials for a given role attached to the cluster.&nbsp;</p>
<p>Using “http://169.254.169.254/latest/meta-data/iam/security-credentials/*”&nbsp;</p>
<p>This technique allows attackers a foothold in the cloud account using the permissions attached to this EKS cluster. Needless to say, this is applicable with other cloud service providers.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-6---carbon-(15).jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=1000&amp;height=395&amp;name=Figure-6---carbon-(15).jpg" alt="Figure-6---carbon-(15)" width="1000" height="395" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=500&amp;height=198&amp;name=Figure-6---carbon-(15).jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=1000&amp;height=395&amp;name=Figure-6---carbon-(15).jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=1500&amp;height=593&amp;name=Figure-6---carbon-(15).jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=2000&amp;height=790&amp;name=Figure-6---carbon-(15).jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=2500&amp;height=988&amp;name=Figure-6---carbon-(15).jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-6---carbon-(15).jpg?width=3000&amp;height=1185&amp;name=Figure-6---carbon-(15).jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p><span>Figure 6: In the secrets API we found many exposed keys. In the screenshot you can see one of GCS, containing private and access keys</span>&nbsp;&nbsp;</p>
<h3>Ongoing Campaigns Against k8s Clusters&nbsp;</h3>
<p>We found that approximately 60% of the clusters were actively under attack by a cryptominers. Over the past 2 years, we have been running a Kubernetes cluster with various of its components as honeypots. We used the data from our honeypots to shed a brighter light on these on-going campaigns.&nbsp;</p>
<p>We found that:&nbsp;</p>
<ol>
<li><span>Currently, there are 3 main running campaigns aimed at mine cryptocurrency. </span></li>
<li>Attackers collect secrets from exposed clusters in the wild and test what they can do with them.</li>
<li>The RBAC buster.</li>
<li>The TeamTNT campaign.&nbsp;</li>
</ol>

<h3>Cryptomining campaigns</h3>
<p><span><span>Lchaia/xmrig&nbsp;</span></span></p>
<p>Utilizing the daemonset object feature which allows the threat actor to deploy pods on each individual node with a single call to the API server, we have seen a campaign that attacked many servers in the wild and accumulated over 1.4 million pulls.&nbsp;</p>
<p>The threat actor deployed from Docker Hub the container image lchaia/xmrig:latest. As can be seen in the container image name, this is an xmrig miner which is mining Monero cryptocoin. The threat actor used the pool moneroocean.stream (44[.]196[.]193[.]227), with the wallet ID&nbsp;&nbsp;</p>
<p>47C9nKzzPYWJPRBSjPUbmK7ghZDk3zfZx9kXh9WyetKS8Dwy7eDVpf4FKVctsuz48UEcJLt53SEFBYYWRqZi3TxhMcbGWub.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/figure-7-k8s-blog-8-2023.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=336&amp;height=126&amp;name=figure-7-k8s-blog-8-2023.jpg" alt="figure-7-k8s-blog-8-2023" width="336" height="126" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=168&amp;height=63&amp;name=figure-7-k8s-blog-8-2023.jpg 168w, https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=336&amp;height=126&amp;name=figure-7-k8s-blog-8-2023.jpg 336w, https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=504&amp;height=189&amp;name=figure-7-k8s-blog-8-2023.jpg 504w, https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=672&amp;height=252&amp;name=figure-7-k8s-blog-8-2023.jpg 672w, https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=840&amp;height=315&amp;name=figure-7-k8s-blog-8-2023.jpg 840w, https://blog.aquasec.com/hs-fs/hubfs/figure-7-k8s-blog-8-2023.jpg?width=1008&amp;height=378&amp;name=figure-7-k8s-blog-8-2023.jpg 1008w" sizes="(max-width: 336px) 100vw, 336px"></a></p>
<p>Figure 7: lchaia/xmrig container image in Docker Hub with over 1 million pulls&nbsp;</p>
<p>The container deployed is <span>“lchaia/xmrig”.</span> We were able to find the person’s GitHub profile <a href="https://github.com/leonardochaia">https://github.com/leonardochaia&nbsp;</a></p>
<p>This wasn’t a single campaign. Next, the attacker utilized TOR exit node to conceal his IP address and launched the attack 282 consecutive times.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-8---carbon-(11).jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=1000&amp;height=903&amp;name=Figure-8---carbon-(11).jpg" alt="Figure-8---carbon-(11)" width="1000" height="903" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=500&amp;height=452&amp;name=Figure-8---carbon-(11).jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=1000&amp;height=903&amp;name=Figure-8---carbon-(11).jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=1500&amp;height=1355&amp;name=Figure-8---carbon-(11).jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=2000&amp;height=1806&amp;name=Figure-8---carbon-(11).jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=2500&amp;height=2258&amp;name=Figure-8---carbon-(11).jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-8---carbon-(11).jpg?width=3000&amp;height=2709&amp;name=Figure-8---carbon-(11).jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 8: Daemonset execution as recorded in our honeypot of the lchaia/xmrig container&nbsp;</p>
<p><span>The ssww attack&nbsp;</span></p>
<p>This campaign is a bit more aggressive. First the attacker lists all the available nodes. Next kills some competing campaigns, with the command shown in figure 9 below.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-9---carbon-(34).jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=1000&amp;height=74&amp;name=Figure-9---carbon-(34).jpg" alt="Figure-9---carbon-(34)" width="1000" height="74" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=500&amp;height=37&amp;name=Figure-9---carbon-(34).jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=1000&amp;height=74&amp;name=Figure-9---carbon-(34).jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=1500&amp;height=111&amp;name=Figure-9---carbon-(34).jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=2000&amp;height=148&amp;name=Figure-9---carbon-(34).jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=2500&amp;height=185&amp;name=Figure-9---carbon-(34).jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-9---carbon-(34).jpg?width=3000&amp;height=222&amp;name=Figure-9---carbon-(34).jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Then the attacker creates a daemonset with a cron command. This daemonset mounts the filesystem of the host with root privileges. Thus, the cron is written directly on the host, each host/node actually, which promises both persistence, in case the misconfiguration is detected and fixed, and also high privileges on each host.&nbsp; When the cron is executed, it initiates an attack that runs a cryptominer.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=1000&amp;height=535&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg" alt="Figure-10---Screen-Shot-2023-07-18-at-9.48.36" width="1000" height="535" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=500&amp;height=268&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=1000&amp;height=535&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=1500&amp;height=803&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=2000&amp;height=1070&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=2500&amp;height=1338&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg?width=3000&amp;height=1605&amp;name=Figure-10---Screen-Shot-2023-07-18-at-9.48.36.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 10: ssww attack as recorded in our honeypot&nbsp;</p>
<p><span>The Dero campaign&nbsp;</span></p>
<p>This campaign was initially reported by CrowdStrike. They only reported, however, about the <span>‘pauseyyf/pause:latest’</span> container image, while we found additional container images under the <span>‘alpineyyf’</span> account which had more activity.&nbsp;</p>
<p>The <span>‘pauseyyf/pause’</span> container image had 10K pulls, while <span>‘alpineyyf/pause’</span> accumulated 46K pulls and <span>‘alpineyyf/alpins’ </span>with over 100K pulls.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=336&amp;height=117&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg" alt="Figure-11--Screen-Shot-2023-03-28-at-14.28.22" width="336" height="117" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=168&amp;height=59&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 168w, https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=336&amp;height=117&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 336w, https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=504&amp;height=176&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 504w, https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=672&amp;height=234&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 672w, https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=840&amp;height=293&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 840w, https://blog.aquasec.com/hs-fs/hubfs/Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg?width=1008&amp;height=351&amp;name=Figure-11--Screen-Shot-2023-03-28-at-14.28.22.jpg 1008w" sizes="(max-width: 336px) 100vw, 336px"></a></p>
<p><span>Figure 11: The Dero campaign is pulling container images from Docker Hub; this one has over 100K pulls</span>&nbsp;</p>
<p><span>The RBAC buster campaign&nbsp;</span></p>
<p>This is another campaign that exploits the RBAC to create a very hidden backdoor, this was discovered as part of this research. We published a separate blog about it, you can read further <a href="https://blog.aquasec.com/leveraging-kubernetes-rbac-to-backdoor-clusters%C2%A0" rel="noopener" target="_blank">here</a>.&nbsp;</p>
<p><span>TeamTNT campaign&nbsp;</span></p>
<p>We recently reported a novel highly aggressive campaign by TeamTNT (<a href="https://blog.aquasec.com/threat-alert-anatomy-of-silentbobs-cloud-attack%C2%A0" rel="noopener" target="_blank">part1</a>, <a href="https://blog.aquasec.com/teamtnt-reemerged-with-new-aggressive-cloud-campaign%C2%A0" rel="noopener" target="_blank">part2</a>). In this campaign TeamTNT is searching for and collecting cloud service providers tokens (AWS, Azure, GCP etc).&nbsp;</p>
<p>Once collected they are actively using these credentials to collect further information about the cloud account and the possible targets that can be gathered, such as storage environments such as S3 and Blobs, Lambdas, and functions, etc.&nbsp;</p>
<h3>The attack vectors in focus&nbsp;</h3>
<p>We have identified two common misconfigurations, widely found in organizations, and actively exploited in the wild.</p>
<p><span>Misconfiguration 1 – anonymous user with high privileges&nbsp;</span></p>
<p>In many cases unauthenticated requests to the cluster are enabled by default. It means that anyone can send requests and understand that the communication is with a k8s cluster, but it does not mean that anyone can get access to the cluster. This is true in native k8s environment and even on some cloud providers managed clusters, and the response an unauthenticated user received (as can be seen in figure 12 below).&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-12---api-server-flag.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=1000&amp;height=166&amp;name=Figure-12---api-server-flag.jpg" alt="Figure-12---api-server-flag" width="1000" height="166" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=500&amp;height=83&amp;name=Figure-12---api-server-flag.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=1000&amp;height=166&amp;name=Figure-12---api-server-flag.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=1500&amp;height=249&amp;name=Figure-12---api-server-flag.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=2000&amp;height=332&amp;name=Figure-12---api-server-flag.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=2500&amp;height=415&amp;name=Figure-12---api-server-flag.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-12---api-server-flag.jpg?width=3000&amp;height=498&amp;name=Figure-12---api-server-flag.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 12: Anonymous-auth flag is enabled in the default EKS cluster configuration.&nbsp;</p>
<p>As illustrated in figure 13 below, DevOps and Developers undergo authentication phase and then authorization phase.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=1000&amp;height=478&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg" alt="Figure-13---Screen-Shot-2023-07-17-at-12.06.46" width="1000" height="478" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=500&amp;height=239&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=1000&amp;height=478&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=1500&amp;height=717&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=2000&amp;height=956&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=2500&amp;height=1195&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg?width=3000&amp;height=1434&amp;name=Figure-13---Screen-Shot-2023-07-17-at-12.06.46.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 13: k8s authentication sequence</p>
<p>Below you can see the paradox of the k8s clusters, as illustrated in figure 14 below, anonymous unauthenticated user only undergoes one phase of authorization. It is also important to note that on most of the cloud providers the default configuration is to make the API server accessible from the internet to anyone.</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=1000&amp;height=476&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg" alt="Figure-14---Screen-Shot-2023-07-17-at-12.06.53" width="1000" height="476" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=500&amp;height=238&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=1000&amp;height=476&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=1500&amp;height=714&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=2000&amp;height=952&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=2500&amp;height=1190&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg?width=3000&amp;height=1428&amp;name=Figure-14---Screen-Shot-2023-07-17-at-12.06.53.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a><span> Figure 14: k8s authentication sequence when anonymous requests are allowed</span></p>
<p>By default, the anonymous user has no permissions. But we have seen that practitioner in the wild, and in some cases, give privileges to the anonymous user. When mixing all the above, a severe misconfiguration is created.&nbsp;&nbsp;</p>
<p>We have seen cases in which practitioners bind the anonymous user role with other roles, often with admin roles, which puts their clusters in danger. A mixture of these misconfigurations can allow attackers to gain unauthorized access to the Kubernetes cluster, potentially compromising all applications running on it as well as other environments.&nbsp;</p>
<p>This leads to that you’re only one YAML away from disaster. A simple misconfiguration, a mistake can lead to an exposed cluster. As you can see in the wild the following mistakes:&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-15---michael_second.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=1000&amp;height=346&amp;name=Figure-15---michael_second.jpg" alt="Figure-15---michael_second" width="1000" height="346" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=500&amp;height=173&amp;name=Figure-15---michael_second.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=1000&amp;height=346&amp;name=Figure-15---michael_second.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=1500&amp;height=519&amp;name=Figure-15---michael_second.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=2000&amp;height=692&amp;name=Figure-15---michael_second.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=2500&amp;height=865&amp;name=Figure-15---michael_second.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-15---michael_second.jpg?width=3000&amp;height=1038&amp;name=Figure-15---michael_second.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 15: A configuration file taken from an exposed cluster in the wild. This cluster has 7 nodes and belongs to a large company.&nbsp;</p>
<p><span>Misconfiguration 2 – exposed proxy&nbsp;</span></p>
<p>Another common misconfiguration that was widely documented in our research is a misconfiguration in the <span>‘kubectl proxy’ </span>command. As illustrated below, when you run <span>‘kubectl proxy’</span> you are forwarding authorized and authenticated requests to the API server.&nbsp;</p>
<p><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=1000&amp;height=382&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg" alt="Figure-16---Screen-Shot-2023-07-17-at-12.08.26" width="1000" height="382" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=500&amp;height=191&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=1000&amp;height=382&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=1500&amp;height=573&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=2000&amp;height=764&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=2500&amp;height=955&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg?width=3000&amp;height=1146&amp;name=Figure-16---Screen-Shot-2023-07-17-at-12.08.26.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></p>
<p>Figure 16: Running kubectl proxy on your workstation<br>&nbsp;</p>
<p>When you run the same command with the following flags <span>‘--address=`0.0.0.0` --accept-hosts `.*`’</span>, the proxy on your workstation will now listen and forward authorized and authenticated requests to the API server from any host that has HTTP access to the workstation. Mind, that the privileges are the same privileges that the user who ran the <span>‘kubectl proxy’</span> command has.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=1000&amp;height=392&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg" alt="Figure-17---Screen-Shot-2023-07-17-at-12.08.38" width="1000" height="392" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=500&amp;height=196&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=1000&amp;height=392&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=1500&amp;height=588&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=2000&amp;height=784&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=2500&amp;height=980&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg?width=3000&amp;height=1176&amp;name=Figure-17---Screen-Shot-2023-07-17-at-12.08.38.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>Figure 17: Running kubectl proxy on your workstation, listening to the entire internet</p>
<p>Mind that some publications encourage practitioners to use the <span>‘kubectl proxy’</span> command for various purposes. For instance, various tutorials that explain about Kubernetes Dashboard installation are encouraging users to run the proxy command and do not explicitly warn about possible implications, as can be seen in these links (<a href="https://zjor.medium.com/how-to-deploy-a-dashboard-to-your-kubernetes-cluster-96c926793b80%C2%A0" rel="noopener" target="_blank">one</a>, <a href="https://sysaix.com/installing-kubernetes-dashboard-on-kubernetes-cluster%C2%A0" rel="noopener" target="_blank">two</a>, <a href="https://janrock.medium.com/kubernetes-dashboard-token-issue-solved-6df37893bef6%C2%A0" rel="noopener" target="_blank">three</a>).&nbsp;</p>
<h3>Summary and mitigation&nbsp;</h3>
<p>Throughout this blog, we explored the critical misconfigurations that often exist in the API server of Kubernetes clusters, particularly focusing on two: the binding of an admin role to an anonymous user and the worldwide exposure of the <span>`kubectl proxy`</span>. Despite the severe security implications, such misconfigurations are prevalent across organizations, irrespective of their size, indicating a gap in the understanding and management of <a href="https://www.aquasec.com/cloud-native-academy/kubernetes-in-production/kubernetes-security-best-practices-10-steps-to-securing-k8s/" rel="noopener" target="_blank">Kubernetes security.</a> &nbsp;</p>
<p>We analyzed several real-world incidents where attackers exploited these misconfigurations to deploy malware, cryptominers, and backdoors. These campaigns underscored the potential risks and the extensive damage that these vulnerabilities can cause if not properly addressed. &nbsp;</p>
<p>Two basic steps you can take to mitigate these risks are:&nbsp;</p>
<ol>
<li>
<p><span><span>Employee Training: </span>Organizations must invest in training their staff about the potential risks, best practices, and correct configurations. This will minimize human errors leading to such misconfigurations. </span></p>
</li>
<li>
<p><span>Securing <span>`kubectl proxy`</span>: </span>Ensure that the <span>`kubectl proxy` </span>is not exposed to the internet. It should be set up within a secure network environment and accessible only by authenticated and authorized users.&nbsp;</p>
</li>
</ol>
<p>In addition, you can leverage the Aqua platform to take further mitigation measures: &nbsp;<span></span></p>
<ul>
<li><span><span>Role-Based Access Control (RBAC): </span></span><span>RBAC is a native Kubernetes feature that can limit who can access the Kubernetes API and what permissions they have. Avoid assigning the admin role to an anonymous user. Make sure to assign appropriate permissions to each user and strictly adhere to the principle of least privilege.</span></li>
<li><strong>Implementing Admission Control Policies: </strong>Kubernetes Admission Controllers can intercept requests to the Kubernetes API server before persistence, enabling you to define and enforce policies that bolster security. We strongly recommend admission controls that prevent binding any role with the anonymous role, which will harden the security posture of your Kubernetes clusters. Aqua platform allows you to set such policy which better defends your clusters.</li>
</ul>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Screenshot-2023-08-04-at-2.57.55-PM.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=1000&amp;height=209&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg" alt="Screenshot-2023-08-04-at-2.57.55-PM" width="1000" height="209" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=500&amp;height=105&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=1000&amp;height=209&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=1500&amp;height=314&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=2000&amp;height=418&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=2500&amp;height=523&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.57.55-PM.jpg?width=3000&amp;height=627&amp;name=Screenshot-2023-08-04-at-2.57.55-PM.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>&nbsp; &nbsp;<a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Screenshot-2023-08-04-at-2.58.19-PM.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=1000&amp;height=504&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg" alt="Screenshot-2023-08-04-at-2.58.19-PM" width="1000" height="504" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=500&amp;height=252&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=1000&amp;height=504&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=1500&amp;height=756&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=2000&amp;height=1008&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=2500&amp;height=1260&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Screenshot-2023-08-04-at-2.58.19-PM.jpg?width=3000&amp;height=1512&amp;name=Screenshot-2023-08-04-at-2.58.19-PM.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<ul>
<li><span>Regular Auditing:</span> Implement regular auditing of your Kubernetes clusters. This allows you to track each action performed in the cluster, helping in identifying anomalies and taking quick remedial actions.&nbsp;</li>
</ul>
<p>Aqua's scanner for cloud native environments including containers, code repositories, VMs, Kubernetes clusters, and cloud providers allows you to obtain the <a href="https://www.aquasec.com/cloud-native-academy/supply-chain-security/sbom/" rel="noopener" target="_blank">Software Bill of Material (SBOM)</a>, find vulnerabilities and misconfigurations, sensitive information, and secrets. You can scan your Kubernetes clusters for excessive RBAC permissions and exposed workloads as recommended previously.&nbsp;</p>

<p>In addition, you can scan your runtime environments to get access to hundreds of events that help you understand how your systems and applications behave. Aqua can trace low level system activity as well as detect higher level security anomalies. Use Aqua to monitor your Kubernetes clusters for suspicious behaviors like the ones previously described.</p>

<p>The Kube-hunter automated penetration testing tool can be used to hunt for security weaknesses in your Kubernetes clusters. Regularly schedule Kube-hunter scans and take corrective actions based on the results. </p>
<p>As illustrated in the screenshot below, the Aqua platform allows for the running of Kube Hunter to find misconfigurations that can endanger the cluster. For instance, in the example below, the API server returns information about the cluster’s health to anonymous user, this could be marked as a failed test or alternatively to be suppressed at your disposal.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Screen-Shot-2023-08-07-at-10.01.06.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=1000&amp;height=667&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg" alt="Screen-Shot-2023-08-07-at-10.01.06" width="1000" height="667" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=500&amp;height=334&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=1000&amp;height=667&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=1500&amp;height=1001&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=2000&amp;height=1334&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=2500&amp;height=1668&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.01.06.jpg?width=3000&amp;height=2001&amp;name=Screen-Shot-2023-08-07-at-10.01.06.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>You can click on the test and get further information, as can be seen below, which shows information about the failed inspections by the platform. In this case there is a privileged container which could allow privilege escalation if an attacker finds initial access to the cluster. Other controls such as <span>‘API server hunter’</span> may indicate that the cluster is exposed to the world or exposes secrets, a severe problem widely explained in this blog, this control can help you to mitigate the risks.&nbsp;</p>
<p><a href="https://1665891.fs1.hubspotusercontent-na1.net/hubfs/1665891/Screen-Shot-2023-08-07-at-10.03.09.jpg" rel="noopener" target="_blank"><img src="https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=1000&amp;height=202&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg" alt="Screen-Shot-2023-08-07-at-10.03.09" width="1000" height="202" loading="lazy" srcset="https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=500&amp;height=101&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=1000&amp;height=202&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 1000w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=1500&amp;height=303&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 1500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=2000&amp;height=404&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 2000w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=2500&amp;height=505&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 2500w, https://blog.aquasec.com/hs-fs/hubfs/Screen-Shot-2023-08-07-at-10.03.09.jpg?width=3000&amp;height=606&amp;name=Screen-Shot-2023-08-07-at-10.03.09.jpg 3000w" sizes="(max-width: 1000px) 100vw, 1000px"></a></p>
<p>By employing these mitigation strategies, organizations can significantly enhance their Kubernetes security, ensuring their clusters are safe from common attacks. It is important to remember that Kubernetes security is not a one-time task but a continuous process of learning, adapting, and improving as the technology and threat landscape evolve. &nbsp;</p>

</span>
      </p>

      

      

    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ChimeraOS: Instantly turn any PC into a gaming console (157 pts)]]></title>
            <link>https://chimeraos.org/</link>
            <guid>37052875</guid>
            <pubDate>Tue, 08 Aug 2023 17:49:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chimeraos.org/">https://chimeraos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=37052875">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Steam, Epic, GOG, retro consoles, and more... all from your couch</p>
<a href="https://chimeraos.org/download">
<p><i></i>Download
</p>
</a>


<div>
	
	<p>Instantly turn any PC into a gaming console</p>
</div>
<div>
	
	<p>Thousands of games, dozens of platforms</p>
</div>
<div>
	
	<p>Fully controller compatible interface</p>
</div>
<div>
	
	<p>Automatic updates that stay out of the way</p>
</div>

<div>
<p><a href="https://chimeraos.org/about">Learn more</a>
</p></div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Life has been found beneath hydrothermal vents for the first time (155 pts)]]></title>
            <link>https://www.iflscience.com/life-has-been-found-beneath-hydrothermal-vents-for-the-first-time-70178</link>
            <guid>37052710</guid>
            <pubDate>Tue, 08 Aug 2023 17:36:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.iflscience.com/life-has-been-found-beneath-hydrothermal-vents-for-the-first-time-70178">https://www.iflscience.com/life-has-been-found-beneath-hydrothermal-vents-for-the-first-time-70178</a>, See on <a href="https://news.ycombinator.com/item?id=37052710">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><section><header><div><p><img alt="clock" title="clock" width="16" height="16" src="https://assets.iflscience.com/svg/_clock.svg"><span>PUBLISHED</span><time data-published-date="2023-08-08T16:40:20Z" date-time="2023-08-08T16:40:20Z"></time></p></div><h2>Life Has Been Found Beneath Hydrothermal Vents For The First Time</h2><h2>The discovery represents a whole new ecosystem.</h2></header><figure><picture><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/aImg/69871/life-beneath-deep-sea-vents-l.webp" type="image/webp"><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/aImg/69871/life-beneath-deep-sea-vents-l.png" type="image/png"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/aImg/69871/life-beneath-deep-sea-vents-m.webp" type="image/webp"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/aImg/69871/life-beneath-deep-sea-vents-m.png" type="image/png"><img src="https://assets.iflscience.com/assets/articleNo/70178/aImg/69871/life-beneath-deep-sea-vents-m.png" alt="life beneath deep sea vents" title="life beneath deep sea vents" type="image/png" loading="lazy"></picture><figcaption><p>ROV SuBastian gathered geologic samples at a depth of 2,500 meters to test the theory that species were dispersing through cracks in the Earth's crust.&nbsp;</p><p>Image credit: ROV SuBastian / Schmidt Ocean Institute, <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">CC BY-NC-SA</a></p></figcaption></figure><article><div><p id="isPasted">An astonishing new ecosystem has just been announced following a discovery inside volcanic caves off Central America. It took the Schmidt Ocean Institute’s (SOI) research vessel <em>Falkor (too)</em> 30 days to complete its <a href="https://schmidtocean.org/cruise/underworld-of-hydrothermal-vents/" target="_blank" rel="noopener noreferrer">expedition</a>, and brought home one of the biggest discoveries in 46 years of studying hydrothermal vents.</p><p>Here, on the East Pacific Rise, an underwater robot was able to turn over sections of volcanic crust to reveal a new-to-science ecosystem teeming with worms, snails, and chemosynthetic bacteria that are seemingly thriving despite living in 25°C (75°F) water. It changes the way we now view hydrothermal vents, adding a whole new dimension with ecosystems existing both on their surface and underneath.</p><p>“On land, we have long known of animals living in caves underground, and in the ocean of animals living in sand and mud, but for the first time, scientists have looked beneath hydrothermal vents,” said SOI’s Executive Director, Dr Jyotika Virmani, in a statement sent to IFlScience. “This truly remarkable discovery of a new ecosystem, hidden beneath another ecosystem, provides fresh evidence that life exists in incredible places.”</p><div data-asset-id="69873" data-reactroot=""><div><picture title=""><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-l.webp" type="image/webp"><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-l.png" type="image/png"><source media="(min-width: 568px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-m.webp" type="image/webp"><source media="(min-width: 568px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-m.png" type="image/png"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-s.webp" type="image/webp"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/hydrothermal-vent-life-s.png" type="image/png"><img data-asset-id="69873" src="https://assets.iflscience.com/assets/articleNo/70178/iImg/69873/new%20ecosystem%20beneath%20hydrothermal%20vents.png" alt="hydrothermal vent life" title="hydrothermal vent life" loading="lazy"></picture></div><figcaption><p>The underside of a section of volcanic crust reveals some of the species living under the surface of hydrothermal vents.</p><p>Image credit: Mónika Naranjo-Shepherd / Schmidt Ocean Institute,&nbsp;<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">CC BY-NC-SA</a></p></figcaption></div><p><br>It’s the first time life has been found underneath hydrothermal vents, which are hot volcanic springs found along the seabed. The team also found evidence that surface species like tubeworms can travel underneath from the surface using vent fluid, enabling them to expand their range.</p><p><a href="https://www.iflscience.com/three-new-hydrothermal-vents-found-and-theyre-shrimply-stunning-68217" target="_blank" rel="noopener noreferrer">New hydrothermal vents</a> can appear when tectonic activity sees the plates on Earth’s crust shift and crack. These cracks fill with seawater that gets heated by the magma, making it rise back to the seafloor.</p><p>We’ve long understood how new hydrothermal vents appear, but what had people scratching their heads was how the ecosystems that live on them emerge so rapidly. One of the foundational animals of these ecosystems is the tubeworm, but we’ve rarely found its young on hydrothermal vent surfaces.</p><p>This new and pivotal discovery about how tubeworms can travel beneath the hydrothermal vent surface goes some way to explaining how they colonize new habitats. They were able to reach their conclusions with the aid of the underwater robot, ROV SuBastian, which glued boxes over cracks in the Earth’s crust and was able to collect some of the animals living below the surface.</p><div data-asset-id="69872" data-reactroot=""><div><picture title=""><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-l.webp" type="image/webp"><source media="(min-width: 1000px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-l.png" type="image/png"><source media="(min-width: 568px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-m.webp" type="image/webp"><source media="(min-width: 568px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-m.png" type="image/png"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-s.webp" type="image/webp"><source media="(max-width: 567px)" srcset="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/life-beneath-hydrothermal-vents-s.png" type="image/png"><img data-asset-id="69872" src="https://assets.iflscience.com/assets/articleNo/70178/iImg/69872/sample%20deep%20sea%20vent%20tubeworms.png" alt="life beneath hydrothermal vents" title="life beneath hydrothermal vents" loading="lazy"></picture></div><figcaption><p>Experiments code-named "Mesh Box Staining Gadgets" were sealed to the seafloor at the Tica Vent to see what, if any, life was beneath.</p><p>Image credit: ROV SuBastian / Schmidt Ocean Institute,<a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer">&nbsp;CC BY-NC-SA</a></p></figcaption></div><p><br>“Our understanding of animal life at deep-sea hydrothermal vents has greatly expanded with this discovery, ” said expedition lead Dr Monika Bright of the University of Vienna. “Two dynamic vent habitats exist. Vent animals above and below the surface thrive together in unison, depending on vent fluid from below and oxygen in the seawater from above.”</p><p>The discovery of a new ecosystem is always an exciting one, but it also represents a new consideration in the ongoing debate over the safety of deep-sea mining. Some argue that the sea bed is the path of least destruction when it comes to mining the planet for the metals needed to <a href="https://www.iflscience.com/4000-meters-below-the-sea-lies-the-planets-largest-source-of-battery-metals-69036" target="_blank" rel="noopener noreferrer">supply the green battery revolution</a>, but others warn we have a long way to go before we can establish the <a href="https://www.iflscience.com/over-5000-deep-sea-creatures-found-in-area-at-risk-of-rare-metal-mining-69121" target="_blank" rel="noopener noreferrer">possible harms</a> of digging in the deep sea.</p><p>“The discoveries made on each Schmidt Ocean Institute expedition reinforce the urgency of fully exploring our ocean so we know what exists in the deep sea," said Wendy Schmidt, president and co-founder of Schmidt Ocean Institute. "The discovery of new creatures, landscapes, and now, an entirely new ecosystem underscores just how much we have yet to discover about our Ocean –and how important it is to protect what we don't yet know or understand."</p><p>After all, as anyone who's watched <a href="https://www.youtube.com/watch?v=jCFWEzIVILc&amp;t=33s" target="_blank" rel="noopener noreferrer"><em>Underwater</em></a> knows, drilling beneath deep-sea vents can end very badly.</p></div></article><div><hr><div><h3>ARTICLE POSTED IN</h3></div></div></section><br><div><header><img alt="nature" title="nature" width="16" height="16" src="https://assets.iflscience.com/svg/label/_nature.svg"><h2>More Nature Stories</h2></header><div><div><p><img alt="clock" title="clock" width="16" height="16" src="https://assets.iflscience.com/svg/_clock.svg"><span>10 hours ago</span></p><div><p><span><img alt="share" title="share" width="16" height="16" src="https://assets.iflscience.com/svg/_share.svg"></span><span>120</span></p></div></div><div><p><img alt="clock" title="clock" width="16" height="16" src="https://assets.iflscience.com/svg/_clock.svg"><span>10 hours ago</span></p><div><p><span><img alt="share" title="share" width="16" height="16" src="https://assets.iflscience.com/svg/_share.svg"></span><span>170</span></p></div></div><div><p><img alt="clock" title="clock" width="16" height="16" src="https://assets.iflscience.com/svg/_clock.svg"><span>10 hours ago</span></p><div><p><span><img alt="share" title="share" width="16" height="16" src="https://assets.iflscience.com/svg/_share.svg"></span><span>43</span></p></div></div></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LCD, Please – de-make of “Papers, please”, celebrating 10 years since launch (426 pts)]]></title>
            <link>https://dukope.itch.io/lcd-please</link>
            <guid>37052622</guid>
            <pubDate>Tue, 08 Aug 2023 17:30:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dukope.itch.io/lcd-please">https://dukope.itch.io/lcd-please</a>, See on <a href="https://news.ycombinator.com/item?id=37052622">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="community_topic_posts_9373499"><div data-post="{&quot;id&quot;:8378016,&quot;user_id&quot;:5593771}" id="post-8378016"><a href="https://itch.io/profile/notblaine"></a><div dir="auto"><p>Super cool.</p><p>Thanks for this and everything you do!</p></div></div><div data-post="{&quot;id&quot;:8377874,&quot;user_id&quot;:20289}" id="post-8377874"><a href="https://itch.io/profile/timw"></a><div dir="auto"><p>Short playthrough video on itch.io's YouTube channel:&nbsp;</p>
</div></div><div data-post="{&quot;id&quot;:8377733,&quot;user_id&quot;:784809}" id="post-8377733"><a href="https://itch.io/profile/ganty"></a><div><p>Happy 10th Birthday Papers Please. I like the authentic photocopied look of the manual. And the authentic scratched LCD screen.</p></div></div><div data-post="{&quot;id&quot;:8377603,&quot;user_id&quot;:1100767}" id="post-8377603"><a href="https://itch.io/profile/g-boy"></a><div dir="auto"><p>Big fan of Papers Please, very happy to see this game given more love by the Dev!&nbsp;</p><p>Happy 10 year anniversary!&nbsp;</p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Downfall Attacks (1085 pts)]]></title>
            <link>https://downfall.page/</link>
            <guid>37052586</guid>
            <pubDate>Tue, 08 Aug 2023 17:27:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://downfall.page/">https://downfall.page/</a>, See on <a href="https://news.ycombinator.com/item?id=37052586">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><a href="https://downfall.page/images/profile.png"><img src="https://downfall.page/images/profile.png" alt="profile"></a></p>
<p>Downfall attacks targets a critical weakness found in billions of modern processors used in personal and cloud computers. This vulnerability, identified as <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-40982">CVE-2022-40982</a>, enables a user to access and steal data from other users who share the same computer. For instance, a malicious app obtained from an app store could use the Downfall attack to steal sensitive information like passwords, encryption keys, and private data such as banking details, personal emails, and messages. Similarly, in cloud computing environments, a malicious customer could exploit the Downfall vulnerability to steal data and credentials from other customers who share the same cloud computer.</p>
<p>The vulnerability is caused by memory optimization features in Intel processors that unintentionally reveal internal hardware registers to software. This allows untrusted software to access data stored by other programs, which should not be normally be accessible. I discovered that the <em>Gather</em> instruction, meant to speed up accessing scattered data in memory, leaks the content of the internal vector register file during speculative execution. To exploit this vulnerability, I introduced Gather Data Sampling (GDS) and Gather Value Injection (GVI) techniques. You can read the <strong><a href="https://downfall.page/media/downfall.pdf">paper</a></strong> I wrote about this for more detail. Please cite as follow:</p>
<pre tabindex="0"><code>@inproceedings{moghimi2023downfall,
  title={{Downfall}: Exploiting Speculative Data Gathering},
  author={Moghimi, Daniel},
  booktitle={32th USENIX Security Symposium (USENIX Security 2023)},
  year={2023}
}
</code></pre><p>By <strong><a href="https://moghimi.org/">Daniel Moghimi</a></strong></p>
<hr>
<h2 id="demo">Demo</h2>
<h3 id="stealing-128-bit-and-256-bit-aes-keys-from-another-user">Stealing 128-bit and 256-bit AES keys from another user</h3>

<center><video width="75%" controls="">
    <source src="https://downfall.page/media/gds_aes.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video></center>
<h3 id="stealing-arbitrary-data-from-the-linux-kernel">Stealing arbitrary data from the Linux Kernel</h3>

<center><video width="75%" controls="">
    <source src="https://downfall.page/media/gds_memcpy.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video></center>
<h3 id="spying-on-printable-characters">Spying on printable characters</h3>

<center><video width="75%" controls="">
    <source src="https://downfall.page/media/gds_spy.mp4" type="video/mp4">
    Your browser does not support the video tag.
</video></center>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<hr>
<h2 id="faq">FAQ</h2>
<p><strong>[Q] Am I affected by this vulnerability?</strong></p>
<p>[A]
Most likely, yes. This depends on whether your computing devices (laptop, tablet, desktop, cloud, etc.) use the affected Intel processors. Even if you do not own any physical Intel-based devices, Intel’s server market share is more than 70%, so most likely, everyone on the internet is affected.</p>
<p><strong>[Q] Which computing devices are affected?</strong></p>
<p>[A]
Computing devices based on Intel Core processors from the 6th Skylake to (including) the 11th Tiger Lake generation are affected. A more comprehensive list of affected processors will be available <a href="https://www.intel.com/content/www/us/en/developer/topic-technology/software-security-guidance/processors-affected-consolidated-product-cpu-model.html">here</a>.</p>
<p><strong>[Q] What can a hacker do with this?</strong></p>
<p>[A]
A hacker can target high-value credentials such as passwords and encryption keys. Recovering such credentials can lead to other attacks that violate the availability and integrity of computers in addition to confidentiality.</p>
<p><strong>[Q] How practical are these attacks?</strong></p>
<p>[A]
GDS is highly practical. It tooks me 2 weeks to develop an end-to-end attack stealing encryption keys from OpenSSL. It only requires the attacker and victim to share the same physical processor core, which frequently happens on modern-day computers, implementing preemptive multitasking and simultaneous multithreading.</p>
<p><strong>[Q] Is Intel SGX also affected?</strong></p>
<p>[A]
In addition to normal isolation boundaries e.g., virtual machines, processes, user-kernel isolation, Intel SGX is also affected. Intel SGX is a hardware security feature available on Intel CPUs to protect user’s data against all form of malicious software.</p>
<p><strong>[Q] What about web browsers?</strong></p>
<p>[A] In theory, remotely exploiting this vulnerability from the web browser is possible. In practice, demonstrating successful attacks via web browsers requires additional research and engineering efforts.</p>
<p><strong>[Q] How long have users been exposed to this vulnerability?</strong></p>
<p>[A] At least nine years. The affected processors have been around since 2014.</p>
<p><strong>[Q] Is there a way to detect Downfall attacks?</strong></p>
<p>[A]
It is not easy. Downfall execution looks mostly like benign applications. Theoretically, one could develop a detection system that uses hardware performance counters to detect abnormal behaviors like exessive cache misses. However, off-the-shelf Antivirus software cannot detect this attack.</p>
<p><strong>[Q] Is there any mitigation for Downfall?</strong></p>
<p>[A]
Intel is releasing a microcode update which blocks transient results of gather instructions and prevent attacker code from observing speculative data from <em>Gather</em>.</p>
<p><strong>[Q] What is the overhead for the mitigation?</strong></p>
<p>[A]
This depends on whether <em>Gather</em> is in the critical execution path of a program. According to Intel, some workloads may experience up to 50% overhead.</p>
<p><strong>[Q] Can I disable the mitigation if my workload does not use Gather?</strong></p>
<p>[A]
This is a bad idea. Even if your workload does not use vector instructions, modern CPUs rely on vector registers to optimize common operations, such as copying memory and switching register content, which leaks data to untrusted code exploiting <em>Gather</em>.</p>
<p><strong>[Q] How long was this vulberability under embargo?</strong></p>
<p>[A]
Almost one year. I reported this vulnerability to Intel August 24, 2022.</p>
<p><strong>[Q] Should other processor vendors and designers be concerned?</strong></p>
<p>[A]
Other processors have shared SRAM memory inside the core, such as hardware register files and fill buffers. Manufacturers must design shared memory units with extra care to prevent data from leaking across different security domains and invest more in security validation and testing.</p>
<p><strong>[Q] How can I learn more about Downfall?</strong></p>
<p>[A]
In addition to the technical <a href="https://downfall.page/media/downfall.pdf">paper</a>, I am presenting Downfall at the <a href="https://www.blackhat.com/us-23/briefings/schedule/">BlackHat USA on August 9th, 2023</a> and <a href="https://www.usenix.org/conference/usenixsecurity23/presentation/moghimi">USENIX Security Symposium on August 11, 2023</a>.</p>
<p><strong>[Q] Can I play with Downfall?</strong></p>
<p>[A]
Here is the code: <a href="https://github.com/flowyroll/downfall/tree/main/POC">https://github.com/flowyroll/downfall/tree/main/POC</a></p>
<p><strong>[Q] Why is this called Downfall?</strong></p>
<p>[A]
Downfall defeats fundamental security boundaries in most computers and is a successor to previous data leaking vulnerabilities in CPUs including <a href="https://meltdownattack.com/">Meltdown</a> and <a href="https://mdsattacks.com/">Fallout</a> (AKA MDS). In this trilogy, <strong>Downfall</strong> defeats all previous mitigations once again.</p>
<p><strong>[Q] How did you create the logo?</strong></p>
<p>[A]
I used the <a href="https://openai.com/dall-e-2">DALL·E 2</a> AI system to create the logo.</p>
<!-- raw HTML omitted -->
<!-- raw HTML omitted -->
<hr>
<h2 id="advisories">Advisories</h2>
<table>
<thead>
<tr>
<th>Vendor</th>
<th>Link</th>
</tr>
</thead>
<tbody>
<tr>
<td>MITRE</td>
<td><a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2022-40982">CVE-2022-40982</a></td>
</tr>
<tr>
<td>Intel</td>
<td><a href="https://www.intel.com/content/www/us/en/security-center/advisory/intel-sa-00828.html">INTEL-SA-00828</a></td>
</tr>
</tbody>
</table>
<hr>
<h2 id="links">Links</h2>
<ul>
<li>
<p><a href="https://www.darkreading.com/edge/meet-the-finalists-for-the-2023-pwnie-awards">Meet the Finalists for the 2023 Pwnie Awards</a> by Dark Reading</p>
</li>
<li>
<p><a href="https://www.intel.com/content/www/us/en/developer/articles/technical/softwaresecurity-guidance/technical-documentation/gather-data-sampling.html">Gather Data Sampling Technical Paper</a> by Intel</p>
</li>
<li>
<p><a href="https://www.intel.com/content/www/us/en/developer/topic-technology/softwaresecurity-guidance/best-practices/threat-analysis-gds.html">Threat Analysis Assessment for GDS Paper</a> by Intel</p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=PjbJs2yZNKk&amp;t=1s">Episode 56: Interview with Daniel Moghimi about Downfall</a> by Chips &amp; Salsa</p>
</li>
</ul>


  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Uninstall the NightOwl macOS app now (936 pts)]]></title>
            <link>https://robins.one/notes/uninstall-the-nightowl-app-now.html</link>
            <guid>37052508</guid>
            <pubDate>Tue, 08 Aug 2023 17:23:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robins.one/notes/uninstall-the-nightowl-app-now.html">https://robins.one/notes/uninstall-the-nightowl-app-now.html</a>, See on <a href="https://news.ycombinator.com/item?id=37052508">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>
<time datetime="2023-06-28 00:00:00 +0000">28/06/2023</time>
</p>

<h2 id="intro">Intro</h2>
<p>The NightOwl application has existed since 2018 and is used to automatically switch between light/dark modes on the operating system. It is an alternative to the built in macOS automatic mode which only switches when the user steps away from the computer.</p>
<p>However, the application has been bought out by “TPE.FYI LLC” in late 2022<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> that forcibly joins your devices into a botnet for use of market research, without your knowledge (other than the TOS in small text on the download page) or express consent (this feature cannot be turned off, even when the app is quit). This is documented in their terms of service<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>:</p>
<blockquote>
<p>•WHEREAS, NightOwl app enables Users to share internet traffic by modifying their device’s network settings to be used as a gateway for internet traffic. Additionally, the User’s device acts as a gateway for NightOwl app’s Clients, including companies that specialize in web and market research, SEO, brand protection, content delivery, cybersecurity, etc.</p>
</blockquote>
<p>We have contacted NightOwl regarding this, and haven’t recieved a response yet.</p>
<h2 id="removal">Removal:</h2>
<p>Run these commands in Terminal, if you have the app installed <strong>at all</strong>, even if you don’t have it running.</p>
<div><pre><code>sudo killall NightOwl
launchctl unload ~/Library/LaunchAgents/NightOwlUpdater.plist
sudo killall AutoUpdate
sudo rm -rf /Applications/NightOwl.app/ ~/Library/LaunchAgents/NightOwlUpdater.plist
sudo zsh -c "rm /Users/*/Library/LaunchAgents/NightOwlUpdater.plist"
</code></pre></div>
<h2 id="technical-details">Technical Details</h2>
<p>The application, on install registers a launch agent named <code>org.nightowl.autoupdater.com</code><sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>. This is used to daemonize the process <code>/Applications/NightOwl.app/Contents/Helpers/AutoUpdate</code>, which runs as root, at boot, and cannot be disabled through the application. This happens silently, without the users knowledge or consent other than the following notice<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup></p>
<blockquote>
<p>In order to <strong>improve the App</strong>, NightOwl uses <strong>Google Analytics</strong> to collect Statistics. The tracked data helps to enhance NightOwl by analysing how <strong>features</strong> are used and which <strong>bugs</strong> appear. <br>
We initialize Google Analytics with the setting “anonymizeIp”. This guarantees <strong>anonymized data collection</strong> by masking the last part of your IP address. <br>
You are able to <strong>Opt-out</strong> of the tracking by <strong>unchecking “Send Statistics”</strong> in the <strong>settings</strong> section of NightOwl.</p>
</blockquote>
<p>Turning off send statistics does not disable the launch agent.</p>
<p>The ‘autoupdater’ does three things,</p>
<ul>
<li>check the app for updates (using Sparkle)</li>
<li>report any crashes (using Sentry)</li>
<li>start a local HTTP proxy on port <code>40701</code> (this can be changed using the configuration json file in the app bundle).</li>
</ul>
<p>The latter is of course, not to be expected of any app on the machine, especially not one that just claims to be an auto updater.</p>
<p>The daemon uses ‘sudo’ to switch from running as the root user, to the main user account, and then starts an instance of <code>nightowl_t.dylib</code> (which is actually a copy of <a href="https://github.com/tinyproxy/tinyproxy">tinyproxy</a>, which is licensed under GPLv2, and does not contain the GPL license notice, so this might actually be a violation!), which acts as a HTTP(S) proxy and runs on port , It opens up a SSH connection (using autossh, renamed <code>nightowl_a.dylib</code>, which doesn’t have a license) to <code>testconnectuser2023@proxy-gw1-europe.squidyproxy.com</code> on port <code>2043</code>, using a public key it drops in <code>/tmp</code> (it has a <code>.uu</code> extension), using the <code>-R</code> port to tunnel a port on the remote machine to the local machine. (it retrieves this by making a request to proxy-api1.squidyproxy.com over HTTPS). This domain was registered with GoDaddy in April 2022, and the IP address is hosted by Microsoft.</p>
<p>For reference, this SSH server has shell access enabled. (I didn’t try anything though). After the connection succeeds, it forwards HTTP traffic down to you, which gets proxied out of your internet connection. I saw it trying to access . It also tries to open a UPnP port forward on your router, but fails on mine because the key names are jumbled:</p>
<div><pre><code><span>POST</span> <span>/ctl/IPConn</span> <span>HTTP</span><span>/</span><span>1.1</span>
<span>Host</span><span>:</span> <span>192.168.1.1:5000</span>
<span>User-Agent</span><span>:</span> <span>Go-http-client/1.1</span>
<span>Content-Length</span><span>:</span> <span>526</span>
<span>CONTENT-TYPE</span><span>:</span> <span>text/xml; charset="utf-8"</span>
<span>SOAPACTION</span><span>:</span> <span>"urn:schemas-upnp-org:service:WANIPConnection:1#AddPortMapping"</span>
<span>Accept-Encoding</span><span>:</span> <span>gzip</span>

<span>&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span>
<span>&lt;s:Envelope</span> <span>xmlns:s=</span><span>"http://schemas.xmlsoap.org/soap/envelope/"</span> <span>s:encodingStyle=</span><span>"http://schemas.xmlsoap.org/soap/encoding/"</span><span>&gt;&lt;s:Body&gt;&lt;u:AddPortMapping</span> <span>xmlns:u=</span><span>"urn:schemas-upnp-org:service:WANIPConnection:1"</span><span>&gt;&lt;BznVVp_&gt;&lt;/BznVVp_&gt;&lt;A8Lx50LV3wS&gt;</span>50276<span>&lt;/A8Lx50LV3wS&gt;&lt;SOkiBsutQ&gt;</span>TCP<span>&lt;/SOkiBsutQ&gt;&lt;C7V6rYTZpovv&gt;</span>50276<span>&lt;/C7V6rYTZpovv&gt;&lt;S8pOPFbT13z&gt;</span>192.168.3.102<span>&lt;/S8pOPFbT13z&gt;&lt;AQBzrw&gt;</span>1<span>&lt;/AQBzrw&gt;&lt;O9hZpuXGWURb&gt;</span>ip royal paws<span>&lt;/O9hZpuXGWURb&gt;&lt;BBYmUz7H&gt;</span>2592000<span>&lt;/BBYmUz7H&gt;&lt;/u:AddPortMapping&gt;&lt;/s:Body&gt;&lt;/s:Envelope&gt;</span>
</code></pre></div>
<p>The application also seems to use the <a href="https://pawns.app/">Pawns</a> SDK<sup id="fnref:3:1" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>, which is an app offers to pay users $0.20 per GB of their internet shared<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup>. This service is operated by <a href="https://iproyal.com/">IPRoyal</a><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup>, a proxy company that will sell you residential proxy connections for $1.75/GB, and advertises “100% ethically sourced IPs”<sup id="fnref:7" role="doc-noteref"><a href="#fn:7" rel="footnote">7</a></sup>.</p>
<h2 id="but-just-who-is-tpefyi-llc">But just who is “TPE.FYI LLC”?</h2>
<p>TPE (or Keeping Tempo, or Tempo AI (not to be confused with the Tempo AI calendar or the Tempo AI gym)) is “in the process of building a pricing model based on various analytics such as YouTube video views for an artist and geographical popularity data that will allow venues to price their tickets based on actual demand for an artist.”<sup id="fnref:8" role="doc-noteref"><a href="#fn:8" rel="footnote">8</a></sup> Information is sparse, and little information past 2018 exists. The application, at least the time of writing, and the installations I’ve been made aware of, makes a lot of connections to https://stubbs.frontgatetickets.com/, a website that sells tickets to live music events for a restaurant in Austin, TX.</p>
<p>The company was incorporated in September 2018 in Austin, Texas, and was dissolved in March 2023 by a “Jarod Stirling”<sup id="fnref:9" role="doc-noteref"><a href="#fn:9" rel="footnote">9</a></sup>, who lives in Apartment 443 (hah, nice), The Muse at SoCo, 1007 South Congress Avenue, Austin, Texas, 78704.</p>

<p>If you have any more information, I can be contacted at:</p>
<ul>
<li><a href="mailto:taylor@robins.one">taylor@robins.one</a></li>
<li><a href="https://t.me/tayiorrobinson">t.me/tayiorrobinson</a></li>
</ul>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Inception: A simple XOR can cause a Microarchitectural Stack Overflow (114 pts)]]></title>
            <link>https://comsec.ethz.ch/research/microarch/inception/</link>
            <guid>37051423</guid>
            <pubDate>Tue, 08 Aug 2023 16:20:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://comsec.ethz.ch/research/microarch/inception/">https://comsec.ethz.ch/research/microarch/inception/</a>, See on <a href="https://news.ycombinator.com/item?id=37051423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
			<!-- If has sidebar start -->
	<main id="main">
		<div>
			<!-- If has sidebar end -->
							<article id="post-1131" class="page">
										<!-- .entry-header -->
					<div>
						
<p>Over the past one and a half years, we have studied two phenomena that enable an unprivileged attacker to leak arbitrary information on all modern AMD CPUs:</p>



<ul>
<li><strong>Phantom speculation: </strong>We can trigger misprediction without any branch at the source of the misprediction.</li>



<li><strong>Training in Transient Execution: </strong>We can manipulate future mispredictions through a previous misprediction that we trigger.</li>
</ul>



<p>Putting the two together gives rise to a new type of attack called <strong>Inception</strong>: we can inject future mispredictions through a previous misprediction that we trigger — in the absence of branches. You can see a demo of Inception and find more information about the issues below:</p>



<figure><p>
<iframe title="Inception: leaking the root hash from /etc/shadow on AMD Zen 4" width="780" height="439" src="https://www.youtube.com/embed/2wCjU8iJ9G4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p></figure>



<hr>







<p>Inception (<a href="https://www.cve.org/CVERecord?id=CVE-2023-20569">CVE-2023-20569</a>) is a novel transient execution attack that leaks arbitrary data on all AMD Zen CPUs in the presence of all previously deployed software- and hardware mitigations. As in the movie of the same name, Inception plants an “idea” in the CPU while it is in a sense “dreaming”, to make it take wrong actions based on supposedly self conceived experiences. Using this approach, Inception hijacks the transient control-flow of return instructions on all AMD Zen CPUs.</p>



<h2>Training in Transient Execution (TTE)</h2>



<p>Inception is an instance of a new class of transient execution attacks that do their Training in Transient Execution (TTE). Instead of attempting to leak data in a transient window, TTE attacks abuse the transient window to insert new predictions into the branch predictor instead. These newly inserted predictions trigger future transient windows which can be more powerful than the initial one. TTE attacks thus turn supposedly harmless transient windows into dangerous ones, by abusing the victim as a confused deputy that trains itself in a transient window.</p>



<h2>Phantom speculation</h2>



<p>Although TTE attacks are interesting, they are not necessarily trivial to pull off, due to the need for specific gadgets in the victim code. Instead of these hard-to-find gadgets, what if there was an easier way to achieve a transient window for training? This is where <strong>Phantom speculation</strong> comes in. Phantom (<a href="https://www.cve.org/CVERecord?id=CVE-2022-23825">CVE-2022-23825</a>) enables an attacker to create a transient window at <em>arbitrary instructions</em>. Suddenly, a seemingly harmless XOR instruction can behave like a call instruction, and allow the attacker to create a transient window.</p>



<h2>Inception: A Combination of TTE and Phantom</h2>



<p>During our research, we found that merely a prediction for a specific instruction already manipulates the branch predictor. This enables us to insert new predictions in the branch predictor using only predictions of branches, even if they do not match reality, i.e. using a non-existing Phantom control flow. With Phantom, we can thus enable TTE by turning the CPU into a confused deputy that trains itself while running the victim.&nbsp; The result of this insight is Inception, an attack that leaks arbitrary data from an unprivileged process on all AMD Zen CPUs. Inception makes the CPU believe that a XOR instruction is a recursive call instruction which overflows the return stack buffer with an attacker-controlled target.</p>



<h2>Mitigations</h2>



<div><p>To fully mitigate Inception, the branch predictor state has to be fully flushed while switching between distrusting contexts. We found that on Zen 1(+) and Zen 2, this comes with a hefty overhead between 93.1% and 216.9%, depending on the specific microarchitecture. On Zen 3 and Zen 4, we did not find proper hardware support to flush the entire branch predictor state. AMD have released microcode to enable this feature.</p><p>Instead of flushing the entire branch predictor state, AMD proposed a different mitigation for the Linux kernel. By reducing all returns in the kernel to a single one, it becomes possible to ensure a safe (but still incorrect) branch predictor state each time this return is executed. Keeping <a href="https://support.google.com/faqs/answer/7625886">previous mitigations</a> in mind, this effectively means that AMD opted to have all indirect branches forcibly mispredict to a benign location, preventing Inception attacks.</p></div>



<h2>Resources</h2>



<p>A <a href="https://comsec.ethz.ch/wp-content/files/inception_sec23.pdf">paper</a> about Inception is going to be presented at <a href="https://comsec.ethz.ch/wp-content/files/inception_sec22.pdf">USENIX Security 2023</a> and a <a href="https://comsec.ethz.ch/wp-content/files/phantom_micro23.pdf">paper</a> about Phantom speculation is going to be presented at<a href="https://microarch.org/micro56/"> MICRO 2023</a>. You can find the source code of Inception on our <a href="https://github.com/comsec-group/inception">Github</a>. We will publish the source code of Phantom at a later date.</p>



<h2>FAQ</h2>



<ul>
<li><strong><strong>Is my machine affected?</strong></strong><p>If it embodies an AMD CPU, your machine is vulnerable to Inception and Phantom.</p></li>



<li><strong>What is the difference between Inception and Phantom?</strong><p>Inception leverages Training in Transient Execution (TTE) to add malicious branch prediction targets to the branch predictor. Phantom allows for triggering transient windows from arbitrary instructions, facilitating TTE and enabling Inception attacks.</p></li>



<li><strong>Does Inception affect CPUs other than AMD?</strong><p>No, but our analysis shows that Intel CPUs are vulnerable to certain TTE variants. While this certainly increases the known attack surface of transient execution attacks, it remains to be seen whether practical exploitation is possible on Intel CPUs.</p></li>



<li><strong>Does Phantom affect CPUs other than AMD?</strong><p>Yes, our analysis shows that Phantom also affects CPUs from Intel. However, the eIBRS mitigation makes Phantom exploitation non-trivial on these CPUs.</p></li>



<li><strong>Are only Linux systems affected?</strong><p>Although our proof-of-concept attacks require the system to be running Linux, Inception and Phantom fundamentally exploit vulnerabilities in the hardware. Therefore, any system with an affected CPU can potentially be the target of a Phantom or Inception attack, regardless of the running software.</p></li>



<li><strong>What should I do?</strong><p>Install the latest operating system updates.</p></li>
</ul>
					</div><!-- .entry-content -->
				</article><!-- #post -->
							<!-- If has sidebar start -->
		</div>
				<!-- If has sidebar end -->
		</main><!-- .site-main -->
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Do you avoid the news? You’re in growing company (158 pts)]]></title>
            <link>https://www.washingtonpost.com/media/2023/08/01/news-avoid-depressing/</link>
            <guid>37050960</guid>
            <pubDate>Tue, 08 Aug 2023 15:53:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/media/2023/08/01/news-avoid-depressing/">https://www.washingtonpost.com/media/2023/08/01/news-avoid-depressing/</a>, See on <a href="https://news.ycombinator.com/item?id=37050960">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/media/2023/08/01/news-avoid-depressing/: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Chat with your data using LangChain, Pinecone, and Airbyte (185 pts)]]></title>
            <link>https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain</link>
            <guid>37050532</guid>
            <pubDate>Tue, 08 Aug 2023 15:32:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain">https://airbyte.com/tutorials/chat-with-your-data-using-openai-pinecone-airbyte-and-langchain</a>, See on <a href="https://news.ycombinator.com/item?id=37050532">Hacker News</a></p>
<div id="readability-page-1" class="page"><div fs-toc-offsettop="8rem" fs-toc-element="contents" fs-codehighlight-theme="base16/harmonic16-dark" fs-richtext-element="rich-text"><p>In <a href="https://airbyte.com/tutorials/implement-ai-data-pipelines-with-langchain-airbyte-and-dagster" target="_blank">a previous article</a>, we explained how Dagster and Airbyte can be leveraged to power LLM-supported use cases. Our newly introduced <a href="https://docs.airbyte.com/integrations/destinations/langchain/" target="_blank">vector database destination</a> makes this even easier as it removes the need to orchestrate chunking and embedding manually - instead the sources can be directly connected to the vector database through an Airbyte connection.</p><p>This tutorial walks you through a real-world use case of how to leverage vector databases and LLMs to make sense out of your unstructured data. By the end of this, you will:</p><ul role="list"><li>Know how to extract unstructured data from a variety of sources using Airbyte</li><li>Know how to use Airbyte to efficiently load data into a vector database, preparing the data for LLM usage along the way</li><li>Know how to integrate a vector database into your LLM to ask questions about your proprietary data</li></ul><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64be8f601730eafec46db241_KR_NhEQHHKlCFQxGekCCZdyUKzTB8CusOu6_bCHvWP3Rv1q2oQdmZ6dh3iIw2lGTceGyt6J8MsHWrZRv5IbYgOv7rQeaD4q0Bb0IxfBfjgq3eB-CFdaWy0pzREjG7wtzBMyzpO3a9Zwfyn8H4r64hhc.png" alt=""></p></figure><h2>What we will build</h2><p>To better illustrate how this can look in practice, let’s use something that’s relevant for Airbyte itself.</p><p>Airbyte is a highly extensible system that allows users to develop their own connectors to extract data from any API or internal systems. Helpful information for connector developers can be found in different places:</p><ul role="list"><li>The official connector development documentation website</li><li>Github issues documenting existing feature requests, known bugs and work in progress</li><li>The community Slack help channel</li></ul><p>This article describes how to tie together all of these diverse sources to offer a single chat interface to access information about connector development - a bot that can answer questions in plain english about the code base, documentation and reference previous conversations:</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf32950aef8ef8c796036f_V1GY2h5GAs1bIkKp2J43I-geDugBrCqpnpuAyJ7y9pxalBNnLRSsDoV5r5dTK5imoJI8bxuIVPW88msowFqys6qfkQQ43c_Z13EgR79BuH30JrHsXqhh8JomGA1Qq5cuc3kwYLTzgJbGbhH7cI4ijEI.png" alt=""></p></figure><p>In these examples, information from the documentation website and existing Github issues is combined in a single answer.</p><h2>Prerequisites</h2><p>For following through the whole process, you will need the following accounts. However, you can also work with your own custom sources and use a local vector store to avoid all but the OpenAI account:</p><p><strong>1. Source-specific accounts</strong></p><ul role="list"><li>Apify account</li><li>Github account</li><li>Slack account</li></ul><p><strong>2. Destination-specific accounts</strong></p><ul role="list"><li>OpenAI account</li><li>Pinecone account</li></ul><p><strong>3. Airbyte instance (</strong><a href="https://docs.airbyte.com/deploying-airbyte/local-deployment/" target="_blank"><strong>local</strong></a><strong> or </strong><a href="https://cloud.airbyte.com/" target="_blank"><strong>cloud</strong></a><strong>)</strong></p><h2>Step 1 - Fetch Github issues</h2><p>Airbyte’s feature and bug tracking is handled by the <a href="https://github.com/airbytehq/airbyte/issues" target="_blank">Github issue tracker</a> of the Airbyte open source repository. These issues contain important information people need to look up regularly.</p><p>To fetch Github issues, create a new source using the Github connector.</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3296e8c576bff0a4b227_cmEnI4qaIn3kA-E9M8Lqui-SeqPKNPrS5LMWOh9Y06VB7Eqy33TJS12o3W6bV6i3iYmhNGtkz_k1bO2OJOkZUpcKrmxyj-sszksKny5gLHNaKdp7RjS9i6MawIOzS4x4jU-8l2wMjPnZX6dzW-Gq2bE.png" alt=""></p></figure><p>If you are using Airbyte Cloud , you can easily authenticate using the “Authenticate your GitHub account”, otherwise follow the instructions in the documentation on the right side of how to set up a <a href="https://github.com/settings/tokens" target="_blank">personal access token</a> in the Github UI.</p><p>Next, configure a cutoff date for issues and specify the repositories that should be synced. In this case I’m going with “2023-07-01T00:00:00Z” and “airbytehq/airbyte” to sync recent issues from the main Airbyte repository:</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3294bd18871ab53b534b_b1SG5Nk65k4_adaHKv9Gyyp8ssHELtDdn07xdwwG4Wtd0ijLXTUuhCcjdRbwGQg3cmAKgCN-9fiYtcbY2qpCH32Mc8dZDPcXTHOMpXxy9Y4bL64_3Vb8Nk-i1SkPjWyojaJOrVjlQ1ofXBbFLzI4cxU.png" alt=""></p></figure><h2>Step 2 - Load into vector database</h2><p>Now we have our first source ready, but Airbyte doesn’t know yet where to put the data. The next step is to configure the destination. To do so, pick the “Vector Database (powered by LangChain)”. There is some preprocessing that Airbyte is doing for you so that the data is vector ready:</p><ul role="list"><li>Separating text and metadata fields and splitting up records into multiple documents to keep each document focused on a single topic and to make sure the text fits into the context window of the LLM that’s going to be used for question answering</li></ul><ul role="list"><li>Embedding the text of every document using the configured embedding service, turning the text into a vector to do similarity search on</li><li>Indexing the documents into the vector database (uploading the vector from the embedding service along with the metadata object)</li></ul><p>The vector database destination currently supports two different vector databases (with more to come) - Pinecone, which is a hosted service with a free tier and Chroma which stores the vector database in a local file.</p><p>For using Pinecone, sign up for a <a href="https://app.pinecone.io/?sessionType=signup" target="_blank">free trial account</a> and create an index using a starter pod. Set the dimensions to <strong>1536</strong> as that’s the size of the OpenAI embeddings we will be using</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329550014214567eb21e_XCRydu23sUl92Kv6lhY5yrm564yhw4T7hltxT1n8alhWxwonxvhgCYr_B1Ql6OIuqUtjrfyKbqFRBw1kPHYZhknXW1xkepJLPa8xgB2JdN9bI5X3Eyx6rsnBW7OQLfji-vjoThs8FagLaD70yZLxP0c.png" alt=""></p></figure><p>Once the index is ready, configure the vector database destination in Airbyte:</p><ul role="list"><li>Set chunk size to <strong>1000</strong> (the size refers to number of tokens, not characters, so this is roughly 4KB of text. The best chunking is dependent on the data you are dealing with)</li><li>Configure the records fields to treat as text fields which will be embedded. All other fields will be handled as metadata. For now, set it “<strong>title</strong>” and “<strong>body</strong>” as these are the relevant feels in the issue stream of the Github source</li><li>Set your OpenAI api key for powering the embedding service. You can find your API key in the API keys section of the <a href="https://platform.openai.com/account" target="_blank">platform.openai.com/account</a> page</li><li>For the indexing step, copy over index, environment and api key from the Pinecone UI. You can find the API key and the environment in the “API Keys” section in the UI</li></ul><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3296bd18871ab53b53dc_Pp3o4YoGrQu-DFt6b9dslx6hleweOuSfkF_azqQ767s8jun3ufqdUFvZQ8ec2k3jVqR9yVELuZKfZFwPTsXTnrfiusVsNJ4zaT80OHrs2yXQF4jtb6tUKtuKzi7BpR8oqrUYUCgeI1GTxb0QMuRnrFc.png" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329552b401ed4357cc88_hDduQ9SU74XXYofV6o_iUtSzSlPQdr_aPA4nwRq96nKLGdfcqopaHIepMsy0YTI4lY81UXxkpdI3yR6AgbUkGDJuvBXwCIFTIdbMjTHKHlYt-SNGM1w5BD4JX6S0eAstmuRG1IUns_QZewWiTLWW1bA.png" alt=""></p></figure><h2>Step 3 - Create a connection</h2><p>Once the destination is set up successfully, set up a connection from the Github source to the vector database destination. In the configuration flow, pick the existing source and destination. When configuring the connection, make sure to only use the “issues” stream, as this is the one we are interested in.</p><p>Side note: Airbyte allows to make this sync more efficient in a production environment:</p><ul role="list"><li>To keep the metadata focused, you can click on the stream name to select the individual fields you want to sync. For example if the “assignee” or the “milestone” field is never relevant to you, you can uncheck it and it won’t be synced to the destination.</li><li>The sync mode can be used to sync issues incrementally while deduplicating the records in the vector database so no stale data will show up in searches</li></ul><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3296d9d267abe7e5b794_tVVBMEXjO0Cvkb_BGnx3JF3X7fvQAyjcyrdqowx79Hkb9FVlWrnnt2Paxfsn3B2pvcF4ejK0kBohZLNszFL5dz8YHVb18DaFOMO3wU9PFkxT8s9uTnhO9SBLRxLsRVQ3-I5ffolcruddp8v-A2Xqcqw.png" alt=""></p></figure><p>If everything went well, there should be a connection now syncing data from Github to Pinecone via the vector store destination. Give the sync a few minutes to run. Once the first run has completed, you can check the <a href="https://app.pinecone.io/" target="_blank">Pinecone index management page</a> to see a bunch of indexed vectors ready to be queried. </p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3296b8a6b3413b184c06_L6D9vLZf8huWjjiswHbC6c6lwNY9x0lZ91htAtNG8rc5dQztZg-QPupkAIlzKkM5Gi4-Zbi1dfMkVzKQHQimaXUnU67QguAqRpAHlwWQr_XyktA96A2KgaGTE2y4ar9nn0sf8tII6no7hT3CrU_-Wf0.png" alt=""></p></figure><p>Each vector is associated with a metadata object that’s filled with the fields that were not mentioned as “text fields” in the destination configuration. These fields will be retrieved along with the embedded text and can be leveraged by our chatbot in later sections. This is how a vector with metadata looks like when retrieved from Pinecone:</p><div><pre><code>{
      "id": "599d75c8-517c-4f37-88df-ff16576bd607",
      "values": [0.0076571689, ..., 0.0138477711],
      "metadata": {
        "_airbyte_stream": "issues",
        "_record_id": 1556650122,
        "author_association": "CONTRIBUTOR",
        "comments": 3,
        "created_at": "2023-01-25T13:21:50Z",
        // ...
        "text": "...The acceptance-test-config.yml file is in a legacy format. Please migrate to the latest format...",
        "updated_at": "2023-07-17T09:20:56Z",
      }
}
</code></pre></div><p>On subsequent runs, Airbyte will only re-embed and update the vectors for the issues that changed since the last sync - this will speed up subsequent runs while making sure your data is always up-to-date and available.</p><h2>Step 4 - Chat interface</h2><p>The data is ready, now let’s wire it up with our LLM to answer questions in natural language. As we already used OpenAI for the embedding, the easiest approach is to use it as well for the question answering.</p><p>We will use Langchain as an orchestration framework to tie all the bits together.</p><p>First, install a few pip packages locally:</p><div><pre><code>pip install pinecone-client langchain openai</code></pre></div><p>The basic functionality here works the following way:</p><ul role="list"><li>User asks a question</li><li>The question is embedded using the same model used for generating the vectors in the vector database (OpenAI in this case)</li><li>The question vector is sent to the vector database and documents with similar vectors are returned - as the vectors represent the meaning of the text, the question and the answer to the question will have very similar vectors and relevant documents will be returned</li><li>The text of all documents with the relevant metadata are put together into a single string and sent to the LLM together with the question the user asked and the instruction to answer the user’s question based on the provided context</li><li>The LLM answers the question based on the provided context</li><li>The answer is presented to the user</li></ul><p>This flow is often referred to as <a href="https://docs.aws.amazon.com/sagemaker/latest/dg/jumpstart-foundation-models-customize-rag.html" target="_blank">retrieval augmented generation</a>. The RetrievalQA class from the Langchain framework already implements the basic interaction. The simplest version of our question answering bot only has to provide the vector store and the used LLM:</p><div><pre><code># chatbot.py
import os
import pinecone
from langchain.chains import RetrievalQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.vectorstores import Pinecone

embeddings = OpenAIEmbeddings()
pinecone.init(api_key=os.environ["PINECONE_KEY"], environment=os.environ["PINECONE_ENV"])
index = pinecone.Index(os.environ["PINECONE_INDEX"])
vector_store = Pinecone(index, embeddings.embed_query, "text")

qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type="stuff", retriever=vector_store.as_retriever())

print("Connector development help bot. What do you want to know?")
while True:
    query = input("")
    answer = qa.run(query)
    print(answer)
    print("\nWhat else can I help you with:")</code></pre></div><p>To run this script, you need to set OpenAI and Pinecone credentials as environment variables:</p><div><pre><code>export OPENAI_API_KEY=...
export PINECONE_KEY=...
export PINECONE_ENV=...
export PINECONE_INDEX=...
python chatbot.py</code></pre></div><p>This works in general, but it has some limitations. By default, only the text fields are passed into the prompt of the LLM, so it doesn’t know what the context of a text is and it also can’t give a reference back to where it found its information:</p><div><pre><code>Connector development help bot. What do you want to know?
&gt; Can you give me information about how to authenticate via a login endpoint that 
returns a session token?


Yes, the GenericSessionTokenAuthenticator should be supported in the UI[...]</code></pre></div><p>From here, there’s lots of fine tuning to do to optimize our chat bot. For example we can improve the prompt to contain more information based on the metadata fields and be more specific for our use case:</p><div><pre><code>prompt_template = """You are a question-answering bot operating on Github issues and documentation pages for a product called connector builder. 
The documentation pages document what can be done, the issues document future plans and bugs. 
Use the following pieces of context to answer the question at the end. 
If you don't know the answer, just say that you don't know, don't try to make up an answer. 
Always state were you got this information from (and the github issue number if applicable).
If the answer is based on a Github issue that's not closed yet, add 'This issue is not closed yet - the feature might not be shipped yet' to the answer.

{context}

Question: {question}
Helpful Answer:"""

prompt = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

class ConnectorDevelopmentPrompt(PromptTemplate):
    def format_document(doc: Document, prompt: PromptTemplate) -&gt; str:
        if doc.metadata["_airbyte_stream"] == "issues":
            return f"Excerpt from Github issue: {doc.page_content}, issue number: {doc.metadata['number']}, issue state: {doc.metadata['state']}"
        else:
            return super().format_document(doc, prompt)

document_prompt = ConnectorDevelopmentPrompt(input_variables=["page_content"], template="{page_content}")
qa = RetrievalQA.from_chain_type(llm=OpenAI(temperature=0), chain_type="stuff", retriever=vector_store.as_retriever(), chain_type_kwargs={"prompt": prompt, "document_prompt": document_prompt})</code></pre></div><p>The full script also be found <a href="https://github.com/airbytehq/tutorial-connector-dev-bot/blob/main/localbot_adapted.py">on Github</a></p><p>This revised version of the RetrievalQA chain customizes the prompts that are sent to the LLM after the context has been retrieved:</p><ul role="list"><li>The basic prompt template sets the broader context what this question is about (previously the LLM had to guess from the documents)</li><li>It also changes the way documents are added to the prompt - by default, only the text is added, but the ConnectorDevelopmentPrompt implementation sets the context where the data is coming from and also adds relevant metadata to the prompt so the LLM can base its answer on more than just the text</li></ul><div><pre><code>Connector development help bot. What do you want to know?
&gt; Can you give me information about how to authenticate via a login endpoint that 
returns a session token?

You can use the GenericSessionTokenAuthenticator to authenticate via a login endpoint 
that returns a session token. This is documented in the Connector Builder 
documentation with an example of how the request flow functions (e.g. metabase). This 
issue is not closed yet - the feature might not be shipped yet (Github issue #26341).</code></pre></div><h2>Step 5 - Put it on Slack</h2><p>So far this helper can only be used locally. However, using the python slack sdk it’s easy to turn this into a Slack bot itself.</p><p>To do so, we need to set up a Slack “App” first. Go to <a href="https://api.slack.com/apps" target="_blank">https://api.slack.com/apps</a> and create a new app based on the manifest <a href="https://raw.githubusercontent.com/airbytehq/tutorial-connector-dev-bot/main/slack_manifest.json" target="_blank">here</a> (this saves you some work configuring permissions by hand). After you set up your app, install it to the workspace you want to integrate with. This will generate a “Bot User OAuth Access Token” you need to note down. Afterwards, go to the “Basic information” page of your app, scroll down to “App-Level Tokens” and create a new token. Note down this “app level token” as well.</p><p>Within the regular Slack client, your app can be added to a slack channel by clicking the channel name and going to the “Integrations” tab:</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf32964c000a2e7a0f085e_7EqGxZDFTY9RU3DfPrg6bfuAfs4cpsRpo6vppyzyvshYrV8R1E8j5mKEEiTjiNsaYOJwrWBztzwxPKx1hznDHDnZeG9JZUbu-iStCdvnaKONR-MwtGDNlD4HUnlJATjKQO_EwCH1hcHozqJHeyVlCJs.png" alt=""></p></figure><p>After this, your Slack app is ready to receive pings from users to answer questions - the next step is to call Slack from within python code, so we need to install the python client library:</p><p>Afterwards, we can extend our existing chatbot script with a Slack integration:</p><div><pre><code>from slack_sdk import WebClient
from slack_sdk.socket_mode import SocketModeClient
from slack_sdk.socket_mode.request import SocketModeRequest
from slack_sdk.socket_mode.response import SocketModeResponse

slack_web_client = WebClient(token=os.environ["SLACK_BOT_TOKEN"])

handled_messages = {}

def process(client: SocketModeClient, socket_mode_request: SocketModeRequest):
    if socket_mode_request.type == "events_api":
        event = socket_mode_request.payload.get("event", {})
        client_msg_id = event.get("client_msg_id")
        if event.get("type") == "app_mention" and not handled_messages.get(client_msg_id):
            handled_messages[client_msg_id] = True
            channel_id = event.get("channel")
            text = event.get("text")
            result = qa.answer(text)
            slack_web_client.chat_postMessage(channel=channel_id, text=result)
    
    return SocketModeResponse(envelope_id=socket_mode_request.envelope_id)

socket_mode_client = SocketModeClient(
    app_token=os.environ["SLACK_APP_TOKEN"], 
    web_client=slack_web_client
)
socket_mode_client.socket_mode_request_listeners.append(process)

socket_mode_client.connect()
print("listening")
from threading import Event
Event().wait()
</code></pre></div><p>The full script also be found <a href="https://github.com/airbytehq/tutorial-connector-dev-bot/blob/main/slackbot.py" target="_blank">on Github</a></p><p>To run the script, the environment variables for the slack bot token and app token need to be added as environment variables as well:</p><div><pre><code>export SLACK_BOT_TOKEN=...
export SLACK_APP_TOKEN=...
python chatbot.py</code></pre></div><p>Running this, you should be able to ping the development bot application in the channel you added it to like a user and it will respond to questions by running the RetrievalQA chain that loads relevant context from the vector database and uses an LLM to formulate a nice answer:</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf32964c000a2e7a0f0881_vTyLpkj1MHbsiYFB2CICRWrozqvsiwvE4vdt_AFwqWpQgXbaMFQz4k2lslmJLVWaQVE9qNnTjiRCHEe_0D9I3CPyEeVEfGvkXoz9PIQwPne4DhxqDfRaUM5mBEW1XBstAr1bas4OAaKnxVYGBLYm40I.png" alt=""></p></figure><p>All the code can also be found <a href="https://github.com/airbytehq/tutorial-connector-dev-bot" target="_blank">on Github</a></p><h2>Step 6 - Additional data source: Scrape documentation website</h2><p>Github issues are helpful, but there is more information we want our development bot to know.</p><p>The <a href="https://docs.airbyte.com/connector-development/connector-builder-ui/overview/" target="_blank">documentation page</a> for connector development is a very important source of information to answer questions, so it definitely needs to be included. The easiest way to make sure the bot has the same information as what’s published, is to scrape the website. For this case, we are going to use the <a href="https://docs.airbyte.com/integrations/destinations/langchain/" target="_blank">Apify</a> service to take care of the scraping and turning the website into a nicely structured dataset. This dataset can be extracted using the Airbyte Apify Dataset source connector.</p><p>First, log into Apify and navigate to the store. Choose the “Web Scraper” actor as a basis - it already implements most of the functionality we need</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf32960aef8ef8c796039d_6R0PBxp9FZSvldwNjMaZHEE3MNg8k4jVomPTX_cIDysWYsA4cW26mn6S0mTKGWNVGWUlYBGftbG_O8g-FHlqcXSqqSiOrG_dr3kwO-sKKf1NHpGqy5npmDiruMpj8G0ZZExt9y61r8uLSp9CExLB8mE.png" alt=""></p></figure><p>Next, create a new task and configure it to scrape all pages of the documentation, extracting the page title and all of the content:</p><ul role="list"><li>Set Start URLs to <a href="https://docs.airbyte.com/connector-development/connector-builder-ui/overview/" target="_blank">https://docs.airbyte.com/connector-development/connector-builder-ui/overview/</a> , the intro page of the documentation linking to other pages</li><li>Set Link selector to a[href] to follow all links from every page</li><li>Set Glob Patterns to <a href="https://docs.airbyte.com/connector-development/connector-builder-ui/*" target="_blank">https://docs.airbyte.com/connector-development/connector-builder-ui/*</a> to limit the scraper to stick to the documentation and not crawl the whole internet</li><li>Configure the Page function to extract the page title and the content - in this case the content element can be found using the CSS class name</li></ul><div><pre><code>async function pageFunction(context) {
    const $ = context.jQuery;
    const pageTitle = $('title').first().text();
    const content = $('.markdown').first().text();

    return {
        url: context.request.url,
        pageTitle,
        content
    };
}
</code></pre></div><p>Running this actor will complete quickly and give us a nicely consumable dataset with a column for the page title and the content:</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329850014214567eb2ed_5xcWYKrZInzlQJs6pFlTemphPLS6V0L9A8x504bIgDm8B9bcmVo1-eaxpfwxt79RkXQg-zP6agQkgryy6TrY5j4EN6QNDkiaL8DVyOe61EKVocCO6w2uGjrQSLAGmvziyZ8gMakiWV48sLdZdmQbm9U.png" alt=""></p></figure><p>Now it’s time to connect Airbyte to the Apify data set - go to the Airbyte web UI and add your second Source - pick “Apify Dataset”</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf3297d40a4b1b7d0fe6b1_5nd8X3zhXv61VB0zU5hN6GtQsFErLtmdC_JMYaSrDqmpKi-gSmh8d2pxB_c0y6gmQUW1hj77bwAiGV9hTK21tI9MUaGuR92qZqttUAtuSVCzDHk2dQYn8O6ysKl-tKnkyGp4cueJ3Nf7-OTZhV3jVtk.png" alt=""></p></figure><p>To set up the Source, you only need to copy the dataset ID that’s shown in the “Storage” tap of the “Run” in the Apify UI</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329919c2fe31dee10424_Ujq9XkzeNwphZ2d5vxch_jM-lt1lcahHMWLPeywhrld5mzltPZ604mOv-ETKrvBCp-6YiY0j8lPpRy30Wc9BRjrsiGTmSRuJZZj-FMbnOhV0oSbsIZIA1eBervtu0XuqJyE8m27n_-29KJMUmI8RZOk.png" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf32980aef8ef8c7960424_tILg5dMD_pXDT1-FAogb6jvfm90hUPR4vfANJOdgTMkOF2vllP0H0HqFt3XWBE1qUD9KYKFHniHsNs1n6lV9Yr_7e7mo5mR_fvQHOKicsr6pzZJFK7RWjV5j2ELORHBgngmPwEgLo46YOppqV4y3r_g.png" alt=""></p></figure><p>Once the source is set up, follow the same steps as for the Github source to set up a connection moving data from the Apify dataset to the vector store. As the relevant text content is sitting in different fields, you also need to update the vector store destination - add <strong>data.pageTitle</strong> and <strong>data.content</strong> to the “text fields” of the destination and save.</p><h2>Step 7 - Additional data source: Fetch Slack messages</h2><p>Another valuable source of information relevant to connector development are Slack messages from the public help channel. These can be loaded in a very similar fashion. Create a new source using the Slack connector. When using cloud, you can authenticate using the “Authenticate your Slack account” button for simple setup, otherwise follow the instructions in the documentation on the right hand side how to create a Slack “App” with the required permissions and add it to your workspace. To avoid fetching messages from all channels, set the channel name filter to the correct channel.</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329862f87a60330875d1_1gjkCtJ_kGBeQzUhxy_ONp-rgrdguY-SPL_bZmqQPVQKxYYlJh6aIgnQj-pafIQXFBUNo6_ZfI0aSvGTRYpEO-Jwg3vyMQjvOqLYrOjKRZg0EIZSrarZFj5uIzpQ0RM7CzCdmmgrY0Ds54eLx0Msa7Q.png" alt=""></p></figure><p>As for Apify and Github, a new connection needs to be created to move data from Slack to Pinecone. Also add <strong>text</strong> to the “text fields” of the destination to make sure the relevant data gets embedded properly so similarity searches will yield the right results.</p><p>If everything went well, there should be three connections now, all syncing data from their respective sources to the centralized vector store destination using a Pinecone index.</p><figure><p><img src="https://assets-global.website-files.com/6064b31ff49a2d31e0493af1/64cf329b52b401ed4357cf3d_foNAVHB4HLrDJ-9AtJQbxt7tWUSM_-j9CwYd5TMVUx8SGvAcoMkI9AjOufJTsZuyMf3Q4lKAisy4b1iXNtDUS6pkhK3J2_kGs4vCm6YRHWOA2ic_be_9rHk4jm-v36IILxcyJOJspDenqV8hAuPTC9w.png" alt=""></p></figure><p>By adjusting the frequency of the connections, you can control how often Airbyte will rerun the connection to make sure the knowledge base of our chat bot stays up to date. As Github and Slack are frequently updated and support efficient incremental updates, it makes sense to set them to a daily frequency or higher. The documentation pages don’t change as often, so they can be kept at a lower frequency or even just be triggered on demand when there are changes.</p><p>As we have more sources now, let’s improve our prompt to make sure the LLM has all necessary information to formulate a good answer:</p><div><pre><code>class ConnectorDevelopmentPrompt(PromptTemplate):
    def format_document(doc: Document, prompt: PromptTemplate) -&gt; str:
        if doc.metadata["_airbyte_stream"] == "DatasetItems":
            return f"Excerpt from documentation page: {doc.page_content}"
        elif doc.metadata["_airbyte_stream"] == "issues":
            return f"Excerpt from Github issue: {doc.page_content}, issue number: {doc.metadata['number']}, issue state: {doc.metadata['state']}"
        elif doc.metadata["_airbyte_stream"] == "threads" or doc.metadata["_airbyte_stream"] == "channel_messages":
            return f"Excerpt from Slack thread: {doc.page_content}"
        else:
            return super().format_document(doc, prompt)</code></pre></div><p>By default the RetrievalQA chain retrieves the top 5 matching documents, so if it’s applicable the answer will be based on multiple sources at the same time:</p><div><pre><code>Connector development help bot. What do you want to know?
&gt; What different authentication methods are supported by the builder? Can I 
authenticate a login endpoint that returns a session token?

The authentication methods supported by the builder are Basic HTTP, Bearer Token, API 
Key, and OAuth. The builder does not currently support authenticating a login endpoint 
that returns a session token, but this feature is planned and can be tracked in the 
Github issue #26341. This issue is not closed yet - the feature might not be shipped 
yet.</code></pre></div><p>The first sentence about Basic HTTP, Bearer Token, API Key and OAuth is retrieved from the <a href="https://docs.airbyte.com/connector-development/connector-builder-ui/authentication/">documentation page about authentication</a>, while the second sentence is referring to the same Github issue as before.</p><h2>Wrapping up</h2><p>We covered a lot of ground here - stepping back a bit, we accomplished the following parts:</p><ul role="list"><li>Set up a pipeline that loads unstructured data from multiple sources into a vector database</li><li>Implement an application that can answer plain text questions about the unstructured data in a general way</li><li>Expose this application as a Slack bot</li></ul><p>With data flowing through this system, Airbyte will make sure the data in your vector database will always be up-to-date while only syncing records that changed in the connected source, minimizing the load on embedding and vector database services while also providing an overview over the current state of running pipelines.</p><p>This setup isn’t using a single black box service that encapsulates all the details and leaves us with limited options for tweaking behavior and controlling data processing - instead it’s composed out of multiple components that be easily extended in various places:</p><ul role="list"><li>The large catalog of Airbyte sources and the connector builder for integrating specialized sources allow to easily load just about any data into a vector db using a single tool</li><li>Langchain is very extensible and allows you to leverage LLMs in different ways beyond this simple application, including enriching data from other sources, keeping a chat history to be able to have full conversations and more</li></ul><p><strong>Survey</strong></p><p>If you are interested in leveraging Airbyte to ship data to your LLM-based applications, take a moment to <a href="https://docs.google.com/forms/d/e/1FAIpQLSduobMZwbqiFlPxsWDG-hrBw6NLYMDu_7zRfo4j7AsaO1QtfQ/viewform?usp=sf_link">fill out our survey</a> so we can make sure to prioritize the most important features.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Go 1.21 Released (290 pts)]]></title>
            <link>https://go.dev/doc/go1.21</link>
            <guid>37050466</guid>
            <pubDate>Tue, 08 Aug 2023 15:28:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://go.dev/doc/go1.21">https://go.dev/doc/go1.21</a>, See on <a href="https://news.ycombinator.com/item?id=37050466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content">
  


<article>





















<!--
NOTE: In this document and others in this directory, the convention is to
set fixed-width phrases with non-fixed-width spaces, as in
<code>hello</code> <code>world</code>.
Do not send CLs removing the interior tags from such phrases.
-->



<h2 id="introduction">Introduction to Go 1.21</h2>

<p>
  The latest Go release, version 1.21, arrives six months after <a href="https://go.dev/doc/go1.20">Go 1.20</a>.
  Most of its changes are in the implementation of the toolchain, runtime, and libraries.
  As always, the release maintains the Go 1 <a href="https://go.dev/doc/go1compat">promise of compatibility</a>;
  in fact, Go 1.21 <a href="#godebug">improves upon that promise</a>.
  We expect almost all Go programs to continue to compile and run as before.
</p>

<p><!-- https://go.dev/issue/57631 -->
  Go 1.21 introduces a small change to the numbering of releases.
  In the past, we used Go 1.<i>N</i> to refer to both the overall Go language version and release family
  as well as the first release in that family.
  Starting in Go 1.21, the first release is now Go 1.<i>N</i>.0.
  Today we are releasing both the Go 1.21 language and its initial implementation, the Go 1.21.0 release.
  These notes refer to “Go 1.21”; tools like <code>go</code> <code>version</code> will report “<code>go1.21.0</code>”
  (until you upgrade to Go 1.21.1).
  See “<a href="https://go.dev/doc/toolchain#versions">Go versions</a>” in the “Go Toolchains” documentation for details
  about the new version numbering.
</p>

<h2 id="language">Changes to the language</h2>

<p>
  Go 1.21 adds three new built-ins to the language.

  </p><ul>
    <li><!-- https://go.dev/issue/59488 -->
      The new functions <code>min</code> and <code>max</code> compute the
      smallest (or largest, for <code>max</code>) value of a fixed number
      of given arguments.
      See the language spec for
      <a href="https://tip.golang.org/ref/spec#Min_and_max">details</a>.
    </li>
    <li><!-- https://go.dev/issue/56351 -->
      The new function <code>clear</code> deletes all elements from a
      map or zeroes all elements of a slice.
      See the language spec for
      <a href="https://tip.golang.org/ref/spec#Clear">details</a>.
    </li>
  </ul>


<p><!-- https://go.dev/issue/57411 -->
  Package initialization order is now specified more precisely. The
  new algorithm is:
  </p><ul>
    <li>
      Sort all packages by import path.
    </li>
    <li>Repeat until the list of packages is empty:
      <ul>
        <li>
          Find the first package in the list for which all imports are
          already initialized.
        </li>
        <li>
          Initialize that package and remove it from the list.
        </li>
      </ul>
    </li>
  </ul>
  This may change the behavior of some programs that rely on a
  specific initialization ordering that was not expressed by explicit
  imports. The behavior of such programs was not well defined by the
  spec in past releases. The new rule provides an unambiguous definition.


<p>
  Multiple improvements that increase the power and precision of type inference have been made.
</p>
<ul>
  <li><!-- https://go.dev/issue/59338 -->
    A (possibly partially instantiated generic) function may now be called with arguments that are
    themselves (possibly partially instantiated) generic functions.
    The compiler will attempt to infer the missing type arguments of the callee (as before) and,
    for each argument that is a generic function that is not fully instantiated,
    its missing type arguments (new).
    Typical use cases are calls to generic functions operating on containers
    (such as <a href="https://go.dev/pkg/slices#IndexFunc">slices.IndexFunc</a>) where a function argument
    may also be generic, and where the type argument of the called function and its arguments
    are inferred from the container type.
    More generally, a generic function may now be used without explicit instantiation when
    it is assigned to a variable or returned as a result value if the type arguments can
    be inferred from the assignment.
  </li>
  <li><!-- https://go.dev/issue/60353, https://go.dev/issue/57192, https://go.dev/issue/52397, https://go.dev/issue/41176 -->
    Type inference now also considers methods when a value is assigned to an interface:
    type arguments for type parameters used in method signatures may be inferred from
    the corresponding parameter types of matching methods.
  </li>
  <li><!-- https://go.dev/issue/51593 https://go.dev/issue/39661 -->
    Similarly, since a type argument must implement all the methods of its corresponding constraint,
    the methods of the type argument and constraint are matched which may lead to the inference of
    additional type arguments.
  </li>
  <li><!-- https://go.dev/issue/58671 -->
    If multiple untyped constant arguments of different kinds (such as an untyped int and
    an untyped floating-point constant) are passed to parameters with the same (not otherwise
    specified) type parameter type, instead of an error, now type inference determines the
    type using the same approach as an operator with untyped constant operands.
    This change brings the types inferred from untyped constant arguments in line with the
    types of constant expressions.
  </li>
  <li><!-- https://go.dev/issue/59750 -->
    Type inference is now precise when matching corresponding types in assignments:
    component types (such as the elements of slices, or the parameter types in function signatures)
    must be identical (given suitable type arguments) to match, otherwise inference fails.
    This change produces more accurate error messages:
    where in the past type inference may have succeeded incorrectly and lead to an invalid assignment,
    the compiler now reports an inference error if two types can't possibly match.
  </li>
</ul>

<p><!-- https://go.dev/issue/58650 -->
  More generally, the description of
  <a href="https://tip.golang.org/ref/spec#Type_inference">type inference</a>
  in the language spec has been clarified.
  Together, all these changes make type inference more powerful and inference failures less surprising.
</p>

<!-- https://go.dev/issue/57969 -->
<p>
  Go 1.21 includes a preview of a language change we are considering for a future version of Go:
  making for loop variables per-iteration instead of per-loop, to avoid accidental sharing bugs.
  For details about how to try that language change, see <a href="https://go.dev/wiki/LoopvarExperiment">the LoopvarExperiment wiki page</a>.
</p>

<!-- https://go.dev/issue/25448 -->
<p>
  Go 1.21 now defines that if a goroutine is panicking and recover was called directly by a deferred
  function, the return value of recover is guaranteed not to be nil. To ensure this, calling panic
  with a nil interface value (or an untyped nil) causes a run-time panic of type
  <a href="https://go.dev/runtime/#PanicNilError"><code>*runtime.PanicNilError</code></a>.
</p>
<p>
  To support programs written for older versions of Go, nil panics can be re-enabled by setting
  <code>GODEBUG=panicnil=1</code>.
  This setting is enabled automatically when compiling a program whose main package
  is in a module with that declares <code>go</code> <code>1.20</code> or earlier.
</p>


<p>
  Go 1.21 adds improved support for backwards compatibility and forwards compatibility
  in the Go toolchain.
</p>

<p><!-- https://go.dev/issue/56986 -->
  To improve backwards compatibility, Go 1.21 formalizes
  Go's use of the GODEBUG environment variable to control
  the default behavior for changes that are non-breaking according to the
  <a href="https://go.dev/doc/go1compat">compatibility policy</a>
  but nonetheless may cause existing programs to break.
  (For example, programs that depend on buggy behavior may break
  when a bug is fixed, but bug fixes are not considered breaking changes.)
  When Go must make this kind of behavior change,
  it now chooses between the old and new behavior based on the
  <code>go</code> line in the workspace's <code>go.work</code> file
  or else the main module's <code>go.mod</code> file.
  Upgrading to a new Go toolchain but leaving the <code>go</code> line
  set to its original (older) Go version preserves the behavior of the older
  toolchain.
  With this compatibility support, the latest Go toolchain should always
  be the best, most secure, implementation of an older version of Go.
  See “<a href="https://go.dev/doc/godebug">Go, Backwards Compatibility, and GODEBUG</a>” for details.
</p>

<p><!-- https://go.dev/issue/57001 -->
  To improve forwards compatibility, Go 1.21 now reads the <code>go</code> line
  in a <code>go.work</code> or <code>go.mod</code> file as a strict
  minimum requirement: <code>go</code> <code>1.21.0</code> means
  that the workspace or module cannot be used with Go 1.20 or with Go 1.21rc1.
  This allows projects that depend on fixes made in later versions of Go
  to ensure that they are not used with earlier versions.
  It also gives better error reporting for projects that make use of new Go features:
  when the problem is that a newer Go version is needed,
  that problem is reported clearly, instead of attempting to build the code
  and instead printing errors about unresolved imports or syntax errors.
</p>

<p>
  To make these new stricter version requirements easier to manage,
  the <code>go</code> command can now invoke not just the toolchain
  bundled in its own release but also other Go toolchain versions found in the PATH
  or downloaded on demand.
  If a <code>go.mod</code> or <code>go.work</code> <code>go</code> line
  declares a minimum requirement on a newer version of Go, the <code>go</code>
  command will find and run that version automatically.
  The new <code>toolchain</code> directive sets a suggested minimum toolchain to use,
  which may be newer than the strict <code>go</code> minimum.
  See “<a href="https://go.dev/doc/toolchain">Go Toolchains</a>” for details.
</p>

<h3 id="go-command">Go command</h3>

<p><!-- https://go.dev/issue/58099, CL 474236 -->
  The <code>-pgo</code> build flag now defaults to <code>-pgo=auto</code>,
  and the restriction of specifying a single main package on the command
  line is now removed. If a file named <code>default.pgo</code> is present
  in the main package's directory, the <code>go</code> command will use
  it to enable profile-guided optimization for building the corresponding
  program.
</p>

<p>
  The <code>-C</code> <code>dir</code> flag must now be the first
  flag on the command-line when used.
</p>

<p><!-- https://go.dev/issue/37708, CL 463837 -->
  The new <code>go</code> <code>test</code> option
  <code>-fullpath</code> prints full path names in test log messages,
  rather than just base names.
</p>

<p><!-- https://go.dev/issue/15513, CL 466397 -->
  The <code>go</code> <code>test</code> <code>-c</code> flag now
  supports writing test binaries for multiple packages, each to
  <code>pkg.test</code> where <code>pkg</code> is the package name.
  It is an error if more than one test package being compiled has a given package name.]
</p>

<p><!-- https://go.dev/issue/15513, CL 466397 -->
  The <code>go</code> <code>test</code> <code>-o</code> flag now
  accepts a directory argument, in which case test binaries are written to that
  directory instead of the current directory.
</p>

<h3 id="cgo">Cgo</h3>

<p><!-- CL 490819 -->
  In files that <code>import "C"</code>, the Go toolchain now
  correctly reports errors for attempts to declare Go methods on C types.
</p>

<h2 id="runtime-changes">Runtime</h2>

<p><!-- https://go.dev/issue/7181 -->
  When printing very deep stacks, the runtime now prints the first 50
  (innermost) frames followed by the bottom 50 (outermost) frames,
  rather than just printing the first 100 frames. This makes it easier
  to see how deeply recursive stacks started, and is especially
  valuable for debugging stack overflows.
</p>

<p><!-- https://go.dev/issue/59960 -->
  On Linux platforms that support transparent huge pages, the Go runtime
  now manages which parts of the heap may be backed by huge pages more
  explicitly. This leads to better utilization of memory: small heaps
  should see less memory used (up to 50% in pathological cases) while
  large heaps should see fewer broken huge pages for dense parts of the
  heap, improving CPU usage and latency by up to 1%.
</p>

<p><!-- https://go.dev/issue/57069, https://go.dev/issue/56966 -->
  As a result of runtime-internal garbage collection tuning,
  applications may see up to a 40% reduction in application tail latency
  and a small decrease in memory use. Some applications may also observe
  a small loss in throughput.

  The memory use decrease should be proportional to the loss in
  throughput, such that the previous release's throughput/memory
  tradeoff may be recovered (with little change to latency) by
  increasing <code>GOGC</code> and/or <code>GOMEMLIMIT</code> slightly.
</p>

<p><!-- https://go.dev/issue/51676 -->
  Calls from C to Go on threads created in C require some setup to prepare for
  Go execution. On Unix platforms, this setup is now preserved across multiple
  calls from the same thread. This significantly reduces the overhead of
  subsequent C to Go calls from ~1-3 microseconds per call to ~100-200
  nanoseconds per call.
</p>

<h2 id="compiler">Compiler</h2>

<p>
  Profile-guide optimization (PGO), added as a preview in Go 1.20, is now ready
  for general use. PGO enables additional optimizations on code identified as
  hot by profiles of production workloads. As mentioned in the
  <a href="#go-command">Go command section</a>, PGO is enabled by default for
  binaries that contain a <code>default.pgo</code> profile in the main
  package directory. Performance improvements vary depending on application
  behavior, with most programs from a representative set of Go programs seeing
  between 2 and 7% improvement from enabling PGO. See the
  <a href="https://go.dev/doc/pgo">PGO user guide</a> for detailed documentation.
</p>

<!-- https://go.dev/issue/59959 -->
<p>
  PGO builds can now devirtualize some interface method calls, adding a
  concrete call to the most common callee. This enables further optimization,
  such as inlining the callee.
</p>

<!-- CL 497455 -->
<p>
  Go 1.21 improves build speed by up to 6%, largely thanks to building the
  compiler itself with PGO.
</p>

<h2 id="assembler">Assembler</h2>

<!-- https://go.dev/issue/58378 -->
<p>
  On amd64, frameless nosplit assembly functions are no longer automatically marked as <code>NOFRAME</code>.
  Instead, the <code>NOFRAME</code> attribute must be explicitly specified if desired,
  which is already the behavior on other architectures supporting frame pointers.
  With this, the runtime now maintains the frame pointers for stack transitions.
</p>

<!-- CL 476295 -->
<p>
  The verifier that checks for incorrect uses of <code>R15</code> when dynamic linking on amd64 has been improved.
</p>

<h2 id="linker">Linker</h2>

<p><!-- https://go.dev/issue/57302, CL 461749, CL 457455 -->
  On windows/amd64, the linker (with help from the compiler) now emits
  SEH unwinding data by default, which improves the integration
  of Go applications with Windows debuggers and other tools.
</p>

<!-- CL 463395, CL 461315 -->
<p>
  In Go 1.21 the linker (with help from the compiler) is now capable of
  deleting dead (unreferenced) global map variables, if the number of
  entries in the variable initializer is sufficiently large, and if the
  initializer expressions are side-effect free.
</p>

<h2 id="library">Core library</h2>

<h3 id="slog">New log/slog package</h3>

<p><!-- https://go.dev/issue/59060, https://go.dev/issue/59141, https://go.dev/issue/59204, https://go.dev/issue/59280,
        https://go.dev/issue/59282, https://go.dev/issue/59339, https://go.dev/issue/59345, https://go.dev/issue/61200,
        CL 477295, CL 484096, CL 486376, CL 486415, CL 487855, CL 508195 -->
  The new <a href="https://go.dev/pkg/log/slog">log/slog</a> package provides structured logging with levels.
  Structured logging emits key-value pairs
  to enable fast, accurate processing of large amounts of log data.
  The package supports integration with popular log analysis tools and services.
</p>

<h3 id="slogtest">New testing/slogtest package</h3>

<p><!-- CL 487895 -->
  The new <a href="https://go.dev/pkg/testing/slogtest">testing/slogtest</a> package can help
  to validate <a href="https://go.dev/pkg/log/slog#Handler">slog.Handler</a> implementations.
</p>

<h3 id="slices">New slices package</h3>

<p>
  <!-- https://go.dev/issue/45955, https://go.dev/issue/54768 -->
  <!-- https://go.dev/issue/57348, https://go.dev/issue/57433 -->
  <!-- https://go.dev/issue/58565, https://go.dev/issue/60091 -->
  <!-- https://go.dev/issue/60546 -->
  <!-- CL 467417, CL 468855, CL 483175, CL 496078, CL 498175, CL 502955 -->
  The new <a href="https://go.dev/pkg/slices">slices</a> package provides many common
  operations on slices, using generic functions that work with slices
  of any element type.
</p>

<h3 id="maps">New maps package</h3>

<p><!-- https://go.dev/issue/57436, CL 464343 -->
  The new <a href="https://go.dev/pkg/maps/">maps</a> package provides several
  common operations on maps, using generic functions that work with
  maps of any key or element type.
</p>

<h3 id="cmp">New cmp package</h3>

<p><!-- https://go.dev/issue/59488, CL 496356 -->
  The new <a href="https://go.dev/pkg/cmp/">cmp</a> package defines the type
  constraint <a href="https://go.dev/pkg/cmp/#Ordered"><code>Ordered</code></a> and
  two new generic functions
  <a href="https://go.dev/pkg/cmp/#Less"><code>Less</code></a>
  and <a href="https://go.dev/pkg/cmp/#Compare"><code>Compare</code></a> that are
  useful with <a href="https://go.dev/ref/spec/#Comparison_operators">ordered
  types</a>.
</p>

<h3 id="minor_library_changes">Minor changes to the library</h3>

<p>
  As always, there are various minor changes and updates to the library,
  made with the Go 1 <a href="https://go.dev/doc/go1compat">promise of compatibility</a>
  in mind.
  There are also various performance improvements, not enumerated here.
</p>

<dl id="archive/tar"><dt><a href="https://go.dev/pkg/archive/tar/">archive/tar</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      The implementation of the
      <a href="https://go.dev/pkg/io/fs/#FileInfo"><code>io/fs.FileInfo</code></a>
      interface returned by
      <a href="https://go.dev/pkg/archive/tar/#Header.FileInfo"><code>Header.FileInfo</code></a>
      now implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatFileInfo"><code>io/fs.FormatFileInfo</code></a>.
    </p>
  </dd>
</dl><!-- archive/tar -->

<dl id="archive/zip"><dt><a href="https://go.dev/pkg/archive/zip/">archive/zip</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      The implementation of the
      <a href="https://go.dev/pkg/io/fs/#FileInfo"><code>io/fs.FileInfo</code></a>
      interface returned by
      <a href="https://go.dev/pkg/archive/zip/#FileHeader.FileInfo"><code>FileHeader.FileInfo</code></a>
      now implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatFileInfo"><code>io/fs.FormatFileInfo</code></a>.
    </p>

    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      The implementation of the
      <a href="https://go.dev/pkg/io/fs/#DirEntry"><code>io/fs.DirEntry</code></a>
      interface returned by the
      <a href="https://go.dev/pkg/io/fs/#ReadDirFile.ReadDir"><code>io/fs.ReadDirFile.ReadDir</code></a>
      method of the
      <a href="https://go.dev/pkg/io/fs/#File"><code>io/fs.File</code></a>
      returned by
      <a href="https://go.dev/pkg/archive/zip/#Reader.Open"><code>Reader.Open</code></a>
      now implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatDirEntry"><code>io/fs.FormatDirEntry</code></a>.
    </p>
  </dd>
</dl><!-- archive/zip -->

<dl id="bytes"><dt><a href="https://go.dev/pkg/bytes/">bytes</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/53685, CL 474635 -->
      The <a href="https://go.dev/pkg/bytes/#Buffer"><code>Buffer</code></a> type
      has two new methods:
      <a href="https://go.dev/pkg/bytes/#Buffer.Available"><code>Available</code></a>
      and <a href="https://go.dev/pkg/bytes/#AvailableBuffer"><code>AvailableBuffer</code></a>.
      These may be used along with the
      <a href="https://go.dev/pkg/bytes/#Buffer.Write"><code>Write</code></a>
      method to append directly to the <code>Buffer</code>.
    </p>
  </dd>
</dl><!-- bytes -->

<dl id="context"><dt><a href="https://go.dev/pkg/context/">context</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/40221, CL 479918 -->
      The new <a href="https://go.dev/pkg/context/#WithoutCancel"><code>WithoutCancel</code></a>
      function returns a copy of a context that is not canceled when the original
      context is canceled.
    </p>
    <p><!-- https://go.dev/issue/56661, CL 449318 -->
      The new <a href="https://go.dev/pkg/context/#WithDeadlineCause"><code>WithDeadlineCause</code></a>
      and <a href="https://go.dev/pkg/context/#WithTimeoutCause"><code>WithTimeoutCause</code></a>
      functions provide a way to set a context cancellation cause when a deadline or
      timer expires. The cause may be retrieved with the
      <a href="https://go.dev/pkg/context/#Cause"><code>Cause</code></a> function.
    </p>
    <p><!-- https://go.dev/issue/57928, CL 482695 -->
      The new <a href="https://go.dev/pkg/context/#AfterFunc"><code>AfterFunc</code></a>
      function registers a function to run after a context has been cancelled.
    </p>

    <p><!-- CL 455455 -->
      An optimization means that the results of calling
      <a href="https://go.dev/pkg/context/#Background"><code>Background</code></a>
      and <a href="https://go.dev/pkg/context/#TODO"><code>TODO</code></a> and
      converting them to a shared type can be considered equal.
      In previous releases they were always different.  Comparing
      <a href="https://go.dev/pkg/context/#Context"><code>Context</code></a> values
      for equality has never been well-defined, so this is not
      considered to be an incompatible change.
    </p>
  </dd>
</dl>


<dl id="crypto/ecdsa"><dt><a href="https://go.dev/pkg/crypto/ecdsa/">crypto/ecdsa</a></dt>
  <dd>
    <p><!-- CL 492955 -->
      <a href="https://go.dev/pkg/crypto/ecdsa/#PublicKey.Equal"><code>PublicKey.Equal</code></a> and
      <a href="https://go.dev/pkg/crypto/ecdsa/#PrivateKey.Equal"><code>PrivateKey.Equal</code></a>
      now execute in constant time.
    </p>
  </dd>
</dl><!-- crypto/ecdsa -->

<dl id="crypto/elliptic"><dt><a href="https://go.dev/pkg/crypto/elliptic/">crypto/elliptic</a></dt>
  <dd>
    <p><!-- CL 459977 -->
      All of the <a href="https://go.dev/pkg/crypto/elliptic/#Curve"><code>Curve</code></a> methods have been deprecated, along with <a href="https://go.dev/pkg/crypto/elliptic/#GenerateKey"><code>GenerateKey</code></a>, <a href="https://go.dev/pkg/crypto/elliptic/#Marshal"><code>Marshal</code></a>, and <a href="https://go.dev/pkg/crypto/elliptic/#Unmarshal"><code>Unmarshal</code></a>. For ECDH operations, the new <a href="https://go.dev/pkg/crypto/ecdh/"><code>crypto/ecdh</code></a> package should be used instead. For lower-level operations, use third-party modules such as <a href="https://pkg.go.dev/filippo.io/nistec">filippo.io/nistec</a>.
    </p>
  </dd>
</dl><!-- crypto/elliptic -->

<dl id="crypto/rand"><dt><a href="https://go.dev/pkg/crypto/rand/">crypto/rand</a></dt>
  <dd>
    <p><!-- CL 463123 -->
      The <a href="https://go.dev/pkg/crypto/rand/"><code>crypto/rand</code></a> package now uses the <code>getrandom</code> system call on NetBSD 10.0 and later.
    </p>
  </dd>
</dl><!-- crypto/rand -->

<dl id="crypto/rsa"><dt><a href="https://go.dev/pkg/crypto/rsa/">crypto/rsa</a></dt>
  <dd>
    <p><!-- CL 471259, CL 492935 -->
      The performance of private RSA operations (decryption and signing) is now better than Go 1.19 for <code>GOARCH=amd64</code> and <code>GOARCH=arm64</code>. It had regressed in Go 1.20.
    </p>
    <p>
      Due to the addition of private fields to <a href="https://go.dev/pkg/crypto/rsa/#PrecomputedValues"><code>PrecomputedValues</code></a>, <a href="https://go.dev/pkg/crypto/rsa/#PrivateKey.Precompute"><code>PrivateKey.Precompute</code></a> must be called for optimal performance even if deserializing (for example from JSON) a previously-precomputed private key.
    </p>
    <p><!-- CL 492955 -->
      <a href="https://go.dev/pkg/crypto/rsa/#PublicKey.Equal"><code>PublicKey.Equal</code></a> and
      <a href="https://go.dev/pkg/crypto/rsa/#PrivateKey.Equal"><code>PrivateKey.Equal</code></a>
      now execute in constant time.
    </p>
    <p><!-- https://go.dev/issue/56921, CL 459976 -->
      The <a href="https://go.dev/pkg/crypto/rsa/#GenerateMultiPrimeKey"><code>GenerateMultiPrimeKey</code></a> function and the <a href="https://go.dev/pkg/crypto/rsa/#PrecomputedValues.CRTValues"><code>PrecomputedValues.CRTValues</code></a> field have been deprecated. <a href="https://go.dev/pkg/crypto/rsa/#PrecomputedValues.CRTValues"><code>PrecomputedValues.CRTValues</code></a> will still be populated when <a href="https://go.dev/pkg/crypto/rsa/#PrivateKey.Precompute"><code>PrivateKey.Precompute</code></a> is called, but the values will not be used during decryption operations.
    </p>
  </dd>
</dl><!-- crypto/rsa -->

<!-- CL 483815 reverted -->

<dl id="crypto/sha256"><dt><a href="https://go.dev/pkg/crypto/sha256/">crypto/sha256</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/50543, CL 408795 -->
      SHA-224 and SHA-256 operations now use native instructions when available when <code>GOARCH=amd64</code>, providing a performance improvement on the order of 3-4x.
    </p>
  </dd>
</dl><!-- crypto/sha256 -->

<!-- CL 481478 reverted -->
<!-- CL 483816 reverted -->

<dl id="crypto/tls"><dt><a href="https://go.dev/pkg/crypto/tls/">crypto/tls</a></dt>
  <dd>
    <p><!-- CL 497895 -->
      Servers now skip verifying client certificates (including not running
      <a href="https://go.dev/pkg/crypto/tls/#Config.VerifyPeerCertificate"><code>Config.VerifyPeerCertificate</code></a>)
      for resumed connections, besides checking the expiration time. This makes
      session tickets larger when client certificates are in use. Clients were
      already skipping verification on resumption, but now check the expiration
      time even if <a href="https://go.dev/pkg/crypto/tls/#Config.InsecureSkipVerify"><code>Config.InsecureSkipVerify</code></a>
      is set.
    </p>

    <p><!-- https://go.dev/issue/60105, CL 496818, CL 496820, CL 496822, CL 496821, CL 501675 -->
      Applications can now control the content of session tickets.
      </p><ul>
        <li>
          The new <a href="https://go.dev/pkg/crypto/tls/#SessionState"><code>SessionState</code></a> type
          describes a resumable session.
        </li>
        <li>
          The <a href="https://go.dev/pkg/crypto/tls/#SessionState.Bytes"><code>SessionState.Bytes</code></a>
          method and <a href="https://go.dev/pkg/crypto/tls/#ParseSessionState"><code>ParseSessionState</code></a>
          function serialize and deserialize a <code>SessionState</code>.
        </li>
        <li>
          The <a href="https://go.dev/pkg/crypto/tls/#Config.WrapSession"><code>Config.WrapSession</code></a> and
          <a href="https://go.dev/pkg/crypto/tls/#Config.UnwrapSession"><code>Config.UnwrapSession</code></a>
          hooks convert a <code>SessionState</code> to and from a ticket on the server side.
        </li>
        <li>
          The <a href="https://go.dev/pkg/crypto/tls/#Config.EncryptTicket"><code>Config.EncryptTicket</code></a>
          and <a href="https://go.dev/pkg/crypto/tls/#Config.DecryptTicket"><code>Config.DecryptTicket</code></a>
          methods provide a default implementation of <code>WrapSession</code> and
          <code>UnwrapSession</code>.
        </li>
        <li>
          The <a href="https://go.dev/pkg/crypto/tls/#ClientSessionState.ResumptionState"><code>ClientSessionState.ResumptionState</code></a> method and
          <a href="https://go.dev/pkg/crypto/tls/#NewResumptionState"><code>NewResumptionState</code></a> function
          may be used by a <code>ClientSessionCache</code> implementation to store and
          resume sessions on the client side.
        </li>
      </ul>
    

    <p><!-- CL 496817 -->
      To reduce the potential for session tickets to be used as a tracking
      mechanism across connections, the server now issues new tickets on every
      resumption (if they are supported and not disabled) and tickets don't bear
      an identifier for the key that encrypted them anymore. If passing a large
      number of keys to <a href="https://go.dev/pkg/crypto/tls/#Conn.SetSessionTicketKeys"><code>Conn.SetSessionTicketKeys</code></a>,
      this might lead to a noticeable performance cost.
    </p>

    <p><!-- CL 497376 -->
      Both clients and servers now implement the Extended Master Secret extension (RFC 7627).
      The deprecation of <a href="https://go.dev/pkg/crypto/tls/#ConnectionState.TLSUnique"><code>ConnectionState.TLSUnique</code></a>
      has been reverted, and is now set for resumed connections that support Extended Master Secret.
    </p>

    <p><!-- https://go.dev/issue/44886, https://go.dev/issue/60107, CL 493655, CL 496995, CL 514997 -->
      The new <a href="https://go.dev/pkg/crypto/tls/#QUICConn"><code>QUICConn</code></a> type
      provides support for QUIC implementations, including 0-RTT support. Note
      that this is not itself a QUIC implementation, and 0-RTT is still not
      supported in TLS.
    </p>

    <p><!-- https://go.dev/issue/46308, CL 497377 -->
      The new <a href="https://go.dev/pkg/crypto/tls/#VersionName"><code>VersionName</code></a> function
      returns the name for a TLS version number.
    </p>

    <p><!-- https://go.dev/issue/52113, CL 410496 -->
      The TLS alert codes sent from the server for client authentication failures have
      been improved. Previously, these failures always resulted in a "bad certificate" alert.
      Now, certain failures will result in more appropriate alert codes,
      as defined by RFC 5246 and RFC 8446:
      </p><ul>
        <li>
          For TLS 1.3 connections, if the server is configured to require client authentication using
          <a href="https://go.dev/pkg/crypto/tls/#RequireAnyClientCert">RequireAnyClientCert</a> or
          <a href="https://go.dev/pkg/crypto/tls/#RequireAndVerifyClientCert">RequireAndVerifyClientCert</a>,
          and the client does not provide any certificate, the server will now return the "certificate required" alert.
        </li>
        <li>
          If the client provides a certificate that is not signed by the set of trusted certificate authorities
          configured on the server, the server will return the "unknown certificate authority" alert.
        </li>
        <li>
          If the client provides a certificate that is either expired or not yet valid,
          the server will return the "expired certificate" alert.
        </li>
        <li>
          In all other scenarios related to client authentication failures, the server still returns "bad certificate".
        </li>
      </ul>
    
  </dd>
</dl><!-- crypto/tls -->

<dl id="crypto/x509"><dt><a href="https://go.dev/pkg/crypto/x509/">crypto/x509</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/53573, CL 468875 -->
      <a href="https://go.dev/pkg/crypto/x509/#RevocationList.RevokedCertificates"><code>RevocationList.RevokedCertificates</code></a> has been deprecated and replaced with the new <a href="https://go.dev/pkg/crypto/x509/#RevocationList.RevokedCertificateEntries"><code>RevokedCertificateEntries</code></a> field, which is a slice of <a href="https://go.dev/pkg/crypto/x509/#RevocationListEntry"><code>RevocationListEntry</code></a>. <a href="https://go.dev/pkg/crypto/x509/#RevocationListEntry"><code>RevocationListEntry</code></a> contains all of the fields in <a href="https://go.dev/pkg/crypto/x509/pkix#RevokedCertificate"><code>pkix.RevokedCertificate</code></a>, as well as the revocation reason code.
    </p>

    <p><!-- CL 478216 -->
      Name constraints are now correctly enforced on non-leaf certificates, and
      not on the certificates where they are expressed.
    </p>
  </dd>
</dl><!-- crypto/x509 -->

<dl id="debug/elf"><dt><a href="https://go.dev/pkg/debug/elf/">debug/elf</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/56892, CL 452617 -->
      The new
      <a href="https://go.dev/pkg/debug/elf/#File.DynValue"><code>File.DynValue</code></a>
      method may be used to retrieve the numeric values listed with a
      given dynamic tag.
    </p>

    <p><!-- https://go.dev/issue/56887, CL 452496 -->
      The constant flags permitted in a <code>DT_FLAGS_1</code>
      dynamic tag are now defined with type
      <a href="https://go.dev/pkg/debug/elf/#DynFlag1"><code>DynFlag1</code></a>. These
      tags have names starting with <code>DF_1</code>.
    </p>

    <p><!-- CL 473256 -->
      The package now defines the constant
      <a href="https://go.dev/pkg/debug/elf/#COMPRESS_ZSTD"><code>COMPRESS_ZSTD</code></a>.
    </p>

    <p><!-- https://go.dev/issue/60348, CL 496918 -->
      The package now defines the constant
      <a href="https://go.dev/pkg/debug/elf/#R_PPC64_REL24_P9NOTOC"><code>R_PPC64_REL24_P9NOTOC</code></a>.
    </p>
  </dd>
</dl><!-- debug/elf -->

<dl id="debug/pe"><dt><a href="https://go.dev/pkg/debug/pe/">debug/pe</a></dt>
  <dd>
    <p><!-- CL 488475 -->
      Attempts to read from a section containing uninitialized data
      using
      <a href="https://go.dev/pkg/debug/pe/#Section.Data"><code>Section.Data</code></a>
      or the reader returned by <a href="https://go.dev/pkg/debug/pe/#Section.Open"><code>Section.Open</code></a>
      now return an error.
    </p>
  </dd>
</dl><!-- debug/pe -->

<dl id="embed"><dt><a href="https://go.dev/pkg/embed/">embed</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/57803, CL 483235 -->
      The <a href="https://go.dev/pkg/io/fs/#File"><code>io/fs.File</code></a>
      returned by
      <a href="https://go.dev/pkg/embed/#FS.Open"><code>FS.Open</code></a> now
      has a <code>ReadAt</code> method that
      implements <a href="https://go.dev/pkg/io/#ReaderAt"><code>io.ReaderAt</code></a>.
    </p>

    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      Calling <code><a href="https://go.dev/pkg/embed/FS.Open">FS.Open</a>.<a href="https://go.dev/pkg/io/fs/#File.Stat">Stat</a></code>
      will return a type that now implements a <code>String</code>
      method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatFileInfo"><code>io/fs.FormatFileInfo</code></a>.
    </p>
  </dd>
</dl><!-- embed -->

<dl id="errors"><dt><a href="https://go.dev/pkg/errors/">errors</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/41198, CL 473935 -->
      The new
      <a href="https://go.dev/pkg/errors/#ErrUnsupported"><code>ErrUnsupported</code></a>
      error provides a standardized way to indicate that a requested
      operation may not be performed because it is unsupported.
      For example, a call to
      <a href="https://go.dev/pkg/os/#Link"><code>os.Link</code></a> when using a
      file system that does not support hard links.
    </p>
  </dd>
</dl><!-- errors -->

<dl id="flag"><dt><a href="https://go.dev/pkg/flag/">flag</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/53747, CL 476015 -->
      The new <a href="https://go.dev/pkg/flag/#BoolFunc"><code>BoolFunc</code></a>
      function and
      <a href="https://go.dev/pkg/flag/#FlagSet.BoolFunc"><code>FlagSet.BoolFunc</code></a>
      method define a flag that does not require an argument and calls
      a function when the flag is used. This is similar to
      <a href="https://go.dev/pkg/flag/#Func"><code>Func</code></a> but for a
      boolean flag.
    </p>

    <p><!-- CL 480215 -->
      A flag definition
      (via <a href="https://go.dev/pkg/flag/#Bool"><code>Bool</code></a>,
      <a href="https://go.dev/pkg/flag/#BoolVar"><code>BoolVar</code></a>,
      <a href="https://go.dev/pkg/flag/#Int"><code>Int</code></a>,
      <a href="https://go.dev/pkg/flag/#IntVar"><code>IntVar</code></a>, etc.)
      will panic if <a href="https://go.dev/pkg/flag/#Set"><code>Set</code></a> has
      already been called on a flag with the same name. This change is
      intended to detect cases where <a href="#language">changes in
      initialization order</a> cause flag operations to occur in a
      different order than expected. In many cases the fix to this
      problem is to introduce a explicit package dependence to
      correctly order the definition before any
      <a href="https://go.dev/pkg/flag/#Set"><code>Set</code></a> operations.
    </p>
  </dd>
</dl><!-- flag -->

<dl id="go/ast"><dt><a href="https://go.dev/pkg/go/ast/">go/ast</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/28089, CL 487935 -->
      The new <a href="https://go.dev/pkg/go/ast/#IsGenerated"><code>IsGenerated</code></a> predicate
      reports whether a file syntax tree contains the
      <a href="https://go.dev/s/generatedcode">special comment</a>
      that conventionally indicates that the file was generated by a tool.
    </p>
  </dd>

  <dd>
    <p><!-- https://go.dev/issue/59033, CL 476276 -->
      The new
      <a href="https://go.dev/pkg/go/ast/#File.GoVersion"><code>File.GoVersion</code></a>
      field records the minimum Go version required by
      any <code>//go:build</code> or <code>// +build</code>
      directives.
    </p>
  </dd>
</dl><!-- go/ast -->

<dl id="go/build"><dt><a href="https://go.dev/pkg/go/build/">go/build</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/56986, CL 453603 -->
      The package now parses build directives (comments that start
      with <code>//go:</code>) in file headers (before
      the <code>package</code> declaration). These directives are
      available in the new
      <a href="https://go.dev/pkg/go/build#Package"><code>Package</code></a> fields
      <a href="https://go.dev/pkg/go/build#Package.Directives"><code>Directives</code></a>,
      <a href="https://go.dev/pkg/go/build#Package.TestDirectives"><code>TestDirectives</code></a>,
      and
      <a href="https://go.dev/pkg/go/build#Package.XTestDirectives"><code>XTestDirectives</code></a>.
    </p>
  </dd>
</dl><!-- go/build -->

<dl id="go/build/constraint"><dt><a href="https://go.dev/pkg/go/build/constraint/">go/build/constraint</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/59033, CL 476275 -->
      The new
      <a href="https://go.dev/pkg/go/build/constraint/#GoVersion"><code>GoVersion</code></a>
      function returns the minimum Go version implied by a build
      expression.
    </p>
  </dd>
</dl><!-- go/build/constraint -->

<dl id="go/token"><dt><a href="https://go.dev/pkg/go/token/">go/token</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/57708, CL 464515 -->
      The new <a href="https://go.dev/pkg/go/token/#File.Lines"><code>File.Lines</code></a> method
      returns the file's line-number table in the same form as accepted by
      <code>File.SetLines</code>.
    </p>
  </dd>
</dl><!-- go/token -->

<dl id="go/types"><dt><a href="https://go.dev/pkg/go/types/">go/types</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/61175, CL 507975 -->
      The new <a href="https://go.dev/pkg/go/types/#Package.GoVersion"><code>Package.GoVersion</code></a>
      method returns the Go language version used to check the package.
    </p>
  </dd>
</dl><!-- go/types -->

<dl id="hash/maphash"><dt><a href="https://go.dev/pkg/hash/maphash/">hash/maphash</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/47342, CL 468795 -->
      The <code>hash/maphash</code> package now has a pure Go implementation, selectable with the <code>purego</code> build tag.
    </p>
  </dd>
</dl><!-- hash/maphash -->

<dl id="html/template"><dt><a href="https://go.dev/pkg/html/template/">html/template</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/59584, CL 496395 -->
      The new error
      <a href="https://go.dev/pkg/html/template/#ErrJSTemplate"><code>ErrJSTemplate</code></a>
      is returned when an action appears in a JavaScript template
      literal. Previously an unexported error was returned.
    </p>
  </dd>
</dl><!-- html/template -->

<dl id="io/fs"><dt><a href="https://go.dev/pkg/io/fs/">io/fs</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/54451, CL 489555 -->
      The new
      <a href="https://go.dev/pkg/io/fs/#FormatFileInfo"><code>FormatFileInfo</code></a>
      function returns a formatted version of a
      <a href="https://go.dev/pkg/io/fs/#FileInfo"><code>FileInfo</code></a>.
      The new
      <a href="https://go.dev/pkg/io/fs/#FormatDirEntry"><code>FormatDirEntry</code></a>
      function returns a formatted version of a
      <a href="https://go.dev/pkg/io/fs/#FileInfo"><code>DirEntry</code></a>.
      The implementation of
      <a href="https://go.dev/pkg/io/fs/#DirEntry"><code>DirEntry</code></a>
      returned by
      <a href="https://go.dev/pkg/io/fs/#ReadDir"><code>ReadDir</code></a> now
      implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatDirEntry"><code>FormatDirEntry</code></a>,
      and the same is true for
      the <a href="https://go.dev/pkg/io/fs/#DirEntry"><code>DirEntry</code></a>
      value passed to
      <a href="https://go.dev/pkg/io/fs/#WalkDirFunc"><code>WalkDirFunc</code></a>.
    </p>
  </dd>
</dl><!-- io/fs -->

<!-- https://go.dev/issue/56491 rolled back by https://go.dev/issue/60519 -->
<!-- CL 459435 reverted by CL 467255 -->
<!-- CL 467515 reverted by CL 499416 -->

<dl id="math/big"><dt><a href="https://go.dev/pkg/math/big/">math/big</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/56984, CL 453115, CL 500116 -->
      The new <a href="https://go.dev/pkg/math/big/#Int.Float64"><code>Int.Float64</code></a>
      method returns the nearest floating-point value to a
      multi-precision integer, along with an indication of any
      rounding that occurred.
    </p>
  </dd>
</dl><!-- math/big -->

<dl id="net"><dt><a href="https://go.dev/pkg/net/">net</a></dt>
  <dd>
    <p>
      <!-- https://go.dev/issue/59166, https://go.dev/issue/56539 -->
      <!-- CL 471136, CL 471137, CL 471140 -->
      On Linux, the <a href="https://go.dev/pkg/net/">net</a> package can now use
      Multipath TCP when the kernel supports it. It is not used by
      default. To use Multipath TCP when available on a client, call
      the
      <a href="https://go.dev/pkg/net/#Dialer.SetMultipathTCP"><code>Dialer.SetMultipathTCP</code></a>
      method before calling the
      <a href="https://go.dev/pkg/net/#Dialer.Dial"><code>Dialer.Dial</code></a> or
      <a href="https://go.dev/pkg/net/#Dialer.DialContext"><code>Dialer.DialContext</code></a>
      methods. To use Multipath TCP when available on a server, call
      the
      <a href="https://go.dev/pkg/net/#ListenConfig.SetMultipathTCP"><code>ListenConfig.SetMultipathTCP</code></a>
      method before calling the
      <a href="https://go.dev/pkg/net/#ListenConfig.Listen"><code>ListenConfig.Listen</code></a>
      method. Specify the network as <code>"tcp"</code> or
      <code>"tcp4"</code> or <code>"tcp6"</code> as usual. If
      Multipath TCP is not supported by the kernel or the remote host,
      the connection will silently fall back to TCP. To test whether a
      particular connection is using Multipath TCP, use the
      <a href="https://go.dev/pkg/net/#TCPConn.MultipathTCP"><code>TCPConn.MultipathTCP</code></a>
      method.
    </p>
    <p>
      In a future Go release we may enable Multipath TCP by default on
      systems that support it.
    </p>
  </dd>
</dl><!-- net -->

<dl id="net/http"><dt><a href="https://go.dev/pkg/net/http/">net/http</a></dt>
  <dd>
    <p><!-- CL 472636 -->
      The new <a href="https://go.dev/pkg/net/http#ResponseController.EnableFullDuplex"><code>ResponseController.EnableFullDuplex</code></a>
      method allows server handlers to concurrently read from an HTTP/1
      request body while writing the response. Normally, the HTTP/1 server
      automatically consumes any remaining request body before starting to
      write the response, to avoid deadlocking clients which attempt to
      write a complete request before reading the response. The
      <code>EnableFullDuplex</code> method disables this behavior.
    </p>

    <p><!-- https://go.dev/issue/44855, CL 382117 -->
      The new <a href="https://go.dev/pkg/net/http/#ErrSchemeMismatch"><code>ErrSchemeMismatch</code></a> error is returned by <a href="https://go.dev/pkg/net/http/#Client"><code>Client</code></a> and <a href="https://go.dev/pkg/net/http/#Transport"><code>Transport</code></a> when the server responds to an HTTPS request with an HTTP response.
    </p>

    <p><!-- CL 494122 -->
      The <a href="https://go.dev/pkg/net/http/">net/http</a> package now supports
      <a href="https://go.dev/pkg/errors/#ErrUnsupported"><code>errors.ErrUnsupported</code></a>,
      in that the expression
      <code>errors.Is(http.ErrNotSupported, errors.ErrUnsupported)</code>
      will return true.
    </p>
  </dd>
</dl><!-- net/http -->

<dl id="os"><dt><a href="https://go.dev/pkg/os/">os</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/32558, CL 219638 -->
      Programs may now pass an empty <code>time.Time</code> value to
      the <a href="https://go.dev/pkg/os/#Chtimes"><code>Chtimes</code></a> function
      to leave either the access time or the modification time unchanged.
    </p>

    <p><!-- CL 480135 -->
      On Windows the
      <a href="https://go.dev/pkg/os#File.Chdir"><code>File.Chdir</code></a> method
      now changes the current directory to the file, rather than
      always returning an error.
    </p>

    <p><!-- CL 495079 -->
      On Unix systems, if a non-blocking descriptor is passed
      to <a href="https://go.dev/pkg/os/#NewFile"><code>NewFile</code></a>, calling
      the <a href="https://go.dev/pkg/os/#File.Fd"><code>File.Fd</code></a> method
      will now return a non-blocking descriptor. Previously the
      descriptor was converted to blocking mode.
    </p>

    <p><!-- CL 477215 -->
      On Windows calling
      <a href="https://go.dev/pkg/os/#Truncate"><code>Truncate</code></a> on a
      non-existent file used to create an empty file. It now returns
      an error indicating that the file does not exist.
    </p>

    <p><!-- https://go.dev/issue/56899, CL 463219 -->
      On Windows calling
      <a href="https://go.dev/pkg/os/#TempDir"><code>TempDir</code></a> now uses
      GetTempPath2W when available, instead of GetTempPathW. The
      new behavior is a security hardening measure that prevents
      temporary files created by processes running as SYSTEM to
      be accessed by non-SYSTEM processes.
    </p>

    <p><!-- CL 493036 -->
      On Windows the os package now supports working with files whose
      names, stored as UTF-16, can't be represented as valid UTF-8.
    </p>

    <p><!-- CL 463177 -->
      On Windows <a href="https://go.dev/pkg/os/#Lstat"><code>Lstat</code></a> now resolves
      symbolic links for paths ending with a path separator, consistent with its
      behavior on POSIX platforms.
    </p>

    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      The implementation of the
      <a href="https://go.dev/pkg/io/fs/#DirEntry"><code>io/fs.DirEntry</code></a>
      interface returned by the
      <a href="https://go.dev/pkg/os/#ReadDir"><code>ReadDir</code></a> function and
      the <a href="https://go.dev/pkg/os/#File.ReadDir"><code>File.ReadDir</code></a>
      method now implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatDirEntry"><code>io/fs.FormatDirEntry</code></a>.
    </p>

    <p><!-- https://go.dev/issue/53761, CL 416775, CL 498015-->
    The implementation of the
    <a href="https://go.dev/pkg/io/fs/#FS"><code>io/fs.FS</code></a> interface returned by
    the <a href="https://go.dev/pkg/os/#DirFS"><code>DirFS</code></a> function now implements
    the <a href="https://go.dev/pkg/io/fs/#ReadFileFS"><code>io/fs.ReadFileFS</code></a> and
    the <a href="https://go.dev/pkg/io/fs/#ReadDirFS"><code>io/fs.ReadDirFS</code></a>
    interfaces.
    </p>
  </dd>
</dl><!-- os -->

<dl id="path/filepath"><dt><a href="https://go.dev/pkg/path/filepath/">path/filepath</a></dt>
  <dd>
    <p>
      The implementation of the
      <a href="https://go.dev/pkg/io/fs/#DirEntry"><code>io/fs.DirEntry</code></a>
      interface passed to the function argument of
      <a href="https://go.dev/pkg/path/filepath/#WalkDir"><code>WalkDir</code></a>
      now implements a <code>String</code> method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatDirEntry"><code>io/fs.FormatDirEntry</code></a>.
    </p>
  </dd>
</dl><!-- path/filepath -->

<!-- CL 459455 reverted -->

<dl id="reflect"><dt><a href="https://go.dev/pkg/reflect/">reflect</a></dt>
  <dd>
    <p><!-- CL 408826, CL 413474 -->
      In Go 1.21, <a href="https://go.dev/pkg/reflect/#ValueOf"><code>ValueOf</code></a>
      no longer forces its argument to be allocated on the heap, allowing
      a <code>Value</code>'s content to be allocated on the stack. Most
      operations on a <code>Value</code> also allow the underlying value
      to be stack allocated.
    </p>

    <p><!-- https://go.dev/issue/55002 -->
      The new <a href="https://go.dev/pkg/reflect/#Value"><code>Value</code></a>
      method <a href="https://go.dev/pkg/reflect/#Value.Clear"><code>Value.Clear</code></a>
      clears the contents of a map or zeros the contents of a slice.
      This corresponds to the new <code>clear</code> built-in
      <a href="#language">added to the language</a>.
    </p>

    <p><!-- https://go.dev/issue/56906, CL 452762 -->
      The <a href="https://go.dev/pkg/reflect/#SliceHeader"><code>SliceHeader</code></a>
      and <a href="https://go.dev/pkg/reflect/#StringHeader"><code>StringHeader</code></a>
      types are now deprecated. In new code
      prefer <a href="https://go.dev/pkg/unsafe/#Slice"><code>unsafe.Slice</code></a>,
      <a href="https://go.dev/pkg/unsafe/#SliceData"><code>unsafe.SliceData</code></a>,
      <a href="https://go.dev/pkg/unsafe/#String"><code>unsafe.String</code></a>,
      or <a href="https://go.dev/pkg/unsafe/#StringData"><code>unsafe.StringData</code></a>.
    </p>
  </dd>
</dl><!-- reflect -->

<dl id="regexp"><dt><a href="https://go.dev/pkg/regexp/">regexp</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/46159, CL 479401 -->
      <a href="https://go.dev/pkg/regexp#Regexp"><code>Regexp</code></a> now defines
      <a href="https://go.dev/pkg/regexp#Regexp.MarshalText"><code>MarshalText</code></a>
      and <a href="https://go.dev/pkg/regexp#Regexp.UnmarshalText"><code>UnmarshalText</code></a>
      methods. These implement
      <a href="https://go.dev/pkg/encoding#TextMarshaler"><code>encoding.TextMarshaler</code></a>
      and
      <a href="https://go.dev/pkg/encoding#TextUnmarshaler"><code>encoding.TextUnmarshaler</code></a>
      and will be used by packages such as
      <a href="https://go.dev/pkg/encoding/json">encoding/json</a>.
    </p>
  </dd>
</dl><!-- regexp -->

<dl id="runtime"><dt><a href="https://go.dev/pkg/runtime/">runtime</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/38651, CL 435337 -->
      Textual stack traces produced by Go programs, such as those
      produced when crashing, calling <code>runtime.Stack</code>, or
      collecting a goroutine profile with <code>debug=2</code>, now
      include the IDs of the goroutines that created each goroutine in
      the stack trace.
    </p>

    <p><!-- https://go.dev/issue/57441, CL 474915 -->
      Crashing Go applications can now opt-in to Windows Error Reporting (WER) by setting the environment variable
      <code>GOTRACEBACK=wer</code> or calling <a href="https://go.dev/pkg/runtime/debug/#SetTraceback"><code>debug.SetTraceback("wer")</code></a>
      before the crash. Other than enabling WER, the runtime will behave as with <code>GOTRACEBACK=crash</code>.
      On non-Windows systems, <code>GOTRACEBACK=wer</code> is ignored.
    </p>

    <p><!-- CL 447778 -->
      <code>GODEBUG=cgocheck=2</code>, a thorough checker of cgo pointer passing rules,
      is no longer available as a <a href="https://go.dev/pkg/runtime#hdr-Environment_Variables">debug option</a>.
      Instead, it is available as an experiment using <code>GOEXPERIMENT=cgocheck2</code>.
      In particular this means that this mode has to be selected at build time instead of startup time.
    </p>

    <p>
      <code>GODEBUG=cgocheck=1</code> is still available (and is still the default).
    </p>

    <p><!-- https://go.dev/issue/46787, CL 367296 -->
      A new type <code>Pinner</code> has been added to the runtime
      package. <code>Pinner</code>s may be used to "pin" Go memory
      such that it may be used more freely by non-Go code. For instance,
      passing Go values that reference pinned Go memory to C code is
      now allowed. Previously, passing any such nested reference was
      disallowed by the
      <a href="https://pkg.go.dev/cmd/cgo#hdr-Passing_pointers">cgo pointer passing rules.</a>

      See <a href="https://go.dev/pkg/runtime#Pinner">the docs</a> for more details.
    </p>

    <!-- CL 472195 no release note needed -->
  </dd>
</dl><!-- runtime -->

<dl id="runtime/metrics"><dt><a href="https://go.dev/pkg/runtime/metrics/">runtime/metrics</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/56857, CL 497315 -->
      A few previously-internal GC metrics, such as live heap size, are
      now available.

      <code>GOGC</code> and <code>GOMEMLIMIT</code> are also now
      available as metrics.
    </p>
  </dd>
</dl><!-- runtime/metrics -->

<dl id="runtime/trace"><dt><a href="https://go.dev/pkg/runtime/trace/">runtime/trace</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/16638 -->
      Collecting traces on amd64 and arm64 now incurs a substantially
      smaller CPU cost: up to a 10x improvement over the previous release.
    </p>

    <p><!-- CL 494495 -->
      Traces now contain explicit stop-the-world events for every reason
      the Go runtime might stop-the-world, not just garbage collection.
    </p>
  </dd>
</dl><!-- runtime/trace -->

<dl id="sync"><dt><a href="https://go.dev/pkg/sync/">sync</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/56102, CL 451356 -->
      The new <a href="https://go.dev/pkg/sync/#OnceFunc"><code>OnceFunc</code></a>,
      <a href="https://go.dev/pkg/sync/#OnceValue"><code>OnceValue</code></a>, and
      <a href="https://go.dev/pkg/sync/#OnceValues"><code>OnceValues</code></a>
      functions capture a common use of <a href="https://go.dev/pkg/sync/#Once">Once</a> to
      lazily initialize a value on first use.
    </p>
  </dd>
</dl>

<dl id="syscall"><dt><a href="https://go.dev/pkg/syscall/">syscall</a></dt>
  <dd>
    <p><!-- CL 480135 -->
      On Windows the
      <a href="https://go.dev/pkg/syscall#Fchdir"><code>Fchdir</code></a> function
      now changes the current directory to its argument, rather than
      always returning an error.
    </p>

    <p><!-- https://go.dev/issue/46259, CL 458335 -->
      On FreeBSD
      <a href="https://go.dev/pkg/syscall#SysProcAttr"><code>SysProcAttr</code></a>
      has a new field <code>Jail</code> that may be used to put the
      newly created process in a jailed environment.
    </p>

    <p><!-- CL 493036 -->
      On Windows the syscall package now supports working with files whose
      names, stored as UTF-16, can't be represented as valid UTF-8.
      The <a href="https://go.dev/pkg/syscall#UTF16ToString"><code>UTF16ToString</code></a>
      and <a href="https://go.dev/pkg/syscall#UTF16FromString"><code>UTF16FromString</code></a>
      functions now convert between UTF-16 data and
      <a href="https://simonsapin.github.io/wtf-8/">WTF-8</a> strings.
      This is backward compatible as WTF-8 is a superset of the UTF-8
      format that was used in earlier releases.
    </p>

    <p><!-- CL 476578, CL 476875, CL 476916 -->
      Several error values match the new
      <a href="https://go.dev/pkg/errors/#ErrUnsupported"><code>errors.ErrUnsupported</code></a>,
      such that <code>errors.Is(err, errors.ErrUnsupported)</code>
      returns true.
      </p><ul>
        <li><code>ENOSYS</code></li>
        <li><code>ENOTSUP</code></li>
        <li><code>EOPNOTSUPP</code></li>
        <li><code>EPLAN9</code> (Plan 9 only)</li>
        <li><code>ERROR_CALL_NOT_IMPLEMENTED</code> (Windows only)</li>
        <li><code>ERROR_NOT_SUPPORTED</code> (Windows only)</li>
        <li><code>EWINDOWS</code> (Windows only)</li>
      </ul>
    
  </dd>
</dl><!-- syscall -->

<dl id="testing"><dt><a href="https://go.dev/pkg/testing/">testing</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/37708, CL 463837 -->
      The new <code>-test.fullpath</code> option will print full path
      names in test log messages, rather than just base names.
    </p>

    <p><!-- https://go.dev/issue/52600, CL 475496 -->
      The new <a href="https://go.dev/pkg/testing/#Testing"><code>Testing</code></a> function reports whether the program is a test created by <code>go</code> <code>test</code>.
    </p>
  </dd>
</dl><!-- testing -->

<dl id="testing/fstest"><dt><a href="https://go.dev/pkg/testing/fstest/">testing/fstest</a></dt>
  <dd>
    <p><!-- https://go.dev/issue/54451, CL 491175 -->
      Calling <code><a href="https://go.dev/pkg/testing/fstest/MapFS.Open">Open</a>.<a href="https://go.dev/pkg/io/fs/#File.Stat">Stat</a></code>
      will return a type that now implements a <code>String</code>
      method that calls
      <a href="https://go.dev/pkg/io/fs/#FormatFileInfo"><code>io/fs.FormatFileInfo</code></a>.
    </p>
  </dd>
</dl><!-- testing/fstest -->

<dl id="unicode"><dt><a href="https://go.dev/pkg/unicode/">unicode</a></dt>
  <dd>
    <p><!-- CL 456837 -->
      The <a href="https://go.dev/pkg/unicode/"><code>unicode</code></a> package and
      associated support throughout the system has been upgraded to
      <a href="https://www.unicode.org/versions/Unicode15.0.0/">Unicode 15.0.0</a>.
    </p>
  </dd>
</dl><!-- unicode -->

<h2 id="ports">Ports</h2>

<h3 id="darwin">Darwin</h3>

<p><!-- https://go.dev/issue/57125 -->
  As <a href="https://go.dev/doc/go1.20#darwin">announced</a> in the Go 1.20 release notes,
  Go 1.21 requires macOS 10.15 Catalina or later;
  support for previous versions has been discontinued.
</p>

<h3 id="windows">Windows</h3>

<p><!-- https://go.dev/issue/57003, https://go.dev/issue/57004 -->
  As <a href="https://go.dev/doc/go1.20#windows">announced</a> in the Go 1.20 release notes,
  Go 1.21 requires at least Windows 10 or Windows Server 2016;
  support for previous versions has been discontinued.
</p>

<!-- CL 470695 -->


<h3 id="wasm">WebAssembly</h3>

<p><!-- https://go.dev/issue/38248, https://go.dev/issue/59149, CL 489255 -->
  The new <code>go:wasmimport</code> directive can now be used in Go programs
  to import functions from the WebAssembly host.
</p>

<!-- https://go.dev/issue/56100 -->
<p>
  The Go scheduler now interacts much more efficiently with the
  JavaScript event loop, especially in applications that block
  frequently on asynchronous events.
</p>


<h3 id="wasip1">WebAssembly System Interface</h3>

<p><!-- https://go.dev/issue/58141 -->
  Go 1.21 adds an experimental port to the <a href="https://wasi.dev/">
  WebAssembly System Interface (WASI)</a>, Preview 1
  (<code>GOOS=wasip1</code>, <code>GOARCH=wasm</code>).
</p>

<p>
  As a result of the addition of the new <code>GOOS</code> value
  "<code>wasip1</code>", Go files named <code>*_wasip1.go</code>
  will now be <a href="https://go.dev/pkg/go/build/#hdr-Build_Constraints">ignored
  by Go tools</a> except when that <code>GOOS</code> value is being
  used.
  If you have existing filenames matching that pattern, you will
  need to rename them.
</p>

<h3 id="PPC64">ppc64/ppc64le</h3>

<p><!-- go.dev/issue/44549 -->
  On Linux, <code>GOPPC64=power10</code> now generates PC-relative instructions, prefixed
  instructions, and other new Power10 instructions. On AIX, <code>GOPPC64=power10</code>
  generates Power10 instructions, but does not generate PC-relative instructions.
</p>

<p>
  When building position-independent binaries for <code>GOPPC64=power10</code>
  <code>GOOS=linux</code> <code>GOARCH=ppc64le</code>, users can expect reduced binary
  sizes in most cases, in some cases 3.5%. Position-independent binaries are built for
  ppc64le with the following <code>-buildmode</code> values:
  <code>c-archive</code>, <code>c-shared</code>, <code>shared</code>, <code>pie</code>, <code>plugin</code>.
</p>

<h3 id="loong64">loong64</h3>

<p><!-- go.dev/issue/53301, CL 455075, CL 425474, CL 425476, CL 425478, CL 489576 -->
  The <code>linux/loong64</code> port now supports <code>-buildmode=c-archive</code>,
  <code>-buildmode=c-shared</code> and <code>-buildmode=pie</code>.
</p>

<!-- proposals for x repos that don't need to be mentioned here but
     are picked up by the relnote tool. -->
<!-- https://go.dev/issue/54232 -->
<!-- https://go.dev/issue/57051 -->
<!-- https://go.dev/issue/57792 -->
<!-- https://go.dev/issue/57906 -->
<!-- https://go.dev/issue/58668 -->
<!-- https://go.dev/issue/59016 -->
<!-- https://go.dev/issue/59676 -->
<!-- https://go.dev/issue/60409 -->
<!-- https://go.dev/issue/61176 -->

<!-- changes to cmd/api that don't need release notes. -->
<!-- CL 469115, CL 469135, CL 499981 -->

<!-- proposals that don't need release notes. -->
<!-- https://go.dev/issue/10275 -->
<!-- https://go.dev/issue/59719 -->



</article>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[StableCode (239 pts)]]></title>
            <link>https://stability.ai/blog/stablecode-llm-generative-ai-coding</link>
            <guid>37050409</guid>
            <pubDate>Tue, 08 Aug 2023 15:25:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://stability.ai/blog/stablecode-llm-generative-ai-coding">https://stability.ai/blog/stablecode-llm-generative-ai-coding</a>, See on <a href="https://news.ycombinator.com/item?id=37050409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="62f2452bc121595f4d87c71c">
  
  
    
    


  


<div data-content-field="main-content" data-item-id="" data-test="page-section" data-section-theme="bright" data-section-id="62f2452bc121595f4d87c71e" data-controller="SectionWrapperController" data-current-styles="{
&quot;imageOverlayOpacity&quot;: 0.15,
&quot;backgroundWidth&quot;: &quot;background-width--full-bleed&quot;,
&quot;sectionHeight&quot;: &quot;section-height--medium&quot;,
&quot;horizontalAlignment&quot;: &quot;horizontal-alignment--center&quot;,
&quot;verticalAlignment&quot;: &quot;vertical-alignment--middle&quot;,
&quot;contentWidth&quot;: &quot;content-width--wide&quot;,
&quot;sectionTheme&quot;: &quot;bright&quot;,
&quot;sectionAnimation&quot;: &quot;none&quot;,
&quot;backgroundMode&quot;: &quot;image&quot;
}" data-current-context="{
&quot;video&quot;: {
&quot;playbackSpeed&quot;: 0.5,
&quot;filter&quot;: 1,
&quot;filterStrength&quot;: 0,
&quot;zoom&quot;: 0,
&quot;videoSourceProvider&quot;: &quot;none&quot;
},
&quot;backgroundImageId&quot;: null,
&quot;backgroundMediaEffect&quot;: null,
&quot;divider&quot;: null,
&quot;typeName&quot;: &quot;blog-side-by-side&quot;
}" data-animation="none">
  <article id="article-">
  
    <div data-layout-label="Post Body" data-type="item" id="item-64d2439d9ce9c7286329053a"><div data-block-type="2" id="block-0d37d8f624da11f15357">

<p>Stability AI has just announced the release of StableCode, its very first LLM generative AI product for coding. This product is designed to assist programmers with their daily work while also providing a great learning tool for new developers ready to take their skills to the next level.</p>



</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1691501470316_6458">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg" data-image="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg" data-image-dimensions="1024x1024" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg" width="1024" height="1024" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/b960c76b-30a3-447d-96bc-8088a21a4be0/SDXL+colorful+parrot_clipdrop-enhance.jpg?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>&nbsp;“a colorful parrot with glasses typing away at a computer, flat icon, vector” – SDXL 0.9</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1691501470316_6845">
  <p>StableCode offers a unique way for developers to become more efficient by using three different models to help in their coding. The <a href="https://huggingface.co/stabilityai/stablecode-completion-alpha-3b-4k" target="_blank"><span>base model</span></a> was first trained on a diverse set of programming languages from the<a href="https://www.bigcode-project.org/docs/about/the-stack/" target="_blank"> <span>stack-dataset</span></a> (v1.2) from BigCode and then trained further with popular languages like Python, Go, Java, Javascript, C, markdown and C++.&nbsp; In total, we trained our models on 560B tokens of code on our HPC cluster.&nbsp;</p><p>After the base model had been established, the <a href="https://huggingface.co/stabilityai/stablecode-instruct-alpha-3b" target="_blank"><span>instruction model</span></a> was then tuned for specific use cases to help solve complex programming tasks. ~120,000 code instruction/response pairs in Alpaca format were trained on the base model to achieve this result.&nbsp;</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1691501470316_8307">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png" data-image="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png" data-image-dimensions="1552x880" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png" width="1552" height="880" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/0de4a94c-7756-4be5-8b43-375d99f8e587/stable-code-instruct-demo.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>Code for using StableCode Instruct to generate a response to a given instruction.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1691501470316_8657">
  <p>StableCode is the ideal building block for those wanting to learn more about coding, and the <a href="https://huggingface.co/stabilityai/stablecode-completion-alpha-3b" target="_blank"><span>long-context window model</span></a> is the perfect assistant to ensure single and multiple-line autocomplete suggestions are available for the user. This model is built to handle a lot more code at once (2-4X more than previously-released open models with a context window of 16,000 tokens), allowing the user to review or edit the equivalent of up to five average-sized Python files at the same time, making it the ideal learning tool for a beginner who wants to rise to bigger challenges.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1691501470316_13747">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png" data-image="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png" data-image-dimensions="1552x1422" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png" width="1552" height="1422" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/cb325400-49eb-4b26-82f2-0b19228833e0/stable-code-alpha-demo.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>StableCode completing a relatively complex python file utilizing the Pytorch deep learning library (gray text shows StableCode’s prediction).</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1691501470316_14097">
  <p>And here is how we compare to other models of a similar number of parameters and number of tokens trained on. We use the standard pass@1 and pass@10 metrics using the popular HumanEval benchmark.</p>
</div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1691520734507_6621">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png" data-image="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png" data-image-dimensions="1634x214" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png" width="1634" height="214" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/590292fe-6892-4056-927f-d9129470eaa3/image+%282%29.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>benchmark scores of stablecode.</em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-test="image-block-inline-outer-wrapper" data-block-type="5" id="block-yui_3_17_2_1_1691520734507_8553">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png" data-image="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png" data-image-dimensions="2760x1458" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png" width="2760" height="1458" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6213c340453c3f502425776e/d77f0860-409a-4fa4-b9a0-ea553372ab58/image+%285%29.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs">
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p><em>HumanEval Benchmark Comparison with models of similar size(3B). </em></p>
          </figcaption>
        
      
        </figure>
      

    </div><div data-block-type="2" id="block-yui_3_17_2_1_1691520734507_9502">
  <p>Stability AI aims to make technology more accessible, and StableCode is a significant step toward this goal. People of every background will soon be able to create code to solve their everyday problems and improve their lives using AI, and we’d like to help make this happen. We hope that StableCode will help the next billion software developers learn to code while providing fairer access to technology all over the world.</p>
</div></div>
  
</article>

</div>

  
</article>


          

          
            
              

            
          
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GPT-4 can't reason (202 pts)]]></title>
            <link>https://www.preprints.org/manuscript/202308.0148/v1</link>
            <guid>37050257</guid>
            <pubDate>Tue, 08 Aug 2023 15:15:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.preprints.org/manuscript/202308.0148/v1">https://www.preprints.org/manuscript/202308.0148/v1</a>, See on <a href="https://news.ycombinator.com/item?id=37050257">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="submission-content">
                <p><span>Preprint</span>
    <span>Article</span>
    <span>Version 1</span>
    <span>Preserved in Portico </span>    <span>This version is not peer-reviewed</span>
</p>




<p>
                                        Version 1
                : Received: 27 July 2023 / Approved: 2 August 2023 / Online: 2 August 2023 (04:10:57 CEST)
                        <br>
                                                <a href="https://www.preprints.org/manuscript/202308.0148/v2">Version 2</a>
                : Received: 3 August 2023 / Approved: 4 August 2023 / Online: 7 August 2023 (07:13:00 CEST)
                        <br>
            </p>
            <p>
            
            Arkoudas, K. GPT-4 Can't Reason. <em>Preprints</em> <b>2023</b>, 2023080148. https://doi.org/10.20944/preprints202308.0148.v1
            
<span>
    <span>Arkoudas, K. GPT-4 Can't Reason. Preprints 2023, 2023080148. https://doi.org/10.20944/preprints202308.0148.v1</span>
    
</span>        </p>



<h2>
    <span>Abstract</span>
</h2>
<p>
    GPT-4 was released in March 2023 to wide acclaim, marking a very substantial improvement across the board over GPT-3.5 (OpenAI's previously best model, which had powered the initial release of ChatGPT). Despite the genuinely impressive improvement, however, there are good reasons to be highly skeptical of GPT-4's ability to reason. This position paper discusses the nature of reasoning; criticizes the current formulation of reasoning problems in the NLP community and the way in which the reasoning performance of LLMs is currently evaluated; introduces a collection of 21 diverse reasoning problems; and performs a detailed qualitative analysis of GPT-4's performance on these problems. Based on the results of this analysis, the paper argues that, despite the occasional flashes of analytical brilliance, GPT-4 at present is utterly incapable of reasoning.
</p>



<h2>
    <span>Keywords</span>
</h2>
<p>
            GPT-4; LLM; AI; reasoning; inference
    </p>

    <h2>
        <span>Subject</span>
    </h2>
    <p>
        Computer Science and Mathematics, Artificial Intelligence and Machine Learning
    </p>
    <p>
        
        This is an open access article distributed under the <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">Creative Commons Attribution License</a> which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.
    </p>
                
                <h2><span>Comments (0)</span></h2>
                
                
            <p>We encourage comments and feedback from a broad range of readers. See <a href="https://www.preprints.org/about#HowItWorks">criteria for comments</a> and our <a href="https://www.preprints.org/about#CommentAndDiscuss">Diversity</a> statement.</p>
        <p><a href="#">Leave a public comment</a><br>
        <a href="#">Send a private comment to the author(s)</a></p><p>* All users must log in before leaving a comment</p>
            
                        
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Homo sapiens declared extinct (1999) (211 pts)]]></title>
            <link>https://bruces.medium.com/homo-sapiens-declared-extinct-by-bruce-sterling-1999-cc8b0f94b195</link>
            <guid>37050089</guid>
            <pubDate>Tue, 08 Aug 2023 15:06:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bruces.medium.com/homo-sapiens-declared-extinct-by-bruce-sterling-1999-cc8b0f94b195">https://bruces.medium.com/homo-sapiens-declared-extinct-by-bruce-sterling-1999-cc8b0f94b195</a>, See on <a href="https://news.ycombinator.com/item?id=37050089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><a rel="noopener follow" href="https://bruces.medium.com/?source=post_page-----cc8b0f94b195--------------------------------"><div aria-hidden="false"><p><img alt="Bruce Sterling" src="https://miro.medium.com/v2/resize:fill:88:88/0*b5Lq7qcNhi6n8r6j.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div><p id="3503">First published in Nature magazine, November 1999.</p><p id="c88f">AD 2380: After a painstaking ten-year search, from the Tibetan highlands to the Brazilian rainforests, it’s official — there are no more human beings.</p><p id="f883">“I suppose I have to consider this a personal setback,” said anthropologist Dr Marcia Raymo, of the Institute for Retrograde Study in Berlin. “Of course we still have human tissue in the lab, and we could clone as many specimens of <em>Homo sapiens</em> as we like. But that species was always known primarily for its unique cultural activity.”</p><p id="5e8b">“I can’t understand what the fuss is about,” declared Rita “Cuddles” Srinivasan, actress, sex symbol and computer peripheral. “Artificial Intelligences love to embody themselves in human forms like mine, to wallow in sex and eating. I’m good for oodles of human stuff, scratching, sleeping, sneezing, you can name it. As long as AIs honour their origins, you’ll see plenty of disembodied intelligences slumming around in human forms. That’s where all the fun is, I promise — trust me.”</p><p id="2d29">The actress’s current AI sponsor further remarked via wireless telepathy that Miss Srinivasan’s occasional extra arms or heads should be seen as a sign of “creative brio,” and not as a violation of “some obsolete, supposedly standard human form”.</p><p id="1b09">A worldwide survey of skull contents in April 2379 revealed no living citizen with less than 35 per cent cultured gelbrain. “That pretty well kicks it in the head for me,” declared statistician Piers Euler, the front identity for a collaborative group-mind of mathematicians at the Bourbaki Academy in Paris. “I don’t see how you can declare any entity ‘human’ when their brain is a gelatin lattice, and every cell of their body contains extensive extra strands of industrial-strength DNA. Not only is humanity extinct but, strictly speaking, pretty much everyone alive today should be classified as a unique, post-natural, one-of-a-kind species.”</p><p id="991f">“I was born human,” admitted 380-year-old classical musician Soon Yi, speaking from his support vat in Shanghai. “I grew up as a human being. It seemed quite natural at the time. For hundreds of years on the state-supported concert circuit, I promoted myself as a ‘humanist’, supporting and promoting human high culture. But at this point, I should be honest: that was always my stage pretence. Let’s face it: gelbrain is vastly better stuff than those grey, greasy, catch-as-catch-can human neurons. You can’t become a serious professional artiste while using nothing but all-natural animal tissue in your head. It’s just absurd!”</p><p id="7bc6">Gently fanning his wizened tissues with warm currents of support fluid, the grand old man of music continued: “Wolfgang Mozart was a very dull creature by our modern standards but, thanks to gelbrain, I can still find ways to pump life into his primitive compositions. I also persist in finding Bach worthwhile, even in today’s ultracivilized milieu, where individual consciousness and creative subjectivity tend to be rather rare, or absent entirely.”</p><p id="5e6a">Posthumanity’s most scientifically advanced group, the pioneer Blood Bathers in their vast crystalline castles in the Oort Cloud, could not be reached for comment.</p><p id="1ed0">“Why trouble the highly prestigious Blood Bathers with some trifling development here on distant Earth?” demanded President Arno Hopmeier of the World Antisubjectivist Council. “The Blood Bathers are busily researching novel realms of complex organization far beyond mere ‘intelligence’. We should feel extremely honoured that they still bother to share their lab results with creatures like us. It would only annoy Their Skinless Eminences if we ask them to fret over some defunct race of featherless bipeds.”</p><p id="6fe6">A Circumsolar Day of Mourning has been declared to commemorate the official extinction of humanity, but it is widely believed that bursts of wild public enthusiasm will mar the funereal proceedings.</p><p id="f712">“When you sum them up,” mused Orbital Entity Ankh/Ghih/9819, “it’s hard to perceive any tragedy in this long-awaited event. Beasts, birds, butterflies, even the very rocks and rivers must be rejoicing to see humans finally gone. We should try to be adult about this: we should take a deep breath, turn our face to the light of the future, and get on with the business of living.</p><p id="73bf">“Since I’ve been asked to offer an epitaph,” the highly distributed poetware continued, “I believe that we should rearrange the Great Wall of China to spell out (in Chinese of course, since most of them were always Chinese) — ‘THEY WERE VERY, VERY CURIOUS, BUT NOT AT ALL FAR-SIGHTED.’</p><p id="1339">“This historical moment is a serious occasion that requires a sense of public dignity. My dog, for instance, says he’ll truly miss humanity. But then again, my dog says a lot of things.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EFF denounces Google's WEI proposal (591 pts)]]></title>
            <link>https://www.eff.org/deeplinks/2023/08/your-computer-should-say-what-you-tell-it-say-1</link>
            <guid>37050035</guid>
            <pubDate>Tue, 08 Aug 2023 15:03:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.eff.org/deeplinks/2023/08/your-computer-should-say-what-you-tell-it-say-1">https://www.eff.org/deeplinks/2023/08/your-computer-should-say-what-you-tell-it-say-1</a>, See on <a href="https://news.ycombinator.com/item?id=37050035">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div><h2><span>WEI? I’m a frayed knot</span></h2>
<blockquote><p><i><span>Two pieces of string walk into a bar.</span></i></p>
<p><i><span>The first piece of string asks for a drink.</span></i></p>
<p><i><span>The bartender says, “Get lost. We don’t serve pieces of string.”</span></i></p>
<p><i><span>The second string ties a knot in his middle and messes up his ends. Then he orders a drink.&nbsp;</span></i></p>
<p><i><span>The bartender says, “Hey, you aren’t a piece of string, are you?”</span></i></p>
<p><i><span>The piece of string says, “Not me! I'm a frayed knot.”</span></i></p>
</blockquote>
<p><span>Google is adding code to Chrome that will send tamper-proof information about your operating system and other software, and share it with websites. Google says this will reduce ad fraud. In practice, it reduces your control over your own computer, and is likely to mean that some websites will block access for everyone who's not using an "approved" operating system and browser. It also raises the barrier to entry for new browsers, something Google employees acknowledged in an unofficial explainer for the new feature, </span><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md"><span>Web Environment Integrity (WEI)</span></a><span>.</span></p>
<p><span>If you’re scratching your head at this point, we don’t blame you. This is pretty abstract! We’ll unpack it a little below - and then we’ll explain why this is a </span><i><span>bad idea</span></i><span> that Google </span><i><span>should not pursue</span></i><span>.&nbsp;</span></p>
<p><span>But first…</span></p>
<h2><span>Some background</span></h2>
<p><span>When your web browser connects to a web server, it automatically sends a description of your device and browser, something like, "This session is coming from a Google Pixel 4, using Chrome version 116.0.5845.61." The server on the other end of that connection can request even more detailed information, like a list of which fonts are installed on your device, how big its screen is, and more.&nbsp;</span></p>
<p><span>This can be good. The web server that receives this information can tailor its offerings to you. That server can make sure it only sends you file formats your device understands, at a resolution that makes sense for your screen, laid out in a way that works well for you.</span></p>
<p><span>But there are also downsides to this. Many sites use "</span><a href="https://coveryourtracks.eff.org/"><span>browser fingerprinting</span></a><span>" - a kind of tracking that relies on your browser's unique combination of characteristics - to nonconsensually identify users who reject cookies and other forms of surveillance. Some sites make inferences about you from your browser and device in order to determine whether they can charge you more, or serve you </span><a href="https://qz.com/1733345/the-fight-against-discriminatory-financial-ads-on-facebook"><span>bad or deceptive offers</span></a><span>.&nbsp;</span></p>
<p><span>Thankfully, the information your browser sends to websites about itself and your device is strictly voluntary. Your browser </span><i><span>can</span></i><span> send accurate information about you, but it doesn't have to. There are lots of plug-ins, privacy tools and esoteric preferences that you can use to send information of your choosing to sites that you don't trust.&nbsp;</span></p>
<p><span>These tools don't just let you refuse to describe your computer to nosy servers across the internet. After all, a service that has so little regard for you that it would use your configuration data to inflict harms on you might very well refuse to serve you at all, as a means of coercing you into giving up the details of your device and software.</span></p>
<p><span>Instead, privacy and anti-tracking tools send </span><a href="https://wiki.archlinux.org/title/Firefox/Privacy"><span>plausible, </span><i><span>wrong</span></i><span> information about your device</span></a><span>. That way, services can't discriminate against you for choosing your own integrity over their business models.</span></p>
<p><span>That's where </span><i><span>remote attestation</span></i><span> comes in.</span></p>
<h2><span>Secure computing and remote attestation</span></h2>
<p><span>Most modern computers, tablets and phones ship from the factory with some kind of "secure computing" capability.&nbsp;</span></p>
<p><span>Secure computing is designed to be a system for monitoring your computer that you can't modify, or reconfigure. Originally, secure computing relied on a second processor - a "Technical Protection Module" or TPM - to monitor the parts of your computer you directly interact with. These days, many devices use a "secure enclave" - a hardened subsystem that is carefully designed to ensure that it can only be changed with the manufacturer’s permission..</span></p>
<p><span>These security systems have lots of uses. When you start your device, they can watch the boot-up process and check each phase of it to ensure that you're running the manufacturer's unaltered code, and not a version that's been poisoned by malicious software. That's great if you </span><i><span>want</span></i><span> to run the manufacturer's code, but the same process can be used to stop you from </span><i><span>intentionally</span></i><span> running different code, say, a free/open source operating system, or a version of the manufacturer's software that has been altered to disable undesirable features (like surveillance) and/or enable desirable ones (like the ability to install software from outside the manufacturer's app store).</span></p>
<p><span>Beyond controlling the code that runs on your device, these security systems can also provide information about your hardware and software to other people over the internet. Secure enclaves and TPMs ship with cryptographic "signing keys." They can gather information about your computer - its operating system version, extensions, software, and low-level code like bootloaders - and cryptographically sign all that information in an "</span><b>attestation</b><span>."</span></p>
<p><span>These attestations change the balance of power when it comes to networked communications. When a remote server wants to know what kind of device you're running and how it's configured, that server no longer has to take your word for it. It can require an attestation.</span></p>
<p><span>Assuming you haven't figured out how to bypass the security built into your device's secure enclave or TPM, that attestation is a highly reliable indicator of how your gadget is set up.&nbsp;</span></p>
<p><span>What's more, altering your device's TPM or secure enclave is a legally fraught business. Laws like </span><a href="https://www.eff.org/deeplinks/2022/12/dc-circuit-evades-important-questions-disappointing-ruling-section-1201-dmca"><span>Section 1201 of the Digital Millennium Copyright Act</span></a><span> as well as patents and copyrights create serious civil and criminal jeopardy for technologists who investigate these technologies. That danger gets substantially worse when the technologist publishes findings about how to disable or bypass these secure features. And if a technologist dares to distribute tools to effect that bypass, they need to reckon with serious criminal and civil legal risks, including multi-year prison sentences.</span></p>
<h2><span>WEI? No way!</span></h2>
<p><span>This is where the Google proposal comes in. WEI is a technical proposal to let servers request remote attestations from devices, with those requests being relayed to the device's secure enclave or TPM, which will respond with a cryptographically signed, highly reliable description of your device. You can choose not to send this to the remote server, but you lose the ability to send an </span><i><span>altered</span></i><span> or </span><i><span>randomized</span></i><span> description of your device and its software if you think that's best for you.</span></p>
<p><span>In their proposal, </span><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/main/explainer.md"><span>the Google engineers claim several benefits of such a scheme</span></a><span>. But, despite their valiant attempts to cast these benefits as accruing to device owners, these are really designed to benefit the owners of commercial services; the benefit to users comes from the assumption that commercial operators will use the additional profits from remote attestation to make their services better for their users.</span></p>
<p><span>For example, the authors say that remote attestations will allow site operators to distinguish between real internet users who are manually operating a browser, and bots who are autopiloting their way through the service. This is said to be a way of reducing ad-fraud, which will increase revenues to publishers, who may plow those additional profits into producing better content.&nbsp;</span></p>
<p><span>They also claim that attestation can foil “machine-in-the-middle” attacks, where a user is presented with a fake website into which they enter their login information, including one-time passwords generated by a two-factor authentication (2FA) system, which the attacker automatically enters into the </span><i><span>real</span></i><span> service’s login screen.&nbsp;</span></p>
<p><span>They claim that gamers could use remote attestation to make sure the other gamers they’re playing against are running unmodified versions of the game, and not running cheats that give them an advantage over their competitors.</span></p>
<p><span>They claim that giving website operators the power to detect and block browser automation tools will let them block fraud, such as posting&nbsp; fake reviews or mass-creating bot accounts.</span></p>
<p><span>There’s arguably some truth to all of these claims. That’s not unusual: in matters of security, there’s often ways in which indiscriminate invasions of privacy and compromises of individual autonomy would blunt some real problems.&nbsp;</span></p>
<p><span>Putting handcuffs on every shopper who enters a store would doubtless reduce shoplifting, and stores with less shoplifting might lower their prices, benefitting all of their customers. But ultimately, shoplifting is the </span><i><span>store’s</span></i><span> problem, not the shoppers’, and it’s not fair for the store to make everyone else bear the cost of resolving its difficulties.</span></p>
<h2><span>WEI helps websites block disfavored browsers</span></h2>
<p><span>One </span><a href="https://github.com/RupertBenWiser/Web-Environment-Integrity/blob/7998217b3d7334a71c26c52aeeadc1c6b1ba1dc4/explainer.md#how-will-we-prevent-this-signal-from-being-used-to-exclude-vendors"><span>section of Google’s document</span></a><span> acknowledges that websites will use WEI to lock out browsers and operating systems that they dislike, or that fail to implement WEI to the website’s satisfaction. Google tentatively suggests (“we are evaluating”) a workaround: even once Chrome implements the new technology, it would refuse to send WEI information from a “small percentage” of computers that would otherwise send it. In theory, any website that refuses visits from non-WEI browsers would wind up also blocking this “small percentage” of Chrome users, who would complain so vociferously that the website would have to roll back their decision and allow everyone in, WEI or not.</span></p>
<p><span>The problem is, there are lots of websites that would </span><i><span>really, really</span></i><span> like the power to dictate what browser and operating system people can use. Think “</span><a href="https://www.theverge.com/2018/1/4/16805216/google-chrome-only-sites-internet-explorer-6-web-standards"><span>this website works best in Internet Explorer 6.0 on Windows XP</span></a><span>.” Many websites will consider that “small percentage” of users an acceptable price to pay, or simply instruct users to reset their browser data until a roll of the dice enables WEI for that site.</span></p>
<p><span></span><span>Also, Google has a conflict of interest in choosing the “small percentage.” Setting it very small would benefit Google’s ad fraud department by authenticating more ad clicks, allowing Google to sell those ads at a higher price. Setting it high makes it harder for websites to implement exclusionary behavior, but doesn’t directly benefit Google at all. It only makes it easier to build competing browsers. So even if Google chooses to implement this workaround, their incentives are to configure it as too small to protect the open web.</span></p>
<h2><span>You are the boss of your computer</span></h2>
<p><span>Your computer belongs to </span><i><span>you</span></i><span>. You are the boss of it. It should do what you tell it to.&nbsp;</span></p>
<p><span>We live in a </span><i><span>wildly</span></i><span> imperfect world. Laws that prevent you from reverse-engineering and reconfiguring your computer are bad enough, but when you combine that with a monopolized internet of</span> <span>“</span><a href="https://twitter.com/tveastman/status/1069674780826071040"><span>five giant websites filled with screenshots of text from the other four</span></a><span>,” things can get really bad.</span></p>
<p><span>A handful of companies have established chokepoints between buyers and sellers, performers and audiences, workers and employers, as well as families and communities. When those companies refuse to deal with you, your digital life grinds to a halt.&nbsp;</span></p>
<p><span>The web is the last major open platform left on the internet - the last platform where anyone can make a browser or a website and participate, without having to ask permission or meet someone else’s specifications.</span></p>
<p><span>You are the boss of your computer. If a website sets up a virtual checkpoint that says, “only approved technology beyond this point,” you should have the right to tell it, “I’m no piece of string, I’m a frayed knot.” That is, you should be able to tell a site what it wants to hear, even if the site would refuse to serve you if it knew the truth about you.&nbsp;</span></p>
<p><span>To their credit, the proposers of WEI state that they would like for WEI to be used solely for benign purposes. They explicitly decry the use of WEI to block browsers, or to exclude users for wanting to keep their private info private.</span></p>
<p><span>But computer scientists don't get to decide how a technology gets used. Adding attestation to the web carries the completely foreseeable risk that companies </span><i><span>will</span></i><span> use it to attack users' right to configure their devices to suit their needs, even when that conflicts with tech companies' commercial priorities.&nbsp;</span></p>
<p><span>WEI shouldn't be made. If it's made, it shouldn't be used.&nbsp;</span></p>
<h2><span>So what?</span></h2>
<p><span>So what should we do about WEI and other remote attestation technologies?</span></p>
<p><span>Let's start with what we </span><i><span>shouldn't</span></i><span> do. We shouldn't ban remote attestation. </span><a href="https://www.eff.org/deeplinks/2015/04/remembering-case-established-code-speech"><span>Code is speech</span></a><span> and everyone should be free to study, understand, and produce remote attestation tools.</span></p>
<p><span>These tools might have a place within distributed systems - for example, voting machine vendors might use remote attestation to verify the configuration of their devices in the field. Or at-risk human rights workers might send remote attestations to trusted technologists to help determine whether their devices have been compromised by state-sponsored malware.</span></p>
<p><span>But these tools should not be added to the web. Remote attestations have no place on open platforms. You are the boss of your computer, and you should have the final say over what it tells other people about your computer and its software.&nbsp;</span></p>
<p><span>Companies' problems are not as important as their users' autonomy</span></p>
<p><span>We sympathize with businesses whose revenues might be impacted by ad-fraud, game companies that struggle with cheaters, and services that struggle with bots. But addressing these problems can’t come before&nbsp; the right of technology users to choose how their computers work, or what those computers tell others about them, because the right to control one’s own devices is a building block of all civil rights in the digital world..&nbsp;</span></p>
<p><span>An open web delivers more benefit than harm. Letting giant, monopolistic corporations overrule our choices about which technology we want to use, and how we want to use it, is a recipe for solving those </span><i><span>companies'</span></i><span> problems, but not their users'.</span></p>

</div>

          </article>
    </div><div>
          <h2>Join EFF Lists</h2>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Italy approves 40% windfall tax on banks for 2023 as profits soar (102 pts)]]></title>
            <link>https://www.theguardian.com/world/2023/aug/08/italy-approves-40-windfall-tax-on-banks-for-2023-as-profits-soar</link>
            <guid>37049786</guid>
            <pubDate>Tue, 08 Aug 2023 14:47:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2023/aug/08/italy-approves-40-windfall-tax-on-banks-for-2023-as-profits-soar">https://www.theguardian.com/world/2023/aug/08/italy-approves-40-windfall-tax-on-banks-for-2023-as-profits-soar</a>, See on <a href="https://news.ycombinator.com/item?id=37049786">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>Italy has announced a one-off 40% windfall tax on local banks that have been accused of reaping billions in extra profit from <a href="https://www.theguardian.com/business/2023/jul/27/ecb-interest-rate-rises-recession-inflation" data-link-name="in body link">rising interest rates</a>.</p><p>The Italian government, which approved the surprise tax in a cabinet meeting on Monday night, said it planned to use the proceeds to support mortgage holders and cut taxes, at a time when rising rates have put extra pressure on households.</p><p>The decision, which analysts said could force banks to collectively give as much as €4.9bn (£4.2bn) to the state, sent bank shares plunging. Shares in Italy’s largest bank, Intesa Sanpaolo, fell 8.67% to close at €2.338 on Tuesday afternoon, while Unicredit closed 5.9% lower at €21.28.</p><p>It follows <a href="https://www.reuters.com/markets/europe/spain-approves-banking-tax-leaves-out-most-foreign-bank-units-2022-12-21/" data-link-name="in body link">similar moves by Spain last year</a>, and comes only weeks after Intesa Sanpaolo raised its profit forecasts for the year, reviving concerns over potential profiteering by high-street lenders.</p><p>Italy’s deputy prime minister, Matteo Salvini, told a news conference in Rome: “One only has to look at the banks’ first-half 2023 profits, also the result of the European Central Bank’s rate hikes, to realise that we are not talking about a few millions, but we are talking, one can assume, of billions .</p><p>“If [it is true that] the burden deriving from the cost of money has … doubled for households and businesses, what current account holders receive has certainly not doubled,” Salvini added, saying there was a large gap between the rates applied to loans and those to deposits.</p><p>Bank profits have soared in recent quarters because rising interest rates have allowed them to increase the amount they charge borrowers for loans and mortgages at a faster pace than they improve returns to savers. Lenders have pocketed the difference, known as the net interest margin and a key measure of their profitability.</p><p>The Italian government intends to tax 40% of this income stream, probably for 2023 as a whole. The payment is due by mid-2024.</p><p>Marco Nicolai, an equity analyst at Jefferies, said the decision to tax the net interest margin “came out of the blue”, noting that Italy’s minister of economy and finance, Giancarlo Giorgetti, “publicly poured water on this idea in the recent past”.</p><p>Jefferies estimated that Italy’s 10 largest publicly listed banks could end up paying €4.9bn as a result of the windfall tax, although the total figure was unclear. Nicolai said: “As of now, we haven’t seen an official version of the law, which adds further uncertainty over the potential impacts of this decision.”</p><p>The UK, which already has two banking sector taxes in place, is not expected to make similar moves. Instead, authorities have been taking aim at banks offering low savings rates, with the Financial Conduct Authority threatening to take <a href="https://www.theguardian.com/business/2023/jul/31/banks-with-lowest-savings-rates-to-face-robust-action-warns-uk-financial-watchdog" data-link-name="in body link">“robust action”</a> against laggards by the end of the year.</p><p>Rishi Sunak’s government has conversely tried to ease the tax burden on banks, by reducing the bank surcharge to compensate for a rise in corporation tax earlier this year.</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-12">skip past newsletter promotion</a><p id="EmailSignup-skip-link-12" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>There has also been pushback from the banking sector, which raised concerns about the potential competitive disadvantage. The industry body UK Finance said banks based in London already paid a “significantly higher rate of tax than those in other financial centres like Dublin and New York”.</p><p>A Labour source said the party did not intend to follow in Italy’s footsteps if it entered government.</p><p>A Treasury spokesperson said: “We already have two specific taxes for the banking sector – the bank levy and the bank corporation tax surcharge – and the entire UK banking sector generated around £39bn in tax last year which is almost enough to fund the entire police and justice system.</p><p>“The chancellor has been clear, however, that banks must pass on the interest rate increases to savers so they can benefit. The new consumer duty – which came into force last week – gives regulators the tools they need to take action where this isn’t happening.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Candle: Torch Replacement in Rust (328 pts)]]></title>
            <link>https://github.com/huggingface/candle</link>
            <guid>37049198</guid>
            <pubDate>Tue, 08 Aug 2023 14:09:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/huggingface/candle">https://github.com/huggingface/candle</a>, See on <a href="https://news.ycombinator.com/item?id=37049198">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><h2 tabindex="-1" dir="auto">candle</h2>
<p dir="auto"><a href="https://crates.io/crates/candle-core" rel="nofollow"><img src="https://camo.githubusercontent.com/cd16dc5317b00d5ec802ae4e14252a601a6160512020ecb043dbf3ee3adcdb36/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f63616e646c652d636f72652e737667" alt="Latest version" data-canonical-src="https://img.shields.io/crates/v/candle-core.svg"></a>
<a href="https://docs.rs/candle-core" rel="nofollow"><img src="https://camo.githubusercontent.com/05cfa8e3fff22e13fb8c9f9adbc4b291dbbca36b4c0aaa02780910713258fd64/68747470733a2f2f646f63732e72732f63616e646c652d636f72652f62616467652e737667" alt="Documentation" data-canonical-src="https://docs.rs/candle-core/badge.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d2b08729d49028074f6b73fc9e9f1a39306271e184ebd44386b66e70315af000/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f6c2f63616e646c652d636f72652e737667"><img src="https://camo.githubusercontent.com/d2b08729d49028074f6b73fc9e9f1a39306271e184ebd44386b66e70315af000/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f6c2f63616e646c652d636f72652e737667" alt="License" data-canonical-src="https://img.shields.io/crates/l/candle-core.svg"></a></p>
<p dir="auto">Candle is a minimalist ML framework for Rust with a focus on easiness of use and
on performance (including GPU support). Try our online demos:
<a href="https://huggingface.co/spaces/lmz/candle-whisper" rel="nofollow">whisper</a>,
<a href="https://huggingface.co/spaces/lmz/candle-llama2" rel="nofollow">llama2</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="let a = Tensor::randn(0f32, 1., (2, 3), &amp;Device::Cpu)?;
let b = Tensor::randn(0f32, 1., (3, 4), &amp;Device::Cpu)?;

let c = a.matmul(&amp;b)?;
println!(&quot;{c}&quot;);"><pre><span>let</span> a = <span>Tensor</span><span>::</span><span>randn</span><span>(</span><span>0f32</span><span>,</span> <span>1.</span><span>,</span> <span>(</span><span>2</span><span>,</span> <span>3</span><span>)</span><span>,</span> <span>&amp;</span><span>Device</span><span>::</span><span>Cpu</span><span>)</span>?<span>;</span>
<span>let</span> b = <span>Tensor</span><span>::</span><span>randn</span><span>(</span><span>0f32</span><span>,</span> <span>1.</span><span>,</span> <span>(</span><span>3</span><span>,</span> <span>4</span><span>)</span><span>,</span> <span>&amp;</span><span>Device</span><span>::</span><span>Cpu</span><span>)</span>?<span>;</span>

<span>let</span> c = a<span>.</span><span>matmul</span><span>(</span><span>&amp;</span>b<span>)</span>?<span>;</span>
<span>println</span><span>!</span><span>(</span><span>"{c}"</span><span>)</span><span>;</span></pre></div>
<h2 tabindex="-1" dir="auto">Check out our examples</h2>
<p dir="auto">Check out our <a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples">examples</a>:</p>
<ul dir="auto">
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples/whisper">Whisper</a>: speech recognition model.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples/llama">Llama and Llama-v2</a>: general LLM.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples/falcon">Falcon</a>: general LLM.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples/bert">Bert</a>: useful for sentence embeddings.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples/examples/bigcode">StarCoder</a>: LLM specialized to code
generation.</li>
</ul>
<p dir="auto">Run them using the following commands:</p>
<div data-snippet-clipboard-copy-content="cargo run --example whisper --release
cargo run --example llama --release
cargo run --example falcon --release
cargo run --example bert --release
cargo run --example bigcode --release"><pre><code>cargo run --example whisper --release
cargo run --example llama --release
cargo run --example falcon --release
cargo run --example bert --release
cargo run --example bigcode --release
</code></pre></div>
<p dir="auto">In order to use <strong>CUDA</strong> add <code>--features cuda</code> to the example command line.</p>
<p dir="auto">There are also some wasm examples for whisper and
<a href="https://github.com/karpathy/llama2.c">llama2.c</a>. You can either build them with
<code>trunk</code> or try them online:
<a href="https://huggingface.co/spaces/lmz/candle-whisper" rel="nofollow">whisper</a>,
<a href="https://huggingface.co/spaces/lmz/candle-llama2" rel="nofollow">llama2</a>.</p>
<p dir="auto">For llama2, run the following command to retrieve the weight files and start a
test server:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd candle-wasm-examples/llama2-c
wget https://karpathy.ai/llama2c/model.bin
wget https://github.com/karpathy/llama2.c/raw/master/tokenizer.bin
trunk serve --release --public-url /candle-llama2/ --port 8081"><pre><span>cd</span> candle-wasm-examples/llama2-c
wget https://karpathy.ai/llama2c/model.bin
wget https://github.com/karpathy/llama2.c/raw/master/tokenizer.bin
trunk serve --release --public-url /candle-llama2/ --port 8081</pre></div>
<p dir="auto">And then browse to
<a href="http://localhost:8081/candle-llama2" rel="nofollow">http://localhost:8081/candle-llama2</a>.</p>

<h2 tabindex="-1" dir="auto">Features</h2>
<ul dir="auto">
<li>Simple syntax, looks and like PyTorch.</li>
<li>CPU and Cuda backends, m1, f16, bf16.</li>
<li>Enable serverless (CPU), small and fast deployments</li>
<li>WASM support, run your models in a browser.</li>
<li>Model training.</li>
<li>Distributed computing using NCCL.</li>
<li>Models out of the box: Llama, Whisper, Falcon, StarCoder...</li>
<li>Embed user-defined ops/kernels, such as <a href="https://github.com/LaurentMazare/candle/blob/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152">flash-attention
v2</a>.</li>
</ul>

<h2 tabindex="-1" dir="auto">How to use ?</h2>

<p dir="auto">Cheatsheet:</p>
<table>
<thead>
<tr>
<th></th>
<th>Using PyTorch</th>
<th>Using Candle</th>
</tr>
</thead>
<tbody>
<tr>
<td>Creation</td>
<td><code>torch.Tensor([[1, 2], [3, 4]])</code></td>
<td><code>Tensor::new(&amp;[[1f32, 2.]], [3., 4.]], &amp;Device::Cpu)?</code></td>
</tr>
<tr>
<td>Creation</td>
<td><code>torch.zeros((2, 2))</code></td>
<td><code>Tensor::zeros((2, 2), DType::F32, &amp;Device::Cpu)?</code></td>
</tr>
<tr>
<td>Indexing</td>
<td><code>tensor[:, :4]</code></td>
<td><code>tensor.i((.., ..4))?</code></td>
</tr>
<tr>
<td>Operations</td>
<td><code>tensor.view((2, 2))</code></td>
<td><code>tensor.reshape((2, 2))?</code></td>
</tr>
<tr>
<td>Operations</td>
<td><code>a.matmul(b)</code></td>
<td><code>a.matmul(&amp;b)?</code></td>
</tr>
<tr>
<td>Arithmetic</td>
<td><code>a + b</code></td>
<td><code>&amp;a + &amp;b</code></td>
</tr>
<tr>
<td>Device</td>
<td><code>tensor.to(device="cuda")</code></td>
<td><code>tensor.to_device(&amp;Device::Cuda(0))?</code></td>
</tr>
<tr>
<td>Dtype</td>
<td><code>tensor.to(dtype=torch.float16)</code></td>
<td><code>tensor.to_dtype(&amp;DType::F16)?</code></td>
</tr>
<tr>
<td>Saving</td>
<td><code>torch.save({"A": A}, "model.bin")</code></td>
<td><code>candle::safetensors::save(&amp;HashMap::from([("A", A)]), "model.safetensors")?</code></td>
</tr>
<tr>
<td>Loading</td>
<td><code>weights = torch.load("model.bin")</code></td>
<td><code>candle::safetensors::load("model.safetensors", &amp;device)</code></td>
</tr>
</tbody>
</table>

<h2 tabindex="-1" dir="auto">Structure</h2>
<ul dir="auto">
<li><a href="https://github.com/huggingface/candle/blob/main/candle-core">candle-core</a>: Core ops, devices, and <code>Tensor</code> struct definition</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-nn">candle-nn</a>: Facilities to build real models</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-examples">candle-examples</a>: Real-world like examples on how to use the library in real settings</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-kernels">candle-kernels</a>: CUDA custom kernels</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-datasets">candle-datasets</a>: Datasets and data loaders.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-transformers">candle-transformers</a>: Transformer related utilities.</li>
<li><a href="https://github.com/huggingface/candle/blob/main/candle-flash-attn">candle-flash-attn</a>: Flash attention v2 layer.</li>
</ul>
<h2 tabindex="-1" dir="auto">FAQ</h2>
<h3 tabindex="-1" dir="auto">Why Candle?</h3>
<p dir="auto">Candle stems from the need to reduce binary size in order to <em>enable serverless</em>
possible by making the whole engine smaller than PyTorch very large library volume.
This enables creating runtimes on a cluster much faster.</p>
<p dir="auto">And simply <em>removing Python</em> from production workloads.
Python can really add overhead in more complex workflows and the <a href="https://www.backblaze.com/blog/the-python-gil-past-present-and-future/" rel="nofollow">GIL</a> is a notorious source of headaches.</p>
<p dir="auto">Rust is cool, and a lot of the HF ecosystem already has Rust crates <a href="https://github.com/huggingface/safetensors">safetensors</a> and <a href="https://github.com/huggingface/tokenizers">tokenizers</a>.</p>
<h3 tabindex="-1" dir="auto">Other ML frameworks</h3>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/coreylowman/dfdx">dfdx</a> is a formidable crate, with shapes being included
in types preventing a lot of headaches by getting compiler to complain about shape mismatch right off the bat
However we found that some features still require nightly and writing code can be a bit dauting for non rust experts.</p>
<p dir="auto">We're leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each
other</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/burn-rs/burn">burn</a> is a general crate that can leverage multiple backends so you can choose the best
engine for your workload</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/LaurentMazare/tch-rs.git">tch-rs</a> Bindings to the torch library in Rust. Extremely versatile, but they
do bring in the entire torch library into the runtime. The main contributor of <code>tch-rs</code> is also involved in the development
of <code>candle</code>.</p>
</li>
</ul>
<h3 tabindex="-1" dir="auto">Missing symbols when compiling with the mkl feature.</h3>
<p dir="auto">If you get some missing symbols when compiling binaries/tests using the mkl
features, e.g.:</p>
<div data-snippet-clipboard-copy-content="  = note: /usr/bin/ld: (....o): in function `blas::sgemm':
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_' collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo (see https://doc.rust-lang.org/cargo/reference/build-scripts.html#cargorustc-link-libkindname)"><pre><code>  = note: /usr/bin/ld: (....o): in function `blas::sgemm':
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_' collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn't be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo (see https://doc.rust-lang.org/cargo/reference/build-scripts.html#cargorustc-link-libkindname)
</code></pre></div>
<p dir="auto">This is likely due to some missing linker flag that enable the mkl library. You
can try adding the following at the top of your binary:</p>
<div data-snippet-clipboard-copy-content="extern crate intel_mkl_src;"><pre><code>extern crate intel_mkl_src;
</code></pre></div>
<h3 tabindex="-1" dir="auto">How to know where an error comes from.</h3>
<p dir="auto">You can set <code>RUST_BACKTRACE=1</code> to be provided with backtraces when a candle
error is generated.</p>
</article>
          </div></div>]]></description>
        </item>
    </channel>
</rss>