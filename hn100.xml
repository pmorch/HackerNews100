<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 30 Nov 2024 11:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Engineering Sleep (142 pts)]]></title>
            <link>https://minjunes.ai/posts/sleep/index.html</link>
            <guid>42279454</guid>
            <pubDate>Sat, 30 Nov 2024 04:33:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://minjunes.ai/posts/sleep/index.html">https://minjunes.ai/posts/sleep/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=42279454">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>Engineering Sleep</span></p><p><span>Background</span><span>&nbsp;</span></p><p><span>Sleep claims a third of human life. Like water, it’s not a desire but a necessity. Sleep rules virtually every important system: brain, heart, mood, and immunity. Nature’s terms are harsh. Sleep eight hours or face mental and physical decay. Can we rewrite the terms in our favor? Can we sleep less, but still feel refreshed? I believe we can, and that now is the best time to start engineering sleep.</span></p><p><span>Rare mutations suggest a great variation in sleep efficiency between people</span><span>.</span><span>&nbsp;A small proportion of the population have Familial Natural Short Sleep (FNSS), a benign mutation that allows them to sleep 1-2 hours less than the recommended 7-9 hours, without experiencing the negative effects of sleep deprivation [</span><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">1</a></span><span>]</span><span>. </span></p><p><span>Contrary to symptoms of chronic sleep deprivation, people with FNSS are “healthy, energetic, optimistic, with high pain threshold, and do not seem to suffer adverse effects of chronic restricted sleep” [</span><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">2</a></span><span>]</span><span>. This goes against everything we know about sleep. The most plausible explanation is that people with FNSS are more efficient sleepers. Whichever functions of sleep make it so crucial, they are doing it faster and better.</span></p><p><span>The Sleep Mutation</span></p><p><span>How does FNSS work? Five genes have been implicated in the FNSS phenotype, but DEC2 is the most studied. In 2009, professor Ying-Hui Fu at UCSF discovered a DEC2 point mutation from two individuals in the same family who slept 6.25 hours on average [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. DEC2 codes for a repressive transcription factor (a protein that inhibits the expression of some gene). Normally, the gene that this transcription factor represses is responsible for expressing orexin, a neurotransmitter. In the mutation, proline is replaced by arginine at position 384 in exon 5 (DEC2P384R), disrupting its ability to repress orexin expression. Consequently, more orexin is expressed in individuals with this mutation. The UCSF group hypothesizes that this elevated level of orexin expression partially explains reduced sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">4</a></span><span>]. </span></p><p><span><img alt="image3" src="https://minjunes.ai/posts/sleep/images/image3.jpg" title=""></span></p><p><span>Fig 1. In normal humans, Dec2 weakens E12/Myod1’s binding affinity to the Ebox1 promoter site of prepro-orexin, which is responsible for endogenous orexin synthesis. In FNSS mutants, the DEC2P384R interaction with the E12/Myod1 complex is weaker, and there is greater orexin expression.</span></p><p><span>Two decades of sleep research supports the link between orexin and sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">5</a></span><span>]. In both narcolepsy and insomnia, orexin is the key neurotransmitter that modulates awakeness. A deficit of orexin producing neurons is responsible for excessive sleepiness in narcolepsy [</span><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">6</a></span><span>]. An overexpression of orexin is responsible for hypervigilance in insomnia [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">7</a></span><span>]. Throughout the day and night, we move between the wake-sleep axis defined by orexin levels, which are lowest in the middle of the day and highest during the transition from NREM to REM sleep [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">8</a></span><span>].</span></p><p><span>Orexin is a commercially validated lever for controlling sleep. As of late 2024, there are eight orexin receptor agonists (promotes firing of neuron) in clinical trials for treating narcolepsy and hypersomnia, and two orexin receptor antagonists (inhibits firing of neuron) on the market for treating insomnia. To summarize orexin, too little of it makes you sleepy, and too much of it makes you unable to sleep.</span></p><p><span>But if elevated orexin levels explain reduced sleep in both FNSS carriers and insomniacs, why is one sleep deprived but not the other? We don’t know. Variation in dynamics of when, where, and how much orexin is released could explain the difference. Also, FNSS carriers might have developed compensatory mechanisms to cope with elevated orexin, leading to more efficient sleep. Experiments to reproduce FNSS will give us answers. </span></p><p><span>Reproducing FNSS</span></p><p><span>Given our current knowledge of FNSS, has anyone tried to reproduce it? A true reproduction would be safe and effective over the lifetime of the host, just like we see in the natural phenotype. The closest attempt was by the UCSF group that identified the DEC2P384R mutation. In their pioneering 2009 study, the group embryonically edited human DEC2P384R into transgenic mice and saw a 1-2 hour reduction in sleep. However, we don’t know if it was safe and effective over the lifetime of the mice. They recorded sleep architecture and sleep recovery during a 24-hour window in six to eight month old mice, tracking no other health markers [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">3</a></span><span>]. </span></p><p><span>The study intervened at the embryo level of the host and saw short-term success reproducing FNSS. But what we’re really interested in is adulthood intervention and lifelong efficacy. Giving normal people the ability to sleep more efficiently is the ultimate goal. Expressing the DEC2P384R mutation in normal adult animals and conducting a lifelong study would answer this question. Two possible pathways to reproducing FNSS are reviewed below. </span></p><p><span>Path I: Orexin Agonists</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image2.jpg" title=""></span></p><p><span>Fig 2. Pathway I success case</span></p><p><span>Approach</span></p><p><span>Orally dose orexin receptor agonists. The mechanism leverages direct receptor activation, similar to drugs currently in clinical trials for treating narcolepsy. These small molecules are designed for optimal blood-brain barrier penetration and selective binding to orexin receptors. </span></p><p><span>Unknowns</span></p><p><span>Primarily, we don’t know if elevated orexin levels explain the FNSS phenotype. Also, we don’t know the effects of chronic orexin receptor activation on sleep architecture and cognition. Pharma companies developing orexin agonists have data on short-term sleep effects, but none of them have published data on long term effects [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">9</a></span><span>]. Also unknown are tolerance and withdrawal effects over time: like other receptor agonists (think nicotine), we may see diminishing effects, and withdrawal effects on return to baseline. Finally, variations in individual response are unknown. </span></p><p><span>Path II: Gene Therapy</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image5.jpg" title=""></span></p><p><span>Fig 3. </span><span>Pathway II success case</span></p><p><span>Approach</span></p><p><span>Replicate the natural FNSS mutation through episomal expression. Episomal expression is when the gene is expressed from a piece of DNA that is outside the cell’s chromosomal DNA. Since chromosomal DNA is left alone, there is no risk of passing down the mutation to offspring. For this approach, we use Adeno-Associated Virus serotype 9 (AAV9) vectors to deliver the DEC2P384R gene to orexin-expressing neurons in adult mice. The vectors (the piece of extra chromosomal DNA) remain in the nucleus, continuously synthesizing the mutant DEC2 protein. This aims to partially mirror the mechanism seen in FNSS.</span></p><p><span>Unknowns</span></p><p><span>We are more certain that DEC2P384R explains FNSS, but we don’t know if expressing it in adulthood works. We also don’t know off-target effects on DEC2-regulated pathways beyond sleep. A specific unknown to episomal expression is the competition dynamics between DEC2P384R and native DEC2. The usual unknowns of variations between individual responses, particularly immune response, apply. </span></p><p><span>Overview of Pathways</span></p><p><span><img alt="image1" src="https://minjunes.ai/posts/sleep/images/image1.png" title=""></span></p><p><span>Too good to be true? &nbsp;</span></p><p><span>Around 90 families with FNSS have been identified to date [</span><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">10</a></span><span>]. If FNSS is truly benign, why is it so rare? Shouldn’t more efficient sleep confer a survival advantage? It could be that the mutation really is benign, but does not help reproductive success. But, the mutation could also have negative fitness effects that are not observed.</span></p><p><span><img alt="" src="https://minjunes.ai/posts/sleep/images/image4.jpg" title=""></span></p><p><span>Fig 4. Fisher-Wright simulation showing allele frequency dynamics with 10% fitness penalty across population sizes (N=100, 1,000, 10,000). Initial carrier frequency 1%, tracked for 20 generations over 100 simulations. Solid lines show means; shaded regions show standard deviations.</span></p><p><span>Under the Fisher-Wright model, harmful mutations can appear neutral when tracking small populations across just a few generations. If the mutation has a tiny effective population size, limited generational depth, and low carrier frequency, it would be hard to distinguish between neutral drift and negative selection.</span></p><p><span>Fortunately, there is no risk of the mutation being passed down to offsprings in either the orexin agonist pathway or the gene therapy pathway. So we can rule out the nightmare scenario of offspring effects gone wrong. Instead, the risks are concentrated in medium to long term health of individuals who undergo therapy. As of now, we simply don’t have enough data to profile risk factors. More experiments are needed to know if “FNSS for all” is too good to be true. </span></p><p><span>Where is my better sleep? </span></p><p><span>People with FNSS are living proof that we don’t need 7-9 hours of sleep to be healthy. We already don’t get enough sleep. 34% of Americans are chronically sleep deprived [</span><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">11</a></span><span>]. What if they could keep sleeping less, but with no consequences? That’s possible with advanced sleep engineering. Here’s what else would be possible: falling asleep and waking at will, sleeping 4 hours but feeling like you slept 8 hours, always in perfect mental and physical condition. Considering the huge upside of engineering sleep, an unreasonably small number of experiments have studied FNSS. </span></p><p><span>Due to their relatively singular effect on sleep, FNSS mutations are a gold mine for studying sleep. But, there have been only two attempts to mimic FNSS outside of Fu et al: a study that found better memory consolidation in sleep deprived mice [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">12</a></span><span>], and another that found greater longevity in flies [</span><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">13</a></span><span>]. None have been lifetime studies in mammals, which are most relevant to therapy development. </span></p><p><span>15 years after its pioneering work that identified DEC2P384R, Ying-Hui Fu’s lab is the only group that came close to reverse engineering FNSS. Perhaps this represents what J Storss Halls called a “civilizational failure of nerve”, where institutions become pathologically risk-averse, more focusing on preventing downside risks than enabling upside potential [</span><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">14</a></span><span>]. Scientific and technological progress rests on the willingness to experiment. If existing institution’s won’t give us better sleep, we should build ones that do.</span></p><p><span>Next Steps</span></p><p><span>Contact me if you are interested in: </span></p><ul><li><span>Expanding the known FNSS database, and sequencing everyone in it</span></li><li><span>Testing pathways I and II</span></li><li><span>Funding the above</span></li></ul><p><span>Special thanks to Andy Kong, Ishan Goel, Tazik Shahjahan, and Mae Richardson for valuable feedback. </span></p><p><span>References</span></p><ol start="1"><li><span><a target="_blank" rel="noopener noreferrer" href="https://my.clevelandclinic.org/health/diseases/short-sleeper-syndrome-sss&amp;sa=d&amp;source=editors&amp;ust=1732929030565618&amp;usg=aovvaw0vywxxv5vmhkrvjzmx">Short Sleeper Syndrome</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://journals.lww.com/neurotodayonline/fulltext/2019/12050/a_genetic_mutation_for_short_sleep_prevents_memory.8.aspx">A Genetic Mutation for Short Sleep Prevents Memory Deficits in a Mouse Model</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/19679812/">He Y, Jones CR, Fujiki N, Xu Y, Guo B, Holder JL Jr, Rossner MJ, Nishino S, Fu YH. The transcriptional repressor DEC2 regulates sleep length in mammals. Science. 2009 Aug 14;325(5942):866-70. doi: 10.1126/science.1174443. PMID: 19679812; PMCID: PMC2884988.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/29531056/">Hirano A, Hsu PK, Zhang L, Xing L, McMahon T, Yamazaki M, Ptáček LJ, Fu YH. DEC2 modulates orexin expression and regulates sleep. Proc Natl Acad Sci U S A. 2018 Mar 27;115(13):3434-3439. doi: 10.1073/pnas.1801693115. Epub 2018 Mar 12. PMID: 29531056; PMCID: PMC5879715.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/35851580/">De Luca R, Nardone S, Grace KP, Venner A, Cristofolini M, Bandaru SS, Sohn LT, Kong D, Mochizuki T, Viberti B, Zhu L, Zito A, Scammell TE, Saper CB, Lowell BB, Fuller PM, Arrigoni E. Orexin neurons inhibit sleep to promote arousal. Nat Commun. 2022 Jul 18;13(1):4163. doi: 10.1038/s41467-022-31591-y. PMID: 35851580; PMCID: PMC9293990.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy">https://sleep.hms.harvard.edu/education-training/public-education/sleep-and-health-education-program/sleep-health-education-4#:~:text=Research%20has%20revealed%20that%20narcolepsy,in%20the%20development%20of%20narcolepsy</a></span><span>.</span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37086045/">Muehlan C, Roch C, Vaillant C, Dingemanse J. The orexin story and orexin receptor antagonists for the treatment of insomnia. J Sleep Res. 2023 Dec;32(6):e13902. doi: 10.1111/jsr.13902. Epub 2023 Apr 22. PMID: 37086045.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37686711/">Mogavero, M. P., Godos, J., Grosso, G., Caraci, F., &amp; Ferri, R. (2023). Rethinking the Role of Orexin in the Regulation of REM Sleep and Appetite. Nutrients, 15(17), 3679. https://doi.org/10.3390/nu15173679</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/36108771/">Ishikawa T, Hara H, Kawano A, Kimura H. Danavorexton, a selective orexin 2 receptor agonist, provides a symptomatic improvement in a narcolepsy mouse model. Pharmacol Biochem Behav. 2022 Oct;220:173464. doi: 10.1016/j.pbb.2022.173464. Epub 2022 Sep 13. PMID: 36108771.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516">https://reporter.nih.gov/search/n0rjIH9BFE6TYwe-IE46Gw/project-details/10893516</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx">https://news.gallup.com/poll/642704/americans-sleeping-less-stressed.aspx</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/31619542/">Xing, L., Shi, G., Mostovoy, Y., Gentry, N. W., Fan, Z., McMahon, T. B., Kwok, P. Y., Jones, C. R., Ptáček, L. J., &amp; Fu, Y. H. (2019). Mutant neuropeptide S receptor reduces sleep duration with preserved memory consolidation. Science translational medicine, 11(514), eaax2014. https://doi.org/10.1126/scitranslmed.aax2014</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://pubmed.ncbi.nlm.nih.gov/37163058/">Pandey P, Wall PK, Lopez SR, Dubuisson OS, Zunica ERM, Dantas WS, Kirwan JP, Axelrod CL, Johnson AE. A familial natural short sleep mutation promotes healthy aging and extends lifespan in Drosophila. bioRxiv [Preprint]. 2023 Apr 26:2023.04.25.538137. doi: 10.1101/2023.04.25.538137. PMID: 37163058; PMCID: PMC10168263.</a></span></li><li><span><a target="_blank" rel="noopener noreferrer" href="https://press.stripe.com/where-is-my-flying-car#:~:text=In%20Where%20Is%20My%20Flying,that%20started%20in%20the%201970s.">Hall, J. S. (2021). Where is my flying car? Stripe Press.</a></span></li></ol></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Engagement Is Better on Bluesky (101 pts)]]></title>
            <link>https://bsky.social/about/blog/11-29-2024-engagement</link>
            <guid>42277963</guid>
            <pubDate>Fri, 29 Nov 2024 23:13:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bsky.social/about/blog/11-29-2024-engagement">https://bsky.social/about/blog/11-29-2024-engagement</a>, See on <a href="https://news.ycombinator.com/item?id=42277963">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><header><section><a href="https://bsky.social/about/blog">Blog</a><svg width="8" height="12" viewBox="0 0 8 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 10L6 6L2 2" stroke="#667999" stroke-width="2" stroke-linecap="square"></path></svg><span>The Engagement Is Better on Bluesky</span></section><div><p>November 29, 2024</p><p><span>by <!-- -->The Bluesky Team</span></p></div></header><div><p>We could go on about how we welcome publishers, we don't demote links, we encourage independent developers to build apps and extensions on top of Bluesky's network.... but instead, we'll show you:</p>
<h3>The Boston Globe</h3>
<blockquote data-bluesky-uri="at://did:plc:e6zr6q76g4h7agw4tw6pnu3n/app.bsky.feed.post/3lbunm54agc2k" data-bluesky-cid="bafyreiddcne3ci43tnhmwmwdiihomvqkpliyxslsjshnnwxpryynal7udq"><p lang="en">Traffic from Bluesky to @bostonglobe.com is already 3x that of Threads, and we are seeing 4.5x the conversions to paying digital subscribers.</p>— Matt Karolian (<a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n?ref_src=embed">@mkarolian.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:e6zr6q76g4h7agw4tw6pnu3n/post/3lbunm54agc2k?ref_src=embed">November 26, 2024 at 10:19 AM</a></blockquote>
<h3>The Guardian</h3>
<blockquote data-bluesky-uri="at://did:plc:ayz3ljwsllsn7htnmu4q3zhq/app.bsky.feed.post/3lbvwh42ipk2y" data-bluesky-cid="bafyreihfz7ezs23z7scv4vyy7xi4vacsqan5llft5v4dc56umjhr7w7cfy"><p lang="en">By which I mean, I'm pretty sure traffic from 
@bsky.app to @theguardian.com is *significantly* higher than the very obvious 2x that of Threads
</p><div><p>This post brought to you by a reply to @mkarolian.bsky.social on Threads, where it has had just 105 engagements, as opposed to the 18k+ here</p><p><a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">[image or embed]</a></p></div>— Dave Earley (<a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq?ref_src=embed">@earleyedition.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:ayz3ljwsllsn7htnmu4q3zhq/post/3lbvwh42ipk2y?ref_src=embed">November 26, 2024 at 10:30 PM</a></blockquote>
<h3>The New York Times</h3>
<blockquote data-bluesky-uri="at://did:plc:ty42uz67qbam52si5yduwwaa/app.bsky.feed.post/3lbm65hi7bj2y" data-bluesky-cid="bafyreigjbemi4znbpyw52mdf77qxjlozfv6fzzds5mmn5rnkgprboclyaa"><div lang=""><p>hard to exaggerate how nuts the engagement is on Bluesky compared to 𝕏. a vastly smaller user base (at least officially), but just look at these stats for one of the biggest newspapers on Earth. Musk has absolutely trashed the platform. folks, you are not locked in on 𝕏. not even a little.</p><p><a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">[image or embed]</a></p></div>— Kevin Rothrock (<a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa?ref_src=embed">@kevinrothrock.me</a>) <a href="https://bsky.app/profile/did:plc:ty42uz67qbam52si5yduwwaa/post/3lbm65hi7bj2y?ref_src=embed">November 23, 2024 at 1:21 AM</a></blockquote>
<h3>Open-source Web Dev</h3>
<blockquote data-bluesky-uri="at://did:plc:2gkh62xvzokhlf6li4ol3b3d/app.bsky.feed.post/3lbwwdqztic2s" data-bluesky-cid="bafyreie2rhlpgr4rdrird346s7g77a2txztot2yelri5pcdzgdekzd4wuu"><div lang="en"><p>We have 6% of the followers here compared to the 100k in X. The vite 6.0 announcement in bluesky already got half the reposts and a third of the likes. And most of the comments and quotes from OSS maintainers happened here. I don't know about other communities, but OSS web dev is a bluesky game now.</p><p><a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">[image or embed]</a></p></div>— patak (<a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d?ref_src=embed">@patak.dev</a>) <a href="https://bsky.app/profile/did:plc:2gkh62xvzokhlf6li4ol3b3d/post/3lbwwdqztic2s?ref_src=embed">November 27, 2024 at 8:01 AM</a></blockquote>
<h3>Democracy Docket</h3>
<blockquote data-bluesky-uri="at://did:plc:pjiafkey2cokiupsxpswqlk7/app.bsky.feed.post/3lbwnypsssc2s" data-bluesky-cid="bafyreigqm6acubxf6hykcdxhjscpp5yynlbr5ni6eincnewe5dutubqmfm"><p lang="en">Traffic from Bluesky to @democracydocket.com is surging while X is falling and Threads remains largely irrelevant. This is powering rapid growth of both free subscribers and paid members.</p>— Marc Elias (<a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7?ref_src=embed">@marcelias.bsky.social</a>) <a href="https://bsky.app/profile/did:plc:pjiafkey2cokiupsxpswqlk7/post/3lbwnypsssc2s?ref_src=embed">November 27, 2024 at 5:31 AM</a></blockquote>
<p>Join us: <a href="https://bsky.app/download">bsky.app/download</a>. Publishers, you can find our <a href="https://bsky.social/about/blog/press-faq">press FAQ here</a>.</p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geometric line-art of Wacław Szpakowski (2017) (164 pts)]]></title>
            <link>https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</link>
            <guid>42277850</guid>
            <pubDate>Fri, 29 Nov 2024 22:54:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/">https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/</a>, See on <a href="https://news.ycombinator.com/item?id=42277850">Hacker News</a></p>
Couldn't get https://www.theparisreview.org/blog/2017/02/15/rhythmical-lines/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The Deterioration of Google (199 pts)]]></title>
            <link>https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</link>
            <guid>42277673</guid>
            <pubDate>Fri, 29 Nov 2024 22:26:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.baldurbjarnason.com/2024/the-deterioration-of-google/">https://www.baldurbjarnason.com/2024/the-deterioration-of-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42277673">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="skip">
	



<p><time datetime="2024-11-07">7 November 2024</time> – <em>Baldur
		Bjarnason</em></p>
<ul>
		<li><a href="https://www.baldurbjarnason.com/tags/google/">google</a></li>
</ul>








<p>This post announcing the closure of Giant Freakin Robot set me on a bit of a journey into the state of Google.</p>
<p><a href="https://www.giantfreakinrobot.com/ent/independent-ends.html">“The End Of Independent Publishing And Giant Freakin Robot”</a></p>
<blockquote>
<p>GIANT FREAKIN ROBOT isn’t the first site to shut down. Hundreds of independent publishers have shuttered in the last two years, and thousands more are on the way. I’m in communication with dozens of other independents focused on different topics. None of them are doing well. They all expect to be out of business soon.</p>
<p>I went to Google directly, on their behalf, and told them about the problem. The message I walked away with, was that they do not care. Our industry is done.</p>
</blockquote>
<p>What I discovered was that web media companies can’t count on any of the traffic coming from Google or Facebook any more. Very few, even one that are frugally run, are capable of surviving on the traffic that remains.</p>
<p>The problem doesn’t seem limited to a few sites. What seems to have happened is that Google tried to “fix” their search engine results by using machine learning to rank sites.</p>
<p>From <a href="https://www.mariehaynes.com/what-we-can-learn-from-the-google-creators-summit-for-hcu-impacted-sites/"><em>What we can learn from the Google creators summit for HCU impacted sites</em></a>:</p>
<blockquote>
<p>We know that the helpful content system was a machine learning (AI) system.  Machine learning systems are trained by seeing good examples and bad examples. They then work to figure out the characteristics they can consider and how much weight to give them so as to predict whether an unseen example is a good one or a bad one.</p>
</blockquote>
<p>But this does not seem to be working properly. Anybody who has used Google for search over the past year knows that it lets a lot of LLM-generated spam through and blogs and small sites have basically disappeared from most results. Those sites have effectively been delisted by the machine learning model and nobody seems to know exactly why.</p>
<p>Some have been hit hard. From <a href="https://mike-hardaker.com/f/i-drank-the-kool-aid-at-the-2024-google-web-creator-summit/">“I Drank the Kool-Aid at the 2024 Google Web Creator Summit”</a>:</p>
<blockquote>
<p>I’m 44 years old, luckily I don’t have a mortgage, I barely getting by, I’m eating at the food bank now, I had grossed $250,000 last year and I just don’t know where to go from here my traffic is down 97%</p>
</blockquote>
<p>Even if your first reaction might be “good riddance” these are all people whose work Google <em>wants</em> to see in the search engine results. That’s why they were invited to the summit.</p>
<p>An exchange on Twitter, which I usually avoid but is where this crowd seems to still be congregating, describing a scene from the summit <a href="https://x.com/CharlestonCraft/status/1851643761375277103">captured the situation perfectly</a>:</p>
<blockquote>
<p>Lily Ray: I’m still stuck on “your content wasn’t the issue.” What?</p>
<p>Morgan: So, so many times they said this. Literally Danny hand picked us because we all create helpful and satisfying content. They just cannot get the algorithm to understand that. They are actively doing query debugging based on examples sent by our group.</p>
<p>Morgan: Literally Danny said he sat with an engineer team with examples of people in the room and said why aren’t they showing up and they did their “debugging process” and couldn’t figure it out.</p>
<p>Morgan: the robots are winning.</p>
</blockquote>
<p>The “algorithm” seems to have become a black box even Google engineers can’t figure out</p>
<p>The fact that over a year ago ML experts at Google (El-Mahdi El-Mhamdi at least, if I recall correctly) who have since left warned that LLMs should be avoided because they made products chaotic and hard to control seems relevant.</p>
<p>As is the fact that around the same time others also warned that one common consequence of mass layoffs is they tend to turn internal systems into black boxes because everybody with a deep understanding of them has left.</p>
<p>But, fundamentally, what lets this deterioration continue is that it does not affect business outcomes at Google in any way. They are a monopoly and monopolies are extremely effective at capturing whatever value happens in their vicinity, even if the utility of their products declines.</p>
<p>And, given the political situation in the US, the tech industry monopolies and oligopolies are only going to be strengthened and the actual productivity, performance, and effectiveness of their products will be less and less important to them.</p>
<p>Because they know that most of us will not have any real alternative.</p>

		<ul>
				<li>
					
				</li><li>
				
				</li>
		</ul>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brits are scrolling away from X and aren't that interested in AI (129 pts)]]></title>
            <link>https://www.theregister.com/2024/11/29/ofcom_online_nation/</link>
            <guid>42277089</guid>
            <pubDate>Fri, 29 Nov 2024 21:03:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2024/11/29/ofcom_online_nation/">https://www.theregister.com/2024/11/29/ofcom_online_nation/</a>, See on <a href="https://news.ycombinator.com/item?id=42277089">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>Usage of Elon Musk's X social media platform is declining in the UK, and adult Brits aren't particularly interested in generative AI tools.</p>
<p>That's according to Ofcom's <a target="_blank" rel="nofollow" href="https://www.ofcom.org.uk/media-use-and-attitudes/online-habits/online-nation/">Online Nation</a> report, an annual publication looking at what UK citizens do during their hours online and how much time they spend glued to gadgets.</p>
<p>According to the comms regulator, adults spent an average of four hours 20 minutes a day online in May 2024 across tablets, smartphones, and computers.</p>

    

<p>The report also shows that the total UK adult reach in a month of X (formerly Twitter) continues to decline. For May 2022, Ofcom measured X's adult reach at 26.8 million. In 2023, it was 24 million. By May 2024, it had fallen to 22.1 million, a year-on-year decline of 8 percent.</p>

        


        

<p>X suffered the most significant fall in total adult use of all social media sites, which also resulted in it sliding down the rankings to sixth, behind Reddit, which registered the largest year-on-year growth – 47 percent – taking May's figure to 22.9 million.</p>
<p><a target="_blank" rel="nofollow" href="https://www.theregister.com/2024/11/20/x_marks_the_spot_for/">Several changes</a> have been made at X in recent months, but the platform has continued on a downward trajectory in Britain and Northern Ireland.</p>

        

<p>Ofcom's figures align with other research on X. While still hugely popular, the service has been shedding users over the last two years. UK-based <a target="_blank" rel="nofollow" href="https://soax.com/research/twitter-active-users">SOAX reported</a> an 8.83 percent decrease in monthly active users since 2022 and 5.14 percent since 2023. This is despite global growth in social media users, according to <a target="_blank" rel="nofollow" href="https://www.statista.com/statistics/278414/number-of-worldwide-social-network-users/">Statista</a>.</p>
<p>The decline co-incides with a change of ownership after Musk bought the business for <a target="_blank" href="https://www.theregister.com/2022/10/27/musk_sink_twitter/">$44 billion in October 2022</a>, and it became a doyen of free speech - whether that includes more hateful or more honest content depends on the users' perspective.</p>
<h3>AI – huh – what is good for? Perhaps a bit of searching?</h3>
<p>Ofcom also found that Google's search engine dominance in the UK also slipped slightly over the year, with 83 percent of online adults visiting in May 2024 compared to 86 percent the year before. Microsoft's Bing fell further, down to 39 percent from 46 percent.</p>
<p>Microsoft and Google have invested heavily in AI, with generative AI content turning up in the search results from their respective services. However, ChatGPT remains the most popular GenAI tool. Microsoft's Copilot came second, with 15 percent of UK internet users aged 16 and over having used it. Despite being only recently introduced, Google's Gemini was ranked fourth, with 10 percent of users.</p>
<ul>

<li><a href="https://www.theregister.com/2024/11/21/online_safety_act/">Now Online Safety Act is law, UK has 'priorities' – but still won't explain 'spy clause'</a></li>

<li><a href="https://www.theregister.com/2024/11/13/ofcom_mmwave_spectrum_auction/">Brit telcos to clash in high-speed mmWave spectrum showdown next year</a></li>

<li><a href="https://www.theregister.com/2024/11/12/cma_vodafone_three_remedies/">Watchdog reluctantly blesses Vodafone-Three merger – with strings attached</a></li>

<li><a href="https://www.theregister.com/2024/11/11/australia_social_media_ban/">Australia tells tots: No TikTok till you're 16... or X, Instagram and Facebook</a></li>
</ul>
<p>The figures also show sluggish AI adoption. More than half of adults in the survey had yet to use GenAI, with 38 percent declaring they were "not interested" and 35 percent saying they "did not need to."</p>
<p>Forty-eight percent of adults had used the technology, but only "for fun." Forty-three percent had used one for work, and the most popular activity was finding content. However, less than one in five (18 percent) trusted the output.</p>
<p>The numbers are slightly different for the under-16s. Fifty-four percent said they had used a GenAI tool, with more than half (53 percent) of those saying they had used it for schoolwork. Sixty-three percent reported using a GenAI tool "for fun."</p>

        

<p>The distribution across age groups shows that AI is making more significant inroads into younger demographics than older. However, it appears that investors may have to wait a little longer before AI bets start paying off. ®</p>                                
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Breaking the 4Chan CAPTCHA (367 pts)]]></title>
            <link>https://www.nullpt.rs/breaking-the-4chan-captcha</link>
            <guid>42276865</guid>
            <pubDate>Fri, 29 Nov 2024 20:32:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nullpt.rs/breaking-the-4chan-captcha">https://www.nullpt.rs/breaking-the-4chan-captcha</a>, See on <a href="https://news.ycombinator.com/item?id=42276865">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>Breaking the 4Chan CAPTCHA</span></p><h2 id="introduction">Introduction</h2>
<p>This project was entered into as a learning experience, to enhance my knowledge of machine learning, as well as TensorFlow specifically. At the end, I wanted to have a trained machine learning model that runs in the browser to reliably (at least 80% accuracy, &gt;90% preferred) solve the 4Chan CAPTCHA. These goals were achieved - let's talk about how I got there!</p>
<p>If you'd like to follow along with the code references, I have made the code public on GitHub <a href="https://github.com/AppleDash/4chan-captcha-playground">here</a>.</p>
<h2 id="terminology">Terminology</h2>
<ul>
<li><strong>CAPTCHA</strong>: A challenge-response test to determine whether or not a computer or website user is a human. The acronym stands for Completely Automated Public Turing test to tell Computers and Humans Apart.</li>
<li><strong>4Chan</strong>: A public, anonymous imageboard website with discussion boards on various topics. These boards are used for posting images and text discussions. Filling out a CAPTCHA is required before every post or reply.</li>
<li><strong>Normal CAPTCHA</strong>: The simplest form of the 4Chan CAPTCHA, that consists of an image with 5 or 6 alphanumeric characters. The user must read and correctly enter all of the characters in a field in order to make a post on 4Chan.</li>
<li><strong>Slider CAPTCHA</strong>: A more complex form of the 4Chan CAPTCHA, that consists of a background image with random-looking character fragments, and a foreground image with transparent "holes" or "windows" in it. A slider in the browser CAPTCHA form must be moved to correctly align the two images in order to see the CAPTCHA text.</li>
</ul>
<h2 id="getting-the-data">Getting the Data</h2>
<p>I've heard many times that the hardest part of any machine learning problem is getting the data to train your model. This assertion was definitely pertinent here, for several reasons. There's two parts to this problem: Getting the CAPTCHAs, and getting solutions to those CAPTCHAs.</p>
<h3 id="scraping-captchas-from-4chan">Scraping CAPTCHAs from 4Chan</h3>
<p>After looking at the HTTP requests in the browser console when requesting a new CAPTCHA, I found that it makes a request to <code>https://sys.4chan.org/captcha?framed=1&amp;board={board}</code>, where <code>{board}</code> is the name of the board we're trying to post on. The response is an HTML document that contains a script tag with a <code>window.parent.postMessage()</code> call with some JSON. On a hunch, I tried to remove the <code>framed=1</code> parameter, and found that this causes it to just spit out the raw JSON. That should be easier to work with. The JSON looks like this:</p>
<pre><code><span>{</span>
    <span>"challenge"</span><span>:</span> <span>"[some long and random string here]"</span><span>,</span>
    <span>"ttl"</span><span>:</span> <span>120</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>5</span><span>,</span>
    <span>"img"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"img_width"</span><span>:</span> <span>300</span><span>,</span>
    <span>"img_height"</span><span>:</span> <span>80</span><span>,</span>
    <span>"bg"</span><span>:</span> <span>"[a base64 string here]"</span><span>,</span>
    <span>"bg_width"</span><span>:</span> <span>349</span>
<span>}</span>
</code></pre>
<p>Some of these keys are pretty obvious. <code>ttl</code> and <code>cd</code> are the least obvious to me. I know from experience that the 4Chan CAPTCHA only displays for about 2 minutes before it expires and you have to request a new one, so that's what <code>ttl</code> must be. But what about <code>cd</code>? Let's make another request, shortly after the first one:</p>
<pre><code><span>{</span>
    <span>"error"</span><span>:</span> <span>"You have to wait a while before doing this again"</span><span>,</span>
    <span>"cd"</span><span>:</span> <span>23</span>
<span>}</span>
</code></pre>
<p>If I keep making the same request, the <code>cd</code> parameter steadily decreases, at a rate of about 1 per second. Alright, so this is how long you have to wait before requesting a new CAPTCHA. <code>cd</code> likely stands for "cooldown".</p>
<p>If I wait the 23 seconds, and then make another request, I get a successful response, but this time, the <code>cd</code> is 32. We have to wait longer every time. After some experimentation with a script, it looks like the first few requests can be made every 5 seconds, then it increments to 8, and then continues to roughly double until it's capped at 280 seconds, and stays there.</p>
<p>Additionally, once you've hit the 280 second timers, the CAPTCHA gets somewhat harder. It looks like this:</p>
<figure><img alt="Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-hard.png&amp;w=3840&amp;q=75"><figcaption>Difficult 4Chan CAPTCHA with several horizontal lines and an oval obscuring the text, in addition to general noise all over the image</figcaption></figure>
<p>instead of this:</p>
<figure><img alt="Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-easy.png&amp;w=3840&amp;q=75"><figcaption>Easier 4Chan CAPTCHA with one curved line over the text, in addition to general noise all over the image</figcaption></figure>
<p>So, there's some throttling in place. The data also gets of lower (but still usable) quality if you make too many requests.</p>
<p>Something I will briefly touch on is that the user has to pass a Cloudflare Turnstile challenge to even request a CAPTCHA in the first place. As a result, simply using many proxies with a naive script is not realistic, without first passing the Cloudflare Turnstile and saving the relevant cookies. When I was scraping CAPTCHAs with the script I wrote for this, I simply copied the Cloudflare cookies from my browser, and manually replaced them whenever they expired.</p>
<p>I scraped several hundred CAPTCHAs in this manner - not enough to train the model, but it's at least a start. This still leaves us with a problem, though. We have all these CAPTCHAs, but we don't have the solutions. I could fill them out manually, but instead, let's try something else.</p>
<h3 id="getting-the-solutions">Getting the Solutions</h3>
<p>Or, <em>Humans are bad at solving the 4Chan CAPTCHA</em>.</p>
<p>A recurring theme in this project has been "this is easy for a computer to do, but hard for a human to do." Many users find the "slider" style CAPTCHAs incredibly frustrating, but I've had a 100% success rate in aligning them with the heuristic script I made (<code>trainer/captcha_aligner.py</code>). The 4Chan CAPTCHAs in general are widely considered by users of the site to be frustrating to solve. But, surely, for people who solve CAPTCHAs <em>for a living</em>, it shouldn't be an insurmountable challenge, right?</p>
<p>I coded a quick script (seen in the project under <code>trainer/labeler.py</code>) to send the CAPTCHAs to <a href="https://anti-captcha.com/">a commercial CAPTCHA solving service</a>, where real humans would solve the CAPTCHAs for me for a nominal fee. Writing the script was simple, but actually employing it was an exercise in frustration. I sent a couple dozen CAPTCHAs to the service, and nearly all of them came back with one or more characters incorrectly solved.</p>
<p>The service has a feature called "100% Recognition", which allowed me to specify that all my requests be first sent to <code>n</code> workers, and if <code>x</code> of those workers don't return the same solution, then send them to up to <code>y</code> more workers. It would only return an error after sending the CAPTCHAs to <code>n + y</code> workers and not getting at least <code>x</code> solutions the same. I configured my account with the values <code>n = 2</code>, <code>x = 2</code>, and <code>y = 3</code> - that is, initially send the CAPTCHA to 2 workers, and if they don't both agree, then send them to up to 3 additional workers until two of them agree, or none of them agree.</p>
<p>This improved the situation somewhat. About 80% of the CAPTCHAs were now being successfully solved, and after reviewing the results, 90% of those were correct, but about 10% had errors in them, which indicated that multiple workers were making the same mistakes. This was still less than ideal.</p>
<p><strong>A quick aside: What if I just ask someone I know to be reliable to do it for me, or even do it myself?</strong> I explored both of these approaches. I wrote a quick user script that saved the CAPTCHA image and the solution text, and just sat there requesting and solving CAPTCHAs in my free time. I also asked a good friend of mine to do the same. This yielded several hundred images, which I did add to the training set, but in the end this approach was abandoned because we still ran into the throttling problem, and the problem of the CAPTCHAs getting harder (and eventually, near-impossible) if you request too many of them.</p>
<p>I begun to wonder if there was a different way to look at this altogether. What if we didn't need to scrape CAPTCHAs and have them solved by humans?</p>
<h3 id="generating-synthetic-data">Generating Synthetic Data</h3>
<p>What if we could generate our own 4Chan CAPTCHAs? 4Chan, and the CAPTCHA it uses, are not open source, so I couldn't literally run the same code locally. But I could definitely approximate it.</p>
<p>The 4Chan CAPTCHA can be dissected into two main parts. The background, which looks like this:</p>
<figure><img alt="4Chan CAPTCHA background with the characters removed, leaving only general noise over the image" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-background.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA background with the characters removed, leaving only general noise over the image</figcaption></figure>
<p>and the characters, which look like this:</p>
<figure><img alt="4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-letters.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA character set, the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y with general noise and distortion</figcaption></figure>
<p>We don't need to generate our own backgrounds from scratch. It's a relatively simple computer vision problem to take an image like the 4Chan CAPTCHA, and find all of the large <a href="https://docs.opencv.org/3.4/d4/d73/tutorial_py_contours_begin.html">contours</a> in the image, which represent the characters, and remove them. This leaves only the noisy background, as seen in the image above, which was generated using this algorithm.</p>
<p>Next, we need to isolate a decent number of characters, and label them with their values. If this was trivial to do with an algorithmic script, well, we wouldn't be here, because solving the CAPTCHA would also be trivial to do with an algorithmic script :) It's pretty easy to do this by hand, though, and that's what I settled on doing. It was annoying. I tagged the characters with <a href="https://github.com/microsoft/VoTT">VoTT</a> and then extracted them with a quick and dirty script, which also postprocessed them to make sure it was only the characters in the images. I ended up with 50-150 isolated images of each character. It was during this stage of the project that I realized the 4Chan CAPTCHA incoudes only the characters 0, 2, 4, A, D, G, H, K, M, N, P, S, X, and Y - likely done to avoid ambiguity.</p>
<p>Now we just have to put it all together. When extracting the digits, I observed a few patterns in how the characters are usually clustered or spread apart, and so I wrote my script to assemble images with backgrounds according to these formulas. And, of course, since the input character images are labelled, I can easily label the generated synthetic CAPTCHAs with their solutions.</p>
<h2 id="creating-the-model">Creating the Model</h2>
<p>Now we've got the data, it's time to train the model. I assembled a model architecture based on some research, after reading several different articles on CAPTCHA solving using neural networks.
I settled on an <abbr title="Long Short-Term Memory">LSTM</abbr> <abbr title="Convolutional Neural Network">CNN</abbr> architecture with 3 convolutional/max-pooling layers and 2 LSTM layers.
A fourth convolutional layer was also tested, but it did not improve performance.
CTC encoding of the CAPTCHA text was used, because the output was of variable length (either 5 or 6 characters).
I built the model using <a href="https://keras.io/">Keras</a> on top of <a href="https://www.tensorflow.org/">TensorFlow</a>.</p>
<h3 id="processing-the-data">Processing the data</h3>
<p>The input to the model was a mix of pre-aligned slider CAPTCHAs, normal CAPTCHAs, and synthetic CAPTCHAs.
The training script took care of ensuring they were 300x80 pixels and converted to pure black-and-white.</p>
<h4 id="always-read-the-docs">Always read the docs</h4>
<p><em>The arguments might not be in the order you expect.</em></p>
<p>One of the important steps in my data processing pipeline was making sure that all the CAPTCHA images are exactly 300x80 pixels.
Some images from the dataset, namely the older aligned "slider" CAPTCHAs, don't match this resolution / aspect ratio.
I could just fix the training data, but it's better in the end to make the training script able to cope with any data I throw at it.</p>
<p>I used <code>tf.image.resize()</code> for this. <a href="https://www.tensorflow.org/api_docs/python/tf/image/resize">The docs</a> on this are pretty simple,
for my use case I just need to pass the input image tensor, and the size, which is probably just a tuple of <code>(width, height)</code>, right?
Well, I made that assumption, and the code ran fine, so I didn't really give it a second thought.</p>
<p>Until... My model's performance was absolutely abysmal! Even after training for 32+ epochs,
the model barely performed at all on images it had seen before, and it really couldn't make anything at all of brand new CAPTCHA images,
yielding seemingly random predictions. What the heck was going on?</p>
<p>I decided to actually visualize the images I was feeding into the model, and see what they looked like
- maybe my black/white thresholding was going wrong?
I took a random image from the input data after processing, and visualized it, and I got... this:</p>
<figure><img alt="4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-sideways.png&amp;w=3840&amp;q=75"><figcaption>4Chan CAPTCHA that is vertically stretched to 80x300 pixels and completely unreadable</figcaption></figure>
<p>Yeah, you probably saw that coming as soon as I said "probably just a tuple of <code>(width, height)</code>". Turns out it's not. It is, in fact, a tuple of <code>(height, width)</code>! Had I taken the time to read the whole documentation page, I would have found this near the bottom of the page, where it provides more detail on the expected argument. This is definitely a lesson learned - read the documentation thoroughly when working with libraries you're unfamiliar with, even if you think you know how it works, and especially if things aren't working how you'd expect.</p>
<p>After fixing this bug, the training performance looked a lot more promising.</p>
<h3 id="training-the-model">Training the model</h3>
<p>The final dataset consisted of approximately 500 hand-solved images, and approximately 50,000 synthetically-generated images.
The synthetic images were generated based on random samples from approximately 2,500 background images and 50-150 images of each character.
This dataset was randomly shuffled, and then segmented 90/10 into training and evaluation sets.
Training took approximately 45 seconds per epoch on my NVIDIA RTX A4000 Laptop GPU.</p>
<p>At the end of the first epoch, the loss did not look very promising - it's still all the way up at 19. During the evaluation callback phase, predictions were nowhere near correct, yielding only 1-2 predicted characters that didn't match any of the characters in the image. This is to be expected during the early stages of training.</p>
<p>Later epochs greatly improved performance. By the end of the fourth epoch, loss decreased to 0.55, and the predictions were already looking good, with 5/5 of the random test predictions at this stage yielding correct results. Loss steadily decreased throughout the rest of the training epochs.</p>
<p>After experimenting with different numbers of epochs, 8-16 epochs was found to be a good trade-off between time and final model performance.
Loss stabilized by the 8th epoch, and increasing the epoch count beyond 16 yielded greatly diminishing returns.</p>
<figure><img alt="Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2F4chan-captcha-loss.png&amp;w=3840&amp;q=75"><figcaption>Graph of model loss versus epochs, showing initial large decrease followed by steady decline and levelling out</figcaption></figure>
<p>I wrote a quick test script (<code>trainer/infer.py</code>) to infer CAPTCHA solutions in Python. Results were promising on images the model had not seen before, yielding correct solutions in the limited number of test cases I tried.</p>
<h2 id="using-the-model-in-tensorflowjs">Using the Model in TensorFlow.js</h2>
<p>Writing the <a href="https://www.tensorflow.org/js">TensorFlow.js</a> code for the user script was quite straightforward. I chose TypeScript for this task. I re-implemented the CAPTCHA alignment algorithm from the Python code, as well as the image preprocessing code. All of this code is located in the <code>user-scripts/</code> directory in the repository.</p>
<p>The Python TensorFlow/Keras model formats aren't compatible with the model format expected by TensorFlow.js. There's an <a href="https://www.tensorflow.org/js/guide/conversion">official conversion script</a>, with instructions on how to use it. This should be easy, right?</p>
<h3 id="the-converter-doesnt-work-on-python-312">The converter doesn't work on Python 3.12</h3>
<p>This was a pretty simple problem that took awhile to figure out. The official TensorFlow-to-TFJS model converter doesn't work on Python 3.12. This doesn't seem to really be documented, and the error messages thrown when you try to use it on Python 3.12 are non-obvious. I tried an older version of Python (3.10) on a hunch, using PyEnv, and it worked like a charm.</p>
<h3 id="tensorflowjs-doesnt-support-keras-3">TensorFlow.js doesn't support Keras 3</h3>
<p>New problem: The conversion script supports converting Keras 3 models to TensorFlow.js format. The only problem? TensorFlow.js doesn't support actually reading those converted models. I found this out from a <a href="https://discuss.ai.google.dev/t/corrupted-configuration-and-batch-input-shape-loading-pre-trained-layers-model-in-tensorflow-js/24454">forum post</a>, after I spent a bit of time puzzling out why TFJS wouldn't read the model that the official conversion script output.</p>
<p>Luckily, the solution was easy: Use Keras 2. We can do this by training the model with the environment variable <code>TF_USE_LEGACY_KERAS=1</code> set, after installing the legacy <code>tf_keras</code> package. This may require some code changes. In my case, I only had to trivially modify one line. We also have to export the model using the legacy <code>.h5</code> model format, and specify that as the input format when running the conversion script.</p>
<h2 id="real-world-performance">Real-World Performance</h2>
<p>We've seen the performance on the training dataset, which consists mainly of synthetic images. But it doesn't matter if it can solve synthetic CAPTCHAs - we care about solving the real ones.</p>
<p>Good news: It works great on the real 4Chan CAPTCHA. Solving is fast, taking about 1 second to load the model the first time, and then being imperceptibly quick on subsequent executions. In my experience over hundreds of real CAPTCHAs solved in the browser, the model exhibits a greater than 90% successful solve rate. It rarely gets characters wrong - when it is innacurate, it typically omits a single character entirely. I believe this could be improved with greater training on actual data, or possibly tweaking the CAPTCHA layouts in the synthetic dataset generator.</p>
<figure><img alt="Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script." loading="lazy" width="100" height="100" decoding="async" data-nimg="1" sizes="100vw" srcset="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=640&amp;q=75 640w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=750&amp;q=75 750w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=828&amp;q=75 828w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1080&amp;q=75 1080w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1200&amp;q=75 1200w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=1920&amp;q=75 1920w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=2048&amp;q=75 2048w, https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75 3840w" src="https://www.nullpt.rs/_next/image?url=%2Fposts%2Fbreaking-the-4chan-captcha%2Fdemo.gif&amp;w=3840&amp;q=75"><figcaption>Animation of requesting a CAPTCHA in the 4Chan post form, and it being automatically solved by the user script.</figcaption></figure>
<p>Small fun fact: This model has far better accuracy than the human-powered CAPTCHA solving service I described above.</p>
<h3 id="4-character-captchas">4-character CAPTCHAs</h3>
<p>While I was writing and editing this article after completing the project,
I noticed that 4Chan begun sometimes serving CAPTCHAs with only 4 characters, rather than the usual 5 and 6-character CAPTCHAs.
Despite this model only having been trained on 5 and 6-character CAPTCHAs,
performance on the 4-character CAPTCHAs is the same as for the 5 and 6-character CAPTCHAs.</p>
<h2 id="conclusion">Conclusion</h2>
<p>I enjoyed this project a lot. It had a few challenges to overcome, and I learned a ton about machine learning and computer vision in the process. There are surely improvements that can be made, but for now, I'm pleased with the results, because I achieved what I set out to do from the start.</p>
<p>I hope you enjoyed reading this write-up as much as I enjoyed writing it, and I hope you learned something too!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What does this button do? – My new car has a mysterious and undocumented switch (388 pts)]]></title>
            <link>https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</link>
            <guid>42276620</guid>
            <pubDate>Fri, 29 Nov 2024 19:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr">https://blog.koenvh.nl/what-does-this-button-do-cm42u2oi7000a09l42f54g2pr</a>, See on <a href="https://news.ycombinator.com/item?id=42276620">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><h2>My new car has a mysterious and undocumented switch</h2></p></div><div id="post-content-parent"><p>Last week I bought a car. After twelve years of service, my old trusty Peugeot 107 in blue has had its best. Expensive repairs were coming <em>at some point</em>, and I did not feel like waiting around for them to come. Plus the existing list of faults (like the high oil usage of about a litre per month, a brake that sometimes blocked without reason, or the smell of exhaust fumes that sometimes came into the car when the fan was on high) also started getting longer and longer.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732888980123/91643929-8f55-468a-8568-97d1a64862da.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Anyway, new car time! After a lot of research I ended up with an Opel Corsa from 2020. To be precise, it’s an Opel Corsa Edition with 101 HP, and most importantly, it’s mine.</p>
<p>Unlike the Peugeot, the Opel has gadgets - quite a few of them. Of course it being my car, I want to know what all buttons do, so I read the entire manual (which is very annoying to read, as they make one manual for every version of the car, so half of it does not apply to this car, but I digress). One of those buttons was the following below the lighting controls.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889068247/f39bda1d-77c1-4186-862b-c566cce517bb.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Those do not appear in the manual, or the website, or anywhere. What could they be? Just flipping the switch does nothing, apart from turning off the light on the switch. So let’s look where the button goes. I can see that part of it is wired to the back of the OBD2 port (a port that retrieves data from the onboard computer about the car, such as pedal position, temperature, lights, rev count, speed - basically if you can see it on your dashboard it can be read using the OBD2 port), so it is getting information from the car, but apart from that the wires go to places that I can’t see without taking the car further apart.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889143592/00372c30-63b8-4807-9ae3-4b15727304e5.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>Something else that I noticed before is that I heard the typical inference noise coming from that area of the car when putting the ignition on. You know, <a target="_blank" href="https://youtu.be/FYjs7vsaSEw">this</a> sound. <em>Ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, ti-ti ta, TAAAAAAAAAAA</em>. That gave me the ominous feeling there might be something sending data in there. Sure, my car does that too so I can see in the app where I parked it (seriously, it does that), but at least I gave permission for that.</p>
<p>I asked the wisdom of the crowd. A lot of ideas came up: nitrous (would have been fun), LPG switch (it’s only petrol), flame kit (I wish), front parking sensors (those are standard on the car). No avail.</p>
<p>I called my dealership and asked. They guessed it might have been an immobiliser - bit strange on a car this young and type, and also strange for it to be a switch like this. I called the dealership that previously maintained the vehicle based on the phone number in the service history. They did not install it, and guessed it might be a black box. They did tell me who it previously belonged to (a large company), so I called their headquarters. They told me they don’t do their own cars any more, but that they outsourced it, and gave me a phone number. I called them, they told me they don’t do that, but he speculated it might be a GPS tracker.</p>
<p>Some more searching, and I figured I would just drive to my dealership. More speculating with the salespeople, who told me to make an appointment with the mechanics. I did, they had a quick look at it and I now have an answer:</p>
<p>The metal part is something to hold a magnet next to. It registers who's driving to a fleet tracker via a device also mounted in the car, which sends it to a fleet manager via the internet. That way it can be tracked which employee did what (and potentially who to send the fine to). That would also explain the mobile phone interference noises I've heard from that area of the car. So it’s a black box, a GPS tracker, and maybe also an immobiliser? I am not sure about the last one (and why it has a switch).</p>
<p>I'm getting it removed because now I'm basically driving around with a foreign GPS tracker. Some lease company somewhere is getting data on wherever I go. Kind of spooky if you think of it, especially as I assume I am one of the few actually looking into what this is. Most people would have probably driven around for years with a foreign GPS tracker.</p>
<p><img data-zoomable="true" loading="lazy" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1732889803408/1353bcc6-c25c-482b-9a75-67686582c479.jpeg?auto=compress,format&amp;format=webp" alt=""></p>
<p>And that’s how the search comes to an end. After a bit of perseverance I figured out what it is. I now know my car is being tracked still, and that they know I did try out what the car’s acceleration is like at full throttle.</p>
<p>There are more interesting angles to this, like “can I request my data from the fleet manager thing that has been tracking my whereabouts under the GDPR?”, and “can I get free data from the SIM card embedded in the device that I now technically own?” but I will leave those for another day.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US house prices in 1950 vs. 2024, accounting for inflation (130 pts)]]></title>
            <link>https://brilliantmaps.com/us-houses-prices-1950-2024/</link>
            <guid>42276155</guid>
            <pubDate>Fri, 29 Nov 2024 19:03:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brilliantmaps.com/us-houses-prices-1950-2024/">https://brilliantmaps.com/us-houses-prices-1950-2024/</a>, See on <a href="https://news.ycombinator.com/item?id=42276155">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="text">
			<p><img decoding="async" src="https://brilliantmaps.com/wp-content/uploads/1950-vs-2024.png" alt="How Much US Houses Cost In 1950 vs How Much The Cost In 2024" width="1640" height="647" srcset="https://brilliantmaps.com/wp-content/uploads/1950-vs-2024.png 1640w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-300x118.png 300w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-1024x404.png 1024w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-768x303.png 768w, https://brilliantmaps.com/wp-content/uploads/1950-vs-2024-1536x606.png 1536w" sizes="(max-width: 1640px) 100vw, 1640px"></p>
<p>The map above shows how much houses cost in 1950 in each US state in 2024 inflation adjusted US dollars, compared to what the average cost actually is in 2024.  </p>
<p>In every single US state the increase was at at least double the rate of inflation from a low in Ohio of just 107% above inflation to a high in <a href="https://brilliantmaps.com/us-maps/alaska-map/" data-internallinksmanager029f6b8e52c="99" title="Map of Alaska The Government Doesn’t Want You To See">Alaska</a> of 675% above inflation. </p>
<p>The following map shows the percentage increase above inflation:</p>

<p><img decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation.png" alt="House price increases above inflation 1950-2024" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-increase-1950-2024-above-inflation-1536x1212.png 1536w" sizes="(max-width: 1640px) 100vw, 1640px"></p>
<p>And here are 3 maps showing Median Home Value in 1950 (in non-inflation adjusted terms), and bigger versions of the two maps at the top.</p>
<p>Finally, you can see all the data at the bottom:</p>
<h2>Median home value by state in 1950 in non-inflation adjusted dollars</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars.png" alt="median home value by state in 1950 in non-inflation adjusted dollars" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-non-inflation-adjusted-dollars-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<h2>Median home value by state in 1950 in inflation adjusted dollars</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars.png" alt="Median home value by state in 1950 in inflation adjusted dollars" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-1950-in-inflation-adjusted-dollars-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<h2>Actual Median home value by state in 2024</h2>
<p><img loading="lazy" decoding="async" src="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024.png" alt="Median home value by state in 2024" width="1640" height="1294" srcset="https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024.png 1640w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-300x237.png 300w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-1024x808.png 1024w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-768x606.png 768w, https://brilliantmaps.com/wp-content/uploads/median-home-value-by-state-in-2024-1536x1212.png 1536w" sizes="auto, (max-width: 1640px) 100vw, 1640px"></p>
<p>And here’s all the data on the changes:</p>

<table id="tablepress-223">
<thead>
<tr>
	<th>State</th><th>Median Home Value (1950)</th><th>Inflation Adjusted Median Home Value (1950)</th><th>Median Home Value (2024)</th><th>Absolute $ Increase Above Inflation</th><th>Percent Increase Above Inflation</th>
</tr>
</thead>
<tbody>
<tr>
	<td>Alabama</td><td>$4,473</td><td>$60,072</td><td>$227,508</td><td>$167,436</td><td>279%</td>
</tr>
<tr>
	<td>Alaska</td><td>$3,477</td><td>$46,696</td><td>$362,098</td><td>$315,402</td><td>675%</td>
</tr>
<tr>
	<td>Arizona</td><td>$5,935</td><td>$79,707</td><td>$428,711</td><td>$349,004</td><td>438%</td>
</tr>
<tr>
	<td>Arkansas</td><td>$4,087</td><td>$54,888</td><td>$208,078</td><td>$153,190</td><td>279%</td>
</tr>
<tr>
	<td>California</td><td>$9,564</td><td>$128,445</td><td>$771,057</td><td>$642,612</td><td>500%</td>
</tr>
<tr>
	<td>Colorado</td><td>$7,151</td><td>$96,038</td><td>$541,072</td><td>$445,034</td><td>463%</td>
</tr>
<tr>
	<td>Connecticut</td><td>$11,862</td><td>$159,307</td><td>$405,595</td><td>$246,289</td><td>155%</td>
</tr>
<tr>
	<td>Delaware</td><td>$9,079</td><td>$121,931</td><td>$388,654</td><td>$266,723</td><td>219%</td>
</tr>
<tr>
	<td>District of Columbia</td><td>$14,498</td><td>$194,708</td><td>$602,769</td><td>$408,060</td><td>210%</td>
</tr>
<tr>
	<td>Florida</td><td>$6,612</td><td>$88,799</td><td>$392,176</td><td>$303,376</td><td>342%</td>
</tr>
<tr>
	<td>Georgia</td><td>$5,235</td><td>$70,306</td><td>$326,617</td><td>$256,311</td><td>365%</td>
</tr>
<tr>
	<td>Hawaii</td><td>$12,283</td><td>$164,961</td><td>$845,946</td><td>$680,985</td><td>413%</td>
</tr>
<tr>
	<td>Idaho</td><td>$5,852</td><td>$78,592</td><td>$451,520</td><td>$372,928</td><td>475%</td>
</tr>
<tr>
	<td>Illinois</td><td>$8,646</td><td>$116,116</td><td>$266,706</td><td>$150,590</td><td>130%</td>
</tr>
<tr>
	<td>Indiana</td><td>$6,226</td><td>$83,615</td><td>$242,113</td><td>$158,498</td><td>190%</td>
</tr>
<tr>
	<td>Iowa</td><td>$6,320</td><td>$84,878</td><td>$220,277</td><td>$135,400</td><td>160%</td>
</tr>
<tr>
	<td>Kansas</td><td>$5,462</td><td>$73,355</td><td>$229,012</td><td>$155,658</td><td>212%</td>
</tr>
<tr>
	<td>Kentucky</td><td>$5,283</td><td>$70,951</td><td>$212,088</td><td>$141,137</td><td>199%</td>
</tr>
<tr>
	<td>Louisiana</td><td>$5,141</td><td>$69,044</td><td>$201,519</td><td>$132,476</td><td>192%</td>
</tr>
<tr>
	<td>Maine</td><td>$4,856</td><td>$65,216</td><td>$401,297</td><td>$336,081</td><td>515%</td>
</tr>
<tr>
	<td>Maryland</td><td>$8,033</td><td>$107,883</td><td>$418,438</td><td>$310,555</td><td>288%</td>
</tr>
<tr>
	<td>Massachusetts</td><td>$9,144</td><td>$122,804</td><td>$623,131</td><td>$500,327</td><td>407%</td>
</tr>
<tr>
	<td>Michigan</td><td>$7,496</td><td>$100,671</td><td>$245,716</td><td>$145,044</td><td>144%</td>
</tr>
<tr>
	<td>Minnesota</td><td>$7,806</td><td>$104,835</td><td>$334,119</td><td>$229,285</td><td>219%</td>
</tr>
<tr>
	<td>Mississippi</td><td>$4,159</td><td>$55,855</td><td>$181,313</td><td>$125,457</td><td>225%</td>
</tr>
<tr>
	<td>Missouri</td><td>$6,399</td><td>$85,939</td><td>$248,328</td><td>$162,389</td><td>189%</td>
</tr>
<tr>
	<td>Montana</td><td>$5,797</td><td>$77,854</td><td>$462,631</td><td>$384,777</td><td>494%</td>
</tr>
<tr>
	<td>Nebraska</td><td>$5,918</td><td>$79,479</td><td>$259,443</td><td>$179,964</td><td>226%</td>
</tr>
<tr>
	<td>Nevada</td><td>$8,859</td><td>$118,976</td><td>$442,185</td><td>$323,209</td><td>272%</td>
</tr>
<tr>
	<td>New Hampshire</td><td>$6,199</td><td>$83,253</td><td>$478,955</td><td>$395,703</td><td>475%</td>
</tr>
<tr>
	<td>New Jersey</td><td>$10,408</td><td>$139,779</td><td>$534,773</td><td>$394,994</td><td>283%</td>
</tr>
<tr>
	<td>New Mexico</td><td>$5,697</td><td>$76,511</td><td>$303,910</td><td>$227,399</td><td>297%</td>
</tr>
<tr>
	<td>New York</td><td>$10,152</td><td>$136,341</td><td>$482,742</td><td>$346,400</td><td>254%</td>
</tr>
<tr>
	<td>North Carolina</td><td>$4,901</td><td>$65,820</td><td>$328,715</td><td>$262,895</td><td>399%</td>
</tr>
<tr>
	<td>North Dakota</td><td>$5,396</td><td>$72,468</td><td>$263,410</td><td>$190,942</td><td>263%</td>
</tr>
<tr>
	<td>Ohio</td><td>$8,304</td><td>$111,523</td><td>$230,798</td><td>$119,275</td><td>107%</td>
</tr>
<tr>
	<td>Oklahoma</td><td>$5,228</td><td>$70,212</td><td>$205,968</td><td>$135,756</td><td>193%</td>
</tr>
<tr>
	<td>Oregon</td><td>$6,846</td><td>$91,942</td><td>$492,683</td><td>$400,742</td><td>436%</td>
</tr>
<tr>
	<td>Pennsylvania</td><td>$6,992</td><td>$93,903</td><td>$268,824</td><td>$174,921</td><td>186%</td>
</tr>
<tr>
	<td>Rhode Island</td><td>$9,767</td><td>$131,171</td><td>$467,485</td><td>$336,314</td><td>256%</td>
</tr>
<tr>
	<td>South Carolina</td><td>$5,112</td><td>$68,654</td><td>$295,769</td><td>$227,115</td><td>331%</td>
</tr>
<tr>
	<td>South Dakota</td><td>$5,410</td><td>$72,656</td><td>$306,944</td><td>$234,287</td><td>322%</td>
</tr>
<tr>
	<td>Tennessee</td><td>$5,268</td><td>$70,749</td><td>$319,208</td><td>$248,458</td><td>351%</td>
</tr>
<tr>
	<td>Texas</td><td>$5,805</td><td>$77,961</td><td>$300,267</td><td>$222,306</td><td>285%</td>
</tr>
<tr>
	<td>Utah</td><td>$7,409</td><td>$99,503</td><td>$517,020</td><td>$417,517</td><td>420%</td>
</tr>
<tr>
	<td>Vermont</td><td>$6,277</td><td>$84,300</td><td>$390,132</td><td>$305,832</td><td>363%</td>
</tr>
<tr>
	<td>Virginia</td><td>$6,581</td><td>$88,383</td><td>$392,682</td><td>$304,299</td><td>344%</td>
</tr>
<tr>
	<td>Washington</td><td>$7,169</td><td>$96,280</td><td>$588,856</td><td>$492,576</td><td>512%</td>
</tr>
<tr>
	<td>West Virginia</td><td>$5,473</td><td>$73,502</td><td>$168,172</td><td>$94,670</td><td>129%</td>
</tr>
<tr>
	<td>Wisconsin</td><td>$7,927</td><td>$106,460</td><td>$306,566</td><td>$200,106</td><td>188%</td>
</tr>
<tr>
	<td>Wyoming</td><td>$6,811</td><td>$91,472</td><td>$354,108</td><td>$262,636</td><td>287%</td>
</tr>
</tbody>
</table>
<!-- #tablepress-223 from cache -->
<p>Data for 1950 US house prices came from the <a href="https://www.census.gov/data/tables/time-series/dec/coh-values.html" target="_blank" rel="noopener">US Census</a>, inflation data for the <a href="https://data.bls.gov/cgi-bin/cpicalc.pl" target="_blank" rel="noopener">Bureau of Labour Statistics</a> and the 2024 house prices from <a href="https://www.zillow.com/research/data/" target="_blank" rel="noopener">Zillow</a>. Maps created using <a href="https://www.datawrapper.de/" target="_blank" rel="noopener">Datawrapper</a>.    </p>
<p>Why do you think home prices have outpaced inflation since the 1950s?</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Influence of Bell Labs (153 pts)]]></title>
            <link>https://www.construction-physics.com/p/the-influence-of-bell-labs</link>
            <guid>42275944</guid>
            <pubDate>Fri, 29 Nov 2024 18:36:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.construction-physics.com/p/the-influence-of-bell-labs">https://www.construction-physics.com/p/the-influence-of-bell-labs</a>, See on <a href="https://news.ycombinator.com/item?id=42275944">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg" width="980" height="500" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:500,&quot;width&quot;:980,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Xerox PARC and the Origins of GUI | CRM.org&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="Xerox PARC and the Origins of GUI | CRM.org" title="Xerox PARC and the Origins of GUI | CRM.org" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc8c63679-10fb-4f92-9957-498dcbe02818_980x500.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>We’ve </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">talked previously</a><span> about Bell Labs’ long, storied history as an innovation engine and a generator of new technology. For decades, it spun off new major inventions and scientific discoveries as part of its mandate to help build AT&amp;T’s telephone network.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png" width="609" height="591" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a5e6d681-1029-41a0-a428-e6475b68b126_609x591.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:591,&quot;width&quot;:609,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5e6d681-1029-41a0-a428-e6475b68b126_609x591.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Bell Labs was notable for combining the best aspects of academic and industrial research. As in a conventional academic lab, scientists had the freedom to pursue research avenues they found promising without being bound by concerns of immediate profitability or return on investment. It was understood that efforts might take years to pay off, and only a handful would. Researchers could also publish papers and engage with the broader intellectual community in their field, while using cutting-edge equipment that only an industrial lab could provide. And they could pursue their research without having to worry about teaching classes or applying for grants.</p><p>Discussion of Bell Labs tends to center around the impact and successes of the Labs itself. But a perhaps underappreciated impact of Bell Labs is the influence it had on other large corporations. Bell Labs was highly prestigious, and its invention of the transistor demonstrated that world-changing products could come by funding “basic” scientific research. Inspired by Bell Labs, in the second half of the 20th century, a variety of corporations started their own research operations based on the Bell Labs model.</p><p>Industrial research labs started to become popular in the US around the turn of the 20th century. Along with Bell Labs, companies like DuPont, General Electric, and Kodak all employed scientists in research labs, and by 1940 there were over 1,000 industrial research labs in the U.S. Most of these labs were small (on average they employed fewer than 100 people), and as late as 1940 there were fewer than 30,000 people employed in a “scientific” capacity in all US manufacturing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png" width="684" height="461" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:461,&quot;width&quot;:684,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff50d776a-a0a7-4e0a-a845-c8c0d4dcdd59_684x461.png 1456w" sizes="100vw"></picture></div></a><figcaption>Research labs in the U.S. over time.</figcaption></figure></div><p>But following WWII, research spending by both the government and the private sector increased enormously. In 1946, private R&amp;D spending in the U.S. was about $500 million annually, roughly what it had been before the war. By 1951 it had increased four-fold to $2 billion annually, and between 1953 and 1977, in real terms, it quadrupled again.</p><p>Unpacking the reasons for this increase goes beyond the extent of this essay, and it certainly wasn’t just because of AT&amp;T and Bell Labs. But Bell Labs’ achievements, particularly the invention of the transistor in 1947, seem to have prompted the decisions of many companies to start their own R&amp;D labs, and influenced how those labs were structured.</p><p>There seem to have been several modes of influence. For one, the transistor itself ushered in a new world of semiconductor devices. Semiconductors were a product of deep, scientific understanding of the physical nature of matter. Anyone who wanted to compete in the new market by developing their own semiconductor-based products would need to acquire the relevant scientific expertise.</p><p>The transistor also demonstrated that “basic” research could result in enormously successful, world-changing products. The world had just seen the amazing power of scientific research in wartime achievements like radar and the atomic bomb, and the transistor showed that the fruits of such research weren’t limited to enormous government projects. The success of nylon, another successful product that was the result of basic research by DuPont, also reinforced this perception.</p><p><span>Finally, Bell Labs was incredibly prestigious, and companies wanted to burnish their reputations by having their own scientific research establishments. Not only was this prestige desirable in its own right, but it could allow companies to acquire the sort of talent that they otherwise might not be able to. The transistor cemented Bell Labs’ reputation as one of the best research labs in the world, which allowed it to acquire some of the world’s best scientific talent, which resulted in </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">further scientific achievements</a><span>.</span></p><blockquote><p><em>Its prestige, reputation for excellence, and envious working environment allowed Bell Labs to acquire some of the most talented researchers in the world. Bell Labs Nobel Prize winner Horst Stormer noted that “Over a very long stretch of time, it was the best place in the world and it attracted — and attracts — the best people.” In his short memoir about Bell Labs, Michael Noll likewise noted that “it seemed everybody wanted to get a job there.” Of Bell Labs’ 10 Nobel Prizes, 8 came from researchers hired in the ‘50s, ‘60s, and ‘70s following the invention of the transistor.</em></p></blockquote><p>Bell Labs thus created a new world that required some degree of scientific capability, showed what could result from creating such capabilities, and provided a playbook for how to do it. In the 1950s and beyond, many companies started their own research operations on the Bell Labs model: creating an academic-esque environment and giving researchers freedom to follow their interests, without necessarily needing to worry about marketable products or immediate profitability.</p><p><span>Several of these research labs, unsurprisingly, were founded by companies in the computers and electronics industry. IBM, for instance, had a research division prior to the 1950s, but it was mostly a small group of electrical engineers who were focused on figuring out how to build new products. Thomas Watson Jr., son of the founder of IBM and its former CEO, </span><a href="https://www.amazon.com/Father-Son-Co-Life-Beyond/dp/0553070118" rel="">describes it in his autobiography</a><span>:</span></p><blockquote><p><em>IBM’s main laboratory, on North Street in Endicott, was a very peculiar place. Between three hundred and four hundred people worked there, but the whole thing was built around seven senior engineers whom Dad called his “inventors”... When [Dad] had an idea for a product, he’d call in one or two of these old birds and describe what he wanted it to do. Then the inventors would go back and try to “put it in metal” as they used to say.</em></p></blockquote><p>At the time, IBM primarily produced mechanical punchcard-based calculators, but Watson Jr, recognizing that the future was in electronics, scaled up their research operations and hired thousands of scientists and engineers who understood semiconductors and solid-state physics. To organize a program of “pure research," IBM hired Emanuel Piore, the former head of the Office of Naval Research:</p><blockquote><p><em>Piore gave a jolt to some of our product development engineers as well. They were like sprinters encountering their first marathon runner, and were amazed to see IBM start funding experiments in exotic fields that seemed unlikely to bear fruit for decades, if ever — like superconductors and artificial intelligence. What the engineers thought of as basic research Piore often dismissed as mere long-term product development, and what he called research was so far removed from what the engineers were doing that they saw no reason for it at all. At Piore’s urging we doubled the percentage of our revenues devoted to research and development, and much of the additional spending was earmarked for pure science.</em></p></blockquote><p><span>IBM Research went on to spawn a variety of major scientific and technological discoveries. </span><a href="https://en.wikipedia.org/wiki/IBM_Research" rel="">From Wikipedia</a><span>:</span></p><blockquote><p><em>IBM Research's numerous contributions to physical and computer sciences include the Scanning Tunneling Microscope and high-temperature superconductivity, both of which were awarded the Nobel Prize. IBM Research was behind the inventions of the SABRE travel reservation system, the technology of laser eye surgery, magnetic storage, the relational database, UPC barcodes and Watson, the question-answering computing system that won a match against human champions on the Jeopardy! television quiz show.</em></p></blockquote><p><span>When setting up its research efforts, IBM consciously took notes from Bell Labs. An </span><a href="https://www.amazon.com/Making-World-Work-Better-Century/dp/0132755106" rel="">official company history</a><span> of IBM’s history of innovation notes that “IBM had a model: AT&amp;T’s Bell Laboratories”. </span><a href="https://www.amazon.com/Innovation-Passport-First-Kind-Research/dp/0133438759" rel="">Another book published</a><span> by IBM about its research commercialization strategies likewise notes that “Originally, the IBM Research division operated as a separate entity, patterned after Bell Labs.”</span></p><p><span>Another electronics manufacturer that patterned its research efforts after Bell Labs was Texas Instruments. </span><a href="https://en.wikipedia.org/wiki/Gordon_Kidd_Teal" rel="">Gordon Teal</a><span>, who invented single-crystal pulling at Bell Labs, was hired by Texas Instruments in 1953 to run its newly established research labs, the Central Research Laboratory. An </span><a href="https://www.amazon.com/Engineering-World-Stories-First-Instruments/dp/0870745026" rel="">official company history</a><span> states that “The strength of CRL was influenced by the basic research model that Teal had learned at his previous job with AT&amp;T's Bell Labs.” In an </span><a href="https://ethw.org/Oral-History:Gordon_K._Teal#Texas_Instruments" rel="">oral history</a><span>, Teal describes how researchers were allowed to pursue their own projects that they felt were promising:</span></p><blockquote><p><em>Goldstein: You were saying that by the late 'fifties and early 'sixties, you were spending less time in the lab. Where did the direction for the laboratory come from? Who was in charge of the projects that they were working on?</em></p><p><em>Teal: No one. As the people that I brought in got experience, they were capable of having good ideas themselves and not have to be directed in everything they did.</em></p><p><em>Goldstein: They would launch their own research projects?</em></p><p><em>Teal: Yes, and I depended on the group heads to give them instructions rather than me.</em></p></blockquote><p>While these efforts are described as “basic research," they don’t appear to be quite as sequestered from product development as in some other Bell Labs-inspired research labs. In the oral history, Teal notes that the labs’ efforts weren’t quite pure science, and research directions tended to be product-focused. They nevertheless appear to be highly influenced by Teals’ Bell Labs experience. Research at Texas Instruments would ultimately result in the first production silicon transistor, and the co-invention of the integrated circuit.</p><p><span>Perhaps the most famous research lab inspired by Bell Labs was Xerox’s Palo Alto Research Center (PARC). Concerned that their copier business would potentially be undermined by advancing computer technology, Xerox acquired computer manufacturer SDS in 1969 to help it stay at the forefront of modern technology. Following the purchase, chief scientist Jack Goldman convinced company leadership to build a new research operation. From </span><em>Dealers of Lightning</em><span>, a history of Xerox PARC:</span></p><blockquote><p><em>On the surface the rationale for the so-called “Xerox Advanced Scientific and Systems Laboratory” was to fortify the new subsidiary’s weak research capability. But from that foundation Goldman was intent on building a much larger edifice. Cannily recognizing that Xerox yearned to be ranked alongside such paragons of industrial muscle as IBM and AT&amp;T, he sketched out a corporate research center engaged in basic science independent of any existing product group, exactly like IBM’s fabled Yorktown Heights research center and AT&amp;T’s Bell Laboratories. About half the staff would be devoted to advanced physics and materials research, and the rest to the new sciences of systems and computing.</em></p></blockquote><p>PARC would be founded “by men whose experience had taught them that the only way to get the best research was to hire the best researchers they could find and leave them unburdened by directives, instructions, or deadlines.”&nbsp;</p><blockquote><p><em>For the most part, the computer engineers of PARC were exempt from corporate imperatives to improve Xerox’s existing products. They had a different charge: to lead the company into new and uncharted territory.</em></p></blockquote><div><p><span>PARC would become famous as the birthplace of much of the technology behind the PC revolution: out of PARC came the </span><a href="https://en.wikipedia.org/wiki/Xerox_Alto" rel="">first personal computer</a><span>, the graphical user interface, ethernet, and the laser printer.</span></p><p><span>But not every research lab inspired by Bell Labs was at a computer or electronics manufacturer. PARC was established by Jack Goldberg, who had formerly led the science arm of Ford’s Scientific Research Lab, which had been </span><a href="https://askus.thehenryford.org/researchguides/faq/372100" rel="">founded in 1951</a><span> and </span><a href="https://books.google.com/books?id=nBdXAAAAMAAJ&amp;pg=PA92&amp;dq=%22Ford%22+%22Jack+Goldman%22&amp;hl=en&amp;newbks=1&amp;newbks_redir=0&amp;sa=X&amp;ved=2ahUKEwiPjoiShM2JAxWtgIQIHUrCE_0Q6AF6BAgLEAI#v=onepage&amp;q=%22Ford%22%20%22Jack%20Goldman%22&amp;f=false" rel="">was intended</a><span> “to be a major scientific institution producing innovation," pursuing basic research independent of any product development. Ford’s research efforts also </span><a href="https://spectrum.ieee.org/how-the-ford-motor-co-invented-the-squid" rel="">seem to have been inspired</a><span> by Bell Labs:</span></p></div><blockquote><p><em>…The lab operated according to a philosophy that was established by AT&amp;T’s Bell Labs and IBM’s Thomas J. Watson Research Center and that has now been essentially abandoned. These great institutions pursued research topics not because they were likely to contribute to the parent company’s bottom line anytime soon but because the corporation believed that research for research’s sake was something a real company did.</em></p><p><em>“We had the freedom to do what we were interested in,” says Arnold Silver, who worked in the Ford lab in its heyday. “We could follow our noses — and particularly, we could follow the data.”</em></p></blockquote><p><span>Among the achievements of Ford’s research labs are the </span><a href="https://en.wikipedia.org/wiki/SQUID" rel="">SQUID</a><span> (an extremely sensitive magnetic field sensor) and the </span><a href="https://en.wikipedia.org/wiki/Sodium%E2%80%93sulfur_battery" rel="">sodium-sulfur</a><span> battery.</span></p><p><span>Another Bell Labs-inspired research lab outside the electronics industry was Exxon’s. In the early 1970s Exxon was worried that petroleum would begin to be exhausted in the coming decades, and was willing to fund long-term research in the hunt for alternative energy technologies. These efforts were wide-ranging, including “fuel cells, solar cells, computer chips, superconductors, and batteries, as well some non-energy projects, such as fax machines and word processors.” Exxon researchers had a great deal of freedom, access to the best equipment, and weren’t burdened with questions of profitability or return on investment. From </span><em><a href="https://www.amazon.com/Long-Hard-Road-Lithium-Ion-Electric-ebook/dp/B09GB3HGHY?crid=328KTS4O3GJ7D&amp;dib=eyJ2IjoiMSJ9.9Hutwsk8qUiVp9bQaV50jsN9H42ejgLzWSDjU7RdBqo.CWvvF0gifrr5G-axjtk2dop_kZJtK61q3KzRyvFB4N4&amp;dib_tag=se&amp;keywords=long+hard+road+the+lithium-ion+battery+and+the+electric+car&amp;qid=1731014737&amp;sprefix=the+long+hard+road+%2Caps%2C243&amp;sr=8-1" rel="">The Long Hard Road</a></em><span>, a history of the lithium ion battery and the electric car:</span></p><blockquote><p><em>…Life at Exxon Research and Engineering was turning out to be a lot like life at Stanford. Exxon Research featured a highly academic atmosphere — groups of PhDs in small labs, surrounded by more small labs with more PhDs, mostly doing chemical and solids research. Moreover, Exxon’s lab was legally considered a not-for-profit entity, so there was no pressure to produce any sort of short-term economic benefit.</em></p></blockquote><p>Exxon felt that it was in direct competition with Bell Labs, and acted accordingly:</p><blockquote><p><em>Exxon corporate management felt they were in a head-to-head competition with Bell Labs, which was about twenty miles down the road in Murray Hill, New Jersey. Edward E. David, who was later named president of Exxon Research and Engineering, actually saw it as a point of pride. David had a doctorate from MIT in electrical engineering. He had previously served as a scientific advisor to President Richard Nixon and had spent twenty years at Bell Labs. And he wanted Exxon Research to be better than Bell Labs. Better, in fact, than any corporate lab in the world. Moreover, he kept score, not by counting dollars but by counting scientific papers and patents.</em></p></blockquote><p><span>Exxon research would later become infamous for </span><a href="https://news.harvard.edu/gazette/story/2023/01/harvard-led-analysis-finds-exxonmobil-internal-research-accurately-predicted-climate-change/" rel="">predicting</a><span> the climate impacts of greenhouse emissions, then suppressing the findings, but it also created the </span><a href="https://spectrum.ieee.org/lithium-ion-battery-2662487214" rel="">first rechargeable lithium ion battery</a><span>.</span></p><p><span>Bell Labs ultimately wasn’t able to maintain its long-horizon research environment following the dissolution of the AT&amp;T monopoly, and it seems like the same is true for the Bell Labs-inspired research organizations. IBM still funds a great deal of research, but is much more tightly integrated with product development, and its </span><a href="https://web.archive.org/web/20110629122453/http://www.research.ibm.com/resources/awards.shtml" rel="">major science and technology awards</a><span> mostly seem to be for work done decades ago. Likewise, Exxon </span><a href="https://corporate.exxonmobil.com/who-we-are/technology-and-collaborations/university-and-national-labs-partnerships/exxonmobil-invests-1-billion-per-year-in-energy-research-emerging-technologies" rel="">spends</a><span> more than a billion dollars annually on research, but via a more carefully managed “stage-gating” process, where “Researchers partner with the business lines to determine the business benefit of a technology, establish research and development goals and timelines, steward independent project reviews and authorize project funding.” In </span><em>Dealers of Lightning</em><span>, Michael Hiltzik argues that by the 1990s PARC was no longer engaged in such unrestricted research decoupled from product development.</span></p><p><span>This probably shouldn’t be surprising. I argued in my </span><a href="https://www.construction-physics.com/p/what-would-it-take-to-recreate-bell" rel="">earlier piece on Bell Labs</a><span> that only a fairly unique set of historical circumstances allowed Bell Labs to exist:</span></p><blockquote><p><em>Bell Labs was made possible by a large-scale, vertically integrated telephone monopoly that allowed for an unusually long and wide research and development horizon for an industrial lab. Outside of those conditions (not likely to be repeated), funding a Bell Labs-style operation does not appear to be something most companies are willing to do. Even a company like Google, which spends billions on R&amp;D and has displayed a willingness to fund speculative, longer-term moonshot projects like self-driving cars or life extension, doesn’t completely bite the Bell Labs bullet. Google’s Moonshot projects absorb billions in funding each year, but they tend to be organized as independent companies that raise money outside Google and get spun off when they seem promising enough.&nbsp;</em></p><p><em>Bell Labs also took advantage of historical circumstances: discoveries in quantum mechanics yielded promising new phenomena, and WWII energized the organization while simultaneously creating scientific and technological progress that could later be capitalized on. These contingencies were the result of pure chance, not anything that could be controlled.</em></p></blockquote><p><span>Part of corporations increasing unwillingness to fund unrestricted, speculative research likely comes down to the fact that labs with unrestricted research operations don’t appear to have been particularly successful. In </span><em><a href="https://books.google.com/books/about/Science_in_the_Twentieth_Century.html?id=sb6MlItuOqsC" rel="">Science in the Twentieth Centur</a><span>y</span></em><span>, W. Bernard Carlson argues that corporations turned away from unrestricted research because it didn’t achieve anything as transformative as the transistor or nylon:</span></p><blockquote><p><em>In investing in R&amp;D, American companies employed thousands of Ph.D scientists and built elaborate research “campuses.” At these new facilities, scientists were granted a large degree of autonomy, in the belief that such freedom had been the crucial ingredient in the development of nylon and the transistor. And yet despite ample funds, new facilities, and unprecedented freedom, scientists at the major corporate labs came up with few major breakthroughs from the 1950s to the 1980s.&nbsp;</em></p></blockquote><p><span>Looking at the history of the Bell Labs-inspired organizations seems to at least somewhat confirm this thesis. I haven’t studied their output exhaustively, but their most successful achievements — things like the Texas Instruments’ integrated circuit, IBM’s DRAM, and Xerox’s laser printer — mostly seem fairly closely tied to immediate product needs, and aren’t obviously the sort of thing you’d need to fund “basic” research to get. Indeed, research on the laser printer started years before Xerox formed PARC, and the other co-inventor of the integrated circuit was Fairchild Semiconductor, which as far as I can tell didn’t operate anything like a basic research lab. Their longer-timeline, “breakthrough” achievements seem to perhaps yield interesting scientific discoveries (the scanning tunneling microscope, Mandelbrot’s </span><a href="https://www.amazon.com/Fractal-Geometry-Nature-Benoit-Mandelbrot/dp/0716711869" rel="">work on fractals</a><span>, the SQUID), but not industry-transforming products. The only real “transformative” discovery to me seems like Exxon’s lithium-ion battery, and it was only subsequent developments outside of Exxon that made this successful.</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-151672861" href="https://www.construction-physics.com/p/the-influence-of-bell-labs#footnote-1-151672861" target="_self" rel="">1</a></span></p><p><span>There’s a well-known phenomenon that technological progress is often driven by </span><a href="https://www.amazon.com/Boom-Bubbles-Stagnation-Byrne-Hobart/dp/1953953476" rel="">bubbles</a><span>, as irrational enthusiasm drives huge amounts of investment in a novel technology far beyond what can be economically justified. Carlota Perez describes the dynamic in </span><em>Technological Revolutions and Financial Capital</em><span>:</span></p><blockquote><p><em>Two or three decades of turbulent adaptation and assimilation elapse from the moment when the set of new technologies, products, industries and infrastructure make their first impact to the beginning of a “golden age’” or “era of good feeling” based on them… Historically, those decades have brought the greatest excitement in financial markets, where brilliant successes and innovations share the stage with great manias and outrageous swindles. They have also ended with the most virulent crashes, recessions, and depressions…</em></p></blockquote><p>It’s possible something similar happened with Bell Labs following the invention of the transistor. Not necessarily a bubble in electronics investment (though that could well be the case), but in the meta-idea of economically unjustifiable investments in pursuing basic research decoupled from immediate product needs. People often bemoan that American companies aren’t willing to fund research the way that they once did, but perhaps that age of industrial research was simply a bubble that was invariably going to pop.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Simple Sabotage for the 21st Century – Specific Suggestions (107 pts)]]></title>
            <link>https://specificsuggestions.com</link>
            <guid>42275919</guid>
            <pubDate>Fri, 29 Nov 2024 18:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://specificsuggestions.com">https://specificsuggestions.com</a>, See on <a href="https://news.ycombinator.com/item?id=42275919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="generatorBlock">
            
            <p>
                <h2>SPECIFIC SUGGESTIONS</h2>
                <h2>SIMPLE SABOTAGE FOR THE 21<span>ST</span> CENTURY</h2>
            </p>
            <p>The most potent tools for fighting injustice are the ones already in your hands.</p>
            
            <div id="publicDomain">
                <p>
                    Secret</p>

                <p>This work is dedicated to the <span>Public Domain</span></p>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 300 300">
                    <g data-name="Public Domain Stamp">
                        <path d="M110.65,192.52l12.51-25.89a30.43,30.43,0,0,1,22.23-46L157.9,94.72a56.31,56.31,0,0,0-8.77-.69h-.72c-.25,0-.49,0-.73,0h-.35a56.78,56.78,0,0,0-36.68,98.49Z"></path>
                        <path d="M176.54,164a30.41,30.41,0,0,1-23.86,17l-12.49,25.86A56.73,56.73,0,0,0,204.39,164Z"></path>
                        <path d="M187.49,108.94,175,134.83a30.42,30.42,0,0,1,1.55,2.79h27.85A56.72,56.72,0,0,0,187.49,108.94Z"></path>
                        <path d="M149.13,51.45c-.42,0-.87,0-1.29,0a100,100,0,1,0,1.29,0ZM71.07,150.8a78.08,78.08,0,0,1,76.54-78.06h1.52a78.06,78.06,0,0,1,21.37,3L103.64,214.24A78,78,0,0,1,71.07,150.8Zm78.06,78.07a78,78,0,0,1-21.36-3L194.63,87.36a78.07,78.07,0,0,1-45.5,141.51Z"></path>
                        <path d="M21.38,121.87l7.53,1.8a4.85,4.85,0,0,0,3.2,0c.68-.35,1.21-1.31,1.58-2.86l.17-.72,2.59.61-4.09,17.14-2.59-.62.13-.56c.38-1.57.33-2.66-.14-3.27A4.93,4.93,0,0,0,26.93,132l-18.7-4.47a4.82,4.82,0,0,0-3.19,0c-.68.36-1.21,1.3-1.58,2.84l-.18.77-2.59-.62,2.78-12.89c.77-3.2,1.45-5.66,2-7.36a13.16,13.16,0,0,1,2.57-4.48A8.32,8.32,0,0,1,12,103.19a8.57,8.57,0,0,1,4.47-.1,8,8,0,0,1,4.85,3.19,9.36,9.36,0,0,1,1.76,5.5,33.42,33.42,0,0,1-1.1,7.76Zm-2.8-.67.37-1.54c.59-2.47.45-4.24-.44-5.33a7.18,7.18,0,0,0-4-2.27,7.84,7.84,0,0,0-4.14,0,4.34,4.34,0,0,0-2.51,1.84,16.16,16.16,0,0,0-1.53,4.4Z"></path>
                        <path d="M26.21,69.22l-2-1.74,11.18-13,2,1.73-.36.42c-1.05,1.23-1.51,2.21-1.38,3a5.09,5.09,0,0,0,1.88,2.56l9.74,8.36a20.89,20.89,0,0,0,4.55,3.15,6.4,6.4,0,0,0,4.24.32,7.65,7.65,0,0,0,4.11-2.6,8.46,8.46,0,0,0,2.14-4.82,6.8,6.8,0,0,0-1-4.46,22.65,22.65,0,0,0-4.19-4.41l-8.29-7.12c-2.53-2.17-4.83-2-6.93.4l-2-1.73,7.83-9.13,2,1.73a4.88,4.88,0,0,0-1,2A3.24,3.24,0,0,0,49,46.09a8.1,8.1,0,0,0,1.93,2.22l8.24,7.07a30,30,0,0,1,4.05,4.07,9.83,9.83,0,0,1,1.88,4.37,11.66,11.66,0,0,1-.5,5.64,16.69,16.69,0,0,1-3.32,5.77,17.33,17.33,0,0,1-5.33,4.32A11.78,11.78,0,0,1,50.59,81a10.28,10.28,0,0,1-4.51-1,20.84,20.84,0,0,1-4.36-3L32,68.59a4.7,4.7,0,0,0-2.9-1.45C28.32,67.18,27.36,67.87,26.21,69.22Z"></path>
                        <path d="M104.47,24.49a14.18,14.18,0,0,1,7.81.18,7.4,7.4,0,0,1,4.34,4.43,7.36,7.36,0,0,1-.55,6.93c-1.34,2.17-4.22,4.12-8.63,5.88L91.6,48.19l-1-2.47c1.59-.63,2.55-1.3,2.87-2s.19-1.79-.39-3.26l-7-17.72a4.63,4.63,0,0,0-1.9-2.62c-.69-.33-1.87-.17-3.52.49l-1-2.47,11.48-5,1.65-.65q7.84-3.12,11.47-2.3a6.6,6.6,0,0,1,5,4.18,6.1,6.1,0,0,1-.18,5A14.17,14.17,0,0,1,104.47,24.49Zm-7.91,1.64,1.54-.61a5.51,5.51,0,0,0,3.2-2.6c.49-1.08.37-2.57-.38-4.45a6.77,6.77,0,0,0-2.09-3,3.67,3.67,0,0,0-2.62-.79,14.88,14.88,0,0,0-3.78,1.09Zm1.08,2.72,3.4,8.58a5.79,5.79,0,0,0,1,1.79,2.38,2.38,0,0,0,1.43.68,4.45,4.45,0,0,0,2.28-.4,3.91,3.91,0,0,0,2.58-2.75,8.35,8.35,0,0,0-.72-4.9,8.92,8.92,0,0,0-2.17-3.46,3.86,3.86,0,0,0-2.61-1.06,11,11,0,0,0-3.75.94Z"></path>
                        <path d="M174.44,25l-1,10.77-29.54-2.32.21-2.65.48,0c1.62.12,2.7-.09,3.23-.65a4.91,4.91,0,0,0,1-3L150.31,8a4.77,4.77,0,0,0-.53-3.16c-.46-.62-1.48-1-3.06-1.12l-.47,0,.2-2.65,17.38,1.37-.21,2.65L163,5c-1.62-.13-2.7.09-3.23.65a4.86,4.86,0,0,0-1,3l-1.45,18.5a10.19,10.19,0,0,0,0,2.77,2.27,2.27,0,0,0,1.16,1.25A9,9,0,0,0,162,32c2.83.22,5-.32,6.52-1.64a11.39,11.39,0,0,0,3.32-5.52Z"></path>
                        <path d="M209.25,17l1.24-2.35,15.23,8L224.48,25l-.44-.23q-2.14-1.12-3.21-.66a4.91,4.91,0,0,0-2.08,2.39l-8.91,17a4.8,4.8,0,0,0-.77,3.1c.17.75,1,1.49,2.36,2.23l.45.23-1.23,2.36-15.24-8,1.24-2.36c1.53.8,2.67,1.1,3.41.9s1.49-1,2.24-2.43l8.91-17a4.57,4.57,0,0,0,.75-3.16C211.74,18.6,210.84,17.81,209.25,17Z"></path>
                        <path d="M260.08,83.11l-9.6,7.54-1.64-2.1a8,8,0,0,0,1.6-3,14.37,14.37,0,0,1-9.8-5.89q-4.66-5.94-3.58-12.55a16.76,16.76,0,0,1,6.42-10.81,17.71,17.71,0,0,1,12.12-3.81q6.86.3,11.75,6.53a14.11,14.11,0,0,1,3.13,10.32,21,21,0,0,0,2.9-1L275,70.41l-9.24,7.68L264.14,76a14.48,14.48,0,0,0,3.44-7.6,9,9,0,0,0-1.94-6.53,7.07,7.07,0,0,0-6.53-3q-3.92.36-9.44,4.7A31.43,31.43,0,0,0,244,69.08a7.49,7.49,0,0,0-1.62,5.13,8.44,8.44,0,0,0,1.83,4.85A9.27,9.27,0,0,0,250,82.52a14.25,14.25,0,0,0,8.39-1.5Z"></path>
                        <path d="M267.08,148.1l2.64.34c-.22,1.7-.11,2.86.35,3.49s1.47,1,3,1.24l19.09,2.52a4.69,4.69,0,0,0,3.21-.37c.63-.45,1.06-1.56,1.29-3.32l2.61.35-.37,3.89c-.35,3.92-.68,7-1,9.21a52.92,52.92,0,0,1-1.83,9,17,17,0,0,1-3.69,6.21,14.6,14.6,0,0,1-6.26,4,17.39,17.39,0,0,1-7.84.67,16.16,16.16,0,0,1-7.37-2.77,14.54,14.54,0,0,1-4.72-5.47,15.3,15.3,0,0,1-1.66-6.53,86.91,86.91,0,0,1,.95-10.85Zm28,16.56-22.19-2.93a13.21,13.21,0,0,0-2.91-.18,2.19,2.19,0,0,0-1.4.91,5.42,5.42,0,0,0-.87,2.6,7.61,7.61,0,0,0,2.39,7.13c2,1.76,5.17,2.94,9.53,3.51a18.21,18.21,0,0,0,8.61-.53,8.91,8.91,0,0,0,4.81-3.69A18.27,18.27,0,0,0,295.12,164.66Z"></path>
                        <path d="M265.89,216.92a16.8,16.8,0,0,1,5.32,7.13,15.18,15.18,0,0,1,.88,9,20.5,20.5,0,0,1-3.84,8.33q-5.21,6.82-12.1,7.7a16.63,16.63,0,0,1-12.61-3.49,16.13,16.13,0,0,1-6.39-11q-1-6.84,4.12-13.5a20.73,20.73,0,0,1,8.07-6.58,14.11,14.11,0,0,1,9-1A19.53,19.53,0,0,1,265.89,216.92ZM260,225q-6-4.54-9.83-5a6.54,6.54,0,0,0-6.27,2.75,7.13,7.13,0,0,0-1.39,6.81q1.13,3.53,7.17,8.13,5.53,4.22,9.45,4.72a7.45,7.45,0,0,0,7.71-9.69Q265.54,229.26,260,225Z"></path>
                        <path d="M194.34,258.35l20.31,19.38-6-15.71a13.46,13.46,0,0,0-1.47-3,3.28,3.28,0,0,0-2-1.17,5,5,0,0,0-2.86.29l-.94-2.49,10.93-4.16.95,2.48a4.46,4.46,0,0,0-2.2,1.7,3.15,3.15,0,0,0-.63,2.22,15.29,15.29,0,0,0,1,3.21l6.09,16c.58,1.52,1.23,2.44,2,2.75s1.89.16,3.51-.45l.94,2.48-12.16,4.64-17-16.39-1.85,23.56-12.21,4.65-1-2.48.61-.23c1.52-.58,2.41-1.24,2.65-2a5,5,0,0,0-.42-3.13l-6.84-18a4.79,4.79,0,0,0-1.81-2.63c-.68-.37-1.77-.27-3.26.3l-.69.27-.95-2.49,16.53-6.3.95,2.49-.61.23c-1.5.57-2.38,1.23-2.62,2a4.89,4.89,0,0,0,.41,3.14l6.8,17.85L192.59,259Z"></path>
                        <path d="M137.91,275.9l.86-1.49a7.92,7.92,0,0,0,1-2.27,1.74,1.74,0,0,0-.54-1.75,5.38,5.38,0,0,0-2.48-.85l.4-2.63,10.61,1.62-.4,2.63c-2-.31-4,1.16-5.88,4.39L127.82,299l-2.77-.43-6.27-26.42c-.62-2.62-1.3-4.23-2-4.85a4.47,4.47,0,0,0-2.2-1.11l.4-2.63,16,2.44-.4,2.63a5.2,5.2,0,0,0-2.75,0,1.31,1.31,0,0,0-.68,1,3.84,3.84,0,0,0,.2,1.56l.2.78.56,2.49Zm-1.43,2.57-7.8-1.19,2.54,10.21Z"></path>
                        <path d="M79.39,279.86,78,282.12l-14.61-9.07,1.41-2.26.42.27c1.38.85,2.43,1.15,3.16.89a4.93,4.93,0,0,0,2.24-2.23l10.14-16.33a4.89,4.89,0,0,0,1-3c-.12-.76-.86-1.56-2.2-2.39l-.43-.27,1.4-2.26,14.61,9.07-1.4,2.26c-1.47-.91-2.58-1.29-3.34-1.15s-1.57.91-2.41,2.26L77.84,274.21a4.66,4.66,0,0,0-1,3.1C77,278.06,77.87,278.91,79.39,279.86Z"></path>
                        <path d="M38.31,236.68l12.44-8.26c2-1.33,3-2.54,3.13-3.65a5.24,5.24,0,0,0-1-3.35l2.22-1.48,6.75,10.17-2.22,1.47a4.8,4.8,0,0,0-2.13-1.84,3.35,3.35,0,0,0-2.26-.25A11.71,11.71,0,0,0,52.47,231l-13.82,9.18q-4.14,2.75-1.56,6.62l-2.22,1.47-6.07-9.14,6.72-25.85-9.93,6.59c-2.95,2-3.61,4.19-1.95,6.68L21.42,228,15,218.26l2.22-1.47A4.16,4.16,0,0,0,19,218.32a3.37,3.37,0,0,0,2.23.26A9,9,0,0,0,24,217.22l20.79-13.8,1.7,2.55Z"></path>
                    </g>
                </svg>
            </div>
        </div><div id="manual">
            <article>
                <section id="introduction">
                    <h2>1. <i>Introduction</i></h2>
                    <p>The <span>enemy</span> has a new form. Today's wars are fought from computer
                        consoles; climate disinformation campaigns are planned in web conferences; decisions to deny
                        healthcare are codified in software.</p>
                    <p>Free and just futures demand new strategies.</p>
                    <p>Unassuming civilians have an outsized ability to make a difference by directly impacting the
                        ordinary services we build and maintain everyday. Many small actions can create a constant and
                        tangible drag on the systems of violence and exploitation. When tyranny suffers, we create an
                        opportunity for more sustainable and prosperous systems to replace it.</p>
                    <p>These ideas are specific suggestions for taking action in this new theater.</p>
                    <p>This is not a guide for overt displays of heroism. Surveillance is abundant in the 21st century
                        work environment. Presented here are practical, everyday actions for reducing systemic harm
                        while minimizing vulnerability.</p>
                    <p>These are Specific Suggestions for <a href="https://www.gutenberg.org/ebooks/26184" target="_blank">Simple Sabotage</a> in the 21st century.</p>
                </section>

                <section id="simple-sabotage">
                    <h2>2. <i>Simple Sabotage</i></h2>
                    <ol>
                        <li>Simple sabotage is more than malicious mischief, and it should always consist of acts whose
                            results will be detrimental to the tools and systems of oppression.</li>
                        <li>Occurring on a wide scale, simple sabotage will be a constant and tangible drag on the
                            operations of hostile systems, making it possible for just, resilient, and thriving ones to
                            take their place.</li>
                        <li>Simple sabotage does not require specially prepared tools or equipment; it is executed by an
                            ordinary person, and it is carried out in such a way as to involve a minimum danger of
                            injury, detection, and retaliation.</li>
                        <li>The saboteur should be creative in using their every-day instruments. Opportunities will
                            present themselves if one looks at their surroundings in a different light. For example,
                            disabling the productivity of an entire workplace may at first seem impossible, but if the
                            saboteur were to unplug a single wifi access point within a space, work might grind to a
                            halt.</li>
                        <li>Where destruction is involved, the weapons of the saboteur are materials and tools they
                            might normally be expected to possess in their particular occupation. Their arsenal is the
                            conference room, the email client, their own usual software applications and supplies. The
                            targets of sabotage are objects to which they have normal and inconspicuous access in
                            everyday life.</li>
                        <li>There is also a type of simple sabotage that requires no destructive tools whatsoever and
                            produces physical damage, if any, by highly indirect means. It is based on universal
                            opportunities to make faulty decisions and generally slow the efficiency of a hostile
                            process. Making a faulty decision may be simply a matter of committing software changes to
                            one repository instead of another or copying the wrong person onto an email.
                            <p>
                                This type of activity, sometimes referred to as the "human element," is frequently
                                responsible for accidents, delays, and general obstruction even under normal conditions.
                                The potential saboteur should discover what types of faulty decisions and operations are
                                normally found in their work and should then devise their sabotage so as to enlarge that
                                "margin for error" while avoiding detection.
                            </p>
                        </li>
                        <li>The saboteur should never attack targets beyond their capacity or the capacity of their
                            tools. An inexperienced person should not, for example, attempt to deploy malware or falsify
                            legal documents, but should make use of familiar tools to carry out their work.</li>
                        <li>The saboteur finds power in the routine, the inconspicuous, and the mundane.</li>
                        <li>The saboteur should try to damage only objects, materials, and systems known to be used to
                            carry out oppression or to be destined for use in harmful systems. (It will be safe to
                            assume that almost any surveillance technology is destined for oppressive use.) Without
                            special knowledge, however, it would be undesirable to attempt destruction of accessibility
                            technologies or interfere with the distribution of health services.</li>
                        <li>The saboteur should never aim to hinder aid.</li>
                        <li>Potential saboteurs should vigilantly consider the extent of surveillance in contemporary
                            work environments. <strong>Assume all actions are monitored</strong> when using an
                            employer-provided digital device, such as a computer or smartphone, or on personal devices
                            after any employer-provided software is installed onto them. Devices provided for public use
                            like those in libraries should also be used with caution.</li>
                        <li>Although the saboteur may rarely have direct access to explicitly malicious processes—such
                            as eviction and displacement, ecological destruction, or the manufacture of anti-personnel
                            weapons—they should prioritize these above all others.</li>
                        <li>It will not be possible to evaluate the desirability of simple sabotage in an organization
                            without having in mind what specific individual acts and results are embraced by the
                            definition of simple sabotage.</li>
                        <li>Access to these materials should not depend upon any one individual and should be published
                            widely to increase resilience.</li>
                    </ol>
                </section>
                <section id="specific-suggestions">
                    <h2>3. <i>Specific Suggestions</i></h2>
                    <ol>
                        <li>Unplugging routers, committing buggy code, changing file extensions, acting absentminded,
                            feigning ignorance, and hiding key technologies and supplies will waste the materials,
                            manpower, and time of the enemy. Sabotage may be as mundane as leaving the caps off of
                            shared dry erase markers or as complex as supporting unprofitable business objectives.</li>
                        <li>The generator provided on this webpage suggests specific acts, classified according to
                            context.</li>
                        <li>This entire library of specific suggestions and accompanying source code is deliberately
                            placed into the public domain allowing anyone to download and repurpose for their particular
                            needs.</li>
                        <li>As new techniques are developed, or new fields explored, the public is encouraged to make
                            amendments and independently republish this reference with their own updates.</li>
                        <li>The suggestions presented here focus on novel actions within contemporary office and
                            administrative work settings. More traditional environments are better covered by the <a href="https://www.gutenberg.org/ebooks/26184" target="_blank">Simple Sabotage Field
                                Manual</a> published by the United States Office of Strategic Services.</li>
                        <li>Interactive table of specific suggestions is provided below.</li>
                        
                        
                        <p>
                            <a target="_blank" href="https://specificsuggestions.com/viewtables.html">Table Exploration Tools</a>
                        </p>
                    </ol>

                </section>
                <section id="motivation">
                    <h2>4. <i>Motivating The Saboteur</i></h2>
                    <div id="motivationQuotes" onclick="showQuote();">
                        <blockquote>
                            There's a time when the operation of the machine becomes so odious, makes you so sick at heart that you can't take part! You can't even passively take part! … That doesn't mean that you have to break anything. One thousand people sitting down some place, not letting anybody by, not [letting] anything happen, can stop any machine.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Mario_Savio');">Mario Savio</cite>
                        </blockquote>
                        <blockquote>
                            We must always take sides. Neutrality helps the oppressor, never the victim. Silence encourages the tormentor, never the tormented.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Elie_Wiesel');">Elie Wiesel</cite>
                        </blockquote>
                        <blockquote>
                            Nonviolence is a powerful and just weapon. It is a weapon unique in history, which cuts without wounding and ennobles the man who wields it. It is a sword that heals.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Martin_Luther_King_Jr.');">Martin Luther King Jr.</cite>
                        </blockquote>
                        <blockquote>
                            When we identify where our privilege intersects with somebody else's oppression, we'll find our opportunities to make real change.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Ijeoma_Oluo');">Ijeoma Oluo</cite>
                        </blockquote>
                        <blockquote>
                            When you get these jobs you have been so brilliantly trained for, just remember that your real job is that if you are free, you need to free somebody else. If you have some power, then your job is to empower somebody else.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Toni_Morrison');">Toni Morrison</cite>
                        </blockquote>
                        <blockquote>Don't sit around and wait for the perfect opportunity to come along — find something and make it an opportunity.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Cecile_Richards');">Cecile Richards</cite>
                        </blockquote>
                        <blockquote>
                            Our problems stem from our acceptance of this filthy, rotten system.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Dorothy_Day');">Dorothy Day</cite>
                        </blockquote>
                        <blockquote>Colorful demonstrations and weekend marches are vital but alone are not powerful enough to stop wars. Wars will be stopped only when soldiers refuse to fight, when workers refuse to load weapons onto ships and aircraft, when people boycott the economic outposts of Empire that are strung across the globe.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Arundhati_Roy');">Arundhati Roy</cite>
                        </blockquote>
                        <blockquote>
                            Tyranny, like hell, is not easily conquered; yet we have this consolation with us, that the harder the conflict, the more glorious the triumph.
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Thomas_Paine');">Thomas Paine</cite>
                        </blockquote>
                        <blockquote>自由、公正、平等是我們的目標。
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Sun_Yat-sen');">孙逸仙</cite>
                        </blockquote>
                        <blockquote>As we contemplate the vast amount of work to be done for justice and peace in this world, we trust that we will find the grace to accomplish , to believe in, and to hope for the greatest things. 
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Peter_Faber');">Peter Faber</cite>
                        </blockquote>
                        <blockquote>It is the greatest of all mistakes to do nothing because you can only do a little.  
                            <cite onclick="quoteInfo(event, 'https://wikipedia.org/wiki/Sydney_Smith');">Sydney Smith</cite>
                        </blockquote>
                        </div>
                </section>
                
                <section id="publication">
                    <hr>
                    <p>Published into the Public Domain.</p>
                    <div id="dates">
                        <p>First Published: <span>NOV 28 2024</span></p>
                        <p>Updated: <span>NOV 29 2024</span></p> </div>
                </section>
            </article>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Chinese pebble-bed nuclear reactor passes "meltdown" test (135 pts)]]></title>
            <link>https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/</link>
            <guid>42275834</guid>
            <pubDate>Fri, 29 Nov 2024 18:21:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/">https://www.ans.org/news/article-6241/china-pebblebed-reactor-passes-meltdown-test/</a>, See on <a href="https://news.ycombinator.com/item?id=42275834">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="expand_6241"><p>The <a href="https://www.tsinghua.edu.cn/en/info/1399/10915.htm">Shidaowan plant</a>, a demonstration high-temperature, gas-cooled reactor with a pebble-bed module (HTR-PM), went into commercial operation last December. </p><p>Shidaowan’s twin 100-MW units house tiny uranium capsules encased in graphite shells about the size of billiard balls (dubbed “pebbles”), which make the energy density of the fuel much lower than in a traditional nuclear reactor with fuel rods. In the pebble design, the nuclear fission reaction occurs more slowly than in conventional reactors, but the fuel can withstand higher temperatures for longer and the heat resulting from the fission reaction is dispersed, enabling a passive cooling process.</p><p>The reactor doesn’t rely on large volumes of water in the cooling process—instead, a small amount of helium gas, which can withstand much higher temperatures than water, is piped through the system to naturally cool it down. If the reactor starts to get too hot, its components automatically slow down the nuclear reaction and the system cools. This setup makes such a reactor “meltdown proof,” in concept.</p><p><strong>The study:</strong> Researchers at Tsinghua University in China performed two safety tests on the Shidaowan plant’s reactor modules by shutting off active power supply to see if the decay heat could be removed passively. The responses of temperatures and nuclear power in each unit confirmed that they can be cooled down naturally, without active intervention.</p><p>“The results of the tests manifest the existence of commercial-scale inherent safety for the first time,” according to findings published in the journal <em><a href="https://www.cell.com/joule/abstract/S2542-4351(24)00290-3?_returnURL=https%3A%2F%2Flinkinghub.elsevier.com%2Fretrieve%2Fpii%2FS2542435124002903%3Fshowall%3Dtrue">Joule</a></em>.</p><p>The Shidaowan project is a collaboration involving Tsinghua University as a technical leader, responsible for research and development and main components and systems design; China Huaneng Group as owner and operator of the plant; and China National Nuclear Corporation as overseer of engineering and procurement and fuel manufacturing.</p><p><strong>Other pebble beds:</strong> The pebble bed technology and design has previously been used in prototype reactors in China and Germany, but not a larger-scale plant like Shidaowan.</p><p>In the U.S., X-energy is working to deploy its pebble-fueled <a href="https://x-energy.com/reactors/xe-100">Xe-100</a> design—an 80-MWe high-temperature, gas-cooled reactor that can be scaled into a four-pack to make a 320-MWe power plant. X-energy’s license request is <a href="https://www.nrc.gov/reactors/new-reactors/advanced/who-were-working-with/licensing-activities/pre-application-activities/xe-100.html">under review</a> by the Nuclear Regulatory Commission.</p><p>X-energy was <a href="https://x-energy.com/media/news-releases/x-energy-awarded-80-million-department-of-energy-advanced-reactor-demonstration-program-ardp">one of two chosen</a> for the Department of Energy’s Advanced Reactor Demonstration Program in 2020. With $160 million in initial funding, ARDP set out to help bring two advanced reactors to commercial operation within seven years. (TerraPower’s Natrium reactor is the other.)</p><p>X-energy has a joint development agreement with Dow to develop its first Xe-100 plant at the chemical company’s plant in Seadrift, Texas. X-energy is also working with Energy Northwest under a joint development agreement to bring up to 12 of the Xe-100 small modular reactors to Washington state. That project is expected to be developed at a site adjacent to Energy Northwest’s Columbia nuclear power plant.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Buy Nothing Day (163 pts)]]></title>
            <link>https://buynothingday.co.uk/</link>
            <guid>42275745</guid>
            <pubDate>Fri, 29 Nov 2024 18:10:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buynothingday.co.uk/">https://buynothingday.co.uk/</a>, See on <a href="https://news.ycombinator.com/item?id=42275745">Hacker News</a></p>
Couldn't get https://buynothingday.co.uk/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why pipes sometimes get "stuck": buffering (359 pts)]]></title>
            <link>https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/</link>
            <guid>42275033</guid>
            <pubDate>Fri, 29 Nov 2024 16:43:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/">https://jvns.ca/blog/2024/11/29/why-pipes-get-stuck-buffering/</a>, See on <a href="https://news.ycombinator.com/item?id=42275033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
     <p>Here’s a niche terminal problem that has bothered me for years but that I never
really understood until a few weeks ago. Let’s say you’re running this command
to watch for some specific output in a log file:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>If log lines are being added to the file relatively slowly, the result I’d see
is… nothing! It doesn’t matter if there were matches in the log file or not,
there just wouldn’t be any output.</p>
<p>I internalized this as “uh, I guess pipes just get stuck sometimes and don’t
show me the output, that’s weird”, and I’d handle it by just
running <code>grep thing1 /some/log/file | grep thing2</code> instead, which would work.</p>
<p>So as I’ve been doing a terminal deep dive over the last few months I was
really excited to finally learn exactly why this happens.</p>
<h3 id="why-this-happens-buffering">why this happens: buffering</h3>
<p>The reason why “pipes get stuck” sometimes is that it’s VERY common for
programs to buffer their output before writing it to a pipe or file. So the
pipe is working fine, the problem is that the program never even wrote the data
to the pipe!</p>
<p>This is for performance reasons: writing all output immediately as soon as you
can uses more system calls, so it’s more efficient to save up data until you
have 8KB or so of data to write (or until the program exits) and THEN write it
to the pipe.</p>
<p>In this example:</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>the problem is that <code>grep thing1</code> is saving up all of its matches until it has
8KB of data to write, which might literally never happen.</p>
<h3 id="programs-don-t-buffer-when-writing-to-a-terminal">programs don’t buffer when writing to a terminal</h3>
<p>Part of why I found this so disorienting is that <code>tail -f file | grep thing</code>
will work totally fine, but then when you add the second <code>grep</code>, it stops
working!! The reason for this is that the way <code>grep</code> handles buffering depends
on whether it’s writing to a terminal or not.</p>
<p>Here’s how <code>grep</code> (and many other programs) decides to buffer its output:</p>
<ul>
<li>Check if stdout is a terminal or not using the <code>isatty</code> function
<ul>
<li>If it’s a terminal, use line buffering (print every line immediately as soon as you have it)</li>
<li>Otherwise, use “block buffering” – only print data if you have at least 8KB or so of data to print</li>
</ul>
</li>
</ul>
<p>So if <code>grep</code> is writing directly to your terminal then you’ll see the line as
soon as it’s printed, but if it’s writing to a pipe, you won’t.</p>
<p>Of course the buffer size isn’t always 8KB for every program, it depends on the implementation. For <code>grep</code> the buffering is handled by libc, and libc’s buffer size is
defined in the <code>BUFSIZ</code> variable. <a href="https://github.com/bminor/glibc/blob/c69e8cccaff8f2d89cee43202623b33e6ef5d24a/libio/stdio.h#L100">Here’s where that’s defined in glibc</a>.</p>
<p>(as an aside: “programs do not use 8KB output buffers when writing to a
terminal” isn’t, like, a law of terminal physics, a program COULD use an 8KB
buffer when writing output to a terminal if it wanted, it would just be
extremely weird if it did that, I can’t think of any program that behaves that
way)</p>
<h3 id="commands-that-buffer-commands-that-don-t">commands that buffer &amp; commands that don’t</h3>
<p>One annoying thing about this buffering behaviour is that you kind of need to
remember which commands buffer their output when writing to a pipe.</p>
<p>Some commands that <strong>don’t</strong> buffer their output:</p>
<ul>
<li>tail</li>
<li>cat</li>
<li>tee</li>
</ul>
<p>I think almost everything else will buffer output, especially if it’s a command
where you’re likely to be using it for batch processing. Here’s a list of some
common commands that buffer their output when writing to a pipe, along with the
flag that disables block buffering.</p>
<ul>
<li>grep (<code>--line-buffered</code>)</li>
<li>sed (<code>-u</code>)</li>
<li>awk (there’s a <code>fflush()</code> function)</li>
<li>tcpdump (<code>-l</code>)</li>
<li>jq (<code>-u</code>)</li>
<li>tr (<code>-u</code>)</li>
<li>cut (can’t disable buffering)</li>
</ul>
<p>Those are all the ones I can think of, lots of unix commands (like <code>sort</code>) may
or may not buffer their output but it doesn’t matter because <code>sort</code> can’t do
anything until it finishes receiving input anyway.</p>
<p>Also I did my best to test both the Mac OS and GNU versions of these but there
are a lot of variations and I might have made some mistakes.</p>
<h3 id="programming-languages-where-the-default-print-statement-buffers">programming languages where the default “print” statement buffers</h3>
<p>Also, here are a few programming language where the default print statement
will buffer output when writing to a pipe, and some ways to disable buffering
if you want:</p>
<ul>
<li>C (disable with <code>setvbuf</code>)</li>
<li>Python (disable with <code>python -u</code>, or <code>PYTHON_UNBUFFERED=1</code>, or <code>sys.stdout.reconfigure(line_buffering=False)</code>, or <code>print(x, flush=True)</code>)</li>
<li>Ruby (disable with <code>STDOUT.sync = true</code>)</li>
<li>Perl (disable with <code>$| = 1</code>)</li>
</ul>
<p>I assume that these languages are designed this way so that the default print
function will be fast when you’re doing batch processing.</p>
<p>Also whether output is buffered or not might depend on what print function you
use, for example in Rust <code>print!</code> buffers when writing to a pipe but <code>println!</code>
will flush its output.</p>
<h3 id="when-you-press-ctrl-c-on-a-pipe-the-contents-of-the-buffer-are-lost">when you press <code>Ctrl-C</code> on a pipe, the contents of the buffer are lost</h3>
<p>Let’s say you’re running this command as a hacky way to watch for DNS requests
to <code>example.com</code>, and you forgot to pass <code>-l</code> to tcpdump:</p>
<pre><code>sudo tcpdump -ni any port 53 | grep example.com
</code></pre>
<p>When you press <code>Ctrl-C</code>, what happens? In a magical perfect world, what I would
<em>want</em> to happen is for <code>tcpdump</code> to flush its buffer, <code>grep</code> would search for
<code>example.com</code>, and I would see all the output I missed.</p>
<p>But in the real world, what happens is that all the programs get killed and the
output in <code>tcpdump</code>’s buffer is lost.</p>
<p>I think this problem is probably unavoidable – I spent a little time with
<code>strace</code> to see how this works and <code>grep</code> receives the <code>SIGINT</code> before
<code>tcpdump</code> anyway so even if <code>tcpdump</code> tried to flush its buffer <code>grep</code> would
already be dead.</p>
<h3 id="redirecting-to-a-file-also-buffers">redirecting to a file also buffers</h3>
<p>It’s not just pipes, this will also buffer:</p>
<pre><code>sudo tcpdump -ni any port 53 &gt; output.txt
</code></pre>
<p>Redirecting to a file doesn’t have the same “<code>Ctrl-C</code> will totally destroy the
contents of the buffer” problem though – in my experience it usually behaves
more like you’d want, where the contents of the buffer get written to the file
before the program exits. I’m not 100% sure whether this is something you can
always rely on or not.</p>
<h3 id="a-bunch-of-potential-ways-to-avoid-buffering">a bunch of potential ways to avoid buffering</h3>
<p>Okay, let’s talk solutions. Let’s say you’ve run this command or s</p>
<pre><code>tail -f /some/log/file | grep thing1 | grep thing2
</code></pre>
<p>I asked people on Mastodon how they would solve this in practice and there were
5 basic approaches. Here they are:</p>
<h4 id="solution-1-run-a-program-that-finishes-quickly">solution 1: run a program that finishes quickly</h4>
<p>Historically my solution to this has been to just avoid the “command writing to
pipe slowly” situation completely and instead run a program that will finish quickly
like this:</p>
<pre><code>cat /some/log/file | grep thing1 | grep thing2 | tail
</code></pre>
<p>This doesn’t do the same thing as the original command but it does mean that
you get to avoid thinking about these weird buffering issues.</p>
<p>(you could also do <code>grep thing1 /some/log/file</code> but I often prefer to use an
“unnecessary” <code>cat</code>)</p>
<h4 id="solution-2-remember-the-line-buffer-flag-to-grep">solution 2: remember the “line buffer” flag to grep</h4>
<p>You could remember that grep has a flag to avoid buffering and pass it like this:</p>
<pre><code>tail -f /some/log/file | grep --line-buffered thing1 | grep thing2
</code></pre>
<h4 id="solution-3-use-awk">solution 3: use awk</h4>
<p>Some people said that if they’re specifically dealing with a multiple greps
situation, they’ll rewrite it to use a single <code>awk</code> instead, like this:</p>
<pre><code>tail -f /some/log/file |  awk '/thing1/ &amp;&amp; /thing2/'
</code></pre>
<p>Or you would write a more complicated <code>grep</code>, like this:</p>
<pre><code>tail -f /some/log/file |  grep -E 'thing1.*thing2'
</code></pre>
<p>(<code>awk</code> also buffers, so for this to work you’ll want <code>awk</code> to be the last command in the pipeline)</p>
<h4 id="solution-4-use-stdbuf">solution 4: use <code>stdbuf</code></h4>
<p><code>stdbuf</code> uses LD_PRELOAD to turn off libc’s buffering, and you can use it to turn off output buffering like this:</p>
<pre><code>tail -f /some/log/file | stdbuf -o0 grep thing1 | grep thing2
</code></pre>
<p>Like any <code>LD_PRELOAD</code> solution it’s a bit unreliable – it doesn’t work on
static binaries, I think won’t work if the program isn’t using libc’s
buffering, and doesn’t always work on Mac OS. Harry Marr has a really nice <a href="https://hmarr.com/blog/how-stdbuf-works/">How stdbuf works</a> post.</p>
<h4 id="solution-5-use-unbuffer">solution 5: use <code>unbuffer</code></h4>
<p><code>unbuffer program</code> will force the program’s output to be a TTY, which means
that it’ll behave the way it normally would on a TTY (less buffering, colour
output, etc). You could use it in this example like this:</p>
<pre><code>tail -f /some/log/file | unbuffer grep thing1 | grep thing2
</code></pre>
<p>Unlike <code>stdbuf</code> it will always work, though it might have unwanted side
effects, for example <code>grep thing1</code>’s will also colour matches.</p>
<p>If you want to install unbuffer, it’s in the <code>expect</code> package.</p>
<h3 id="that-s-all-the-solutions-i-know-about">that’s all the solutions I know about!</h3>
<p>It’s a bit hard for me to say which one is “best”, I think personally I’m
mostly likely to use <code>unbuffer</code> because I know it’s always going to work.</p>
<p>If I learn about more solutions I’ll try to add them to this post.</p>
<h3 id="i-m-not-really-sure-how-often-this-comes-up">I’m not really sure how often this comes up</h3>
<p>I think it’s not very common for me to have a program that slowly trickles data
into a pipe like this, normally if I’m using a pipe a bunch of data gets
written very quickly, processed by everything in the pipeline, and then
everything exits. The only examples I can come up with right now are:</p>
<ul>
<li>tcpdump</li>
<li><code>tail -f</code></li>
<li>watching log files in a different way like with <code>kubectl logs</code></li>
<li>the output of a slow computation</li>
</ul>
<h3 id="what-if-there-were-an-environment-variable-to-disable-buffering">what if there were an environment variable to disable buffering?</h3>
<p>I think it would be cool if there were a standard environment variable to turn
off buffering, like <code>PYTHON_UNBUFFERED</code> in Python. I got this idea from a
<a href="https://blog.plover.com/Unix/stdio-buffering.html">couple</a> of <a href="https://blog.plover.com/Unix/stdio-buffering-2.html">blog posts</a> by Mark Dominus
in 2018. Maybe <code>NO_BUFFER</code> like <a href="https://no-color.org/">NO_COLOR</a>?</p>
<p>The design seems tricky to get right; Mark points out that NETBSD has <a href="https://man.netbsd.org/setbuf.3">environment variables called <code>STDBUF</code>, <code>STDBUF1</code>, etc</a> which gives you a
ton of control over buffering but I imagine most developers don’t want to
implement many different environment variables to handle a relatively minor
edge case.</p>
<p>I’m also curious about whether there are any programs that just
automatically flush their output buffers after some period of time (like 1
second). It feels like it would be a nice solution but I can’t think of any
program that does that, maybe it’s not easy to implement?</p>
<h3 id="stuff-i-left-out">stuff I left out</h3>
<p>Some things I didn’t talk about in this post since these posts have been
getting pretty long recently and seriously does anyone REALLY want to read 3000
words about buffering?</p>
<ul>
<li>the difference between line buffering and having totally unbuffered output</li>
<li>how buffering to stderr is different from buffering to stdout</li>
<li>this post is only about buffering that happens <strong>inside the program</strong>, your
operating system’s TTY driver also does a little bit of buffering sometimes</li>
<li>other reasons you might need to flush your output other than “you’re writing
to a pipe”</li>
</ul>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Prometheus 3.0 (193 pts)]]></title>
            <link>https://prometheus.io/blog/2024/11/14/prometheus-3-0/</link>
            <guid>42274660</guid>
            <pubDate>Fri, 29 Nov 2024 15:52:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://prometheus.io/blog/2024/11/14/prometheus-3-0/">https://prometheus.io/blog/2024/11/14/prometheus-3-0/</a>, See on <a href="https://news.ycombinator.com/item?id=42274660">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      

<p>Following the recent release of <a href="https://prometheus.io/blog/2024/09/11/prometheus-3-beta/">Prometheus 3.0 beta</a> at PromCon in Berlin, the Prometheus Team
is excited to announce the immediate availability of Prometheus Version 3.0!</p>

<p>This latest version marks a significant milestone as it is the first major release in 7 years. Prometheus has come a long way in that time, 
evolving from a project for early adopters to becoming a standard part of the cloud native monitoring stack. Prometheus 3.0 aims to 
continue that journey by adding some exciting new features while largely maintaining stability and compatibility with previous versions.</p>

<p>The full 3.0 release adds some new features on top of the beta and also introduces a few additional breaking changes that we will describe in this article.</p>


<div><ul>
<li><a href="#new-ui">New UI
</a></li>
<li><a href="#remote-write-2-0">Remote Write 2.0
</a></li>
<li><a href="#utf-8-support">UTF-8 Support
</a></li>
<li><a href="#otlp-support">OTLP Support
</a></li>
<ul>
<li><a href="#otlp-ingestion">OTLP Ingestion
</a></li>
<li><a href="#utf-8-normalization">UTF-8 Normalization
</a></li>
</ul>
<li><a href="#native-histograms">Native Histograms
</a></li>
<li><a href="#breaking-changes">Breaking Changes
</a></li>
</ul></div>

<p>Here is a summary of the exciting changes that have been released as part of the beta version, as well as what has been added since:</p>

<h2 id="new-ui">New UI<a href="#new-ui" name="new-ui"></a>
</h2>

<p>One of the highlights in Prometheus 3.0 is its brand-new UI that is enabled by default:</p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/blog_post_screenshot_tree_view-s.png" alt="New UI query page"></p>

<p>The UI has been completely rewritten with less clutter, a more modern look and feel, new features like a <a href="https://promlens.com/"><strong>PromLens</strong></a>-style tree view,
and will make future maintenance easier by using a more modern technical stack.</p>

<p>Learn more about the new UI in general in <a href="https://promlabs.com/blog/2024/09/11/a-look-at-the-new-prometheus-3-0-ui/">Julius' detailed article on the PromLabs blog</a>.
Users can temporarily enable the old UI by using the <code>old-ui</code> feature flag.</p>

<p>Since the new UI is not battle-tested yet, it is also very possible that there are still bugs. If you find any, please 
<a href="https://github.com/prometheus/prometheus/issues/new?assignees=&amp;labels=&amp;projects=&amp;template=bug_report.yml">report them on GitHub</a>.</p>

<p>Since the beta, the user interface has been updated to support UTF-8 metric and label names.</p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/utf8_ui.png" alt="New UTF-8 UI"></p>

<h2 id="remote-write-2-0">Remote Write 2.0<a href="#remote-write-2-0" name="remote-write-2-0"></a>
</h2>

<p>Remote-Write 2.0 iterates on the previous protocol version by adding native support for a host of new elements including metadata, exemplars,
created timestamp and native histograms. It also uses string interning to reduce payload size and CPU usage when compressing and decompressing. 
There is better handling for partial writes to provide more details to clients when this occurs. More details can be found
<a href="https://prometheus.io/docs/specs/remote_write_spec_2_0/">here</a>.</p>

<h2 id="utf-8-support">UTF-8 Support<a href="#utf-8-support" name="utf-8-support"></a>
</h2>

<p>Prometheus now allows all valid UTF-8 characters to be used in metric and label names by default, as well as label values,
as has been true in version 2.x.</p>

<p>Users will need to make sure their metrics producers are configured to pass UTF-8 names, and if either side does not support UTF-8,
metric names will be escaped using the traditional underscore-replacement method. PromQL queries can be written with the new quoting syntax
in order to retrieve UTF-8 metrics, or users can specify the <code>__name__</code>  label name manually.</p>

<p>Currently only the Go client library has been updated to support UTF-8, but support for other languages will be added soon.</p>

<h2 id="otlp-support">OTLP Support<a href="#otlp-support" name="otlp-support"></a>
</h2>

<p>In alignment with <a href="https://prometheus.io/blog/2024/03/14/commitment-to-opentelemetry/">our commitment to OpenTelemetry</a>, Prometheus 3.0 features 
several new features to improve interoperability with OpenTelemetry. </p>

<h3 id="otlp-ingestion">OTLP Ingestion<a href="#otlp-ingestion" name="otlp-ingestion"></a>
</h3>

<p>Prometheus can be configured as a native receiver for the OTLP Metrics protocol, receiving OTLP metrics on the <code>/api/v1/otlp/v1/metrics</code> endpoint.</p>

<p>See our <a href="https://prometheus.io/docs/guides/opentelemetry">guide</a> on best practices for consuming OTLP metric traffic into Prometheus.</p>

<h3 id="utf-8-normalization">UTF-8 Normalization<a href="#utf-8-normalization" name="utf-8-normalization"></a>
</h3>

<p>With Prometheus 3.0, thanks to <a href="#utf-8-support">UTF-8 support</a>, users can store and query OpenTelemetry metrics without annoying changes to metric and label names like <a href="https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/pkg/translator/prometheus">changing dots to underscores</a>.</p>

<p>Notably this allows <strong>less confusion</strong> for users and tooling in terms of the discrepancy between what’s defined in OpenTelemetry semantic convention or SDK and what’s actually queryable.</p>

<p>To achieve this for OTLP ingestion, Prometheus 3.0 has experimental support for different translation strategies. See <a href="https://prometheus.io/docs/prometheus/latest/configuration/configuration/#:%7E:text=Settings%20related%20to%20the%20OTLP%20receiver%20feature">otlp section in the Prometheus configuration</a> for details.</p>

<blockquote>

</blockquote>

<h2 id="native-histograms">Native Histograms<a href="#native-histograms" name="native-histograms"></a>
</h2>

<p>Native histograms are a Prometheus metric type that offer a higher efficiency and lower cost alternative to Classic Histograms. Rather than having to choose (and potentially have to update) bucket boundaries based on the data set, native histograms have pre-set bucket boundaries based on exponential growth.</p>

<p>Native Histograms are still experimental and not yet enabled by default, and can be turned on by passing <code>--enable-feature=native-histograms</code>. Some aspects of Native Histograms, like the text format and accessor functions / operators are still under active design.</p>

<h2 id="breaking-changes">Breaking Changes<a href="#breaking-changes" name="breaking-changes"></a>
</h2>

<p>The Prometheus community strives to <a href="https://prometheus.io/docs/prometheus/latest/stability/">not break existing features within a major release</a>. With a new major release we took the opportunity to clean up a few, but small, long-standing issues. In other words, Prometheus 3.0 contains a few breaking changes. This includes changes to feature flags, configuration files, PromQL, and scrape protocols.</p>

<p>Please read the <a href="https://prometheus.io/docs/prometheus/3.0/migration/">migration guide</a> to find out if your setup is affected and what actions to take.</p>



<p>It’s impressive to see what we have accomplished in the community since Prometheus 2.0. We all love numbers, so let’s celebrate the efficiency improvements we made for both CPU and memory use for the TSDB mode. Below you can see performance numbers between 3 Prometheus versions on the node with 8 CPU and 49 GB allocatable memory.</p>

<ul>
<li>2.0.0 (7 years ago)</li>
<li>2.18.0 (4 years ago)</li>
<li>3.0.0 (now)</li>
</ul>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/memory_bytes_ui.png" alt="Memory bytes"></p>

<p><img src="https://prometheus.io/assets/blog/2024-11-14/cpu_seconds_ui.png" alt="CPU seconds"></p>

<p>It’s furthermore impressive that those numbers were taken using our <a href="https://github.com/prometheus/prometheus/pull/15366">prombench macrobenchmark</a> 
that uses the same PromQL queries, configuration and environment–highlighting backward compatibility and stability for the core features, even with 3.0.</p>



<p>There are still tons of exciting features and improvements we can make in Prometheus and the ecosystem. Here is a non-exhaustive list to get you excited and… 
hopefully motivate you to contribute and join us!</p>

<ul>
<li>New, more inclusive <strong>governance</strong>
</li>
<li>More <strong>OpenTelemetry</strong> compatibility and features</li>
<li>OpenMetrics 2.0, now under Prometheus governance!</li>
<li>Native Histograms stability (and with custom buckets!)</li>
<li>More optimizations!</li>
<li>UTF-8 support coverage in more SDKs and tools</li>
</ul>



<p>You can try out Prometheus 3.0 by downloading it from our <a href="https://prometheus.io/download/#prometheus">official binaries</a> and <a href="https://quay.io/repository/prometheus/prometheus?tab=tags">container images</a>.</p>

<p>If you are upgrading from Prometheus 2.x, check out the migration guide for more information on any adjustments you will have to make.
Please note that we strongly recommend upgrading to v2.55 before upgrading to v3.0. Rollback is possible from v3.0 to v2.55, but not to earlier versions.</p>

<p>As always, we welcome feedback and contributions from the community!</p>


    <article>

    
    
    
  </article></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama.cpp guide – Running LLMs locally on any hardware, from scratch (332 pts)]]></title>
            <link>https://steelph0enix.github.io/posts/llama-cpp-guide/</link>
            <guid>42274489</guid>
            <pubDate>Fri, 29 Nov 2024 15:28:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://steelph0enix.github.io/posts/llama-cpp-guide/">https://steelph0enix.github.io/posts/llama-cpp-guide/</a>, See on <a href="https://news.ycombinator.com/item?id=42274489">Hacker News</a></p>
Couldn't get https://steelph0enix.github.io/posts/llama-cpp-guide/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[PR process killing morale and productivity (104 pts)]]></title>
            <link>https://blackentropy.com/your-pr-process-is-killing-morale-and-productivity/</link>
            <guid>42274003</guid>
            <pubDate>Fri, 29 Nov 2024 14:14:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blackentropy.com/your-pr-process-is-killing-morale-and-productivity/">https://blackentropy.com/your-pr-process-is-killing-morale-and-productivity/</a>, See on <a href="https://news.ycombinator.com/item?id=42274003">Hacker News</a></p>
<div id="readability-page-1" class="page">
  
  <header>
    <a href="https://blackentropy.com/">
      <h2>
        _blackentropy
      </h2>
    </a>
    <nav>
      <p><a href="https://blackentropy.com/">About</a> <a href="https://blackentropy.com/blog/">Blog</a></p>

    </nav>
  </header>
  <main>
    

    
        
    

    
        

        <p>
            <i>
                <time datetime="2024-11-29T13:12Z">
                    29 Nov, 2024
                </time>
            </i>
        </p>
    

    <p>Code reviews are supposed to be about improving code quality and sharing knowledge, but when PR comments start hitting the hundreds, something is very wrong. I’ve recently come across a discussion where a new developer joined a team and faced over <strong>300 PR comments</strong> on their first contribution. Most of it was stylistic nitpicking. This isn’t just unproductive, it’s outright toxic.</p>
<hr>
<h2 id="why-this-happens">Why This Happens</h2><ol>
<li><p><strong>You’re Not Using Linters or Auto-Formatters</strong><br>
If your team is still arguing over spacing, naming conventions, or line length, you’re wasting everyone’s time. Tools like <code>Prettier</code>, <code>ESLint</code>, or <code>Black</code> exist for a reason. Not automating this is borderline malpractice in modern development.</p>
</li>
<li><p><strong>Your Team Has a "Style Over Substance" Obsession</strong><br>
PR reviews are about catching bugs and improving maintainability, not enforcing arbitrary style rules that aren't documented or standardized. If your team cares more about renaming variables than functional design, your priorities are upside down.</p>
</li>
<li><p><strong>Metrics Gone Wild</strong><br>
It’s alarming how often management incentivizes the wrong things. If PR comments are being used as a performance metric, you’re inviting pointless comments that add zero value. Quality &gt; quantity, always.</p>
</li>
<li><p><strong>Toxic Culture</strong><br>
Let’s call it what it is: some teams use code reviews as a power play. Picking apart trivialities doesn’t make your team “high quality”; it makes them unapproachable. Worse, it alienates newer members and kills morale.</p>
</li>
</ol>
<hr>
<h2 id="what-needs-to-change">What Needs to Change</h2><ol>
<li><p><strong>Automate the Trivial Stuff</strong><br>
Use linters and auto-formatters to eliminate 90% of style debates. If it can be automated, it’s not worth discussing in a review.</p>
</li>
<li><p><strong>Focus on What Matters</strong><br>
PR reviews should focus on functionality, maintainability, and architecture—not spacing or whether a function is “too long.” Teach your team to look at the big picture.</p>
</li>
<li><p><strong>Define (and Stick To) a Style Guide</strong><br>
If you really care about code style, write it down and agree on it as a team. Then enforce it with tools, not through endless PR debates.</p>
</li>
<li><p><strong>Measure the Right Things</strong><br>
Stop rewarding pointless activity. Instead of tracking PR comments, focus on metrics like reduced bugs, faster deployment times, or team satisfaction.</p>
</li>
</ol>
<hr>
<h2 id="stop-wasting-everyones-time">Stop Wasting Everyone’s Time</h2><p>Hundreds of comments on a PR are a <strong>red flag</strong>, not a badge of honor. It means your process is broken. Fix the culture, fix the tooling, and focus on what actually matters: shipping high-quality, maintainable software. Anything else is just noise.</p>


    

    
        

        
            


        
    


  </main>
  

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Core copyright violation moves ahead in The Intercept's lawsuit against OpenAI (238 pts)]]></title>
            <link>https://www.niemanlab.org/2024/11/copyright-claim-moves-ahead-in-the-intercepts-lawsuit-against-openai/</link>
            <guid>42273817</guid>
            <pubDate>Fri, 29 Nov 2024 13:48:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.niemanlab.org/2024/11/copyright-claim-moves-ahead-in-the-intercepts-lawsuit-against-openai/">https://www.niemanlab.org/2024/11/copyright-claim-moves-ahead-in-the-intercepts-lawsuit-against-openai/</a>, See on <a href="https://news.ycombinator.com/item?id=42273817">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Nov.  27, 2024, 11:19 a.m.</p><p>The ruling comes after a judge dismissed similar claims filed by Raw Story and AlterNet earlier this month.</p><div id="content_div-233168">


<p>Last week, a <a href="https://storage.courtlistener.com/recap/gov.uscourts.nysd.616536/gov.uscourts.nysd.616536.122.0.pdf">New York federal judge ruled</a> a key copyright violation claim by The Intercept against OpenAI would move ahead in court. The ruling is the latest in a series of major legal decisions involving the AI developer this month, after OpenAI sought to dismiss lawsuits from several digital news publishers.</p>
<p>Judge Jed Rakoff said he’d hear the claim that OpenAI <a href="https://www.law.cornell.edu/uscode/text/17/1202#:~:text=(b)Removal,management%20information%2C">removed authorship information</a> when it allegedly fed The Intercept’s articles into the training data sets it used to build ChatGPT. Doing so could be a violation of the <a href="https://www.copyright.gov/dmca/">Digital Millennium Copyright Act (DMCA)</a>, a 1998 law that, among other protections, makes it illegal to remove the author name, usage terms, or title from a digital work.</p>
<p>The judge dismissed The Intercept’s claim that OpenAI had <a href="https://www.law.cornell.edu/uscode/text/17/1202#:~:text=(3)distribute%2C%20import%20for%20distribution%2C%20or%20publicly%20perform%20works%2C%20copies%20of%20works%2C%20or%20phonorecords%2C%20knowing%20that%20copyright%20management%20information%20has%20been%20removed%20or%20altered%20without%20authority%20of%20the%20copyright%20owner%20or%20the%20law%2C">knowingly distributed copies</a> of its articles after removing the DMCA-protected information. The judge also dismissed all The Intercept’s claims against Microsoft, which has a <a href="https://www.cnbc.com/2024/10/30/microsoft-cfo-says-openai-investment-will-cut-into-profit-this-quarter.html">multibillion-dollar</a> investment in OpenAI and was named in the initial filing. An opinion from the judge, laying out his reasoning for the dismissals, will be published in the coming weeks.</p>
<p>“The decision allows for a DMCA claim on behalf of digital publishers who do not have copyright registrations to proceed against OpenAI,” said <a href="https://www.loevy.com/attorneys/matt-topic/">Matt Topic</a>, a partner at Loevy &amp; Loevy, who is representing The Intercept. “We’re obviously disappointed to lose the claims against Microsoft, but the core claim is the DMCA claim against OpenAI, and we’re very happy to see that that will be going forward.”</p>
<p>“Our models are trained on publicly available data, grounded in fair use and related principles that we view as fair for creators,” OpenAI spokesperson Jason Deutrom said in a statement.</p>
<p>Earlier this year <a href="https://www.niemanlab.org/2024/03/the-intercept-charts-a-new-legal-strategy-for-digital-publishers-suing-openai/">I reported</a> that The Intercept’s case was carving out a new legal strategy for digital news publishers to sue OpenAI.</p>
<p>The New York Times’ lawsuit against OpenAI, and similar suits filed by <a href="https://www.nydailynews.com/2024/04/30/daily-news-sues-microsoft-open-ai-artifcial-intelligence-federal-court/">The New York Daily News</a> and <a href="https://revealnews.org/press/cir-sues-openai/">Mother Jones</a>, lead with claims of copyright infringement. Infringement suits require that relevant works were first registered with the U.S. Copyright Office (USCO). But most digital news publishers don’t have their article archives registered. For many, The Intercept included, filing all of their published work on the internet with the USCO is too costly or burdensome.</p>
<p>Until this summer, the government body required each individual website article page be filed and charged separately. In August, though, the USCO <a href="https://www.govinfo.gov/content/pkg/FR-2024-07-22/pdf/2024-15880.pdf">added a rule</a> that allows “news websites” to file articles in bulk. Among other reasons, the decision cited concerns about unchecked infringement of online news content and a hope for copyright registrations to stay “adaptive to technological changes.” But for most digital news publishers seeking legal action against OpenAI, particularly for its use of their work to train ChatGPT, the new rule came too late.</p>
<p>For now, The Intercept case is the only litigation by a news publisher, that is not tied to copyright infringement, to move past the motion-to-dismiss stage.</p>
<p>Earlier this month, the DMCA-focused legal strategy <a href="https://www.wired.com/story/opena-alternet-raw-story-copyright-lawsuit-dmca-standing/">took a major hit</a> when another New York federal judge dismissed all DMCA claims against OpenAI filed by Raw Story and AlterNet. The progressive digital news sites are jointly represented by Loevy &amp; Loevy.</p>
<p>“Let us be clear about what is really at stake here. The alleged injury for which Plaintiffs truly seek redress is not the exclusion of [content management information] from Defendants’ training sets, but rather Defendants’ use of Plaintiffs’ articles to develop ChatGPT without compensation,” wrote Judge Colleen MacMahon <a href="https://www.bloomberglaw.com/public/desktop/document/RawStoryMediaIncetalvOpenAIIncetalDocketNo124cv01514SDNYFeb282024/4?doc_id=X18AGVQ2BEU9DCBFDQULD4SNTVV">in that decision</a>.</p>
<p>Despite the setback, the judge said she would consider an amended complaint against OpenAI that took into account her concerns. A proposed amended complaint by Raw Story and AlterNet was filed by Loevy &amp; Loevy last week, just before The Intercept ruling was announced.</p>
<p>“When they populated their training sets with works of journalism, Defendants had a choice: they could train ChatGPT using works of journalism with the copyright management information protected by the DMCA intact, or they could strip it away. Defendants chose the latter,” reads the <a href="https://www.courtlistener.com/docket/68290709/119/1/raw-story-media-inc-v-openai-inc/">proposed amended complaint</a>. “In the process, [OpenAI] trained ChatGPT not to acknowledge or respect copyright, not to notify ChatGPT users when the responses they received were protected by journalists’ copyrights, and not to provide attribution when using the works of human journalists.”</p>
<p>Like The Intercept, Raw Story and AlterNet are asking for $2,500 in damages for each instance that OpenAI allegedly removed DMCA-protected information in its training data sets. If damages are calculated based on each individual article allegedly used to train ChatGPT, it could quickly balloon to tens of thousands of violations.</p>
<p>“The proposed amended complaint would match up and probably even go beyond the allegations that survived in The Intercept case,” said Topic. “Different judges could come out differently on the same question, but we feel optimistic that we will have the opportunity to proceed with an amended claim.”</p>
<p>It is unclear if the Intercept ruling will embolden other publications to consider DMCA litigation; few publications have followed in their footsteps so far. As time goes on, there is concern that new suits against OpenAI would be vulnerable to statute of limitations restrictions, particularly if news publishers want to cite the training data sets underlying ChatGPT. But the ruling is one signal that Loevy &amp; Loevy is narrowing in on a specific DMCA claim that can actually stand up in court.</p>
<p>“We do think that the claim that has survived for The Intercept is a claim that most digital publishers would also be able to bring,” said Topic.</p>
<p>Unsplash</p>







<p><a href="https://www.niemanlab.org/author/adeck">Andrew Deck</a> is a generative AI staff writer at Nieman Lab. Have tips about how AI is being used in your newsroom? You can reach Andrew via <a href="mailto:andrew_deck@harvard.edu">email</a> (andrew_deck@harvard.edu), <a href="https://twitter.com/decka227">Twitter</a> (@decka227), or Signal (+1 203-841-6241).</p>





















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Alibaba releases an 'open' challenger to OpenAI's O1 reasoning model (120 pts)]]></title>
            <link>https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/</link>
            <guid>42273780</guid>
            <pubDate>Fri, 29 Nov 2024 13:40:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/">https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/</a>, See on <a href="https://news.ycombinator.com/item?id=42273780">Hacker News</a></p>
Couldn't get https://techcrunch.com/2024/11/27/alibaba-releases-an-open-challenger-to-openais-o1-reasoning-model/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Fuck with Scroll (359 pts)]]></title>
            <link>https://dontfuckwithscroll.com</link>
            <guid>42273505</guid>
            <pubDate>Fri, 29 Nov 2024 12:52:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dontfuckwithscroll.com">https://dontfuckwithscroll.com</a>, See on <a href="https://news.ycombinator.com/item?id=42273505">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Momentum (aka. smooth or interia) scrolling plugins (example <a href="https://dontfuckwithscroll.com/smooth.html">here</a>), while marketed as enhancements, are a plague upon the internet. They disrupt the natural, efficient, and predictable web browsing experience in countless ways, by they often degrading usability, accessibility, and performance. Here are ten reasons why they ruin the web for everyone.</p><div>
    <li>
      <h2>Violates User Expectations</h2>
      <p>Users know how scrolling works. It's been the same since the dawn of the web: you scroll, content moves. Momentum scrolling plugins hijack this fundamental behavior. Instead of instant and predictable movement, users get some bizarrely animated experience that feels more like playing a bad video game. Muscle memory? Tossed out the window. It's like giving people a steering wheel in a car and making it turn the opposite direction—just for kicks.</p>
      <p><strong>Impact:</strong> This disrupts muscle memory and established habits, which users rely on for efficient navigation. The experience feels artificial and clunky, making users feel like they're fighting against the page instead of interacting with it naturally.</p>
    </li>

    <li>
      <h2>Causes Motion Sickness</h2>
      <p>Not everyone wants a theme-park ride when reading an article. Momentum scrolling plugins introduce floaty, swoopy animations that feel like watching a shaky cam on repeat. Users prone to motion sickness or vertigo (and there are more than you think) can't handle these unnecessary flourishes. What's worse, many sites don't even offer an option to turn it off, leaving people stuck feeling queasy just trying to read your blog post.</p>
      <p><strong>Impact:</strong> Users prone to motion sickness or vertigo may find the website literally nauseating to use. Is your content so unimportant that you'd rather users leave than scroll down? Probably not.</p>
    </li>

    <li>
      <h2>Reduces Accessibility for Disabled Users</h2>
      <p>Web accessibility is a right, not an optional feature. Momentum scrolling plugins laugh in the face of inclusivity. They disrupt assistive technologies like screen readers and keyboard navigation by introducing timing delays. For users with disabilities, such as motor impairments or visual limitations, these delays can render a site unusable. A feature that excludes millions of users isn't a feature—it's a flaw.</p>
      <p><strong>Impact:</strong> Users with disabilities may struggle to interact with the site. Do you really want to alienate an entire demographic just to make scrolling look a little fancier? Accessibility isn't optional—it's a baseline requirement.</p>
    </li>

    <li>
      <h2>Inconsistent Performance Across Devices</h2>
      <p>Momentum scrolling plugins don't care if you're on a state-of-the-art gaming rig or a five-year-old budget phone. They load JavaScript that can lag, stutter, or outright break on older or lower-end devices. Why make your website cater only to people with perfect hardware? The web is supposed to work for everyone, not just the ones who can afford shiny new gadgets every year.</p>
      <p><strong>Impact:</strong> Instead of feeling "Momentum," the page feels broken on weaker devices. Great job—now you've ensured your site only works properly for people with high-end tech. Good UX means working for everyone, not just the rich.</p>
    </li>

    <li>
      <h2>Impairs Usability for Power Users</h2>
      <p>Power users exist. They're the ones who zoom through documentation, rapidly scroll through pages, and want precision. Momentum scrolling spits in their faces. It slows down their workflow by forcing them to endure molasses-like animations. They're not here for your slow, cutesy effects—they're here to get things done. Stop standing in their way. It's like making a racecar driver go 20 mph because it "looks prettier."</p>
      <p><strong>Impact:</strong> These users will hate your site. And let's be clear, power users are often the ones most likely to recommend or share content. Do you really want to alienate your most enthusiastic audience?</p>
    </li>

    <li>
      <h2>Increases Page Load Times</h2>
      <p>Momentum scrolling plugins add bloated JavaScript libraries, extra dependencies, and more CPU cycles to render animations. Guess what? That comes at a cost.</p>
      <p><strong>Impact:</strong> Slower load times annoy everyone. On mobile networks, especially in areas with poor connectivity, your fancy scrolling makes the page slower and less accessible. Congrats, you've sacrificed performance for aesthetics.</p>
    </li>

    <li>
      <h2>Breaks Native Browser Features</h2>
      <p>Modern browsers already include Momentum scrolling settings for users who want them. Adding third-party plugins often overrides or conflicts with these native features, breaking custom scroll gestures or momentum scrolling.</p>
      <p><strong>Impact:</strong> Your site ends up less functional than the browser it's displayed in. Users who expect their preferences to work (e.g., system-wide reduced motion settings) will feel betrayed. You just took something that worked and made it worse.</p>
    </li>

    <li>
      <h2>Makes Scroll Position Unclear</h2>
      <p>Momentum scrolling animations introduce a delay between action and result, making it hard to tell exactly where you are on the page. Combine this with long pages, and users are left feeling lost.</p>
      <p><strong>Impact:</strong> Users now spend extra time figuring out their position. Nobody likes a website that feels like a guessing game. Quick navigation becomes a chore instead of a feature. Great job, you just turned scrolling into a problem.</p>
    </li>

    <li>
      <h2>Adds Maintenance Overhead</h2>
      <p>Momentum scrolling plugins aren't "set it and forget it." They need regular updates to stay compatible with modern browsers, operating systems, and devices. And every update risks introducing new bugs.</p>
      <p><strong>Impact:</strong> You've now created extra work for your development team, all for a feature nobody really asked for. That's time and money that could've been spent making your site faster, more secure, or better optimized. But sure, keep chasing that "Momentum" scroll.</p>
    </li>

    <li>
      <h2>Disrespects the User's Control</h2>
      <p>Users come to your website for content, not for an overly choreographed scrolling experience. Overriding default scrolling assumes your vision of scrolling is better than the user's preferences or needs.</p>
      <p><strong>Impact:</strong> By enforcing Momentum scrolling, you're essentially telling users: "We know better than you." That arrogance doesn't go unnoticed. Respect your users' autonomy—don't dictate how they interact with your site.</p>
    </li>
  </div><p>Momentum scrolling plugins are the web equivalent of turning a functional bike into a unicycle because it "looks cool." It adds unnecessary complexity, degrades usability, and frustrates users. Instead of reinventing scrolling, stick to what works: native, predictable, fast scrolling behavior.</p><p>Don't make scrolling a thing. Just let people scroll.</p><p>And if you're still not convinced, go to the <a href="https://dontfuckwithscroll.com/smooth.html">smooth version</a> and try to tell me it's better.</p></div>]]></description>
        </item>
    </channel>
</rss>