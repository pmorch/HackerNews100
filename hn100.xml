<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Fri, 20 Jun 2025 09:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hurl: Run and test HTTP requests with plain text (168 pts)]]></title>
            <link>https://github.com/Orange-OpenSource/hurl</link>
            <guid>44324592</guid>
            <pubDate>Fri, 20 Jun 2025 03:55:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Orange-OpenSource/hurl">https://github.com/Orange-OpenSource/hurl</a>, See on <a href="https://news.ycombinator.com/item?id=44324592">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true"> 
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-dark.svg?sanitize=true"> 
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/logo-light.svg?sanitize=true" width="264px" alt="Hurl Logo">
</picture></themed-picture>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/actions"><img src="https://github.com/Orange-OpenSource/hurl/workflows/test/badge.svg" alt="deploy status"></a>
<a href="https://orange-opensource.github.io/hurl/coverage" rel="nofollow"><img src="https://camo.githubusercontent.com/19edc85a2bb776555d2d2ed00e86d9926f7c0befd6339b768874bc7c866eaaa4/68747470733a2f2f4f72616e67652d4f70656e536f757263652e6769746875622e696f2f6875726c2f636f7665726167652f6261646765732f666c61742e737667" alt="coverage" data-canonical-src="https://Orange-OpenSource.github.io/hurl/coverage/badges/flat.svg"></a>
<a href="https://crates.io/crates/hurl" rel="nofollow"><img src="https://camo.githubusercontent.com/9b74b944af9e26d5adb9d2f853bb93c53c45d75f888cabc4d3406fa838b813fa/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f6875726c2e737667" alt="Crates.io" data-canonical-src="https://img.shields.io/crates/v/hurl.svg"></a>
<a href="https://hurl.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/d78580786d47c7d5ecc3d261edae2f60c95978e25086984df45588f4a1214929/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2d646f63756d656e746174696f6e2d666630323838" alt="documentation" data-canonical-src="https://img.shields.io/badge/-documentation-ff0288"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What's Hurl?</h2><a id="user-content-whats-hurl" aria-label="Permalink: What's Hurl?" href="#whats-hurl"></a></p>
<p dir="auto">Hurl is a command line tool that runs <b>HTTP requests</b> defined in a simple <b>plain text format</b>.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very
versatile: it can be used for both <b>fetching data</b> and <b>testing HTTP</b> sessions.</p>
<p dir="auto">Hurl makes it easy to work with <b>HTML</b> content, <b>REST / SOAP / GraphQL</b> APIs, or any other <b>XML / JSON</b> based APIs.</p>
<div data-snippet-clipboard-copy-content="# Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code># Get home:
GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


# Do login!
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto">Chaining multiple requests is easy:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3"><pre lang="hurl"><code>GET https://example.org/api/health
GET https://example.org/api/step1
GET https://example.org/api/step2
GET https://example.org/api/step3
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Also an HTTP Test Tool</h2><a id="user-content-also-an-http-test-tool" aria-label="Permalink: Also an HTTP Test Tool" href="#also-an-http-test-tool"></a></p>
<p dir="auto">Hurl can run HTTP requests but can also be used to <b>test HTTP responses</b>.
Different types of queries and predicates are supported, from <a href="https://en.wikipedia.org/wiki/XPath" rel="nofollow">XPath</a> and <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a> on body response,
to assert on status code and response headers.</p>
<p dir="auto"><a href="https://hurl.dev/player.html?id=starwars&amp;speed=3" rel="nofollow"><img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/poster-starwars.png" width="100%" alt="Hurl Demo"></a></p>
<p dir="auto">It is well adapted for <b>REST / JSON APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;4568&quot;,
    &quot;evaluate&quot;: true
}
HTTP 200
[Asserts]
header &quot;X-Frame-Options&quot; == &quot;SAMEORIGIN&quot;
jsonpath &quot;$.status&quot; == &quot;RUNNING&quot;    # Check the status code
jsonpath &quot;$.tests&quot; count == 25      # Check the number of items
jsonpath &quot;$.id&quot; matches /\d{4}/     # Check the format of the id"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "4568",
    "evaluate": true
}
HTTP 200
[Asserts]
header "X-Frame-Options" == "SAMEORIGIN"
jsonpath "$.status" == "RUNNING"    # Check the status code
jsonpath "$.tests" count == 25      # Check the number of items
jsonpath "$.id" matches /\d{4}/     # Check the format of the id
</code></pre></div>
<p dir="auto"><b>HTML content</b></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
xpath &quot;normalize-space(//head/title)&quot; == &quot;Hello world!&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
xpath "normalize-space(//head/title)" == "Hello world!"
</code></pre></div>
<p dir="auto"><b>GraphQL</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200"><pre lang="hurl"><code>POST https://example.org/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
HTTP 200
</code></pre></div>
<p dir="auto">and even <b>SOAP APIs</b></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto">Hurl can also be used to test the <b>performance</b> of HTTP endpoints</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration < 1000  # Duration in ms"><pre lang="hurl"><code>GET https://example.org/api/v1/pets
HTTP 200
[Asserts]
duration &lt; 1000  # Duration in ms
</code></pre></div>
<p dir="auto">And check response bytes</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto">Finally, Hurl is easy to <b>integrate in CI/CD</b>, with text, JUnit, TAP and HTML reports</p>
<themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png">
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-dark.png">
    <img src="https://github.com/Orange-OpenSource/hurl/raw/master/docs/assets/img/home-waterfall-light.png" width="480" alt="HTML report">
</picture></themed-picture>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why Hurl?</h2><a id="user-content-why-hurl" aria-label="Permalink: Why Hurl?" href="#why-hurl"></a></p>
<ul dir="auto">
    <li><b>Text Format:</b> for both devops and developers</li>
    <li><b>Fast CLI:</b> a command line for local dev and continuous integration</li>
    <li><b>Single Binary:</b> easy to install, with no runtime required</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Powered by curl</h2><a id="user-content-powered-by-curl" aria-label="Permalink: Powered by curl" href="#powered-by-curl"></a></p>
<p dir="auto">Hurl is a lightweight binary written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. Under the hood, Hurl HTTP engine is
powered by <a href="https://curl.se/libcurl/" rel="nofollow">libcurl</a>, one of the most powerful and reliable file transfer libraries.
With its text file format, Hurl adds syntactic sugar to run and test HTTP requests,
but it's still the <a href="https://curl.se/" rel="nofollow">curl</a> that we love: <strong>fast</strong>, <strong>efficient</strong> and <strong>IPv6 / HTTP/3 ready</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedbacks</h2><a id="user-content-feedbacks" aria-label="Permalink: Feedbacks" href="#feedbacks"></a></p>
<p dir="auto">To support its development, <a href="https://github.com/Orange-OpenSource/hurl/stargazers">star Hurl on GitHub</a>!</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl/issues">Feedback, suggestion, bugs or improvements</a> are welcome.</p>
<div data-snippet-clipboard-copy-content="POST https://hurl.dev/api/feedback
{
  &quot;name&quot;: &quot;John Doe&quot;,
  &quot;feedback&quot;: &quot;Hurl is awesome!&quot;
}
HTTP 200"><pre lang="hurl"><code>POST https://hurl.dev/api/feedback
{
  "name": "John Doe",
  "feedback": "Hurl is awesome!"
}
HTTP 200
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Resources</h2><a id="user-content-resources" aria-label="Permalink: Resources" href="#resources"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/license.html" rel="nofollow">License</a></p>
<p dir="auto"><a href="https://hurl.dev/blog/" rel="nofollow">Blog</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/tutorial/your-first-hurl-file.html" rel="nofollow">Tutorial</a></p>
<p dir="auto"><a href="https://hurl.dev/docs/installation.html" rel="nofollow">Documentation</a> (download <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.html">HTML</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.pdf">PDF</a>, <a href="https://github.com/Orange-OpenSource/hurl/blob/master/docs/standalone/hurl-6.1.0.md">Markdown</a>)</p>
<p dir="auto"><a href="https://github.com/Orange-OpenSource/hurl">GitHub</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#samples">Samples</a>
<ul dir="auto">
<li><a href="#getting-data">Getting Data</a>
<ul dir="auto">
<li><a href="#http-headers">HTTP Headers</a></li>
<li><a href="#query-params">Query Params</a></li>
<li><a href="#basic-authentication">Basic Authentication</a></li>
<li><a href="#passing-data-between-requests">Passing Data between Requests </a></li>
</ul>
</li>
<li><a href="#sending-data">Sending Data</a>
<ul dir="auto">
<li><a href="#sending-html-form-data">Sending HTML Form Data</a></li>
<li><a href="#sending-multipart-form-data">Sending Multipart Form Data</a></li>
<li><a href="#posting-a-json-body">Posting a JSON Body</a></li>
<li><a href="#templating-a-json-body">Templating a JSON Body</a></li>
<li><a href="#templating-a-xml-body">Templating a XML Body</a></li>
<li><a href="#using-graphql-query">Using GraphQL Query</a></li>
<li><a href="#using-dynamic-datas">Using Dynamic Datas</a></li>
</ul>
</li>
<li><a href="#testing-response">Testing Response</a>
<ul dir="auto">
<li><a href="#testing-status-code">Testing Status Code</a></li>
<li><a href="#testing-response-headers">Testing Response Headers</a></li>
<li><a href="#testing-rest-apis">Testing REST APIs</a></li>
<li><a href="#testing-html-response">Testing HTML Response</a></li>
<li><a href="#testing-set-cookie-attributes">Testing Set-Cookie Attributes</a></li>
<li><a href="#testing-bytes-content">Testing Bytes Content</a></li>
<li><a href="#ssl-certificate">SSL Certificate</a></li>
<li><a href="#checking-full-body">Checking Full Body</a></li>
</ul>
</li>
<li><a href="#reports">Reports</a>
<ul dir="auto">
<li><a href="#html-report">HTML Report</a></li>
<li><a href="#json-report">JSON Report</a></li>
<li><a href="#junit-report">JUnit Report</a></li>
<li><a href="#tap-report">TAP Report</a></li>
<li><a href="#json-output">JSON Output</a></li>
</ul>
</li>
<li><a href="#others">Others</a>
<ul dir="auto">
<li><a href="#http-version">HTTP Version</a></li>
<li><a href="#ip-address">IP Address</a></li>
<li><a href="#polling-and-retry">Polling and Retry</a></li>
<li><a href="#delaying-requests">Delaying Requests</a></li>
<li><a href="#skipping-requests">Skipping Requests</a></li>
<li><a href="#testing-endpoint-performance">Testing Endpoint Performance</a></li>
<li><a href="#using-soap-apis">Using SOAP APIs</a></li>
<li><a href="#capturing-and-using-a-csrf-token">Capturing and Using a CSRF Token</a></li>
<li><a href="#redacting-secrets">Redacting Secrets</a></li>
<li><a href="#checking-byte-order-mark-bom-in-response-body">Checking Byte Order Mark (BOM) in Response Body</a></li>
<li><a href="#aws-signature-version-4-requests">AWS Signature Version 4 Requests</a></li>
<li><a href="#using-curl-options">Using curl Options</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#manual">Manual</a>
<ul dir="auto">
<li><a href="#name">Name</a></li>
<li><a href="#synopsis">Synopsis</a></li>
<li><a href="#description">Description</a></li>
<li><a href="#hurl-file-format">Hurl File Format</a>
<ul dir="auto">
<li><a href="#capturing-values">Capturing values</a></li>
<li><a href="#asserts">Asserts</a></li>
</ul>
</li>
<li><a href="#options">Options</a></li>
<li><a href="#environment">Environment</a></li>
<li><a href="#exit-codes">Exit Codes</a></li>
<li><a href="#www">WWW</a></li>
<li><a href="#see-also">See Also</a></li>
</ul>
</li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#binaries-installation">Binaries Installation</a>
<ul dir="auto">
<li><a href="#linux">Linux</a>
<ul dir="auto">
<li><a href="#debian--ubuntu">Debian / Ubuntu</a></li>
<li><a href="#alpine">Alpine</a></li>
<li><a href="#arch-linux--manjaro">Arch Linux / Manjaro</a></li>
<li><a href="#nixos--nix">NixOS / Nix</a></li>
</ul>
</li>
<li><a href="#macos">macOS</a>
<ul dir="auto">
<li><a href="#homebrew">Homebrew</a></li>
<li><a href="#macports">MacPorts</a></li>
</ul>
</li>
<li><a href="#freebsd">FreeBSD</a></li>
<li><a href="#windows">Windows</a>
<ul dir="auto">
<li><a href="#zip-file">Zip File</a></li>
<li><a href="#installer">Installer</a></li>
<li><a href="#chocolatey">Chocolatey</a></li>
<li><a href="#scoop">Scoop</a></li>
<li><a href="#windows-package-manager">Windows Package Manager</a></li>
</ul>
</li>
<li><a href="#cargo">Cargo</a></li>
<li><a href="#conda-forge">conda-forge</a></li>
<li><a href="#docker">Docker</a></li>
<li><a href="#npm">npm</a></li>
</ul>
</li>
<li><a href="#building-from-sources">Building From Sources</a>
<ul dir="auto">
<li><a href="#build-on-linux">Build on Linux</a>
<ul dir="auto">
<li><a href="#debian-based-distributions">Debian based distributions</a></li>
<li><a href="#fedora-based-distributions">Fedora based distributions</a></li>
<li><a href="#red-hat-based-distributions">Red Hat based distributions</a></li>
<li><a href="#arch-based-distributions">Arch based distributions</a></li>
<li><a href="#alpine-based-distributions">Alpine based distributions</a></li>
</ul>
</li>
<li><a href="#build-on-macos">Build on macOS</a></li>
<li><a href="#build-on-windows">Build on Windows</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Samples</h2><a id="user-content-samples" aria-label="Permalink: Samples" href="#samples"></a></p>
<p dir="auto">To run a sample, edit a file with the sample content, and run Hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl"><pre>$ vi sample.hurl

GET https://example.org

$ hurl sample.hurl</pre></div>
<p dir="auto">By default, Hurl behaves like <a href="https://curl.se/" rel="nofollow">curl</a> and outputs the last HTTP response's <a href="https://hurl.dev/docs/entry.html" rel="nofollow">entry</a>. To have a test
oriented output, you can use <a href="https://hurl.dev/docs/manual.html#test" rel="nofollow"><code>--test</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test sample.hurl"><pre>$ hurl --test sample.hurl</pre></div>
<p dir="auto">A particular response can be saved with <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options] section</code></a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200"><pre lang="hurl"><code>GET https://example.ord/cats/123
[Options]
output: cat123.txt    # use - to output to stdout
HTTP 200

GET https://example.ord/dogs/567
HTTP 200
</code></pre></div>
<p dir="auto">Finally, Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test integration/*.hurl
$ hurl --test ."><pre>$ hurl --test integration/<span>*</span>.hurl
$ hurl --test <span>.</span></pre></div>
<p dir="auto">You can check <a href="https://github.com/Orange-OpenSource/hurl/tree/master/integration/hurl/tests_ok">Hurl tests suite</a> for more samples.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Data</h2><a id="user-content-getting-data" aria-label="Permalink: Getting Data" href="#getting-data"></a></p>
<p dir="auto">A simple GET:</p>

<p dir="auto">Requests can be chained:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c"><pre lang="hurl"><code>GET https://example.org/a
GET https://example.org/b
HEAD https://example.org/c
GET https://example.org/c
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#method" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Headers</h3><a id="user-content-http-headers" aria-label="Permalink: HTTP Headers" href="#http-headers"></a></p>
<p dir="auto">A simple GET with headers:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive"><pre lang="hurl"><code>GET https://example.org/news
User-Agent: Mozilla/5.0 
Accept: */*
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Query Params</h3><a id="user-content-query-params" aria-label="Permalink: Query Params" href="#query-params"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100"><pre lang="hurl"><code>GET https://example.org/news
[Query]
order: newest
search: something to search
count: 100
</code></pre></div>
<p dir="auto">Or:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100"><pre lang="hurl"><code>GET https://example.org/news?order=newest&amp;search=something%20to%20search&amp;count=100
</code></pre></div>
<blockquote>
<p dir="auto">With <code>[Query]</code> section, params don't need to be URL escaped.</p>
</blockquote>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#query-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Authentication</h3><a id="user-content-basic-authentication" aria-label="Permalink: Basic Authentication" href="#basic-authentication"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/protected
[BasicAuth]
bob: secret"><pre lang="hurl"><code>GET https://example.org/protected
[BasicAuth]
bob: secret
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#basic-authentication" rel="nofollow">Doc</a></p>
<p dir="auto">This is equivalent to construct the request with a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Authorization" rel="nofollow">Authorization</a> header:</p>
<div data-snippet-clipboard-copy-content="# Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== "><pre lang="hurl"><code># Authorization header value can be computed with `echo -n 'bob:secret' | base64`
GET https://example.org/protected
Authorization: Basic Ym9iOnNlY3JldA== 
</code></pre></div>
<p dir="auto">Basic authentication section allows per request authentication. If you want to add basic authentication to all the
requests of a Hurl file you could use <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>-u/--user</code> option</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --user bob:secret login.hurl"><pre>$ hurl --user bob:secret login.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a> option can also be set per request:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200"><pre lang="hurl"><code>GET https://example.org/login
[Options]
user: bob:secret
HTTP 200

GET https://example.org/login
[Options]
user: alice:secret
HTTP 200
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Passing Data between Requests</h3><a id="user-content-passing-data-between-requests" aria-label="Permalink: Passing Data between Requests" href="#passing-data-between-requests"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Captures</a> can be used to pass data from one request to another:</p>
<div data-snippet-clipboard-copy-content="POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath &quot;$.order.id&quot;

GET https://sample.org/orders/{{order_id}}
HTTP 200"><pre lang="hurl"><code>POST https://sample.org/orders
HTTP 201
[Captures]
order_id: jsonpath "$.order.id"

GET https://sample.org/orders/{{order_id}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Sending Data</h2><a id="user-content-sending-data" aria-label="Permalink: Sending Data" href="#sending-data"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending HTML Form Data</h3><a id="user-content-sending-html-form-data" aria-label="Permalink: Sending HTML Form Data" href="#sending-html-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344"><pre lang="hurl"><code>POST https://example.org/contact
[Form]
default: false
token: {{token}}
email: john.doe@rookie.org
number: 33611223344
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#form-parameters" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Sending Multipart Form Data</h3><a id="user-content-sending-multipart-form-data" aria-label="Permalink: Sending Multipart Form Data" href="#sending-multipart-form-data"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip"><pre lang="hurl"><code>POST https://example.org/upload
[Multipart]
field1: value1
field2: file,example.txt;
# One can specify the file content type:
field3: file,example.zip; application/zip
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multipart-form-data" rel="nofollow">Doc</a></p>
<p dir="auto">Multipart forms can also be sent with a <a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">multiline string body</a>:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/upload
Content-Type: multipart/form-data; boundary=&quot;boundary&quot;
```
--boundary
Content-Disposition: form-data; name=&quot;key1&quot;

value1
--boundary
Content-Disposition: form-data; name=&quot;upload1&quot;; filename=&quot;data.txt&quot;
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name=&quot;upload2&quot;; filename=&quot;data.html&quot;
Content-Type: text/html

<div>Hello <b>World</b>!</div>
--boundary--
```"><pre lang="hurl"><code>POST https://example.org/upload
Content-Type: multipart/form-data; boundary="boundary"
```
--boundary
Content-Disposition: form-data; name="key1"

value1
--boundary
Content-Disposition: form-data; name="upload1"; filename="data.txt"
Content-Type: text/plain

Hello World!
--boundary
Content-Disposition: form-data; name="upload2"; filename="data.html"
Content-Type: text/html

&lt;div&gt;Hello &lt;b&gt;World&lt;/b&gt;!&lt;/div&gt;
--boundary--
```
</code></pre></div>
<p dir="auto">In that case, files have to be inlined in the Hurl file.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Posting a JSON Body</h3><a id="user-content-posting-a-json-body" aria-label="Permalink: Posting a JSON Body" href="#posting-a-json-body"></a></p>
<p dir="auto">With an inline JSON:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
{
    &quot;id&quot;: &quot;456&quot;,
    &quot;evaluate&quot;: true
}"><pre lang="hurl"><code>POST https://example.org/api/tests
{
    "id": "456",
    "evaluate": true
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">With a local file:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/tests
Content-Type: application/json
file,data.json;"><pre lang="hurl"><code>POST https://example.org/api/tests
Content-Type: application/json
file,data.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a JSON Body</h3><a id="user-content-templating-a-json-body" aria-label="Permalink: Templating a JSON Body" href="#templating-a-json-body"></a></p>
<div data-snippet-clipboard-copy-content="PUT https://example.org/api/hits
Content-Type: application/json
{
    &quot;key0&quot;: &quot;{{a_string}}&quot;,
    &quot;key1&quot;: {{a_bool}},
    &quot;key2&quot;: {{a_null}},
    &quot;key3&quot;: {{a_number}}
}"><pre lang="hurl"><code>PUT https://example.org/api/hits
Content-Type: application/json
{
    "key0": "{{a_string}}",
    "key1": {{a_bool}},
    "key2": {{a_null}},
    "key3": {{a_number}}
}
</code></pre></div>
<p dir="auto">Variables can be initialized via command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl"><pre>$ hurl --variable a_string=apple \
       --variable a_bool=true \
       --variable a_null=null \
       --variable a_number=42 \
       test.hurl</pre></div>
<p dir="auto">Resulting in a PUT request with the following JSON body:</p>
<div data-snippet-clipboard-copy-content="{
    &quot;key0&quot;: &quot;apple&quot;,
    &quot;key1&quot;: true,
    &quot;key2&quot;: null,
    &quot;key3&quot;: 42
}"><pre><code>{
    "key0": "apple",
    "key1": true,
    "key2": null,
    "key3": 42
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Templating a XML Body</h3><a id="user-content-templating-a-xml-body" aria-label="Permalink: Templating a XML Body" href="#templating-a-xml-body"></a></p>
<p dir="auto">Using templates with <a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">XML body</a> is not currently supported in Hurl. You can use templates in
<a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">XML multiline string body</a> with variables to send a variable XML body:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/echo/post/xml
```xml
<?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?>
<Request>
    <Login>{{login}}</Login>
    <Password>{{password}}</Password>
</Request>
```"><pre lang="hurl"><code>POST https://example.org/echo/post/xml
```xml
&lt;?xml version="1.0" encoding="utf-8"?&gt;
&lt;Request&gt;
    &lt;Login&gt;{{login}}&lt;/Login&gt;
    &lt;Password&gt;{{password}}&lt;/Password&gt;
&lt;/Request&gt;
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using GraphQL Query</h3><a id="user-content-using-graphql-query" aria-label="Permalink: Using GraphQL Query" href="#using-graphql-query"></a></p>
<p dir="auto">A simple GraphQL query:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
{
  human(id: &quot;1000&quot;) {
    name
    height(unit: FOOT)
  }
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
{
  human(id: "1000") {
    name
    height(unit: FOOT)
  }
}
```
</code></pre></div>
<p dir="auto">A GraphQL query with variables:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  &quot;episode&quot;: &quot;JEDI&quot;,
  &quot;withFriends&quot;: false
}
```"><pre lang="hurl"><code>POST https://example.org/starwars/graphql
```graphql
query Hero($episode: Episode, $withFriends: Boolean!) {
  hero(episode: $episode) {
    name
    friends @include(if: $withFriends) {
      name
    }
  }
}

variables {
  "episode": "JEDI",
  "withFriends": false
}
```
</code></pre></div>
<p dir="auto">GraphQL queries can also use <a href="https://hurl.dev/docs/templates.html" rel="nofollow">Hurl templates</a>.</p>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#graphql-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using Dynamic Datas</h3><a id="user-content-using-dynamic-datas" aria-label="Permalink: Using Dynamic Datas" href="#using-dynamic-datas"></a></p>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Functions</a> like <code>newUuid</code> and <code>newDate</code> can be used in templates to create dynamic datas:</p>
<p dir="auto">A file that creates a dynamic email (i.e <code>0531f78f-7f87-44be-a7f2-969a1c4e6d97@test.com</code>):</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/api/foo
{
  &quot;name&quot;: &quot;foo&quot;,
  &quot;email&quot;: &quot;{{newUuid}}@test.com&quot;
}"><pre lang="hurl"><code>POST https://example.org/api/foo
{
  "name": "foo",
  "email": "{{newUuid}}@test.com"
}
</code></pre></div>
<p dir="auto">A file that creates a dynamic query parameter (i.e <code>2024-12-02T10:35:44.461731Z</code>):</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200"><pre lang="hurl"><code>GET https://example.org/api/foo
[Query]
date: {{newDate}}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#functions" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Testing Response</h2><a id="user-content-testing-response" aria-label="Permalink: Testing Response" href="#testing-response"></a></p>
<p dir="auto">Responses are optional, everything after <code>HTTP</code> is part of the response asserts.</p>
<div data-snippet-clipboard-copy-content="# A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;running&quot;"><pre lang="hurl"><code># A request with (almost) no check:
GET https://foo.com

# A status code check:
GET https://foo.com
HTTP 200

# A test on response body
GET https://foo.com
HTTP 200
[Asserts]
jsonpath "$.state" == "running"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Status Code</h3><a id="user-content-testing-status-code" aria-label="Permalink: Testing Status Code" href="#testing-status-code"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
HTTP 200"><pre lang="hurl"><code>GET https://example.org/order/435
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status >= 200
status < 300"><pre lang="hurl"><code>GET https://example.org/order/435
# Testing status code is in a 200-300 range
HTTP *
[Asserts]
status &gt;= 200
status &lt; 300
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#status-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Response Headers</h3><a id="user-content-testing-response-headers" aria-label="Permalink: Testing Response Headers" href="#testing-response-headers"></a></p>
<p dir="auto">Use implicit response asserts to test header values:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#headers" rel="nofollow">Doc</a></p>
<p dir="auto">Or use explicit response asserts with <a href="https://hurl.dev/docs/asserting-response.html#predicates" rel="nofollow">predicates</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 302
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org
HTTP 302
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#header-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit and explicit asserts can be combined:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header &quot;Location&quot; contains &quot;www.example.net&quot;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
Set-Cookie: theme=light
Set-Cookie: sessionToken=abc123; Expires=Wed, 09 Jun 2021 10:18:14 GMT
[Asserts]
header "Location" contains "www.example.net"
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing REST APIs</h3><a id="user-content-testing-rest-apis" aria-label="Permalink: Testing REST APIs" href="#testing-rest-apis"></a></p>
<p dir="auto">Asserting JSON body response (node values, collection count etc...) with <a href="https://goessner.net/articles/JsonPath/" rel="nofollow">JSONPath</a>:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath &quot;$.validated&quot; == true
jsonpath &quot;$.userInfo.firstName&quot; == &quot;Franck&quot;
jsonpath &quot;$.userInfo.lastName&quot; == &quot;Herbert&quot;
jsonpath &quot;$.hasDevice&quot; == false
jsonpath &quot;$.links&quot; count == 12
jsonpath &quot;$.state&quot; != null
jsonpath &quot;$.order&quot; matches &quot;^order-\\d{8}$&quot;
jsonpath &quot;$.order&quot; matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath &quot;$.created&quot; isIsoDate"><pre lang="hurl"><code>GET https://example.org/order
screencapability: low
HTTP 200
[Asserts]
jsonpath "$.validated" == true
jsonpath "$.userInfo.firstName" == "Franck"
jsonpath "$.userInfo.lastName" == "Herbert"
jsonpath "$.hasDevice" == false
jsonpath "$.links" count == 12
jsonpath "$.state" != null
jsonpath "$.order" matches "^order-\\d{8}$"
jsonpath "$.order" matches /^order-\d{8}$/     # Alternative syntax with regex literal
jsonpath "$.created" isIsoDate
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#jsonpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing HTML Response</h3><a id="user-content-testing-html-response" aria-label="Permalink: Testing HTML Response" href="#testing-html-response"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath &quot;string(/html/head/title)&quot; contains &quot;Example&quot; # Check title
xpath &quot;count(//p)&quot; == 2  # Check the number of p
xpath &quot;//p&quot; count == 2  # Similar assert for p
xpath &quot;boolean(count(//h2))&quot; == false  # Check there is no h2  
xpath &quot;//h2&quot; not exists  # Similar assert for h2
xpath &quot;string(//div[1])&quot; matches /Hello.*/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
Content-Type: text/html; charset=UTF-8
[Asserts]
xpath "string(/html/head/title)" contains "Example" # Check title
xpath "count(//p)" == 2  # Check the number of p
xpath "//p" count == 2  # Similar assert for p
xpath "boolean(count(//h2))" == false  # Check there is no h2  
xpath "//h2" not exists  # Similar assert for h2
xpath "string(//div[1])" matches /Hello.*/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xpath-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Set-Cookie Attributes</h3><a id="user-content-testing-set-cookie-attributes" aria-label="Permalink: Testing Set-Cookie Attributes" href="#testing-set-cookie-attributes"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/home
HTTP 200
[Asserts]
cookie &quot;JSESSIONID&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Value]&quot; == &quot;8400BAFE2F66443613DC38AE3D9D6239&quot;
cookie &quot;JSESSIONID[Expires]&quot; contains &quot;Wed, 13 Jan 2021&quot;
cookie &quot;JSESSIONID[Secure]&quot; exists
cookie &quot;JSESSIONID[HttpOnly]&quot; exists
cookie &quot;JSESSIONID[SameSite]&quot; == &quot;Lax&quot;"><pre lang="hurl"><code>GET https://example.org/home
HTTP 200
[Asserts]
cookie "JSESSIONID" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Value]" == "8400BAFE2F66443613DC38AE3D9D6239"
cookie "JSESSIONID[Expires]" contains "Wed, 13 Jan 2021"
cookie "JSESSIONID[Secure]" exists
cookie "JSESSIONID[HttpOnly]" exists
cookie "JSESSIONID[SameSite]" == "Lax"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#cookie-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Bytes Content</h3><a id="user-content-testing-bytes-content" aria-label="Permalink: Testing Bytes Content" href="#testing-bytes-content"></a></p>
<p dir="auto">Check the SHA-256 response body hash:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;"><pre lang="hurl"><code>GET https://example.org/data.tar.gz
HTTP 200
[Asserts]
sha256 == hex,039058c6f2c0cb492c533b0a4d14ef77cc0f78abccced5287d84a1a2011cfb81;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#sha-256-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">SSL Certificate</h3><a id="user-content-ssl-certificate" aria-label="Permalink: SSL Certificate" href="#ssl-certificate"></a></p>
<p dir="auto">Check the properties of a SSL certificate:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Asserts]
certificate &quot;Subject&quot; == &quot;CN=example.org&quot;
certificate &quot;Issuer&quot; == &quot;C=US, O=Let's Encrypt, CN=R3&quot;
certificate &quot;Expire-Date&quot; daysAfterNow > 15
certificate &quot;Serial-Number&quot; matches /[\da-f]+/"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Asserts]
certificate "Subject" == "CN=example.org"
certificate "Issuer" == "C=US, O=Let's Encrypt, CN=R3"
certificate "Expire-Date" daysAfterNow &gt; 15
certificate "Serial-Number" matches /[\da-f]+/
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#ssl-certificate-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Full Body</h3><a id="user-content-checking-full-body" aria-label="Permalink: Checking Full Body" href="#checking-full-body"></a></p>
<p dir="auto">Use implicit body to test an exact JSON body match:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/cats/123
HTTP 200
{
  &quot;name&quot; : &quot;Purrsloud&quot;,
  &quot;species&quot; : &quot;Cat&quot;,
  &quot;favFoods&quot; : [&quot;wet food&quot;, &quot;dry food&quot;, &quot;<strong>any</strong> food&quot;],
  &quot;birthYear&quot; : 2016,
  &quot;photo&quot; : &quot;https://learnwebcode.github.io/json-example/images/cat-2.jpg&quot;
}"><pre lang="hurl"><code>GET https://example.org/api/cats/123
HTTP 200
{
  "name" : "Purrsloud",
  "species" : "Cat",
  "favFoods" : ["wet food", "dry food", "&lt;strong&gt;any&lt;/strong&gt; food"],
  "birthYear" : 2016,
  "photo" : "https://learnwebcode.github.io/json-example/images/cat-2.jpg"
}
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#json-body" rel="nofollow">Doc</a></p>
<p dir="auto">Or an explicit assert file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;"><pre lang="hurl"><code>GET https://example.org/index.html
HTTP 200
[Asserts]
body == file,cat.json;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#body-assert" rel="nofollow">Doc</a></p>
<p dir="auto">Implicit asserts supports XML body:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/api/catalog
HTTP 200
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<catalog>
   <book id=&quot;bk101&quot;>
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications with XML.</description>
   </book>
</catalog>"><pre lang="hurl"><code>GET https://example.org/api/catalog
HTTP 200
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;catalog&gt;
   &lt;book id="bk101"&gt;
      &lt;author&gt;Gambardella, Matthew&lt;/author&gt;
      &lt;title&gt;XML Developer's Guide&lt;/title&gt;
      &lt;genre&gt;Computer&lt;/genre&gt;
      &lt;price&gt;44.95&lt;/price&gt;
      &lt;publish_date&gt;2000-10-01&lt;/publish_date&gt;
      &lt;description&gt;An in-depth look at creating applications with XML.&lt;/description&gt;
   &lt;/book&gt;
&lt;/catalog&gt;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto">Plain text:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,&quot;ac, abs, moon&quot;,3000.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition&quot;&quot;&quot;,&quot;&quot;,4900.00
1999,Chevy,&quot;Venture &quot;&quot;Extended Edition, Very Large&quot;&quot;&quot;,,5000.00
1996,Jeep,Grand Cherokee,&quot;MUST SELL! air, moon roof, loaded&quot;,4799.00
```"><pre lang="hurl"><code>GET https://example.org/models
HTTP 200
```
Year,Make,Model,Description,Price
1997,Ford,E350,"ac, abs, moon",3000.00
1999,Chevy,"Venture ""Extended Edition""","",4900.00
1999,Chevy,"Venture ""Extended Edition, Very Large""",,5000.00
1996,Jeep,Grand Cherokee,"MUST SELL! air, moon roof, loaded",4799.00
```
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#multiline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">One line:</p>
<div data-snippet-clipboard-copy-content="POST https://example.org/helloworld
HTTP 200
`Hello world!`"><pre lang="hurl"><code>POST https://example.org/helloworld
HTTP 200
`Hello world!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#oneline-string-body" rel="nofollow">Doc</a></p>
<p dir="auto">File:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
file,data.bin;"><pre lang="hurl"><code>GET https://example.org
HTTP 200
file,data.bin;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#file-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Reports</h2><a id="user-content-reports" aria-label="Permalink: Reports" href="#reports"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTML Report</h3><a id="user-content-html-report" aria-label="Permalink: HTML Report" href="#html-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-html build/report/ *.hurl"><pre>$ hurl --test --report-html build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Report</h3><a id="user-content-json-report" aria-label="Permalink: JSON Report" href="#json-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-json build/report/ *.hurl"><pre>$ hurl --test --report-json build/report/ <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JUnit Report</h3><a id="user-content-junit-report" aria-label="Permalink: JUnit Report" href="#junit-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-junit build/report.xml *.hurl"><pre>$ hurl --test --report-junit build/report.xml <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">TAP Report</h3><a id="user-content-tap-report" aria-label="Permalink: TAP Report" href="#tap-report"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --test --report-tap build/report.txt *.hurl"><pre>$ hurl --test --report-tap build/report.txt <span>*</span>.hurl</pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/running-tests.html#generating-report" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">JSON Output</h3><a id="user-content-json-output" aria-label="Permalink: JSON Output" href="#json-output"></a></p>
<p dir="auto">A structured output of running Hurl files can be obtained with <a href="https://hurl.dev/docs/manual.html#json" rel="nofollow"><code>--json</code> option</a>. Each file will produce a JSON export of the run.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Others</h2><a id="user-content-others" aria-label="Permalink: Others" href="#others"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">HTTP Version</h3><a id="user-content-http-version" aria-label="Permalink: HTTP Version" href="#http-version"></a></p>
<p dir="auto">Testing HTTP version (HTTP/1.0, HTTP/1.1, HTTP/2 or HTTP/3) can be done using implicit asserts:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200"><pre lang="hurl"><code>GET https://foo.com
HTTP/3 200

GET https://bar.com
HTTP/2 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-status" rel="nofollow">Doc</a></p>
<p dir="auto">Or explicit:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
version == &quot;3&quot;

GET https://bar.com
HTTP 200
[Asserts]
version == &quot;2&quot;
version toFloat > 1.1"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
version == "3"

GET https://bar.com
HTTP 200
[Asserts]
version == "2"
version toFloat &gt; 1.1
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#version-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">IP Address</h3><a id="user-content-ip-address" aria-label="Permalink: IP Address" href="#ip-address"></a></p>
<p dir="auto">Testing the IP address of the response, as a string. This string may be IPv6 address:</p>
<div data-snippet-clipboard-copy-content="GET https://foo.com
HTTP 200
[Asserts]
ip == &quot;2001:0db8:85a3:0000:0000:8a2e:0370:733&quot;
ip startsWith &quot;2001&quot;
ip isIpv6"><pre lang="hurl"><code>GET https://foo.com
HTTP 200
[Asserts]
ip == "2001:0db8:85a3:0000:0000:8a2e:0370:733"
ip startsWith "2001"
ip isIpv6
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Polling and Retry</h3><a id="user-content-polling-and-retry" aria-label="Permalink: Polling and Retry" href="#polling-and-retry"></a></p>
<p dir="auto">Retry request on any errors (asserts, captures, status code, runtime etc...):</p>
<div data-snippet-clipboard-copy-content="# Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath &quot;$.id&quot;
[Asserts]
jsonpath &quot;$.state&quot; == &quot;RUNNING&quot;


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath &quot;$.state&quot; == &quot;COMPLETED&quot;"><pre lang="hurl"><code># Create a new job
POST https://api.example.org/jobs
HTTP 201
[Captures]
job_id: jsonpath "$.id"
[Asserts]
jsonpath "$.state" == "RUNNING"


# Pull job status until it is completed
GET https://api.example.org/jobs/{{job_id}}
[Options]
retry: 10   # maximum number of retry, -1 for unlimited
retry-interval: 500ms
HTTP 200
[Asserts]
jsonpath "$.state" == "COMPLETED"
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/entry.html#retry" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Delaying Requests</h3><a id="user-content-delaying-requests" aria-label="Permalink: Delaying Requests" href="#delaying-requests"></a></p>
<p dir="auto">Add delay for every request, or a particular request:</p>
<div data-snippet-clipboard-copy-content="# Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200"><pre lang="hurl"><code># Delaying this request by 5 seconds (aka sleep)
GET https://example.org/turtle
[Options]
delay: 5s
HTTP 200

# No delay!
GET https://example.org/turtle
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#delay" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Skipping Requests</h3><a id="user-content-skipping-requests" aria-label="Permalink: Skipping Requests" href="#skipping-requests"></a></p>
<div data-snippet-clipboard-copy-content="# a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d"><pre lang="hurl"><code># a, c, d are run, b is skipped
GET https://example.org/a

GET https://example.org/b
[Options]
skip: true

GET https://example.org/c

GET https://example.org/d
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#skip" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing Endpoint Performance</h3><a id="user-content-testing-endpoint-performance" aria-label="Permalink: Testing Endpoint Performance" href="#testing-endpoint-performance"></a></p>
<div data-snippet-clipboard-copy-content="GET https://sample.org/helloworld
HTTP *
[Asserts]
duration < 1000   # Check that response time is less than one second"><pre lang="hurl"><code>GET https://sample.org/helloworld
HTTP *
[Asserts]
duration &lt; 1000   # Check that response time is less than one second
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#duration-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using SOAP APIs</h3><a id="user-content-using-soap-apis" aria-label="Permalink: Using SOAP APIs" href="#using-soap-apis"></a></p>
<div data-snippet-clipboard-copy-content="POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: &quot;http://www.w3.org/2003/05/soap-envelope&quot;
<?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?>
<soap:Envelope xmlns:soap=&quot;http://www.w3.org/2003/05/soap-envelope&quot; xmlns:m=&quot;https://example.org&quot;>
  <soap:Header></soap:Header>
  <soap:Body>
    <m:GetStockPrice>
      <m:StockName>GOOG</m:StockName>
    </m:GetStockPrice>
  </soap:Body>
</soap:Envelope>
HTTP 200"><pre lang="hurl"><code>POST https://example.org/InStock
Content-Type: application/soap+xml; charset=utf-8
SOAPAction: "http://www.w3.org/2003/05/soap-envelope"
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:m="https://example.org"&gt;
  &lt;soap:Header&gt;&lt;/soap:Header&gt;
  &lt;soap:Body&gt;
    &lt;m:GetStockPrice&gt;
      &lt;m:StockName&gt;GOOG&lt;/m:StockName&gt;
    &lt;/m:GetStockPrice&gt;
  &lt;/soap:Body&gt;
&lt;/soap:Envelope&gt;
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#xml-body" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing and Using a CSRF Token</h3><a id="user-content-capturing-and-using-a-csrf-token" aria-label="Permalink: Capturing and Using a CSRF Token" href="#capturing-and-using-a-csrf-token"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath &quot;string(//meta[@name='_csrf_token']/@content)&quot;


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302"><pre lang="hurl"><code>GET https://example.org
HTTP 200
[Captures]
csrf_token: xpath "string(//meta[@name='_csrf_token']/@content)"


POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
HTTP 302
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#xpath-capture" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Redacting Secrets</h3><a id="user-content-redacting-secrets" aria-label="Permalink: Redacting Secrets" href="#redacting-secrets"></a></p>
<p dir="auto">Using command-line for known values:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --secret token=1234 file.hurl"><pre>$ hurl --secret token=1234 file.hurl</pre></div>
<div data-snippet-clipboard-copy-content="POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code>POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/templates.html#secrets" rel="nofollow">Doc</a></p>
<p dir="auto">Using <code>redact</code> for dynamic values:</p>
<div data-snippet-clipboard-copy-content="# Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header &quot;X-Token&quot; redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  &quot;name&quot;: &quot;Alice&quot;,
  &quot;value&quot;: 100
}
HTTP 200"><pre lang="hurl"><code># Get an authorization token:
GET https://example.org/token
HTTP 200
[Captures]
token: header "X-Token" redact

# Send an authorized request:
POST https://example.org
X-Token: {{token}}
{
  "name": "Alice",
  "value": 100
}
HTTP 200
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/capturing-response.html#redacting-secrets" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Checking Byte Order Mark (BOM) in Response Body</h3><a id="user-content-checking-byte-order-mark-bom-in-response-body" aria-label="Permalink: Checking Byte Order Mark (BOM) in Response Body" href="#checking-byte-order-mark-bom-in-response-body"></a></p>
<div data-snippet-clipboard-copy-content="GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;"><pre lang="hurl"><code>GET https://example.org/data.bin
HTTP 200
[Asserts]
bytes startsWith hex,efbbbf;
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/asserting-response.html#bytes-assert" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AWS Signature Version 4 Requests</h3><a id="user-content-aws-signature-version-4-requests" aria-label="Permalink: AWS Signature Version 4 Requests" href="#aws-signature-version-4-requests"></a></p>
<p dir="auto">Generate signed API requests with <a href="https://docs.aws.amazon.com/AmazonS3/latest/API/sig-v4-authenticating-requests.html" rel="nofollow">AWS Signature Version 4</a>, as used by several cloud providers.</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto">The Access Key is given per <a href="https://hurl.dev/docs/manual.html#user" rel="nofollow"><code>--user</code></a>, either with command line option or within the <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code></a> section:</p>
<div data-snippet-clipboard-copy-content="POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15"><pre lang="hurl"><code>POST https://sts.eu-central-1.amazonaws.com/
[Options]
aws-sigv4: aws:amz:eu-central-1:sts
user: bob=secret
[Form]
Action: GetCallerIdentity
Version: 2011-06-15
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/manual.html#aws-sigv4" rel="nofollow">Doc</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using curl Options</h3><a id="user-content-using-curl-options" aria-label="Permalink: Using curl Options" href="#using-curl-options"></a></p>
<p dir="auto">curl options (for instance <a href="https://hurl.dev/docs/manual.html#resolve" rel="nofollow"><code>--resolve</code></a> or <a href="https://hurl.dev/docs/manual.html#connect-to" rel="nofollow"><code>--connect-to</code></a>) can be used as CLI argument. In this case, they're applicable
to each request of an Hurl file.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl"><pre>$ hurl --resolve foo.com:8000:127.0.0.1 foo.hurl</pre></div>
<p dir="auto">Use  <a href="https://hurl.dev/docs/request.html#options" rel="nofollow"><code>[Options]</code> section</a> to configure a specific request:</p>
<div data-snippet-clipboard-copy-content="GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`"><pre lang="hurl"><code>GET http://bar.com
HTTP 200


GET http://foo.com:8000/resolve
[Options]
resolve: foo.com:8000:127.0.0.1
HTTP 200
`Hello World!`
</code></pre></div>
<p dir="auto"><a href="https://hurl.dev/docs/request.html#options" rel="nofollow">Doc</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Manual</h2><a id="user-content-manual" aria-label="Permalink: Manual" href="#manual"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Name</h2><a id="user-content-name" aria-label="Permalink: Name" href="#name"></a></p>
<p dir="auto">hurl - run and test HTTP requests.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synopsis</h2><a id="user-content-synopsis" aria-label="Permalink: Synopsis" href="#synopsis"></a></p>
<p dir="auto"><strong>hurl</strong> [options] [FILE...]</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Description</h2><a id="user-content-description" aria-label="Permalink: Description" href="#description"></a></p>
<p dir="auto"><strong>Hurl</strong> is a command line tool that runs HTTP requests defined in a simple plain text format.</p>
<p dir="auto">It can chain requests, capture values and evaluate queries on headers and body response. Hurl is very versatile, it can be used for fetching data and testing HTTP sessions: HTML content, REST / SOAP / GraphQL APIs, or any other XML / JSON based APIs.</p>

<p dir="auto">If no input files are specified, input is read from stdin.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo GET http://httpbin.org/get | hurl
    {
      &quot;args&quot;: {},
      &quot;headers&quot;: {
        &quot;Accept&quot;: &quot;*/*&quot;,
        &quot;Accept-Encoding&quot;: &quot;gzip&quot;,
        &quot;Content-Length&quot;: &quot;0&quot;,
        &quot;Host&quot;: &quot;httpbin.org&quot;,
        &quot;User-Agent&quot;: &quot;hurl/0.99.10&quot;,
        &quot;X-Amzn-Trace-Id&quot;: &quot;Root=1-5eedf4c7-520814d64e2f9249ea44e0&quot;
      },
      &quot;origin&quot;: &quot;1.2.3.4&quot;,
      &quot;url&quot;: &quot;http://httpbin.org/get&quot;
    }"><pre>$ <span>echo</span> GET http://httpbin.org/get <span>|</span> hurl
    {
      <span><span>"</span>args<span>"</span></span>: {},
      <span><span>"</span>headers<span>"</span></span>: {
        <span><span>"</span>Accept<span>"</span></span>: <span><span>"</span>*/*<span>"</span></span>,
        <span><span>"</span>Accept-Encoding<span>"</span></span>: <span><span>"</span>gzip<span>"</span></span>,
        <span><span>"</span>Content-Length<span>"</span></span>: <span><span>"</span>0<span>"</span></span>,
        <span><span>"</span>Host<span>"</span></span>: <span><span>"</span>httpbin.org<span>"</span></span>,
        <span><span>"</span>User-Agent<span>"</span></span>: <span><span>"</span>hurl/0.99.10<span>"</span></span>,
        <span><span>"</span>X-Amzn-Trace-Id<span>"</span></span>: <span><span>"</span>Root=1-5eedf4c7-520814d64e2f9249ea44e0<span>"</span></span>
      },
      <span><span>"</span>origin<span>"</span></span>: <span><span>"</span>1.2.3.4<span>"</span></span>,
      <span><span>"</span>url<span>"</span></span>: <span><span>"</span>http://httpbin.org/get<span>"</span></span>
    }</pre></div>
<p dir="auto">Hurl can take files as input, or directories. In the latter case, Hurl will search files with <code>.hurl</code> extension recursively.</p>
<p dir="auto">Output goes to stdout by default. To have output go to a file, use the <a href="#output"><code>-o, --output</code></a> option:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl -o output input.hurl"><pre>$ hurl -o output input.hurl</pre></div>
<p dir="auto">By default, Hurl executes all HTTP requests and outputs the response body of the last HTTP call.</p>
<p dir="auto">To have a test oriented output, you can use <a href="#test"><code>--test</code></a> option:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Hurl File Format</h2><a id="user-content-hurl-file-format" aria-label="Permalink: Hurl File Format" href="#hurl-file-format"></a></p>
<p dir="auto">The Hurl file format is fully documented in <a href="https://hurl.dev/docs/hurl-file.html" rel="nofollow">https://hurl.dev/docs/hurl-file.html</a></p>
<p dir="auto">It consists of one or several HTTP requests</p>
<div data-snippet-clipboard-copy-content="GET http://example.org/endpoint1
GET http://example.org/endpoint2"><pre lang="hurl"><code>GET http://example.org/endpoint1
GET http://example.org/endpoint2
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Capturing values</h3><a id="user-content-capturing-values" aria-label="Permalink: Capturing values" href="#capturing-values"></a></p>
<p dir="auto">A value from an HTTP response can be-reused for successive HTTP requests.</p>
<p dir="auto">A typical example occurs with CSRF tokens.</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath &quot;normalize-space(//meta[@name='_csrf_token']/@content)&quot;

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}"><pre lang="hurl"><code>GET https://example.org
HTTP 200
# Capture the CSRF token value from html body.
[Captures]
csrf_token: xpath "normalize-space(//meta[@name='_csrf_token']/@content)"

# Do the login !
POST https://example.org/login?user=toto&amp;password=1234
X-CSRF-TOKEN: {{csrf_token}}
</code></pre></div>
<p dir="auto">More information on captures can be found here <a href="https://hurl.dev/docs/capturing-response.html" rel="nofollow">https://hurl.dev/docs/capturing-response.html</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Asserts</h3><a id="user-content-asserts" aria-label="Permalink: Asserts" href="#asserts"></a></p>
<p dir="auto">The HTTP response defined in the Hurl file are used to make asserts. Responses are optional.</p>
<p dir="auto">At the minimum, response includes assert on the HTTP status code.</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301"><pre lang="hurl"><code>GET http://example.org
HTTP 301
</code></pre></div>
<p dir="auto">It can also include asserts on the response headers</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
Location: http://www.example.org"><pre lang="hurl"><code>GET http://example.org
HTTP 301
Location: http://www.example.org
</code></pre></div>
<p dir="auto">Explicit asserts can be included by combining a query and a predicate</p>
<div data-snippet-clipboard-copy-content="GET http://example.org
HTTP 301
[Asserts]
xpath &quot;string(//title)&quot; == &quot;301 Moved&quot;"><pre lang="hurl"><code>GET http://example.org
HTTP 301
[Asserts]
xpath "string(//title)" == "301 Moved"
</code></pre></div>
<p dir="auto">With the addition of asserts, Hurl can be used as a testing tool to run scenarios.</p>
<p dir="auto">More information on asserts can be found here <a href="https://hurl.dev/docs/asserting-response.html" rel="nofollow">https://hurl.dev/docs/asserting-response.html</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<p dir="auto">Options that exist in curl have exactly the same semantics.</p>
<p dir="auto">Options specified on the command line are defined for every Hurl file's entry,
except if they are tagged as cli-only (can not be defined in the Hurl request [Options] entry)</p>
<p dir="auto">For instance:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ hurl --location foo.hurl"><pre>$ hurl --location foo.hurl</pre></div>
<p dir="auto">will follow redirection for each entry in <code>foo.hurl</code>. You can also define an option only for a particular entry with an <code>[Options]</code> section. For instance, this Hurl file:</p>
<div data-snippet-clipboard-copy-content="GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200"><pre lang="hurl"><code>GET https://example.org
HTTP 301

GET https://example.org
[Options]
location: true
HTTP 200
</code></pre></div>
<p dir="auto">will follow a redirection only for the second entry.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#aws-sigv4" id="user-content-aws-sigv4"><code>--aws-sigv4 &lt;PROVIDER1[:PROVIDER2[:REGION[:SERVICE]]]&gt;</code></a></td>
<td>Generate an <code>Authorization</code> header with an AWS SigV4 signature.<p>Use <a href="#user"><code>-u, --user</code></a> to specify Access Key Id (username) and Secret Key (password).</p><p>To use temporary session credentials (e.g. for an AWS IAM Role), add the <code>X-Amz-Security-Token</code> header containing the session token.</p></td>
</tr>
<tr>
<td><a href="#cacert" id="user-content-cacert"><code>--cacert &lt;FILE&gt;</code></a></td>
<td>Specifies the certificate file for peer verification. The file may contain multiple CA certificates and must be in PEM format.<br>Normally Hurl is built to use a default file for this, so this option is typically used to alter that default file.<br></td>
</tr>
<tr>
<td><a href="#cert" id="user-content-cert"><code>-E, --cert &lt;CERTIFICATE[:PASSWORD]&gt;</code></a></td>
<td>Client certificate file and password.<p>See also <a href="#key"><code>--key</code></a>.</p></td>
</tr>
<tr>
<td><a href="#color" id="user-content-color"><code>--color</code></a></td>
<td>Colorize debug output (the HTTP response output is not colorized).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#compressed" id="user-content-compressed"><code>--compressed</code></a></td>
<td>Request a compressed response using one of the algorithms br, gzip, deflate and automatically decompress the content.<br></td>
</tr>
<tr>
<td><a href="#connect-timeout" id="user-content-connect-timeout"><code>--connect-timeout &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow Hurl's connection to take.<p>You can specify time units in the connect timeout expression. Set Hurl to use a connect timeout of 20 seconds with <code>--connect-timeout 20s</code> or set it to 35,000 milliseconds with <code>--connect-timeout 35000ms</code>. No spaces allowed.</p><p>See also <a href="#max-time"><code>-m, --max-time</code></a>.</p></td>
</tr>
<tr>
<td><a href="#connect-to" id="user-content-connect-to"><code>--connect-to &lt;HOST1:PORT1:HOST2:PORT2&gt;</code></a></td>
<td>For a request to the given HOST1:PORT1 pair, connect to HOST2:PORT2 instead. This option can be used several times in a command line.<p>See also <a href="#resolve"><code>--resolve</code></a>.</p></td>
</tr>
<tr>
<td><a href="#continue-on-error" id="user-content-continue-on-error"><code>--continue-on-error</code></a></td>
<td>Continue executing requests to the end of the Hurl file even when an assert error occurs.<br>By default, Hurl exits after an assert error in the HTTP response.<p>Note that this option does not affect the behavior with multiple input Hurl files.</p><p>All the input files are executed independently. The result of one file does not affect the execution of the other Hurl files.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie" id="user-content-cookie"><code>-b, --cookie &lt;FILE&gt;</code></a></td>
<td>Read cookies from FILE (using the Netscape cookie file format).<p>Combined with <a href="#cookie-jar"><code>-c, --cookie-jar</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#cookie-jar" id="user-content-cookie-jar"><code>-c, --cookie-jar &lt;FILE&gt;</code></a></td>
<td>Write cookies to FILE after running the session.<br>The file will be written using the Netscape cookie file format.<p>Combined with <a href="#cookie"><code>-b, --cookie</code></a>, you can simulate a cookie storage between successive Hurl runs.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#curl" id="user-content-curl"><code>--curl &lt;FILE&gt;</code></a></td>
<td>Export each request to a list of curl commands.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#delay" id="user-content-delay"><code>--delay &lt;MILLISECONDS&gt;</code></a></td>
<td>Sets delay before each request (aka sleep). The delay is not applied to requests that have been retried because of <a href="#retry"><code>--retry</code></a>. See <a href="#retry-interval"><code>--retry-interval</code></a> to space retried requests.<p>You can specify time units in the delay expression. Set Hurl to use a delay of 2 seconds with <code>--delay 2s</code> or set it to 500 milliseconds with <code>--delay 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#error-format" id="user-content-error-format"><code>--error-format &lt;FORMAT&gt;</code></a></td>
<td>Control the format of error message (short by default or long)<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#file-root" id="user-content-file-root"><code>--file-root &lt;DIR&gt;</code></a></td>
<td>Set root directory to import files in Hurl. This is used for files in multipart form data, request body and response output.<br>When it is not explicitly defined, files are relative to the Hurl file's directory.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#from-entry" id="user-content-from-entry"><code>--from-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file from ENTRY_NUMBER (starting at 1).<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#glob" id="user-content-glob"><code>--glob &lt;GLOB&gt;</code></a></td>
<td>Specify input files that match the given glob pattern.<p>Multiple glob flags may be used. This flag supports common Unix glob patterns like *, ? and [].<br>However, to avoid your shell accidentally expanding glob patterns before Hurl handles them, you must use single quotes or double quotes around each pattern.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#header" id="user-content-header"><code>-H, --header &lt;HEADER&gt;</code></a></td>
<td>Add an extra header to include in information sent. Can be used several times in a command<p>Do not add newlines or carriage returns</p></td>
</tr>
<tr>
<td><a href="#http10" id="user-content-http10"><code>-0, --http1.0</code></a></td>
<td>Tells Hurl to use HTTP version 1.0 instead of using its internally preferred HTTP version.<br></td>
</tr>
<tr>
<td><a href="#http11" id="user-content-http11"><code>--http1.1</code></a></td>
<td>Tells Hurl to use HTTP version 1.1.<br></td>
</tr>
<tr>
<td><a href="#http2" id="user-content-http2"><code>--http2</code></a></td>
<td>Tells Hurl to use HTTP version 2.<br>For HTTPS, this means Hurl negotiates HTTP/2 in the TLS handshake. Hurl does this by default.<br>For HTTP, this means Hurl attempts to upgrade the request to HTTP/2 using the Upgrade: request header.<br></td>
</tr>
<tr>
<td><a href="#http3" id="user-content-http3"><code>--http3</code></a></td>
<td>Tells Hurl to try HTTP/3 to the host in the URL, but fallback to earlier HTTP versions if the HTTP/3 connection establishment fails. HTTP/3 is only available for HTTPS and not for HTTP URLs.<br></td>
</tr>
<tr>
<td><a href="#ignore-asserts" id="user-content-ignore-asserts"><code>--ignore-asserts</code></a></td>
<td>Ignore all asserts defined in the Hurl file.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#include" id="user-content-include"><code>-i, --include</code></a></td>
<td>Include the HTTP headers in the output<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#insecure" id="user-content-insecure"><code>-k, --insecure</code></a></td>
<td>This option explicitly allows Hurl to perform "insecure" SSL connections and transfers.<br></td>
</tr>
<tr>
<td><a href="#interactive" id="user-content-interactive"><code>--interactive</code></a></td>
<td>Stop between requests.<p>This is similar to a break point, You can then continue (Press C) or quit (Press Q).</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#ipv4" id="user-content-ipv4"><code>-4, --ipv4</code></a></td>
<td>This option tells Hurl to use IPv4 addresses only when resolving host names, and not for example try IPv6.<br></td>
</tr>
<tr>
<td><a href="#ipv6" id="user-content-ipv6"><code>-6, --ipv6</code></a></td>
<td>This option tells Hurl to use IPv6 addresses only when resolving host names, and not for example try IPv4.<br></td>
</tr>
<tr>
<td><a href="#jobs" id="user-content-jobs"><code>--jobs &lt;NUM&gt;</code></a></td>
<td>Maximum number of parallel jobs in parallel mode. Default value corresponds (in most cases) to the<br>current amount of CPUs.<p>See also <a href="#parallel"><code>--parallel</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#json" id="user-content-json"><code>--json</code></a></td>
<td>Output each Hurl file result to JSON. The format is very closed to HAR format.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#key" id="user-content-key"><code>--key &lt;KEY&gt;</code></a></td>
<td>Private key file name.<br></td>
</tr>
<tr>
<td><a href="#limit-rate" id="user-content-limit-rate"><code>--limit-rate &lt;SPEED&gt;</code></a></td>
<td>Specify the maximum transfer rate you want Hurl to use, for both downloads and uploads. This feature is useful if you have a limited pipe and you would like your transfer not to use your entire bandwidth. To make it slower than it otherwise would be.<br>The given speed is measured in bytes/second.<br></td>
</tr>
<tr>
<td><a href="#location" id="user-content-location"><code>-L, --location</code></a></td>
<td>Follow redirect. To limit the amount of redirects to follow use the <a href="#max-redirs"><code>--max-redirs</code></a> option<br></td>
</tr>
<tr>
<td><a href="#location-trusted" id="user-content-location-trusted"><code>--location-trusted</code></a></td>
<td>Like <a href="#location"><code>-L, --location</code></a>, but allows sending the name + password to all hosts that the site may redirect to.<br>This may or may not introduce a security breach if the site redirects you to a site to which you send your authentication info (which is plaintext in the case of HTTP Basic authentication).<br></td>
</tr>
<tr>
<td><a href="#max-filesize" id="user-content-max-filesize"><code>--max-filesize &lt;BYTES&gt;</code></a></td>
<td>Specify the maximum size in bytes of a file to download. If the file requested is larger than this value, the transfer does not start.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#max-redirs" id="user-content-max-redirs"><code>--max-redirs &lt;NUM&gt;</code></a></td>
<td>Set maximum number of redirection-followings allowed<p>By default, the limit is set to 50 redirections. Set this option to -1 to make it unlimited.</p></td>
</tr>
<tr>
<td><a href="#max-time" id="user-content-max-time"><code>-m, --max-time &lt;SECONDS&gt;</code></a></td>
<td>Maximum time in seconds that you allow a request/response to take. This is the standard timeout.<p>You can specify time units in the maximum time expression. Set Hurl to use a maximum time of 20 seconds with <code>--max-time 20s</code> or set it to 35,000 milliseconds with <code>--max-time 35000ms</code>. No spaces allowed.</p><p>See also <a href="#connect-timeout"><code>--connect-timeout</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc" id="user-content-netrc"><code>-n, --netrc</code></a></td>
<td>Scan the .netrc file in the user's home directory for the username and password.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a> and <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-file" id="user-content-netrc-file"><code>--netrc-file &lt;FILE&gt;</code></a></td>
<td>Like <a href="#netrc"><code>--netrc</code></a>, but provide the path to the netrc file.<p>See also <a href="#netrc-optional"><code>--netrc-optional</code></a>.</p></td>
</tr>
<tr>
<td><a href="#netrc-optional" id="user-content-netrc-optional"><code>--netrc-optional</code></a></td>
<td>Similar to <a href="#netrc"><code>--netrc</code></a>, but make the .netrc usage optional.<p>See also <a href="#netrc-file"><code>--netrc-file</code></a>.</p></td>
</tr>
<tr>
<td><a href="#no-color" id="user-content-no-color"><code>--no-color</code></a></td>
<td>Do not colorize output.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#no-output" id="user-content-no-output"><code>--no-output</code></a></td>
<td>Suppress output. By default, Hurl outputs the body of the last response.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#noproxy" id="user-content-noproxy"><code>--noproxy &lt;HOST(S)&gt;</code></a></td>
<td>Comma-separated list of hosts which do not use a proxy.<p>Override value from Environment variable no_proxy.</p></td>
</tr>
<tr>
<td><a href="#output" id="user-content-output"><code>-o, --output &lt;FILE&gt;</code></a></td>
<td>Write output to FILE instead of stdout.<br></td>
</tr>
<tr>
<td><a href="#parallel" id="user-content-parallel"><code>--parallel</code></a></td>
<td>Run files in parallel.<p>Each Hurl file is executed in its own worker thread, without sharing anything with the other workers. The default run mode is sequential. Parallel execution is by default in <a href="#test"><code>--test</code></a> mode.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#path-as-is" id="user-content-path-as-is"><code>--path-as-is</code></a></td>
<td>Tell Hurl to not handle sequences of /../ or /./ in the given URL path. Normally Hurl will squash or merge them according to standards but with this option set you tell it not to do that.<br></td>
</tr>
<tr>
<td><a href="#pinnedpubkey" id="user-content-pinnedpubkey"><code>--pinnedpubkey &lt;HASHES&gt;</code></a></td>
<td>When negotiating a TLS or SSL connection, the server sends a certificate indicating its identity. A public key is extracted from this certificate and if it does not exactly match the public key provided to this option, Hurl aborts the connection before sending or receiving any data.<br></td>
</tr>
<tr>
<td><a href="#progress-bar" id="user-content-progress-bar"><code>--progress-bar</code></a></td>
<td>Display a progress bar in test mode. The progress bar is displayed only in interactive TTYs. This option forces the progress bar to be displayed even in non-interactive TTYs.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#proxy" id="user-content-proxy"><code>-x, --proxy &lt;[PROTOCOL://]HOST[:PORT]&gt;</code></a></td>
<td>Use the specified proxy.<br></td>
</tr>
<tr>
<td><a href="#repeat" id="user-content-repeat"><code>--repeat &lt;NUM&gt;</code></a></td>
<td>Repeat the input files sequence NUM times, -1 for infinite loop. Given a.hurl, b.hurl, c.hurl as input, repeat two<br>times will run a.hurl, b.hurl, c.hurl, a.hurl, b.hurl, c.hurl.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-html" id="user-content-report-html"><code>--report-html &lt;DIR&gt;</code></a></td>
<td>Generate HTML report in DIR.<p>If the HTML report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-json" id="user-content-report-json"><code>--report-json &lt;DIR&gt;</code></a></td>
<td>Generate JSON report in DIR.<p>If the JSON report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-junit" id="user-content-report-junit"><code>--report-junit &lt;FILE&gt;</code></a></td>
<td>Generate JUnit File.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#report-tap" id="user-content-report-tap"><code>--report-tap &lt;FILE&gt;</code></a></td>
<td>Generate TAP report.<p>If the FILE report already exists, it will be updated with the new test results.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#resolve" id="user-content-resolve"><code>--resolve &lt;HOST:PORT:ADDR&gt;</code></a></td>
<td>Provide a custom address for a specific host and port pair. Using this, you can make the Hurl requests(s) use a specified address and prevent the otherwise normally resolved address to be used. Consider it a sort of /etc/hosts alternative provided on the command line.<br></td>
</tr>
<tr>
<td><a href="#retry" id="user-content-retry"><code>--retry &lt;NUM&gt;</code></a></td>
<td>Maximum number of retries, 0 for no retries, -1 for unlimited retries. Retry happens if any error occurs (asserts, captures, runtimes etc...).<br></td>
</tr>
<tr>
<td><a href="#retry-interval" id="user-content-retry-interval"><code>--retry-interval &lt;MILLISECONDS&gt;</code></a></td>
<td>Duration in milliseconds between each retry. Default is 1000 ms.<p>You can specify time units in the retry interval expression. Set Hurl to use a retry interval of 2 seconds with <code>--retry-interval 2s</code> or set it to 500 milliseconds with <code>--retry-interval 500ms</code>. No spaces allowed.</p></td>
</tr>
<tr>
<td><a href="#secret" id="user-content-secret"><code>--secret &lt;NAME=VALUE&gt;</code></a></td>
<td>Define secret value to be redacted from logs and report. When defined, secrets can be used as variable everywhere variables are used.<br></td>
</tr>
<tr>
<td><a href="#ssl-no-revoke" id="user-content-ssl-no-revoke"><code>--ssl-no-revoke</code></a></td>
<td>(Windows) This option tells Hurl to disable certificate revocation checks. WARNING: this option loosens the SSL security, and by using this flag you ask for exactly that.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#test" id="user-content-test"><code>--test</code></a></td>
<td>Activate test mode: with this, the HTTP response is not outputted anymore, progress is reported for each Hurl file tested, and a text summary is displayed when all files have been run.<p>In test mode, files are executed in parallel. To run test in a sequential way use <code>--job 1</code>.</p><p>See also <a href="#jobs"><code>--jobs</code></a>.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#to-entry" id="user-content-to-entry"><code>--to-entry &lt;ENTRY_NUMBER&gt;</code></a></td>
<td>Execute Hurl file to ENTRY_NUMBER (starting at 1).<br>Ignore the remaining of the file. It is useful for debugging a session.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#unix-socket" id="user-content-unix-socket"><code>--unix-socket &lt;PATH&gt;</code></a></td>
<td>(HTTP) Connect through this Unix domain socket, instead of using the network.<br></td>
</tr>
<tr>
<td><a href="#user" id="user-content-user"><code>-u, --user &lt;USER:PASSWORD&gt;</code></a></td>
<td>Add basic Authentication header to each request.<br></td>
</tr>
<tr>
<td><a href="#user-agent" id="user-content-user-agent"><code>-A, --user-agent &lt;NAME&gt;</code></a></td>
<td>Specify the User-Agent string to send to the HTTP server.<p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#variable" id="user-content-variable"><code>--variable &lt;NAME=VALUE&gt;</code></a></td>
<td>Define variable (name/value) to be used in Hurl templates.<br></td>
</tr>
<tr>
<td><a href="#variables-file" id="user-content-variables-file"><code>--variables-file &lt;FILE&gt;</code></a></td>
<td>Set properties file in which your define your variables.<p>Each variable is defined as name=value exactly as with <a href="#variable"><code>--variable</code></a> option.</p><p>Note that defining a variable twice produces an error.</p><p>This is a cli-only option.</p></td>
</tr>
<tr>
<td><a href="#verbose" id="user-content-verbose"><code>-v, --verbose</code></a></td>
<td>Turn on verbose output on standard error stream.<br>Useful for debugging.<p>A line starting with '&gt;' means data sent by Hurl.<br>A line staring with '&lt;' means data received by Hurl.<br>A line starting with '*' means additional info provided by Hurl.</p><p>If you only want HTTP headers in the output, <a href="#include"><code>-i, --include</code></a> might be the option you're looking for.</p></td>
</tr>
<tr>
<td><a href="#very-verbose" id="user-content-very-verbose"><code>--very-verbose</code></a></td>
<td>Turn on more verbose output on standard error stream.<p>In contrast to  <a href="#verbose"><code>--verbose</code></a> option, this option outputs the full HTTP body request and response on standard error. In addition, lines starting with '**' are libcurl debug logs.</p></td>
</tr>
<tr>
<td><a href="#help" id="user-content-help"><code>-h, --help</code></a></td>
<td>Usage help. This lists all current command line options with a short description.<br></td>
</tr>
<tr>
<td><a href="#version" id="user-content-version"><code>-V, --version</code></a></td>
<td>Prints version information<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Environment</h2><a id="user-content-environment" aria-label="Permalink: Environment" href="#environment"></a></p>
<p dir="auto">Environment variables can only be specified in lowercase.</p>
<p dir="auto">Using an environment variable to set the proxy has the same effect as using the <a href="#proxy"><code>-x, --proxy</code></a> option.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>http_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTP.<br></td>
</tr>
<tr>
<td><code>https_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use for HTTPS.<br></td>
</tr>
<tr>
<td><code>all_proxy [PROTOCOL://]&lt;HOST&gt;[:PORT]</code></td>
<td>Sets the proxy server to use if no protocol-specific proxy is set.<br></td>
</tr>
<tr>
<td><code>no_proxy &lt;comma-separated list of hosts&gt;</code></td>
<td>List of host names that shouldn't go through any proxy.<br></td>
</tr>
<tr>
<td><code>HURL_name value</code></td>
<td>Define variable (name/value) to be used in Hurl templates. This is similar than <a href="#variable"><code>--variable</code></a> and <a href="#variables-file"><code>--variables-file</code></a> options.<br></td>
</tr>
<tr>
<td><code>NO_COLOR</code></td>
<td>When set to a non-empty string, do not colorize output (see <a href="#no-color"><code>--no-color</code></a> option).<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Exit Codes</h2><a id="user-content-exit-codes" aria-label="Permalink: Exit Codes" href="#exit-codes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Value</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0</code></td>
<td>Success.<br></td>
</tr>
<tr>
<td><code>1</code></td>
<td>Failed to parse command-line options.<br></td>
</tr>
<tr>
<td><code>2</code></td>
<td>Input File Parsing Error.<br></td>
</tr>
<tr>
<td><code>3</code></td>
<td>Runtime error (such as failure to connect to host).<br></td>
</tr>
<tr>
<td><code>4</code></td>
<td>Assert Error.<br></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">WWW</h2><a id="user-content-www" aria-label="Permalink: WWW" href="#www"></a></p>
<p dir="auto"><a href="https://hurl.dev/" rel="nofollow">https://hurl.dev</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">See Also</h2><a id="user-content-see-also" aria-label="Permalink: See Also" href="#see-also"></a></p>
<p dir="auto">curl(1)  hurlfmt(1)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Binaries Installation</h2><a id="user-content-binaries-installation" aria-label="Permalink: Binaries Installation" href="#binaries-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Linux</h3><a id="user-content-linux" aria-label="Permalink: Linux" href="#linux"></a></p>
<p dir="auto">Precompiled binary (depending on libc &gt;=2.35) is available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl-$VERSION-x86_64-unknown-linux-gnu.tar.gz | tar xvz -C $INSTALL_DIR
$ export PATH=$INSTALL_DIR/hurl-$VERSION-x86_64-unknown-linux-gnu/bin:$PATH"><pre>$ INSTALL_DIR=/tmp
$ VERSION=6.1.1
$ curl --silent --location https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu.tar.gz <span>|</span> tar xvz -C <span>$INSTALL_DIR</span>
$ <span>export</span> PATH=<span>$INSTALL_DIR</span>/hurl-<span>$VERSION</span>-x86_64-unknown-linux-gnu/bin:<span>$PATH</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian / Ubuntu</h4><a id="user-content-debian--ubuntu" aria-label="Permalink: Debian / Ubuntu" href="#debian--ubuntu"></a></p>
<p dir="auto">For Debian &gt;=12 / Ubuntu &gt;=22.04, Hurl can be installed using a binary .deb file provided in each Hurl release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/$VERSION/hurl_${VERSION}_amd64.deb
$ sudo apt update &amp;&amp; sudo apt install ./hurl_${VERSION}_amd64.deb"><pre>$ VERSION=6.1.1
$ curl --location --remote-name https://github.com/Orange-OpenSource/hurl/releases/download/<span>$VERSION</span>/hurl_<span>${VERSION}</span>_amd64.deb
$ sudo apt update <span>&amp;&amp;</span> sudo apt install ./hurl_<span>${VERSION}</span>_amd64.deb</pre></div>
<p dir="auto">For Ubuntu &gt;=18.04, Hurl can be installed from <code>ppa:lepapareil/hurl</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=&quot;${VERSION}&quot;*"><pre>$ VERSION=6.1.1
$ sudo apt-add-repository -y ppa:lepapareil/hurl
$ sudo apt install hurl=<span><span>"</span><span>${VERSION}</span><span>"</span></span><span>*</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine</h4><a id="user-content-alpine" aria-label="Permalink: Alpine" href="#alpine"></a></p>
<p dir="auto">Hurl is available on <code>testing</code> channel.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl"><pre>$ apk add --repository http://dl-cdn.alpinelinux.org/alpine/edge/testing hurl</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch Linux / Manjaro</h4><a id="user-content-arch-linux--manjaro" aria-label="Permalink: Arch Linux / Manjaro" href="#arch-linux--manjaro"></a></p>
<p dir="auto">Hurl is available on <a href="https://archlinux.org/packages/extra/x86_64/hurl/" rel="nofollow">extra</a> channel.</p>

<p dir="auto"><h4 tabindex="-1" dir="auto">NixOS / Nix</h4><a id="user-content-nixos--nix" aria-label="Permalink: NixOS / Nix" href="#nixos--nix"></a></p>
<p dir="auto"><a href="https://search.nixos.org/packages?from=0&amp;size=1&amp;sort=relevance&amp;type=packages&amp;query=hurl" rel="nofollow">NixOS / Nix package</a> is available on stable channel.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">macOS</h3><a id="user-content-macos" aria-label="Permalink: macOS" href="#macos"></a></p>
<p dir="auto">Precompiled binaries for Intel and ARM CPUs are available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew</h4><a id="user-content-homebrew" aria-label="Permalink: Homebrew" href="#homebrew"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">MacPorts</h4><a id="user-content-macports" aria-label="Permalink: MacPorts" href="#macports"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">FreeBSD</h3><a id="user-content-freebsd" aria-label="Permalink: FreeBSD" href="#freebsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Windows</h3><a id="user-content-windows" aria-label="Permalink: Windows" href="#windows"></a></p>
<p dir="auto">Windows requires the <a href="https://learn.microsoft.com/en-us/cpp/windows/latest-supported-vc-redist?view=msvc-170#latest-microsoft-visual-c-redistributable-version" rel="nofollow">Visual C++ Redistributable Package</a> to be installed manually, as this is not included in the installer.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Zip File</h4><a id="user-content-zip-file" aria-label="Permalink: Zip File" href="#zip-file"></a></p>
<p dir="auto">Hurl can be installed from a standalone zip file at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>. You will need to update your <code>PATH</code> variable.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installer</h4><a id="user-content-installer" aria-label="Permalink: Installer" href="#installer"></a></p>
<p dir="auto">An executable installer is also available at <a href="https://github.com/Orange-OpenSource/hurl/releases/latest">Hurl latest GitHub release</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Chocolatey</h4><a id="user-content-chocolatey" aria-label="Permalink: Chocolatey" href="#chocolatey"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Scoop</h4><a id="user-content-scoop" aria-label="Permalink: Scoop" href="#scoop"></a></p>

<p dir="auto"><h4 tabindex="-1" dir="auto">Windows Package Manager</h4><a id="user-content-windows-package-manager" aria-label="Permalink: Windows Package Manager" href="#windows-package-manager"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Cargo</h3><a id="user-content-cargo" aria-label="Permalink: Cargo" href="#cargo"></a></p>
<p dir="auto">If you're a Rust programmer, Hurl can be installed with cargo.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ cargo install --locked hurl"><pre>$ cargo install --locked hurl</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">conda-forge</h3><a id="user-content-conda-forge" aria-label="Permalink: conda-forge" href="#conda-forge"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ conda install -c conda-forge hurl"><pre>$ conda install -c conda-forge hurl</pre></div>
<p dir="auto">Hurl can also be installed with <a href="https://conda-forge.org/" rel="nofollow"><code>conda-forge</code></a> powered package manager like <a href="https://prefix.dev/" rel="nofollow"><code>pixi</code></a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ docker pull ghcr.io/orange-opensource/hurl:latest"><pre>$ docker pull ghcr.io/orange-opensource/hurl:latest</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">npm</h3><a id="user-content-npm" aria-label="Permalink: npm" href="#npm"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ npm install --save-dev @orangeopensource/hurl"><pre>$ npm install --save-dev @orangeopensource/hurl</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Building From Sources</h2><a id="user-content-building-from-sources" aria-label="Permalink: Building From Sources" href="#building-from-sources"></a></p>
<p dir="auto">Hurl sources are available in <a href="https://github.com/Orange-OpenSource/hurl">GitHub</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Linux</h3><a id="user-content-build-on-linux" aria-label="Permalink: Build on Linux" href="#build-on-linux"></a></p>
<p dir="auto">Hurl depends on libssl, libcurl and libxml2 native libraries. You will need their development files in your platform.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Debian based distributions</h4><a id="user-content-debian-based-distributions" aria-label="Permalink: Debian based distributions" href="#debian-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev"><pre>$ apt install -y build-essential pkg-config libssl-dev libcurl4-openssl-dev libxml2-dev libclang-dev</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fedora based distributions</h4><a id="user-content-fedora-based-distributions" aria-label="Permalink: Fedora based distributions" href="#fedora-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ dnf install -y pkgconf-pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Red Hat based distributions</h4><a id="user-content-red-hat-based-distributions" aria-label="Permalink: Red Hat based distributions" href="#red-hat-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel"><pre>$ yum install -y pkg-config gcc openssl-devel libxml2-devel clang-devel</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Arch based distributions</h4><a id="user-content-arch-based-distributions" aria-label="Permalink: Arch based distributions" href="#arch-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang"><pre>$ pacman -S --noconfirm pkgconf gcc glibc openssl libxml2 clang</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Alpine based distributions</h4><a id="user-content-alpine-based-distributions" aria-label="Permalink: Alpine based distributions" href="#alpine-based-distributions"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev"><pre>$ apk add curl-dev gcc libxml2-dev musl-dev openssl-dev clang-dev</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on macOS</h3><a id="user-content-build-on-macos" aria-label="Permalink: Build on macOS" href="#build-on-macos"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ xcode-select --install
$ brew install pkg-config"><pre>$ xcode-select --install
$ brew install pkg-config</pre></div>
<p dir="auto">Hurl is written in <a href="https://www.rust-lang.org/" rel="nofollow">Rust</a>. You should <a href="https://www.rust-lang.org/tools/install" rel="nofollow">install</a> the latest stable release.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ curl https://sh.rustup.rs -sSf | sh -s -- -y
$ source $HOME/.cargo/env
$ rustc --version
$ cargo --version"><pre>$ curl https://sh.rustup.rs -sSf <span>|</span> sh -s -- -y
$ <span>source</span> <span>$HOME</span>/.cargo/env
$ rustc --version
$ cargo --version</pre></div>
<p dir="auto">Then build hurl:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone https://github.com/Orange-OpenSource/hurl
$ cd hurl
$ cargo build --release
$ ./target/release/hurl --version"><pre>$ git clone https://github.com/Orange-OpenSource/hurl
$ <span>cd</span> hurl
$ cargo build --release
$ ./target/release/hurl --version</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build on Windows</h3><a id="user-content-build-on-windows" aria-label="Permalink: Build on Windows" href="#build-on-windows"></a></p>
<p dir="auto">Please follow the <a href="https://github.com/Orange-OpenSource/hurl/blob/master/contrib/windows/README.md">contrib on Windows section</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source can't coordinate (105 pts)]]></title>
            <link>https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</link>
            <guid>44323904</guid>
            <pubDate>Fri, 20 Jun 2025 01:06:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html">https://matklad.github.io/2025/05/20/open-source-cant-coordinate.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323904">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <article>
        <h2>
          Open Source Can’t Coordinate <time datetime="2025-05-20">May 20, 2025</time>
        </h2>
        <p>
          I was taking a shower this morning, and was pondering <a href="https://matklad.github.io/2025/05/19/profiling-challenge-results.html">yesterday’s problem</a>, where I <em>suspect</em>
          that I have an outdated version of <a href="https://github.com/KDAB/hotspot">hotspot</a> Linux profiler, but I can’t just go and download a fresh
          release from GitHub, because hotspot is a KDE app, and I use NixOS.
          And NixOS isn’t a problem — it’s a solution.
        </p>
        <p>
          Linux on desktop is a rickety tower of competing libraries, protocols
          and standards, which is always in an Escheresque sort of perpetual
          motion, taking off but simultaneously falling, and the best way to
          enjoy it is to take a photo, a frozen snapshot in time.
        </p>
        <p>
          The underlying force there is the absence of one unified baseline set
          of APIs for writing desktop programs. There’s no single entity that
          can coordinate the API, in contrast to Windows and MacOS.
        </p>
        <p>
          But then, how can Linux exist? How does that square with “never break
          the user space?” I’ll let you ponder the question, but let me first
          tell you a story from a domain where I consider myself an expert.
        </p>
        <section id="Better-LSP-Than-Never">
          <h2>
            <a href="#Better-LSP-Than-Never">Better LSP Than Never </a>
          </h2>
          <p>
            The past ten years saw a big shift in how we are writing software:
            baseline level of “interactive static analysis” became the norm, go
            to definition is universally available. The surprising fact here is
            that the shift occurred a decade too late!
          </p>
          <p>
            The shift was caused by Microsoft releasing its Language Server
            Protocol specification. But there’s little value in the protocol
            itself. Its implementation is
            <a href="https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html">mediocre</a>, it was strictly worse than <a href="https://htmlpreview.github.io/?https://github.com/dart-lang/sdk/blob/8e6a02d899ef62ef5b8405518b36340e609198e2/pkg/analysis_server/doc/api.html">the state of the art at that time</a>, and its
            <a href="https://github.com/microsoft/language-server-protocol/pull/2027#issuecomment-2822857896">governance is abysmal</a>. The only great thing about LSP is that
            it exists!
          </p>
          <p>
            If you were anywhere near JetBrains a decade ago, it was blindingly
            obvious that the absence of broad availability of basic IDE features
            leaves a lot of the value on the table, and that the multi-process
            IPC architecture is the way to go (JetBrains did IPC for Rider). But
            it is also clear why JetBrains didn’t do LSP — why would they? While
            the right solution on the technical grounds, you aren’t going to get
            paid for being technically right. As sad as it is, some amount of
            <a href="https://en.wikipedia.org/wiki/Deadweight_loss">deadweight loss</a> is needed to capture some of the value you are
            producing, and you need to be able to capture value to invest in
            things! So the world had to wait for Microsoft to pick up the slack
            here, when they decided to gobble up the entire developer ecosystem
            as an investment.
          </p>
          <p>
            There was a decade of opportunity for OSS to coordinate around an
            IDE protocol, but that didn’t happen, because OSS is bad at
            coordination.
          </p>
        </section>
        <section id="Why-Linux">
          <h2>
            <a href="#Why-Linux">Why Linux? </a>
          </h2>
          <p>
            But then, why and how does Linux exist? I think part of that is a
            rather unique governance structure, where there’s a centralized
            control over the API area and strong commitment to the public
            interfaces. But the bigger part is POSIX. The reason why we have
            Linux, and BSDs, and XNU is that they all provide the same baseline
            API, which was defined from the outside. The coordination problem
            was pre-solved, and what remained is just filling-in the
            implementation. But there was no one to coordinate Linux on desktop.
          </p>
        </section>
      </article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infinite Mac OS X (193 pts)]]></title>
            <link>https://blog.persistent.info/2025/03/infinite-mac-os-x.html</link>
            <guid>44323719</guid>
            <pubDate>Fri, 20 Jun 2025 00:16:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.persistent.info/2025/03/infinite-mac-os-x.html">https://blog.persistent.info/2025/03/infinite-mac-os-x.html</a>, See on <a href="https://news.ycombinator.com/item?id=44323719">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p><strong>tl;dr:</strong> Infinite Mac can now <a href="https://infinitemac.org/?filter=macosx">run early Mac OS X</a>, with <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1">10.1</a> and <a href="https://infinitemac.org/2003/Mac%20OS%20X%2010.3">10.3</a> being the best supported versions. It’s not particularly snappy, but as someone who lived through that period, I can tell you that it wasn’t much better on real hardware. Infinite HD has also been rebuilt to have some notable indie software from that era.</p>

<p>
  <img alt="Mac OS X 10.1 running NetNewsWire Lite and Terminal" height="928" src="https://persistent.info/images/infinite-mac-mac-os-x-10.1.webp" width="1184">
</p>

<h3>Porting PearPC</h3>

<p>I’ve been <a href="https://github.com/search?q=repo%3Amihaip%2Finfinite-mac+219&amp;type=commits&amp;s=committer-date&amp;o=desc">tracking</a> DingusPPC progress since my initial <a href="https://blog.persistent.info/2023/12/dingusppc.html">port</a> and making the occasional contribution <a href="https://github.com/dingusdev/dingusppc/commits?author=mihaip">myself</a>, with the hope of using it to run Mac OS X in Infinite Mac. While it has continued to improve, I reached a plateau last summer; my attempts would result in either kernel panics or graphical corruption. I tried to reduce the problem a bit via a <a href="https://github.com/dingusdev/dingusppc/pull/120">deterministic execution mode</a>, but it wasn’t really clear where to go next. I decided to take a break from this emulator and explore alternate paths of getting Mac OS X to run.</p>

<p><a href="https://github.com/sebastianbiallas/pearpc">PearPC</a> was the obvious choice – it was created with the express purpose of emulating Mac OS X on x86 Windows and Linux machines in the early 2000s. By <a href="https://www.osnews.com/story/7085/pearpc-01-is-it-a-miracle/">all accounts</a>, it did this successfully for a few years, until interest waned after the Intel switch. I had earlier <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=I%20also%20briefly%20considered%20PearPC%20(which%20is%20much%20more%20focused%20on%20early%20PowerMacs%20than%20QEMU)%2C%20but%20it%E2%80%99s%20also%20in%20a%20state%20of%20abandonment%20(development%20mostly%20stopped%20in%202005%2C%20with%20a%20brief%20resurrection%20in%202015).">dismissed it</a> as a “dead” codebase, but I decided that the satisfaction of getting something working compensated for dealing with legacy C++ (complete with its own <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/str.h">string class</a>, <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/tools/snprintf.cc">sprintf implementation</a>, and <a href="https://github.com/sebastianbiallas/pearpc/blob/master/src/system/gif.cc">GIF decoder</a>). An encouraging discovery was that <a href="https://github.com/kanjitalk755">kanjitalk755</a> (the de-facto Basilisk II and SheepShaver maintainer) had somewhat recently set up <a href="https://github.com/sebastianbiallas/pearpc/compare/master...kanjitalk755:pearpc:macos_sdl2">an experimental branch</a> of PearPC that built and ran on modern macOS. I was able to replicate their work without too much trouble, and with that existence proof I started on my sixth port of an emulator to WebAssembly/Emscripten and the Infinite Mac runtime.</p>

<p>In some ways PearPC not being actively developed made things easier –&nbsp;I didn’t have to worry about merging in changes from upstream, or agonize over how to structure my modifications to make them easier to contribute back. It was also helpful that PearPC was already a multi-platform codebase and thus had the right layers of abstraction to make adding another target pretty easy. As a bonus, it didn’t make pervasive use of threads or other harder-to-port concepts. Over the course of a few days, I was able to <a href="https://github.com/mihaip/pearpc/commit/a63c1145964843c09e4d21fc55c182ccb53e82ce">get it to build</a>, <a href="https://github.com/mihaip/pearpc/commit/b13f6813321af579895122a71aa09ba2cb793717">output video</a>, <a href="https://github.com/mihaip/pearpc/commit/dde5322f13a2ca64727cd94a98795f5c1f20f6b0">load disk images</a>, and <a href="https://github.com/mihaip/pearpc/commit/526ba08845122e991268c5d995167efbd083ac8e">get mouse and keyboard input</a> hooked up. It was pretty satisfying to have Mac OS X 10.2 running in a browser more reliably than it previously had.</p>

<h3>Performance</h3>

<p>While PearPC ran 10.2 more reliably, it felt slower than DingusPCC. I had spent some time last year making <a href="https://github.com/dingusdev/dingusppc/commit/564c43c907917f498d7090c6f108ead03f6b123d">some</a> <a href="https://github.com/dingusdev/dingusppc/commit/b759f25d87a21b95ea0384fa9a83644591bb6305">optimizations</a> to the latter, partly inspired by the <a href="https://github.com/kwhr0/macemu/blob/master/SheepShaver/src/TinyPPC.cpp">TinyPPC emulator</a> in <a href="http://kwhr0.g2.xrea.com/macemu.html">this SheepShaver fork</a> (aren’t all these names fun?). I <a href="https://github.com/mihaip/pearpc/commit/0856ed0acb9674420fb6c858e684a02033b3cdc3">ported</a> DingusPPC’s benchmark harness and then <a href="https://github.com/mihaip/pearpc/commit/75dbcfb9f5e28735792bff085d58cb206631564b">set</a> <a href="https://github.com/mihaip/pearpc/commit/71059084de0169b760f4c908d52961d2e69399a1">about</a> <a href="https://github.com/mihaip/pearpc/commit/c87caace8a5479caf160a6a0a8d9183de5165132">replicating</a> <a href="https://github.com/mihaip/pearpc/commit/4ac34d860b0b58d6ff3cefa630d98f5681443b5b">the</a> <a href="https://github.com/mihaip/pearpc/commit/3e979205950b9d540577204d8e86a494f53157a2">performance</a> <a href="https://github.com/mihaip/pearpc/commit/14d050101f1ada51c49197e494211f7e9e15e847">work</a> <a href="https://github.com/mihaip/pearpc/commit/c3b29968fde9c5d860ba9fdfcf5c5a3b3537760b">in</a> <a href="https://github.com/mihaip/pearpc/commit/6cad14c927b12ec832709d15d9663ba1b2b0dd78">PearPC</a> (both emulators are pure interpreters driven by a lookup table, so the process was relatively straightforward). I was able to shave off about 15 seconds from the 10.2 boot time – it helps from a <a href="https://folklore.org/Saving_Lives.html">saving lives perspective</a>, but is still not enough given that it takes almost 2 minutes to be fully operational. In the end, I copped out and <a href="https://github.com/mihaip/infinite-mac/commit/280a527ef0b682dc142bd14ec61cbe37978a39f7">added a UI disclaimer</a> that Mac OS X can be slow to boot. I also got flashbacks to the <a href="https://arstechnica.com/gadgets/2001/04/macos-x/#page-6:~:text=will%20Mac%20OS%20X%20have%20a%20snappy%20UI">“is it snappy yet?”</a> discussions from the early days of Mac OS X –&nbsp;it was indeed slow, but not this slow.</p>

<p>Performance is still not as good as DingusPPC’s – the biggest bottleneck is the lack of any kind of caching in the MMU, so all loads and stores are expensive since they involve complex address computations. DingusPPC has a much more mature <a href="https://github.com/dingusdev/dingusppc/blob/master/zdocs/developers/cpu/powerpc/mmuemu.md">tiered cache</a> that appears to be quite effective. More generally, while PearPC may be more stable than DingusPPC at running 10.2-10.4, it’s a much less principled codebase (I came across <a href="https://github.com/sebastianbiallas/pearpc/commit/152604c0af3f0613bae37cf4287f188a42be0c06">many mystery commits</a>) and it “cheats” in many ways (it has a <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/io/prom/promboot.cc#L977">custom</a> firmware and <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/ppccfg.example#L75-L78">video driver</a>, and only the <a href="https://github.com/sebastianbiallas/pearpc/blob/7eb63de8a92b86e1b7438019ddcf935005112501/src/cpu/cpu_generic/ppc_alu.cc#L116-L117">subset</a> of PowerPC instructions that are needed for Mac OS X are implemented). I’m still holding out hope for DingusPPC to be the fast, stable, and correct choice for the long term.</p>

<h3>A Side Quest</h3>

<p>I implemented the “unified decoding table” approach in PearPC’s interpreter one opcode family at a time. When I got to the floating point operations, I assumed it was going to be another mechanical change. I was instead surprised to see that behavior regressed – I got some rendering glitches in the Dock, and the Finder windows would not open at all. After some debugging, I noticed that the <a href="https://github.com/mihaip/pearpc/blob/3e979205950b9d540577204d8e86a494f53157a2/src/cpu/cpu_generic/ppc_dec.cc#L106-L172">dispatching for opcode groups 59 and 63</a> didn’t just do a basic lookup on the relevant instruction bits. It first checked the <code>FP</code> bit of the <a href="https://en.wikipedia.org/wiki/Machine_state_register">Machine State Register (MSR)</a>, and if it was not set it would throw a “floating point unavailable” exception.</p>

<p>I initially thought this was the emulator being pedantic – all PowerPC chips used in Macs had an FPU, so this should never happen. However, setting a breakpoint showed that the exception was being hit pretty frequently during Mac OS X startup. The <a href="https://github.com/apple-oss-distributions/xnu/tree/xnu-124.7">xnu kernel sources</a> of that time period are available, and though I’m not familiar with the details, there are places where the FP bit <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L201">is</a> <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L1012">cleared</a> and a <a href="https://github.com/apple-oss-distributions/xnu/blob/xnu-124.7/osfmk/ppc/cswtch.s#L656-L707">handler for the resulting exception</a> is registered. I assume this is an optimization to avoid having to save/restore FPU registers during context switches (if they’re not being used). The upshot was that once I implemented the equivalent <code>FP</code> check in my optimized dispatch code, the rendering problems went away.</p>

<p>This reminded me of the rendering glitches that I had encountered when trying to run Mac OS X under DingusPPC. Even when booting from the 10.2 install CD (which does not kernel panic) I would end up with missing text and other issues:</p>

<p>
  <img alt="Mac OS X 10.2 installer showing text rendering glitches" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-broken.webp" width="832">
</p>

<p>Checking the DingusPPC sources showed that it never checked the <code>FP</code> bit, and always allowed floating point instructions to go through. I did a quick hack to check it and raise an exception if needed, and the glitches went away!</p>

<p>
  <img alt="Mac OS X 10.2 installer correctly rendering text" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-10.2-installer-fixed.webp" width="832">
</p>

<p>The <a href="https://github.com/dingusdev/dingusppc/pull/135">proper implementation</a> was a bit more complicated, and I ended up <a href="https://github.com/dingusdev/dingusppc/pull/136">revising it a bit</a> to avoid a performance hit (and another contributor did <a href="https://github.com/dingusdev/dingusppc/commit/82a48899f0c28a9418a07b56b5d39f7e161b1549">another pass</a>). But at the end of it all, DingusPPC became a lot more stable, which was a nice side effect. Better yet, it can run 10.1 reliably, which PearPC cannot. I ended up using a combination of both emulators to run a broader subset of early Mac OS X (unfortunately 10.0 is still unstable, and the Public Beta kernel panics immediately, but I’m holding out hope for the future).</p>

<h3>Rebuilding Infinite HD</h3>

<p>Part of the appeal of Infinite Mac is that the emulated machines also have an “Infinite HD” mounted with a lot of era-appropriate software to try. With Mac OS X running, it was time to build an alternate version that went beyond the 80s and 90s classic Mac apps I had collected. I had my favorites, but I also <a href="https://hachyderm.io/@mihaip/113977444999284253">put out a call for suggestions</a> and got plenty of ideas.</p>

<p>For actually building the disk image, I extended the <a href="https://blog.persistent.info/2022/03/blog-post.html#:~:text=Building%20Disk%20Images%2C%20or%20Docker%201995%2Dstyle">automated approach</a> that I first launched the site with. Disk images were even more popular in the early days of Mac OS X than they are today, so I <a href="https://github.com/mihaip/infinite-mac/commit/a7f69373a7b2eb1d85ea33e975180b4a2ca02a44">added a way</a> to import .dmgs as additional folders in the generated image. However, I quickly discovered that despite having the same extension, there are <a href="https://github.com/libyal/libmodi/blob/main/documentation/Mac%20OS%20disk%20image%20types.asciidoc#1-overview">many variants</a>, and the <code>hdiutil</code> that ships with modern macOS cannot always mount images generated more than 20 years ago. In the end I ended up with a <a href="https://github.com/mihaip/infinite-mac/commit/119000a268bb3f21180e06ea899331b2307b695e">Rube Goldberg approach</a> that first extracts the raw partition via <a href="https://github.com/Lekensteyn/dmg2img">dmg2img</a> and then recreates a “modern” disk image that can be mounted and copied from.</p>

<p>As for getting the actual software, the usual sites like <a href="https://macintoshgarden.org/">Macintosh Garden</a> do have some from that era, but it’s not a priority for them. Early to mid 2000s Mac OS X software appears to be a bit of a blind spot –&nbsp;it’s too new to be truly “retro”, but too old to still be available from the original vendor (<a href="https://rogueamoeba.com/legacy/">though</a> <a href="https://files.omnigroup.com/software/MacOSX/">there</a> <a href="https://download-cdn.panic.com/">are</a> <a href="https://c-command.com/dropdmg/support#older-versions">exceptions</a>). I ended up using the <a href="https://web.archive.org/">Wayback Machine</a> a lot. As a bonus, I also installed the companion “Developer” CDs for each Mac OS X version, so tools like Project Builder and Interface Builder are also accessible.</p>

<p>
  <img alt="Mac OS X 10.4 running Delicious Library, CandyBar, PCalc and Pixelmator" height="768" src="https://persistent.info/images/infinite-mac-mac-os-x-hd.webp" width="1024">
</p>

<p>The only limitation that I ran into is that my disk build process is centered around HFS, but HFS+ was the default of that time period, and it introduced more advanced capabilities like longer file names containing arbitrary Unicode characters. Files from disk images that rely HFS+ features do not translate losslessly, but luckily this was not an issue for most software. To actually mount multiple drives (up to 3, between the boot disk, Infinite HD, and <a href="https://blog.persistent.info/2023/09/infinite-mac-improved-persistence.html">Saved HD</a>), I <a href="https://github.com/mihaip/dingusppc/commit/51019e4fa0109fa8268cd547b92dee0e7065ac5c">ended</a> <a href="https://github.com/mihaip/pearpc/commit/93f224a8a9676479ff79aad9bf7632d400a5c693">up</a> <a href="https://github.com/mihaip/dingusppc/commit/b220d7b9ed39953780d2a42f9f83caaf8a6cf06e">borrowing</a> a clever solution from a <a href="https://github.com/joevt/dingusppc/">DingusPPC fork</a>: a multi-partition disk image is created on the fly from an arbitrary number of partition images that are specified at startup.</p>

<h3>Aqua</h3>

<p>To make the addition of Mac OS X to Infinite Mac complete, I also wanted to have an Aqua mode for the site’s controls, joining the <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=To%20reduce%20the%20cognitive%20dissonance%20(and%20to%20have%20a%20bit%20of%20fun)%2C%20I%20made%20the%20UI%20resemble%20the%20look%2Dand%2Dfeel%20of%20the%20OS%20that%20is%20being%20booted">classic, Platinum</a>, and <a href="https://blog.persistent.info/search/label/Infinite%20Mac#:~:text=With%20the%20initial%20emulator%20being%20brought%20up%2C%20there%20were%20some%20more%20fun%20tasks%2C%20like%20adding%20a%20NeXT%2Dstyle%20monitor%20frame%20and%20a%20NeXT%20appearance%20to%20the%20Infinite%20Mac%20controls%20(working%20on%20them%20is%20giving%20me%20Kaleidoscope%20scheme%20flashbacks).">NeXT</a> appearances. That prompted the question: <a href="https://512pixels.net/projects/aqua-screenshot-library/">which Aqua</a>?</p>

<p>
  <img alt="Screenshots of the logout dialog in Mac OS X 10.1 to 10.4" height="369" src="https://persistent.info/images/infinite-mac-mac-os-x-aqua.webp" width="901"><br>
  <i>Aqua: the early years</i>
</p>

<p>Though the more subdued versions from 10.3 and 10.4 are my favorites, I decided to go with the 10.0/10.1 one since it has the biggest nostalgia factor. I wanted to use the exact same image assets as the OS, and since they make heavy use of semi-transparency, regular screenshots were not going to be good enough. I used <a href="https://github.com/fuzziqersoftware/resource_dasm">resource_dasm</a> and <a href="https://kwasi-ich.de/software/aqua/">pxm2tga</a> to extract the original assets from <a href="http://www.atpm.com/11.06/customizing.shtml">Extras.rsrc</a> and create <a href="https://github.com/mihaip/infinite-mac/commit/cbc6a3ea8ac0523fbea27dbd57770837c60465db">my own version of Aqua</a>:</p>

<p>
  <img alt="Infinite Mac custom instance configuration dialog, rendered with an Aqua appearance" height="708" src="https://persistent.info/images/infinite-mac-mac-os-x-custom.webp" width="661">
</p>

<p>If the recent rumors of a <a href="https://www.bloomberg.com/news/articles/2025-03-10/apple-readies-dramatic-design-overhauls-for-ios-19-ipados-19-and-macos-16">big UI revamp</a> do come true, it’ll be nice to have this reference point of its ancestor.</p>

<h3>Odds and Ends</h3>

<p>The ability to mount multiple images means that you can also have a Mac OS 9 partition and start the Classic compatibility environment (this only works under 10.1 – PearPC never supported Classic). You can thus emulate classic Mac apps inside an emulated Mac OS X inside a WebAssembly virtual machine:</p>

<p>
  <img alt="Mac OS X 10.1 running Stickies, Scrapbook and Calculator under Classic" height="624" src="https://persistent.info/images/infinite-mac-mac-os-x-classic.webp" width="832">
</p>

<p>There was a recent storm in a teacup about <a href="https://mjtsai.com/blog/2025/01/30/repeating-calculator-operations/">a Calculator behavior change</a>. Using these Mac OS X images, it’s possible to verify that versions through 10.3 didn’t have the “repeatedly press equals” behavior, but 10.4 did.</p>

<p>Since Mac OS X boot is rather slow, I wanted to have a way to show more progress. PearPC has <a href="https://github.com/mihaip/infinite-mac/blob/cb6b16c3ace1b36c9228d991397176c0036bc960/src/Data/PearPCConfig.txt#L56-L61">a built-in way</a> to trigger verbose mode, but DingusPPC did not, so I added a way to <a href="https://github.com/dingusdev/dingusppc/commit/a6e1b8c338b4b93fcafe97605dc8b493c61fb2a3">specify Open Firmware variables at startup</a>. This is now exposed in the <a href="https://infinitemac.org/2001/Mac%20OS%20X%2010.1?edit">custom instance dialog</a> via the “Debug Mode” switch.</p>

<p>Though I’ve moved away from custom domain names, I thought <a href="https://macosx.app/">macosx.app</a> would make a nice <a href="https://system6.app/">addition</a> <a href="https://system7.app/">to</a> <a href="https://macos8.app/">my</a> <a href="https://macos9.app/">collection</a>. Unfortunately it’s taken, though in a rather weird way. I even contacted the YouTuber whose video it redirects to, and he said he was not the one that registered it. It expires in a couple of months, so maybe I’ll be able to grab it.</p>

<h3>The End Of The Line?</h3>

<blockquote>“When Alexander saw the breadth of his domain, he wept for there were no more worlds to conquer.”<br>
— <s>Hans Gruber</s> <s>Plutarch</s> <a href="https://www.theparisreview.org/blog/2020/03/19/and-alexander-wept/">Some Frenchman</a></blockquote>

<p>Mac OS X support catches Infinite Mac up to the modern day, unless I happen to get access to some <a href="https://web.archive.org/web/20171006210639/https://twitter.com/mcclure111/status/916405883202129921">time travel mechanics</a>. There are of course two more CPU transitions to go through and numerous small changes, but Tiger is fundamentally recognizable to any current-day macOS user.</p>
<p>Except that in the retrocomputing world, it’s always possible to go deeper or more obscure. <a href="https://en.wikipedia.org/wiki/A/UX">A/UX</a> is not something that I’m very familiar with, but it was a contemporary of classic Mac OS and would be interesting to compare to NeXTStep. <a href="https://github.com/pruten/shoebill">Shoebill</a> runs it, and the codebase looks approachable enough to port. Then there’s <a href="https://github.com/mihaip/infinite-mac/issues/167">Lisa</a>, the <a href="https://en.wikipedia.org/wiki/Apple_Pippin">Pippin</a> (DingusPPC has some <a href="https://github.com/dingusdev/dingusppc/blob/master/machines/machinepippin.cpp">nascent support</a>), and further afield the Newton (via <a href="https://github.com/pguyot/Einstein">Einstein</a>?). We’ll see what moves me next.</p>

<h3>A Post-Credits Sequence</h3>

<p>When I first began exploring ways of running Mac OS X, I mentioned that <a href="https://blog.persistent.info/2023/12/dingusppc.html#:~:text=The%20obvious%20choice%20was%20QEMU%20%E2%80%93%20it%20has%20very%20broad%20guest%20OS%20support%20and%20is%20very%20actively%20developed.%20However%2C%20it%E2%80%99s%20also%20a%20beast%20of%20a%20project%20to%20build%20and%20navigate%20around%3B%20it%20didn%E2%80%99t%20seem%20like%20it%20would%20be%20something%20I%20would%20able%20to%20make%20much%20progress%20on%20while%20working%20on%20it%20for%20a%20few%20hours%20a%20week.">QEMU seemed too daunting to port</a> to WebAssembly given my limited time. Furthermore, the performance of the <a href="https://github.com/atrosinenko/qemujs">qemu.js</a> experiment from a few years ago made it seem like even if it did run, it would be much too slow to be usable. However, I recently became aware of <a href="https://github.com/ktock/qemu-wasm">qemu-wasm</a> via <a href="https://fosdem.org/2025/schedule/event/fosdem-2025-6290-running-qemu-inside-browser/">this FOSDEM presentation</a>. The performance of its Linux guest <a href="https://ktock.github.io/qemu-wasm-demo/">demos</a> is encouraging: I ran an impromptu bennmark of computing an MD5 checksum of 100 MB of data and it completed it in 8 seconds (vs. 13 for DingusPPC and 18 for PearPC). There’s still a big gap between that and a graphical guest like Mac OS X, but it’s nice to have this existence proof.</p>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I wrote a new BitTorrent tracker in Elixir (256 pts)]]></title>
            <link>https://github.com/Dahrkael/ExTracker</link>
            <guid>44323253</guid>
            <pubDate>Thu, 19 Jun 2025 22:49:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Dahrkael/ExTracker">https://github.com/Dahrkael/ExTracker</a>, See on <a href="https://news.ycombinator.com/item?id=44323253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Dahrkael/ExTracker/blob/master/.github/extracker-logo.png"><img src="https://github.com/Dahrkael/ExTracker/raw/master/.github/extracker-logo.png" alt="ExTracker"></a>
The Bittorrent Tracker made in Elixir</p>
<p dir="auto"><a href="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/build-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/test-on-push.yml/badge.svg" alt="CI"></a>
<a href="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml"><img src="https://github.com/Dahrkael/ExTracker/actions/workflows/docker-release.yml/badge.svg" alt="CI"></a></p>
<p dir="auto">👷‍♂️This project is a Work In Progress. While not ready for full industrial usage it does work.<br>
There is a testing instance running at <a href="http://extracker.dahrkael.net:6969/about" rel="nofollow">extracker.dahrkael.net:6969</a> with all current features enabled (<a href="http://extracker.dahrkael.net:9568/tracker-stats.html" rel="nofollow">Live statistics</a>).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<p dir="auto">Implementation Legend:
🔲 Not Yet 🔰 Partially ✅ Done ❌ Won't do</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Important Features</h3><a id="user-content-important-features" aria-label="Permalink: Important Features" href="#important-features"></a></p>
<ul dir="auto">
<li>✅ High performance (uses ALL the available cores, in-memory storage)</li>
<li>✅ Low memory usage (~200MB of RAM for each 1.000.000 peers)</li>
<li>✅ Zero setup (launch it and it just works)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Tracker-related BitTorrent Enhancement Proposals</h3><a id="user-content-tracker-related-bittorrent-enhancement-proposals" aria-label="Permalink: Tracker-related BitTorrent Enhancement Proposals" href="#tracker-related-bittorrent-enhancement-proposals"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Final and Active Process BEPs</h4><a id="user-content-final-and-active-process-beps" aria-label="Permalink: Final and Active Process BEPs" href="#final-and-active-process-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 0:</strong> <a href="https://www.bittorrent.org/beps/bep_0003.html" rel="nofollow">The BitTorrent Protocol Specification</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Accepted BEPs</h4><a id="user-content-accepted-beps" aria-label="Permalink: Accepted BEPs" href="#accepted-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 15:</strong> <a href="https://www.bittorrent.org/beps/bep_0015.html" rel="nofollow">UDP Tracker Protocol</a></li>
<li>✅ <strong>BEP 23:</strong> <a href="https://www.bittorrent.org/beps/bep_0023.html" rel="nofollow">Tracker Returns Compact Peer Lists</a></li>
<li>🔲 <strong>BEP 27:</strong> <a href="https://www.bittorrent.org/beps/bep_0027.html" rel="nofollow">Private Torrents</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Draft BEPs</h4><a id="user-content-draft-beps" aria-label="Permalink: Draft BEPs" href="#draft-beps"></a></p>
<ul dir="auto">
<li>✅ <strong>BEP 7:</strong> <a href="https://www.bittorrent.org/beps/bep_0007.html" rel="nofollow">IPv6 Tracker Extension</a></li>
<li>🔲 <strong>BEP 21:</strong> <a href="https://www.bittorrent.org/beps/bep_0021.html" rel="nofollow">Extension for partial seeds</a></li>
<li>✅ <strong>BEP 24:</strong> <a href="https://www.bittorrent.org/beps/bep_0024.html" rel="nofollow">Tracker Returns External IP</a></li>
<li>🔲 <strong>BEP 31:</strong> <a href="https://www.bittorrent.org/beps/bep_0031.html" rel="nofollow">Tracker Failure Retry Extension</a></li>
<li>✅ <strong>BEP 41:</strong> <a href="https://www.bittorrent.org/beps/bep_0041.html" rel="nofollow">UDP Tracker Protocol Extensions</a></li>
<li>🔰 <strong>BEP 48:</strong> <a href="https://www.bittorrent.org/beps/bep_0048.html" rel="nofollow">Tracker Protocol Extension: Scrape</a></li>
<li>✅ <strong>BEP 52:</strong> <a href="https://www.bittorrent.org/beps/bep_0052.html" rel="nofollow">The BitTorrent Protocol Specification v2</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Deferred BEPs</h4><a id="user-content-deferred-beps" aria-label="Permalink: Deferred BEPs" href="#deferred-beps"></a></p>
<ul dir="auto">
<li>❌ <strong>BEP 8:</strong> <a href="https://www.bittorrent.org/beps/bep_0008.html" rel="nofollow">Tracker Peer Obfuscation</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Other Features</h3><a id="user-content-other-features" aria-label="Permalink: Other Features" href="#other-features"></a></p>
<ul dir="auto">
<li>✅ HTTPS support</li>
<li>✅ Database backups to disk</li>
<li>❌ WebTorrent</li>
<li>🔰 Infohash whitelist/blacklist</li>
<li>🔰 Peer management (interval enforcement, cleanup, banning, etc)</li>
<li>🔰 Metrics</li>
<li>🔰 GeoIP support (statistics, peer restrictions)</li>
<li><strong>Feel free to propose features in the <a href="https://github.com/Dahrkael/ExTracker/issues">Issues</a></strong></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Setup</h2><a id="user-content-setup" aria-label="Permalink: Setup" href="#setup"></a></p>
<p dir="auto">There are 3 main ways of running ExTracker currently</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Straight from source code</h3><a id="user-content-straight-from-source-code" aria-label="Permalink: Straight from source code" href="#straight-from-source-code"></a></p>
<p dir="auto">For this method to work you need to have <strong>Erlang</strong> and <strong>Elixir</strong> installed on your system</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">config/runtime.exs</a> to fit your needs</li>
<li>run <code>MIX_ENV=prod iex -S mix</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">From Releases</h3><a id="user-content-from-releases" aria-label="Permalink: From Releases" href="#from-releases"></a></p>
<p dir="auto">Currently there are no official releases built (soon™️). You can however make your own and deploy it where needed:</p>
<ul dir="auto">
<li>Clone the repository: <code>git clone https://github.com/Dahrkael/ExTracker.git &amp;&amp; cd ExTracker</code></li>
<li>run <code>MIX_ENV=prod mix release extracker</code> for Linux or <code>MIX_ENV=prod mix release extrackerw</code> for Windows</li>
<li>Find the release files inside the <em>_build/prod/rel/extracker</em> folder (if its a different machine make sure the OS and architecture is the same!)</li>
<li>Copy the folder to its final destination</li>
<li>If needed, modify the configuration in <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">releases/{VERSION}/runtime.exs</a> to fit your needs</li>
<li>Run <code>bin/extracker start</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Docker</h3><a id="user-content-docker" aria-label="Permalink: Docker" href="#docker"></a></p>
<p dir="auto">For this method you can directly run the <a href="https://github.com/Dahrkael/ExTracker/pkgs/container/extracker/422008654?tag=latest">available docker image</a>: <code>docker run ghcr.io/dahrkael/extracker:latest</code><br>
or use it as part of docker-compose. Theres an <a href="https://github.com/Dahrkael/ExTracker/blob/master/docker-compose.yml">example compose file</a> available.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Since modifying the <a href="https://github.com/Dahrkael/ExTracker/blob/master/config/runtime.exs">runtime.exs</a> file to tune the configuration inside the container is not easy you can also configure it using <strong>Environment Variables</strong>, see the example compose file for the complete list.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Copyright and license</h2><a id="user-content-copyright-and-license" aria-label="Permalink: Copyright and license" href="#copyright-and-license"></a></p>
<p dir="auto">Copyright (c) Dahrkael &lt;dahrkael at outlook dot com&gt;<br>
Distributed under the terms of the Apache License, Version 2.0. Please refer to the <a href="https://github.com/Dahrkael/ExTracker/blob/master/LICENSE">LICENSE file</a> in the repository root directory for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Estrogen: A Trip Report (149 pts)]]></title>
            <link>https://smoothbrains.net/posts/2025-06-15-estrogen.html</link>
            <guid>44322153</guid>
            <pubDate>Thu, 19 Jun 2025 20:15:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://smoothbrains.net/posts/2025-06-15-estrogen.html">https://smoothbrains.net/posts/2025-06-15-estrogen.html</a>, See on <a href="https://news.ycombinator.com/item?id=44322153">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
    
    
    <section>
        
<hr>

<hr>
<p>I have <a href="https://en.wikipedia.org/wiki/Gender_dysphoria">gender dysphoria</a>. I find labels overly reifying; I feel reluctant to call myself <em>transgender</em>, per se: when prompted to state my gender identity or preferred pronouns, I fold my hands into the <a href="https://www.yogapedia.com/definition/6871/dhyana-mudra"><em>dhyana mudra</em></a> and state that I <em>practice <a href="https://en.wikipedia.org/wiki/%C5%9A%C5%ABnyat%C4%81">emptiness</a> on the concept of gender</em>. Mostly people seem to vibe it, but sometimes it feels a little like weasel words. Other times, when I’m in a sillier mood, I’ll tell people I’m <em>genderfluid</em> – if only because it sounds like something I’d put in my station wagon. Of course, my faithful Subaru Outback was made before 2008, which means it wants the <a href="https://www.amazon.com/Genuine-Subaru-SOA868V9210-Coolant-Gallon/dp/B007L72U1C/">green, long-life genderfluid</a>…</p>
<p>I experience an ongoing <a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">brain-body map</a> <a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/">prediction error</a> – my brain seems to expect a differently shaped body to the one I wound up with. I have been acutely aware of this since before I hit puberty. Out of shame and embarassment, I suppressed this, but I also made a promise to myself that if I hadn’t come out by the time I turned thirty then I was allowed to get as weird as I needed to.</p>
<!-- To expand on the above: While I experience strong bodily dysphoria, I don't necessarily experience strong dysphoria around my sense of identity. It's possible that this is because I'm so chronically depersonalised that there's nothing really *there* to hang a sense of identity on. It's also possible that any sense of femininity I once felt was so deeply buried by the time I unearthed all this that I have a difficult time reconnecting to it. -->
<p>During the COVID-19 pandemic I went through a phase of using self-administered ketamine therapy to refactor a long list of maladaptive behavioural patterns, and eventually this particular issue became impossible to ignore. I had avoided reifying it for long enough, and this wasn’t working for me – I had to try something different. One evening in July 2021, I sat down with a close friend. <em>I am going to put a large amount of ketamine up my nose</em>, I said. <em>Your job is to start asking me questions about my sexuality.</em></p>
<p>Not long after, I had jumped through the relevant bureaucratic hoops, <!-- backed up my gametes, --> and subsequently found myself cycling home from the pharmacy with a paper bag filled with repurposed menopause medication – a starter pack of <em>100 µg/24 hr</em> estradiol patches, to be applied twice a week.</p>
<figure>
<img src="https://smoothbrains.net/images/random/estrogen/patches.jpg">
</figure>
<p>While the <em>physical</em> effects of estrogen are <a href="https://genderdysphoria.fyi/en/second-puberty-fem">well-documented</a>, back when I came out I had difficulty finding detailed phenomenological reports of the <em>subjective</em> effects of estrogen. I did wind up reading a large number of anecdotal reports on <a href="https://www.reddit.com/r/asktransgender">Reddit</a>, and found that in aggregate, people tend to report <a href="https://www.reddit.com/r/asktransgender/comments/rfpokm/mental_effects_of_estrogen_hrt/">positive subjective effects</a>. One could propose a number of non-exclusive hypotheses as to why – I’ll attempt to review these later in this post.</p>
<p>Did it make sense for me to try this? It was time to find out for myself. I unboxed the patches and placed one on my stomach.</p>

<h2 id="what-does-estrogen-do"><a href="#what-does-estrogen-do">What does estrogen <em>do</em>?</a></h2>
<p>The <a href="https://en.wikipedia.org/wiki/Sex_hormone">sex hormones</a> – <a href="https://en.wikipedia.org/wiki/Androgen">androgens</a>, <a href="https://en.wikipedia.org/wiki/Estrogen">estrogens</a>, and <a href="https://en.wikipedia.org/wiki/Progestogen">progestogens</a> – are produced by the <a href="https://en.wikipedia.org/wiki/Endocrine_system">endocrine system</a>. They are released into the bloodstream in response to a range of regulatory factors – primarily the <a href="https://en.wikipedia.org/wiki/Hypothalamic%E2%80%93pituitary%E2%80%93gonadal_axis">hypothalamic–pituitary–gonadal axis</a> – as a signal for distant cells to regulate a wide variety of bodily functions.</p>

<p>At the other end, <a href="https://en.wikipedia.org/wiki/Receptor_(biochemistry)"><em>receptors</em></a> are – very generally speaking – a class of proteins which can <a href="https://en.wikipedia.org/wiki/Conformational_change">change their shape</a> when <a href="https://en.wikipedia.org/wiki/Ligand_(biochemistry)">specific molecules</a> bind to them. Of these, <a href="https://en.wikipedia.org/wiki/Estrogen_receptor"><em>estrogen receptors</em></a> are primarily <a href="https://en.wikipedia.org/wiki/Nuclear_receptor"><em>nuclear receptors</em></a>, although a smaller fraction of them are <a href="https://en.wikipedia.org/wiki/Cell_surface_receptor"><em>cell surface receptors</em></a>. These are typically located in the cell’s <a href="https://en.wikipedia.org/wiki/Cytoplasm"><em>cytoplasm</em></a> – but when activated, they pass through the <a href="https://en.wikipedia.org/wiki/Nuclear_envelope"><em>nuclear membrane</em></a>, bind directly to DNA, and <a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression">regulate the expression of specific genes</a>. For comparison, <a href="https://en.wikipedia.org/wiki/Neurotransmitter_receptor"><em>neurotransmitter receptors</em></a> are primarily <a href="https://en.wikipedia.org/wiki/Cell_surface_receptor"><em>cell surface receptors</em></a>. These are located in the <a href="https://en.wikipedia.org/wiki/Cell_membrane"><em>cell membrane</em></a> – and when activated might <a href="https://en.wikipedia.org/wiki/Ligand-gated_ion_channel">allow ions to pass through the cell membrane</a> or <a href="https://en.wikipedia.org/wiki/Metabotropic_receptor">trigger other messaging systems within the cell</a>.</p>
<figure>
<a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression#/media/File:Regulation_of_gene_expression_by_steroid_hormone_receptor.svg"><img src="https://smoothbrains.net/images/random/estrogen/regulation_of_gene_expression.png"></a>
<figcaption>
Illustration of a hormone receptor regulating gene expression, from <a href="https://en.wikipedia.org/wiki/Regulation_of_gene_expression">Wikipedia</a>.
</figcaption>
</figure>
<p>Estrogen receptors are located throughout the body. Of these, there are two main types – <a href="https://en.wikipedia.org/wiki/ER%CE%B1">ERα</a> and <a href="https://en.wikipedia.org/wiki/Estrogen_receptor_beta">ERβ</a>. These have similar <a href="https://en.wikipedia.org/wiki/Ligand_(biochemistry)#binding_affinity">binding affinities</a> for estradiol, but are expressed in different proportions in different bodily tissues, and can have different effects on gene regulation.</p>
<p>Estrogen receptors are of course also located in the brain. <a href="https://pubmed.ncbi.nlm.nih.gov/33396472/">The Role of Estrogen Receptors and Their Signaling across Psychiatric Disorders</a> (Hwang et al., 2020) includes a map of where they are concentrated:</p>
<blockquote>
<figure>
<a href="https://pubmed.ncbi.nlm.nih.gov/33396472/#&amp;gid=article-figures&amp;pid=figure-1-uid-0"><img src="https://smoothbrains.net/images/random/estrogen/estrogen_receptor_distributions.jpg"></a>
<figcaption>
<strong>Figure 1.</strong> A schematic diagram of distributions of estrogen receptor alpha and estrogen receptor beta in our brains. The receptors have a different predominance of expression in distinct regions. ERα is predominantly expressed in the <a href="https://en.wikipedia.org/wiki/Amygdala">amygdala</a> and <a href="https://en.wikipedia.org/wiki/Hypothalamus">hypothalamus</a>, whereas ERβ is predominantly expressed in the <a href="https://en.wikipedia.org/wiki/Primary_somatosensory_cortex">somatosensory cortex</a>, <a href="https://en.wikipedia.org/wiki/Hippocampus">hippocampus</a>, <a href="https://en.wikipedia.org/wiki/Thalamus">thalamus</a>, and <a href="https://en.wikipedia.org/wiki/Cerebellum">cerebellum</a>.
</figcaption>
</figure>
</blockquote>
<p>It is not surprising, then, that estrogen can have an influence on multiple aspects of brain function, including neurotransmitter levels. There’s a recent review paper which covers the latest information we have on this. From <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1348551/full">The impact of estradiol on serotonin, glutamate, and dopamine systems</a> (Bendis et al., 2024):</p>
<blockquote>
<figure>
<a href="https://www.frontiersin.org/files/Articles/1348551/fnins-18-1348551-HTML-r1/image_m/fnins-18-1348551-t001.jpg"><img src="https://smoothbrains.net/images/random/estrogen/estradiol_table_1.png"></a>
<figcaption>
<strong>Table 1</strong>. Summary of the main findings on the role of estradiol on serotonin, glutamate, and dopamine systems.
</figcaption>
</figure>
</blockquote>
<blockquote>
<p>Estradiol is a steroid hormone that influences the serotonergic, dopaminergic, and glutamatergic systems. Estradiol exerts its effects through classical mechanisms by binding to nuclear estrogen receptors α, and β, or through nonclassical mechanisms through binding to membrane bound estrogen receptors α, β, and <a href="https://en.wikipedia.org/wiki/GPER">GPER</a>.</p>
</blockquote>
<p>The effects are so wide-ranging that any review I can write will no doubt oversimplify things. That said, I’d like to highlight two findings relevant to neurotransmitter levels:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Serotonin"><em>Serotonin</em></a> synthesis is upregulated by ERβ via <a href="https://en.wikipedia.org/wiki/Tryptophan_hydroxylase">tryptophan hydroxylase</a> transcription.</li>
<li><a href="https://en.wikipedia.org/wiki/Dopamine"><em>Dopamine</em></a> synthesis is upregulated by ERα and downregulated by ERβ via <a href="https://en.wikipedia.org/wiki/Tyrosine_hydroxylase">tyrosine hydroxylase</a> transcription. Potentially, they work in tandem to maintain homeostatic levels, but ERα has greater influence at higher estradiol levels.</li>
</ul>
<p>These neurotransmitters are, of course, <a href="https://x.com/AskYatharth/status/1615157727625637888">stereotypically</a> associated with <em>mood</em> and <em>reward</em>.</p>

<p>Estrogen receptors can also upregulate or downregulate production of neurotransmitter receptors. However, most of the evidence we have for this is from <a href="https://en.wikipedia.org/wiki/Ligand_binding_assay">binding assays</a> performed on <em>rats</em>. As stated in another review paper, <a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00037/full">Sex hormones affect neurotransmitters and shape the adult female brain during hormonal transition periods</a> (Barth et al., 2015):</p>
<blockquote>
<p>Evidence from neuroimaging findings to link estrogen and the
serotonergic system in humans are still relatively sparse. Animal
data support ovariectomy to decrease <a href="https://en.wikipedia.org/wiki/5-HT1_receptor">5-HT1</a> binding, <a href="https://en.wikipedia.org/wiki/5-HT2A_receptor">5-HT2A</a> binding and expression, and <a href="https://en.wikipedia.org/wiki/Serotonin_transporter">5-HT transporter</a> binding sites and expression. These findings have
been shown to be reversible with estrogen replacement therapy.</p>
</blockquote>
<p>This process involves several steps: First, researchers remove the ovaries from female rats, and then divide them into two groups – one receiving estrogen treatment and the other serving as a control. Next, finely sliced brain samples are taken from both groups and exposed to a radioactive ligand, which binds to the receptor of interest. Finally, these radioactive samples are used to <a href="https://en.wikipedia.org/wiki/Autoradiograph">create images on radiosensitive film</a>, which is then developed and analysed.</p>
<blockquote>
<figure>
<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6740259/"><img src="https://smoothbrains.net/images/random/estrogen/rat_hippocampi.png"></a>
<figcaption>
Autoradiographs of <sup>3</sup>H-<a href="https://en.wikipedia.org/wiki/Dizocilpine">MK-801</a> binding in the hippocampus of female rats which received: <strong>(a)</strong> a sham surgery with no ovariectomy; <strong>(b)</strong> ovariectomy and injection with a control substance; <strong>(c)</strong> ovariectomy and <em>40 μg/kg</em> estrogen; <strong>(d)</strong> ovariectomy and <em>0.5 mg/kg</em> progesterone.
</figcaption>
</figure>
</blockquote>
<p>This is not the kind of procedure we generally perform on humans. Additionally, these preclinical rat model studies concern ovarectomized female rats and are intended to inform treatment programmes for postmenopausal human women – so their relevance to humans starting from an androgenic baseline is possibly somewhat limited. Still, there’s a <a href="https://academic.oup.com/endo/article-abstract/131/2/662/2496261">couple</a> <a href="https://www.sciencedirect.com/science/article/abs/pii/096007609500075B">of</a> these studies I’d like to highlight, which found estrogen caused:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/NMDA_receptor"><em>NMDA receptor</em></a> upregulation in the <a href="https://en.wikipedia.org/wiki/Hippocampus_proper#CA1">CA1 region</a> of the <a href="https://en.wikipedia.org/wiki/Hippocampus">hippocampus</a>.</li>
<li><a href="https://en.wikipedia.org/wiki/5-HT2A_receptor"><em>5-HT2A receptor</em></a> upregulation in the <a href="https://en.wikipedia.org/wiki/Forebrain">forebrain</a>, particularly the <a href="https://en.wikipedia.org/wiki/Prefrontal_cortex">anterior frontal cortex</a>, <a href="https://en.wikipedia.org/wiki/Anterior_cingulate_cortex">anterior cingulate cortex</a>, <a href="https://en.wikipedia.org/wiki/Primary_olfactory_cortex">primary olfactory cortex</a> and the <a href="https://en.wikipedia.org/wiki/Nucleus_accumbens">nucleus accumbens</a>.</li>
</ul>
<p>That said, there <em>do</em> exist a <a href="https://pubmed.ncbi.nlm.nih.gov/12900319/">couple</a> <a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext">of</a> studies assessing the influence of estrogen on 5-HT2A receptor binding in humans, using a radioactive ligand and <a href="https://en.wikipedia.org/wiki/Positron_emission_tomography">positron emission tomography</a>. In both studies, five postmenopausal women were assessed both before and after hormone replacement therapy, and both found estrogen increased 5-HT2A receptor binding in <a href="https://en.wikipedia.org/wiki/Prefrontal_cortex">prefrontal regions</a>. The resolution is pretty low, but see for yourself:</p>
<blockquote>
<figure>
<a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext"><img src="https://smoothbrains.net/images/random/estrogen/binding_sites_5-ht2a.png"></a>
<figcaption>
Regions where 5-HT2A receptor binding potential increased following hormone replacement therapy. <strong>Row A</strong> and <strong>Row B</strong> indicate estradiol and combined estradiol and progesterone treatment respectively, with a voxel threshold of <em>P</em> &lt; 0.01. <strong>Row C</strong> indicates estradiol treatment, with a less strict voxel threshold of <em>P</em> &lt; 0.05.
</figcaption>
</figure>
</blockquote>
<p>Alright, so what are these <em>NMDA</em> and <em>5-HT2A</em> receptors responsible for? These are glutamate and serotonin receptors, respectively – and these are also the specific receptors that are <a href="https://en.wikipedia.org/wiki/Receptor_antagonist"><em>antagonised</em></a> by <a href="https://psychonautwiki.org/wiki/Ketamine">ketamine</a> and <a href="https://en.wikipedia.org/wiki/Agonist"><em>agonised</em></a> by most <a href="https://psychonautwiki.org/wiki/Serotonergic_psychedelic">serotonergic psychedelics</a>. If recreational drugs targeting these receptors can engender euphoric subjective effects – what might estrogen be capable of?</p>

<!--
Comments from Anna:

- [https://docs.google.com/document/d/1YkfMTobh2VFviFrd_9kmDwGf_IJTpJc7CBVF-Po3l-U/](https://docs.google.com/document/d/1YkfMTobh2VFviFrd_9kmDwGf_IJTpJc7CBVF-Po3l-U/)

All this is to say that I think the basic science in your post is correct, but I am significantly skeptical that:

A. Potential neurological effects of increasing estrogen levels in normal healthy adults won’t tend to get buffered out by other regulatory systems, given that you're acting a couple steps upstream
B. We should typically expect to be able to generalize from AMABs to AFABs when it comes to this kind of thing.
-->
<h2 id="what-does-estrogen-feel-like"><a href="#what-does-estrogen-feel-like">What does estrogen <em>feel like</em>?</a></h2>
<p>The subjective perceptual and psychological effects of estrogen are wide-ranging and subtle. I’ll start by discussing the more mundane sensory changes I experienced before moving on to those which might be more nebulous or ineffable.</p>
<!-- The big parts were that estrogen decreased autistic sensory sensitivities, decreased muscular tension and increased emotional fluidity. But I'll go through these in detail. -->
<h4 id="dosage"><a href="#dosage">Dosage</a></h4>
<p>At the time of writing, I’ve been on and off estrogen for a period of nearly three years. My initial dosage was one of the <em>100 µg/24 hr</em> <a href="https://en.wikipedia.org/wiki/Estradiol">estradiol</a> patches, but I doubled this after a short while. I have also tried <em>2 mg</em> <a href="https://en.wikipedia.org/wiki/Estradiol_valerate">estradiol valerate</a> pills, twice or three times daily – though this turned out to be too low, and I wound up switching back to patches. I have found using patches to result in the most striking and noticeable subjective effects. I have not yet tried injected estrogen, though I anticipate doing so before long.</p>
<!-- I did also take a [selective estrogen receptor modulator](https://transfemscience.org/articles/nonbinary-transfem-overview/#selective-estrogen-receptor-modulators-serms) because I wish to attenuate breast growth – *60 mg* [raloxifene](https://en.wikipedia.org/wiki/Raloxifene), once daily. This has worked to prevent development of breast tissue, but it has not prevented fat redistribution. It is hard to tell if this has any subjective effect. -->
<p>Additionally, at one point I tried taking a <em>300 mg</em> <a href="https://en.wikipedia.org/wiki/Progesterone">progesterone</a> suppository. This made me feel quite stupid the following day, so I did not try this again.</p>
<h3 id="gustatory-perception"><a href="#gustatory-perception">Gustatory perception</a></h3>
<p>I’ve long been in the bad habit of rolling out of bed and grabbing a Monster Zero straight from the fridge first thing in the morning, and I tend to follow this up with Diet Coke throughout the day. This means that I’m fairly attuned to the taste of artificial sweeteners, so naturally the change in taste perception was the first thing I noticed – within a day or two of first putting the patches on, I found that <em>sweet</em> things tasted <em>sweeter</em>; and <em>sour</em> things tasted both <em>sweeter</em> and more <em>metallic</em> – and the cinnamon taste in my standard reference Diet Coke really <em>shone through</em>.</p>
<p>This was rather exciting; I was not expecting to find that the <a href="https://en.wikipedia.org/wiki/Taste#Basic_tastes">primary tastes</a> were not in fact primal, but in fact could shift around inside a lower-dimensional <a href="https://en.wikipedia.org/wiki/Latent_space">latent space</a>. This got me theorising – as I wrote <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-somatic-field">elsewhere</a>:</p>
<blockquote>
<p>Perhaps taste could be built out of something like <a href="https://en.wikipedia.org/wiki/Dyad_(music)"><em>dyadic</em></a> vibrations, tuned by evolution towards <a href="https://en.wikipedia.org/wiki/Consonance_and_dissonance">consonance or dissonance</a> in order to generate an attractive or aversive response in the organism?</p>
</blockquote>
<!-- What might "metallic" mean, here? Slapback reverb? -->
<h3 id="olfactory-perception"><a href="#olfactory-perception">Olfactory perception</a></h3>
<p>It took me a little while before I noticed any change to my sense of smell, but this was more a factor of encountering the relevant stimulus. It was boys. Boys smelt different.</p>
<p>Much earlier in life, I’d had to convince myself I was gay by using the fact that boys smelt <em>really good</em>. This was very much no longer the case, and I began to notice wide variation in the way boys smelt, which sometimes was really quite unpleasant – <em>oniony</em>, even.</p>

<!-- In return, the boys in my life took turns smelling my armpits; they all said I smelt great. -->
<!-- Estrogen is known to [upregulate 5-HT2A receptor expression in the olfactory cortex of rats](https://pubmed.ncbi.nlm.nih.gov/7632610/). I was unable to find any similar information about the gustatory cortex. -->
<h3 id="somatic-perception"><a href="#somatic-perception">Somatic perception</a></h3>
<p>I have somatic sensory issues. Skin sensations have always been overwhelming – my mother will confirm that I would scream if she attempted to dress me in wool, and in adulthood I avoid buying clothing with sleeves. By default, my skin feels like a bag of white noise – and when things get bad it can feel like my whole body is covered with randomised pinprick sensations, like minuscule <a href="https://smoothbrains.net/posts/2024-03-01-5-meo-dmt.html">topological defects</a> in the <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-somatic-field">somatic field</a>.</p>
<p>This has interfered with my ability to experience intimacy; simply lying in bed with somebody could be a stressful time for me. Estrogen ramps all of this way down in intensity – it’s a tremendous relief.</p>
<p>Perhaps my cleaning habits can provide an objective measure. Because things like sweat on my skin or leftover food in my mouth constitute intolerable sensory distractions, I’d tend to shower up to four times a day and brush my teeth about as often – since starting estrogen, I’m much less neurotic about both of these things.</p>
<p>A less turbulent nervous system also seems to be less disruptive for sleep. Beforehand, I took it for granted that I would often wake up throughout the night in a state of discomfort, whereas while I am on estrogen I reliably wake up in the morning feeling well-rested.</p>
<h3 id="visual-perception"><a href="#visual-perception">Visual perception</a></h3>
<p>It’s fairly common to hear reports of <a href="https://www.reddit.com/r/MtF/comments/xcr66g/color_on_estrogen/">colours becoming more intense after starting hormone replacement therapy</a>. I’m familiar with how <a href="https://psychonautwiki.org/wiki/Color_enhancement">serotonergic psychedelics can produce this effect</a>, but I can’t say I observed any such thing myself. What did change was my sense of <em>space</em>.</p>
<p>This one’s quite subtle – it was the kind of thing that was more noticeable when I experimented with deliberately spiking my hormones. I’ll do my best to explain. It’s as if I took the entire volumetric representation of the space around me and increased the degree to which every point within that could influence the location of every other point, recursively. This allows everything to elastically settle into a more harmonious equilibrium. This effect is basically identical to what a small dose of psychedelics can do, specifically a tryptamine like <a href="https://psychonautwiki.org/wiki/Psilocybin_mushrooms">psilocybin</a> or <a href="https://psychonautwiki.org/wiki/DMT">DMT</a>.</p>

<p>It’s hard to say what the utility of this might be. The balance between entropy and harmony is an important one – too much entropy and it’s hard to tell signal from noise, and too much harmony and you might miss important details. I did feel that with a more parsimonious model of the space around me, I got better at driving – though my friends would say I got more <em>confident</em> at driving. Competence might be orthogonal to confidence, but I maintain that parallel parking is much easier now.</p>
<h3 id="motor-output"><a href="#motor-output">Motor output</a></h3>
<p>I ride my bicycle every morning – this is my primary meditative practice. I am also surrounded by steep hills, so I noticed within a couple of days that I could not activate my quads and hamstrings as hard as I was used to. This happened much faster than could possibly be accounted for by muscular atrophy, so I surmised that this must be a neuromuscular phenomenon. Later on I switched back to my own hormones for a short period, and once again the change was quite rapid. There was nothing quite like the rush of <em>powering</em> uphill once again.</p>
<p>Being less strong honestly sucked pretty bad, and this required some psychological adjustment. <!-- I learned that muscular strength is but one of many axes along which one can maximise one's agency. --> The flipside of this was that I found estrogen to be a <em>superb</em> muscle relaxant, and ultimately this made the effect a net positive.</p>
<p>Around the time I transitioned was also the period when I was exploring some quite extreme ketamine-assisted <a href="https://www.fasciaresearch.com/literature/sensory-innervation/InnervationExcerpt.pdf">myofascial release</a> techniques in order to shake off a lifetime’s worth of accumulated tension from things like bad ergonomics and social anxiety. I’d say estrogen has been partially instrumental in getting me from a place where I’m constantly attacking myself with a foam roller and massage gun just to feel comfortable in my own body – to one where massage is more of a light maintenance task, like a bird preening its feathers.</p>
<!-- It's a fair trade. I like being soft and pliable. -->

<h3 id="emotional-modulation"><a href="#emotional-modulation">Emotional modulation</a></h3>
<p>I have spent a big chunk of my life navigating chronic emotional disaffection – high school sucked, and later I had an acute week-long dissociative episode when I was twenty-one which I’m not sure I ever quite came back from. Suffice it to say I lived an emotionally stagnant existence for most of my twenties – so when the hormones opened things up, I got quite attached to my new feelings.</p>
<p>Funny things were <em>funnier</em> – I recall a moment about a week after I started the hormone treatment, when I laughed at something I saw on YouTube – the surge of joy was like an electric cauteriser through my breastbone. Music <a href="https://www.youtube.com/watch?v=XGWbIw8oK9I"><em>works</em></a> now. I can lean in to the sense of affection I feel towards my friends. I cry more frequently; but this is clearly critical for releasing tension that would otherwise remain below the surface.</p>
<p>There’s another side to all this. I have had to navigate a number of situations where I now found myself unable to dissociate from some issue in my life that had been bothering me – I <em>had</em> to do something. Often this felt destructive; in retrospect there’s things I could have handled with far more grace and care, but instead I chose to drive a bulldozer through them.</p>
<!-- when normally I'd weather emotionally turbulent events without too much fuss -->
<p>For better or worse, this is what the hormones can do. It’s a bit of an epistemic nightmare – do I take action to deal with the thing that’s bugging me, or would it be better to skip my hormones for a day or two and see if I consider things differently? I can only recommend entering into this groundless game of instrumental hormone manipulation if one is comfortable taking responsibility for epistemic frame-shifting.</p>
<h3 id="attentional-modulation"><a href="#attentional-modulation">Attentional modulation</a></h3>
<p>I’d engaged with a number of deliberate psychological interventions in the lead-up to coming out, with the general aim of managing my social self-awareness. I knew I needed the confidence. If I was to socially transition, I’d need to not get too overwhelmed or hung up on what other people thought of me.</p>
<p>Of these, the most effective was <a href="https://x.com/m_ashcroft">Michael Ashcroft</a>’s <a href="http://expandingawareness.org/">extremely straightforward course</a> on <a href="https://en.wikipedia.org/wiki/Alexander_Technique">Alexander Technique</a>. I wrote about this in my writeup on <a href="https://smoothbrains.net/posts/2023-10-28-attention-and-awareness.html">attention and awareness</a>:</p>
<blockquote>
<p>Here’s how I usually explain it to people: You have <em>awareness</em>, which corresponds to everything currently in your sensorium. Then you have <em>attention</em>, which is a subset of that – like the beam of a spotlight – and most importantly, you have <em>agency</em> over it, you can choose where to point it and how wide or narrow you would like it to be.</p>
</blockquote>
<p>Sometimes we might feel that our attention is involuntarily yanked around by invisible aversive forces that are seemingly beyond our control – for instance, I might find it challenging to make eye contact with people at a party, and spend the whole time with my attention collapsed and pointed at the floor.</p>
<p>I think what Alexander Technique does is <a href="https://x.com/m_ashcroft/status/1807008725548363845">teach mindfulness of this class of phenomena and how to <em>expand</em> attention out of them</a>. Prior to transition, I deliberately experimented with this form of attentional modulation – primarily in the kind of social setting that I would normally find overwhelming, but also just while riding my bicycle outside. I think this kind of practice has a lot of potential for helping undo the archetypal trauma-induced behavioural patterns displayed by socially anxious autistic people. Personally I found it to be remarkably effective, and after some months of this I felt that my anxiety disorder was mostly in remission.</p>
<p>So it was a humungous letdown when I found that all of this got <em>significantly harder</em> on estrogen. I cringed my way through social events, and returned to staring at the floor – but I didn’t let this stop me. I thought of it like Goku training in the <a href="https://dragonball.fandom.com/wiki/Gravity_Machine">one hundred times Earth gravity chamber</a>. I just learned it all again from scratch.</p>
<h2 id="how-does-estrogen-work"><a href="#how-does-estrogen-work">How does estrogen <em>work</em>?</a></h2>
<p>If someone feels that they’d rather have a feminine body, estrogen is going to satisfy this desire – <em>within reason</em>. This is obvious. I’m more interested in finer-grained, <em>bottom-up</em> rather than <em>top-down</em> sensory phenomena. What are the other reasons that estrogen might <em>feel good</em>? I’d like to propose a number of theories – I’ll try to order them from least speculative to most speculative.</p>
<p>What should my <a href="https://en.wikipedia.org/wiki/Null_hypothesis">null hypothesis</a> be? <a href="https://www.reddit.com/r/DrWillPowers/comments/fcxboa/the_story_of_how_i_screwed_up_a_dose_calculation/">Would estrogen make someone without gender dysphoria feel good too?</a> Is it just a miraculous coincidence that estrogen just so happens to fix other issues that tend to be correlated with gender dysphoria – or do people with gender dysphoria suffer from an innate neurochemical deficit which can be corrected by hormone therapy?</p>

<h3 id="estrogen-is-like-the-opposite-of-ketamine"><a href="#estrogen-is-like-the-opposite-of-ketamine">Estrogen is like the opposite of ketamine</a></h3>
<p>Transgender writer <a href="https://zinniajones.com/">Zinnia Jones</a> suffers from <a href="https://en.wikipedia.org/wiki/Depersonalization-derealization_disorder">depersonalisation-derealisation disorder</a>, and found that her symptoms were <em>dissolved completely</em> when she started hormone replacement therapy.</p>
<!--
<aside>
   I'll avoid using the term *dissociation*, which could mean [about four or five different things](https://x.com/br___ian/status/1761429178115932653).
</aside>
-->
<p>The phenomenology of depersonalisation-derealisation is notoriously difficult to describe, but Zinnia has written the single best description of it that I’ve ever read. From her blog post, <a href="https://zinniajones.medium.com/trip-report-lamotrigine-a-drug-to-treat-depersonalization-e8171e165813">Trip report: Lamotrigine, a drug to treat depersonalization</a>:</p>
<blockquote>
<p>There was no point where I didn’t feel somehow removed from the world around me – this disconcerting sensation was present from my earliest memories. As a child I just didn’t really see the point of practically anything I was doing, or that anyone else was doing; it held no real emotional resonance or meaning for me. Whatever interests I chose to pursue felt more like an obligatory way of filling time, not something that had any value or importance in its own right.</p>
<p>I always felt the lack of spontaneity characteristic of depersonalization disorder, and whenever I chose to say anything, it felt rehearsed and acted out as if I had to engage my every word and action manually. Most of the time I would choose to say nothing at all. My feelings seemed to be kept at a distance, happening as something separate from an interior “me” who didn’t truly experience these emotions and seemingly couldn’t be touched by them. I was painfully conscious of all of these things.</p>
</blockquote>
<p>She continues with a visual description which I found particularly fascinating:</p>
<blockquote>
<p>In sufferers of depersonalization, symptoms can become more prominent in the form of sudden attacks – and it gets worse the more you keep thinking about it. Later that night, I step outside to get some air, and the thought enters my mind that the trees, cars, and houses on our street could just be particularly elaborate Lego pieces. The clouds in the night sky could easily pass for a simple rendering in Blender. Isn’t at least half of what we see practically a hallucination that’s filled in by our brain without us even noticing? If all these things were just renderings, it seems like it would be easy to take advantage of that.</p>
<p>I can almost envision everything on our street coming apart piece by piece like an exploded technical diagram. The asphalt, the curb, the patches of grass, all of them could just lift into the air and drift apart, nothing but thin surfaces, almost like abstractions or mere representations. If I were to take a shovel and start digging a hole in the road, it would just be an indentation in that surface, pushing it to extend a bit in one direction or another – but underneath it, nothing. The houses along the street are just outgrowths of the surface, a sort of puckering in it, like a ball on a rubber sheet to demonstrate how gravity is the curvature of spacetime.</p>
</blockquote>
<!--
See also, her [comment on r/transgender](https://www.reddit.com/r/asktransgender/comments/7t1z1w/comment/dt9e6xx/):

> Depersonalization (unreality and "no-self" feelings) was a really prominent feature of my life before transitioning, and it was highly distressing. I felt like a robot, like all my expressed emotions and actions were running entirely on manual, and I just wished anything could make me stop feeling this way. HRT made it go away within a week or two, and I had no idea that could even happen – I thought that was just my "normal", and it turns out it wasn't (I didn't even know depersonalization was a thing until a few years ago, so I had no language to describe it). I've been so, so happy since then and I feel that was when my life really began. It turns out depersonalization is much more common among trans people than among cis people, and that it declines after transitioning, specifically after treatment with HRT.
>
> I don't know enough about the relevant chemistry to remark on how this might have worked for your friend, but ketamine does have a rapid antidepressant effect and has been used in trials for this purpose, so it's possible that's what they were experiencing. Lamotrigine (Lamictal) is an anticonvulsant that's something like the opposite of ketamine: it inhibits glutamate release whereas ketamine stimulates it, resulting in ketamine's dissociative and DP/DR effects. It specifically blunts many of ketamine's effects (e.g. ketamine as an anesthetic will not work in cases of lamotrigine overdose). Lamotrigine, in combination with an SSRI, is one of the very few (possibly the only) treatments that's been found to be mostly effective for depersonalization disorder – it seems to have an anti-dissociative effect.
>
> I got on lamotrigine a few weeks back because I was curious about this (I really can't recommend this, as it can have serious side effects). After I'd titrated up, I went off my hormones for about 11 days. Normally when this happens I have a really noticeable and unbearable return of my depersonalization within 3-4 days. This time I was easily able to hold out for a week or so. Somehow, I felt almost normal. Things didn't really feel quite the same, but overall it felt like my DP/DR was at a 4 when it would normally be a screaming 10. I had no sense of feeling robotic, lacking spontaneity, or having a compulsive inner-monologue "observer", or lacking in genuine emotions. But by the last day I was starting to have some cognitive fog and a sense of the world being nothing but some strange infinitesimally thin surface stretched over infinite hollowness. It made me pretty uneasy, so since then I've been back on my HRT and that's all gone away.
-->
<p>When I read this, I could not help but think two things:</p>
<ul>
<li>Wow, <em>this sounds just like my life</em>.</li>
<li>Wow, <em>this sounds just like being on <a href="https://smoothbrains.net/posts/2023-08-01-ketamine.html">ketamine</a></em>.</li>
</ul>
<p>I related very strongly to both her description of feeling distanced from life – as well as her description of the <a href="https://smoothbrains.net/posts/2024-06-18-an-informal-review-of-anthropic-qualia-states.html#the-visual-field">visual field</a> being – as she has written <a href="https://www.reddit.com/r/asktransgender/comments/7t1z1w/comment/dt9e6xx/">elsewhere</a> – <em>nothing but some strange infinitesimally thin surface stretched over infinite hollowness</em>. Both of these effects increase when I experiment with ketamine, and I also notice that both of these effects reverse when I use estrogen. In particular, the way in which estrogen alters <a href="#attentional-modulation">attentional modulation</a> also seems responsible for an increase in <a href="https://slehar.wordpress.com/2014/09/12/amodal-perception/">amodal perception</a>, which in turn makes the visual field feel less <em>hollow</em> – though I don’t necessarily regard this as <em>desirable</em> or <em>undesirable</em>. It just is.</p>
<figure>
<a href="https://slehar.wordpress.com/2014/09/12/amodal-perception/"><img src="https://smoothbrains.net/images/random/estrogen/tomatoamodal.png"></a>
<figcaption>
Illustration of amodal perception, by <a href="https://smoothbrains.net/posts/2022-10-01-an-introduction-to-steven-lehar-part-i.html">Steven Lehar</a>. I found estrogen made objects feel less “hollow”.
</figcaption>
</figure>
<p>I’d also previously read <a href="https://x.com/slatestarcodex">Scott Alexander</a>’s blog post, <a href="https://slatestarcodex.com/2017/06/28/why-are-transgender-people-immune-to-optical-illusions">Why Are Transgender People Immune To Optical Illusions</a>, in which he speculates that if ketamine is an <em>NMDA receptor antagonist</em> which causes depersonalisation – and if estrogen <em>upregulates NDMA receptor expression</em> – then it’s possible that changes to the NMDA receptor network could be what’s responsible for the relevant changes in phenomenology.</p>
<figure>
<a href="http://slehar.com/wwwRel/cartoonepist/cartoonepist12.html"><img src="https://smoothbrains.net/images/random/estrogen/Fig12.jpg"></a>
<figcaption>
Illustration of the visual field, by <a href="https://smoothbrains.net/posts/2022-10-01-an-introduction-to-steven-lehar-part-i.html">Steven Lehar</a>. I found estrogen made it feel less “flat”. Can you imagine how this would make someone’s internal world simulation feel less “fake”?
</figcaption>
</figure>
<p>Right now I don’t have much to add beyond: <em>wow, I think this checks out</em>. The question remains – does estrogen correct some kind of underlying <em>NMDA receptor expression deficit</em>, which ultimately leads to the psychological problems correlated with gender dysphoria – and, how does this relate to gender dysphoria itself?</p>

<!--
<aside>
    Speculatively, I also think ketamine *hits harder* when I'm not on estrogen, but that's another story.
</aside>
-->
<h3 id="estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time"><a href="#estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time">Estrogen is like being on a mild dose of psychedelics all the time</a></h3>
<p>There’s a psychedelic research paper I’m a fan of – <a href="https://www.nature.com/articles/s41598-022-11999-8">Phenomenology and content of the inhaled <em>N</em>, <em>N</em>-DMT experience</a> (Lawrence et al., 2022) – in which the authors scrape ten years’ worth of comments from the <a href="https://www.reddit.com/r/DMT/">r/DMT</a> Reddit community, and tabulate different aspects of the <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/2">somatic</a>, <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/3">visual</a>, and <a href="https://www.nature.com/articles/s41598-022-11999-8/tables/4">entity encounter</a> phenomenology by how frequently they were reported.</p>
<p>Much of my personal research simply consists of reading a large number of Reddit comments. As such, I sorely wish for there to exist an equivalent paper to the DMT phenomenology one, but which scrapes <a href="http://reddit.com/r/asktransgender/">transgender</a> <a href="https://www.reddit.com/r/AskMtFHRT/">support</a> <a href="https://www.reddit.com/r/TransDIY/">subreddits</a> for subjective reports instead. However, until such time as one exists, the reader may just have to take my word for it when I claim a particular effect of estrogen is “commonly reported”.</p>
<p>One effect “commonly reported” by people just starting estrogen is that <a href="https://www.reddit.com/search/?q=estrogen+color">colours appear more saturated</a>. From a <a href="https://www.reddit.com/r/MtF/comments/1dxe691/comment/lc1eyab/">typical comment</a> on an <a href="https://www.reddit.com/r/MtF/">r/MtF</a> thread <a href="https://www.reddit.com/r/MtF/comments/1dxe691/anyone_on_hrt_do_any_of_yall_see_colors_more/">asking if anyone experiences colours more vibrantly</a>:</p>
<blockquote>
<p>Yes! I was at the art museum yesterday and I became utterly infatuated with a shade of blue I’ve never seen before. Sat and stared at it for like 15 minutes.</p>
<p>Then again, I may just be happier now.</p>
</blockquote>
<p>Referring back to the DMT phenomenology paper, <em>vivid</em> or <em>hyperintense</em> colours were reported in 25.2% of experiences. Personally, I didn’t experience any shift in colour perception, but I did find the other <a href="#visual-perception">visual perception</a> changes I experienced to be distinctively <em>psychedelic</em> in nature – as I mentioned earlier, particularly reminiscent of a tryptamine like <a href="https://psychonautwiki.org/wiki/Psilocybin_mushrooms">psilocybin</a> or <a href="https://psychonautwiki.org/wiki/DMT">DMT</a>. This is especially noticeable when I deliberately spike my levels with an extra patch, and on some days I suspect I even notice a slight amount of increased <a href="https://x.com/MatthijsCox/status/1611363519093694465">symmetrical texture repetition</a>.</p>
<figure>
<iframe src="https://www.youtube.com/embed/sY8nsjo__ek" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="">
</iframe>
<figcaption>
Replication of psilocybin visuals, by <a href="https://www.youtube.com/@SymmetricVision">Symmetric Vision</a> on YouTube.
</figcaption>
</figure>
<p>Estrogen is known to <em>upregulate 5-HT2A receptor expression</em>, which is of course the same serotonin receptor which is agonised by most <a href="https://en.wikipedia.org/wiki/Psychedelic_drug">serotonergic psychedelics</a>. It seems quite reasonable to me to assume that this is what’s responsible for the various reported sensory enhancements in addition to the <a href="#emotional-modulation">changes in mood</a>.</p>
<p>I now have an additional question. In addition to correcting some kind of <em>NMDA receptor expression deficit</em> inherent to the gender dysphoric neurotype, does estrogen also correct a <em>5-HT2A receptor expression deficit</em> – or does tripping on estrogen <em>just feel good</em>?</p>
<!--
<aside>
    The neuroscientist [Robin Carhart-Harris](https://en.wikipedia.org/wiki/Robin_Carhart-Harris) theorises that the serotonin system is responsible for managing ongoing stress – and that the *5-HT1A receptor* is responsible for a *passive coping* mechanism while the *5-HT2A receptor* is responsible for an *active coping* mechanism. For a discussion of this theory, please see my post, [5-MeO-DMT: A crash course in phenomenal field topology](/posts/2024-03-01-5-meo-dmt.html).
</aside>
-->
<h3 id="estrogen-loosens-the-bodymind"><a href="#estrogen-loosens-the-bodymind">Estrogen loosens the bodymind</a></h3>
<p>As <a href="#motor-output">mentioned above</a>, I found estrogen to be an incredibly powerful muscle relaxant. Using the <a href="https://slatestarcodex.com/2016/09/12/its-bayes-all-the-way-up/">Bayesian brain</a> model to understand this, it seems as if my nervous system holds <a href="https://www.lesswrong.com/w/priors"><em>priors</em></a> for how tense every muscle in my body should be in response to a given situation – and these priors are <em>relaxed</em> under the influence of estrogen.</p>
<p>I have to credit estrogen with helping fix a number of long-standing neck and upper back problems which I’ve been dealing with for most of my life. It’s sufficiently powerful that I am skeptical that I would have been able to fix these issues while I was on testosterone. Notably, these issues don’t return when I stop taking estrogen.</p>
<p>The effects feel more foundational than this, however; estrogen feels like it reshapes my body map itself, <a href="https://smoothbrains.net/posts/2024-05-29-what-is-a-bodymind-knot.html">smoothing out knots</a> – like an elastic membrane being tightened, or a soap bubble reaching equilibrium. I’ve seen it “commonly reported” that estrogen makes people feel <em>more embodied</em>, and I suspect that this is what people might tend to mean by that.</p>
<figure>
<a href="https://a.carapetis.com/csf/">
<video autoplay="" loop="" muted="" playsinline="">
<source src="https://smoothbrains.net/images/random/estrogen/curve_shortening_flow.mp4" type="video/mp4">
</video>
</a>
<figcaption>
Demonstration of <a href="http://en.wikipedia.org/wiki/Curve-shortening_flow">curve-shortening flow</a>, from <a href="https://a.carapetis.com/csf/">Anthony Carapetis’ personal website</a>.
</figcaption>
</figure>
<p>Could this be related to the serotonergic activity? Might the estrogen be unwinding a lifetime of accumulated neuromuscular trauma through a form of low-dose psychedelic therapy? I suspect this effect is also responsible for my <a href="#emotional-modulation">changes in mood</a> – do emotions resonate more freely through a more parsimonious bodymind?</p>
<h3 id="estrogen-downregulates-autistic-sensory-sensitivity-issues"><a href="#estrogen-downregulates-autistic-sensory-sensitivity-issues">Estrogen downregulates autistic sensory sensitivity issues</a></h3>
<p>There’s a <a href="http://x.com/johnsonmxe">Mike Johnson</a> post I relate to, proposing a novel theory about <a href="https://en.wikipedia.org/wiki/Autism">autistic spectrum disorders</a>. From <a href="https://opentheory.net/2023/05/autism-as-a-disorder-of-dimensionality/">Autism as a disorder of dimensionality</a>:</p>
<blockquote>
<p>Every circuit has its own <a href="https://en.wikipedia.org/wiki/Hausdorff_dimension">natural density/dimensionality</a> it’s designed for, and my intuition is that organs closer to the brain are designed to have higher dimensionality. In some sense this makes them more capable of general processing, but also more prone to the particular deficits expressed in autism, with the brain as the apex of this hierarchy.</p>
<p>Over time, civilization has thrown humanity increasingly high-dimensional challenges, leading to evolution progressively ‘dialing the dimensionality knob up’ on our nervous systems. Perhaps we can view dysfunctional autists as those who overshot the human nervous system’s current ‘Goldilocks zone’ for dimensionality and have nervous systems dominated by static/turbulence as a result. There may be different ‘flavors’ of autism, depending on which brain regions and tissues have elevated dimensionality.</p>
</blockquote>
<!-- [Neuron Number and Size in Prefrontal Cortex of Children With Autism](https://jamanetwork.com/journals/jama/fullarticle/1104609) (Courchesne et al., 2011) -->
<p>When I read this some years ago, I had something of an <em>I’m in this picture and I don’t like it</em> moment. I don’t know that his theory is necessarily true, but I certainly felt that my own sensorium was <em>dominated by static/turbulence</em>.</p>
<figure>
<img src="https://smoothbrains.net/images/random/estrogen/lain_static.gif">
<figcaption>
Static is used as a recurring motif in the anime <a href="https://en.wikipedia.org/wiki/Serial_Experiments_Lain">Serial Experiments Lain</a>, in which it is strongly hinted that the protagonist experiences sensory sensitivities.
</figcaption>
</figure>
<p>As <a href="#somatic-perception">mentioned above</a>, I found that estrogen toned down my ongoing somatic sensitivities to more manageable levels – and there’s a handful of trans women I’ve spoken to who agreed with me that it turned the static down.</p>
<p>Autism tends to be <a href="https://www.cdc.gov/mmwr/volumes/74/ss/ss7402a1.htm">diagnosed more often in those assigned male at birth</a>, and there’s a fair amount of research into the <a href="https://www.frontiersin.org/journals/endocrinology/articles/10.3389/fendo.2024.1371148/full">links between hormone levels and neuroatypicality</a>. Some researchers have even <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5193073/#__ffn_sectitle">proposed estrogen as a therapeutic target</a> for autism spectrum disorders.</p>
<p>Additionally, as <a href="https://x.com/slatestarcodex">Scott Alexander</a> mentions in <a href="https://www.astralcodexten.com/p/why-do-transgender-people-report">Why Do Transgender People Report Hypermobile Joints?</a>, <a href="https://www.theatlantic.com/health/archive/2016/11/the-link-between-autism-and-trans-identity/507509/"><em>people with autism are about 8x more likely to be gender divergent than the general population</em></a>. Certainly this fits popular stereotypes of trans women, at least in my corner of the internet. Scott speculates:</p>
<blockquote>
<p>My guess is something like joint issues → poor proprioception → all sensory experience is noisy and confusing → the brain, which is embodied and spends most of its time trying to process sensory experience, learns a different reasoning style → different reasoning style is less context-dependent (producing symptoms of autism) → different reasoning style when trying to interpret bodily correlates of gender (eg sex hormones) → transgender.</p>
</blockquote>
<p>Personally, I don’t have any joint issues, and I think that his theory of dyphoria could be simpler than this. Perhaps autistic sensory sensitivities mean that the brain is constanly dealing with having to reject overly noisy sensory input, leading to a stressed out, overly tense, disembodied nervous system – and this is what ultimately manifests as dysphoria? However, this would only explain <em>sensory dysphoria</em>, and not <em>gender dysphoria</em>.</p>
<p>I also find that <a href="https://en.wikipedia.org/wiki/Ketogenic_diet">ketogenic dieting</a> helps with my sensory issues – as well as <a href="https://slatestarcodex.com/2019/07/18/know-your-gabapentinoids/">gabapentinoids like phenibut and pregabalin</a> – presumably by <em>reducing glutamatergic signalling</em>. Occasional <a href="https://opentheory.net/2019/11/neural-annealing-toward-a-neural-theory-of-everything/">neural annealing</a> through mild doses of <a href="https://psychonautwiki.org/wiki/Serotonergic_psychedelic">serotonergic psychedelics</a> is also quite helpful. It’s difficult to say whether it’s the glutamate or serotonin system which is the root cause, but perhaps estrogen is particularly effective because it delivers changes to both?</p>
<h3 id="estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal"><a href="#estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal">Estrogen can produce a psychological shift from autistic to schizotypal</a></h3>
<p>A couple of years ago <a href="https://x.com/ElytraMithra">Ely</a> recommended that I read the paper, <a href="https://journals.sagepub.com/doi/10.1177/17456916221075252">Autistic-Like Traits and Positive Schizotypy as Diametric Specializations of the Predictive Mind</a> (Andersen, 2022). It turned out to be the most interesting paper I read while writing this post. The author proposes that the archetypal behavioural traits observed in <a href="https://en.wikipedia.org/wiki/Autism"><em>autism</em></a> and <a href="https://en.wikipedia.org/wiki/Schizotypy"><em>schizotypy</em></a> – like variation in attentional modulation, theory of mind, and exploratory behaviour – are downstream from a fundamental <em>oversensitivity</em> or <em>undersensitivity</em> to sensory <a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/">prediction errors</a>, respectively:</p>
<blockquote>
<p>It has previously been argued that autism-spectrum conditions can be understood as resulting from a predictive-processing mechanism in which an inflexibly high weight is given to sensory-prediction errors that results in overfitting their predictive models to the world. Deficits in executive functioning, theory of mind, and central coherence are all argued to flow naturally from this core underlying mechanism.</p>
<p>The diametric model of autism and psychosis suggests a simple extension of this hypothesis. If people on the autism spectrum give an inflexibly high weight to sensory input, could it be that people with a predisposition to psychosis (i.e., people high in <em>positive schizotypy</em>) give an inflexibly <em>low</em> weight to sensory input?</p>
</blockquote>
<p>Andersen carefully describes the terms <em>autism</em> and <em>schizotypy</em> as he uses them in the paper, emphasizing that these categories should be viewed as flexible and not defined by dysfunction:</p>
<blockquote>
<p>In this article I refer to this axis as the <em>autism-schizotypy continuum</em>. For convenience, I refer to people on either end of this continuum as being an “autistic type” or a “schizotype”, although it should be understood that there are no clear-cut “types” and that these differences are continuous rather than categorical.</p>
<p>According to these models, everyone falls somewhere on the autism–schizotypy continuum, and neither autistic-like traits nor positive schizotypy represent dysfunction. Instead, each side of the continuum is accompanied by its own set of cognitive-perceptual strengths and weaknesses. People high in autistic-like traits are detail-oriented, have a focused attentional style that allows them to ignore distractors, have some advantages in sensory-discrimination abilities, and have highly developed systemizing skills, allowing them to learn and use complicated rules-based systems.</p>
<p>People high in positive schizotypy tend to be imaginative and creative and have a more diffuse attentional style (compared with the average person) that allows them to switch their attention more easily. There is also some evidence that people high in positive schizotypy tend to direct their attention toward highly abstract, “big-picture” concerns rather than focusing on details.</p>
</blockquote>
<p>Andersen proposes that in the case of schizotypy, lower sensitivity to prediction errors permits sensory input to flow further up the predictive processing hierarchy, which is what results in the observed behavioural traits:</p>
<blockquote>
<p>In autism, inflexibly high precision weighting of sensory input means that prediction matching tends to take place at relatively low levels of the processing hierarchy. Inflexibly low precision weighting of sensory input with positive schizotypy would have the opposite effect. Because the schizotype is, on average, handling fewer sensory-prediction errors than the autistic type (because they pay attention only to the large errors and ignore the smaller ones), prediction errors will tend to propagate farther up the processing hierarchy, affecting values, goals, and beliefs at higher levels of abstraction.</p>
</blockquote>
<p>At this stage, I had to ask myself if the hormone I’d been taking which seemed to reduce my symptoms of autism was doing so by reducing an inherent oversensitivity to prediction errors? If this was the case, might it also be pushing me further towards the other end of the <em>autism-schizotypy continuum</em>? What might that look like? The paper has this to say about schizotypal patterns of belief:</p>
<blockquote>
<p>Although the autistic type may rely more on culturally inherited high-level belief systems, the schizotype’s proclivity for tinkering with high-level priors may lead to the construction of relatively idiosyncratic high-level belief systems. In our own culture, this could manifest as having odd or (seemingly) unlikely beliefs about high-level causes. This may include beliefs in the paranormal, idiosyncratic religious beliefs (e.g., being “spiritual but not religious”), or believing conspiracy theories, all of which are associated with positive schizotypy.</p>
</blockquote>
<p>I’ll outline some of the psychological changes I’ve noticed in myself since starting estrogen. The term “schizo” is used very informally in today’s internet vernacular, making it difficult to discuss these concepts in a sensible manner – but if the reader is comfortable playing armchair psychologist, perhaps they can judge for themselves whether the following makes me more “schizo”:</p>
<ul>
<li>Increased predisposition towards <a href="https://www.cell.com/trends/cognitive-sciences/abstract/S1364-6613(23)00094-3"><em>associative thinking</em></a>. Activities like tarot are more appealing.</li>
<li>Increased predisposition towards <a href="https://x.com/cube_flipper/status/1757637512682692991"><em>magical thinking</em></a>, leading to some idiosyncratic worldviews. This can probably be gauged by the <a href="https://x.com/cube_flipper/status/1800179966992400775">nonsense I post on Twitter</a>.</li>
<li>Increased experience of <a href="https://meaningness.com/"><em>meaningness</em></a> in day-to-day life. <a href="#emotional-modulation">This felt really good</a>.</li>
<li>Increased <em>mentalising</em> of other people’s internal states, resulting in a mixture of higher empathy and higher social anxiety. I’m somewhat more neurotic about potential threats.</li>
<li>Decreased <a href="#somatic-perception"><em>sensory sensitivity</em></a>.</li>
<li>Decreased <a href="#attentional-modulation"><em>attentional diffusion</em></a>, contrary to what the paper predicts.</li>
<li>Decreased <em>systematising</em> and <em>attention to detail</em>, for instance with tedious matters like finances.</li>
</ul>
<!--
<aside>
    Mind you, I was already kinda like this anyway.
</aside>
-->
<p>Armchair diagnoses aside, I do wish to assert that these psychological changes are quite similar to the kind of psychological changes I tend to experience while on a mild dose of psychedelics. So far as the pharmacology goes, there is an argument to be made that psychedelics induce a temporary state of psychosis via 5-HT2A agonism. From <a href="https://journals.sagepub.com/doi/full/10.1177/0269881120959637">Pivotal mental states</a> (Brouwer and Carhart-Harris, 2021):</p>
<blockquote>
<p>The psychotomimetic (psychosis-mimicking) effects of classic 5-HT2A receptor agonist psychedelics have been well documented. Importantly, psychedelics are felt to be useful models of <em>incipient</em> psychotic states that may be more likely to display psychedelic-like phenomena, such as changes in perception, cognition and ego functioning. Conversely, established psychotic disorders such as schizophrenia are more likely to feature characteristics of <em>rigid</em> cognition such as fixed delusions. Selective 5-HT2A receptor antagonism attenuates the main characteristic subjective effects of LSD, psilocybin and ayahuasca and the intensity of psychedelic states is reliably predicted by 5-HT2A receptor occupancy.</p>
</blockquote>
<p>It’s important to note that the authors are specifically discussing <em>psychosis</em> rather than <em>schizotypy</em>, and I couldn’t find any evidence that <em>schizotypy</em> involves 5-HT2A receptor signalling. That said, given the two are related, and given that estrogen <em>upregulates 5-HT2A receptor expression</em>, could estrogen be responsible for increased positive schizotypy via a similar mechanism to psychedelics?</p>
<!--
<aside>
The leading predictive processing based theory of psychedelic action, [REBUS and the Anarchic Brain: Toward a Unified
Model of the Brain Action of Psychedelics](https://pmc.ncbi.nlm.nih.gov/articles/PMC6588209/) ("Relaxed beliefs under psychedelics") (Carhart-Harris and Friston, 2019) implicates *loosened priors*, rather than *decreased sensitivity to prediction errors*. I'm not sure how to square these models
</aside>
-->
<!--
<aside>
Ely also recommended that I read [A Neuronal Model of Predictive Coding Accounting for the Mismatch Negativity](https://www.jneurosci.org/content/32/11/3665) (Wacongne et al., 2012). I haven't done so yet.
</aside>
-->
<hr>

<p>I’d like to review what I’ve claimed so far:</p>
<ul>
<li>Estrogen <em>upregulates NMDA receptor expression</em>, which may result in:
<ul>
<li><a href="#estrogen-is-like-the-opposite-of-ketamine">Decreased depersonalisation and derealisation</a></li>
</ul></li>
<li>Estrogen <em>upregulates 5-HT2A receptor expression</em>, which may result in:
<ul>
<li><a href="#estrogen-is-like-being-on-a-mild-dose-of-psychedelics-all-the-time">Increased “psychedelic” phenomenology</a></li>
<li><a href="#estrogen-loosens-the-bodymind">Increased “bodymind” flexibility and sense of embodiment</a></li>
<li><a href="#estrogen-downregulates-autistic-sensory-sensitivity-issues">Decreased autistic traits</a></li>
<li><a href="#estrogen-can-produce-a-psychological-shift-from-autistic-to-schizotypal">Increased schizotypal traits</a></li>
</ul></li>
</ul>
<p>First of all, I should note that I don’t expect these claims about estrogen phenomenology to generalise from trans women to cis women, and I’d also be cautious about generalizing neuroendocrinological findings from postmenopausal women to people starting from an androgenic baseline. <!-- Additionally, the neurological effects I've described may be buffered by other regulatory systems, given that estrogen acts several steps upstream in complex biological pathways. --> All this aside, I think this should be mostly sufficient to explain why estrogen might make somebody <em>feel good</em>, especially if they are predisposed to depersonalisation, disembodiment, or autistic sensory sensitivities. However, I don’t think we’re that much closer to understanding whether hormone replacement therapy is actually correcting some kind of <em>innate deficit</em>.</p>
<p>Innateness of gender identity is a difficult topic to discuss. Here we are in 2025, and different political factions are motivated to claim that <em>gender dysphoria</em> is either a <a href="https://genderdysphoria.fyi/en/causes"><em>genuine phenomenon</em></a> or <a href="https://x.com/cube_flipper/status/1909409074619543977"><em>just a delusion</em></a>. Theories abound, and one of the more colourful – and <em>confronting</em> – treatments of the topic was written by <a href="https://sinceriously.blog-mirror.com/">Ziz</a>… <a href="https://x.com/kenthecowboy_/status/1884393311827550716">who is currently in jail</a>. From <a href="https://sinceriously.blog-mirror.com/intersex-brains-and-conceptual-warfare/">Intersex Brains And Conceptual Warfare</a>:</p>
<blockquote>
<p>The simplest explanation which fits the data (including nonbrain intersex conditions) is that sexual differentiation is a fragile rube goldberg machine, prone to random breakage. I speculate that humans have intersex brains so often because of evolution pulling out all stops for large brains and breaking things as a side effect.</p>
</blockquote>
<p>Any honest public appraisal of the topic is likely to be clouded by politics, and given the current political climate, it seems unlikely that research may continue. Which is a shame, because I suspect research into <a href="https://www.nature.com/articles/s41598-020-72486-6">prenatal hormone exposure</a>, <a href="https://pubmed.ncbi.nlm.nih.gov/34030966/">neuroanatomical variation</a>, and <a href="https://www.reddit.com/r/DrWillPowers/wiki/meyer-powers_syndrome_faq/">atypical endocrine signalling</a> are promising avenues of exploration.</p>
<p>While I don’t think people should have to convince the medical system of the validity of their internal experience in order to justify a hormone prescription – other people <em>do</em>, and I don’t think this is likely to change anytime soon. So I think this research is <em>important</em> – not least because this is an issue that directly affects an unusually productive and talented segment of society, many of whom I consider my friends.</p>

<h3 id="phenomenology-of-gender-dysphoria"><a href="#phenomenology-of-gender-dysphoria">Phenomenology of gender dysphoria</a></h3>
<p>Here’s how I’d like to thread the needle. Gender dysphoria occupies an unusual epistemic status within a society not known for <a href="https://cosmicindigestion.substack.com/p/around-here-we-take-our-phenomenology">taking phenomenology seriously</a>, because – at least in liberal spaces – people’s self reports are generally never questioned.</p>
<p>I’m not complaining – I don’t think this is a bad thing, even though I can be picky with my metaepistemics sometimes. What I would like to see is further development into phenomenological models of gender dysphoria. <a href="https://genderdysphoria.fyi/">Existing models</a> are already quite comprehensive, covering phenomena from high-level <a href="https://genderdysphoria.fyi/en/social-dysphoria"><em>social dysphoria</em></a> to low-level <a href="https://genderdysphoria.fyi/en/physical-dysphoria"><em>physical dysphoria</em></a> – but I think they could utilise <em>even more</em> detail, as it may provide essential clues to what’s going on.</p>
<figure>
<a href="https://www.ebmconsult.com/articles/homunculus-sensory-motor-cortex"><img src="https://smoothbrains.net/images/random/dmt/somatosensory_and_motor_homunculus.png"></a>
<figcaption>
The <a href="https://en.wikipedia.org/wiki/Primary_somatosensory_cortex">somatosensory cortex</a> is a long thin section of cortex which wraps around the brain like a headband. It is located just posterior to the <a href="https://en.wikipedia.org/wiki/Motor_cortex">motor cortex</a>, which follows a similar shape. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5830421/">Electrode studies on live humans</a> have revealed the shape of their respective homunculi.
</figcaption>
</figure>
<p>The low-level phenomenology of <a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">brain-body map mismatches</a> seems like a big part of the puzzle. There’s an old friend of mine, a loud-mouthed transman with a thick Queensland accent who swears up and down that he’s got a <em>fuckin’ ghost cock, mate</em>. Certainly the prevalence of phantom penises is <a href="https://www.researchgate.net/publication/348950276_Phantom_Penis_Extrapolating_Neuroscience_and_Employing_Imagination_for_Trans_Male_Sexual_Embodiment">well-documented in the literature</a>. What’s going on there? My understanding of the <a href="https://en.wikipedia.org/wiki/Cortical_homunculus">somatosensory homunculus</a> is that it can be quite <a href="https://smoothbrains.net/posts/2023-06-30-the-oral-tesseract.html">flexible with its representations</a>, so why might it persistently render a body corresponding to the opposite gender?</p>
<p>This wouldn’t be a <a href="https://smoothbrains.net/">smoothbrains.net</a> post if it didn’t have some nonsensical spitballing at the end. My usual psychedelic research requires me to entertain all kinds of metaphysical schizotheories – so I’m not averse to considering all kinds of theories of gender dysphoria, including ones incorporating <!-- [*body schemas*](https://x.com/cube_flipper/status/1702351420475990020) --> <a href="https://x.com/cube_flipper/status/1671342436294221826"><em>morphogenetic fields</em></a>, <a href="https://smoothbrains.net/posts/2024-05-29-what-is-a-bodymind-knot.html"><em>bodymind knots</em></a>, <a href="https://x.com/KanizsaBoundary/status/1809314763345908004"><em>past lives</em></a>, or even <a href="https://x.com/KanizsaBoundary/status/1808991203570209226"><em>vector field topology</em></a>.</p>
<p>Could it be the case that gender dysphoria is a morphic resonance phenomenon – and estrogen helps access the cosmic feminine unconscious by loading a different configuration file from the akashic records? <em>Who can say.</em> After all, if estrogen does make me more schizotypal… <em>why not lean into it</em>?</p>

<hr>
<h2 id="references"><a href="#references">References</a></h2>
<h4 id="hormone-replacement-therapy"><a href="#hormone-replacement-therapy">Hormone replacement therapy</a></h4>
<ul>
<li><a href="https://www.lesswrong.com/posts/KznQLLpDprpwqcAKD/gender-exploration">Gender Exploration</a> by <a href="https://www.lesswrong.com/users/deluks917">sapphire</a> on <a href="https://www.lesswrong.com/">LessWrong</a> (2024)</li>
<li><a href="https://transfemscience.org/articles/transfem-intro/">An Introduction to Hormone Therapy for Transfeminine People</a> by <a href="https://transfemscience.org/about/#aly">Aly</a> on <a href="https://transfemscience.org/">Transfeminine Science</a> (2024)</li>
</ul>
<h4 id="gender-dysphoria"><a href="#gender-dysphoria">Gender dysphoria</a></h4>
<ul>
<li><a href="https://slatestarcodex.com/2013/02/18/typical-mind-and-gender-identity/">Typical mind and gender identity</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://slatestarcodex.com/">Slate Star Codex</a> (2013)</li>
<li><a href="https://slatestarcodex.com/2017/06/28/why-are-transgender-people-immune-to-optical-illusions">Why Are Transgender People Immune To Optical Illusions</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://slatestarcodex.com/">Slate Star Codex</a> (2017)</li>
<li><a href="https://zinniajones.medium.com/trip-report-lamotrigine-a-drug-to-treat-depersonalization-e8171e165813">Trip report: Lamotrigine, a drug to treat depersonalization</a> by <a href="https://zinniajones.com/">Zinnia Jones</a> on <a href="https://zinniajones.medium.com/">Medium</a> (2018)</li>
<li><a href="https://sinceriously.blog-mirror.com/intersex-brains-and-conceptual-warfare/">Intersex Brains And Conceptual Warfare</a> by <a href="https://sinceriously.blog-mirror.com/author/Ziz/">Ziz</a> on <a href="https://sinceriously.blog-mirror.com/">Sinceriously</a> (2019)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/34030966/">The Neuroanatomy of Transgender Identity: Mega-Analytic Findings From the ENIGMA Transgender Persons Working Group</a> (Mueller et al., 2021)</li>
<li><a href="https://www.astralcodexten.com/p/why-do-transgender-people-report">Why Do Transgender People Report Hypermobile Joints?</a> by <a href="https://x.com/slatestarcodex">Scott Alexander</a> on <a href="https://www.astralcodexten.com/">Astral Codex Ten</a> (2023)</li>
</ul>
<h4 id="autism-and-schizotypy"><a href="#autism-and-schizotypy">Autism and schizotypy</a></h4>
<ul>
<li><a href="https://opentheory.net/2023/05/autism-as-a-disorder-of-dimensionality/">Autism as a disorder of dimensionality</a> by <a href="http://x.com/johnsonmxe">Mike Johnson</a> on <a href="https://opentheory.net/">opentheory.net</a></li>
<li><a href="https://journals.sagepub.com/doi/10.1177/17456916221075252">Autistic-Like Traits and Positive Schizotypy as Diametric Specializations of the Predictive Mind</a> (Andersen, 2022)</li>
</ul>
<h4 id="estrogen"><a href="#estrogen">Estrogen</a></h4>
<ul>
<li><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2015.00037/full">Sex hormones affect neurotransmitters and shape the adult female brain during hormonal transition periods</a> (Barth et al., 2015)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/33396472/">The Role of Estrogen Receptors and Their Signaling across Psychiatric Disorders</a> (Hwang et al., 2020)</li>
<li><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2024.1348551/full">The impact of estradiol on serotonin, glutamate, and dopamine systems</a> (Bendis et al., 2024)</li>
<li><a href="https://www.reddit.com/r/DrWillPowers/wiki/meyer-powers_syndrome_faq/">Meyer-Powers Syndrome FAQ</a> by <a href="https://www.reddit.com/user/Drwillpowers/">Dr.&nbsp;Will Powers</a> on <a href="https://www.reddit.com/r/DrWillPowers/">r/DrWillPowers</a> (2025)</li>
</ul>
<h4 id="estrogen-and-the-glutamate-system"><a href="#estrogen-and-the-glutamate-system">Estrogen and the glutamate system</a></h4>
<ul>
<li><a href="https://academic.oup.com/endo/article-abstract/131/2/662/2496261">Estradiol selectively regulates agonist binding sites on the N-methyl-D-aspartate receptor complex in the CA1 region of the hippocampus</a> (Weiland, 1992)</li>
<li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6740259/">Effects of estrogen and progesterone treatment on rat hippocampal NMDA receptors: Relationship to Morris water maze performance</a> (El-Bakri et al., 2004)</li>
</ul>
<h4 id="estrogen-and-the-serotonin-system"><a href="#estrogen-and-the-serotonin-system">Estrogen and the serotonin system</a></h4>
<ul>
<li><a href="https://www.sciencedirect.com/science/article/abs/pii/096007609500075B">Estrogen increases the density of 5-Hydroxytryptamine<sub>2A</sub> receptors in cerebral cortex and nucleus accumbens in the female rat</a> (Sumner and Fink, 1995)</li>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/12900319/">Increase in Prefrontal Cortex Serotonin 2A Receptors Following Estrogen Treatment in Postmenopausal Women</a> (Kugaya et al., 2003)</li>
<li><a href="https://www.fertstert.org/article/S0015-0282(03)00973-7/fulltext">Widespread increases of cortical serotonin type 2A receptor availability after hormone therapy in euthymic postmenopausal women</a> (Moses-Kolko et al., 2003)</li>
</ul>
<h4 id="the-serotonin-system"><a href="#the-serotonin-system">The serotonin system</a></h4>
<ul>
<li><a href="https://pubmed.ncbi.nlm.nih.gov/28858536/">Serotonin and brain function: a tale of two receptors</a> (Carhart-Harris and Nutt, 2017)</li>
<li><a href="https://journals.sagepub.com/doi/10.1177/0269881120959637">Pivotal mental states</a> (Brouwer and Carhart-Harris, 2021)</li>
<li><a href="https://academic.oup.com/brain/article-abstract/147/1/56/7273051">A role for the serotonin 2A receptor in the expansion and functioning of human transmodal cortex</a> (Luppi et al., 2024)</li>
</ul>
    </section>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Compiling LLMs into a MegaKernel: A path to low-latency inference (225 pts)]]></title>
            <link>https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17</link>
            <guid>44321672</guid>
            <pubDate>Thu, 19 Jun 2025 19:20:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17">https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17</a>, See on <a href="https://news.ycombinator.com/item?id=44321672">Hacker News</a></p>
Couldn't get https://zhihaojia.medium.com/compiling-llms-into-a-megakernel-a-path-to-low-latency-inference-cf7840913c17: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Juneteenth in Photos (207 pts)]]></title>
            <link>https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</link>
            <guid>44320851</guid>
            <pubDate>Thu, 19 Jun 2025 17:41:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/">https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/</a>, See on <a href="https://news.ycombinator.com/item?id=44320851">Hacker News</a></p>
Couldn't get https://texashighways.com/travel-news/the-history-of-juneteenth-in-photos/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[In praise of "normal" engineers (142 pts)]]></title>
            <link>https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</link>
            <guid>44320806</guid>
            <pubDate>Thu, 19 Jun 2025 17:36:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/">https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/</a>, See on <a href="https://news.ycombinator.com/item?id=44320806">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p><em>This article was originally <a href="https://refactoring.fm/p/in-praise-of-normal-engineers">commissioned by Luca Rossi</a> (paywalled) for refactoring.fm, on February 11th, 2025. Luca edited a version of it that emphasized the importance of building “10x engineering teams” . It was later picked up by IEEE Spectrum (!!!), who scrapped most of the teams content and published a <a href="https://spectrum.ieee.org/10x-engineer">different, shorter piece</a> on March 13th.</em></p>
<p><em>This is my personal edit. It is not exactly identical to either of the versions that have been publicly released to date. It contains a lot of the source material for the talk I gave last week at #LDX3 in London, “<a href="https://speakerdeck.com/charity/in-praise-of-normal-engineers-ldx3">In Praise of ‘Normal’ Engineers</a>” (slides), and a couple weeks ago at CraftConf.&nbsp;</em></p>

<p>Most of us have encountered a few engineers who seem practically magician-like, a class apart from the rest of us in their ability to reason about complex mental models, leap to non-obvious yet elegant solutions, or emit waves of high quality code at unreal velocity.<img data-recalc-dims="1" decoding="async" data-attachment-id="10015" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-praise-black-squish/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="In Praise of “Normal” Engineers" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=174%2C174&amp;ssl=1" alt="In Praise of &quot;Normal&quot; Engineers" width="174" height="174" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-praise-black-squish.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 174px) 100vw, 174px"></p>
<p>I have run into any number of these incredible beings over the course of my career. I think this is what explains the curious durability of the “10x engineer” meme. It may be based on flimsy, shoddy research, and the claims people have made to defend it have often been&nbsp;risible (e.g. “10x engineers have dark backgrounds, are rarely seen doing UI work, are poor mentors and interviewers”), or blatantly double down on stereotypes (“we look for young dudes in hoodies that remind us of Mark Zuckerberg”). But damn if it doesn’t resonate with experience. It just feels true.</p>
<p>The problem is not the idea that there are engineers who are 10x as productive as other engineers. I don’t have a problem with this statement; in fact, that much seems self-evidently true. The problems I do have are twofold.</p>
<h2>Measuring productivity is fraught and imperfect</h2>
<p>First: how are you measuring productivity? I have a problem with the implication that there is One True Metric of productivity that you can standardize and sort people by. Consider, for a moment, the sheer combinatorial magnitude of skills and experiences at play:</p>
<ul>
<li>Are you working on microprocessors, IoT, database internals, web services, user experience, mobile apps, consulting, embedded systems, cryptography, animation, training models for gen AI… what?</li>
<li>Are you using golang, python, COBOL, lisp, perl, React, or brainfuck? What version, which libraries, which frameworks, what data models? What other software and build dependencies must you have mastered?<img data-recalc-dims="1" decoding="async" data-attachment-id="10009" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-rainbow-black/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-rainbow-black" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=173%2C173&amp;ssl=1" alt="" width="173" height="173" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-rainbow-black.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 173px) 100vw, 173px"></li>
<li>What adjacent skills, market segments, or product subject matter expertise are you drawing upon…design, security, compliance, data visualization, marketing, finance, etc?</li>
<li>What stage of development? What scale of usage? What matters most — giving good advice in a consultative capacity, prototyping rapidly to find product-market fit, or writing code that is maintainable and performant over many years of amortized maintenance? Or are you writing for the Mars Rover, or shrinkwrapped software you can never change?</li>
</ul>
<p>Also: people and their skills and abilities are not static. At one point, I was a pretty good DBRE (I even co-wrote the book on it). Maybe I was even a 10x DB engineer then, but certainly not now. I haven’t debugged a query plan in years.</p>
<p>“10x engineer” makes it sound like 10x productivity is an immutable characteristic of a person. But someone who is a 10x engineer in a particular skill set is still going to have infinitely more areas where they are normal or average (or less). I know a lot of world class engineers, but I’ve never met anyone who is 10x better than everyone else across the board, in every situation.</p>
<h2>Engineers don’t own software, teams own software</h2>
<p>Second, and even more importantly: So what? It doesn’t matter. Individual engineers don’t own software, teams own software. <strong>The smallest unit of software ownership and delivery is the engineering team</strong>. It doesn’t matter how fast an individual engineer can write software, what matters is how fast the team can collectively write, test, review, ship, maintain, refactor, extend, architect, and revise the software that they own.</p>
<p>Everyone uses the same software delivery pipeline. If it takes the slowest engineer at your company five hours to ship a single line of code, it’s going to take the fastest engineer at your company five hours to ship a single line of code. The time spent writing code is typically dwarfed by the time spent on every other part of the software development lifecycle.</p>
<p>If you have services or software components that are owned by a single engineer, that person is a single point of failure.<img data-recalc-dims="1" fetchpriority="high" decoding="async" data-attachment-id="10013" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-spof/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-spof" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=226%2C226&amp;ssl=1" alt="" width="226" height="226" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-spof.png?w=1024&amp;ssl=1 1024w" sizes="(max-width: 226px) 100vw, 226px"></p>
<p>I’m not saying this should never happen. It’s quite normal at startups to have individuals owning software, because the biggest existential risk that you face is not moving fast enough, not finding product market fit, and going out of business. But as you start to grow up as a company, as users start to demand more from you, and you start planning for the survival of the company to extend years into the future…ownership needs to get handed over to a team. Individual engineers get sick, go on vacation, and leave the company, and the business has got to be resilient to that.</p>
<p>If teams own software, then the key job of any engineering leader is to craft high-performing engineering teams. If you must 10x something, 10x this. <strong>Build 10x engineering teams.</strong></p>
<h2>The best engineering orgs are the ones where normal engineers can do great work</h2>
<p>When people talk about world-class engineering orgs, they often have in mind teams that are top-heavy with staff and principal engineers, or recruiting heavily from the ranks of ex-FAANG employees or top universities.</p>
<p>But I would argue that a truly great engineering org is one where you don’t HAVE to be one of the “best” or most pedigreed engineers in the world to get shit done and have a lot of impact on the business.</p>
<p>I think it’s actually the other way around. A truly great engineering organization is one where perfectly normal, workaday software engineers, with decent software engineering skills and an ordinary amount of expertise, can consistently move fast, ship code, respond to users, understand the systems they’ve built, and move the business forward a little bit more, day by day, week by week.</p>
<p>Any asshole can build an org where the most experienced, brilliant engineers in the world can build product and make progress. That is not hard. And putting all the spotlight on individual ability has a way of letting your leaders off the hook for doing their jobs. It is a HUGE competitive advantage if you can build sociotechnical systems where less experienced engineers can convert their effort and energy into product and business momentum.</p>
<p>A truly great engineering org also happens to be one that mints world-class software engineers. But we’re getting ahead of ourselves, here.</p>
<h2>Let’s talk about “normal” for a moment</h2>
<p>A lot of technical people got really attached to our identities as smart kids. The software industry tends to reflect and reinforce this preoccupation at every turn, from Netflix’s “we look for the top 10% of global talent” to Amazon’s talk about “bar-raising” or Coinbase’s recent claim to “hire the top .1%”. (Seriously, guys? Ok, well, Honeycomb is going to hire only the top <em>.00001%</em>!)</p>
<p>In this essay, I would like to challenge us to set that baggage to the side and think about ourselves as <em>normal people</em>.</p>
<p>It can be humbling to think of ourselves as normal people, but most of us are in fact pretty normal people (albeit with many years of highly specialized practice and experience), and<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10011" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-made-not-born/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-made-not-born" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=264%2C264&amp;ssl=1" alt="" width="264" height="264" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-made-not-born.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 264px) 100vw, 264px"> there is <em>nothing wrong with that</em>. Even those of us who are certified geniuses on certain criteria are likely quite normal in other ways — kinesthetic, emotional, spatial, musical, linguistic, etc.</p>
<p>Software engineering both selects for and develops certain types of intelligence, particularly around abstract reasoning, but <em>nobody</em> is born a great software engineer. <strong>Great engineers are made, not born</strong>. I just don’t think there’s a lot more we can get out of thinking of ourselves as a special class of people, compared to the value we can derive from thinking of ourselves collectively as relatively normal people who have practiced a fairly niche craft for a very long time.</p>
<h2>Build sociotechnical systems with “normal people” in mind</h2>
<p>When it comes to hiring talent and building teams, yes, absolutely, we should focus on identifying the ways people are exceptional and talented and strong. But when it comes to building sociotechnical systems for software delivery, we should focus on all the ways people are <em>normal</em>.</p>
<h4><img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=122%2C122&amp;ssl=1" alt="" width="122" height="122" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 122px) 100vw, 122px"></h4>
<p>Normal people have cognitive biases — confirmation bias, recency bias, hindsight bias. We work hard, we care, and we do our best; but we also forget things, get impatient, and zone out. Our eyes are inexorably drawn to the color red (unless we are colorblind). We develop habits and ways of doing things, and resist changing them. When we see the same text block repeatedly, we stop reading it.</p>
<p>We are embodied beings who can get overwhelmed and fatigued. If an alert wakes us up at 3 am, we are much more likely to make mistakes while responding to that alert than if we tried to do the same thing at 3pm. Our emotional state can affect the quality of our work. Our relationships impact our ability to get shit done.</p>
<p>When your systems are designed to be used by normal engineers, all that excess brilliance they have can get poured into the product itself, instead of wasting it on navigating the system itself.</p>
<h2>How do you turn normal engineers into 10x engineering teams?</h2>
<p>None of this should be terribly surprising; it’s all well known wisdom. In order to build the kind of sociotechnical systems for software delivery that enable normal engineers to move fast, learn continuously, and deliver great results as a team, you should:</p>
<h4>Shrink the interval between when you write the code and when the code goes live.</h4>
<p>Make it as short as possible; the shorter the better. I’ve written and given talks about this many, many times. The shorter the interval, the lower the cognitive carrying costs. The faster you can iterate, the better. The more of your brain can go into the product instead of the process of building it.</p>
<p>One of the most powerful things you can do is have a short, fast enough deploy cycle that you can ship one commit per deploy. I’ve referred to this as the “software engineering death spiral” … when the deploy cycle takes so long that you end up batching together a bunch of engineers’ diffs in every build. The slower it gets, the more you batch up, and the harder it becomes to figure out what happened or roll back. The longer it takes, the more people you need, the higher the coordination costs, and the more slowly everyone moves.</p>
<p>Deploy time is the feedback loop at the heart of the development process. It is almost impossible to overstate the centrality of keeping this short and tight.</p>
<h4>Make it easy and fast to roll back or recover from mistakes.</h4>
<p>Developers should be able to deploy their own code, figure out if it’s working as intended or not, and if not, roll forward or back swiftly and easily. No muss, no fuss, no thinking involved.</p>
<h4>Make it easy to do the right thing and hard to do the wrong thing. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10018" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-sparkles/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-sparkles" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=137%2C137&amp;ssl=1" alt="" width="137" height="137" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-sparkles.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 137px) 100vw, 137px"></h4>
<p>Wrap designers and design thinking into all the touch points your engineers have with production systems. Use your platform engineering team to think about how to empower people to swiftly make changes and self-serve, but also remember that a lot of times people will be engaging with production late at night or when they’re very stressed, tired, and&nbsp;possibly freaking out. Build guard rails. The fastest way to ship a single line of code should also be the easiest way to ship a single line of code.</p>
<h4>Invest in instrumentation and observability.</h4>
<p>You’ll never know — not really — what the code you wrote does just by reading it. The only way to be sure is by instrumenting your code and watching real users run it in production. Good, friendly sociotechnical systems invest <em>heavily</em> in tools for sense-making.</p>
<p>Being able to visualize your work is what makes engineering abstractions accessible to actual engineers. You shouldn’t have to be a world-class engineer just to debug your own damn code.</p>
<h4>Devote engineering cycles to internal tooling and enablement.</h4>
<p>If fast, safe deploys, with guard rails, instrumentation, and highly parallelized test suites are “everybody’s job”, they will end up nobody’s job. Engineering productivity isn’t something you can outsource. Managing the interfaces between your software vendors and your own teams is both a science and an art. Making it look easy and intuitive is really hard. It needs an owner.</p>
<h4>Build an inclusive culture.</h4>
<p>Growth is the norm, growth is the baseline. People do their best work when they feel a sense of belonging. An inclusive culture is one where everyone feels safe to ask questions, explore, and make mistakes; where everyone is held to the same high standard, and given the support and encouragement they need to achieve their goals.</p>
<h4>Diverse teams are resilient teams.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10017" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-transp-rainbow/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-transp-rainbow" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=196%2C196&amp;ssl=1" alt="" width="196" height="196" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-transp-rainbow.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 196px) 100vw, 196px"></h4>
<p>Yeah, a team of super-senior engineers who all share a similar background can move incredibly fast, but a monoculture is fragile. Someone gets sick, someone gets pregnant, you start to grow and you need to integrate people from other backgrounds and the whole team can get derailed — fast.</p>
<p>When your teams are used to operating with a mix of genders, racial backgrounds, identities, age ranges, family statuses, geographical locations, skill sets, etc — when this is just table stakes, standard operating procedure — you’re better equipped to roll with it when life happens.</p>
<h4>Assemble engineering teams from a range of levels.</h4>
<p>The best engineering teams aren’t top-heavy with staff engineers and principal engineers. The best engineering teams are ones where nobody is running on autopilot, banging out a login page for the 300th time; everyone is working on something that challenges them and pushes their boundaries. Everyone is learning, everyone is teaching, everyone is pushing their own boundaries and growing. All the time.</p>
<p>By the way — all of that work you put into making your systems resilient, well-designed, and humane is the same work you would need to do to help onboard new engineers, develop junior talent, or let engineers move between teams.</p>
<p>It gets used and reused. Over and over and over again.</p>
<h2>The only meaningful measure of productivity is impact to the business</h2>
<p>The only thing that actually matters when it comes to engineering productivity is whether or not you are moving the business materially forward.</p>
<p>Which means…we can’t do this in a vacuum. The most important question is whether or not we are working on the right thing, which is a problem engineering can’t answer without help from product, design, and the rest of the business.</p>
<p>Software engineering isn’t about writing lots of lines of code, it’s about solving business problems using technology.</p>
<p>Senior and intermediate engineers are actually the workhorses of the industry. They move the business forward, step by step, day by day. They get to put their heads down and crank instead of constantly looking around the org and solving coordination problems. If you have to be a staff+ engineer to move the product forward, something is seriously wrong.</p>
<h2>Great engineering orgs mint world-class engineers</h2>
<p>A great engineering org is one where you don’t HAVE to be one of the best engineers in the world to have a lot of impact. But — rather ironically — great engineering orgs mint world class engineers like nobody’s business.</p>
<p>The best engineering orgs are not the ones with the smartest, most experienced people in the world, they’re the ones where normal software engineers can consistently make progress, deliver value to users, and move the business forward, day after day.<img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10019" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-system-does/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-system-does" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=253%2C253&amp;ssl=1" alt="" width="253" height="253" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-system-does.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 253px) 100vw, 253px"></p>
<p>Places where engineers can get shit done and have a lot of impact are a magnet for top performers. Nothing makes engineers happier than building things, solving problems, making progress.</p>
<p>If you’re lucky enough to have world-class engineers in your org, good for you! Your role as a leader is to leverage their brilliance for the good of your customers and your other engineers, without coming to depend on their brilliance. After all, these people don’t belong to you. They may walk out the door at any moment, and that has to be okay.</p>
<p>These people can be phenomenal assets, assuming they can be team players and keep their egos in check. Which is probably why so many tech companies seem to obsess over identifying and hiring them, especially in Silicon Valley.</p>
<p>But companies categorically overindex on finding these people after they’ve already been minted, which ends up reinforcing and replicating all the prejudices and inequities of the world at large. Talent may be evenly distributed across populations, but opportunity is not.</p>
<h2>Don’t hire the “best” people. Hire the right people.</h2>
<p>We (by which I mean the entire human race) place too much emphasis on individual agency and characteristics, and not enough on the systems that shape us and inform our behaviors.</p>
<p>I feel like a whole slew of issues (candidates self-selecting out of the interview process, diversity of applicants, etc) would be improved simply by shifting the focus on engineering hiring and interviewing away from this inordinate emphasis on hiring the BEST PEOPLE and realigning around the more reasonable and accurate RIGHT PEOPLE. <img data-recalc-dims="1" loading="lazy" decoding="async" data-attachment-id="10023" data-permalink="https://charity.wtf/2025/06/19/in-praise-of-normal-engineers/normal-hire/" data-orig-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=1024%2C1024&amp;ssl=1" data-orig-size="1024,1024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="normal-hire" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=300%2C300&amp;ssl=1" data-large-file="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?fit=660%2C660&amp;ssl=1" src="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=182%2C182&amp;ssl=1" alt="" width="182" height="182" srcset="https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=300%2C300&amp;ssl=1 300w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=150%2C150&amp;ssl=1 150w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?resize=768%2C768&amp;ssl=1 768w, https://i0.wp.com/charity.wtf/wp-content/uploads/2025/06/normal-hire.png?w=1024&amp;ssl=1 1024w" sizes="auto, (max-width: 182px) 100vw, 182px"></p>
<p>It’s a competitive advantage to build an environment where people can be hired for their unique strengths, not their lack of weaknesses; where the emphasis is on composing teams rather than hiring the BEST people; where inclusivity is a given both for ethical reasons and&nbsp;because it raises the bar for performance for everyone. Inclusive culture is what actual meritocracy depends on.</p>
<p>This is the kind of place that engineering talent (and good humans) are drawn to like a moth to a flame. <strong>It feels good to ship</strong>. It feels <em>good</em> to move the business forward. It feels <em>good</em> to sharpen your skills and improve your craft. It’s the kind of place that people go when they want to become world class engineers. And it’s the kind of place where world class engineers want to stick around, to train up the next generation.</p>
<p>&lt;3, charity</p>

			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: EnrichMCP – A Python ORM for Agents (108 pts)]]></title>
            <link>https://github.com/featureform/enrichmcp</link>
            <guid>44320772</guid>
            <pubDate>Thu, 19 Jun 2025 17:32:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/featureform/enrichmcp">https://github.com/featureform/enrichmcp</a>, See on <a href="https://news.ycombinator.com/item?id=44320772">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">EnrichMCP</h2><a id="user-content-enrichmcp" aria-label="Permalink: EnrichMCP" href="#enrichmcp"></a></p>
<p dir="auto"><strong>The ORM for AI Agents - Turn your data model into a semantic MCP layer</strong></p>
<p dir="auto"><a href="https://github.com/featureform/enrichmcp/actions/workflows/ci.yml"><img src="https://github.com/featureform/enrichmcp/actions/workflows/ci.yml/badge.svg" alt="CI"></a>
<a href="https://codecov.io/gh/featureform/enrichmcp" rel="nofollow"><img src="https://camo.githubusercontent.com/7855073cf4372a4aceef8ff09904a532a0f7c9e5fe32ae01099e0acd39de873a/68747470733a2f2f636f6465636f762e696f2f67682f66656174757265666f726d2f656e726963686d63702f6272616e63682f6d61696e2f67726170682f62616467652e737667" alt="Coverage" data-canonical-src="https://codecov.io/gh/featureform/enrichmcp/branch/main/graph/badge.svg"></a>
<a href="https://pypi.org/project/enrichmcp/" rel="nofollow"><img src="https://camo.githubusercontent.com/eb717e44a9bca52f6bba59058aaee7ffb7d1117a378af677b2e15712e355594c/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f656e726963686d63702e737667" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/enrichmcp.svg"></a>
<a href="https://www.python.org/downloads/" rel="nofollow"><img src="https://camo.githubusercontent.com/1e5852941fcfe768cdba62e1ef6b1db0d9c87c4f9017432c39ad06853f6d4df9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31312b2d626c75652e737667" alt="Python 3.11+" data-canonical-src="https://img.shields.io/badge/python-3.11+-blue.svg"></a>
<a href="https://github.com/featureform/enrichmcp/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/c355f200ea90fddaa407b6eaab303663a669248ea3ca7b1fcf77dbe04ff5f48c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322e302d626c75652e737667" alt="License" data-canonical-src="https://img.shields.io/badge/license-Apache%202.0-blue.svg"></a></p>
<p dir="auto">EnrichMCP is a Python framework that helps AI agents understand and navigate your data. Built on MCP (Model Context Protocol), it adds a semantic layer that turns your data model into typed, discoverable tools - like an ORM for AI.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is EnrichMCP?</h2><a id="user-content-what-is-enrichmcp" aria-label="Permalink: What is EnrichMCP?" href="#what-is-enrichmcp"></a></p>
<p dir="auto">Think of it as SQLAlchemy for AI agents. EnrichMCP automatically:</p>
<ul dir="auto">
<li><strong>Generates typed tools</strong> from your data models</li>
<li><strong>Handles relationships</strong> between entities (users → orders → products)</li>
<li><strong>Provides schema discovery</strong> so AI agents understand your data structure</li>
<li><strong>Validates all inputs/outputs</strong> with Pydantic models</li>
<li><strong>Works with any backend</strong> - databases, APIs, or custom logic</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install enrichmcp

# With SQLAlchemy support
pip install enrichmcp[sqlalchemy]"><pre>pip install enrichmcp

<span><span>#</span> With SQLAlchemy support</span>
pip install enrichmcp[sqlalchemy]</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Show Me Code</h2><a id="user-content-show-me-code" aria-label="Permalink: Show Me Code" href="#show-me-code"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 1: I Have SQLAlchemy Models (30 seconds)</h3><a id="user-content-option-1-i-have-sqlalchemy-models-30-seconds" aria-label="Permalink: Option 1: I Have SQLAlchemy Models (30 seconds)" href="#option-1-i-have-sqlalchemy-models-30-seconds"></a></p>
<p dir="auto">Transform your existing SQLAlchemy models into an AI-navigable API:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP
from enrichmcp.sqlalchemy import include_sqlalchemy_models, sqlalchemy_lifespan, EnrichSQLAlchemyMixin
from sqlalchemy.ext.asyncio import create_async_engine
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column, relationship

engine = create_async_engine(&quot;postgresql+asyncpg://user:pass@localhost/db&quot;)

# Add the mixin to your declarative base
class Base(DeclarativeBase, EnrichSQLAlchemyMixin):
    pass

class User(Base):
    __tablename__ = &quot;users&quot;

    id: Mapped[int] = mapped_column(primary_key=True)
    email: Mapped[str] = mapped_column(unique=True)
    status: Mapped[str] = mapped_column(default=&quot;active&quot;)
    orders: Mapped[list[&quot;Order&quot;]] = relationship(back_populates=&quot;user&quot;)

class Order(Base):
    __tablename__ = &quot;orders&quot;

    id: Mapped[int] = mapped_column(primary_key=True)
    user_id: Mapped[int] = mapped_column(ForeignKey(&quot;users.id&quot;))
    total: Mapped[float] = mapped_column()
    user: Mapped[User] = relationship(back_populates=&quot;orders&quot;)

# That's it! Create your MCP app
app = EnrichMCP(
    &quot;E-commerce Data&quot;,
    lifespan=sqlalchemy_lifespan(Base, engine, cleanup_db_file=True),
)
include_sqlalchemy_models(app, Base)

if __name__ == &quot;__main__&quot;:
    app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>
<span>from</span> <span>enrichmcp</span>.<span>sqlalchemy</span> <span>import</span> <span>include_sqlalchemy_models</span>, <span>sqlalchemy_lifespan</span>, <span>EnrichSQLAlchemyMixin</span>
<span>from</span> <span>sqlalchemy</span>.<span>ext</span>.<span>asyncio</span> <span>import</span> <span>create_async_engine</span>
<span>from</span> <span>sqlalchemy</span>.<span>orm</span> <span>import</span> <span>DeclarativeBase</span>, <span>Mapped</span>, <span>mapped_column</span>, <span>relationship</span>

<span>engine</span> <span>=</span> <span>create_async_engine</span>(<span>"postgresql+asyncpg://user:pass@localhost/db"</span>)

<span># Add the mixin to your declarative base</span>
<span>class</span> <span>Base</span>(<span>DeclarativeBase</span>, <span>EnrichSQLAlchemyMixin</span>):
    <span>pass</span>

<span>class</span> <span>User</span>(<span>Base</span>):
    <span>__tablename__</span> <span>=</span> <span>"users"</span>

    <span>id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>primary_key</span><span>=</span><span>True</span>)
    <span>email</span>: <span>Mapped</span>[<span>str</span>] <span>=</span> <span>mapped_column</span>(<span>unique</span><span>=</span><span>True</span>)
    <span>status</span>: <span>Mapped</span>[<span>str</span>] <span>=</span> <span>mapped_column</span>(<span>default</span><span>=</span><span>"active"</span>)
    <span>orders</span>: <span>Mapped</span>[<span>list</span>[<span>"Order"</span>]] <span>=</span> <span>relationship</span>(<span>back_populates</span><span>=</span><span>"user"</span>)

<span>class</span> <span>Order</span>(<span>Base</span>):
    <span>__tablename__</span> <span>=</span> <span>"orders"</span>

    <span>id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>primary_key</span><span>=</span><span>True</span>)
    <span>user_id</span>: <span>Mapped</span>[<span>int</span>] <span>=</span> <span>mapped_column</span>(<span>ForeignKey</span>(<span>"users.id"</span>))
    <span>total</span>: <span>Mapped</span>[<span>float</span>] <span>=</span> <span>mapped_column</span>()
    <span>user</span>: <span>Mapped</span>[<span>User</span>] <span>=</span> <span>relationship</span>(<span>back_populates</span><span>=</span><span>"orders"</span>)

<span># That's it! Create your MCP app</span>
<span>app</span> <span>=</span> <span>EnrichMCP</span>(
    <span>"E-commerce Data"</span>,
    <span>lifespan</span><span>=</span><span>sqlalchemy_lifespan</span>(<span>Base</span>, <span>engine</span>, <span>cleanup_db_file</span><span>=</span><span>True</span>),
)
<span>include_sqlalchemy_models</span>(<span>app</span>, <span>Base</span>)

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>app</span>.<span>run</span>()</pre></div>
<p dir="auto">AI agents can now:</p>
<ul dir="auto">
<li><code>explore_data_model()</code> - understand your entire schema</li>
<li><code>list_users(status='active')</code> - query with filters</li>
<li><code>get_user(id=123)</code> - fetch specific records</li>
<li>Navigate relationships: <code>user.orders</code> → <code>order.user</code></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 2: I Have REST APIs (2 minutes)</h3><a id="user-content-option-2-i-have-rest-apis-2-minutes" aria-label="Permalink: Option 2: I Have REST APIs (2 minutes)" href="#option-2-i-have-rest-apis-2-minutes"></a></p>
<p dir="auto">Wrap your existing APIs with semantic understanding:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP, EnrichModel, Relationship
from pydantic import Field

app = EnrichMCP(&quot;API Gateway&quot;)

@app.entity
class Customer(EnrichModel):
    &quot;&quot;&quot;Customer in our CRM system.&quot;&quot;&quot;

    id: int = Field(description=&quot;Unique customer ID&quot;)
    email: str = Field(description=&quot;Primary contact email&quot;)
    tier: str = Field(description=&quot;Subscription tier: free, pro, enterprise&quot;)

    # Define navigable relationships
    orders: list[&quot;Order&quot;] = Relationship(description=&quot;Customer's purchase history&quot;)

@app.entity
class Order(EnrichModel):
    &quot;&quot;&quot;Customer order from our e-commerce platform.&quot;&quot;&quot;

    id: int = Field(description=&quot;Order ID&quot;)
    customer_id: int = Field(description=&quot;Associated customer&quot;)
    total: float = Field(description=&quot;Order total in USD&quot;)
    status: str = Field(description=&quot;Order status: pending, shipped, delivered&quot;)

    customer: Customer = Relationship(description=&quot;Customer who placed this order&quot;)

# Define how to fetch data
@app.resource
async def get_customer(customer_id: int) -> Customer:
    &quot;&quot;&quot;Fetch customer from CRM API.&quot;&quot;&quot;
    response = await http.get(f&quot;/api/customers/{customer_id}&quot;)
    return Customer(**response.json())

# Define relationship resolvers
@Customer.orders.resolver
async def get_customer_orders(customer_id: int) -> list[Order]:
    &quot;&quot;&quot;Fetch orders for a customer.&quot;&quot;&quot;
    response = await http.get(f&quot;/api/customers/{customer_id}/orders&quot;)
    return [Order(**order) for order in response.json()]

app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>, <span>EnrichModel</span>, <span>Relationship</span>
<span>from</span> <span>pydantic</span> <span>import</span> <span>Field</span>

<span>app</span> <span>=</span> <span>EnrichMCP</span>(<span>"API Gateway"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Customer</span>(<span>EnrichModel</span>):
    <span>"""Customer in our CRM system."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Unique customer ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Primary contact email"</span>)
    <span>tier</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Subscription tier: free, pro, enterprise"</span>)

    <span># Define navigable relationships</span>
    <span>orders</span>: <span>list</span>[<span>"Order"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Customer's purchase history"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Order</span>(<span>EnrichModel</span>):
    <span>"""Customer order from our e-commerce platform."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order ID"</span>)
    <span>customer_id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Associated customer"</span>)
    <span>total</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order total in USD"</span>)
    <span>status</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Order status: pending, shipped, delivered"</span>)

    <span>customer</span>: <span>Customer</span> <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Customer who placed this order"</span>)

<span># Define how to fetch data</span>
<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>get_customer</span>(<span>customer_id</span>: <span>int</span>) <span>-&gt;</span> <span>Customer</span>:
    <span>"""Fetch customer from CRM API."""</span>
    <span>response</span> <span>=</span> <span>await</span> <span>http</span>.<span>get</span>(<span>f"/api/customers/<span><span>{</span><span>customer_id</span><span>}</span></span>"</span>)
    <span>return</span> <span>Customer</span>(<span>**</span><span>response</span>.<span>json</span>())

<span># Define relationship resolvers</span>
<span>@<span>Customer</span>.<span>orders</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>get_customer_orders</span>(<span>customer_id</span>: <span>int</span>) <span>-&gt;</span> <span>list</span>[<span>Order</span>]:
    <span>"""Fetch orders for a customer."""</span>
    <span>response</span> <span>=</span> <span>await</span> <span>http</span>.<span>get</span>(<span>f"/api/customers/<span><span>{</span><span>customer_id</span><span>}</span></span>/orders"</span>)
    <span>return</span> [<span>Order</span>(<span>**</span><span>order</span>) <span>for</span> <span>order</span> <span>in</span> <span>response</span>.<span>json</span>()]

<span>app</span>.<span>run</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Option 3: I Want Full Control (5 minutes)</h3><a id="user-content-option-3-i-want-full-control-5-minutes" aria-label="Permalink: Option 3: I Want Full Control (5 minutes)" href="#option-3-i-want-full-control-5-minutes"></a></p>
<p dir="auto">Build a complete data layer with custom logic:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import EnrichMCP, EnrichModel, Relationship, EnrichContext
from datetime import datetime
from decimal import Decimal

app = EnrichMCP(&quot;Analytics Platform&quot;)

@app.entity
class User(EnrichModel):
    &quot;&quot;&quot;User with computed analytics fields.&quot;&quot;&quot;

    id: int = Field(description=&quot;User ID&quot;)
    email: str = Field(description=&quot;Contact email&quot;)
    created_at: datetime = Field(description=&quot;Registration date&quot;)

    # Computed fields
    lifetime_value: Decimal = Field(description=&quot;Total revenue from user&quot;)
    churn_risk: float = Field(description=&quot;ML-predicted churn probability 0-1&quot;)

    # Relationships
    orders: list[&quot;Order&quot;] = Relationship(description=&quot;Purchase history&quot;)
    segments: list[&quot;Segment&quot;] = Relationship(description=&quot;Marketing segments&quot;)

@app.entity
class Segment(EnrichModel):
    &quot;&quot;&quot;Dynamic user segment for marketing.&quot;&quot;&quot;

    name: str = Field(description=&quot;Segment name&quot;)
    criteria: dict = Field(description=&quot;Segment criteria&quot;)
    users: list[User] = Relationship(description=&quot;Users in this segment&quot;)

# Complex resource with business logic
@app.resource
async def find_high_value_at_risk_users(
    lifetime_value_min: Decimal = 1000,
    churn_risk_min: float = 0.7,
    limit: int = 100
) -> list[User]:
    &quot;&quot;&quot;Find valuable customers likely to churn.&quot;&quot;&quot;
    users = await db.query(
        &quot;&quot;&quot;
        SELECT * FROM users
        WHERE lifetime_value >= ? AND churn_risk >= ?
        ORDER BY lifetime_value DESC
        LIMIT ?
        &quot;&quot;&quot;,
        lifetime_value_min, churn_risk_min, limit
    )
    return [User(**u) for u in users]

# Async computed field resolver
@User.lifetime_value.resolver
async def calculate_lifetime_value(user_id: int) -> Decimal:
    &quot;&quot;&quot;Calculate total revenue from user's orders.&quot;&quot;&quot;
    total = await db.query_single(
        &quot;SELECT SUM(total) FROM orders WHERE user_id = ?&quot;,
        user_id
    )
    return Decimal(str(total or 0))

# ML-powered field
@User.churn_risk.resolver
async def predict_churn_risk(user_id: int, context: EnrichContext) -> float:
    &quot;&quot;&quot;Run churn prediction model.&quot;&quot;&quot;
    features = await gather_user_features(user_id)
    model = context.get(&quot;ml_models&quot;)[&quot;churn&quot;]
    return float(model.predict_proba(features)[0][1])

app.run()"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>EnrichMCP</span>, <span>EnrichModel</span>, <span>Relationship</span>, <span>EnrichContext</span>
<span>from</span> <span>datetime</span> <span>import</span> <span>datetime</span>
<span>from</span> <span>decimal</span> <span>import</span> <span>Decimal</span>

<span>app</span> <span>=</span> <span>EnrichMCP</span>(<span>"Analytics Platform"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>User</span>(<span>EnrichModel</span>):
    <span>"""User with computed analytics fields."""</span>

    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"User ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Contact email"</span>)
    <span>created_at</span>: <span>datetime</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Registration date"</span>)

    <span># Computed fields</span>
    <span>lifetime_value</span>: <span>Decimal</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Total revenue from user"</span>)
    <span>churn_risk</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"ML-predicted churn probability 0-1"</span>)

    <span># Relationships</span>
    <span>orders</span>: <span>list</span>[<span>"Order"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Purchase history"</span>)
    <span>segments</span>: <span>list</span>[<span>"Segment"</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Marketing segments"</span>)

<span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Segment</span>(<span>EnrichModel</span>):
    <span>"""Dynamic user segment for marketing."""</span>

    <span>name</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Segment name"</span>)
    <span>criteria</span>: <span>dict</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Segment criteria"</span>)
    <span>users</span>: <span>list</span>[<span>User</span>] <span>=</span> <span>Relationship</span>(<span>description</span><span>=</span><span>"Users in this segment"</span>)

<span># Complex resource with business logic</span>
<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>find_high_value_at_risk_users</span>(
    <span>lifetime_value_min</span>: <span>Decimal</span> <span>=</span> <span>1000</span>,
    <span>churn_risk_min</span>: <span>float</span> <span>=</span> <span>0.7</span>,
    <span>limit</span>: <span>int</span> <span>=</span> <span>100</span>
) <span>-&gt;</span> <span>list</span>[<span>User</span>]:
    <span>"""Find valuable customers likely to churn."""</span>
    <span>users</span> <span>=</span> <span>await</span> <span>db</span>.<span>query</span>(
        <span>"""</span>
<span>        SELECT * FROM users</span>
<span>        WHERE lifetime_value &gt;= ? AND churn_risk &gt;= ?</span>
<span>        ORDER BY lifetime_value DESC</span>
<span>        LIMIT ?</span>
<span>        """</span>,
        <span>lifetime_value_min</span>, <span>churn_risk_min</span>, <span>limit</span>
    )
    <span>return</span> [<span>User</span>(<span>**</span><span>u</span>) <span>for</span> <span>u</span> <span>in</span> <span>users</span>]

<span># Async computed field resolver</span>
<span>@<span>User</span>.<span>lifetime_value</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>calculate_lifetime_value</span>(<span>user_id</span>: <span>int</span>) <span>-&gt;</span> <span>Decimal</span>:
    <span>"""Calculate total revenue from user's orders."""</span>
    <span>total</span> <span>=</span> <span>await</span> <span>db</span>.<span>query_single</span>(
        <span>"SELECT SUM(total) FROM orders WHERE user_id = ?"</span>,
        <span>user_id</span>
    )
    <span>return</span> <span>Decimal</span>(<span>str</span>(<span>total</span> <span>or</span> <span>0</span>))

<span># ML-powered field</span>
<span>@<span>User</span>.<span>churn_risk</span>.<span>resolver</span></span>
<span>async</span> <span>def</span> <span>predict_churn_risk</span>(<span>user_id</span>: <span>int</span>, <span>context</span>: <span>EnrichContext</span>) <span>-&gt;</span> <span>float</span>:
    <span>"""Run churn prediction model."""</span>
    <span>features</span> <span>=</span> <span>await</span> <span>gather_user_features</span>(<span>user_id</span>)
    <span>model</span> <span>=</span> <span>context</span>.<span>get</span>(<span>"ml_models"</span>)[<span>"churn"</span>]
    <span>return</span> <span>float</span>(<span>model</span>.<span>predict_proba</span>(<span>features</span>)[<span>0</span>][<span>1</span>])

<span>app</span>.<span>run</span>()</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Features</h2><a id="user-content-key-features" aria-label="Permalink: Key Features" href="#key-features"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔍 Automatic Schema Discovery</h3><a id="user-content--automatic-schema-discovery" aria-label="Permalink: 🔍 Automatic Schema Discovery" href="#-automatic-schema-discovery"></a></p>
<p dir="auto">AI agents explore your entire data model with one call:</p>
<div dir="auto" data-snippet-clipboard-copy-content="schema = await explore_data_model()
# Returns complete schema with entities, fields, types, and relationships"><pre><span>schema</span> <span>=</span> <span>await</span> <span>explore_data_model</span>()
<span># Returns complete schema with entities, fields, types, and relationships</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔗 Relationship Navigation</h3><a id="user-content--relationship-navigation" aria-label="Permalink: 🔗 Relationship Navigation" href="#-relationship-navigation"></a></p>
<p dir="auto">Define relationships once, AI agents traverse naturally:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# AI can navigate: user → orders → products → categories
user = await get_user(123)
orders = await user.orders()  # Automatic resolver
products = await orders[0].products()"><pre><span># AI can navigate: user → orders → products → categories</span>
<span>user</span> <span>=</span> <span>await</span> <span>get_user</span>(<span>123</span>)
<span>orders</span> <span>=</span> <span>await</span> <span>user</span>.<span>orders</span>()  <span># Automatic resolver</span>
<span>products</span> <span>=</span> <span>await</span> <span>orders</span>[<span>0</span>].<span>products</span>()</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🛡️ Type Safety &amp; Validation</h3><a id="user-content-️-type-safety--validation" aria-label="Permalink: 🛡️ Type Safety &amp; Validation" href="#️-type-safety--validation"></a></p>
<p dir="auto">Full Pydantic validation on every interaction:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.entity
class Order(EnrichModel):
    total: float = Field(ge=0, description=&quot;Must be positive&quot;)
    email: EmailStr = Field(description=&quot;Customer email&quot;)
    status: Literal[&quot;pending&quot;, &quot;shipped&quot;, &quot;delivered&quot;]"><pre><span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Order</span>(<span>EnrichModel</span>):
    <span>total</span>: <span>float</span> <span>=</span> <span>Field</span>(<span>ge</span><span>=</span><span>0</span>, <span>description</span><span>=</span><span>"Must be positive"</span>)
    <span>email</span>: <span>EmailStr</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"Customer email"</span>)
    <span>status</span>: <span>Literal</span>[<span>"pending"</span>, <span>"shipped"</span>, <span>"delivered"</span>]</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">✏️ Mutability &amp; CRUD</h3><a id="user-content-️-mutability--crud" aria-label="Permalink: ✏️ Mutability &amp; CRUD" href="#️-mutability--crud"></a></p>
<p dir="auto">Fields are immutable by default. Mark them as mutable and use
auto-generated patch models for updates:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.entity
class Customer(EnrichModel):
    id: int = Field(description=&quot;ID&quot;)
    email: str = Field(mutable=True, description=&quot;Email&quot;)

@app.create
async def create_customer(email: str) -> Customer:
    ...

@app.update
async def update_customer(cid: int, patch: Customer.PatchModel) -> Customer:
    ...

@app.delete
async def delete_customer(cid: int) -> bool:
    ..."><pre><span>@<span>app</span>.<span>entity</span></span>
<span>class</span> <span>Customer</span>(<span>EnrichModel</span>):
    <span>id</span>: <span>int</span> <span>=</span> <span>Field</span>(<span>description</span><span>=</span><span>"ID"</span>)
    <span>email</span>: <span>str</span> <span>=</span> <span>Field</span>(<span>mutable</span><span>=</span><span>True</span>, <span>description</span><span>=</span><span>"Email"</span>)

<span>@<span>app</span>.<span>create</span></span>
<span>async</span> <span>def</span> <span>create_customer</span>(<span>email</span>: <span>str</span>) <span>-&gt;</span> <span>Customer</span>:
    ...

<span>@<span>app</span>.<span>update</span></span>
<span>async</span> <span>def</span> <span>update_customer</span>(<span>cid</span>: <span>int</span>, <span>patch</span>: <span>Customer</span>.<span>PatchModel</span>) <span>-&gt;</span> <span>Customer</span>:
    ...

<span>@<span>app</span>.<span>delete</span></span>
<span>async</span> <span>def</span> <span>delete_customer</span>(<span>cid</span>: <span>int</span>) <span>-&gt;</span> <span>bool</span>:
    ...</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">📄 Pagination Built-in</h3><a id="user-content--pagination-built-in" aria-label="Permalink: 📄 Pagination Built-in" href="#-pagination-built-in"></a></p>
<p dir="auto">Handle large datasets elegantly:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from enrichmcp import PageResult

@app.resource
async def list_orders(
    page: int = 1,
    page_size: int = 50
) -> PageResult[Order]:
    orders, total = await db.get_orders_page(page, page_size)
    return PageResult.create(
        items=orders,
        page=page,
        page_size=page_size,
        total_items=total
    )"><pre><span>from</span> <span>enrichmcp</span> <span>import</span> <span>PageResult</span>

<span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>list_orders</span>(
    <span>page</span>: <span>int</span> <span>=</span> <span>1</span>,
    <span>page_size</span>: <span>int</span> <span>=</span> <span>50</span>
) <span>-&gt;</span> <span>PageResult</span>[<span>Order</span>]:
    <span>orders</span>, <span>total</span> <span>=</span> <span>await</span> <span>db</span>.<span>get_orders_page</span>(<span>page</span>, <span>page_size</span>)
    <span>return</span> <span>PageResult</span>.<span>create</span>(
        <span>items</span><span>=</span><span>orders</span>,
        <span>page</span><span>=</span><span>page</span>,
        <span>page_size</span><span>=</span><span>page_size</span>,
        <span>total_items</span><span>=</span><span>total</span>
    )</pre></div>
<p dir="auto">See the <a href="https://featureform.github.io/enrichmcp/pagination" rel="nofollow">Pagination Guide</a> for more examples.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔐 Context &amp; Authentication</h3><a id="user-content--context--authentication" aria-label="Permalink: 🔐 Context &amp; Authentication" href="#-context--authentication"></a></p>
<p dir="auto">Pass auth, database connections, or any context:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@app.resource
async def get_user_profile(user_id: int, context: EnrichContext) -> UserProfile:
    # Access context provided by MCP client
    auth_user = context.get(&quot;authenticated_user_id&quot;)
    if auth_user != user_id:
        raise PermissionError(&quot;Can only access your own profile&quot;)
    return await db.get_profile(user_id)"><pre><span>@<span>app</span>.<span>resource</span></span>
<span>async</span> <span>def</span> <span>get_user_profile</span>(<span>user_id</span>: <span>int</span>, <span>context</span>: <span>EnrichContext</span>) <span>-&gt;</span> <span>UserProfile</span>:
    <span># Access context provided by MCP client</span>
    <span>auth_user</span> <span>=</span> <span>context</span>.<span>get</span>(<span>"authenticated_user_id"</span>)
    <span>if</span> <span>auth_user</span> <span>!=</span> <span>user_id</span>:
        <span>raise</span> <span>PermissionError</span>(<span>"Can only access your own profile"</span>)
    <span>return</span> <span>await</span> <span>db</span>.<span>get_profile</span>(<span>user_id</span>)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why EnrichMCP?</h2><a id="user-content-why-enrichmcp" aria-label="Permalink: Why EnrichMCP?" href="#why-enrichmcp"></a></p>
<p dir="auto">EnrichMCP adds three critical layers on top of MCP:</p>
<ol dir="auto">
<li><strong>Semantic Layer</strong> - AI agents understand what your data means, not just its structure</li>
<li><strong>Data Layer</strong> - Type-safe models with validation and relationships</li>
<li><strong>Control Layer</strong> - Authentication, pagination, and business logic</li>
</ol>
<p dir="auto">The result: AI agents can work with your data as naturally as a developer using an ORM.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">Check out the <a href="https://github.com/featureform/enrichmcp/blob/main/examples/README.md">examples directory</a>:</p>
<ul dir="auto">
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/hello_world">hello_world</a> - The smallest possible EnrichMCP app</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api">shop_api</a> - In-memory shop API with pagination and filters</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api_sqlite">shop_api_sqlite</a> - SQLite-backed version</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/shop_api_gateway">shop_api_gateway</a> - EnrichMCP as a gateway in front of FastAPI</li>
<li><a href="https://github.com/featureform/enrichmcp/blob/main/examples/sqlalchemy_shop">sqlalchemy_shop</a> - Auto-generated API from SQLAlchemy models</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<ul dir="auto">
<li>📖 <a href="https://featureform.github.io/enrichmcp" rel="nofollow">Full Documentation</a></li>
<li>🚀 <a href="https://featureform.github.io/enrichmcp/getting-started" rel="nofollow">Getting Started Guide</a></li>
<li>🔧 <a href="https://featureform.github.io/enrichmcp/api" rel="nofollow">API Reference</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions! See <a href="https://github.com/featureform/enrichmcp/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Apache 2.0 - See <a href="https://github.com/featureform/enrichmcp/blob/main/LICENSE">LICENSE</a></p>
<hr>
<p dir="auto">Built by <a href="https://featureform.com/" rel="nofollow">Featureform</a> • <a href="https://modelcontextprotocol.io/" rel="nofollow">MCP Protocol</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How OpenElections uses LLMs (103 pts)]]></title>
            <link>https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html</link>
            <guid>44320001</guid>
            <pubDate>Thu, 19 Jun 2025 16:11:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html">https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/index.html</a>, See on <a href="https://news.ycombinator.com/item?id=44320001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="quarto-content">
<!-- sidebar -->
  

<!-- margin-sidebar -->
    
<!-- main -->
<main id="quarto-document-content">





<p>In the 12-plus years that we’ve been turning official precinct election results into data at <a href="https://github.com/openelections">OpenElections</a>, the single biggest problem has been converting pictures of results into CSV files. Many of the precinct results files we get are image PDFs, and for those there are essentially two options: data entry or Optical Character Recognition. The former has some advantages, but not many. While most people are not great at manual repetitive tasks, you can improve with lots of practice, to the point where the results are very accurate. In the past we did pay for data entry services, and while we developed working relationships with two individuals in particular, the results almost always contained some mistakes and the cost could run into the hundreds of dollars pretty quickly. For a volunteer project, it just didn’t make sense.</p>
<p>We also used commercial OCR software, most often Able2Extract, which did pretty well, but had a harder time with PDFs that had markings or were otherwise difficult to parse. Thankfully, most election results PDFs are in one of a small handful of formats, which makes things a bit less complicated, but commercial OCR has too many restrictions.</p>
<p>For parsing image PDFs into CSV files, Google’s Gemini is my model of choice, for two main reasons. First, the results are usually very, very accurate (with a few caveats I’ll detail below), and second, Gemini’s large context window means it’s possible to work with PDF files that can be multiple MBs in size. Here are some examples using image PDFs from Texas counties of how OpenElections uses Gemini for its work.</p>
<section id="limestone-county">
<h3 data-anchor-id="limestone-county">Limestone County</h3>
<p>The Limestone County file containing its 2024 general election results isn’t too bad for an image PDF:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/limestone.png" width="800"></p>
</figure>
</div>
<p>It has clear black text on a white background without markings. But two big issues make it hard for most OCR software to deal with: the two-column layout, with results from races on the left and the right; and those annoying dots between the end of candidate values and the vote totals. It’s like a delimited layout within a fixed-width layout. If you use OCR software, generally you have to draw the boxes around areas of PDFs like this in order to make the extraction results usable. <a href="https://github.com/openelections/openelections-sources-tx/blob/master/2024/general/2024%20Limestone%20County%2C%20TX%20precinct-level%20results.pdf">This PDF</a> isn’t too large at 42 pages, but that’s still a fair bit of manual labor to get the results, and even then there would be some cleanup required.</p>
<p>This is where good LLMs should be able to make a difference, because what you want is high-quality OCR results <em>and</em> the ability to provide some domain or business logic to the process without having to do it all yourself. You can see from <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221vZq4hi_eCqR58TkuzqPugDcOc2kE1tms%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">this Google Gemini session</a> that I didn’t have to provide much in the way of instructions after giving an example of the CSV output and some basic office standardization, just “The results are split into two columns on each page; parse the left column first and then the right column.”</p>
<p>How did Gemini do? Pretty well, almost perfectly. The numbers are accurate, according to some spot checks of candidate totals from <a href="https://results.texas-election.com/county">the Texas Secretary of State website</a>. It did make some formatting mistakes; removing a blank column in some of the Registered Voters and Ballots Cast rows, for example. But that’s a quick fix, and the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__limestone__precinct.csv">finished result</a> is exactly what we need. It’s easy to be impressed, but it’s also just 42 pages and had a simple format.</p>
</section>
<section id="live-oak-county">
<h3 data-anchor-id="live-oak-county">Live Oak County</h3>
<p>The PDF with results from Live Oak County comes in a common format that features a green background. But Live Oak’s image PDF is a black and white scan with different variations of shading, plus we don’t want the four columns containing percentages. For commercial OCR software, this would be a real problem thanks to the layout alone. Indeed, for electronic PDFs that are produced using the same software, we’ve got <a href="https://github.com/openelections/openelections-data-tx/blob/master/python-parsers/greenbox.py">a Python script that converts the PDF to text and parses it into a CSV file</a>. But this one is different:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/live_oak.png" width="800"></p>
</figure>
</div>
<p>The <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221gLcHgzgEkJsJYe8q1FeBjR9vBy55C8gb%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">prompt to convert this 90-page image PDF</a> is like the first one: an example tailored to the first set of results and the unusual placement of the registered voters and ballots cast figures. Gemini repeated the earlier mistake of removing a blank column from the Registered Voters and Ballots Cast rows, but otherwise was spot on in its accuracy. Here’s the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__live_oak__precinct.csv">fixed CSV result</a>.</p>
</section>
<section id="cameron-county">
<h3 data-anchor-id="cameron-county">Cameron County</h3>
<p>One of the areas where LLMs, even Gemini, can struggle with is sustained processes. Converting a few or a few dozen pages is usually pretty simple work for high-performing models, but what about hundreds of pages? <a href="https://github.com/openelections/openelections-sources-tx/blob/master/2024/general/2024%20Cameron%20County%2C%20TX%20precinct-level%20results.pdf">Cameron County’s PDF</a>, all 11.7 MB of it, offers a good challenge, and not just owing to its size:</p>
<div>
<figure>
<p><img src="https://thescoop.org/archives/2025/06/09/how-openelections-uses-llms/cameron.png" width="800"></p>
</figure>
</div>
<p>Notice how the “Precinct 16” is slightly obscured by an actual punch-hole in this document, and the same is true at the bottom of the image with “Overvotes” and “Undervotes”. Both of those issues could trip up commercial OCR engines. Providing an example of the output, as in the Limestone example, should help fill those literal holes, along with further instructions to ignore the <code>VOTE %</code> column entirely. The first attempt at parsing the 653-page PDF eventually “worked” in that it produced a CSV file. But I had to urge Gemini to “continue” multiple times, and it appeared to need more attention starting about halfway through. Most important, the vote figures in the CSV file were close, but not always correct. Back to the drawing board.</p>
<p>The <a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%221-Wiq7tYnEC12-TOckMUja1EyUp_lJ_bQ%22%5D,%22action%22:%22open%22,%22userId%22:%22112158284796315028405%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing">process that generated an accurate CSV file</a> involved splitting the single PDF into multiple parts of about 100 pages each and feeding them one at a time to Gemini. That did mean copying and pasting the output, and one drawback of providing a lot of information in one session was that some of the offices didn’t get quoted properly in the CSV file (to be fair, this probably wouldn’t matter if I were using Gemini’s structured output feature). That meant a little bit of clean-up work, but again, the <a href="https://github.com/openelections/openelections-data-tx/blob/master/2024/counties/20241105__tx__general__cameron__precinct.csv">end result</a> is an accurate precinct results file in about an hour. From a 653-page image PDF, with no data entry.</p>
<p>Could other models do similar work? Probably so, especially for smaller PDFs. But there are couple of other things that make Gemini the first choice for this: its <a href="https://aistudio.google.com/">AI Studio</a> UI allows me to turn the temperature down to 0 (less creativity) and, for models where the “thinking mode” is optional, the ability to disable it if the task at hand is pretty straight-forward. In the six weeks since we started working on Texas precinct results, we’ve been able to convert them for more than half of the state’s 254 counties, including many image PDFs like the ones on display here. That pace simply wouldn’t be possible with data entry or traditional OCR software.</p>
<p>Speed isn’t the most important factor here, though: accuracy is, and using LLMs still means a system of checks to ensure that the results are what the originals say they are. One step in that is taken care of by a suite of tests that run every time a new or changed CSV gets pushed to one of our data repositories. Those tests look for some formatting issues, duplicate records and basic math inconsistencies. A second step - for now manual - is verifying that multiple totals derived from the precinct CSV match the numbers in an official cumulative report <a href="https://www.co.live-oak.tx.us/upload/page/1218/2024/Entered%20By%20Bec/official%20cumulative%20results.pdf">like this one from Live Oak County</a>. A better version of that could also involve using LLMs to produce both cumulative and precinct-level data, but that would raise the possibility that a model makes similar mistakes in different documents. If you have ideas, head over to <a href="https://github.com/openelections">our GitHub organization</a> and get involved.</p>


</section>

</main> <!-- /main -->

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Curved-Crease Sculpture (171 pts)]]></title>
            <link>https://erikdemaine.org/curved/</link>
            <guid>44318874</guid>
            <pubDate>Thu, 19 Jun 2025 14:13:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://erikdemaine.org/curved/">https://erikdemaine.org/curved/</a>, See on <a href="https://news.ycombinator.com/item?id=44318874">Hacker News</a></p>
Couldn't get https://erikdemaine.org/curved/: Error: getaddrinfo ENOTFOUND erikdemaine.org]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A DOS-like hobby OS written in Rust and x86 assembly (173 pts)]]></title>
            <link>https://github.com/krustowski/rou2exOS</link>
            <guid>44318588</guid>
            <pubDate>Thu, 19 Jun 2025 13:38:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/krustowski/rou2exOS">https://github.com/krustowski/rou2exOS</a>, See on <a href="https://news.ycombinator.com/item?id=44318588">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">rou2exOS Rusted Edition</h2><a id="user-content-rou2exos-rusted-edition" aria-label="Permalink: rou2exOS Rusted Edition" href="#rou2exos-rusted-edition"></a></p>
<p dir="auto">A second iteration of the RoureXOS operating system, rewritten in Rust.</p>
<ul dir="auto">
<li><a href="https://krusty.space/projects/rourexos/" rel="nofollow">Original RoureXOS (a blog post)</a></li>
<li><a href="https://blog.vxn.dev/rou2exos-rusted-edition" rel="nofollow">rou2exOS Rusted Edition (a blog post)</a></li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/108d5a7e9f0a67d395b8594fd4b20592fcfd7b3104138733c2401358e5941242/68747470733a2f2f626c6f672e76786e2e6465762f696d616765732f706f7374732f726f753265786f732f636f7665722e77656270"><img src="https://camo.githubusercontent.com/108d5a7e9f0a67d395b8594fd4b20592fcfd7b3104138733c2401358e5941242/68747470733a2f2f626c6f672e76786e2e6465762f696d616765732f706f7374732f726f753265786f732f636f7665722e77656270" alt="rou2exOS startup" data-canonical-src="https://blog.vxn.dev/images/posts/rou2exos/cover.webp"></a></p>
<p dir="auto">To run the OS, you can use the attached ISO image from any Release, and run it in QEMU emulator. The system was also tested on x86_64 baremetal (booted from the USB flash disk).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to build and run</h2><a id="user-content-how-to-build-and-run" aria-label="Permalink: How to build and run" href="#how-to-build-and-run"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# install Rust and its dependencies
make init

# make sure you have `xorriso`, `net-tools` and `grub2-tools` (or just grub-tools) installed (Linux)
dnf install xorriso net-tools grub2-tools qemu qemu-common qemu-system-x86

# compile the kernel and stage2 bootloader, link it into an ELF binary and bake into an ISO
# image with GRUB stage1 bootloader
make build

# run the QEMU emulation with ISO image (respectively with additional floppy image attached as well)
make run_iso
make run_iso_floppy

# (alternative) run the kernel exclusively only (needs the `bootloader` dependency in Cargo.toml to be added)
cargo bootimage
make run"><pre><span><span>#</span> install Rust and its dependencies</span>
make init

<span><span>#</span> make sure you have `xorriso`, `net-tools` and `grub2-tools` (or just grub-tools) installed (Linux)</span>
dnf install xorriso net-tools grub2-tools qemu qemu-common qemu-system-x86

<span><span>#</span> compile the kernel and stage2 bootloader, link it into an ELF binary and bake into an ISO</span>
<span><span>#</span> image with GRUB stage1 bootloader</span>
make build

<span><span>#</span> run the QEMU emulation with ISO image (respectively with additional floppy image attached as well)</span>
make run_iso
make run_iso_floppy

<span><span>#</span> (alternative) run the kernel exclusively only (needs the `bootloader` dependency in Cargo.toml to be added)</span>
cargo bootimage
make run</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to test ICMP/SLIP</h2><a id="user-content-how-to-test-icmpslip" aria-label="Permalink: How to test ICMP/SLIP" href="#how-to-test-icmpslip"></a></p>
<p dir="auto">Run the kernel in QEMU to get the <code>pty</code> number in stdout:</p>
<div data-snippet-clipboard-copy-content="make run

char device redirected to /dev/pts/3 (label serial0)"><pre><code>make run

char device redirected to /dev/pts/3 (label serial0)
</code></pre></div>
<p dir="auto">Listen for SLIP packets and create a <code>sl0</code> interface:</p>
<div data-snippet-clipboard-copy-content="sudo slattach -L -p slip -s 115200 /dev/pts/3
sudo ifconfig sl0 192.168.3.1 pointopoint 192.168.3.2 up"><pre><code>sudo slattach -L -p slip -s 115200 /dev/pts/3
sudo ifconfig sl0 192.168.3.1 pointopoint 192.168.3.2 up
</code></pre></div>
<p dir="auto">Catch packets using <code>tcpdump</code>:</p>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft wants you to buy a new computer. Make your current one secure again? (245 pts)]]></title>
            <link>https://endof10.org/</link>
            <guid>44318420</guid>
            <pubDate>Thu, 19 Jun 2025 13:14:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://endof10.org/">https://endof10.org/</a>, See on <a href="https://news.ycombinator.com/item?id=44318420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><div><p>Support for Windows 10 ends on October 14, 2025.</p><p>Microsoft wants you to buy a new computer.</p><p>But what if you could make your current one fast and secure again?</p></div><p><img src="https://endof10.org/laptop.svg" alt="Use your old computer but with fresh new software."></p></div><p>If you bought your computer after 2010, there's most likely no
reason to throw it out. By just installing an up-to-date Linux
operating system you can keep using it for years to come.</p><p>Installing an operating system may sound difficult, but you don't have to
do it alone. With any luck, there are people in your area
ready to help!</p><p><a href="https://endof10.org/places">Find someone to help&nbsp;you
&nbsp;→</a></p><p><a href="https://endof10.org/install/">Install Linux yourself →</a></p><h2 id="5-reasons-to-upgrade-your-old-computer-to-linux"><strong>5 Reasons</strong> to upgrade your old computer to Linux</h2><ol><li><strong>No New Hardware, No Licensing Costs</strong><br>A new laptop costs a lot of money, but several Linux operating systems
are available for free. Software updates are also free, forever. You can
of course show your support with donations!</li><li><strong>Enhanced Privacy</strong><br>Windows comes with lots of ads and spyware. This slows down your computer,
lets companies spy on you, and increases your energy bills.</li><li><strong>Good For The Planet</strong><br>Production of a computer accounts for 75+% of carbon emissions over its lifecycle.
Keeping a functioning device longer is a hugely effective way to reduce emissions.
With a Linux operating system you can use your device longer.</li><li><strong>Community &amp; Professional Support</strong><br>There are local repair cafes and independent, professional services and
computer shops available for providing you help. You can find support in online
forums, too.</li><li><strong>Better User Control</strong><br>Linux grants you the four freedoms of software. You are free to use, study, share, and
improve the program, for as long as you wish. You are in control of your device.</li></ol><h2 id="supporters">Supporters</h2><p>These organizations have joined us in support of the campaign.</p><h2 id="convinced">Convinced?</h2><p>Then find your closest repair cafe or independent computer shop
and enjoy your brand-new, old computer!</p><p><a href="https://endof10.org/places">Repair your old computer
&nbsp;→</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What would a Kubernetes 2.0 look like (208 pts)]]></title>
            <link>https://matduggan.com/what-would-a-kubernetes-2-0-look-like/</link>
            <guid>44317825</guid>
            <pubDate>Thu, 19 Jun 2025 12:00:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/what-would-a-kubernetes-2-0-look-like/">https://matduggan.com/what-would-a-kubernetes-2-0-look-like/</a>, See on <a href="https://news.ycombinator.com/item?id=44317825">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
        <main id="main-content" role="main">
            
<article>
    

    
    <div>
            <p>Around 2012-2013 I started to hear a <em>lot</em> in the sysadmin community about a technology called "Borg". It was (apparently) some sort of Linux container system inside of Google that ran all of their stuff. The terminology was a bit baffling, with something called a "Borglet" inside of clusters with "cells" but the basics started to leak. There was a concept of "services" and a concept of "jobs", where applications could use services to respond to user requests and then jobs to complete batch jobs that ran for much longer periods of time. </p><p>Then on June 7th, 2014, we got our first commit of Kubernetes. The Greek word for 'helmsman' that absolutely no one could pronounce correctly for the first three years. (Is it koo-ber-NET-ees? koo-ber-NEET-ees? Just give up and call it k8s like the rest of us.) </p><p>Microsoft, RedHat, IBM, Docker join the Kubernetes community pretty quickly after this, which raised Kubernetes from an interesting Google thing to "maybe this is a real product?" On July 21st 2015 we got the v1.0 release as well as the creation of the CNCF. </p><p>In the ten years since that initial commit, Kubernetes has become a large part of my professional life. I use it at home, at work, on side projects—anywhere it makes sense. It's a tool with a steep learning curve, but it's also a massive force multiplier. We no longer "manage infrastructure" at the server level; everything is declarative, scalable, recoverable and (if you’re lucky) self-healing.</p><p>But the journey hasn't been without problems. Some common trends have emerged, where mistakes or misconfiguration arise from where Kubernetes isn't opinionated enough. Even ten years on, we're still seeing a lot of churn inside of ecosystem and people stepping on well-documented landmines. So, knowing what we know now, what could we do differently to make this great tool even more applicable to more people and problems? </p><h3 id="what-did-k8s-get-right">What did k8s get right?</h3><p>Let's start with the positive stuff. Why are we still talking about this platform now? </p><p><strong>Containers at scale</strong></p><p>Containers as a tool for software development make perfect sense. Ditch the confusion of individual laptop configuration and have one standard, disposable concept that works across the entire stack. While tools like Docker Compose allowed for some deployments of containers, they were clunky and still required you as the admin to manage a lot of the steps. I set up a Compose stack with a deployment script that would remove the instance from the load balancer, pull the new containers, make sure they started and then re-added it to the LB, as did lots of folks. </p><p>K8s allowed for this concept to scale out, meaning it was possible to take a container from your laptop and deploy an identical container across thousands of servers. This flexibility allowed organizations to revisit their entire design strategy, dropping monoliths and adopting more flexible (and often more complicated) micro-service designs. </p><p><strong>Low-Maintenance</strong></p><p>If you think of the history of Operations as a sort of "naming timeline from pets to cattle", we started with what I affectionately call the "Simpsons" era. Servers were bare metal boxes set up by teams, they often had one-off names that became slang inside of teams and everything was a snowflake. The longer a server ran, the more cruft it picked up until it became a scary operation to even reboot them, much less attempt to rebuild them. I call it the "Simpsons" era because among the jobs I was working at the time, naming them after Simpsons characters was surprisingly common. Nothing fixed itself, everything was a manual operation. </p><p>Then we transition into the "01 Era". Tools like Puppet and Ansible have become common place, servers are more disposable and you start to see things like bastion hosts and other access control systems become the norm. Servers aren't all facing the internet, they're behind a load balancer and we've dropped the cute names for stuff like "app01" or "vpn02". Organizations designed it so they could lose some of their servers some of the time. However failures still weren't self-healing, someone still had to SSH in to see what broke, write up a fix in the tooling and then deploy it across the entire fleet. OS upgrades were still complicated affairs. </p><p>We're now in the "UUID Era". Servers exist to run containers, they are entirely disposable concepts. Nobody cares about how long a particular version of the OS is supported for, you just bake a new AMI and replace the entire machine. K8s wasn't the only technology enabling this, but it was the one that accelerated it. Now the idea of a bastion server with SSH keys that I go to the underlying server to fix problems is seen as more of a "break-glass" solution. Almost all solutions are "destroy that Node, let k8s reorganize things as needed, make a new Node". </p><p>A lot of the Linux skills that were critical to my career are largely nice to have now, not need to have. You can be happy or sad about that, I certainly switch between the two emotions on a regular basis, but it's just the truth. </p><p><strong>Running Jobs </strong></p><p>The k8s jobs system isn't perfect, but it's so much better than the "snowflake cron01 box" that was an extremely common sight at jobs for years. Running on a cron schedule or running from a message queue, it was now possible to reliably put jobs into a queue, have them get run, have them restart if they didn't work and then move on with your life. </p><p>Not only does this free up humans from a time-consuming and boring task, but it's also simply a more efficient use of resources. You are still spinning up a pod for every item in the queue, but your teams have a lot of flexibility inside of the "pod" concept for what they need to run and how they want to run it. This has really been a quality of life improvement for a lot of people, myself included, who just need to be able to easily background tasks and not think about them again. </p><p><strong>Service Discoverability and Load Balancing</strong></p><p>Hard-coded IP addresses that lived inside of applications as the template for where requests should be routed has been a curse following me around for years. If you were lucky, these dependencies weren't based on IP address but were actually DNS entries and you could change the thing behind the DNS entry without coordinating a deployment of a million applications. </p><p>K8s allowed for simple DNS names to call other services. It removed an entire category of errors and hassle and simplified the entire thing down. With the Service API you had a stable, long lived IP and hostname that you could just point things towards and not think about any of the underlying concepts. You even have concepts like ExternalName that allow you to treat external services like they're in the cluster. </p><h3 id="ditch-yaml-for-hcl">Ditch YAML for HCL</h3><p>YAML was appealing because it wasn't JSON or XML, which is like saying your new car is great because it's neither a horse nor a unicycle. It demos nicer for k8s, looks nicer sitting in a repo and has the <em>illusion</em> of being a simple file format. In reality. YAML is just too much for what we're trying to do with k8s and it's not a safe enough format. Indentation is error-prone, the files don't scale great (you really don't want a super long YAML file), debugging can be annoying. YAML has <em>so many</em> subtle behaviors outlined in its spec.</p><p>I still remember not believing what I was seeing the first time I saw the Norway Problem. For those lucky enough to not deal with it, the Norway Problem in YAML is when 'NO' gets interpreted as false. Imagine explaining to your Norwegian colleagues that their entire country evaluates to false in your configuration files. Add in accidental numbers from lack of quotes, the list goes on and on. There are much better posts on why YAML is crazy than I'm capable of writing: <a href="https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell">https://ruudvanasseldonk.com/2023/01/11/the-yaml-document-from-hell</a></p><p><strong>Why HCL?</strong></p><p>HCL is already the format for Terraform, so at least we'd only have to hate one configuration language instead of two. It's strongly typed with explicit types. There's already good validation mechanisms. It is specifically designed to do the job that we are asking YAML to do and it's not much harder to read. It has built-in functions people are already using that would allow us to remove some of the third-party tooling from the YAML workflow. </p><p>I would wager 30% of Kubernetes clusters today are <em>already</em> being managed with HCL via Terraform. We don't need the Terraform part to get a lot of the benefits of a superior configuration language. </p><p>The only downsides are that HCL is slightly more verbose than YAML, and its Mozilla Public License 2.0 (MPL-2.0) would require careful legal review for integration into an Apache 2.0 project like Kubernetes. However, for the quality-of-life improvements it offers, these are hurdles worth clearing.</p><p><strong>Why HCL is better</strong></p><p>Let's take a simple YAML file. </p><pre><code># YAML doesn't enforce types
replicas: "3"  # String instead of integer
resources:
  limits:
    memory: 512  # Missing unit suffix
  requests:
    cpu: 0.5m    # Typo in CPU unit (should be 500m)</code></pre><p>Even in the most basic example, there are footguns everywhere. HCL and the type system would catch all of these problems. </p><pre><code>replicas = 3  # Explicitly an integer

resources {
  limits {
    memory = "512Mi"  # String for memory values
  }
  requests {
    cpu = 0.5  # Number for CPU values
  }
}</code></pre><p>Take a YAML file like this that you probably have 6000 in your k8s repo. Now look at HCL without needing external tooling. </p><pre><code># Need external tools or templating for dynamic values
apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
data:
  # Can't easily generate or transform values
  DATABASE_URL: "postgres://user:password@db:5432/mydb"
  API_KEY: "static-key-value"
  TIMESTAMP: "2023-06-18T00:00:00Z"  # Hard-coded timestamp</code></pre><pre><code>resource "kubernetes_config_map" "app_config" {
  metadata {
    name = "app-config"
  }
  
  data = {
    DATABASE_URL = "postgres://${var.db_user}:${var.db_password}@${var.db_host}:${var.db_port}/${var.db_name}"
    API_KEY      = var.api_key != "" ? var.api_key : random_string.api_key.result
    TIMESTAMP    = timestamp()
  }
}

resource "random_string" "api_key" {
  length  = 32
  special = false
}</code></pre><p>Here's all the pros you get with this move. </p><ol><li><strong>Type Safety</strong>: Preventing type-related errors before deployment</li><li><strong>Variables and References</strong>: Reducing duplication and improving maintainability</li><li><strong>Functions and Expressions</strong>: Enabling dynamic configuration generation</li><li><strong>Conditional Logic</strong>: Supporting environment-specific configurations</li><li><strong>Loops and Iteration</strong>: Simplifying repetitive configurations</li><li><strong>Better Comments</strong>: Improving documentation and readability</li><li><strong>Error Handling</strong>: Making errors easier to identify and fix</li><li><strong>Modularity</strong>: Enabling reuse of configuration components</li><li><strong>Validation</strong>: Preventing invalid configurations</li><li><strong>Data Transformations</strong>: Supporting complex data manipulations<br></li></ol><h3 id="allow-etcd-swap-out">Allow etcd swap-out</h3><p>I know, I'm the 10,000 person to write this. Etcd has done a fine job, but it's a little crazy that it is the only tool for the job. For smaller clusters or smaller hardware configuration, it's a large use of resources in a cluster type where you will never hit the node count where it pays off. It's also a strange relationship between k8s and etcd now, where k8s is basically the only etcd customer left. </p><p>What I'm suggesting is taking the work of <a href="https://github.com/k3s-io/kine" rel="noreferrer">kine</a> and making it official. It makes sense for the long-term health of the project to have the ability to plug in more backends, adding this abstraction means it (should) be easier to swap in new/different backends in the future and it also allows for more specific tuning depending on the hardware I'm putting out there. </p><p>What I suspect this would end up looking like is much like this: <a href="https://github.com/canonical/k8s-dqlite">https://github.com/canonical/k8s-dqlite</a>. Distributed SQlite in-memory with Raft consensus and almost zero upgrade work required that would allow cluster operators to have more flexibility with the persistence layer of their k8s installations. If you have a conventional server setup in a datacenter and etcd resource usage is not a problem, great! But this allows for lower-end k8s to be a nicer experience and (hopefully) reduces dependence on the etcd project. </p><h3 id="beyond-helm-a-native-package-manager">Beyond Helm: A Native Package Manager</h3><p>Helm is a perfect example of a temporary hack that has grown to be a permanent dependency. I'm grateful to the maintainers of Helm for all of their hard work, growing what was originally a hackathon project into the de-facto way to install software into k8s clusters. It has done as good a job as something could in fulfilling that role without having a deeper integration into k8s. </p><p>All that said, Helm is a nightmare to use. The Go templates are tricky to debug, often containing complex logic that results in really confusing error scenarios. The error messages you get from those scenarios are often gibberish. Helm isn't a very good package system because it fails at some of the basic tasks you need a package system to do, which are transitive dependencies and resolving conflicts between dependencies. </p><p><strong>What do I mean?</strong></p><p>Tell me what this conditional logic is trying to do:</p><pre><code># A real-world example of complex conditional logic in Helm
{{- if or (and .Values.rbac.create .Values.serviceAccount.create) (and .Values.rbac.create (not .Values.serviceAccount.create) .Values.serviceAccount.name) }}
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: {{ template "myapp.fullname" . }}
  labels:
    {{- include "myapp.labels" . | nindent 4 }}
{{- end }}</code></pre><p>Or if I provide multiple values files to my chart, which one wins:</p><pre><code>helm install myapp ./mychart -f values-dev.yaml -f values-override.yaml --set service.type=NodePort</code></pre><p>Ok, what if I want to manage my application and all the application dependencies with a Helm chart. This makes sense, I have an application that itself has dependencies on other stuff so I want to put them all together. So I define my sub-charts or umbrella charts inside of my Chart.yaml. <br></p><pre><code>dependencies:
- name: nginx
  version: "1.2.3"
  repository: "&lt;https://example.com/charts&gt;"
- name: memcached
  version: "1.2.3"
  repository: "&lt;https://another.example.com/charts&gt;"
</code></pre><p>But assuming I have multiple applications, it's entirely possible that I have 2 services both with a dependency on nginx or whatever like this:<br></p><figure><img src="https://matduggan.com/content/images/2025/06/image-2.png" alt="" loading="lazy" width="367" height="176"></figure><p>Helm doesn't handle this situation gracefully because template names are global with their templates loaded alphabetically. Basically you need to:</p><ul><li>Don't declare a dependency on the same chart more than once (hard to do for a lot of microservices)</li><li>If you do have the same chart declared multiple times, has to use the exact same version</li></ul><p>The list of issues goes on and on. </p><ul><li>Cross-Namespace installation stinks</li><li>Chart verification process is a pain and nobody uses it</li></ul><p>Let's just go to the front page of artifacthub:</p><figure><img src="https://matduggan.com/content/images/2025/06/image-3.png" alt="" loading="lazy" width="978" height="794" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-3.png 600w, https://matduggan.com/content/images/2025/06/image-3.png 978w" sizes="(min-width: 720px) 720px"></figure><p>I'll grab elasticsearch cause that seems important. </p><figure><img src="https://matduggan.com/content/images/2025/06/image-4.png" alt="" loading="lazy" width="504" height="296"></figure><figure><img src="https://matduggan.com/content/images/2025/06/image-5.png" alt="" loading="lazy" width="522" height="404"></figure><p>Seems <em>pretty bad</em> for the Official Elastic helm chart. Certainly <code>ingress-nginx</code> will be right, it's an absolute critical dependency for the entire industry. </p><figure><img src="https://matduggan.com/content/images/2025/06/image-6.png" alt="" loading="lazy" width="751" height="184" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-6.png 600w, https://matduggan.com/content/images/2025/06/image-6.png 751w" sizes="(min-width: 720px) 720px"></figure><p>Nope. Also how is the maintainer of the chart "Kubernetes" and it's <em>still</em> not marked as a <code>verified publisher</code>. Like Christ how much more verified does it get.</p><ul><li>No metadata in chart searching. You can only search by name and description, not by features, capabilities, or other metadata.</li></ul><figure><img src="https://matduggan.com/content/images/2025/06/image-7.png" alt="" loading="lazy" width="1138" height="929" srcset="https://matduggan.com/content/images/size/w600/2025/06/image-7.png 600w, https://matduggan.com/content/images/size/w1000/2025/06/image-7.png 1000w, https://matduggan.com/content/images/2025/06/image-7.png 1138w" sizes="(min-width: 720px) 720px"></figure><ul><li>Helm doesn't strictly enforce semantic versioning</li></ul><pre><code># Chart.yaml with non-semantic version
apiVersion: v2
name: myapp
version: "v1.2-alpha" </code></pre><ul><li>If you uninstall and reinstall a chart with CRDs, it might delete resources created by those CRDs. This one has screwed me <em>multiple times</em> and is crazy unsafe. </li></ul><p>I could keep writing for another 5000 words and still wouldn't have outlined all the problems. There isn't a way to make Helm good enough for the task of "package manager for all the critical infrastructure on the planet". </p><h4 id="what-would-a-k8s-package-system-look-like">What would a k8s package system look like?</h4><p>Let's call our hypothetical package system KubePkg, because if there's one thing the Kubernetes ecosystem needs, it's another abbreviated name with a 'K' in it. We would try to copy as much of the existing work inside the Linux ecosystem while taking advantage of the CRD power of k8s. My idea looks something like this:</p><figure><img src="https://matduggan.com/content/images/2025/06/image-8.png" alt="" loading="lazy" width="600" height="356" srcset="https://matduggan.com/content/images/2025/06/image-8.png 600w"></figure><p>The packages are bundles like a Linux package:<br></p><figure><img src="https://matduggan.com/content/images/2025/06/image-9.png" alt="" loading="lazy" width="528" height="196"></figure><p>There's a definition file that accounts for as many of the real scenarios that you actually encounter when installing a thing. </p><pre><code>apiVersion: kubepkg.io/v1
kind: Package
metadata:
  name: postgresql
  version: 14.5.2
spec:
  maintainer:
    name: "PostgreSQL Team"
    email: "<a href="https://matduggan.com/cdn-cgi/l/email-protection" data-cfemail="9df0fcf4f3e9fcf4f3f8efeeddedf2eee9faeff8eeecf1b3f8e5fcf0edf1f8b3fef2f0">[email&nbsp;protected]</a>"
  description: "PostgreSQL database server"
  website: "https://postgresql.org"
  license: "PostgreSQL"
  
  # Dependencies with semantic versioning
  dependencies:
    - name: storage-provisioner
      versionConstraint: "&gt;=1.0.0"
    - name: metrics-collector
      versionConstraint: "^2.0.0"
      optional: true
  
  # Security context and requirements
  security:
    requiredCapabilities: ["CHOWN", "SETGID", "SETUID"]
    securityContextConstraints:
      runAsUser: 999
      fsGroup: 999
    networkPolicies:
      - ports:
        - port: 5432
          protocol: TCP
    
  # Resources to be created (embedded or referenced)
  resources:
    - apiVersion: v1
      kind: Service
      metadata:
        name: postgresql
      spec:
        ports:
        - port: 5432
    - apiVersion: apps/v1
      kind: StatefulSet
      metadata:
        name: postgresql
      spec:
        # StatefulSet definition
  
  # Configuration schema using JSON Schema
  configurationSchema:
    type: object
    properties:
      replicas:
        type: integer
        minimum: 1
        default: 1
      persistence:
        type: object
        properties:
          size:
            type: string
            pattern: "^[0-9]+[GMK]i$"
            default: "10Gi"
  
  # Lifecycle hooks with proper sequencing
  hooks:
    preInstall:
      - name: database-prerequisites
        job:
          spec:
            template:
              spec:
                containers:
                - name: init
                  image: postgres:14.5
    postInstall:
      - name: database-init
        job:
          spec:
            # Job definition
    preUpgrade:
      - name: backup
        job:
          spec:
            # Backup job definition
    postUpgrade:
      - name: verify
        job:
          spec:
            # Verification job definition
    preRemove:
      - name: final-backup
        job:
          spec:
            # Final backup job definition
  
  # State management for stateful applications
  stateManagement:
    backupStrategy:
      type: "snapshot"  # or "dump"
      schedule: "0 2 * * *"  # Daily at 2 AM
      retention:
        count: 7
    recoveryStrategy:
      type: "pointInTime"
      verificationJob:
        spec:
          # Job to verify recovery success
    dataLocations:
      - path: "/var/lib/postgresql/data"
        volumeMount: "data"
    upgradeStrategies:
      - fromVersion: "*"
        toVersion: "*"
        strategy: "backup-restore"
      - fromVersion: "14.*.*"
        toVersion: "14.*.*"
        strategy: "in-place"</code></pre><p>There's a real signing process that would be required and allow you more control over the process. <br></p><pre><code>apiVersion: kubepkg.io/v1
kind: Repository
metadata:
  name: official-repo
spec:
  url: "https://repo.kubepkg.io/official"
  type: "OCI"  # or "HTTP"
  
  # Verification settings
  verification:
    publicKeys:
      - name: "KubePkg Official"
        keyData: |
          -----BEGIN PUBLIC KEY-----
          MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAvF4+...
          -----END PUBLIC KEY-----
    trustPolicy:
      type: "AllowList"  # or "KeyRing"
      allowedSigners:
        - "KubePkg Official"
        - "Trusted Partner"
    verificationLevel: "Strict"  # or "Warn", "None"</code></pre>
<p>Like how great would it be to have something where I could automatically update packages without needing to do anything on my side. </p><pre><code>apiVersion: kubepkg.io/v1
kind: Installation
metadata:
  name: postgresql-main
  namespace: database
spec:
  packageRef:
    name: postgresql
    version: "14.5.2"
  
  # Configuration values (validated against schema)
  configuration:
    replicas: 3
    persistence:
      size: "100Gi"
    resources:
      limits:
        memory: "4Gi"
        cpu: "2"
  
  # Update policy
  updatePolicy:
    automatic: false
    allowedVersions: "14.x.x"
    schedule: "0 2 * * 0"  # Weekly on Sunday at 2am
    approvalRequired: true
  
  # State management reference
  stateRef:
    name: postgresql-main-state
    
  # Service account to use
  serviceAccountName: postgresql-installer</code></pre><p>What k8s needs is a system that meets the following requirements:</p><ol><li><strong>True Kubernetes Native</strong>: Everything is a Kubernetes resource with proper status and events</li><li><strong>First-Class State Management</strong>: Built-in support for stateful applications</li><li><strong>Enhanced Security</strong>: Robust signing, verification, and security scanning</li><li><strong>Declarative Configuration</strong>: No templates, just structured configuration with schemas</li><li><strong>Lifecycle Management</strong>: Comprehensive lifecycle hooks and upgrade strategies</li><li><strong>Dependency Resolution</strong>: Linux-like dependency management with semantic versioning</li><li><strong>Audit Trail</strong>: Complete history of changes with who, what, and when, not what Helm currently provides. </li><li><strong>Policy Enforcement</strong>: Support for organizational policies and compliance. </li><li><strong>Simplified User Experience</strong>: Familiar Linux-like package management commands. It seems wild that we're trying to go a different direction from the package systems that have worked for decades. </li></ol><h3 id="ipv6-by-default">IPv6 By Default</h3><p>Try to imagine, across the entire globe, how much time and energy has been invested in trying to solve any one of the following three problems. </p><ol><li>I need this pod in this cluster to talk to that pod in that cluster. </li><li>There is a problem happening somewhere in the NAT traversal process and I need to solve it</li><li>I have run out of IP addresses with my cluster because I didn't account for how many you use. Remember: A company starting with a /20 subnet (4,096 addresses), deploys 40 nodes with 30 pods each, and suddenly realizes they're approaching their IP limit. Not that many nodes!</li></ol><p>I am not suggesting the entire internet switches over to IPv6 and right now k8s happily supports IPv6-only if you want and a dualstack approach. But I'm saying now is the time to flip the default and just go IPv6. You eliminate a huge collection of problems all at once. </p><ul><li>Flatter, less complicated network topology inside of the cluster. </li><li>The distinction between multiple clusters becomes a thing organizations can choose to ignore if they want if they want to get public IPs.</li><li>Easier to understand exactly the flow of traffic inside of your stack. </li><li>Built-in IPSec</li></ul><p>It has nothing to do with driving IPv6 adoption across the entire globe and just an acknowledgement that we no longer live in a world where you have to accept the weird limitations of IPv4 in a universe where you may need 10,000 IPs suddenly with very little warning. </p><p>The benefits for organizations with public IPv6 addresses is pretty obvious, but there's enough value there for cloud providers and users that even the corporate overlords might get behind it. AWS never needs to try and scrounge up more private IPv4 space inside of a VPC. That's gotta be worth something. </p><h3 id="conclusion">Conclusion </h3><p>The common rebuttal to these ideas is, "Kubernetes is an open platform, so the community can build these solutions." While true, this argument misses a crucial point: <strong>defaults are the most powerful force in technology.</strong> The "happy path" defined by the core project dictates how 90% of users will interact with it. If the system defaults to expecting signed packages and provides a robust, native way to manage them, that is what the ecosystem will adopt.</p><p>This is an ambitious list, I know. But if we're going to dream, let's dream big. After all, we're the industry that thought naming a technology 'Kubernetes' would catch on, and somehow it did!</p><p>We see this all the time in other areas like mobile developer and web development, where platforms assess their situation and make <em>radical</em> jumps forward. Not all of these are necessarily projects that the maintainers or companies <em>would</em> take on but I think they're all ideas that <em>someone</em> should at least revisit and think "is it worth doing now that we're this nontrivial percentage of all datacenter operations on the planet"? </p><p>Questions/feedback/got something wrong? Find me here: <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p>
        </div>



</article>

        </main>
        
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Guess I'm a Rationalist Now (273 pts)]]></title>
            <link>https://scottaaronson.blog/?p=8908</link>
            <guid>44317180</guid>
            <pubDate>Thu, 19 Jun 2025 10:22:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://scottaaronson.blog/?p=8908">https://scottaaronson.blog/?p=8908</a>, See on <a href="https://news.ycombinator.com/item?id=44317180">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-8908">
				
<p>A week ago I attended <a href="https://less.online/">LessOnline</a>, a rationalist blogging conference featuring many people I’ve known for years—Scott Alexander, Eliezer Yudkowsky, Zvi Mowshowitz, Sarah Constantin, Carl Feynman—as well as people I’ve known only online and was delighted to meet in person, like Joe Carlsmith and Jacob Falkovich and Daniel Reeves.  The conference was at <a href="https://www.lighthaven.space/">Lighthaven</a>, a bewildering maze of passageways, meeting-rooms, sleeping quarters, gardens, and vines off Telegraph Avenue in Berkeley, which has recently emerged as the nerd Shangri-La, or Galt’s Gulch, or Shire, or whatever.  I did two events at this year’s LessOnline: a conversation with Nate Soares about the <a href="https://www.lesswrong.com/w/orthogonality-thesis">Orthogonality Thesis</a>, and an ask-me-anything session about quantum computing and theoretical computer science (no new ground there for regular consumers of my content).</p>



<p>What I’ll remember most from LessOnline is not the sessions, mine or others’, but the unending conversation among hundreds of people all over the grounds, which took place in parallel with the sessions and before and after them, from morning till night (and through the night, apparently, though I’ve gotten too old for that).  It felt like a single conversational archipelago, the largest in which I’ve ever taken part, and the conference’s real point.  (Attendees were exhorted, in the opening session, to skip as many sessions as possible in favor of intense small-group conversations—not only because it was better but also because the session rooms were too small.)</p>



<p>Within the conversational blob, just making my way from one building to another could take hours.  My mean free path was approximately five feet, before someone would notice my nametag and stop me with a question.  Here was my favorite opener:</p>



<p>“You’re Scott Aaronson?!  The quantum physicist who’s always getting into arguments on the Internet, and who’s essentially always right, but who sustains an unreasonable amount of psychic damage in the process?”</p>



<p>“Yes,” I replied, not bothering to correct the “physicist” part.</p>



<p>One night, I walked up to Scott Alexander, who sitting on the ground, with his large bald head and a blanket he was using as a robe, resembled a monk.  “Are you enjoying yourself?” he asked.</p>



<p>I replied, “you know, after all these years of being coy about it, I think I’m finally ready to become a Rationalist.  Is there, like, an initiation ritual or something?”</p>



<p>Scott said, “Oh, you were already initiated a decade ago; you just didn’t realize it at the time.”  Then he corrected himself: “two decades ago.”</p>



<p>The first thing I did, after coming out as a Rationalist, was to get into a heated argument with Other Scott A., Joe  Carlsmith, and other fellow-Rationalists about the ideas I set out twelve years ago in my <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">Ghost in the Quantum Turing Machine</a> essay.  Briefly, my argument was that the irreversibility and ephemerality of biological life, which contrasts with the copyability, rewindability, etc. of programs running on digital computers, and which can ultimately be traced back to microscopic details of the universe’s initial state, subject to the No-Cloning Theorem of quantum mechanics, which then get chaotically amplified during brain activity … might be a clue to a deeper layer of the world, one that we understand about as well as the ancient Greeks understood Newtonian physics, but which is the layer where mysteries like free will and consciousness will ultimately need to be addressed.</p>



<p>I got into this argument partly because it came up, but partly also because this seemed like the biggest conflict between my beliefs and the consensus of my fellow Rationalists.  Maybe part of me wanted to demonstrate that my intellectual independence remained intact—sort of like a newspaper that gets bought out by a tycoon, and then immediately runs an investigation into the tycoon’s corruption, as well as his diaper fetish, just to prove it can.</p>



<p>The funny thing, though, is that all my beliefs are the same as they were before.  I’m still a computer scientist, an academic, a straight-ticket Democratic voter, a liberal Zionist, a Jew, etc. (all identities, incidentally, well-enough represented at LessOnline that I don’t even think I was the unique attendee in the intersection of them all).</p>



<p>Given how much I resonate with what the Rationalists are trying to do, why did it take me so long to identify as one?</p>



<p>Firstly, while 15 years ago I shared the Rationalists’ interests, sensibility, and outlook, and their stances on most issues, I also found them bizarrely, inexplicably obsessed with the question of whether AI would soon become superhumanly powerful and change the basic conditions of life on earth, and with how to make the AI transition go well.  Why <em>that</em>, as opposed to all the other sci-fi scenarios one could worry about, not to mention all the nearer-term risks to humanity?</p>



<p>Suffice it to say that empirical developments have since caused me to withdraw my objection.  Sometimes weird people are weird merely because they see the future sooner than others.  Indeed, it seems to me that the biggest thing the Rationalists got wrong about AI was to <em>underestimate</em> how soon the revolution would happen, and to overestimate how many new ideas would be needed for it (mostly, as we now know, it just took lots more compute and training data).  Now that I, too, spend some of my time working on AI alignment, I was able to use LessOnline in part for research meetings with colleagues.</p>



<p>A second reason I didn’t identify with the Rationalists was cultural: they were, and are, centrally a bunch of twentysomethings who “work” at an ever-changing list of Berkeley- and San-Francisco-based “orgs” of their own invention, and who live in group houses where they explore their exotic sexualities, gender identities, and fetishes, sometimes with the aid of psychedelics.  I, by contrast, am a straight, monogamous, middle-aged tenured professor, married to another such professor and raising two kids who go to normal schools.  Hanging out with the Rationalists always makes me feel older and younger at the same time.</p>



<p>So what changed?  For one thing, with the march of time, a significant fraction of Rationalists now have marriages, children, or both—indeed, a highlight of LessOnline was the many adorable toddlers running around the Lighthaven campus.  Rationalists are successfully reproducing!  Some because of explicit pronatalist ideology, or because they were persuaded by Bryan Caplan’s arguments in <em><a href="https://www.amazon.com/Selfish-Reasons-Have-More-Kids/dp/0465028616">Selfish Reasons to Have More Kids</a></em>.  But others simply because of the same impulses that led their ancestors to do the same for eons.  And perhaps because, like the Mormons or Amish or Orthodox Jews, but unlike typical secular urbanites, the Rationalists <em>believe </em>in something.  For all their fears around AI, they don’t <em>act</em> doomy, but buzz with ideas about how to build a better world for the next generation.</p>



<p>At a LessOnline parenting session, hosted by Julia Wise, I was surrounded by parents who worry about the same things I do: how do we raise our kids to be independent and agentic yet socialized and reasonably well-behaved, technologically savvy yet not droolingly addicted to iPad games?  What schooling options will let them accelerate in math, save them from the crushing monotony that we experienced?  How much of our own lives should we sacrifice on the altar of our kids’ “enrichment,” versus trusting Judith Rich Harris that such efforts quickly hit a point of diminishing returns?</p>



<p>A third reason I didn’t identify with the Rationalists was, frankly, that they gave off some (not all) of the vibes of a cult, with Eliezer as guru.  Eliezer writes in parables and koans.  He teaches that the fate of life on earth hangs in the balance, that the select few who understand the stakes have the terrible burden of steering the future.  Taking what Rationalists call the “outside view,” <em>how good is the track record for this sort of thing?</em></p>



<p>OK, but what did I actually see at Lighthaven?  I saw something that seemed to resemble a cult only insofar as the Beatniks, the Bloomsbury Group, the early Royal Society, or any other community that believed in something did.  When Eliezer himself—the bearded, cap-wearing Moses who led the nerds from bondage to their Promised Land in Berkeley—showed up, he was argued with like anyone else.  Eliezer has in any case largely passed his staff to a new generation: Nate Soares and Zvi Mowshowitz have found new and, in various ways, better ways of talking about AI risk; Scott Alexander has for the last decade written the blog that’s the community’s intellectual center; figures from Kelsey Piper to Jacob Falkovich to Aella have taken Rationalism in new directions, from mainstream political engagement to the … err … <a href="https://aella.substack.com/p/my-birthday-gangbang">statistical analysis of orgies</a>.</p>



<p>I’ll say this, though, on the naysayers’ side: it’s <em>really</em> hard to make dancing to AI-generated pop songs about Bayes’ theorem and Tarski’s definition of truth not feel cringe, as I can now attest from experience.</p>



<p>The cult thing brings me to the deepest reason I hesitated for so long to identify as a Rationalist: namely, I was scared that if I did, people whose approval I craved (including my academic colleagues, but also just randos on the Internet) would sneer at me.  For years, I searched of some way of explaining this community’s appeal so reasonable that it would silence the sneers.</p>



<p>It took years of psychological struggle, and (frankly) solidifying my own place in the world, to follow the true path, which of course is not to give a shit what some haters think of my life choices.  Consider: five years ago, it felt obvious to me that the entire Rationalist community might be about to implode, under existential threat from Cade Metz’s <em>New York Times</em> article, as well as RationalWiki and SneerClub and all the others laughing at the Rationalists and accusing them of every evil.  Yet last week at LessOnline, I saw a community that’s never been thriving more, with a beautiful real-world campus, excellent writers on every topic who felt like this was the place to be, and even a crop of kids.  How many of the sneerers are living such fulfilled lives?  To judge from their own angry, depressed self-disclosures, probably not many.</p>



<p>But are the sneerers right that, even if the Rationalists are enjoying their own lives, they’re making other people’s lives miserable?  Are they closet far-right monarchists, like Curtis Yarvin?  I liked how <em>The New Yorker</em> put it in its recent, long and (to my mind) <a href="https://www.newyorker.com/magazine/2025/06/09/curtis-yarvin-profile">devastating profile of Yarvin</a>:</p>



<blockquote>
<p>The most generous engagement with Yarvin’s ideas has come from bloggers associated with the rationalist movement, which prides itself on weighing evidence for even seemingly far-fetched claims. Their formidable patience, however, has also worn thin. “He never addressed me as an equal, only as a brainwashed person,” Scott Aaronson, an eminent computer scientist, said of their conversations. “He seemed to think that if he just gave me one more reading assignment about happy slaves singing or one more monologue about F.D.R., I’d finally see the light.”</p>
</blockquote>



<p>The closest to right-wing politics that I witnessed at LessOnline was a session, with <a href="https://www.vox.com/authors/kelsey-piper">Kelsey Piper</a> and current and former congressional staffers, about the prospects for moderate Democrats to articulate a moderate, pro-abundance agenda that would resonate with the public and finally defeat MAGA.</p>



<p>But surely the Rationalists are incels, bitter that they can’t get laid?  Again, the closest I saw was a session where Jacob Falkovich helped a standing-room-only crowd of mostly male nerds confront their fears around dating and understand women better, with Rationalist women eagerly volunteering to answer questions about their perspective.  Gross, right?  (Also, for those already in relationships, Eliezer’s primary consort and former couples therapist <a href="https://www.grettaduleba.com/">Gretta Duleba</a> did a session on relationship conflict.)</p>



<p>So, yes, when it comes to the Rationalists, I’m going to believe my own lying eyes over the charges of the sneerers.  The sneerers can even say about me, in their favorite formulation, that I’ve “gone mask off,” confirmed the horrible things they’ve always suspected.  Yes, the mask is off—and beneath the mask is the same person I always was, who has an inordinate fondness for the <a href="https://en.wikipedia.org/wiki/Busy_beaver">Busy Beaver function</a> and the complexity class <a href="https://arxiv.org/abs/1004.0377">BQP/qpoly</a>, and who uses too many filler words and moves his hands too much, and who strongly supports the Enlightenment, and who once feared that his best shot at happiness in life would be to earn women’s pity rather than their contempt.  Incorrectly, as I’m glad to report.  From my nebbishy nadir to the present, a central thing that’s changed is that, from my family to my academic colleagues to the Rationalist community to my blog readers, I finally found some people who want what I have to sell.</p>



<hr>



<p><strong><mark>Unrelated Announcements:</mark></strong></p>



<p>My replies to comments on this post might be light, as I’ll be accompanying my daughter on a school trip to the Galapagos Islands!</p>



<p>A few weeks ago, I was “ambushed” into leading a session on philosophy and theoretical computer science at UT Austin.  (I.e., asked to show up for the session, but thought I’d just be a participant rather than the main event.)  The session was then <a href="https://www.youtube.com/watch?v=OST1DjD08Hg">recorded and placed on YouTube</a>—and surprisingly, given the circumstances, some people seemed to like it!</p>



<p>Friend-of-the-blog <a href="https://www.alonrosen.net/">Alon Rosen</a> has asked me to announce a <a href="https://cs.unibocconi.eu/call-nominations-trevisan-prize-2025">call for nominations</a> for a new theoretical computer science prize, in memory of my former professor (and fellow TCS blogger) <a href="https://scottaaronson.blog/?p=8057">Luca Trevisan</a>, who was lost to the world too soon.</p>



<p>And one more: Mahdi Cheraghchi has asked me to announce the STOC’2025 online poster session, registration deadline June 12; <a href="https://acm-stoc.org/stoc2025/call-for-posters.html">see here for more</a>.  Incidentally, I’ll be at STOC in Prague to give a plenary on quantum algorithms; I look forward to meeting any readers who are there!</p>

		
				
				<p>
					<small>
						This entry was posted
												on Monday, June 9th, 2025 at 8:02 pm						and is filed under <a href="https://scottaaronson.blog/?cat=10" rel="category">Adventures in Meatspace</a>, <a href="https://scottaaronson.blog/?cat=31" rel="category">Announcements</a>, <a href="https://scottaaronson.blog/?cat=18" rel="category">Embarrassing Myself</a>, <a href="https://scottaaronson.blog/?cat=11" rel="category">Nerd Interest</a>, <a href="https://scottaaronson.blog/?cat=29" rel="category">Nerd Self-Help</a>, <a href="https://scottaaronson.blog/?cat=42" rel="category">Obviously I'm Not Defending Aaronson</a>.
						You can follow any responses to this entry through the <a href="https://scottaaronson.blog/?feed=rss2&amp;p=8908">RSS 2.0</a> feed.

													You can <a href="#respond">leave a response</a>, or <a href="https://scottaaronson.blog/wp-trackback.php?p=8908" rel="trackback">trackback</a> from your own site.

						
					</small>
				</p>

			</div><p>You can use rich HTML in comments!  You can also use basic TeX, by enclosing it within <span>$$ $$</span> for displayed equations or <span>\( \)</span> for inline equations.</p><p>
	After two decades of mostly-open comments, in July 2024 <i>Shtetl-Optimized</i> transitioned to the following policy:
	
</p><p>All comments are treated, by default, as personal missives to me, Scott Aaronson---with no expectation either that they'll appear on the blog or that I'll reply to them.

</p><p>At my leisure and discretion, and in consultation with the <a href="https://scottaaronson.blog/?p=6576"><i>Shtetl-Optimized</i> Committee of Guardians</a>, I'll put on the blog a curated selection of comments that I judge to be particularly interesting or to move the topic forward, and I'll do my best to answer those.  But it will be more like Letters to the Editor.  Anyone who feels unjustly censored is welcome to the rest of the Internet.

</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Claude Code Usage Monitor – real-time tracker to dodge usage cut-offs (221 pts)]]></title>
            <link>https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</link>
            <guid>44317012</guid>
            <pubDate>Thu, 19 Jun 2025 09:46:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor">https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor</a>, See on <a href="https://news.ycombinator.com/item?id=44317012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🎯 Claude Code Usage Monitor</h2><a id="user-content--claude-code-usage-monitor" aria-label="Permalink: 🎯 Claude Code Usage Monitor" href="#-claude-code-usage-monitor"></a></p>
<p dir="auto"><a href="https://python.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/dec1d99c8e1ae20b8b158f2c346d5762e185f4b00fce1ef873f83115b84ee974/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e362b2d626c75652e737667" alt="Python Version" data-canonical-src="https://img.shields.io/badge/python-3.6+-blue.svg"></a>
<a href="https://opensource.org/licenses/MIT" rel="nofollow"><img src="https://camo.githubusercontent.com/6cd0120cc4c5ac11d28b2c60f76033b52db98dac641de3b2644bb054b449d60c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
<a href="http://makeapullrequest.com/" rel="nofollow"><img src="https://camo.githubusercontent.com/d88d8d77fa79e828eea397f75a1ebd114d13488aeec4747477ffbd2274de95ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs Welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a></p>
<p dir="auto">A beautiful real-time terminal monitoring tool for Claude AI token usage. Track your token consumption, burn rate, and get predictions about when you'll run out of tokens.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/doc/sc.png"><img src="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/raw/main/doc/sc.png" alt="Claude Token Monitor Screenshot"></a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📑 Table of Contents</h2><a id="user-content--table-of-contents" aria-label="Permalink: 📑 Table of Contents" href="#-table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#-key-features">✨ Key Features</a></li>
<li><a href="#-installation">🚀 Installation</a>
<ul dir="auto">
<li><a href="#-quick-start">⚡ Quick Start</a></li>
<li><a href="#-production-setup-recommended">🔒 Production Setup (Recommended)</a></li>
<li><a href="#virtual-environment-setup">Virtual Environment Setup</a></li>
</ul>
</li>
<li><a href="#-usage">📖 Usage</a>
<ul dir="auto">
<li><a href="#basic-usage">Basic Usage</a></li>
<li><a href="#configuration-options">Configuration Options</a></li>
<li><a href="#available-plans">Available Plans</a></li>
</ul>
</li>
<li><a href="#-features--how-it-works">✨ Features &amp; How It Works</a>
<ul dir="auto">
<li><a href="#current-features">Current Features</a></li>
<li><a href="#understanding-claude-sessions">Understanding Claude Sessions</a></li>
<li><a href="#token-limits-by-plan">Token Limits by Plan</a></li>
<li><a href="#smart-detection-features">Smart Detection Features</a></li>
</ul>
</li>
<li><a href="#-usage-examples">🚀 Usage Examples</a>
<ul dir="auto">
<li><a href="#common-scenarios">Common Scenarios</a></li>
<li><a href="#best-practices">Best Practices</a></li>
</ul>
</li>
<li><a href="#-contact">📞 Contact</a></li>
<li><a href="#-additional-documentation">📚 Additional Documentation</a></li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Key Features</h2><a id="user-content--key-features" aria-label="Permalink: ✨ Key Features" href="#-key-features"></a></p>
<ul dir="auto">
<li><strong>🔄 Real-time monitoring</strong> - Updates every 3 seconds with smooth refresh</li>
<li><strong>📊 Visual progress bars</strong> - Beautiful color-coded token and time progress bars</li>
<li><strong>🔮 Smart predictions</strong> - Calculates when tokens will run out based on current burn rate</li>
<li><strong>🤖 Auto-detection</strong> - Automatically switches to custom max when Pro limit is exceeded</li>
<li><strong>📋 Multiple plan support</strong> - Works with Pro, Max5, Max20, and auto-detect plans</li>
<li><strong><g-emoji alias="warning">⚠️</g-emoji> Warning system</strong> - Alerts when tokens exceed limits or will deplete before session reset</li>
<li><strong>💼 Professional UI</strong> - Clean, colorful terminal interface with emojis</li>
<li><strong>⏰ Customizable scheduling</strong> - Set your own reset times and timezones</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Installation</h2><a id="user-content--installation" aria-label="Permalink: 🚀 Installation" href="#-installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">⚡ Quick Start</h3><a id="user-content--quick-start" aria-label="Permalink: ⚡ Quick Start" href="#-quick-start"></a></p>
<p dir="auto">For immediate testing (not recommended for regular use):</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install dependencies
npm install -g ccusage
pip install pytz

# Clone and run
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor
python ccusage_monitor.py"><pre><span><span>#</span> Install dependencies</span>
npm install -g ccusage
pip install pytz

<span><span>#</span> Clone and run</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor
python ccusage_monitor.py</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">🔒 Production Setup (Recommended)</h3><a id="user-content--production-setup-recommended" aria-label="Permalink: 🔒 Production Setup (Recommended)" href="#-production-setup-recommended"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Prerequisites</h4><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ol dir="auto">
<li><strong>Python 3.6+</strong> installed on your system</li>
<li><strong>Node.js</strong> for ccusage CLI tool</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Virtual Environment Setup</h3><a id="user-content-virtual-environment-setup" aria-label="Permalink: Virtual Environment Setup" href="#virtual-environment-setup"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Why Use Virtual Environment?</h4><a id="user-content-why-use-virtual-environment" aria-label="Permalink: Why Use Virtual Environment?" href="#why-use-virtual-environment"></a></p>
<p dir="auto">Using a virtual environment is <strong>strongly recommended</strong> because:</p>
<ul dir="auto">
<li><strong>🛡️ Isolation</strong>: Keeps your system Python clean and prevents dependency conflicts</li>
<li><strong>📦 Portability</strong>: Easy to replicate the exact environment on different machines</li>
<li><strong>🔄 Version Control</strong>: Lock specific versions of dependencies for stability</li>
<li><strong>🧹 Clean Uninstall</strong>: Simply delete the virtual environment folder to remove everything</li>
<li><strong>👥 Team Collaboration</strong>: Everyone uses the same Python and package versions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installing virtualenv (if needed)</h4><a id="user-content-installing-virtualenv-if-needed" aria-label="Permalink: Installing virtualenv (if needed)" href="#installing-virtualenv-if-needed"></a></p>
<p dir="auto">If you don't have <code>venv</code> module available:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Ubuntu/Debian
sudo apt-get update
sudo apt-get install python3-venv

# Fedora/RHEL/CentOS
sudo dnf install python3-venv

# macOS (usually comes with Python)
# If not available, install Python via Homebrew:
brew install python3

# Windows (usually comes with Python)
# If not available, reinstall Python from python.org
# Make sure to check &quot;Add Python to PATH&quot; during installation"><pre><span><span>#</span> Ubuntu/Debian</span>
sudo apt-get update
sudo apt-get install python3-venv

<span><span>#</span> Fedora/RHEL/CentOS</span>
sudo dnf install python3-venv

<span><span>#</span> macOS (usually comes with Python)</span>
<span><span>#</span> If not available, install Python via Homebrew:</span>
brew install python3

<span><span>#</span> Windows (usually comes with Python)</span>
<span><span>#</span> If not available, reinstall Python from python.org</span>
<span><span>#</span> Make sure to check "Add Python to PATH" during installation</span></pre></div>
<p dir="auto">Alternatively, use the <code>virtualenv</code> package:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Install virtualenv via pip
pip install virtualenv

# Then create virtual environment with:
virtualenv venv
# instead of: python3 -m venv venv"><pre><span><span>#</span> Install virtualenv via pip</span>
pip install virtualenv

<span><span>#</span> Then create virtual environment with:</span>
virtualenv venv
<span><span>#</span> instead of: python3 -m venv venv</span></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Step-by-Step Setup</h4><a id="user-content-step-by-step-setup" aria-label="Permalink: Step-by-Step Setup" href="#step-by-step-setup"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Install ccusage globally
npm install -g ccusage

# 2. Clone the repository
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
cd Claude-Code-Usage-Monitor

# 3. Create virtual environment
python3 -m venv venv
# Or if using virtualenv package:
# virtualenv venv

# 4. Activate virtual environment
# On Linux/Mac:
source venv/bin/activate
# On Windows:
# venv\Scripts\activate

# 5. Install Python dependencies
pip install pytz

# 6. Make script executable (Linux/Mac only)
chmod +x ccusage_monitor.py

# 7. Run the monitor
python ccusage_monitor.py"><pre><span><span>#</span> 1. Install ccusage globally</span>
npm install -g ccusage

<span><span>#</span> 2. Clone the repository</span>
git clone https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor.git
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> 3. Create virtual environment</span>
python3 -m venv venv
<span><span>#</span> Or if using virtualenv package:</span>
<span><span>#</span> virtualenv venv</span>

<span><span>#</span> 4. Activate virtual environment</span>
<span><span>#</span> On Linux/Mac:</span>
<span>source</span> venv/bin/activate
<span><span>#</span> On Windows:</span>
<span><span>#</span> venv\Scripts\activate</span>

<span><span>#</span> 5. Install Python dependencies</span>
pip install pytz

<span><span>#</span> 6. Make script executable (Linux/Mac only)</span>
chmod +x ccusage_monitor.py

<span><span>#</span> 7. Run the monitor</span>
python ccusage_monitor.py</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Daily Usage</h4><a id="user-content-daily-usage" aria-label="Permalink: Daily Usage" href="#daily-usage"></a></p>
<p dir="auto">After initial setup, you only need:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to project directory
cd Claude-Code-Usage-Monitor

# Activate virtual environment
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Run monitor
./ccusage_monitor.py  # Linux/Mac
# python ccusage_monitor.py  # Windows

# When done, deactivate
deactivate"><pre><span><span>#</span> Navigate to project directory</span>
<span>cd</span> Claude-Code-Usage-Monitor

<span><span>#</span> Activate virtual environment</span>
<span>source</span> venv/bin/activate  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> venv\Scripts\activate   # Windows</span>

<span><span>#</span> Run monitor</span>
./ccusage_monitor.py  <span><span>#</span> Linux/Mac</span>
<span><span>#</span> python ccusage_monitor.py  # Windows</span>

<span><span>#</span> When done, deactivate</span>
deactivate</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Pro Tip: Shell Alias</h4><a id="user-content-pro-tip-shell-alias" aria-label="Permalink: Pro Tip: Shell Alias" href="#pro-tip-shell-alias"></a></p>
<p dir="auto">Create an alias for quick access:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'

# Then just run:
claude-monitor"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Then just run:</span>
claude-monitor</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📖 Usage</h2><a id="user-content--usage" aria-label="Permalink: 📖 Usage" href="#-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic Usage</h3><a id="user-content-basic-usage" aria-label="Permalink: Basic Usage" href="#basic-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Default (Pro plan - 7,000 tokens)
./ccusage_monitor.py

# Exit the monitor
# Press Ctrl+C to gracefully exit"><pre><span><span>#</span> Default (Pro plan - 7,000 tokens)</span>
./ccusage_monitor.py

<span><span>#</span> Exit the monitor</span>
<span><span>#</span> Press Ctrl+C to gracefully exit</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Configuration Options</h3><a id="user-content-configuration-options" aria-label="Permalink: Configuration Options" href="#configuration-options"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Specify Your Plan</h4><a id="user-content-specify-your-plan" aria-label="Permalink: Specify Your Plan" href="#specify-your-plan"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan (~7,000 tokens) - Default
./ccusage_monitor.py --plan pro

# Max5 plan (~35,000 tokens)
./ccusage_monitor.py --plan max5

# Max20 plan (~140,000 tokens)
./ccusage_monitor.py --plan max20

# Auto-detect from highest previous session
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Pro plan (~7,000 tokens) - Default</span>
./ccusage_monitor.py --plan pro

<span><span>#</span> Max5 plan (~35,000 tokens)</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> Max20 plan (~140,000 tokens)</span>
./ccusage_monitor.py --plan max20

<span><span>#</span> Auto-detect from highest previous session</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Custom Reset Times</h4><a id="user-content-custom-reset-times" aria-label="Permalink: Custom Reset Times" href="#custom-reset-times"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at 3 AM
./ccusage_monitor.py --reset-hour 3

# Reset at 10 PM
./ccusage_monitor.py --reset-hour 22"><pre><span><span>#</span> Reset at 3 AM</span>
./ccusage_monitor.py --reset-hour 3

<span><span>#</span> Reset at 10 PM</span>
./ccusage_monitor.py --reset-hour 22</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Timezone Configuration</h4><a id="user-content-timezone-configuration" aria-label="Permalink: Timezone Configuration" href="#timezone-configuration"></a></p>
<p dir="auto">The default timezone is <strong>Europe/Warsaw</strong>. Change it to any valid timezone:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Use US Eastern Time
./ccusage_monitor.py --timezone US/Eastern

# Use Tokyo time
./ccusage_monitor.py --timezone Asia/Tokyo

# Use UTC
./ccusage_monitor.py --timezone UTC

# Use London time
./ccusage_monitor.py --timezone Europe/London"><pre><span><span>#</span> Use US Eastern Time</span>
./ccusage_monitor.py --timezone US/Eastern

<span><span>#</span> Use Tokyo time</span>
./ccusage_monitor.py --timezone Asia/Tokyo

<span><span>#</span> Use UTC</span>
./ccusage_monitor.py --timezone UTC

<span><span>#</span> Use London time</span>
./ccusage_monitor.py --timezone Europe/London</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Available Plans</h3><a id="user-content-available-plans" aria-label="Permalink: Available Plans" href="#available-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Token Limit</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>pro</strong></td>
<td>~7,000</td>
<td>Light usage, testing (default)</td>
</tr>
<tr>
<td><strong>max5</strong></td>
<td>~35,000</td>
<td>Regular development</td>
</tr>
<tr>
<td><strong>max20</strong></td>
<td>~140,000</td>
<td>Heavy usage, large projects</td>
</tr>
<tr>
<td><strong>custom_max</strong></td>
<td>Auto-detect</td>
<td>Uses highest from previous sessions</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">✨ Features &amp; How It Works</h2><a id="user-content--features--how-it-works" aria-label="Permalink: ✨ Features &amp; How It Works" href="#-features--how-it-works"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Current Features</h3><a id="user-content-current-features" aria-label="Permalink: Current Features" href="#current-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔄 Real-time Monitoring</h4><a id="user-content--real-time-monitoring" aria-label="Permalink: 🔄 Real-time Monitoring" href="#-real-time-monitoring"></a></p>
<ul dir="auto">
<li>Updates every 3 seconds with smooth refresh</li>
<li>No screen flicker - intelligent display updates</li>
<li>Live token consumption tracking across multiple sessions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">📊 Visual Progress Bars</h4><a id="user-content--visual-progress-bars" aria-label="Permalink: 📊 Visual Progress Bars" href="#-visual-progress-bars"></a></p>
<ul dir="auto">
<li><strong>Token Progress</strong>: Color-coded bars showing current usage vs limits</li>
<li><strong>Time Progress</strong>: Visual countdown to next session reset</li>
<li><strong>Burn Rate Indicator</strong>: Real-time consumption velocity</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔮 Smart Predictions</h4><a id="user-content--smart-predictions" aria-label="Permalink: 🔮 Smart Predictions" href="#-smart-predictions"></a></p>
<ul dir="auto">
<li>Calculates when tokens will run out based on current burn rate</li>
<li>Warns if tokens will deplete before next session reset</li>
<li>Analyzes usage patterns from the last hour</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🤖 Auto-Detection System</h4><a id="user-content--auto-detection-system" aria-label="Permalink: 🤖 Auto-Detection System" href="#-auto-detection-system"></a></p>
<ul dir="auto">
<li><strong>Smart Plan Switching</strong>: Automatically switches from Pro to custom_max when limits exceeded</li>
<li><strong>Limit Discovery</strong>: Scans previous sessions to find your actual token limits</li>
<li><strong>Intelligent Notifications</strong>: Shows when automatic switches occur</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding Claude Sessions</h3><a id="user-content-understanding-claude-sessions" aria-label="Permalink: Understanding Claude Sessions" href="#understanding-claude-sessions"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How Claude Code Sessions Work</h4><a id="user-content-how-claude-code-sessions-work" aria-label="Permalink: How Claude Code Sessions Work" href="#how-claude-code-sessions-work"></a></p>
<p dir="auto">Claude Code operates on a <strong>5-hour rolling session window system</strong>:</p>
<ol dir="auto">
<li><strong>Session Start</strong>: Begins with your first message to Claude</li>
<li><strong>Session Duration</strong>: Lasts exactly 5 hours from that first message</li>
<li><strong>Token Limits</strong>: Apply within each 5-hour session window</li>
<li><strong>Multiple Sessions</strong>: Can have several active sessions simultaneously</li>
<li><strong>Rolling Windows</strong>: New sessions can start while others are still active</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Session Reset Schedule</h4><a id="user-content-session-reset-schedule" aria-label="Permalink: Session Reset Schedule" href="#session-reset-schedule"></a></p>
<p dir="auto"><strong>Default reference times</strong> (in your configured timezone):</p>
<ul dir="auto">
<li><code>04:00</code>, <code>09:00</code>, <code>14:00</code>, <code>18:00</code>, <code>23:00</code></li>
</ul>
<blockquote>
<p dir="auto"><strong><g-emoji alias="warning">⚠️</g-emoji> Important</strong>: These are reference times for planning. Your actual token refresh happens exactly 5 hours after YOUR first message in each session.</p>
</blockquote>
<p dir="auto"><strong>Example Session Timeline:</strong></p>
<div data-snippet-clipboard-copy-content="10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)"><pre><code>10:30 AM - First message (Session A starts)
03:30 PM - Session A expires (5 hours later)

12:15 PM - First message (Session B starts) 
05:15 PM - Session B expires (5 hours later)
</code></pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Burn Rate Calculation</h4><a id="user-content-burn-rate-calculation" aria-label="Permalink: Burn Rate Calculation" href="#burn-rate-calculation"></a></p>
<p dir="auto">The monitor calculates burn rate using sophisticated analysis:</p>
<ol dir="auto">
<li><strong>Data Collection</strong>: Gathers token usage from all sessions in the last hour</li>
<li><strong>Pattern Analysis</strong>: Identifies consumption trends across overlapping sessions</li>
<li><strong>Velocity Tracking</strong>: Calculates tokens consumed per minute</li>
<li><strong>Prediction Engine</strong>: Estimates when current session tokens will deplete</li>
<li><strong>Real-time Updates</strong>: Adjusts predictions as usage patterns change</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Token Limits by Plan</h3><a id="user-content-token-limits-by-plan" aria-label="Permalink: Token Limits by Plan" href="#token-limits-by-plan"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Standard Plans</h4><a id="user-content-standard-plans" aria-label="Permalink: Standard Plans" href="#standard-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>Approximate Limit</th>
<th>Typical Usage</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Claude Pro</strong></td>
<td>~7,000 tokens</td>
<td>Light coding, testing, learning</td>
</tr>
<tr>
<td><strong>Claude Max5</strong></td>
<td>~35,000 tokens</td>
<td>Regular development work</td>
</tr>
<tr>
<td><strong>Claude Max20</strong></td>
<td>~140,000 tokens</td>
<td>Heavy usage, large projects</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Auto-Detection Plans</h4><a id="user-content-auto-detection-plans" aria-label="Permalink: Auto-Detection Plans" href="#auto-detection-plans"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Plan</th>
<th>How It Works</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>custom_max</strong></td>
<td>Scans all previous sessions, uses highest token count found</td>
<td>Users with variable/unknown limits</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Smart Detection Features</h3><a id="user-content-smart-detection-features" aria-label="Permalink: Smart Detection Features" href="#smart-detection-features"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Automatic Plan Switching</h4><a id="user-content-automatic-plan-switching" aria-label="Permalink: Automatic Plan Switching" href="#automatic-plan-switching"></a></p>
<p dir="auto">When using the default Pro plan:</p>
<ol dir="auto">
<li><strong>Detection</strong>: Monitor notices token usage exceeding 7,000</li>
<li><strong>Analysis</strong>: Scans previous sessions for actual limits</li>
<li><strong>Switch</strong>: Automatically changes to custom_max mode</li>
<li><strong>Notification</strong>: Displays clear message about the change</li>
<li><strong>Continuation</strong>: Keeps monitoring with new, higher limit</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Limit Discovery Process</h4><a id="user-content-limit-discovery-process" aria-label="Permalink: Limit Discovery Process" href="#limit-discovery-process"></a></p>
<p dir="auto">The auto-detection system:</p>
<ol dir="auto">
<li><strong>Scans History</strong>: Examines all available session blocks</li>
<li><strong>Finds Peaks</strong>: Identifies highest token usage achieved</li>
<li><strong>Validates Data</strong>: Ensures data quality and recency</li>
<li><strong>Sets Limits</strong>: Uses discovered maximum as new limit</li>
<li><strong>Learns Patterns</strong>: Adapts to your actual usage capabilities</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Usage Examples</h2><a id="user-content--usage-examples" aria-label="Permalink: 🚀 Usage Examples" href="#-usage-examples"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Common Scenarios</h3><a id="user-content-common-scenarios" aria-label="Permalink: Common Scenarios" href="#common-scenarios"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌅 Morning Developer</h4><a id="user-content--morning-developer" aria-label="Permalink: 🌅 Morning Developer" href="#-morning-developer"></a></p>
<p dir="auto"><strong>Scenario</strong>: You start work at 9 AM and want tokens to reset aligned with your schedule.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Set custom reset time to 9 AM
./ccusage_monitor.py --reset-hour 9

# With your timezone
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern"><pre><span><span>#</span> Set custom reset time to 9 AM</span>
./ccusage_monitor.py --reset-hour 9

<span><span>#</span> With your timezone</span>
./ccusage_monitor.py --reset-hour 9 --timezone US/Eastern</pre></div>
<p dir="auto"><strong>Benefits</strong>:</p>
<ul dir="auto">
<li>Reset times align with your work schedule</li>
<li>Better planning for daily token allocation</li>
<li>Predictable session windows</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌙 Night Owl Coder</h4><a id="user-content--night-owl-coder" aria-label="Permalink: 🌙 Night Owl Coder" href="#-night-owl-coder"></a></p>
<p dir="auto"><strong>Scenario</strong>: You often work past midnight and need flexible reset scheduling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Reset at midnight for clean daily boundaries
./ccusage_monitor.py --reset-hour 0

# Late evening reset (11 PM)
./ccusage_monitor.py --reset-hour 23"><pre><span><span>#</span> Reset at midnight for clean daily boundaries</span>
./ccusage_monitor.py --reset-hour 0

<span><span>#</span> Late evening reset (11 PM)</span>
./ccusage_monitor.py --reset-hour 23</pre></div>
<p dir="auto"><strong>Strategy</strong>:</p>
<ul dir="auto">
<li>Plan heavy coding sessions around reset times</li>
<li>Use late resets to span midnight work sessions</li>
<li>Monitor burn rate during peak hours</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🔄 Heavy User with Variable Limits</h4><a id="user-content--heavy-user-with-variable-limits" aria-label="Permalink: 🔄 Heavy User with Variable Limits" href="#-heavy-user-with-variable-limits"></a></p>
<p dir="auto"><strong>Scenario</strong>: Your token limits seem to change, and you're not sure of your exact plan.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect your highest previous usage
./ccusage_monitor.py --plan custom_max

# Monitor with custom scheduling
./ccusage_monitor.py --plan custom_max --reset-hour 6"><pre><span><span>#</span> Auto-detect your highest previous usage</span>
./ccusage_monitor.py --plan custom_max

<span><span>#</span> Monitor with custom scheduling</span>
./ccusage_monitor.py --plan custom_max --reset-hour 6</pre></div>
<p dir="auto"><strong>Approach</strong>:</p>
<ul dir="auto">
<li>Let auto-detection find your real limits</li>
<li>Monitor for a week to understand patterns</li>
<li>Note when limits change or reset</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">🌍 International User</h4><a id="user-content--international-user" aria-label="Permalink: 🌍 International User" href="#-international-user"></a></p>
<p dir="auto"><strong>Scenario</strong>: You're working across different timezones or traveling.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# US East Coast
./ccusage_monitor.py --timezone America/New_York

# Europe
./ccusage_monitor.py --timezone Europe/London

# Asia Pacific
./ccusage_monitor.py --timezone Asia/Singapore

# UTC for international team coordination
./ccusage_monitor.py --timezone UTC --reset-hour 12"><pre><span><span>#</span> US East Coast</span>
./ccusage_monitor.py --timezone America/New_York

<span><span>#</span> Europe</span>
./ccusage_monitor.py --timezone Europe/London

<span><span>#</span> Asia Pacific</span>
./ccusage_monitor.py --timezone Asia/Singapore

<span><span>#</span> UTC for international team coordination</span>
./ccusage_monitor.py --timezone UTC --reset-hour 12</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">⚡ Quick Check</h4><a id="user-content--quick-check" aria-label="Permalink: ⚡ Quick Check" href="#-quick-check"></a></p>
<p dir="auto"><strong>Scenario</strong>: You just want to see current status without configuration.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Just run it with defaults
./ccusage_monitor.py

# Press Ctrl+C after checking status"><pre><span><span>#</span> Just run it with defaults</span>
./ccusage_monitor.py

<span><span>#</span> Press Ctrl+C after checking status</span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plan Selection Strategies</h3><a id="user-content-plan-selection-strategies" aria-label="Permalink: Plan Selection Strategies" href="#plan-selection-strategies"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">How to Choose Your Plan</h4><a id="user-content-how-to-choose-your-plan" aria-label="Permalink: How to Choose Your Plan" href="#how-to-choose-your-plan"></a></p>
<p dir="auto"><strong>Start with Default (Recommended for New Users)</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Pro plan detection with auto-switching
./ccusage_monitor.py"><pre><span><span>#</span> Pro plan detection with auto-switching</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Monitor will detect if you exceed Pro limits</li>
<li>Automatically switches to custom_max if needed</li>
<li>Shows notification when switching occurs</li>
</ul>
<p dir="auto"><strong>Known Subscription Users</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# If you know you have Max5
./ccusage_monitor.py --plan max5

# If you know you have Max20
./ccusage_monitor.py --plan max20"><pre><span><span>#</span> If you know you have Max5</span>
./ccusage_monitor.py --plan max5

<span><span>#</span> If you know you have Max20</span>
./ccusage_monitor.py --plan max20</pre></div>
<p dir="auto"><strong>Unknown Limits</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Auto-detect from previous usage
./ccusage_monitor.py --plan custom_max"><pre><span><span>#</span> Auto-detect from previous usage</span>
./ccusage_monitor.py --plan custom_max</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Best Practices</h3><a id="user-content-best-practices" aria-label="Permalink: Best Practices" href="#best-practices"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Setup Best Practices</h4><a id="user-content-setup-best-practices" aria-label="Permalink: Setup Best Practices" href="#setup-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Start Early in Sessions</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Begin monitoring when starting Claude work
./ccusage_monitor.py"><pre><span><span>#</span> Begin monitoring when starting Claude work</span>
./ccusage_monitor.py</pre></div>
<ul dir="auto">
<li>Gives accurate session tracking from the start</li>
<li>Better burn rate calculations</li>
<li>Early warning for limit approaches</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Use Virtual Environment</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Production setup with isolation
python3 -m venv venv
source venv/bin/activate
pip install pytz"><pre><span><span>#</span> Production setup with isolation</span>
python3 -m venv venv
<span>source</span> venv/bin/activate
pip install pytz</pre></div>
<ul dir="auto">
<li>Prevents dependency conflicts</li>
<li>Clean uninstallation</li>
<li>Reproducible environments</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Custom Shell Alias</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Add to ~/.bashrc or ~/.zshrc
alias claude-monitor='cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py'"><pre><span><span>#</span> Add to ~/.bashrc or ~/.zshrc</span>
<span>alias</span> claude-monitor=<span><span>'</span>cd ~/Claude-Code-Usage-Monitor &amp;&amp; source venv/bin/activate &amp;&amp; ./ccusage_monitor.py<span>'</span></span></pre></div>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Usage Best Practices</h4><a id="user-content-usage-best-practices" aria-label="Permalink: Usage Best Practices" href="#usage-best-practices"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Monitor Burn Rate Velocity</strong></p>
<ul dir="auto">
<li>Watch for sudden spikes in token consumption</li>
<li>Adjust coding intensity based on remaining time</li>
<li>Plan big refactors around session resets</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Strategic Session Planning</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Plan heavy usage around reset times
./ccusage_monitor.py --reset-hour 9"><pre><span><span>#</span> Plan heavy usage around reset times</span>
./ccusage_monitor.py --reset-hour 9</pre></div>
<ul dir="auto">
<li>Schedule large tasks after resets</li>
<li>Use lighter tasks when approaching limits</li>
<li>Leverage multiple overlapping sessions</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Timezone Awareness</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Always use your actual timezone
./ccusage_monitor.py --timezone Europe/Warsaw"><pre><span><span>#</span> Always use your actual timezone</span>
./ccusage_monitor.py --timezone Europe/Warsaw</pre></div>
<ul dir="auto">
<li>Accurate reset time predictions</li>
<li>Better planning for work schedules</li>
<li>Correct session expiration estimates</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Optimization Tips</h4><a id="user-content-optimization-tips" aria-label="Permalink: Optimization Tips" href="#optimization-tips"></a></p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Terminal Setup</strong></p>
<ul dir="auto">
<li>Use terminals with at least 80 character width</li>
<li>Enable color support for better visual feedback</li>
<li>Consider dedicated terminal window for monitoring</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Workflow Integration</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Start monitoring with your development session
tmux new-session -d -s claude-monitor './ccusage_monitor.py'

# Check status anytime
tmux attach -t claude-monitor"><pre><span><span>#</span> Start monitoring with your development session</span>
tmux new-session -d -s claude-monitor <span><span>'</span>./ccusage_monitor.py<span>'</span></span>

<span><span>#</span> Check status anytime</span>
tmux attach -t claude-monitor</pre></div>
</li>
<li>
<p dir="auto"><strong>Multi-Session Strategy</strong></p>
<ul dir="auto">
<li>Remember sessions last exactly 5 hours</li>
<li>You can have multiple overlapping sessions</li>
<li>Plan work across session boundaries</li>
</ul>
</li>
</ol>
<p dir="auto"><h4 tabindex="-1" dir="auto">Real-World Workflows</h4><a id="user-content-real-world-workflows" aria-label="Permalink: Real-World Workflows" href="#real-world-workflows"></a></p>
<p dir="auto"><strong>Large Project Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Setup for sustained development
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York"><pre><span><span>#</span> Setup for sustained development</span>
./ccusage_monitor.py --plan max20 --reset-hour 8 --timezone America/New_York</pre></div>
<p dir="auto"><strong>Daily Routine</strong>:</p>
<ol dir="auto">
<li><strong>8:00 AM</strong>: Fresh tokens, start major features</li>
<li><strong>10:00 AM</strong>: Check burn rate, adjust intensity</li>
<li><strong>12:00 PM</strong>: Monitor for afternoon session planning</li>
<li><strong>2:00 PM</strong>: New session window, tackle complex problems</li>
<li><strong>4:00 PM</strong>: Light tasks, prepare for evening session</li>
</ol>
<p dir="auto"><strong>Learning &amp; Experimentation</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Flexible setup for learning
./ccusage_monitor.py --plan pro"><pre><span><span>#</span> Flexible setup for learning</span>
./ccusage_monitor.py --plan pro</pre></div>
<p dir="auto"><strong>Sprint Development</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# High-intensity development setup
./ccusage_monitor.py --plan max20 --reset-hour 6"><pre><span><span>#</span> High-intensity development setup</span>
./ccusage_monitor.py --plan max20 --reset-hour 6</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📞 Contact</h2><a id="user-content--contact" aria-label="Permalink: 📞 Contact" href="#-contact"></a></p>
<p dir="auto">Have questions, suggestions, or want to collaborate? Feel free to reach out!</p>
<p dir="auto"><strong>📧 Email</strong>: <a href="mailto:maciek@roboblog.eu">maciek@roboblog.eu</a></p>
<p dir="auto">Whether you need help with setup, have feature requests, found a bug, or want to discuss potential improvements, don't hesitate to get in touch. I'm always happy to help and hear from users of the Claude Code Usage Monitor!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📚 Additional Documentation</h2><a id="user-content--additional-documentation" aria-label="Permalink: 📚 Additional Documentation" href="#-additional-documentation"></a></p>
<ul dir="auto">
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/DEVELOPMENT.md">Development Roadmap</a></strong> - ML features, PyPI package, Docker plans</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/CONTRIBUTING.md">Contributing Guide</a></strong> - How to contribute, development guidelines</li>
<li><strong><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/TROUBLESHOOTING.md">Troubleshooting</a></strong> - Common issues and solutions</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📝 License</h2><a id="user-content--license" aria-label="Permalink: 📝 License" href="#-license"></a></p>
<p dir="auto"><a href="https://github.com/Maciek-roboblog/Claude-Code-Usage-Monitor/blob/main/LICENSE">MIT License</a> - feel free to use and modify as needed.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🙏 Acknowledgments</h2><a id="user-content--acknowledgments" aria-label="Permalink: 🙏 Acknowledgments" href="#-acknowledgments"></a></p>
<p dir="auto">This tool builds upon the excellent <a href="https://github.com/ryoppippi/ccusage">ccusage</a> by <a href="https://github.com/ryoppippi">@ryoppippi</a>, adding a real-time monitoring interface with visual progress bars, burn rate calculations, and predictive analytics.</p>
<hr>

</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Base44 sells to Wix for $80M cash (123 pts)]]></title>
            <link>https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</link>
            <guid>44316920</guid>
            <pubDate>Thu, 19 Jun 2025 09:31:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/">https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</a>, See on <a href="https://news.ycombinator.com/item?id=44316920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">There’s a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of <a href="https://www.amazon.com/Single-Handed-Unicorn-Billion-Dollar-Solopreneurs-Business/dp/B0DWSRS62N" target="_blank" rel="noreferrer noopener nofollow">“solo unicorns”</a> — one-person companies worth over $1 billion.</p>

<p>While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible.&nbsp;</p>







<p>Shlomo sold his 6-month-old, bootstrapped vibe-coding startup Base44 to Wix for $80 million, Wix <a href="https://www.globenewswire.com/news-release/2025/06/18/3101508/0/en/Wix-Further-Expands-into-Vibe-Coding-with-Acquisition-of-Base44-a-Hyper-Growth-Startup-that-Simplifies-Web-and-App-Creation-with-AI.html" target="_blank" rel="noreferrer noopener nofollow">announced</a> Wednesday. And the deal was cash, Wix confirmed to TechCrunch.&nbsp;</p>

<p>Admittedly, this wasn’t a billion dollars or close to it. And Shlomo wasn’t truly solo — he had eight employees, Wix confirmed. They will collectively receive $25 million of the $80 million as a “retention” bonus. Wix declined to give details on that part of the deal, like how long they have to stay in their jobs to get full payouts.</p>

<p>Still, Base44’s rapid rise and impressive sale price have been the talk of the <a href="https://x.com/benln/status/1935327374079574427" target="_blank" rel="noreferrer noopener nofollow">vibe-coding community</a>.&nbsp;</p>

<p>In its six months as a stand-alone company, Base44 reportedly grew to 250,000 users, hitting 10,000 users within its first three weeks. According to <a href="https://www.linkedin.com/feed/update/urn:li:activity:7336025796509077504/" target="_blank" rel="noreferrer noopener nofollow">Shlomo’s posts</a> on X and LinkedIn, the company was profitable, generating $189,000 in profit in May even after covering high LLM token costs, which he also documented publicly.</p>

<p>Base44 spread mostly through word of mouth as Shlomo, a 31-year-old programmer, shared his building journey on LinkedIn and Twitter. The project began as a side venture, he told <a href="https://www.calcalistech.com/ctechnews/article/s1iflnlelx" target="_blank" rel="noreferrer noopener nofollow">Israeli tech news site CTech</a>.&nbsp;&nbsp;</p>


<p>“Base44 is a moonshot experiment — helping everyone, technical or not, build software without coding at all,” he <a rel="nofollow" href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_excited-to-share-a-project-ive-been-working-activity-7297302969652277252-vcj8?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos">explained on LinkedIn</a> when he launched it to the public.</p>

<p>It’s one of the newer crop of vibe-coding products designed for non-programmers. Users enter text prompts, and the platform builds complete applications, with database, storage, authentication, analytics, and integration. It also supports email, texting, and maps, with a roadmap for more enterprise-grade security support.</p>

<p>Base44 isn’t unique in this area. Other vibe coders like <a href="https://techcrunch.com/2025/04/22/adaptive-computer-wants-to-reinvent-the-pc-with-vibe-coding-for-non-programmers/">Adaptive Computer</a> handle similar infrastructure work. But Base44’s fast rise was astounding all the same.</p>







<p>Shlomo was already known in the Israeli startup community through his previous startup, the Insight Partners-backed data analytics company <a href="https://techcrunch.com/2021/05/18/explorium-scores-75m-series-c-just-10-months-after-b-round/">Explorium</a>. His brother is also a co-founder of an <a href="https://techcrunch.com/2025/01/27/hackers-are-targeting-machine-identities-token-security-just-raised-20m-to-stop-them/">AI security startup, Token Security,</a> which just raised $20 million led by Notable Capital (formerly GGV Capital) and a bunch of Israeli tech angels.</p>

<p>He quickly gained partnership agreements  for Base44 with big Israeli tech companies like eToro and Similarweb.</p>

<p>After posting about his decision to use Anthropic’s Claude LLM through AWS instead of models by OpenAI — mostly for cost-per-performance reasons — Amazon invited Base44 to demo at a Tel Aviv AWS event last month, which <a href="https://www.linkedin.com/posts/maor-shlomo-1088b4144_it-was-an-honor-to-present-base44-on-the-activity-7333519004138942464-EVoB/?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAAEjzLUBg333G2D9H7FJaye0FUkOP4V2yos" target="_blank" rel="noreferrer noopener nofollow">Shlomo documented.</a></p>

<p>“Crazy f***ing journey so far,” Shlomo <a href="https://www.linkedin.com/feed/update/urn:li:activity:7341088575049891840/" target="_blank" rel="noreferrer noopener nofollow">posted on LinkedIn</a> when announcing the news of the acquisition. Despite the growth and the profits — or really because of it — he sold his still-bootstrapped company because “the scale and volume we need is not something we can organically grow into&nbsp;… If we were able to get so far organically, bootstrapped, I’m excited to see our new pace now that we have all the resources in place,” he wrote.</p>

<p>For its part, Wix picked up a proven, fast-growing, local vibe-coding platform for a relative song because of its youth. <a href="https://techcrunch.com/2025/04/22/why-openai-wanted-to-buy-cursor-but-opted-for-the-fast-growing-windsurf/">OpenAI paid $3 billion for Windsurf,</a> which was founded in 2021.&nbsp;</p>

<p>Wix, of course, offers no-code website building that look professionally designed. Adding a profitable LLM vibe-coding product to its offerings is a logical move.</p>

<p>Shlomo could not be immediately reached for additional comment.</p>
</div></div>]]></description>
        </item>
    </channel>
</rss>