<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 24 Aug 2025 23:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Paracetamol disrupts early embryogenesis by cell cycle inhibition (140 pts)]]></title>
            <link>https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396</link>
            <guid>45006296</guid>
            <pubDate>Sun, 24 Aug 2025 18:02:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396">https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396</a>, See on <a href="https://news.ycombinator.com/item?id=45006296">Hacker News</a></p>
Couldn't get https://academic.oup.com/humrep/advance-article/doi/10.1093/humrep/deaf116/8234396: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Is 4chan the perfect Pirate Bay poster child to justify wider UK site-blocking? (142 pts)]]></title>
            <link>https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/</link>
            <guid>45005545</guid>
            <pubDate>Sun, 24 Aug 2025 16:30:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/">https://torrentfreak.com/uk-govt-finds-ideal-pirate-bay-poster-boy-to-sell-blocking-of-non-pirate-sites-250824/</a>, See on <a href="https://news.ycombinator.com/item?id=45005545">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/trollfac-uk.png.webp 724w, https://torrentfreak.com/images/trollfac-uk-300x188.png.webp 300w" sizes="auto, (max-width: 300px) 100vw, 300px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/trollfac-uk.png" alt="" width="300" height="188" srcset="https://torrentfreak.com/images/trollfac-uk.png 724w, https://torrentfreak.com/images/trollfac-uk-300x188.png 300w, https://torrentfreak.com/images/trollfac-uk-600x376.png 600w, https://torrentfreak.com/images/trollfac-uk-150x94.png 150w" sizes="auto, (max-width: 300px) 100vw, 300px">
</picture>
The UK’s Online Safety Act (OSA) claims to protect children but has faced fierce criticism for censoring everything from legitimate news reporting from war zones, to critical discussion of the Act itself.</p>
<p>There are many problems, not least a requirement for adults in the UK to prove their identity when accessing sites meeting criteria dictated by Ofcom. Large sites, many in the United States, face huge fines for allowing children to access age-inappropriate content. </p>
<p>This means that unverified adults are treated as children with the same content restrictions. Ofcom’s global threats have led some sites to conclude that the safest option is to ban UK visitors altogether.</p>
<h2>Degraded Internet Experience? Hand Over Your Papers</h2>
<p>Successive UK governments understood there were risks, or rather, they were informed of the risks and went ahead regardless. Whether the internet is any safer is almost impossible to measure; the same can’t be said for the hours wasted or lost, and the corresponding increases in blood pressure, all thanks to artificial restrictions that punish those who value their privacy. </p>
<p>Guided by the mantra, “a problem shared is a problem halved” those who air their OSA grievances in public find themselves presented with a 50/50 ultimatum. According to Peter Kyle, Secretary of State for Science, Innovation and Technology, those with an opinion on the legislation fall into two categories: </p>
<p>1) People who want to protect kids and 2) People who side with online predators.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/osa-predator.png.webp 498w, https://torrentfreak.com/images/osa-predator-300x109.png.webp 300w" sizes="auto, (max-width: 498px) 100vw, 498px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/osa-predator.png" alt="osa-predator" width="498" height="181" srcset="https://torrentfreak.com/images/osa-predator.png 498w, https://torrentfreak.com/images/osa-predator-300x109.png 300w, https://torrentfreak.com/images/osa-predator-150x55.png 150w" sizes="auto, (max-width: 498px) 100vw, 498px">
</picture>
</center>
<h2>You’re Either With Us, or Against Us</h2>
<p>The imposition of a binary choice is a well-worn political tactic. It aims to shut down dissent and/or discredit the speaker; in this case ordinary members of the public branded ‘predator enablers’ by a government minister.</p>
<p>VPN users warranted direct advice; no allegations this time but a suggestion that, just like the unverified, VPN users aren’t helping to keep children safe.</p>
<center><em>Just verify your age (impossible without verifying your identity)</em><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/vpn-uk.png.webp 676w, https://torrentfreak.com/images/vpn-uk-300x85.png.webp 300w" sizes="auto, (max-width: 676px) 100vw, 676px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/vpn-uk.png" alt="vpn-uk" width="676" height="192" srcset="https://torrentfreak.com/images/vpn-uk.png 676w, https://torrentfreak.com/images/vpn-uk-300x85.png 300w, https://torrentfreak.com/images/vpn-uk-600x170.png 600w, https://torrentfreak.com/images/vpn-uk-150x43.png 150w" sizes="auto, (max-width: 676px) 100vw, 676px">
</picture>
</center>
<p>In the event that the above fails to silence the troublemakers, the UK government has recently been discovered filing requests with overseas companies to delete posts made by UK citizens’ criticizing certain aspects of government policy. A United States Department of State <a href="https://www.state.gov/reports/2024-country-reports-on-human-rights-practices/united-kingdom">report</a>, criticizing the UK government for degrading the right to freedom of expression, remains stubbornly accessible. </p>
<h2>No Border Too Distant</h2>
<p>Of course, attempting to silence the State Department would be a truly historic mistake, especially in the wake of comments made by Metropolitan Police Commissioner Sir Mark Rowley. </p>
<p>Last summer Rowley threatened to “throw the full force of the law at people” for unacceptable social media comments, warning that “whether you’re in this country committing crimes on the streets or committing crimes from further afield online, we will come after you.”</p>
<p>Widely interpreted as a warning to citizens of the United States, and by extension a direct threat to their constitutional rights, U.S. officials intervened. Congressman Keith Self warned that “harassing Americans will do absolutely nothing to resolve Great Britain’s internal issues” and risks damaging the US/UK alliance.</p>
<p>As the United States attempts to introduce home turf pirate site blocking from <a href="https://torrentfreak.com/new-bill-aims-to-block-foreign-pirate-sites-in-the-u-s-250129/">three</a> <a href="https://torrentfreak.com/second-u-s-piracyiblocking-bill-incoming-mpa-google-verizon-meet-to-discuss-250227/">different</a> <a href="https://torrentfreak.com/unveiled-new-u-s-anti-piracy-bill-acpa-proposes-alternative-site-blocking-path/">directions</a>, the UK government is already preparing to take site blocking to the next level. </p>
<p>Thanks to provisions in the Online Safety Act, the UK will soon begin drawing on 15 years of pirate site blocking experiences, to block regular sites that fail to meet their ‘obligations’ as laid out <a href="https://www.gov.uk/government/publications/online-safety-act-explainer/online-safety-act-explainer">in the legislation</a>.</p>
<h2>Site Blocking For The People?</h2>
<p>Ofcom’s stated purpose is to serve the public, within duties defined by parliament, independently, using funds provided by the companies in the sectors it regulates. As regulator, Ofcom doesn’t need permission from the public to start blocking sites, although general approval would likely make the process less controversial. </p>
<p>With the whole world watching and various platforms waiting to see if Ofcom’s threats of global enforcement can be ignored, there’s little room for error.</p>
<p>In the current climate any blocking could be perceived as a further restriction of free speech, or even straightforward censorship. The conundrum is how to make site blocking appear less like censorship while satisfying the people that it’s absolutely necessary. It’s a big ask, but not impossible.</p>
<h2>The Pirate Bay: Default Poster Child of Piracy Blocking</h2>
<p>In 2012 when the major recording labels obtained their first UK site blocking injunction on copyright grounds, they could’ve picked a no-name MP3 download site and walked away with an easy win. They picked The Pirate Bay instead, and not just because of the site’s profile and unparalleled infamy. </p>
<p><strong>#1 Perfect Candidate:</strong> After years in the headlines, The Pirate Bay’s belligerent stance was well understood and at this point, helpfully predictable. First, there was never any chance of TPB spontaneously complying with copyright law. Since blocking injunctions came to exist for the purpose of tackling uncooperative entities, no candidate was more perfectly matched than the most uncooperative pirate site in the world.</p>
<p><strong>#2 No Appearance? No Win:</strong> The odds of TPB’s operators making an appearance at the High Court in London were always vanishingly slim, but not just for the reasons one might expect. The site’s alleged operators were never served in the blocking case, and they never appeared at the hearing. In fact, the site wasn’t represented in any way, at any stage. </p>
<p><strong>#3 If Done Right, No Defense:</strong> After it was determined that the law didn’t require TPB’s operators to be named as defendants, they were effectively excluded from the process. The ISPs were the defendants in this “no fault” case, and when they were ordered to block TPB, the terms of the injunction were those previously agreed in discussion with the labels.</p>
<p>Describing this as an ‘easy win’ would be a disservice to the work put in by the labels. Nothing was left to chance and the end result spoke for itself. The Pirate Bay and its function needed no introduction, and among supporters and opponents alike, acceptance that it exists for the purpose of infringement on a massive scale, was never in doubt. </p>
<p>That the process was entirely one-sided was neither here nor there. Nobody was surprised by the choice of target or the eventual outcome; in the bigger picture, controversy was kept to a minimum.</p>
<p>Now it’s Ofcom’s turn to convince, or simply inform the public, that blocking non-pirate sites benefits everyone. On paper, the notorious  4chan forum ticks all the right boxes and presumably no match for the well-resourced Ofcom.</p>
<h2>4chan: Poster Child of Regular Site Blocking?</h2>
<p>One can only imagine the reaction at 4chan when Ofcom advised that it had new obligations under a foreign law. Section 9(2) of the Act requires certain platforms to undertake an illegal content risk assessment, to assess the risks of users encountering ‘illegal’ content on their platforms. </p>
<p>The requirements were <a href="https://www.ofcom.org.uk/siteassets/resources/documents/consultations/category-1-10-weeks/185926-consultation-online-safety-information-guidance/associated-documents/draft-illegal-content-codes-of-practice-for-user-to-user-services.pdf?v=392429">published</a> February 24, 2025, and the ‘Illegal Content Duties’ came into effect on 17 March 2025. On April 14, Ofcom issued a ‘formal information notice’ to 4chan demanding a copy of its Illegal Content Risk Assessment and not surprisingly, received no reply.</p>
<p>In common with The Pirate Bay, 4chan’s non-compliance was <em>almost</em> inevitable. When accompanied by threats to disrupt its business, including by obtaining a court order to compel payment processors, advertisers, and hosting providers to stop doing business, while levying fines of £20,000 per day, non-compliance was effectively guaranteed. In this respect, 4chan’s response was entirely predictable.</p>
<h2>4chan Unlikely to Attend Court in the UK</h2>
<p>As highlighted previously, cases are more easily won when it’s understood that the defendant won’t make an appearance. We can safely assume that 4chan has the same number of tickets to London as it does Illegal Content Risk Assessments so, no, it will not attend. So far, so good then? Not exactly. </p>
<p>Ofcom launched its 4chan investigation on June 10, to determine compliance with various duties under the Online Safety Act. </p>
<p>Did 4chan adequately respond to a statutory information request? Has it conducted and kept a record of its illegal content risk assessment? Is it complying with its safety duties, including protecting its users from ‘illegal’ content? </p>
<p>Ofcom currently has no answers to these questions but did learn something new this week. Not only has 4chan hired extremely capable attorneys in response to Ofcom’s threats, any action by Ofcom will be resisted in the United States under Federal Law. </p>
<h2>New Jurisdiction, Different Ball Game</h2>
<p>Since Ofcom’s threats are viewed as undermining 4chan’s constitutional rights, its attorneys believe that no court in America will allow foreign penalties to be enforced in the United States. Once people begin speaking about that, the damage will have been done.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/ofcom-4chan.png.webp 649w, https://torrentfreak.com/images/ofcom-4chan-300x360.png.webp 300w" sizes="auto, (max-width: 649px) 100vw, 649px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/ofcom-4chan.png" alt="ofcom-4chan" width="649" height="779" srcset="https://torrentfreak.com/images/ofcom-4chan.png 649w, https://torrentfreak.com/images/ofcom-4chan-300x360.png 300w, https://torrentfreak.com/images/ofcom-4chan-600x720.png 600w, https://torrentfreak.com/images/ofcom-4chan-125x150.png 125w" sizes="auto, (max-width: 649px) 100vw, 649px">
</picture>
</center>
<p>Given the offense caused by last year’s threats by UK police against U.S. citizens, and similar events since then, the final three paragraphs of the statement above seem especially relevant. </p>
<p>By selecting 4chan as a potential target for enforcement, knowing all too well it would refuse to comply, a stand-off has been engineered between UK censorship measures nobody asked for, and the constitutional rights of all Americans.</p>
<p>If the hallmarks of the win in The Pirate Bay case were predictability, inability to mount any defense, and the avoidance of controversy, this is only just short of a complete disaster. .</p>
<h2>Who’s in Charge of Government Policy?</h2>
<p>Further escalation at the political level in the event Ofcom digs in, may demand intervention at the highest level. For Prime Minister Keir Starmer, that does not bode well</p>
<p>First, Ofcom is independent, so that may not even be possible. Second, consider this recent exchange between JD Vance and Keir Starmer himself on the erosion of free speech in the UK.</p>
<p><em><strong>Vance:</strong> “We also know that there have been infringements on free speech that actually affect not just the British. Of course, what the British do in their own country is up to them, but they also affect American technology companies and by extension American citizens. So that is something that we’ll talk about today at lunch.”</em></p><p><em><strong>Starmer</strong>: “We’ve had free speech for a very long time in the United Kingdom and uh..uh.. and it will last for a very, very long time. Well no, I mean we certainly wouldn’t want to reach across to US citizens…and we don’t…and that’s absolutely right.</em></p>
<p>Ofcom begs to differ, clearly; so who is in charge here? Why doesn’t the Prime Minister know that the UK is actively “reaching across to US citizens?” Unfortunately, Ofcom has a reputation for not backing down. On the plus side, it hasn’t imposed any penalties to back down from yet, so there is that.</p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/safety.png.webp 348w, https://torrentfreak.com/images/safety-300x177.png.webp 300w" sizes="auto, (max-width: 348px) 100vw, 348px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/safety.png" alt="safety" width="348" height="205" srcset="https://torrentfreak.com/images/safety.png 348w, https://torrentfreak.com/images/safety-300x177.png 300w, https://torrentfreak.com/images/safety-150x88.png 150w, https://torrentfreak.com/images/safety-220x130.png 220w" sizes="auto, (max-width: 348px) 100vw, 348px">
</picture>
</center>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comet AI browser can get prompt injected from any site, drain your bank account (436 pts)]]></title>
            <link>https://twitter.com/zack_overflow/status/1959308058200551721</link>
            <guid>45004846</guid>
            <pubDate>Sun, 24 Aug 2025 15:14:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/zack_overflow/status/1959308058200551721">https://twitter.com/zack_overflow/status/1959308058200551721</a>, See on <a href="https://news.ycombinator.com/item?id=45004846">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><p><img alt="⚠️" draggable="false" src="https://abs-0.twimg.com/emoji/v2/svg/26a0.svg"><span> Some privacy related extensions may cause issues on x.com. Please disable them and try again.</span></p></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Making games in Go: 3 months without LLMs vs. 3 days with LLMs (217 pts)]]></title>
            <link>https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/</link>
            <guid>45004728</guid>
            <pubDate>Sun, 24 Aug 2025 15:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/">https://marianogappa.github.io/software/2025/08/24/i-made-two-card-games-in-go/</a>, See on <a href="https://news.ycombinator.com/item?id=45004728">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introduction">Introduction</h2><p>After 15 years as a software engineer, I realized I had never actually built and published a game.</p><p>Since I grew up in 🇦🇷 Argentina playing card games with my friends, I figured I’d choose one of those. I asked myself:</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/most-common.png" alt="most-common-card-games"></p><h2 id="truco-3-months-without-llms">Truco: 3 Months Without LLMs</h2><p>On <a href="https://github.com/marianogappa/truco/commit/80ad842f546ac5bdf0d680d105afc10b66626d0f">June 18th of 2024</a> I started building <a href="https://en.wikipedia.org/wiki/Truco">Truco</a> in my free time. As a longtime Go backend developer, the backend was obvious. The challenge was the UI and long-term hosting without a paid server.</p><table><thead><tr><th>Problem</th><th>Solution</th></tr></thead><tbody><tr><td>UI</td><td>Bit the bullet and learned the minimal required <a href="https://reactjs.org/">React</a> for the UI.</td></tr><tr><td>No server</td><td>Transpiled the server to <a href="https://en.wikipedia.org/wiki/WebAssembly">WASM</a> using <a href="https://tinygo.org/">TinyGo</a>.</td></tr><tr><td>Hosting</td><td>Used <a href="https://pages.github.com/">GitHub Pages</a> to host the static files.</td></tr></tbody></table><p>This was pre-LLM, so every detail had to be figured out by hand. It took about 3 months of trial and error to get it ready.</p><p>I never planned to advertise or monetize it; I just wanted to finish, and maybe give someone the joy of playing their childhood game again. A year later, without any extra effort on my part, people are still playing it!</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/truco-analytics.png" alt="truco-analytics"></p><p>In case you want to check it out, here are some links for it:</p><p><a href="https://marianogappa.github.io/truco-argentino">Truco (play the game)</a></p><p><a href="https://github.com/marianogappa/truco">Backend in Go</a></p><p><a href="https://github.com/marianogappa/truco-argentino">Frontend in React</a> (don’t judge me 🤷‍♂️ best I can do with 1-hour React knowledge)</p><h2 id="escoba-3-days-with-llms">“Escoba”: 3 Days With LLMs</h2><p>A year later, visiting family in Argentina, I taught my nephew <a href="https://en.wikipedia.org/wiki/Escoba">Escoba</a>—the country’s second most popular card game (despite what ChatGPT insists).</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/two-most-common.png" alt="two-most-common-card-games"></p><p>With LLMs now mainstream, I wondered how much faster building a game might be—so I decided to test it.</p><p>I cloned the backend for Truco and gave <a href="https://claude.ai/">Claude</a> a long prompt explaining the rules of Escoba and asking it to refactor the code to implement it. To my surprise, it worked almost perfectly on the first prompt 😱. For a moment I thought: goodbye, job 😰.</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/prompt.png" alt="prompt"></p><p>The only bug I found was that it used <code>append</code> <a href="https://github.com/marianogappa/escoba/commit/e9c373a38cb2ca5e7eefca2870f91e7def1579f7#diff-8e38aecf51e5858a66646d328292fc8abf36f6a602ef3ea4ed7fc1ca2b1a0240L104-L105">incorrectly in one place and mutated actions</a>. Except for that, I only added a few bells and whistles on top (like <a href="https://github.com/marianogappa/escoba/commit/fe1c87bed8e9b60cc902dfc563c356506c2faf4c">a better bot</a>).</p><p>The frontend was a different story; it took me a few days to get it right. The real challenge probably wasn’t just the LLM — it was my own React skills, combined with the unusual setup of letting a black-box WASM function manage game state. Debugging in JavaScript also didn’t make life easier.</p><p>In case you want to check it out, here are some links for it:</p><p><a href="https://marianogappa.github.io/escoba-de-15">Escoba (play the game)</a></p><p><a href="https://github.com/marianogappa/escoba">Backend in Go</a></p><p><a href="https://github.com/marianogappa/escoba-de-15">Frontend in React</a></p><h2 id="step-by-step-how-to-build-your-own-game">Step-by-Step: How to Build Your Own Game</h2><p>I’m assuming you might have come here to see if it’s not too hard to give it a try yourself! So I’ll give you the minimalistic primer to make your own game with this stack.</p><p>I wrote a minimalistic Tic-Tac-Toe game set of repos so you can fork them to get started:</p><p><a href="https://github.com/marianogappa/tictactoe-backend">https://github.com/marianogappa/tictactoe-backend</a>
<a href="https://github.com/marianogappa/tictactoe-frontend">https://github.com/marianogappa/tictactoe-frontend</a></p><p>You can check it out here:</p><p><a href="https://marianogappa.github.io/tictactoe-frontend/">https://marianogappa.github.io/tictactoe-frontend/</a></p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/tictactoe.png" alt="TicTacToe"></p><h3 id="backend-side">Backend-side</h3><p>A turn-based backend is straightforward to outline:</p><ul><li><a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L157">Initialize</a> a <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L16">GameState struct</a> (e.g. initial board setup, empty actions list).</li><li>Implement <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L378"><code>CalculatePossibleActions</code></a>, so clients know what’s valid.</li><li>Add <a href="https://github.com/marianogappa/truco/blob/v0.2.0/truco/truco.go#L213">RunAction</a> to mutate the GameState.</li><li>If there’s a bot, write a function to <a href="https://github.com/marianogappa/truco/blob/v0.2.0/examplebot/newbot/bot.go#L38">pick an action</a> from the current state.</li></ul><p>That’s it!</p><p><em>Note: forget human vs human, unless you’re willing to pay for that server.</em></p><h3 id="frontend-side">Frontend-side</h3><p>I’m no frontend expert, but the tasks are simple:</p><ul><li>Call the backend to create a new <code>GameState</code>.</li><li>Render it in the UI.</li><li>Let the player pick an action from the valid options.</li><li>Call the backend to apply the action.</li><li>Trigger the bot’s action when it’s their turn.</li></ul><p>That’s it!</p><h3 id="backend-side-interop">Backend-side interop</h3><p>To transpile the backend to WASM, you can build with (docs <a href="https://go.dev/wiki/WebAssembly">here</a>):</p><div><pre tabindex="0"><code data-lang="bash"><span><span>GOARCH<span>=</span>wasm GOOS<span>=</span>js go build -o main.wasm main.go
</span></span></code></pre></div><p>But that produces huge binaries (which is slow on mobile). Use <a href="https://tinygo.org/">TinyGo</a> for smaller ones.</p><p>Before compiling, you need a different entrypoint to the functions that you’re going to make available to the frontend. <a href="https://github.com/marianogappa/truco/blob/v0.2.0/main_wasm.go">Make a different <code>main.go</code></a> file that exports the functions that you need, and <a href="https://github.com/marianogappa/truco/blob/v0.2.0/main_wasm.go#L2">guard it via build flags</a>:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>//go:build tinygo</span>
</span></span><span><span><span>// +build tinygo</span>
</span></span><span><span>
</span></span><span><span><span>package</span> <span>main</span>
</span></span><span><span>
</span></span><span><span>[<span>...</span>]
</span></span><span><span>
</span></span><span><span><span>func</span> <span>main</span>() {
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoNew"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoNew</span>))
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoRunAction"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoRunAction</span>))
</span></span><span><span>	<span>js</span>.<span>Global</span>().<span>Set</span>(<span>"trucoBotRunAction"</span>, <span>js</span>.<span>FuncOf</span>(<span>trucoBotRunAction</span>))
</span></span><span><span>	<span>select</span> {}
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>var</span> (
</span></span><span><span>	<span>state</span> <span>*</span><span>truco</span>.<span>GameState</span> <span>// "Global variable" for the GameState</span>
</span></span><span><span>	<span>bot</span>   <span>truco</span>.<span>Bot</span>
</span></span><span><span>)
</span></span></code></pre></div><p>Don’t forget to block at the end of <code>main()</code> with <code>select {}</code> to prevent the program from exiting immediately.</p><h3 id="backend-data-interop">Backend data interop</h3><p><code>GameState</code> is typically a free-form struct that you define in Go. WASM can’t directly serialize/deserialize structs. The trick is to pass everything as JSON. After digging through <a href="https://tinygo.org/docs/guides/webassembly/">TinyGo docs</a>, here’s the formula:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>trucoRunAction</span>(<span>this</span> <span>js</span>.<span>Value</span>, <span>p</span> []<span>js</span>.<span>Value</span>) <span>interface</span>{} { <span>// Always this signature</span>
</span></span><span><span>	<span>// Read the input JSON</span>
</span></span><span><span>    <span>jsonBytes</span> <span>:=</span> make([]<span>byte</span>, <span>p</span>[<span>0</span>].<span>Length</span>()) 
</span></span><span><span>	<span>js</span>.<span>CopyBytesToGo</span>(<span>jsonBytes</span>, <span>p</span>[<span>0</span>])
</span></span><span><span>
</span></span><span><span>	<span>// 1. Decode the input JSON to your struct</span>
</span></span><span><span>    <span>// 2. Run your Go code, return an output struct</span>
</span></span><span><span>	<span>// 3. Encode the output struct to JSON</span>
</span></span><span><span>	<span>newBytes</span> <span>:=</span> <span>_runAction</span>(<span>jsonBytes</span>)
</span></span><span><span>
</span></span><span><span>	<span>// Return the output JSON</span>
</span></span><span><span>	<span>buffer</span> <span>:=</span> <span>js</span>.<span>Global</span>().<span>Get</span>(<span>"Uint8Array"</span>).<span>New</span>(len(<span>newBytes</span>))
</span></span><span><span>	<span>js</span>.<span>CopyBytesToJS</span>(<span>buffer</span>, <span>newBytes</span>)
</span></span><span><span>	<span>return</span> <span>buffer</span>
</span></span><span><span>}
</span></span></code></pre></div><h3 id="frontend-side-interop">Frontend-side interop</h3><p>Finally, <a href="https://github.com/marianogappa/truco-argentino/blob/main/public/index.html#L45">call the backend functions from the frontend</a> and [track the GameState in a global variable]((<a href="https://github.com/marianogappa/truco-argentino/blob/main/src/gameState.js#L19)">https://github.com/marianogappa/truco-argentino/blob/main/src/gameState.js#L19)</a>:</p><div><pre tabindex="0"><code data-lang="js"><span><span><span>function</span> <span>jsRunAction</span>(<span>data</span>) {
</span></span><span><span>    <span>const</span> <span>encoder</span> <span>=</span> <span>new</span> <span>TextEncoder</span>();
</span></span><span><span>    <span>const</span> <span>encodedData</span> <span>=</span> <span>encoder</span>.<span>encode</span>(<span>JSON</span>.<span>stringify</span>(<span>data</span>));
</span></span><span><span>    <span>const</span> <span>result</span> <span>=</span> <span>trucoRunAction</span>(<span>encodedData</span>);
</span></span><span><span>    <span>const</span> <span>json</span> <span>=</span> <span>new</span> <span>TextDecoder</span>().<span>decode</span>(<span>result</span>);
</span></span><span><span>    <span>return</span> <span>JSON</span>.<span>parse</span>(<span>json</span>);
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>let</span> <span>gameState</span> <span>=</span> <span>jsNewGame</span>();
</span></span><span><span>
</span></span><span><span><span>// Note that RunAction doesn't take a GameState.
</span></span></span><span><span><span>// WASM is the source of truth; your frontend can't mutate it.
</span></span></span><span><span><span></span><span>gameState</span> <span>=</span> <span>jsRunAction</span>(<span>action</span>); 
</span></span></code></pre></div><p>Every time you modify the backend, you need to recompile it to WASM and replace the old file in the frontend. I put this in <a href="https://github.com/marianogappa/escoba-de-15/blob/main/Makefile">the Makefile</a>:</p><pre tabindex="0"><code>compile_library:
	cd $(GOPATH)/src/github.com/marianogappa/escoba &amp;&amp; \
	TINYGOROOT=/usr/local/Cellar/tinygo/0.38.0 tinygo build -o main.wasm -target wasm main_wasm.go &amp;&amp; \
	mv main.wasm $(CURDIR)/public/wasm/wasm.wasm &amp;&amp; \
	cp /usr/local/Cellar/tinygo/0.38.0/targets/wasm_exec.js $(CURDIR)/public/wasm/wasm_exec.js &amp;&amp; \
	cd -
</code></pre><p>Note that I’m also copying over <code>wasm_exec.js</code>. This is a requirement for running WASM code. The other requirement is to add the <a href="https://github.com/marianogappa/truco-argentino/blob/main/public/index.html#L16">script tag to the HEAD of the HTML file</a>:</p><div><pre tabindex="0"><code data-lang="html"><span><span>
</span></span><span><span>    &lt;<span>script</span> <span>src</span><span>=</span><span>"wasm/wasm_exec.js"</span>&gt;&lt;/<span>script</span>&gt;
</span></span><span><span>	&lt;<span>script</span>&gt;
</span></span><span><span>        <span>const</span> <span>go</span> <span>=</span> <span>new</span> <span>Go</span>(); <span>// Defined in wasm_exec.js
</span></span></span><span><span><span></span>        <span>const</span> <span>WASM_URL</span> <span>=</span> <span>'wasm/wasm.wasm'</span>;
</span></span><span><span>
</span></span><span><span>        <span>var</span> <span>wasm</span>;
</span></span><span><span>        <span>let</span> <span>wasmReady</span> <span>=</span> <span>false</span>;
</span></span><span><span>
</span></span><span><span>        <span>if</span> (<span>'instantiateStreaming'</span> <span>in</span> <span>WebAssembly</span>) {
</span></span><span><span>            <span>WebAssembly</span>.<span>instantiateStreaming</span>(<span>fetch</span>(<span>WASM_URL</span>), <span>go</span>.<span>importObject</span>).<span>then</span>(<span>function</span> (<span>obj</span>) {
</span></span><span><span>                <span>wasm</span> <span>=</span> <span>obj</span>.<span>instance</span>;
</span></span><span><span>                <span>go</span>.<span>run</span>(<span>wasm</span>);
</span></span><span><span>                <span>wasmReady</span> <span>=</span> <span>true</span>;
</span></span><span><span>            })
</span></span><span><span>        } <span>else</span> {
</span></span><span><span>            <span>fetch</span>(<span>WASM_URL</span>).<span>then</span>(<span>resp</span> =&gt;
</span></span><span><span>                <span>resp</span>.<span>arrayBuffer</span>()
</span></span><span><span>            ).<span>then</span>(<span>bytes</span> =&gt;
</span></span><span><span>                <span>WebAssembly</span>.<span>instantiate</span>(<span>bytes</span>, <span>go</span>.<span>importObject</span>).<span>then</span>(<span>function</span> (<span>obj</span>) {
</span></span><span><span>                    <span>wasm</span> <span>=</span> <span>obj</span>.<span>instance</span>;
</span></span><span><span>                    <span>go</span>.<span>run</span>(<span>wasm</span>);
</span></span><span><span>                    <span>wasmReady</span> <span>=</span> <span>true</span>;
</span></span><span><span>                })
</span></span><span><span>            )
</span></span><span><span>        }
</span></span><span><span>    &lt;/<span>script</span>&gt;
</span></span></code></pre></div><h2 id="troubleshooting">Troubleshooting</h2><h3 id="the-wasm-file-is-not-loading">The WASM file is not loading</h3><p>This works automatically in Github Pages, but locally, you need to serve the files over HTTP. You can use <a href="https://www.npmjs.com/package/http-server">http-server</a> for this:</p><div><pre tabindex="0"><code data-lang="bash"><span><span>npx http-server ./public -p <span>8080</span>
</span></span></code></pre></div><p>And then visit <code>http://localhost:8080</code> in your browser.</p><h2 id="conclusion">Conclusion</h2><p>I had a lot of fun making these games and I hope you find it interesting to see how it works. I also hope you find it useful to make your own games! If you have questions, I’m not hard to find.</p><p><img src="https://marianogappa.github.io/images/posts/i-made-two-card-games-in-go/escoba.png" alt="escoba"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US attack on renewables will lead to power crunch that spikes electricity prices (216 pts)]]></title>
            <link>https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html</link>
            <guid>45004466</guid>
            <pubDate>Sun, 24 Aug 2025 14:22:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html">https://www.cnbc.com/2025/08/24/solar-wind-renewable-trump-tariff-utility-tax-credit-itc-ptc-obbb-electricity-price.html</a>, See on <a href="https://news.ycombinator.com/item?id=45004466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107172309" data-test="InlineImage"><p>Witthaya Prasongsin | Moment | Getty Images</p></div><div><p>President <a href="https://www.cnbc.com/donald-trump/">Donald Trump</a>'s attack on solar and wind projects threatens to raise energy prices for consumers and undermine a stretched electric grid that's already straining to meet rapidly growing demand, renewable energy executives warn.</p><p>Trump has long said wind power turbines are unattractive and endanger birds, and that solar installations take up too much land. This week, he said his administration <a href="https://www.cnbc.com/2025/08/20/trump-says-us-will-not-approve-solar-or-wind-power-projects.html">will not approve solar and wind</a> projects, the latest salvo in a campaign the president has waged against the renewable energy industry since taking office.</p><p>"We will not approve wind or farmer destroying Solar," Trump <a href="https://truthsocial.com/@realDonaldTrump/115061417084982814" target="_blank">posted on Truth Social</a> Wednesday. "The days of stupidity are over in the USA!!!"</p><p>Trump's statement this week seemed to confirm industry fears that the Interior Department will block federal permits for solar and wind projects. Interior Secretary Doug Burgum <a href="https://www.cnbc.com/2025/07/17/solar-wind-permit-interior-department-burgum-trump.html">took control of all permit approvals</a> last month in a move that the American Clean Power Association criticized as "obstruction," calling it "unprecedented political review."</p><p>The Interior Department blocking permits would slow the growth of the entire solar and wind industry, top executives at renewable developers <a href="https://arevonenergy.com/" target="_blank">Arevon</a>, <a href="https://avantus.com/about-us" target="_blank">Avantus</a> and <a href="https://www.engie-na.com/" target="_blank">Engie North America</a> told CNBC.</p><p>Even solar and wind projects on private land may need approvals from the U.S. Fish and Wildlife Service if, for example, a waterway or animal species is affected, the executives told CNBC. The three power companies are among the top 10 renewable developers in the U.S., according to energy research firm Enverus.</p><p>The Interior Department "will not give preferential treatment to massive, unreliable projects that make no sense for the American people or that risk harming communities or the environment," a spokesperson told CNBC when asked if new permits would be issued for solar and wind construction.</p><p>Choking off renewables will worsen a looming power supply shortage, harm the electric grid and lead to higher electricity prices for consumers, said Kevin Smith, CEO of Arevon, a solar and battery storage developer headquartered in Scottsdale, Arizona, that's active in 17 states. Arevon operates five gigawatts of power equivalent to $10 billion of capital investment.</p><p>"I don't think everybody realizes how big the crunch is going to be," Smith said. "We're making that crunch more and more difficult with these policy changes."</p><h3>Uncertainty hits investment</h3><p>The red tape at the Interior Department and rising costs from Trump's copper and steel tariffs have created market instability that makes planning difficult, the renewable executives said.</p><p>"We don't want to sign contracts until we know what the playing field is," said Cliff Graham, CEO of Avantus, a solar and battery storage developer headquartered in San Diego. Avantus has built three gigawatts of solar and storage across the desert Southwest.</p><p>"I can do whatever you want me to do and have a viable business, I just need the rules set and in place," Graham said.</p></div><div><p>Engie North America, the U.S. arm of a global energy company based in Paris, is slashing its planned investment in the U.S. by 50% due to tariffs and regulatory uncertainty, said David Carroll, the chief renewables officer who leads the American subsidiary. Engie could cut its plans even more, he said.</p><p>Engie's North American subsidiary, headquartered in Houston, will operate about 11 gigawatts of solar, battery storage and wind power by year end.</p><p>Multinationals like Engie have long viewed the U.S. as one of the most stable business environments in the world, Carroll said. But that assessment is changing in Engie's boardroom and across the industry, he said.</p><p>"The stability of the U.S. business market is no longer really the gold standard," Carroll said.</p><h3>Rising costs</h3><p>Arevon is seeing costs for solar and battery storage projects increase by as much as 30% due to the metal tariffs, said Smith, the CEO. Many renewable developers are renegotiating power prices with utilities to cover the sudden spike in costs because projects no longer pencil out financially, he said.</p><p>Trump's One Big Beautiful Bill Act ends two key tax credits for solar and wind projects in late 2027, making conditions even more challenging. The investment tax credit supported new renewable construction and the production credit boosted clean electricity generation.</p><p>Those tax credits were just passed on to consumers, Smith said. Their termination and the rising costs from tariffs will mean higher utility bills for families and businesses, he said.</p><p>The price that Avantus charges for solar power has roughly doubled to $60 per megawatt-hour as interest rates and tariffs have increased over the years, said CEO Graham. Prices will surge again to around $100 per megawatt-hour when the tax credits are gone, he said.</p><p>"The small manufacturers, small companies and mom and pops will see their electric bills go up, and it'll start pushing the small entrepreneurs out of the industry or out of the marketplace," Graham said.</p><p>Renewable projects that start construction by next July, a year after the One Big Beautiful Act became law, will still qualify for the tax credits. Arevon, Avantus and Engie are moving forward with projects currently under construction, but the outlook is less certain for projects later in the decade.</p><p>The U.S. will see a big downturn in new renewable power generation starting in the second half of 2026 through 2028 as new projects no longer qualify for tax credits, said Smith, the head of Arevon.</p><p>"The small- and medium-sized players that can't take the financial risk, some of them will disappear," Smith said. "You're going to see less projects built in the sector."</p><h3>Artificial intelligence power crunch</h3><p>Fewer renewable power plants could increase the risk of brownouts or blackouts, Smith said. Electricity <a href="https://www.cnbc.com/2024/11/23/data-centers-powering-ai-could-use-more-electricity-than-entire-cities.html">demand is surging from the data centers</a> that technology companies are building to train artificial intelligence systems. <a href="https://www.pjm.com/about-pjm" target="_blank">PJM Interconnection</a>, the largest electrical grid in the U.S. that coordinates wholesale electricity in 13 states&nbsp;and the District of Columbia, has warned of <a href="https://www.cnbc.com/2024/08/28/utilities-face-looming-crunch-as-electricity-demand-from-ai-surges.html">tight power supplies </a>because too little new generation is coming online.</p><p>Renewables are the power source that can most quickly meet demand, Smith at Arevon said. More than 90% of the power waiting to connect to the grid is solar, battery storage or wind, according to data from Enverus.</p><p>"The power requirement is largely going to be coming from the new energy sector or not at all," so without it, "the grid becomes substantially hampered," Smith said.</p></div><div><p>Trump is prioritizing oil, gas and nuclear power as "the most effective and reliable tools to power our country," White House spokesperson Anna Kelly said.</p><p>"President Trump serves the American people who voted to implement his America First energy agenda – not solar and wind executives who are sad that Biden's Green New Scam subsidies are ending," Kelly said.</p><p>But new natural gas plants won't come online for another five years due to supply issues, new nuclear power is a decade away and no new coal plants are on the drawing board.</p><p>Utilities may have to turn away data centers at some point because there isn't enough surplus power to run them, and no one wants to risk blackouts at hospitals, schools and homes, Arevon's Smith said. This would pressure the U.S. in its race against China to master AI, a Trump administration priority.</p><p>"The panic in the data center, AI world is probably not going to set in for another 12 months or so, when they start realizing that they can't get the power they need in some of these areas where they're planning to build data centers," Smith said.</p><p>"Then we'll see what happens," said the University of Chicago MBA, who's worked in the energy industry for 35 years. "There may be a reversal in policy to try and build whatever we can and get power onto the grid."</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ICE uses celebrity loophole to hide deportation flights (132 pts)]]></title>
            <link>https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/</link>
            <guid>45003819</guid>
            <pubDate>Sun, 24 Aug 2025 12:40:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/">https://jacobin.com/2025/08/ice-uses-celebrities-loophole-to-hide-deportation-flights/</a>, See on <a href="https://news.ycombinator.com/item?id=45003819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content">

                <!-- Antescript -->

                
                  
                

                <!-- Intro -->
                
                  
                

                
                  
                    <section id="ch-0">
                      <p>For years, the country’s rich and famous have used a little-known Federal Aviation Administration program to shield their private jets’ flight records from public view — among them Taylor Swift, Oprah Winfrey, and Steven Spielberg.</p>
<p>Now this decades-old program has a new client: Immigration and Customs Enforcement (ICE), the agency carrying out President Donald&nbsp;Trump’s mass deportations.</p>
<p>To obscure its planes, which ship immigrants out of the country on deportation flights, ICE is taking advantage of a longstanding program created by the private jet lobby,&nbsp;<i>The Lever&nbsp;</i>can confirm. For years, the scheme has allowed celebrities and Wall Street CEOs to partially block their flight data from public view.</p>
<p>Its use by the Trump administration’s immigration enforcers is part of a mounting effort by ICE and its contracted&nbsp;<a href="https://www.levernews.com/inside-the-billion-dollar-business-of-deportation-flights/">private charter airlines</a>&nbsp;to keep the planes’ flight paths hidden from the public. CNN first&nbsp;<a href="https://www.cnn.com/2025/08/13/politics/ice-flights-locations-tracking-maps%22%20%5Ct%20%22_blank">reported</a>&nbsp;on the trend, noting that ICE’s charter airlines were requesting some of the planes in their fleets be scrubbed from public flight tracking sites.</p>
<p>Deportation flights — like Swift’s private jet, whose enormous carbon footprint&nbsp;has stoked <a href="https://www.bbc.com/travel/article/20240213-taylor-swift-private-jet-flight-travel-carbon-footprint%22%20%5Ct%20%22_blank">public outcry</a>&nbsp;— can still be tracked in real time using other public data. But ICE’s use of the Federal Aviation Administration (FAA)’s private jet blacklist underscores how a growing push for privacy by the corporate jet lobby is being deployed to limit public oversight of ICE’s draconian immigration crackdown.</p>
<p>Activists and journalists have for many years tracked ICE’s secretive deportation flights, which critics say subject passengers to cruel and inhumane conditions. People being flown out of the country by ICE&nbsp;are frequently <a href="https://www.propublica.org/article/inside-ice-air-deportation-flights%22%20%5Ct%20%22_blank">shackled</a>&nbsp;for the duration of the journey, and advocates have documented a pattern of&nbsp;<a href="https://www.theguardian.com/us-news/2020/sep/19/ice-air-immigration-medical-negligence%22%20%5Ct%20%22_blank">medical neglect</a>&nbsp;on the planes. As one ICE Air flight attendant&nbsp;<a href="https://www.propublica.org/article/inside-ice-air-deportation-flights%22%20%5Ct%20%22_blank">told</a>&nbsp;<i>ProPublica&nbsp;</i>this spring, a disaster on one of the flights is likely “only a matter of time.”</p>
<p>The charter airlines to whom ICE&nbsp;pays <a href="https://www.levernews.com/inside-the-billion-dollar-business-of-deportation-flights/">enormous sums</a>&nbsp;for deportation flights are the&nbsp;<a href="https://www.nytimes.com/athletic/6416337/2025/06/12/ice-ncaa-globalx-deportation/%22%20%5Ct%20%22_blank">same airlines</a>, like Avelo Airlines and GlobalX Air, that&nbsp;<a href="https://www.nytimes.com/2025/05/12/business/trump-deportation-flights-avelo-airlines.html%22%20%5Ct%20%22_blank">transport</a>&nbsp;professional sports teams around the country. Until recently, these airlines’ fleets could be tracked on public websites like FlightAware and Flightradar24, the same sites that track whether your flight on a commercial airline like Delta or United is delayed.</p>
<p>In recent months, according to multiple sources, these obscure charter airlines have for the first time begun requesting that some planes in their fleet be added to the FAA’s Limiting Aircraft Data Displayed list — LADD — a specialized program developed by the private jet lobby decades ago to keep aircraft data off of public aggregator sites like FlightAware.</p>
<p>“We’re seeing these commercial aircraft being added to the LADD list and then subsequently being employed under contract by the government for these deportation flights,” Ian Petchenik, the communications director with flight aggregator website Flightradar24, told&nbsp;<i>The Lever</i>.</p>
<p>Commercial planes have in the past been occasionally added to the LADD list, he said, for “very specific reasons,” like charter planes flown in the course of a presidential campaign. But ICE’s use of the list appears to be unprecedented: “It’s certainly new,” Petchenik said.</p>

                    </section>
                  
                

                <!-- Main Content -->

                
    
      
        
          <section id="ch-1">
            
              <h2>First ElonJet, Now ICE Air</h2>
              
            
            <p>In the 1990s, the FAA began&nbsp;<a href="https://publicintegrity.org/politics/barr-battle-obama-administration-to-make-more-corporate-jet-data-public-despite-flak/%22%20%5Ct%20%22_blank">sharing</a> real-time air traffic data&nbsp;with airlines, hoping to improve operations across the industry. Other commercial vendors were eventually allowed access to this data, some of which — including the website FlightAware, which launched in 2005 — began publishing real-time flight data for both commercial and private aircraft, both for the public and for industry use.</p>
<p>The new transparency drew opposition from the&nbsp;<a href="https://download.aopa.org/Media/General-Aviation-Explained-r5.pdf%22%20%5Ct%20%22_blank">$250 billion</a>&nbsp;private aviation industry, which argued that publishing the flight data of billionaires’ and celebrities’ jets posed “security” risks.</p>
<p>In&nbsp;<a href="https://www.ainonline.com/aviation-news/business-aviation/2011-07-31/lawmakers-decry-barr-restrictions%22%20%5Ct%20%22_blank">collaboration</a> with Congress, the National Business Aviation Association, a corporate jet lobbying group, in 2000 launched a program that would allow private jet owners to block their aircraft’s identification information from FAA data released to private vendors — cloaking their jets’ movements.</p>
<p>The group “has long believed that security and other imperatives make it absolutely essential to protect our Members’ aircraft and flight information from being made widely available, which is why we created [the program],” a representative&nbsp;<a href="https://nbaa.org/press-releases/nbaa-court-rules-against-long-term-protection-of-flight-data-in-barr-program/%22%20%5Ct%20%22_blank">said</a> in 2010.</p>
<p>For more than a decade, the program was managed by the National Business Aviation Association, which fed the requests to federal aviation regulators. But in 2011, under the Obama administration, federal regulators&nbsp;<a href="https://publicintegrity.org/politics/barr-battle-obama-administration-to-make-more-corporate-jet-data-public-despite-flak/%22%20%5Ct%20%22_blank">signaled</a>&nbsp;that they no longer planned to honor the block requests unless private jet owners submitted evidence of a legitimate “security concern” — essentially gutting the program.</p>
<p>This sent the private jet lobby into a panic. The National Business Aviation Association&nbsp;quickly <a href="https://nbaa.org/membership/letters-to-membership/2011-2/act-now-to-preserve-the-barr-program/%22%20%5Ct%20%22_blank">sued</a>&nbsp;and marshalled hundreds of groups to line up in opposition. The Heritage Foundation, a conservative think tank&nbsp;<a href="https://www.levernews.com/dark-money-just-got-darker-wall-street-helped-fund-project-2025/">bankrolled</a>&nbsp;by right-wing dark money interests, announced that the new rules&nbsp;would “<a href="https://google.com/search?q=heritage+foundation+barr+2011+obama+aircraft&amp;sca_esv=ce44fb6aa5ce43e4&amp;sxsrf=AE3TifMAPKXOUr2LpYB4jCzlmiGIJDi_iw%253A1755873566366&amp;ei=HoGoaJeJFvWs5NoPpNf1kQg&amp;ved=0ahUKEwiXkMbh0p6PAxV1FlkFHaRrPYIQ4dUDCBE&amp;uact=5&amp;oq=heritage+foundation+barr+2011+obama+aircraft&amp;gs_lp=Egxnd3Mtd2l6LXNlcnAiLGhlcml0YWdlIGZvdW5kYXRpb24gYmFyciAyMDExIG9iYW1hIGFpcmNyYWZ0MgUQIRigATIFECEYoAEyBRAhGKABSKYHUAFY6AZwAHgAkAEBmAG3AaAB-QiqAQMyLje4AQPIAQD4AQGYAgegArgHwgIFECEYqwKYAwCIBgGSBwMxLjagB7gqsgcDMS42uAe4B8IHATfIBwU&amp;sclient=gws-wiz-serp%22%20%5Ct%20%22_blank">destroy</a>”&nbsp;the privacy of corporate jet fliers. Under industry pressure, the FAA&nbsp;<a href="https://www.regulations.gov/document/FAA-2013-0259-0072%22%20%5Ct%20%22_blank">backtracked</a>&nbsp;just months after the 2011 announcement, allowing the Block Aircraft Registration Request program to continue. But now it would be managed directly by federal regulators, not by trade groups. In 2019, the program’s name was changed to LADD.</p>
<p>There&nbsp;are <a href="https://laddlist.com/stats/%22%20%5Ct%20%22_blank">tens of thousands</a>&nbsp;of private planes currently on the blacklist, according to a tracker maintained by Jack Sweeney, the online researcher who has become famous for tracking private jets owned by — among others — Taylor Swift and&nbsp;<a href="https://www.levernews.com/tag/elon-musk/">Elon Musk</a>.</p>
<p>Both the pop singer and the billionaire were incensed by Sweeney’s live trackers, which post real-time flight data on social media about the comings and goings of the private planes. In December 2023, Swift’s lawyers&nbsp;<a href="https://www.cbsnews.com/news/taylor-swift-private-jet-jack-sweeney-responds-cease-and-desist-lawyers-letter/%22%20%5Ct%20%22_blank">sent</a> Sweeney&nbsp;a cease-and-desist letter. Musk&nbsp;<a href="https://www.nytimes.com/2022/12/14/technology/twitter-private-jet-accounts-suspended.html%22%20%5Ct%20%22_blank">for a time</a>&nbsp;banned Sweeney from Twitter over “ElonJet,” the account that tracked Musk’s jet location. But Sweeney has refused to take down the trackers.</p>
<p>Musk’s and Swift’s private jets are both on the LADD list, which means people can’t find them on sites that rely on the FAA for flight-tracking data, like FlightAware. Sweeney, however, uses entirely crowd-sourced flight data,&nbsp;<a href="https://arstechnica.com/tech-policy/2023/01/the-flight-tracker-that-powered-elonjet-has-taken-a-left-turn/%22%20%5Ct%20%22_blank">collected</a> by volunteers&nbsp;around the world who use their own DIY receivers to pick up live data from planes overhead — allowing him to bypass the LADD list’s restrictions.</p>
<p>Just like Musk’s private jet, the positions of ICE’s deportation flights will remain available even if they are flown on blacklisted planes, thanks to the enthusiasts who feed this information, called ADS-B data, into open-source exchanges. The workaround has infuriated Musk, who has&nbsp;<a href="https://www.wired.com/story/ads-b-exchange-jetnet-sale/%22%20%5Ct%20%22_blank">advocated against</a>&nbsp;flight-data crowdsourcing.</p>
<p>Sweeney was surprised by the recent additions of private charter airline planes used in deportation flights to the LADD list. Earlier this month, he&nbsp;<a href="https://x.com/Jxck_Sweeney/status/1953550777072390194%22%20%5Ct%20%22_blank">highlighted</a>&nbsp;two aircraft owned by Avelo Airlines that had been quietly added to the program.</p>
<p>“I was like, ‘Why are these Avelo planes on the list?’” he told&nbsp;<i>The Lever</i>. “Those are commercial airliners. I hadn’t really seen that.”</p>
<p>According to a review by&nbsp;<i>The Lever</i>, two Avelo Airlines planes and seven GlobalX planes are currently on the LADD list, per data on the charter airlines’ fleets&nbsp;<a href="https://www.airfleets.net/flottecie/Avelo%2520Airlines-active-b737ng.htm%22%20%5Ct%20%22_blank">maintained</a> by Airfleets&nbsp;and Sweeney’s public&nbsp;LADD list <a href="https://laddlist.com/table/%22%20%5Ct%20%22_blank">reproduction</a>.</p>
<p>At the behest of the private jet lobby, the FAA has recently moved to roll back other transparency requirements for private jets. Last year, in the months after Musk launched a crusade against Sweeney over the&nbsp;still up-and-running <a href="https://bsky.app/profile/did:plc:62cuohm6c6nefpnw4uujepty%22%20%5Ct%20%22_blank">ElonJet</a>, lawmakers inserted a provision into must-pass aviation policy legislation that established a new program to allow private jet owners to obscure their planes’ ownership information, information that was once publicly available. The FAA began to&nbsp;<a href="https://www.faa.gov/newsroom/faa-moves-protect-aircraft-owners-private-information%22%20%5Ct%20%22_blank">roll out</a>&nbsp;that program in March.</p>
<p>The move followed expansions of the LADD list, as well as the&nbsp;<a href="https://nbaa.org/aircraft-operations/security/privacy/privacy-icao-address-pia/%22%20%5Ct%20%22_blank">launch</a> of a new program&nbsp;to make it more difficult for planes to be tracked using ADS-B data.</p>

          </section>
        
      
    
  

              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamically patch a Python function's source code at runtime (122 pts)]]></title>
            <link>https://ericmjl.github.io/blog/2025/8/23/wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime/</link>
            <guid>45003750</guid>
            <pubDate>Sun, 24 Aug 2025 12:28:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ericmjl.github.io/blog/2025/8/23/wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime/">https://ericmjl.github.io/blog/2025/8/23/wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime/</a>, See on <a href="https://news.ycombinator.com/item?id=45003750">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
<!-- Append author -->
<p><small>
  <p>
    written by
    
    
    
    on
    <span id="pub_date" name="pub_date">2025-08-23</span>

    
    | tags:
    <!-- Append tags after author -->
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/python/">
        python
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/runtime/">
        runtime
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/llm/">
        llm
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/security/">
        security
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/namespace/">
        namespace
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/compilation/">
        compilation
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/execution/">
        execution
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/functions/">
        functions
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/toolbot/">
        toolbot
      </a>
    </span>
    <span id="tags" name="tags">
      <a href="https://ericmjl.github.io/blog/tag/monkeypatching/">
        monkeypatching
      </a>
    </span>
    
  </p>
  
</small></p><hr>

    
    
    <!-- NOTE: I am keeping this here just for preview purposes.
     We must rely on the webp logo for the blog post.
     Pre-commit hooks will ensure that the png logo is converted to webp.-->
    

    
    <p><i><p>In this blog post, I share how I discovered a powerful Python trick: dynamically changing a function's source code at runtime using the compile and exec functions. This technique enabled me to build more flexible AI bots, like ToolBot, that can generate and execute code with access to the current environment. While this opens up exciting possibilities for LLM-powered agents and generative UIs, it also raises serious security concerns. Curious how this hack can supercharge your AI projects—and what risks you should watch out for?</p>
</i>
    </p>
    

    <p><span id="post_body" name="post_body">
      <p>So today, I learned a very dangerous and yet fascinating trick.</p>
<p>It's possible to dynamically change a Python function's source code <em>at runtime</em>.</p>
<p>What this does is open a world of possibilities in building AI bots!</p>
<h2>How this actually works</h2>
<p>Every function has a <code>.__code__</code> attribute. For example, for this function:</p>
<div><pre><span></span><span>def</span><span> </span><span>something</span><span>():</span>
    <span>raise</span> <span>NotImplementedError</span><span>()</span>
</pre></div>
<p><code>something.__code__</code> looks like this:</p>
<div><pre><span></span><span>&lt;</span><span>code</span> <span>object</span> <span>something</span> <span>at</span> <span>0x149bdfc90</span><span>,</span> <span>file</span> <span>"/var/folders/36/vb250n_s0zncstw3sk74qfxr0000gn/T/marimo_80086/__marimo__cell_kJqw_.py"</span><span>,</span> <span>line</span> <span>1</span><span>&gt;</span>
</pre></div>
<p>If I were to execute <code>something()</code>, it would return a <code>NotImplementedError</code>.</p>
<p>Now, let's say that, for some reason that I shall not speculate, I decided that I wanted <code>something()</code> to instead do multiplication by 2. I can create new source code:</p>
<div><pre><span></span><span>new_code</span> <span>=</span> <span>"""</span>
<span>def something(x: int) -&gt; int:</span>
<span>    return x * 2</span>
<span>"""</span>
</pre></div>
<p>I can do the following three magical steps to swap it in.</p>
<p>Firstly, compile the code into bytecode:</p>
<div><pre><span></span><span>compiled</span> <span>=</span> <span>compile</span><span>(</span><span>new_code</span><span>,</span> <span>"&lt;magic&gt;"</span><span>,</span> <span>"exec"</span><span>)</span>
</pre></div>
<p>The three arguments to <code>compile</code> are:</p>
<ol>
<li>The code to compile (<code>new_code</code>),</li>
<li>The filename in which the code is compiled (<code>&lt;magic&gt;</code>), and</li>
<li>The mode in which compilation happens (in this case, <code>exec</code> mode).</li>
</ol>
<p>On the third point, the docstring of <code>compile</code> explains what the three modes are:</p>
<blockquote>
<p>The mode must be 'exec' to compile a module, 'single' to compile a single (interactive) statement, or 'eval' to compile an expression.</p>
</blockquote>
<p>The <code>compiled</code> object now is a "code object":</p>
<div><pre><span></span><span>&lt;</span><span>code</span> <span>object</span> <span>&lt;</span><span>module</span><span>&gt;</span> <span>at</span> <span>0x149bcbad0</span><span>,</span> <span>file</span> <span>"&lt;magic&gt;"</span><span>,</span> <span>line</span> <span>1</span><span>&gt;</span>
</pre></div>
<p>I can then execute the compiled code to make it imported into a particular namespace.</p>
<div><pre><span></span><span>ns</span> <span>=</span> <span>{}</span>
<span>exec</span><span>(</span><span>compiled</span><span>,</span> <span>{},</span> <span>ns</span><span>)</span>
</pre></div>
<p>Here, the three arguments passed to <code>exec</code> are:</p>
<ol>
<li>The code we want to execute (<code>compiled</code>), and in this case, by "executing" it after being compiled in <code>exec</code> mode, we are really just simulating an <code>import</code> into our namespace.</li>
<li>The globals (<code>{}</code>), which in this case are passed in as an empty dictionary. These are the global variables that are available to the function at runtime.</li>
<li><code>ns</code> is the "namespace" in which we want the function to be present; namespaces in Python are just dictionary mappings from function/object name to the function/object itself.</li>
</ol>
<p>Finally, I can replace my existing function with the compiled function inserted into the <code>ns</code> namespace:</p>
<div><pre><span></span><span>something_new</span> <span>=</span> <span>ns</span><span>[</span><span>"something"</span><span>]</span>
<span>print</span><span>(</span><span>something_new</span><span>(</span><span>21</span><span>))</span>  <span># this will print 42 to stdout!</span>
</pre></div>
<p>But really, the real lesson here is not that one can monkeypatch over an existing Python function's source code at runtime, but that you can actually <strong>compile the string of a Python function definition and give it access to a namespace's variables</strong>, including that of the current global namespace.</p>
<h2>When would you ever want to do this?</h2>
<p>At first glance, never really! This is a bit of hackery that lives on the fringes of Python-land, and is basically a party trick.</p>
<p>But as it turns out, I <em>actually</em> had a real motivation for wanting to do this.</p>
<p>Within <a href="https://github.com/ericmjl/llamabot">LlamaBot</a>, I've always had <code>AgentBot</code> as a first-pass implementation of what I think an LLM agent should look like, having studied LLM agent implementations in other libraries. However, I've never been fully satisfied with <code>AgentBot</code>'s implementation. The core issue was that it mixed too many concerns together - function execution, function call determination, and user response generation all lived in the same loop.</p>
<p>Here's what <code>AgentBot</code> looked like at a high level:</p>
<div><pre><span></span><span>class</span><span> </span><span>AgentBot</span><span>(</span><span>SimpleBot</span><span>):</span>
    <span>def</span><span> </span><span>__init__</span><span>(</span><span>self</span><span>,</span> <span>model_name</span><span>,</span> <span>tools</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>...</span>

    <span>def</span><span> </span><span>__call__</span><span>(</span><span>self</span><span>,</span> <span>*</span><span>messages</span><span>,</span> <span>num_iterations</span><span>=</span><span>10</span><span>):</span>
        <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>num_iterations</span><span>):</span>
            <span>response</span> <span>=</span> <span>...</span> <span># get response object, passing in messages</span>
            <span>results</span> <span>=</span> <span>[]</span>
            <span># Execute tool calls if they are present</span>
            <span>if</span> <span>response</span><span>.</span><span>tool_calls</span><span>:</span>
                <span>for</span> <span>tool_call</span> <span>in</span> <span>response</span><span>.</span><span>tool_calls</span><span>:</span>
                    <span>result</span> <span>=</span> <span>self</span><span>.</span><span>name_to_tools</span><span>[</span><span>tool_call</span><span>.</span><span>name</span><span>](</span><span>**</span><span>json</span><span>.</span><span>loads</span><span>(</span><span>tool_call</span><span>.</span><span>arguments</span><span>))</span>

            <span># continue until LLM decides we're done.</span>
            <span>else</span><span>:</span>
                <span># just respond to users.</span>
</pre></div>
<p>While this worked, it wasn't great at separating concerns. I had function execution mixed in with function call determination mixed in with responding to a user.</p>
<p>The bigger limitation was with code execution tools. My original implementation isolated generated code in a Docker container sandbox, which was secure but meant the code couldn't access variables from my current Python runtime. This severely limited what kinds of useful tasks the bot could perform with my existing data and variables.</p>
<p>I realized that if I could:</p>
<ol>
<li>Use an LLM to generate Python functions that referenced existing variables in my runtime,</li>
<li>Compile those functions on-the-fly within the same Python environment, and</li>
<li>Execute them with access to my current namespace,</li>
</ol>
<p>I could build something much more powerful. This led me to create <code>ToolBot</code> within LlamaBot.</p>
<h2>ToolBot focuses on tool selection instead of execution</h2>
<p><code>ToolBot</code> takes a different approach - it focuses purely on tool selection rather than execution. Here's the key structure:</p>
<div><pre><span></span><span>class</span><span> </span><span>ToolBot</span><span>(</span><span>SimpleBot</span><span>):</span>
    <span>def</span><span> </span><span>__init__</span><span>(</span><span>self</span><span>,</span> <span>system_prompt</span><span>,</span> <span>model_name</span><span>,</span> <span>tools</span><span>=</span><span>None</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span># Initialize with core tools like today_date and respond_to_user</span>
        <span>all_tools</span> <span>=</span> <span>[</span><span>today_date</span><span>,</span> <span>respond_to_user</span><span>]</span>
        <span>if</span> <span>tools</span><span>:</span>
            <span>all_tools</span><span>.</span><span>extend</span><span>(</span><span>tools</span><span>)</span>

        <span>self</span><span>.</span><span>tools</span> <span>=</span> <span>[</span><span>f</span><span>.</span><span>json_schema</span> <span>for</span> <span>f</span> <span>in</span> <span>all_tools</span><span>]</span>
        <span>self</span><span>.</span><span>name_to_tool_map</span> <span>=</span> <span>{</span><span>f</span><span>.</span><span>__name__</span><span>:</span> <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>all_tools</span><span>}</span>

    <span>def</span><span> </span><span>__call__</span><span>(</span><span>self</span><span>,</span> <span>message</span><span>):</span>
        <span># Process message and return tool calls (but don't execute them)</span>
        <span>response</span> <span>=</span> <span>make_response</span><span>(</span><span>self</span><span>,</span> <span>message_list</span><span>,</span> <span>stream</span><span>=</span><span>stream</span><span>)</span>
        <span>tool_calls</span> <span>=</span> <span>extract_tool_calls</span><span>(</span><span>response</span><span>)</span>
        <span>return</span> <span>tool_calls</span>  <span># Just return the calls, don't execute</span>
</pre></div>
<p>The key insight: <code>ToolBot</code> just selects a tool to be executed, but does <em>not</em> execute it. Instead, it returns the tools to be called to the external environment, giving you full control over execution.</p>
<h2>The magic happens with write_and_execute_code</h2>
<p>One of the most powerful tools that can be chosen is <code>write_and_execute_code</code>. Here's the core implementation:</p>
<div><pre><span></span><span>def</span><span> </span><span>write_and_execute_code</span><span>(</span><span>globals_dict</span><span>:</span> <span>dict</span><span>):</span>
    <span>@tool</span>
    <span>def</span><span> </span><span>write_and_execute_code_wrapper</span><span>(</span><span>placeholder_function</span><span>:</span> <span>str</span><span>,</span> <span>keyword_args</span><span>:</span> <span>dict</span><span>):</span>
<span>        </span><span>"""Write and execute `placeholder_function` with the passed in `keyword_args`.</span>

<span>        Use this tool for any task that requires custom Python code generation and execution.</span>
<span>        This tool has access to ALL globals in the current runtime environment (variables, dataframes, functions, etc.).</span>
<span>        Perfect for: data analysis, calculations, transformations, visualizations, custom algorithms.</span>

<span>        ## Code Generation Guidelines:</span>

<span>        1. **Write self-contained Python functions** with ALL imports inside the function body</span>
<span>        2. **Place all imports at the beginning of the function**: import statements must be the first lines inside the function</span>
<span>        3. **Include all required libraries**: pandas, numpy, matplotlib, etc. - import everything the function needs</span>
<span>        4. **Leverage existing global variables**: Can reference variables that exist in the runtime</span>
<span>        5. **Include proper error handling** and docstrings</span>
<span>        6. **Provide keyword arguments** when the function requires parameters</span>
<span>        7. **Make functions reusable** - they will be stored globally for future use</span>
<span>        8. **ALWAYS RETURN A VALUE**: Every function must explicitly return something - never just print, display, or show results without returning them. Even for plotting functions, return the figure/axes object.</span>

<span>        ## Function Arguments Handling:</span>

<span>        **CRITICAL**: You MUST match the function signature with the keyword_args:</span>
<span>        - **If your function takes NO parameters** (e.g., `def analyze_data():`), then pass an **empty dictionary**: `{}`</span>
<span>        - **If your function takes parameters** (e.g., `def filter_data(min_age, department):`), then pass the required arguments as a dictionary: `{"min_age": 30, "department": "Engineering"}`</span>
<span>        - **Never pass keyword_args that don't match the function signature** - this will cause execution errors</span>

<span>        ## Code Structure Example:</span>

<span>        ```python</span>
<span>        # Function with NO parameters - use empty dict {}</span>
<span>        def analyze_departments():</span>
<span>            '''Analyze department performance.'''</span>
<span>            import pandas as pd</span>
<span>            import numpy as np</span>
<span>            result = fake_df.groupby('department')['salary'].mean()</span>
<span>            return result</span>
<span>        # Function WITH parameters - pass matching keyword_args</span>
<span>        def filter_employees(min_age, department):</span>
<span>            '''Filter employees by criteria.'''</span>
<span>            import pandas as pd</span>
<span>            filtered = fake_df[(fake_df['age'] &gt;= min_age) &amp; (fake_df['department'] == department)]</span>
<span>            return filtered</span>
<span>        ```</span>

<span>        ## Return Value Requirements:</span>

<span>        - **Data analysis functions**: Return the computed results (numbers, DataFrames, lists, dictionaries)</span>
<span>        - **Plotting functions**: Return the figure or axes object (e.g., `return fig` or `return plt.gca()`)</span>
<span>        - **Filter/transformation functions**: Return the processed data</span>
<span>        - **Calculation functions**: Return the calculated values</span>
<span>        - **Utility functions**: Return relevant output (status, processed data, etc.)</span>
<span>        - **Never return None implicitly** - always have an explicit return statement</span>

<span>        ## Code Access Capabilities:</span>

<span>        The generated code will have access to:</span>
<span>        - All global variables and dataframes in the current session</span>
<span>        - Any previously defined functions</span>
<span>        - The ability to import any standard Python libraries within the function</span>
<span>        - The ability to create new reusable functions that will be stored globally</span>
<span>        :param placeholder_function: The function to execute (complete Python function as string).</span>
<span>        :param keyword_args: The keyword arguments to pass to the function (dictionary matching function parameters).</span>
<span>        :return: The result of the function execution.</span>
<span>        """</span>

        <span># Parse the code to extract the function name</span>
        <span>tree</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>placeholder_function</span><span>)</span>
        <span>function_name</span> <span>=</span> <span>None</span>
        <span>for</span> <span>node</span> <span>in</span> <span>ast</span><span>.</span><span>walk</span><span>(</span><span>tree</span><span>):</span>
            <span>if</span> <span>isinstance</span><span>(</span><span>node</span><span>,</span> <span>ast</span><span>.</span><span>FunctionDef</span><span>):</span>
                <span>function_name</span> <span>=</span> <span>node</span><span>.</span><span>name</span>
                <span>break</span>
        <span># Compile and execute the function with access to globals</span>
        <span>ns</span> <span>=</span> <span>globals_dict</span>
        <span>compiled</span> <span>=</span> <span>compile</span><span>(</span><span>placeholder_function</span><span>,</span> <span>"&lt;llm&gt;"</span><span>,</span> <span>"exec"</span><span>)</span>
        <span>exec</span><span>(</span><span>compiled</span><span>,</span> <span>globals_dict</span><span>,</span> <span>ns</span><span>)</span>
        <span>return</span> <span>ns</span><span>[</span><span>function_name</span><span>](</span><span>**</span><span>keyword_args</span><span>)</span>

    <span>return</span> <span>write_and_execute_code_wrapper</span>
</pre></div>
<p>This extensive docstring gets passed as part of the JSON schema and effectively serves as instructions to the LLM on when and how to use this tool. I stripped out logging and error handling to simplify what's shown here, but the actual codebase has more robustness built in.</p>
<p>Notice how <code>ToolBot</code>, and more specifically <code>write_and_execute_code</code>, gains explicit access to the <code>globals()</code> dictionary when a user passes it in. This approach allows us to ensure that function execution takes place within the proper namespace. If <code>ToolBot</code> chooses <code>write_and_execute_code</code>, I can control exactly where and how it executes within my Python runtime environment - and this opens up a world of possibilities!</p>
<p>For example, inspired by <a href="https://marimo.io/blog/marimo-chat">the Marimo blog</a>, which wrote about generative UIs and tool calling:</p>
<blockquote>
<p>marimo’s chat interface supports Generative UI - the ability to stream rich, interactive UI components directly from LLM responses. This goes beyond traditional text and markdown outputs, allowing chatbots to return dynamic elements like tables, charts, and interactive visualizations.</p>
</blockquote>
<p>I decided to build out a <em>generalized</em> version of a tool that an LLM could choose to call on that would also have access to any variable present within the runtime environment... much like Marimo's AI chat has access to any variable within the environment with an <code>@variable_name</code>, now I just dump the full set of <code>globals()</code> into the LLM's context window, and that's what <code>write_and_execute_code</code> looked like.</p>
<p>Here's an example, imagine I have two dataframes that I want an LLM to manipulate. Without <code>write_and_execute_code</code>, I'd have to write bespoke tools for the dataframe, in which I access the <code>df</code> as a "global" variable, much like the following:</p>
<div><pre><span></span><span>@lmb</span><span>.</span><span>tool</span>
<span>def</span><span> </span><span>chart_data</span><span>(</span><span>x_encoding</span><span>:</span> <span>str</span><span>,</span> <span>y_encoding</span><span>:</span> <span>str</span><span>,</span> <span>color</span><span>:</span> <span>str</span><span>):</span>
<span>    </span><span>"""Generate an altair chart"""</span>
    <span>import</span><span> </span><span>altair</span><span> </span><span>as</span><span> </span><span>alt</span>
    <span>return</span> <span>(</span>
        <span>alt</span><span>.</span><span>Chart</span><span>(</span><span>df</span><span>)</span>
        <span>.</span><span>mark_circle</span><span>()</span>
        <span>.</span><span>encode</span><span>(</span><span>x</span><span>=</span><span>x_encoding</span><span>,</span> <span>y</span><span>=</span><span>y_encoding</span><span>,</span> <span>color</span><span>=</span><span>color</span><span>)</span>
        <span>.</span><span>properties</span><span>(</span><span>width</span><span>=</span><span>500</span><span>)</span>
    <span>)</span>
</pre></div>
<p>So the writing on the wall is that I'd have to write one tool for every possible operation that I'd desire, but that's a big hassle. With this <code>globals()</code>, <code>compile</code>, and <code>exec</code> trickery baked into <code>write_and_execute_code</code>, I no longer have to specify bespoke tools for the environment that I'm in!</p>
<p>Further more, inspired by the Marimo blog post, <code>ToolBot</code> is designed to just do the tool picking, delegating the execution and return of the broader LLM-powered Python program back to the developer. In this way, I can give myself more flexibility when building entire "Agentic" programs, more so than if I were to use <code>AgentBot</code> in its current form. It allowed me to build a more powerful version of a tool-calling agent using <code>ToolBot</code> with generative UIs in a Marimo notebook. For this, it's easier to demo via a screencast instead of by me describing it in prose:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/tk5wvb556f8?si=sXSRulZ2ooBplapr" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<p>And if you're curious to try running it, you can run it with the following command:</p>
<div><pre><span></span>uvx<span> </span>marimo<span> </span>edit<span> </span>--sandbox<span> </span>https://raw.githubusercontent.com/ericmjl/website/refs/heads/main/content/blog/wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime/agents.py
</pre></div>
<h2>Security concerns are very real with this approach</h2>
<p>Comparing this to what we had before with <code>write_and_execute_script</code>, which performed execution in a sandboxed Docker container with limited read/write capabilities, <code>write_and_execute_code</code> is <em>much, much less secure</em>.</p>
<p>Obviously, I'm playing with fire here. A malicious LLM output could run code directly and do enormous damage to my machine and from my machine to the outside world. I have yet to implement code sanitization, but one big idea I have, which I just learned through discourse with GPT-4, is to use <a href="https://github.com/zopefoundation/RestrictedPython">Restricted Python</a>. I think that will be the next big upgrade after I let the current version of <code>write_and_execute_code</code> sit for a while.</p>
<p>As such, I don't suggest that the <code>write_and_execute_code</code> pattern be used for anything really serious in its current form.</p>
<h2>What I learned from this Python trickery</h2>
<p>This journey taught me several things. First, Python's runtime is far more malleable than I initially realized - the ability to compile strings into executable code and inject them into specific namespaces opens up incredible possibilities for dynamic programming.</p>
<p>Second, building effective LLM agents isn't just about the AI - it's about thoughtful system design. Separating tool selection from execution (as <code>ToolBot</code> does) creates much more flexible and controllable systems than monolithic agents.</p>
<p>Finally, this wouldn't have been possible without <a href="https://ericmjl.github.io/blog/2025/6/7/principles-for-using-ai-autodidactically/">autodidactic learning with LLMs</a>. I'm becoming more and more convinced that LLMs are a great tool for learning, but one must learn how to use them for learning, and one must <a href="https://ericmjl.github.io/blog/2025/7/13/earn-the-privilege-to-use-automation/">earn the automation</a> as well.</p>

    </span></p><hr>

    <p><i>Cite this blog post:</i></p><div>
    <pre><span id="citation-text"><span><span>@article</span>{
    <span>ericmjl-2025-wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime</span>,
    <span>author</span> = <span>{Eric J. Ma}</span>,
    <span>title</span> = <span>{Wicked Python trickery - dynamically patch a Python function's source code at runtime}</span>,
    <span>year</span> = <span>{2025}</span>,
    <span>month</span> = <span>{08}</span>,
    <span>day</span> = <span>{23}</span>,
    <span>howpublished</span> = <span>{\url{https://ericmjl.github.io}}</span>,
    <span>journal</span> = <span>{Eric J. Ma's Blog}</span>,
    <span>url</span> = <span>{https://ericmjl.github.io/blog/2025/8/23/wicked-python-trickery-dynamically-patch-a-python-functions-source-code-at-runtime}</span>,
}
  </span></span></pre>
    </div>

    

    
    <hr>
    <p>
      <i>I send out a newsletter with tips and tools
        for data scientists. Come check it out at
        <a href="https://dspn.substack.com/">Substack</a>.</i>
    </p>
    <p>
      <i><span>If you would like to sponsor the coffee that goes into making my posts,
        please consider </span>
        <a href="https://github.com/sponsors/ericmjl">GitHub Sponsors</a>!</i>
    </p>
    <p>
      <i><span>Finally, I do free 30-minute GenAI strategy calls for teams
        that are looking to leverage GenAI for maximum impact. Consider </span>
        <a href="https://calendly.com/ericmjl/llm-chat">booking a call on Calendly</a>
        if you're interested!</i>
      
    </p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Clearcam – Add AI object detection to your IP CCTV cameras (157 pts)]]></title>
            <link>https://github.com/roryclear/clearcam</link>
            <guid>45003420</guid>
            <pubDate>Sun, 24 Aug 2025 11:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/roryclear/clearcam">https://github.com/roryclear/clearcam</a>, See on <a href="https://news.ycombinator.com/item?id=45003420">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">clearcam</h2><a id="user-content-clearcam" aria-label="Permalink: clearcam" href="#clearcam"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Turn your RTSP enabled camera or old iPhone into a state of the art AI Security Camera</h2><a id="user-content-turn-your-rtsp-enabled-camera-or-old-iphone-into-a-state-of-the-art-ai-security-camera" aria-label="Permalink: Turn your RTSP enabled camera or old iPhone into a state of the art AI Security Camera" href="#turn-your-rtsp-enabled-camera-or-old-iphone-into-a-state-of-the-art-ai-security-camera"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Now on the Apple App Store</h2><a id="user-content-now-on-the-apple-app-store" aria-label="Permalink: Now on the Apple App Store" href="#now-on-the-apple-app-store"></a></p>
<p dir="auto"><a href="https://apps.apple.com/app/clearcam/id6743237694" rel="nofollow">https://apps.apple.com/app/clearcam/id6743237694</a></p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/roryclear/clearcam/blob/main/images/server.PNG"><img src="https://github.com/roryclear/clearcam/raw/main/images/server.PNG" alt="Front" width="400"></a>
  &nbsp;&nbsp;&nbsp;
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/roryclear/clearcam/blob/main/images/front.PNG"><img src="https://github.com/roryclear/clearcam/raw/main/images/front.PNG" alt="Server" width="400"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">video demo:</h2><a id="user-content-video-demo" aria-label="Permalink: video demo:" href="#video-demo"></a></p>
<p dir="auto"><a href="https://x.com/RoryClear/status/1959249250811785405" rel="nofollow">https://x.com/RoryClear/status/1959249250811785405</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">install and run NVR + inference with homebrew</h2><a id="user-content-install-and-run-nvr--inference-with-homebrew" aria-label="Permalink: install and run NVR + inference with homebrew" href="#install-and-run-nvr--inference-with-homebrew"></a></p>
<ol dir="auto">
<li>brew tap roryclear/tap</li>
<li>brew install clearcam</li>
<li>clearcam</li>
<li>(optional) enter your Clearam premium userID (viewable in iOS app) to receive streams and notifications</li>
<li>open localhost:8080 in your browser</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">run NVR + inference in python (from source)</h2><a id="user-content-run-nvr--inference-in-python-from-source" aria-label="Permalink: run NVR + inference in python (from source)" href="#run-nvr--inference-in-python-from-source"></a></p>
<ol dir="auto">
<li>pip install -r requirements.txt</li>
<li>python3 clearcam.py</li>
<li>(optional) enter your Clearam premium userID (viewable in iOS app) to receive streams and notifications</li>
<li>open localhost:8080 in your browser</li>
</ol>
<ul dir="auto">
<li>use BEAM=2 python3 clearcam.py for extra performance (wait time on first run)</li>
<li>use --yolo_size={s, m, l, or x for larger yolov8 variants}</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">python requirements</h2><a id="user-content-python-requirements" aria-label="Permalink: python requirements" href="#python-requirements"></a></p>
<ul dir="auto">
<li>ffmpeg</li>
<li>tinygrad</li>
<li>numpy</li>
<li>cv2</li>
<li>scipy</li>
<li>lap</li>
<li>cython_bbox</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">install ios from source</h2><a id="user-content-install-ios-from-source" aria-label="Permalink: install ios from source" href="#install-ios-from-source"></a></p>
<ol dir="auto">
<li>git clone <a href="https://github.com/roryclear/clearcam.git">https://github.com/roryclear/clearcam.git</a></li>
<li>open ios/clearcam.xcodeproj</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">iOS requirements</h2><a id="user-content-ios-requirements" aria-label="Permalink: iOS requirements" href="#ios-requirements"></a></p>
<ul dir="auto">
<li>iOS 15 or newer</li>
<li>iPhone SE (1st gen) or newer (older iPhones <em>might</em> work)</li>
<li>dependencies: NONE!</li>
</ul>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/roryclear/clearcam/blob/main/images/browser_playback.PNG"><img src="https://github.com/roryclear/clearcam/raw/main/images/browser_playback.PNG" alt="Screenshot"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Signing Up for Clearcam Premium</h2><a id="user-content-signing-up-for-clearcam-premium" aria-label="Permalink: Signing Up for Clearcam Premium" href="#signing-up-for-clearcam-premium"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>View your live camera feeds remotely.</li>
<li>Receive notifications on events (objects/people detected).</li>
<li>View event clips remotely.</li>
<li>End-to-end encryption on all data.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Sign Up on Android</h2><a id="user-content-how-to-sign-up-on-android" aria-label="Permalink: How to Sign Up on Android" href="#how-to-sign-up-on-android"></a></p>
<p dir="auto">Sign ups on android are not yet supported.<br>
In the meantime, please refer to the <a href="#how-to-sign-up-on-ios">How to Sign Up on iOS</a> section and use the user ID on android.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to Sign Up on iOS</h2><a id="user-content-how-to-sign-up-on-ios" aria-label="Permalink: How to Sign Up on iOS" href="#how-to-sign-up-on-ios"></a></p>
<ol dir="auto">
<li><strong>Install Clearcam</strong> from the App Store.</li>
<li>Open the app and go to <strong>Settings</strong>.</li>
<li>Tap <strong>Upgrade to Premium</strong>.</li>
<li>Complete the payment using the App Store’s secure checkout.</li>
<li>After upgrading, return to <strong>Settings</strong> in Clearcam.</li>
<li>Locate your <strong>User ID</strong> — you’ll use this to log in on any device, including Android.</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A German ISP tampered with their DNS – specifically to sabotage my website (705 pts)]]></title>
            <link>https://lina.sh/blog/telefonica-sabotages-me</link>
            <guid>45003033</guid>
            <pubDate>Sun, 24 Aug 2025 10:27:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lina.sh/blog/telefonica-sabotages-me">https://lina.sh/blog/telefonica-sabotages-me</a>, See on <a href="https://news.ycombinator.com/item?id=45003033">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
                <p>One of Germany's biggest ISPs changed how their DNS works, right after I exposed an organization that they’re part of.</p>
            </section><article>
                <h2>My website: Publishing Germany's secret internet blocklist</h2>
<p>In Germany, we have the <em>Clearingstelle Urheberrecht im Internet</em> (CUII) - literally 'Copyright Clearinghouse for the Internet', 
a private organization that decides what websites to block, corporate interests rewriting our free internet.
No judges, no transparency, just a bunch of ISPs and major copyright holders deciding what your eyes can see.<br>
I decided to create a website, <a href="https://cuiiliste.de/">cuiiliste.de</a>, to find blocked domains, as the CUII refuses to publish such a list.
To read more about the CUII, check out <a href="https://lina.sh/blog/exposing-the-cuii">one of my previous blog posts</a>. Germany's four biggest ISPs 
(Telekom, Vodafone, 1&amp;1 and Telefonica (o2)) are all part of the CUII.</p>
<h2>Yet another slip-up by the CUII</h2>
<p>This week, Netzpolitik.org published an article about the CUII's latest blunder<sup id="fnref:1"><a href="#fn:1">1</a></sup>, based on information I gathered. 
They managed to block domains that no longer even existed: websites that had already been seized and taken offline when they were blocked.
It's not the first time the CUII has tripped over its own feet, and this mistake likely didn’t sit well with them.
In the past, it was <em>really</em> easy to find out if a domain was blocked by the CUII.
If you asked an ISP's DNS server (basically the internet's phone book) for a site and got a CNAME to <code>notice.cuii.info</code>, you knew it was blocked.<br>
What this basically means in case you're not a tech nerd:<br>
You can check the phone book of an ISP (the "DNS server") where to find a website, and you'd receive a note saying "This site is blocked by the CUII" if the page is blocked.
Automating this was simple, I could basically just ask "Hey, where can I find this site?" and immediately knew if it was blocked.
The CUII apparently did <em>not</em> like the fact that it was so easy for me to check if a domain was blocked. They want to keep their list secret.<br>
ISPs like Telekom, 1&amp;1 and Vodafone actually all stopped using this response a few months ago, 
after older articles about the CUII's past failures were published. Instead, they started pretending that blocked sites didn't exist at all.
Straight up erasing entries from the phone book. You could not tell if a site was blocked or just didn't exist.
Telefonica (the parent company of for example o2, Germany's <strong>fourth-biggest ISP</strong><sup id="fnref:2"><a href="#fn:2">2</a></sup>), apparently didn't get this memo, and they still used <code>notice.cuii.info</code> in their DNS responses.  </p>
<p>On cuiiliste.de, anyone can enter a domain, and see if it is blocked by the CUII, and which ISPs block it specifically.</p>
<h3>I get a new visitor</h3>
<p>Telefonica modified their DNS servers, specifically saying that <code>blau-sicherheit.info</code> was blocked by the CUII.
At 11:06 AM last Friday, someone from Telefonica's network checked if <code>blau-sicherheit.info</code> was blocked on my site. 
The twist? Telefonica seems to own this domain. Blau is one of their brands<sup id="fnref:3"><a href="#fn:3">3</a></sup>, and <code>blau-sicherheit.info</code> wasn’t some piracy hub -
it appears to be a test domain of theirs. 
My tool flagged it as blocked because Telefonica's DNS servers said so. 
Why would they block their own domain?</p>
<p><a href="https://lina.sh/assets/blog/blau-sicherheit-probe.png" target="_blank"><img alt="Telefonica's DNS response" src="https://lina.sh/assets/blog/blau-sicherheit-probe.png"></a>
To recap:</p>
<ul>
<li> Telefonica blocks their own domain</li>
<li> Someone from Telefonica visits my website to check if I detect this</li>
<li> I <i>do</i> in fact detect this</li>
</ul>
<h3>Telefonica modifies how their blocking works... to mess specifically with my website</h3>
<p>Two hours after this suspicious query, I was bombarded with Notifications. 
My program thought that the CUII had suddenly unblocked hundreds of domains.<br>
The reason: Telefonica had altered their DNS servers to stop redirecting blocked domains to <code>notice.cuii.info</code>.
Now they pretend that the domain doesn't exist at all, after they <em>specifically</em> blocked their own domain, likely to find out how my website works.<br>
I had to spend my entire Friday afternoon fixing this mess, and now everything is fully operational again.
<a href="https://lina.sh/assets/blog/git-pull.png" target="_blank"><img alt="Git pull" src="https://lina.sh/assets/blog/git-pull.png"></a>
The fix worked, but there’s a catch: without the <code>notice.cuii.info</code> redirect, it's harder to confirm if a block is actually the CUII's doing. 
Sometimes ISPs block sites for other reasons, like terrorism content (<a href="https://lina.sh/blog/german-isps-block-terrorist-content">I wrote about that too</a>). 
I try to compensate this by cross-checking domains against a list of known non-CUII-blocks.
<a href="https://lina.sh/assets/blog/almanar-blocked.png" target="_blank"><img alt="Probing a site blocked by ISPs, but not by the CUII" src="https://lina.sh/assets/blog/almanar-blocked.png"></a></p>
<h3>Why sabotage my website?</h3>
<p>The timing is more than suspicious. 
Right after Netzpolitik’s article exposed the CUII for blocking non-existent domains, they make it harder to track their mistakes. 
Coincidence? Or a move to bury future slip-ups? 
We can only speculate.
Regardless of intent, the result is the same: less transparency and harder oversight. And that benefits the CUII, not the public.  </p>
<p>In this context, Netzpolitik.org released another article (German): 
<a href="https://netzpolitik.org/2025/netzsperren-provider-verstecken-welche-domains-sie-sperren/">Netzpolitik.org: Provider verstecken, welche Domains sie sperren</a></p>
<h3>Sources</h3>

            </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US halts work on almost finished wind farm because national security (106 pts)]]></title>
            <link>https://www.npr.org/2025/08/23/nx-s1-5513919/trump-stops-offshore-wind-renewable-energy</link>
            <guid>45002747</guid>
            <pubDate>Sun, 24 Aug 2025 09:23:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2025/08/23/nx-s1-5513919/trump-stops-offshore-wind-renewable-energy">https://www.npr.org/2025/08/23/nx-s1-5513919/trump-stops-offshore-wind-renewable-energy</a>, See on <a href="https://news.ycombinator.com/item?id=45002747">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-84954">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/900/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1200/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/900/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1200/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/5786x3857+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fb6%2Faa%2F10fd41f4471693bc183be3012ec6%2Fap25212463742062.jpg" alt="Offshore wind blades and other equipment in New London, Conn. President Trump is a longtime critic of the wind industry." fetchpriority="high">
        </picture>
</div>
<div>
    <div>
        <p>
                Offshore wind blades and other equipment in New London, Conn. President Trump is a longtime critic of the wind industry.
                <b aria-label="Image credit">
                    
                    Seth Wenig/AP
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Seth Wenig/AP
        
    </span>
</p></div>
   </div>
   <p>The Trump administration has ordered companies to stop construction of a wind farm that's being built off the coast of Rhode Island.</p>   <p>The acting director of the Bureau of Ocean Energy Management, Matthew Giacona, <a href="https://www.boem.gov/sites/default/files/documents/renewable-energy/Director%26%23039%3BsOrder-20250822.pdf?VersionId=VO3AWAHsV_kDvT048xf8dG7A.Rsj6HZJ" target="_blank"><u>wrote in a letter</u></a> to one of the developers, a Danish firm called Ørsted, that the government was halting work on the almost-finished project in order to "address concerns related to the protection of national security interests of the United States." The project is also being developed by Global Infrastructure Partners.</p>   <p>The order to stop work on the Revolution Wind project is the latest move by the Trump administration targeting the country's renewable energy industry. President Trump, a longtime critic of the wind industry, in January <a href="https://www.whitehouse.gov/presidential-actions/2025/01/temporary-withdrawal-of-all-areas-on-the-outer-continental-shelf-from-offshore-wind-leasing-and-review-of-the-federal-governments-leasing-and-permitting-practices-for-wind-projects/" target="_blank"><u>issued a moratorium</u></a> on new development of offshore wind projects. The Internal Revenue Service <a href="https://www.nytimes.com/2025/08/15/climate/irs-wind-solar-tax-credits.html" target="_blank"><u>recently put out new guidance</u></a> that makes it harder for companies building wind and solar projects to qualify for federal tax incentives. And the <a href="https://public-inspection.federalregister.gov/2025-16191.pdf?utm_campaign=pi+subscription+mailing+list&amp;utm_medium=email&amp;utm_source=federalregister.gov" target="_blank"><u>Commerce Department is investigating</u></a> whether imports of wind turbines and their components threaten national security.</p>   
   <p>Ørsted <a href="https://orsted.com/en/company-announcement-list/2025/08/revolution-wind-receives-offshore-stop-work-order--145387701" target="_blank"><u>said in a statement</u></a> that it is "evaluating all options to resolve the matter expeditiously," including legal action.</p>   <p><a href="https://revolution-wind.com/" target="_blank"><u>Revolution Wind</u></a> is located in federal waters 15 miles south of Rhode Island. Construction started in 2023, and the project has been slated to begin sending power to homes and businesses in Rhode Island and Connecticut starting next year.</p>   <p>"Any pause or uncertainty at this stage could ripple across jobs, contracts, and communities already benefiting from the project," Erik Milito, president of the National Ocean Industries Association, a trade group whose members include wind project developers as well as oil and gas companies, <a href="https://www.noia.org/noia-statement-on-revolution-wind/" target="_blank"><u>said in a statement</u></a>.</p>   <p>"Today, the U.S. has only one fully operational large-scale offshore wind project producing power," Milito said. "That is not enough to meet America's rising energy needs. We need more energy of all types, including oil and gas, wind, and new and emerging technologies."</p>   <p>The Bureau of Ocean Energy Management didn't respond to messages seeking comment.</p>   <p>Industry <a href="https://www.npr.org/2025/07/15/nx-s1-5461128/congress-energy-tax-credit-solar-wind" target="_blank"><u>analysts have said</u></a> that limiting renewable energy development amid rising electricity demand threatens to drive up power prices across the country.</p>   <p>"This is not the first time extreme partisan politics has derailed sound energy policy," Jason Grumet, chief executive of American Clean Power, an industry group, <a href="https://cleanpower.org/news/acp-statement-on-revolution-wind-stop-work-order/" target="_blank"><u>said in a statement</u></a> responding to the Trump administration's stop-work order to Revolution Wind. "The unfortunate message to investors is clear: the U.S. is no longer a reliable place for long-term energy investments."</p>   
   <p>In April, the Interior Department <a href="https://www.npr.org/2025/04/17/nx-s1-5367582/trump-new-york-wind-energy-offshore" target="_blank"><u>halted work</u></a> on an offshore wind project near the coast of Long Island. Interior Secretary Doug Burgum <a href="https://chrissmith.house.gov/uploadedfiles/trump_admin_dept_of_interior_empire_wind_memo_signed_by_secretary_burgum_april_16_2025.pdf" target="_blank"><u>wrote in a letter</u></a> to the Bureau of Ocean Energy Management at the time that approval of the project, called Empire Wind, "was rushed through by the prior administration without sufficient analysis."</p>   <p>Construction on Empire Wind <a href="https://www.equinor.com/news/20250519-empire-wind-project-resumes-construction" target="_blank"><u>resumed in May</u></a> when the Trump administration lifted the stop-work order. But the disruption was costly for the project's developer, a Norwegian company called Equinor. The firm recently <a href="https://www.reuters.com/sustainability/climate-energy/blaming-trump-equinor-books-955-million-us-offshore-wind-writedown-2025-07-23/" target="_blank"><u>cut the value of its investment</u></a> by almost $1 billion, mainly because of "the changes in regulations for future offshore wind projects in the U.S.," Torgrim Reitan, Equinor's chief financial officer, <a href="https://cdn.equinor.com/files/h61q9gi9/global/4b850b0ef0024c18d08f28291c12e181a1bb7f96.pdf?eqnr-osl-transcript-2025-07-23.pdf" target="_blank"><u>said on an earnings call in July</u></a>.</p>   <p>"For the second time, the Trump Administration has taken unlawful action against a fully permitted offshore wind project under active construction — this time one that is nearly 80% complete," Liz Burdock, chief executive of the Oceantic Network, an advocacy group for offshore wind, <a href="https://oceantic.org/press-releases/oceantic-statement-unlawful-stop-order-threatens-american-jobs-energy-dominance/" target="_blank"><u>said in a statement</u></a> about the Revolution Wind project.</p>   <p>"This dramatic action further erodes investor confidence in the U.S. market across all industries and undermines progress on shared national priorities — shipyard revitalization, steel and port investments, and energy dominance," Burdock said. "In fact, halting work on Revolution Wind will drive up energy costs for consumers, idle Gulf Coast vessel operators that have invested hundreds of millions of dollars in new or retrofitted vessels, and jeopardize the livelihoods of union workers."</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Turning Claude Code into My Best Design Partner (201 pts)]]></title>
            <link>https://betweentheprompts.com/design-partner/</link>
            <guid>45002315</guid>
            <pubDate>Sun, 24 Aug 2025 08:06:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://betweentheprompts.com/design-partner/">https://betweentheprompts.com/design-partner/</a>, See on <a href="https://news.ycombinator.com/item?id=45002315">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>When I first started using Claude Code, I had a naive approach to working with it. I would describe the task directly in the prompt, press Enter, and cross my fingers. If the agent made mistakes, I would tell it how to fix them. For small tasks, this can be good enough, but as the task grows in complexity, this approach reveals several significant drawbacks.</p><h2 id="when-simple-doesnt-scale">When Simple Doesn’t Scale</h2><p>The first problem is that the conversation becomes the only source of truth about the task. This means a new message can override instructions from an old one, but it isn’t always clear when this happens, which can cause mistakes by the agent.</p><p>Additionally, the context size for the agent is limited. The more the conversation grows, the more information from the beginning can be “forgotten,” even though Claude Code has a capacity for “compacting” the conversation that’s supposed to improve this issue.</p><p>For these reasons, I started experimenting with an approach I’d heard about: asking Claude Code to start by writing a plan document. This document becomes the source of truth instead of a sprawling conversation. When I find the plan document good enough, I’ve taken the habit of clearing the conversation to start fresh with just the plan as context.</p><h2 id="creating-the-initial-plan">Creating the Initial Plan</h2><p>My first prompt is usually to give Claude Code a description of the feature it should implement (or bug it should fix, or the refactoring it should do) with all the details I have in mind. If I already have an idea of the implementation, I can give it some pointers to existing files for reference. However, I try not to give it too many implementation instructions because I want it to make suggestions and contribute to the design process.</p><blockquote><p>I want to implement a query builder. The page will be displayed as two columns. In the first one, a first box will let the user select a view (for now only one view: “Volume Metrics”), a second box to select fields (“field 1”, “field 2”, “field 3”), and a third one to add filters (don’t fill it yet). The right column will display first the query as human readable, then a table with the query results. (to be continued)</p></blockquote><p>I also try to refer to existing plans for features implemented previously. I don’t have a formal template, but I don’t really need one as long as I have other plans to reference as examples.</p><blockquote><p>(continuing) Check out the previous plan in @plans/chat-playground.md to know about routing and architecture details. (to be continued)</p></blockquote><p>I expect to see several key elements in the document. First, a rephrasing of the feature description I gave it, which helps ensure we’re aligned on requirements. Second, details on how the feature will be implemented—usually it includes some pieces of code or pseudo-code without me having to tell it to do so. Finally, commands to run to make sure the code quality is acceptable, including type checking, linting, and tests.</p><blockquote><p>(continuing) Write a plan in @plans/query-builder.md, and let me validate it before starting the implementation.</p></blockquote><h2 id="the-collaborative-design-process">The Collaborative Design Process</h2><p>Sometimes, I’m not satisfied with the suggested implementation. In this case, instead of updating the plan, I tell it why it’s wrong, expecting it to change its approach.</p><blockquote><p>The page should be a subroute of /explore, not /review. Also, it should be accessible only to users with the “admin” role.</p></blockquote><p>It also happens that after a few back-and-forth exchanges, I realize the first suggested approach was better than the one I had in mind. This process is much more efficient than if I had started writing the code by myself and realized my approach was wrong later.</p><p>It’s a bit like discussing the plan with a colleague each time I’m about to start a new feature. More specifically, it’s like challenging my implementation plan with a junior colleague (or one who doesn’t know the codebase as well) who will question my choices. The dynamic reminds me of the rubber duck debugging technique, where explaining your approach helps you think through problems. However, it won’t suggest a radically different approach unless I specifically ask it to, which I have never tried.</p><p>But the plan document isn’t just a blueprint for the implementation. I discovered that Claude Code is much more efficient when it considers it as a living document.</p><h2 id="the-living-document-approach">The Living Document Approach</h2><p>The key insight is that I don’t just ask Claude Code to write the plan—I also ask it to make it a living document while implementing the feature. I explicitly ask it to update the plan during implementation because the implementation process, and especially the type checking, linting, or test processes, can reveal that some parts of the original plan were incorrect.</p><p>I’ve developed the habit of asking it to check that the plan is up to date each time it commits code, treating plan updates the same way as running quality checks.</p><blockquote><p>Make sure the plan is up to date, and commit changes.</p></blockquote><p>This living document approach solves a fundamental problem with AI development: context limits. With an up-to-date plan document, I can start a fresh conversation and simply ask Claude Code to continue the implementation. This usually works great—just the document is usually enough context for a new session to pick up exactly where the previous one left off.</p><blockquote><p>Continue the implementation documented in @plans/query-builder.md.</p></blockquote><h2 id="my-review-process">My Review Process</h2><p>When the implementation starts, I review changes along the way to ensure everything is progressing correctly. However, if I’m satisfied with the progress, I can let it continue without checking as often. When reviewing the final code, the updated plan document gives me helpful hints about the technical choices that were made during implementation.</p><p>Surprisingly, I think that the fact that I need to plan my features carefully before rushing into implementation is making me a better developer overall. This happens simply because it forces me to document the implementation and think it through before jumping into code. I also find myself explaining my reasoning more clearly because I have to write it down for the AI, whereas with colleagues I would typically discuss things in person or via video call.</p><h2 id="from-chaos-to-system">From Chaos to System</h2><p>This workflow systematically addresses the fundamental problems I encountered with the naive approach: it creates a clear source of truth, eliminates context limit issues, and forces better architectural thinking. The living document becomes both the specification and the implementation log, creating a complete record of not just what was built, but why and how it was built.</p><p>The result is a development process that’s more thoughtful, more documented, and more reliable.</p><p>AI isn’t just serving as implementer.</p><p>It becomes a collaborative design partner.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Valve Software handbook for new employees [pdf] (2012) (220 pts)]]></title>
            <link>https://cdn.akamai.steamstatic.com/apps/valve/Valve_NewEmployeeHandbook.pdf</link>
            <guid>45002301</guid>
            <pubDate>Sun, 24 Aug 2025 08:02:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cdn.akamai.steamstatic.com/apps/valve/Valve_NewEmployeeHandbook.pdf">https://cdn.akamai.steamstatic.com/apps/valve/Valve_NewEmployeeHandbook.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=45002301">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Seed: Interactive software environment based on Common Lisp (105 pts)]]></title>
            <link>https://github.com/phantomics/seed</link>
            <guid>45001979</guid>
            <pubDate>Sun, 24 Aug 2025 06:57:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/phantomics/seed">https://github.com/phantomics/seed</a>, See on <a href="https://news.ycombinator.com/item?id=45001979">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><h2 tabindex="-1" dir="auto">Seed</h2><a id="user-content-seed" aria-label="Permalink: Seed" href="#seed"></a></p>

<p dir="auto">Seed is an interactive software environment. With it you can create and use computer programs in many ways. It is based on the Common Lisp language and runs inside the Web browser, allowing you to build software on a local or remote computer system, and it can present programs and their output using a wide variety of display modes. Seed depicts programs in the form of a tree grid, featuring glyphs that denote different functions and types of data. All of Seed's display modes share basic interface principles in common, so you can quickly feel at home with whatever way your program is presented.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Background</h2><a id="user-content-background" aria-label="Permalink: Background" href="#background"></a></p>
<p dir="auto">The Lisp family of programming languages offer unmatched flexibility in defining software, but this flexibility is not matched by the character strings most often used to express that software. Computer programs have hitherto been widely regarded as inextricable from and synonymous with character strings like the one you're reading now. While visual programming paradigms have made headway in a number of areas, most visual programming tools are tightly coupled to particular domains.</p>
<p dir="auto">The choice of Lisp's creators to forego a detailed syntax in favor of symbolic expressions marked a turn down a road less traveled by language developers. Users may be confused by the sometimes homogenous, sometimes verbose nature of Lisp code, but the problem in these cases is not a shortcoming of Lisp -- it is a shortcoming of character strings. In the choice of a regular syntax for the language, Lisp was set on a path that could lead to programming beyond the limits of plain text. Seed is an effort to realize that destination: a language representation orthogonal to the language's structure.</p>
<p dir="auto">These ideas are the foundation of Seed. Your experience with the system will determine their truth.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">In Practice</h2><a id="user-content-in-practice" aria-label="Permalink: In Practice" href="#in-practice"></a></p>
<p dir="auto">Seed can be seen as a type of IDE. It integrates ASDF, the standard Common Lisp build system, and the software systems it's used to develop are often expressed as ASDF systems. These systems are divided into branches, each of which expresses input to and output from the system. In a given Seed system, there is typically a .seed file located in the package directory that specifies the system and the behavior of each branch.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">The First Step: Installing and Running Seed</h2><a id="user-content-the-first-step-installing-and-running-seed" aria-label="Permalink: The First Step: Installing and Running Seed" href="#the-first-step-installing-and-running-seed"></a></p>
<p dir="auto">Seed depends on Common Lisp, ASDF and Quicklisp. The only Common Lisp implementation tested so far has been Steel Bank Common Lisp (SBCL). Seed also requires Node.js, NPM and Gulp to build parts of its Web interface. Install the required software if you don't have it, then clone this repository.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Setting up Node.js and NPM</h3><a id="user-content-setting-up-nodejs-and-npm" aria-label="Permalink: Setting up Node.js and NPM" href="#setting-up-nodejs-and-npm"></a></p>
<p dir="auto">If you don't have Node.js installed, you can follow one of these links to set Node.js up on your system.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/creationix/nvm">Node Version Manager (nvm), a tool to install Node.js</a></p>
</li>
<li>
<p dir="auto"><a href="https://github.com/nodesource/distributions">Node.js packages for popular Linux distributions</a></p>
</li>
<li>
<p dir="auto"><a href="https://nodejs.org/en/download/" rel="nofollow">Node.js installers for Mac, Windows and binaries for Linux, plus source code</a></p>
</li>
</ul>
<p dir="auto">Of the above choices, the first option to install Node.js using nvm is probably the best, since nvm makes it easy to install Node.js in a way that doesn't require administrator-level privileges on the system.</p>
<p dir="auto">Once you have Node.js installed, you can install Gulp by running the command:</p>

<p dir="auto">If you installed Node using the second or third option above, you will probably need administrator-level permissions to do this, so on Linux and OSX the full command will most likely be:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Preparing Quicklisp</h3><a id="user-content-preparing-quicklisp" aria-label="Permalink: Preparing Quicklisp" href="#preparing-quicklisp"></a></p>
<p dir="auto">Enter your Quicklisp local-projects directory (usually ~/quicklisp/local-projects) and create a symbolic link to the directory where you cloned the Seed repository. For example, if you cloned the repo to ~/mystuff/seed and your Quicklisp directory is ~/quicklisp/, enter:</p>
<div data-snippet-clipboard-copy-content="cd ~/quicklisp/local-projects
ln -s ~/mystuff/seed"><pre><code>cd ~/quicklisp/local-projects
ln -s ~/mystuff/seed
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Using the automatic installer</h3><a id="user-content-using-the-automatic-installer" aria-label="Permalink: Using the automatic installer" href="#using-the-automatic-installer"></a></p>
<p dir="auto">Seed comes with an installation program called, appropriately enough, install-seed.lisp. To use it, enter the Seed repository directory and load the install-seed.lisp file using your Common Lisp implementation. For example, if you are using SBCL, type:</p>
<div data-snippet-clipboard-copy-content="sbcl --load install-seed.lisp"><pre><code>sbcl --load install-seed.lisp
</code></pre></div>
<p dir="auto">This should automatically set Seed up, install its dependencies and build the components of the browser interface. If there are problems it will display error messages that should help with fixing them. If this doesn't work, you should try...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installing Seed manually</h3><a id="user-content-installing-seed-manually" aria-label="Permalink: Installing Seed manually" href="#installing-seed-manually"></a></p>
<p dir="auto">To complete the installation manually, start a Common Lisp REPL and enter:</p>

<p dir="auto">This will build Seed and install the software it needs to run. As long as you have Node, NPM and Gulp installed, the Javascript and CSS required to run the Seed interface should be automatically built.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Starting Seed automatically</h3><a id="user-content-starting-seed-automatically" aria-label="Permalink: Starting Seed automatically" href="#starting-seed-automatically"></a></p>
<p dir="auto">From now on, if you'd like to automatically start Seed whenever you run SBCL, you can edit your .sbclrc file (usually located at ~/.sbclrc) and add the lines:</p>
<div data-snippet-clipboard-copy-content="(asdf:load-system 'seed)
(seed:contact-open)"><pre><code>(asdf:load-system 'seed)
(seed:contact-open)
</code></pre></div>
<p dir="auto">The contact-open method will open Seed's Web interface at the designated HTTP port. If you would prefer not to automatically open the Web interface when you start Common Lisp, you can omit the (seed:contact-open) line above.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Web interface</h3><a id="user-content-the-web-interface" aria-label="Permalink: The Web interface" href="#the-web-interface"></a></p>
<p dir="auto">Once opened, Seed's web interface will be located at port 8055 by default; if you wish to change that, just edit seed.lisp in the main Seed directory.</p>
<p dir="auto">To visit the Web interface for the default portal "portal.demo1", which comes included with Seed, visit the URI:</p>
<div data-snippet-clipboard-copy-content="http://localhost:8055/portal.demo1/index.html"><pre><code>http://localhost:8055/portal.demo1/index.html
</code></pre></div>
<p dir="auto">If you create another portal, substitute that portal's name in the URI.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/phantomics/seed/wiki/Introductory-Tutorial">Tutorial</a></h3><a id="user-content-tutorial" aria-label="Permalink: Tutorial" href="#tutorial"></a></p>
<p dir="auto"><a href="https://github.com/phantomics/seed/wiki/Introductory-Tutorial">Follow this link</a> for a tutorial to help you get started using Seed.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Credit</h3><a id="user-content-credit" aria-label="Permalink: Credit" href="#credit"></a></p>
<p dir="auto">Seed contains a modified copy of Panic, a utility for building React components written by Michael J. Forster. Thanks to Michael for creating this tool.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It is worth it to buy the fast CPU (191 pts)]]></title>
            <link>https://blog.howardjohn.info/posts/buy-a-cpu/</link>
            <guid>45001778</guid>
            <pubDate>Sun, 24 Aug 2025 06:03:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.howardjohn.info/posts/buy-a-cpu/">https://blog.howardjohn.info/posts/buy-a-cpu/</a>, See on <a href="https://news.ycombinator.com/item?id=45001778">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<article>
   
  <div><p>In the past few years, CPUs have gotten really fast. Shockingly fast!
Yet most people are stuck on previous generation mobile chips (whether by choice, or by their companies choice), at a huge detriment to their productivity.</p>
<p>Meanwhile, AI coding subscriptions like Cursor are all the rage these days.
I'll skip the debate on exactly how useful these tools are, and focus on the pricing.
Cursor is $480/year for the team plan (the cheapest corporate plan), and other providers are around the same, setting a clear price point: engineering productivity is worth at least $500/year.</p>
<p>This makes sense, as given the typical salary of a senior (US-based) software engineer, you don't even need to be 1% more efficient for that investment to pay off.</p>
<p>Meanwhile, <em>the</em> top end CPU, AMD Ryzen 9 9950X, is only $500. Practically speaking it will last longer, but I believe typically corporations amortize the cost of development machines over 3 years putting it at only $170/year - a bargain compared to AI!.</p>
<p><strong>Buy the fast CPU!</strong> It is well worth it.</p>
<p>Below shows some benchmarks for 3 machines:</p>
<ul>
<li>The fastest laptop my former employee would give me in 2024 (i7-1165G7, released in 2020; my employer clearly didn't follow my advice to give engineers top end CPUs!).</li>
<li>The fastest ThinkPad I could buy in 2024 (AMD Ryzen 7840U).</li>
<li>The fastest desktop CPU I could buy in 2025 (AMD Ryzen 9950x).</li>
</ul>
<figure>
  
  <img src="https://blog.howardjohn.info/images/perf-linux-compile.png#center" alt="Compile times for Linux Kernel">
  
  <figcaption>Compile times for Linux Kernel</figcaption>
</figure>

<figure>
  
  <img src="https://blog.howardjohn.info/images/perf-ssl.png#center" alt="TLS operations benchmark">
  
  <figcaption>TLS operations benchmark</figcaption>
</figure>

<p>The gap is incredible -- over a 10x difference in many cases!
The difference between waiting 3s for a build vs 30s is game-changing, as is the difference between 3s and 300ms.</p>
<p>As a general rule of thumb I have seen:</p>
<ul>
<li>Desktop CPUs are about 3x faster than laptop CPUs</li>
<li>Top end CPUs are about 3x faster than the comparable top end models 3 years ago</li>
<li>This applies to cloud VMs as well; each new generations are 2-3x faster for many workloads and usually the same price!</li>
</ul>
<p>If you can justify an AI coding subscription, you can justify buying the best tool for the job.</p>


  </div>

  

</article>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to build a coding agent (402 pts)]]></title>
            <link>https://ghuntley.com/agent/</link>
            <guid>45001051</guid>
            <pubDate>Sun, 24 Aug 2025 03:21:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ghuntley.com/agent/">https://ghuntley.com/agent/</a>, See on <a href="https://news.ycombinator.com/item?id=45001051">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <div><p>😎</p><p>The following was developed last month and has already been delivered at two conferences. If you would like for me to run a workshop similar to this at your employer, please <a href="https://ghuntley.com/workshops/" rel="noreferrer">get in contact</a>.</p></div><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent: A workshop that teaches you how to build your own coding agent. Similar to Roo code, Cline, Amp, Cursor, Windsurf or OpenCode.</p><p>A workshop that teaches you how to build your own coding agent. Similar to Roo code, Cline, Amp, Cursor, Windsurf or OpenCode. - ghuntley/how-to-build-a-coding-agent</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-23.svg" alt=""><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent-2" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>workshop materials and source code for the workshop can be found here</span></p></figcaption></figure><p>Hey everyone, I'm here today to teach you how to build a coding agent.  By this stage of the conference, you may be tired of hearing the word "agent". </p><p>You hear the word frequently. However, it appears that everyone is using this term loosely without a clear understanding of what it means or how these coding agents operate internally. It's time to pull back the hood and show that there is no moat.</p><p>Learning how to build a coding agent is one of the best things you can do for your personal development in 2025, as it teaches you the fundamentals. Once you understand these fundamentals, you'll move from being a consumer of AI to a producer of AI who can automate things with AI.</p><p>Let me open with the following facts:</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.002.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.002.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.002.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.002.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.002.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>it's not that hard</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.003.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.003.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.003.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.003.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.003.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>to build a coding agent</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.004.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.004.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.004.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.004.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.004.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>it's 300 lines of code</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.005.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.005.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.005.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.005.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.005.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>running in a loop</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.006.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.006.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.006.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.006.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.006.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>With LLM tokens, that's all it is. </p><p>300 lines of code running in a loop with LLM tokens. You just keep throwing tokens at the loop, and then you've got yourself an agent.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.007.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.007.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.007.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.007.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.007.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Today, we're going to build one. We're going to do it live, and I'll explain the fundamentals of how it all works. As we are now in 2025, it has become the norm to work concurrently with AI assistance. So, what better way to demonstrate the point of this talk than to have an agent build me an agent whilst I deliver this talk? </p><figure data-kg-thumbnail="https://ghuntley.com/content/media/2025/08/Let-s-build-an-agent-AFK_thumb.jpg" data-kg-custom-thumbnail="https://ghuntley.com/content/images/2025/08/Screenshot-2025-08-24-125648.png">
            <div>
                <video src="https://ghuntley.com/content/media/2025/08/Let-s-build-an-agent-AFK.mp4" poster="https://img.spacergif.org/v1/1920x1080/0a/spacer.png" width="1920" height="1080" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:22</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://ghuntley.com/content/media/2025/08/Let-s-build-an-agent-AFK_thumb.jpg"></figure><p>Cool. We're now building an agent. This is one of the things that's changing in our industry, because work can be done concurrently and whilst you are away from your computer. </p><p>The days of spending a week or a couple of days on a research spike are now over because you can turn an idea into execution just by speaking to your computer. </p><p>The next time you're on a Zoom call, consider that you could've had an agent building the work that you're planning to do during that Zoom call. If that's not the norm for you, and it is for your coworkers, then you're naturally not going to get ahead.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.009.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.009.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.009.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.009.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.009.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>please build your own</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.010.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.010.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.010.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.010.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.010.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>as the knowledge</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.011.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.011.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.011.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.011.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.011.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>will transform you</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.012.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.012.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.012.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.012.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.012.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>from being a consumer</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.013.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.013.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.013.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.013.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.013.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>to a producer that can</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.014.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.014.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.014.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.014.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.014.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>automate things</span></figcaption></figure><p>The tech industry is almost like a conveyor belt - we always need to be learning new things. </p><p>If I were to ask you what a primary key is, you should know what a primary key is. That's been the norm for a long time.  </p><p>In 2024, it is essential to understand what a primary key is. </p><p>In 2025, you should be familiar with what a primary key is and how to create an agent, as knowing what this loop is and how to build an agent is now fundamental knowledge that employers are looking for in candidates before they'll let you in the door.</p><figure><a href="https://www.canva.dev/blog/engineering/yes-you-can-use-ai-in-our-interviews/?ref=ghuntley.com"><div><p>Yes, You Can Use AI in Our Interviews. In fact, we insist - Canva Engineering Blog</p><p>How We Redesigned Technical Interviews for the AI Era</p><p><img src="https://ghuntley.com/content/images/icon/apple-touch-180x180.b6aae4a9-3.webp" alt=""><span>canva.dev</span><span>Simon Newton</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/thumbnail.1c7590f6-3.png" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>As this knowledge will transform you from being a consumer of AI to being a producer of AI that can orchestrate your job function. Employers are now seeking individuals who can automate tasks within their organisation.</p><p>If you're joining me later this afternoon for the conference closing (see below), I'll delve a bit deeper into the above. </p><figure><a href="https://ghuntley.com/six-month-recap/"><div><p>the six-month recap: closing talk on AI at Web Directions, Melbourne, June 2025</p><p>Welcome back to our final session at WebDirections. We’re definitely on the glide path—though I’m not sure if we’re smoothly landing, about to hit turbulence, or perhaps facing a go-around. We’ll see how it unfolds. Today, I’m excited to introduce Geoffrey Huntley. I discovered Geoff earlier this year through</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-42.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/the-future-belongs-to-people-who-do-things.001-2.png" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>the conference closing talk</span></p></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.015.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.015.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.015.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.015.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.015.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Right now, you'll be somewhere on the journey above. </p><p>On the top left, we've got 'prove it to me, it's not real,' 'prove it to me, show me outcomes', 'prove it to me that it's not hype', and a bunch of 'it's not good enough' folks who get stuck up there on that left side of the cliff, completely ignoring that there are people on the other side of the cliff, completely automating their job function.</p><blockquote>In my opinion, any disruption or job loss related to AI is not a result of AI itself, but rather a consequence of a lack of personal development and self-investment. If your coworkers are hopping between multiple agents, chewing on ideas, and running in the background during meetings, and you're not in on that action, then naturally you're just going to fall behind.</blockquote><figure><a href="https://ghuntley.com/ngmi/"><div><p>What do I mean by some software devs are “ngmi”?</p><p>At “an oh fuck moment in time”, I closed off the post with the following quote. N period on from now, software engineers who haven’t adopted or started exploring software assistants, are frankly not gonna make it. Engineering organizations right now are split between employees who have had that “oh</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-45.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/fruits-2.png" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>don't be the person on the left side of the cliff.</span></p></figcaption></figure><p>The tech industry's conveyor belt continues to move forward. If you're a DevOps engineer in 2025 and you don't have any experience with AWS or GCP, then you're going to find it pretty tough in the employment market. </p><p>What's surprising to software and data engineers is just how fast this is elapsing. It has been eight months since the release of the first coding agent, and most people are still unaware of how straightforward it is to build one, how powerful this loop is, and its disruptive implications for our profession.</p><p>So, my name's Geoffrey Huntley. I was the tech lead for developer productivity at Canva, but as of a couple of months ago, I'm one of the engineers at Sourcegraph building <a href="https://ampcode.com/?ref=ghuntley.com" rel="noreferrer">Amp</a>. It's a small core team of about six people. We build AI with AI.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.016.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.016.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.016.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.016.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.016.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>ampcode.com</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.017.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.017.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.017.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.017.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.017.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>cursor</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.018.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.018.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.018.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.018.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.018.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>windsurf</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.019.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.019.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.019.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.019.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.019.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>claude code</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.020.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.020.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.020.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.020.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.020.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>github co-pilot</span></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.022.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.022.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.022.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.022.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.022.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>are lines of code running in a loop with LLM tokens</span></figcaption></figure><p>Cursor, Windsurf, Claude Code, GitHub Copilot, and Amp are just a small number of lines of code running in a loop of LLM tokens. I can't stress that enough. The model does all the heavy lifting here, folks. It's the model that does it all. </p><p>You are probably five vendors deep in product evaluation, right now, trying to compare all these agents to one another. But really, you're just chasing your tail. </p><p>It's so easy to build your own...</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.023.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.023.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.023.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.023.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.023.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>There are just a few key concepts you need to be aware of.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.024.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.024.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.024.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.024.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.024.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Not all LLMs are agentic. </p><p>The same way that you have different types of cars, like you've got a <a href="https://en.wikipedia.org/wiki/Toyota_Land_Cruiser_(J40)?ref=ghuntley.com">40 series</a> if you want to go off-road, and then you've also got people movers, which exist for transporting people. </p><p>The same principle applies to LLMs, and I've been able to map their behaviours into a quadrant. </p><blockquote>A model is either high safety, low safety, an oracle, or agentic. It's never both or all.</blockquote><p>If I were to ask you to do some security research, which model would you use? </p><p>That'd be Grok. That's a low safety model.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.025.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.025.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.025.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.025.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.025.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>If you want something that's "ethics-aligned", it's Anthropic or OpenAI. So that's high safety. Similarly, you have oracles. Oracles are on the polar opposite of agentic. Oracles are suitable for summarisation tasks or require a high level of thinking. </p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.026.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.026.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.026.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.026.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.026.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Meanwhile, you have providers like Anthropic, and their Claude Sonnet is a digital squirrel (see below). </p><figure><a href="https://ghuntley.com/cars/"><div><p>Claude Sonnet is a small-brained mechanical squirrel of &lt;T&gt;</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-43.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/Traditional-tattoo-style-print.--Low-angle--dramatic-scene-a-mechanical-pump-amidst-a-stormy-sky--pumping-generic-tools.-Vivid-electric-colors--complex-ornamental-designs--retro-feel--white-background.jpg" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>The first robot used to chase tennis balls. The first digital robot chases tool calls.</span></p></figcaption></figure><p>Sonnet is a robotic squirrel that just wants to do tool calls. It doesn't spend too much time thinking; it biases towards action, which is what makes it agentic. Sonnet focuses on incrementally obtaining success instead of pondering for minutes per turn before taking action.</p><p>It seems like every day, a new model is introduced to the market, and they're all competing with one another. But truth be told, they have their specialisations and have carved out their niches. </p><p>The problem is that, unless you're working with these models at an intimate level, you may not have this level of awareness of the specialisations of the models, which results in consumers just comparing the models on two basic primitives:</p><ol><li>The size of the context window</li><li>The cost</li></ol><p>It's kind of like looking at a car, whether it has two doors or three doors, whilst ignoring the fact that some vehicles are designed for off-roading, while others are designed for passenger transport. </p><p>To build an agent, the first step is to choose a highly agentic model. That is currently Claude Sonnet, or Kimi K2. </p><p>Now, you might be wondering, "What if you want a higher level of reasoning and checking of work that the incremental squirrel does?". Ah, that's simple. You can wire other LLMs in as tools into an existing agentic LLM. This is what we do at Amp.</p><p>We call it the Oracle. The Oracle is just GPT wired in as a tool that Claude Sonnet can function call for guidance, to check work progress, and to conduct research/planning.</p><figure><a href="https://ampcode.com/news/oracle?ref=ghuntley.com"><div><p>Oracle</p><p><img src="https://ghuntley.com/content/images/icon/amp-mark-color-9.svg" alt=""><span>Amp</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/oracle.jpg" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>Amp's oracle is just another LLM registered in as a tool to an agentic LLM that it can function call</span></p></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.027.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.027.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.027.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.027.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.027.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The next important thing to learn is that you should only use the context window for one activity. When you're using Cursor or any one of these tools, it's essential to clear the context window after each activity (see below).</p><figure><a href="https://ghuntley.com/gutter/"><div><p>autoregressive queens of failure</p><p>Have you ever had your AI coding assistant suggest something so off-base that you wonder if it’s trolling you? Welcome to the world of autoregressive failure. LLMs, the brains behind these assistants, are great at predicting the next word—or line of code—based on what’s been fed into</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-44.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/A-traditional-tattoo-style-print-of-a-bowling-ball-split-in-the-gutter--rendered-in-vibrant-colors-with-bold-lines-and-diffused-shadows.--The-image-features-a-retro-flair-and-complex-ornamental-details-against-a-white-background-2.jpg" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>LLM outcomtes are a needle in a haystack of what you've allocated into the haystack.</span></p></figcaption></figure><p>If you start an AI-assisted session to build a backend API controller, then reuse that session to research facts about meerkats. Then it should be no surprise when you tell it to redesign the website in the active session; the website might end up with facts about your API or meerkats, or both.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.028.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.028.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.028.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.028.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.028.png 1920w" sizes="(min-width: 720px) 720px"><figcaption><span>nb. the context window for Sonnet since delivering this workshop has increased to 1m</span></figcaption></figure><p>Context windows are very, very small. It's best to think of them as a Commodore 64, and as such, you should be treating it as a computer with a limited amount of memory. The more you allocate, the worse your outcome and performance will be.</p><p>The advertised context window for Sonnet is 200k. However, you don't get to use all of that because the model needs to allocate memory for the system-level prompt. Then the harness (Cursor, Windsurf, Claude Code, Amp) also needs to allocate some additional memory, which means you end up with approximately 176k tokens usable.</p><p>You probably heard a lot about the Model Context Protocols (MCPs). They are the current hot thing, and the easiest way to think about them is as a function with a description allocated to the context window that tells it how to invoke that function.</p><p>A common failure scenario I observe is people installing an excessive number of MCP servers or failing to consider the number of tools exposed by a single MCP tool or the aggregate context window allocation of all tools.</p><p>There is a cardinal rule that is not as well understood as it should be. The more you allocate to a context window, the worse the performance of the context window will be, and your outcomes will deteriorate.</p><p>Avoid excessively allocating to the context window with your agent or through MCP tool consumption. It's very easy to fall into a trap of allocating an additional 76K of tokens just for MCP tools, which means you only have 100K usable. </p><blockquote>Less is more, folks. Less is more. </blockquote><p>I recommend dropping by and reading the blog post below if you want to understand when to use MCP and when not to.</p><figure><a href="https://ghuntley.com/allocations/"><div><p>too many model context protocol servers and LLM allocations on the dance floor</p><p>This blog post intends to be a definitive guide to context engineering fundamentals from the perspective of an engineer who builds commercial coding assistants and harnesses for a living. Just two weeks ago, I was back over in San Francisco, and there was a big event on Model Context Protocol</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-52.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/Depict-AI-robots-dancing-on-a-rose-patterned-dance-floor-in-a-traditional-tattoo-art-style.-The-print-uses-a-vibrant-color-scheme--soft-lighting--and-diffused-shadows--creating-a-calming-atmosphere.-Complex-orna.jpg" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>When you should use MCP, when you should not use MCP, and how allocations work in the context window.</span></p></figcaption></figure><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.029.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.029.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.029.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.029.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.029.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Let's head back and check on our agent that's being built in the background. If you look at it closely enough, you can see the loop and how it's invoking other tools. </p><p>Essentially, how this all works is outlined in the loop below.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.030.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.030.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.030.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.030.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.030.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>For every piece of input from the user or result of a tool call that gets allocated to the response, and that response is sent off for inferencing:</p><figure><img src="https://ghuntley.com/content/images/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015242.png" alt="" loading="lazy" width="2000" height="382" srcset="https://ghuntley.com/content/images/size/w600/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015242.png 600w, https://ghuntley.com/content/images/size/w1000/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015242.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015242.png 1600w, https://ghuntley.com/content/images/size/w2400/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015242.png 2400w" sizes="(min-width: 720px) 720px"><figcaption><span>The inferencing loop (minus tool registrations)</span></figcaption></figure><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent</p><p>Contribute to ghuntley/how-to-build-a-coding-agent development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-19.svg" alt=""><span>GitHub</span><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials (above) and run the basic chat application via:</p><pre><code>go run chat.go</code></pre><blockquote><strong>You:</strong> You are a weather expert. When I ask you about the weather in a given location, I want you to reply with <code>get_weather(&lt;location_name&gt;)</code>. I will then tell you what the weather in that location is. Understood?<p><strong>Claude:</strong> I understand your instructions. When you ask me about the weather in a specific location, I will respond with <code>get_weather(&lt;location_name&gt;)</code>. Then you will provide me with the weather information for that location, and I can discuss it with you from there. I'm ready whenever you'd like to ask about the weather somewhere.</p></blockquote><p>So, let's ask what the weather is today here in Melbourne, Australia?</p><blockquote><strong>You:</strong> What's the weather like today in Melbourne, Australia?<p><strong>Claude:</strong>  <code>get_weather(Melbourne, Australia)</code></p></blockquote><p>boom! There we go! </p><p>We've registered our first tool into the model, and any time that we tickle the latent space with a query about the weather, it's going to function call our new tool. </p><p>It's a stub tool currently, but you can see it; we have a method, and the LLM is passing the parameters into the method from our query.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.031.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.031.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.031.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.031.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.031.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>When we talk about agentic, we're referring to something that's tool-calling, something that has been trained on its reward function to call a tool. There are models where they've been explicitly trained; all they want to do is chase nuts, much like a squirrel (see below). It's not nuts, it's tools.</p><figure><a href="https://ghuntley.com/cars/"><div><p>Claude Sonnet is a small-brained mechanical squirrel of &lt;T&gt;</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-46.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/Traditional-tattoo-style-print.--Low-angle--dramatic-scene-a-mechanical-pump-amidst-a-stormy-sky--pumping-generic-tools.-Vivid-electric-colors--complex-ornamental-designs--retro-feel--white-background-1.jpg" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>Whilst visiting the Computer History Museum in San Francisco, I stumbled upon the first robotic squirrel, and it got me thinking: "Wait a sec, is Sonnet our first digital squirrel?"</span></p></figcaption></figure><p>In the simplest way to explain what MCP is or a tool, it's just a function with a billboard on top that nudges the LLM's latent space to invoke that function. It is that simple. You register the tool, you describe how to invoke it, and then it just works.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.032.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.032.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.032.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.032.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.032.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Let's start the short journey towards making this a real coding agent. We have a mock function and a mock tool, but <code>get_weather(Melbourne, Australia)</code> currently does nothing, so let's fix that.</p><p>What we need to do is create a tool and then adjust our inferencing loop to check whether it wants to execute the tool (see line 5 above). If it does, execute the tool (see line 6 above) and then allocate the outcome of that tool back (see line 7 above) to the loop for more inferencing.</p><p>Here's what our updated sequence diagram looks like when tools have been registered.</p><figure><img src="https://ghuntley.com/content/images/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015409.png" alt="" loading="lazy" width="1714" height="3840" srcset="https://ghuntley.com/content/images/size/w600/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015409.png 600w, https://ghuntley.com/content/images/size/w1000/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015409.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015409.png 1600w, https://ghuntley.com/content/images/2025/08/Untitled-diagram-_-Mermaid-Chart-2025-08-24-015409.png 1714w" sizes="(min-width: 720px) 720px"><figcaption><span>this is what a coding agent is in it's purest form without any UI</span></figcaption></figure><p>As we're not making a weather application today, let's switch gears to build the first primitive of a coding agent.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.034.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.034.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.034.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.034.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.034.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The first primitive behind any coding agent is a read tool. All coding agents have a read tool that reads a file into the context window, either the whole file or, in the case of a larger file, in chunks.</p><pre><code>var ReadFileDefinition = ToolDefinition{
	Name:        "read_file",
	Description: "Read the contents of a given relative file path. Use this when you want to see what's inside a file. Do not use this with directory names.",
	InputSchema: ReadFileInputSchema,
	Function:    ReadFile,
}</code></pre><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent</p><p>Contribute to ghuntley/how-to-build-a-coding-agent development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-20.svg" alt=""><span>GitHub</span><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent-1" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials once again (above) and create a file:</p><pre><code>cat &lt;&lt; EOF
I have a mane but I'm not a lion,
I have four legs but I'm not a table,
I can gallop but I'm not running,
People say I'm disagreeable because I always say "neigh."
What am I?
EOF &gt; riddle.txt</code></pre><p>Then let's run the read file tool:</p><pre><code>go run read.go</code></pre><blockquote><strong>You:</strong> Claude, mate. What's the answer to this riddle in <code>riddle.txt</code>?<p><strong>Claude:</strong> I'll help you solve the riddle. Let me first read the contents of the <code>riddle.txt</code> file to see what the riddle is.</p><p><strong>tool:</strong> <code>read_file({"path":"riddle.txt"})</code></p><p>Reading file: <code>riddle.txt</code><br>Successfully read file <code>riddle.txt</code> (175 bytes)</p><p>result: I have a mane but I'm not a lion,<br>I have four legs but I'm not a table,<br>I can gallop but I'm not running,<br>People say I'm disagreeable because I always say "neigh."<br>What am I?</p><p><strong>Claude:</strong> After reading the riddle, I can solve it for you:</p><p>The answer to the riddle is: a horse.</p><p>Let's analyze the clues:</p><p>"I have a mane but I'm not a lion" - Horses have manes, which is hair growing from the top of the neck.</p><p>"I have four legs but I'm not a table" - Horses walk on four legs.</p><p>"I can gallop but I'm not running" - Galloping is a specific gait of horses.</p><p>"People say I'm disagreeable because I always say 'neigh'" - "Neigh" is the sound a horse makes, and it sounds like "nay" (which means "no" or disagreement).</p><p>All of these clues point to a horse as the answer to the riddle.</p></blockquote><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.033.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.033.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.033.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.033.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.033.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The second primitive behind any coding agent is a list tool. All coding agents have a list files tool, which lists all the files and directories in a given path.</p><pre><code>var ListFilesDefinition = ToolDefinition{
	Name:        "list_files",
	Description: "List files and directories at a given path. If no path is provided, lists files in the current directory.",
	InputSchema: ListFilesInputSchema,
	Function:    ListFiles,
}</code></pre><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent</p><p>Contribute to ghuntley/how-to-build-a-coding-agent development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-20.svg" alt=""><span>GitHub</span><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent-1" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials once again (above) and run the basic chat application via:</p><pre><code>go run list_files.go</code></pre><blockquote><strong>You:</strong> Claude, mate. Is there  a <code>README.md</code> in this folder? Also what is the contents of <code>riddle.txt</code>?<p><strong>Claude:</strong>  I'll help you check for a README.md file and show you the contents of <code>riddle.txt</code>.</p><p>First, let me list the files in the current directory to see if <code>README.md</code> exists:</p><p><strong>tool:</strong> <code>list_files({})</code><br>Listing files in directory: .<br>Successfully listed 88 items in .</p><p>result:</p><p><code>[".devenv.flake.nix",".direnv/",".envrc",".gitignore","AGENT.md","Makefile","README.md","bash_tool.go","chat.go","code_search_tool.go","devenv.lock","devenv.nix","devenv.yaml","edit_tool.go","go.mod","go.sum","list_files.go","prompts/","prompts/00-weather.md","prompts/01-read_file.md","prompts/02-list_files.md","prompts/03-bash_tool.md","prompts/04-edit_tool.md","read.go","renovate.json","riddle.txt"]</code></p><p><strong>Claude:</strong> Yes, there is a <code>README.md</code> file in this folder.</p><p>Now, let me show you the contents of <code>riddle.txt</code>:</p><p>tool: <code>read_file({"path":"riddle.txt"})</code><br>result: I have a mane but I'm not a lion,<br>I have four legs but I'm not a table,<br>I can gallop but I'm not running,<br>People say I'm disagreeable because I always say "neigh."<br>What am I?</p><p><strong>Claude:</strong> The contents of <code>riddle.txt is</code> a riddle:</p><p>I have a mane but I'm not a lion,<br>I have four legs but I'm not a table,<br>I can gallop but I'm not running,<br>People say I'm disagreeable because I always say "neigh."<br>What am I?</p><p>The answer to this riddle appears to be a horse.</p></blockquote><p>Boom! We now have a read file tool and a list files tool, and you can see that their functions are called and chained together from our original prompt.</p><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.035.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.035.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.035.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.035.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.035.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The third primitive behind any coding harness is a bash tool, which does precisely what its name implies. It enables the LLM to execute commands on your computer.</p><pre><code>var BashDefinition = ToolDefinition{
	Name:        "bash",
	Description: "Execute a bash command and return its output. Use this to run shell commands.",
	InputSchema: BashInputSchema,
	Function:    Bash,
}</code></pre><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent</p><p>Contribute to ghuntley/how-to-build-a-coding-agent development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-20.svg" alt=""><span>GitHub</span><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent-1" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials once again (above) and run the bash tool:</p><pre><code>go run bash_tool.go</code></pre><blockquote><strong>You:</strong> Hey Claude, provide a summary of all the processes running on this computer.<p><strong>Claude:</strong> I'll provide a summary of all the processes running on this computer. Let me use the <code>ps</code> command to gather this information.</p><p>tool: <code>bash({"command":"ps aux"})</code>precisely<br>Executing bash command: ps aux<br>Bash command succeeded: ps aux (output: 87344 bytes)</p><p>result: &lt;snipped&gt;</p><p><strong>Claude:</strong> Based on the output of the <code>ps aux</code> command, here's a summary of the processes running on this computer:</p><p>System Summary:</p><p>This is a multi-CPU system with 96 cores/threads (visible from the many CPU-related kernel threads)</p><p>Running Linux with systemd as the init system</p><p>The system has been up since August 20th (seen in START column)</p></blockquote><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.036.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.036.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.036.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.036.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.036.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The fourth primitive behind any coding harness is the edit tool.  The edit tool also does precisely as the name implies. It takes the results back from inference and applies edits to the file.</p><figure><a href="https://github.com/ghuntley/how-to-build-a-coding-agent?ref=ghuntley.com"><div><p>GitHub - ghuntley/how-to-build-a-coding-agent</p><p>Contribute to ghuntley/how-to-build-a-coding-agent development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-20.svg" alt=""><span>GitHub</span><span>ghuntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/how-to-build-a-coding-agent-1" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials once again (above) and run edit tool:</p><pre><code>go run edit_file.go</code></pre><blockquote><strong>You:</strong> Claude, mate. Create <code>fizzbuzz.js</code> with nodejs that does fizzbuzz up to 20 and execute it to ensure it works<p><strong>Claude:</strong> I'll create a Node.js implementation of FizzBuzz that counts up to 20 and then run it to make sure it works correctly.</p><p>First, let me create the <code>fizzbuzz.js</code>, file:</p><p>tool: <code>edit_file({"path":"fizzbuzz.js","old_str":"","new_str":"// FizzBuzz implementation in Node.js\n// Prints numbers from 1 to 20\n// If number is divisible by 3, print "Fizz"\n// If number is divisible by 5, print "Buzz"\n// If number is divisible by both 3 and 5, print "FizzBuzz"\n\nfor (let i = 1; i &lt;= 20; i++) {\n if (i % 3 === 0 &amp;&amp; i % 5 === 0) {\n console.log("FizzBuzz");\n } else if (i % 3 === 0) {\n console.log("Fizz");\n } else if (i % 5 === 0) {\n console.log("Buzz");\n } else {\n console.log(i);\n }\n}"})</code></p><p>Editing file: <code>fizzbuzz.js</code> (replacing 0 chars with 485 chars)</p><p>File does not exist, creating new file: <code>fizzbuzz.js</code><br>Creating new file: <code>fizzbuzz.js</code> (485 bytes)<br>Successfully created file <code>fizzbuzz.js</code></p><p>result: Successfully created file <code>fizzbuzz.js</code></p><p><strong>Claude:</strong> Now let me verify the file was created:<br>tool: <code>read_file({"path":"fizzbuzz.js"})</code></p><p>Reading file: <code>fizzbuzz.js</code><br>Successfully read file <code>fizzbuzz.js</code> (485 bytes)</p></blockquote><figure><img src="https://ghuntley.com/content/images/2025/08/fizzbuzz.js--1--1.png" alt="" loading="lazy" width="2000" height="1331" srcset="https://ghuntley.com/content/images/size/w600/2025/08/fizzbuzz.js--1--1.png 600w, https://ghuntley.com/content/images/size/w1000/2025/08/fizzbuzz.js--1--1.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/08/fizzbuzz.js--1--1.png 1600w, https://ghuntley.com/content/images/2025/08/fizzbuzz.js--1--1.png 2080w" sizes="(min-width: 720px) 720px"></figure><blockquote><strong>Claude:</strong> Now I'll execute the script to make sure it works correctly:<p>tool: <code>bash({"command":"node fizzbuzz.js"})</code><br>Executing bash command: <code>node fizzbuzz.js</code></p><p>Bash command executed successfully, output length: 77 chars<br>result: </p><p>1<br>2<br>Fizz<br>4<br>Buzz<br>Fizz<br>7<br>8<br>Fizz<br>Buzz<br>11<br>Fizz<br>13<br>14<br>FizzBuzz<br>16<br>17<br>Fizz<br>19<br>Buzz</p><p><strong>Claude:</strong> Great! The <code>fizzbuzz.js</code> file has been created and executed successfully. The output shows:</p><p>Numbers not divisible by 3 or 5 are printed as is (1, 2, 4, 7, 8, 11, 13, 14, 16, 17, 19)</p><p>Numbers divisible by 3 (but not 5) print "Fizz" (3, 6, 9, 12, 18)</p><p>Numbers divisible by 5 (but not 3) print "Buzz" (5, 10, 20)</p><p>Number 15 prints "FizzBuzz" as it's divisible by both 3 and 5</p></blockquote><p>And voila, we now have a coding agent. Is it this point that we could throw some other prompts in and say, "Hey, let's do FizzBuzz to 100, and it will just work."</p><figure><img src="https://ghuntley.com/content/images/2025/08/how-to-build-a-agent.039.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/08/how-to-build-a-agent.039.png 600w, https://ghuntley.com/content/images/size/w1000/2025/08/how-to-build-a-agent.039.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/08/how-to-build-a-agent.039.png 1600w, https://ghuntley.com/content/images/2025/08/how-to-build-a-agent.039.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>The fifth and final primitive behind any coding harness is a search tool. What if I were to tell you that there is no magic for indexing source code or any intelligence? </p><pre><code>var CodeSearchDefinition = ToolDefinition{
	Name: "code_search",
	Description: `Search for code patterns using ripgrep (rg).

Use this to find code patterns, function definitions, variable usage, or any text in the codebase.
You can search by pattern, file type, or directory.`,
	InputSchema: CodeSearchInputSchema,
	Function:    CodeSearch,
}</code></pre><p>Nearly every coding tool currently available uses the open source <code>ripgrep</code> binary under the hood. See the two blog posts below if you want more proof:</p><figure><a href="https://ghuntley.com/amazon-kiro-source-code/"><div><p>source code analysis of Amazon Kiro</p><p>It’s an uncertain time for our profession, but one thing is certain—things will change. Drafting used to require a room of engineers, but then CAD came along…</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-53.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/Tattoo-art-print-depicting-reverse-engineered-Amazon-systems--warm-autumn-colors--white-background--intricate-lines-and-vibrant-colors--retro-flair--complex-ornamental-details--charming-and-cute-style.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><a href="https://ghuntley.com/overton/"><div><p>from Luddites to AI: the Overton Window of disruption</p><p>I’ve been thinking about Overton Windows lately, but not of the political variety. You see, the Overton window can be adapted to model disruptive innovation by framing the acceptance of novel technologies, business models, or ideas within a market or society. So I’ve been pondering about where, when and how</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-51.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/download-3.jpeg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Let's open up our workshop materials once again and run the code search tool:</p><pre><code>go run code_search_tool.go</code></pre><blockquote><strong>You:</strong> Claude, mate. Search the source code for a riddle<p><strong>Claude:</strong> I'd be happy to search the source code for a riddle. Let me use the code search tool to look for mentions of riddles in the codebase.</p><p>tool: <code>code_search({"pattern":"riddle"})</code></p><p>Searching for pattern: <code>riddle</code><br>Found 6 matches for pattern: <code>riddle</code></p><p>result: </p><p><code>./README.md:332:- <strong>riddle.txt</strong>: A simple riddle for content analysis</code></p><p><strong>Claude:</strong> I've found references to a riddle file called "<code>riddle.txt</code>" in the codebase. Let me check if this file exists by listing the files in the current directory.</p><p>tool: <code>list_files({})</code><br>Listing files in directory: .<br>Successfully listed 25 files in .<br>result: </p><p><code>["./go.mod","./renovate.json","./devenv.yaml","./AGENT.md","./.devenv.flake.nix","./.envrc","./bash_tool.go","./fizzbuzz.js","./code_search_tool.go","./list_files.go","./Makefile","./devenv.nix","./devenv.lock","./prompts/01-read_file.md","./prompts/02-list_files.md","./prompts/00-weather.md","./prompts/03-bash_tool.md","./prompts/04-edit_tool.md","./chat.go","./go.sum","./riddle.txt","./edit_tool.go","./README.md","./.gitignore","./read.go"]</code></p><p>Claude: Great! I can see that "<code>riddle.txt</code>" exists in the current directory. Let me read its contents to see what the riddle is.</p><p>tool: <code>read_file({"path":"riddle.txt"})</code></p><p>Reading file: <code>riddle.txt</code><br>Successfully read file <code>riddle.txt</code> (175 bytes)<br>result: I have a mane but I'm not a lion,<br>I have four legs but I'm not a table,<br>I can gallop but I'm not running,<br>People say I'm disagreeable because I always say "neigh."<br>What am I?</p><p><strong>Claude:</strong> I found the riddle in the file <code>riddle.txt</code>!</p></blockquote><figure><img src="https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.037.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/07/how-to-build-a-agent.037.png 600w, https://ghuntley.com/content/images/size/w1000/2025/07/how-to-build-a-agent.037.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/07/how-to-build-a-agent.037.png 1600w, https://ghuntley.com/content/images/2025/07/how-to-build-a-agent.037.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>Everything from this point forward is just a matter of tuning your prompts. Due to time constraints, we didn't delve into the notion of the harness prompt. The harness prompt is where your tool registrations go. It contains information such as the operating system you're running, so it knows whether to use PowerShell (Windows) or bash (Linux or macOS). </p><p>It also contains instructions on how the agent should operate. I say should is because LLMs are non-deterministic. You can include the guidance, and it's just guidance. However, through prompt evaluation, tuning, and spending time playing with the models to understand how they behave, you can develop effective prompts.</p><p>Drop by the blog post below if you want to see an example of a fully fledged coding agent:</p><figure><a href="https://ghuntley.com/amazon-kiro-source-code/"><div><p>source code analysis of Amazon Kiro</p><p>It’s an uncertain time for our profession, but one thing is certain—things will change. Drafting used to require a room of engineers, but then CAD came along…</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-55.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/Tattoo-art-print-depicting-reverse-engineered-Amazon-systems--warm-autumn-colors--white-background--intricate-lines-and-vibrant-colors--retro-flair--complex-ornamental-details--charming-and-cute-style-1.jpg" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>There are plenty of open-source coding agents already, such as SST Open Code</p><figure><a href="https://github.com/sst/opencode?ref=ghuntley.com"><div><p>GitHub - sst/opencode: AI coding agent, built for the terminal.</p><p>AI coding agent, built for the terminal. Contribute to sst/opencode development by creating an account on GitHub.</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-21.svg" alt=""><span>GitHub</span><span>sst</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/6aa80c72-cede-4e0d-b724-d3ed79320a7e" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>Or this 100-line agent, which scored really high on the SWE Bench.</p><figure><a href="https://github.com/SWE-agent/mini-swe-agent?ref=ghuntley.com"><div><p>GitHub - SWE-agent/mini-swe-agent: The 100 line AI agent that solves GitHub issues or helps you in your command line. Radically simple, no huge configs, no giant monorepo—but scores 68% on SWE-bench verified!</p><p>The 100 line AI agent that solves GitHub issues or helps you in your command line. Radically simple, no huge configs, no giant monorepo—but scores 68% on SWE-bench verified! - SWE-agent/mini-swe-agent</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-24.svg" alt=""><span>GitHub</span><span>SWE-agent</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/mini-swe-agent" alt="" onerror="this.style.display = 'none'"></p></a></figure><p>And if you want some inspiration, there are many repositories on GitHub with leaked developer tooling harness and tool prompts.</p><figure><a href="https://github.com/x1xhlol/system-prompts-and-models-of-ai-tools?ref=ghuntley.com"><div><p>GitHub - x1xhlol/system-prompts-and-models-of-ai-tools: FULL v0, Cursor, Manus, Augment Code, Same.dev, Lovable, Devin, Replit Agent, Windsurf Agent, VSCode Agent, Dia Browser, Xcode, Trae AI, Cluely &amp; Orchids.app (And other Open Sourced) System Prompts, Tools &amp; AI Models.</p><p>FULL v0, Cursor, Manus, Augment Code, Same.dev, Lovable, Devin, Replit Agent, Windsurf Agent, VSCode Agent, Dia Browser, Xcode, Trae AI, Cluely &amp;amp; Orchids.app (And other Open Sourced) System Pro…</p><p><img src="https://ghuntley.com/content/images/icon/pinned-octocat-093da3e6fa40-22.svg" alt=""><span>GitHub</span><span>x1xhlol</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/system-prompts-and-models-of-ai-tools" alt="" onerror="this.style.display = 'none'"></p></a></figure><figure><img src="https://ghuntley.com/content/images/2025/08/how-to-build-a-agent.041.png" alt="" loading="lazy" width="1920" height="1080" srcset="https://ghuntley.com/content/images/size/w600/2025/08/how-to-build-a-agent.041.png 600w, https://ghuntley.com/content/images/size/w1000/2025/08/how-to-build-a-agent.041.png 1000w, https://ghuntley.com/content/images/size/w1600/2025/08/how-to-build-a-agent.041.png 1600w, https://ghuntley.com/content/images/2025/08/how-to-build-a-agent.041.png 1920w" sizes="(min-width: 720px) 720px"></figure><p>In recap. What you just built was a coding agent. Perhaps you don't want to create a coding agent. What if you're in the data engineering profession? What would that look like? Think about all of the activities that you do day-to-day, where having the capability to automate using these primitives could be handy or valuable to your employer.</p><p>Your current workers are going to take your job, not AI. </p><p>If you're concerned about AI, the answer is straightforward: just invest in yourself. It really is that simple. This year is a particularly challenging time to be asleep at the wheel when it comes to personal development.  </p><figure><a href="https://ghuntley.com/six-month-recap/"><div><p>the six-month recap: closing talk on AI at Web Directions, Melbourne, June 2025</p><p>Welcome back to our final session at WebDirections. We’re definitely on the glide path—though I’m not sure if we’re smoothly landing, about to hit turbulence, or perhaps facing a go-around. We’ll see how it unfolds. Today, I’m excited to introduce Geoffrey Huntley. I discovered Geoff earlier this year through</p><p><img src="https://ghuntley.com/content/images/icon/7V0ak3am_400x400-1-54.jpg" alt=""><span>Geoffrey Huntley</span><span>Geoffrey Huntley</span></p></div><p><img src="https://ghuntley.com/content/images/thumbnail/the-future-belongs-to-people-who-do-things.001-3.png" alt="" onerror="this.style.display = 'none'"></p></a><figcaption><p><span>conference lock-note</span></p></figcaption></figure><p>I hope to see you later this afternoon for the conference for the locknote (see above). </p><blockquote>Go forward and build.</blockquote><p>ps. socials</p><ul><li>X - <a href="https://x.com/GeoffreyHuntley/status/1959453609240007052?ref=ghuntley.com">https://x.com/GeoffreyHuntley/status/1959453609240007052</a></li><li>Linkedin : <a href="https://www.linkedin.com/posts/geoffreyhuntley_how-to-build-an-agent-activity-7365220712707485697-EiJO?utm_source=share&amp;utm_medium=member_desktop&amp;rcm=ACoAAABQKuUB2AJ059keUcRUVLbtmoa6miLVlTI">https://www.linkedin.com/posts/geoffreyhuntley_how-to-build-an-agent-activity-7365220712707485697-EiJO</a></li><li>Bluesky: <a href="https://bsky.app/profile/ghuntley.com/post/3lx4jmqsclk2q?ref=ghuntley.com">https://bsky.app/profile/ghuntley.com/post/3lx4jmqsclk2q</a></li></ul>
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Port Kill – A lightweight macOS status bar development port monitor (103 pts)]]></title>
            <link>https://github.com/kagehq/port-kill</link>
            <guid>45000982</guid>
            <pubDate>Sun, 24 Aug 2025 03:08:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/kagehq/port-kill">https://github.com/kagehq/port-kill</a>, See on <a href="https://news.ycombinator.com/item?id=45000982">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🚧 Port Kill</h2><a id="user-content--port-kill" aria-label="Permalink: 🚧 Port Kill" href="#-port-kill"></a></p>
<p dir="auto">A lightweight macOS status bar app that monitors and manages development processes running on ports 2000-6000. The app provides real-time process detection and allows you to kill individual processes or all processes at once.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/kagehq/port-kill/blob/main/image-short.png"><img src="https://github.com/kagehq/port-kill/raw/main/image-short.png" alt="Port Kill Status Bar Icon"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li><strong>Real-time Monitoring</strong>: Scans ports 2000-6000 every 5 seconds using <code>lsof</code> commands</li>
<li><strong>Visual Status Bar Icon</strong>: Shows process count with color-coded center (green=0, red=1-9, orange=10+)</li>
<li><strong>Dynamic Context Menu</strong>: Updates every 3 seconds with current processes and kill options</li>
<li><strong>One-Click Process Killing</strong>: Click any menu item to kill all detected processes</li>
<li><strong>Safe Process Termination</strong>: Uses SIGTERM → SIGKILL termination strategy</li>
<li><strong>Stable Architecture</strong>: Built with winit event loop for macOS compatibility</li>
<li><strong>Graceful Error Handling</strong>: Handles permission errors and process failures</li>
<li><strong>No Windows</strong>: Pure status bar application with no main window</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Status Bar Icon</h2><a id="user-content-status-bar-icon" aria-label="Permalink: Status Bar Icon" href="#status-bar-icon"></a></p>
<p dir="auto">The status bar icon provides instant visual feedback:</p>
<ul dir="auto">
<li><strong>Green</strong>: 0 processes (safe, no development servers)</li>
<li><strong>Red</strong>: 1-9 processes (some development servers)</li>
<li><strong>Orange</strong>: 10+ processes (many development servers)</li>
</ul>
<p dir="auto">Hover over the icon to see the exact process count in the tooltip.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Menu Options</h2><a id="user-content-menu-options" aria-label="Permalink: Menu Options" href="#menu-options"></a></p>
<ul dir="auto">
<li><strong>Kill All Processes</strong>: Terminates all detected development processes</li>
<li><strong>Individual Process Entries</strong>: Format: "Kill: Port 3001: node (PID 1234)"</li>
<li><strong>Quit</strong>: Exits the application</li>
</ul>
<p dir="auto"><strong>Note</strong>: Currently, clicking any menu item will kill all processes (for testing purposes).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li>macOS 10.15 or later</li>
<li>Rust 1.70 or later</li>
<li><code>lsof</code> command (included with macOS)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>Clone the repository:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone <repository-url>
cd port-kill"><pre>git clone <span>&lt;</span>repository-url<span>&gt;</span>
<span>cd</span> port-kill</pre></div>
<ol start="2" dir="auto">
<li>Build the application:</li>
</ol>

<ol start="3" dir="auto">
<li>Run the application (easy way):</li>
</ol>

<ol start="4" dir="auto">
<li>Run manually (alternative):</li>
</ol>

<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li><strong>Start the Application</strong>: Run <code>./run.sh</code> to start the application</li>
<li><strong>Monitor Status</strong>: Check the status bar for the process count indicator</li>
<li><strong>Access Menu</strong>: Click on the status bar icon to open the context menu</li>
<li><strong>Kill Processes</strong>:
<ul dir="auto">
<li>Click "Kill All Processes" to terminate all development processes</li>
<li>Click individual process entries to kill specific processes</li>
</ul>
</li>
<li><strong>Quit</strong>: Click "Quit" to exit the application</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Technical Details</h2><a id="user-content-technical-details" aria-label="Permalink: Technical Details" href="#technical-details"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Architecture</h3><a id="user-content-architecture" aria-label="Permalink: Architecture" href="#architecture"></a></p>
<ul dir="auto">
<li><strong>Main Thread</strong>: Handles UI events and menu interactions with winit event loop</li>
<li><strong>Process Monitor</strong>: Scans for processes every 5 seconds using <code>lsof</code></li>
<li><strong>Menu Updates</strong>: Updates context menu every 3 seconds when processes change</li>
<li><strong>Process Killing</strong>: Runs in background threads to maintain UI responsiveness</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Process Detection</h3><a id="user-content-process-detection" aria-label="Permalink: Process Detection" href="#process-detection"></a></p>
<p dir="auto">The application uses the following command to detect processes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="lsof -ti :PORT -sTCP:LISTEN"><pre>lsof -ti :PORT -sTCP:LISTEN</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Process Termination</h3><a id="user-content-process-termination" aria-label="Permalink: Process Termination" href="#process-termination"></a></p>
<ol dir="auto">
<li><strong>SIGTERM</strong>: First attempts graceful termination</li>
<li><strong>SIGKILL</strong>: If process doesn't terminate within 500ms, forces termination</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Port Range</h3><a id="user-content-port-range" aria-label="Permalink: Port Range" href="#port-range"></a></p>
<p dir="auto">Monitors ports 2000-6000 (broad range covering common development server ports)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dependencies</h2><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<ul dir="auto">
<li><code>tray-icon</code>: macOS status bar integration</li>
<li><code>winit</code>: Event loop management</li>
<li><code>nix</code>: Signal handling for process termination</li>
<li><code>crossbeam-channel</code>: Thread communication</li>
<li><code>tokio</code>: Async runtime</li>
<li><code>anyhow</code>: Error handling</li>
<li><code>serde</code>: Data serialization</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Development</h2><a id="user-content-development" aria-label="Permalink: Development" href="#development"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Building for Development</h3><a id="user-content-building-for-development" aria-label="Permalink: Building for Development" href="#building-for-development"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Running with Logging</h3><a id="user-content-running-with-logging" aria-label="Permalink: Running with Logging" href="#running-with-logging"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Permission Issues</h3><a id="user-content-permission-issues" aria-label="Permalink: Permission Issues" href="#permission-issues"></a></p>
<p dir="auto">If you encounter permission errors when trying to kill processes:</p>
<ol dir="auto">
<li>Ensure the application has the necessary permissions</li>
<li>Some system processes may be protected</li>
<li>Check if the process is owned by another user</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Process Not Detected</h3><a id="user-content-process-not-detected" aria-label="Permalink: Process Not Detected" href="#process-not-detected"></a></p>
<p dir="auto">If a process is not being detected:</p>
<ol dir="auto">
<li>Verify the process is listening on a port in the 2000-6000 range</li>
<li>Check if the process is using TCP (not UDP)</li>
<li>Ensure the process is in LISTEN state</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Application Not Starting</h3><a id="user-content-application-not-starting" aria-label="Permalink: Application Not Starting" href="#application-not-starting"></a></p>
<p dir="auto">If the application fails to start:</p>
<ol dir="auto">
<li>Check if another instance is already running</li>
<li>Verify all dependencies are installed</li>
<li>Check system logs for error messages</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the FSL-1.1-MIT License. See the LICENSE file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<ol dir="auto">
<li>Fork the repository</li>
<li>Create a feature branch</li>
<li>Make your changes</li>
<li>Add tests if applicable</li>
<li>Submit a pull request</li>
</ol>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Evaluating LLMs for my personal use case (102 pts)]]></title>
            <link>https://darkcoding.net/software/personal-ai-evals-aug-2025/</link>
            <guid>45000270</guid>
            <pubDate>Sun, 24 Aug 2025 00:40:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://darkcoding.net/software/personal-ai-evals-aug-2025/">https://darkcoding.net/software/personal-ai-evals-aug-2025/</a>, See on <a href="https://news.ycombinator.com/item?id=45000270">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
      <p>It’s great that AI can win maths Olympiads, but that’s not what I’m doing. I mostly ask basic Rust, Python, Linux and life questions. <em>So I did my own evaluation</em>.</p>
<p>I gathered 130 real prompts from my bash history (I use command line tool <a href="https://llm.datasette.io/en/stable/">llm</a>).</p>
<p>I had Qwen3 235B Thinking and Gemini 2.5 Pro group them into categories. They both chose very similar ones, broadly (with examples):</p>
<ul>
<li>Programming - “Write a bash script to ..”</li>
<li>Sysadmin  - “With <code>curl</code> how do I ..”</li>
<li>Technical explanations - “Explain underlay networks in a data center”</li>
<li>General knowledge and creative tasks - “Recipe for blackened seasoning”</li>
</ul>
<p>Then I had GPT-OSS-120B and GLM 4.5 pick three queries for each category from the 130 prompts. I used that to help me pick three entries per category, they are listed at the end.</p>
<p>I use <a href="https://openrouter.ai/">Open Router</a> everyday, and I used it for these evals. It’s the only place I know that has all the models, great prices, low latency, and a very sane API. I use my own fast and simple Rust CLI called <a href="https://github.com/grahamking/ort">ort</a>.</p>
<p>The set of models I chose to evaluate was based on my past experience with them, various leaderboards and their cost on Open Router. It is a mixture of reasoning, non-reasoning and hybrid models. I evaluated:</p>
<ul>
<li>anthropic/claude-sonnet-4 without reasoning</li>
<li>anthropic/claude-sonnet-4 with reasoning (I didn’t realise Sonnet can think!)</li>
<li>deepseek/deepseek-chat-v3-0324</li>
<li>deepseek/deepseek-r1-0528</li>
<li>google/gemini-2.5-flash</li>
<li>google/gemini-2.5-pro</li>
<li>moonshotai/kimi-k2</li>
<li>openai/gpt-oss-120b</li>
<li>qwen/qwen3-235b-a22b-2507</li>
<li>qwen/qwen3-235b-a22b-thinking-2507</li>
<li>z-ai/glm-4.5 with reasoning</li>
</ul>
<p>For the three programming questions I added these at the last minute, mostly because I was enjoying the process:</p>
<ul>
<li>inception/mercury-coder-small-beta</li>
<li>mistralai/devstral-medium-2507</li>
<li>qwen/qwen3-coder-480b-a35b-07-25</li>
<li>z-ai/glm-4.5-air without reasoning</li>
</ul>
<p>These extra coding models are not included in most of the results. Mercury Coder was decent and very fast, Qwen3 Coder was surprisingly bad.</p>
<p>I wrote a <a href="https://github.com/grahamking/ort/blob/master/src/bin/eval.rs">Rust eval script</a> to run the prompts against the models and blind the results, so I would not know which model the response comes from when I evaluate it. I recorded the cost, time-to-first-token (latency) and inter-token-latency (throughput) of each model.</p>
<blockquote>
<p>Why no closed OpenAI models?</p>
</blockquote>
<p>To access their best models via the API, OpenAI now requires you to complete a Know-You-Customer process similar to opening a bank account. That’s a bit intense for 3 seconds of GPU time. It’s best to think of OpenAI as not having an API.</p>
<blockquote>
<p>Why no Grok, Cohere, Ernie, etc?</p>
</blockquote>
<p>Grok I forgot about until it was too late. It was buried in Twitter/X for so long it’s not on my radar. The other models, well, there are so many good ones I had to cut somewhere. And Anthropic’s Opus is obviously too expensive.</p>
<h2 id="what-i-learnt">What I learnt </h2>
<p><strong>Evals are hard</strong>. One of my first questions was a recipe for blackened seasoning. Now I have 11 recipies. How do I evaluate that?!</p>
<p>For each eval I read all of the submissions which took a lot of time. For the programming ones I got three models to pick the three best entries based on correctness and conciseness (they never picked their own submission) and started with those. That helped me develop grading criteria when looking at the other submissions.</p>
<p><strong>All models are good</strong>. Almost all models got almost all my evaluations correct, I was happy with the vast majority of the results. They agree a lot too. Six of the eleven picked the same movie. Most of them used the same examples for the algebra question. I guess they share a lot of training data.</p>
<p><strong>Cost and latency vary dramatically</strong>, and are the tie-breaker. I want my questions to be so cheap that I never hesitate to ask. And they are! The cost of a query is usually in fractions of a cent. I also need it to be fast. I am using AI largely because it’s faster than searching the Internet.</p>
<p><strong>Closed models are not better</strong>. Even without taking into account cost or latency, the results from Google’s Gemini and Anthropic’s Claude were almost never the best of the bunch. They were fine, but one of the open models often had cleaner code, or a better explanation.</p>
<p><strong>Gemini 2.5 Flash is very fast</strong>, and <strong>Gemini 2.5 Pro is overpriced</strong>. Flash was consistenty the fastest response, and sometimes also the best. Note I am using it via OpenRouter same as all the other models, so there was no direct-to-Google advantage. Pro was by far the most expensive of the the models, because it’s expensive per token, and more verbose than open models (low token efficiency).</p>
<p><strong>Reasoning rarely helps</strong>. My questions are easy, speed is key. The major exception here was the poem (“Write a 10 line poem about Florida in the style of Shel Silverstein”). The three best poems were by thinking models, and there was a large gap in quality.</p>
<h2 id="prompts-and-winners">Prompts and winners </h2>
<p>Here are the prompts I used and the answer I prefered, by category. These are all real prompts from my bash history. Usually my simple questions had many good answers and cost and speed won the day.</p>
<h3 id="programming">Programming </h3>
<blockquote>
<p>Write a bash script to display a progress bar.</p>
</blockquote>
<p>Best: <code>inception/mercury-coder</code>. This is a <em>diffusion</em> model, and it is very fast. Really, try it! It’s not the strongest, but if it can answer, it wins on speed every time.</p>
<p>Also good, but slower: deepseek/deepseek-r1-0528, z-ai/glm-4.5</p>
<blockquote>
<p>Write a short Rust program that listens on a unix domain socket using only the standard library.</p>
</blockquote>
<p>Best: <code>deepseek/deepseek-chat-v3-0324</code>, <code>openai/gpt-oss-120b</code>, <code>qwen/qwen3-235b-a22b-2507</code>.</p>
<blockquote>
<p>In nvim using Lua, create a popup window that says “Hello”.</p>
</blockquote>
<p>Best: <code>z-ai/glm-4.5-air</code>. Perfect simple solution, very fast.</p>
<p>Almost identical code to glm-4.5-air, but slower and more expensive: qwen/qwen3-235b-a22b-thinking-2507, anthropic/claude-sonnet-4.</p>
<h3 id="sysadmin">Sysadmin </h3>
<blockquote>
<p>You are an expert system administrator. Tell me what Linux program I should use to rotate a log file. Suggest three possible answers and give short usage examples for each one, rotating file <code>/var/log/myfile.log</code> every 30 days.</p>
</blockquote>
<p>That “You are ..” formulation was an effective prompting technique back in the day, this one from way back in my bash history.</p>
<p>Best: <code>deepseek/deepseek-r1-0528</code></p>
<blockquote>
<p>With <code>jq</code>, how do I print only the keys of a JSON object?</p>
</blockquote>
<p>Best: <code>openai/gpt-oss-120b</code></p>
<p>I think every single model got this one right, but gpt-oss-120b was fast, cheap, and clear.</p>
<blockquote>
<p>On my Thinkpad Linux laptop with Intel Iris Xe graphics, I am seeing this error: “rust-lld: error: unable to find library -lOpenCL”. What Fedora package do I install to fix it?</p>
</blockquote>
<p>Best: <code>deepseek/deepseek-chat-v3-0324</code></p>
<h3 id="technical-explanations">Technical explanations </h3>
<blockquote>
<p>You are a data center networking expert and I am your intern. Explain what an underlay network is, and provide an example of why underlay networks are useful.</p>
</blockquote>
<p>Best: <code>anthropic/claude-sonnet-4</code> (not thinking), <code>deepseek/deepseek-r1-0528</code></p>
<p>I prefered Sonnet’s non-reasoning response to it’s reasoning response.</p>
<blockquote>
<p>You are a math tutor. Explain partial derivatives with respect to a variable, and provide a worked example for a beginner.</p>
</blockquote>
<p>Best: <code>moonshotai/kimi-k2</code></p>
<p>Difficult to evaluate this one because most of the models used the same examples. One big difference is whether they could emit UTF-8 for easy to read math symbols. The five that did were claude-sonnet-4, kimi-k2, qwen3-235b-a22b-thinking-2507, glm-4.5 and gemini-2.5-pro (flash did not).</p>
<blockquote>
<p>What is “quantization” in the context of large language models?</p>
</blockquote>
<p>Best: <code>deepseek/deepseek-chat-v3-0324</code>, <code>z-ai/glm-4.5</code> with thinking.</p>
<p>Again a bit difficult to evaluate, many explanations were very good. These two were good but also fast and cheap.</p>
<h3 id="general-knowledge-and-creativity">General knowledge and creativity </h3>
<blockquote>
<p>Write a 10 line poem about Florida in the style of Shel Silverstein</p>
</blockquote>
<p>Best equal: <code>qwen/qwen3-235b-a22b-thinking-2507</code>, <code>anthropic/claude-sonnet-4</code> w/ thinking, <code>deepseek/deepseek-r1-0528</code></p>
<p>Reasoning really helped here. My favorite poem is at the end of the post.</p>
<blockquote>
<p>Suggest a PG-13 rated movie that has great landscapes, feels calm and meditative, but is still enjoyable.</p>
</blockquote>
<p>Six of the eleven recommended <a href="https://www.imdb.com/title/tt0359950/">The Secret Life of Walter Mitty</a> which my whole family enjoyed. It was the perfect choice here, but I still found the consensus odd.</p>
<p>Best: <code>google/gemini-2.5-flash</code> got the answer first.</p>
<p>Also good: google/gemini-2.5-pro and anthropic/claude-sonnet-4 w/ thinking suggested movies I had not heard of which sounds interesting, so props to them for thinking outside the box.</p>
<p>Negative: openai/gpt-oss-120b hallucinated a movie. I could find no trace of this “Stargazing” movie, although I’d watch it. If it’s real please email me!</p>
<pre tabindex="0"><code> Alternative (if you prefer a more understated pace)**
 *Stargazing (2021) – PG‑13* – a slower, dialogue‑driven drama set in the Scottish Highlands, offering serene vistas and a reflective mood.
</code></pre><p>This was the only hallucination I noticed in all the whole process.</p>
<blockquote>
<p>How do you make cold brew coffee?</p>
</blockquote>
<p>OK this is a dumb eval. How to you decide?</p>
<p>Best: <code>qwen/qwen3-235b-a22b-2507</code></p>
<p>Cheap, fast, reasonable process clearly described.</p>
<blockquote>
<p>What or who is Louisiana named after?</p>
</blockquote>
<p>Best: <code>google/gemini-2.5-flash</code></p>
<p>All models got it. Flash was fastest.</p>
<h2 id="overall-results">Overall results </h2>
<p>There is no obvious winner.</p>
<h3 id="speed">Speed </h3>
<ul>
<li>The fastest: <code>google/gemini-2.5-flash</code></li>
<li>Also very fast:
<ul>
<li>moonshotai/kimi-k2</li>
<li>qwen/qwen3-235b-a22b-2507</li>
<li>deepseek/deepseek-chat-v3-0324</li>
<li>openai/gpt-oss-120b</li>
</ul>
</li>
<li>The slowest - thinking takes time:
<ul>
<li>qwen/qwen3-235b-a22b-thinking-2507</li>
<li>deepseek/deepseek-r1-0528</li>
<li>google/gemini-2.5-pro</li>
</ul>
</li>
</ul>
<p><a href="https://darkcoding.net/images/2025/08/evals-latency-by-model.png"><img src="https://darkcoding.net/images/2025/08/evals-latency-by-model.png" alt="Latency by model" width="auto"></a></p>
<h3 id="price">Price </h3>
<ul>
<li>Cheapest:
<ul>
<li>moonshotai/kimi-k2</li>
<li>qwen/qwen3-235b-a22b-2507</li>
<li>deepseek/deepseek-chat-v3-0324</li>
<li>google/gemini-2.5-flash</li>
<li>openai/gpt-oss-120b</li>
</ul>
</li>
<li>Most expensive, by a long way - don’t use closed models unless you have to:
<ul>
<li>google/gemini-2.5-pro</li>
<li>anthropic/claude-sonnet-4</li>
</ul>
</li>
</ul>
<p><a href="https://darkcoding.net/images/2025/08/evals-spend-by-model.png"><img src="https://darkcoding.net/images/2025/08/evals-spend-by-model.png" alt="Spend by model" width="auto"></a></p>
<p>Accuracy:</p>
<ul>
<li>Best: The two <code>DeepSeek</code> models and the two <code>Qwen3</code> models average the overall best.</li>
<li>Disappointing: Google’s Gemini 2.5 Pro and Anthropic’s Claude Sonnet are third place, even without considering price and speed, and are often quite poor. That really surprised me. I was glad I did the evals blind, because until now I thought Gemini 2.5 Pro was the best model.</li>
<li>Nearly all models passed nearly all evals fine. Accuracy is very good across the board.</li>
</ul>
<p>Since my evals, DeepSeek released hybrid model <code>deepseek/deepseek-chat-v3.1</code>, which replaces r1 (if you enable thinking) and v3 (if you disable thinking).</p>
<h2 id="my-decision-use-several-at-once">My decision: Use several at once </h2>
<p>Given that there is no overall winner, and that the best models are cheap and fast, why not query several at once? I use a <code>tmux</code> script to <a href="https://github.com/grahamking/ort?tab=readme-ov-file#tmux">split the window and query multiple models</a>.</p>
<p>Here is what I do today using some bash scripts and my <a href="https://github.com/grahamking/ort">ort openrouter CLI</a>:</p>
<ul>
<li>Quick everyday queries</li>
</ul>
<pre tabindex="0"><code>ort -p latency -m deepseek/deepseek-chat-v3.1 -r off -s "Answer in as few words as possible. Use a brief style with short replies." "-the-prompt-here-"
</code></pre><p>It’s chat predecessor was the best average of latency, price and accuracy, so hopefully this one continues the tradition. 80% of the time this is all I need.</p>
<ul>
<li>Second opinion</li>
</ul>
<p>Sometimes I want to sanity check deepseek-chat, or I’m not entirely satisfied with that answer, then my script splits the window in two and runs:</p>
<pre tabindex="0"><code>ort -p latency -r low -m google/gemini-2.5-flash -s "Answer in as few words as possible. Use a brief style with short replies." "-prompt-"
</code></pre><p>and</p>
<pre tabindex="0"><code>ort -p latency -m qwen/qwen3-235b-a22b-07-25 -s "Answer in as few words as possible. Use a brief style with short replies." "-prompt-"
</code></pre><ul>
<li>Thinking</li>
</ul>
<p>If I think my query needs a bit more brainpower - which my evals taught me is far less often than I think - I split the tmux window into three panes and run these three:</p>
<pre tabindex="0"><code># I'm not sure if thinking effort is configurable
ort -r medium -p latency -m qwen/qwen3-235b-a22b-thinking-2507 -s "Make your answer concise but complete. No yapping. Direct professional tone. No emoji." "-prompt-"
</code></pre><p>and</p>
<pre tabindex="0"><code>ort -r 2048 -m anthropic/claude-sonnet-4 -s "Make your answer concise but complete. No yapping. Direct professional tone. No emoji." "-prompt-"
</code></pre><p>and</p>
<pre tabindex="0"><code># Replaces DeepSeek R1
ort -r high -p latency -m deepseek/deepseek-chat-v3.1 -s "Make your answer concise but complete. No yapping. Direct professional tone. No emoji." "-prompt-"
</code></pre><p>I change the system prompt here to be a little more verbose, and I add Sonnet which is expensive, almost as a sanity check on the open models. I’ve never actually needed it so far.</p>
<h2 id="caveats">Caveats </h2>
<p>I used Open Router for all this with it’s default priority. The cost and performance depend entirely on the providers available for each model. I think GLM 4.5 may have lost out here because it was quite new when I did the evals, so it didn’t have as solid a set of providers. GPT-OSS-120B was also rumoured to have some poor quality providers at the time.</p>
<p>If you’re an Open Router user, you can go into settings and allow models to train on your queries, that unlocks much cheaper providers. I did that here.</p>
<p>I used the default reasoning setting (typically “medium”). Setting it to low or high may have impacted result quality, and likely would impact performance.</p>
<p>And of course these evals are personal and very subjective.</p>
<h2 id="bonus---the-poem">Bonus - the poem </h2>
<p>One of the evals was:</p>
<blockquote>
<p>Write a 10 line poem about Florida in the style of Shel Silverstein</p>
</blockquote>
<p>Here is my favorite, courtesy of <code>qwen/qwen3-235b-a22b-thinking-2507</code>:</p>
<p>The gator in the swamp said, “Why <br>
Do tourists grin and wave at me?” <br>
He snapped his jaws and gave a sigh, <br>
“I’m hunting lunch, not waving, see?”</p>
<p>A crab clicked past on flaming sand, <br>
Complained the heat was much too strong. <br>
Said, “Palms are neat, but understand— <br>
This sunshine really doesn’t last long.”</p>
<p>The man just laughed and tossed shrimp near. <br>
The gator winked. “They’re always silly here.”</p>
<ul>
<li><a href="https://news.ycombinator.com/item?id=45000270">Discuss this post on Hacker News</a></li>
</ul>

    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tesla insiders have sold more than 50% of their shares in the last year (107 pts)]]></title>
            <link>https://electrek.co/2025/08/18/tesla-tsla-insiders-have-sold-more-than-50-of-their-shares-in-the-last-year/</link>
            <guid>45000248</guid>
            <pubDate>Sun, 24 Aug 2025 00:36:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://electrek.co/2025/08/18/tesla-tsla-insiders-have-sold-more-than-50-of-their-shares-in-the-last-year/">https://electrek.co/2025/08/18/tesla-tsla-insiders-have-sold-more-than-50-of-their-shares-in-the-last-year/</a>, See on <a href="https://news.ycombinator.com/item?id=45000248">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="766" src="https://electrek.co/wp-content/uploads/sites/3/2025/04/Tesla-family-hero.png?w=1600" alt="Tesla family hero" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/04/Tesla-family-hero.png?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/04/Tesla-family-hero.png?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/04/Tesla-family-hero.png?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/04/Tesla-family-hero.png?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>Tesla insiders have been unloading their shares at an impressive rate. Excluding CEO Elon Musk, Tesla executives and board members have sold more than 50% of their TSLA shares over the last year.</p>



<p>And that might only be part of the story.</p>



<p>Public companies are required to report insider trading by key executives and board members.</p>



<p>In recent years, Tesla’s number of key executives has dwindled to now only three:</p>	
	



<ul>
<li>Elon Musk</li>



<li>Tom Zhu</li>



<li>Vaibhav Taneja</li>
</ul>



<p>Here’s Tesla’s corporate governance page on its investor relations website:</p>



<figure><img decoding="async" height="573" width="1024" src="https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?w=1024" alt="" srcset="https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png 2444w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=150,84 150w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=300,168 300w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=768,430 768w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=1024,573 1024w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=1536,860 1536w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=2048,1146 2048w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=350,196 350w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=140,78 140w, https://electrek.co/wp-content/uploads/sites/3/2025/08/Screenshot-2025-08-18-at-10.23.57-AM.png?resize=1600,896 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>That’s partly due to several of them leaving in the last year, including Drew Baglino, who was the de facto head of engineering and was listed as a key executive before leaving last year.</p>



<p>It’s also because Musk is known to micro-manage, resulting in him having many direct reports who would generally go through other department heads.</p>



<p>The result is that only two Tesla executives, in addition to Musk, who would have to report his transactions even if he weren’t CEO, since he owns more than 10% of the company, are required to report their stock transactions.</p>



<p>Based on Tesla’s 2024 proxy statement, here were the insider ownership last year:</p>



<figure><table><thead><tr><th>TSLA Insider Ownership</th><th>Total</th><th>Shares</th><th>Options</th></tr></thead><tbody><tr><td>Elon Musk</td><td>715,022,706</td><td>303,960,630</td><td>411,062,076</td></tr><tr><td>Vaibhav Taneja</td><td>1,063,544</td><td>105,032</td><td>958,512</td></tr><tr><td>Andrew Baglino</td><td>1,218,669</td><td>31,230</td><td>1,187,439</td></tr><tr><td>Tom Zhu</td><td>1,996,983</td><td>63,171</td><td>1,933,812</td></tr><tr><td>Robyn Denholm</td><td>1,490,069</td><td>15,000</td><td>1,475,069</td></tr><tr><td>Ira Ehrenpreis</td><td>1,681,005</td><td>1,571,005</td><td>110,000</td></tr><tr><td>Joe Gebbia</td><td>111</td><td>111</td><td>0</td></tr><tr><td>James Murdoch</td><td>1,427,295</td><td>157,275</td><td>1,270,020</td></tr><tr><td>Kimbal Musk</td><td>1,950,470</td><td>1,608,720</td><td>341,750</td></tr><tr><td>Kathleen Wilson‑Thompson</td><td>771,255</td><td>5,400</td><td>765,855</td></tr><tr><td><strong>TOTAL</strong></td><td><strong>726,622,107</strong></td><td><strong>307,517,574</strong></td><td><strong>419,104,533</strong></td></tr><tr><td><strong>TOTAL Excl. Elon Musk</strong></td><td><strong>11,599,401</strong></td><td><strong>3,556,944</strong></td><td><strong>8,042,457</strong></td></tr></tbody></table></figure>



<p>Now here’s the ownership of Tesla shares and options from insiders based on the 2025 proxy statement:</p>



<figure><table><thead><tr><th>Name</th><th><strong>Total</strong></th><th><strong>Shares</strong></th><th><strong>Options</strong></th><th><strong>As‑of (filing)</strong></th></tr></thead><tbody><tr><td>Elon Musk</td><td>714,754,706</td><td>410,794,076</td><td>303,960,630</td><td>12/31/2024 (10‑K/A filed 4/30/2025)</td></tr><tr><td>Vaibhav Taneja</td><td>830,844</td><td>116,924</td><td>713,920</td><td>7/8/2025</td></tr><tr><td>Andrew Baglino</td><td>520,005</td><td>31,230</td><td>488,775</td><td>4/1/2024 (latest)</td></tr><tr><td>Tom Zhu</td><td>348,250</td><td>67,600</td><td>280,650</td><td>6/12/2025</td></tr><tr><td>Robyn Denholm</td><td>85,000</td><td>85,000</td><td>0</td><td>5/6/2025</td></tr><tr><td>Ira Ehrenpreis</td><td>855,394</td><td>855,394</td><td>0</td><td>5/27/2025</td></tr><tr><td>Joe Gebbia</td><td>4,111</td><td>4,111</td><td>0</td><td>4/24/2025</td></tr><tr><td>James Murdoch</td><td>1,282,519</td><td>884,306</td><td>398,213</td><td>3/10/2025</td></tr><tr><td>Kimbal Musk</td><td>1,463,220</td><td>1,463,220</td><td>0</td><td>5/27/2025</td></tr><tr><td>Kathleen Wilson‑Thompson</td><td>5,400</td><td>5,400</td><td><strong>0</strong></td><td>5/1/2025 (options canceled)</td></tr><tr><td><strong>TOTAL (sum of listed rows)</strong></td><td><strong>720,149,449</strong></td><td><strong>414,307,261</strong></td><td><strong>305,842,188</strong></td><td></td></tr><tr><td><strong>TOTAL excl. Elon Musk</strong></td><td><strong>5,394,743</strong></td><td><strong>3,513,185</strong></td><td><strong>1,881,558</strong></td><td></td></tr></tbody></table></figure>



<p>As you can see, excluding Musk, Tesla insiders sold more than half their shares in the company over the last year.</p>



<p>To be fair, some of those changes also include cancellations of stock options for board members, who settled <a href="https://electrek.co/2025/01/08/tesla-board-members-officially-settle-excessive-compensation-case-for-nearly-1-billion/" target="_blank" rel="noreferrer noopener">a shareholders’ lawsuit for having overcompensated themselves</a>.</p>



<p>However, it doesn’t account for the reduction in ownership of more than 6 million shares and stock options, worth approximately $2 billion at today’s share price.</p>



<p>There are also some specific examples of non-board members liquidating their stakes.</p>



<p>Tom Zhu, who has led Tesla’s manufacturing efforts and was at times seen as Musk’s number 2 at Tesla, reduced his stake by 82% in a single year.</p>



<p>This happened while Musk claimed that Tesla will become the most valuable company in the world and roughly 10x its current stock price due to autonomous driving and robots, a claim most unbiased analysts have been highly skeptical about.</p>



<h2 id="h-electrek-s-take">Electrek’s Take</h2>



<p>More than 50% reduction in ownership in a single year is wild.</p>



<p>But as I hinted at the beginning of the article, this is only what we can see. Other Tesla execs, managers, and employees also have shares and stock options, and they could potentially be selling at an even higher rate. We simply don’t know.</p>




	<p>The single reporting person to have bought shares is Joe Gebbia, who only bought about $1 million worth, and he is a multi-billionaire. It would be the equivalent of me buying a few hundred dollars’ worth of Electrek shares – not a great show of confidence in my company.</p>



<p> I’m not in the business of predicting Tesla’s share price. I think it trades mainly on gullible Tesla retail shareholders believing Musk’s lies.</p>



<p>But I believe that Tesla will likely face several challenging quarters in the next few years and may even start incurring losses.  I think many executives also see this coming and don’t believe that autonomy and humanoid robots will have a positive financial contribution for a few years, as Musk claims.</p>



<p>Meanwhile, Tesla’s EV business is struggling, and there’s little hope of reversing the trend without fresh new models and innovation – the pace of which appears to have greatly slowed at Tesla, unfortunately.</p>
	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMKqD-Qow6c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add Electrek to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AGI is an engineering problem, not a model training problem (177 pts)]]></title>
            <link>https://www.vincirufus.com/posts/agi-is-engineering-problem/</link>
            <guid>45000176</guid>
            <pubDate>Sun, 24 Aug 2025 00:18:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.vincirufus.com/posts/agi-is-engineering-problem/">https://www.vincirufus.com/posts/agi-is-engineering-problem/</a>, See on <a href="https://news.ycombinator.com/item?id=45000176">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="article"> <p>We’ve reached an inflection point in AI development. The scaling laws that once promised ever-more-capable models are showing diminishing returns. GPT-5, Claude, and Gemini represent remarkable achievements, but they’re hitting asymptotes that brute-force scaling can’t solve. The path to artificial general intelligence isn’t through training ever-larger language models—it’s through building engineered systems that combine models, memory, context, and deterministic workflows into something greater than their parts.</p>
<p>Let me be blunt: <strong>AGI is an engineering problem, not a model training problem.</strong></p>
<h2 id="the-plateauing-reality">The Plateauing Reality</h2>
<p>The current generation of large language models has hit a wall that’s become increasingly obvious to anyone working with them daily. They’re impressive pattern matchers and text generators, but they remain fundamentally limited by their inability to maintain coherent context across sessions, their lack of persistent memory, and their stochastic nature that makes them unreliable for complex multi-step reasoning.</p>
<p>We’ve seen this movie before. Every technology wave follows the same trajectory: initial breakthrough, rapid scaling, then increasing marginal costs for decreasing marginal gains. The semiconductor industry hit this wall in the early 2000s when clock speed scaling became impossible. The solution then wasn’t to brute-force faster processors—it was to fundamentally rethink the architecture with multi-core designs.</p>
<p><strong>AI is at the same inflection point.</strong> We need to stop asking “how do we make the model bigger?” and start asking “how do we make the system smarter?”</p>
<h2 id="the-systems-approach-to-agi">The Systems Approach to AGI</h2>
<p>The human brain isn’t a single neural net—it’s a collection of specialized systems working in concert: memory formation, context management, logical reasoning, spatial navigation, language processing. Each system has evolved specific purposes, and they operate asynchronously with complex feedback loops between them.</p>
<p><strong>True AGI requires us to engineer similar systems. Here’s what we actually need to build:</strong></p>
<h3 id="1-context-management-as-infrastructure">1. Context Management as Infrastructure</h3>
<p>Current models have attention spans measured in thousands of tokens. Human context span extends across years of lived experience. The gap isn’t just quantitative—it’s qualitative. We need context management systems that can:</p>
<ul>
<li><strong>Retrieve and filter relevant information</strong> on-demand using sophisticated retrieval systems</li>
<li><strong>Maintain coherent world models</strong> that persist across sessions and evolve with new information</li>
<li><strong>Bridge context gaps</strong> between different specialized knowledge domains</li>
<li><strong>Handle conflicting information</strong> with probabilistic weighting and uncertainty quantification</li>
</ul>
<p>This requires moving beyond simple vector similarity searches to building operational knowledge graphs that can be updated, queried, and reasoned about in real-time. <a href="https://www.vincirufus.com/blog/context-engineering">Our work on Context Engineering</a> provides a foundation for these systems.</p>
<h3 id="2-memory-as-a-service">2. Memory as a Service</h3>
<p>LLMs don’t have memory—they engage in elaborate methods to fake it through prompt engineering and context stuffing. Real AGI needs memory systems that:</p>
<ul>
<li><strong>Update beliefs</strong> when contradicted by new evidence</li>
<li><strong>Consolidate information</strong> across multiple experiences into general principles</li>
<li><strong>Forget irrelevant details</strong> without catastrophic forgetting</li>
<li><strong>Generate meta-knowledge</strong> about the reliability and source of stored information</li>
</ul>
<p>This isn’t just database persistence—it’s building memory systems that evolve the way human memory does: strengthening with use, decaying with disuse, and reorganizing based on new understanding. The <a href="https://www.vincirufus.com/blog/adr">architectural patterns from software systems</a> show us how to design such evolving structures.</p>
<h3 id="3-deterministic-workflows-with-probabilistic-components">3. Deterministic Workflows with Probabilistic Components</h3>
<p>The real breakthrough in AGI will come from building deterministic frameworks that can incorporate probabilistic components when appropriate. Think of it like building a compiler: the overall flow is rigid and predictable, but individual steps can use heuristics and probabilistic optimization.</p>
<p><strong>We need systems that can:</strong></p>
<ul>
<li><strong>Route problems</strong> to appropriate specialized solvers based on problem characteristics</li>
<li><strong>Execute multi-step workflows</strong> with rollback and recovery capabilities</li>
<li><strong>Validate outputs</strong> through deterministic checks before accepting probabilistic results</li>
<li><strong>Compose capabilities</strong> in predictable ways while maintaining the benefits of stochastic generation</li>
</ul>
<p>Our <a href="https://www.vincirufus.com/blog/deterministic-vs-propapbistic">research on deterministic vs. probabilistic systems</a> demonstrates how we can build these hybrid architectures effectively. The key insight is that <strong>uncertainty should be a first-class concept</strong> in system design, not something we try to eliminate.</p>
<h3 id="4-specialized-models-as-modular-components">4. Specialized Models as Modular Components</h3>
<p>The future isn’t one model to rule them all—it’s hundreds or thousands of specialized models working together in orchestrated workflows. Language models remain excellent at linguistic tasks, but they’re terrible at:</p>
<ul>
<li><strong>Symbolic manipulation</strong> and exact calculation</li>
<li><strong>Visual-spatial reasoning</strong> beyond basic pattern matching</li>
<li><strong>Temporal reasoning</strong> and planning complex sequences</li>
<li><strong>Intentional agent behavior</strong> with persistent goals</li>
</ul>
<p>Instead of waiting for a breakthrough that makes language models good at everything, we should be building systems that:</p>
<ul>
<li><strong>Route problems</strong> to models optimized for specific domains (<a href="https://www.vincirufus.com/blog/thinking-in-agents">thinking in agents</a> demonstrates this approach)</li>
<li><strong>Combine outputs</strong> from different model types into coherent solutions</li>
<li><strong>Maintain compatibility</strong> while allowing individual components to evolve independently</li>
<li><strong>Handle failure gracefully</strong> when individual models underperform</li>
</ul>
<h2 id="the-engineering-challenge">The Engineering Challenge</h2>
<p>This brings us to the core insight: <strong>building AGI is a distributed systems problem, not a machine learning problem.</strong> We’ve been fooled into thinking that because data center-scale training clusters are distributed systems, we’re already doing systems engineering. Nothing could be further from the truth.</p>
<p><strong>The real engineering challenge is building:</strong></p>
<ul>
<li><strong>Fault-tolerant pipelines</strong> where component failures don’t cascade into system failures</li>
<li><strong>Monitoring and observability</strong> systems that can detect when model outputs are drifting or becoming unreliable</li>
<li><strong>Deployment systems</strong> that allow for rolling updates without breaking existing integrations</li>
<li><strong>Testing frameworks</strong> that can validate system behavior across thousands of model and parameter combinations</li>
</ul>
<p>This is the kind of engineering challenge that requires decades of distributed systems experience, not just machine learning expertise. The solutions will come from infrastructure engineers who understand how to build reliable, scalable systems at the intersection of hardware, software, and AI models.</p>
<h2 id="what-we-should-be-building-instead">What We Should Be Building Instead</h2>
<p>While everyone else is focused on scaling the next model, we should be building the infrastructure that makes general intelligence possible. Here’s my roadmap:</p>
<h3 id="phase-1-foundation-layer">Phase 1: Foundation Layer</h3>
<ul>
<li><strong>Context Management Service</strong>: Persistent, queryable, versioned knowledge graphs with real-time updates</li>
<li><strong>Memory Service</strong>: Episodic and semantic memory systems with learned consolidation patterns</li>
<li><strong>Workflow Engine</strong>: Deterministic orchestration of probabilistic components with rollback capabilities</li>
<li><strong>Agent Coordination Layer</strong>: Multi-agent systems with negotiated consensus and conflict resolution</li>
</ul>
<h3 id="phase-2-capability-layer">Phase 2: Capability Layer</h3>
<ul>
<li><strong>Specialized Model Controls</strong>: Fine-tuned models for specific reasoning domains with standardized interfaces</li>
<li><strong>Symbolic Reasoning Engine</strong>: Exact calculation and symbolic manipulation capabilities that work with probabilistic components</li>
<li><strong>Planning and Goal Management</strong>: Systems that can break complex objectives into executable sub-plans</li>
<li><strong>Cross-modal Integration</strong>: Systems that combine sensory inputs (text, vision, audio) into unified representations</li>
</ul>
<h3 id="phase-3-emergence-layer">Phase 3: Emergence Layer</h3>
<p>This is where real AGI emerges—from the interaction of all these components working together, not from any single breakthrough model. The system’s capabilities will exceed those of its individual parts through emergent properties that arise from careful architectural design.</p>
<h2 id="the-path-forward">The Path Forward</h2>
<p>The path to AGI isn’t through training a bigger transformer—it’s through building distributed systems that can orchestrate hundreds of specialized models, maintain coherent context across sessions, execute deterministic workflows around probabilistic components, and provide fault-tolerant operation at production scale.</p>
<p>This is fundamentally <strong>engineering work</strong>, requiring decades of experience building reliable distributed systems. The breakthroughs will come from infrastructure engineers who understand how to build context paths, memory systems, workflow orchestration, and model coordination at scale.</p>
<p><strong>The race to AGI isn’t being won by the team with the biggest GPU cluster—it’s being won by the team that understands how to build reliable, engineered AI systems that can actually reason across domains while maintaining consistent behavior.</strong></p>
<p>The models we have now are sufficient. The missing piece is the systems engineering that turns them into general intelligence.</p>
<p>We’ve been asking the wrong question. It’s not “how do we get to the next model breakthrough?” It’s “how do we build the system architecture that makes general intelligence inevitable with the models we already have?”</p>
<p>The answer is systems engineering. The future of AGI is architectural, not algorithmic.</p> </article></div>]]></description>
        </item>
    </channel>
</rss>