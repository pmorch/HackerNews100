(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 01 Sep 2024 17:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Apple and Nvidia in talks to invest in ChatGPT (122 pts)]]></title>
            <link>https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</link>
            <guid>41418302</guid>
            <pubDate>Sun, 01 Sep 2024 16:46:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30">https://www.businesstoday.in/technology/news/story/apple-nvidia-in-talks-to-invest-in-chatgpt-maker-openai-potentially-valuing-company-over-100-billion-443624-2024-08-30</a>, See on <a href="https://news.ycombinator.com/item?id=41418302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="descriptionStoryId"><p>Apple and Nvidia are reportedly in talks to invest in OpenAI, the company behind ChatGPT, as part of a new fundraising round. This round could potentially value OpenAI at over $100 billion, according to media reports.</p>

<p>The Wall Street Journal reported that Apple is exploring the possibility of joining the funding round, while Bloomberg News indicated Nvidia’s potential involvement. This comes after news that Thrive Capital, a venture capital firm, is planning to invest around $1 billion in OpenAI, leading the current fundraising efforts.</p><div><h4>Related Articles</h4><div><ul><li><a target="_blank" title="OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation" href="https://www.businesstoday.in/technology/news/story/openai-launches-fine-tuning-for-gpt-4o-unlocking-enhanced-performance-and-customisation-442518-2024-08-22">OpenAI launches fine-tuning for GPT-4o, unlocking enhanced performance and customisation</a></li><li><a target="_blank" title="Ex-Google CEO thinks company's ‘work-life balance’ mentality is why it is losing AI race to startups like OpenAI" href="https://www.businesstoday.in/technology/news/story/ex-google-ceo-thinks-companys-work-life-balance-mentality-is-why-it-is-losing-ai-race-to-startups-like-openai-441535-2024-08-14">Ex-Google CEO thinks company's ‘work-life balance’ mentality is why it is losing AI race to startups like OpenAI</a></li></ul></div></div>

<p>OpenAI has become increasingly integral to Apple’s AI strategy. In June, Apple introduced OpenAI’s chatbot, ChatGPT, to its devices under the initiative called “Apple Intelligence.” Additionally, Apple is reportedly set to gain an observer role on OpenAI’s board, highlighting the deepening relationship between the two companies.</p>

<p>Microsoft, OpenAI’s largest investor with over $10 billion already committed, is also expected to participate in this new funding round. However, the specific amounts that Apple, Nvidia, and Microsoft are planning to invest have not been disclosed.</p>

<p>OpenAI’s rising valuation is a result of the intense competition in the AI sector, which intensified after the launch of ChatGPT in late 2022. This launch spurred companies across various industries to pour billions into AI technology to stay competitive. Earlier this year, OpenAI was valued at $80 billion following a tender offer led by Thrive Capital, where the firm sold existing shares.<br>
&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a Leading Chain of Psychiatric Hospitals Traps Patients (141 pts)]]></title>
            <link>https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</link>
            <guid>41417284</guid>
            <pubDate>Sun, 01 Sep 2024 14:33:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html">https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html</a>, See on <a href="https://news.ycombinator.com/item?id=41417284">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/09/01/business/acadia-psychiatric-patients-trapped.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Linkpreview, see how your sites looks in social media and chat apps (123 pts)]]></title>
            <link>https://linkpreview.xyz</link>
            <guid>41416714</guid>
            <pubDate>Sun, 01 Sep 2024 13:07:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://linkpreview.xyz">https://linkpreview.xyz</a>, See on <a href="https://news.ycombinator.com/item?id=41416714">Hacker News</a></p>
<div id="readability-page-1" class="page"><!--teleport start anchor--><!--teleport anchor--><div id="__nuxt"><!--[--><div><!--[--><header><div><svg fill="none" height="48" viewBox="0 0 48 48" width="48" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><filter id="a" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="54" width="48" x="0" y="-3"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feBlend in="SourceGraphic" in2="BackgroundImageFix" mode="normal" result="shape"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="-3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.1 0"></feColorMatrix><feBlend in2="shape" mode="normal" result="effect1_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feOffset dy="3"></feOffset><feGaussianBlur stdDeviation="1.5"></feGaussianBlur><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0.1 0"></feColorMatrix><feBlend in2="effect1_innerShadow_3051_46941" mode="normal" result="effect2_innerShadow_3051_46941"></feBlend><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1" result="effect3_innerShadow_3051_46941"></feMorphology><feOffset></feOffset><feComposite in2="hardAlpha" k2="-1" k3="1" operator="arithmetic"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.0627451 0 0 0 0 0.0941176 0 0 0 0 0.156863 0 0 0 0.24 0"></feColorMatrix><feBlend in2="effect2_innerShadow_3051_46941" mode="normal" result="effect3_innerShadow_3051_46941"></feBlend></filter><filter id="b" color-interpolation-filters="sRGB" filterUnits="userSpaceOnUse" height="42" width="36" x="6" y="5.25"><feFlood flood-opacity="0" result="BackgroundImageFix"></feFlood><feColorMatrix in="SourceAlpha" result="hardAlpha" type="matrix" values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"></feColorMatrix><feMorphology in="SourceAlpha" operator="erode" radius="1.5" result="effect1_dropShadow_3051_46941"></feMorphology><feOffset dy="2.25"></feOffset><feGaussianBlur stdDeviation="2.25"></feGaussianBlur><feComposite in2="hardAlpha" operator="out"></feComposite><feColorMatrix type="matrix" values="0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0 0.141176 0 0 0 0.1 0"></feColorMatrix><feBlend in2="BackgroundImageFix" mode="normal" result="effect1_dropShadow_3051_46941"></feBlend><feBlend in="SourceGraphic" in2="effect1_dropShadow_3051_46941" mode="normal" result="shape"></feBlend></filter><linearGradient id="c" gradientUnits="userSpaceOnUse" x1="24" x2="26" y1=".000001" y2="48"><stop offset="0" stop-color="#fff" stop-opacity="0"></stop><stop offset="1" stop-color="#fff" stop-opacity=".12"></stop></linearGradient><linearGradient id="d" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="9" y2="39"><stop offset="0" stop-color="#fff" stop-opacity=".8"></stop><stop offset="1" stop-color="#fff" stop-opacity=".5"></stop></linearGradient><linearGradient id="e" gradientUnits="userSpaceOnUse" x1="24" x2="24" y1="0" y2="48"><stop offset="0" stop-color="#fff" stop-opacity=".12"></stop><stop offset="1" stop-color="#fff" stop-opacity="0"></stop></linearGradient><clipPath id="f"><rect height="48" rx="12" width="48"></rect></clipPath><g filter="url(#a)"><g clip-path="url(#f)"><rect fill="#0c111d" height="48" rx="12" width="48"></rect><path d="m0 0h48v48h-48z" fill="url(#c)"></path><g filter="url(#b)"><path clip-rule="evenodd" d="m15 9c-3.3137 0-6 2.6863-6 6v18c0 3.3137 2.6863 6 6 6h18c3.3137 0 6-2.6863 6-6v-18c0-3.3137-2.6863-6-6-6zm2.25 11.625h7.4733l-8.7991 8.7992 2.6516 2.6516 8.7992-8.7991v7.4733h3.75v-12c0-1.0355-.8395-1.875-1.875-1.875h-12z" fill="url(#d)" fill-rule="evenodd"></path></g></g><rect height="46" rx="11" stroke="url(#e)" stroke-width="2" width="46" x="1" y="1"></rect></g></svg><p>LinkPreview</p></div><div><!--[--><a href="https://supersaas.dev/" rel="noopener noreferrer" target="_blank"><!--[--><!--[--><!----><!--]--><!--[--><img src="https://supersaas.dev/logo.png" alt="Supersaas"><!--]--><!--[--><!----><!--]--><!--]--></a><!--]--><!--[--><!--]--></div></header><div><form data-n-ids="{&quot;np6cif8hBbo-0&quot;:&quot;np6cif8hBbo-0&quot;}"><!--[--><!--]--></form><!----></div><!--[--><p><a href="https://supersaas.dev/" target="_blank"><img src="https://essentials.supersaas.dev/supersaas-banner.png" alt="Supersaas"></a></p><!--]--><!--]--></div><!--]--><section aria-label="Notifications alt+T" tabindex="-1"><!--[--><ol data-sonner-toaster="" dir="ltr" tabindex="-1" data-theme="light" data-rich-colors="false" data-y-position="top" data-x-position="center"><!--[--><!--]--></ol><!--]--></section><!--teleport start--><!--teleport end--></div>
</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Anarchy in Sudan has spawned the world’s worst famine in 40 years (204 pts)]]></title>
            <link>https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</link>
            <guid>41415819</guid>
            <pubDate>Sun, 01 Sep 2024 10:48:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years">https://www.economist.com/briefing/2024/08/29/anarchy-in-sudan-has-spawned-the-worlds-worst-famine-in-40-years</a>, See on <a href="https://news.ycombinator.com/item?id=41415819">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><main role="main" id="content"><article data-test-id="Article" id="new-article-template"><div data-test-id="standard-article-template"><section><p><span><a href="https://www.economist.com/briefing" data-analytics="sidebar:section"><span>Briefing</span></a></span><span> | <!-- -->An intensifying calamity</span></p><h2>Anarchy in Sudan has spawned the world’s worst famine in 40 years</h2><h2>Millions are likely to perish</h2></section><section><figure><img alt="Sudanese refugees wait for food distribution at a camp in Chad" fetchpriority="high" width="1280" height="720" decoding="async" data-nimg="1" sizes="(min-width: 960px) 700px, 95vw" srcset="https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/content-assets/images/20240831_FBP001.jpg"><figcaption><span>Photograph: Panos Pictures/ Sven Torfinn</span></figcaption></figure></section><div><section data-body-id="cp2"><p data-component="paragraph"><span data-caps="initial">I</span><small>T IS OFFICIAL</small>: for only the third time in the past 20 years, the <small>UN</small> has declared a full-blown famine. The declaration concerns a refugee camp called Zamzam, on the outskirts of the city of el-Fasher in Sudan. As long ago as April, Médecins Sans Frontières, a charity, estimated that every two hours a child in the camp was dying from starvation or disease—and since then the situation has got worse.</p></section><p>This article appeared in the Briefing section of the print edition under the headline “An intensifying calamity”</p><div orientation="vertical" data-test-id="vertical"><div orientation="vertical"><figure><img alt="Sudan: Why its catastrophic war is the world’s problem" loading="lazy" width="1280" height="1709" decoding="async" data-nimg="1" sizes="300px" srcset="https://www.economist.com/cdn-cgi/image/width=16,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 16w, https://www.economist.com/cdn-cgi/image/width=32,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 32w, https://www.economist.com/cdn-cgi/image/width=48,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 48w, https://www.economist.com/cdn-cgi/image/width=64,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 64w, https://www.economist.com/cdn-cgi/image/width=96,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 96w, https://www.economist.com/cdn-cgi/image/width=128,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 128w, https://www.economist.com/cdn-cgi/image/width=256,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 256w, https://www.economist.com/cdn-cgi/image/width=360,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 360w, https://www.economist.com/cdn-cgi/image/width=384,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 384w, https://www.economist.com/cdn-cgi/image/width=480,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 480w, https://www.economist.com/cdn-cgi/image/width=600,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 600w, https://www.economist.com/cdn-cgi/image/width=834,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 834w, https://www.economist.com/cdn-cgi/image/width=960,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 960w, https://www.economist.com/cdn-cgi/image/width=1096,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1096w, https://www.economist.com/cdn-cgi/image/width=1280,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1280w, https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg 1424w" src="https://www.economist.com/cdn-cgi/image/width=1424,quality=80,format=auto/media-assets/image/20240831_DE_EU.jpg"></figure></div><div orientation="vertical"><h3 orientation="vertical">From the August 31st 2024 edition</h3><p orientation="vertical">Discover stories from this section and more in the list of contents</p><p><a href="https://www.economist.com/weeklyedition/2024-08-31" data-analytics="sidebar:weekly_edition"><span>Explore the edition</span></a></p></div></div></div></div></article></main></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Einstein's Other Theory of Everything (106 pts)]]></title>
            <link>https://nautil.us/einsteins-other-theory-of-everything-823245/</link>
            <guid>41415647</guid>
            <pubDate>Sun, 01 Sep 2024 10:09:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nautil.us/einsteins-other-theory-of-everything-823245/">https://nautil.us/einsteins-other-theory-of-everything-823245/</a>, See on <a href="https://news.ycombinator.com/item?id=41415647">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                        
            <p><span>E</span>instein finished his masterwork, the theory of general relativity, in 1915. He was 37 years old and would live for another 40 years. He spent these decades in the attempt to explain that everything—matter, energy, and even ourselves—were simply deformations of spacetime.&nbsp;</p><p>Einstein, feeling that his theory of general relativity was incomplete, wanted to develop a unified field theory—a framework that would combine space and time with energy and matter. (Indeed, it was Einstein who coined the term “unified theory.”) He ultimately failed. But I have begun to wonder if his idea, as ambitious as it was startling, isn’t worth revisiting.</p>
      
    <p>Einstein built his unified theory off of general relativity, which says that gravity is a property of spacetime. This is often depicted with a marble that weighs down a rubber sheet. The rubber sheet is spacetime, the marble’s mass provides gravity. If a smaller marble rolls by the larger one, it will not roll in a straight line. It will roll in a curve as if it was attracted to the bigger marble. You need that marble to cause the curvature in the first place. It’s the same in Einstein’s general relativity: You need spacetime <em>and</em> matter in it to describe what we see happening in the universe.</p><p>Einstein seems to have tried to find a theory in which there is <em>only</em> spacetime and <em>no</em> matter—and in which we only interpret some of the spacetime as matter. He wanted to find equations that would have solutions that correspond to the fundamental particles of nature, such as electrons.</p>
          <blockquote>
<p>Einstein and Rosen assumed the black hole has no inside and instead connects two universes.</p>
</blockquote><p>When Einstein set out to find this theory, in the first half of the 20th century, physicists’ knowledge of the properties of matter and how it behaved were incomplete. Today, we know of four fundamental interactions. Beside gravity, there’s electromagnetism and the strong and weak nuclear interactions. But in the early 20th century, the strong nuclear interaction had not yet been discovered, and the theory for the weak nuclear interaction had not yet been developed. Einstein therefore really only had two interactions to work with to make sense of matter: gravity and electromagnetism. The gravitational force law, also known as Newton’s law, is similar to that for electric charges, known as Coulomb’s law. And because Einstein had been so successful with describing gravity as the curvature of space, he wondered whether electromagnetism could be described in much the same way.</p><p>In 1919, Einstein published a <a href="https://einsteinpapers.press.princeton.edu/vol7-trans/96" target="_blank" rel="noreferrer noopener">paper</a> titled “Do gravitational fields play an essential role in the structure of the elementary particles of matter?” The idea he pursued in the paper was to take a modified version of general relativity, with different field equations, then add electromagnetism and ask whether this would give rise to solutions that could be interpreted as particles.</p><p>The conclusion he arrived at is: No, this doesn’t work because the quantity that could be interpreted as mass could take on any value, whereas the particles that matter are made of have very specific values.</p>
          <p>In 1923, he published another paper in which he basically said that his previous idea to make matter from spacetime didn’t work because there were some equations missing. He then proposed some equations that might do the job … but again concluded that this doesn’t work</p><p>In 1925, he published yet <em>another</em> paper in which he said that he had been trying for two years to combine electromagnetism with gravity, and it didn’t work.&nbsp;</p><p>But Einstein had another clue for his unified theory: black holes.</p><p>You see, as soon as Einstein had finished his theory of general relativity, the German physicist and astronomer Karl Schwarzschild discovered a solution to Einstein’s equations that described what we now call black holes. But this solution has singularities, places where some quantities take on infinite values. Einstein thought that this couldn’t be right. Singularities shouldn’t happen in reality. And if his theory allowed those, then there was something wrong with it. He therefore tried to use the requirement that singularities should be absent to go back and find solutions that would describe elementary particles.</p>
          <p>But he made a mistake there. In Schwarzschild’s black hole solution, there isn’t just one singularity, but two. One is at the horizon of the black hole, the other in the center. We know today that the singularity at the horizon does not correspond to any physically measurable quantity. It’s a mathematical artifact that can be removed. Einstein tried to find a way to remove this singularity that wasn’t there. (You’d think that physicists would have learned from this that it’s a mistake to go on about the properties of unobservable quantities, but still, it’s the same mistake that led to all these wrong predictions for the Large Hadron Collider. But I digress.)</p><blockquote>
<p>I want to call this Einstein’s Other Theory of Everything: that matter is really just made of spacetime.</p>
</blockquote><div><p>Einstein’s quest to get rid of black hole singularities is what led to his famous paper with Nathan Rosen in 1935, in which they introduced what is now called an Einstein-Rosen bridge. They assumed the black hole has no inside and instead connects two universes. It’s the simplest known example of a wormhole.</p><p>But they didn’t write the paper to introduce wormholes. Einstein and Rosen thought these wormholes were elementary particles. After they’d constructed their bridge, they wrote very clearly, “We see now in the given solution, free from singularities, the mathematical representation of an elementary particle (neutrons or neutrinos).”</p></div><div><p>They then went on to add electric charges and interpreted those as charged particles. Now, we know today that neutrons are not elementary particles, they are made of smaller particles (quarks and gluons). But this wasn’t the main problem with the idea. The main problem is that one can calculate the size of the bridge, or wormhole, or whatever you want to call it, from its mass. And that’d tell you that the “size” of a neutron would be about 10<sup>-52</sup> centimeters. That’s more than 30 orders of magnitude smaller than its actual size. For other elementary particles, this becomes even more extreme.</p><p>This means that if elementary particles were wormholes or black holes, they would be much smaller than the quantum uncertainty that we measure. (Stephen Hawking also taught us that they’d be unstable, but again, Einstein couldn’t have known this.)</p></div>
          <div><p>In any case, he didn’t pursue this idea further. Instead, he pursued a different direction which he had proposed in 1925: that the properties of matter are encoded in the relations between different locations in spacetime, an approach that he dubbed “tele-parallelism.” It is this tele-parallelism that later became known as Einstein’s unified field theory. It has, however, little to do with his original idea.</p><p>This teleparallel approach to a unified field theory was not pursued after Einstein’s death in 1955. Because by then it had become clear that it wasn’t compatible with the new things that physicists had discovered, such as the weak and strong nuclear forces.</p></div><p>That said, I find it somewhat surprising—and maybe even concerning—that physicists have also thrown out Einstein’s original idea, that I want to call his Other Theory of Everything: that matter is really just made of spacetime, curved in a particular way. The notion has survived in some areas of physics, where such objects are known as “solitons”—or noise-free subsystems—but mostly it’s been given up.&nbsp;</p><p>It has been replaced by a different idea of unification, that matter and spacetime are both made of something else, such as, for example, strings or loops or networks.</p><p>So why am I returning to this old story? Primarily because I think it’s interesting what Einstein, undoubtedly one of the most intelligent people to walk on this planet, did with much of his life. But also because I don’t want Einstein’s idea—about what we and the universe might be made out of—to be forgotten. <img decoding="async" src="https://assets.nautil.us/sites/3/nautilus/nautilus-favicon-14.png?fm=png" alt=""></p>
          <p><em>Lead image: Muhammad suryanto / Shutterstock</em></p>              
                            <ul>
                                      <li>
                      <div>
                        <h6>
                          Sabine Hossenfelder                        </h6>
                        <p>
                          Posted on <time datetime="2024-08-30T10:39:35-05:00">August 30, 2024</time>
                        </p>
                      </div>
                                                <p>
                            Sabine Hossenfelder is a theoretical physicist at the Munich Center for Mathematical Philosophy, in Germany, focusing on modifications of general relativity, phenomenological quantum gravity, and the foundations of quantum mechanics. She is the creative director of the YouTube channel <a href="https://www.youtube.com/channel/UC1yNl2E66ZzKApQdRuTQ4tw">“Science without the gobbledygook”</a> where she talks about recent scientific developments and debunks hype. Her latest book is <i><a href="https://www.penguinrandomhouse.com/books/616868/existential-physics-by-sabine-hossenfelder/">Existential Physics: A Scientist’s Guide to Life’s Biggest Questions</a></i>. Follow her on X (formerly known as Twitter) <a href="https://twitter.com/skdh">@skdh</a>.                          </p>
                                            </li>
                                  </ul>
            <div>
  <p><img src="https://nautil.us/wp-content/themes/nautilus-block-theme/images/icons/logo-icon.svg" alt="new_letter"></p><div>
    <h4>Get the Nautilus newsletter</h4>
    <p>Cutting-edge science, unraveled by the very brightest living thinkers.</p>
  </div>

  
</div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Honey, I shrunk {fmt}: bringing binary size to 14k and ditching the C++ runtime (173 pts)]]></title>
            <link>https://vitaut.net/posts/2024/binary-size/</link>
            <guid>41415238</guid>
            <pubDate>Sun, 01 Sep 2024 08:30:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://vitaut.net/posts/2024/binary-size/">https://vitaut.net/posts/2024/binary-size/</a>, See on <a href="https://news.ycombinator.com/item?id=41415238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div v-pre=""><p><img src="https://vitaut.net/img/kennedy.jpg#floatright" alt="" title="We do this not because it is easy, but because we thought it would be easy."></p><p><a href="https://github.com/fmtlib/fmt">The {fmt} formatting library</a> is known for its small binary footprint,
often producing code that is several times smaller per function call compared
to alternatives like IOStreams, Boost Format, or, somewhat ironically,
tinyformat. This is mainly achieved through careful application of type erasure
on various levels, which effectively minimizes template bloat.</p><p>Formatting arguments are passed via type-erased <code>format_args</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>vformat</span><span>(</span><span>string_view</span> <span>fmt</span><span>,</span> <span>format_args</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>template</span> <span>&lt;</span><span>typename</span><span>...</span> <span>T</span><span>&gt;</span>
</span></span><span><span><span>auto</span> <span>format</span><span>(</span><span>format_string</span><span>&lt;</span><span>T</span><span>...</span><span>&gt;</span> <span>fmt</span><span>,</span> <span>T</span><span>&amp;&amp;</span><span>...</span> <span>args</span><span>)</span> <span>-&gt;</span> <span>std</span><span>::</span><span>string</span> <span>{</span>
</span></span><span><span>  <span>return</span> <span>vformat</span><span>(</span><span>fmt</span><span>,</span> <span>fmt</span><span>::</span><span>make_format_args</span><span>(</span><span>args</span><span>...));</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>As you can see, <code>format</code> delegates all its work to <code>vformat</code>, which is not a
template.</p><p>Output iterators and other output types are also type-erased through a specially
designed buffer API.</p><p>This approach confines template usage to a minimal top-level layer, leading to
both a smaller binary size and <a href="https://vitaut.net/posts/2024/faster-cpp-compile-times/">faster build times</a>.</p><p>For example, the following code:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>// test.cc
</span></span></span><span><span><span></span><span>#include</span> <span>&lt;fmt/base.h&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>  <span>fmt</span><span>::</span><span>print</span><span>(</span><span>"The answer is {}."</span><span>,</span> <span>42</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>compiles to just</p><pre tabindex="0"><code>.LC0:
        .string "The answer is {}."
main:
        sub     rsp, 24
        mov     eax, 1
        mov     edi, OFFSET FLAT:.LC0
        mov     esi, 17
        mov     rcx, rsp
        mov     rdx, rax
        mov     DWORD PTR [rsp], 42
        call    fmt::v11::vprint(fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;)
        xor     eax, eax
        add     rsp, 24
        ret
</code></pre><p><a href="https://godbolt.org/z/PMKdPPnYn">godbolt</a></p><p>It is much smaller than the equivalent IOStreams code and comparable to that
of <code>printf</code>:</p><pre tabindex="0"><code>.LC0:
        .string "The answer is %d."
main:
        sub     rsp, 8
        mov     esi, 42
        mov     edi, OFFSET FLAT:.LC0
        xor     eax, eax
        call    printf
        xor     eax, eax
        add     rsp, 8
        ret
</code></pre><p><a href="https://godbolt.org/z/soTjfno71">godbolt</a></p><p>Unlike <code>printf</code>, {fmt} offers full runtime type safety. Errors in format strings
can be caught at compile time, and even when the format string is determined at
runtime, errors are managed through exceptions, preventing undefined behavior,
memory corruption, and potential crashes. Additionally, {fmt} calls are
generally more efficient, particularly when using positional arguments, which C
varargs are not well-suited for.</p><p>Back in 2020, I dedicated some time to <a href="https://vitaut.net/posts/2020/reducing-library-size/">optimizing the library size</a>,
successfully reducing it to under 100kB (just ~57kB with <code>-Os -flto</code>).
A lot has changed since then. Most notably, {fmt} now uses the exceptional
<a href="https://github.com/jk-jeon/dragonbox">Dragonbox</a> algorithm for floating-point formatting, kindly
contributed by its author, Junekey Jeon. Let’s explore how these changes have
impacted the binary size and see if further reductions are possible.</p><p>But why, some say, the binary size? Why choose this as our goal?</p><p>There has been considerable interest in using {fmt} on memory-constrained
devices, see e.g. <a href="https://github.com/fmtlib/fmt/issues/758">#758</a> and <a href="https://github.com/fmtlib/fmt/issues/1226">#1226</a> for just two examples from
the distant past. A particularly intriguing use case is retro computing, with
people using {fmt} on systems like Amiga (<a href="https://github.com/fmtlib/fmt/issues/4054">#4054</a>).</p><p>We’ll apply the same methodology as in <a href="https://vitaut.net/posts/2020/reducing-library-size/">previous work</a>, examining the
executable size of a program that uses {fmt}, as this is most relevant to end
users. All tests will be conducted on an aarch64 Ubuntu 22.04 system with GCC
11.4.0.</p><p>First, let’s establish the baseline: what is the binary size for the latest
version of {fmt} (11.0.2)?</p><pre tabindex="0"><code>$ git checkout 11.0.2
$ g++ -Os -flto -DNDEBUG -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 75K Aug 30 19:24 a.out
</code></pre><p>The resulting binary size is 75kB (stripped). The positive takeaway is that
despite numerous developments over the past four years, the size has not
significantly regressed.</p><p>Now, let’s explore potential optimizations. One of the first adjustments you
might consider is disabling locale support. All the formatting in {fmt} is
locale-independent by default (which breaks with the C++’s tradition of having
wrong defaults), but it is still available as an opt in via the <code>L</code> format
specifier. It can be disabled in a somewhat obscure way via the
<code>FMT_STATIC_THOUSANDS_SEPARATOR</code> macro:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 71K Aug 30 19:25 a.out
</code></pre><p>Disabling locale support reduces the binary size to 71kB.</p><p>Next, let’s examine the results using our trusty tool, <a href="https://github.com/google/bloaty">Bloaty</a>:</p><pre tabindex="0"><code>$ bloaty -d symbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  43.8%  41.1Ki  43.6%  29.0Ki    [121 Others]
   6.4%  6.04Ki   8.1%  5.42Ki    fmt::v11::detail::do_write_float&lt;&gt;()
   5.9%  5.50Ki   7.5%  4.98Ki    fmt::v11::detail::write_int_noinline&lt;&gt;()
   5.7%  5.32Ki   5.8%  3.88Ki    fmt::v11::detail::write&lt;&gt;()
   5.4%  5.02Ki   7.2%  4.81Ki    fmt::v11::detail::parse_replacement_field&lt;&gt;()
   3.9%  3.69Ki   3.7%  2.49Ki    fmt::v11::detail::format_uint&lt;&gt;()
   3.2%  3.00Ki   0.0%       0    [section .symtab]
   2.7%  2.50Ki   0.0%       0    [section .strtab]
   2.3%  2.12Ki   2.9%  1.93Ki    fmt::v11::detail::dragonbox::to_decimal&lt;&gt;()
   2.0%  1.89Ki   2.4%  1.61Ki    fmt::v11::detail::write_int&lt;&gt;()
   2.0%  1.88Ki   0.0%       0    [ELF Section Headers]
   1.9%  1.79Ki   2.5%  1.66Ki    fmt::v11::detail::write_float&lt;&gt;()
   1.9%  1.78Ki   2.7%  1.78Ki    [section .dynstr]
   1.8%  1.72Ki   2.4%  1.62Ki    fmt::v11::detail::format_dragon()
   1.8%  1.68Ki   1.5%    1016    fmt::v11::detail::format_decimal&lt;&gt;()
   1.6%  1.52Ki   2.1%  1.41Ki    fmt::v11::detail::format_float&lt;&gt;()
   1.6%  1.49Ki   0.0%       0    [Unmapped]
   1.5%  1.45Ki   2.2%  1.45Ki    [section .dynsym]
   1.5%  1.45Ki   2.0%  1.31Ki    fmt::v11::detail::write_loc()
   1.5%  1.44Ki   2.2%  1.44Ki    [section .rodata]
   1.5%  1.40Ki   1.1%     764    fmt::v11::detail::do_write_float&lt;&gt;()::{lambda()#2}::operator()()
 100.0%  93.8Ki 100.0%  66.6Ki    TOTAL
</code></pre><p>Unsurprisingly, a significant portion of the binary size is dedicated to numeric
formatting, particularly floating-point numbers. FP formatting also relies on
sizable tables, which aren’t shown here. But what if floating-point support
isn’t required? {fmt} provides a way to disable it, though the method is
somewhat ad hoc and doesn’t extend to other types.</p><p>The core issue is that formatting functions need to be aware of all formattable
types. Or do they? This is true for <code>printf</code> as defined by the C standard, but
not necessarily for {fmt}. {fmt} supports an extension API that allows
formatting arbitrary types without knowing the complete set of types in advance.
While built-in and string types are handled specially for performance reasons,
focusing on binary size might warrant a different approach. By removing this
special handling and routing every type through the extension API, you can avoid
paying for types you don’t use.</p><p>I did an experimental <a href="https://github.com/fmtlib/fmt/commit/377cf20">implementation of this idea</a>. With the
<code>FMT_BUILTIN_TYPES</code> macro set to 0, only <code>int</code> is handled specially, and all
other types go through the general extension API. We still need to know about
<code>int</code> for dynamic width and precision, for example</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>fmt</span><span>::</span><span>print</span><span>(</span><span>"{:{}}</span><span>\n</span><span>"</span><span>,</span> <span>"hello"</span><span>,</span> <span>10</span><span>);</span> <span>// prints "hello     "
</span></span></span></code></pre></div><p>This gives you the “don’t pay for what you don’t use” model, though it comes
with a slight increase in per-call binary size. If you do format floating-point
numbers or other types, the relevant code will still be included in the build.
While it’s possible to make the FP implementation smaller, we won’t delve into
that here.</p><p>With <code>FMT_BUILTIN_TYPES=0</code>, the binary size in our example reduced to 31kB,
representing a substantial improvement:</p><pre tabindex="0"><code>$ git checkout 377cf20
$ g++ -Os -flto -DNDEBUG \
      "-DFMT_STATIC_THOUSANDS_SEPARATOR=','" -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 31K Aug 30 19:37 a.out
</code></pre><p>However, the updated Bloaty results reveal some lingering locale artifacts,
such as <code>digit_grouping</code>:</p><pre tabindex="0"><code>$ bloaty -d fullsymbols a.out

    FILE SIZE        VM SIZE
 --------------  --------------
  41.8%  18.0Ki  39.7%  11.0Ki    [84 Others]
   6.4%  2.77Ki   0.0%       0    [section .symtab]
   5.3%  2.28Ki   0.0%       0    [section .strtab]
   4.6%  1.99Ki   6.9%  1.90Ki    fmt::v11::detail::format_handler&lt;char&gt;::on_format_specs(int, char const*, char const*)
   4.4%  1.88Ki   0.0%       0    [ELF Section Headers]
   4.1%  1.78Ki   5.8%  1.61Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int_noinline&lt;char, fmt::v11::basic_appender&lt;char&gt;, unsigned int&gt;(fmt::v11::basic_appender&lt;char&gt;, fmt::v11::detail::write_int_arg&lt;unsigned int&gt;, fmt::v11::format_specs const&amp;, fmt::v11::detail::locale_ref) (.constprop.0)
   3.7%  1.60Ki   5.8%  1.60Ki    [section .dynstr]
   3.5%  1.50Ki   4.8%  1.34Ki    void fmt::v11::detail::vformat_to&lt;char&gt;(fmt::v11::detail::buffer&lt;char&gt;&amp;, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::detail::vformat_args&lt;char&gt;::type, fmt::v11::detail::locale_ref) (.constprop.0)
   3.5%  1.49Ki   4.9%  1.35Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned __int128, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
   3.1%  1.31Ki   4.7%  1.31Ki    [section .dynsym]
   3.0%  1.29Ki   4.2%  1.15Ki    fmt::v11::basic_appender&lt;char&gt; fmt::v11::detail::write_int&lt;fmt::v11::basic_appender&lt;char&gt;, unsigned long, char&gt;(fmt::v11::basic_appender&lt;char&gt;, unsigned long, unsigned int, fmt::v11::format_specs const&amp;, fmt::v11::detail::digit_grouping&lt;char&gt; const&amp;)
</code></pre><p>After disabling these artifacts in commits <a href="https://github.com/fmtlib/fmt/commit/e582d37">e582d37</a> and
<a href="https://github.com/fmtlib/fmt/commit/b3ccc2d">b3ccc2d</a>, and introducing a more user-friendly option to opt out via
the <code>FMT_USE_LOCALE</code> macro, the binary size drops to 27kB:</p><pre tabindex="0"><code>$ git checkout b3ccc2d
$ g++ -Os -flto -DNDEBUG -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 \
      -I include test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 27K Aug 30 19:38 a.out
</code></pre><p>The library includes several areas where size is traded off for speed.
For example, consider this function used to compute the number of decimal
digits:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>do_count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>// An optimization by Kendall Willets from https://bit.ly/3uOIQrB.
</span></span></span><span><span><span>// This increments the upper 32 bits (log10(T) - 1) when &gt;= T is added.
</span></span></span><span><span><span></span><span>#  define FMT_INC(T) (((sizeof(#T) - 1ull) &lt;&lt; 32) - T)
</span></span></span><span><span><span></span>  <span>static</span> <span>constexpr</span> <span>uint64_t</span> <span>table</span><span>[]</span> <span>=</span> <span>{</span>
</span></span><span><span>      <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>          <span>FMT_INC</span><span>(</span><span>0</span><span>),</span>           <span>// 8
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>         <span>FMT_INC</span><span>(</span><span>10</span><span>),</span>          <span>// 64
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>        <span>FMT_INC</span><span>(</span><span>100</span><span>),</span>         <span>// 512
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>       <span>FMT_INC</span><span>(</span><span>1000</span><span>),</span>        <span>// 4096
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>      <span>FMT_INC</span><span>(</span><span>10000</span><span>),</span>       <span>// 32k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>     <span>FMT_INC</span><span>(</span><span>100000</span><span>),</span>      <span>// 256k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>    <span>FMT_INC</span><span>(</span><span>1000000</span><span>),</span>     <span>// 2048k
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>   <span>FMT_INC</span><span>(</span><span>10000000</span><span>),</span>    <span>// 16M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>  <span>FMT_INC</span><span>(</span><span>100000000</span><span>),</span>   <span>// 128M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span>  <span>// 1024M
</span></span></span><span><span><span></span>      <span>FMT_INC</span><span>(</span><span>1000000000</span><span>),</span> <span>FMT_INC</span><span>(</span><span>1000000000</span><span>)</span>                        <span>// 4B
</span></span></span><span><span><span></span>  <span>};</span>
</span></span><span><span>  <span>auto</span> <span>inc</span> <span>=</span> <span>table</span><span>[</span><span>__builtin_clz</span><span>(</span><span>n</span> <span>|</span> <span>1</span><span>)</span> <span>^</span> <span>31</span><span>];</span>
</span></span><span><span>  <span>return</span> <span>static_cast</span><span>&lt;</span><span>int</span><span>&gt;</span><span>((</span><span>n</span> <span>+</span> <span>inc</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>The table used here is 256 bytes. There isn’t a one-size-fits-all solution,
and changing it unconditionally might negatively impact other use cases.
Fortunately, we have a fallback implementation of this function for scenarios
where <code>__builtin_clz</code> is unavailable, such as with <code>constexpr</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>constexpr</span> <span>auto</span> <span>count_digits_fallback</span><span>(</span><span>T</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span>  <span>int</span> <span>count</span> <span>=</span> <span>1</span><span>;</span>
</span></span><span><span>  <span>for</span> <span>(;;)</span> <span>{</span>
</span></span><span><span>    <span>// Integer division is slow so do it for a group of four digits instead
</span></span></span><span><span><span></span>    <span>// of for every digit. The idea comes from the talk by Alexandrescu
</span></span></span><span><span><span></span>    <span>// "Three Optimization Tips for C++". See speed-test for a comparison.
</span></span></span><span><span><span></span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10</span><span>)</span> <span>return</span> <span>count</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>100</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>1</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>1000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>2</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>n</span> <span>&lt;</span> <span>10000</span><span>)</span> <span>return</span> <span>count</span> <span>+</span> <span>3</span><span>;</span>
</span></span><span><span>    <span>n</span> <span>/=</span> <span>10000u</span><span>;</span>
</span></span><span><span>    <span>count</span> <span>+=</span> <span>4</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>All that remains is to provide users with control over when to use the fallback
implementation via (you guessed it) another configuration macro,
<code>FMT_OPTIMIZE_SIZE</code>:</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>auto</span> <span>count_digits</span><span>(</span><span>uint32_t</span> <span>n</span><span>)</span> <span>-&gt;</span> <span>int</span> <span>{</span>
</span></span><span><span><span>#ifdef FMT_BUILTIN_CLZ
</span></span></span><span><span><span></span>  <span>if</span> <span>(</span><span>!</span><span>is_constant_evaluated</span><span>()</span> <span>&amp;&amp;</span> <span>!</span><span>FMT_OPTIMIZE_SIZE</span><span>)</span> <span>return</span> <span>do_count_digits</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>#endif
</span></span></span><span><span><span></span>  <span>return</span> <span>count_digits_fallback</span><span>(</span><span>n</span><span>);</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>With this and a few similar adjustments, we reduced the binary size to 23kB:</p><pre tabindex="0"><code>$ git checkout 8e3da9d
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      test.cc src/format.cc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 23K Aug 30 19:41 a.out
</code></pre><p>We could likely reduce the binary size even further with additional tweaks,
but let’s address the elephant in the room which is, of course, the C++ standard
library. What’s the point of optimizing the size when you end up getting
a megabyte or two of the C++ runtime?</p><p>While {fmt} relies minimally on the standard library, is it possible to
remove it completely as a dependency? One obvious problem is exceptions and
those can be disabled via <code>FMT_THROW</code>, e.g. by defining it to <code>abort</code>.
In general it is not recommended but it might be OK for some use cases
especially considering that most errors are caught at compile time.</p><p>Let’s try it out and compile with <code>-nodefaultlibs</code> and exceptions disabled:</p><pre tabindex="0"><code>$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc

/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::basic_memory_buffer&lt;char, 500ul, std::allocator&lt;char&gt; &gt;::grow(fmt::v11::detail::buffer&lt;char&gt;&amp;, unsigned long)':
&lt;artificial&gt;:(.text+0xaa8): undefined reference to `std::__throw_bad_alloc()'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xab8): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: &lt;artificial&gt;:(.text+0xaf8): undefined reference to `operator delete(void*, unsigned long)'
/usr/bin/ld: /tmp/cc04DFeK.ltrans0.ltrans.o: in function `fmt::v11::vprint_buffered(_IO_FILE*, fmt::v11::basic_string_view&lt;char&gt;, fmt::v11::basic_format_args&lt;fmt::v11::context&gt;) [clone .constprop.0]':
&lt;artificial&gt;:(.text+0x18c4): undefined reference to `operator delete(void*, unsigned long)'
collect2: error: ld returned 1 exit status
</code></pre><p>Amazingly, this approach mostly works. The only remaining dependency on the C++
runtime comes from <code>fmt::basic_memory_buffer</code>, which is a small stack-allocated
buffer that can grow into dynamic memory if necessary.</p><p><code>fmt::print</code> can write directly into the <code>FILE</code> buffer and generally
doesn’t require dynamic allocation. So we could remove the dependency on
<code>fmt::basic_memory_buffer</code> from <code>fmt::print</code>. However, since it may be used
elsewhere, a better solution is to replace the default allocator with one that
uses <code>malloc</code> and <code>free</code> instead of <code>new</code> and <code>delete</code>.</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span> <span>struct</span> <span>allocator</span> <span>{</span>
</span></span><span><span>  <span>using</span> <span>value_type</span> <span>=</span> <span>T</span><span>;</span>
</span></span><span><span>
</span></span><span><span>  <span>T</span><span>*</span> <span>allocate</span><span>(</span><span>size_t</span> <span>n</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>FMT_ASSERT</span><span>(</span><span>n</span> <span>&lt;=</span> <span>max_value</span><span>&lt;</span><span>size_t</span><span>&gt;</span><span>()</span> <span>/</span> <span>sizeof</span><span>(</span><span>T</span><span>),</span> <span>""</span><span>);</span>
</span></span><span><span>    <span>T</span><span>*</span> <span>p</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>T</span><span>*&gt;</span><span>(</span><span>malloc</span><span>(</span><span>n</span> <span>*</span> <span>sizeof</span><span>(</span><span>T</span><span>)));</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>!</span><span>p</span><span>)</span> <span>FMT_THROW</span><span>(</span><span>std</span><span>::</span><span>bad_alloc</span><span>());</span>
</span></span><span><span>    <span>return</span> <span>p</span><span>;</span>
</span></span><span><span>  <span>}</span>
</span></span><span><span>
</span></span><span><span>  <span>void</span> <span>deallocate</span><span>(</span><span>T</span><span>*</span> <span>p</span><span>,</span> <span>size_t</span><span>)</span> <span>{</span> <span>free</span><span>(</span><span>p</span><span>);</span> <span>}</span>
</span></span><span><span><span>};</span>
</span></span></code></pre></div><p>This reduces binary size to just 14kB:</p><pre tabindex="0"><code>$ git checkout c0fab5e
$ g++ -Os -flto -DNDEBUG -I include \
      -DFMT_USE_LOCALE=0 -DFMT_BUILTIN_TYPES=0 -DFMT_OPTIMIZE_SIZE=1 \
      '-DFMT_THROW(s)=abort()' -fno-exceptions test.cc src/format.cc \
      -nodefaultlibs -lc
$ strip a.out &amp;&amp; ls -lh a.out
-rwxrwxr-x 1 vagrant vagrant 14K Aug 30 19:06 a.out
</code></pre><p>Considering that a C program with an empty <code>main</code> function is 6kB on this
system, {fmt} now adds less than 10kB to the binary.</p><p>We can also easily verify that it no longer depends on the C++ runtime:</p><pre tabindex="0"><code>$ ldd a.out
        linux-vdso.so.1 (0x0000ffffb0738000)
        libc.so.6 =&gt; /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffb0530000)
        /lib/ld-linux-aarch64.so.1 (0x0000ffffb06ff000)
</code></pre><p>Hope you found this interesting and happy embedded formatting!</p><hr id="EOF"><p>Last modified on 2024-08-30</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[E Ink faces growing competition in the "paper-like" display space (135 pts)]]></title>
            <link>https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</link>
            <guid>41415144</guid>
            <pubDate>Sun, 01 Sep 2024 08:09:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/">https://liliputing.com/e-ink-faces-growing-competition-in-the-paper-like-display-space/</a>, See on <a href="https://news.ycombinator.com/item?id=41415144">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article id="post-171433"><div><div><p><em><p>Disclosure: Some links on this page are monetized by the <a rel="nofollow" href="http://go.skimlinks.com/?id=32X105&amp;xs=1&amp;url=http://skimlinks.com">Skimlinks</a>, <a rel="nofollow" href="https://affiliate-program.amazon.com/welcome">Amazon</a>, <a rel="nofollow" href="https://rakutenadvertising.com/">Rakuten Advertising, and </a><a rel="no follow" href="https://partnernetwork.ebay.com/">eBay</a>, affiliate programs, and Liliputing may earn a commission if you make a purchase after clicking on those links. All prices are subject to change, and this article only reflects the prices available at time of publication.</p></em></p></div><p>For the past few decades, E Ink has dominated the market for the paper-like displays found in eBook readers and other devices. The screens are high-contrast, easy to view indoors or outdoors, don’t require a backlight, don’t reflect glare, and consume very little power.</p><p>But E Ink displays also have slow screen refresh rates, limited support for color (on models that support any color at all), and generally aren’t very useful for high-motion graphics like videos or games. So while there are a handful of companies producing <a href="https://liliputing.com/tag/e-ink-phone/">E Ink smartphones</a> and <a href="https://liliputing.com/tag/e-ink-tablet/">tablets</a>, they tend to be niche devices. And now we’re seeing a growing number of companies offering products with reflective LCD displays or similar technology that offer some of the paper-like qualities of E Ink, but which are more suitable for animation and video.</p><figure id="attachment_171436" aria-describedby="caption-attachment-171436"><img fetchpriority="high" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_02.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171436">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>Reflective LCD displays don’t have a backlight and instead reflect ambient light, allowing you to use them without any additional illumination as long as you’re in a brightly lit environment. If you want to make a tablet or another device with a reflective LCD that can be used in dimmer environments, you’ll want to add some front-lights that shine onto the screen… much the way most modern eReaders with E Ink displays have front lighting.</p><p>But while reflective LCD technology has been around for decades, the screens don’t tend to look as bright or vibrant as the transmissive LCDs (with backlights) or OLED screens that have become more common in recent years.</p><p>Recently several companies have decided to try to make&nbsp;<em>better</em> reflective screens though, in an effort to offer an alternative to E Ink that can be used as a paper-like screen for reading and writing, but which also supports full-motion graphics for video, smooth scrolling, and other applications.</p><p>One effort that’s gotten a lot of attention this year is the <a href="https://liliputing.com/daylight-computer-dc-1-is-a-799-tablet-with-a-live-paper-display-designed-to-be-easy-on-the-eyes-but-not-the-wallet/"><strong>Daylight Computer DC-1</strong></a>, which has a “Live Paper” display that’s a black and white IGZO LCD display with a 60 Hz refresh rate and an amber-colored backlight (that can be turned entirely off when you don’t need it).</p><p><img decoding="async" src="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg" alt="" width="762" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/05/dc1_02-762x500.jpg 762w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-400x262.jpg 400w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-150x98.jpg 150w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02-768x504.jpg 768w, https://liliputing.com/wp-content/uploads/2024/05/dc1_02.jpg 1200w" sizes="(max-width: 762px) 100vw, 762px"></p><p><a href="https://daylightcomputer.com/" rel="nofollow"><strong>Daylight</strong></a> is a startup that’s pushing the DC-1 as a tablet that can do more than a typical eReader, while still offering a comfortable viewing experience indoors or outdoors. It has a 10.5 inch display with support for touch and Wacom EMR pen input and the tablet runs a custom version of Android. It’s also expensive, with <a href="https://daylightcomputer.com/cart" rel="nofollow">a $729 price tag</a>.</p><p>If that price tag seems too steep, there’s always TCL’s <a href="https://www.tcl.com/global/en/tcl-nxtpaper-technology" rel="nofollow"><strong>NXTPAPER</strong></a> display technology. The company has been using its full-color, glare-free matte displays on a handful of smartphones and tablets over the past few years. I’ve seen mixed reports on whether this is technically a reflective LCD or not, but while TCL tends to use these displays on relatively affordable devices with budget or mid-range specs, the <a href="https://www.zdnet.com/article/i-gave-away-my-kindle-and-ipad-within-hours-of-testing-this-tablet/" rel="nofollow">screens tend to get positive reviews</a> from folks who are comparing them to E Ink.</p><figure id="attachment_165542" aria-describedby="caption-attachment-165542"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg" alt="" width="749" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-749x500.jpg 749w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-400x267.jpg 400w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-150x100.jpg 150w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g-768x513.jpg 768w, https://liliputing.com/wp-content/uploads/2024/01/tab-10-nxtpaper-5g.jpg 1200w" sizes="(max-width: 749px) 100vw, 749px"><figcaption id="caption-attachment-165542">TCL NXTPAPER 10 5G</figcaption></figure><p>A TCL NXTPAPER 5G Android tablet with a 10.4 inch display currently <a href="https://fave.co/3MtxTqI" rel="nofollow">sells for $240 at Verizon</a>, making it pricier than an <a href="https://amzn.to/3AKts8d" rel="nofollow">Amazon Kindle Paperwhite</a>, but comparable to the list price for an <a href="https://amzn.to/3yOsA20" rel="nofollow">Amazon Fire Max 11</a>.</p><p>One of the more recent entries into this space is HannSpree’s <strong><a href="https://www.hannspree.eu/about-ecovision-paper-display/" rel="nofollow">ecoVISION Paper Display</a></strong> technology, which also offers “fast, full-colour performance,” energy efficiency, and “true 8-bit, non-FRC, flicker-free, and low blue light features” that are said to “help reduce eye strain.”</p><p>One of the first devices featuring this display has the <a href="https://www.hannspree.com/hannsnote2" rel="nofollow"><strong>Hannspree HannsNote 2</strong></a>.&nbsp; It’s a device that the company is positioning as an eReader, but it’s basically an Android tablet with a 10 inch, 1600 x 1200 pixel (200 ppi), 60 Hz display and USI 2.0 stylus support.</p><figure id="attachment_171438" aria-describedby="caption-attachment-171438"><img loading="lazy" decoding="async" src="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg" alt="" width="415" height="500" srcset="https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-415x500.jpg 415w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-332x400.jpg 332w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-125x150.jpg 125w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-768x925.jpg 768w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05-400x482.jpg 400w, https://liliputing.com/wp-content/uploads/2024/08/hannsnote-2_05.jpg 1200w" sizes="(max-width: 415px) 100vw, 415px"><figcaption id="caption-attachment-171438">Hannspree HannsNote 2 with ecoVISION Paper Display</figcaption></figure><p>It also has a Rockchip RK3566 quad-core ARM Cortex-A55 processor, 4GB of RAM, 64GB of storage, and an Android 13-based operating system. The Google Play store comes pre-loaded.</p><p>Interestingly one thing the HannsNote 2 lacks? A front-light. It’s meant to be used&nbsp;<em>only</em> with ambient lighting, which should make it easy to use outdoors or in brightly lit rooms. But if you want to read in the dark you’ll probably need a clip-on booklight.</p><p>The tablet doesn’t seem to be available for purchase in the US, but it’s sold in Europe <a href="https://fave.co/4dK2vjM" rel="nofollow">for about 315€</a>.</p><p><iframe loading="lazy" title="RLCD Color E-Paper Tablet: HannsNote 2 First Look" width="780" height="439" src="https://www.youtube.com/embed/0d7gc8xflHI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p><p>HannSpree has also announced plans to launch a series of “<a href="https://www.prnewswire.com/news-releases/hannspree-unveils-ecovision-paper-display-at-ifa-2024-302233719.html" rel="nofollow">next-generation e-readers</a>” soon, with ecoVISION displays, Android 14 software, and 10 inch or 7.8 inch displays, as well as other products including a 23.8 inch monitor digital signage featuring up to a 28-inch ecoVISION display.</p><div id="custom_html-9"><p>Liliputing's primary sources of revenue are advertising and affiliate links (if you click the "<a target="_blank" rel="nofollow noopener" href="https://www.amazon.com/Best-Sellers-Computers-Accessories/zgbs/pc/ref=as_li_ss_tl?_encoding=UTF8&amp;linkCode=ll2&amp;tag=liliputing_shop-20&amp;linkId=93aaf7ba4e36ed56d46003558471548d">Shop</a>" button at the top of the page and buy something on Amazon, for example, we'll get a small commission).</p><p>But there are several ways you can support the site directly even if you're using an ad blocker* and hate online shopping.</p><h3>Contribute to our <a href="https://www.patreon.com/bradlinder">Patreon campaign</a></h3><p> <em>or...</em></p><h3>Contribute via <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&amp;hosted_button_id=PTBQ9EKAYTZBS&amp;source=url">PayPal</a></h3><p> * If you <em>are</em> using an ad blocker like uBlock Origin and seeing a pop-up message at the bottom of the screen, we have a <a target="blank_" href="https://liliputing.com/2020/09/ublock-origin-how-to-hide-googles-script-blocking-warning-for-websites-using-funding-choices.html" rel="noopener">guide that may help you disable it.</a></p></div><div id="blog_subscription-2"><p> Join 9,573 other subscribers</p></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Founder Mode (487 pts)]]></title>
            <link>https://paulgraham.com/foundermode.html</link>
            <guid>41415023</guid>
            <pubDate>Sun, 01 Sep 2024 07:35:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://paulgraham.com/foundermode.html">https://paulgraham.com/foundermode.html</a>, See on <a href="https://news.ycombinator.com/item?id=41415023">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="435"><tbody><tr><td><img src="https://s.turbifycdn.com/aah/paulgraham/founder-mode-1.gif" width="118" height="18" alt="Founder Mode"><span size="2" face="verdana">September 2024<p>At a YC event last week Brian Chesky gave a talk that everyone who
was there will remember. Most founders I talked to afterward said
it was the best they'd ever heard. Ron Conway, for the first time
in his life, forgot to take notes. I'm not going to try to reproduce
it here. Instead I want to talk about a question it raised.</p><p>The theme of Brian's talk was that the conventional wisdom about
how to run larger companies is mistaken. As Airbnb grew, well-meaning
people advised him that he had to run the company in a certain way
for it to scale. Their advice could be optimistically summarized
as "hire good people and give them room to do their jobs." He
followed this advice and the results were disastrous. So he had to
figure out a better way on his own, which he did partly by studying
how Steve Jobs ran Apple. So far it seems to be working. Airbnb's
free cash flow margin is now among the best in Silicon Valley.</p><p>The audience at this event included a lot of the most successful
founders we've funded, and one after another said that the same
thing had happened to them. They'd been given the same advice about
how to run their companies as they grew, but instead of helping
their companies, it had damaged them.</p><p>Why was everyone telling these founders the wrong thing? That was
the big mystery to me. And after mulling it over for a bit I figured
out the answer: what they were being told was how to run a company
you hadn't founded — how to run a company if you're merely a
professional manager. But this m.o. is so much less effective that
to founders it feels broken. There are things founders can do that
managers can't, and not doing them feels wrong to founders, because
it is.</p><p>In effect there are two different ways to run a company: founder
mode and manager mode. Till now most people even in Silicon Valley
have implicitly assumed that scaling a startup meant switching to
manager mode. But we can infer the existence of another mode from
the dismay of founders who've tried it, and the success of their
attempts to escape from it.</p><p>There are as far as I know no books specifically about founder mode.
Business schools don't know it exists. All we have so far are the
experiments of individual founders who've been figuring it out for
themselves. But now that we know what we're looking for, we can
search for it. I hope in a few years founder mode will be as well
understood as manager mode. We can already guess at some of the
ways it will differ.</p><p>The way managers are taught to run companies seems to be like modular
design in the sense that you treat subtrees of the org chart as
black boxes. You tell your direct reports what to do, and it's up
to them to figure out how. But you don't get involved in the details
of what they do. That would be micromanaging them, which is bad.</p><p>Hire good people and give them room to do their jobs. Sounds great
when it's described that way, doesn't it? Except in practice, judging
from the report of founder after founder, what this often turns out
to mean is: hire professional fakers and let them drive the company
into the ground.</p><p>One theme I noticed both in Brian's talk and when talking to founders
afterward was the idea of being gaslit. Founders feel like they're
being gaslit from both sides — by the people telling them they
have to run their companies like managers, and by the people working
for them when they do. Usually when everyone around you disagrees
with you, your default assumption should be that you're mistaken.
But this is one of the rare exceptions. VCs who haven't been founders
themselves don't know how founders should run companies, and C-level
execs, as a class, include some of the most skillful liars in the
world.
</p><span color="#dddddd">[<a href="#f1n"><span color="#dddddd">1</span></a>]</span><p>Whatever founder mode consists of, it's pretty clear that it's going
to break the principle that the CEO should engage with the company
only via his or her direct reports. "Skip-level" meetings will
become the norm instead of a practice so unusual that there's a
name for it. And once you abandon that constraint there are a huge
number of permutations to choose from.</p><p>For example, Steve Jobs used to run an annual retreat for what he
considered the 100 most important people at Apple, and these were
not the 100 people highest on the org chart. Can you imagine the
force of will it would take to do this at the average company? And
yet imagine how useful such a thing could be. It could make a big
company feel like a startup. Steve presumably wouldn't have kept
having these retreats if they didn't work. But I've never heard of
another company doing this. So is it a good idea, or a bad one? We
still don't know. That's how little we know about founder mode.
</p><span color="#dddddd">[<a href="#f2n"><span color="#dddddd">2</span></a>]</span><p>Obviously founders can't keep running a 2000 person company the way
they ran it when it had 20. There's going to have to be some amount
of delegation. Where the borders of autonomy end up, and how sharp
they are, will probably vary from company to company. They'll even
vary from time to time within the same company, as managers earn
trust. So founder mode will be more complicated than manager mode.
But it will also work better. We already know that from the examples
of individual founders groping their way toward it.</p><p>Indeed, another prediction I'll make about founder mode is that
once we figure out what it is, we'll find that a number of individual
founders were already most of the way there — except that in doing
what they did they were regarded by many as eccentric or worse.
</p><span color="#dddddd">[<a href="#f3n"><span color="#dddddd">3</span></a>]</span><p>Curiously enough it's an encouraging thought that we still know so
little about founder mode. Look at what founders have achieved
already, and yet they've achieved this against a headwind of bad
advice. Imagine what they'll do once we can tell them how to run
their companies like Steve Jobs instead of John Sculley.</p><p><b>Notes</b></p><p>[</p><a name="f1n"><span color="#000000">1</span></a>]
The more diplomatic way of phrasing this statement would be
to say that experienced C-level execs are often very skilled at
managing up. And I don't think anyone with knowledge of this world
would dispute that.<p>[</p><a name="f2n"><span color="#000000">2</span></a>]
If the practice of having such retreats became so widespread
that even mature companies dominated by politics started to do it,
we could quantify the senescence of companies by the average depth
on the org chart of those invited.<p>[</p><a name="f3n"><span color="#000000">3</span></a>]
I also have another less optimistic prediction: as soon as
the concept of founder mode becomes established, people will start
misusing it. Founders who are unable to delegate even things they
should will use founder mode as the excuse. Or managers who aren't
founders will decide they should try act like founders. That may
even work, to some extent, but the results will be messy when it
doesn't; the modular approach does at least limit the damage a bad
CEO can do.<span color="888888"><b>Thanks</b> to Brian Chesky, Patrick Collison, 
Ron Conway, Jessica
Livingston, Elon Musk, Ryan Petersen, Harj Taggar, and Garry Tan
for reading drafts of this.</span></span></td></tr></tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Playstation 2 GS emulation – the final frontier of Vulkan compute emulation (177 pts)]]></title>
            <link>https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</link>
            <guid>41413662</guid>
            <pubDate>Sun, 01 Sep 2024 02:14:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/">https://themaister.net/blog/2024/07/03/playstation-2-gs-emulation-the-final-frontier-of-vulkan-compute-emulation/</a>, See on <a href="https://news.ycombinator.com/item?id=41413662">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-754">
	
	<!-- .entry-header -->

	<div>
		<p>As you may, or may not know, I wrote paraLLEl-RDP back in 2020. It aimed at implementing the N64 RDP in Vulkan compute. Lightning fast, and extremely accurate, plus the added support of up-scaling on top. I’m quite happy how it turned out. Of course, the extreme accuracy was due to Angrylion being used as reference and I could aim for bit-exactness against that implementation.</p>
<p>Since then, there’s been the lingering idea of doing the same thing, but for PlayStation 2. Until now, there’s really only been one implementation in town, GSdx, which has remained the state-of-the-art for 20 years.</p>
<p><a href="https://github.com/Arntzen-Software/parallel-gs">paraLLEl-GS</a> is actually not the first compute implementation of the PS2 GS. An attempt was made back in 2014 for OpenCL as far as I recall, but it was never completed. At the very least, I cannot find it in the current upstream repo anymore.</p>
<p>The argument for doing compute shader raster on PS2 is certainly weaker than on N64. Angrylion was – and is – extremely slow, and N64 is extremely sensitive to accuracy where hardware acceleration with graphics APIs is impossible without serious compromises. PCSX2 on the other hand has a well-optimized software renderer, and a pretty solid graphics-based renderer, but that doesn’t mean there aren’t issues. The software renderer does not support up-scaling for example, and there are a myriad bugs and glitches with the graphics-based renderer, especially with up-scaling. As we’ll see, the PS2 GS is quite the nightmare to emulate in its own way.</p>
<p>My main motivation here is basically “because I can”. I already had a project lying around that did “generic” compute shader rasterization. I figured that maybe we could retro-fit this to support PS2 rendering.</p>
<p>I didn’t work on this project alone. My colleague, Runar Heyer, helped out a great deal in the beginning to get this started, doing all the leg-work to study the PS2 from various resources, doing the initial prototype implementation and fleshing out the Vulkan GLSL to emulate PS2 shading. Eventually, we hit some serious roadblocks in debugging various games, and the project was put on ice for a while since I was too drained dealing with horrible D3D12 game debugging day in and day out. The last months haven’t been a constant fire fight, so I’ve finally had the mental energy to finish it.</p>
<p>My understanding of the GS is mostly based on what Runar figured out, and what I’ve seen by debugging games. The GSdx software renderer does not seem like it’s hardware bit-accurate, so we were constantly second-guessing things when trying to compare output. This caused a major problem when we had the idea of writing detailed tests that directly compared against GSdx software renderer, and the test-driven approach fell flat very quickly. As a result, paraLLEl-GS isn’t really aiming for bit-accuracy against hardware, but it tries hard to avoid obvious accuracy issues at the very least.</p>
<h2>Basic GS overview</h2>
<p>Again, this is based on my understanding, and it might not be correct. 😀</p>
<h3>GS is a pixel-pushing monster</h3>
<p>The GS is infamous for its insane fill-rate and bandwidth. It could push over a billion pixels per second (in theory at least) back in 2000 which was nuts. While the VRAM is quite small (4 MiB), it was designed to be continuously streamed into using the various DMA engines.</p>
<p>Given the extreme fill-rate requirements, we have to design our renderer accordingly.</p>
<h3>GS pixel pipeline is very basic, but quirky</h3>
<p>In many ways, the GS is actually simpler than N64 RDP. Single texture, and a single cycle combiner, where N64 had a two stage combiner + two stage blender. Whatever AA support is there is extremely basic as well, where N64 is delightfully esoteric. The parts of the pixel pipeline that is painful to implement with traditional graphics APIs is:</p>
<h4>Blending goes beyond 1.0</h4>
<p>Inherited from PS1, 0x80 is treated as 1.0, and it can go all the way up to 0xff (almost 2). Shifting by 7 is easier than dividing by 255 I suppose. I’ve seen some extremely ugly workarounds in PCSX2 before to try working around this since UNORM formats cannot support this as is. Textures are similar, where alpha &gt; 1.0 is representable.</p>
<p>There is also wrapping logic that can be used for when colors or alpha goes above 0xFF.</p>
<h4>Destination alpha testing</h4>
<p>The destination alpha can be used as a pseudo-stencil of sorts, and this is extremely painful without programmable blending. I suspect this was added as PS1 compatibility, since PS1 also had this strange feature.</p>
<h4>Conditional blending</h4>
<p>Based on the alpha, it’s possible to conditionally disable blending. Quite awkward without programmable blending … This is another PS1 compat feature. With PS1, it can be emulated by rendering every primitive twice with state changes in-between, but this quickly gets impractical with PS2.</p>
<h4>Alpha correction</h4>
<p>Before alpha is written out, it’s possible to OR in the MSB. Essentially forcing alpha to 1. It is not equivalent to alphaToOne however, since it’s a bit-wise OR of the MSB.</p>
<h4>Alpha test can partially discard</h4>
<p>A fun thing alpha tests can do is to partially discard. E.g. you can discard just color, but keep the depth write. Quite nutty.</p>
<h4>AA1 – coverage-to-alpha – can control depth write per pixel</h4>
<p>This is also kinda awkward. The only anti-alias PS2 has is AA1 which is a coverage-to-alpha feature. Supposedly, less than 100% coverage should disable depth writes (and blending is enabled), but the GSdx software renderer behavior here is extremely puzzling. I don’t really understand it yet.</p>
<h4>32-bit fixed-point Z</h4>
<p>I’ve still yet to see any games actually using this, but technically, it has D32_UINT support. Fun! From what I could grasp, GSdx software renderer implements this with FP64 (one of the many reasons I refuse to believe GSdx is bit-accurate), but FP64 is completely impractical on GPUs. When I have to, I’ll implement this with fixed-point math. 24-bit Z and 16-bit should be fine with FP32 interpolation I think.</p>
<h4>Pray you have programmable blending</h4>
<p>If you’re on a pure TBDR GPU most of this is quite doable, but immediate mode desktop GPUs quickly degenerates into ROV or per-pixel barriers after every primitive to emulate programmable blending, both which are horrifying for performance. Of course, with compute we can make our own TBDR to bypass all this. 🙂</p>
<h3>D3D9-style raster rules</h3>
<p>Primitives are fortunately provided in a plain form in clip-space. No awkward N64 edge equations here. The VU1 unit is supposed to do transforms and clipping, and emit various per-vertex attributes:</p>
<p>X/Y: 12.4 unsigned fixed-point<br>
Z: 24-bit or 32-bit uint<br>
FOG: 8-bit uint<br>
RGBA: 8-bit, for per-vertex lighting<br>
STQ: For perspective correct texturing with normalized coordinates. Q = 1 / w, S = s * Q, T = t * Q. Apparently the lower 8-bits of the mantissa are clipped away, so bfloat24? Q can be negative, which is always fun. No idea how this interacts with Inf and NaN …<br>
UV: For non-perspective correct texturing. 12.4 fixed-point un-normalized.</p>
<ul>
<li>Triangles are top-left raster, just like modern GPUs.</li>
<li>Pixel center is on integer coordinate, just like D3D9. (This is a common design mistake that D3D10+ and GL/Vulkan avoids).</li>
<li>Lines use Bresenham’s algorithm, which is not really feasible to upscale, so we have to fudge it with rect or parallelogram.</li>
<li>Points snap to nearest pixel. Unsure which rounding is used though … There is no interpolation ala gl_PointCoord.</li>
<li>Sprites are simple quads with two coordinates. STQ or UV can be interpolated and it seems to assume non-rotated coordinates. To support rotation, you’d need 3 coordinates to disambiguate.</li>
</ul>
<p>All of this can be implemented fairly easily in normal graphics APIs, as long as we don’t consider upscaling. We have to rely on implementation details in GL and Vulkan, since these APIs don’t technically guarantee top-left raster rules.</p>
<p>Since X/Y is unsigned, there is an XY offset that can be applied to center the viewport where you want. This means the effective range of X/Y is +/- 4k pixels, a healthy guard band for 640×448 resolutions.</p>
<h3>Vertex queue</h3>
<p>The GS feels very much like old school OpenGL 1.0 with glVertex3f and friends. It even supports TRIANGLE_FAN! Amazing … RGBA, STQ and various registers are set, and every XYZ register write forms a vertex “kick” which latches vertex state and advances the queue. An XYZ register write may also be a drawing kick, which draws a primitive if the vertex queue is sufficiently filled. The vertex queue is managed differently depending on the topology. The semantics here seem to be pretty straight forward where strip primitives shift the queue by one, and list primitives clear the queue. Triangle fans keep the first element in the queue.</p>
<h3>Fun swizzling formats</h3>
<p>A clever idea is that while rendering to 24-bit color or 24-bit depth, there is 8 bits left unused in the MSBs. You can place textures there, because why not. 8H, 4HL, 4HH formats support 8-bit and 4-bit palettes nicely.</p>
<p>Pixel coordinates on PS2 are arranged into “pages”, which are 8 KiB, then subdivided into 32 blocks, and then, the smaller blocks are swizzled into a layout that fits well with a DDA-style renderer. E.g. for 32-bit RGBA, a page is 64×32 pixels, and 32 8×8 blocks are Z-order swizzled into that page.</p>
<h3>Framebuffer cache and texture cache</h3>
<p>There is a dedicated cache for framebuffer rendering and textures, one page’s worth. Games often abuse this to perform feedback loops, where they render on top of the pixels being sampled from. This is the root cause of extreme pain. N64 avoided this problem by having explicit copies into TMEM (and not really having the bandwidth to do elaborate feedback effects), and other consoles rendered to embedded SRAM (ala a tiler GPU), so these feedbacks aren’t as painful, but the GS is complete YOLO. Dealing with this gracefully is probably the biggest challenge. Combined with the PS2 being a bandwidth monster, developers knew how to take advantage of copious blending and blurring passes …</p>
<h3>Texturing</h3>
<p>Texturing on the GS is both very familar, and arcane.</p>
<p>On the plus side, the texel-center is at half-pixel, just like modern APIs. It seems like it has 4-bit sub-texel precision instead of 8 however. This is easily solved with some rounding. It also seems to have floor-rounding instead of nearest-rounding for bi-linear.</p>
<p>The bi-linear filter is a normal bi-linear. No weird 3-point N64 filter here.</p>
<p>On the weirder side, there are two special addressing modes.</p>
<p>REGION_CLAMP supports an arbitrary clamp inside a texture atlas (wouldn’t this be nice in normal graphics APIs? :D). It also works with REPEAT, so you can have REPEAT semantics on border, but then clamp slightly into the next “wrap”. This is trivial to emulate.</p>
<p>REGION_REPEAT is … worse. Here we can have custom bit-wise computation per coordinate. So something like u’ = (u &amp; MASK) | FIX. This is done per-coordinate in bi-linear filtering, which is … painful, but solvable. This is another weird PS1 feature that was likely inherited for compatibility. At least on PS1, there was no bi-linear filtering to complicate things 🙂</p>
<p>Mip-mapping is also somewhat curious. Rather than relying on derivatives, the log2 of interpolated Q factor, along with some scaling factors are used to compute the LOD. This is quite clever, but I haven’t really seen any games use it. The down-side is that triangle-setup becomes rather complex if you want to account for correct tri-linear filtering, and it cannot support e.g. anisotropic filtering, but this is 2000, who cares! Not relying on derivatives is a huge boon for the compute implementation.</p>
<p>Formats are always “normalized” to RGBA8_UNORM. 5551 format is expanded to 8888 without bit-replication. There is no RGBA4444 format.</p>
<p>It’s quite feasible to implement the texturing with plain bindless.</p>
<h3>CLUT</h3>
<p>This is a 1 KiB cache that holds the current palette. There is an explicit copy step from VRAM into that CLUT cache before it can be used. Why hello there, N64 TMEM!</p>
<p>The CLUT is organized such that it can hold one full 256 color palette in 32-bit colors. On the other end, it can hold 32 palettes of 16 colors at 16 bpp.</p>
<h3>TEXFLUSH</h3>
<p>There is an explicit command that functions like a “sync and invalidate texture cache”. In the beginning I was hoping to rely on this to guide the hazard tracking, but oh how naive I was. In the end, I simply had to ignore TEXFLUSH. Basically, there are two styles of caching we could take with GS.</p>
<p>With “maximal” caching, we can assume that frame buffer caches and texture caches are infinitely large. The only way a hazard needs to be considered is after an explicit flush. This … breaks hard. Either games forget to use TEXFLUSH (because it happened to work on real hardware), or they TEXFLUSH way too much.</p>
<p>With “minimal” caching, we assume there is no caching and hazards are tracked directly. Some edge case handling is considered for feedback loops.</p>
<p>I went with “minimal”, and I believe GSdx did too.</p>
<h3>Poking registers with style – GIF</h3>
<p>The way to interact with the GS hardware is through the GIF, which is basically a unit that reads data and pokes the correct hardware registers. At the start of a GIF packet, there is a header which configures which registers should be written to, and how many “loops” there are. This maps very well to mesh rendering. We can consider something like one “loop” being:</p>
<ul>
<li>Write RGBA vertex color</li>
<li>Write texture coordinate</li>
<li>Write position with draw kick</li>
</ul>
<p>And if we have 300 vertices to render, we’d use 300 loops. State registers can be poked through the Address + Data pair, which just encodes target register + 64-bit payload. It’s possible to render this way too of course, but it’s just inefficient.</p>
<p>Textures are uploaded through the same mechanism. Various state registers are written to set up transfer destinations, formats, etc, and a special register is nudged to transfer 64-bit at a time to VRAM.</p>
<h2>Hello Trongle – GS</h2>
<p>If you missed the brain-dead simplicity of OpenGL 1.0, this is the API for you! 😀</p>
<p>For testing purposes, I added a tool to generate a .gs dump format that PCSX2 can consume. This is handy for comparing implementation behavior.</p>
<p>First, we program the frame buffer and scissor:</p>
<pre>TESTBits test = {};
test.ZTE = TESTBits::ZTE_ENABLED;
test.ZTST = TESTBits::ZTST_GREATER; // Inverse Z, LESS is not supported.
iface.write_register(RegisterAddr::TEST_1, test);

FRAMEBits frame = {};
frame.FBP = 0x0 / PAGE_ALIGNMENT_BYTES;
frame.PSM = PSMCT32;
frame.FBW = 640 / BUFFER_WIDTH_SCALE;
iface.write_register(RegisterAddr::FRAME_1, frame);

ZBUFBits zbuf = {};
zbuf.ZMSK = 0; // Enable Z-write
zbuf.ZBP = 0x118000 / PAGE_ALIGNMENT_BYTES;
iface.write_register(RegisterAddr::ZBUF_1, zbuf);

SCISSORBits scissor = {};
scissor.SCAX0 = 0;
scissor.SCAY0 = 0;
scissor.SCAX1 = 640 - 1;
scissor.SCAY1 = 448 - 1;
iface.write_register(RegisterAddr::SCISSOR_1, scissor);</pre>
<p>Then we nudge some registers to draw:</p>
<pre>struct Vertex
{
    PackedRGBAQBits rgbaq;
    PackedXYZBits xyz;
} vertices[3] = {};

for (auto &amp;vert : vertices)
{
   vert.rgbaq.A = 0x80;
   vert.xyz.Z = 1;
}

vertices[0].rgbaq.R = 0xff;
vertices[1].rgbaq.G = 0xff;
vertices[2].rgbaq.B = 0xff;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.X = p2.x &lt;&lt; SUBPIXEL_BITS;
vertices[2].xyz.Y = p2.y &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 0; // Turn off texturing.
prim.IIP = 1; // Interpolate RGBA (Gouraud shading)
prim.PRIM = int(PRIMType::TriangleList);

static const GIFAddr addr[] = { GIFAddr::RGBAQ, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>This draws a triangle. We provide coordinates directly in screen-space.</p>
<p>And finally, we need to program the CRTC. Most of this is just copy-pasta from whatever games tend to do.</p>
<pre>auto &amp;priv = iface.get_priv_register_state();

priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_ALP;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0x0;
priv.bgcolor.G = 0x0;
priv.bgcolor.B = 0x0;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.pmode.ALP = 0xff;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;

dump.write_vsync(0, iface);
dump.write_vsync(1, iface);</pre>
<p>When the GS is dumped, we can load it up in PCSX2 and voila:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png"><img fetchpriority="high" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/gs_dump.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>And here’s the same .gs dump is played through parallel-gs-replayer with RenderDoc. For debugging, I’ve spent a lot of time making it reasonably convenient. The images are debug storage images where I can store before and after color, depth, debug values for interpolants, depth testing state, etc, etc. It’s super handy to narrow down problem cases. The render pass can be split into 1 or more triangle chunks as needed.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png" alt="" width="660" height="384" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1024x596.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-300x175.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-768x447.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-1536x894.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rdoc-2048x1192.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To add some textures, and flex the capabilities of the CRTC a bit, we can try uploading a texture:</p>
<pre>int chan;
auto *buf = stbi_load("/tmp/test.png", &amp;w, &amp;h, &amp;chan, 4);
iface.write_image_upload(0x300000, PSMCT32, w, h, buf,
                         w * h * sizeof(uint32_t));
stbi_image_free(buf);

TEX0Bits tex0 = {};
tex0.PSM = PSMCT32;
tex0.TBP0 = 0x300000 / BLOCK_ALIGNMENT_BYTES;
tex0.TBW = (w + BUFFER_WIDTH_SCALE - 1) / BUFFER_WIDTH_SCALE;
tex0.TW = Util::floor_log2(w - 1) + 1;
tex0.TH = Util::floor_log2(h - 1) + 1;
tex0.TFX = COMBINER_DECAL;
tex0.TCC = 1; // Use texture alpha as blend alpha
iface.write_register(RegisterAddr::TEX0_1, tex0);

TEX1Bits tex1 = {};
tex1.MMIN = TEX1Bits::LINEAR;
tex1.MMAG = TEX1Bits::LINEAR;
iface.write_register(RegisterAddr::TEX1_1, tex1);

CLAMPBits clamp = {};
clamp.WMS = CLAMPBits::REGION_CLAMP;
clamp.WMT = CLAMPBits::REGION_CLAMP;
clamp.MINU = 0;
clamp.MAXU = w - 1;
clamp.MINV = 0;
clamp.MAXV = h - 1;
iface.write_register(RegisterAddr::CLAMP_1, clamp);</pre>
<p>While PS2 requires POT sizes for textures, REGION_CLAMP is handy for NPOT. Super useful for texture atlases.</p>
<pre>struct Vertex
{
    PackedUVBits uv;
    PackedXYZBits xyz;
} vertices[2] = {};

for (auto &amp;vert : vertices)
    vert.xyz.Z = 1;

vertices[0].xyz.X = p0.x &lt;&lt; SUBPIXEL_BITS;
vertices[0].xyz.Y = p0.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.X = p1.x &lt;&lt; SUBPIXEL_BITS;
vertices[1].xyz.Y = p1.y &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.U = w &lt;&lt; SUBPIXEL_BITS;
vertices[1].uv.V = h &lt;&lt; SUBPIXEL_BITS;

PRIMBits prim = {};
prim.TME = 1; // Turn on texturing.
prim.IIP = 0;
prim.FST = 1; // Use unnormalized coordinates.
prim.PRIM = int(PRIMType::Sprite);

static const GIFAddr addr[] = { GIFAddr::UV, GIFAddr::XYZ2 };
constexpr uint32_t num_registers = sizeof(addr) / sizeof(addr[0]);
constexpr uint32_t num_loops = sizeof(vertices) / sizeof(vertices[0]);
iface.write_packed(prim, addr, num_registers, num_loops, vertices);</pre>
<p>Here we render a sprite with un-normalized coordinates.</p>
<p>Finally, we use the CRTC to do blending against white background.</p>
<pre>priv.pmode.EN1 = 1;
priv.pmode.EN2 = 0;
priv.pmode.CRTMD = 1;
priv.pmode.MMOD = PMODEBits::MMOD_ALPHA_CIRCUIT1;
priv.smode1.CMOD = SMODE1Bits::CMOD_NTSC;
priv.smode1.LC = SMODE1Bits::LC_ANALOG;
priv.bgcolor.R = 0xff;
priv.bgcolor.G = 0xff;
priv.bgcolor.B = 0xff;
priv.pmode.SLBG = PMODEBits::SLBG_ALPHA_BLEND_BG;
priv.smode2.INT = 1;

priv.dispfb1.FBP = 0;
priv.dispfb1.FBW = 640 / BUFFER_WIDTH_SCALE;
priv.dispfb1.PSM = PSMCT32;
priv.dispfb1.DBX = 0;
priv.dispfb1.DBY = 0;
priv.display1.DX = 636; // Magic values that center the screen.
priv.display1.DY = 50; // Magic values that center the screen.
priv.display1.MAGH = 3; // scaling factor = MAGH + 1 = 4 -&gt; 640 px wide.
priv.display1.MAGV = 0;
priv.display1.DW = 640 * 4 - 1;
priv.display1.DH = 448 - 1;</pre>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/vk.png"><img decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png" alt="" width="660" height="380" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/vk-1024x590.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-300x173.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-768x443.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/vk-1536x886.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/vk.png 2005w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Glorious 256×179 logo 😀</p>
<h2>Implementation details</h2>
<h3>The rendering pipeline</h3>
<p>Before we get into the page tracker, it’s useful to define a rendering pipeline where synchronization is implied between each stage.</p>
<ul>
<li>Synchronize CPU copy of VRAM to GPU. This is mostly unused, but happens for save state load, or similar</li>
<li>Upload data to VRAM (or perform local-to-local copy)</li>
<li>Update CLUT cache from VRAM</li>
<li>Unswizzle VRAM into VkImages that can be sampled directly, and handle palettes as needed, sampling from CLUT cache</li>
<li>Perform rendering</li>
<li>Synchronize GPU copy of VRAM back to CPU. This will be useful for readbacks. Then CPU should be able to unswizzle directly from a HOST_CACHED_BIT buffer as needed</li>
</ul>
<p>This pipeline matches what we expect a game to do over and over:</p>
<ul>
<li>Upload texture to VRAM</li>
<li>Upload palette to VRAM</li>
<li>Update CLUT cache</li>
<li>Draw with texture
<ul>
<li>Trigger unswizzle from VRAM into VkImage if needed</li>
<li>Begins building a “render pass”, a batch of primitives</li>
</ul>
</li>
</ul>
<p>When there are no backwards hazards here, we can happily keep batching and defer any synchronization. This is critical to get any performance out of this style of renderer.</p>
<p>Some common hazards here include:</p>
<h4>Copy to VRAM which was already written by copy</h4>
<p>This is often a false positive, but we cannot track per-byte. This becomes a simple copy barrier and we move on.</p>
<h4>Copy to VRAM where a texture was sampled from, or CLUT cache read from</h4>
<p>Since the GS has a tiny 4 MiB VRAM, it’s very common that textures are continuously streamed in, sampled from, and thrown away. When this is detected, we have to submit all vram copy work, all texture unswizzle work and then begin a new batch. Primitive batches are not disrupted.</p>
<p>This means we’ll often see:</p>
<ul>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Copy xN</li>
<li>Barrier</li>
<li>Unswizzle xN</li>
<li>Barrier</li>
<li>Rendering</li>
</ul>
<h4>Sample texture that was rendered to</h4>
<p>Similar, but here we need to flush out everything. This basically breaks the render pass and we start another one. Too many of these is problematic for performance obviously.</p>
<h4>Copy to VRAM where rendering happened</h4>
<p>Basically same as sampling textures, this is a full flush.</p>
<p>Other hazards are ignored, since they are implicitly handled by our pipeline.</p>
<h3>Page tracker</h3>
<p>Arguably, the hardest part of GS emulation is dealing with hazards. VRAM is read and written to with reckless abandon and any potential read-after-write or write-after-write hazard needs to be dealt with. We cannot rely on any game doing this for us, since PS2 GS just deals with sync in most cases, and TEXFLUSH is the only real command games will use (or forget to use).</p>
<p>Tracking per byte is ridiculous, so my solution is to first subdivide the 4 MiB VRAM into pages. A page is the unit for frame buffers and depth buffers, so it is the most meaningful place to start.</p>
<h4>PageState</h4>
<p>On page granularity, we track:</p>
<ul>
<li>Pending frame buffer write?</li>
<li>Pending frame buffer read? (read-only depth)</li>
</ul>
<p>Textures and VRAM copies have 256 byte alignment, and to avoid a ton of false positives, we need to track on a per-block basis. There are 32 blocks per page, so a u32 bit-mask is okay.</p>
<ul>
<li>VRAM copy writes</li>
<li>VRAM copy reads</li>
<li>Pending read into CLUT cache or VkImage</li>
<li>Blocks which have been clobbered by any write, on next texture cache invalidate, throw away images that overlap</li>
</ul>
<p>As mentioned earlier, there are also cases where you can render to 24-bit color, while sampling from the upper 8-bits without hazard. We need to optimize for that case too, so there is also:</p>
<ul>
<li>A write mask for framebuffers</li>
<li>A read mask for textures</li>
</ul>
<p>In the example above, FB write mask is 0xffffff and texture cache mask is 0xff000000. No overlap, no invalidate 😀</p>
<p>For host access, there are also timeline semaphore values per page. These values state which sync point to wait for if the host desires mapped read or mapped write access. Mapped write access may require more sync than mapped read if there are pending reads on that page.</p>
<h4>Caching textures</h4>
<p>Every page contains a list of VkImages which have been associated with it. When a page’s textures has been invalidated, the image is destroyed and has to be unswizzled again from VRAM.</p>
<p>There is a one-to-many relationship with textures and pages. A texture may span more than one page, and it’s enough that only one page is clobbered before the texture is invalidated.</p>
<p>Overall, there are a lot of micro-details here, but the important things to note here is that conservative and simple tracking will not work on PS2 games. Tracking at a 256 byte block level and considering write/read masks is critical.</p>
<h4>Special cases</h4>
<p>There are various situations where we may have false positives due to how textures work. Since textures are POT sized, it’s fairly common for e.g. a 512×448 texture of a render target to be programmed as a 512×512 texture. The unused region should ideally be clamped out with REGION_CLAMP, but most games don’t. A render target might occupy those unused pages. As long as the game’s UV coordinates don’t extend into the unused red zone, there are no hazards, but this is very painful to track. We would have to analyze every single primitive to detect if it’s sampling into the red zone.</p>
<p>As a workaround, we ignore any potential hazard in that red zone, and just pray that a game isn’t somehow relying on ridiculous spooky-action-at-a-distance hazards to work in the game’s favor.</p>
<p>There are more spicy special cases, especially with texture sampling feedback, but that will be for later.</p>
<h3>Updating CLUT in a batched way</h3>
<p>Since we want to batch texture uploads, we have to batch CLUT uploads too. To make this work, we have 1024 copies of CLUT, a ring buffer of snapshots.</p>
<p>One workgroup loops through the updates and writes them to an SSBO. I did a similar thing for N64 RDP’s TMEM update, where TMEM was instanced. Fortunately, CLUT update is <strong>far</strong> simpler than TMEM update.</p>
<pre>shared uint tmp_clut[512];

// ...

// Copy from previous instance to allow a
// CLUT entry to be partially overwritten and used later
uint read_index = registers.read_index * CLUT_SIZE_16;
tmp_clut[gl_LocalInvocationIndex] =
    uint(clut16.data[read_index]);
tmp_clut[gl_LocalInvocationIndex + 256u] =
    uint(clut16.data[read_index + 256u]);
barrier();

for (uint i = 0; i &lt; registers.clut_count; i++)
{
  // ...
  if (active_lane)
  {
    // update tmp_clut. If 256 color, all threads participate.
    // 16 color update is a partial update.
  }

  // Flush current CLUT state to SSBO.
  barrier();
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex]);
  clut16.data[gl_LocalInvocationIndex + clut.instance * CLUT_SIZE_16 + 256u] =
    uint16_t(tmp_clut[gl_LocalInvocationIndex + 256u]);
  barrier();
}</pre>
<p>One potential optimization is that for 256 color / 32 bpp updates, we can parallelize the CLUT update, since nothing from previous iterations will be preserved, but the CLUT update time is tiny anyway.</p>
<h3>Unswizzling textures from VRAM</h3>
<p>Since this is Vulkan, we can just allocate a new VkImage, suballocate it from VkDeviceMemory and blast it with a compute shader.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/upload.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/upload-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/upload-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Using Vulkan’s specialization constants, we specialize the texture format and all the swizzling logic becomes straight forward code.</p>
<p>REGION_REPEAT shenanigans is also resolved here, so that the ubershader doesn’t have to consider that case and do manual bilinear filtering.</p>
<p>Even for render targets, we roundtrip through the VRAM SSBO. There is not really a point going to the length of trying to forward render targets into textures. Way too many bugs to squash and edge cases to think about.</p>
<h3>Triangle setup and binning</h3>
<p>Like paraLLEl-RDP, paraLLEl-GS is a tile-based renderer. Before binning can happen, we need triangle setup. As inputs, we provide attributes in three arrays.</p>
<h5>Position</h5>
<pre>struct VertexPosition
{
  ivec2 pos;
  float z;     // TODO: Should be uint for 32-bit Z.
  int padding; // Free real-estate?
};</pre>
<h5>Per-Vertex attributes</h5>
<pre>struct VertexAttribute
{
  vec2 st;
  float q;
  uint rgba; // unpackUnorm4x8
  float fog; // overkill, but would be padding anyway
  u16vec2 uv;
};</pre>
<h5>Per-primitive attributes</h5>
<pre>struct PrimitiveAttribute
{
  i16vec4 bb; // Scissor
  // Index into state UBO, as well as misc state bits.
  uint state;
  // Texture state which should be scalarized. Affects code paths.
  // Also holds the texture index (for bindless).
  uint tex;
  // Texture state like lod scaling factors, etc.
  // Does not affect code paths.
  uint tex2;  
  uint alpha; // AFIX / AREF
  uint fbmsk;
  uint fogcol;
};</pre>
<p>For rasterization, we have a straight forward barycentric-based rasterizer. It is heavily inspired by <a href="https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/">https://fgiesen.wordpress.com/2011/07/06/a-trip-through-the-graphics-pipeline-2011-part-6/</a>, which in turn is based on <a href="https://www.cs.drexel.edu/~david/Classes/Papers/comp175-06-pineda.pdf">A Parallel Algorithm for Polygon Rasterization (Paneda, 1988)</a> and describes the “standard” way to write a rasterizer with parallel hardware. Of course, the PS2 GS is DDA, i.e. a scanline rasterizer, but in practice, this is just a question of nudging ULPs of precision, and since I’m not aware of a bit-exact description of the GS’s DDA, this is fine. paraLLEl-RDP implements the raw DDA form for example. It’s certainly possible if we <strong>have</strong> to.</p>
<p>As an extension to a straight-forward triangle rasterizer, I also need to support parallelograms. This is used to implement wide-lines and sprites. Especially wide-line is kinda questionable, but I’m not sure it’s possible to fully solve up-scaling + Bresenham in the general case. At least I haven’t run into a case where this really matters.</p>
<p>Evaluating coverage and barycentric I/J turns into something like this:</p>
<pre>bool evaluate_coverage_single(PrimitiveSetup setup,
  bool parallelogram, 
  ivec2 parallelogram_offset,
  ivec2 coord, inout float i, inout float j)
{
  int a = idot3(setup.a, coord);
  int b = idot3(setup.b, coord);
  int c = idot3(setup.c, coord);

  precise float i_result = float(b) * setup.inv_area + setup.error_i;
  precise float j_result = float(c) * setup.inv_area + setup.error_j;
  i = i_result;
  j = j_result;

  if (parallelogram &amp;&amp; a.x &lt; 0)
  {
    b += a + parallelogram_offset.x;
    c += a + parallelogram_offset.y;
    a = 0;
  }

  return all(greaterThanEqual(ivec3(a, b, c), ivec3(0)));
}</pre>
<p>inv_area is computed in a custom fixed-point RCP, which is ~24.0 bit accurate. Using the standard GPU RCP would be bad since it’s just ~22.5 bit accurate and not consistent across implementations. There is no reason to skimp on reproducibility and accuracy, since we’re not doing work per-pixel.</p>
<p>error_i and error_j terms are caused by the downsampling of the edge equations and tie-break rules. As a side effect of the GS’s [-4k, +4k] pixel range, the range of the cross-product requires 33-bit in signed integers. By downsampling a bit, we can get 32-bit integer math to work just fine with 8 sub-pixel accuracy for super-sampling / multi-sampling. Theoretically, this means our upper up-sampling limit is 8×8, but that’s ridiculous anyway, so we’re good here.</p>
<p>The parallelogram offsets are very small numbers meant to nudge the tie-break rules in our favor as needed. The exact details of the implementation escape me. I wrote that code years ago. It’s not very hard to derive however.</p>
<p>Every primitive gets a struct of transformed attributes as well. This is only read if we actually end up shading a primitive, so it’s important to keep this separate to avoid polluting caches with too much garbage.</p>
<pre>struct TransformedAttributes
{
  vec4 stqf0;
  vec4 stqf1;
  vec4 stqf2;
  uint rgba0;
  uint rgba1;
  uint rgba2;
  uint padding;
  vec4 st_bb;
};</pre>
<p>Using I/J like this will lead to small inaccuracies when interpolating primitives which expect to land exactly on the top-left corner of a texel with NEAREST filtering. To combat this, a tiny epsilon offset is used when snapping texture coordinates. Very YOLO, but what can you do. As far as I know, hardware behavior is sub-texel floor, not sub-texel round.</p>
<pre>precise vec2 uv_1 = uv * scale_1;

// Want a soft-floor here, not round behavior.
const float UV_EPSILON_PRE_SNAP = 1.0 / 16.0;
// We need to bias less than 1 / 512th texel, so that linear filter will RTE to correct subpixel.
// This is a 1 / 1024th pixel bias to counter-act any non-POT inv_scale_1 causing a round-down event.
const float UV_EPSILON_POST_SNAP = 16.0 / 1024.0;

if (sampler_clamp_s)
  uv_1.x = texture_clamp(uv_1.x, region_coords.xz, LOD_1);
if (sampler_clamp_t)
  uv_1.y = texture_clamp(uv_1.y, region_coords.yw, LOD_1);

// Avoid micro-precision issues with UV and flooring + nearest.
// Exact rounding on hardware is somwhat unclear.
// SotC requires exact rounding precision and is hit particularly bad.
// If the epsilon is too high, then FF X save screen is screwed over,
// so ... uh, ye.
// We likely need a more principled approach that is actually HW accurate in fixed point.
uv_1 = (floor(uv_1 * 16.0 + UV_EPSILON_PRE_SNAP) + UV_EPSILON_POST_SNAP) *
       inv_scale_1 * 0.0625;</pre>
<h3>Binning</h3>
<p>This is mostly uninteresting. Every NxN pixel block gets an array of u16 primitive indices to shade. This makes the maximum number of primitives per render pass 64k, but that’s enough for PS2 games. Most games I’ve seen so far tend to be between 10k and 30k primitives for the “main” render pass, but I haven’t tested the real juggernauts of primitive grunt yet, but even so, having to do a little bit of incremental rendering isn’t a big deal.</p>
<p>NxN is usually 32×32, but it can be dynamically changed depending on how heavy the geometry load is. For large resolutions and high primitive counts, the binning and memory cost is unacceptable if the resolution is just 16×16 for example. One subgroup is responsible for iterating through all primitives in a block.</p>
<p>Since binning and triangle is state-less, triangle-setup and binning for back-to-back passes are batched up nicely to avoid lots of silly barriers.</p>
<h3>The ubershader</h3>
<p>A key difference between N64 and PS2 is fill-rate and per-pixel complexity. For N64, the ideal approach is to specialize the rasterizing shader, write out per-pixel color + depth + coverage + etc, then merge that data in a much simpler ubershader that only needs to consider depth and blend state rather than full texturing state and combiner state. This is very bandwidth intensive on the GPU, but the alternative is the slowest ubershader written by man. We’re saved by the fact that N64 fill-rate is abysmal. <a href="https://www.youtube.com/watch?v=GC_jLsxZ7nw">Check out this video by Kaze to see how horrible it is</a>.</p>
<p>The GS is a quite different beast. Fill-rate is very high, and per-pixel complexity is fairly low, so a pure ubershader is viable. We can also rely on bindless this time around too, so texturing complexity becomes a fraction of what I had to deal with on N64.</p>
<h4>Fine-grained binning</h4>
<p>Every tile is 4×4, 4×8 and 8×8 for subgroup sizes 16, 32 and 64 respectively. For super-sampling it’s even smaller (it’s 4×4 / 4×8 / 8×8 in the higher resolution domain instead).</p>
<p>In the outer loop, we pull in up to SubgroupSize’s worth of primitives, and bin them in parallel.</p>
<pre>for (int i = 0; i &lt; tile.coarse_primitive_count;
     i += int(gl_SubgroupSize))
{
  int prim_index = i + int(gl_SubgroupInvocationID);
  bool is_last_iteration = i + int(gl_SubgroupSize) &gt;= 
                           tile.coarse_primitive_count;

  // Bin primitives to tile.
  bool binned_to_tile = false;
  uint bin_primitive_index;
  if (prim_index &lt; tile.coarse_primitive_count)
  {
    bin_primitive_index = 
      uint(coarse_primitive_list.data[
           tile.coarse_primitive_list_offset + prim_index]);
    binned_to_tile = primitive_intersects_tile(bin_primitive_index);
  }

  // Iterate per binned primitive, do per pixel work now.
  // Scalar loop.
  uvec4 work_ballot = subgroupBallot(binned_to_tile);</pre>
<p>In the inner loop, we can do a scalarized loop which checks coverage per-pixel, one primitive at a time.</p>
<pre>// Scalar data
uint bit = subgroupBallotFindLSB(work_ballot);

if (gl_SubgroupSize == 64)
{
  if (bit &gt;= 32)
    work_ballot.y &amp;= work_ballot.y - 1;
  else
    work_ballot.x &amp;= work_ballot.x - 1;
}
else
{
  work_ballot.x &amp;= work_ballot.x - 1;
}

shade_primitive_index = subgroupShuffle(bin_primitive_index, bit);</pre>
<h4>Early Z</h4>
<p>We can take advantage of early-Z testing of course, but we have to be careful if there are rasterized pixels we haven’t resolved yet, and there are Z-writes in flight. In this case we have to defer to late Z to perform test.</p>
<pre>// We might have to remove opaque flag.
bool pending_z_write_can_affect_result =
  (pixel.request.z_test || !pixel.request.z_write) &amp;&amp;
  pending_shade_request.z_write;

if (pending_z_write_can_affect_result)
{
  // Demote the pixel to late-Z,
  // it's no longer opaque and we cannot discard earlier pixels.
  // We need to somehow observe the previous results.
  pixel.opaque = false;
}</pre>
<h4>Deferred on-tile shading</h4>
<p>Since we’re an uber-shader, all pixels are “on-chip”, i.e. in registers, so we can take advantage of culling pixels that won’t be visible anyway. The basic idea here is that after rasterization, if a pixel is considered opaque, it will simply replace the shading request that exists for that framebuffer coordinate. It won’t be visible at all anyway.</p>
<h4>Lazy pixel shading</h4>
<p>We only need to perform shading when we really have to, i.e., we’re shading a pixel that depends on the previous pixel’s results. This can happen for e.g. alpha test (if test fails, we preserve existing data), color write masks, or of course, alpha blending.</p>
<p>If our pixel remains opaque, we can just kill the pending pixel shade request. Very nice indeed. The gain here wasn’t as amazing as I had hoped since PS2 games love blending, but it helps culling out a lot of shading work.</p>
<pre>if (pixel.request.coverage &gt; 0)
{
  need_flush = !pixel.opaque &amp;&amp; pending_shade_request.coverage &gt; 0;

  // If there is no hazard, we can overwrite the pending pixel.
  // If not, defer the update until we run a loop iteration.
  if (!need_flush)
  {
    set_pending_shade_request(pixel.request, shade_primitive_index);
    pixel.request.coverage = 0;
    pixel.request.z_write = false;
  }
}</pre>
<p>If we have flushes that need to happen, we do so if one pixel needs it. It’s just as fast to resolve all pixels anyway.</p>
<pre>// Scalar branch
if (subgroupAny(need_flush))
{
  shade_resolve();
  if (has_work &amp;&amp; pixel.request.coverage &gt; 0)
    set_pending_shade_request(pixel.request, shade_primitive_index);
}</pre>
<p>The resolve is a straight forward waterfall loop that stays in uniform control flow to be well defined on devices without maximal reconvergence support.</p>
<pre>while (subgroupAny(has_work))
{
  if (has_work)
  {
    uint state_index =
      subgroupBroadcastFirst(pending_shade_request.state);
    uint tex = subgroupBroadcastFirst(prim_tex);
    if (state_index == pending_shade_request.state &amp;&amp; prim_tex == tex)
    {
      has_work = false;
      shade_resolve(pending_primitive_index, state_index, tex);
    }
  }
}</pre>
<p>This scalarization ensures that all branches on things like alpha test mode, blend modes, etc, are purely scalar, and GPUs like that. Scalarizing on the texture index is technically not that critical, but it means we end up hitting the same branches for filtering modes, UBOs for scaling factors are loaded uniformly, etc.</p>
<p>When everything is done, the resulting framebuffer color and depth is written out to SSBO. GPU bandwidth is kept to a minimum, just like a normal TBDR renderer.</p>
<h3>Super-sampling</h3>
<p>Just implementing single sampled rendering isn’t enough for this renderer to be really useful. The software renderer is certainly quite fast, but not fast enough to keep up with intense super-sampling. We can fix that now.</p>
<p>For e.g. 8x SSAA, we keep 10 versions of VRAM on the GPU.</p>
<ul>
<li>1 copy represents the single-sampled VRAM. It is super-sampled.</li>
<li>1 copy represents the reference value for single-sampled VRAM. This allows us to track when we should discard the super-samples and splat the single sample to all. This can happen if someone copies to VRAM over a render target for whatever reason.</li>
<li>8 copies which each represent the super-samples. Technically, we can reconstruct a higher resolution image from these samples if we really want to, but only the CRTC could easily do that.</li>
</ul>
<p>When rendering super-sampled, we load the single-sampled VRAM and reference. If they match, we load the super-sampled version. This is important for cases where we’re doing incremental rendering.</p>
<p>On tile completion we use clustered subgroup ops to do multi-sample resolve, then write out the super-samples, and the two single-sampled copies.</p>
<pre>uvec4 ballot_color = subgroupBallot(fb_color_dirty);
uvec4 ballot_depth = subgroupBallot(fb_depth_dirty);

// No need to mask, we only care about valid ballot for the
// first sample we write-back.
if (NUM_SAMPLES &gt;= 16)
{
  ballot_color |= ballot_color &gt;&gt; 8u;
  ballot_depth |= ballot_depth &gt;&gt; 8u;
}

if (NUM_SAMPLES &gt;= 8)
{
  ballot_color |= ballot_color &gt;&gt; 4u;
  ballot_depth |= ballot_depth &gt;&gt; 4u;
}

if (NUM_SAMPLES &gt;= 4)
{
  ballot_color |= ballot_color &gt;&gt; 2u;
  ballot_depth |= ballot_depth &gt;&gt; 2u;
}

ballot_color |= ballot_color &gt;&gt; 1u;
ballot_depth |= ballot_depth &gt;&gt; 1u;

// GLSL does not accept cluster reduction as spec constant.
if (NUM_SAMPLES == 16)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 16) / 16.0);
else if (NUM_SAMPLES == 8)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 8) / 8.0);
else if (NUM_SAMPLES == 4)
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 4) / 4.0);
else
  fb_color = packUnorm4x8(subgroupClusteredAdd(
    unpackUnorm4x8(fb_color), 2) / 2.0);

fb_color_dirty = subgroupInverseBallot(ballot_color);
fb_depth_dirty = subgroupInverseBallot(ballot_depth);</pre>
<p>The main advantage of super-sampling over straight up-scaling is that up-scaling will still have jagged edges, and super-sampling retains a coherent visual look where 3D elements have similar resolution as UI elements. One of my pet peeves is when UI elements have a significantly different resolution from 3D objects and textures. HD texture packs can of course alleviate that, but that’s a very different beast.</p>
<p>Super-sampling also lends itself very well to CRT post-processing shading, which is also a nice bonus.</p>
<h3>Dealing with super-sampling artifacts</h3>
<p>It’s a fact of life that super-sampling always introduces horrible artifacts if not handled with utmost care. Mitigating this is arguably easier with software renderers over traditional graphics APIs, since we’re not limited by the fixed function interpolators. These tricks won’t make it perfect by any means, but it greatly mitigates jank in my experience, and I already fixed many upscaling bugs that GSdx Vulkan backend does not solve as we shall see later.</p>
<h4>Sprite primitives should always render at single-rate</h4>
<p>Sprites are always UI elements or similar, and games do not expect us to up-scale them. Doing so either results in artifacts where we sample outside the intended rect, or we risk overblurring the image if bilinear filtering is used.</p>
<p>The trick here is just to force-snap the pixel coordinate we use when rasterizing and interpolating. This is very inefficient of course, but UI shouldn’t take up the entire screen. And if it does (like in a menu), the GPU load is tiny anyway.</p>
<pre>const uint SNAP_RASTER_BIT = (1u &lt;&lt; STATE_BIT_SNAP_RASTER);
const uint SNAP_ATTR_BIT = (1u &lt;&lt; STATE_BIT_SNAP_ATTRIBUTE);

if (SUPER_SAMPLE &amp;&amp; (prim_state &amp; SNAP_RASTER_BIT) != 0)
  fb_pixel = tile.fb_pixel_single_rate;

res.request.coverage = evaluate_coverage(
  prim, fb_pixel, i, j,
  res.request.multisample, SAMPLING_RATE_DIM_LOG2);</pre>
<h4>Flat primitives should interpolate at single-pixel coordinate</h4>
<p>Going further, we can demote SSAA interpolation to MSAA center interpolation dynamically. Many UI elements are unfortunately rendered with normal triangles, so we have to be a bit more careful. This snap only affects attribute interpolation, not Z of course.</p>
<pre>res.request.st_bb = false;
if (SUPER_SAMPLE &amp;&amp;
    (prim_state &amp; (SNAP_RASTER_BIT | SNAP_ATTR_BIT)) == SNAP_ATTR_BIT)
{
  vec2 snap_ij = evaluate_barycentric_ij(
    prim.b, prim.c, prim.inv_area,
    prim.error_i, prim.error_j, tile.fb_pixel_single_rate,
    SAMPLING_RATE_DIM_LOG2);

  i = snap_ij.x;
  j = snap_ij.y;
  res.request.st_bb = true;
}</pre>
<p>Here, we snap interpolation to the top-left pixel. This fixes any artifacts for primitives which align their rendering to a pixel center, but some games are mis-aligned, so this snapping can cause texture coordinates to go outside the expected area. To clean this up, we compute a bounding box of final texture coordinates. Adding bounding boxes can technically cause notorious block-edge artifacts, but that was mostly a thing on PS1 since emulators like to convert nearest sampling to bilinear.</p>
<p>The heuristic for this is fairly simple. If perspective is used, if all vertices in a triangle have exact same Q, we assume it’s a flat UI primitive. The primitive’s Z coordinates must also match. This is done during triangle setup on the GPU. There can of course be false positives here, but it should be rare. In my experience this hack works well enough in the games I tried.</p>
<h2>Results</h2>
<p>Here’s a good example of up-sampling going awry in PCSX2. This is with Vulkan backend:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1024x674.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-300x198.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-768x506.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts-1536x1012.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-artifacts.jpg 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-glitch.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Notice the bloom on the glass being mis-aligned and a subtle (?) rectangular pattern being overlaid over the image. This is caused by a post-processing pass rendering in a page-like pattern, presumably to optimize for GS caching behavior.</p>

<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/abyss-gs.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>With 8x SSAA in paraLLEl-GS it looks like this instead. There is FSR1 post-upscale in effect here which changes the look a bit, but the usual trappings of bad upscale cannot be observed here. This is another reason to do super-sample; texture mis-alignment has a tendency to fix itself.</p>
<p>Also, if you’re staring at the perf numbers, this is RX 7600 in a low power state :’)</p>
<p>Typical UI issues can be seen in games as well. Here’s native resolution:</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>and 4x upscale, which … does not look acceptable.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png" alt="" width="660" height="428" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1024x664.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-300x194.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-768x498.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x-1536x995.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-ffx-4x.png 1753w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This UI is tricky to render in upscaled mode, since it uses triangles, but the MSAA snap trick above works well and avoids all artifacts. With straight upscale, this is hard to achieve in normal graphics APIs since you’d need interpolateAtOffset beyond 0.5 pixels, which isn’t supported. Perhaps you could do custom interpolation with derivatives or something like that, but either way, this glitch can be avoided. The core message is basically to never upscale UI beyond plain nearest neighbor integer scale. It just looks bad.</p>
<p>There are cases where PCSX2 asks for high blending accuracy. One example is MGS2, and I found a spot where GPU perf is murdered. My desktop GPU cannot keep 60 FPS here at 4x upscale. PCSX2 asks you to turn up blend-accuracy for this game, but …</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>What happens here is we hit the programmable blending path with barrier between every primitive. Ouch! This wouldn’t be bad for the tiler mobile GPUs, but for a desktop GPU, it is where perf goes to die. The shader in question does subpassLoad and does programmable blending as expected. Barrier, tiny triangle, barrier, tiny triangle, hnnnnnnng.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/ouch.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png" alt="" width="660" height="371" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1024x576.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-300x169.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-768x432.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-1536x864.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/ouch-2048x1152.png 2048w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>paraLLEl-GS on the other hand always runs with 100% blend accuracy (assuming no bugs of course). Here’s 16xSSAA (equivalent to 4x upscale). This is just 25 W and 17% GPU utilization on RX 7600. Not bad.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-16xssaa.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Other difficult cases include texture sampling feedback. One particular case I found was in Valkyrie Profile 2.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg" alt="" width="660" height="400" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1024x621.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-300x182.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-768x466.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2-1536x932.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valprofile2.jpg 1747w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>This game has a case where it’s sampling it’s own pixel’s alpha as a palette index. Quirky as all hell, and similar to MGS2 there’s a barrier between every pixel.</p>
<p>In paraLLEl-GS, this case is detected, and we emit a magical texture index, which resolved to just looking at in-register framebuffer color instead. Programmable blending go brr. These cases have to be checked per primitive, which is quite rough on CPU time, but it is what it is. If we don’t hit the good path, GPU performance completely tanks.</p>
<p>The trick here is to analyze the effective UV coordinates, and see if UV == framebuffer position. If we fall off this path, we have to go via texture uploads, which is bad.</p>
<pre>ivec2 uv0_delta = uv0 - pos[0].pos;
ivec2 uv1_delta = uv1 - pos[1].pos;
ivec2 min_delta = min(uv0_delta, uv1_delta);
ivec2 max_delta = max(uv0_delta, uv1_delta);

if (!quad)
{
  ivec2 uv2_delta = uv2 - pos[2].pos;
  min_delta = min(min_delta, uv2_delta);
  max_delta = max(max_delta, uv2_delta);
}

int min_delta2 = min(min_delta.x, min_delta.y);
int max_delta2 = max(max_delta.x, max_delta.y);

// The UV offset must be in range of [0, 2^SUBPIXEL_BITS - 1].
// This guarantees snapping with NEAREST.
// 8 is ideal. That means pixel centers during interpolation
// will land exactly in the center of the texel.
// In theory we could allow LINEAR if uv delta was
// exactly 8 for all vertices.
if (min_delta2 &lt; 0 || max_delta2 &gt;= (1 &lt;&lt; SUBPIXEL_BITS))
  return ColorFeedbackMode::Sliced;

// Perf go brrrrrrr.
return ColorFeedbackMode::Pixel;</pre>
<pre>if (feedback_mode == ColorFeedbackMode::Pixel)
{
  mark_render_pass_has_texture_feedback(ctx.tex0.desc);
  // Special index indicating on-tile feedback.
  // We could add a different sentinel for depth feedback.
  // 1024k CLUT instances and 32 sub-banks. Fits in 15 bits.
  // Use bit 15 MSB to mark feedback texture.
  return (1u &lt;&lt; (TEX_TEXTURE_INDEX_BITS - 1u)) |
         (render_pass.clut_instance * 32 + uint32_t(ctx.tex0.desc.CSA));
}</pre>
<p>It’s comfortably full-speed on PCSX2 here, despite the copious number of barriers, but paraLLEl-GS is reasonably close perf-wise, actually. At 8x SSAA.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg" alt="" width="660" height="457" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1024x709.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-300x208.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-768x532.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs-1536x1064.jpg 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/valkyrie-gs.jpg 1708w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>Overall, we get away with 18 render pass barriers instead of 500+ which was the case without this optimization. You may notice the interlacing artifacts on the swirlies. Silly game has a progressive scan output, but downsamples it on its own to a field before hitting CRTC, hnnnnng 🙁 Redirecting framebuffer locations in CRTC might work as a per-game hack, but either way, I still need to consider a better de-interlacer. Some games actually render explicitly in fields (640×224), which is very annoying.</p>
<p>This scene in the MGS2 intro also exposes some funny edge cases with sampling.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png" alt="" width="660" height="443" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-1024x687.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-300x201.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro-768x515.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/mgs2-intro.png 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>To get the camo effect, it’s sampling its own framebuffer as a texture, with overlapping coordinates, but not pixel aligned, so this raises some serious questions about caching behavior. PCSX2 doesn’t seem to add any barriers here, and I kinda had to do the same thing. It looks fine to me compared to software renderer at least.</p>
<pre>if (feedback_mode == ColorFeedbackMode::Sliced)
{
  // If game explicitly clamps the rect to a small region,
  // it's likely doing well-defined feedbacks.
  // E.g. Tales of Abyss main menu ping-pong blurs.
  // This code is quite flawed,
  // and I'm not sure what the correct solution is yet.
  if (desc.clamp.desc.WMS == CLAMPBits::REGION_CLAMP &amp;&amp;
      desc.clamp.desc.WMT == CLAMPBits::REGION_CLAMP)
  {
    ivec4 clamped_uv_bb(
      int(desc.clamp.desc.MINU),
      int(desc.clamp.desc.MINV),
      int(desc.clamp.desc.MAXU),
      int(desc.clamp.desc.MAXV));

    ivec4 hazard_bb(
      std::max&lt;int&gt;(clamped_uv_bb.x, bb.x),
      std::max&lt;int&gt;(clamped_uv_bb.y, bb.y),
      std::min&lt;int&gt;(clamped_uv_bb.z, bb.z),
      std::min&lt;int&gt;(clamped_uv_bb.w, bb.w));

    cache_texture = hazard_bb.x &gt; hazard_bb.z ||
                    hazard_bb.y &gt; hazard_bb.w;
  }
  else
  {
    // Questionable,
    // but it seems almost impossible to do this correctly and fast.
    // Need to emulate the PS2 texture cache exactly,
    // which is just insane.
    // This should be fine.
    cache_texture = false;
  }
}</pre>
<p>If we’re in a mode where texture points directly to the frame buffer we should relax the hazard tracking a bit to avoid 2000+ barriers. This is clearly spooky since Tales of Abyss’s bloom effect as shown earlier depends on this to be well behaved, but in that case, at least it uses REGION_CLAMP to explicitly mark the ping-pong behavior. I’m not sure what the proper solution is here.</p>
<p>The only plausible solution to true bit-accuracy with real hardware is to emulate the caches directly, one pixel at a time. You can kiss performance good bye in that case.</p>
<p>One of the worst stress tests I’ve found so far has to be Shadow of the Collosus. Just in the intro, we can make the GPU kneel down to 24 FPS with maximum blend accuracy on PCSX2, at just 2x upscale! Even with normal blending accuracy, it is extremely heavy during the intro cinematic.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png" alt="" width="660" height="434" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1024x674.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-300x198.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-768x506.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy-1536x1012.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/pcsx2-max-blend-accuracy.png 1775w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>At 8x SSAA, perf is still looking pretty good for paraLLEl-GS, but it’s clearly sweating now.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg" alt="" width="660" height="462" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-1024x717.jpg 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-300x210.jpg 300w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc-768x538.jpg 768w, https://themaister.net/blog/wp-content/uploads/2024/07/parallel-sotc.jpg 1280w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<p>We’re actually still CPU bound on the geometry processing. Optimizing the CPU code hasn’t been a huge priority yet. There’s unfortunately a lot of code that has to run per-primitive, where hazards can happen around every corner that has to be dealt with somehow. I do some obvious optimizations, but it’s obviously not as well-oiled as PCSX2 in that regard.</p>
<p><a href="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png"><img loading="lazy" decoding="async" src="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png" alt="" width="660" height="394" srcset="https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1024x611.png 1024w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-300x179.png 300w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-768x458.png 768w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600-1536x917.png 1536w, https://themaister.net/blog/wp-content/uploads/2024/07/rgp-rx7600.png 1766w" sizes="(max-width: 660px) 100vw, 660px"></a></p>
<h3>Deck?</h3>
<p>It seems fast enough to comfortably do 4x SSAA. Maybe not in SotC, but … hey. 😀</p>
<h2>What now?</h2>
<p>For now, the only real way to test this is through GS dumps. <a href="https://github.com/Arntzen-Software/parallel-gs/blob/main/misc/0001-Add-an-ad-hoc-GS-stream-format.patch">There’s a hack-patch for PCSX2</a> that lets you dump out a raw GS trace, which can be replayed. This works via mkfifo as a crude hack to test in real-time, but some kind of integration into an emulator needs to happen at some point if this is to turn into something that’s useful for end users.</p>
<p>There’s guaranteed to be a million bugs lurking since the PS2 library is ridiculously large and there’s only so much I can be arsed to test myself. At least, paraLLEl-GS has now become my preferred way to play PS2 games, so I can say mission complete.</p>
<p>A potential use case for this is due to its standalone library nature, it may be useful as very old-school rendering API for the old greybeards around that still yearn for the day of PS2 programming for whatever reason :p</p>
	</div><!-- .entry-content -->

	
	<!-- .entry-footer -->

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Taming the beast that is the Django ORM – An introduction (136 pts)]]></title>
            <link>https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</link>
            <guid>41413641</guid>
            <pubDate>Sun, 01 Sep 2024 02:07:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/">https://www.davidhang.com/blog/2024-09-01-taming-the-django-orm/</a>, See on <a href="https://news.ycombinator.com/item?id=41413641">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><img src="https://www.davidhang.com/_astro/1.UiFfZ6wR_IHH0Y.webp" alt="man fighting dragon which represents the django orm" width="1024" height="1024" loading="lazy" decoding="async"></p>
<p>The material this blog post was originally developed from was a bunch of slides
used for a skill share presentation I gave at my workplace <span>@</span> <a href="https://coreplan.io/">coreplan.io</a>.</p>
<p>I have 3+ years of experience with Django, with it being the main framework that
underpins the backend of CorePlan’s main SaaS product. It is a mature, batteries
included framework that has been around for a while now. One particular powerful
yet dangerous feature of Django is the ORM. This is a Django specific ORM which
cannot be separated from the rest of the framework. The other major python ORM
is SQLAlchemy which can be used with other python web frameworks, but is an
independent tool.</p>
<p>Below are some of the things that I have learned about the Django ORM, how it
compares to raw SQL and gotchas that you should be aware of when using it.</p>
<hr>
<h2 id="what-is-an-orm-object-relational-mapper">What is an ORM (Object Relational Mapper)?</h2>
<ul>
<li>Abstraction over SQL to interact with databases</li>
</ul>
<p>Code -&gt; SQL</p>
<pre tabindex="0" data-language="python"><code><span><span>Hole.objects.all()</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<hr>
<h2 id="why-use-an-orm---pros">Why use an ORM? - Pros</h2>
<ul>
<li>Abstraction over SQL, no need to write raw SQL (plus and minus)</li>
<li>Portability - Can change out database engines easily !?
<ul>
<li>Probably not true, often will rely on db specific features e.g. postgres jsonb, triggers, etc</li>
</ul>
</li>
<li>Direct mapping from db to models</li>
<li>Automatic schema generation
<ul>
<li>Migrations are automatically generated</li>
</ul>
</li>
<li>Security
<ul>
<li>abstracts away enough that sql injection is less likely</li>
</ul>
</li>
</ul>
<hr>
<h2 id="why-use-an-orm---cons">Why use an ORM? - Cons</h2>
<ul>
<li>Abstraction over SQL…
<ul>
<li>Hides the underlying SQL</li>
<li>Can be difficult to debug</li>
<li>Lazy loading can cause N+1 queries without the developer realising</li>
<li>Harder to onboard new developers if they haven’t used Django before</li>
</ul>
</li>
<li>Performance
<ul>
<li>Generated sql be slower than crafted SQL</li>
</ul>
</li>
</ul>
<hr>
<h2 id="fundamentals">Fundamentals</h2>
<ul>
<li>Models = Tables</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span># drilling/models.py</span></span>
<span></span>
<span><span>from</span><span> django.db </span><span>import</span><span> models</span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>    name </span><span>=</span><span> models.TextField()</span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>CREATE</span><span> TABLE</span><span> drilling_hole</span><span> (</span></span>
<span><span>    id </span><span>SERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span><span>    name</span><span> VARCHAR</span><span>(</span><span>100</span><span>)</span></span>
<span><span>);</span></span>
<span></span></code></pre>
<hr>
<h2 id="migrations">Migrations</h2>
<pre tabindex="0" data-language="bash"><code><span><span>python</span><span> manage.py</span><span> makemigrations</span><span> # generate migration files</span></span>
<span><span>python</span><span> manage.py</span><span> migrate</span><span> # apply migrations</span></span>
<span></span>
<span><span>python</span><span> manage.py</span><span> drilling</span><span> --empty</span><span> # generate empty file for data migration</span></span>
<span></span></code></pre>
<p><a href="https://docs.djangoproject.com/en/dev/topics/migrations/">https://docs.djangoproject.com/en/dev/topics/migrations/</a></p>
<hr>

<h2 id="querying">Querying</h2>
<ul>
<li><code>ActiveRecord</code> pattern - ala Ruby on Rails style</li>
<li>QuerySets (<code>Hole.objects.all()</code>)
<ul>
<li>lazy</li>
<li>chainable</li>
<li>cached when iterated over multiple times <a href="https://docs.djangoproject.com/en/dev/topics/db/queries/#caching-and-querysets">!?</a>
<ul>
<li>I would not recommend relying on this because it hard to comprehend when it is cached and when it is not when you are reading code</li>
</ul>
</li>
</ul>
</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>) </span><span># not evaluated yet</span></span>
<span><span>holes_qs </span><span>=</span><span> holes_qs.filter(</span><span>depth__gt</span><span>=</span><span>100</span><span>) </span><span># still not evaluated</span></span>
<span></span>
<span><span>list</span><span>(holes_qs) </span><span># evaluated</span></span>
<span><span>list</span><span>(holes_qs) </span><span># cached</span></span>
<span></span>
<span><span>holes_qs[</span><span>2</span><span>] </span><span># not cached</span></span>
<span><span>holes_qs.first() </span><span># not cached</span></span>
<span><span>holes_qs.get(</span><span>id</span><span>=</span><span>1</span><span>) </span><span># not cached</span></span>
<span></span></code></pre>
<hr>
<h2 id="where">WHERE</h2>
<ul>
<li><code>WHERE</code> clause ≈ <code>filter()</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_hole</span><span>.</span><span>name</span><span> =</span><span> 'cheese'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-across-tables">WHERE across tables?</h2>
<ul>
<li>But how do you do a left/inner join? With the ORM it isn’t done declaratively, but implicitly</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.filter(</span><span>pad__name</span><span>=</span><span>"cheese board"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> *</span><span> </span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> drilling_pad </span><span>ON</span><span> drilling_hole</span><span>.</span><span>pad_id</span><span> =</span><span> drilling_pad</span><span>.</span><span>id</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="where-other-conditionals">WHERE other conditionals</h2>
<ul>
<li><code>filter(name="cheese")</code> -&gt; <code>filter(name__exact="cheese")</code> -&gt; <code>WHERE name = 'cheese'</code></li>
<li><code>filter(name__iexact="cheese")</code> -&gt; <code>WHERE name ILIKE 'cheese'</code></li>
<li><code>filter(name__contains="cheese")</code> -&gt; <code>WHERE name LIKE '%cheese%'</code></li>
<li><code>filter(name__icontains="cheese")</code> -&gt; <code>WHERE name ILIKE '%cheese%'</code></li>
<li><code>filter(name__in=["cheese", "board"])</code> -&gt; <code>WHERE name IN ('cheese', 'board')</code></li>
<li><code>filter(name__gt=100)</code> -&gt; <code>WHERE name &gt; 100</code> etc</li>
<li><code>filter(name__isnull=True)</code> -&gt; <code>WHERE name IS NULL</code>
<ul>
<li>At least for postgres shouldn’t <code>name = None</code>, <a href="https://www.postgresql.org/docs/current/functions-comparison.html">null != null</a></li>
</ul>
</li>
</ul>
<hr>
<h2 id="as">AS</h2>
<ul>
<li><code>annotate</code> ≈ <code>AS</code></li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>))</span></span>
<span><span>hole </span><span>=</span><span> holes_qs.first()</span></span>
<span><span>print</span><span>(hole.this_thang)</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  *</span><span> , </span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>INNER JOIN</span><span> "drilling_pad"</span><span> ON</span><span> (</span><span>"drilling_hole"</span><span>.</span><span>"pad_id"</span><span> =</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span></span>
<span></span></code></pre>
<hr>
<h2 id="subqueries">Subqueries</h2>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Project</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  project </span><span>=</span><span> models.ForeignKey(Project, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># find pads that are on project_id=1</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>project_id</span><span>=</span><span>1</span><span>).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.filter(</span><span>hole__in</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span><span> INNER JOIN</span><span> "drilling_hole"</span><span> ON</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span> =</span><span> "drilling_hole"</span><span>.</span><span>"pad_id"</span><span>)</span></span>
<span><span>WHERE</span><span> "drilling_hole"</span><span>.</span><span>"id"</span><span> IN</span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"project_id"</span><span> =</span><span> 1</span></span>
<span><span> )</span></span>
<span></span></code></pre>
<hr>

<p>Correlated subqueries are where the inner query depends on outer query</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span># include the hole id of any hole that has a foreign key to the pad</span></span>
<span><span>hole_subquery </span><span>=</span><span> Hole.objects.filter(</span><span>pad_id</span><span>=</span><span>OuterRef(</span><span>"pk"</span><span>)).values(</span><span>"pk"</span><span>)</span></span>
<span><span>pad_qs </span><span>=</span><span> Pad.objects.annotate(</span><span>hole_id</span><span>=</span><span>Subquery(hole_subquery))</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> "drilling_pad"</span><span>.</span><span>"id"</span><span>,</span></span>
<span><span> "drilling_pad"</span><span>.</span><span>"name"</span><span>,</span></span>
<span><span> (</span></span>
<span><span>  SELECT</span><span> U0.</span><span>"id"</span></span>
<span><span>  FROM</span><span> "drilling_hole"</span><span> U0</span></span>
<span><span>  WHERE</span><span> U0.</span><span>"pad_id"</span><span> =</span><span> (</span><span>"drilling_pad"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span> ) </span><span>AS</span><span> "hole_id"</span></span>
<span><span>FROM</span><span> "drilling_pad"</span></span>
<span></span></code></pre>
<hr>
<h2 id="performance-improvements">Performance improvements</h2>
<ul>
<li>Reduce N+1
<ul>
<li>You typically want to reduce N+1 queries because they have communication
overhead</li>
<li><code>select_related</code></li>
<li><code>prefetch_related</code></li>
<li>You also might choose to use <code>annotate()</code> instead of <code>select_related</code>
because select related pulls all the data for the associated table when you
might only need one column. That associated might have a jsonb column which
contains a lot of unnecessary data that you don’t need.</li>
</ul>
</li>
</ul>
<hr>

<pre tabindex="0" data-language="python"><code><span><span>holes </span><span>=</span><span> Hole.objects.all()</span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># N+1 queries</span></span>
<span></span>
<span><span>holes </span><span>=</span><span> Hole.objects.select_related(</span><span>"pad"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes:</span></span>
<span><span>  print</span><span>(hole.pad.name) </span><span># no extra query</span></span>
<span></span>
<span></span></code></pre>
<hr>

<p>You would use prefetch related when you are not pulling a direct foreign key
such a many-to-many relationship like below.</p>
<p><img src="https://www.davidhang.com/_astro/2.Cd5VA_n2_Z22TJnn.svg" alt="width:400px" width="340" height="465" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span></span>
<span><span>class</span><span> Faculty</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>class</span><span> Course</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  faculty </span><span>=</span><span> models.ForeignKey(Faculty, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Student</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  courses </span><span>=</span><span> models.ManyToManyField(Course, </span><span>through</span><span>=</span><span>"Enrolment"</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span><span>"courses"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># extra query</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "courses"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.select_related(</span><span>"faculty"</span><span>)</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.courses.all():</span></span>
<span><span>    print</span><span>(course.name) </span><span># no extra query</span></span>
<span><span>    print</span><span>(course.faculty.name) </span><span># no extra query</span></span>
<span></span></code></pre>
<hr>
<h2 id="to_attr">to_attr</h2>
<p><code>to_attr</code> can be used to make “filtered” relationships available on the instance.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Enrolment</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  course </span><span>=</span><span> models.ForeignKey(Course, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  student </span><span>=</span><span> models.ForeignKey(Student, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span><span>  grade </span><span>=</span><span> models.FloatField()</span></span>
<span></span>
<span><span>students </span><span>=</span><span> Student.objects.prefetch_related(</span></span>
<span><span>  Prefetch(</span></span>
<span><span>    "course"</span><span>, </span></span>
<span><span>    queryset</span><span>=</span><span>Course.objects.filter(</span><span>grade__gt</span><span>=</span><span>80.0</span><span>).select_related(</span><span>"faculty"</span><span>), </span><span>to_attr</span><span>=</span><span>"hd_courses"</span></span>
<span><span>  )</span></span>
<span><span>)</span></span>
<span></span>
<span><span>for</span><span> student </span><span>in</span><span> students:</span></span>
<span><span>  for</span><span> course </span><span>in</span><span> student.hd_courses.all():</span></span>
<span><span>    ...</span></span>
<span></span></code></pre>
<hr>
<h2 id="multiple-instances-when-filtering-across-many-to-many">Multiple instances when filtering across many-to-many</h2>
<p>One gotcha is selecting across a many-to-many relationship can return multiple of the same instances.</p>
<p><img src="https://www.davidhang.com/_astro/3.DMAdguVG_TLkyj.webp" alt="data model showing many to many relationship" width="530" height="810" loading="lazy" decoding="async"></p>
<pre tabindex="0" data-language="python"><code><span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>) </span><span># inner join returns duplicated rows</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>, </span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span><span>Student.objects.filter(</span><span>courses__faculty__name</span><span>=</span><span>"Science"</span><span>).distinct()</span></span>
<span><span>&lt;</span><span>QuerySet [</span><span>&lt;</span><span>Student: Student </span><span>object</span><span> (</span><span>1</span><span>)</span><span>&gt;</span><span>]</span><span>&gt;</span></span>
<span></span>
<span></span></code></pre>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span></span>
<span><span>  "testing_student"</span><span>.</span><span>"id"</span><span>, </span></span>
<span><span>  "testing_student"</span><span>.</span><span>"name"</span><span> </span></span>
<span><span>FROM</span><span> </span></span>
<span><span>  "testing_student"</span><span> </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_enrolment"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_student"</span><span>.</span><span>"id"</span><span> =</span><span> "testing_enrolment"</span><span>.</span><span>"student_id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_course"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_enrolment"</span><span>.</span><span>"course_id"</span><span> =</span><span> "testing_course"</span><span>.</span><span>"id"</span><span>) </span></span>
<span><span>INNER JOIN</span><span> </span></span>
<span><span>  "testing_faculty"</span><span> </span></span>
<span><span>ON</span><span> </span></span>
<span><span>  (</span><span>"testing_course"</span><span>.</span><span>"faculty_id"</span><span> =</span><span> "testing_faculty"</span><span>.</span><span>"id"</span><span>)</span></span>
<span><span>WHERE</span><span> </span></span>
<span><span>  "testing_faculty"</span><span>.</span><span>"name"</span><span> =</span><span> 'Science'</span></span>
<span></span></code></pre>
<hr>
<h2 id="gotchas-and-other-funky-stuff">Gotchas and other Funky stuff</h2>
<ul>
<li>Model instances when retrieved will try to populate all columns, if column
removed in migration, and the worker still up exception occurs
<ul>
<li><code>get()</code> or <code>first()</code></li>
<li><code>for hole in Hole.objects.all()</code></li>
</ul>
</li>
<li>This can make migrations hard, as older workers will be requesting columns that might have been removed or renamed which will cause errors</li>
<li>There are ways to do down-timeless migrations but are bit <a href="https://hackernoon.com/deleting-a-column-from-a-django-model-on-production">funky and multi
step</a></li>
<li>Recommendation is to avoid deleting or renaming columns</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>class</span><span> Pad</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.annotate(</span><span>this_thang</span><span>=</span><span>F(</span><span>"pad__name"</span><span>)).get()</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- pulls all columns </span></span>
<span><span>  drilling_hole</span><span>.</span><span>pad_id</span><span>,</span></span>
<span><span>  drilling_pad</span><span>.</span><span>name</span><span> AS</span><span> this_thang</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span><span>WHERE</span><span> drilling_pad</span><span>.</span><span>name</span><span> =</span><span> 'cheese board'</span><span>;</span></span>
<span><span>LIMIT</span><span> 1</span><span>;</span></span>
<span></span></code></pre>
<hr>
<h2 id="values">Values</h2>
<ul>
<li>So how do you to only retrieve certain columns?</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span><span>  pad </span><span>=</span><span> models.ForeignKey(Pad, </span><span>on_delete</span><span>=</span><span>models.</span><span>CASCADE</span><span>)</span></span>
<span></span>
<span><span>holes_qs </span><span>=</span><span> Hole.objects.values(</span><span>"name"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(</span><span>type</span><span>(hole)) </span><span># dict</span></span>
<span><span>  # not `Hole` object, hence no class functions, no lazy loading e.g. can't access `hole.pad.name`</span></span>
<span></span></code></pre>
<p>⬇️</p>
<pre tabindex="0" data-language="sql"><code><span><span>SELECT</span><span> </span></span>
<span><span>  drilling_hole</span><span>.</span><span>name</span><span>, </span><span>-- only pulls name and maps it to a python dictionary object</span></span>
<span><span>FROM</span><span> drilling_hole;</span></span>
<span></span></code></pre>
<ul>
<li>Less data sent down the wire, but no lazy loading and no class functions as
the data is a python dictionary</li>
</ul>
<hr>
<h2 id="other-options">Other options</h2>
<ul>
<li><code>only()</code> and <code>defer()</code></li>
<li>Will retrieve model instances, but won’t retrieve all fields</li>
<li>Values not declared when accessed on the model are lazy loaded</li>
<li>Would not recommend to be used regularly, very high chance of N+1</li>
</ul>
<pre tabindex="0" data-language="python"><code><span><span>holes_qs </span><span>=</span><span> Hole.objects.only(</span><span>"pad_id"</span><span>)</span></span>
<span></span>
<span><span>for</span><span> hole </span><span>in</span><span> holes_qs:</span></span>
<span><span>  print</span><span>(hole.pad_id) </span><span># no extra query</span></span>
<span><span>  print</span><span>(hole.name) </span><span># name will be lazy loaded, N+1 queries</span></span>
<span></span></code></pre>
<hr>
<h3 id="how-do-you-know-what-sql-is-being-generated">How do you know what SQL is being generated?</h3>
<ul>
<li><code>print(queryset.query)</code></li>
<li><a href="https://github.com/jazzband/django-debug-toolbar">Django Debug Toolbar</a></li>
<li><a href="https://kolo.app/">Kolo</a></li>
</ul>
<hr>
<h2 id="updating-rows">Updating rows</h2>
<p>There are three typical ways to update a row in the database.</p>
<pre tabindex="0" data-language="python"><code><span><span>class</span><span> Hole</span><span>(</span><span>models</span><span>.</span><span>Model</span><span>):</span></span>
<span><span>  name </span><span>=</span><span> models.TextField()</span></span>
<span></span>
<span><span>instance </span><span>=</span><span> Hole.objects.create(</span><span>name</span><span>=</span><span>"cheese"</span><span>)</span></span>
<span></span>
<span><span># save()</span></span>
<span><span>instance.name </span><span>=</span><span> "board"</span></span>
<span><span>instance.save()</span></span>
<span></span>
<span><span># update()</span></span>
<span><span>Model.objects.filter(</span><span>name</span><span>=</span><span>"board"</span><span>).update(</span><span>name</span><span>=</span><span>"board2"</span><span>)</span></span>
<span></span>
<span><span># bulk_update()</span></span>
<span><span>instance.name </span><span>=</span><span> "board3"</span></span>
<span><span>instances_to_update </span><span>=</span><span> [instance]</span></span>
<span><span>Model.objects.bulk_update(instances_to_update, [</span><span>"name"</span><span>])</span></span>
<span></span></code></pre>
<hr>
<h2 id="problems-with-updates">Problems with updates</h2>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger <code>save()</code> method on the model</li>
<li>built in django signals (publish/subscribe pattern), there are post_save and pre_save signals which can be triggered when calling <code>save()</code>
<ul>
<li><code>update()</code> and <code>bulk_update()</code> do not trigger those signals…</li>
</ul>
</li>
<li><code>updated_at</code> column would not normally be updated when calling <code>update()</code> or
<code>bulk_update()</code> but if queryset is a descendant of <code>CoreplanQuerySet</code> then it will.</li>
</ul>
<hr>

<ul>
<li>Pagination / order_by
<ul>
<li>Not a Django ORM thing, but a Django ORM hides the implementation detail,
which may lead to unexpected result</li>
<li>Page pagination is default in DRF list views and implemented with <code>LIMIT</code> and <code>OFFSET</code> in SQL</li>
</ul>
</li>
</ul>
<p><code>?page_size=10&amp;page=3</code></p>
<pre tabindex="0" data-language="plaintext"><code><span><span>SELECT * </span></span>
<span><span>FROM drilling_hole </span></span>
<span><span>LIMIT 10 </span></span>
<span><span>OFFSET 20;</span></span>
<span><span></span></span></code></pre>
<p>Anything wrong with this query?</p>
<ul>
<li>There is no deterministic guarantee that the same 10 rows will be returned each time.</li>
<li>A plain <code>SELECT</code> in postgres (may be different in different dbs) provides no
guarantee of order, unless <code>ORDER BY</code> is specified</li>
<li>It often appears to return in insertion/<code>id</code> order, but that is not guaranteed
in postgres</li>
<li>Model Meta <code>ordering</code> may set a default order, but sometimes tht is <a href="https://docs.djangoproject.com/en/dev/releases/2.2/#features-deprecated-in-2-2">ignored</a></li>
<li>For list views you should to provide a deterministic order_by</li>
<li><code>order_by(name)</code> is not enough if name is not unique
<ul>
<li><code>order_by(name, id)</code> is required, because id is unique</li>
</ul>
</li>
<li>This can been the the cause of some flaky tests issues where lists are
returned seemingly in insertion order and asserted to return in id order</li>
</ul>
<hr>
<p>Thanks for reading! I hope this has been useful to you. There are definitely
more particularities and gotchas to be aware of when using the Django ORM and
Django in general but I think these are the most common ones.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AirTags key to discovery of Houston's plastic recycling deception (143 pts)]]></title>
            <link>https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</link>
            <guid>41413174</guid>
            <pubDate>Sun, 01 Sep 2024 00:38:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception">https://appleinsider.com/articles/24/08/31/airtags-key-to-discovery-of-houstons-plastic-recycling-deception</a>, See on <a href="https://news.ycombinator.com/item?id=41413174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-hero" aria-labelledby="hero-cap" role="figure">
                          <p id="hero-cap" title="Apple employs an advanced robot named Daisy to disassemble old iPhones.">Apple employs an advanced robot named Daisy to disassemble old iPhones.</p>
                                    <p><a href="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg">
              <img fetchpriority="high" src="https://photos5.appleinsider.com/gallery/60877-125351-Unknown-xl.jpg" alt="">
            </a>
                      </p></div><div>
          <p>One Houston resident was suspicious of the city's "all plastic accepted" recycling program, and used <a href="https://appleinsider.com/inside/airtags" title="AirTag" data-kpt="1">AirTags</a> to discover where the plastic waste actually ended up.
</p><p>Deason, who regularly recycles her packaging and other waste, began to have doubts about the city's plastic recycling program. Houston's program boasted of being able to accept even types of plastic that aren't normally considered recyclable.
</p><p>Curious as to where the plastic was going, she bought a set of AirTags, and included them in various bags of her plastic recycling. Of the bags she tracked, nearly all of them went to a company called Wright Waste Management, located in nearby Harris County.
</p><p>The company is not approved to store plastic waste, and has failed three fire inspections.
</p><p>CBS News correspondent Ben Tracy <a href="https://www.khou.com/article/news/local/houston-recycling-tracking-device-plastic/">referred</a> to Deason as "the James Bond of plastic recycling" for her initiative. Aerial footage showed that the facility had large piles of plastic waste as tall as 10 feet high.
</p><p>Deason said she thought that the company simply storing the unrecyclable plastic waste was "kind of strange." She later contacted Houston's Director of Solid Waste Management Mark Wilfalk, to ask about the discrepancy.
</p><p>When shown the drone footage, Wilfalk admitted "it's not the most desirable-looking site." He promised Deason he'd investigate the problems that caused Wright Waste Management to fail the fire inspections.
</p><p>Wilfalk later acknowledged that the city had collected some 250 tons of plastic since the end of 2022. He revealed that none of it had been recycled as of yet.
</p><p>"We're gonna stockpile it for now," he admitted. "We're gonna see what happens."
</p><p>By contrast, Apple has been an <a href="https://appleinsider.com/articles/24/04/16/apple-highlights-device-recycling-iphone-trade-in-and-the-removal-of-leather-for-earth-day" title="Apple's environmental efforts">industry leader</a> in reducing its use of plastic. It uses paper for packaging, and metal rather than plastic for its computer line.
</p><p>It does use some plastic for products such as its <a href="https://appleinsider.com/inside/airpods" title="AirPods" data-kpt="1">AirPods</a> earbuds. It has invested in robotics to help recycle old Apple products.
</p><p>Houston, as it turns out, is waiting on a promised sorting facility to open, where the stored recycling will be sorted and treated. The company behind the sorting facility, Cyclix, says it has developed a method to create recyclable pellets out of the plastic waste.
</p><p>However, only a fraction of these pellets can be made into new plastic. Most will be melted and turned into fuel that is burned, adding to carbon emissions.
</p><p>California Attorney General Rob Bonta has been investigating Cyclix owner and plastic manufacturer ExxonMobil's claims regarding plastic recycling in that state. He has characterized Cyclix's claims of plastic recycling are largely fictional.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building LLMs from the Ground Up: A 3-Hour Coding Workshop (781 pts)]]></title>
            <link>https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up</link>
            <guid>41412256</guid>
            <pubDate>Sat, 31 Aug 2024 21:45:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up">https://magazine.sebastianraschka.com/p/building-llms-from-the-ground-up</a>, See on <a href="https://news.ycombinator.com/item?id=41412256">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>If you’d like to spend a few hours this weekend to dive into Large Language Models (LLMs) and understand how they work, I've prepared a 3-hour coding workshop presentation on implementing, training, and using LLMs.</p><div id="youtube2-quh7z1q7-uc" data-attrs="{&quot;videoId&quot;:&quot;quh7z1q7-uc&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/quh7z1q7-uc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>Below, you'll find a table of contents to get an idea of what this video covers (the video itself has clickable chapter marks, allowing you to jump directly to topics of interest):</p><p>0:00 – Workshop overview</p><p>2:17 – Part 1: Intro to LLMs</p><p>9:14 – Workshop materials</p><p>10:48 – Part 2: Understanding LLM input data</p><p>23:25 – A simple tokenizer class</p><p>41:03 – Part 3: Coding an LLM architecture</p><p>45:01 – GPT-2 and Llama 2</p><p>1:07:11 – Part 4: Pretraining</p><p>1:29:37 – Part 5.1: Loading pretrained weights</p><p>1:45:12 – Part 5.2: Pretrained weights via LitGPT</p><p>1:53:09 – Part 6.1: Instruction finetuning</p><p>2:08:21 – Part 6.2: Instruction finetuning via LitGPT</p><p>02:26:45 – Part 6.3: Benchmark evaluation</p><p>02:36:55 – Part 6.4: Evaluating conversational performance</p><p>02:42:40 – Conclusion</p><p>It's a slight departure from my usual text-based content, but the last time I did this a few months ago, it was so well-received that I thought it might be nice to do another one!</p><p><strong>Happy viewing!</strong></p><ol><li><p><a href="https://mng.bz/M96o" rel="">Build an LLM from Scratch book</a></p></li><li><p><a href="https://github.com/rasbt/LLMs-from-scratch" rel="">Build an LLM from Scratch GitHub repository</a></p></li><li><p><a href="https://github.com/rasbt/LLM-workshop-2024" rel="">GitHub repository with workshop code</a></p></li><li><p><a href="https://lightning.ai/lightning-ai/studios/llms-from-the-ground-up-workshop" rel="">Lightning Studio for this workshop</a></p></li><li><p><a href="https://github.com/Lightning-AI/litgpt" rel="">LitGPT GitHub repository</a></p></li></ol></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A brief history of barbed wire fence telephone networks (104 pts)]]></title>
            <link>https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/</link>
            <guid>41412221</guid>
            <pubDate>Sat, 31 Aug 2024 21:41:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/">https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/</a>, See on <a href="https://news.ycombinator.com/item?id=41412221">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page">
							<main id="main" role="main">

					
						
<article id="post-4658">
	<!-- .entry-header -->

	<div>
		
<p>If you look at <a href="https://loriemerson.net/2024/03/14/table-of-contents-for-other-networks-a-radical-technology-sourcebook/">the table of contents</a> for my book, <em>Other Networks: A Radical Technology Sourcebook</em>, you’ll see that entries on networks before/outside the internet are arranged first by underlying infrastructure and then chronologically. You’ll also notice that within the section on wired networks, there are two sub-sections: one for electrical wire and another for barbed wire. Even though the barbed wire section is quite short, it was one of the most fascinating to research and write about – mostly because the history of using barbed wire to communicate is surprisingly long and almost entirely undocumented, even though barbed wire fence phones in particular were an essential part of early- to mid-twentieth century rural life in many parts of the U.S. and Canada! </p>



<p>While I was researching barbed wire fence phones and wondering whether any artists had been intrepid enough to experiment with this other network, I came across <a href="https://philipbpeters.com/">Phil Peters</a> and <a href="https://davidrueter.com/">David Rueter</a>‘s work “Barbed Wire Fence Telephone” which they installed in a Chicago gallery in 2015. libi striegl (Managing Director of the <a href="http://mediaarchaeologylab.com/">Media Archaeology Lab</a> through which we run many of our <a href="http://othernetworks.net/">Other Networks</a> projects) and I decided we should see if we can get Peters and Rueter to re-install their barbed wire fence telephone on the CU Boulder campus…to our delight and surprise, they said yes. But even more delightful and surprising was the fact that the college I’m now based in, the College of Media, Communication, and Information (CMCI), was enthusiastically supportive of our ask to install this fence phone network in a university classroom! In fact, not only was CMCI supportive in principle, they helped fund the project and staff members even helped us drill holes, put up fence posts, and string barbed wire. Phil and libi (with modest assistance from me) wrapped up the installation of “<a href="https://othernetworks.net/2024/08/02/barbed-wire-fence-telephone-ii/">Barbed Wire Fence Telephone II</a>” on Thursday August 29th and on Friday August 30th Phil gave a group of about 20 people a hands-on demo of this ad hoc network.</p>



<p>Since so little documentation exists online about the history of this important communication network, below I include the introduction I wrote for the section on barbed wire along with the entry on barbed wire fence phones. I admit I hope someone adds this information to Wikipedia and cites either this post or <em>Other Networks: A Radical Technology Sourcebook</em> (forthcoming in 2025 by Anthology Editions). </p>



<p>***</p>



<p><strong>Barbed Wire Networks</strong></p>



<p>Barbed wire was originally proposed as an inexpensive and potentially painful material that could be used to create a fence and thus act as a deterrent to keep livestock within a confined area and/or to keep out intruders. Alan Krell documents numerous designs for wire that featured barbs throughout the 19th century, including one proposed by French inventor Léonce Eugène Grassin-Baledans in 1860 for a “Grating of wire-work for fences and other purposes.” The first patent in the U.S. for a wire fence featuring barbs was given to Lucien B. Smith from Kent, Ohio (U.S.) in 1867. Illinois farmer Joseph Glidden submitted a patent for an improved version of barbed wire in 1874 which has since become the dominant design. As Reviel Netz puts it, after this point the physical control of wide open spaces was largely complete. Many farmers objected to the cruelty built into barbed wire, the way in which the fencing meant cattle drives were no longer possible, and the way it marked the end of seemingly free and open public land; notably they formed anti-barbed-wire associations and pleaded with legislators and government officials to enact laws limiting or regulating the use of the wire. Nonetheless, as the price of wire fell from twenty cents per pound in 1874 to two cents a pound by 1893, few ranchers could afford any other type of fencing material. By the 1890s, the barbed wire industry had become wealthy enough and powerful enough that they effectively quelled all opposition to the wire. The availability of inexpensive barbed wire, especially across the western U.S. in the late 19th century, largely made it possible to keep larger herds of livestock than had been possible up to that point. It also played a significant role in “settling” the American west by violently asserting individual ownership over land that was already occupied by Native Americans.</p>



<p>Appropriately nicknamed ‘the devil’s rope,’ barbed wire is made from steel (later coated in zinc, a zinc-aluminum alloy, or a kind of polymer coating such as polyvinyl chloride) and single or double barbs placed roughly four to six inches apart. To erect a fence, one only needs barbed wire, posts, and materials to afix the wire to the posts. Finally, although this section focuses on its use as a cooperative, non-commercial form of telecommunications network, it is also worth noting the frequent use barbed wire for trench warfare or as a security measure atop walls or buildings.</p>



<p>Sources: Alan Krell, <em>The Devil’s Rope: A Cultural History of Barbed Wire</em> (Reaktion Books, 2002); Léonce Eugène Grassin-Baledans, “Grating of wire-work for fences and other purposes,” France Patent 45827; Lucien B. Smith, “Wire Fence,” US Patent 66182A (25 June 1867); Joseph Glidden, “Improvement in Wire Fences,” US Patent 157124A (27 OCtober 1873); Reviel Netz, <em>Barbed Wire: An Ecology of Modernity</em> (Wesleyan University Press, 2009)</p>



<p><strong>53. Fence Phones</strong></p>



<p>Country of Origin: U.S.A.</p>



<p>Creator(s): unknown</p>



<p>Earliest Known Use: roughly 1893</p>



<p>Basic Materials: copper wire, barbed wire, posts, fasteners (such as nails or staples), insulators (such as porcelain knobs, glass bottles, leather, corn cobs, cow horns), battery-powered telephone handsets</p>



<p>Description: A fence phone, also referred to as a barbed wire fence phone or squirrel lines, is the use of “smooth” (presumably copper) wire running from a house to nearby barbed wire fencing to create an informal, ad hoc, cooperative, non-commercial, local telephone network. Two key developments in the 1890s led to its adoption primarily by farmers, ranchers, and those living in rural or isolated areas especially in the U.S. and Canada: the widespread availability and inexpensiveness of barbed wire in the 1890s; and the erosion of Alexander Graham Bell’s patent monopoly in 1893 and 1894 which, according to Robert MacDougall, led to the sudden explosion of 80 to 90 independent telephone companies manufacturing telephone sets that could be used outside of the burgeoning Bell telephone system. According to Ronald Kline, the sudden explosion of independent telphone companies in turn set into motion the independent telephone movement. Not only had Bell largely neglected to provide those in rural areas with telephone service in favor of focusing on those in urban areas, but early Bell telephone owners were also intent on controlling telephone usage. Writes MacDougall, “Bell’s early managers sought to limit frivolous telephoning, especially undignified activities like courting or gossiping over the telephone, and to control certain groups of users, like women, children, and servants, who were thought to be particular offenders.” By contrast, according to Kline, the independent telephone companies recognized it would be too expensive to build lines in rural areas and they instead openly “advised farm people to buy their own telephone equipment, build their own lines, and create cooperatives to bring phones to the countryside.”</p>



<p>In need of a practical way to overcome social isolation; communicate emergencies, weather, and crop prices; and chafing under attempts to curtail free speech, ranchers and farmers began to take advantage of the growing ubiquity of both telephone sets and barbed wire fencing. They would hook up telephones to wire strung from their homes to a nearby fence; at the time, telephones had their own battery which produced a DC current that could carry a voice signal; turning a crank on the phone would generate an AC current to produce a ring at the end of the line. Bob Holmes elaborates on the process: “the barbed wire networks had no central exchange, no operators–and no monthly bill. Instead of ringing through the exchange to a single address, every call made every phone on the system ring. Soon each household had its own personal ringtone…but anyone could pick up…Talk was free, and so people soon began to ‘hang out’ on the phone.” The fence phone lines could also be used to broadcast urgent information to everyone on the line. Reportedly, the quality of the signal traveling over the heavy wire was excellent, but weather would frequently cause short circuits which locals attempted to fix with anything that could serve as an insulator (such as leather straps, corn cobs, cow horns, or glass bottles).</p>


<div>
<figure><img data-attachment-id="4669" data-permalink="https://loriemerson.net/2024/08/31/a-brief-history-of-barbed-wire-fence-telephone-networks/fencephones3/" data-orig-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png" data-orig-size="1124,1487" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fencePhones3" data-image-description="" data-image-caption="" data-medium-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=227" data-large-file="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=750" tabindex="0" role="button" width="774" height="1023" src="https://loriemerson.net/wp-content/uploads/2024/08/fencephones3.png?w=774" alt="black and white photograph of a pan in a suit and bowler hat standing in front of a barbed wire fence talking on the phone"><figcaption>from “A CHEAP TELEPHONE SYSTEM FOR FARMERS”, <em>Scientific American</em> 82:13 (MARCH 31, 1900), p. 196</figcaption></figure></div>


<p>There are newspaper reports of ranchers and farmers using fence phones in U.S. states such as California, Texas, New Mexico, Colorado, Kansas, Iowa, Nebraska, Indiana, Minnesota, Ohio, Pennsylvania, New York, Montana, South Dakota and also parts of Canada. For example, a 1902 issue of the Chicago-based magazine Telephony reported on a barbed wire fence telephone network that operated between Broomfield and Golden, Colorado (U.S.A.) over a distance of 25 miles and which cost roughly $10 to build. The line was used for a “woman operator” to notify a worker at the end of the line “when to send down a head of water and how much.” The author notes one “peculiar feature of this system is that only the operator can begin the talk. When it is decided to send down water the operator calls up the man at the headgate and gives him specific instructions, which he must follow. If he has anything to say he must say it then or hold his peace till he is called up again, for it is not a circuit system and only the Broomfield office can call up. This gives the lady the advantage of being able to shut off the other fellow at will and of getting in the last word.” The fence phone systems also seemed to thrive in areas known for having cooperatives, especially related to farming. The model of a cooperative network particularly thrived throughout the 1920s as farmers experienced economic depression some years before the Great Depression. For example, according to David Sicilia, farmers in Montana created the Montana East Line Telephone Association to which they each contributed $25 plus several dollars a year for maintenance along with telephone sets, batteries, wire, and insulators.</p>



<p>Anecdotally, fence phones were still being used throughout the 1970s and perhaps even later. C.F. Eckhardt describes calling his parents who lived in rural Texas and still used a fence phone; their number was simply 37, designated on the small local network by three long rings and one short ring.</p>



<p>Sources: Alan Krell, <em>The Devil’s Rope: A Cultural History of Barbed Wire</em> (Reaktion Books, 2002); David B. Sicilia, “How the West Was Wired,” Inc.com (15 June 1997); Early W. Hayter, <em>Free Range and Fencing</em>, Vol. 3 (Kansas State Teachers College of Emporia Department of English, 1960); Robert MacDougall, <em>The People’s Network: The Political Economy of the Telephone in the Gilded Age</em> (University of Pennsylvania Press, 2014); Ronald Kline, <em>Consumers in the Country: Technology and Social Change in Rural America</em> (Johns Hopkins University Press, 2002); “A CHEAP TELEPHONE SYSTEM FOR FARMERS,” <em>Scientific American</em>, 82:13 (31 March 1900); “Bloomfield’s Barbed Wire System,” <em>Telephony: An Illustrated Monthly Telephone Journal</em> 4:6 (December 1902); Bob Holmes, “Wired Wild West: Cowpokes chatted on fence-wire phones,” <em>New Scientist</em> (17 December 2013); C. F. Eckhardt, “Before Maw Bell: Rural Telephone Systems in the West,” Texasescapes.com (2008); Phil Peters, “Barbed Wire Fence Telephone,” <a href="https://philipbpeters.com/" rel="nofollow">https://philipbpeters.com/</a> (2014)</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-## -->
							<!-- .navigation -->
	
						
					
				</main><!-- #main -->
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Threat to OpenAI (137 pts)]]></title>
            <link>https://www.wsj.com/tech/ai/ai-chatgpt-nvidia-apple-facebook-383943d1</link>
            <guid>41411478</guid>
            <pubDate>Sat, 31 Aug 2024 19:56:03 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/ai/ai-chatgpt-nvidia-apple-facebook-383943d1">https://www.wsj.com/tech/ai/ai-chatgpt-nvidia-apple-facebook-383943d1</a>, See on <a href="https://news.ycombinator.com/item?id=41411478">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/ai/ai-chatgpt-nvidia-apple-facebook-383943d1: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[WatchYourLAN: Lightweight Network IP Scanner (172 pts)]]></title>
            <link>https://github.com/aceberg/WatchYourLAN</link>
            <guid>41411281</guid>
            <pubDate>Sat, 31 Aug 2024 19:32:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/aceberg/WatchYourLAN">https://github.com/aceberg/WatchYourLAN</a>, See on <a href="https://news.ycombinator.com/item?id=41411281">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://github.com/aceberg/WatchYourLAN">
    <img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/logo.png" width="20">
</a>WatchYourLAN</h2><a id="user-content-----watchyourlan" aria-label="Permalink: WatchYourLAN" href="#----watchyourlan"></a></div>

<p dir="auto"><a href="https://github.com/aceberg/WatchYourLAN/actions/workflows/main-docker-all.yml"><img src="https://github.com/aceberg/WatchYourLAN/actions/workflows/main-docker-all.yml/badge.svg" alt="Docker"></a>
<a href="https://goreportcard.com/report/github.com/aceberg/WatchYourLAN" rel="nofollow"><img src="https://camo.githubusercontent.com/2e8d4fc73c5dc60c4a5ae0025b9cd0db42ef07d6f26d1479d55adbeb75cf03e6/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f616365626572672f5761746368596f75724c414e" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/aceberg/WatchYourLAN"></a>
<a href="https://codeclimate.com/github/aceberg/WatchYourLAN/maintainability" rel="nofollow"><img src="https://camo.githubusercontent.com/60e9a9f739cc625dc0fa6aaa25a86c5097b94570dfe90d61dc52b5741a5b1e0f/68747470733a2f2f6170692e636f6465636c696d6174652e636f6d2f76312f6261646765732f34366231376639396564633137323662356437642f6d61696e7461696e6162696c697479" alt="Maintainability" data-canonical-src="https://api.codeclimate.com/v1/badges/46b17f99edc1726b5d7d/maintainability"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/23e7bee7caecf858d56d4665f00bb906da1f2ba916a7912d1ac050c7ae11e518/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f616365626572672f7761746368796f75726c616e"><img src="https://camo.githubusercontent.com/23e7bee7caecf858d56d4665f00bb906da1f2ba916a7912d1ac050c7ae11e518/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f696d6167652d73697a652f616365626572672f7761746368796f75726c616e" alt="Docker Image Size (latest semver)" data-canonical-src="https://img.shields.io/docker/image-size/aceberg/watchyourlan"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/648dc770497678d13bdd6f00d103b648703af328fcfa7fd3cf5ca2ed6afac821/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f616365626572672f7761746368796f75726c616e"><img src="https://camo.githubusercontent.com/648dc770497678d13bdd6f00d103b648703af328fcfa7fd3cf5ca2ed6afac821/68747470733a2f2f696d672e736869656c64732e696f2f646f636b65722f70756c6c732f616365626572672f7761746368796f75726c616e" alt="Docker Pulls" data-canonical-src="https://img.shields.io/docker/pulls/aceberg/watchyourlan"></a></p>
<p dir="auto">Lightweight network IP scanner with web GUI. Features:</p>
<ul dir="auto">
<li>Send notification when new host is found</li>
<li>Monitor hosts online/offline history</li>
<li>Keep a list of all hosts in the network</li>
<li>Send data to <code>InfluxDB2</code> to make a <code>Grafana</code> dashboard</li>
</ul>
<div dir="auto"><p dir="auto">Warning</p><p dir="auto">This is version 2.0. Version 1.0 can be found in this brunch: <a href="https://github.com/aceberg/WatchYourLAN/tree/v1">v1</a></p>
</div>
<div dir="auto"><p dir="auto">Caution</p><p dir="auto"><strong>BREAKING CHANGES!</strong> Version 2.0 is not compatible with v1.0. For now v2.0 docker images will be released under <code>v2</code> tag. It will be tagged <code>latest</code> in a few weeks (probably, in October).</p>
</div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_1.png"><img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_1.png" alt="Screenshot_1"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">More screenshots</h2><a id="user-content-more-screenshots" aria-label="Permalink: More screenshots" href="#more-screenshots"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_5.png"><img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_5.png" alt="Screenshot_5"></a><br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_2.png"><img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_2.png" alt="Screenshot_2"></a><br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_3.png"><img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_3.png" alt="Screenshot_3"></a><br>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_4.png"><img src="https://raw.githubusercontent.com/aceberg/WatchYourLAN/main/assets/Screenshot_4.png" alt="Screenshot_4"></a></p>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto">Replace <code>$YOURTIMEZONE</code> with correct time zone and <code>$YOURIFACE</code> with network interface you want to scan. Network mode must be <code>host</code>. Set <code>$DOCKERDATAPATH</code> for container to save data:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --name wyl \
	-e &quot;IFACES=$YOURIFACE&quot; \
	-e &quot;TZ=$YOURTIMEZONE&quot; \
	--network=&quot;host&quot; \
	-v $DOCKERDATAPATH/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2"><pre>docker run --name wyl \
	-e <span><span>"</span>IFACES=<span>$YOURIFACE</span><span>"</span></span> \
	-e <span><span>"</span>TZ=<span>$YOURTIMEZONE</span><span>"</span></span> \
	--network=<span><span>"</span>host<span>"</span></span> \
	-v <span>$DOCKERDATAPATH</span>/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2</pre></div>
<p dir="auto">Web GUI should be at <a href="http://localhost:8840/" rel="nofollow">http://localhost:8840</a></p>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Config</h2><a id="user-content-config" aria-label="Permalink: Config" href="#config"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto">Configuration can be done through config file, GUI or environment variables</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Basic config</h3><a id="user-content-basic-config" aria-label="Permalink: Basic config" href="#basic-config"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>TZ</td>
<td>Set your timezone for correct time</td>
<td></td>
</tr>
<tr>
<td>HOST</td>
<td>Listen address</td>
<td>0.0.0.0</td>
</tr>
<tr>
<td>PORT</td>
<td>Port for web GUI</td>
<td>8840</td>
</tr>
<tr>
<td>THEME</td>
<td>Any theme name from <a href="https://bootswatch.com/" rel="nofollow">https://bootswatch.com</a> in lowcase or <a href="https://github.com/aceberg/aceberg-bootswatch-fork">additional</a></td>
<td>sand</td>
</tr>
<tr>
<td>COLOR</td>
<td>Background color: light or dark</td>
<td>dark</td>
</tr>
<tr>
<td>NODEPATH</td>
<td>Path to local node modules</td>
<td></td>
</tr>
<tr>
<td>SHOUTRRR_URL</td>
<td>Link to any notification service supported by <a href="https://github.com/containrrr/shoutrrr">Shoutrrr</a> (gotify, email, telegram and others) or <a href="https://github.com/containrrr/shoutrrr/blob/main/docs/services/generic.md">Generic Webhook</a></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Scan settings</h3><a id="user-content-scan-settings" aria-label="Permalink: Scan settings" href="#scan-settings"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>IFACES</td>
<td>Interfaces to scan. Could be one or more, separated by space. Currently <code>docker0</code> is not supported, as <code>arp-scan</code> wouldn't work with it correctly</td>
<td></td>
</tr>
<tr>
<td>TIMEOUT</td>
<td>Time between scans (seconds)</td>
<td>120</td>
</tr>
<tr>
<td>ARP_ARGS</td>
<td>Arguments for <code>arp-scan</code>. See <code>man arp-scan</code> for more. Enable <code>debug</code> log level to see resulting command. (Example: <code>-r 1</code>)</td>
<td></td>
</tr>
<tr>
<td>LOG_LEVEL</td>
<td>Log level: <code>debug</code>, <code>info</code>, <code>warn</code> or <code>error</code></td>
<td>info</td>
</tr>
<tr>
<td>TRIM_HIST</td>
<td>Remove history after (hours)</td>
<td>48</td>
</tr>
<tr>
<td>HIST_IN_DB</td>
<td>Store History in DB - if <code>false</code>, the History will be stored only in memory and will be lost on app restart. Though, it will keep the app DB smaller (and InfluxDB is recommended for long term History storage)</td>
<td>false</td>
</tr>
<tr>
<td>USE_DB</td>
<td>Either <code>sqlite</code> or <code>postgres</code></td>
<td>sqlite</td>
</tr>
<tr>
<td>PG_CONNECT</td>
<td>Address to connect to PostgreSQL. (Example: <code>postgres://username:password@192.168.0.1:5432/dbname?sslmode=disable</code>). Full list of URL parameters <a href="https://pkg.go.dev/github.com/lib/pq#hdr-Connection_String_Parameters" rel="nofollow">here</a></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">InfluxDB2 config</h3><a id="user-content-influxdb2-config" aria-label="Permalink: InfluxDB2 config" href="#influxdb2-config"></a></p>
<p dir="auto">This config matches Grafana's config for InfluxDB data source</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
<th>Default</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>INFLUX_ENABLE</td>
<td>Enable export to InfluxDB2</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>INFLUX_SKIP_TLS</td>
<td>Skip TLS Verify</td>
<td>false</td>
<td>true</td>
</tr>
<tr>
<td>INFLUX_ADDR</td>
<td>Address:port of InfluxDB2 server</td>
<td></td>
<td><a href="https://192.168.2.3:8086/" rel="nofollow">https://192.168.2.3:8086/</a></td>
</tr>
<tr>
<td>INFLUX_BUCKET</td>
<td>InfluxDB2 bucket</td>
<td></td>
<td>test</td>
</tr>
<tr>
<td>INFLUX_ORG</td>
<td>InfluxDB2 org</td>
<td></td>
<td>home</td>
</tr>
<tr>
<td>INFLUX_TOKEN</td>
<td>Secret token, generated by InfluxDB2</td>
<td></td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Config file</h2><a id="user-content-config-file" aria-label="Permalink: Config file" href="#config-file"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto">Config file name is <code>config_v2.yaml</code>. Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="arp_args: &quot;&quot;
color: dark
hist_in_db: false
host: 0.0.0.0
ifaces: enp4s0
influx_addr: &quot;&quot;
influx_bucket: &quot;&quot;
influx_enable: false
influx_org: &quot;&quot;
influx_skip_tls: false
influx_token: &quot;&quot;
log_level: info
nodepath: &quot;&quot;
pg_connect: &quot;&quot;
port: &quot;8840&quot;
shoutrrr_url: &quot;gotify://192.168.0.1:8083/AwQqpAae.rrl5Ob/?title=Unknown host detected&amp;DisableTLS=yes&quot;
theme: sand
timeout: 60
trim_hist: 48
use_db: sqlite"><pre><span>arp_args</span>: <span><span>"</span><span>"</span></span>
<span>color</span>: <span>dark</span>
<span>hist_in_db</span>: <span>false</span>
<span>host</span>: <span>0.0.0.0</span>
<span>ifaces</span>: <span>enp4s0</span>
<span>influx_addr</span>: <span><span>"</span><span>"</span></span>
<span>influx_bucket</span>: <span><span>"</span><span>"</span></span>
<span>influx_enable</span>: <span>false</span>
<span>influx_org</span>: <span><span>"</span><span>"</span></span>
<span>influx_skip_tls</span>: <span>false</span>
<span>influx_token</span>: <span><span>"</span><span>"</span></span>
<span>log_level</span>: <span>info</span>
<span>nodepath</span>: <span><span>"</span><span>"</span></span>
<span>pg_connect</span>: <span><span>"</span><span>"</span></span>
<span>port</span>: <span><span>"</span>8840<span>"</span></span>
<span>shoutrrr_url</span>: <span><span>"</span>gotify://192.168.0.1:8083/AwQqpAae.rrl5Ob/?title=Unknown host detected&amp;DisableTLS=yes<span>"</span></span>
<span>theme</span>: <span>sand</span>
<span>timeout</span>: <span>60</span>
<span>trim_hist</span>: <span>48</span>
<span>use_db</span>: <span>sqlite</span></pre></div>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Options</h2><a id="user-content-options" aria-label="Permalink: Options" href="#options"></a></p>
<details>
  <summary>Expand</summary>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Key</th>
<th>Description</th>
<th>Default</th>
</tr>
</thead>
<tbody>
<tr>
<td>-d</td>
<td>Path to config dir</td>
<td>/data/WatchYourLAN</td>
</tr>
<tr>
<td>-n</td>
<td>Path to node modules (see below)</td>
<td></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Local network only</h2><a id="user-content-local-network-only" aria-label="Permalink: Local network only" href="#local-network-only"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto">By default, this app pulls themes, icons and fonts from the internet. But, in some cases, it may be useful to have an independent from global network setup. I created a separate <a href="https://github.com/aceberg/my-dockerfiles/tree/main/node-bootstrap">image</a> with all necessary modules and fonts.
Run with Docker:</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --name node-bootstrap          \
    -p 8850:8850                          \
    aceberg/node-bootstrap"><pre>docker run --name node-bootstrap          \
    -p 8850:8850                          \
    aceberg/node-bootstrap</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --name wyl \
	-e &quot;IFACES=$YOURIFACE&quot; \
	-e &quot;TZ=$YOURTIMEZONE&quot; \
	--network=&quot;host&quot; \
	-v $DOCKERDATAPATH/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2 -n &quot;http://$YOUR_IP:8850&quot;"><pre>docker run --name wyl \
	-e <span><span>"</span>IFACES=<span>$YOURIFACE</span><span>"</span></span> \
	-e <span><span>"</span>TZ=<span>$YOURTIMEZONE</span><span>"</span></span> \
	--network=<span><span>"</span>host<span>"</span></span> \
	-v <span>$DOCKERDATAPATH</span>/wyl:/data/WatchYourLAN \
    aceberg/watchyourlan:v2 -n <span><span>"</span>http://<span>$YOUR_IP</span>:8850<span>"</span></span></pre></div>
<p dir="auto">Or use <a href="https://github.com/aceberg/WatchYourLAN/blob/main/docker-compose-local.yml">docker-compose</a></p>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">API</h2><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<details>
  <summary>Expand</summary>
<p dir="auto">Moved to <a href="https://github.com/aceberg/WatchYourLAN/blob/main/docs/API.md">docs/API.md</a></p>
</details> 
<p dir="auto"><h2 tabindex="-1" dir="auto">Thanks</h2><a id="user-content-thanks" aria-label="Permalink: Thanks" href="#thanks"></a></p>
<details>
  <summary>Expand</summary>
<ul dir="auto">
<li>All go packages listed in <a href="https://github.com/aceberg/WatchYourLAN/network/dependencies">dependencies</a></li>
<li>Favicon and logo: <a href="https://www.flaticon.com/free-icons/access-point" rel="nofollow">Access point icons created by Freepik - Flaticon</a></li>
<li><a href="https://getbootstrap.com/" rel="nofollow">Bootstrap</a></li>
<li>Themes: <a href="https://bootswatch.com/" rel="nofollow">Free themes for Bootstrap</a></li>
</ul>
</details> 
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nearly half of Nvidia's revenue comes from four mystery whales each buying $3B+ (224 pts)]]></title>
            <link>https://fortune.com/2024/08/29/nvidia-jensen-huang-ai-customers/</link>
            <guid>41410450</guid>
            <pubDate>Sat, 31 Aug 2024 17:42:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2024/08/29/nvidia-jensen-huang-ai-customers/">https://fortune.com/2024/08/29/nvidia-jensen-huang-ai-customers/</a>, See on <a href="https://news.ycombinator.com/item?id=41410450">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Microchip designer <a href="https://fortune.com/company/nvidia/" target="_blank" aria-label="Go to https://fortune.com/company/nvidia/">Nvidia</a> more than doubled its second-quarter revenue thanks to just a handful of whales that accounted for nearly one out of every two dollars in sales the company booked.</p><div>



<p>Four customers, whose identities were kept anonymous for competitive reasons, directly purchased goods and services collectively worth 46% of Nvidia’s $30 billion in turnover. That amounts to roughly $13.8 billion, according to the company’s&nbsp;<a href="https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/78501ce3-7816-4c4d-8688-53dd140df456.pdf" target="_blank" aria-label="Go to https://d18rn0p25nwr6d.cloudfront.net/CIK-0001045810/78501ce3-7816-4c4d-8688-53dd140df456.pdf" rel="noopener">10-Q regulatory filing</a>&nbsp;published alongside its&nbsp;<a href="https://fortune.com/2024/08/23/nvidia-jensen-huang-quarterly-earnings-tech-bull-market-ai/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks" target="_self" aria-label="Go to https://fortune.com/2024/08/23/nvidia-jensen-huang-quarterly-earnings-tech-bull-market-ai/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks">hotly anticipated</a>&nbsp;quarterly investor update.</p>



<p>Each was responsible for more than a tenth of overall top line, and their purchases were all related to its booming business selling chips to data centers, the likes of which entrepreneurs such as&nbsp;<a href="https://fortune.com/2024/04/29/elon-musk-tesla-ai-fsd-china-ev-sales/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks" target="_self" aria-label="Go to https://fortune.com/2024/04/29/elon-musk-tesla-ai-fsd-china-ev-sales/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks">Elon Musk</a>&nbsp;are in a&nbsp;<a href="https://fortune.com/2024/06/18/elon-musk-xai-memphis-supercomputer-site/" target="_self" aria-label="Go to https://fortune.com/2024/06/18/elon-musk-xai-memphis-supercomputer-site/">rush to build</a>&nbsp;amid the gold rush in artificial intelligence.&nbsp;</p>



<p>To put that into perspective, this quartet of customers contributed more in sales than Nvidia reported for the prior year’s period as a whole.&nbsp;</p>



<blockquote><p lang="en" dir="ltr">Video of the inside of Cortex today, the giant new AI training supercluster being built at <a href="https://fortune.com/company/tesla/" target="_blank" aria-label="Go to https://fortune.com/company/tesla/">Tesla</a> HQ in Austin to solve real-world AI <a href="https://t.co/DwJVUWUrb5" target="_blank" aria-label="Go to https://t.co/DwJVUWUrb5" rel="noopener">pic.twitter.com/DwJVUWUrb5</a></p>— Elon Musk (@elonmusk) <a href="https://twitter.com/elonmusk/status/1827981493924155796?ref_src=twsrc%5Etfw" target="_blank" aria-label="Go to https://twitter.com/elonmusk/status/1827981493924155796?ref_src=twsrc%5Etfw" rel="noopener">August 26, 2024</a></blockquote>



<p>Although the names of the mystery AI whales are not known, <a href="https://finance.yahoo.com/news/nvidias-largest-customers-201900375.html?" target="_blank" aria-label="Go to https://finance.yahoo.com/news/nvidias-largest-customers-201900375.html?" rel="noopener">they are likely to include</a> Amazon, Meta, Microsoft, Alphabet, OpenAI, or Tesla.</p>



<p>Nvidia’s hottest products are AI chips like the H200. These are needed to train large language models like OpenAI’s GPT-4. They are also used to power inference, the process that ChatGPT or&nbsp;<a href="https://fortune.com/2024/02/16/sora-openai-sam-altman-text-to-video-generative-ai/" target="_self" aria-label="Go to https://fortune.com/2024/02/16/sora-openai-sam-altman-text-to-video-generative-ai/">Sora</a>&nbsp;uses to generate answers to text-based prompts.</p>



<p>This dependency on a handful of major customers also highlights a rising concern in the market over just how sustainable this abrupt, exponential growth from just one corner of its business can be. Some investors like&nbsp;<a href="https://fortune.com/2024/08/02/ai-nvidia-intel-arm-stock-bubble-elliott/" target="_self" aria-label="Go to https://fortune.com/2024/08/02/ai-nvidia-intel-arm-stock-bubble-elliott/">Elliott Management</a>&nbsp;and Citadel have&nbsp;<a href="https://fortune.com/2024/07/02/ken-griffin-citadel-generative-ai-hype-openai-mira-murati-nvidia-jobs/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks" target="_self" aria-label="Go to https://fortune.com/2024/07/02/ken-griffin-citadel-generative-ai-hype-openai-mira-murati-nvidia-jobs/?utm_source=search&amp;utm_medium=suggested_search&amp;utm_campaign=search_link_clicks">voiced skepticism</a>&nbsp;over how long this can be maintained.</p>



<p>History does give reason for concern. The semiconductor industry is known for its boom-and-bust cycles.</p>



<p>Shares in Nvidia are expected to open lower on Thursday, underperforming the broader equity market.</p>



<h2>One customer provided revenue greater than Nvidia’s second-largest business</h2>



<p>In fact Nvidia’s business ties with these whales are so significant the company flags them in a section of its quarterly reports titled “concentration of revenue,” which is dedicated to cluster risks.</p>



<p>“We have experienced periods where we receive a significant amount of our revenue from a limited number of customers,” it stated in its 10-Q regulatory filing, “and this trend may continue.”&nbsp;</p>



<p>It’s a trend that is staggeringly profitable. Nvidia pocketed $5.60 out of every $10 of revenue it made over the entire first half as net income—margins most companies can only dream of.&nbsp;</p>



<p>That explains why profit after tax nearly quadrupled to $31.5 billion during this six-month period over the previous year. Whether revenue, and therefore earnings, can continue to grow at this blistering pace is crucial to its investment story.</p>



<p>Take “Customer B” cited in the filing, for example: Its direct purchases represented 11% of Nvidia’s $30 billion in revenue. That means a single company contributed more in business than the group’s second largest division—gaming, with $2.9 billion—did as a whole.</p>



<p>Customer B, however, remained below the 10% threshold for the entire first half, which suggests it significantly ramped up spending during the past quarter seemingly out of the blue. The exact same could be said about “Customer C”; the numbers provided by Nvidia are identical.&nbsp;</p>



<blockquote><p lang="qme" dir="ltr"><a href="https://twitter.com/search?q=%24NVDA&amp;src=ctag&amp;ref_src=twsrc%5Etfw" target="_blank" aria-label="Go to https://twitter.com/search?q=%24NVDA&amp;src=ctag&amp;ref_src=twsrc%5Etfw" rel="noopener">$NVDA</a> <a href="https://t.co/Lym4uHBCXs" target="_blank" aria-label="Go to https://t.co/Lym4uHBCXs" rel="noopener">pic.twitter.com/Lym4uHBCXs</a></p>— Jesse Cohen (@JesseCohenInv) <a href="https://twitter.com/JesseCohenInv/status/1828404561867923571?ref_src=twsrc%5Etfw" target="_blank" aria-label="Go to https://twitter.com/JesseCohenInv/status/1828404561867923571?ref_src=twsrc%5Etfw" rel="noopener">August 27, 2024</a></blockquote>



<p>Speaking to Bloomberg TV on Wednesday, CEO Jensen Huang answered a question on where demand is coming from, beyond the handful of hyperscalers like <a href="https://fortune.com/company/microsoft/" target="_blank" aria-label="Go to https://fortune.com/company/microsoft/">Microsoft</a>, <a href="https://fortune.com/company/alphabet/" target="_blank" aria-label="Go to https://fortune.com/company/alphabet/">Google</a>, and <a href="https://fortune.com/company/amazon-com/" target="_blank" aria-label="Go to https://fortune.com/company/amazon-com/">Amazon</a>.</p>



<p>“We’re relatively diversified today,” he&nbsp;<a href="https://www.youtube.com/watch?v=NC5NZPrxbHk&amp;t=99s" target="_blank" aria-label="Go to https://www.youtube.com/watch?v=NC5NZPrxbHk&amp;t=99s" rel="noopener">claimed</a>, citing a range of different customer groups.&nbsp;</p>



<p>Yet his own company’s numbers appear to dispute that conclusion. This time last year, for example, there were no direct customers whose business made up 10% or more of total revenue—neither for the first nor the second quarter.</p>



<p>Nvidia didn’t immediately respond to a request from&nbsp;<em>Fortune</em>&nbsp;for comment.</p></div><div data-cy="subscriptionPlea"><p><strong>Recommended reading:</strong><br>In our new special issue, a Wall Street legend gets a radical makeover, a tale of crypto iniquity, misbehaving poultry royalty, and more.<br><a href="https://fortune.com/packages/digital-issue-kkr/?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=kkr_issue" target="_self" aria-label="Go to https://fortune.com/packages/digital-issue-kkr/?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=kkr_issue">Read the stories.</a></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Client-side QR code generator with SVG output (150 pts)]]></title>
            <link>https://fietkau.software/qr</link>
            <guid>41410442</guid>
            <pubDate>Sat, 31 Aug 2024 17:42:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fietkau.software/qr">https://fietkau.software/qr</a>, See on <a href="https://news.ycombinator.com/item?id=41410442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main" tabindex="-1"><div><p>QRSVG is a small JavaScript project to render a two-dimensional bitmask (mostly assumed to be a QR code) to an SVG element as a collection of SVG paths with defined purposes.</p></div><section><h2>Project Description</h2><p><a href="https://en.wikipedia.org/wiki/QR_code">QR codes</a> have established themselves as a popular way to provide a chunk of digital information (most commonly a web address to jump to) via physical media. I myself occasionally use them in flyers, posters, or presentation slides.</p><p>They are not too complicated to generate and a variety of free websites exist for this purpose. Sadly none of them appear to have all of the customization options that I want, plus most of them use some manner of ads and/or data tracking. The demo on this page combines <a href="https://www.nayuki.io/page/qr-code-generator-library">Project Nayuki’s QR Code generator library</a> (a multi-language open source project that can, among other things, perform the conversion of text into raw QR code data) with my own QRSVG project, which can turn a QR-like two-dimensional boolean data map into an efficient vector description of its own visualization by tracing the contours of contiguous shapes. Or in simpler terms: it turns a QR code into a straightforward and customizable SVG file. The demo up top showcases a number of stylistic customizations enabled by QRSVG. Its strengths include:</p><ul><li>Conversion of QR code data into efficient SVG markup</li><li>Shape and color customization</li><li>QR codes can be made downloadable in SVG and PNG formats</li><li>Entirely client-side, hostable as static files (i.e. making this available to you costs me nothing)</li></ul><p>If the demo QR code generator at the top of this page is convenient for you too, please feel free to spread the word!</p></section></div></div>]]></description>
        </item>
    </channel>
</rss>