<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 05 Sep 2024 16:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Show HN: Hacker League – Open-Source Rocket League on Linux (127 pts)]]></title>
            <link>https://github.com/moritztng/hacker-league</link>
            <guid>41456411</guid>
            <pubDate>Thu, 05 Sep 2024 13:24:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/moritztng/hacker-league">https://github.com/moritztng/hacker-league</a>, See on <a href="https://news.ycombinator.com/item?id=41456411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><details open="">
  <summary>
    
    <span aria-label="Video description hacker-league.mp4">hacker-league.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/19519902/364779763-3a630d46-ec17-4da8-8879-76320ea563fe.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1NTA1MDEsIm5iZiI6MTcyNTU1MDIwMSwicGF0aCI6Ii8xOTUxOTkwMi8zNjQ3Nzk3NjMtM2E2MzBkNDYtZWMxNy00ZGE4LTg4NzktNzYzMjBlYTU2M2ZlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDE1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNkMDg3MjdiZmFkMTZiODk4YTJiYzBkYzc4MTk4ZGNmOTJjZjYxMjY3NzI1MGMzOTFjNTg1Y2YxNWVkOWE1OWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.C7QQg92wm3q0awLIIoj6I8rQuGAJsOeWGMyqE9soFcQ" data-canonical-src="https://private-user-images.githubusercontent.com/19519902/364779763-3a630d46-ec17-4da8-8879-76320ea563fe.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1NTA1MDEsIm5iZiI6MTcyNTU1MDIwMSwicGF0aCI6Ii8xOTUxOTkwMi8zNjQ3Nzk3NjMtM2E2MzBkNDYtZWMxNy00ZGE4LTg4NzktNzYzMjBlYTU2M2ZlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDE1MzAwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNkMDg3MjdiZmFkMTZiODk4YTJiYzBkYzc4MTk4ZGNmOTJjZjYxMjY3NzI1MGMzOTFjNTg1Y2YxNWVkOWE1OWYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.C7QQg92wm3q0awLIIoj6I8rQuGAJsOeWGMyqE9soFcQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto">Currently only debian based distros with x86_64. Please help me build it on other platforms. If you have an external GPU, make sure the drivers are installed</p>
<div dir="auto" data-snippet-clipboard-copy-content="sudo apt install curl &amp;&amp; curl -sL https://raw.githubusercontent.com/moritztng/hacker-league/main/install.sh | bash"><pre>sudo apt install curl <span>&amp;&amp;</span> curl -sL https://raw.githubusercontent.com/moritztng/hacker-league/main/install.sh <span>|</span> bash</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Play</h2><a id="user-content-play" aria-label="Permalink: Play" href="#play"></a></p>
<p dir="auto">Use a gamepad for maximum fun</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd hacker-league
./hacker-league"><pre><span>cd</span> hacker-league
./hacker-league</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Build from source</h2><a id="user-content-build-from-source" aria-label="Permalink: Build from source" href="#build-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/moritztng/hacker-league.git
cd hacker-league
sudo apt install libvulkan-dev vulkan-validationlayers-dev spirv-tools libglfw3-dev libglm-dev libeigen3-dev vim-common xxd g++ make
curl -L -o ./shaders/glslc https://github.com/moritztng/hacker-league/releases/download/glslc/glslc
chmod +x ./shaders/glslc
make debug
curl -L -o &quot;gamepad.txt&quot; https://raw.githubusercontent.com/mdqinc/SDL_GameControllerDB/master/gamecontrollerdb.txt"><pre>git clone https://github.com/moritztng/hacker-league.git
<span>cd</span> hacker-league
sudo apt install libvulkan-dev vulkan-validationlayers-dev spirv-tools libglfw3-dev libglm-dev libeigen3-dev vim-common xxd g++ make
curl -L -o ./shaders/glslc https://github.com/moritztng/hacker-league/releases/download/glslc/glslc
chmod +x ./shaders/glslc
make debug
curl -L -o <span><span>"</span>gamepad.txt<span>"</span></span> https://raw.githubusercontent.com/mdqinc/SDL_GameControllerDB/master/gamecontrollerdb.txt</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<ul dir="auto">
<li>Discord Server: <a href="https://discord.gg/BbNH27st" rel="nofollow">https://discord.gg/BbNH27st</a></li>
<li>I build in public on X: <a href="https://x.com/moritzthuening" rel="nofollow">https://x.com/moritzthuening</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Porting systemd to musl Libc-powered Linux (150 pts)]]></title>
            <link>https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/</link>
            <guid>41454779</guid>
            <pubDate>Thu, 05 Sep 2024 08:44:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/">https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/</a>, See on <a href="https://news.ycombinator.com/item?id=41454779">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-449">
	<!-- .entry-header -->

	
	
	<div>
		
<p>I have completed an <a href="https://code.atwilcox.tech/sphen/scaly/systemd/-/commits/adelie-v256">initial new port</a> of systemd to musl.  This patch set does not share much in common with the existing OpenEmbedded patchset.  I wanted to make a fully updated patch series targeting more current releases of systemd and musl, taking advantage of the latest features and updates in both.  I also took a focus on writing patches that could be sent for consideration of inclusion upstream.</p>



<p>The final result is a system that appears to be surprisingly reliable considering the newness of the port, and very fast to boot.</p>



<h2>Why?</h2>



<p>I have wanted to do this work for almost a decade.  In fact, a mention of multiple service manager options – including systemd – is present on the <a href="https://web.archive.org/web/20160109133511/http://adelielinux.org/">original Adélie Web site from 2015</a>.  Other initiatives have always taken priority, until someone contacted us at <a href="https://www.wilcoxti.com/">Wilcox Technologies Inc. (WTI)</a> interested in paying on a contract basis to see this effort completed.</p>



<p>I want to be clear that I did not do this for money.  I believe strongly that there is genuine value in having multiple service managers available.  User freedom and user choice matter.  There are cases where this support would have been useful to me and to many others in the community.  I am excited to see this work nearing public release and honoured to be a part of creating more choice in the Linux world.</p>



<h2>How?</h2>



<p>I started with the latest release tag, v256.5.  I wanted a version closely aligned to upstream’s current progress, yet not too far away from the present “stable” 255 release.  I also wanted to make sure that the fallout from upstream’s removal of split-/usr support would be felt to its maximum, since reverting that decision is a high priority.</p>



<p>I fixed build errors as they happened until I finally had a built systemd.  During this phase, I consulted the original OE patchset twice: once for usage of <code>GLOB_BRACE</code>, and the other for usage of <code>malloc_info</code> and <code>malloc_trim</code>.  Otherwise, the patchset was authored entirely originally, mostly through the day (and into the night) of August 16th, 2024.</p>



<p>Many of the issues seen were related to inclusion of headers, and I am already working on <a href="https://github.com/systemd/systemd/pull/34064">bringing</a> those fixes <a href="https://github.com/systemd/systemd/pull/34066">upstream</a>.  It was then time to run the test suite.</p>



<h2>Tests!</h2>



<p>The test suite started with 27 failures.  Most of them were simple fixes, but one that gave me a lot of trouble was the <code>time-util</code> test.  The <a href="https://git.musl-libc.org/cgit/musl/tree/src/time/strptime.c"><code>strptime</code> implementation in musl</a> does not support the <code>%z</code> format specifier (for time zones), which the systemd test relies on.  I could have disabled those tests, but I felt like this would be taking away a lot of functionality.  I considered things like important journals from other systems – they would likely have timestamps with <code>%z</code> formats.  I wrote a <code>%z</code> translation for systemd and saw the tests passing.</p>



<p>Other test failures were simple <a href="https://github.com/systemd/systemd/pull/34065">C portability fixes</a>, which are also in the process of being sent upstream.</p>



<p>The test suite for <code>systemd-sysusers</code> was the next sticky one.  It really exercises the POSIX library functions <code>getgrent</code> and <code>getpwent</code>.  The musl implementations of these are fine, but they don’t cope well with the old NIS compatibility shims from the glibc world.  They also <a href="https://www.openwall.com/lists/musl/2021/10/11/1">can’t handle “incomplete” lines</a>.  The fix for incomplete line handling is pending, so in the meantime I made the test have no incomplete lines.  I added a shim for the NIS compatibility entries in systemd’s <code>putgrent_sane</code> function, making it a little less “sane” but fixing the support perfectly.</p>



<p>Then it was time for the final failing test: <code>test-recurse-dir</code>, which was receiving an <code>EFAULT</code> error code from <code>getdents64</code>.  Discussing this with my friends on the Gentoo IRC, we began to wonder if this was an architecture-specific bug.  I was doing my port work on my Talos II, a 64-bit PowerPC system.  I copied the code over to an Intel Skylake and found the test suite passed.  That was both good, in that the tests were all passing, but also bad, because it meant I was dealing with a PPC64-specific bug.  I wasn’t sure if this was a kernel bug, a musl bug, or a systemd bug.</p>



<p>Digging into it further, I realised that the pointer math being done would be invalid when cast to a pointer-to-structure on PPC64 due to object alignment guarantees in the ABI.  I changed it to use a temporary variable for the pointer math and casting that temporary, and it passed!</p>



<p>And that is how I became the first person alive to see systemd passing its entire test suite on a big-endian 64-bit PowerPC musl libc system.</p>



<h2>The moment of truth</h2>



<p>I created a small disk image and ran a very strange command: <code>apk add adelie-base-posix dash-binsh systemd</code>.  I booted it up as a KVM VM in Qemu and saw “Welcome to Adélie Linux 1.0 Beta 5” before a rather ungraceful – and due to Qemu framebuffer endian issues, colour-swapped – segmentation fault:</p>



<figure><img data-attachment-id="453" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/the-dawn-of-a-new-error/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png" data-orig-size="1736,1392" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="the-dawn-of-a-new-error" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=840" tabindex="0" role="button" width="1024" height="821" src="https://catfox.life/wp-content/uploads/2024/09/the-dawn-of-a-new-error.png?w=1024" alt=""><figcaption>Welcome to an endian-swapped systemd core dump!</figcaption></figure>



<p>Debugging this was an experience in early systems debugging that I haven’t had in years.  There’s a great summary on this methodology at <a href="https://linus.schreibt.jetzt/posts/debugging-pid1.html">Linus’s blog</a>.</p>



<p>It turned out that I had disabled a test from build-util as I incorrectly assumed that was only used when debugging in the build root.  Since I did not want to spend time digging around how it manually parses ELF files to find their RPATH entries for a feature we are unlikely to use, I stubbed that functionality out entirely.  We can always fix it later.</p>



<p>Recreating the disk image and booting it up, I was greeted by an Adélie “rescue” environment booted by systemd.  It was frankly bizarre, but also really cool.</p>



<figure><img data-attachment-id="454" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/habbening/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png" data-orig-size="2064,1470" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="habbening" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=840" tabindex="0" role="button" width="1024" height="729" src="https://catfox.life/wp-content/uploads/2024/09/habbening.png?w=1024" alt=""><figcaption>The first time systemd ever booted an Adélie Linux system.</figcaption></figure>



<h2>From walking to flying</h2>



<p>Next, I built test packages on the Skylake builder we are using for x86_64 development.  I have a 2012 MacBook Pro that I keep around for testing various experiments, and this felt like a good system for the ultimate experiment.  The goal: swapping init systems with a single command.</p>



<p>It turns out that D-Bus and PolicyKit require systemd support to be enabled or disabled at build-time.  There is no way to build them in a way that allows them to operate on both types of init system.  This is an area I would like to work on more in the future.</p>



<p>I wrote package recipes for both that are built against systemd and “replace” the non-systemd versions.  I also marked them to <code>install_if</code> the system wanted systemd.</p>



<p>Next up were some more configuration and dependency fixes.  I found out via this experiment that some of the Adélie system packages do not place their pkg-config files in the proper place.  I also decided that if I’m already testing this far, I’d use networkd to bring up the laptop in question.</p>



<p>I ran the fateful command <code>apk del openrc; apk add systemd</code> and rebooted.  To my surprise, it all worked!  The system booted up perfectly with systemd.  The oddest sight was my utmps units running:</p>



<figure><img data-attachment-id="455" data-permalink="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/need-more-fromage-2/" data-orig-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png" data-orig-size="1280,800" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="need-more-fromage-2" data-image-description="" data-image-caption="" data-medium-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=300" data-large-file="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=840" tabindex="0" role="button" width="1024" height="640" src="https://catfox.life/wp-content/uploads/2024/09/need-more-fromage-2.png?w=1024" alt=""><figcaption>systemd running s6-ipcserver.  The irony is not lost on me.</figcaption></figure>



<h2>Still needed: polish…</h2>



<p>While the system works really well, and boots in 1/3rd the time of OpenRC on the same system, it isn’t ready for prime time just yet.</p>



<p>Rebooting from a KDE session causes the compositor to freeze.  I can reboot manually from a command line, or even from a Konsole inside the session, but not using Plasma’s built-in power buttons.  This may be a PolicyKit issue – I haven’t debugged it properly yet.</p>



<p>There aren’t any service unit files written or packaged yet, other than OpenSSH and utmps.  We are working with our sponsor on an effort to add -systemd split packages to any of the packages with -openrc splits.  We should be able to rely on upstream units where present, and lean on Gentoo and Fedora’s systemd experts to have good base files to reference when needed.  I’ve already landed <a href="https://git.adelielinux.org/adelie/abuild/-/merge_requests/16">support for this in abuild</a>.</p>



<h2>…and You!</h2>



<p>This project could not have happened without the generous sponsors of Wilcox Technologies Inc (WTI) making it possible, nor without the generous sponsors of Adélie Linux keeping the distro running.  Please consider supporting both <a href="https://www.adelielinux.org/contribute/">Adélie Linux</a> and <a href="https://www.patreon.com/WilcoxTech">WTI</a> if you have the means.  Together, we are creating the future of Linux systems – a future where users have the choice and freedom to use the tooling they desire.</p>



<p>If you want to help test this new system out, please reach out to me on IRC (awilfox on Interlinked or Libera), or the Adéliegram Telegram channel.  It will be a little while before a public beta will be available, as more review and discussion with other projects is needed.  We are working with systemd, musl, and other projects to make this as smooth as possible.  We want to ensure that what we provide for testing is up to our highest standards of quality.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a WoW (World of Warcraft) Server in Elixir (153 pts)]]></title>
            <link>https://pikdum.dev/posts/thistle-tea/</link>
            <guid>41454741</guid>
            <pubDate>Thu, 05 Sep 2024 08:36:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pikdum.dev/posts/thistle-tea/">https://pikdum.dev/posts/thistle-tea/</a>, See on <a href="https://news.ycombinator.com/item?id=41454741">Hacker News</a></p>
Couldn't get https://pikdum.dev/posts/thistle-tea/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Desed: Demystify and debug your sed scripts (122 pts)]]></title>
            <link>https://github.com/SoptikHa2/desed</link>
            <guid>41453557</guid>
            <pubDate>Thu, 05 Sep 2024 04:46:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/SoptikHa2/desed">https://github.com/SoptikHa2/desed</a>, See on <a href="https://news.ycombinator.com/item?id=41453557">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Desed</h2><a id="user-content-desed" aria-label="Permalink: Desed" href="#desed"></a></p>
<p dir="auto">Demystify and debug your sed scripts, from comfort of your terminal.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SoptikHa2/desed/blob/master/img/desed.gif"><img src="https://github.com/SoptikHa2/desed/raw/master/img/desed.gif" alt="desed usage example" data-animated-image=""></a></p>
<p dir="auto">Desed is a command line tool with beautiful TUI that provides users with comfortable interface and practical debugger, used to step through complex sed scripts.</p>
<p dir="auto">Some of the notable features include:</p>
<ul dir="auto">
<li>Preview variable values, both of them!</li>
<li>See how will a substitute command affect pattern space before it runs</li>
<li>Step through sed script - both forward and backwards!</li>
<li>Place breakpoints and examine program state</li>
<li>Hot reload and see what changes as you edit source code</li>
<li>Its name is a palindrome</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Alpine Linux</h3><a id="user-content-alpine-linux" aria-label="Permalink: Alpine Linux" href="#alpine-linux"></a></p>
<p dir="auto"><code>aports/testing/desed</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Arch Linux</h3><a id="user-content-arch-linux" aria-label="Permalink: Arch Linux" href="#arch-linux"></a></p>
<p dir="auto">Via AUR: <a href="https://aur.archlinux.org/packages/desed-git/" rel="nofollow">desed-git</a> or <a href="https://aur.archlinux.org/packages/desed/" rel="nofollow">desed</a> as stable version.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">DragonFly BSD</h3><a id="user-content-dragonfly-bsd" aria-label="Permalink: DragonFly BSD" href="#dragonfly-bsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Fedora</h3><a id="user-content-fedora" aria-label="Permalink: Fedora" href="#fedora"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">FreeBSD</h3><a id="user-content-freebsd" aria-label="Permalink: FreeBSD" href="#freebsd"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Void Linux</h3><a id="user-content-void-linux" aria-label="Permalink: Void Linux" href="#void-linux"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Source</h3><a id="user-content-source" aria-label="Permalink: Source" href="#source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/soptikha2/desed
cd desed
cargo install --path .
cp &quot;desed.1&quot; &quot;$(manpath | cut -d':' -f1)/man1&quot;"><pre>git clone https://github.com/soptikha2/desed
<span>cd</span> desed
cargo install --path <span>.</span>
cp <span><span>"</span>desed.1<span>"</span></span> <span><span>"</span><span><span>$(</span>manpath <span>|</span> cut -d<span><span>'</span>:<span>'</span></span> -f1<span>)</span></span>/man1<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cargo</h3><a id="user-content-cargo" aria-label="Permalink: Cargo" href="#cargo"></a></p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Precompiled binaries</h3><a id="user-content-precompiled-binaries" aria-label="Permalink: Precompiled binaries" href="#precompiled-binaries"></a></p>
<p dir="auto">See <a href="https://github.com/SoptikHa2/desed/releases">releases</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dependencies:</h3><a id="user-content-dependencies" aria-label="Permalink: Dependencies:" href="#dependencies"></a></p>
<p dir="auto">Development: <code>rust</code>, <code>cargo</code> (&gt;= 1.38.0)</p>
<p dir="auto">Runtime: <code>sed</code> (GNU version, &gt;= 4.6) (desed works on BSD if you installed <code>gsed</code>)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Controls</h2><a id="user-content-controls" aria-label="Permalink: Controls" href="#controls"></a></p>
<ul dir="auto">
<li>Mouse scroll to scroll through source code, click on line to toggle breakpoint</li>
<li><code>j</code>, <code>k</code>, <code>g</code>, <code>G</code>, just as in Vim. Prefixing with numbers works too.</li>
<li><code>b</code> to toggle breakpoint (prefix with number to toggle breakpoint on target line)</li>
<li><code>s</code> to step forward, <code>a</code> to step backwards</li>
<li><code>r</code> to run to next breakpoint or end of script, <code>R</code> to do the same but backwards</li>
<li><code>l</code> to instantly reload code and continue debugging in the exactly same place as before</li>
<li><code>q</code> to <a href="https://github.com/hakluke/how-to-exit-vim">quit</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How does it work?</h2><a id="user-content-how-does-it-work" aria-label="Permalink: How does it work?" href="#how-does-it-work"></a></p>
<p dir="auto">GNU sed actually provides pretty useful debugging interface, try it yourself with <code>--debug</code> flag. However the interface is not interactive and I wanted something closer to traditional debugger. <a href="https://soptik.tech/articles/building-desed-the-sed-debugger.html" rel="nofollow">I've written something here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Does it really work?</h2><a id="user-content-does-it-really-work" aria-label="Permalink: Does it really work?" href="#does-it-really-work"></a></p>
<p dir="auto">Depends. Sed actually doesn't tell me which line number is it currently executing, so I have to emulate parts of sed to guess that. Which might not be bulletproof. But it certainly worked good enough to debug tetris without issues.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why sed??</h2><a id="user-content-why-sed" aria-label="Permalink: Why sed??" href="#why-sed"></a></p>
<p dir="auto">Sed is the perfect programming language, <a href="https://tildes.net/~comp/b2k/programming_challenge_find_path_from_city_a_to_city_b_with_least_traffic_controls_inbetween#comment-2run" rel="nofollow">especially for graph problems</a>. It's plain and simple and doesn't clutter your screen with useless identifiers like <code>if</code>, <code>for</code>, <code>while</code>, or <code>int</code>. Furthermore since it doesn't have things like numbers, it's very simple to use.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">But why?</h2><a id="user-content-but-why" aria-label="Permalink: But why?" href="#but-why"></a></p>
<p dir="auto">I wanted to program in sed but it lacked good tooling up to this point, so I had to do something about it.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<p dir="auto">Because it's the standard stream editor for filtering and transforming text. And someone wrote <a href="https://github.com/uuner/sedtris">tetris</a> in it!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is the roadmap for future updates?</h2><a id="user-content-what-is-the-roadmap-for-future-updates" aria-label="Permalink: What is the roadmap for future updates?" href="#what-is-the-roadmap-for-future-updates"></a></p>
<p dir="auto">I would like to introduce syntax highlighting and add this tool to standard repositories of all major distributions.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Is this a joke?</h2><a id="user-content-is-this-a-joke" aria-label="Permalink: Is this a joke?" href="#is-this-a-joke"></a></p>
<p dir="auto">I thought it was. But apparently it's actually useful for some people.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Other projects</h2><a id="user-content-other-projects" aria-label="Permalink: Other projects" href="#other-projects"></a></p>
<ul dir="auto">
<li><a href="https://github.com/soptikha2/video-summarizer">video summarizer</a>, a tool and browser extensions that determines if people in video are currently talking or not, and speeds up the video accordingly. Great for long lecture videos for skipping time spent writing on a whiteboard.</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kids who use ChatGPT as a study assistant do worse on tests (155 pts)]]></title>
            <link>https://hechingerreport.org/kids-chatgpt-worse-on-tests/</link>
            <guid>41453300</guid>
            <pubDate>Thu, 05 Sep 2024 03:50:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hechingerreport.org/kids-chatgpt-worse-on-tests/">https://hechingerreport.org/kids-chatgpt-worse-on-tests/</a>, See on <a href="https://news.ycombinator.com/item?id=41453300">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="content">
		<main id="main">

								

				
				<div>

					<section id="block-2"><p><em>The Hechinger Report is a national nonprofit newsroom that reports on one topic: education. Sign up for our&nbsp;<a href="https://hechingerreport.org/newsletters" target="_blank" rel="noreferrer noopener">weekly newsletters</a>&nbsp;to get stories like this delivered directly to your inbox.&nbsp;Consider supporting our stories and becoming&nbsp;<a href="https://hechingerreport.fundjournalism.org/?campaign=701VK000003ezHZYAY" target="_blank" rel="noreferrer noopener">a member</a>&nbsp;today.</em></p></section>

<article id="post-103317">
	<div>

		
		
					<p>Does AI actually help students learn? A recent experiment in a high school provides a cautionary tale.&nbsp;</p><p>Researchers at the University of Pennsylvania found that Turkish high school students who had access to ChatGPT while doing practice math problems did worse on a math test compared with students who didn’t have access to ChatGPT. Those with ChatGPT solved 48 percent more of the practice problems correctly, but they ultimately scored 17 percent worse on a test of the topic that the students were learning.&nbsp;</p><p>A third group of students had access to a revised version of ChatGPT that functioned more like a tutor. This chatbot was programmed to provide hints without directly divulging the answer. The students who used it did spectacularly better on the practice problems, solving 127 percent more of them correctly compared with students who did their practice work without any high-tech aids. But on a test afterwards, these AI-tutored students did no better. Students who just did their practice problems the old fashioned way — on their own — matched their test scores.</p><p>The researchers titled their paper, “Generative AI Can Harm Learning,” to make clear to parents and educators that the current crop of freely available AI chatbots can “substantially inhibit learning.” Even a fine-tuned version of ChatGPT designed to mimic a tutor doesn’t necessarily help.</p><p>The researchers believe the problem is that students are using the chatbot as a “crutch.” When they analyzed the questions that students typed into ChatGPT, students often simply asked for the answer. Students were not building the skills that come from solving the problems themselves.&nbsp;</p><p>ChatGPT’s errors also may have been a contributing factor. The chatbot only answered the math problems correctly half of the time. Its arithmetic computations were wrong 8 percent of the time, but the bigger problem was that its step-by-step approach for how to solve a problem was wrong 42 percent of the time. The tutoring version of ChatGPT was directly fed the correct solutions and these errors were minimized.</p><p>A <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4895486">draft paper about the experiment</a> was posted on the website of SSRN, formerly known as the Social Science Research Network, in July 2024. The paper has not yet been published in a peer-reviewed journal and could still be revised.&nbsp;</p><p>This is just one experiment in another country, and more studies will be needed to confirm its findings. But this experiment was a large one, involving nearly a thousand students in grades nine through 11 during the fall of 2023. Teachers first reviewed a previously taught lesson with the whole classroom, and then their classrooms were randomly assigned to practice the math in one of three ways: with access to ChatGPT, with access to an AI tutor powered by ChatGPT or with no high-tech aids at all. Students in each grade were assigned the same practice problems with or without AI. Afterwards, they took a test to see how well they learned the concept. Researchers conducted four cycles of this, giving students four 90-minute sessions of practice time in four different math topics to understand whether AI tends to help, harm or do nothing.</p><p>ChatGPT also seems to produce overconfidence. In surveys that accompanied the experiment, students said they did not think that ChatGPT caused them to learn less even though they had. Students with the AI tutor thought they had done significantly better on the test even though they did not. (It’s also another good reminder to all of us that our <a href="https://hechingerreport.org/proof-points-college-students-often-dont-know-when-theyre-learning/">perceptions of how much we’ve learned are often wrong</a>.)</p><p>The authors likened the problem of learning with ChatGPT to autopilot. They recounted how an overreliance on autopilot led the Federal Aviation Administration to recommend that pilots minimize their use of this technology. Regulators wanted to make sure that pilots still know how to fly when autopilot fails to function correctly.&nbsp;</p><p>ChatGPT is not the first technology to present a tradeoff in education. Typewriters and computers reduce the need for handwriting. Calculators reduce the need for arithmetic. When students have access to ChatGPT, they might answer more problems correctly, but learn less. Getting the right result to one problem won’t help them with the next one.</p><p><em>This story about&nbsp;using <a href="https://hechingerreport.org/kids-chatgpt-worse-on-tests/">ChatGPT to practice math</a>&nbsp;was written by Jill Barshay and produced by&nbsp;<a href="https://hechingerreport.org/special-reports/higher-education/" target="_blank" rel="noreferrer noopener">The Hechinger Report</a>, a nonprofit, independent news organization focused on inequality and innovation in education. Sign up for&nbsp;<a href="https://hechingerreport.org/proofpoints/" target="_blank" rel="noreferrer noopener"><em>Proof Points</em></a>&nbsp;and other&nbsp;<a href="https://hechingerreport.org/newsletters/" target="_blank" rel="noreferrer noopener"><em>Hechinger newsletters</em></a>.</em></p>
<div id="custom_html-3">
	
<p>The Hechinger Report provides in-depth, fact-based, unbiased reporting on education that is free to all readers. But that doesn't mean it's free to produce. Our work keeps educators and the public informed about pressing issues at schools and on campuses throughout the country. We tell the whole story, even when the details are inconvenient. Help us keep doing that.</p>

<p><a href="https://checkout.fundjournalism.org/memberform?amount=15&amp;installmentPeriod=monthly&amp;org_id=hechingerreport&amp;campaign=701f4000000dsvy">Join us today.</a></p>
</div>	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
			<div>
															<p><a href="https://hechingerreport.org/author/jill-barshay/" rel="author">
											<img alt="Avatar photo" src="https://hechingerreport.org/wp-content/uploads/2015/01/Barshay-80x80.jpg" srcset="https://i0.wp.com/hechingerreport.org/wp-content/uploads/2015/01/Barshay.jpg?fit=154%2C150&amp;ssl=1 2x" height="80" width="80">											</a></p><!-- .author-bio-text -->

			</div><!-- .author-bio -->
			
</article><!-- #post-${ID} -->

<!-- #comments -->
				</div><!-- .main-content -->

			
		</main><!-- #main -->
	</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Yi-Coder: A Small but Mighty LLM for Code (179 pts)]]></title>
            <link>https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md</link>
            <guid>41453237</guid>
            <pubDate>Thu, 05 Sep 2024 03:38:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md">https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md</a>, See on <a href="https://news.ycombinator.com/item?id=41453237">Hacker News</a></p>
Couldn't get https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Accelerando (2005) (133 pts)]]></title>
            <link>https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html</link>
            <guid>41452962</guid>
            <pubDate>Thu, 05 Sep 2024 02:33:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html">https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html</a>, See on <a href="https://news.ycombinator.com/item?id=41452962">Hacker News</a></p>
Couldn't get https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html: Error: unable to verify the first certificate]]></description>
        </item>
        <item>
            <title><![CDATA[Canadian mega landlord using AI 'pricing scheme' as it hikes rents (130 pts)]]></title>
            <link>https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/</link>
            <guid>41452781</guid>
            <pubDate>Thu, 05 Sep 2024 01:59:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/">https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/</a>, See on <a href="https://news.ycombinator.com/item?id=41452781">Hacker News</a></p>
Couldn't get https://breachmedia.ca/canadian-mega-landlord-ai-pricing-scheme-hikes-rents/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Tinystatus: A tiny status page generated by a Python script (147 pts)]]></title>
            <link>https://github.com/harsxv/tinystatus</link>
            <guid>41452339</guid>
            <pubDate>Thu, 05 Sep 2024 00:40:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/harsxv/tinystatus">https://github.com/harsxv/tinystatus</a>, See on <a href="https://news.ycombinator.com/item?id=41452339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">TinyStatus</h2><a id="user-content-tinystatus" aria-label="Permalink: TinyStatus" href="#tinystatus"></a></p>
<p dir="auto">TinyStatus is a simple, customizable status page generator that allows you to monitor the status of various services and display them on a clean, responsive web page. <a href="https://status.harry.id/" rel="nofollow">Check out an online demo.</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/32115753/364659939-28227221-d1e1-442e-89a4-2a0a09615514.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MzYxMDIsIm5iZiI6MTcyNTUzNTgwMiwicGF0aCI6Ii8zMjExNTc1My8zNjQ2NTk5MzktMjgyMjcyMjEtZDFlMS00NDJlLTg5YTQtMmEwYTA5NjE1NTE0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDExMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2Zjc0OGQxMGYxYzRjYmI0MmU0MGVkMzczMmIxMGZjNDQ4YzdkYWEyY2VmMTgxYWQ2YTMyYzA5MzFiZWJjYTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QCCL41W8KUg1xVUkqRXKeIjf9PYclCeikbDKVyKaZK4"><img src="https://private-user-images.githubusercontent.com/32115753/364659939-28227221-d1e1-442e-89a4-2a0a09615514.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MzYxMDIsIm5iZiI6MTcyNTUzNTgwMiwicGF0aCI6Ii8zMjExNTc1My8zNjQ2NTk5MzktMjgyMjcyMjEtZDFlMS00NDJlLTg5YTQtMmEwYTA5NjE1NTE0LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDExMzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTA2Zjc0OGQxMGYxYzRjYmI0MmU0MGVkMzczMmIxMGZjNDQ4YzdkYWEyY2VmMTgxYWQ2YTMyYzA5MzFiZWJjYTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.QCCL41W8KUg1xVUkqRXKeIjf9PYclCeikbDKVyKaZK4" alt="image"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Monitor HTTP endpoints, ping hosts, and check open ports</li>
<li>Responsive design for both status page and history page</li>
<li>Customizable service checks via YAML configuration</li>
<li>Incident history tracking</li>
<li>Automatic status updates at configurable intervals</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Prerequisites</h2><a id="user-content-prerequisites" aria-label="Permalink: Prerequisites" href="#prerequisites"></a></p>
<ul dir="auto">
<li>Python 3.7 or higher</li>
<li>pip (Python package manager)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Clone the repository or download the source code:</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/yourusername/tinystatus.git
cd tinystatus"><pre><code>git clone https://github.com/yourusername/tinystatus.git
cd tinystatus
</code></pre></div>
</li>
<li>
<p dir="auto">Install the required dependencies:</p>
<div data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre><code>pip install -r requirements.txt
</code></pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Create a <code>.env</code> file in the project root and customize the variables:</p>
<div data-snippet-clipboard-copy-content="CHECK_INTERVAL=30
MAX_HISTORY_ENTRIES=100
LOG_LEVEL=INFO
CHECKS_FILE=checks.yaml
INCIDENTS_FILE=incidents.md
TEMPLATE_FILE=index.html.theme
HISTORY_TEMPLATE_FILE=history.html.theme
STATUS_HISTORY_FILE=history.json"><pre><code>CHECK_INTERVAL=30
MAX_HISTORY_ENTRIES=100
LOG_LEVEL=INFO
CHECKS_FILE=checks.yaml
INCIDENTS_FILE=incidents.md
TEMPLATE_FILE=index.html.theme
HISTORY_TEMPLATE_FILE=history.html.theme
STATUS_HISTORY_FILE=history.json
</code></pre></div>
</li>
<li>
<p dir="auto">Edit the <code>checks.yaml</code> file to add or modify the services you want to monitor. Example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="- name: GitHub Home
  type: http
  host: https://github.com
  expected_code: 200

- name: Google DNS
  type: ping
  host: 8.8.8.8

- name: Database
  type: port
  host: db.example.com
  port: 5432"><pre>- <span>name</span>: <span>GitHub Home</span>
  <span>type</span>: <span>http</span>
  <span>host</span>: <span>https://github.com</span>
  <span>expected_code</span>: <span>200</span>

- <span>name</span>: <span>Google DNS</span>
  <span>type</span>: <span>ping</span>
  <span>host</span>: <span>8.8.8.8</span>

- <span>name</span>: <span>Database</span>
  <span>type</span>: <span>port</span>
  <span>host</span>: <span>db.example.com</span>
  <span>port</span>: <span>5432</span></pre></div>
</li>
<li>
<p dir="auto">(Optional) Customize the <code>incidents.md</code> file to add any known incidents or maintenance schedules.</p>
</li>
<li>
<p dir="auto">(Optional) Modify the <code>index.html.theme</code> and <code>history.html.theme</code> files to customize the look and feel of your status pages.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Run the TinyStatus script:</p>

</li>
<li>
<p dir="auto">The script will generate two HTML files:</p>
<ul dir="auto">
<li><code>index.html</code>: The main status page</li>
<li><code>history.html</code>: The status history page</li>
</ul>
</li>
<li>
<p dir="auto">To keep the status page continuously updated, you can run the script in the background:</p>
<ul dir="auto">
<li>On Unix-like systems (Linux, macOS):
<div data-snippet-clipboard-copy-content="nohup python tinystatus.py &amp;"><pre><code>nohup python tinystatus.py &amp;
</code></pre></div>
</li>
<li>On Windows, you can use the Task Scheduler to run the script at startup.</li>
</ul>
</li>
<li>
<p dir="auto">Serve the generated HTML files using your preferred web server (e.g., Apache, Nginx, or a simple Python HTTP server for testing).</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Customization</h2><a id="user-content-customization" aria-label="Permalink: Customization" href="#customization"></a></p>
<ul dir="auto">
<li>Adjust the configuration variables in the <code>.env</code> file to customize the behavior of TinyStatus.</li>
<li>Customize the appearance of the status page by editing the CSS in <code>index.html.theme</code> and <code>history.html.theme</code>.</li>
<li>Add or remove services by modifying the <code>checks.yaml</code> file.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions are welcome! Please feel free to submit a Pull Request.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is open source and available under the <a href="https://github.com/harsxv/tinystatus/blob/master/LICENSE">MIT License</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Laminar – Open-Source DataDog + PostHog for LLM Apps, Built in Rust (166 pts)]]></title>
            <link>https://github.com/lmnr-ai/lmnr</link>
            <guid>41451698</guid>
            <pubDate>Wed, 04 Sep 2024 22:52:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/lmnr-ai/lmnr">https://github.com/lmnr-ai/lmnr</a>, See on <a href="https://news.ycombinator.com/item?id=41451698">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://www.ycombinator.com/companies/laminar-ai" rel="nofollow"><img src="https://camo.githubusercontent.com/3bf938994198a5b1d850adab39ba81e5675045b3b2b496b9856ce7b833eae93a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f59253230436f6d62696e61746f722d5332342d6f72616e6765" alt="Static Badge" data-canonical-src="https://img.shields.io/badge/Y%20Combinator-S24-orange"></a>
<a href="https://x.com/lmnrai" rel="nofollow"><img src="https://camo.githubusercontent.com/7217689996b50018699ee10564c16fa62744b484f8ab968cfcd2b4b992212b15/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6c6d6e726169" alt="X (formerly Twitter) Follow" data-canonical-src="https://img.shields.io/twitter/follow/lmnrai"></a>
<a href="https://discord.gg/nNFUUDAKub" rel="nofollow"> <img src="https://camo.githubusercontent.com/3c567c02e658b3bbc878a42c214883dc7706c5206ceea744dd66138c5b9e348f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6f696e5f446973636f72642d3436343634363f266c6f676f3d646973636f7264266c6f676f436f6c6f723d353836354632" alt="Static Badge" data-canonical-src="https://img.shields.io/badge/Join_Discord-464646?&amp;logo=discord&amp;logoColor=5865F2"> </a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Laminar - Open-Source observability, analytics, evals and prompt chains for complex LLM apps.</h2><a id="user-content-laminar---open-source-observability-analytics-evals-and-prompt-chains-for-complex-llm-apps" aria-label="Permalink: Laminar - Open-Source observability, analytics, evals and prompt chains for complex LLM apps." href="#laminar---open-source-observability-analytics-evals-and-prompt-chains-for-complex-llm-apps"></a></p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/14181915/364260202-88e1f801-1dbf-4e5b-af71-1a3923661cd1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MTgxMDIsIm5iZiI6MTcyNTUxNzgwMiwicGF0aCI6Ii8xNDE4MTkxNS8zNjQyNjAyMDItODhlMWY4MDEtMWRiZi00ZTViLWFmNzEtMWEzOTIzNjYxY2QxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDA2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYyYTBmYjliYjg1YjAzYWJmY2IyZTBhMGIzNDRhMGFjNTdmZmMxODQ1MDliZGRkOWE2ZDdjOWY4YzQxMzQzMmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7I9SrNoGGdke9Vnw-RjlOeneRQgabGyiRu8uDYQadi4"><img width="1439" alt="traces" src="https://private-user-images.githubusercontent.com/14181915/364260202-88e1f801-1dbf-4e5b-af71-1a3923661cd1.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjU1MTgxMDIsIm5iZiI6MTcyNTUxNzgwMiwicGF0aCI6Ii8xNDE4MTkxNS8zNjQyNjAyMDItODhlMWY4MDEtMWRiZi00ZTViLWFmNzEtMWEzOTIzNjYxY2QxLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA5MDUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwOTA1VDA2MzAwMlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYyYTBmYjliYjg1YjAzYWJmY2IyZTBhMGIzNDRhMGFjNTdmZmMxODQ1MDliZGRkOWE2ZDdjOWY4YzQxMzQzMmYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7I9SrNoGGdke9Vnw-RjlOeneRQgabGyiRu8uDYQadi4"></a>
<p dir="auto">Think of it as DataDog + PostHog for LLM apps.</p>
<ul dir="auto">
<li>OpenTelemetry-based instrumentation: automatic for LLM / vector DB calls with just 2 lines of code + decorators to track functions (powered by an amazing <a href="https://github.com/traceloop/openllmetry">OpenLLMetry</a> open-source package by TraceLoop).</li>
<li>Semantic events-based analytics. Laminar hosts background job queues of LLM pipelines. Outputs of those pipelines are turned into metrics. For example, you can design a pipeline which extracts "my AI drive-through agent made an upsell" data, and track this metric in Laminar.</li>
<li>Built for scale with a modern stack: written in Rust, RabbitMQ for message queue, Postgres for data, Clickhouse for analytics</li>
<li>Insightful, fast dashboards for traces / spans / events</li>
</ul>
<p dir="auto">Read the <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a>.</p>
<p dir="auto">This is a work in progress repo and it will be frequently updated.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Laminar Cloud</h3><a id="user-content-laminar-cloud" aria-label="Permalink: Laminar Cloud" href="#laminar-cloud"></a></p>
<p dir="auto">The easiest way to get started is with a generous free tier on our managed platform -&gt; <a href="https://www.lmnr.ai/" rel="nofollow">lmnr.ai</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-hosting with Docker compose</h3><a id="user-content-self-hosting-with-docker-compose" aria-label="Permalink: Self-hosting with Docker compose" href="#self-hosting-with-docker-compose"></a></p>
<p dir="auto">Start local version with docker compose.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:lmnr-ai/lmnr
cd lmnr
docker compose up"><pre>git clone git@github.com:lmnr-ai/lmnr
<span>cd</span> lmnr
docker compose up</pre></div>
<p dir="auto">This will spin up the following containers:</p>
<ul dir="auto">
<li>app-server – the core app logic, backend, and the LLM proxies</li>
<li>rabbitmq – message queue for sending the traces and observations reliably</li>
<li>qdrant – vector database</li>
<li>semantic-search-service – service for interacting with qdrant and embeddings</li>
<li>frontend – the visual front-end dashboard for interacting with traces</li>
<li>postgres – the database for all the application data</li>
<li>clickhouse – columnar OLAP database for more efficient event and trace analytics</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Instrumenting Python code</h3><a id="user-content-instrumenting-python-code" aria-label="Permalink: Instrumenting Python code" href="#instrumenting-python-code"></a></p>
<p dir="auto">First, create a project and generate a Project API Key. Then,</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install lmnr
echo &quot;LMNR_PROJECT_API_KEY=<YOUR_PROJECT_API_KEY>&quot; >> .env"><pre>pip install lmnr
<span>echo</span> <span><span>"</span>LMNR_PROJECT_API_KEY=&lt;YOUR_PROJECT_API_KEY&gt;<span>"</span></span> <span>&gt;&gt;</span> .env</pre></div>
<p dir="auto">To automatically instrument LLM calls of popular frameworks and LLM provider libraries just add</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L
L.initialize(project_api_key=&quot;<LMNR_PROJECT_API_KEY>&quot;)"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>
<span>L</span>.<span>initialize</span>(<span>project_api_key</span><span>=</span><span>"&lt;LMNR_PROJECT_API_KEY&gt;"</span>)</pre></div>
<p dir="auto">In addition to automatic instrumentation, we provide a simple <code>@observe()</code> decorator, if you want to trace inputs / outputs of functions</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example</h4><a id="user-content-example" aria-label="Permalink: Example" href="#example"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
from openai import OpenAI

from lmnr import observe, Laminar as L
L.initialize(project_api_key=&quot;<LMNR_PROJECT_API_KEY>&quot;)

client = OpenAI(api_key=os.environ[&quot;OPENAI_API_KEY&quot;])

@observe()  # annotate all functions you want to trace
def poem_writer(topic=&quot;turbulence&quot;):
    prompt = f&quot;write a poem about {topic}&quot;
    response = client.chat.completions.create(
        model=&quot;gpt-4o&quot;,
        messages=[
            {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a helpful assistant.&quot;},
            {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt},
        ],
    )
    poem = response.choices[0].message.content
    return poem

if __name__ == &quot;__main__&quot;:
    print(poem_writer(topic=&quot;laminar flow&quot;))"><pre><span>import</span> <span>os</span>
<span>from</span> <span>openai</span> <span>import</span> <span>OpenAI</span>

<span>from</span> <span>lmnr</span> <span>import</span> <span>observe</span>, <span>Laminar</span> <span>as</span> <span>L</span>
<span>L</span>.<span>initialize</span>(<span>project_api_key</span><span>=</span><span>"&lt;LMNR_PROJECT_API_KEY&gt;"</span>)

<span>client</span> <span>=</span> <span>OpenAI</span>(<span>api_key</span><span>=</span><span>os</span>.<span>environ</span>[<span>"OPENAI_API_KEY"</span>])

<span>@<span>observe</span>()  <span># annotate all functions you want to trace</span></span>
<span>def</span> <span>poem_writer</span>(<span>topic</span><span>=</span><span>"turbulence"</span>):
    <span>prompt</span> <span>=</span> <span>f"write a poem about <span><span>{</span><span>topic</span><span>}</span></span>"</span>
    <span>response</span> <span>=</span> <span>client</span>.<span>chat</span>.<span>completions</span>.<span>create</span>(
        <span>model</span><span>=</span><span>"gpt-4o"</span>,
        <span>messages</span><span>=</span>[
            {<span>"role"</span>: <span>"system"</span>, <span>"content"</span>: <span>"You are a helpful assistant."</span>},
            {<span>"role"</span>: <span>"user"</span>, <span>"content"</span>: <span>prompt</span>},
        ],
    )
    <span>poem</span> <span>=</span> <span>response</span>.<span>choices</span>[<span>0</span>].<span>message</span>.<span>content</span>
    <span>return</span> <span>poem</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>print</span>(<span>poem_writer</span>(<span>topic</span><span>=</span><span>"laminar flow"</span>))</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Sending events</h4><a id="user-content-sending-events" aria-label="Permalink: Sending events" href="#sending-events"></a></p>
<p dir="auto">You can send events in two ways:</p>
<ul dir="auto">
<li><code>.event(name, value)</code> – instant event with a value.</li>
<li><code>.evaluate_event(name, evaluator, data)</code> –  event that is evaluated by evaluator pipeline based on the data.</li>
</ul>
<p dir="auto">Note that to run an evaluate event, you need to crate an evaluator pipeline and create a target version for it.</p>
<p dir="auto">Laminar processes background job queues of pipeline processes and records outputs of pipelines as events.</p>
<p dir="auto">Read our <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a> to learn more about event types and how they are created and evaluated.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L
# ...
poem = response.choices[0].message.content

# this will register True or False value with Laminar
L.event(&quot;topic alignment&quot;, topic in poem)

# this will run the pipeline `check_wordy` with `poem` set as the value
# of `text_input` node, and write the result as an event with name
# &quot;excessive_wordiness&quot;
L.evaluate_event(&quot;excessive_wordiness&quot;, &quot;check_wordy&quot;, {&quot;text_input&quot;: poem})"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>
<span># ...</span>
<span>poem</span> <span>=</span> <span>response</span>.<span>choices</span>[<span>0</span>].<span>message</span>.<span>content</span>

<span># this will register True or False value with Laminar</span>
<span>L</span>.<span>event</span>(<span>"topic alignment"</span>, <span>topic</span> <span>in</span> <span>poem</span>)

<span># this will run the pipeline `check_wordy` with `poem` set as the value</span>
<span># of `text_input` node, and write the result as an event with name</span>
<span># "excessive_wordiness"</span>
<span>L</span>.<span>evaluate_event</span>(<span>"excessive_wordiness"</span>, <span>"check_wordy"</span>, {<span>"text_input"</span>: <span>poem</span>})</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Laminar pipelines as prompt chain managers</h4><a id="user-content-laminar-pipelines-as-prompt-chain-managers" aria-label="Permalink: Laminar pipelines as prompt chain managers" href="#laminar-pipelines-as-prompt-chain-managers"></a></p>
<p dir="auto">You can create Laminar pipelines in the UI and manage chains of LLM calls there.</p>
<p dir="auto">After you are ready to use your pipeline in your code, deploy it in Laminar by selecting the target version for the pipeline.</p>
<p dir="auto">Once your pipeline target is set, you can call it from Python in just a few lines.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lmnr import Laminar as L

L.initialize('<YOUR_PROJECT_API_KEY>')

result = l.run(
    pipeline = 'my_pipeline_name',
    inputs = {'input_node_name': 'some_value'},
    # all environment variables
    env = {'OPENAI_API_KEY': 'sk-some-key'},
)"><pre><span>from</span> <span>lmnr</span> <span>import</span> <span>Laminar</span> <span>as</span> <span>L</span>

<span>L</span>.<span>initialize</span>(<span>'&lt;YOUR_PROJECT_API_KEY&gt;'</span>)

<span>result</span> <span>=</span> <span>l</span>.<span>run</span>(
    <span>pipeline</span> <span>=</span> <span>'my_pipeline_name'</span>,
    <span>inputs</span> <span>=</span> {<span>'input_node_name'</span>: <span>'some_value'</span>},
    <span># all environment variables</span>
    <span>env</span> <span>=</span> {<span>'OPENAI_API_KEY'</span>: <span>'sk-some-key'</span>},
)</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Learn more</h2><a id="user-content-learn-more" aria-label="Permalink: Learn more" href="#learn-more"></a></p>
<p dir="auto">To learn more about instrumenting your code, check out our client libraries:</p>
<p dir="auto"><a href="https://www.npmjs.com/package/@lmnr-ai/lmnr" rel="nofollow"> <img src="https://camo.githubusercontent.com/6b3081997512b3addac3266d3dcaa06d9fe0cfdc9d34a7b64f56c68ee0e10398/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f2534306c6d6e722d61692532466c6d6e723f6c6162656c3d6c6d6e72266c6f676f3d6e706d266c6f676f436f6c6f723d434233383337" alt="NPM Version" data-canonical-src="https://img.shields.io/npm/v/%40lmnr-ai%2Flmnr?label=lmnr&amp;logo=npm&amp;logoColor=CB3837"> </a>
<a href="https://pypi.org/project/lmnr/" rel="nofollow"> <img src="https://camo.githubusercontent.com/667df376d1224a1681f52ee5b358b52d73094911caecd6bcfa5fd55e6622df40/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6c6d6e723f6c6162656c3d6c6d6e72266c6f676f3d70797069266c6f676f436f6c6f723d333737354139" alt="PyPI - Version" data-canonical-src="https://img.shields.io/pypi/v/lmnr?label=lmnr&amp;logo=pypi&amp;logoColor=3775A9"> </a></p>
<p dir="auto">To get deeper understanding of the concepts, follow on to the <a href="https://docs.lmnr.ai/" rel="nofollow">docs</a> and <a href="https://docs.lmnr.ai/tutorials" rel="nofollow">tutorials</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lesser known parts of Python standard library – Trickster Dev (156 pts)]]></title>
            <link>https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/</link>
            <guid>41450824</guid>
            <pubDate>Wed, 04 Sep 2024 21:07:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/">https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/</a>, See on <a href="https://news.ycombinator.com/item?id=41450824">Hacker News</a></p>
Couldn't get https://www.trickster.dev/post/lesser-known-parts-of-python-standard-library/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Archive loses appeal over eBook lending (197 pts)]]></title>
            <link>https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</link>
            <guid>41449229</guid>
            <pubDate>Wed, 04 Sep 2024 18:56:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending">https://www.theverge.com/2024/9/4/24235958/internet-archive-loses-appeal-ebook-lending</a>, See on <a href="https://news.ycombinator.com/item?id=41449229">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Internet Archive has lost its appeal in a fight to lend out scanned ebooks without the approval of publishers. In a <a href="https://www.documentcloud.org/documents/25091194-internet-archive-appeal?responsive=1&amp;title=1">decision on Wednesday</a>, the Second Circuit Court of Appeals ruled that permitting the Internet Archive’s digital library would “allow for widescale copying that deprives creators of compensation and diminishes the incentive to produce new works.”</p><p>The decision is another blow to the nonprofit in the <em>Hachette v. Internet Archive</em> case. In 2020, four major publishers — Hachette, Penguin Random House, Wiley, and HarperCollins — <a href="https://www.theverge.com/2020/6/1/21277036/internet-archive-publishers-lawsuit-open-library-ebook-lending">sued the Internet Archive</a> over claims its digital library constitutes “willful digital piracy on an industrial scale.”</p><p>The Internet Archive has long offered a system called the Open Library, where users can “check out” digital scans of physical books. The library was based on a principle called controlled digital lending, where each loan corresponds to a physically purchased book held in a library — avoiding, in theory, a piracy claim. It’s a fundamentally different system from programs like OverDrive, where publishers sell limited-time licenses to ebooks on their own terms.</p><p>However, the Internet Archive <a href="https://blog.archive.org/2020/03/30/internet-archive-responds-why-we-released-the-national-emergency-library/">expanded its library project during the covid-19 pandemic</a>. It launched the National Emergency Library, allowing an unlimited number of people to access the same copies of ebooks. That’s when the publishers banded together to file the lawsuit, targeting both online libraries.</p><p>The Second Circuit Court’s decision acknowledges the benefits and drawbacks of the Internet Archive’s digital library in its decision. But it ultimately sides with publishers:</p><div><blockquote><p>On the one hand, eBook licensing fees may impose a burden on libraries and reduce access to creative work. On the other hand, authors have a right to be compensated in connection with the copying and distribution of their original creations. Congress balanced these “competing claims upon the public interest” in the Copyright Act. We must uphold that balance here.</p></blockquote></div><div><p>Last year, <a href="https://www.theverge.com/2023/3/24/23655804/internet-archive-hatchette-publisher-ebook-library-lawsuit">a federal judge ruled that the Internet Archive</a> doesn’t have the right to scan and lend out books in the same way a library would. The Internet Archive later <a href="https://www.theverge.com/2023/9/11/23868870/internet-archive-hachette-open-library-copyright-lawsuit-appeal">appealed that decision</a>. </p></div><p>“We are disappointed in today’s opinion about the Internet Archive’s digital lending of books that are available electronically elsewhere,” Chris Freeland, the director of library services at the Internet Archive, <a href="https://blog.archive.org/2024/09/04/internet-archive-responds-to-appellate-opinion/">writes in a post on the site</a>. “We are reviewing the court’s opinion and will continue to defend the rights of libraries to own, lend, and preserve books.” Freeland also <a href="https://www.change.org/p/let-readers-read-an-open-letter-to-the-publishers-in-hachette-v-internet-archive?utm_medium=custom_url&amp;utm_source=share_petition&amp;recruited_by_id=eb10e620-2915-11ef-99de-71750e499499">points to a petition</a> you can sign to restore access to the 500,000 books publishers restricted access to.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi: Announcing The Assistant (454 pts)]]></title>
            <link>https://blog.kagi.com/announcing-assistant</link>
            <guid>41448985</guid>
            <pubDate>Wed, 04 Sep 2024 18:35:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/announcing-assistant">https://blog.kagi.com/announcing-assistant</a>, See on <a href="https://news.ycombinator.com/item?id=41448985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <div>
  <p>
    <iframe width="800" height="450" src="https://www.youtube-nocookie.com/embed/0cMcOtVQUkE?si=0cMcOtVQUkE&amp;rel=0&amp;vq=hd1080" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
  </p>
</div>
<p><em>Yes, the rumours are true!</em></p>

<p>Kagi has been thoughtfully integrating AI into our search experience, creating a smarter, faster, and more intuitive search. This includes <a href="https://help.kagi.com/kagi/ai/quick-answer.html">Quick Answer</a> which delivers knowledge instantly for many searches (can be activated by appending ? to the end of your searches), <a href="https://help.kagi.com/kagi/ai/summarize-page.html">Summarize Page</a> for the quick highlights of a web page, and even the ability to <a href="https://help.kagi.com/kagi/ai/ask-questions.html">ask questions about a web page</a> in your search results. And all of these features are on-demand and ready when you need them.</p>

<p>Today we’re excited to unveil the Assistant by Kagi.  A user friendly Assistant that has everything you want and none of the things you don’t (such as user data harvesting, ads &amp; tracking).  Major features include:</p>

<ul>
<li>Integration with Kagi’s legendary quality search results<br>
</li>
<li>Choice of leading LLM models from all the leading providers (OpenAI, Anthropic, Google, Mistral, …)<br>
</li>
<li>Powerful Custom Assistants that include your own custom instructions, choice of leading models, and tools like search and internet access<br>
</li>
<li>Mid-thread editing and branching for making the most of your conversations without starting over<br>
</li>
<li>All threads are private by default, retained only as long as you want and subscriber data is not used for training models.</li>
</ul>

<h2>Powered by Kagi Search</h2>

<p>Kagi Assistant has the ability to use Kagi Search to source the highest quality information meaning that its responses are grounded in the most up-to-date factual information while disregarding most “spam” and “made for advertising” sites with our unique ranking algorithm and user search personalizations on top.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-334029-upload-5b01ebb868ee82236b769125e19d2b10.png" alt="image">
</p><center><em>Assistant with References</em></center>

<h2>Choice of Best Models</h2>

<p>Kagi Assistant provides the best in class capabilities for coding, information retrieval, problem solving, brainstorming, creative writing, and other LLM applications by leveraging the finest LLM models available. You can select from any model and switch whenever you like. The Assistant can always make use of the latest models as they become available. In addition, you can decide whether to give the model web access (via Kagi Search) or you want to use the model in ‘raw’ mode.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361807-99305-upload-0c181df6fd10988592f870adcabf9142.png" alt="image">
</p><center><em>Model Selection</em></center>

<h2>Powerful Custom Assistants</h2>

<p>LLMs are incredibly flexible tools you can use for many tasks.  With Kagi’s Custom Assistants you can build a tool that meets your exact needs.  For example you may be a car enthusiast and are looking for advice about your VW Bus.</p>

<p>You could create a Custom Assistant to help with the myriad of questions a owner of a classic vehicle might have.  Start by naming your Custom Assistant and select the tools and options.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725389662-205507-image.png" alt="image">
</p><center><em>Custom Assistant Options</em></center>

<p><br>
Then give the Custom Assistant context and clear instructions on how it should respond.  In this case providing relevant details on your car and guidelines for the advice.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389665-535788-image2.png" alt="image">
<em></em></p><center><em>Custom Assistant Instructions</em></center>

<p>Use the Custom Assistant to get the answers you need with the context and instructions provided.  Here the model provides relevant advice on diagnosing a oil leak.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725389839-290214-image3.png" alt="image">
<em></em></p><center><em>Using Custom Assistant</em></center>

<h2>Mid-Thread Editing and Branching</h2>

<p>Any LLM user has seen that sometimes they can get data wrong, hallucinate or just become confused.  Or we might want to refine our prompt as we see how a model responds. For instance if you’re interested in understanding how to handle imbalanced data sets you might ask Assistant:</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-569146-upload-744debb8ceb4547fd753110a30e3c18a.png" alt="image"></p>

<center><em>Starting a Thread</em></center>


<p>The response is correct, but a little too generic; you can edit the question and add that you’re working on a binary classification problem to get a more specific answer.  You could even switch the model or turn on/off web access.<br>
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-385380-upload-5a8180e572dc07ebe4ac4c8be278b5fc.png" alt="image">
</p><center><em>Editing the Prompt to add Specifics</em></center>

<p><br>
Clarifying the question yields much more useful advice but if it didn’t you could just go back to the original branch and continue on.</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725361806-284938-upload-baca920305f0b650338782e0d3e109a3.png" alt="image"></p>

<center><em>Updated Answer with New Detail &amp; Branch Navigation</em></center>

<h2>Private by Default</h2>

<p>We know many of you are concerned about what AI companies may be doing with your data. According to a <a href="https://www.pewresearch.org/internet/2023/10/18/how-americans-view-data-privacy/">survey by the Pew Research Center</a> about 80% of people “familiar with AI say its use by companies will lead to people’s personal information being used in ways they won’t be comfortable with (81%) or that weren’t originally intended (80%)” and “Among those who’ve heard about AI, 70% have little to no trust in companies to make responsible decisions about how they use it in their products.”</p>

<p><img src="https://kagifeedback.org/assets/files/2024-09-03/1725386335-668027-pi-20231018-data-privacy-0-04.webp"></p>



<p>Kagi is committed to protecting your information. Your threads automatically expire and are deleted according to your settings (default is after 24 hours) and you can choose to save threads you really need for later.  This approach helps not only with protecting your data, but with managing the thread clutter as well.
<img src="https://kagifeedback.org/assets/files/2024-09-03/1725391573-898057-screenshot-2024-09-03-at-122557.png" alt="image">
</p><center><em>Thread Saving Settings</em></center>


<p>Since we don’t show ads (and never will) and don’t train on subscriber data there’s no reason for us to harvest your data, track your clicks, searches, threads, or build a profile of you.  When we use third party models via their APIs it is protected under terms of service that forbid using data for training their models (e.g. <a href="https://support.anthropic.com/en/articles/7996885-how-do-you-use-personal-data-in-model-training">Anthropic Terms</a> &amp; <a href="https://ai.google.dev/gemini-api/terms#data-use-paid">Google Terms</a>).</p>

<h2>Pricing &amp; Availability</h2>

<p>The Assistant by Kagi is available today as part of the Kagi Ultimate Plan for $25 per month, which also includes full access to Kagi Search. Discount available for annual subscriptions.  <a href="https://kagi.com/">Learn more at Kagi.com</a>.</p>

<h2>FAQ:</h2>

<p><strong>Q:</strong> Can I try out Assistant today?<br>
<strong>A:</strong> Yes, the Assistant is generally available today to all Kagi Ultimate tier members   You can create an account today to try it out and cancel at any time with no long term commitments.</p>

<p><strong>Q:</strong> Is the Assistant available in Kagi’s Starter or Professional tier?<br>
<strong>A:</strong> As of today the Assistant is only available on our Ultimate tier (and Family plan members upgraded to Ultimate tier).  We are always looking for ways to provide more value to our members and are evaluating how we can offer Assistant to the Starter and Professional tiers.</p>

<p><strong>Q:</strong> What are the LLM limitations in place?<br>
<strong>A:</strong> The Assistant currently has no hard limits on usage. We would like it to stay unlimited and will be monitoring this actively. Please do not abuse so everyone can enjoy no-limit access. Provider APIs may have limitations in place.</p>

<p><strong>Q:</strong> Does the Assistant have file upload capability?<br>
<strong>A:</strong> The Assistant will have file upload capabilities very soon (work in progress). You can still access beta version that had it using <a href="https://kagi.com/v1_assistant">this link</a>.</p>

<p><strong>Q:</strong> I found a bug in Assistant, how do I report it?<br>
<strong>A:</strong> Please report all bugs and feature suggestions using <a href="https://kagifeedback.org/">Kagi Feedback</a>.</p>

<p><strong>Q:</strong> What is Kagi’s overall strategy about using LLMs in search?<br>
<strong>A:</strong> We are continuing to relentlessly focus on the core search experience and build thoughtfully integrated features on top of it. Read more about it in our <a href="https://blog.kagi.com/what-is-next-for-kagi#8">recent blog post</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon bans its drivers from moving their own lips too much at work (233 pts)]]></title>
            <link>https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio</link>
            <guid>41448866</guid>
            <pubDate>Wed, 04 Sep 2024 18:24:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio">https://www.freightwaves.com/news/should-truckers-be-allowed-to-sing-along-with-the-radio</a>, See on <a href="https://news.ycombinator.com/item?id=41448866">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Welcome to the WHAT THE TRUCK?!? <a href="https://freightwaves.com/wtt">Newsletter</a> presented by <a href="https://truckstop.com/">Truckstop.</a> In this issue, inward dash cams penalize singing?; Flexport’s last supper&nbsp; and more.</p><div id="omeda-post-content">


<p><strong><a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/"><img decoding="async" width="624" height="219" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfeqfTVpWUk21h2Q1tzZ2gnQ3rEpUf21aEPBc1uLi3zgU9zmIcn6ug9SOj4wilNOJ7dt2kENHbS6yc5NHTR2cOtbfQ7s08vy-f_we-b6QaByzackminnfD7qyd1nlaprMXomAZM0zHCEveQm-VW_jBorF4?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong><br><a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/">Reddit</a></p>







<p><strong>Big brother — </strong>Amazon Delivery Service Partner (DSP) drivers on <a href="https://www.reddit.com/r/AmazonDSPDrivers/comments/1f2y2cp/try_to_tell_me_when_i_can_move_my_own_mouth_im_out/">Reddit</a> are furious over a new set of standards the company is imposing on them in regards to their inward facing dash cams.&nbsp;<br></p>



<p>According to a number of Redditors as well as drivers that I’ve confirmed with, Amazon is trying to crack down on distracted driving. Now, some of those partners are being warned that singing along with the radio will trigger the inward facing camera in their cab.&nbsp;<br></p>



<div><p>Why? A new update to their Netradyne systems has advanced the scope of how it detects eye and mouth movement.&nbsp;</p><p>Amazon’s <a href="https://hiring.amazon.com/job-opportunities/delivery-driver-jobs#/">website</a> describes their DSP program as “an independent third-party business.” However, that level of independence is under question after these latest measures that are proving to be very unpopular.</p></div>



<p><img loading="lazy" decoding="async" width="624" height="160" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcw-BIe6ZT0I8oHvFr4xjaiJ4nzqwlGXKY4hjNVhTJ3sgXytyfxhs_ZGqeYM2hfKN9IoaPVSuS87AAzV7SLQRBPwgiSuO60zaMTzRF2Nh4f6XE-crvaxLWCM3btBkPtC1rdoh1j1S8zbi1LlQCKZlDooAws?key=lGXafURkKN6DLhpG9BhIMQ"><br></p>



<div><p><strong>Shake it off — </strong>Does anyone really believe that singing distracts drivers or is this a case of AI and surveillance overstepping its bounds? For me personally, hitting the high notes on a Whitney song energizes me and keeps me between the white lines.</p><p>I asked my network that is almost entirely composed of supply chain or supply chain adjacent followers what they thought about the issue. Over <a href="https://x.com/TimothyDooner/status/1829146707290169433">94% of X</a> users and <a href="https://www.linkedin.com/posts/timothydooner_should-truck-drivers-be-allowed-to-sing-along-activity-7234913956052553729-YVBg?utm_source=share&amp;utm_medium=member_desktop">97% of LinkedIn</a> users believe that drivers should be allowed to croon.</p></div>



<p><strong>Here’s what some truckers had to say:</strong><br></p>



<p><a href="https://x.com/EdMapes1/status/1829148133286388110">Ed Mapes</a> – It helps us stay focused and awake.<br></p>



<div><p><a href="https://x.com/NewTruckerMike/status/1829167209194893782">New Trucker Mike</a> – I rock, ska, and country my way all over the highways. Go ahead and try to stop me.</p></div>



<p><img loading="lazy" decoding="async" width="624" height="124" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXeosLmqqn3FS87EV7nzxRwVieeYSniqPpPaQg5LPGrgzu-vTDJfEi54zrbU3wBt_xk2ENsF5v4Oa09-c4GVgywzgYBE76f2zRZ56zUGaXCkIGbfbOsFSjoOERsWc6e1qLwP9q7tskCUk_ty7SZIEFDSqRI?key=lGXafURkKN6DLhpG9BhIMQ"></p>



<p><a href="https://x.com/TommyApples80/status/1829188060904349762">X</a>&nbsp;</p>



<p><br><a href="https://x.com/sask_trucker_/status/1829153392448672073">Sask Trucker</a> – If Shania comes on I’m singing.</p>











<p><strong>Data – </strong>Opinions may be anecdotal, but there are studies that have looked at the relationship between music and distracted driving.&nbsp;<br></p>



<p><strong><em>It was concluded that, in some indicators, listening to music has adverse effects on driving. However, in many indicators, music has a positive impact on improving driving safety. It is better to choose appropriate music for different driving conditions and to train the drivers about it. – </em></strong><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10790125/"><strong><em>National Library of Medicine&nbsp;</em></strong></a><br></p>



<p>While there were some negative factors associated with music, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10790125/">the study</a> found that, “Listening to music can enhance not only the driver’s driving quality but also their physiological performance. In particular, listening to music while driving is effective in controlling stress, calming emotions, and preventing driver drowsiness”&nbsp;<br></p>



<div><p><strong>Sound off –</strong>&nbsp; While it probably isn’t likely that Amazon is specifically targeting singing, the end result is the same. What do you think? Should drivers be allowed to sing while behind the wheel? <a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#6b0f0404050e192b0d02190e0819041c0545080406">Email me</a>.&nbsp;</p><p><strong>The last shipper</strong></p></div>



<div><p><img loading="lazy" decoding="async" width="508" height="579" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcpsHkE_RgeXHvYCOaGjY03VQwGZSmBESAf3x1f7QiE0K7CQZcERCkSdVs8wjSvgLXRPg9wAexl1kBfHd2imCM3_30--Pn_Idzq5o0kg7zTJXoQ9fHoMDdkOgsrkKEAFNdJYd1ggHROm7F588fUYgWIm9s?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/typesfast/status/1828925875372593167">X</a></p><p><strong>Controversy – </strong>Flexport’s Ryan Petersen <a href="https://x.com/typesfast/status/1828925875372593167?s=46&amp;t=P3RlHpCY-GJkhcsno3878g">posted</a> his latest AI-generated artwork to X on Wednesday, and it hasn’t been well received by everyone. The image appears to show a number of Flexport executives and apostles celebrating the last supper.</p></div>







<p><strong>“This dude really looked at the bad publicity around the Olympics Opening Ceremony and said ‘I gotta get my company in on that.’ – </strong><a href="https://x.com/Logistorian/status/1828934367877468300"><strong>Logistorian on X</strong></a><br></p>



<p>In July, the Olympic opening ceremony in Paris came under fire when a performance appeared to mock da Vinci’s famous painting “The Last Supper.” The artistic director of that <a href="https://x.com/Olympics/status/1816929100532945380?ref_src=twsrc%5Etfw%7Ctwcamp%5Etweetembed%7Ctwterm%5E1816929100532945380%7Ctwgr%5E9664cca506ae15d2bb810c2b3b24f7734d8bd0b4%7Ctwcon%5Es1_&amp;ref_url=https%3A%2F%2Fwww.snopes.com%2Fnews%2F2024%2F07%2F30%2Folympics-last-supper%2F">said it was a misinterpretation</a>, and instead they were referencing Dionysus, the Greek God of wine and festivity.&nbsp;<br></p>



<div><p>Not everyone accepted that answer, but Petersen’s piece is less ambiguous as it clearly shows Jesus levitating over the table.</p></div>



<div><p><img loading="lazy" decoding="async" width="624" height="145" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfH_MKLlLrWnUlT1XaQJ9e9sOwb-qGgo-ie1NfcvHnSNVDv0gZNOOxqQQlXH8Jl7ayyyVx4AHzrsk-2AJiy36niYjus8SMSNq5EfQ54h2mb-kW2BcXEy-3RIqh51IhhqRB1Gp19pC705VsX7Ywwn2k1Y-Yt?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/Girldad741/status/1829017497875496991">X</a></p><p><strong>The Judas Cradle – </strong>Many of the comments under the image have called it blasphemous or unnecessary. However, a few didn’t mind at all. Petersen may have even sold a few copies of his book, ‘<a href="https://www.amazon.com/Big-Ship-Little-Digger/dp/1667800442">The Big Ship and the Little Digger</a>’ in the process.</p></div>



<div><p><img loading="lazy" decoding="async" width="624" height="108" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfpF-_e7d-e6yiyIHQ4gnfSOMm7YD5u2L-rmZBECvJow-XmLBZNulnI3VEna7r2lK20eGjBT3jflvZW1e6ZEHtRXt9R9frss651dpF7rllUA9lQli3bsbaitpKn1nroozQrFUjSaXgoXQ_aSCoAx4nElELD?key=lGXafURkKN6DLhpG9BhIMQ"><a href="https://x.com/carsjam33/status/1828929385342083252">X</a></p><p>What do you think? Was it a&nbsp; good use of AI or a misguided attempt at marketing? <a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#d0b4bfbfbeb5a290b6b9a2b5b3a2bfa7befeb3bfbd">Email me</a>.</p></div>







<p><strong>Gear for the gals</strong><br></p>



<div><p><img loading="lazy" decoding="async" width="624" height="396" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfgKhBplDWyySYxmA-jKxBx-1BiL3hQ1-Gn4_YTAj0zxePg1b_4xXCrZKzD8OXLoc5m-w_JIFOl87u7efo2hwWRnuaWA0D9qE1cC-2tzsIFK2yYYc6qLEpgZI8MMsRgSL4BncZvB0ODiXBL0_rnkdLK3uhL?key=lGXafURkKN6DLhpG9BhIMQ"><br><strong>Crop top –</strong> Head on over to<strong> </strong><a href="https://wttgear.com/products/rate-the-strap-work-t-shirt">WTTGear.com</a> to get our latest merch! Use code WTTFans for 10% off.</p><p><strong>WTT Friday</strong></p></div>



<p><strong><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdHvGD4P0xxnQXu2Fb6AEP_IWXwbvF6oCKMu_a1XgKFh1FBXhi4PPM46zbOYRLUCSXSTyNo50XqZ2BG63GVGqgXBPhas8Mt6VMt-ZcJDpdcCTy71JeufG8vWq-XtXVdB_OjNDc47Yjs7QO_SK0b0YsckiVk?key=lGXafURkKN6DLhpG9BhIMQ"></strong></p>



<p><strong>How Costco leveraged its supply chain to become the 3rd biggest retailer on Earth —</strong> Friday live at 12 p.m. Eastern, we’re joined by supply chain super consultant Brittain Ladd to talk about how Costco leveraged its supply chain to become the third largest retailer in the world. Nearly one third of Americans count themselves as members and the company is now expanding into East Asia. Ladd shares how Costco is using tech to scale the business even further.<br>&nbsp;</p>



<p>MoLo co-founder and podcaster Andrew Silver returns to the show to talk about the state of the industry and lessons learned from his time in the trenches. We’ll also find out how he’s building his show The Freight Pod and what insights he’s gleaned from top leaders in freight.<br></p>



<div><p>Plus, headlines, weirdness and more.</p><p><strong>Catch new shows live at noon EDT Mondays, Wednesdays and Fridays on FreightWaves </strong><a href="https://www.linkedin.com/company/freightwaves/"><strong>LinkedIn</strong></a><strong>, </strong><a href="https://www.facebook.com/FreightWaves"><strong>Facebook</strong></a><strong>, </strong><a href="https://twitter.com/freightwaves?lang=en"><strong>X</strong></a><strong> or </strong><a href="https://www.youtube.com/c/FreightWaves"><strong>YouTube</strong></a><strong>, or on demand by looking up WHAT THE TRUCK?!? on your favorite podcast player and at 5 p.m. Eastern on SiriusXM’s Road Dog Trucking Channel 146.</strong></p></div>











<p><strong><a href="https://www.freightwaves.com/news/the-logistic-of-death-what-the-truck"><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcL2Xm10RIw2oK3XpuveodDbrPQKZfdXVlNyyUbvMZumm_ka2Ts_toeotavLFbNaGryY27FsAsvDJx9EI1Z2QR0N00fkmJQ5C1ei6PFp8OTEQM32NH6BNFlBV4f8B8hJHDtoSWid1zcbaP9ch6a6puB-vU?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong></p>



<p><strong><a href="https://www.freightwaves.com/news/rail-strike-decision-disastrous-trooper-bens-rules-of-the-road-freight-magic-what-the-truck">Rail strike decision “disastrous”; Trooper Ben’s rules of the road; freight magic</a></strong></p>



<p><strong><a href="https://www.freightwaves.com/news/rail-strike-decision-disastrous-trooper-bens-rules-of-the-road-freight-magic-what-the-truck"><img loading="lazy" decoding="async" width="624" height="351" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfUGgx8Bo7kWDbGgniJEjEdB2wloA2CsBwV3LB27iCDLyI9_X4rGQXaGg1SdBloaMgtZ3J3bUVHGXuSyEJNRDjiZvNtm2G1A6VVqBJDkSp8nqXroq6ehSecCeBUq3YogdVEX8pUtXVCOM1cueKl6rGU9Wwo?key=lGXafURkKN6DLhpG9BhIMQ"></a></strong></p>



<p><strong>The rest of the noise</strong></p>



<ul>
<li><a href="https://www.freightwaves.com/news/hazmat-carrier-sues-dali-shipowners-for-negligence"><strong>Hazmat carrier sues Dali shipowners for negligence</strong></a></li>



<li><a href="https://www.freightwaves.com/news/us-mexico-trade-relations-enter-uncharted-territory-expert-says"><strong>US-Mexico trade relations enter “uncharted territory,” expert says</strong></a></li>



<li><a href="https://www.freightwaves.com/news/impact-minimal-from-canada-rail-shutdown"><strong>Supply chain sees unexpected impact from Canada rail ramp-up</strong></a></li>



<li><a href="https://www.freightwaves.com/news/former-polar-air-cargo-executive-receives-18-month-jail-sentence"><strong>Former Polar Air Cargo executive receives 18-month jail sentence</strong></a></li>



<li><a href="https://www.businessinsider.com/kraft-heinz-ai-lighthouse-helps-forecast-supply-chain-demands-2024-8"><strong>Kraft Heinz is using AI to make more autonomous supply-chain decisions</strong></a></li>
</ul>







<p><strong>Thanks for reading, and feel free to forward this to a friend.</strong></p>



<p><br><a href="https://twitter.com/TimothyDooner"><strong>Tweet @ Dooner</strong></a></p>



<p><a href="https://www.freightwaves.com/cdn-cgi/l/email-protection#3753585859524577515e455254455840591954585a"><strong>Email me</strong></a></p>



<p><a href="https://freightwaves.com/communities"><strong>Subscribe to the newsletter</strong></a></p>







<p><strong>Subscribe to the show</strong></p>



<p><a href="https://podcasts.apple.com/us/podcast/what-the-truck/id1357715797"><strong>Apple Podcasts</strong></a></p>



<p><a href="https://open.spotify.com/show/5X1AlbXLIKJAwwwA059sVd?si=KxAg2SYvS3O6WjK2Ftzt9Q"><strong>Spotify</strong></a></p>



<p><a href="https://www.youtube.com/playlist?list=PLVi2PdlRdiSqmJsM01U1gwAfc_y75q_PW"><strong>YouTube</strong></a></p>



<p><a href="https://www.tiktok.com/@fwwhatthetruck"><strong>TikTok</strong></a></p>



<p><a href="https://twitter.com/FWwhatthetruck"><strong>Twitter</strong></a></p>



<p><strong>Or simply look up WHAT THE TRUCK?!? on your favorite podcast player. Or, if you have SiriusXM, tune in to the show Monday, Wednesday and Friday at 5 p.m. Eastern time on Road Dog Trucking Channel 146.</strong></p>







<p><strong>Exit through the gift shop: </strong><a href="http://wttgear.com/"><strong>WTTGear.com&nbsp;</strong></a></p>







<p><strong>Don’t be a stranger,</strong></p>



<p><strong>Dooner</strong></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS @property and the New Style (499 pts)]]></title>
            <link>https://ryanmulligan.dev/blog/css-property-new-style/</link>
            <guid>41448740</guid>
            <pubDate>Wed, 04 Sep 2024 18:13:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ryanmulligan.dev/blog/css-property-new-style/">https://ryanmulligan.dev/blog/css-property-new-style/</a>, See on <a href="https://news.ycombinator.com/item?id=41448740">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">




<section>
  <div>
    

    <p><span>Posted on <strong>September 2, 2024</strong></span>
  </p></div>
  <div>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="var(--color-text-accent)" viewBox="0 0 256 256"><rect width="256" height="256" fill="none"></rect><circle cx="128" cy="128" r="88" fill="var(--color-theme)"></circle><circle cx="128" cy="128" r="88" fill="none" stroke="var(--color-text-accent)" stroke-miterlimit="10" stroke-width="16"></circle><line x1="128" y1="128" x2="167.6" y2="88.4" fill="none" stroke="var(--color-text-accent)" stroke-linecap="round" stroke-linejoin="round" stroke-width="16"></line><line x1="104" y1="8" x2="152" y2="8" fill="none" stroke="var(--color-text-accent)" stroke-linecap="round" stroke-linejoin="round" stroke-width="16"></line></svg>

    <p><span> Takes about <strong>9 minutes</strong> to read </span>
  </p></div>
</section>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@property"><code>@property</code></a> at-rule recently gained support across all modern browsers, unlocking the ability to explicitly define a syntax, initial value, and inheritance for CSS custom properties. It seems like forever ago that CSS Houdini and its <a href="https://developer.mozilla.org/en-US/docs/Web/API/CSS_Properties_and_Values_API">CSS Properties and Values API</a> were initially introduced. I experimented sparingly over time, reading articles that danced around the concepts, but I had barely scratched the surface of what <code>@property</code> could offer. The ensuing demo explores what's possible in the next generation of CSS.</p>
<h2 id="calls-to-action">Calls to action</h2>
<p>Ever seen those sleek, attention-seeking, shiny call-to-action webpage elements? Waves of sites across the web, especially the ones marketing services and software urging for you to "Upgrade your account" or "Sign up today," have discovered the look and latched on. I'm not here to knock it and admittedly think it's kind of fresh. I thought I'd give that style a try myself. Check out the result in the CodePen below.</p>
<p data-height="500" data-preview="false" data-default-tab="result" data-slug-hash="MWMqXbK" data-user="hexagoncircle">
  <a href="https://codepen.io/hexagoncircle/pen/MWMqXbK??editors=0100">
    
    <span>Open CodePen demo</span>
  </a>
</p>

<p>There's a ton to unpack in this demo. Let's start with that shine looping around the button. Toggle open the demo's CSS panel to find a collection of <code>@property</code> rules related to those custom properties that need to animate. Here's the one defined for the <code>--gradient-angle</code>:</p>
<pre><code><span><span>@property</span> --gradient-angle</span> <span>{</span>
  <span>syntax</span><span>:</span> <span>"&lt;angle&gt;"</span><span>;</span>
  <span>initial-value</span><span>:</span> 0deg<span>;</span>
  <span>inherits</span><span>:</span> <span>false</span><span>;</span>
<span>}</span></code></pre>
<p>The <code>@property</code> rule communicates to the browser that <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/angle"><code>&lt;angle&gt;</code></a> is the allowed syntax for this custom property and its initial value is <code>0deg</code>. This enables the browser to smoothly transition from <code>0deg</code> to <code>360deg</code> and output a rotating gradient.</p>
<pre><code><span><span>@keyframes</span> rotate-gradient</span> <span>{</span>
  <span>to </span><span>{</span> <span>--gradient-angle</span><span>:</span> 360deg<span>;</span> <span>}</span>
<span>}</span>

<span>.rotate-gradient </span><span>{</span>
  <span>background</span><span>:</span> <span>conic-gradient</span><span>(</span>from <span>var</span><span>(</span>--gradient-angle<span>)</span><span>,</span> transparent<span>,</span> black<span>)</span><span>;</span>
  <span>animation</span><span>:</span> rotate-gradient 10s linear infinite<span>;</span>
<span>}</span></code></pre>
<p>I put together a simple gradient spin demo to focus on the handful of lines necessary to render this concept.</p>
<p data-height="300" data-preview="true" data-default-tab="result" data-slug-hash="eYwLqJx" data-user="hexagoncircle">
  <a href="https://codepen.io/hexagoncircle/pen/eYwLqJx">
    
    <span>Open CodePen demo</span>
  </a>
</p>

<p>We can achieve the shiny animated border effect by evolving this code a bit. We'll introduce a <code>linear-gradient</code> as the first value of the element's <code>background</code> property and set a <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/background-origin"><code>background-origin</code></a> to each value.</p>
<ul>
<li>The origin of the <code>linear-gradient</code> is set to <code>padding-box</code>. This prevents the gradient from spilling into the border area.</li>
<li>The <code>conic-gradient</code> origin is set to <code>border-box</code>. This gradient overflows into the space created by the border width.</li>
<li>To reveal the rotating <code>conic-gradient</code>, a single-pixel transparent border is added.</li>
</ul>
<pre><code><span>.border-gradient </span><span>{</span>
  <span>background</span><span>:</span> 
    <span>linear-gradient</span><span>(</span>black<span>,</span> black<span>)</span> padding-box<span>,</span>
    <span>conic-gradient</span><span>(</span>from <span>var</span><span>(</span>--gradient-angle<span>)</span><span>,</span> transparent 25%<span>,</span> white<span>,</span> transparent 50%<span>)</span> border-box<span>;</span>
  <span>border</span><span>:</span> 1px solid transparent<span>;</span>
<span>}</span></code></pre>
<p>In the CSS panel of the <a href="#cp_embed_eYwLqJx">simple gradient spin demo</a>, uncomment the <code>.border-gradient</code> ruleset to reveal the shiny animated border. Looking pretty slick! For more examples, I've included a bunch of animated gradient border articles in the <a href="#helpful-resources">resources section</a> at the end of the post.</p>
<h2 id="silky-smooth-hover-transitions">Silky smooth hover transitions</h2>
<p>A few special ingredients help facilitate a buttery smooth gradient transition when the element is hovered. Let's dig into its <code>background</code> values:</p>
<pre><code><span>.shiny-cta </span><span>{</span>
  <span>background</span><span>:</span> 
    <span>linear-gradient</span><span>(</span><span>var</span><span>(</span>--shiny-cta-bg<span>)</span><span>,</span> <span>var</span><span>(</span>--shiny-cta-bg<span>)</span><span>)</span> padding-box<span>,</span>
    <span>conic-gradient</span><span>(</span>
        <span>from</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-angle<span>)</span> <span>-</span> <span>var</span><span>(</span>--gradient-angle-offset<span>)</span><span>)</span><span>,</span>
        transparent<span>,</span>
        <span>var</span><span>(</span>--shiny-cta-highlight<span>)</span> <span>var</span><span>(</span>--gradient-percent<span>)</span><span>,</span>
        <span>var</span><span>(</span>--gradient-shine<span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 2<span>)</span><span>,</span>
        <span>var</span><span>(</span>--shiny-cta-highlight<span>)</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 3<span>)</span><span>,</span>
        transparent <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-percent<span>)</span> <span>*</span> 4<span>)</span>
      <span>)</span>
      border-box<span>;</span>
<span>}</span></code></pre>
<p>Each custom property that needs to animate has a <code>syntax</code> declared in its <code>@property</code> definition so that the browser can interpolate between corresponding value changes and transition them seamlessly. The size of the shiny area is determined by the <code>--gradient-percent</code> value. On hover, a higher percentage lengthens the shine. The <code>--gradient-angle-offset</code> value is used to readjust the gradient angle so that the shine doesn't rubber band back and forth on hover.</p>
<figure>
    <video preload="metadata" loop="" muted="" playsinline="" controls="">
      <source src="https://ryanmulligan.dev/videos/shiny-cta-angle-offset.webm#t=0.001" type="video/webm">
      <source src="https://ryanmulligan.dev/videos/shiny-cta-angle-offset.mp4#t=0.001" type="video/mp4">
      <p>Your browser cannot play the provided video file.</p>
    </video>
  <figcaption>Demonstrating the transition behavior without the angle offset value</figcaption></figure>
<p>I had to fine-tune the percent and offset values until the shine length and transition felt optically aligned. Finally, the <code>--gradient-shine</code> brightness gets toned down to blend more seamlessly with the adjacent highlight colors.</p>
<h2 id="slow-it-on-down">Slow it on down</h2>
<p>This <a href="https://css-tip.com/slow-down-rotation/">CSS tip to slow down a rotation on hover</a> truly blew my mind. In the tip's example code, the same rotate animation is declared twice. The second one is reversed and paused, its duration divided in half. When the element is hovered, <code>animation-play-state: running</code> overrides the <code>paused</code> value and slows the rotation to half speed. The mind-blowing part, at least to me, is that the animation speeds back up at the current position when the element is no longer hovered. No snapping back to a start position, no extra wrapper elements necessary. That is one heck of a tip.</p>
<p>The <a href="#cp_embed_MWMqXbK">call-to-action animations</a> rely on this method to slow them down when the button is hovered. This technique keeps all the rotations and movements in sync as they change speed.</p>
<h2 id="tiny-shiny-dots">Tiny shiny dots</h2>
<p>Looking even closer, we'll discover pinhole-sized dots shimmering inside the button as the shiny border passes near them. To render this dot pattern, a <code>radial-gradient</code> background is created.</p>
<pre><code><span>.shiny-cta::before </span><span>{</span>
  <span>--position</span><span>:</span> 2px<span>;</span>
  <span>--space</span><span>:</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--position<span>)</span> <span>*</span> 2<span>)</span><span>;</span>
  <span>background</span><span>:</span> <span>radial-gradient</span><span>(</span>
      circle at <span>var</span><span>(</span>--position<span>)</span> <span>var</span><span>(</span>--position<span>)</span><span>,</span>
      white <span>calc</span><span>(</span><span>var</span><span>(</span>--position<span>)</span> <span>/</span> 4<span>)</span><span>,</span>
      transparent 0
    <span>)</span>
    padding-box<span>;</span>
  <span>background-size</span><span>:</span> <span>var</span><span>(</span>--space<span>)</span> <span>var</span><span>(</span>--space<span>)</span><span>;</span>
  <span>background-repeat</span><span>:</span> space<span>;</span>
<span>}</span></code></pre>
<p>Remember that <code>--gradient-angle</code> custom property? It has returned! But this time, it's being used in a <code>conic-gradient</code> mask that reveals parts of the dot pattern as it rotates. The gradient angle is offset by 45 degrees to align it perfectly with the shiny border rotation.</p>
<pre><code><span>.shiny-cta::before </span><span>{</span>
  <span>mask-image</span><span>:</span> <span>conic-gradient</span><span>(</span>
    <span>from</span> <span>calc</span><span>(</span><span>var</span><span>(</span>--gradient-angle<span>)</span> <span>+</span> 45deg<span>)</span><span>,</span>
    black<span>,</span>
    transparent 10% 90%<span>,</span>
    black
  <span>)</span><span>;</span>
<span>}</span></code></pre>
<p>For one last touch of magic, a gradient containing the highlight color is added to the <code>::after</code> pseudo element, spinning in unison with the shine area. These highlights flowing through the button add a pleasant, welcoming ambience that was previously missing.</p>
<h2 id="enhancing-the-hover-colors">Enhancing the hover colors</h2>
<p>The hover styles looked decent. But they didn't seem totally finished. I felt the desire to enhance. Create more depth. <a href="https://ryanmulligan.dev/blog/detect-js-support-in-css/#:~:text=%22Make%20it%20pop!%22">Make it pop, as they say</a>.</p>
<p>The button's <code>::before</code> and <code>::after</code> pseudo elements were already in use so I wrapped the button text in a <code>span</code> element. A blurred <code>box-shadow</code> containing the highlight color is applied to one of its pseudo elements which is then expanded to fill the button dimensions. On hover, the pseudo element slowly scales up and down, evoking a vibe similar to relaxed breathing. Paired with the spinning highlight color inside the button, the effect finally resonated with me. This intricately designed call-to-action button felt complete.</p>
<h2 id="in-with-the-new-style">In with the new style</h2>
<p>Many of the above techniques would have been nearly impossible only a short time ago. Explicitly defining custom properties unlocks a great big world of opportunity. I'm especially eager to see how <code>@property</code> will be utilized in large-scale applications and design systems. <a href="https://moderncss.dev/providing-type-definitions-for-css-with-at-property/">Providing Type Definitions for CSS with @property</a> by Stephanie Eckles as well as Adam Argyle's <a href="https://nerdy.dev/cant-break-this-design-system">Type safe CSS design systems with @property</a> are just a couple glimpses into a really promising future for publishing our CSS.</p>
<h2 id="helpful-resources">Helpful resources</h2>
<ul>
<li><a href="https://www.learnwithjason.dev/blog/animated-css-gradient-border/">Animated CSS gradient borders (no JavaScript, no hacks)</a></li>
<li><a href="https://ibelick.com/blog/create-animated-gradient-borders-with-css">Creating an animated gradient border with CSS</a></li>
<li><a href="https://web.dev/articles/css-border-animations">CSS border animations</a></li>
<li><a href="https://www.bram.us/2021/01/29/animating-a-css-gradient-border/">Animating a CSS Gradient Border</a></li>
<li><a href="https://codepen.io/hexagoncircle/full/LYKJPjm">CSS border ripple effect</a></li>
<li><a href="https://www.smashingmagazine.com/2024/05/times-need-custom-property-instead-css-variable/">The Times You Need A Custom @property Instead Of A CSS Variable</a></li>
<li><a href="https://web.dev/blog/at-property-baseline">@property: Next-gen CSS variables now with universal browser support</a></li>
</ul>

<p>
  <a href="https://ryanmulligan.dev/blog/">Back to all blog posts</a>
</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's functional programming all about? (2017) (148 pts)]]></title>
            <link>https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html</link>
            <guid>41448664</guid>
            <pubDate>Wed, 04 Sep 2024 18:04:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html">https://www.lihaoyi.com/post/WhatsFunctionalProgrammingAllAbout.html</a>, See on <a href="https://news.ycombinator.com/item?id=41448664">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>There are many descriptions floating around the internet, trying to explain functional programming in simple terms. Unfortunately, most discuss details only loosely related to functional programming, while others focus on topics that are completely irrelevant. So of course, I had to write my own!</p>
<p>This post is my own understanding of what is the "core" of "functional programming", how it differs from "imperative" programming, and what the main benefits of the approach are. As a worked example, we will use a kitchen recipe as a proxy for the more-abstract kind of logic you find in program source code, to try and make concrete what is normally a very abstract topic. That recipe is one of my favorite recipes available online, <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a>.</p><hr><p><a href="https://www.handsonscala.com/"><img src="https://www.lihaoyi.com/handsonscala-mockup.png"></a></p><p><b>About the Author: </b><i>Haoyi is a software engineer, and the author of many open-source Scala tools such as the Ammonite REPL and the Mill Build Tool. If you enjoyed the contents on this blog, you may also enjoy Haoyi's book <a href="https://www.handsonscala.com/"><b><i>Hands-on Scala Programming</i></b></a></i></p><hr>
<ul>
  <li><a href="#what-functional-programming-is-not">What Functional Programming is Not</a>
    <ul>
      <li><a href="#helper-methods">Helper Methods</a></li>
      <li><a href="#writing-things-in-haskell">Writing Things in Haskell</a></li>
      <li><a href="#compile-time-ast-macros">Compile-time AST Macros</a></li>
      <li><a href="#static-types">Static Types</a></li>
    </ul>
  </li>
  <li><a href="#step-by-step-imperative-recipes">Step by Step Imperative Recipes</a>
    <ul>
      <li><a href="#kitchen-refactoring">Kitchen Refactoring</a></li>
    </ul>
  </li>
  <li><a href="#functional-programming-recipes">Functional Programming Recipes</a>
    <ul>
      <li><a href="#tiramisu-diagram-to-functional-programming">Tiramisu Diagram to Functional Programming</a></li>
      <li><a href="#preventing-errors-with-functional-programming">Preventing Errors with Functional Programming</a></li>
      <li><a href="#refactoring-a-functional-tiramisu-recipe">Refactoring a Functional Tiramisu Recipe</a></li>
      <li><a href="#the-core-of-functional-programming">The Core of Functional Programming</a></li>
    </ul>
  </li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>
<p>A topic as broad as "Functional Programming", or "FP" has too many different interpretations and facets to be summarized in one blog post. Nevertheless, this post will discuss what <em>I</em> think is the most core, basic level of functional programming. This will hopefully be something that everyone, from FP newbies to FP "experts", should be able to empathise with and agree is a useful part of functional programming.</p>
<p>It's not surprising that many people have tried to explain functional programming using kitchen/recipe/cookbook examples: learning things "by analogy" of things you already know is one of the easiest ways of learning. However, all explanations I have seen fall short. I will begin by examining some typical, <em>incorrect</em> explanations of what functional programming is about, before discussing how <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a> recipe:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Tiramisu.jpg" alt="TiramisuDiagram"></p>
<p>Can provide insight into what I think are the core techniques and benefits of functional programming.</p><h2 id="what-functional-programming-is-not">What Functional Programming is Not<a href="#what-functional-programming-is-not"></a></h2>
<p>There are many poor explanations people have given for "what is functional programming". Here is a selection:</p><h3 id="helper-methods">Helper Methods<a href="#helper-methods"></a></h3>
<p>One of the most common misconceptions of what FP is is illustrated by the following example:</p>
<blockquote>
  <p>FP =&gt; I'll have a Sazerac</p>
  <p>Imperative =&gt; Excuse me sir, could you take some ice, add rye whiskey, add bitters, add absinthe, shake, strain into a glass, and add a lemon garnish before bringing it to me</p>
</blockquote>
<p>While this example was taken from the <a href="https://news.ycombinator.com/item?id=13281413">y-combinator message board</a>, I've seen this attitude in many places: the idea that functional programming is just taking imperative instructions, and wrapping them in a helper. In this case, the messy imperative code will all sit inside a single helper:</p>
<pre><code>def sazerac():
    ... 10000 lines of messy imperative code ...
</code></pre>
<p>But even in imperative programming you always end up factoring things into helper methods. Java has helper methods. Write assembly, and it ends up being organized with sub-procedures to encapsulate messes of imperative code. </p>
<p>Thus, while this is a useful technique, writing helper methods to wrap your messy code in a single method/function/subprocess/subroutine call does not count as functional programming. </p>
<p>Furthermore, <em>picking an easier/simpler problem</em>, despite making your code look neater, does not count as "Functional Programming" either. Calling a single method that executes a huge blob of code that <em>someone else</em> has written is convenient, but is not functional programming. The point of FP is to face the complexity, own it, and control it, not shove it inside some unmaintained helper function or say it's a problem for some "other department" to deal with.</p><h3 id="writing-things-in-haskell">Writing Things in Haskell<a href="#writing-things-in-haskell"></a></h3>
<pre><code>sazerac = do
    add ice
    add ryeWhisky
    add bitters
    add absinthe
    shake
    strainInto glass
    add lemonGarnish

main = serve $ makeCocktail sazerac
</code></pre>
<ul>
  <li>Also from the <a href="https://news.ycombinator.com/item?id=13281413">y-combinator message board</a></li>
</ul>
<p>It's often said that you can write COBOL in any language, that you can write Java in any language. Well, you can write any language in Haskell too: the above is basically writing Bash in Haskell</p>
<p>Just because something is implemented in Haskell with Monads, doesn't mean it's functional programming. If it looks like imperative code written in Bash, and it's semantics are like imperative code written in Bash, it's imperative code. This example certainly looks exactly like imperative code written in Bash except it's run using <code>serve $ makeCocktail</code> instead of <code>bash cocktail.sh</code>.</p><h3 id="compile-time-ast-macros">Compile-time AST Macros<a href="#compile-time-ast-macros"></a></h3>
<p>Some variant of Lisp (or <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a>?) was probably one of the first implemented FP languages; and Lisps tend to have compile-time AST macros that allow you to transform sections of the program at compile-time. </p>
<p>But compile-time code-transformations are not unique to Lisp; apart from other FP languages that have them, like <a href="https://wiki.haskell.org/Template_Haskell">Template Haskell</a> or <a href="http://docs.scala-lang.org/overviews/macros/overview.html">Scala Macros</a>, many languages have some sort of compile-time code transformation. From <a href="http://hannesdorfmann.com/annotation-processing/annotationprocessing101">Java Annotation Processors</a>, to my own <a href="https://github.com/lihaoyi/macropy">MacroPy</a> project in Python, it turns out that compile-time ast macros are just as feasible in imperative languages, doing imperative programming. You can manipulate mutable ASTs using imperative Python code just as easily as you can elegantly transform immutable ASTs using Scala.</p>
<p>Furthermore, there are a large set of "obviously" functional programming languages that don't have AST-transforming macros at all. Purescript, non-Template Haskell, Scala 2.9, and many other "obviously" functional languages do not include support for compile-time AST transformations. So whatever is the core of functional programming, it's not AST macros.</p><h3 id="static-types">Static Types<a href="#static-types"></a></h3>
<p>There are a large number of people who use FP together with static types, e.g. in languages like Haskell, Scala, or Ocaml. Thus, if you spend all your time within this world, it might be tempting to think that FP is all about static types. <a href="http://stackoverflow.com/questions/6246719/what-is-a-higher-kinded-type-in-scala">Higher-kinded</a>, <a href="https://wiki.haskell.org/Rank-N_types">Rank-N</a>, <a href="https://en.wikipedia.org/wiki/Dependent_type">Dependent</a>, the fancier the types, the more functional the programming. </p>
<p>However, there are probably just as many people using FP without static types: in some parts of the Javascript community, Clojure, Scheme or one of the many other Lisps. It turns out, that all those using FP without types still get many of the benefits. And then there are all those people in static-typed languages like Java that use minimal FP in their code. </p>
<p>So static types, while present in many FP languages, are not the core of FP.</p><h2 id="step-by-step-imperative-recipes">Step by Step Imperative Recipes<a href="#step-by-step-imperative-recipes"></a></h2>
<p>Now that we've looked at a few common misconceptions of what FP is, let's look at what the core of FP <em>actually is</em> (according to me) in contrast to "imperative" programming, using <a href="http://www.cookingforengineers.com/recipe/60/The-Classic-Tiramisu-original-recipe">Michael Chu's Classic Tiramisu</a>:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Tiramisu.jpg" alt="TiramisuDiagram"></p>
<p>As an example. To begin with, we'll explore an "imperative" recipe, that is probably familiar to those you already know.</p>
<p>Michael Chu's Classic Tiramisu, like all the other recipe's on his excellent recipe site has roughly four sections on the page:</p>
<ol>
  <li>
  <p>The backstory of the recipe</p></li>
  <li>
  <p>A step-by-step guide, with photos, of how to make the Tiramisu</p></li>
  <li>
  <p>A diagram of the overall process, showing which ingredients are combined with  which others, to create the resultant Tiramisu</p></li>
  <li>
  <p>A lively and entertaining comments section</p></li>
</ol>
<p>For the purpose of this programming blog we will only be looking at parts <code>2.</code> and <code>3.</code>: the step by step guide, and the process diagram. The step by step guide details, in order, a series of steps that you can take to make a Tiramisu. At a high level, hiding many of the details, it looks like this:</p>
<ol>
  <li>
  <p>Begin by assembling four large egg yolks, 1/2 cup sweet marsala wine, 16  ounces mascarpone cheese, 12 ounces espresso, 2 tablespoons cocoa powder, 1  cup heavy cream, 1/2 cup granulated sugar, and enough lady fingers to layer a  12x8 inch pan twice (40).</p></li>
  <li>
  <p>Stir two tablespoons of granulated sugar into the espresso and put it in  the refrigerator to chill.</p></li>
  <li>
  <p>Whisk the egg yolks</p></li>
  <li>
  <p>Pour in the sugar and wine and whisked briefly until it was well blended.</p></li>
  <li>
  <p>Pour some water into a saucepan and set it over high heat until it began  to boil. </p></li>
  <li>
  <p>Lowering the heat to medium, place the heatproof bowl over the water and  stirred as the mixture began to thicken and smooth out. </p></li>
  <li>
  <p>Whip the heavy cream until soft peaks.</p></li>
  <li>
  <p>Beat the mascarpone cheese until smooth and creamy. </p></li>
  <li>
  <p>Poured the mixture onto the cheese and beat</p></li>
  <li>
  <p>Fold in the whipped cream</p></li>
  <li>
    <p>Assemble the tiramisu. </p>
    <ul>
      <li>
      <p>Give the each ladyfinger cookie  a one second soak on each side and then arrange it on the pan</p></li>
      <li>
      <p>After the first layer of ladyfingers are done, use a spatula to spread  half the cream mixture over it.</p></li>
      <li>
      <p>Cover the cream layer with another layer of soaked ladyfingers.</p></li>
      <li>
      <p>The rest of the cream is spread onto the top and cocoa powder sifted over  the surface to cover the tiramisu.</p></li>
    </ul>
  </li>
  <li>
  <p>The tiramisu was now complete and would require a four hour chill in the refrigerator.</p></li>
</ol>
<p>This is, I think, something like what most people would think of when told "imperative recipe". You start with a set of inputs (the bullet <code>1.</code>) and then perform a series of steps until you have a result at the end. (For now, I'm ignoring the pictures in the recipe, though you could think of them as a sort of <code>assert</code> function for a would-be chef to check some invariants after each step to make sure his tiramisu hasn't gone terribly wrong!)</p>
<p>A simplified Python version of this recipe (ignoring the fact that I'm overloading the same functions to work on different types/number of arguments) may look something like this:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre><h3 id="kitchen-refactoring">Kitchen Refactoring<a href="#kitchen-refactoring"></a></h3>
<p>Like most imperative code, it works, but may be hard to understand deeply or difficult to refactor. For example, in cooking terms, you may ask the following questions:</p>
<ul>
  <li>
  <p>If I have two people to make this tiramisu, which parts can be done in  parallel?</p></li>
  <li>
    <p>My expresso hasn't arrived yet; can I shift that step down and do other  things first and include the expresso later when it arrives? </p>
    <ul>
      <li>
      <p>What if my eggs haven't arrived? Which steps can I do first before  the eggs turn up?</p></li>
    </ul>
  </li>
  <li>
    <p>At step 9. I screwed up and spilled the bowl onto the floor. Which steps do  I need to re-do (and which ingredients I may have to re-purchase) to recover  and continue the recipe?</p>
    <ul>
      <li>
      <p>What if I spilled the bowl at step 10? Or step 8?</p></li>
    </ul>
  </li>
  <li>
    <p>Just before step 10, you realize you forgot to do step 7. How much of  your ingredients have been ruined?</p>
    <ul>
      <li>
      <p>What if the forgotten step was step 4? Or step 2?</p></li>
    </ul>
  </li>
</ul>
<p>All four of these are things that happen regularly in a kitchen, and also happen to correspond to things you do with program code all the time: parallelizing things over the available cores to speed things up, shuffling the order of a computation around, dealing with failures and exceptions, or plain old bugs and mistakes.</p>
<p>The answers to these questions are left as an exercise to the reader; in this case, with 12 steps, it's not terribly hard to figure out. A few minutes carefully studying the recipe and you could probably figure it out, so you should definitely give it a try. </p>
<hr>
<p>In a large software project, with a codebase containing thousands or millions of lines of imperative code, that time could easily stretch to days, weeks, or months trying to figure out how to properly recover when one of those imperative steps fails, or how to make your legacy PHP monolith do something faster by using more than 1 of the 32 cores you have available on your beefy server. </p>
<p><strong>The problem in these cases often isn't that you don't know how to run stuff in a separate process in PHP - the problem is that you don't know enough about your own code to decide what to run in that other process</strong>. To move things onto a separate process, you need to know exactly what each bit of code depends on, and who depends on it, so you can pick a set with minimal dependencies to run somewhere else (since inter-process communication is expensive). That's difficult when you have a pile of imperative code and don't even understand it enough to easily move things around <em>within</em> a single process.</p>
<p>The reason that these kinds of analyses are hard on this imperative recipe is the same reason that the analyses are hard when programming in an imperative style: </p>
<ul>
  <li>
  <p>There is an ordering of the steps, but the ordering between some steps is  required, e.g. the series 9, 10, 11, while those between other steps is  entirely arbitrary: step 2 could be done anywhere before step 11, and step 7  and 8 could be swapped or done much earlier and nobody would care.</p></li>
  <li>
  <p>The instructions are based on changing the state of things, e.g. pouring  stuff into <code>mixture</code>, a term that we use repeatedly throughout the recipe  but means a different thing in each step. Even the meaning of <code>cheese</code> and  <code>cream</code> changes as the recipe progresses (e.g. after calling <code>whip(cream)</code>),  but it is entirely hidden from you and not obvious from the code.</p></li>
</ul>
<p>Overall, these factors make it hard to decide, given a single step <em>S</em>, what steps <em>S</em> depends on, and what <em>other</em> steps depend on <em>S</em>. Again, it is possible to figure it out, but what is somewhat-tedious to figure out in a 16-line tiramisu recipe becomes painful and difficult in a 1,000,000 line enterprise codebase.</p>
<p>So that's what an imperative Tiramisu recipe looks like. What does a "functional programming" Tiramisu recipe look like?</p><h2 id="functional-programming-recipes">"Functional Programming" Recipes<a href="#functional-programming-recipes"></a></h2>
<p>It turns out, there's a FP version of this recipe right underneath the imperative one! The "process diagram" mentioned above is an excellent illustration of how such a recipe would look like using "Functional Programming":</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/TiramisuDiagram.png" alt="TiramisuDiagram"></p>
<p>To read this, the raw ingredients are on the left, and each of the boxes represents a single operation that transforms and combines the ingredients. After all the combinations have taken place, you end up on the right with a single, complete Tiramisu. While this "2D" format is not how people write program source code, the underlying structure is not too different from how people structure "FP" programs, which I will demonstrate below.</p>
<p>This diagram leaves out some the <em>detail</em> that the full imperative recipe provides, even compared to the abridged version I transcribed above. For example, chilling the expresso or explicitly boiling the water are left out, and the details of <em>assemble</em> are not included. Nevertheless, it contains the same high-level steps of how to build the tiramisu I abridged above. We're not leaving out large numbers of operations or hiding things behind high-level instructions: all the same steps are still there, just organized slightly differently.</p>
<p>But even if this diagram has the same "content" as the imperative instruction-list I discussed earlier, what about this makes this presentation of the recipe more "functional"?</p><h3 id="tiramisu-diagram-to-functional-programming">Tiramisu Diagram to Functional Programming<a href="#tiramisu-diagram-to-functional-programming"></a></h3>
<p>While nobody actually writes their code in a 2D table-flowchart-thing like this tiramisu diagram is, it turns out underneath the 2D format the "core" of this diagram is the dependency graph between elements:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/DiagramGraph.png" alt="TiramisuDiagram"></p>
<p>Where each box takes in some "inputs" from the left, and results in an "output" that can be used by more-rightward boxes. This can be straightforwardly represented in code by treating the boxes as functions, e.g. in the following Python code:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
                 
    return refrigerate(
        sift(
            assemble(
                fold(
                    beat(
                        whisk( # over steam
                            beat(beat(eggs), sugar1, wine)
                        ), 
                        beat(cheese)
                    ), 
                    whip(cream)
                ), 
                soak2seconds(fingers, dissolve(sugar2, espresso))
            ), 
            cocoa
        )
    )
</code></pre>
<p>(Again, forgive the fact that I'm overloading the same functions to work on different types and numbers of arguments)</p>
<p>If it's not immediately clear how this code relates to the "functional programming dependency diagram" I discussed above, we can draw the dependency graph <em>of this code</em>: showing where the input variables go, where the return value of each function goes, all the way into the "final" result that gets returned:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/CodeGraph.png" alt="TiramisuDiagram"></p>
<p>It might look like a bit of a mess, but if you look carefully, you will see that <strong>although the graphs are laid out differently, the fundamental structure of the two graphs is identical!</strong> That is what I mean when I say the 2D box-diagram is a "FP Recipe": although people don't tend to write code in 2D box-diagrams, the underlying structure that the diagram represents is totally equivalent to some "FP"-ish Python code, not too dissimilar to what people <em>do</em> write. </p>
<p>This code looks very unlike code you are likely to see in a Python project, "in the wild", but we can fix that! If you prefer to have intermediate named values instead of one big expression, it's straightforward to pull out each function call into it's own statement: </p>
<pre><code># FP         
def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p>That makes it look entirely "pythonic", indistinguishable from the code you might find in any random project on Github</p>
<p>Moving every expression into a separate statement is a straightforward transformation, at least for FP programs, and is the kind of thing that compilers regularly do automatically. Thus, although that block-flow-chart diagram may have looked a bit foreign at first, it really isn't <em>that</em> different from the code people write day to day, all year round.</p>
<p>In fact, it looks not too unlike the "Imperative" version we came up with earlier!</p>
<pre><code># Imperative
def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    soak2seconds(fingers, espresso)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre>
<p>These two snippets of code look very similar, but the top one is "Functional Programming" while the bottom one is "Imperative Programming". The difference between them? </p>
<ul>
  <li>
  <p>In the first, you can see that <code>beat(cheese)</code> must come  before <code>beat(whisked, beat_cheese)</code>, because <code>beat_cheese</code>  is defined by the <code>beat(cheese)</code> and used by <code>beat(whisked, beat_cheese)</code>.  Even if you know nothing about <code>beat</code>, <code>cheese</code> or <code>whisked</code>, it is clear  from the code that if you tried to reverse the order - and  <code>beat(whisked, beat_cheese)</code> <em>before</em> <code>beat(cheese)</code>, it wouldn't work.</p></li>
  <li>
  <p>In the second, it's not so clear: does <code>beat(cheese)</code> <em>need</em> to come before  <code>beat(mixture, cheese)</code>? Or does <code>beat(mixture, cheese)</code> need to come before  <code>beat(cheese)</code>? In this case, we have a link to the "docs" (the original  recipe) so we can look it up, but which one depends on the other - and  whether they are currently in the right order - is not clear from the code.</p></li>
</ul>
<p>But how does this seemingly-trivial difference affect the way you build software?</p><h3 id="preventing-errors-with-functional-programming">Preventing Errors with Functional Programming<a href="#preventing-errors-with-functional-programming"></a></h3>
<p>The difference between the two Python snippets, the <code># FP</code> and <code># Imperative</code> snippets, will become clear with the following thought experiment: what if we try to make changes to the code?</p>
<p>Changing code is something we do all day, and sometimes we do it incorrectly. It would be a nice property of a codebase if changes tended to be easier to make correctly, and incorrect changes were easier to spot. We'll discuss the latter first.</p>
<p>If I try to tidy things up and accidentally move the statement</p>
<pre><code>beat_cheese = beat(cheese)
</code></pre>
<p>below</p>
<pre><code>cheese_mixture = beat(whisked, beat_cheese)
</code></pre>
<p>It should be clear to me that something is wrong, because there will be no <code>beat_cheese</code> in scope to create the <code>cheese_mixture</code>. Even if it's not clear to me, it's probably clear to my linter and editor:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p>
<p>As you can see, not only does the usage of <code>beat_cheese</code> raise an error because no such variable is defined, the <em>definition</em> of <code>beat_cheese</code> <em>also</em> raises a visual warning: it is greyed out since it is dead code! This makes it very hard to miss when you make such trivial error, and saves you time: rather than waiting 10s for your test suite to run, within less than 1s your linter would have lit up and flagged the lines as invalid. Over the days, months and years, this adds up to a significant productivity boost</p>
<p>However, in the <em>Imperative</em> case, it's not clear how </p>
<pre><code>beat(mixture, cheese)
</code></pre>
<p>Relates to the things before or after it. If I remove the <code>beat(cheese)</code> earlier, I still have a <code>cheese</code> to pass in. If I remove the <code>beat(mixture, cheese)</code> entirely, I still have a <code>mixture</code> I can use in later steps of the recipe. So how do I know, from looking at the code, that removing a step or re-ordering them so that <code>beat(cheese)</code> comes after <code>beat(mixture, cheese)</code> is a problem? </p>
<p>The answer is, you often don't, and neither does your computer, or your editor and linter, who aren't going to help you spot the fact that you accidentally swapped two of the imperative statements:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ImperativeError.png" alt="TiramisuDiagram"></p>
<p>Fundamentally, in the "FP" example, the code is laid out in a way that the "correct" usage is obvious: each function, e.g. <code>beat</code>, only depends on the things that are passed into it, and it's output is only depended upon by whoever uses it's return value. In the "Imperative" example, it's not clear who depends on who: you have to memorize the fact that <code>beat(cheese)</code> must come before <code>beat(mixture, cheese)</code>, and not the other way around. </p>
<p>While this is not difficult assuming we are looking at already-correct code (the current order is the correct order!), when mistakes are made, and code happens to be incorrect, "FP" code makes the mistakes much easier for you (or your linter) to spot so you can correct them.</p>
<hr>
<p>While this example may seem contrived, the basic problem exists in all large codebases I've worked with. For example, maybe you've bumped into code similar to the following three functions:</p>
<pre><code>def initialize():
   ... 1000 lines of messy code, no return value...
   
def make_app():
   ... 2000 lines of messy code, no return value...

def start_server():
   ... 4000 lines of messy code, no return value...
</code></pre>
<p>Which transitively depend on a 1 million line codebase ("The App"). How could I know that <code>start_server()</code> needs to be called before <code>make_app()</code>, which itself needs to be called before <code>initialize()</code>, when all of them are global functions which don't take arguments or return anything? I have certainly spent countless days of my career puzzling over such mysteries in large codebases, and I am sure others have too. If <code>start_server</code> returned something I needed to pass to <code>make_app</code>, which returned something I needed to pass to <code>initialize</code>, that would make it clear from the outset which one needs to come before the other.</p>
<p>Re-ordering or shuffling around statements is not uncommon. When you are refactoring a piece of code to let you re-use it in a different place, a lot of time is spent shifting bits of code up and down small amounts, just like the example I showed above, so that the code you want to re-use is all in one place and you can extract it into a helper. </p>
<p>Perhaps you just want to tidy up what was previous a messy function to organize the code a bit better than it already is, grouping related lines so they can be read together easily, without changing any behavior at all.</p>
<p>Or perhaps, as mentioned earlier, someone made a mistake and the code <em>that already exists</em> is incorrect, and your job is to figure out which of the statements is out of order so you can fix it.</p>
<p>All of these are things that software engineers do day in, day out. And often, we make mistakes when doing so. With functional programming, whether in a typed language or not, it tends to be much more clear when you've made a trivial, dumb error. That means you get feedback quicker: you get corrected quietly by your linter in the privacy of your own laptop, and can quickly fix it and make progress, rather than waiting a long time only to be loudly yelled at by Jenkins CI in front of your entire team.</p><h3 id="refactoring-a-functional-tiramisu-recipe">Refactoring a Functional Tiramisu Recipe<a href="#refactoring-a-functional-tiramisu-recipe"></a></h3>
<p>Even if you haven't already-made a mistake, and are just <em>thinking</em> of making a change to a codebase, the <code># FP</code> version of the code is a lot easier to think about than the <code># Imperative</code> version. The same often applies whether you're writing dealing with Python, Javascript, Scala, or a Tiramisu recipe!</p>
<p>I have already shown above how the 2D-block-diagram version of this recipe is exactly equivalent in semantics to a "FP" Python function. For this section I will use the 2D-block-diagrams to illustrate my points, as it is much clearer visually, but the same kind of reasoning applies to "FP" code in Python or any other programming language. While working with an FP style, you quickly get used to performing the same analyses in your head, just as quickly, but on lines of source code rather than 2D-block-diagrams.</p>
<p>What is interesting is that this structure lets us very easily answer some of the questions we asked above:</p>
<blockquote>
  <ul>
    <li>If I have two people to make this tiramisu, which parts can be done in parallel?</li>
  </ul>
</blockquote>
<p>This one is easy: </p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Parallel.png" alt="TiramisuDiagram"></p>
<p>Anything vertically separated can be done in parallel. For example, preparing the ladies fingers and preparing the eggs/sugar/wine are separate and can be done independently, as can whipping the cream and mascarpone cheese. Thus, if you have three people, you might assign: </p>
<ul>
  <li>one person to be the egg/wine/sugar mixture czar,</li>
  <li>one to be the mascarpone/cream czar, and</li>
  <li>one to be the expresso/ladyfingers czar.</li>
</ul>
<p>On the other hand, anything horizontally separated has to be done sequentially:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/Sequential.png" alt="TiramisuDiagram"></p>
<p>Thus even if you parallelize the early bits, the later beat-fold-assembly-refrigerate steps all have to be done sequentially, and how much time you can save on your Tiramisu is limited by the length of the <a href="https://en.wikipedia.org/wiki/Critical_path_method">Critical Path</a>. </p>
<p>Working with the "FP" representation of the recipe doesn't shorten the critical path, and thus doesn't affect how much you can "theoretically" speed up your recipe with parallelism. What it does do is make clear exactly which parts of the recipe can be parallelized and which can't, so you can more quickly organize your work to get maximum parallelism given the constraints of the recipe, and then move on to other things.</p>
<p>Again, while we're looking at a 2D-block-diagram, the same applies to FP-style code in Python, Javascript, Scala, or any other programming language.</p>
<blockquote>
  <ul>
    <li>My expresso hasn't arrived yet; can I shift that step down and do other things first and include the expresso later when it arrives?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/MissingExpresso.png" alt="TiramisuDiagram"></p>
<p>If you expresso hasn't arrived, anything depending on it can't be done, but anything else involving eggs/sugar/wine/cheese/cream can be prepared: the sections marked in red make it clear which parts of the recipe depend on expresso; the rest can be done while waiting for the expresso to arrive</p>
<blockquote>
  <ul>
    <li>What if my eggs haven't arrived? Which steps can I do first before  the eggs turn up?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/MissingEggs.png" alt="TiramisuDiagram"></p>
<p>In this case, the top block can't be done but you can prepare the bottom and middle blocks: preparing the expresso, beating the cream and mascarpone cheese. Again, this is obvious from looking at the diagram</p>
<blockquote>
  <ul>
    <li>At step 9. I screwed up and spilled the bowl onto the floor. Which steps do I need to re-do (and which ingredients I may have to re-purchase) to recover and continue the recipe?</li>
  </ul>
</blockquote>
<p>Step 9 is when you beat the Mascarpone cheese into the egg mixture. Once we find it on the diagram, it's clear what we need to do:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailBeatCheese.png" alt="TiramisuDiagram"></p>
<p>You will need to get some new eggs/sugar/wine/cheese and beat/beat/whisk/beat them all over again </p>
<blockquote>
  <ul>
    <li>What if I spilled the bowl at step 10? Or step 8?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailFoldCream.png" alt="TiramisuDiagram"></p>
<p>Spilling the bowl at step 10 (folding the whipped cream into the main mixture) is the same as spilling the bowl at step 9, except you need to get new cream too.</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FailBeatCream.png" alt="TiramisuDiagram"></p>
<p>Spilling the bowl at step 8 (beating Mascarpone cheese) and you just need to get new mascarpone cheese and beat it. The rest of your ingredients are fine. </p>
<blockquote>
  <ul>
    <li>Just before step 10, you realize you forgot to do step 7. How much of your ingredients have been ruined?</li>
  </ul>
</blockquote>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotWhipCream.png" alt="TiramisuDiagram"></p>
<p>In the diagram above, the red boxes represent the steps we've already done, up to step 10 (folding in the whipped cream). As you can see, not having done step 7 (whipping the heavy cream) is no big deal; we haven't needed to done it up to now, so we can do it and continue with step 10 </p>
<blockquote>
  <ul>
    <li>What if the forgotten step was step 4? Or step 2?</li>
  </ul>
</blockquote>
<p>If you forgot step 4 (whisking in wine and sugar to the beaten eggs) you've ruined your eggs/sugar/wine/cheese:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotWineSugar.png" alt="TiramisuDiagram"></p>
<p>As you can see, the stuff we've been whisking and beating was not prepared properly before being whisked and beaten, since we forgot to mix in the wine and sugar. Assuming we don't know enough kitchen chemistry to incorporate the wine/sugar in at this stage (Our eggs may well have turned into omelettes by now without the additional liquid from the wine...) we will need to re-do all the steps in the upper red box.</p>
<p>If you forgot step 2 (dissolving sugar into expresso) you're fine. The expresso hasn't been needed yet:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/ForgotExpresso.png" alt="TiramisuDiagram"></p>
<p>According to the imperative recipe above, we <em>should</em> have done the expresso mixing first before starting on the egg/wine/cheese. But even though we didn't do it, it is trivial to see from the FP-style recipe that there really isn't any loss: no other steps so far depended on that, no other ingredients were ruined.</p>
<hr>
<p>As you can see, many of the questions that were non-trivial to answer when dealing with the imperative code back in <a href="#kitchen-refactoring">Kitchen Refactoring</a> are now trivial to answer when working with the FP-style 2D-block-diagrams.</p>
<p>Again, while nobody actually codes in 2D-block-diagrams (except skilled engineers running recipe blogs) the 2D-block-diagrams are equivalent to a relatively straightforward snippet as shown above. With some experience dealing with FP code, you can often perform the same analyses just as easily when working directly with the equivalent Python code we showed earlier. And it's not just about programmers: automated tools linters or IDEs often perform the same analysis on the fly, as <a href="#preventing-errors-with-functional-programming">shown earlier</a>, quickly alerting you if you make a mistake that means the recipe can no longer be completed successfully:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p><h3 id="the-core-of-functional-programming">The Core of Functional Programming<a href="#the-core-of-functional-programming"></a></h3>
<p><strong>The core of Functional Programming is thinking about data-flow rather than control-flow</strong>. Although, by virtue of editing plain text, you are forced to order your code in a linear sequence of statements, those statements are a thin skin over what you really care about: the shape and structure of the data-flow graph within your program.</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/CodeGraph.png" alt="TiramisuDiagram"></p> <p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/DiagramGraph.png" alt="TiramisuDiagram"></p>
<p>Similarly, when <em>executing</em> a "functional program" in a single thread, you are forced to pick a linear order in which you execute each individual instruction, which e.g. might be the same as the order in which it is written down in the code. But since we know what <em>really</em> matters is the shape of the data-flow graph, we can freely re-arrange the statements in the code, and the order of execution, as long as the graph shape is preserved. Since the data-flow graph matches the graph of definitions and usages, even your editors and linters understand it enough to warn you if you re-arrange things in an invalid order. In fact, if you have multiple cores (or multiple cooks!) you can execute parts of it in parallel, not in any linear order at all! Exactly in what order the <a href="https://en.wikipedia.org/wiki/Program_counter">program-counter</a> proceeds from instruction to instruction is irrelevant.</p>
<p>This is in contrast to an imperative program, where the exact <em>order</em> in which the program-counter executes each statement, going in and out of loops, in and out of sub-routines, is the key to understanding the program. In an imperative program, you tend to think in terms of steps that must happen "before" and "after", and make sure that the control-flow of the program executes the commands in the right order for the program to work.</p>
<p><strong>Note that none of the FP examples here are "less complex" than the "imperative" recipe we discussed above</strong>. It's about the same number of lines:</p>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    dissolve(sugar2, espresso)
    mixture = whisk(eggs)
    beat(mixture, sugar1, wine)
    whisk(mixture) # over steam
    whip(cream)
    beat(cheese)
    beat(mixture, cheese)
    fold(mixture, cream)
    assemble(mixture, fingers)
    sift(mixture, cocoa)
    refrigerate(mixture)
    return mixture # it's now a tiramisu
</code></pre>
<pre><code>def make_tiramisu(eggs, sugar1, wine, cheese, cream, fingers, espresso, sugar2, cocoa):
    beat_eggs = beat(eggs)
    mixture = beat(beat_eggs, sugar1, wine)
    whisked = whisk(mixture)
    beat_cheese = beat(cheese)
    cheese_mixture = beat(whisked, beat_cheese)
    whipped_cream = whip(cream)
    folded_mixture = fold(cheese_mixture, whipped_cream)
    sweet_espresso = dissolve(sugar2, espresso)
    wet_fingers = soak2seconds(fingers, sweet_espresso)
    assembled = assemble(folded_mixture, wet_fingers)
    complete = sift(assembled, cocoa)
    ready_tiramisu = refrigerate(complete)
    return ready_tiramisu
</code></pre>
<p>whether as multiple statements, one big expression, or as a 2D block diagram. All the same operations are present: <code>beat</code>ing, <code>whip</code>ing, <code>fold</code>ing, etc.. Functional Programming is not about hiding ugly code in helper methods and hoping nobody notices: it's about managing the same complexity in a way that makes the dependencies between each piece of code obvious, by following the graph of where function arguments come from and where return values end up.</p>
<p>When you have a working program, having the dependency graph of function return values being passed into other functions as arguments makes it really easy to analyze code. For example, if we were curious what <em>exactly</em> is required to get our <code>wet_fingers_mixture</code>, we can see:</p>
<ul>
  <li><code>wet_fingers</code> comes from <code>soak2seconds(fingers, sweet_espresso)</code></li>
  <li><code>sweet_espresso</code> comes from <code>dissolve(sugar2, espresso)</code></li>
  <li><code>sugar2</code>, <code>fingers</code>, <code>espresso</code> are the initial ingredients of the recipe</li>
</ul>
<p>An there you have it: just a few steps, entirely mechanical, and we can see exactly what <code>wet_fingers</code> needs. We need no understanding of what <code>dissolve</code> does, or what a <code>sugar2</code> is: just from the structure of the code we can already see what <code>wet_fingers</code> requires. Just as importantly, we can also see that it does <em>not</em> depend on <code>folded_mixture</code>, <code>whipped_cream</code>, or any of the other steps that are above it in the code: while those steps "come before" the operations that give us a <code>wet_fingers</code>, it's clear from this analysis that their ordering is entirely accidental, and that we could e.g. prepare the <code>wet_fingers</code> before the other steps if we so desired.</p>
<p>It's not hard to do this yourself, but any IDE with jump-to-definition should be able to do this for you, and so can automated linters and code analysis tools. And understanding the code is the first step in changing it, without bugs.</p>
<p>When you have a broken program, having the dependencies be easy to analyze means it's easier to spot when you make a mistake or do something out of order: even in a dynamic language like python, a subtly bad copy-paste job can get called out by your editor so you can fix it before needing to run any code:</p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/FunctionalError.png" alt="TiramisuDiagram"></p>
<p>Whether you're working in a dynamic language like Python or a static language like Scala, whether your code is currently working or broken, Functional Programming's data-flow-centric approach helps you understand your code faster, easier and with more tooling help than a Imperative, mutation-heavy approach.</p><h2 id="conclusion">Conclusion<a href="#conclusion"></a></h2>
<p><strong>The core of Functional Programming is thinking about data-flow rather than control-flow</strong></p>
<p><img src="https://www.lihaoyi.com/post/BasicFunctionalProgramming/TiramisuDiagram.png" alt="TiramisuDiagram"></p>
<p>While this may seem a trivial definition of "Functional Programming", I think it is really the core of the idea. While there are many further steps, from the simple (immutability, referential transparency, ...) to the more advanced (monads, lenses, ...) this core of should be something that everyone, from newbies to old hands, whether using Scala or Clojure or Haskell or React.js, should be able to empathise with. Even in a language like Python, as I have used for the examples, it is possible to program in a more "Functional" style, and reap some of the benefits of functional programming.</p>
<p>Those more advanced topics don't really fit this worked example anyway: kitchen ingredients tend to be very, very mutable (and perishable!).</p>
<p>Though it's growing, this baseline-level of FP is not yet widespread in industry. </p>
<ul>
  <li>
  <p>Whole languages, such as Bash, make it a pain in the neck to take  non-trivial function arguments or return non-trivial results, resulting in  people's code writing things to the filesystem, hopefully "before" someone  else needs to read them.</p></li>
  <li>
  <p>Languages like Java encourage  patterns where you instantiate a half-baked object and then set the fields  later, praying that nobody accidentally tries to use it "too early" it in  it's half-baked state while it's internal variables are garbage. </p></li>
</ul>
<p>In all of these cases, the <em>order</em> in which things run - exactly how the program-counter progresses from statement to statement, in and out of for-loops, in and out of sub-routines - is critical. </p>
<p>Even in the kitchen, having a "FP-style" recipe like the block diagram I showed above is helpful, because when the person bringing your Marsala Wine is stuck in traffic, it makes it easier to re-organize your recipe so you can get as much work done immediately. When that person arrives, it helps you figure out how to parallelize the work over the people you have available. When someone screws up, it helps you figure out exactly which ingredients you need to re-purchase and steps you need to re-do. </p>
<p>This widespread applicability, even to fields outside the software world, and to every "FP" language <em>within</em> the software world, is why I think this is truly what functional programming is all about.</p><hr><p><a href="https://www.handsonscala.com/"><img src="https://www.lihaoyi.com/handsonscala-mockup.png"></a></p><p><b>About the Author: </b><i>Haoyi is a software engineer, and the author of many open-source Scala tools such as the Ammonite REPL and the Mill Build Tool. If you enjoyed the contents on this blog, you may also enjoy Haoyi's book <a href="https://www.handsonscala.com/"><b><i>Hands-on Scala Programming</i></b></a></i></p><hr></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: An open-source implementation of AlphaFold3 (276 pts)]]></title>
            <link>https://github.com/Ligo-Biosciences/AlphaFold3</link>
            <guid>41448439</guid>
            <pubDate>Wed, 04 Sep 2024 17:44:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Ligo-Biosciences/AlphaFold3">https://github.com/Ligo-Biosciences/AlphaFold3</a>, See on <a href="https://news.ycombinator.com/item?id=41448439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">AlphaFold3 Open-Source Implementation</h2><a id="user-content-alphafold3-open-source-implementation" aria-label="Permalink: AlphaFold3 Open-Source Implementation" href="#alphafold3-open-source-implementation"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">This is Ligo's open-source implementation of AlphaFold3, an ongoing research project aimed at advancing open-source biomolecular structure prediction. This release implements the full AlphaFold3 model along with the training code. We are releasing the single chain prediction capability first and we will add ligand, multimer, and nucleic acid prediction capabilities once they are trained. <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">Sign up for beta testing here</a>.</p>
<p dir="auto">This repository is intended to accelerate progress towards a faithful, fully open-source implementation of AlphaFold3 for the entire biotech community to use freely.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo Video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo Video" href="#demo-video"></a></p>
<p dir="auto">We find that the model training dynamics are quite fast. The following video is a sample from a model trained for 4,000 steps on 8 A100 GPUs for 10 hours without templates.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Ligo-Biosciences/AlphaFold3/blob/main/media/AlphaFold3-sample-4_000-steps-training.gif"><img src="https://github.com/Ligo-Biosciences/AlphaFold3/raw/main/media/AlphaFold3-sample-4_000-steps-training.gif" alt="AlphaFold3 Sample" data-animated-image=""></a></p>
<p dir="auto">Animation credits: <a href="https://batisio.co.uk/" rel="nofollow">Matthew Clark</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<p dir="auto">This project would not have been possible without the contributions of the following projects and individuals:</p>
<ul dir="auto">
<li>
<p dir="auto">The AlphaFold3 team at Google DeepMind for their groundbreaking work and publishing the core algorithms.</p>
</li>
<li>
<p dir="auto">The OpenFold project (<a href="https://github.com/aqlaboratory/openfold">https://github.com/aqlaboratory/openfold</a>), which laid the foundation for open-source protein structure prediction. We reuse many of their core modules, such as triangular attention and multiplicative update, as well as their data processing pipelines.</p>
</li>
<li>
<p dir="auto">The ProteinFlow library (<a href="https://github.com/adaptyvbio/ProteinFlow">https://github.com/adaptyvbio/ProteinFlow</a>), especially the architect of ProteinFlow, Liza Kozlova (<a href="https://github.com/elkoz">@elkoz</a>), who has been an absolute hero throughout this process. We trained most of our prototype models on ProteinFlow, since it provides a clean and well-documented data pipeline for working with protein data. We have partnered with AdaptyvBio to build the data pipeline of AlphaFold3 based on ProteinFlow that includes full ligand and nucleic acid support. <a href="https://github.com/elkoz">@elkoz</a> and <a href="https://github.com/igor-krawczuk">@igor-krawczuk</a> are building the next release of ProteinFlow to include full support for these data modalities.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Status</h2><a id="user-content-project-status" aria-label="Permalink: Project Status" href="#project-status"></a></p>
<p dir="auto">This is an active research project in its early phases. We are working to prepare a stable release for the community. While we are excited about the potential of this work, we want to emphasise that this is not yet a production-ready tool.
We trained a version of AlphaFold3 on single-chain proteins to test the implementation -- the next release will include full ligand and nucleic acid support.
We are accepting a small number of beta testers to help us test the implementation and provide feedback. If you are interested in beta testing, please <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">join our waitlist</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Discrepancies from AlphaFold3's Pseudocode</h2><a id="user-content-discrepancies-from-alphafold3s-pseudocode" aria-label="Permalink: Discrepancies from AlphaFold3's Pseudocode" href="#discrepancies-from-alphafold3s-pseudocode"></a></p>
<p dir="auto">While working on this project, we discovered a few properties of the algorithms described in the AlphaFold3 supplementary information that were not consistent with surrounding deep learning literature.
We discuss these below:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>MSA Module Order</strong>: In the Supplementary Information, the MSA module communication step occurs before the MSA stack. This results in the MSA stack of the last block not contributing to the structure prediction, since all information flows out through the pair representation. With the order in the pseudocode, the MSA stack in the last block does not have an opportunity to update the pair representation. We swap the OuterProductMean operation and the MSA stack to ensure all blocks contribute to the structure prediction. It is important to note this correction is consistent with the order of operations in the ExtraMSAStack of AlphaFold2. DeepMind mentions these MSA module blocks are "homogeneous". It is unclear whether this means shared weights or same architecture across blocks. If the layers are shared, then gradients will flow through all of them but the final calculation of the MSA stack is idle - this can be safely skipped (not mentioned in the pseudocode). We will resolve this ambiguity in light of DeepMind's response.</p>
</li>
<li>
<p dir="auto"><strong>Loss scaling</strong>: The loss scaling factor described in the Supplementary Information does not give unit-loss at initialization. Unit-loss at initialization is one of the properties that Karras et al. (2022) set as a desirable property of the loss function when training diffusion models, and Max Jaderberg mentions this as one of the properties for why they chose the framework of Karras et al. in this talk <a href="https://youtu.be/AE35XCN5NuU?si=S_9-i3hupk3i9GDR" rel="nofollow">here</a>. We think this is a simple typo in the Supplementary info that is due to an addition being typed as a multiplication -- in our implementation, we use the loss scaling factor consistent with Karras et al. (2022). Our measurements show that this gives unit MSE loss at initialization, whilst the scaling in the Supplementary Information is two to three orders of magnitude larger at initialization. Additionally, the loss scaling factor in the paper has a local minimum at t = 16.0, but then it increases with increasing noise level. This is not in line with the properties of the loss function that Karras et al. (2022) proposed, which emphasises the importance of downweighting the loss at higher noise levels. We add a Jupyter notebook to the repository showing our experiments.</p>
</li>
<li>
<p dir="auto"><strong>DiT block design</strong>: The design of the AttentionPairBias and the DiffusionTransformer blocks seem to closely follow the DiT block design introduced by Peebles &amp; Xie (2022) <a href="https://arxiv.org/abs/2212.09748" rel="nofollow">here</a>. However, the residual connections are missing. It is not explained in the paper why DeepMind chose to omit them. We experiment with both and find that (within the range of steps we trained our models on) the DiT block with residual connections gives much faster convergence and better gradient flow through the network. Note that this is the discrepancy we are the least sure about, and it can be changed in a couple lines in our code if the original implementation does not use the residual connections.</p>
</li>
</ul>
<p dir="auto">These are noted here for transparency and to invite community input on the best approaches to resolve them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Efficiency</h2><a id="user-content-model-efficiency" aria-label="Permalink: Model Efficiency" href="#model-efficiency"></a></p>
<p dir="auto">A significant focus of this implementation has been on optimising the model components for speed and memory efficiency. AlphaFold3 has many transformer-like components, but efficient hardware-aware attention implementations like FlashAttention2 do not integrate out-of-the-box with these modules due to pair biasing in AlphaFold3. All of the attention operations project a pair bias from the pairwise representation that is added after the key-query dot product, and the bias requires a gradient to be backpropagated. This is not out of scope for FlashAttention2, since the bias gradient would have the same gradient as the scaled QK^T dot product, but the current implementation does not support this. More recent attention implementations like <a href="https://pytorch.org/blog/flexattention/" rel="nofollow">FlexAttention</a> are very promising, but they also do not support a bias gradient for now since broadcasting operations of the bias tensor during the forward pass become reductions in the backward pass, and this functionality is not implemented in the first release of FlexAttention.</p>
<ul dir="auto">
<li>
<p dir="auto">We reuse battle-tested components such as TriangularAttention and TriangularMultiplicativeUpdate from the OpenFold project wherever we can. The modular design of the OpenFold project allows us to easily import these modules into our codebase. We are working on improving the efficiency of these modules with Triton, fusing operations to increase performance and reduce intermediate tensor allocation.</p>
</li>
<li>
<p dir="auto">We observed that a naive implementation of the Diffusion Module in PyTorch frequently ran out of memory since the Diffusion Module is replicated 48 times per batch. To solve this issue, we re-purpose the MSARowAttentionWithPairBias kernel from Deepspeed4Science to implement a memory-efficient version of the Diffusion Module, treating the batch replicas with different noise levels as an additional batch dimension. For the AtomAttentionEncoder and AtomAttentionDecoder modules, we experimented with a custom PyTorch-native implementation to reduce the memory footprint from quadratic to linear, but the benefits were not that significant compared to a naive re-purposing of the AttentionPairBias kernel. We include both implementations in the repository, but use the naive implementation for the sake of reducing clutter.
Despite these optimisations, our profiling experiments show that over 60% of the model's operations are memory-bound. We are working on a far more efficient and scalable implementation using the ideas of <a href="https://paperswithcode.com/paper/scalefold-reducing-alphafold-initial-training" rel="nofollow">ScaleFold</a>, which will allow us to reach the training scale of the original AlphaFold3.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">We do not yet provide sampling code since the ligand-protein and nucleic acid prediction capabilities are yet to be trained. The checkpoint weights can be loaded with PyTorch Lightning's checkpoint loading for experimentation and model surgery. The current model only predicts single-chain proteins, which is the same functionality as the original AlphaFold2. The model components are written to be reusable and modular so that researchers can easily incorporate them into their own projects.
For beta testing of ligand-protein and nucleic acid prediction: <a href="https://form.fillout.com/t/ct1BWM5QWqus" rel="nofollow">Join our Waitlist</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">For now, the primary use of this repository is for research and development. We will include more user-facing functionality in the future once the ligand-protein and nucleic acid prediction capabilities are ready.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions from the community! There are likely numerous bugs and subtle implementation errors in our code. Deep learning training often fails silently, where the errors still allow the network to converge but make it work slightly worse. If you're interested in contributing, you can raise a Github issue with a bug description or fork the repository, create a new branch with your corrections and submit a pull request with a clear description of your changes.</p>
<p dir="auto">For any other comments or suggestions please contact us via email at <a href="mailto:alphafold3@ligo.bio">alphafold3@ligo.bio</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Citations</h2><a id="user-content-citations" aria-label="Permalink: Citations" href="#citations"></a></p>
<p dir="auto">If you use this code in your research, please cite the following papers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{Abramson2024-fj,
  title    = &quot;Accurate structure prediction of biomolecular interactions with
              {AlphaFold} 3&quot;,
  author   = &quot;Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans,
              Richard and Green, Tim and Pritzel, Alexander and Ronneberger,
              Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick,
              Joshua and Bodenstein, Sebastian W and Evans, David A and Hung,
              Chia-Chun and O'Neill, Michael and Reiman, David and
              Tunyasuvunakool, Kathryn and Wu, Zachary and {\v Z}emgulyt{\.e},
              Akvil{\.e} and Arvaniti, Eirini and Beattie, Charles and
              Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and
              Congreve, Miles and Cowen-Rivers, Alexander I and Cowie, Andrew
              and Figurnov, Michael and Fuchs, Fabian B and Gladman, Hannah and
              Jain, Rishub and Khan, Yousuf A and Low, Caroline M R and Perlin,
              Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and
              Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine
              and Yakneen, Sergei and Zhong, Ellen D and Zielinski, Michal and
              {\v Z}{\'\i}dek, Augustin and Bapst, Victor and Kohli, Pushmeet
              and Jaderberg, Max and Hassabis, Demis and Jumper, John M&quot;,
  journal  = &quot;Nature&quot;,
  month    = &quot;May&quot;,
  year     =  2024
}"><pre><span>@article</span>{<span>Abramson2024-fj</span>,
  <span>title</span>    = <span><span>"</span>Accurate structure prediction of biomolecular interactions with</span>
<span>              {AlphaFold} 3<span>"</span></span>,
  <span>author</span>   = <span><span>"</span>Abramson, Josh and Adler, Jonas and Dunger, Jack and Evans,</span>
<span>              Richard and Green, Tim and Pritzel, Alexander and Ronneberger,</span>
<span>              Olaf and Willmore, Lindsay and Ballard, Andrew J and Bambrick,</span>
<span>              Joshua and Bodenstein, Sebastian W and Evans, David A and Hung,</span>
<span>              Chia-Chun and O'Neill, Michael and Reiman, David and</span>
<span>              Tunyasuvunakool, Kathryn and Wu, Zachary and {\v Z}emgulyt{\.e},</span>
<span>              Akvil{\.e} and Arvaniti, Eirini and Beattie, Charles and</span>
<span>              Bertolli, Ottavia and Bridgland, Alex and Cherepanov, Alexey and</span>
<span>              Congreve, Miles and Cowen-Rivers, Alexander I and Cowie, Andrew</span>
<span>              and Figurnov, Michael and Fuchs, Fabian B and Gladman, Hannah and</span>
<span>              Jain, Rishub and Khan, Yousuf A and Low, Caroline M R and Perlin,</span>
<span>              Kuba and Potapenko, Anna and Savy, Pascal and Singh, Sukhdeep and</span>
<span>              Stecula, Adrian and Thillaisundaram, Ashok and Tong, Catherine</span>
<span>              and Yakneen, Sergei and Zhong, Ellen D and Zielinski, Michal and</span>
<span>              {\v Z}{\'\i}dek, Augustin and Bapst, Victor and Kohli, Pushmeet</span>
<span>              and Jaderberg, Max and Hassabis, Demis and Jumper, John M<span>"</span></span>,
  <span>journal</span>  = <span><span>"</span>Nature<span>"</span></span>,
  <span>month</span>    = <span><span>"</span>May<span>"</span></span>,
  <span>year</span>     =  <span>2024</span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article {Ahdritz2022.11.20.517210,
	author = {Ahdritz, Gustaf and Bouatta, Nazim and Floristean, Christina and Kadyan, Sachin and Xia, Qinghui and Gerecke, William and O{\textquoteright}Donnell, Timothy J and Berenberg, Daniel and Fisk, Ian and Zanichelli, Niccolò and Zhang, Bo and Nowaczynski, Arkadiusz and Wang, Bei and Stepniewska-Dziubinska, Marta M and Zhang, Shang and Ojewole, Adegoke and Guney, Murat Efe and Biderman, Stella and Watkins, Andrew M and Ra, Stephen and Lorenzo, Pablo Ribalta and Nivon, Lucas and Weitzner, Brian and Ban, Yih-En Andrew and Sorger, Peter K and Mostaque, Emad and Zhang, Zhao and Bonneau, Richard and AlQuraishi, Mohammed},
	title = {{O}pen{F}old: {R}etraining {A}lpha{F}old2 yields new insights into its learning mechanisms and capacity for generalization},
	elocation-id = {2022.11.20.517210},
	year = {2022},
	doi = {10.1101/2022.11.20.517210},
	publisher = {Cold Spring Harbor Laboratory},
	URL = {https://www.biorxiv.org/content/10.1101/2022.11.20.517210},
	eprint = {https://www.biorxiv.org/content/early/2022/11/22/2022.11.20.517210.full.pdf},
	journal = {bioRxiv}
}"><pre><span>@article</span> {<span>Ahdritz2022.11.20.517210</span>,
	<span>author</span> = <span><span>{</span>Ahdritz, Gustaf and Bouatta, Nazim and Floristean, Christina and Kadyan, Sachin and Xia, Qinghui and Gerecke, William and O{\textquoteright}Donnell, Timothy J and Berenberg, Daniel and Fisk, Ian and Zanichelli, Niccolò and Zhang, Bo and Nowaczynski, Arkadiusz and Wang, Bei and Stepniewska-Dziubinska, Marta M and Zhang, Shang and Ojewole, Adegoke and Guney, Murat Efe and Biderman, Stella and Watkins, Andrew M and Ra, Stephen and Lorenzo, Pablo Ribalta and Nivon, Lucas and Weitzner, Brian and Ban, Yih-En Andrew and Sorger, Peter K and Mostaque, Emad and Zhang, Zhao and Bonneau, Richard and AlQuraishi, Mohammed<span>}</span></span>,
	<span>title</span> = <span><span>{</span>{O}pen{F}old: {R}etraining {A}lpha{F}old2 yields new insights into its learning mechanisms and capacity for generalization<span>}</span></span>,
	<span>elocation-id</span> = <span><span>{</span>2022.11.20.517210<span>}</span></span>,
	<span>year</span> = <span><span>{</span>2022<span>}</span></span>,
	<span>doi</span> = <span><span>{</span>10.1101/2022.11.20.517210<span>}</span></span>,
	<span>publisher</span> = <span><span>{</span>Cold Spring Harbor Laboratory<span>}</span></span>,
	<span>URL</span> = <span><span>{</span>https://www.biorxiv.org/content/10.1101/2022.11.20.517210<span>}</span></span>,
	<span>eprint</span> = <span><span>{</span>https://www.biorxiv.org/content/early/2022/11/22/2022.11.20.517210.full.pdf<span>}</span></span>,
	<span>journal</span> = <span><span>{</span>bioRxiv<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article{kozlova_2023_proteinflow,
  author = {Kozlova, Elizaveta and Valentin, Arthur and Khadhraoui, Aous and Gutierrez, Daniel Nakhaee-Zadeh},
  month = {09},
  title = {ProteinFlow: a Python Library to Pre-Process Protein Structure Data for Deep Learning Applications},
  doi = {https://doi.org/10.1101/2023.09.25.559346},
  year = {2023},
  journal = {bioRxiv}
}"><pre><span>@article</span>{<span>kozlova_2023_proteinflow</span>,
  <span>author</span> = <span><span>{</span>Kozlova, Elizaveta and Valentin, Arthur and Khadhraoui, Aous and Gutierrez, Daniel Nakhaee-Zadeh<span>}</span></span>,
  <span>month</span> = <span><span>{</span>09<span>}</span></span>,
  <span>title</span> = <span><span>{</span>ProteinFlow: a Python Library to Pre-Process Protein Structure Data for Deep Learning Applications<span>}</span></span>,
  <span>doi</span> = <span><span>{</span>https://doi.org/10.1101/2023.09.25.559346<span>}</span></span>,
  <span>year</span> = <span><span>{</span>2023<span>}</span></span>,
  <span>journal</span> = <span><span>{</span>bioRxiv<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@misc{ahdritz2023openproteinset,
      title={{O}pen{P}rotein{S}et: {T}raining data for structural biology at scale}, 
      author={Gustaf Ahdritz and Nazim Bouatta and Sachin Kadyan and Lukas Jarosch and Daniel Berenberg and Ian Fisk and Andrew M. Watkins and Stephen Ra and Richard Bonneau and Mohammed AlQuraishi},
      year={2023},
      eprint={2308.05326},
      archivePrefix={arXiv},
      primaryClass={q-bio.BM}
}"><pre><span>@misc</span>{<span>ahdritz2023openproteinset</span>,
      <span>title</span>=<span><span>{</span>{O}pen{P}rotein{S}et: {T}raining data for structural biology at scale<span>}</span></span>, 
      <span>author</span>=<span><span>{</span>Gustaf Ahdritz and Nazim Bouatta and Sachin Kadyan and Lukas Jarosch and Daniel Berenberg and Ian Fisk and Andrew M. Watkins and Stephen Ra and Richard Bonneau and Mohammed AlQuraishi<span>}</span></span>,
      <span>year</span>=<span><span>{</span>2023<span>}</span></span>,
      <span>eprint</span>=<span><span>{</span>2308.05326<span>}</span></span>,
      <span>archivePrefix</span>=<span><span>{</span>arXiv<span>}</span></span>,
      <span>primaryClass</span>=<span><span>{</span>q-bio.BM<span>}</span></span>
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@article{Peebles2022DiT,
  title={Scalable Diffusion Models with Transformers},
  author={William Peebles and Saining Xie},
  year={2022},
  journal={arXiv preprint arXiv:2212.09748},
}"><pre><span>@article</span>{<span>Peebles2022DiT</span>,
  <span>title</span>=<span><span>{</span>Scalable Diffusion Models with Transformers<span>}</span></span>,
  <span>author</span>=<span><span>{</span>William Peebles and Saining Xie<span>}</span></span>,
  <span>year</span>=<span><span>{</span>2022<span>}</span></span>,
  <span>journal</span>=<span><span>{</span>arXiv preprint arXiv:2212.09748<span>}</span></span>,
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{Karras2022edm,
  author    = {Tero Karras and Miika Aittala and Timo Aila and Samuli Laine},
  title     = {Elucidating the Design Space of Diffusion-Based Generative Models},
  booktitle = {Proc. NeurIPS},
  year      = {2022}
}"><pre><span>@inproceedings</span>{<span>Karras2022edm</span>,
  <span>author</span>    = <span><span>{</span>Tero Karras and Miika Aittala and Timo Aila and Samuli Laine<span>}</span></span>,
  <span>title</span>     = <span><span>{</span>Elucidating the Design Space of Diffusion-Based Generative Models<span>}</span></span>,
  <span>booktitle</span> = <span><span>{</span>Proc. NeurIPS<span>}</span></span>,
  <span>year</span>      = <span><span>{</span>2022<span>}</span></span>
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the Apache License 2.0 - see the <a href="https://github.com/Ligo-Biosciences/AlphaFold3/blob/main/LICENSE.txt">LICENSE</a> file for details.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The coming long-run slowdown in corporate profit growth and stock returns [pdf] (2023) (126 pts)]]></title>
            <link>https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf</link>
            <guid>41448139</guid>
            <pubDate>Wed, 04 Sep 2024 17:13:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf">https://www.federalreserve.gov/econres/feds/files/2023041pap.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41448139">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dynamicland 2024 (526 pts)]]></title>
            <link>https://dynamicland.org/</link>
            <guid>41448022</guid>
            <pubDate>Wed, 04 Sep 2024 17:02:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dynamicland.org/">https://dynamicland.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41448022">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Internet Archive has lost its appeal in Hachette vs. Internet Archive (866 pts)]]></title>
            <link>https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf</link>
            <guid>41447758</guid>
            <pubDate>Wed, 04 Sep 2024 16:41:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf">https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=41447758">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
    </channel>
</rss>