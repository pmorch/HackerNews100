<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 16 Mar 2025 00:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Sign in as anyone: Bypassing SAML SSO authentication with parser differentials (169 pts)]]></title>
            <link>https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/</link>
            <guid>43374519</guid>
            <pubDate>Sat, 15 Mar 2025 19:06:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/">https://github.blog/security/sign-in-as-anyone-bypassing-saml-sso-authentication-with-parser-differentials/</a>, See on <a href="https://news.ycombinator.com/item?id=43374519">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
	
<blockquote><p>Critical authentication bypass vulnerabilities (CVE-2025-25291 + CVE-2025-25292) were discovered in ruby-saml up to version 1.17.0. Attackers who are in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization can use it to construct SAML assertions themselves and are in turn able to log in as any user. In other words, it could be used for an account takeover attack. Users of ruby-saml should update to version 1.18.0. References to libraries making use of ruby-saml (such as omniauth-saml) need also be updated to a version that reference a fixed version of ruby-saml.</p></blockquote>
<p>In this blog post, we detail newly discovered authentication bypass vulnerabilities in the <a href="https://github.com/SAML-Toolkits/ruby-saml">ruby-saml</a> library used for single sign-on (SSO) via SAML on the service provider (application) side. GitHub doesn’t currently use ruby-saml for authentication, but began evaluating the use of the library with the intention of using an open source library for SAML authentication once more. This library is, however, used in other popular projects and products. We discovered an exploitable instance of this vulnerability in GitLab, and have notified their security team so they can take necessary actions to protect their users against potential attacks.</p>
<p>GitHub previously used the ruby-saml library up to 2014, but moved to our own SAML implementation due to missing features in ruby-saml at that time. Following bug bounty reports around vulnerabilities in our own implementation (such as <a href="https://docs.github.com/en/enterprise-server@3.13/admin/release-notes#3.13.5-security-fixes">CVE-2024-9487</a>, related to encrypted assertions), GitHub recently decided to explore the use of ruby-saml again. Then in October 2024, a blockbuster vulnerability dropped: an <a href="https://github.com/advisories/GHSA-jw9c-mfg7-9rx2">authentication bypass</a> in ruby-saml (CVE-2024-45409) by <a href="https://hackerone.com/ahacker1">ahacker1</a>. With tangible evidence of exploitable attack surface, GitHub’s switch to ruby-saml had to be evaluated more thoroughly now. As such, GitHub started a <a href="https://hackerone.com/github">private bug bounty engagement</a> to evaluate the security of the ruby-saml library. We gave selected bug bounty researchers access to GitHub test environments using ruby-saml for SAML authentication. In tandem, the GitHub Security Lab also reviewed the attack surface of the ruby-saml library.</p>
<p>As is not uncommon when multiple researchers are looking at the same code, both ahacker1, a participant in the <a href="https://hackerone.com/github">GitHub bug bounty program</a>, and I noticed the same thing during code review: ruby-saml was using two different XML parsers during the code path of signature verification. Namely, REXML and Nokogiri. While REXML is an XML parser implemented in pure Ruby, Nokogiri provides an easy-to-use wrapper API around different libraries like libxml2, libgumbo and Xerces (used for JRuby). Nokogiri supports parsing of XML and HTML. It looks like Nokogiri was added to ruby-saml to support <a href="https://en.wikipedia.org/wiki/Canonical_XML">canonicalization</a> and potentially other things REXML didn’t support at that time.</p>
<p>We both inspected the same code path in the <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268"><code>validate_signature</code></a> of <code>xml_security.rb</code> and found that the signature element to be verified is first read via REXML, and then also with Nokogiri’s XML parser. So, if REXML and Nokogiri could be tricked into retrieving different signature elements for the same XPath query it might be possible to trick ruby-saml into verifying the wrong signature. It looked like there could be a potential authentication bypass due to a <strong>parser differential</strong>!</p>
<p>The reality was actually more complicated than this.</p>

<p>Roughly speaking, four stages were involved in the discovery of this authentication bypass:</p>
<ol>
<li>Discovering that two different XML parsers are used during code review.  </li>
<li>Establishing if and how a parser differential could be exploited.  </li>
<li>Finding an actual parser differential for the parsers in use.  </li>
<li>Leveraging the parser differential to create a full-blown exploit.</li>
</ol>
<p>To prove the security impact of this vulnerability, it was necessary to complete all four stages and create a full-blown authentication bypass exploit.</p>
<h2 id="quick-recap-how-saml-responses-are-validated">Quick recap: how SAML responses are validated<a href="#quick-recap-how-saml-responses-are-validated" aria-label="Quick recap: how SAML responses are validated"></a></h2>
<p>Security assertion markup language (<a href="https://en.wikipedia.org/wiki/Security_Assertion_Markup_Language">SAML</a>) responses are used to transport information about a signed-in user from the identity provider (IdP) to the service provider (SP) in XML format. Often the only important information transported is a username or an email address. When the HTTP POST binding is used, the SAML response travels from the IdP to the SP via the browser of the end user. This makes it obvious why there has to be some sort of signature verification in play to prevent the user from tampering with the message.</p>
<p>Let’s have a quick look at what a simplified SAML response looks like:<br>
<img data-recalc-dims="1" decoding="async" loading="lazy" src="https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?resize=1024%2C355" alt="A diagram depicting a simplified SAML response on the left and the verification of the digest and the signature on the right." width="1024" height="355" srcset="https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2632 2632w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=1536 1536w, https://github.blog/wp-content/uploads/2025/03/goodassertion7_2.png?w=2048 2048w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></p>
<p><em>Note: in the response above the XML namespaces were removed for better readability.</em></p>
<p>As you might have noticed: the main part of a simple SAML response is its assertion element (A), whereas the main information contained in the assertion is the information contained in the <code>Subject</code> element (B) (here the NameID containing the username: admin). A real assertion typically contains more information (e.g. <code>NotBefore</code> and <code>NotOnOrAfter</code> dates as part of a <code>Conditions</code> element.)</p>
<p>Normally, the <code>Assertion</code> (A) (without the whole <code>Signature</code> part) is <a href="https://en.wikipedia.org/wiki/Canonical_XML">canonicalized</a> and then compared against the <code>DigestValue</code> (C) and the <code>SignedInfo</code> (D) is canonicalized and verified against the <code>SignatureValue</code> (E). In this sample, the assertion of the SAML response is signed, and in other cases the whole SAML response is signed.</p>
<h2 id="searching-for-parser-differentials">Searching for parser differentials<a href="#searching-for-parser-differentials" aria-label="Searching for parser differentials"></a></h2>
<p>We learned that ruby-saml used two different XML parsers (REXML and Nokogiri) for validating the SAML response. Now let’s have a look at the verification of the signature and the digest comparison.<br>
The focus of the following explanation lies on the <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L268"><code>validate_signature</code></a> method inside of <code>xml_security.rb</code>.</p>
<p>Inside that method, there’s a broad XPath <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L278C1-L282C8">query</a> with REXML for the first signature element inside the SAML document:</p>
<pre><code>sig_element = REXML::XPath.first(
  @working_copy,
  "//ds:Signature",
  {"ds"=&gt;DSIG}
)
</code></pre>
<p><em>Hint: When reading the code snippets, you can tell the difference between queries for REXML and Nokogiri by looking at how they are called. REXML methods are prefixed with <code>REXML::</code>, whereas Nokogiri methods are called on <code>document</code>.</em></p>
<p>Later, the actual <code>SignatureValue</code> is <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L293C1-L298C92">read</a> from this element:</p>
<pre><code>base64_signature = REXML::XPath.first(
  sig_element,
  "./ds:SignatureValue",
  {"ds" =&gt; DSIG}
)
signature = Base64.decode64(OneLogin::RubySaml::Utils.element_text(base64_signature))
</code></pre>
<p>Note: the name of the <code>Signature</code> element might be a bit confusing. While it contains the actual signature in the <code>SignatureValue</code> node it also contains the part that is actually signed in the <code>SignedInfo</code> node. Most importantly the <code>DigestValue</code> element contains the digest (hash) of the assertion and information about the used key.</p>
<p>So, an actual <code>Signature</code> element could look like this (removed namespace information for better readability):</p>
<pre><code>&lt;Signature&gt;
    &lt;SignedInfo&gt;
        &lt;CanonicalizationMethod Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#" /&gt;
        &lt;SignatureMethod Algorithm="http://www.w3.org/2001/04/xmldsig-more#rsa-sha256" /&gt;
        &lt;Reference URI="#_SAMEID"&gt;
            &lt;Transforms&gt;&lt;Transform Algorithm="http://www.w3.org/2001/10/xml-exc-c14n#" /&gt;&lt;/Transforms&gt;
            &lt;DigestMethod Algorithm="http://www.w3.org/2001/04/xmlenc#sha256" /&gt;
            &lt;DigestValue&gt;Su4v[..]&lt;/DigestValue&gt;
        &lt;/Reference&gt;
    &lt;/SignedInfo&gt;
    &lt;SignatureValue&gt;L8/i[..]&lt;/SignatureValue&gt;
    &lt;KeyInfo&gt;
        &lt;X509Data&gt;
            &lt;X509Certificate&gt;MIID[..]&lt;/X509Certificate&gt;
        &lt;/X509Data&gt;
    &lt;/KeyInfo&gt;
&lt;/Signature&gt;
</code></pre>
<p>Later in the same method (<code>validate_signature</code>) there’s again a <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L307">query for the Signature</a>(s)—but this time with Nokogiri.</p>
<pre><code>noko_sig_element = document.at_xpath('//ds:Signature', 'ds' =&gt; DSIG)
</code></pre>
<p>Then the <code>SignedInfo</code> element is taken from that signature and <a href="https://en.wikipedia.org/wiki/Canonical_XML">canonicalized</a>:</p>
<pre><code>noko_signed_info_element = noko_sig_element.at_xpath('./ds:SignedInfo', 'ds' =&gt; DSIG)

canon_string = noko_signed_info_element.canonicalize(canon_algorithm)
</code></pre>
<p>Let’s remember this <code>canon_string</code> contains the canonicalized <code>SignedInfo</code> element.</p>
<p>The <code>SignedInfo</code> element is then also <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L314C6-L318C8">extracted</a> with REXML:</p>
<pre><code> signed_info_element = REXML::XPath.first(
        sig_element,
        "./ds:SignedInfo",
        { "ds" =&gt; DSIG }
 )
</code></pre>
<p>From this <code>SignedInfo</code> element the <code>Reference</code> node is <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L324">read</a>:</p>
<pre><code>ref = REXML::XPath.first(signed_info_element, "./ds:Reference", {"ds"=&gt;DSIG})
</code></pre>
<p>Now the code <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L326C1-L327C1">queries for the referenced node</a> by looking for nodes with the signed element id using Nokogiri:</p>
<pre><code>reference_nodes = document.xpath("//*[@ID=$id]", nil, { 'id' =&gt; extract_signed_element_id })
</code></pre>
<p>The method <code>extract_signed_element_id</code> <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L406C9-L406C34">extracts</a> the signed element id with help of REXML. From the previous authentication bypass (CVE-2024-45409), there’s now a <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L328">check</a> that only one element with the same ID can exist.</p>
<p>The first of the <code>reference_nodes</code> is taken and canonicalized:</p>
<pre><code>hashed_element = reference_nodes[0][..]canon_hashed_element = hashed_element.canonicalize(canon_algorithm, inclusive_namespaces)
</code></pre>
<p>The <code>canon_hashed_element</code> is then <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L349C7-L349C59">hashed</a>:</p>
<pre><code>hash = digest_algorithm.digest(canon_hashed_element)
</code></pre>
<p>The <code>DigestValue</code> to compare it against is then <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L350C7-L355C99">extracted</a> with REXML:</p>
<pre><code>encoded_digest_value = REXML::XPath.first(
        ref,
        "./ds:DigestValue",
        { "ds" =&gt; DSIG }
      )
digest_value = Base64.decode64(OneLogin::RubySaml::Utils.element_text(encoded_digest_value))
</code></pre>
<p>Finally, the <code>hash</code> (built from the element extracted by Nokogiri) is <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L357">compared</a> against the <code>digest_value</code> (extracted with REXML):</p>
<pre><code>unless digests_match?(hash, digest_value)
</code></pre>
<p>The <code>canon_string</code> extracted some lines ago (a result of an extraction with Nokogiri) is later <a href="https://github.com/SAML-Toolkits/ruby-saml/blob/21b676bdf55452750d8ee5facd2f6e3c51927315/lib/xml_security.rb#L366C7-L366C86">verified against</a> <code>signature</code> (extracted with REXML).</p>
<pre><code>unless cert.public_key.verify(signature_algorithm.new, signature, canon_string)
</code></pre>
<p>In the end, we have the following constellation:</p>
<ol>
<li>The assertion is extracted and canonicalized with Nokogiri, and then hashed. In contrast, the hash against which it will be compared is extracted with REXML.  </li>
<li>The SignedInfo element is extracted and canonicalized with Nokogiri - it is then verified against the SignatureValue, which was extracted with REXML.</li>
</ol>
<h2 id="exploiting-the-parser-differential">Exploiting the parser differential<a href="#exploiting-the-parser-differential" aria-label="Exploiting the parser differential"></a></h2>
<p>The question is: is it possible to create an XML document where REXML sees one signature and Nokogiri sees another?</p>
<p>It turns out, yes.</p>
<p>Ahacker1, participating in the bug bounty, was faster to produce a working exploit using a parser differential. Among other things, ahacker1 was inspired by the <a href="https://mattermost.com/blog/securing-xml-implementations-across-the-web/">XML roundtrips vulnerabilities</a> published by Mattermost’s Juho Forsén in 2021.</p>
<p>Not much later, I produced an exploit using a different parser differential with the help of <a href="https://blog.trailofbits.com/2024/03/29/introducing-ruzzy-a-coverage-guided-ruby-fuzzer/">Trail of Bits’ Ruby fuzzer</a> called ruzzy.</p>
<p>Both exploits result in an authentication bypass. Meaning that an attacker, who is in possession of a single valid signature that was created with the key used to validate SAML responses or assertions of the targeted organization, can use it to construct assertions for any users which will be accepted by ruby-saml. Such a signature can either come from a signed assertion or response from another (unprivileged) user or in certain cases, it can even come from signed metadata of a SAML identity provider (which can be publicly accessible).</p>
<p>An exploit could look like this. Here, an additional Signature was added as part of the <code>StatusDetail</code> element that is only visible to Nokogiri:</p>
<p><img data-recalc-dims="1" decoding="async" loading="lazy" src="https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?resize=1024%2C400" alt="A diagram depicting a simplified SAML response on the left and the verification of the digest and the signature on the right. For both the signature and the digest verification one part is extracted using Nokogiri and the other using REXML." width="1024" height="400" srcset="https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=3496 3496w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=1536 1536w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=2048 2048w, https://github.blog/wp-content/uploads/2025/03/rubysaml-parser-diff-simplified8_2.png?w=3000 3000w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></p>
<p>In summary:</p>
<p>The <code>SignedInfo</code> element (A) from the signature that is visible to Nokogiri is canonicalized and verified against the <code>SignatureValue</code> (B) that was extracted from the signature seen by REXML.</p>
<p>The assertion is retrieved via Nokogiri by looking for its ID. This assertion is then canonicalized and hashed (C). The hash is then compared to the hash contained in the <code>DigestValue</code> (D). This DigestValue was retrieved via REXML. This DigestValue has no corresponding signature.</p>
<p>So, two things take place:</p>
<ul>
<li>A valid SignedInfo with DigestValue is verified against a valid signature. (which checks out)  </li>
<li>A fabricated canonicalized assertion is compared against its calculated digest. (which checks out as well)</li>
</ul>
<p>This allows an attacker, who is in possession of a valid signed assertion for any (unprivileged) user, to fabricate assertions and as such impersonate any other user.</p>
<h3 id="check-for-errors-when-using-nokogiri">Check for errors when using Nokogiri<a href="#check-for-errors-when-using-nokogiri" aria-label="Check for errors when using Nokogiri"></a></h3>
<p>Parts of the currently known, undisclosed exploits can be stopped by checking for Nokogiri parsing errors on SAML responses. Sadly, those errors do not result in exceptions, but need to be checked on the <a href="https://www.rubydoc.info/github/sparklemotion/nokogiri/Nokogiri%2FXML%2FDocument:errors"><code>errors</code></a> member of the parsed document:</p>
<pre><code>doc = Nokogiri::XML(xml) do |config|
  config.options = Nokogiri::XML::ParseOptions::STRICT | Nokogiri::XML::ParseOptions::NONET
end

raise "XML errors when parsing: " + doc.errors.to_s if doc.errors.any?
</code></pre>
<p>While this is far from a perfect fix for the issues at hand, it renders at least one exploit infeasible.</p>
<h2 id="indicators-of-compromise">Indicators of compromise<a href="#indicators-of-compromise" aria-label="Indicators of compromise"></a></h2>
<p>We are not aware of any reliable indicators of compromise. While we’ve found a potential indicator of compromise, it only works in debug-like environments and to publish it, we would have to reveal too many details about how to implement a working exploit so we’ve decided that it’s better not to publish it. Instead, our best recommendation is to look for suspicious logins via SAML on the service provider side from IP addresses that do not align with the user’s expected location.</p>
<h2 id="saml-and-xml-signaturesas-confusing-as-it-gets">SAML and XML signatures:as confusing as it gets<a href="#saml-and-xml-signaturesas-confusing-as-it-gets" aria-label="SAML and XML signatures:as confusing as it gets"></a></h2>
<p>Some might say it’s hard to integrate systems with SAML. That might be true. However, it’s even harder to write implementations of SAML using XML signatures in a secure way. As others have stated before: it’s probably best to <a href="https://ssoready.com/blog/engineering/ruby-saml-pwned-by-xml-signature-wrapping-attacks/#how-to-fix-this-disregard-the-spec">disregard the specifications</a>, as following them doesn’t help build secure implementations.<br>
To rehash how the validation works if the SAML assertion is signed, let’s have a look at the graphic below,  depicting a simplified SAML response. The assertion, which transports the protected information, contains a signature. Confusing, right?</p>
<p><img data-recalc-dims="1" decoding="async" loading="lazy" src="https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?resize=1024%2C497" alt="A diagram showing a SAML response and its parts: the Assertion containing the Signature and the Signature containing the SignedInfo of which the DigestValue is a part." width="1024" height="497" srcset="https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?w=1768 1768w, https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?w=300 300w, https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?w=768 768w, https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?w=1024 1024w, https://github.blog/wp-content/uploads/2025/03/conclusion-combined-saml.png?w=1536 1536w" sizes="auto, (max-width: 1000px) 100vw, 1000px"></p>
<p>To complicate it even more: What is even signed here? The whole assertion? No!</p>
<p>What’s signed is the <code>SignedInfo</code> element and the <code>SignedInfo</code> element contains a <code>DigestValue</code>. This <code>DigestValue</code> is the hash of the canonicalized assertion with the signature element removed before the canonicalization. This two-stage verification process can lead to implementations that have a disconnect between the verification of the hash and the verification of the signature. This is the case for these Ruby-SAML parser differentials: while the hash and the signature check out on their own, they have no connection. The hash is actually a hash of the assertion, but the signature is a signature of a different <code>SignedInfo</code> element containing another hash. What you actually want is a direct connection between the hashed content, the hash, and the signature. (And once the verification is done you only want to retrieve information from the exact part that was actually verified.) Or, alternatively, use a less complicated standard to transport a cryptographically signed username between two systems - but here we are.</p>
<p>In this case, the library already extracted the <code>SignedInfo</code> and used it to verify the signature of its canonicalized string,<code>canon_string</code>. However, it did not use it to obtain the digest value. If the library had used the content of the already extracted <code>SignedInfo</code> to obtain the digest value, it would have been secure in this case even with two XML parsers in use.</p>
<h2 id="conclusion">Conclusion<a href="#conclusion" aria-label="Conclusion"></a></h2>
<p>As shown once again: relying on two different parsers in a security context can be tricky and error-prone. That being said: exploitability is not automatically guaranteed in such cases. As we have seen in this case, checking for Nokogiri errors could not have prevented the parser differential, but could have stopped at least one practical exploitation of it.</p>
<p>The initial fix for the authentication bypasses does not remove one of the XML parsers to prevent API compatibility problems. As noted, the more fundamental issue was the disconnect between verification of the hash and verification of the signature, which was exploitable via parser differentials. The <a href="https://github.com/SAML-Toolkits/ruby-saml/pull/736">removal of one of the XML</a> parsers was already planned for other reasons, and will likely come as part of a major release in combination with additional improvements to strengthen the library. If your company relies on open source software for business-critical functionality, consider <a href="https://github.com/sponsors">sponsoring</a> them to help fund their future development and bug fix releases.</p>
<p>If you’re a user of ruby-saml library, make sure to update to the latest version, 1.18.0, containing fixes for <a href="https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-4vc4-m8qh-g8jm">CVE-2025-25291</a> and <a href="https://github.com/SAML-Toolkits/ruby-saml/security/advisories/GHSA-754f-8gm6-c4r2">CVE-2025-25292</a>. References to libraries making use of ruby-saml (such as <a href="https://github.com/omniauth/omniauth-saml">omniauth-saml</a>) need also be updated to a version that reference a fixed version of ruby-saml. We will publish a proof of concept exploit at a later date in the <a href="https://github.com/github/securitylab">GitHub Security Lab repository</a>.</p>
<h3 id="acknowledgments">Acknowledgments<a href="#acknowledgments" aria-label="Acknowledgments"></a></h3>
<p>Special thanks to Sixto Martín, maintainer of ruby-saml, and Jeff Guerra from the GitHub Bug Bounty program.<br>
Special thanks also to ahacker1 for giving inputs to this blog post.</p>
<h3 id="timeline">Timeline<a href="#timeline" aria-label="Timeline"></a></h3>
<ul>
<li>2024-11-04: Bug bounty report demonstrating an authentication bypass was reported against a GitHub test environment evaluating ruby-saml for SAML authentication.  </li>
<li>2024-11-04: Work started to identify and test potential mitigations.  </li>
<li>2024-11-12: A second authentication bypass was found by Peter that renders the planned mitigations for the first useless.  </li>
<li>2024-11-13: Initial contact with Sixto Martín, maintainer of ruby-saml.  </li>
<li>2024-11-14: Both parser differentials are reported to ruby-saml, the maintainer responds immediately.  </li>
<li>2024-11-14: The work on potential patches by the maintainer and ahacker1 begins. (One of the initial ideas was to remove one of the XML parsers, but this was not feasible without breaking backwards compatibility).  </li>
<li>2025-02-04: ahacker1 proposes a non-backwards compatible fix.  </li>
<li>2025-02-06: ahacker1 also proposes a backwards compatible fix.  </li>
<li>2025-02-12: The 90 days deadline of GitHub Security Lab advisories ends.  </li>
<li>2025-02-16: The maintainer starts working on a fix with the idea to be backwards-compatible and easier to understand.  </li>
<li>2025-02-17: Initial contact with GitLab to coordinate a release of their on-prem product with the release of the ruby-saml library.  </li>
<li>2025-03-12: A fixed version of ruby-saml was released.</li>
</ul>

	
<section>
	<hr>
	<div>
		<h2>Tags:</h2>
		<ul>
							<li>
					<a href="https://github.blog/tag/authentication/" rel="tag">
						authentication					</a>
				</li>
							<li>
					<a href="https://github.blog/tag/github-security-lab/" rel="tag">
						GitHub Security Lab					</a>
				</li>
							<li>
					<a href="https://github.blog/tag/ruby/" rel="tag">
						ruby					</a>
				</li>
							<li>
					<a href="https://github.blog/tag/saml/" rel="tag">
						SAML					</a>
				</li>
							<li>
					<a href="https://github.blog/tag/vulnerability/" rel="tag">
						vulnerability					</a>
				</li>
					</ul>
	</div>
</section>
	<div>
	<h2>
		Written by	</h2>
	
			<article>
	<div>
					<div>
				<picture>
					<source srcset="https://avatars.githubusercontent.com/u/176818?v=4&amp;s=200" width="120" height="120" media="(min-width: 768px)">
					<img src="https://avatars.githubusercontent.com/u/176818?v=4&amp;s=200" alt="Peter Stöckli" width="80" height="80" loading="lazy" decoding="async">
				</picture>
			</div>
				
					<p>Security Researcher at GitHub Security Lab</p>
			</div>
</article>
	</div>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How many artists' careers did the Beatles kill? (137 pts)]]></title>
            <link>https://www.cantgetmuchhigher.com/p/how-many-artists-did-the-beatles</link>
            <guid>43373765</guid>
            <pubDate>Sat, 15 Mar 2025 17:05:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cantgetmuchhigher.com/p/how-many-artists-did-the-beatles">https://www.cantgetmuchhigher.com/p/how-many-artists-did-the-beatles</a>, See on <a href="https://news.ycombinator.com/item?id=43373765">Hacker News</a></p>
Couldn't get https://www.cantgetmuchhigher.com/p/how-many-artists-did-the-beatles: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: A personal YouTube frontend based on yt-dlp (182 pts)]]></title>
            <link>https://github.com/christian-fei/my-yt</link>
            <guid>43373242</guid>
            <pubDate>Sat, 15 Mar 2025 15:45:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/christian-fei/my-yt">https://github.com/christian-fei/my-yt</a>, See on <a href="https://news.ycombinator.com/item?id=43373242">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">my-yt</h2><a id="user-content-my-yt" aria-label="Permalink: my-yt" href="#my-yt"></a></p>
<blockquote>
<p dir="auto">MYGA - make <em>you</em>tube <strong>great</strong> again</p>
</blockquote>
<p dir="auto">A clean and minimal youtube frontend, without all the ads and whistles.
Supported by yt-dlp, and optionally your local AI model, to make your youtube experience local, mindful, succint and ad free.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/christian-fei/my-yt/blob/main/preview.png"><img src="https://github.com/christian-fei/my-yt/raw/main/preview.png" alt="preview my-yt"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Channel management/Subscriptions</li>
<li>Download videos from YouTube, using <code>yt-dlp</code> behind the scenes</li>
<li>Summarize video content using your local AI model</li>
<li>Ignore videos you don't want to watch</li>
<li>Play videos in background</li>
<li>Offline media playback</li>
<li>No dependencies (except for <code>nano-spawn</code>), HTML/CSS only, no JS frameworks on client/server side</li>
<li>Host it in your home network to playback videos on all your devices</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why?</h2><a id="user-content-why" aria-label="Permalink: Why?" href="#why"></a></p>
<ul dir="auto">
<li><strong>Why not??</strong></li>
<li>wanted to get back my chronological feed, instead of a "algorithmically curated" one</li>
<li>no distractions, no ads, just videos and a clean UI</li>
<li>wanted to try integrate the so much hyped AI in a personal project</li>
<li>wanted to try out <code>yt-dlp</code></li>
<li>I am even paying for YouTube Premium, so it's not a matter of money, but a matter of control over my attention and offline experience</li>
</ul>
<blockquote>
<p dir="auto">Application runs on <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a></p>
</blockquote>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation (node.js)</h2><a id="user-content-installation-nodejs" aria-label="Permalink: Installation (node.js)" href="#installation-nodejs"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/christian-fei/my-yt.git
cd my-yt
npm i
# install yt-dlp, please see https://github.com/yt-dlp/yt-dlp

npm start"><pre>git clone https://github.com/christian-fei/my-yt.git
<span>cd</span> my-yt
npm i
<span><span>#</span> install yt-dlp, please see https://github.com/yt-dlp/yt-dlp</span>

npm start</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation (docker)</h2><a id="user-content-installation-docker" aria-label="Permalink: Installation (docker)" href="#installation-docker"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/christian-fei/my-yt.git
cd my-yt
docker compose up --build -d"><pre>git clone https://github.com/christian-fei/my-yt.git
<span>cd</span> my-yt
docker compose up --build -d</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project</h2><a id="user-content-project" aria-label="Permalink: Project" href="#project"></a></p>
<p dir="auto">Here are some links to help you understand the project better:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/server.js">server.js</a></h3><a id="user-content-serverjs" aria-label="Permalink: server.js" href="#serverjs"></a></p>
<p dir="auto">Bare HTTP server</p>
<p dir="auto">Handles SSE for client updates</p>
<p dir="auto">Implements HTTP Ranged requests for video playback</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/llm.js">llm.js</a></h3><a id="user-content-llmjs" aria-label="Permalink: llm.js" href="#llmjs"></a></p>
<p dir="auto">Makes requests using the chat completions API of LMStudio.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/sse.js">sse.js</a></h3><a id="user-content-ssejs" aria-label="Permalink: sse.js" href="#ssejs"></a></p>
<p dir="auto">Utility functions for Server-sent events</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/subtitles-summary.js">subtitles-summary.js</a></h3><a id="user-content-subtitles-summaryjs" aria-label="Permalink: subtitles-summary.js" href="#subtitles-summaryjs"></a></p>
<p dir="auto">Summarizes video transcript using LMStudio API</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/youtube.js">youtube.js</a></h3><a id="user-content-youtubejs" aria-label="Permalink: youtube.js" href="#youtubejs"></a></p>
<p dir="auto">yt-dlp wrapper to download videos, get channel videos and video information and transcript</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/blob/main/lib/repository.js">repository.js</a></h3><a id="user-content-repositoryjs" aria-label="Permalink: repository.js" href="#repositoryjs"></a></p>
<p dir="auto">Handles persistence of video information (set video as downloaded, summary, ignored, upserting videos, etc.)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://github.com/christian-fei/my-yt/tree/main/client">client</a></h3><a id="user-content-client" aria-label="Permalink: client" href="#client"></a></p>
<p dir="auto">dependency less, bare HTML5, CSS3 and JS for a basic frontend</p>
<p dir="auto">Handles SSE updates, interacting with the API</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">General information</h2><a id="user-content-general-information" aria-label="Permalink: General information" href="#general-information"></a></p>
<p dir="auto">Currently, on the LLM side of things:</p>
<ul dir="auto">
<li>supports basic chat completions API (LMStudio right now)
<ul dir="auto">
<li>expects <code>lms server</code> to be running on <code>http://localhost:1234</code></li>
</ul>
</li>
<li>works with <code>meta-llama-3.1-8b-instruct</code> model</li>
<li>customization will come in the future if there's enough interest (let me know by opening an issue or pull-request)</li>
</ul>
<hr>
<p dir="auto">Download the project while you can before I get striked with a DMCA takedown request</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Milk Kanban (287 pts)]]></title>
            <link>https://brodzinski.com/2025/03/milk-kanban.html</link>
            <guid>43373157</guid>
            <pubDate>Sat, 15 Mar 2025 15:32:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brodzinski.com/2025/03/milk-kanban.html">https://brodzinski.com/2025/03/milk-kanban.html</a>, See on <a href="https://news.ycombinator.com/item?id=43373157">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">

<figure><img fetchpriority="high" decoding="async" width="1024" height="580" src="https://brodzinski.com/wp-content/uploads/kanban-1-1024x580.jpg" alt="" srcset="https://brodzinski.com/wp-content/uploads/kanban-1-1024x580.jpg 1024w, https://brodzinski.com/wp-content/uploads/kanban-1-400x227.jpg 400w, https://brodzinski.com/wp-content/uploads/kanban-1-768x435.jpg 768w, https://brodzinski.com/wp-content/uploads/kanban-1-1536x870.jpg 1536w, https://brodzinski.com/wp-content/uploads/kanban-1-2048x1161.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>When people say Kanban, they tend to think of a specific set of practices. Whiteboards &amp; sticky notes (both almost universally virtual). Tasks moving through columns that represent workflow. Every now and then, WIP limits even.</p>



<p>As often as we do it with other things, it reduces a broader principle to a set of oversimplified techniques, which, in turn, tend to underdeliver in many contexts.</p>



<h2>Kanban</h2>



<p>In its original meaning, Kanban represented a visual signal. The thing that communicated, well, something. It might have been a need, option, availability, capacity, request, etc.</p>



<p>In our Kanban systems, the actual Kanban is a sticky note.</p>



<p>It represents work, and given its closest environment (board, columns, other stickies, visual decorators), it communicates what needs, or needs not, to be done.</p>



<p>If it’s yellow, it’s a regular feature. If there’s a blocker on it, it requests focus. If there’s a long queue of neighbors, it suggests flow inefficiency. If it’s a column named “ready for…” it communicates available work and/or handoff.</p>



<p>A visual signal all the way.</p>



<h2>Visual Signals</h2>



<p>Let’s decouple ourselves from the most standard Kanban board design. Let’s forget columns, sticky notes, and all that jazz.</p>



<p>Enters Kasia, our office manager at Lunar. One of the many things Kasia takes care of is making sure we don’t run out of kitchen supplies. The tricky part is that when you don’t drink milk yourself, it becomes a pain to check the cupboard with milk reserves every now and then to ensure we’re stocked.</p>



<p>Then, one day, I found this.</p>



<figure><img decoding="async" width="1024" height="681" src="https://brodzinski.com/wp-content/uploads/milk-kanban-1-1024x681.jpg" alt="" srcset="https://brodzinski.com/wp-content/uploads/milk-kanban-1-1024x681.jpg 1024w, https://brodzinski.com/wp-content/uploads/milk-kanban-1-400x266.jpg 400w, https://brodzinski.com/wp-content/uploads/milk-kanban-1-768x510.jpg 768w, https://brodzinski.com/wp-content/uploads/milk-kanban-1-1536x1021.jpg 1536w, https://brodzinski.com/wp-content/uploads/milk-kanban-1-2048x1361.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>A simple index card taped to the last milk carton in a row stating, “Bring me to Kasia.” That’s it.</p>



<p>In the context, it really says that:</p>



<ul>
<li>we’re running out of (specific kind of) milk</li>



<li>we want to restock soon</li>



<li>there’s enough time to make an order (we don’t drink that much of cappuccinos and macchiatos)</li>
</ul>



<p>But it’s just a visual signal. Kanban at its very core.</p>



<h2>Simplicity is the King</h2>



<p>What Kasia designed is a perfect Kanban system. It relies on visual signals, which are put in the context. Even better, unlike most Kanban boards I see across teams, the system is self-explanatory. Everything one needs to know is written on the index card.</p>



<p>That’s, by the way, another characteristic of a good Kanban system. It should be as simple as possible (but not simpler). Our workflow representations <a href="https://brodzinski.com/2011/01/kanban-board-keep-it-simple.html">tend to get more and more complex over time by themselves</a>; we don’t need to make them so from the outset.</p>



<p>It’s a safe assumption that, almost always, there’s a simpler visualization that would work just as well. We, process designers, often fall into the trap of overengineering our tools.</p>



<p>And it’s a healthy wake-up call when someone who knows close to nothing about our fancy stuff designs a system that we would unlikely think of. One that is a perfect implementation of the original spirit, even if it doesn’t follow any of the common techniques.</p>



<p>Because it’s all about <a href="https://brodzinski.com/2014/08/practices-principles-values.html">principles, not practices</a>.</p>



<p>That’s what we can learn from Milk Kanban.</p>




				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Arbitrary-Scale Super-Resolution with Neural Heat Fields (129 pts)]]></title>
            <link>https://therasr.github.io/</link>
            <guid>43371583</guid>
            <pubDate>Sat, 15 Mar 2025 10:39:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://therasr.github.io/">https://therasr.github.io/</a>, See on <a href="https://news.ycombinator.com/item?id=43371583">Hacker News</a></p>
Couldn't get https://therasr.github.io/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Finland's National Allergy Program Successfully Reduces Allergic Diseases (178 pts)]]></title>
            <link>https://publications.ersnet.org/content/erj/49/6/1700470</link>
            <guid>43370956</guid>
            <pubDate>Sat, 15 Mar 2025 08:23:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://publications.ersnet.org/content/erj/49/6/1700470">https://publications.ersnet.org/content/erj/49/6/1700470</a>, See on <a href="https://news.ycombinator.com/item?id=43370956">Hacker News</a></p>
Couldn't get https://publications.ersnet.org/content/erj/49/6/1700470: Error [ERR_FR_TOO_MANY_REDIRECTS]: Maximum number of redirects exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Transformers Without Normalization (228 pts)]]></title>
            <link>https://jiachenzhu.github.io/DyT/</link>
            <guid>43369633</guid>
            <pubDate>Sat, 15 Mar 2025 03:12:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jiachenzhu.github.io/DyT/">https://jiachenzhu.github.io/DyT/</a>, See on <a href="https://news.ycombinator.com/item?id=43369633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- Figure Section -->
        <div id="figure">
                <p><img src="https://jiachenzhu.github.io/DyT/webpage_assets/before_after.svg" alt="Dynamic Tanh (DyT) as a replacement for normalization in Transformers"></p><p><em>Left:</em> original Transformer block. <em>Right:</em> block with our proposed Dynamic Tanh (DyT) layer. <br>
                    DyT is a straightforward replacement for commonly used Layer Norm or RMSNorm layers. <br>
                    Transformers with DyT match or exceed the performance of their normalized counterparts.
                </p>
            </div>

        <!-- Abstract Section -->
        <section id="abstract">
            <h2>Abstract</h2>
                <p>
                    Normalization layers are ubiquitous in modern neural networks and have long been considered essential.
                    This work demonstrates that Transformers without normalization can achieve the same or better performance using a remarkably simple technique.
                    We introduce Dynamic Tanh (DyT), an element-wise operation $$\mathrm{DyT}(\boldsymbol{x}) = \tanh(\alpha \boldsymbol{x}),$$ as a drop-in replacement for normalization layers in Transformers.
                    DyT is inspired by the observation that layer normalization in Transformers often produces tanh-like, S-shaped input-output mappings.
                    By incorporating DyT, Transformers without normalization can match or exceed the performance of their normalized counterparts, mostly without hyperparameter tuning.
                    We validate the effectiveness of Transformers with DyT across diverse settings, ranging from recognition to generation, supervised to self-supervised learning, and computer vision to language models.
                    These findings challenge the conventional understanding that normalization layers are indispensable in modern neural networks, and offer new insights into their role in deep networks.
                </p>
        </section>
        
        <!-- Implementation Section -->
        <section id="implementation">
            <h2>Implementation</h2>
            <p>
                DyT module can be implemented in a few lines of PyTorch code:
            </p>
            
            <div>
                <pre id="code-block-dyt"><code>class DyT(nn.Module):
    def __init__(self, num_features, alpha_init_value=0.5):
        super().__init__()
        self.alpha = nn.Parameter(torch.ones(1) * alpha_init_value)
        self.weight = nn.Parameter(torch.ones(num_features))
        self.bias = nn.Parameter(torch.zeros(num_features))
    
    def forward(self, x):
        x = torch.tanh(self.alpha * x)
        return x * self.weight + self.bias</code></pre>
            </div>
        </section>

        <!-- Key Findings Section -->
        <section id="key-findings">
            <h2>Key Findings</h2>
            
            <div>
                    
                            <h4>Layer Normalization Behaves Like Scaled Tanh Function</h4>
                            <p>Our analysis shows that layer normalization (LN) in Transformers generates input-output mappings that closely resemble scaled tanh functions. In the earlier layers, these mappings are mostly linear. However, in deeper layers, they take on distinct S-shaped curves characteristic of tanh functions.</p>
                            
                            <div>
                                <p><img src="https://jiachenzhu.github.io/DyT/webpage_assets/figures/inout_vit.png" alt="Input-output relationships in ViT normalization layers">
                                </p>
                                <p><img src="https://jiachenzhu.github.io/DyT/webpage_assets/figures/inout_w2v.png" alt="Input-output relationships in wav2vec 2.0 normalization layers">
                                </p>
                                <p><img src="https://jiachenzhu.github.io/DyT/webpage_assets/figures/inout_dit.png" alt="Input-output relationships in DiT normalization layers">
                                </p>
                                <p><em>Output vs. input of selected LN layers in Vision Transformer (ViT), wav2vec 2.0 (a Transformer model for speech), and Diffusion Transformer (DiT). We plot the input/output values of four LN layers in each model. The S-shaped curves highly resemble that of a tanh function.</em>
                                </p>
                            
                            </div>
                        
                </div>


        <!-- Evaluation Section -->
        <section id="evaluation">
            <h2>Evaluation</h2>
            <p>
                We present a comprehensive evaluation of DyT across a diverse range of architectures and tasks, highlighting its effectiveness and generalizability.  
                Our experiments cover supervised learning in vision (<b>ViT</b> and <b>ConvNeXt</b>), self-supervised learning in vision (<b>MAE</b> and <b>DINO</b>), diffusion models (<b>DiT</b>), large language models (<b>LLaMA</b>), self-supervised learning in speech (<b>wav2vec 2.0</b>), and DNA sequence modeling (<b>HyenaDNA</b> and <b>Caduceus</b>).  
                In every case, Transformers with DyT achieves similar or better performance than their normalized counterparts.  
                For detailed results and comparisons, please refer to our paper.    
            </p>
        </section>                    
                        

            

        <!-- Resources Section -->
        <section id="resources">
            <h2>Resources</h2>
            <div>
                <div>
                            <h5><i></i>Paper</h5>
                            <p>Download our paper for all the details about our research.</p>
                            <p><a href="https://arxiv.org/abs/2503.10622">Download Paper</a>
                        </p></div>
                <div>
                            <h5><i></i>Code</h5>
                            <p>Check out our repository for implementation details.</p>
                            <p><a href="https://github.com/jiachenzhu/DyT">View on GitHub</a>
                        </p></div>
                <div>
                            <h5><i></i>Summary</h5>
                            <p>Read a concise summary of our research findings on X.</p>
                            <p><a href="https://x.com/liuzhuang1234/status/1900370738588135805">View Summary</a>
                        </p></div>
            </div>
        </section>

        <!-- Citations Section -->
        <!-- Citations Section -->
<!-- Citations Section -->
<section id="citations">
    <h2>BibTeX</h2>
            <div>
                <pre id="code-block-citation"><code>@inproceedings{Zhu2025DyT,
  title={Transformers without Normalization},
  author={Zhu, Jiachen and Chen, Xinlei and He, Kaiming and LeCun, Yann and Liu, Zhuang},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025}
}</code></pre>

    </div>
</section>

        <section>
            <h2>Correspondence</h2>
            <div>
                <p>jiachen [dot] zhu [at] nyu [dot] edu</p>
                <p>zhuangl [at] princeton [dot] edu</p>
                <!-- <p></p> -->
            </div>
        </section>
    </section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Being Forced to Sell Chrome Is Not Good for the Web (188 pts)]]></title>
            <link>https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/</link>
            <guid>43369230</guid>
            <pubDate>Sat, 15 Mar 2025 01:57:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/">https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/</a>, See on <a href="https://news.ycombinator.com/item?id=43369230">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>You’ve got a monopoly on lemonade because you pay all the grocery stores to be the default lemonade. </p>



<p>So we’re going to force you sell your car. </p>



<p>What’s with the weird redirect? If the monopoly is directly caused by paying the grocery stores for placement, then stop <em>that part.</em> </p>



<p>We can see this exact redirect happening in the ruling in the U.S. vs Google court case.</p>



<blockquote>
<div><p>Google is a monopolist, and it has acted as one to maintain its monopoly. </p><p>[…]</p><p>For years, Google has secured default placements through distribution contracts. It has entered into such agreements with browser developers, mobile device manufacturers, and wireless carriers.</p><p>[…]</p><p>Because many users simply stick to searching with the default, Google receives billions of queries every day through those access points. </p></div>
<cite>Judge Mehta</cite></blockquote>



<p>In the document:</p>







<p>It’s spelled out quite clearly that being the default is the monopolistic part and that’s caused by paying for it (which is then self-perpetuating as the placement is so valuable, the money generated by it pays for those default placements.)</p>



<p>Fair enough! Let’s stop that. </p>



<p>Let’s stop the monopoly by telling Google they can’t pay (certain? all?) companies to be the default search engine anymore. A step further could be forcing browsers should ask users what they want their default search engine to be.</p>



<p>This would be in line with how Apple was forced to <a href="https://developer.apple.com/support/browser-choice-screen/">allow for browser choice</a>:</p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1024" height="612" data-attachment-id="12076" data-permalink="https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/screenshot-2025-03-12-at-12-52-03-pm/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?fit=1620%2C968&amp;ssl=1" data-orig-size="1620,968" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2025-03-12 at 12.52.03 PM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?fit=300%2C179&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?fit=1024%2C612&amp;ssl=1" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?resize=1024%2C612&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?resize=1024%2C612&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?resize=300%2C179&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?resize=768%2C459&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?resize=1536%2C918&amp;ssl=1 1536w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-12-at-12.52.03%E2%80%AFPM.png?w=1620&amp;ssl=1 1620w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<p>That’s a straight line from problem to solution. </p>



<p>A weird curvy-ass line between problem and solution is this strange solution that is being relentlessly proposed that Google should be forced to <em>sell Chrome.</em></p>



<p>There is a recent round of news covering this that all point to the curvy-ass-line solution. </p>



<ul>
<li><a href="https://www.usatoday.com/story/tech/2025/03/11/google-sell-chrome-doj-antitrust/82277792007/">USA Today</a>: “Google&nbsp;will have to part with its dominant Chrome browser if&nbsp;the U.S. Department of Justice&nbsp;has its way.”</li>



<li><a href="https://www.wired.com/story/the-doj-still-wants-google-to-divest-chrome/">WIRED</a>: “the Department of Justice reiterated that Google should stop paying partners for search placement—and divest its dominant Chrome browser.”</li>



<li><a href="https://arstechnica.com/google/2025/03/doj-google-must-sell-chrome-android-could-be-next/">Ars Technica</a>: “the government maintains that Chrome must go if the playing field is to be made level again.”</li>
</ul>



<p>It’s true that Chrome ships with Google as the default search engine, because, ya know, they invested billions in Chrome and that’s how business works. But still, a more direct line from problem to solution is forcing default search engine choice, not a forced sale of Chrome itself. </p>



<p>Why do I care? The sale of Chrome is bad for the web.</p>



<p><a href="https://chriscoyier.net/2025/01/29/a-little-arm-chair-businessin-about-chrome/">I’ve written before</a> that Chrome is unusual in that it’s really only particularly useful to Google:</p>



<blockquote>
<p>Users don’t pay for Chrome. There aren’t ads in Chrome. There is no&nbsp;<em>direct</em>&nbsp;business model for Chrome. Unlike Safari and Firefox, nobody writes checks to Chrome to make a certain search engine the default.</p>



<p>The value of Chrome is all tangential — it provides value to Google. Whoever buys it does not inherit that same tangential value, they would need to redirect what little of it they can somewhere else, likely fighting against the natural flow that has been baked into it since the beginning.</p>
</blockquote>



<p>I’m not saying Google shouldn’t be forced to sell Chrome just because it’s only valuable to Google. But I do think Google should be allowed to have a browser. Google is a web business, that’s their whole thing. They <em>made</em> a browser to invest in the web itself because what is good for the web is good for Google, and happens to be good for all of us. </p>



<p>Allow me to be more clear about why Chrome is good for all of us. </p>



<p>When you look at (or otherwise experience) anything on a digital device, you’re looking at an operating system. That operating system was probably made by a private company who has total control over it. They have the right to do that, but that operating system exists to serve that company only and entirely. </p>



<p>If you make a native app for mobile devices, it is at the pleasure of the companies who build mobile operating systems and you’ll do it with the technology they allow. Making an app for iOS vs Android is super different and the companies behind them and never going to shake hands and make it easier for developers. It’s largely the same making a native app for desktop computers. While there is a bit more freedom of what you can install there, making a macOS app and a Windows app is two entirely separate endeavors. </p>



<p>Not so with the web. The web is a set of protocols and languages and file formats and other technology that congeal to make digital experiences. No one company owns or controls it. It is designed to be open and it’s <em>good</em> when companies build new things and support web standards. It’s a modern miracle that we have such a thing and it’s on us to protect it. </p>



<p>If I go to a <em>website</em> on iOS, Android, macOS, Windows, some Linux distro, my Samsung phone, or whatever device I have that has a web browser on it,<strong> it really is the same set of files</strong> that deliver that experience. You and I and every company in the world can build things once that go everywhere. That’s how it should be. It’s fair and efficient. It’s good for the world. It’s much better than a world where we are forced to build things only for companies proprietary operating systems.</p>



<p>Google, by virtue of having Chrome, invests heavily in <em>the web itself.</em> Not just Chrome-the-browser, but the web standards that power the web. I can’t claim to know every detail of that investment, but I personally know people employed by Google that literally just try to make the web better all day. </p>



<p>It’s not hard to poke around the W3C specs themselves and see them littered with Google employees. </p>



<figure data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/chriscoyier.net\/2025\/03\/14\/google-being-forced-to-sell-chrome-is-not-good-for-the-web\/&quot;}">
<figure><img data-recalc-dims="1" decoding="async" width="1024" height="820" data-attachment-id="12105" data-permalink="https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/screenshot-2025-03-14-at-8-23-29-am/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?fit=1064%2C852&amp;ssl=1" data-orig-size="1064,852" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2025-03-14 at 8.23.29 AM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?fit=300%2C240&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?fit=1024%2C820&amp;ssl=1" data-id="12105" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?resize=1024%2C820&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?resize=1024%2C820&amp;ssl=1 1024w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?resize=300%2C240&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?resize=768%2C615&amp;ssl=1 768w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.23.29%E2%80%AFAM.png?w=1064&amp;ssl=1 1064w" sizes="(max-width: 1000px) 100vw, 1000px"></figure>



<figure><img data-recalc-dims="1" decoding="async" width="812" height="462" data-attachment-id="12103" data-permalink="https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/screenshot-2025-03-14-at-8-22-26-am/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?fit=812%2C462&amp;ssl=1" data-orig-size="812,462" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2025-03-14 at 8.22.26 AM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?fit=300%2C171&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?fit=812%2C462&amp;ssl=1" data-id="12103" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?resize=812%2C462&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?w=812&amp;ssl=1 812w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?resize=300%2C171&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.22.26%E2%80%AFAM.png?resize=768%2C437&amp;ssl=1 768w" sizes="(max-width: 812px) 100vw, 812px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="812" height="490" data-attachment-id="12104" data-permalink="https://chriscoyier.net/2025/03/14/google-being-forced-to-sell-chrome-is-not-good-for-the-web/screenshot-2025-03-14-at-8-20-27-am/" data-orig-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?fit=812%2C490&amp;ssl=1" data-orig-size="812,490" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot 2025-03-14 at 8.20.27 AM" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?fit=300%2C181&amp;ssl=1" data-large-file="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?fit=812%2C490&amp;ssl=1" data-id="12104" src="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?resize=812%2C490&amp;ssl=1" alt="" srcset="https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?w=812&amp;ssl=1 812w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?resize=300%2C181&amp;ssl=1 300w, https://i0.wp.com/chriscoyier.net/wp-content/uploads/2025/03/Screenshot-2025-03-14-at-8.20.27%E2%80%AFAM.png?resize=768%2C463&amp;ssl=1 768w" sizes="auto, (max-width: 812px) 100vw, 812px"></figure>
</figure>



<p>And there are evangelists, and documentation writers, and other people who aren’t working directly on Chrome, but really the web itself. </p>



<p>Will Google continue to invest like this if they are forced to sell Chrome? It would be hard to blame them if they did not. </p>



<p>Assuming they find a buyer, that buyer will be scrambling to find a way to make that investment worth it. Will they be choosing to employ people who are just <em>abstractly making the web better?</em> I would think not. </p>



<p>The web will suffer should Google be forced to sell Chrome. I think a fair assumption that overall investment and contribution to the open web will take a dive. </p>



<p>Sure, there will be some canonical fork of Chromium that keeps the sure-to-be-shunned buyer company out of it. Sure, the <a href="https://www.linuxfoundation.org/press/linux-foundation-announces-the-launch-of-supporters-of-chromium-based-browsers">Linux Foundation is getting their ducks in a row</a> to have contributors ready. But I can’t see it going well. </p>



<p>It won’t happen overnight, but stagnation will set in. A stagnated web is incentive for the operating system makers of the world to invest in pulling developers toward those proprietary systems. The browser wars sucked but at least we were still making websites. Being <em>forced</em> to make proprietary apps to reach people is an expensive prospect for the rest of us companies of the world, it will probably be done poorly, and we’ll all suffer for it. Heck, those operating systems aren’t required to ship a web browser <em>at all.</em></p>



<p>Whatever way this goes is bad for Mozilla. It’s possible Google is forced to not pay them for default search engine placement anymore, but even if they aren’t, you can imagine Google’s appetite for cutting that check is severely diminished. Mozilla’s <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">2020 layoffs</a> that was publicly about reducing platform development still has me thinking they aren’t entirely serious about pushing the web forward, particularly with much less help. </p>



<p>And bad things happening for Mozilla is <em>also</em> bad for the web, so another domino may fall. Diminishing investments in the web generally will keep knocking over dominos. </p>



<p>I’ve typed enough. Google does all kinds of shitty stuff. Their surely the worst offenders of user surveillance on the web. Let’s not let them off the hook on that. Let’s see the DOJ get involved in that stuff. But forcing a sale of Chrome is not the way. </p>


        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Popular GitHub Action tj-actions/changed-files is compromised (269 pts)]]></title>
            <link>https://semgrep.dev/blog/2025/popular-github-action-tj-actionschanged-files-is-compromised/</link>
            <guid>43368870</guid>
            <pubDate>Sat, 15 Mar 2025 00:43:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://semgrep.dev/blog/2025/popular-github-action-tj-actionschanged-files-is-compromised/">https://semgrep.dev/blog/2025/popular-github-action-tj-actionschanged-files-is-compromised/</a>, See on <a href="https://news.ycombinator.com/item?id=43368870">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>Popular GitHub Action <a rel="noopener noreferrer" href="https://github.com/tj-actions/changed-files">tj-actions/changed-files</a>&nbsp;has been compromised (<a rel="noopener noreferrer" href="https://github.com/tj-actions/changed-files/issues/2463">GitHub issue</a>) with a payload that appears to attempt to dump secrets, impacting thousands of CI pipelines.&nbsp;This isn’t the first security issue with tj-actions/changed-files—see prior vulnerability <a rel="noopener noreferrer" href="https://www.cve.org/CVERecord?id=CVE-2023-51664">CVE-2023-51664</a>.</p><h3>What you should do</h3><ol start="1"><li><p><strong>Find out where you're affected</strong></p><ol start="1"><li><p>The simplest way to find this is to grep for <code>tj-actions</code> in your codebase.</p></li><li><p>If you're on GitHub, look at the results of this query, replacing YOURORG with your organization's name on GitHub:&nbsp;<br><a href="https://github.com/search?q=org%3A">https://github.com/search?q=org%3A</a><a href="https://github.com/search?q=org%3A%3CYOURORG%3E+uses%3A+tj-actions%2F&amp;type=code">&lt;YOURORG&gt;+uses%3A+tj-actions%2F&amp;type=code</a></p></li><li><p>Arguably, Semgrep is overkill for this case. But Lewis Ardern on our team <a href="https://semgrep.dev/playground/r/10Uz5qo/semgrep.tj-actions-compromised">wrote a Semgrep rule to find usages of tj-actions</a>, which you can run locally (without sending code to the cloud) via: <code>semgrep --config r/10Uz5qo/semgrep.tj-actions-compromised</code>. And if we find more information about what tags &amp; commits are affected, we can update the rule over time to become more precise about whether or not you could be impacted. At time of writing, it looks like all versions are compromised.</p></li><li><p>For users of <a href="https://semgrep.dev/login">Semgrep AppSec Platform</a>, we recommend placing <a href="https://semgrep.dev/playground/r/10Uz5qo/semgrep.tj-actions-compromised">the detection rule in blocking mode immediately</a>: visit the rule, click “add to policy”, and select “blocking mode.”</p></li></ol></li></ol><ol start="2"><li><p><strong>Stop using </strong><code>tj-actions/changed-files</code><strong> immediately.</strong> Switch to a safer alternative or inline your file-change detection logic.</p><ol start="1"><li><p>Just removing it from the main branch of your repository won’t be enough — it could still run on other branches depending on how your actions are configured. So you need to remove it from <strong>all</strong> branches to be safe.</p></li><li><p>As an alternative, <a href="https://docs.github.com/en/organizations/managing-organization-settings/disabling-or-limiting-github-actions-for-your-organization#allowing-select-actions-and-reusable-workflows-to-run">GitHub has a feature that lets you allow-list GitHub actions</a> so you can ensure it won’t run, even if it’s still in your code.</p><ol start="1"><li><p>You’ll need a list of GitHub Actions used at your org. Run this query on your codebase:</p><pre><code>$ semgrep -e 'uses: $ACTION' -l yaml --json .github  | jq -r '.results[].extra.metavars["$ACTION"].abstract_content' | grep -vE '^(actions/|docker://|[.]/[.]github/|tj-actions/)' | awk -F'@' '{print $1 "@*,"}' | sort | uniq
DataDog/synthetics-ci-github-action@*,
actions-rs/toolchain@*,
astral-sh/setup-uv@*,
aws-actions/amazon-ecr-login@*,</code></pre></li><li><p>Remove tj-actions/changed-files from the list of GitHub Actions.</p></li><li><p>Go to GitHub settings and configure like this at:<br><a href="https://github.com/semgrep/semgrep-app/settings/actions">https://github.com/semgrep/semgrep-app/settings/actions</a><br><img src="https://semgrep.dev/assets/github-settings-configuration.png"></p></li></ol></li><li><p><strong>Generally, pin all GitHub Actions to specific commit SHAs (rather than version tags) you know are safe.</strong> In this case, it appears that all versions are compromised.</p></li><li><p><strong>Audit past workflow runs for signs of compromise.</strong> Check logs for suspicious outbound network requests. Prioritize repos where your CI runner logs are public, as secrets are dumped to stdout in the payload.</p></li></ol></li></ol><h3>Affected versions</h3><p>At time of writing (2025-03-14T23:55:00Z), we assessed by inspecting tag pointers in the source repo that all versions of tj-actions/changed-files are compromised. Users may verify with <code>git tag --points-at 0e58ed8</code> . See <a href="https://github.com/tj-actions/changed-files/commit/0e58ed8671d6b60d0890c21b07f8835ace038e67">commit 0e58ed8</a> in <a href="https://github.com/tj-actions/changed-files.">https://github.com/tj-actions/changed-files.</a></p><h3>Further reading</h3><ul><li><p><a href="https://www.stepsecurity.io/blog/harden-runner-detection-tj-actions-changed-files-action-is-compromised">StepSecurity’s Incident Analysis</a></p></li><li><p><a href="https://github.com/tj-actions/changed-files/issues/2463">https://github.com/tj-actions/changed-files/issues/2463</a></p></li><li><p><a href="https://www.cve.org/CVERecord?id=CVE-2023-51664">CVE-2023-51664</a></p></li></ul>
                  </div><div>
  <header>
    <h4>About</h4>
    <img src="https://semgrep.dev/build/assets/semgrep-logo-dark-F_zJCZNg.svg">
  </header>
  <p>
    Semgrep lets security teams partner with developers and shift left organically, without introducing friction. Semgrep gives security teams confidence that they are only surfacing true, actionable issues to developers, and makes it easy for developers to fix these issues in their existing environments. 
  </p>
</div></div>]]></description>
        </item>
    </channel>
</rss>