<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 01 Aug 2024 13:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[How I Got My Laser Eye Injury (173 pts)]]></title>
            <link>https://www.funraniumlabs.com/2024/07/how-i-got-my-laser-eye-injury/</link>
            <guid>41127706</guid>
            <pubDate>Thu, 01 Aug 2024 10:25:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.funraniumlabs.com/2024/07/how-i-got-my-laser-eye-injury/">https://www.funraniumlabs.com/2024/07/how-i-got-my-laser-eye-injury/</a>, See on <a href="https://news.ycombinator.com/item?id=41127706">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-5453">

<div>
<p><span>It has been brought to my attention that I have never actually written this story down before, merely told it in person to many students for valuable lessons and also for laughs over cocktails. It is a litany of bad ideas from several people that all came together at once to reach out and zap me.</span></p>
<p><span><strong>DISCLAIMER FOR THE SQUEAMISH:</strong> My eyes and vision are fine. There was some slight retinal bleaching in the peripheral vision of my right eye. If I hold up a large plane of white paper in front of me, like when helping a friend make posters for Ren Faire, there’s a small patch of yellowish tint in the lower right corner. Not a big deal, but damage is damage.</span></p>
<p><span><em>[Scene – A very overcast morning in the spring of 1999. Exterior driveway between Building 6 &amp; 15 of $LASER_COMPANY, roughly 10am]</em></span></p>
<p><span>It was a day much like any other in my four years, five months and eighteen days of working there, not that I was counting or anything. After checking on a couple laser labs and talking to people, I needed to go across the way to visit the optics coating facility. So, I walked out the side door of Building 6 to cross the driveway, go down the stairs and over to the loading dock of Building 15. As I was walking across the driveway, I heard a weird noise. Something was rhythmically clicking away a bit faster than once a second. My thought process went a bit like this.</span></p>
<blockquote><p><span>Me: What is that noise?</span><br>
<span>Me [a few seconds later]: Ohhhhh, I know that noise. That’s the flashlamps of a Quanta-Ray system going off.</span><br>
<span>Me [immediately after, spinning on my heels to head toward the source of the sound]: Why am I hearing this outside?</span></p></blockquote>
<p><span>It was at some point while walking that way and waving my hands and yelling “SHUT IT DOWN!!!” that I took my laser hit from a scattered, fractional beam from the shenanigans going on (I didn’t notice the damage from the hit until several months later). I am going to try to describe what I saw in enough detail that hopefully you can reconstruct the scene in your head, because I don’t want to use my non-existent art skill in Paint to draw this.</span></p>
<figure id="attachment_5454" aria-describedby="caption-attachment-5454"><a href="https://www.funraniumlabs.com/wp-content/uploads/2024/07/Qaunta-Ray.jpg"><img fetchpriority="high" decoding="async" src="https://www.funraniumlabs.com/wp-content/uploads/2024/07/Qaunta-Ray.jpg" alt="" width="226" height="300"></a><figcaption id="caption-attachment-5454"><span>Quanta Ray PRO350 with frequency doubling, emitting a 532nm beam – Sales brochure image from Quanta Ray, unknown date</span></figcaption></figure>
<p><span>The back of&nbsp; Building 6 had their shipping and receiving area and the rear parking lot. In the parking spaces closest to the shipping &amp; receiving area, several spaces had been taken up by a Quanta-Ray’s power supply, a Rubbermaid cart with a large Quanta-Ray laser balanced on it, and it was connected to some Caltrans utility trailer looking contraption downstream and in line with the output aperture of the laser. Beyond the contraption trailer was a VP of Sales’ brand new cherry red Jeep Grand Cherokee. There were umbilicals for chilled water and power running across the parking lot back into the loading dock. Three men are standing behind the laser with another rolling cart being used as moveable workbench, fiddling with the controls for the laser and the contraption it was connected to on the trailer. Two of them were wearing laser safety eyewear. The third, one of our sales engineers who is named Bob, was not wearing any.</span></p>
<p><span>After making sure everything was shut down, I assessed the scene and realized something had gone wrong beyond simply “this entire situation”. This was a sales demo for prospective customers gone horribly awry. I identified myself as the Laser Safety Officer and that I had some questions. The customers looked very much like they wanted to be anywhere but here.</span></p>
<blockquote><p><span>Me: May I see your glasses?</span><br>
<span>[Customers 1 &amp; 2 hand me them]</span><br>
<span>Me: These are argon filters. Are these your glasses at you brought with you?</span><br>
<span>Customer 1: Yes.</span><br>
<span>Me: Shame you’re working with a Nd:YAG laser, not an argon one.</span><br>
<span>Customer 2: Better than nothing, right?</span><br>
<span>Me: These are utterly useless at 1064nm. You both should go make appointments with your ophthalmologists. But at least you understood that you need gogs. Bob, where are yours?</span><br>
<span>Bob: In the lab.</span><br>
<span>Me: Would that be the lab that this laser was in before you wheeled it outside?</span><br>
<span>Bob: Yes.</span><br>
<span>Me: Bob, why is this laser outside? What are you even doing here?</span><br>
<span>Customer 1: You see, we had an idea…</span></p></blockquote>
<p><span>I want to say that, on first blush, their idea was admirable. They were trying to come up with a less destructive way to remove striping from roadways. You have to grind that stuff off, which damages the road surface, leading to increased wear &amp; tear and thus potholes. Their solution was to do it with a laser instead.</span></p>
<blockquote><p><span>Me: Let me see if I understand this right. You want to mount a high power laser on a cart, towed by a Caltrans or contractor truck, to burn the striping off roads?</span><br>
<span>Customer 1: Yes, ingenious isn’t it?</span><br>
<span>Me: The striping with <strong>REFLECTIVE</strong> paint?</span><br>
<span>Customer 2 [looks with concern at Customer 1]: Umm.</span><br>
<span>Me: I’m sure you can find a way with enough power.</span><br>
<span>Customer 1: But look, it worked!</span></p></blockquote>
<p><span>The customer motioned for me to look at the parking lot space stripe that a whole bunch of of round spots on it which had, indeed, burnt the paint off the asphalt.</span></p>
<blockquote><p><span>Me: Bob, $FACILITIES_GUY is going to kill you. He&nbsp;<em>just</em> repaved and striped this parking lot a couple of weeks ago.</span><br>
<span>Bob: [looks morose, as he’s starting to get an inkling of how bad this looks]</span><br>
<span>Me: But you’ve been having some trouble, haven’t you?</span><br>
<span>Customer 1 [surprised]: Yes! We can’t get beam no matter what we do.</span><br>
<span>Me: That’s because you’ve blown the coating on one of your steering optics.</span><br>
<span>Customer 1 &amp; 2: How do you know?</span><br>
<span>Me: Because your beam is not being steered to raster the stripe on the ground. Instead, it’s been firing a flat beam forward and doing a raster scan of [gestures] that Grand Cherokee.</span></p></blockquote>
<p><span>Bob and Customer 1 &amp; 2 looked up to see the stripe of exposed metal on the door of the VP of Sales’ car where the paint had been burnt away. On closer inspection, we later leaned that the Quanta-Ray had burnt through the wheel well and cut the brake line. At this point, I decided I want to really rub in what a terrible idea all this was to them. How they had failed on so many levels.</span></p>
<blockquote><p><span>Me: That’s $VP_of_Sales’ car, isn’t it Bob?</span><br>
<span>Bob: [groans] Yes.</span><br>
<span>Me: Pretty sure that’s your boss, Bob.</span><br>
<span>Bob: Yeah.</span><br>
<span>Me: When did you start doing this?</span><br>
<span>Customer 1: Around 8am.</span><br>
<span>Me: And when did you start having problems?</span><br>
<span>Customer 1: 8:30ish, maybe?</span><br>
<span>Me: Ah, so you were lasing through break time. Bob, what’s behind the car?</span><br>
<span>Bob: Building 15.</span><br>
<span>Me: $VP_of_Sales doesn’t normally get here until after 9am and the roach coach always pulls up at the loading dock of Building 15 at 8:45. So, hopefully you were aiming above eye level for all the employees on break. Also, that exposed brushed steel on the Cherokee is a mirror for near-infrared, so you’ve been shining that beam right back at yourselves. You <em>definitely</em> should call your ophthalmologists. But what’s behind you, Bob?</span><br>
<span>Bob: The fence.</span><br>
<span>Me: What kind of fence is it?</span><br>
<span>Bob: Chain-link.</span><br>
<span>Me: So, not a solid fence then. What’s on the other side of the fence, Bob?</span><br>
<span>Bob: [now staring at the ground in shame] The elementary school.</span><br>
<span>Me: If you’re very lucky, recess happened before your optic failed but we’re still gonna have to send a letter to the school about a potential exposure. Of course, that brushed steel mirror isn’t flat, which means your reflections went all over. Bob, what’s above us?</span><br>
<span>Bob: [picking up where I was going] Planes.</span><br>
<span>Me: How many airports worth of airspace travels over us?</span><br>
<span>Bob: SFO, Oakland, San Jose, the tiny municipal ones.</span><br>
<span>Me: You forgot a really important one. Our neighbor, Moffett fucking Field. Firing a laser into military airspace is an act of war. Are you declaring war on the United States, Bob?</span><br>
<span>Bob: [stands silently]</span><br>
<span>Me: Bob, what else is above us?</span><br>
<span>Bob: [looks up] Clouds.</span></p></blockquote>
<p><span>Because timing is the essence of comedy, that would be when it started to rain on the quarter million dollar laser system, destroying it. Bob no longer worked at $LASER_COMPANY two weeks later.</span></p>
<p><strong>MORAL: </strong>Of all the bystanders you could injure, DO NOT HURT THE SAFETY PERSON.</p>
<p>~fin~</p>
</div>

</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coinbase awarded a $500k bug bounty (138 pts)]]></title>
            <link>https://hackerone.com/coinbase/hacktivity</link>
            <guid>41127446</guid>
            <pubDate>Thu, 01 Aug 2024 09:40:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackerone.com/coinbase/hacktivity">https://hackerone.com/coinbase/hacktivity</a>, See on <a href="https://news.ycombinator.com/item?id=41127446">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Breakthrough a step toward revealing hidden structure of prime numbers (164 pts)]]></title>
            <link>https://www.science.org/content/article/sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers</link>
            <guid>41126944</guid>
            <pubDate>Thu, 01 Aug 2024 07:34:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/content/article/sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers">https://www.science.org/content/article/sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers</a>, See on <a href="https://news.ycombinator.com/item?id=41126944">Hacker News</a></p>
Couldn't get https://www.science.org/content/article/sensational-breakthrough-marks-step-toward-revealing-hidden-structure-prime-numbers: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Killing Games – European Citizens' Initiative (241 pts)]]></title>
            <link>https://www.stopkillinggames.com/eci</link>
            <guid>41126782</guid>
            <pubDate>Thu, 01 Aug 2024 06:59:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.stopkillinggames.com/eci">https://www.stopkillinggames.com/eci</a>, See on <a href="https://news.ycombinator.com/item?id=41126782">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Study: Consumers Actively Turned Off by AI (140 pts)]]></title>
            <link>https://futurism.com/the-byte/study-consumers-turned-off-products-ai</link>
            <guid>41126685</guid>
            <pubDate>Thu, 01 Aug 2024 06:38:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://futurism.com/the-byte/study-consumers-turned-off-products-ai">https://futurism.com/the-byte/study-consumers-turned-off-products-ai</a>, See on <a href="https://news.ycombinator.com/item?id=41126685">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="incArticle"><h2>"When AI is mentioned, it tends to lower emotional trust, which in turn decreases purchase intentions."</h2><h2>Trough Luck</h2><p>Researchers have found that including the words "artificial intelligence" in product marketing is a major turn-off for consumers, suggesting a growing backlash and disillusionment with the tech — and that startups trying to cram "AI" into their product are actually making a grave error.</p><p>As detailed in a <a href="https://www.tandfonline.com/doi/full/10.1080/19368623.2024.2368040">new study</a> published in the <em>Journal of Hospitality Marketing &amp; Management</em>, researchers presented 1,000 respondents with questions and descriptions of products. Surprisingly — or <a href="https://futurism.com/google-ai-ad-sad">perhaps not</a>, depending on <a href="https://futurism.com/the-byte/ai-adding-work-study">your perspective</a> — they found that products described as using AI were consistently less popular.</p><p>"When AI is mentioned, it tends to lower emotional trust, which in turn decreases purchase intentions," said lead author and Washington State University clinical assistant profess of marketing Mesut Cicek in a <a href="https://news.wsu.edu/press-release/2024/07/30/using-the-term-artificial-intelligence-in-product-descriptions-reduces-purchase-intentions/">statement</a>. "We found emotional trust plays a critical role in how consumers perceive AI-powered products."</p><h2>Strong Pass</h2><p>In an experiment, the researchers found that a group of participants were far less likely to purchase a smart television when its description included the words "artificial intelligence." A separate group was far <em>more</em> likely to buy it when the words were omitted from an otherwise identical description.</p><p>For "high-risk" purchases such as expensive electronics or medical devices, the effect was even more pronounced, with Cicek suggesting that consumers are more wary of monetary loss or danger to physical safety.</p><p>"We tested the effect across eight different product and service categories, and the results were all the same: it’s a disadvantage to include those kinds of terms in the product descriptions," Cicek said.</p><p>That kind of growing mistrust is symptomatic of a much larger trend. Earlier this year, technology research and consulting firm Gartner found that the hype surrounding generative AI had passed the "peak of inflated expectations," which is marked by "overenthusiasm and unrealistic projections."</p><p>Companies are feverishly trying to stuff what they claim to be AI into every product, from <a href="https://futurism.com/bumble-founder-future-ai-dating-other-ais">dating apps</a> to <a href="https://futurism.com/the-byte/ai-bot-disabled-dpd">automated car salesmen</a> — despite <a href="https://futurism.com/meta-ai-trump-wasnt-shot">glaring shortcomings</a> that have yet to be solved and <a href="https://futurism.com/investors-concerned-ai-making-money">mounting, astronomical costs</a>.</p><p>And consumers are getting tired of their desperate attempts to capitalize on all the hype.</p><p>"Marketers should carefully consider how they present AI in their product descriptions or develop strategies to increase emotional trust," said Cicek. "Emphasizing AI may not always be beneficial, particularly for high-risk products. Focus on describing the features or benefits and avoid the AI buzzwords."</p><p><strong>More on AI:</strong> <em><a href="https://futurism.com/meta-ai-trump-wasnt-shot">Meta's AI Says Trump Wasn't Shot</a></em></p><br></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[This month in Servo: console logging, parallel tables, OpenXR, and more (127 pts)]]></title>
            <link>https://servo.org/blog/2024/07/31/this-month-in-servo/</link>
            <guid>41126130</guid>
            <pubDate>Thu, 01 Aug 2024 04:21:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://servo.org/blog/2024/07/31/this-month-in-servo/">https://servo.org/blog/2024/07/31/this-month-in-servo/</a>, See on <a href="https://news.ycombinator.com/item?id=41126130">Hacker News</a></p>
<div id="readability-page-1" class="page"><p><span>2024-07-31</span> Servo’s unique parallel layout engine just got even better.</p><div>
  <figure><a href="https://servo.org/img/blog/quest-3-passthrough.png"><img src="https://servo.org/img/blog/quest-3-passthrough.png" alt="Servo displaying WebXR content on a Quest 3 in Quest Link mode"></a>
<figcaption>Figure 1: Servo can now render to XR headsets via OpenXR. Image: Daniel Adams (<a href="https://twitter.com/msub2official/status/1818533316477251669">Twitter</a>)</figcaption></figure>
<p><span></span>
Servo has had several new features land in our nightly builds over the last month:</p>
<ul>
<li>as of 2024-06-27, <strong>document.fonts.ready</strong> (<a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/servo/servo/pull/32576">#32576</a>)</li>
<li>as of 2024-07-03, the <strong>getCompilationInfo() method on GPUShaderModule</strong> (<a href="https://github.com/sagudev">@sagudev</a>, <a href="https://github.com/servo/servo/pull/32642">#32642</a>)</li>
<li>as of 2024-07-08, window.<strong>customElements.getName</strong> (<a href="https://github.com/keithamus">@keithamus</a>, <a href="https://github.com/servo/servo/pull/32715">#32715</a>)</li>
<li>as of 2024-07-09, <strong>&lt;caption&gt; in tables</strong> (<a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/Loirooriol">@Loirooriol</a>, <a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/servo/servo/pull/32657">#32657</a>, <a href="https://github.com/servo/servo/pull/32695">#32695</a>)</li>
<li>as of 2024-07-13, <strong>document.visibilityState</strong> and <strong>document.hidden</strong> (<a href="https://github.com/wusyong">@wusyong</a>, <a href="https://github.com/servo/servo/pull/32635">#32635</a>)</li>
<li>as of 2024-07-18, the <strong>measureText() method on CanvasRenderingContext2D</strong> (<a href="https://github.com/chocolate-pie">@chocolate-pie</a>, <a href="https://github.com/servo/servo/pull/32704">#32704</a>)</li>
<li>as of 2024-07-23, <strong>URL.parse()</strong> (<a href="https://github.com/shanehandley">@shanehandley</a>, <a href="https://github.com/servo/servo/pull/32819">#32819</a>)</li>
</ul>
<p>We’ve also landed an experimental <strong>OpenXR backend</strong> (<a href="https://github.com/msub2">@msub2</a>, <a href="https://github.com/servo/servo/pull/32817">#32817</a>), allowing Servo to display WebXR content on actual headsets like the <strong>Quest 3</strong> in Quest Link mode.
You can enable it with <code>--pref dom.webxr.openxr.enabled</code>, though the backend currently only works on Windows.</p>
<figure><a href="https://servo.org/img/blog/july-2024.png"><img src="https://servo.org/img/blog/july-2024.png" alt="Servo nightly showing a table with a caption, containing demos of several other new features"></a>
<figcaption>Figure 2: a table with a caption, containing demos of several other new features.</figcaption></figure>
<h2 id="rendering-changes" tabindex="-1"><span></span>Rendering changes <a href="#rendering-changes">
        <span><i></i></span>
      </a></h2>
<p><strong>Parallel table layout</strong> is now enabled (<a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/servo/servo/pull/32477">#32477</a>), spreading the work for laying out rows and their columns over all available CPU cores.
This change is a great example of the strengths of <a href="https://crates.io/crates/rayon">Rayon</a> and the opportunistic parallelism in Servo’s layout engine.</p>
<p>We‘ve also made progress on our new <strong>flexbox layout engine</strong> (<code>--pref layout.flexbox.enabled</code>), landing support for <strong>‘min-height’</strong> and <strong>‘max-height’</strong> on row containers (<a href="https://github.com/delan">@delan</a>, <a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/servo/servo/pull/32785">#32785</a>), as well as <strong>baseline alignment of row containers</strong> with their siblings (<a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/delan">@delan</a>, <a href="https://github.com/servo/servo/pull/32841">#32841</a>, <a href="https://github.com/servo/servo/pull/32810">#32810</a>) and for their items by setting <strong>‘align-items’</strong> or <strong>‘align-self’</strong> to <strong>‘baseline’</strong>, <strong>‘first baseline’</strong>, or <strong>‘last baseline’</strong> (<a href="https://github.com/delan">@delan</a>, <a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/nicoburns">@nicoburns</a>, <a href="https://github.com/servo/servo/pull/32787">#32787</a>, <a href="https://github.com/servo/servo/pull/32790">#32790</a>).</p>

<p>We’ve landed support for <strong>generic font families</strong> like ‘sans-serif’ and ‘monospace’ (<a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/mukilan">@mukilan</a>, <a href="https://github.com/servo/servo/pull/32673">#32673</a>), as well as <strong>commas in &lt;font face&gt;</strong> (<a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/servo/servo/pull/32622">#32622</a>) and fixes for font matching on Android and OpenHarmony (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32725">#32725</a>, <a href="https://github.com/servo/servo/pull/32731">#32731</a>).</p>
<p>For <strong>replaced elements</strong> like &lt;img&gt; and &lt;canvas&gt;, the <strong>‘min-width’</strong>, <strong>‘max-width’</strong>, <strong>‘min-height’</strong>, and <strong>‘max-height’</strong> properties now <strong>respect the aspect ratio</strong> of the element (<a href="https://github.com/valadaptive">@valadaptive</a>, <a href="https://github.com/servo/servo/pull/32777">#32777</a>), and you can now change that aspect ratio with the <strong>‘aspect-ratio’ property</strong> (<a href="https://github.com/valadaptive">@valadaptive</a>, <a href="https://github.com/servo/servo/pull/32800">#32800</a>, <a href="https://github.com/servo/servo/pull/32803">#32803</a>).</p>
<figure><a href="https://servo.org/img/blog/devtools-july-2024.png"><img src="https://servo.org/img/blog/devtools-july-2024.png" alt="Firefox devtools connected to Servo, showing several console errors"></a>
<figcaption>Figure 3: console logging is now supported when using the Firefox devtools.</figcaption></figure>

<p>When debugging in Servo <a href="https://book.servo.org/running-servoshell.html">with the <strong>Firefox devtools</strong></a>, you can now see <strong>console messages</strong> from the page (<a href="https://github.com/eerii">@eerii</a>, <a href="https://github.com/servo/servo/pull/32727">#32727</a>), as shown in <em>Figure 3</em>, and you can even debug the devtools connection itself with our new <strong>devtools protocol analyzer</strong> (<a href="https://github.com/eerii">@eerii</a>, <a href="https://github.com/servo/servo/pull/32684">#32684</a>).</p>
<p>servoshell now has experimental <strong>OpenHarmony support</strong> (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32594">#32594</a>), in addition to our experimental Android support and nightly releases for Windows, macOS, and Linux.
We’ve also landed <strong>directory listings</strong> for local files (<a href="https://github.com/Bobulous">@Bobulous</a>, <a href="https://github.com/mrobinson">@mrobinson</a>, <a href="https://github.com/servo/servo/pull/32580">#32580</a>), made the location bar behave more consistently on Android (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32586">#32586</a>), and servoshell no longer quits when you press Escape (<a href="https://github.com/mrego">@mrego</a>, <a href="https://github.com/servo/servo/pull/32603">#32603</a>).</p>
<figure><div>
<table>
<thead>
<tr>
<th>Version and build config</th>
<th><code>servo</code> binary size</th>
</tr>
</thead>
<tbody>
<tr>
<td>Before <a href="https://github.com/servo/servo/pull/32651">#32651</a></td>
<td>126364k</td>
</tr>
<tr>
<td>With <a href="https://github.com/servo/servo/pull/32651">#32651</a></td>
<td>110111k (−12.8%)</td>
</tr>
<tr>
<td>With <a href="https://github.com/servo/servo/pull/32651">#32651</a><br>• Without debug symbols</td>
<td>102878k (−18.5%)</td>
</tr>
<tr>
<td>With <a href="https://github.com/servo/servo/pull/32759">#32759</a><br>• Without <code>layout_2013</code></td>
<td>107652k (−14.8%)</td>
</tr>
<tr>
<td>With <a href="https://github.com/servo/servo/pull/32759">#32759</a><br>• Without debug symbols<br>• Without <code>layout_2013</code></td>
<td>100886k (−20.1%)</td>
</tr>
</tbody>
</table>
</div>
<figcaption>Figure 4: servoshell binary size improvements on Linux (amd64).</figcaption></figure>
<p><span></span>
To reduce servoshell’s binary size, we now build our nightly releases with <strong>ThinLTO</strong> (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32651">#32651</a>), and you can go even further by building Servo <strong>without debug symbols</strong> (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32651">#32651</a>) or <strong>without the legacy layout engine</strong> (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32759">#32759</a>).
Note that these builds use the <code>production</code> profile in Cargo, not the <code>release</code> profile.</p>
<h2 id="changes-for-servo-developers" tabindex="-1">Changes for Servo developers <a href="#changes-for-servo-developers">
        <span><i></i></span>
      </a></h2>
<p><a href="https://book.servo.org/"><strong>The Servo book</strong></a> is now the place to go for Servo’s documentation (<a href="https://github.com/delan">@delan</a>, <a href="https://github.com/servo/servo/pull/32743">#32743</a>).
It includes our architecture and design docs, a link to our API docs, as well as docs on building, running, testing, debugging, and profiling Servo.</p>
<p>Servo now builds without the <code>crown</code> linter by default (<a href="https://github.com/jschwe">@jschwe</a>, <a href="https://github.com/servo/servo/pull/32494">#32494</a>), simplifying the build process in some cases.
If you’re working on DOM code, you can enable it again with <code>./mach build --use-crown</code>.</p>
<figure><a href="https://servo.org/img/blog/dco-check.png"><img src="https://servo.org/img/blog/dco-check.png" alt="GitHub checks popup showing the “DCO” check failing and a link to “Details”"></a>
<figcaption>Figure 5: the DCO check will now fail unless you sign off your commits.</figcaption></figure>
<p><span></span>
When contributing to Servo, <strong>your commits must now be <a href="https://developercertificate.org/">“signed off”</a></strong>, which is essentially a promise that you own (or are allowed to contribute) the code in your patch.
If the DCO check fails, click Details for help on signing off your commits (<em>Figure 5</em>).</p>

<h2 id="donations" tabindex="-1">Donations <a href="#donations">
        <span><i></i></span>
      </a></h2>
<p>Thanks again for your generous support!
We are now receiving <strong>2955 USD/month</strong> (+32.6% over June) in recurring donations.</p>
<p>Servo is now on <a href="https://thanks.dev/">thanks.dev</a>, and already <strong>three GitHub orgs</strong> that depend on Servo are sponsoring us there.
If you use Servo libraries like <a href="https://crates.io/crates/url/reverse_dependencies">url</a>, <a href="https://crates.io/crates/html5ever/reverse_dependencies">html5ever</a>, <a href="https://crates.io/crates/selectors/reverse_dependencies">selectors</a>, or <a href="https://crates.io/crates/cssparser/reverse_dependencies">cssparser</a>, signing up for <a href="https://thanks.dev/">thanks.dev</a> could be a good way for you (or your employer) to give back to the community.</p>
<p>We are still receiving donations from <strong>14 people</strong> on LFX, but we will stop accepting donations there soon — <strong>please move your recurring donations to <a href="https://github.com/sponsors/servo">GitHub</a> or <a href="https://opencollective.com/servo">Open Collective</a></strong>.
In the meantime, we’ve transferred <strong>2723 USD</strong> of donations from LFX to our Open Collective account.</p>
<figure><div>
        <p><strong>2955</strong> USD/month</p>
        
        
        <p><strong>10000</strong></p>
    </div></figure>
<p>As always, use of these funds will be decided transparently in the Technical Steering Committee.
Our updated proposal for a <a href="https://github.com/servo/project/issues/94#issuecomment-2252262955">dedicated server for CI runners</a> (<a href="https://github.com/delan">@delan</a>, <a href="https://github.com/sagudev">@sagudev</a>, <a href="https://github.com/nicoburns">@nicoburns</a>) was accepted, which should reduce build times significantly, and this is just the start!</p>
<p>For more details, head to our <a href="https://servo.org/sponsorship/">Sponsorship page</a>.</p>
<h2 id="conferences-and-blogs" tabindex="-1">Conferences and blogs <a href="#conferences-and-blogs">
        <span><i></i></span>
      </a></h2>
<ul>
<li><a href="https://www.youtube.com/watch?v=SamA5Oz-G5w"><strong>Servo: A web rendering engine for the future</strong></a> (<a href="https://servo.org/slides/2024-07-02-global-software-technology-summit/">slides</a>) — Manuel Rego spoke at the <a href="https://huawei-events.de/en/gsts24.htm">Global Software Technology Summit 2024</a> about the status and long-term vision of the Servo project</li>
<li><a href="https://wusyong.github.io/posts/verso-0-1/"><strong>Verso: A new browser based on Servo</strong></a> — Wu Yu Wei wrote about their plans to build a more polished Servo-based browser while improving Servo’s architecture</li>
<li><a href="https://wusyong.github.io/posts/verso-compositor-part1/"><strong>Verso: Writing its own compositor part 1</strong></a> — Wu Yu Wei uses Verso as a sandbox to explore how we might rework Servo’s compositor to support multiple windows</li>
<li><a href="https://conflor.es/blog/03_halfway_point"><strong>Halfway point</strong></a> — Eri wrote about repairing Servo’s devtools support, from planning to selecting tabs to finding resources and now the console, as part of their Outreachy internship</li>
</ul>
<h2 id="alan-jeffrey-(1967%E2%80%932024)" tabindex="-1">Alan Jeffrey (1967–2024) <a href="#alan-jeffrey-(1967%E2%80%932024)">
        <span><i></i></span>
      </a></h2>
<p><a href="https://web.archive.org/web/20240714161830/https://asaj.org/">Alan Jeffrey</a>, an early member of the Servo team and a key part of helping the Servo project find a new life outside of Mozilla, passed away on 4 July.</p>
<p>His research has furthered a wide range of fields, including concurrent and distributed systems, programming languages, formal verification, software semantics, typesetting, protocol security, and circuit design.</p>
<p>Alan’s family have also written about his kindness, curiosity, and persistence <a href="https://www.linkedin.com/feed/update/activity:7215033040614436865/">on his LinkedIn page</a>.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyTorch – Torchchat: Chat with LLMs Everywhere (138 pts)]]></title>
            <link>https://github.com/pytorch/torchchat</link>
            <guid>41125980</guid>
            <pubDate>Thu, 01 Aug 2024 03:48:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pytorch/torchchat">https://github.com/pytorch/torchchat</a>, See on <a href="https://news.ycombinator.com/item?id=41125980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Chat with LLMs Everywhere</h2><a id="user-content-chat-with-llms-everywhere" aria-label="Permalink: Chat with LLMs Everywhere" href="#chat-with-llms-everywhere"></a></p>
<p dir="auto">torchchat is a small codebase showcasing the ability to run large language models (LLMs) seamlessly. With torchchat, you can run LLMs using Python, within your own (C/C++) application (desktop or server) and on iOS and Android.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What can you do with torchchat?</h2><a id="user-content-what-can-you-do-with-torchchat" aria-label="Permalink: What can you do with torchchat?" href="#what-can-you-do-with-torchchat"></a></p>
<ul dir="auto">
<li><a href="#running-via-pytorch--python">Run models via PyTorch / Python</a>
<ul dir="auto">
<li><a href="#chat">Chat</a></li>
<li><a href="#generate">Generate</a></li>
<li><a href="#browser">Run chat in the Browser</a></li>
</ul>
</li>
<li><a href="#desktopserver-execution">Run models on desktop/server without python</a>
<ul dir="auto">
<li><a href="#aoti-aot-inductor">Use AOT Inductor for faster execution</a></li>
<li><a href="#running-native-using-our-c-runner">Running in c++ using the runner</a></li>
</ul>
</li>
<li><a href="#mobile-execution">Run models on mobile</a>
<ul dir="auto">
<li><a href="#deploy-and-run-on-ios">Deploy and run on iOS</a></li>
<li><a href="#deploy-and-run-on-android">Deploy and run on Android</a></li>
</ul>
</li>
<li><a href="#eval">Evaluate a model</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Highlights</h2><a id="user-content-highlights" aria-label="Permalink: Highlights" href="#highlights"></a></p>
<ul dir="auto">
<li>Command line interaction with popular LLMs such as Llama 3, Llama 2, Stories, Mistral and more</li>
<li>PyTorch-native execution with performance</li>
<li>Supports popular hardware and OS
<ul dir="auto">
<li>Linux (x86)</li>
<li>Mac OS (M1/M2/M3)</li>
<li>Android (Devices that support XNNPACK)</li>
<li>iOS 17+ (iPhone 13 Pro+)</li>
</ul>
</li>
<li>Multiple data types including: float32, float16, bfloat16</li>
<li>Multiple quantization schemes</li>
<li>Multiple execution modes including: Python (Eager, Compile) or Native (AOT Inductor (AOTI), ExecuTorch)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">The following steps require that you have <a href="https://www.python.org/downloads/release/python-3100/" rel="nofollow">Python 3.10</a> installed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# get the code
git clone https://github.com/pytorch/torchchat.git
cd torchchat

# set up a virtual environment
python3 -m venv .venv
source .venv/bin/activate

# install dependencies
./install_requirements.sh"><pre><span><span>#</span> get the code</span>
git clone https://github.com/pytorch/torchchat.git
<span>cd</span> torchchat

<span><span>#</span> set up a virtual environment</span>
python3 -m venv .venv
<span>source</span> .venv/bin/activate

<span><span>#</span> install dependencies</span>
./install_requirements.sh</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Commands</h2><a id="user-content-commands" aria-label="Permalink: Commands" href="#commands"></a></p>
<p dir="auto">The interfaces of torchchat are leveraged through <strong>Python Commands</strong> and <strong>Native Runners</strong>. While the Python Commands are enumerable in the --help menu, the latter are explored in their respective sections.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py --help"><pre>python3 torchchat.py --help</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="# Output
usage: torchchat [-h] {chat,browser,generate,export,eval,download,list,remove,where,server} ...

positional arguments:
  {chat,browser,generate,export,eval,download,list,remove,where,server}
                        The specific command to run
    chat                Chat interactively with a model via the CLI
    generate            Generate responses from a model given a prompt
    browser             Chat interactively with a model in a locally hosted browser
    export              Export a model artifact to AOT Inductor or ExecuTorch
    download            Download model artifacts
    list                List all supported models
    remove              Remove downloaded model artifacts
    where               Return directory containing downloaded model artifacts
    server              [WIP] Starts a locally hosted REST server for model interaction
    eval                Evaluate a model via lm-eval

options:
  -h, --help            show this help message and exit"><pre><span><span>#</span> Output</span>
usage: torchchat [-h] {chat,browser,generate,export,eval,download,list,remove,where,server} ...

positional arguments:
  {chat,browser,generate,export,eval,download,list,remove,where,server}
                        The specific <span>command</span> to run
    chat                Chat interactively with a model via the CLI
    generate            Generate responses from a model given a prompt
    browser             Chat interactively with a model <span>in</span> a locally hosted browser
    <span>export</span>              Export a model artifact to AOT Inductor or ExecuTorch
    download            Download model artifacts
    list                List all supported models
    remove              Remove downloaded model artifacts
    where               Return directory containing downloaded model artifacts
    server              [WIP] Starts a locally hosted REST server <span>for</span> model interaction
    <span>eval</span>                Evaluate a model via lm-eval

options:
  -h, --help            show this <span>help</span> message and <span>exit</span></pre></div>
<p dir="auto"><strong>Python Inference</strong> (chat, generate, browser, server)</p>
<ul dir="auto">
<li>These commands represent different flavors of performing model inference in a Python enviroment.</li>
<li>Models are constructed either from CLI args or from loading exported artifacts.</li>
</ul>
<p dir="auto"><strong>Exporting</strong> (export)</p>
<ul dir="auto">
<li>This command generates model artifacts that are consumed by Python Inference or Native Runners.</li>
<li>More information is provided in the <a href="https://github.com/pytorch/torchchat?tab=readme-ov-file#aoti-aot-inductor">AOT Inductor</a> and <a href="https://github.com/pytorch/torchchat?tab=readme-ov-file#export-for-mobile">ExecuTorch</a> sections.</li>
</ul>
<p dir="auto"><strong>Inventory Management</strong> (download, list, remove, where)</p>
<ul dir="auto">
<li>These commands are used to manage and download models.</li>
<li>More information is provided in the <a href="https://github.com/pytorch/torchchat?tab=readme-ov-file#download-weights">Download Weights</a> section.</li>
</ul>
<p dir="auto"><strong>Evaluation</strong> (eval)</p>
<ul dir="auto">
<li>This command test model fidelity via EleutherAI's <a href="https://github.com/EleutherAI/lm-evaluation-harness">lm_evaluation_harness</a>.</li>
<li>More information is provided in the <a href="https://github.com/pytorch/torchchat?tab=readme-ov-file#eval">Evaluation</a> section.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Download Weights</h2><a id="user-content-download-weights" aria-label="Permalink: Download Weights" href="#download-weights"></a></p>
<p dir="auto">Most models use Hugging Face as the distribution channel, so you will need to create a Hugging Face account.
Create a Hugging Face user access token <a href="https://huggingface.co/docs/hub/en/security-tokens" rel="nofollow">as documented here</a> with the <code>write</code> role.</p>
<p dir="auto">Log into Hugging Face:</p>

<p dir="auto">Once this is done, torchchat will be able to download model artifacts from
Hugging Face.</p>
<div data-snippet-clipboard-copy-content="python3 torchchat.py download llama3.1"><pre><code>python3 torchchat.py download llama3.1
</code></pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">This command may prompt you to request access to Llama 3 via
Hugging Face, if you do not already have access. Simply follow the
prompts and re-run the command when access is granted.*</p>
</div>
<details>
<summary>Additional Model Inventory Management Commands</summary>
<p dir="auto"><h3 tabindex="-1" dir="auto">List</h3><a id="user-content-list" aria-label="Permalink: List" href="#list"></a></p>
<p dir="auto">This subcommands shows the available models</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py list"><pre>python3 torchchat.py list</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Where</h3><a id="user-content-where" aria-label="Permalink: Where" href="#where"></a></p>
<p dir="auto">This subcommands shows location of a particular model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py list"><pre>python3 torchchat.py list</pre></div>
<p dir="auto">This is useful in scripts when you do not want to hard-code paths</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Remove</h3><a id="user-content-remove" aria-label="Permalink: Remove" href="#remove"></a></p>
<p dir="auto">This subcommands removes the specified model</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py remove llama3.1"><pre>python3 torchchat.py remove llama3.1</pre></div>
<p dir="auto">More information about these commands can be found by adding the <code>--help</code> option.</p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Running via PyTorch / Python</h2><a id="user-content-running-via-pytorch--python" aria-label="Permalink: Running via PyTorch / Python" href="#running-via-pytorch--python"></a></p>
<p dir="auto">The simplest way to run a model in PyTorch is via <a href="https://pytorch.org/blog/optimizing-production-pytorch-performance-with-graph-transformations/" rel="nofollow">eager execution</a>.
This is the default execution mode for both PyTorch and torchchat. It performs inference
without creating exporting artifacts or using a separate runner.</p>
<p dir="auto">The model used for inference can also be configured and tailored to specific needs
(compilation, quantization, etc.). See the <a href="https://github.com/pytorch/torchchat/blob/main/docs/model_customization.md">customization guide</a> for the options supported by torchchat.</p>
<div dir="auto"><p dir="auto">Tip</p><p dir="auto">For more information about these commands, please refer to the <code>--help</code> menu.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Chat</h3><a id="user-content-chat" aria-label="Permalink: Chat" href="#chat"></a></p>
<p dir="auto">This mode allows you to chat with an LLM in an interactive fashion.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py chat llama3.1"><pre>python3 torchchat.py chat llama3.1</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Generate</h3><a id="user-content-generate" aria-label="Permalink: Generate" href="#generate"></a></p>
<p dir="auto">This mode generates text based on an input prompt.</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py generate llama3.1 --prompt &quot;write me a story about a boy and his bear&quot;"><pre>python3 torchchat.py generate llama3.1 --prompt <span><span>"</span>write me a story about a boy and his bear<span>"</span></span></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Browser</h3><a id="user-content-browser" aria-label="Permalink: Browser" href="#browser"></a></p>
<p dir="auto">This mode allows you to chat with the model using a UI in your browser
Running the command automatically open a tab in your browser.</p>
<div data-snippet-clipboard-copy-content="streamlit run torchchat.py -- browser llama3.1"><pre><code>streamlit run torchchat.py -- browser llama3.1
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Server</h3><a id="user-content-server" aria-label="Permalink: Server" href="#server"></a></p>
<p dir="auto"><strong>Note: This feature is still a work in progress and not all endpoints are working</strong></p>
<details>
<summary>This mode gives a REST API that matches the OpenAI API spec for interacting with a model</summary>
<p dir="auto">To test out the REST API, <strong>you'll need 2 terminals</strong>: one to host the server, and one to send the request.</p>
<p dir="auto">In one terminal, start the server</p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 torchchat.py server llama3.1"><pre>python3 torchchat.py server llama3.1</pre></div>
<p dir="auto">In another terminal, query the server using <code>curl</code>. Depending on the model configuration, this query might take a few minutes to respond.</p>
<p dir="auto">Setting <code>stream</code> to "true" in the request emits a response in chunks. Currently, this response
is plaintext and will not be formatted to the OpenAI API specification. If <code>stream</code> is unset or not "true", then the client will await the full response from the server.</p>
<p dir="auto"><strong>Example Input + Output</strong></p>
<div data-snippet-clipboard-copy-content="curl http://127.0.0.1:5000/chat \
  -H &quot;Content-Type: application/json&quot; \
  -d '{
    &quot;model&quot;: &quot;llama3.1&quot;,
    &quot;stream&quot;: &quot;true&quot;,
    &quot;messages&quot;: [
      {
        &quot;role&quot;: &quot;system&quot;,
        &quot;content&quot;: &quot;You are a helpful assistant.&quot;
      },
      {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello!&quot;
      }
    ]
  }'"><pre><code>curl http://127.0.0.1:5000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "llama3.1",
    "stream": "true",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful assistant."
      },
      {
        "role": "user",
        "content": "Hello!"
      }
    ]
  }'
</code></pre></div>
<div data-snippet-clipboard-copy-content="{&quot;response&quot;:&quot; I'm a software developer with a passion for building innovative and user-friendly applications. I have experience in developing web and mobile applications using various technologies such as Java, Python, and JavaScript. I'm always looking for new challenges and opportunities to learn and grow as a developer.\n\nIn my free time, I enjoy reading books on computer science and programming, as well as experimenting with new technologies and techniques. I'm also interested in machine learning and artificial intelligence, and I'm always looking for ways to apply these concepts to real-world problems.\n\nI'm excited to be a part of the developer community and to have the opportunity to share my knowledge and experience with others. I'm always happy to help with any questions or problems you may have, and I'm looking forward to learning from you as well.\n\nThank you for visiting my profile! I hope you find my information helpful and interesting. If you have any questions or would like to discuss any topics, please feel free to reach out to me. I&quot;}"><pre><code>{"response":" I'm a software developer with a passion for building innovative and user-friendly applications. I have experience in developing web and mobile applications using various technologies such as Java, Python, and JavaScript. I'm always looking for new challenges and opportunities to learn and grow as a developer.\n\nIn my free time, I enjoy reading books on computer science and programming, as well as experimenting with new technologies and techniques. I'm also interested in machine learning and artificial intelligence, and I'm always looking for ways to apply these concepts to real-world problems.\n\nI'm excited to be a part of the developer community and to have the opportunity to share my knowledge and experience with others. I'm always happy to help with any questions or problems you may have, and I'm looking forward to learning from you as well.\n\nThank you for visiting my profile! I hope you find my information helpful and interesting. If you have any questions or would like to discuss any topics, please feel free to reach out to me. I"}
</code></pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Desktop/Server Execution</h2><a id="user-content-desktopserver-execution" aria-label="Permalink: Desktop/Server Execution" href="#desktopserver-execution"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">AOTI (AOT Inductor)</h3><a id="user-content-aoti-aot-inductor" aria-label="Permalink: AOTI (AOT Inductor)" href="#aoti-aot-inductor"></a></p>
<p dir="auto"><a href="https://pytorch.org/blog/pytorch2-2/" rel="nofollow">AOTI</a> compiles models before execution for faster inference. The process creates a <a href="https://en.wikipedia.org/wiki/Shared_library" rel="nofollow">DSO</a> model (represented by a file with extension <code>.so</code>)
that is then loaded for inference. This can be done with both Python and C++ enviroments.</p>
<p dir="auto">The following example exports and executes the Llama3.1 8B Instruct
model.  The first command compiles and performs the actual export.</p>
<div data-snippet-clipboard-copy-content="python3 torchchat.py export llama3.1 --output-dso-path exportedModels/llama3.1.so"><pre><code>python3 torchchat.py export llama3.1 --output-dso-path exportedModels/llama3.1.so
</code></pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If your machine has cuda add this flag for performance
<code>--quantize config/data/cuda.json</code> when exporting.</p>
</div>
<p dir="auto">For more details on quantization and what settings to use for your use
case visit our <a href="https://github.com/pytorch/torchchat/blob/main/docs/model_customization.md">customization guide</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run in a Python Enviroment</h3><a id="user-content-run-in-a-python-enviroment" aria-label="Permalink: Run in a Python Enviroment" href="#run-in-a-python-enviroment"></a></p>
<p dir="auto">To run in a python enviroment, use the generate subcommand like before, but include the dso file.</p>
<div data-snippet-clipboard-copy-content="python3 torchchat.py generate llama3.1 --dso-path exportedModels/llama3.1.so --prompt &quot;Hello my name is&quot;"><pre><code>python3 torchchat.py generate llama3.1 --dso-path exportedModels/llama3.1.so --prompt "Hello my name is"
</code></pre></div>
<p dir="auto"><strong>Note:</strong> Depending on which accelerator is used to generate the .dso file, the command may need the device specified: <code>--device (cuda | cpu)</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Run using our C++ Runner</h3><a id="user-content-run-using-our-c-runner" aria-label="Permalink: Run using our C++ Runner" href="#run-using-our-c-runner"></a></p>
<p dir="auto">To run in a C++ enviroment, we need to build the runner binary.</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/build_native.sh aoti"><pre>scripts/build_native.sh aoti</pre></div>
<p dir="auto">Then run the compiled executable, with the exported DSO from earlier.</p>
<div dir="auto" data-snippet-clipboard-copy-content="cmake-out/aoti_run exportedModels/llama3.1.so -z `python3 torchchat.py where llama3.1`/tokenizer.model -l 3 -i &quot;Once upon a time&quot;"><pre>cmake-out/aoti_run exportedModels/llama3.1.so -z <span><span>`</span>python3 torchchat.py where llama3.1<span>`</span></span>/tokenizer.model -l 3 -i <span><span>"</span>Once upon a time<span>"</span></span></pre></div>
<p dir="auto"><strong>Note:</strong> Depending on which accelerator is used to generate the .dso file, the runner may need the device specified: <code>-d (CUDA | CPU)</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mobile Execution</h2><a id="user-content-mobile-execution" aria-label="Permalink: Mobile Execution" href="#mobile-execution"></a></p>
<p dir="auto"><a href="https://github.com/pytorch/executorch">ExecuTorch</a> enables you to optimize your model for execution on a
mobile or embedded device.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Set Up ExecuTorch</h3><a id="user-content-set-up-executorch" aria-label="Permalink: Set Up ExecuTorch" href="#set-up-executorch"></a></p>
<p dir="auto">Before running any commands in torchchat that require ExecuTorch, you
must first install ExecuTorch.</p>
<p dir="auto">To install ExecuTorch, run the following commands.  This will download the
ExecuTorch repo to ./et-build/src and install various ExecuTorch libraries to
./et-build/install.</p>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">The following commands should be run from the torchchat root directory.</p>
</div>
<div data-snippet-clipboard-copy-content="export TORCHCHAT_ROOT=${PWD}
./scripts/install_et.sh"><pre><code>export TORCHCHAT_ROOT=${PWD}
./scripts/install_et.sh
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Export for mobile</h3><a id="user-content-export-for-mobile" aria-label="Permalink: Export for mobile" href="#export-for-mobile"></a></p>
<p dir="auto">Similar to AOTI, to deploy onto device, we first export the PTE artifact, then we load the artifact for inference.</p>
<p dir="auto">The following example uses the Llama3.1 8B Instruct model.</p>
<div data-snippet-clipboard-copy-content="# Export
python3 torchchat.py export llama3.1 --quantize config/data/mobile.json --output-pte-path llama3.1.pte"><pre><code># Export
python3 torchchat.py export llama3.1 --quantize config/data/mobile.json --output-pte-path llama3.1.pte
</code></pre></div>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">We use <code>--quantize config/data/mobile.json</code> to quantize the
llama3.1 model to reduce model size and improve performance for
on-device use cases.</p>
</div>
<p dir="auto">For more details on quantization and what settings to use for your use
case visit our <a href="https://github.com/pytorch/torchchat/blob/main/docs/model_customization.md">customization guide</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy and run on Desktop</h3><a id="user-content-deploy-and-run-on-desktop" aria-label="Permalink: Deploy and run on Desktop" href="#deploy-and-run-on-desktop"></a></p>
<p dir="auto">While ExecuTorch does not focus on desktop inference, it is capable
of doing so. This is handy for testing out PTE
models without sending them to a physical device.</p>
<p dir="auto">Specifically there are 2 ways of doing so: Pure Python and via a Runner</p>
<details>
<summary>Deploying via Python</summary>
<div data-snippet-clipboard-copy-content="# Execute
python3 torchchat.py generate llama3.1 --device cpu --pte-path llama3.1.pte --prompt &quot;Hello my name is&quot;"><pre><code># Execute
python3 torchchat.py generate llama3.1 --device cpu --pte-path llama3.1.pte --prompt "Hello my name is"
</code></pre></div>
</details>
<details>
<summary>Deploying via a Runner</summary>
<p dir="auto">Build the runner</p>
<div dir="auto" data-snippet-clipboard-copy-content="scripts/build_native.sh et"><pre>scripts/build_native.sh et</pre></div>
<p dir="auto">Execute using the runner</p>
<div dir="auto" data-snippet-clipboard-copy-content="cmake-out/et_run llama3.1.pte -z `python3 torchchat.py where llama3.1`/tokenizer.model -l 3 -i &quot;Once upon a time&quot;"><pre>cmake-out/et_run llama3.1.pte -z <span><span>`</span>python3 torchchat.py where llama3.1<span>`</span></span>/tokenizer.model -l 3 -i <span><span>"</span>Once upon a time<span>"</span></span></pre></div>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy and run on iOS</h3><a id="user-content-deploy-and-run-on-ios" aria-label="Permalink: Deploy and run on iOS" href="#deploy-and-run-on-ios"></a></p>
<p dir="auto">The following assumes you've completed the steps for <a href="#set-up-executorch">Setting up ExecuTorch</a>.</p>
<details>
<summary>Deploying with Xcode</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Requirements</h4><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<ul dir="auto">
<li><a href="https://apps.apple.com/us/app/xcode/id497799835?mt=12/" rel="nofollow">Xcode</a> 15.0 or later</li>
<li><a href="https://cmake.org/download/" rel="nofollow">Cmake</a> 3.19 or later
<ul dir="auto">
<li>Download and open the macOS <code>.dmg</code> installer and move the Cmake app to <code>/Applications</code> folder.</li>
<li>Install Cmake command line tools: <code>sudo /Applications/CMake.app/Contents/bin/cmake-gui --install</code></li>
</ul>
</li>
<li>A development provisioning profile with the <a href="https://developer.apple.com/documentation/bundleresources/entitlements/com_apple_developer_kernel_increased-memory-limit" rel="nofollow"><code>increased-memory-limit</code></a> entitlement.</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Steps</h4><a id="user-content-steps" aria-label="Permalink: Steps" href="#steps"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Open the Xcode project:</p>
<div dir="auto" data-snippet-clipboard-copy-content="open et-build/src/executorch/examples/demo-apps/apple_ios/LLaMA/LLaMA.xcodeproj"><pre>open et-build/src/executorch/examples/demo-apps/apple_ios/LLaMA/LLaMA.xcodeproj</pre></div>
<blockquote>
<p dir="auto">Note: If you're running into any issues related to package dependencies, close Xcode, clean some of the caches and/or the build products, and open the Xcode project again:</p>
<div dir="auto" data-snippet-clipboard-copy-content="rm -rf \
  ~/Library/org.swift.swiftpm \
  ~/Library/Caches/org.swift.swiftpm \
  ~/Library/Caches/com.apple.dt.Xcode \
  ~/Library/Developer/Xcode/DerivedData"><pre>rm -rf \
  <span>~</span>/Library/org.swift.swiftpm \
  <span>~</span>/Library/Caches/org.swift.swiftpm \
  <span>~</span>/Library/Caches/com.apple.dt.Xcode \
  <span>~</span>/Library/Developer/Xcode/DerivedData</pre></div>
</blockquote>
</li>
<li>
<p dir="auto">Click the Play button to launch the app in the Simulator.</p>
</li>
<li>
<p dir="auto">To run on a device, ensure you have it set up for development and a provisioning profile with the <code>increased-memory-limit</code> entitlement. Update the app's bundle identifier to match your provisioning profile with the required capability.</p>
</li>
<li>
<p dir="auto">After successfully launching the app, copy the exported ExecuTorch model (<code>.pte</code>) and tokenizer (<code>.model</code>) files to the iLLaMA folder. You can find the model file called <code>llama3.1.pte</code> in the current <code>torchchat</code> directory and the tokenizer file at <code>$(python3 torchchat.py where llama3.1)/tokenizer.model</code> path.</p>
<ul dir="auto">
<li><strong>For the Simulator:</strong> Drag and drop both files onto the Simulator window and save them in the <code>On My iPhone &gt; iLLaMA</code> folder.</li>
<li><strong>For a device:</strong> Open a separate Finder window, navigate to the Files tab, drag and drop both files into the iLLaMA folder, and wait for the copying to finish.</li>
</ul>
</li>
<li>
<p dir="auto">Follow the app's UI guidelines to select the model and tokenizer files from the local filesystem and issue a prompt.</p>
</li>
</ol>
<p dir="auto"><em>Click the image below to see it in action!</em></p>
<p dir="auto">
<a href="https://pytorch.org/executorch/main/_static/img/llama_ios_app.mp4" rel="nofollow">
  <img src="https://camo.githubusercontent.com/e6975bf38cc4ad360ada871f6d7efc66c2d2f485c33317107c061ea70199d500/68747470733a2f2f7079746f7263682e6f72672f6578656375746f7263682f6d61696e2f5f7374617469632f696d672f6c6c616d615f696f735f6170702e706e67" width="600" alt="iOS app running a LlaMA model" data-canonical-src="https://pytorch.org/executorch/main/_static/img/llama_ios_app.png">
</a>
</p>
</details>
<p dir="auto"><h3 tabindex="-1" dir="auto">Deploy and run on Android</h3><a id="user-content-deploy-and-run-on-android" aria-label="Permalink: Deploy and run on Android" href="#deploy-and-run-on-android"></a></p>
<p dir="auto">The following assumes you've completed the steps for <a href="#set-up-executorch">Setting up ExecuTorch</a>.</p>
<details>
<summary>Approach 1 (Recommended): Android Studio</summary>
<p dir="auto"><h4 tabindex="-1" dir="auto">Requirements</h4><a id="user-content-requirements-1" aria-label="Permalink: Requirements" href="#requirements-1"></a></p>
<ul dir="auto">
<li>Android Studio</li>
<li><a href="https://developer.android.com/build/jdks" rel="nofollow">Java 17</a></li>
<li><a href="https://developer.android.com/about/versions/14/setup-sdk" rel="nofollow">Android SDK 34</a></li>
<li><a href="https://developer.android.com/tools/adb" rel="nofollow">adb</a></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Steps</h4><a id="user-content-steps-1" aria-label="Permalink: Steps" href="#steps-1"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Download the AAR file, which contains the Java library and corresponding JNI library, to build and run the app.</p>
<ul dir="auto">
<li><a href="https://ossci-android.s3.amazonaws.com/executorch/main/executorch-llama-tiktoken-rc3-0719.aar" rel="nofollow">executorch-llama-tiktoken-rc3-0719.aar</a> (SHASUM: c3e5d2a97708f033c2b1839a89f12f737e3bbbef)</li>
</ul>
</li>
<li>
<p dir="auto">Rename the downloaded AAR file to <code>executorch.aar</code> and move the file to <code>android/torchchat/app/libs/</code>. You may need to create directory <code>android/torchchat/app/libs/</code> if it does not exist.</p>
</li>
<li>
<p dir="auto">Push the model and tokenizer file to your device. You can find the model file called <code>llama3.1.pte</code> in the current <code>torchchat</code> directory and the tokenizer file at <code>$(python3 torchchat.py where llama3.1)/tokenizer.model</code> path.</p>
<div data-snippet-clipboard-copy-content="adb shell mkdir -p /data/local/tmp/llama
adb push <model.pte> /data/local/tmp/llama
adb push <tokenizer.model or tokenizer.bin> /data/local/tmp/llama"><pre><code>adb shell mkdir -p /data/local/tmp/llama
adb push &lt;model.pte&gt; /data/local/tmp/llama
adb push &lt;tokenizer.model or tokenizer.bin&gt; /data/local/tmp/llama
</code></pre></div>
</li>
<li>
<p dir="auto">Use Android Studio to open the torchchat app skeleton, located at <code>android/torchchat</code>.</p>
</li>
<li>
<p dir="auto">Click the Play button (^R) to launch it to emulator/device.</p>
<ul dir="auto">
<li>We recommend using a device with at least 12GB RAM and 20GB storage.</li>
<li>If using an emulated device, refer to <a href="https://stackoverflow.com/questions/45517553/cant-change-the-ram-size-in-avd-manager-android-studio" rel="nofollow">this post</a> on how to set the RAM.</li>
</ul>
</li>
<li>
<p dir="auto">Follow the app's UI guidelines to pick the model and tokenizer files from the local filesystem. Then issue a prompt.</p>
</li>
</ol>
<p dir="auto"><strong>Note:</strong> The AAR file listed in Step 1 has the tiktoken tokenizer, which is used for Llama 3. To tweak or use a custom tokenizer and runtime, modify the ExecuTorch code
and use <a href="https://github.com/pytorch/executorch/blob/main/build/build_android_llm_demo.sh">this script</a> to build the AAR library.</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/8cf1cc62d4896d94efd214dfee81d28fc4065286236c10dd2b4cf4b0ca548581/68747470733a2f2f7079746f7263682e6f72672f6578656375746f7263682f6d61696e2f5f7374617469632f696d672f616e64726f69645f6c6c616d615f6170702e706e67"><img src="https://camo.githubusercontent.com/8cf1cc62d4896d94efd214dfee81d28fc4065286236c10dd2b4cf4b0ca548581/68747470733a2f2f7079746f7263682e6f72672f6578656375746f7263682f6d61696e2f5f7374617469632f696d672f616e64726f69645f6c6c616d615f6170702e706e67" width="600" alt="Android app running a LlaMA model" data-canonical-src="https://pytorch.org/executorch/main/_static/img/android_llama_app.png"></a>
</p>
</details>
<details>
<summary>Approach 2: E2E Script</summary>
<p dir="auto">Alternatively, you can run <code>scripts/android_example.sh</code> which sets up Java, Android SDK Manager, Android SDK, Android emulator (if no physical device is found), builds the app, and launches it for you. It can be used if you don't have a GUI.</p>
<div data-snippet-clipboard-copy-content="export TORCHCHAT_ROOT=$(pwd)
export USE_TIKTOKEN=ON # Set this only for tiktoken tokenizer
sh scripts/android_example.sh"><pre><code>export TORCHCHAT_ROOT=$(pwd)
export USE_TIKTOKEN=ON # Set this only for tiktoken tokenizer
sh scripts/android_example.sh
</code></pre></div>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Eval</h2><a id="user-content-eval" aria-label="Permalink: Eval" href="#eval"></a></p>
<p dir="auto"><strong>Note: This feature is still a work in progress and not all features are working</strong></p>
<p dir="auto">Uses the lm_eval library to evaluate model accuracy on a variety of
tasks. Defaults to wikitext and can be manually controlled using the
tasks and limit args. See <a href="https://github.com/pytorch/torchchat/blob/main/docs/evaluation.md">Evaluation</a></p>
<p dir="auto"><strong>Examples</strong></p>
<p dir="auto">Eager mode:</p>
<div data-snippet-clipboard-copy-content="python3 torchchat.py eval llama3.1 --dtype fp32 --limit 5"><pre><code>python3 torchchat.py eval llama3.1 --dtype fp32 --limit 5
</code></pre></div>
<p dir="auto">To test the perplexity for a lowered or quantized model, pass it in
the same way you would to generate:</p>
<div data-snippet-clipboard-copy-content="python3 torchchat.py eval llama3.1 --pte-path llama3.1.pte --limit 5"><pre><code>python3 torchchat.py eval llama3.1 --pte-path llama3.1.pte --limit 5
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Models</h2><a id="user-content-models" aria-label="Permalink: Models" href="#models"></a></p>
<p dir="auto">The following models are supported by torchchat and have associated
aliases.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Model</th>
<th>Mobile Friendly</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct" rel="nofollow">meta-llama/Meta-Llama-3.1-8B-Instruct</a></td>
<td>✅</td>
<td>Tuned for <code>chat</code> . Alias to <code>llama3.1</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Meta-Llama-3.1-8B" rel="nofollow">meta-llama/Meta-Llama-3.1-8B</a></td>
<td>✅</td>
<td>Best for <code>generate</code>. Alias to <code>llama3.1-base</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" rel="nofollow">meta-llama/Meta-Llama-3-8B-Instruct</a></td>
<td>✅</td>
<td>Tuned for <code>chat</code> . Alias to <code>llama3</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Meta-Llama-3-8B" rel="nofollow">meta-llama/Meta-Llama-3-8B</a></td>
<td>✅</td>
<td>Best for <code>generate</code>. Alias to <code>llama3-base</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Llama-2-7b-chat-hf" rel="nofollow">meta-llama/Llama-2-7b-chat-hf</a></td>
<td>✅</td>
<td>Tuned for <code>chat</code>. Alias to <code>llama2</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Llama-2-13b-chat-hf" rel="nofollow">meta-llama/Llama-2-13b-chat-hf</a></td>
<td></td>
<td>Tuned for <code>chat</code>. Alias to <code>llama2-13b-chat</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Llama-2-70b-chat-hf" rel="nofollow">meta-llama/Llama-2-70b-chat-hf</a></td>
<td></td>
<td>Tuned for <code>chat</code>. Alias to <code>llama2-70b-chat</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/Llama-2-7b-hf" rel="nofollow">meta-llama/Llama-2-7b-hf</a></td>
<td>✅</td>
<td>Best for <code>generate</code>. Alias to <code>llama2-base</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/CodeLlama-7b-Python-hf" rel="nofollow">meta-llama/CodeLlama-7b-Python-hf</a></td>
<td>✅</td>
<td>Tuned for Python and <code>generate</code>. Alias to <code>codellama</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/meta-llama/CodeLlama-34b-Python-hf" rel="nofollow">meta-llama/CodeLlama-34b-Python-hf</a></td>
<td>✅</td>
<td>Tuned for Python and <code>generate</code>. Alias to <code>codellama-34b</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/mistralai/Mistral-7B-v0.1" rel="nofollow">mistralai/Mistral-7B-v0.1</a></td>
<td>✅</td>
<td>Best for <code>generate</code>. Alias to <code>mistral-7b-v01-base</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1" rel="nofollow">mistralai/Mistral-7B-Instruct-v0.1</a></td>
<td>✅</td>
<td>Tuned for <code>chat</code>. Alias to <code>mistral-7b-v01-instruct</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2" rel="nofollow">mistralai/Mistral-7B-Instruct-v0.2</a></td>
<td>✅</td>
<td>Tuned for <code>chat</code>. Alias to <code>mistral</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/karpathy/tinyllamas/tree/main" rel="nofollow">tinyllamas/stories15M</a></td>
<td>✅</td>
<td>Toy model for <code>generate</code>. Alias to <code>stories15M</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/karpathy/tinyllamas/tree/main" rel="nofollow">tinyllamas/stories42M</a></td>
<td>✅</td>
<td>Toy model for <code>generate</code>. Alias to <code>stories42M</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/karpathy/tinyllamas/tree/main" rel="nofollow">tinyllamas/stories110M</a></td>
<td>✅</td>
<td>Toy model for <code>generate</code>. Alias to <code>stories110M</code>.</td>
</tr>
<tr>
<td><a href="https://huggingface.co/openlm-research/open_llama_7b" rel="nofollow">openlm-research/open_llama_7b</a></td>
<td>✅</td>
<td>Best for <code>generate</code>. Alias to <code>open-llama</code>.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">While we describe how to use torchchat using the popular llama3 model,
you can perform the example commands with any of these models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Design Principles</h2><a id="user-content-design-principles" aria-label="Permalink: Design Principles" href="#design-principles"></a></p>
<p dir="auto">torchchat embodies PyTorch’s design philosophy <a href="https://pytorch.org/docs/stable/community/design.html" rel="nofollow">details</a>, especially "usability over everything else".</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Native PyTorch</h3><a id="user-content-native-pytorch" aria-label="Permalink: Native PyTorch" href="#native-pytorch"></a></p>
<p dir="auto">torchchat is a native-PyTorch library. While we provide integrations with the surrounding ecosystem (eg: Hugging Face models, etc), all of the core functionality is written in PyTorch.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Simplicity and Extensibility</h3><a id="user-content-simplicity-and-extensibility" aria-label="Permalink: Simplicity and Extensibility" href="#simplicity-and-extensibility"></a></p>
<p dir="auto">torchchat is designed to be easy to understand, use and extend.</p>
<ul dir="auto">
<li>Composition over implementation inheritance - layers of inheritance for code re-use makes the code hard to read and extend</li>
<li>No training frameworks - explicitly outlining the training logic makes it easy to extend for custom use cases</li>
<li>Code duplication is preferred over unnecessary abstractions</li>
<li>Modular building blocks over monolithic components</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Correctness</h3><a id="user-content-correctness" aria-label="Permalink: Correctness" href="#correctness"></a></p>
<p dir="auto">torchchat provides well-tested components with a high-bar on correctness.
We provide</p>
<ul dir="auto">
<li>Extensive unit-tests to ensure things operate as they should</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community Contributions</h2><a id="user-content-community-contributions" aria-label="Permalink: Community Contributions" href="#community-contributions"></a></p>
<p dir="auto">We really value our community and the contributions made by our wonderful users. We'll use this section to call out some of these contributions! If you'd like to help out as well, please see the <a href="https://github.com/pytorch/torchchat/blob/main/CONTRIBUTING.md">CONTRIBUTING</a> guide.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: Troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto"><strong>CERTIFICATE_VERIFY_FAILED</strong>
Run <code>pip install --upgrade certifi</code>.</p>
<p dir="auto"><strong>Access to model is restricted and you are not in the authorized list</strong>
Some models require an additional step to access. Follow the
link provided in the error to get access.</p>
<p dir="auto"><strong>Installing ET Fails</strong>
If <code>./scripts/install_et.sh</code> fails with an error like <code>Building wheel for executorch (pyproject.toml) did not run successfully</code> It's possible that it's linking to an older version of pytorch installed some other way like via homebrew. You can break the link by uninstalling other versions such as <code>brew uninstall pytorch</code> Note: You may break something that depends on this, so be aware.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Filing Issues</h2><a id="user-content-filing-issues" aria-label="Permalink: Filing Issues" href="#filing-issues"></a></p>
<p dir="auto">Please include the exact command you ran and the output of that command.
Also, run this script and include the output saved to <code>system_info.txt</code> so that we can better debug your issue.</p>
<div data-snippet-clipboard-copy-content="(echo &quot;Operating System Information&quot;; uname -a; echo &quot;&quot;; cat /etc/os-release; echo &quot;&quot;; echo &quot;Python Version&quot;; python --version || python3 --version; echo &quot;&quot;; echo &quot;PIP Version&quot;; pip --version || pip3 --version; echo &quot;&quot;; echo &quot;Installed Packages&quot;; pip freeze || pip3 freeze; echo &quot;&quot;; echo &quot;PyTorch Version&quot;; python -c &quot;import torch; print(torch.__version__)&quot; || python3 -c &quot;import torch; print(torch.__version__)&quot;; echo &quot;&quot;; echo &quot;Collection Complete&quot;) > system_info.txt"><pre><code>(echo "Operating System Information"; uname -a; echo ""; cat /etc/os-release; echo ""; echo "Python Version"; python --version || python3 --version; echo ""; echo "PIP Version"; pip --version || pip3 --version; echo ""; echo "Installed Packages"; pip freeze || pip3 freeze; echo ""; echo "PyTorch Version"; python -c "import torch; print(torch.__version__)" || python3 -c "import torch; print(torch.__version__)"; echo ""; echo "Collection Complete") &gt; system_info.txt
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">The torchchat Repository Content is provided without any guarantees
about performance or compatibility. In particular, torchchat makes
available model architectures written in Python for PyTorch that may
not perform in the same manner or meet the same standards as the
original versions of those models. When using the torchchat Repository
Content, including any model architectures, you are solely responsible
for determining the appropriateness of using or redistributing the
torchchat Repository Content and assume any risks associated with your
use of the torchchat Repository Content or any models, outputs, or
results, both alone and in combination with any other
technologies. Additionally, you may have other legal obligations that
govern your use of other content, such as the terms of service for
third-party models, weights, data, or other technologies, and you are
solely responsible for complying with all such obligations.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: Acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">Thank you to the community for all the
awesome libraries and tools you've built around local LLM inference.</p>
<ul dir="auto">
<li>
<p dir="auto">Georgi Gerganov and his <a href="https://github.com/ggerganov/ggml">GGML</a>
project shining a spotlight on community-based enablement and
inspiring so many other projects.</p>
</li>
<li>
<p dir="auto">Andrej Karpathy and his
<a href="https://github.com/karpathy/llama2.c">llama2.c</a> project.  So many
great (and simple!) ideas in llama2.c that we have directly adopted
(both ideas and code) from his repo.  You can never go wrong by
following Andrej's work.</p>
</li>
<li>
<p dir="auto">Michael Gschwind, Bert Maher, Scott Wolchok, Bin Bao, Chen Yang,
Huamin Li and Mu-Chu Li who built the first version of nanogpt (<code>DSOGPT</code>)
with AOT Inductor proving that AOTI can be used to build efficient
LLMs, and DSOs are a viable distribution format for models.
<a href="https://github.com/karpathy/nanoGPT">nanoGPT</a>.</p>
</li>
<li>
<p dir="auto">Bert Maher and his
<a href="https://github.com/bertmaher/llama2.so">llama2.so</a>, which built on
Andrej's llama2.c and on DSOGPT to close the loop on Llama models
with AOTInductor.</p>
</li>
<li>
<p dir="auto">Christian Puhrsch, Horace He, Joe Isaacson and many more for their
many contributions in Accelerating GenAI models in the <em>"Anything,
Fast!"</em> pytorch.org blogs, and, in particular, Horace He for <a href="https://github.com/pytorch-labs/gpt-fast">GPT,
Fast!</a>, which we have
directly adopted (both ideas and code) from his repo.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">torchchat is released under the <a href="https://github.com/pytorch/torchchat/blob/main/LICENSE">BSD 3 license</a>. (Additional
code in this distribution is covered by the MIT and Apache Open Source
licenses.) However you may have other legal obligations that govern
your use of content, such as the terms of service for third-party
models.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Building a Local Perplexity Alternative with Perplexica, Ollama, and SearXNG (123 pts)]]></title>
            <link>https://jointerminus.medium.com/building-a-local-perplexity-alternative-with-perplexica-ollama-and-searxng-71602523e256</link>
            <guid>41125919</guid>
            <pubDate>Thu, 01 Aug 2024 03:36:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jointerminus.medium.com/building-a-local-perplexity-alternative-with-perplexica-ollama-and-searxng-71602523e256">https://jointerminus.medium.com/building-a-local-perplexity-alternative-with-perplexica-ollama-and-searxng-71602523e256</a>, See on <a href="https://news.ycombinator.com/item?id=41125919">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><h2 id="8ab3" data-testid="storyTitle">Building a Local Perplexity Alternative with Perplexica, Ollama, and SearXNG</h2><div><a rel="noopener follow" href="https://jointerminus.medium.com/?source=post_page-----71602523e256--------------------------------"><div aria-hidden="false"><p><img alt="Terminus" src="https://miro.medium.com/v2/resize:fill:88:88/1*TxKrA9t3wlfWX9755MK2Jg.png" width="44" height="44" loading="lazy" data-testid="authorPhoto"></p></div></a></div></div><figure></figure><p id="547d">You’ve probably heard of Perplexity, the AI search engine that’s been making waves. Compared to traditional searching, it provides concise, synthesized answers to queries rather than just a list of links to boost efficiency and productivity. However, Perplexity’s unique capability comes with a price tag — $20 a month for the Pro Search, with free users limited to just 5 pro searches a day.</p><p id="846a">But what if you could build something similar on your own hardware, without monthly fees or usage limits? In this guide, we’ll walk you through the process of creating your local Perplexity alternative using <a href="https://github.com/beclab/terminus" rel="noopener ugc nofollow" target="_blank">Terminus</a>, an open-source, self-hosted operating system based on Kubernetes, along with other powerful open-source AI tools.</p><figure></figure><h2 id="da84">Recreating Perplexity’s workflow</h2><p id="ad47">Before we dive into our self-hosted solution, let’s briefly explore how Perplexity works. Note that this is a simplified version, the actual workflow is much more sophisticated.</p><figure><figcaption>Perplexity workflow</figcaption></figure><ol><li id="68bb">User sends a question to Perplexity.</li><li id="b419">Perplexity understands the question and sends it to search engines like Google</li><li id="5f79">Google searches the web in real-time.</li><li id="0ba0">Google returns sorted results to Perplexity.</li><li id="5ed2">Perplexity creates a prompt using the question and results and sends it to an AI model like OpenAI’s GPT-4.</li><li id="bf13">AI compiles everything into a coherent answer.</li></ol><p id="e5a6">This workflow boils down to three key components:</p><ul><li id="db6c">Perplexity as the AI search platform and interface.</li><li id="b422">Google as the search engine.</li><li id="4377">OpenAI as the AI model provider.</li></ul><p id="c23c">To recreate this, we will replace them with open source tools:</p><figure><figcaption>Local AI search engine workflow</figcaption></figure><ul><li id="5c98"><a href="https://github.com/ollama/ollama" rel="noopener ugc nofollow" target="_blank"><strong>Ollama</strong></a>: A popular open-source project that enables users to host large language models like Gemma2.</li><li id="142a"><a href="https://github.com/searxng/searxng" rel="noopener ugc nofollow" target="_blank"><strong>SearXNG</strong></a>: An open-source, privacy-respecting internet metasearch engine, fetching real-time results from the web.</li><li id="edff"><a href="https://github.com/ItzCrazyKns/Perplexica" rel="noopener ugc nofollow" target="_blank"><strong>Perplexica</strong></a>: An AI-powered search engine that ties everything together.</li></ul><h2 id="ef1a">Why deploy on Terminus?</h2><p id="0fe1">Compared to regular installation methods, Terminus provides a more streamlined, user-friendly experience for users looking to self-host applications:</p><ul><li id="6033"><strong>Simple and fast deployment<br></strong>Terminus offers one-click installations for apps like Ollama and Perplexica through its marketplace. This allows for rapid deployment and testing of new projects.</li><li id="0f66"><strong>Flexible app and service combination<br></strong>Applications and services in Terminus can be deployed once and flexibly assembled as needed. This allows for easy experimentation with different configurations and service combinations without complex redeployments.</li><li id="98ad"><strong>Anywhere access with a unique domain name.<br></strong>Terminus provides a dedicated domain name for each application and service out-of-the-box, enabling access from any device with a browser.</li></ul><h2 id="b6b5">Prerequisites</h2><ul><li id="1b28">A Windows (Windows 10 or 11) or Linux PC, with a Nvidia GPU</li><li id="f856">Terminus installed. Please refer to the <a href="https://docs.jointerminus.com/overview/introduction/getting-started/windows.html" rel="noopener ugc nofollow" target="_blank">Quick Start</a> guides to install Terminus.</li></ul><h2 id="9905">Step-by-step guide</h2><p id="0603">Take the steps below to build your local AI engine on Terminus.</p><h2 id="5a40">Step1: Launch Terminus</h2><p id="108a">Launch Terminus from your browser, and open Terminus Market from the desktop.</p><blockquote><p id="c59d">N<strong><em>ote</em></strong><em>: You can access Terminus using your personal domain name in any browser.</em></p></blockquote><figure><figcaption>Terminus Market</figcaption></figure><h2 id="5290">Step 2: Install the apps</h2><ol><li id="c318">In <strong>Market</strong>, find Ollama, SearXNG, and Perplexica.</li><li id="e9bd">Click <strong>Get</strong> under each app to install them. Wait until installation finishes.</li></ol><h2 id="2592">Step3: Configure Ollama</h2><p id="d409">Configure Ollama with the AI model. For our setup here, we will use Gemma2, Google’s latest open-source language model.</p><figure><figcaption>Configure Ollama</figcaption></figure><ol><li id="216a">Open Ollama from launcher.</li><li id="248e">Navigate to <strong>Admin Panel</strong> &gt; <strong>Models</strong> &gt; <strong>Pull a model from </strong><a href="http://ollama.com/" rel="noopener ugc nofollow" target="_blank"><strong>Ollama.com</strong></a>, and select <strong>gemma2:27b</strong> as the target model to pull.</li><li id="0daf">Click the download button on the right to start pulling the model. Exit the app when the pulling completes.</li></ol><h2 id="b758">Step 4: Configure Perplexica</h2><p id="339c">We are almost ready. Let’s configure Perplexica, the glue that ties everything together.</p><ol><li id="7900">Open Perplexica from launcher.</li><li id="b76f">In the <strong>Settings</strong> window, specify as shown in the screenshot.</li></ol><figure><figcaption>Configure Perplexica</figcaption></figure><p id="de3f">Since we have already installed Ollama with Gemma2, they will appear as default options here. Congratulations, you just get your self-hosted Perplexity alternative.</p><h2 id="e67f">Step 5: Test your local AI search engine</h2><p id="9bc7">Let’s try by asking the same question on Perplexica and Perplexity and make an apple-to-apple comparison.</p><figure><figcaption>Answer by Perplexica</figcaption></figure><figure><figcaption>Answer by Perplexity</figcaption></figure><p id="d603">As you can see, we asked the same question “why selfhsoting”. While the processing time, info length and details vary due to different models and tech stacks, the answer by Perplexica is acceptable considering the benefits of self-hosting.</p><blockquote><p id="1db6">T<strong><em>ip</em></strong><em>: you can access your self-hosted Perplexica from your phone anywhere, thanks to the dedicated domain provided by Terminus.</em></p></blockquote><h2 id="92b8">Conclusion</h2><p id="8275">By leveraging Terminus and open-source tools like Ollama, SearXNG, and Perplexica, you can create a powerful, self-hosted AI search engine similar to commercial offerings like Perplexity. This setup not only saves you money but also gives you control over your data and search experience.</p><p id="c2c7">We encourage you to experiment with your setup, try different language models, and customize your AI search engine to fit your unique needs.</p><p id="84a6">In our future sessions, we’ll explore setting up other exciting AI projects like Dify and Open WebUI on Terminus. In the meantime, you can keep an eye on the <a href="https://github.com/beclab/terminus" rel="noopener ugc nofollow" target="_blank">Terminus project</a> on GitHub for updates and new features if you like what we are doing.</p><p id="a7c2">Happy self-hosting!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Genomic Code: The genome instantiates a generative model of the organism (112 pts)]]></title>
            <link>https://arxiv.org/abs/2407.15908</link>
            <guid>41125648</guid>
            <pubDate>Thu, 01 Aug 2024 02:25:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2407.15908">https://arxiv.org/abs/2407.15908</a>, See on <a href="https://news.ycombinator.com/item?id=41125648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2407.15908">View PDF</a></p><blockquote>
            <span>Abstract:</span>How does the genome encode the form of the organism? What is the nature of this genomic code? Common metaphors, such as a blueprint or program, fail to capture the complex, indirect, and evolutionarily dynamic relationship between the genome and organismal form, or the constructive, interactive processes that produce it. Such metaphors are also not readily formalised, either to treat empirical data or to simulate genomic encoding of form in silico. Here, we propose a new analogy, inspired by recent work in machine learning and neuroscience: that the genome encodes a generative model of the organism. In this scheme, by analogy with variational autoencoders, the genome does not encode either organismal form or developmental processes directly, but comprises a compressed space of latent variables. These latent variables are the DNA sequences that specify the biochemical properties of encoded proteins and the relative affinities between trans-acting regulatory factors and their target sequence elements. Collectively, these comprise a connectionist network, with weights that get encoded by the learning algorithm of evolution and decoded through the processes of development. The latent variables collectively shape an energy landscape that constrains the self-organising processes of development so as to reliably produce a new individual of a certain type, providing a direct analogy to Waddingtons famous epigenetic landscape. The generative model analogy accounts for the complex, distributed genetic architecture of most traits and the emergent robustness and evolvability of developmental processes. It also provides a new way to explain the independent selectability of specific traits, drawing on the idea of multiplexed disentangled representations observed in artificial and neural systems and lends itself to formalisation.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Kevin Mitchell [<a href="https://arxiv.org/show-email/20ca0445/2407.15908">view email</a>]      <br>    <strong>[v1]</strong>
        Mon, 22 Jul 2024 16:41:25 UTC (3,278 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How Does OpenAI Survive (105 pts)]]></title>
            <link>https://www.wheresyoured.at/to-serve-altman/</link>
            <guid>41125630</guid>
            <pubDate>Thu, 01 Aug 2024 02:18:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wheresyoured.at/to-serve-altman/">https://www.wheresyoured.at/to-serve-altman/</a>, See on <a href="https://news.ycombinator.com/item?id=41125630">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
      <p>Throughout the last year I’ve written in detail about the rot in tech — <a href="https://www.wheresyoured.at/sam-altman-is-full-of-shit/"><u>the spuriousness of charlatans looking to accumulate money and power</u></a>, <a href="https://www.wheresyoured.at/rotcombubble/"><u>the desperation of the most powerful executives to maintain control and rapacious growth</u></a>, <a href="https://www.wheresyoured.at/pop-culture/"><u>and the speciousness of the latest hype cycle</u></a> — but at the end of the day, these are just companies, which leads to a very simple question: can the largest, most prominent company in tech’s latest hype cycle actually survive?&nbsp;</p><p>I am, of course, talking about OpenAI. Regulars to this newsletter will know that I’m highly skeptical of OpenAI’s product, its business model, and its sustainability. While I don’t want to rehash the arguments made in previous newsletters and podcasts, here’s the crux of the matter: generative AI is a product with no mass-market utility - at least on the scale of truly revolutionary movements like the original cloud computing and smartphone booms - and it’s one that costs an eye-watering amount to build and run.&nbsp;</p><p>Those two factors raise genuine questions about OpenAI’s ability to exist on a medium-to-long term, especially if — or, if I may be so bold to say, when — the sluice of investment money and cloud computing credits dries up.</p><p>I don't have all the answers. I don't know every part of every deal that informs every part of every aspect of generative AI. I am neither an engineer nor an economist, nor do I have privileged information. However, I do have the ability to read publicly-available data, as well as evaluate the independent reporting of respected journalists and the opinions of well-informed experts and academics, and come to conclusions as a result.</p><p>I am hypothesizing that for OpenAI to survive for longer than two years, it will have to (in no particular order):</p><ul><li>Successfully navigate a convoluted and onerous relationship with Microsoft, one that exists both as a lifeline and a direct source of competition.</li><li>Raise more money than any startup has ever raised in history, and continue to do so at a pace totally unseen in the history of financing.</li><li>Have a significant technological breakthrough such that it reduces the costs of building and operating GPT — or whatever model that succeeds it — by a factor of thousands of percent.</li><li>Have such a significant technological breakthrough that GPT is able to take on entirely unseen new use cases, ones that are not currently possible or hypothesized as possible by any artificial intelligence researchers.</li><li>Have these use cases be ones that are capable of both creating new jobs and entirely automating existing ones in such a way that it will validate the massive capital expenditures and infrastructural investment necessary to continue.</li></ul><p>I ultimately believe that OpenAI in its current form is untenable. There is no path to profitability, the burn rate is too high, and generative AI as a technology requires too much energy for the power grid to sustain it, and training these models is equally untenable, both as a result of ongoing legal issues (as a result of theft) and the amount of training data necessary to develop them.</p><p>And, quite simply, any technology requiring hundreds of billions of dollars to prove itself is built upon bad architecture. There is no historical precedent for anything that OpenAI needs to happen. Nobody has ever raised the amount of money it will need, nor has a piece of technology required such an incredible financial and systemic force — such as rebuilding the American power grid — to <em>survive,</em> let alone <em>prove itself as a technology worthy of such investment.</em></p><p>To be clear, this piece is focused on OpenAI rather than Generative AI as a technology — though I believe OpenAI's continued existence is necessary to keep companies interested/invested in the industry at all. OpenAI has raised the most money of any generative AI company (<a href="https://www.crunchbase.com/organization/openai?ref=wheresyoured.at"><u>$11.3 billion</u></a>), has arguably the most attention in the press, and both popularized and created the Large Language Mode (LLM)l business model that allowed the current generation of "AI-powered" startups to exist.</p><p>What I am <em>not</em> saying is that OpenAI will for sure collapse, or that generative AI will definitively fail.<a href="https://www.wheresyoured.at/pop-culture/"><u> I have exhaustively discussed the problems with this industry</u></a> in the past, and I won't reiterate those points other than to illustrate what I believe is a deep instability in the tech ecosystem, and my point here is to coldly explain why OpenAI, in its current form, cannot survive longer than a few more years without a stunning confluence of technological breakthroughs and financial wizardry, some of which is possible, much of which has no historic precedence.</p><p>Let's have a look, shall we?</p><h2 id="the-microsoft-and-valuation-problem"><strong>The Microsoft (and Valuation) Problem</strong></h2><p>Before we continue, I should note that OpenAI and Microsoft have not publicly-disclosed the terms of their deals, and there may be things I do not know that change this picture.</p><p>Regardless, OpenAI's relationship with Microsoft is deeply strange,<a href="https://openai.com/index/microsoft-invests-in-and-partners-with-openai/?ref=wheresyoured.at"><u> starting with a $1 billion cash infusion in 2019</u></a>, framed as a "<a href="https://techcrunch.com/2019/07/22/microsoft-invests-1-billion-in-openai-in-new-multiyear-partnership/?ref=wheresyoured.at"><u>multiyear exclusive computing partnership</u></a>" that "port[ed OpenAi's] existing services to work on Azure" (Microsoft's cloud computing product) and made Microsoft "OpenAI's preferred partner." OpenAI CTO Greg<a href="https://news.ycombinator.com/item?id=20498087&amp;ref=wheresyoured.at"><u> Brockman added at the time</u></a> that this was a "cash investment," but noted that OpenAI would "plan to be a big Azure customer."&nbsp;</p><p>One particular thing to note is that Brockman stated that Microsoft would<a href="https://news.ycombinator.com/item?id=20498087&amp;ref=wheresyoured.at#:~:text=pre%2DAGI%20technologies"><u> get access to sell OpenAI's pre-AGI products</u></a> based off of [OpenAI's research] to Microsoft's customers, and in the accompanying blog post added that Microsoft and OpenAI were "<a href="https://openai.com/index/microsoft-invests-in-and-partners-with-openai/?ref=wheresyoured.at#:~:text=develop%20new%20Azure%20AI%20supercomputing%20technologies"><u>jointly developing new Azure AI supercomputing technologies</u></a>."&nbsp;</p><p>Pre-AGI in this case refers to anything OpenAI has ever developed, as it has yet to develop AGI and has<a href="https://www.wheresyoured.at/put-up-or-shut-up/#:~:text=According%20to%20Bloomberg%2C%20these%20five%20levels%20go%20from%20Level%201%20(%22Chatbots%2C%20AI%20with%20conversational%20language%22)%20to"><u> yet to get past the initial "chatbot" stage of its own 5-level system of evaluating artificial intelligence</u></a>.</p><p>In essence, the terms of this funding round involved OpenAI handing over the research it had made to Microsoft, along with the ability for Redmond to sell OpenAI's technology as its own under the Azure banner. Furthermore, Microsoft has access to OpenAI's "pre-AGI product research," meaning that it is able to see exactly how it works, which would allow it to both sell the technology and directly compete with it. This is something that Microsoft is already working on, with<a href="https://www.theinformation.com/articles/meet-mai-1-microsoft-readies-new-ai-model-to-compete-with-google-openai?rc=kz8jh3&amp;ref=wheresyoured.at"><u> The Information reporting in May that Microsoft was readying its own "MAI-1" generative model</u></a>, run by Mustafa Suleyman, the co-founder of Deepmind (<a href="https://techcrunch.com/2014/01/26/google-deepmind/?ref=wheresyoured.at"><u>acquired by Google in 2014</u></a>),<a href="https://www.cnbc.com/2022/01/28/mustafa-suleyman-deepmind-co-founder-quits-google-ai-role-to-be-vc.html?ref=wheresyoured.at"><u> which he left in 2022</u></a> to become a VC. Suleyman later went on to found Inflection ,<a href="https://www.fastcompany.com/91069182/microsoft-inflection-ai-exclusive?ref=wheresyoured.at"><u> a transformer-based chatbot company that was sort-of acquired by Microsoft in March</u></a>, and <a href="https://www.reuters.com/technology/inflection-ai-raises-13-bln-funding-microsoft-others-2023-06-29/?ref=wheresyoured.at"><u>which Microsoft backed</u></a> prior to its acquisition.</p><p>The Information also noted that the OpenAI partnership "<a href="https://www.theinformation.com/articles/microsoft-openai-inside-techs-hottest-romance?rc=kz8jh3&amp;ref=wheresyoured.at"><u>helped Microsoft get ahead of their rivals</u></a>." I am, again, hypothesizing, and the terms of this deal alone are extremely concerning for OpenAI in general.</p><p>Things now get a little confusing.</p><p>Apparently, in 2021 Microsoft made some sort of investment in OpenAI (<a href="https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/?ref=wheresyoured.at"><u>cited here in a 2023 blog post about <em>another </em>funding round I'll get to in a minute</u></a>). Confusingly, I cannot find many details on this round.<a href="https://www.crunchbase.com/funding_round/openai-secondary-market--ac1e85f3?ref=wheresyoured.at"><u> Crunchbase references a 2021 secondary market</u></a> offering of an undisclosed amount (meaning that then-current stockholders at OpenAI were able to sell liquidate their stock), but cites that the money came from Tiger Global Management, Sequoia Capital, Bedrock and Andreessen Horowitz, valuing the company at $14 billion.&nbsp;</p><p>It's unclear whether this was the same round, or if Microsoft otherwise infused capital.<a href="https://www.theinformation.com/briefings/microsoft-openai-new-multi-billion-dollar-investment?rc=kz8jh3&amp;ref=wheresyoured.at"><u> The Information mentions in an article from early 2023</u></a>, but somehow <em>nobody</em> covered it at the time. If I'm wrong, I'd love to see how it did so.</p><p>Regardless,<a href="https://www.cnbc.com/2023/01/10/microsoft-to-invest-10-billion-in-chatgpt-creator-openai-report-says.html?ref=wheresyoured.at"><u> in early 2023 Microsoft invested $10 billion in OpenAI</u></a> — but the most important parts of the deal are both its <em>terms</em> and its <em>distribution. </em>Though the terms of the deal aren't public, <a href="https://www.theverge.com/2023/1/23/23567448/microsoft-openai-partnership-extension-ai?ref=wheresyoured.at"><u>reports state that Microsoft will may receive 75% of OpenAI's profits until it secures "its investment return [a clunky way of saying "makes back the $10 billion it invested],"</u></a> along with a 49% stake in the company,<a href="https://www.wheresyoured.at/sam-altman-freed/"><u> though OpenAI's convoluted non-profit-for-profit structure is strange in and of itself</u></a>.&nbsp;</p><p><a href="https://www.semafor.com/article/11/18/2023/openai-has-received-just-a-fraction-of-microsofts-10-billion-investment?ref=wheresyoured.at"><u>Semafor reports that</u></a>, at least by November 2023, OpenAI had received "a fraction" of the $10 billion investment, which was (is?) delivered in tranches (stages), and that a "significant portion" of that money was in cloud compute credits, meaning that Microsoft's investment was predominantly in the supposed value of a currency that can only be used on its own services. For those who don’t fully understand how weird this is, it’s like an airline investing in a company but, instead of providing cash, it hands over air miles. You can still travel, but you are locked into A) one airline and B) their interpretation of what one “mile” is actually worth.</p><p>Furthermore, it’s extremely bizarre that said “investment” also may have - again, we don’t know the terms of the deal - allowed OpenAI to raise its valuation in the process.&nbsp;</p><p>Semafor also adds (vaguely) that Microsoft has "certain rights to OpenAI's intellectual property," and that it "would still be able to run OpenAI's current models on [its] servers" even if the relationship were to break down.</p><p>What's confusing is that <a href="https://www.cnbc.com/2023/04/08/microsofts-complex-bet-on-openai-brings-potential-and-uncertainty.html?ref=wheresyoured.at"><u>multiple</u></a><a href="https://www.bloomberg.com/news/articles/2024-06-28/microsoft-s-13-billion-openai-pact-faces-extra-eu-scrutiny?ref=wheresyoured.at"><u> reporters</u></a> have said that Microsoft had invested "$13 billion" in OpenAI, yet I can't find the two billion dollars anywhere. Was it in 2021? Was the amount $2 billion? Was it cash, or credits? This number has been reported so regularly for so long, and it's extremely strange that so many have just assumed this happened.</p><p>The reason I think this is concerning is that two billion dollars is a great deal of money by any startup's standards.</p><p>For example, Snowflake, a wildly-successful enterprise computing company,<a href="https://www.crunchbase.com/organization/snowflake-computing?ref=wheresyoured.at"><u> raised a total of $2 billion</u></a>, mostly before going public (though it sold $621.5 million in stock post-IPO in 2022). Also, Snowflake lost $316 million last quarter.</p><p>On top of that, this deal was totally unannounced and unreported, happening in the same year (2021) that Microsoft and OpenAI announced their Azure OpenAI services (<a href="https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/?ref=wheresyoured.at"><u>which took until 2023 to launch publicly</u></a>). While I am guessing here — if I'm wrong, please email me — it seems that Microsoft gave another $2 billion to OpenAI in 2021 at the same time that OpenAI raised an undisclosed amount from other sources. I hypothesize this deal is likely to have been a mixture of cash and cloud credits, though ChatGPT didn't reach the public until November 2022.&nbsp;</p><p>It could also be that those reporting that Microsoft had put "$13 billion" into OpenAI could simply be wrong, but it would be a very commonplace error and one that would likely quickly be refuted by either Microsoft or OpenAI.</p><p>The reason that I'm raising these issues is that Microsoft, at this point, effectively <em>owns</em> OpenAI.<a href="https://www.wsj.com/tech/ai/sam-altman-openai-protected-by-silicon-valley-friends-f3efcf68?ref=wheresyoured.at"><u> Microsoft CEO Satya Nadella was instrumental in Altman's return after he was fired in November 2023</u></a>, and<a href="https://www.techtarget.com/searchenterpriseai/news/366560318/Fallout-after-Microsoft-hires-former-OpenAI-CEO-Sam-Altman?ref=wheresyoured.at"><u> had already planned to poach him if he hadn't returned</u></a>. In many ways, this didn't really matter. Due to the nature of Microsoft's deal with OpenAI, it effectively owns — or at least has access to — all of the intellectual property behind OpenAI's products, along with all of the research, as well as the ability to license it at will.</p><p>OpenAI is inextricably tied to Microsoft. It is bound to use Azure, Microsoft's cloud compute platform, both by its agreements and the fact that the majority of its funding is in credits that can only be used on Microsoft Azure. Microsoft sells access to GPT through Azure, while also directly competing with it with its own upcoming model, and takes three-quarters of any of the (theoretical) profit that would come out of OpenAI's services.</p><p>Microsoft has also not had to really sacrifice anything to do these deals. Even if we assume that the <em>entirety</em> of the previous rounds of funding — a theoretical $3 billion — was in cash, and that, say, 25% of the 2023 deal was in cash versus credits, that's only $5.5 billion, with the latter half delivered in tranches on an indeterminate timeline. Assuming (again, I do not have the exact terms) that this was really $5.5 billion in cash, that's <em>nothing</em> for Microsoft, a company that had over $21 billion in <em>profits </em>in its most recent financial quarter.&nbsp;</p><p>As part of this deal, Microsoft has effectively purchased the rights to OpenAI's "pre-AGI" technology, and licensed all of its technology in a way that extends past any partnership or, I imagine, future deals. Microsoft also "invested" in cloud credits at an indeterminate valuation, both in how OpenAI was valued <em>and the credits themselves.&nbsp;</em></p><p>Ask yourself, what is a dollar of "cloud compute credits," and what do they gain you access to?<a href="https://azure.microsoft.com/en-us/pricing?ref=wheresyoured.at#Estimate-and-budget"><u> Microsoft's Azure cloud has many, many products,</u></a> and it's unclear if OpenAI would receive preferential pricing on them, what products they'd be using, and the terms under which OpenAI receives them.Microsoft effectively created its own currency to invest in OpenAI, which OpenAI would then pay Microsoft in, which Microsoft would, in turn, receive as revenue.</p><p>In many ways, OpenAI's continual existence is as an R&amp;D facility for Microsoft's generative AI business unit, one with the dice rigged in Microsoft's favor. In the event of OpenAI's collapse, OpenAI's technology would still run on Microsoft's servers, and Microsoft would still have access to both OpenAI's intellectual property and products, and in turn be able to sell them. In the event that OpenAI thrives and future generations of GPT become remarkably profitable and successful, Microsoft harvests billions of dollars of profits while still retaining access and license to any research or products used to get there. Even Microsoft's $100 billion supercomputer project is reportedly tied to Altman and OpenAI "meaningfully improving" the capabilities of its AI,<a href="https://www.theinformation.com/articles/microsoft-and-openai-plot-100-billion-stargate-ai-supercomputer?rc=kz8jh3&amp;ref=wheresyoured.at"><u> according to sources talking to The Information</u></a>.</p><p>I am obviously not certain, and have no way of confirming this, but do you not think “pre-AGI” technology and research includes <a href="https://www.theverge.com/2024/7/25/24205701/openai-searchgpt-ai-search-engine-google-perplexity-rival?ref=wheresyoured.at"><u>SearchGPT, OpenAI’s recently-announced competitor to Google Search</u></a>? Is it worth considering, for a second, that Microsoft could benefit whether OpenAI lives or dies?&nbsp;</p><p>It's a devil's deal, one that you would only make if you were burning so much cash that it was necessary to find a benefactor with deep pockets, one that could bail you out repeatedly as you chewed through billions of dollars every year.</p><p>Sadly, that may be the truth for OpenAI.</p><h2 id="the-funding-problem"><strong>The Funding Problem</strong></h2><p>Last week, <a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year?rc=kz8jh3&amp;ref=wheresyoured.at"><u>The Information reported that OpenAI could burn as much as $5 billion dollars in 2024</u></a> based on "previously undisclosed internal financial data and people involved in the business."</p><p>The piece makes several informed estimates (and I encourage you to pay for The Information for this article alone) that I am going to draw upon. While it’s <em>possible</em> that these estimates may be wrong, or that the data they were based on was misleading or incorrect, I trust the Information’s analysis and the rigor of its reporting:</p><ul><li>"OpenAI as of March [2024] was on track to spend nearly $4 billion this year on renting Microsoft's servers to power ChatGPT and its underlying LLMs," sourced to a "person with direct knowledge of the spending."</li><li>"OpenAI's training costs — including paying for the data — could balloon to as much as $3 billion this year."<ul><li>As a note, training costs are not simply getting the data, but cleaning and preparing it — a laborious task — and then using massive amounts of cloud compute to train the model using it.</li></ul></li><li>The Information "guesstimates" that OpenAI's 1500-person (and growing) workforce could cost around $1.5 billion a year. While that sounds a little high — especially considering that figure works out to $1m per person — it’s actually quite plausible. Top AI talent is extremely, extremely expensive, and <a href="https://www.wsj.com/tech/ai/the-fight-for-ai-talent-pay-million-dollar-packages-and-buy-whole-teams-c370de2b?ref=wheresyoured.at#:~:text=Some%20of%20these%20hard%2Dto,million%20a%20year%20or%20more.&amp;text=Salespeople%20in%20AI%20are%20also,set%20and%20depth%20of%20knowledge."><u>seven-figure salaries are far from unusual</u></a>. You then have to factor in things like office space, payroll taxes, equipment, and the other operational costs</li><li>The Information also estimates that OpenAI has<a href="https://www.theinformation.com/articles/openais-annualized-revenue-doubles-to-3-4-billion-since-late-2023?rc=kz8jh3&amp;ref=wheresyoured.at"><u> somewhere between $3.5 billion and $4.5 billion in revenue</u></a>, combining both ChatGPT and charging developers to access OpenAI's APIs to integrate generative functions.</li></ul><p>The Information surmises that OpenAI thus has an operating loss of <strong>$5 billion a year.</strong> That also assumes that OpenAI's revenue is on the higher-end, and could balloon to <strong>$6 billion or more.</strong></p><p>Though we don't have direct knowledge, OpenAI's operating costs have continued to rapidly increase over time.<a href="https://www.businessinsider.com/how-much-chatgpt-costs-openai-to-run-estimate-report-2023-4?ref=wheresyoured.at"><u> An estimate from early 2023 suggested that it cost $700,000 a day to run ChatGPT</u></a> at a time when it was <em>popular</em> but not <em>as popular as it is today, </em>and would put ChatGPT's costs alone at around $235.3 million a year. I would also hypothesize that they were much larger based on OpenAI having raised over $13 billion in the last five years, with the majority of the capital (and credit) raises happening between 2021 and 2023.</p><p>OpenAI has historically, based on reporting, failed to make its models more efficient,<a href="https://www.businessinsider.com/openai-model-arrakis-dystopian-desert-world-dune-2023-10?ref=wheresyoured.at"><u> failing to deliver their more efficient "Arrakis" model to Microsoft in late 2023</u></a>. While the recent launch of its GPT-4o mini model has been hailed as an "efficiency" play,<a href="https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/?ref=wheresyoured.at#:~:text=developers%20to%20build%20and%20scale%20powerful%20AI%20applications%20more%20efficiently%20and%20affordably"><u> it appears to only be more efficient and cost-effective for those developing using OpenAI's tools</u></a>, and while one could posit that this suggests that OpenAI found a more efficient/cost-effective model and thus made it cheaper, it has yet to volunteer this information to confirm.</p><p>Assuming everything exists in a vacuum, <strong>OpenAI needs at least $5 billion in new capital a year to survive. </strong>This would require it to raise more money than has ever been raised by any startup in history, possibly in perpetuity, which would in turn require it to access capital at a scale that I can find no comparable company to in business history.</p><p>WeWork — the decrepit failson of Silicon Valley —<a href="https://www.crunchbase.com/organization/wework/investor_financials?ref=wheresyoured.at"><u> raised a total of $22.2 billion</u></a>, with nearly half of it (over $10 billion) raised in debt financing (loans with varying terms) from Goldman Sachs and SoftBank's Vision Fund,<a href="https://www.nytimes.com/2023/03/17/business/wework-softbank-debt-deal.html?ref=wheresyoured.at"><u> some of which it had to restructure as the company collapsed</u></a>. Much of WeWork's capital was raised during a time with lower interest rates and thus much more available money, and heavily relied on SoftBank's continual willingness to dump cash into a fire. WeWork also had a far more reasonable — though extremely stupid — business model, one that a lot of financiers could get their head around, and thus was able to appeal to a much wider investment market.</p><p>A more reasonable comparable would be CoreWeave, a company that gives other companies access to (and build-outs of) the massive Graphics Processing Unit clusters to power AI applications. CoreWeave has raised a total of<a href="https://www.crunchbase.com/organization/coreweave?ref=wheresyoured.at"><u> $12.1 billion dollars</u></a> with — you guessed it — the majority of it raised in a "<a href="https://www.blackstone.com/news/press/coreweave-secures-7-5-billion-debt-financing-facility-led-by-blackstone-and-magnetar/?ref=wheresyoured.at"><u>debt financing facility</u></a>" offered by asset management firms Blackstone and Magnetar that allows it to draw upon cash at an undisclosed (but likely lower) interest rate.<a href="https://www.wsj.com/tech/ai/ai-cloud-computing-startup-coreweave-valued-at-19-billion-in-new-funding-round-dfdb47cd?ref=wheresyoured.at"><u> CoreWeave has raised at a $19 billion valuation</u></a>, and unlike OpenAI, its services are relatively straightforward. If you need a bunch of compute, CoreWeave will either build it for you, or lease it to you.</p><p>Historically, according to data provided by Crunchbase, the largest funding round of the last decade was $14 billion,<a href="https://techcrunch.com/2018/06/07/ant-financial-raises-14-billion/?ref=wheresyoured.at"><u> raised by Ant Group in 2018</u></a>, followed by Juul, also in 2018,<a href="https://investor.altria.com/press-releases/news-details/2018/Altria-Makes-128-Billion-Minority-Investment-in-JUUL-to-Accelerate-Harm-Reduction-and-Drive-Growth/default.aspx?ref=wheresyoured.at"><u> when it raised $12.8 billion</u></a>. Otherwise, OpenAI dominates.</p><blockquote>As another aside, Uber, <a href="https://www.theverge.com/2024/2/8/24065999/uber-earnings-profitable-year-net-income?ref=wheresyoured.at"><u>a company famed for burning $25 billion dollars to achieve profitability</u></a>, raised a total of...well, <a href="https://www.crunchbase.com/organization/uber?ref=wheresyoured.at"><u>$25 billion</u></a>, which included <u>four different funding rounds in the year 2018 alone.</u><p>And even then it was more profitable than OpenAI, other than in 2020, when it lost $6.7 billion — around $1.7 billion more than OpenAI might lose this year — because <em>people weren’t going anywhere.</em></p><p>On top of that, — and yes, I am directly responding to the Information’s “</p><a href="https://www.theinformation.com/articles/is-openai-a-good-business?utm_source=ti_app&amp;rc=kz8jh3"><u>is OpenAI a good business</u></a>?,” the central argument of which is that OpenAI also needs to burn a bunch of money — Uber immediately had a use case people understood, and immediately generated revenue by devouring the taxi monopolies, subsidized heavily by venture capital. <p>Conversely, OpenAI has devoured no monopoly, and the product category it created — the only one it is really part of — is one entirely subsidized by venture capital and Microsoft. What OpenAI is offering is entirely hype-driven, hard to explain to the layman, a movement driven by a lack of hypergrowth markets.&nbsp;</p><p>Uber was priced to replace a monopoly, and one that most people hated. Taxis were expensive, inconvenient, artificially scarce (especially in cities like New York, which limited the supply of taxis through its medallion system), and seldom accepted credit cards. Worse, discrimination against those of a minority background by drivers was rife and unchallenged (</p><a href="https://www.nytimes.com/2019/05/19/nyregion/nyc-taxis-medallions-suicides.html?ref=wheresyoured.at"><u>and involved exploitative loan schemes</u></a>). While we can dislike Uber as a company and criticize its business practices, you can’t deny it had an objective appeal from the outset.&nbsp;<p>By contrast, OpenAI created an industry-wide FOMO psychosis, and has profited heavily from it, but explaining what ChatGPT is to a layman is possible yet convoluted, which Uber was not. </p><a href="https://www.promarket.org/2019/11/27/false-claims-and-propaganda-why-ubers-narratives-are-wrong-but-successful/?ref=wheresyoured.at"><u>I should also add that the media was used by Uber as a means of laundering Uber’s reputation</u></a>, used specifically to (<a href="https://thebaffler.com/latest/the-miseducation-of-kara-swisher-ongweso?ref=wheresyoured.at"><u>and I quote Edward Ongweso Jr</u></a>.) convince people to “view its growth as progressive, not parasitic.” It’s important to bring attention to OpenAI and Sam Altman’s attempts to create a narrative promising things that its company has no way of doing, and even more so to not find ways to explain away how unsustainable OpenAI is. It is fundamentally not the media’s job to convince the world that OpenAI is a stable company with great things ahead — that’s OpenAI’s job. <p>While I am not sure it’s appropriate to say that I’m a “member of the media,” of the two of us, I think that the PR guy with a part-time newsletter and a podcast should never be the one who’s more willing to be critical.</p></blockquote><p>As of its last round of funding — a secondary market (meaning insiders can sell their stocks to VCs) offering from February of this year —<u> </u><a href="https://www.nytimes.com/2024/02/16/technology/openai-artificial-intelligence-deal-valuation.html?ref=wheresyoured.at"><u>OpenAI is "valued" at $80 billion</u></a>. I say "valued," because Microsoft's investment (which likely increased the valuation of the company, though I can't confirm) was predominantly in funny-money, cloud credits, rather than any actual "investment" that would in turn give something a "valuation."</p><p>Furthermore, debt financing is usually a little harder to get, with onerous cash-heavy terms that can eat a company alive in a bad month.</p><p>Comparables at this scale are few and far between.<a href="https://www.cbinsights.com/research-unicorn-companies?ref=wheresyoured.at"><u> Based on data from CBInsights</u></a>, the only private companies that compete are TikTok developer ByteDance ($225 billion,<a href="https://www.crunchbase.com/organization/bytedance?ref=wheresyoured.at"><u> raised $9.5bn</u></a>) and SpaceX ($150 billion,<a href="https://www.crunchbase.com/organization/space-exploration-technologies?ref=wheresyoured.at"><u> raised $9.8bn</u></a>), with Stripe ($70 billion (though I've seen $65 billion),<a href="https://www.crunchbase.com/organization/stripe?ref=wheresyoured.at"><u> raised $9.4bn</u></a>), Shein ($66 billion,<a href="https://www.crunchbase.com/organization/shein-b79e?ref=wheresyoured.at"><u> raised $4.1bn</u></a>) and Databricks ($43 billion,<a href="https://www.crunchbase.com/organization/databricks?ref=wheresyoured.at"><u> raised $4bn</u></a>) just behind.</p><p>In all of these cases, the companies in question make real money and have real business models. ByteDance (which owns TikTok, as well as several other companies in China)<a href="https://www.ft.com/content/275bd036-8bc2-4308-a5c9-d288325b91a9?ref=wheresyoured.at"><u> made $120 billion in revenue in 2023</u></a>, and its services are used by hundreds of millions of people. SpaceX, while unprofitable, is (for better or worse) effectively tied to the US government as a necessary contractor, and has<a href="https://www.wsj.com/tech/behind-the-curtain-of-elon-musks-secretive-spacex-revenue-growth-and-rising-costs-2c828e2b?ref=wheresyoured.at"><u> succeeded making billions of dollars in reducing its operating costs</u></a>. Stripe is one of the most well-respected payments companies in the world, makes billions of dollars, has extremely useful services, and<a href="https://techcrunch.com/2024/03/13/stripes-growth-payment-1t-fintech/?ref=wheresyoured.at"><u> is "robustly cash flow positive."</u></a> Shein, while a horrible company built on exploitation, makes over<a href="https://www.cnbc.com/2024/01/08/sheins-revenue-is-a-lot-more-than-30-billion-annually-exec.html?ref=wheresyoured.at"><u> $30 billion a year</u></a> and has<a href="https://www.ft.com/content/702223df-2e52-4e62-8f7c-93695a100d9b?ref=wheresyoured.at"><u> $2 billion in profit</u></a> <em>selling stuff. </em>Databricks, a boring-yet-useful data intelligence company,<a href="https://www.databricks.com/company/newsroom/press-releases/databricks-announces-over-70-annualized-growth-emea-fueled?ref=wheresyoured.at#:~:text=Globally%2C%20Databricks%20reached%20over%20%241.6,driven%20by%20rapid%20product%20innovation."><u> reported in April that it had reached $1.6 billion in revenue in a quarter</u></a>, and<a href="https://www.thestack.technology/databricks-just-raised-a-fresh-500-million-why/?ref=wheresyoured.at#:~:text=Databricks%20has%20yet%20to%20achieve,and%20coin%20landing%20in%20coffers."><u> is yet to achieve profitability</u></a> — making it the odd man out, and possibly the closest comparable to OpenAI.</p><p>However, one consistent difference with these companies is that they've <em>proven market viability.</em> While Databricks may be an indeterminate level of unprofitable, it has been raising for longer (since their Series A in 2013), and while it’s raised <em>a lot</em>, OpenAI has had to raise more, in a shorter period of time, and will have to raise again soon.&nbsp;</p><p>SpaceX,<u> </u><a href="https://www.space.com/spacex-starship-second-flight-explosion-cause?ref=wheresyoured.at"><u>which makes rockets that sometimes explode</u></a>, still makes rockets and satellites that provide people with internet access (<a href="https://www.expressnews.com/business/article/spacex-s-starlink-poised-record-revenue-2024-19450589.php?ref=wheresyoured.at"><u>and Starlink makes billions in revenue</u></a>) — which isn't an endorsement of Musk so much as it is a differentiator. Stripe has raised in large chunks, but over a longer timeline and <em>also provides a very obvious and useful product.</em> And I don't have to explain why TikTok or Douyin are important considering they're both some of the largest social networks in the world.</p><p>And in all cases, <strong><em>they've raised less money than OpenAI has to date,</em> </strong>though with the caveat that OpenAI's $10 billion round was mostly in cloud credits.</p><p>Yet that actually raises a much thornier question: is OpenAI <em>capable</em> of raising this much money?<a href="https://techcrunch.com/2023/03/15/stripe-now-valued-at-50b-following-6-5b-raise/?ref=wheresyoured.at"><u> When Stripe raised $6.5 billion in 2023, it dropped its valuation to $50 billion</u></a>,<a href="https://www.reuters.com/business/finance/fintech-giant-stripe-raises-nearly-694-mln-funds-2024-04-12/?ref=wheresyoured.at"><u> which it got back to $65 billion in 2024 when it raised a tender offer of $694 million</u></a>. Again, Stripe is bordering on an essential service, used across wide swaths of the internet to help people buy stuff. <a href="https://www.crunchbase.com/organization/anthropic/company_financials?ref=wheresyoured.at"><u>OpenAI competitor Anthropic has also had to raise over $7 billion since 2021</u></a> (<a href="https://techmonitor.ai/technology/ai-and-automation/aws-anthropic-ai-public-cloud?ref=wheresyoured.at"><u>including billions from Amazon and Google that could also be in cloud credits</u></a>)- and<a href="https://www.theinformation.com/briefings/anthropic-projected-to-burn-more-than-2-7-billion-in-cash-this-year?rc=kz8jh3&amp;ref=wheresyoured.at"><u> The Information reports it could burn $2.7 billion in 2024</u></a> on $800 million in revenue <em>that it has to share with Amazon.</em></p><p>What I'm trying to establish is that OpenAI would have to, at its current pace:</p><ul><li>Raise more money than anyone ever has before — likely at least $3 billion, but more like $10 billion, and do so soon, likely within the next six months.</li><li>Raise either multiple rounds, or the largest funding round ever raised by any company, and then have to keep doing so in perpetuity.</li><li>Raise at either a massive down-round — by taking on more money at a reduced valuation — or raise at a valuation higher than any privately-held company ever has.</li></ul><p>In all of these cases, OpenAI would have to show investors both how it intends to grow revenue and reduce costs, and do so in such a way that it would reassure investors that OpenAI would not simply return asking for more capital in a few months. It would also likely have to amend their corporate structure,<a href="https://www.reuters.com/technology/artificial-intelligence/openai-ceo-says-company-could-become-benefit-corporation-information-2024-06-15/?ref=wheresyoured.at#:~:text=June%2014%20(Reuters)%20%2D%20OpenAI,The%20Information%20reported%20on%20Friday."><u> as Sam Altman has suggested it might</u></a>.</p><p>This isn't <em>impossible</em>, but it feels extremely unlikely that OpenAI would be able to do this for more than a few years.<a href="https://www.wheresyoured.at/put-up-or-shut-up/"><u> Reports suggest that OpenAI is nowhere near Artificial General Intelligence</u></a>, and while Altman could potentially raise another round from venture capitalists desperate to get aboard the company, doing so would risk exposing how bad the burn rate truly is.</p><p>If we assume that<a href="https://www.nytimes.com/2024/02/16/technology/openai-artificial-intelligence-deal-valuation.html?ref=wheresyoured.at"><u> OpenAI's secondary market round from February 2024</u></a> was the best-case scenario — $5 billion in <em>cash</em>, and I'd guess it was less, we truly have no idea — the company still needs another lifeline within the next 12 months.</p><p>In a more realistic case, I believe OpenAI has to raise within the next 3-6 months, which will mean that doing so will involve them raising funds after at least one quarter of reported earnings from Microsoft, with the next coming up on July 30.</p><p>Assuming a burn rate of even $3 billion a year — which would require a remarkable reduction in costs — OpenAI would still have to raise more capital than anyone has ever raised for as long as it takes to either increase revenues or reduce costs. It's extremely concerning, and equally unsustainable.</p><h2 id="the-revenue-cost-and-market-fit-problem"><strong>The Revenue, Cost and Market-Fit Problem</strong></h2><p>As I've written repeatedly,<a href="https://www.wheresyoured.at/pop-culture/"><u> generative AI is deeply unprofitable</u></a>, and<a href="https://www.theinformation.com/articles/why-openai-could-lose-5-billion-this-year?rc=kz8jh3&amp;ref=wheresyoured.at"><u> based on the Information's estimates</u></a>, the cost of goods sold is unsustainable.</p><p>OpenAI's costs have only increased over time, and the cost of making these models "better" are only increasing, and have yet to,<a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf?ref=wheresyoured.at"><u> to paraphrase Goldman Sachs' Jim Covello</u></a>, solve the kind of complex problems that would justify their cost. "Better" is also somewhat of a misnomer — a "better" version of ChatGPT may be faster, give answers that are more accurate or that are generated more-quickly, but it is not able to do significantly <em>more</em>. Since November 2022, ChatGPT has grown more sophisticated, faster at generations, capable of ingesting more data, but has yet to generate a true "killer app," an iPhone-esque moment.</p><p>Furthermore, transformer-based models have become heavily-commoditized, with competition from independent(ish) companies like Anthropic's Claude and Meta's LLama, all trained on the same massive data-sets, to the point that ChatGPT's biggest advantage is in its brand. As a result, we're already seeing a race to the bottom, with<a href="https://x.com/minimaxir/status/1813985834728919249?ref=wheresyoured.at"><u> GPT-4o Mini (OpenAI's "cheaper" model) already beaten in price by Anthropic's Claude Haiku model</u></a>, and I am confident somebody is already working on a similarly-powerful model that they'll sell <em>for even cheaper.</em></p><p>As a result, OpenAI's revenue might <em>climb</em>, but it's likely going to climb by reducing the cost of its services rather than its own operating costs. OpenAI appears to be operating in the standard valley monopoly model — get as many customers as possible and then work out how to get profitable — but is doing so using a technology that is uniquely expensive to both operate and iterate upon.</p><p>As discussed previously, OpenAI — like every single transformer-based model developer — requires masses of training data to make its models "better," and the<a href="https://www.wsj.com/tech/ai/ai-training-data-synthetic-openai-anthropic-9230f8d8?ref=wheresyoured.at"><u> next generation of GPT will require four to five times the amount it needed for GPT-4</u></a><a href="https://www.nytimes.com/2024/07/19/technology/ai-data-restrictions.html?ref=wheresyoured.at"><u> at a time when publishers and the wider internet have found numerous ways to block them from taking it</u></a>.</p><p>Doing so is also likely going to lead to perpetual legal action, especially as 404 Media reports that Runway, a generative video company,<a href="https://www.404media.co/runway-ai-image-generator-training-data-youtube/?ref=wheresyoured.at"><u> likely trained its model on thousands of hours of videos taken from YouTube and pirated sources</u></a>. OpenAI has<a href="https://www.wheresyoured.at/peakai/"><u> been incredibly evasive when asked if it trained their "Sora" model on YouTube videos</u></a>, and if I had to guess, it absolutely has. If it hasn't, it likely will be required to buy tens of thousands — if not millions — of hours of footage, which<a href="https://www.theverge.com/2024/5/22/24162782/openai-licensing-deal-wall-street-journal-news-corp?ref=wheresyoured.at"><u> will be multitudes more expensive than the $250 million it paid to News Corp to train on its articles</u></a>.</p><p>And, to be abundantly clear, <em>I am not sure there is enough training data in existence</em> to get these models past the next generation. Even if generative AI companies were able to legally and freely download every single piece of text and visual media from the internet, it doesn't appear to be enough to train these models, with some model developers <a href="https://www.wheresyoured.at/bubble-trouble/"><u>potentially turning to model-generated "synthetic" data</u></a> — a process that could introduce "<a href="https://www.zdnet.com/article/beware-of-ai-model-collapse-how-training-on-synthetic-data-pollutes-the-next-generation/?ref=wheresyoured.at"><u>model collapse</u></a>," a form of inbreeding that Jathan Sadowski called "Habsburg AI" that destroys the models over time.</p><p>Even if they were successful in somehow acquiring this much training data, and doing so in a way that was legally sound (which, to be clear, I do not think is possible), they would then have the increasing costs of training these models. Anthropic CEO recently said on a podcast that "<a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo?ref=wheresyoured.at"><u>AI models that cost $1 billion to train are underway</u></a>," and that there are ones in the future that will cost $100 billion. As models become more complex and require more training data, so too does the cost of ingesting the larger (and likely more complex) training data.</p><p>And then there's the very big, annoying problem — that generative AI doesn't have a product-market fit at the scale necessary to support its existence.</p><p>To be clear, I am not saying generative AI is completely useless, or that it hasn't got <em>any</em> product-market fit. It's useful for digging through massive data-sets, quick summaries of articles (for better or worse), and generating images. These models have utility,<u> </u><a href="https://www.theverge.com/2024/5/15/24154808/ai-chatgpt-google-gemini-microsoft-copilot-hallucination-wrong?ref=wheresyoured.at"><u>despite the propensity of these models to "hallucinate" (authoritatively state something that isn't true, or generate hands with too many fingers)</u></a>,<a href="https://www.ft.com/content/c35ce925-d7b3-4920-a431-c4ca1aa33503?ref=wheresyoured.at"><u> and people are finding useful things for them to do, particularly in finance</u></a>.</p><p>But what they are not, at this time, is <em>essential.&nbsp;</em></p><p>Generative AI has yet to come up with a reason that you<em> absolutely must integrate it,</em> other than the sense that your company is "behind" if you don't use AI. This wouldn't be a problem if generative AI's operating costs were a minuscule fraction — tens or hundreds of thousands of percent — of what they are today, but as things stand, OpenAI is effectively subsidizing the generative AI movement, all while dealing the problem that while <em>cool</em> and <em>useful</em>, GPT is only changing the world as much as the markets allow it to.</p><p>While complex, generative AI is a technology that probabilistically generates answers, and has no "intelligence." It is inherently limited by its architecture, and in turn can only get "better" in a linear fashion. I see no signs that the transformer-based architecture can do significantly more than it currently does.</p><p>For OpenAI to continue growing, it will either have to significantly increase functionality — something it hasyet to do, but is theoretically possible — or vastly reduce pricing, which will only increase its operating costs.</p><p>And OpenAI <em>must grow,</em> because $3.5 billion to $4.5 billion a year in revenue is simply not enough to keep this company going. This isn't about any personal beliefs I have about generative AI. It's about the fact that this company costs more money to run than any other privately-held startup, and its technology does not — based on OpenAI’s sales — do enough to make up for the fact that it costs so much money.</p><p>Outside of reducing prices, which would increase revenues <em>and </em>operating costs, OpenAI could, theoretically, find new functionality in GPT — though I'm not sure how — or create something entirely different, something it has yet to show any sign of doing. While you could point to tools like Sora (which doesn’t seem particularly useful, and is still far from commercialization), or searchGPT (which would have the same hallucinatory issues that dogged Google search’s own pivot to AI, while also competing against the GPT-enabled Bing), it’s tough to make the case that these products will fill the burning shortfall in OpenAI’s balance sheet, and would likely only add to its operational costs</p><p><a href="https://www.reuters.com/technology/artificial-intelligence/openai-working-new-reasoning-technology-under-code-name-strawberry-2024-07-12/?ref=wheresyoured.at"><u>In July, Reuters reported</u></a> that OpenAI was "working on a new technology called Strawberry" that would be "capable of delivering advanced reasoning capabilities." However, on a deeper read of the article, OpenAI is <em>thinking about this </em>and <em>trying to</em> do it, and has <em>yet to do it.</em></p><p>If it succeeds — which I add would require potentially entirely new branches of psychology and mathematics to do so, as we humans barely understand our brains — that would be a huge technological achievement that still <em>wouldn't</em> turn things around. OpenAI would own a completely new kind of technology, which would be immensely valuable, and could potentially raise in perpetuity off of that, but it would be heavily-dependent on the level of reasoning and the accompanying tasks it could achieve.</p><p>And, to be clear, it is very, very unlikely this happens. It could — and there is always stuff I might not know about OpenAI's research and development — but we have seen little sign of OpenAI innovating, and far more signs that it’s only capable at this time of iterating on GPT.</p><p>OpenAI also has a problem with its marketing.<a href="https://www.wheresyoured.at/sam-altman-is-full-of-shit/"><u> Sam Altman has repeatedly misled the media about what "AI might do,"</u></a> conflating generative AI — which does not "know" things and is not "intelligence" — with the purely-theoretical concept of an autonomous, sentient artificial intelligence. As a result, expectations are higher of what future generations of GPT might do, making it inevitable that the company will disappoint investors and customers.</p><p>While there may be ways to reduce the costs of transformer-based models, the level of cost-reduction would be unprecedented, and likely require entirely new chips, cooling solutions and physical server architecture, none of which OpenAI develops.&nbsp;</p><p>While theoretically Nvidia could produce a much-more-efficient chip, doing so would likely take longer than OpenAI has.<a href="https://techcrunch.com/2024/06/25/etched-is-building-an-ai-chip-that-only-runs-transformer-models/?ref=wheresyoured.at"><u> Though there are companies like Etched that <em>claim</em> they are working on specialized chips</u></a>, they are years from delivering any working silicon at the scale that OpenAI would need, and said chips are focused on singular models, making them iterative rather than innovative concepts.</p><p>One thing I am not heavily-discussing is the fact that there doesn't seem to be general-purpose adoption of generative AI. These numbers are hard to establish, but what I have previously established for certain —<a href="https://www.wheresyoured.at/pop-culture/"><u> in particular based on Goldman Sachs' reporting</u></a> — is that <em>actual meaningful revenue</em> is yet to materialize. This is a bigger existential threat than a lack of adoption. It means people are using it and not getting enough out of it, which could potentially lead to a significant loss of revenue as the hype cycle dies down.</p><p>To summarize:</p><ul><li>OpenAI's only real options are to reduce costs or the price of its offerings. It has not succeeded in reducing costs so far, and reducing prices would only increase costs.</li><li>To progress to the next models of GPT, OpenAI's core product, the company would have to find new functionality.</li><li>OpenAI is inherently limited by GPT's transformer-based architecture, which does not actually automate things, and as a result may only be able to do "more" and "faster," which does not significantly change the product, at least not in such a way that would make it as valuable as it needs to be.</li><li>OpenAI's only other option is to invent an entirely new kind of technology, and be able to productize and monetize said technology, something that the company has not yet been able to do.</li></ul><hr><p><strong>A Note On Energy: </strong>Most of the problems I've listed are existential threats to the future of OpenAI, ones that I can see no quick or easy way out of, but another stands in the way — energy.&nbsp;</p><p>For OpenAI to scale, it would require a massive capital expenditure on multiple levels, chief of them the American power grid (<a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf?ref=wheresyoured.at"><u>see page 15 of this Goldman Sachs report for a conversation with Microsoft's former VP of energy</u></a>), which will likely require extensive expansion the likes of which hasn't happened in decades at a time when America is far less apt at infrastructural development.&nbsp;</p><p>While the US steadily added new electricity generation capacity in the second half of the 1900s, <a href="https://www.statista.com/statistics/188521/total-us-electricity-net-generation/?ref=wheresyoured.at"><u>things started to plateau in the 2010s</u></a>. This is a combination of a bunch of things. Electricity consumption has remained flat or <a href="https://www.sciencedirect.com/science/article/abs/pii/S0301421521005188?ref=wheresyoured.at"><u>decreased slightly across both households and businesses</u></a>. While the US has added capacity, particularly when it comes to renewables and natural gas, that isn’t increasing the amount of electricity generation available, but rather <a href="https://headwaterseconomics.org/economic-development/evolution-electricity-generation/?ref=wheresyoured.at"><u>offsetting the decommissioning of coal-fired power plants</u></a>.&nbsp;</p><p>Scaling AI would require an investment in power generation that would be equivalent in ambition to the New Deal, or Eisenhower’s Interstate Highway System, and it would need to happen quickly. That’s something that doesn’t happen in the power-generation world. For context, in 2021 it took an average of 2.8 years for <a href="https://thundersaidenergy.com/downloads/renewables-how-much-time-to-connect-to-the-grid/?ref=wheresyoured.at#:~:text=The%20median%20time%20to%20receive,2021%2C%20which%20is%202.8%20years."><u>a new solar farm to be connected to the electrical grid</u></a>. Two years later, that <a href="https://www.nytimes.com/2023/02/23/climate/renewable-energy-us-electrical-grid.html?ref=wheresyoured.at"><u>time rose to four years</u></a>. Small modular reactors — a promising approach designed to reduce the cost and build times of nuclear power generations — are still far from mass-commercialization, and even if they weren’t, they’d still have to tend with the bureaucracy of the sector.&nbsp;&nbsp;</p><p>Even if changing this were possible — and it'd be good for society if it was — artificial intelligence (driven by generative AI) is already massively increasing global emissions, particularly from companies like Google,<a href="https://www.bbc.com/news/articles/c51yvz51k2xo?ref=wheresyoured.at"><u> which saw its emissions increase by 48% in the last five years thanks to AI</u></a>.</p><p>For OpenAI to continue scaling, it is reliant on a dramatic expansion of the power grid, at a time when (according to Brian Janous of Cloverleaf Infrastructure) the wait times are <a href="https://www.goldmansachs.com/intelligence/pages/gs-research/gen-ai-too-much-spend-too-little-benefit/report.pdf?ref=wheresyoured.at"><u>ranging from 40-70 months to spin up new power projects</u></a>. And OpenAI isn't the company doing the scaling — much like it’s dependent on Nvidia to continue to produce GPUs for generative AI's cloud compute, so too is it dependent on companies like Microsoft, Google, and Oracle working with power companies to expand the grid.</p><h2 id="a-grim-situation"><strong>A Grim Situation</strong></h2><p>Absolutely nothing about what I've written here is based on personal grievance, or a dislike of generative AI, or really anything other than a frank evaluation of a company that I believe may be teetering on the brink of collapse.</p><p>For OpenAI to continue operating, things have to change dramatically.</p><ul><li>In the event that OpenAI is making the highest-end of their reported revenue range — $4.5 billion — and it has that much in the bank as we speak, it will have to raise at least $2 billion, or as much as $10 billion, within the next 12 months.</li><li>In the event that it hasless than a billion in the bank, OpenAI will likely have to raise $5 billion, and do so in the next three to six months.</li><li>Otherwise, OpenAI will either have to <em>at least </em>halve their operating costs, <em>all while maintaining the current pace of revenue,</em> or find a way to literally double its revenue while keeping costs at the same rate. Even then, these numbers are extremely concerning — though I add there are always things that I don't know as OpenAI is a private company, and thus isn’t subject to the same disclosure rules as publicly-traded companies.</li></ul><p>Survival would require OpenAI to raise more money than anybody ever has. This is technically possible, but would require venture capitalists and investment banks to effectively provide a lifeline to the company in perpetuity, unless the company is capable of either heavily reducing costs or finding billions of dollars more in revenue. Even if it succeeds, if the cost of revenue increases along with sales, all growth would be for nought, and create further problems and dependencies on venture capital — or on companies like Microsoft.</p><p>It would require a way of expanding what OpenAI can sell to address the entirety of corporate America, which would require use cases that I do not believe generative AI is capable of meeting, like automating chunks of the economy rather than<a href="https://www.wsj.com/tech/ai/ai-replace-freelance-jobs-51807bc7?ref=wheresyoured.at"><u> bankrupting freelance designers and copy-editors</u></a>.&nbsp;</p><p>To be clear, I am not advocating for workers being replaced by AI. I am simply saying that for OpenAI to grow to the $10+ billion revenue a year it needs to survive, it would need to replace entire chunks of the labor force. And as a reminder, generative AI is not automation.</p><p>Even if these problems are surmountable, there is simply not enough training data, and even if there were, the cost of processing it will likely vastly outweigh whatever revenue OpenAI makes. Even if this were resolved — which would likely require $30 billion in, at best, cloud credits — doing so would not necessarily make transformer-based models capable of doing what it takes to sell $10 billion of software a year.</p><p>If I had to just choose a number, I hypothesize that OpenAI needs to raise $20 billion in the next two years to even stay in the game, and to get any further — something that isn't guaranteed — will cost them another $20 billion. For context, according to Crunchbase, the aggregate of all funding in 2023 was $299.2 billion, with $147 billion raised so far in 2024.&nbsp;</p><p>OpenAI would have to regularly make up 5-10% <em>of all startup funding, forever</em>, <em>or at least until it works out how to lose less or make more money.</em>&nbsp;</p><blockquote>The only other company that has done so is Uber — and as I’ve discussed above, their situation is very, very different. Comparing the two is ahistorical on the funding climate alone, with Uber existing at a time with lower interest rates. Along with $3.5 billion from Saudi Arabia’s Public Investment fund and over $8 billion from Softbank, the latter a secondary market sale, it also raised (equity and debt financing respectively) from Goldman Sachs and Morgan Stanley — two parties I do not believe are going to be willing to subsidize generative AI. <p>Even if I’m wrong — which I could be, stranger things have happened — the willingness and ease of getting people to hand over hundreds of millions or billions of dollars became markedly different between Uber’s last funding round (September 14 2020) and 2024. The majority of its funding was raised between 2016 and 2019, too, when interest rates were low and, thus, VC coffers were overflowing. </p><p>And, crucially, investors had an incredibly clear path to liquidity — an IPO. Uber was always a dog of a company, but they always knew it’d chug along as a growth-at-all-costs monster on the market. How would OpenAI IPO? Its most recent round was a secondary market raise, selling insider stock to new investors. </p><p>If we humor this idea as the ultimate goal of pumping this company full of money, what are its plans to go public? </p><a href="https://www.reuters.com/technology/openai-ceo-has-no-ipo-plan-due-strange-company-structure-2023-06-06/?ref=wheresyoured.at"><u>Altman said as recently as June 2023 that its company structure would prohibit an IPO</u></a>, but do you think that OpenAI wants to subject itself to the scrutiny of the public markets, especially given their approach to copyrighted material? <p>Microsoft has a built-in profit share, but what of Sequoia? How does it get paid, other than finding another investor who wants the stock?</p><p>Perhaps there’s something I’m missing, but if investors have no path to an IPO, this feels like a game of hot potato, except the loser is left with a big, useless stock.Unless, of course, that investor is Microsoft, who will end up being able to use any leftover tech, and will benefit if OpenAI becomes profitable.</p></blockquote><p>Furthermore, I hypothesize a race to the bottom in generative AI will significantly hamper OpenAI's ability to expand revenue, compounded by the fact that we're approaching the limits of transformer-based architecture.</p><p>And because OpenAI (and the competition) are so deep in the hole with transformer-based models, I believe they will continue to drive billions into them, burning money on training them using data that may or may not have been legally acquired, and any lawsuit that goes in favor of the plaintiff would have potentially apocalyptic consequences for these models, requiring them to be retrained from scratch with an entirely new dataset, costing further hundreds of millions or <em>billions</em>.</p><p>And, quite frankly, I am just not sure how OpenAI will make this all work.</p><p>While OpenAI could — and I believe will — raise another huge, industry-defining round, doing so will require pulling in Canadian pension funds, Saudi sovereign wealth funds, or massive investment funds that would require swaths of equity. Doing so multiple times is possible, but very, very unlikely, in the same way that continuing to increase revenue at hundreds of percent each year is <em>possible,</em> but very, very unlikely. It could come up with something new, or find a way to make generative AI much cheaper, but again, that is so very, very unlikely.</p><p>OpenAI could be the most important tech company of all time, in that it will have to devour the very Gods of Silicon Valley to continue its rapacious growth. In doing so, it will break records in funding and software revenue, and do so while warding off competition from startups — as well as its own investor Microsoft.</p><p>I don't know how OpenAI does it. Writing this piece took me hours, and in doing so, I genuinely tried to work out how OpenAI survives, and every single corner I turned ended with "it can do it if it does something that has never happened."</p><p>I have written this with a dispassionate tone because I need people to take me seriously when I say that to survive, generative AI must do so much more than it currently does, and much cheaper than it's currently doing so. To survive, OpenAI must break every startup record known to man, and to thrive, it must either reinvent transformer-based architecture to reduce its compute requirements, and then invent an entirely new kind of artificial intelligence to do the things that people want AI to do.</p><p>Perhaps I'm wrong. Perhaps there are things that I don't know — about OpenAI, about the things it’s working on in secret, about some sort of energy or chip breakthrough that will approach so suddenly that I will eat crow. Perhaps it has more money in the bank than I thought, or perhaps their costs are currently inflated in a way that I — and the entirety of the tech media — are unaware of.</p><p>But if there were, I believe we would know, or at least have some sort of sign.</p><p>I don't know what happens next, but I do know things have to change. I fear OpenAI will compete on price, sending its costs upward, or charge what it needs to to approach break-even, which I don't think it’s willing to do. I fear for Anthropic, which has less money, less revenue, and equally gruesome burn. I fear for those founders relying on the current pricing for GPT and other models.</p><p>Without OpenAI, the bottom drops out of the entire generative AI market, and will more than likely brutalize any public stock associated with the generative AI boom.</p><p>I recognize reading this you might dismiss me as a cynic, or a pessimist, or as someone rooting for the end, and I have taken great pains to explain my hypotheses here in detail without much opinion or editorializing. If you disagree with me, tell me how I’m wrong — explain to me what I’ve missed, show me the holes in my logic or my math.&nbsp;</p><p>I caution you not to dismiss me, even if what I’ve written deeply upsets you. What I am describing here is a deeply unsustainable company that many have pinned their hopes on, and even if I’m wrong, this kind of analysis is necessary when there is a company burning billions of dollars that will likely attempt to absorb billions more dollars of capital to survive.&nbsp;</p><p>This discussion is equal parts necessary and troubling, uncomfortable in its implications and possibilities, and unsettling in its potential outcomes.&nbsp;</p><p>I hope I'm wrong. I really do.&nbsp;</p>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Don't Let Your Domain Name Become a "Sitting Duck" (101 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/07/dont-let-your-domain-name-become-a-sitting-duck/</link>
            <guid>41125544</guid>
            <pubDate>Thu, 01 Aug 2024 02:00:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/07/dont-let-your-domain-name-become-a-sitting-duck/">https://krebsonsecurity.com/2024/07/dont-let-your-domain-name-become-a-sitting-duck/</a>, See on <a href="https://news.ycombinator.com/item?id=41125544">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>More than a million domain names — including many registered by Fortune 100 firms and brand protection companies — are vulnerable to takeover by cybercriminals thanks to authentication weaknesses at a number of large web hosting providers and domain registrars, new research finds.</p>
<div id="attachment_68225"><p><img aria-describedby="caption-attachment-68225" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2024/07/duckstarget.png" alt="" width="750" height="433"></p><p id="caption-attachment-68225">Image: Shutterstock.</p></div>
<p>Your Web browser knows how to find a site like example.com thanks to the global <a href="https://en.wikipedia.org/wiki/Domain_Name_System" target="_blank" rel="noopener">Domain Name System</a> (DNS), which serves as a kind of phone book for the Internet by translating human-friendly website names (example.com) into numeric Internet addresses.</p>
<p>When someone registers a domain name, the registrar will typically provide two sets of DNS records that the customer then needs to assign to their domain. Those records are crucial because they allow Web browsers to find the Internet address of the hosting provider that is serving that domain.</p>
<p>But potential problems can arise when a domain’s DNS records are “lame,” meaning the authoritative name server does not have enough information about the domain and can’t resolve queries to find it. A domain can become lame in a variety of ways, such as when it is not assigned an Internet address, or because the name servers in the domain’s authoritative record are misconfigured or missing.</p>
<p>The reason lame domains are problematic is that a number of Web hosting and DNS providers allow users to claim control over a domain <em>without accessing the true owner’s account at their DNS provider or registrar</em>.</p>
<p>If this threat sounds familiar, that’s because it is hardly new. Back in 2019, KrebsOnSecurity wrote about thieves employing this method to seize control over thousands of domains registered at GoDaddy, and using those <a href="https://krebsonsecurity.com/2019/01/bomb-threat-sextortion-spammers-abused-weakness-at-godaddy-com/" target="_blank" rel="noopener">to send bomb threats and sextortion emails</a> (GoDaddy says they fixed that weakness in their systems not long after that 2019 story).</p>
<p>In the 2019 campaign, the spammers created accounts on GoDaddy and were able to take over vulnerable domains simply by registering a free account at GoDaddy and being assigned the same DNS servers as the hijacked domain.</p>
<p>Three years before that, the same pervasive weakness was described in a blog post by security researcher <strong>Matthew Bryant</strong>, who showed how one could <a href="https://thehackerblog.com/the-orphaned-internet-taking-over-120k-domains-via-a-dns-vulnerability-in-aws-google-cloud-rackspace-and-digital-ocean/" target="_blank" rel="noopener">commandeer at least 120,000 domains</a> via DNS weaknesses at some of the world’s largest hosting providers.</p>
<p>Incredibly, new research jointly released today by security experts at <strong>Infoblox</strong> and <strong>Eclypsium</strong> finds this same authentication weakness is still present at a number of large hosting and DNS providers.</p>
<p>“It’s easy to exploit, very hard to detect, and it’s entirely preventable,” said <strong>Dave Mitchell</strong>, principal threat researcher at Infoblox. “Free services make it easier [to exploit] at scale. And the bulk of these are at a handful of DNS providers.”</p>
<h2>SITTING DUCKS</h2>
<p><a href="https://blogs.infoblox.com/threat-intelligence/who-knew-domain-hijacking-is-so-easy/" target="_blank" rel="noopener">Infoblox’s report</a> found there are multiple cybercriminal groups abusing these stolen domains as a globally dispersed “traffic distribution system,” which can be used to mask the true source or destination of web traffic and to funnel Web users to malicious or phishous websites.</p>
<p>Commandeering domains this way also can allow thieves to impersonate trusted brands and abuse their positive or at least neutral reputation when sending email from those domains, as we saw in 2019 with the GoDaddy attacks.</p>
<p>“Hijacked domains have been used directly in phishing attacks and scams, as well as large spam systems,” reads the Infoblox report, which refers to lame domains as “<strong>Sitting Ducks</strong>.” “There is evidence that some domains were used for Cobalt Strike and other malware command and control (C2). Other attacks have used hijacked domains in targeted phishing attacks by creating lookalike subdomains. A few actors have stockpiled hijacked domains for an unknown purpose.”</p>
<p>Eclypsium researchers <a href="https://eclypsium.com/blog/ducks-now-sitting-dns-internet-infrastructure-insecurity/" target="_blank" rel="noopener">estimate</a> there are currently about one million Sitting Duck domains, and that at least 30,000 of them have been hijacked for malicious use since 2019.</p>
<p>“As of the time of writing, numerous DNS providers enable this through weak or nonexistent verification of domain ownership for a given account,” Eclypsium wrote.</p>
<p>The security firms said they found a number of compromised Sitting Duck domains were originally registered by brand protection companies that specialize in defensive domain registrations (reserving look-alike domains for top brands before those names can be grabbed by scammers) and combating trademark infringement.</p>
<p>For example, Infoblox found cybercriminal groups using a Sitting Duck domain called <strong>clickermediacorp[.]com</strong>, which was a CBS Interactive Inc. domain initially registered in 2009 at GoDaddy. However, in 2010 the DNS was updated to DNSMadeEasy.com servers, and in 2012 the domain was transferred to <strong>MarkMonitor</strong>.</p>
<p>Another hijacked Sitting Duck domain — <strong>anti-phishing[.]org</strong> — was registered in 2003 by the <strong>Anti-Phishing Working Group</strong> (APWG), a cybersecurity not-for-profit organization that closely tracks phishing attacks.</p>
<p>In many cases, the researchers discovered Sitting Duck domains that appear to have been configured to auto-renew at the registrar, but the authoritative DNS or hosting services were not renewed.</p>
<p>The researchers say Sitting Duck domains all possess three attributes that makes them vulnerable to takeover:</p>
<p>1) the domain uses or delegates authoritative DNS services to a different provider than the domain registrar;<br>
2) the authoritative name server(s) for the domain does not have information about the Internet address the domain should point to;<br>
3) the authoritative DNS provider is “exploitable,” i.e. an attacker can claim the domain at the provider and set up DNS records without access to the valid domain owner’s account at the domain registrar.</p>
<div id="attachment_68226"><p><img aria-describedby="caption-attachment-68226" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/07/sittingduckattack.png" alt="" width="751" height="337" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/07/sittingduckattack.png 784w, https://krebsonsecurity.com/wp-content/uploads/2024/07/sittingduckattack-768x345.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/07/sittingduckattack-782x351.png 782w" sizes="(max-width: 751px) 100vw, 751px"></p><p id="caption-attachment-68226">Image: Infoblox.</p></div>
<p>How does one know whether a DNS provider is exploitable? There is a frequently updated list published on <strong>GitHub</strong> called “<a href="https://github.com/indianajson/can-i-take-over-dns?tab=readme-ov-file" target="_blank" rel="noopener">Can I take over DNS</a>,” which has been documenting exploitability by DNS provider over the past several years. The list includes examples for each of the named DNS providers.<span id="more-68214"></span></p>
<p>In the case of the aforementioned Sitting Duck domain clickermediacorp[.]com, the domain was originally registered by , but it appears to have been hijacked by scammers by claiming it at the web hosting firm <strong>DNSMadeEasy</strong>, which is owned by <strong>Digicert</strong>, one of the industry’s largest issuers of digital certificates (SSL/TLS certificates).</p>
<p>In an interview with KrebsOnSecurity, DNSMadeEasy founder and senior vice president <strong>Steve Job</strong> said the problem isn’t really his company’s to solve, noting that DNS providers who are also not domain registrars have no real way of validating whether a given customer legitimately owns the domain being claimed.</p>
<p>“We do shut down abusive accounts when we find them,” Job said. “But it’s my belief that the onus needs to be on the [domain registrants] themselves. If you’re going to buy something and point it somewhere you have no control over, we can’t prevent that.”</p>
<p>Infoblox, Eclypsium, and the DNS wiki listing at Github all say that web hosting giant <strong>Digital Ocean</strong> is among the vulnerable hosting firms. In response to questions, Digital Ocean said it was exploring options for mitigating such activity.</p>
<p>“The DigitalOcean DNS service is not authoritative, and we are not a domain registrar,” Digital Ocean wrote in an emailed response. “Where a domain owner has delegated authority to our DNS infrastructure with their registrar, and they have allowed their ownership of that DNS record in our infrastructure to lapse, that becomes a ‘lame delegation’ under this hijack model. We believe the root cause, ultimately, is poor management of domain name configuration by the owner, akin to leaving your keys in your unlocked car, but we acknowledge the opportunity to adjust our non-authoritative DNS service guardrails in an effort to help minimize the impact of a lapse in hygiene at the authoritative DNS level. We’re connected with the research teams to explore additional mitigation options.”</p>
<p>In a statement provided to KrebsOnSecurity, the hosting provider and registrar <strong>Hostinger</strong> said they were working to implement a solution to prevent lame duck attacks in the “upcoming weeks.”</p>
<p>“We are working on implementing an SOA-based domain verification system,” Hostinger wrote. “Custom nameservers with a Start of Authority (SOA) record will be used to verify whether the domain truly belongs to the customer. We aim to launch this user-friendly solution by the end of August. The final step is to deprecate preview domains, a functionality sometimes used by customers with malicious intents. Preview domains will be deprecated by the end of September. Legitimate users will be able to use randomly generated temporary subdomains instead.”</p>
<p>What did DNS providers that have struggled with this issue in the past do to address these authentication challenges? The security firms said that to claim a domain name, the best practice providers gave the account holder random name servers that required a change at the registrar before the domains could go live. They also found the best practice providers used various mechanisms to ensure that the newly assigned name server hosts did not match previous name server assignments.</p>
<p>[Side note: Infoblox observed that many of the hijacked domains were being hosted at <strong>Stark Industries Solutions</strong>, a sprawling hosting provider that appeared two weeks before Russia invaded Ukraine and has become <a href="https://krebsonsecurity.com/2024/05/stark-industries-solutions-an-iron-hammer-in-the-cloud/" target="_blank" rel="noopener">the epicenter of countless cyberattacks against enemies of Russia</a>].</p>
<p>Both Infoblox and Eclypsium said that without more cooperation and less finger-pointing by all stakeholders in the global DNS, attacks on sitting duck domains will continue to rise, with domain registrants and regular Internet users caught in the middle.</p>
<p>“Government organizations, regulators, and standards bodies should consider long-term solutions to vulnerabilities in the DNS management attack surface,” the Infoblox report concludes.</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Just Disconnect the Internet (242 pts)]]></title>
            <link>https://computer.rip/2024-07-31-just-disconnect-the-internet.html</link>
            <guid>41125490</guid>
            <pubDate>Thu, 01 Aug 2024 01:52:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://computer.rip/2024-07-31-just-disconnect-the-internet.html">https://computer.rip/2024-07-31-just-disconnect-the-internet.html</a>, See on <a href="https://news.ycombinator.com/item?id=41125490">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>


<p>So, let's say that a security vendor, we'll call them ClownStrike, accidentally
takes down most of their Windows install base with a poorly tested content
update. Rough day at the office, huh? There are lots of things you could say
about this, lots of reasons it happens this way, lots of people to blame and
not to blame, etc., etc., but nearly every time a major security incident like
this hits the news, you see a lot of people repeating an old refrain:</p>
<blockquote>
<p>these systems shouldn't be connected to the internet.</p>
</blockquote>
<p>Every time, I get a little twitch.</p>
<p>The idea that computer systems just "shouldn't be connected to the internet,"
for security or reliability purposes, is a really common one. It's got a lot of
appeal to it! But there's not really that many environments where it's done. In
this unusually applied and present-era article, I want to talk a little about
the real considerations around "just not connecting it to the internet," and
why I wish people wouldn't bring it up if they aren't ready for some serious
considerations.</p>
<h2>We Live in a Society</h2>
<p>In the abstract, computers can perform valuable work by doing, well,
computation. In practice, the computation is rarely that important. In
industry, there is a lot more "information technology" than there is
"computation." Information technology inherently needs to ingest and produce
information, and while that was once facilitated by a department of Operators
loading tapes, we have found the whole Operator thing to be costly and slow
compared to real-time communications.</p>
<p>In other words, the modern business computer is almost primarily a
communications device.</p>
<p>There are not that many practical line-of-business computer systems that
produce value without interconnection with other line-of-business computer
systems. These interconnections often cross organizational and geographical
boundaries.</p>
<p>I am thinking, for example, of the case of airline reservation and scheduling
systems disabled by the CrowdStrike, er, sorry, whatever I called them
incident. These are fundamentally communications systems, and have their
origins as replacements for the telephone and telegraph. It is not possible
to simply not internetwork them, because networking is inherent to their
function.</p>
<h2>Networking is important to maintenance and operations</h2>
<p>But let's consider systems that don't actually require real-time communications
to perform their business purpose. Network connectivity still tends to be really
valuable for these.</p>
<p>For one, consider maintenance: how does a system obtain software updates if you
have no internet connection? How is that system monitored?</p>
<p>And even if you think you can avoid those requirements by declaring a system
"complete" and without the need for any updates or real-time monitoring or
intervention, business requirements have the frustrating habit of changing over
time, and network connectivity reduces the cost of handling those changes
tremendously.</p>
<h2>What does it mean for a system to not be connected to the internet?</h2>
<p>First, we need to consider the fact that there are as many forms of "not
connected to the internet" as there are ways of being connected to the
internet. For this reason alone, proposing that a system shouldn't be
internet-connected is usually too nonspecific to really discuss. Let's consider
a menu of possibilities:</p>
<p>List 1:</p>
<ol>
<li>A single device with no network connection at all.</li>
<li>A system of devices that is "air-gapped" in the strictest sense, with no
connection to any network other than its private local-area one, where data
never crosses the security boundary.</li>
<li>That same system, but someone carries DVD-Rs across the security boundary to
introduce new data to the private network.</li>
<li>That same system, but a cross-domain solution or "data diode" allows
movement of data from a wider (or lower-security) network into the private (or
higher-security) network.</li>
<li>That same system, where the cross-domain solution does <em>not</em> have a costly
and difficult to obtain NSA certification.</li>
</ol>
<p>List 2:</p>
<ol>
<li>A system of devices which interconnect over a private wide-area network
using fully independent physical infrastructure with physical precautions
against tampering.</li>
<li>That same system, but the independent physical infrastructure is run through
commodity shared ducts.</li>
<li>That same system, but the infrastructure is leased dark fiber.</li>
<li>That same system, but the infrastructure is wavelengths on lit fiber.</li>
<li>That same system, but the infrastructure is "virtual private ethernet"
implemented by the provider using, let's say, MPLS.</li>
<li>That same system, but the infrastructure is "virtual private ethernet"
implemented by the provider using a tunneling solution with encryption and
authentication.</li>
</ol>
<p>List 3:</p>
<ol>
<li>A system of devices which interconnect over a common-carrier network (such
as, we might even dare say, the internet), where private network traffic is
tunneled through encryption and authentication performed by hardware devices.</li>
<li>That same system, but the hardware devices do not have a costly and difficult
to obtain NSA certification.</li>
<li>That same system, but the tunneling is performed by a software solution
that is well-designed such that it configures the operating system network
stack, at a low level, to prevent any traffic bypassing the tunnel, and this
has been validated by someone much smarter than me.</li>
<li>That same system, but not so well designed and validated by someone like me.</li>
<li>That same system, but the "software solution" is like Wireguard and an
iptables script that has been "thoroughly tested" by someone on Reddit.</li>
</ol>
<p>List 4:</p>
<ol>
<li>A system of devices which interconnect on a private network that has
interconnection to the internet that is strictly limited by policy-based
routing or other reliable methods, such that only very narrowly defined
traffic flows are possible.</li>
<li>That same system, but the permissible network flows are documented in
some old Jira tickets and some of them were, you know, just thrown in to
make it work.</li>
<li>That same system, but it's basically protected by a firewall that's
pretty liberal about outbound flows (maybe with IPS or something), and
pretty restrictive about inbound flows.</li>
</ol>
<p>List 5:</p>
<ol>
<li>An AWS private VPC without any routing elsewhere.</li>
<li>An AWS private VPC with PrivateLinks and other AWS networking baubles
that allow it communicate with other private VPCs.</li>
<li>That same system, but some of the interconnected VPCs can route traffic
to/from the internet.</li>
<li>An AWS private VPC with NAT GW and IGW but the security groups are set up
pretty tight in both directions.</li>
</ol>
<p>These are all things that I have seen described as non-internet-connected.
Take a moment to work through each list and mark the point at which you think
that is no longer a reasonable claim. It's okay, I'll wait.</p>
<p>I'm not going to provide threat modeling for all of these scenarios because it
would go on for pages, but you can probably see that pretty much every option
is at least slightly different in terms of attack surface and risk.</p>
<p>This might seem like an annoying or pedantic argument, but this is actually the
biggest reason I get irritated when people say that something should never be
connected to the internet. What do they <em>mean</em> by that?  When someone says that
an airline reservation system shouldn't be internet-connected, they clearly
don't actually mean the strictest form of that contention (no network
connection at all) unless their name is Adama and they liked when airline
reservation centers had big turntables of paper cards they spun around to check
off your seat. They must mean one of the midpoints presented above, which are
pretty much all coherent positions, but all positions with different
practical considerations.</p>
<p>This ambiguity makes it hard to actually, seriously consider the merits of
dropping internet connectivity.</p>
<h2>Non-internet connected systems are so very, very annoying</h2>
<p>In my day job, I work with a wide variety of clients with a wide variety of
cultures, IT architectures, and so on. Some of them are in highly regulated
industries or defense or whatever, and so they actually conduct software
operations in networks with either no internet connectivity or tightly
restricted internet connectivity.</p>
<p>When I discover this to be the case, I mentally multiply all of the
schedule/cost estimates by a factor of, I would say, 3 to 10, depending on
where they fall on the above lists (usually 3x to 5x for list 5 and 10x to a
bajillion times forever for list 1, just rule of thumb).</p>
<p>Here's the thing: virtually the entire software landscape has been designed
with the assumption of internet connectivity. Your operating system wants to
obtain its updates from online servers. If you are paying for expensive
licenses for your operating system, the vendor probably offers additional
expensive licenses for infrastructure to perform updates within your private
network. If you are getting your operating system for free-as-in-beer, there's
a good bet you can figure it out yourself, but if you're using anything to new
and cutting-edge it might be a massive hassle.</p>
<p>But that just, you know, scratches the surface. You probably develop and deploy
software using a half dozen different package managers with varying degrees of
accommodation for operating against private, internal repositories. Some of them
make this easy, some of them don't, but the worst part is that you will have to
figure it out about fifty times because of the combinatorial complexity of
multiple package managers, multiple ways of invoking them, and multiple
environments in which they are invoked.</p>
<p>If you are operating a private network, your internal services probably don't
have TLS certificates signed by a popular CA that is in root programs. You will
spend many valuable hours of your life trying to remember the default password
for the JRE's special private trust store and discovering all of the other
things that have special private trust stores, even though your operating
system provides a perfectly reasonable trust store that is relatively easy to
manage, because of Reasons. You will discover that in some tech stacks this is
consistent but in others it depends on what libraries you use.</p>
<p>A bunch of the software you use will want to perform cloud licensing and get
irritated when it cannot phone home for entitlements. You will have to go back
and forth with your vendors to figure out a workaround somewhere between "add
these ninety seven /16s to your firewall exceptions" and "wait six months while
we figure out the internal process to issue you a bespoke licensing scheme."</p>
<p>All of your stuff that requires updates or content updates will have some
different process you have to follow to obtain those updates and then provide
them internally. Here's a not at all made up example, but a real one I have
personally lived through: you will find that a particular (and particularly
hated) enterprise software vendor provides content updates for offline use only
through a customer support portal that is held over from three acquisitions
ago, and that it is only possible to get an account in that customer support
portal by getting an entitlement manually added in a different customer support
portal held over from two acquisitions ago. It will take over three months of
support tickets and escalations through your named account executive to get
accounts opened in successively older customer support portals until you can
finally get into the right one, which incidentally has an invalid TLS cert you
are reassured is not something to worry about. Once you download your offline
content update, you will find that the documented process to apply it no longer
works, and it will take a long email chain with one of the engineers to get the
right instructions. You paid a five-figure sum for a 1-year license to this
software and it has now nearly elapsed while you figured out how to use it. You
will of course get an extension on that license pro bono, because this is
enterprise software sales and what is a quarter worth of my salary between
friends, but they won't manage to issue the extension license until after
your original one has already expired, causing a painful interruption in CI
pipelines and a violent revolution by the developers.</p>
<p>I am sorry, you are not my therapist, I will try to stop remembering that dark
time in my career. Don't worry, the software in question seems to have fallen
out of favor and cannot hurt you.</p>
<p>So, like, that's an over-the-top example (but seriously, a real one!), but you
get the point. It's not really that any individual part of operating in an
offline environment is hard---I mean some of them are, but most of them aren't.
It's a death by a thousand cuts. Every single thing you ever do is harder when
you do not have internet connectivity, and you will pay for it in money and
time.</p>
<p>The largest problem by far is that almost everyone who develops software
assumes that their product will not need to operate in an offline environment,
and if they find out that it does they will fix that with duct tape and shell
scripts because it only matters for a small portion of their customers. You,
the person with the offline environment, will become the proud owner of their
technical debt.</p>
<p>None of this really <em>needs</em> to be that way, it's just how it is! There are not
really that many offline environments, and they tend to be found in big
institutions that have adapted to the fact that they make everything cost more
and take longer, and are surprisingly tolerant of vendors who perform a three
stooges routine every time you say "air-gap," because that's what pretty much
every vendor does. Except for like Red Hat, I genuinely think Red Hat is pretty
good about this, but you betcha what you save in time you are paying in cash.</p>
<h2>Not many people do this</h2>
<p>That's kind of the point, right? The problem with non-internet-connected
environments is that they are rare. The stronger versions, things from List 1
and List 2, are mostly only seen in defense and intelligence, although I have
also seen some banks with pretty impressive practices. You will note that
defense and intelligence, and even banks, are also famously industries where
everything costs way too much and takes way too long. These correlations are
probably not coincidences.</p>
<p>Even the weaker forms tend to be limited to highly-regulated industries
(finance and healthcare are the big ones), although you see the occasional
random software company that just takes security really seriously and keeps
things locked down. Occasionally.</p>
<h2>Okay, let's stop just complaining</h2>
<p>Here's the thing: I genuinely do not think that "fewer systems should be
connected to the internet" is a bad idea. I really wish that things were
different, and that every part of the software industry was more prepared and
more comfortable operating in environments with no or limited internet
connectivity. But that is not the world that we currently live in! So let's
get optimistic, what should we be doing right now?</p>
<ol>
<li>
<p>Apply restrictive network policy on as much of your stuff as possible.
Cloud providers generally make this easier than it has ever been before, it's
not all that easy but it's also not all that hard to operate a practical
non-internet-routed environment in AWS. If you stay within the lanes of all
the AWS managed services, it's mostly pain-free. You will pay for this, but,
you know, AWS always gets their check anyway.</p>
</li>
<li>
<p>Build software with offline environments in mind. Any time that you need
to phone home to get something, provide a way to disable it (if practical)
or a way to override the endpoint that will be used. If the latter, keep in
mind that you will also need to come up with a way for a customer to feasibly
host their own endpoint. If you keep to simple static files, that's really
easy, just nginx and a directory or whatever. If it's an API or something,
well, you're probably going to have to ship your internal implementation.
Brace yourself for the maintenance overhead.</p>
</li>
<li>
<p>Try to think about the little assumptions that go into connecting to other
services that become more complex in an offline environment. Please, for the
love of God, do not assume you can reach LetsEncrypt. But that's not the only
TLS problem, offline environments virtually always imply internal certificate
authorities. <em>Use the system trust store.</em> Please. I am begging you.</p>
</li>
<li>
<p>Avoid fetching any kind of requirements or dependencies at deploy time. One
of the advantages Docker supposedly brought us was making all of the
requirements of a given package self-contained, but then I still run into
Docker containers that can't start if they can't reach the npm repos or
something. And now I have yet another place to fix configuration and trust
store and etc., in your stupid Docker container. It has made things more
difficult instead of less.</p>
</li>
</ol>
<p>Have I mentioned that Docker, paradoxically, actually makes offline
environments <em>more</em> difficult to manage? Yeah, because virtually every
third-party Docker container has <em>at least</em> a TLS trust store you'll have to
modify. Docker is, itself, a profound example of how the modern software
industry simply assumes that everything is running On The Internet.</p>
<h2>Anyway</h2>
<p>I wrote this out in a bit of a huff because I have seen "why were they
connected to the internet at all?" like four times in response to the
CrowdStrike incident. I know, I am committing the cardinal sin of taking things
that people on the internet say seriously, but I feel obligated to point out:
internet connectivity is pretty much completely orthogonal to what happened.
CrowdStrike content updates are the kind of thing that, in a perfect world,
you would promptly make available in your offline environment. In practice, an
internal CrowdStrike update mirror would probably lag days, weeks, months, or
years behind, because that's what usually ends up happening in "hard" offline
environments, but that's a case of two wrongs making a right.</p>
<p>Which they do, more often than you would think, in the world of information
technology.</p>
<p>Don't worry, I'll be back next time with something more carefully written and
less relevant to the world we live in. I just got in a mood, you know? I just
spent like half the day copying Docker images into an offline environment and
then fixing them all. I have to find something to occupy the time while a
certain endpoint security agent pegs the CPU and makes every "docker save" take
ten minutes.</p>
	</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SnowflakeOS: Beginner friendly and GUI focused NixOS variant (174 pts)]]></title>
            <link>https://snowflakeos.org/</link>
            <guid>41124472</guid>
            <pubDate>Wed, 31 Jul 2024 23:06:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://snowflakeos.org/">https://snowflakeos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41124472">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <div>
                        <h2>Simple, Immutable, Reproducible</h2>
                        <p>SnowflakeOS is a <a href="https://nixos.org/">NixOS</a> based Linux distribution focused on
                            beginner friendliness and ease of use.</p>
                    </div>
                <div>
                    <figure>
                        <img alt="SnowflakeOS desktop" src="https://snowflakeos.org/assets/snowflakeos.png">
                    </figure>
                    
                    <p>Not yet ready for daily use!</p>
                </div>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Suspicious data pattern in recent Venezuelan election (789 pts)]]></title>
            <link>https://statmodeling.stat.columbia.edu/2024/07/31/suspicious-data-pattern-in-recent-venezuelan-election/</link>
            <guid>41123155</guid>
            <pubDate>Wed, 31 Jul 2024 20:34:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://statmodeling.stat.columbia.edu/2024/07/31/suspicious-data-pattern-in-recent-venezuelan-election/">https://statmodeling.stat.columbia.edu/2024/07/31/suspicious-data-pattern-in-recent-venezuelan-election/</a>, See on <a href="https://news.ycombinator.com/item?id=41123155">Hacker News</a></p>
Couldn't get https://statmodeling.stat.columbia.edu/2024/07/31/suspicious-data-pattern-in-recent-venezuelan-election/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[An affordable, portable and focused device for music, writing and coding (107 pts)]]></title>
            <link>https://tulip.computer/</link>
            <guid>41122986</guid>
            <pubDate>Wed, 31 Jul 2024 20:15:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tulip.computer/">https://tulip.computer/</a>, See on <a href="https://news.ycombinator.com/item?id=41122986">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <div data-aos="fade-right" id="top">
          <h2><span>The <br>Tulip<br>Creative<br> Computer</span></h2>
          <p><span>An affordable, portable and focused device for music, writing and coding.</span></p>
          <p><a href="#get">Get a Tulip for only US$59</a>
        </p></div>



<div id="more">
    <div>
        <p data-aos="fade-down"><h2>Tulip is an all in one portable computer running the Python programming language, with a touchscreen and music synthesizer.</h2></p>
    </div>
    <p><img src="https://tulip.computer/img/tulip_hero.jpg">
    </p>

    <div>

      <div data-aos="fade-up" data-aos-delay="200">
        <p><span>Simple, focused and fun</span></p><p>Tulip's processor is a low-power real time microcontroller. It boots right into a Python prompt. We provide a code editor and we ship music programs and other examples. It only does what you ask it to. It has no web browser or social media, other than our fun Tulip-only BBS <strong>Tulip WORLD</strong> for sharing files. Its constraints and single focus should help you make amazing creative work.</p>
      </div>

      <div data-aos="fade-up" data-aos-delay="200">
        <p><span>Make your art in code</span></p><p>Tulip ships with the <a href="https://github.com/shorepine/amy">AMY synthesizer</a>, a fully featured additive, subtractive and FM synth (think DX-7 and Juno-6) and you can control every parameter of every oscillator in code. Our graphics API is fully programmable as well, with hardware sprites and scrolling backgrounds. Write your own games or synth UIs in <a href="https://lvgl.io/">LVGL</a> on the Tulip touchscreen and control your creations over MIDI, I2C, or even Wi-Fi.</p>
      </div>

      <div data-aos="fade-up" data-aos-delay="200">
        <p><span>Completely open source and cheap as possible</span></p><p>You're paying the cost of the parts and manufacturing for your US$59 Tulip, with a tiny fee added on to support future development. Tulip is <a href="https://github.com/shorepine/tulipcc">completely open source</a>, from the hardware to the OS to the synthesizer DSP code. It's made possible by excited volunteers and <a href="#involved">we'd love your help!</a> Tulip is just as fun to work on as to make things on.</p>
      </div>
    </div>
  </div>



<div id="more">
    <div>
        <p data-aos="fade-down"><h2>Tulip is packed with features, connectivity and APIs for you to make or build anything you can imagine.</h2></p>
    </div>
    <p><img src="https://tulip.computer/img/tulipcc-voices.jpeg">
    </p>

    <div data-aos="fade-up" data-aos-delay="200">
        <p><span>Synthesizer</span></p><p>Tulip's underlying synthesizer, <a href="https://github.com/shorepine/amy">AMY</a>, supports up to 120 oscillators, stereo sound, filters, reverb, chorus, FM, PCM samples (baked in or loaded from a file), and comes with a Python library for managing voices and patches for polyphony and multitimbral operation. <a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">You can write all your patches, music or interactions with other synths in pure Python.</a></p>
        <p><a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">Make music in code on Tulip</a></p>


      </div>
  </div>

<div>
      <p>
    <h2>Write your music in Python. <a href="https://github.com/shorepine/tulipcc/blob/main/docs/music.md">See more</a></h2>
  </p>
    <div>
      <pre><code> 
# Play a random note of an F minor 7 chord. 
# Beat syncs with other running music programs
import tulip, midi, music, random

chord = music.Chord("F:min7").midinotes()
synth = midi.Synth(1) # single note polyphony
synth.program_change(143) # DX7 BASS 2 patch

def note(t):
    synth.note_on(random.choice(chord), 0.6, time=t)

# Call note() every 24 ticks (twice a quarter note)
slot = tulip.seq_add_callback(note, 24)
      </code></pre>
    </div>
  </div>

<div data-aos="fade" data-aos-delay="200">
  <p>
    <h2>How does it sound? Check it out:</h2>
  </p>
  <p>


        <iframe width="700" height="540" src="https://www.youtube.com/embed/1lYFjQp7Xrw?si=FaSXGabzvbs0BGeF" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

  </p>
</div>



<div id="more">
    <div>
        <p data-aos="fade-down"><h2>Make multichannel sound installations with an optional Alles speaker, or 30</h2></p>
    </div>
    <p><img src="https://tulip.computer/img/nicoboard-alles.jpg">
    </p>

    <div data-aos="fade-up" data-aos-delay="200">
        <p><span>Alles</span></p><p>With an optional <a href="https://github.com/shorepine/alles">Alles speaker</a> (or up to a few dozen!) you can perform multichannel audio in Tulip. The underlying synthesizer can address multiple Alles speakers over a Wi-Fi mesh. Each speaker has the same synthesizer capabilities as in Tulip. You can address them individually or in groups, and send all the same commands you can send on the built-in synth in Tulip. Make stunning whole-room installations of dozens of channels all powered from one Tulip.</p>
        <p><a href="https://notes.variogram.com/2022/09/23/alles-amy/">Read more about Alles</a></p>


      </div>
  </div>



<div id="get">
        <p>
          <h2>Buy a Tulip, DAC or Alles. Ships anywhere in the world.</h2>
        </p>
    <div>

        <div>
          <p><a href="https://www.makerfabs.com/the-tulip-creative-computer.html"><img src="https://tulip.computer/img/tulip-shop-3.jpg" alt="Tulip Creative Computer"></a></p>
        </div>


         <div>
          <p><a href="https://www.makerfabs.com/mabee-dac-gp8413.html"><img src="https://tulip.computer/img/mabee-dac.jpg" alt="Mabee DAC"></a></p><div>
            <h5>Two-channel DAC</h5>
            <p>Plugs right into a Tulip to give you two channels of CV control over modular synths with standard 3.5mm patch cables. With some light modification, you can have up to 4 running at once for 8 channels.</p>
            <p><a href="https://www.makerfabs.com/mabee-dac-gp8413.html">US$5.80 on Makerfabs</a>
          </p></div>
        </div>

         <div>
          <p><a href="https://shop.blinkinlabs.com/products/alles-pcb"><img src="https://tulip.computer/img/alles.jpg" alt="Alles"></a></p>
      </div>

  </div>
</div>




<div id="involved">
  <div>
    <p>
      <h3>Get involved</h3>
    </p>

    
    <div>

      <div data-aos="fade-up">
          <p><a href="https://discord.com/invite/TzBFkUb8pG"><img src="https://tulip.computer/img/discord-mark-black.svg" width="42" height="42"></a>
          </p>
          <div>
            <a href="https://discord.com/invite/TzBFkUb8pG"><h3>Discord</h3></a>
            <p>Join the <strong>shore pine sound systems</strong> Discord to chat about Tulip, AMY and Alles. A fun small community of people experimenting with Tulip.</p>
          </div>
        </div>

      <div data-aos="fade-up" data-aos-delay="200">
          <p><a href="https://github.com/shorepine/tulipcc"><img src="https://tulip.computer/img/github-mark.svg" width="42" height="42/"></a>
          </p>
          <div>
             <a href="https://github.com/shorepine/tulipcc"><h3>Github</h3></a>
            <p>Check out the Tulip Github page for issues, discussions and the code.</p>
          </div>
        </div>


    </div>
  </div>

<div data-aos="fade" data-aos-delay="200">
      <h3>Join our email list</h3>
      <p>We'll send you <strong>very rare</strong> updates about Tulip, Alles, AMY and other projects we're working on.</p>
    </div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Foobar2000 (236 pts)]]></title>
            <link>https://www.foobar2000.org/</link>
            <guid>41122920</guid>
            <pubDate>Wed, 31 Jul 2024 20:05:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.foobar2000.org/">https://www.foobar2000.org/</a>, See on <a href="https://news.ycombinator.com/item?id=41122920">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  <p><a href="https://www.foobar2000.org/screenshots" title="View more screenshots"><img id="pagepic" alt="View more screenshots" src="https://www.foobar2000.org/tinyfoobar.png"></a>


  foobar2000 is an advanced freeware audio player for the Windows platform.
 </p><h2>Latest news</h2>
  <div>
	<h3>2024-05-21</h3>
<p>
    New releases of old versions!
</p>
<p>
    Some of latest bug fixes have been backported to foobar2000 v1.5 and v1.6 series. <br>
    Versions 1.6.18 and 1.5.12 can be downloaded from <a href="https://www.foobar2000.org/old">old versions page</a>. <br>
    Additionally, version 1.5.12 was properly tested on old hardware; unintended SSE CPU requirement present in previous releases has been removed.
</p><h3>2024-05-20</h3>
<p>
    foobar2000 mobile v1.5 has been released. <br>
    This version introduces <a href="https://www.foobar2000.org/mobile/skinformat">new skin file format</a> which can be edited using commonly available tools. <br>
    <a href="https://www.foobar2000.org/apk">Download Android APK...</a>
</p><h3>2023-12-18</h3>
<p>
    foobar2000 v2.1 final has been released. <br>
    <a href="https://www.foobar2000.org/download">Download...</a>
</p>
<p>
    foobar2000 for Mac v2.6 final has also been released. <br>
    <a href="https://www.foobar2000.org/mac">Download foobar2000 for Mac...</a>
</p><h3> <a href="https://www.foobar2000.org/?page=News">View all news</a> </h3>
</div>
      <table>
            <caption>
          advertisement
        </caption>
      <tbody><tr> 
          <td>

          <div onclick="document.location.href='https://www.dbpoweramp.com/dmc.htm?fb=1';">
            <p><span>dBpoweramp mp3 Converter</span>
            <br>
              <span> music conversion perfected<br>&nbsp;</span>
              <br>
                <img alt="dmc" src="https://www.dbpoweramp.com/images/dmc/dmc.png" width="160" height="122"></p><p>&nbsp;
                      <span>Trusted by 30 million people, easy conversion between audio formats</span></p></div>

        </td>

            <td>

              <div onclick="document.location.href='https://www.dbpoweramp.com/perfecttunes.htm?fb=1';">
            <p><span>PerfectTUNES</span>
            <br>
              <span>
                a helping hand for your audio collection<br>&nbsp;</span>
              <br>
                <img alt="" height="122" src="https://www.dbpoweramp.com/images/pt-art-main.png" width="106"></p><p>
                    &nbsp;
                      <span>Add or upgrade Album Art, De-Dup and check for ripping errors</span></p></div>

        </td>

            <td>

              <div onclick="document.location.href='https://www.dbpoweramp.com/cd-ripper.htm?fb=1';">
            <p><span>dBpoweramp CD Ripper</span>
            <br>
              <span>
                CD ripping taken seriously<br>&nbsp;</span>
              <br>
                <img alt="cdripper" height="122" src="https://www.dbpoweramp.com/images/cd-ripper-secure.png" width="80"></p><p>
                    &nbsp;
                      <span>Secure Ripping from the inventors of AccurateRip, fast &amp; bit-perfect CD ripping</span></p></div>

        </td>

      </tr>
  </tbody></table>
  
    <h2>Main features</h2>
  <ul>
    <li>Supported audio formats: MP3, MP4, AAC, CD Audio, WMA, Vorbis, Opus, FLAC, WavPack, WAV, AIFF, Musepack, Speex, AU, SND... and more with additional <a href="https://www.foobar2000.org/?page=Download#components">components</a>.</li>
    <li><a href="https://wiki.hydrogenaudio.org/index.php?title=Gapless" rel="nofollow">Gapless</a> playback.</li>
    <li>Easily <a href="https://wiki.hydrogenaudio.org/index.php?title=Foobar2000:Layout_Editing_Mode" rel="nofollow">customizable user interface layout</a>.</li>
    <li>Advanced <a href="https://wiki.hydrogenaudio.org/index.php?title=Foobar2000redirect:C16D48EE-39BE-4C91-9A35-441BEFA286D2" rel="nofollow">tagging capabilities</a>.</li>
    <li>Support for ripping Audio CDs as well as transcoding all supported audio formats using the <a href="https://www.foobar2000.org/FAQ#converting_audio_files_to_different_file_formats">Converter component</a>.</li>
    <li>Full <a href="https://wiki.hydrogenaudio.org/index.php?title=Replaygain" rel="nofollow">ReplayGain</a> support.</li>
    <li>Customizable keyboard shortcuts.</li>
    <li>Open component architecture allowing third-party developers to extend functionality of the player.</li>
  </ul>
 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cardie – An open source business card designer and sharing platform (135 pts)]]></title>
            <link>https://github.com/nfoert/cardie</link>
            <guid>41122793</guid>
            <pubDate>Wed, 31 Jul 2024 19:50:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/nfoert/cardie">https://github.com/nfoert/cardie</a>, See on <a href="https://news.ycombinator.com/item?id=41122793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nfoert/cardie/blob/main/repo/images/logo_light.png#gh-dark-mode-only"><img src="https://github.com/nfoert/cardie/raw/main/repo/images/logo_light.png#gh-dark-mode-only" alt="Cardie Logo"></a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/nfoert/cardie/blob/main/repo/images/logo_dark.png#gh-light-mode-only"><img src="https://github.com/nfoert/cardie/raw/main/repo/images/logo_dark.png#gh-light-mode-only" alt="Cardie Logo"></a></p>


<p dir="auto">Design a unlimited number of business or information cards about yourself, share a link or QR code to them, print it out, and save other people's cards to your virtual wallet for later. Once you've created a card you can get analytics data on how your cards are getting visited, you can edit your cards as things change, and you can keep cards private so only people with a link to your card can see it.</p>
<p><a href="https://skillicons.dev/" rel="nofollow">
    <img src="https://camo.githubusercontent.com/bd08d39a13b6f75dda24a81596f3aaad051fd93dd2dea9aa285300ab1300633c/68747470733a2f2f736b696c6c69636f6e732e6465762f69636f6e733f693d646a616e676f2c707974686f6e2c68746d6c2c6373732c6a732c6769746875622c6769742c616c70696e656a73" data-canonical-src="https://skillicons.dev/icons?i=django,python,html,css,js,github,git,alpinejs">
  </a>
</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/nfoert/cardie/blob/main/repo/images/screenshot1.png"><img src="https://github.com/nfoert/cardie/raw/main/repo/images/screenshot1.png"></a>
</p>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">Cardie is currently in an open alpha. Things will be rapidly changing and bugs are to be expected.</p>
</div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">First, clone this repository using the following command</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/nfoert/cardie"><pre><code>git clone https://github.com/nfoert/cardie
</code></pre></div>
<p dir="auto">Then, navigate to that directory and create a new python virtual environment</p>
<div data-snippet-clipboard-copy-content="cd cardie
python3 -m venv .venv"><pre><code>cd cardie
python3 -m venv .venv
</code></pre></div>
<p dir="auto">Activate the virtual environment using the command for your system (Linux is used here) and install the required dependencies</p>
<div data-snippet-clipboard-copy-content="source ./.venv/bin/activate
pip install -r requirements.txt"><pre><code>source ./.venv/bin/activate
pip install -r requirements.txt
</code></pre></div>
<p dir="auto">Next, create a django superuser and make and migrate the models</p>
<div data-snippet-clipboard-copy-content="cd cardie
python manage.py createsuperuser
python manage.py makemigrations
python manage.py migrate"><pre><code>cd cardie
python manage.py createsuperuser
python manage.py makemigrations
python manage.py migrate
</code></pre></div>
<p dir="auto">Now just run the server using the following command, or run the <code>Start server</code> task in your Visual Studio Code</p>
<div data-snippet-clipboard-copy-content="python manage.py runserver"><pre><code>python manage.py runserver
</code></pre></div>
<p dir="auto">Finally, navigate to <code>http://127.0.0.1:8000/admin</code> and log in using your new administrator account. Create a new <code>Server</code> object and be sure to configure the <code>ip</code> to be <code>http://127.0.0.1:8000</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Additional steps for Production installation</h3><a id="user-content-additional-steps-for-production-installation" aria-label="Permalink: Additional steps for Production installation" href="#additional-steps-for-production-installation"></a></p>
<p dir="auto">This depends on what server hosting provider you're using. However, there's a couple environment variables you need to set and there's a run command.</p>
<p dir="auto">Set the following global environment variables:</p>
<ul dir="auto">
<li>
<p dir="auto"><code>DJANGO_ALLOWED_HOSTS</code> -&gt; <code>${APP_DOMAIN}</code> (This works on DigitalOcean, this may not work on every hosting provider)</p>
</li>
<li>
<p dir="auto"><code>DJANGO_SETTINGS_MODULE</code> -&gt; <code>cardie.settings_production</code></p>
</li>
<li>
<p dir="auto"><code>DJANGO_LOG_LEVEL</code> -&gt; <code>WARNING</code></p>
</li>
<li>
<p dir="auto"><code>STATIC_URL</code> -&gt; <code>/static/main</code></p>
</li>
<li>
<p dir="auto"><code>SECRET_KEY</code> -&gt; <code>&lt;your new secret key&gt;</code> (Generate this using <code>django.core.management.utils.get_random_secret_key()</code>. If possible you should encrypt this value in your hosting provider.)</p>
</li>
<li>
<p dir="auto"><code>DEBUG</code> -&gt; <code>False</code></p>
</li>
<li>
<p dir="auto"><code>DATABASE_URL</code> -&gt; <code>${db.DATABASE_URL}</code> (This works on DigitalOcean, this may not work on every hosting provider)</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">To Do</h2><a id="user-content-to-do" aria-label="Permalink: To Do" href="#to-do"></a></p>
<p dir="auto">There's lots of things that need implemented or changed in this project. Please see <a href="https://github.com/nfoert/cardie/blob/main/TODO.md">TODO.md</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">I'd love to see contributions to this project! Please check out the <a href="https://github.com/nfoert/cardie/issues">issues</a> page to see what things currently need fixed or added.</p>
<p dir="auto">Additionally, check <a href="https://github.com/nfoert/cardie/blob/main/TODO.md">TODO.md</a> for a rough todo list of things that need implemented, and the <a href="https://github.com/nfoert/cardie/wiki">wiki</a> for some information on how to work with some of the existing systems.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[After years of leniency, ULA cracks down on hobbyist photographers (123 pts)]]></title>
            <link>https://arstechnica.com/space/2024/07/ula-to-amateur-launch-photographers-work-for-me-but-not-for-thee/</link>
            <guid>41121689</guid>
            <pubDate>Wed, 31 Jul 2024 18:13:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/space/2024/07/ula-to-amateur-launch-photographers-work-for-me-but-not-for-thee/">https://arstechnica.com/space/2024/07/ula-to-amateur-launch-photographers-work-for-me-but-not-for-thee/</a>, See on <a href="https://news.ycombinator.com/item?id=41121689">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/07/53891838413_2c9f565c76_k-1-800x533.jpg" alt="This image of an Atlas V launch on Tuesday morning has been intentionally blurred.">
      <figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/07/53891838413_2c9f565c76_k-1.jpg" data-height="1365" data-width="2048">Enlarge</a> <span>/</span> This image of an Atlas V launch on Tuesday morning has been intentionally blurred.</p><p>United Launch Alliance</p></figcaption>  </figure>

  




<!-- cache hit 82:single/related:08b9e0df1f67cb48c06d7d6cec8d2f86 --><!-- empty -->
<p>The emails from United Launch Alliance started popping into the inboxes of photographers a few days after the Fourth of July holiday. Although that day is meant to celebrate freedom and the red glare of rockets, the communication threatened to strip both from some of the company's most ardent devotees.</p>
<p>The message from the launch company announced the implementation of a new "annual agreement" between ULA and all people who place remote cameras at Space Launch Complex-41, the company's active launch site at Cape Canaveral Space Force Station. Anyone interested in setting remotes for future launch dates had 11 days to review and sign the agreement.</p>
<p>The language was clear: Photographers were welcome to set up remote shots at ULA launches if they worked for the media or wanted to post their work on social media. However, photographers could not sell this work independently, including as prints for fellow enthusiasts or for use in annual calendars.</p>
<p>"ULA will periodically confirm editorial publication for media participating in remote camera placement," the email stated. "If publication does not occur, or photos are sold outside of editorial purposes, privileges to place remote cameras may be revoked."</p>
<p>To the photographers who spend many hours preparing their equipment, waiting to set up and remove cameras, and persevering through scrubs and more, it seemed like a harsh judgment.</p>
<p>And nobody knew why it happened.</p>
<h2>No comment</h2>
<p>United Launch Alliance has offered no public comment about the new policy. The company did not respond to questions from Ars Technica about the agreement. And the company's chief executive, Tory Bruno, a frequent tweeter who regularly interacts with fans on the social media site X, has ignored dozens of questions about the policy change. Since the first questions were raised a few days ago, Bruno has not replied to anyone on X.</p>                                                                        
                                                                                
<p>The photographers themselves felt blindsided by the decision.</p>
<p>"I cannot sit by while myself and my colleagues are actively being forbidden from trying to support ourselves to be able to do what we do," said David Diebold, a photographer for Space Scout, <a href="https://x.com/DavidJDPhotos/status/1817268386939666519">on X</a>. "Being forced to sign an agreement that is a net negative for all of the media is the last thing I'll do. If this is the end of the line for covering ULA missions up close, then so be it."</p>
<p>Other photographers shared similar sentiments privately, but they did not want to be seen publicly calling out ULA, the second-most important launch provider in the United States.</p>
<p>The new rules went into effect on Tuesday with <a href="https://arstechnica.com/space/2024/07/with-a-landmark-launch-the-pentagon-is-finally-free-of-russian-rocket-engines/">the final launch of an Atlas V rocket for a national security mission</a>. A ULA representative told participating photographers that the intent of the new rules was to prohibit the sale of images to any commercial entities, including prints to individuals, except for news publications.</p>
<p>There was no explanation given for why.</p>
<h2>How did we get here?</h2>
<p>For a long time, the rules for accessing the press site at Kennedy Space Center in Florida and setting up remote cameras for launches there and at the military launch pads were clear. You had to be working press or have a letter from a publication that you were on assignment. But a decade and a half ago, several things occurred that began to change this.</p>
<p>As the Space Shuttle program wound down, NASA sought to induce positive publicity by inviting social media participants to launches and other events. The events were initially called "<a href="https://en.wikipedia.org/wiki/NASA_Social">Tweetups</a>" at their inception in 2009, and later "NASA Socials." The space agency provided access to non-media spaceflight enthusiasts, who then shared their experiences on Twitter and other social media outlets. The space agency further blurred the lines between traditional reporters and social media enthusiasts by inviting these participants to some news conferences.</p>

                                                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Stop Destroying Videogames – European Citizens' Initiative (113 pts)]]></title>
            <link>https://citizens-initiative.europa.eu/initiatives/details/2024/000007_en</link>
            <guid>41121570</guid>
            <pubDate>Wed, 31 Jul 2024 18:02:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://citizens-initiative.europa.eu/initiatives/details/2024/000007_en">https://citizens-initiative.europa.eu/initiatives/details/2024/000007_en</a>, See on <a href="https://news.ycombinator.com/item?id=41121570">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                  <p>European Citizens' Initiative</p>
                      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Has Run Hundreds of Ads for Cocaine, Opioids and Other Drugs (164 pts)]]></title>
            <link>https://www.wsj.com/tech/meta-cocaine-opioids-ads-dea8e0fc</link>
            <guid>41121237</guid>
            <pubDate>Wed, 31 Jul 2024 17:30:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/tech/meta-cocaine-opioids-ads-dea8e0fc">https://www.wsj.com/tech/meta-cocaine-opioids-ads-dea8e0fc</a>, See on <a href="https://news.ycombinator.com/item?id=41121237">Hacker News</a></p>
Couldn't get https://www.wsj.com/tech/meta-cocaine-opioids-ads-dea8e0fc: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[I prefer rST to Markdown (275 pts)]]></title>
            <link>https://buttondown.email/hillelwayne/archive/why-i-prefer-rst-to-markdown/</link>
            <guid>41120254</guid>
            <pubDate>Wed, 31 Jul 2024 15:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.email/hillelwayne/archive/why-i-prefer-rst-to-markdown/">https://buttondown.email/hillelwayne/archive/why-i-prefer-rst-to-markdown/</a>, See on <a href="https://news.ycombinator.com/item?id=41120254">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                    <date>
                        
                            July 31, 2024
                        </date>
                
                
                
                    <h2>
                        I will never stop dying on this hill
                    </h2>
                

                

                
                    
                        <p>I just published a new version of <a href="https://leanpub.com/logic/" target="_blank">Logic for Programmers</a>! v0.2 has epub support, content on constraint solving and formal specification, and more! Get it <a href="https://leanpub.com/logic/" target="_blank">here</a>.</p>
<p>This is my second book written with <a href="https://www.sphinx-doc.org/en/master/" target="_blank">Sphinx</a>, after the new <a href="https://www.learntla.com/" target="_blank">Learn TLA+</a>. Sphinx uses a peculiar markup called <a href="https://docutils.sourceforge.io/rst.html" target="_blank">reStructured Text</a> (rST), which has a steeper learning curve than markdown. I only switched to it <em>after</em> writing a couple of books in markdown and deciding I needed something better. So I want to talk about why rst was that something.<sup id="fnref:rst"><a href="#fn:rst">1</a></sup></p>
<h2>Why rst is better</h2>
<p>The most important difference between rst and markdown is that markdown is a lightweight representation of html, while rst is a midweight representation of an abstract documentation tree.</p>
<p>It's easiest to see this with a comparison. Here's how to make an image in markdown:</p>

<p>Technically, you don't even need a parser for this. You just need a regex to transform it into  <code>&lt;img alt="alttext" src="example.jpg"/&gt;</code>. Most modern markdown engines <em>do</em> parse this into an intermediate representation, but the <em>essence</em> of markdown is that it's a lightweight html notation.</p>
<p>Now here's how to make an image in rst:</p>
<div><pre><span></span><code><span>..</span> <span>image</span><span>::</span> example.jpg
  <span>:alt:</span> alttext
</code></pre></div>
<p><code>.. image::</code> defines the image "directive". When Sphinx reads it, it looks up the registered handler for the directive, finds <code>ImageDirective</code>, invokes <code>ImageDirective.run</code>, which returns an <code>image_node</code>, which is an object with an <code>alt</code> field containing "alttext". Once Sphinx's processed all nodes, it passes the whole doctree to the HTML Writer, which looks up the rendering function for <code>image_node</code>, which tells it to output an <code>&lt;image&gt;</code> tag.</p>
<p>Whew that's a mouthful. And for all that implementation complexity, we get…  an interface that has 3x the boilerplate as markdown.</p>
<p>On the other hand, the markdown image is hardcoded as a special case in the parser, while the rst image is not. It was added in the exact same way as every other directive in rst: register a handler for the directive, have the handler output a specific kind of node, and then register a renderer for that node for each builder you want.</p>
<p>This means you can extend Sphinx with new text objects! Say you that instead of an <code>&lt;image&gt;</code>, you want a <code>&lt;figure&gt;</code> with a <code>&lt;figcaption&gt;</code>. In basic markdown you have to manually insert the html, with Sphinx you can just register a new <code>figure</code> directive. You can even make your <code>FigureDirective</code> subclass <code>ImageDirective</code> and have it do most of the heavy lifting.</p>
<p>The second benefit is more subtle: you can transform the doctree before rendering it. This is how Sphinx handles cross-referencing: if I put a <code>foo</code> anchor in one document and <code>:ref:`image &lt;foo&gt;`</code> in another, Sphinx will insert the right URL during postprocessing. The transformation code is also first-class with the rest of the build process: I can configure a transform to only apply when I'm outputting html, have it trigger in a certain stage of building, or even remove a builtin transform I don't want to run.</p>
<p>Now, most people may not need this kind of power! Markdown is ubiquitous because it's lightweight and portable, and rst is anything but. But <em>I</em> need that power.</p>

<h3>One use case</h3>
<p><em>Logic for Programmers</em> is a math-adjacent book, and all good math books need exercises for the reader. It's easier to write an exercise if I can put it and the solution right next to each other in the document. But for readers, I want the solutions to show up in the back of the book. I also want to link the two together, and since I might want to eventually print the book, the pdfs should also include page references. Plus they need to be rendered in different ways for latex (pdf) output and epub output. Overall lots of moving parts.</p>
<p>To handle this I wrote my own exercise extension.</p>
<div><pre><span></span><code><span>.. in chapter.rst</span>
<span>..</span> <span>exercise</span><span>::</span> Fizzbuzz
  <span>:name:</span> ex-fizzbuzz

  An exercise

<span>..</span> <span>solution</span><span>::</span> ex-fizzbuzz

  A solution

<span>.. in answers.rst</span>

<span>..</span> <span>solutionlist</span><span>::</span>
</code></pre></div>
<p>How these nodes are processed depends on my compilation target. I like to debug in HTML, so for HTML it just renders the exercise and solution inline.</p>
<p>When generating epub and latex, though, things works a little differently. After generating the whole doctree, I run a transform that moves every solution node from its original location to under <code>solutionlist</code>. Then it attaches a reference node to every exercise, linking it to the <em>new</em> solution location, and vice versa. So it starts like this (using Sphinx's "pseudoxml" format): </p>
<div><pre><span></span><code>--<span> </span>chapter.rst
<span>&lt;exercise_node</span><span> </span><span>ids=</span><span>"ex-fizzbuzz"</span><span>&gt;</span>
<span>  </span><span>&lt;title&gt;</span>
<span>    </span>Fizzbuzz
<span>  </span><span>&lt;paragraph&gt;</span>
<span>    </span>An<span> </span>exercise
<span>&lt;solution_node</span><span> </span><span>ids=</span><span>"ex-fizzbuzz-sol"</span><span>&gt;</span>
<span>  </span><span>&lt;paragraph&gt;</span>
<span>    </span>A<span> </span>solution

--<span> </span>answers.rst
<span>&lt;solutionlist_node&gt;</span>
</code></pre></div>
<p>And it becomes this:</p>
<div><pre><span></span><code>--<span> </span>chapter.rst
<span>&lt;exercise_node</span><span> </span><span>ids=</span><span>"ex-fizzbuzz"</span><span>&gt;</span>
<span>  </span><span>&lt;title&gt;</span>
<span>    </span>Fizzbuzz
<span>  </span><span>&lt;paragraph&gt;</span>
<span>    </span>An<span> </span>exercise
<span>    </span><span>&lt;exsol_ref_node</span><span> </span><span>refuri=</span><span>"/path/to/answers#ex-fizzbuzz-sol"</span><span>&gt;</span>
<span>      </span>Solution

--<span> </span>answers.rst
<span>&lt;solutionlist_node&gt;</span>
<span>  </span><span>&lt;solution_node</span><span> </span><span>ids=</span><span>"ex-fizzbuzz-sol"</span><span>&gt;</span>
<span>    </span><span>&lt;paragraph&gt;</span>
<span>      </span>A<span> </span>solution
<span>      </span><span>&lt;exsol_ref_node</span><span> </span><span>refuri=</span><span>"/path/to/chapter#ex-fizzbuzz"</span><span>&gt;</span>
<span>        </span>(back)
</code></pre></div>

<p>The Latex builder renders this by wrapping each exercise and solution in an <a href="https://ctan.org/pkg/exercise" target="_blank">answers environment</a>, while the epub builder renders the solution as a <a href="https://help.apple.com/itc/booksassetguide/en.lproj/itccf8ecf5c8.html" target="_blank">popup footnote</a>.<sup id="fnref:exsol_ref"><a href="#fn:exsol_ref">2</a></sup> Making this work:</p>
<p><img alt="An example of solution popups on an epub reader" src="https://assets.buttondown.email/images/8a7d66e3-56bd-4b7a-95ac-d4fdf88047c7.png?w=960&amp;fit=max"> </p>
<p>It's a complex dance of operations, but it works enormously well. It even helps with creating a "free sample" subset of the book: the back of the free sample only includes the solutions from the included subset, not the whole book!</p>
<h3>"But I hate the syntax"</h3>
<p>When I gush about rST to other programmers, this is the objection I hear the most: it's ugly. </p>
<p>To which I say, are you really going to avoid using a good tool just because it makes you puke? Because looking at it makes your stomach churn? Because it offends every fiber of your being?</p>
<p>...Okay yeah that's actually a pretty good reason not to use it. I can't get into lisps for the same reason. I'm not going to begrudge anybody who avoids a tool because it's ugly.</p>
<p>Maybe you'd find <a href="https://github.com/asciidoctor/asciidoctor" target="_blank">asciidoc</a> more aesthetically pleasing? Or <a href="https://mystmd.org/spec" target="_blank">MyST</a>? Or <a href="https://github.com/typst/typst" target="_blank">Typst</a>? Or <a href="https://docs.racket-lang.org/pollen/" target="_blank">Pollen</a>? Or even <a href="https://pandoc.org/MANUAL.html#extension-attributes" target="_blank">pandoc-extended markdown</a>? There are lots of solid document builders out there! My point isn't that sphinx/rst is exceptionally <em>good</em> for largescale documentation, it's that simple markdown is exceptionally <em>bad</em>. It doesn't have a uniform extension syntax or native support for pre-render transforms.</p>
<p>This is why a lot of markdown-based documentation generators kind of hack on their own preprocessing step to support new use-cases, which works for the most part (unless you're trying to do something really crazy). But they have to work around the markdown, not in it, which limits how powerful they can be. It also means that most programmer tooling can't understand it well. There's LSP and treesitter for markdown and rst but not for gitbook-markdown or md-markdown or leanpub-markdown.<sup id="fnref:treesitter"><a href="#fn:treesitter">3</a></sup></p>
<p>But if you find a builder that uses markdown and satisfies your needs, more power to you! I just want to expose people to the idea that doc builders can be a lot more powerful than they might otherwise expect.</p>
<hr>
<h3>No newsletter next week</h3>
<p>I'll be in Hong Kong.</p>
<h2>Update 2024-07-31</h2>
<p>Okay since this is blowing up online I'm going to throw in a quick explanation of <em>Logic for Programmers</em> for all of the non-regulars here. I'm working on a book about how formal logic is useful in day-to-day software engineering. It starts with a basic rundown of the math and then goes into eight different applications, such as property testing, database constraints, and decision tables. It's still in the alpha stages but already 20k words and has a lot of useful content. You can find it <a href="https://leanpub.com/logic" target="_blank">here</a>. Reader feedback highly appreciated!</p>

                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.email/hillelwayne" target="_blank">here</a>. Updates are once a week. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
                

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jeff Bezos' management rules are slowly unraveling inside Amazon (200 pts)]]></title>
            <link>https://fortune.com/2024/07/31/amazon-leadership-principles-questions-future-jeff-bezos-departure-andy-jassy/</link>
            <guid>41120201</guid>
            <pubDate>Wed, 31 Jul 2024 15:44:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://fortune.com/2024/07/31/amazon-leadership-principles-questions-future-jeff-bezos-departure-andy-jassy/">https://fortune.com/2024/07/31/amazon-leadership-principles-questions-future-jeff-bezos-departure-andy-jassy/</a>, See on <a href="https://news.ycombinator.com/item?id=41120201">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p>But Hayter, a program manager, was bothered on a deeper level: Because the policy effectively meant that only people living near an Amazon office would be able to continue working at the company, she believed Amazon was violating one of its sacred tenets to “hire and develop the best.”&nbsp;</p>



<p>What’s more, by announcing the mandate with little warning or buy-in, Hayter believed, Amazon CEO Andy Jassy had betrayed his duty to “earn trust,” another important part of the Amazon code.</p>



<p>At Amazon these tenets, known as Leadership Principles, are much more than suggestions. They are a way of life that employees are judged on before they are even hired, steeped in from the moment they join, and scrupulously followed thereafter with the devotion of religious converts.&nbsp;</p>



<p>Hayter’s next move was a case in point: With the help of some of the 30,000 other employees who joined an internal <a href="https://fortune.com/2023/06/04/amazon-unfazed-remote-workers-protest-return-to-office-mandate/" target="_self" aria-label="Go to https://fortune.com/2023/06/04/amazon-unfazed-remote-workers-protest-return-to-office-mandate/">Slack channel she’d created</a>, she drafted a memo to lay out their concerns about the return-to-work mandate. The memo was exactly six pages long.</p>



<p>Like the Leadership Principles, six-page memos (“6-pagers,” in Amazon lingo) are part of a unique work culture forged within the giant internet company over the years and considered as much of a contributor to Amazon’s world-beating success as any blockbuster product or individual, including <a href="https://fortune.com/preview/2024/07/30/jeff-bezos-leadership-rules-are-revered-and-imitated-by-ceos-everywhere-can-they-survive-the-andy-jassy-era-at-amazon/" target="_self" aria-label="Go to https://fortune.com/preview/2024/07/30/jeff-bezos-leadership-rules-are-revered-and-imitated-by-ceos-everywhere-can-they-survive-the-andy-jassy-era-at-amazon/">Amazon founder Jeff Bezos himself</a>.&nbsp;</p>



<p>In reality, these principles and the processes they produce are among Amazon’s grandest innovations.</p>



<p>The customs and practices are widely imitated: More than a dozen books promise to teach managers the secrets to the principles and processes; consultants do brisk business helping firms import Amazon’s methods into their organizations; CEOs load their emails with Amazonian axioms.</p>



<p>And yet, as the Hayter episode shows, the Amazon Way is a fragile concept even within Amazon itself. Jassy defended the return-to-work decision as <a href="https://www.businessinsider.com/amazon-andy-jassy-no-data-return-to-office-rto-aws-2023-8" target="_blank" aria-label="Go to https://www.businessinsider.com/amazon-andy-jassy-no-data-return-to-office-rto-aws-2023-8" rel="noopener">a judgment call</a>; after all, another company leadership principle notes that “leaders are right a lot. They have strong judgment and good instincts.” But the clash between employees and the CEO over who was being more faithful to the code reveals a growing tension that some fear could erode the pillars of the $2 trillion company.&nbsp;</p>


<div><p><img alt="" loading="lazy" width="1024" height="683" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1169387139-e1722363657869.jpg?w=1440&amp;q=75"></p><figcaption>Employees walk past a mural relief reading “Earn Trust” at the Amazon.com Inc. office campus in Hyderabad, India.</figcaption><p>Dhiraj Singh—Bloomberg via Getty Images</p></div>



<p>More than three years after Bezos passed the CEO baton to Jassy, as Amazon recently <a href="https://fortune.com/2024/07/05/jeff-bezos-andy-jassy-amazon-30-year-anniversary/" target="_self" aria-label="Go to https://fortune.com/2024/07/05/jeff-bezos-andy-jassy-amazon-30-year-anniversary/">celebrated its 30th birthday</a>, the durability and staying power of Amazon’s foundational work culture are being watched closely by many inside and outside the organization.&nbsp;</p>



<p>Fortune spoke to two dozen current and recently departed Amazon executives and managers about how the famous Amazon Way is holding up in the post-Bezos era. Many of those interviewed paint a picture of a company where the key principles and practices remain core but have become less universally agreed upon. Increasingly, some insiders say, the leadership principles have become weaponized, diluted, or applied inconsistently.&nbsp;</p>



<p>PowerPoint presentations, once strictly verboten, now pop up occasionally. Longtime leaders who embodied the principles in their every move have moved on.</p>



<p>Perhaps in response to some of these new realities, Amazon recently disseminated to employees <a href="https://www.youtube.com/watch?v=My-2-MyxamQ" target="_blank" aria-label="Go to https://www.youtube.com/watch?v=My-2-MyxamQ" rel="noopener">an hourlong video course hosted by Jassy</a> himself explaining the company’s 16 leadership principles.&nbsp;</p>



<p>“The leadership principles are not something that you just memorize or that you just study for a couple of hours, or you try once or twice and you’ve got them,” Jassy says in the intro. “It’s something that you have to practice a lot.”</p>



<p>Margaret Callahan, an Amazon spokesperson, said that the company regularly updates internal resources and training, including on topics pertaining to the company’s culture. She said that Amazon’s culture—defined by the leadership principles, a “writing culture,” and working backward from customers’ needs—remains strong: “It’s what has driven innovations such as Prime, AWS, the Kindle, Alexa, the Climate Pledge, and Project Kuiper, just to name a few.”</p>



<p>The success of these products, and Amazon’s<a href="https://fortune.com/2024/05/09/amazon-andy-jassy-earnings-accelerated-growth-aws-ads/" target="_self" aria-label="Go to https://fortune.com/2024/05/09/amazon-andy-jassy-earnings-accelerated-growth-aws-ads/"> continued financial growth</a>, indicate that the company is far from facing any immediate crisis. On Thursday, Amazon will report its second-quarter financial results, with Wall Street analysts expecting double-digit revenue and profit growth.&nbsp;</p>



<p>As Amazon seeks to extend its dominance into the next 30 years, however, the leadership principles and special work culture will almost certainly collide with the questions that have challenged so many corporate paragons of the past: Is having a sacred playbook an asset that companies should preserve at all costs, or does it become a liability holding companies back as the world around them changes? And, perhaps more important, is there a point at which a company’s size, growth, and industry-spanning tentacles make a unified culture of decision-making and inventing impossible?</p>



<h2>True believers in the Amazon Way </h2>



<p>Customer obsession.</p>



<p>Bias for action.</p>



<p>Disagree and commit.&nbsp;</p>



<p>There are <a href="https://www.amazon.jobs/content/en/our-workplace/leadership-principles" target="_blank" aria-label="Go to https://www.amazon.jobs/content/en/our-workplace/leadership-principles" rel="noopener">16 Leadership Principles at Amazon</a>. Any Amazon employee can recite most of them by heart (those who can’t won’t last very long).</p>



<p>There are also the various homegrown Amazon practices: the two-pizza rule, which holds that cross-functional, or “single-threaded,” teams focused on a specific goal or project should be lean enough that two pies could suffice as a team meal. There’s also a rabid attention on so-called “input” metrics of a certain business—think selection or price—rather than output metrics such as revenue.&nbsp;</p>



<p>And then there’s the intense focus on written narratives, including the 6-pager, a planning document that describes in storylike fashion a goal for a business line and how to go about accomplishing it, or a new project or plan (one variant of the 6-pager is the so-called PRFAQ, written in the style of a press release announcing the hypothetical future product, and the focal point of Amazon’s “Working Backward” product-development approach). Before a key meeting, every single attendee sits silently and reads the memo to themself. Only then is a discussion permitted to begin in earnest.&nbsp;</p>



<p>It sounds almost cultlike, Amazon insiders acknowledge. But as former Amazon Prime Video boss Bill Carr notes, the payoff is that historically Amazon employees up and down the corporate ladder understand things at a “granular level.”</p>


<div><p><img alt="" loading="lazy" width="1024" height="683" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1445867611-e1722363942847.jpg?w=1440&amp;q=75"></p><figcaption>Andy Jassy took the baton from Amazon founder Bezos in 2021 to become the new CEO.</figcaption><p>Thos Robinson/Getty Images for The New York Times</p></div>



<p>“The executives at Amazon are just so much more well-informed about what is going on in their company, in terms of metrics, in terms of the initiatives that teams are doing, in terms of what’s working, what’s not working,” said Carr, who left in 2015 but is the coauthor of the book <em>Working Backwards</em> and cofounder of a consulting firm by the same name, which both aim to guide business leaders on how to apply Amazon’s principles and practices to their own businesses.&nbsp;</p>



<p>Executives at Amazon brim with personal examples of the power of the leadership mottos. Ideally, multiple principles can mesh together on a project to help unleash a single breakthrough product or service.&nbsp;</p>



<p>Beryl Tomay, a 19-year Amazon veteran and vice president of its transportation division, points to one recent success story that involved “regionalizing” the company’s network of U.S. warehouses so that each facility serves a distinct geographic area. The multiyear project has lowered costs, led to more environmentally friendly trucking routes, and allowed customers to get their goods faster, the company has said.&nbsp;</p>



<p>From brainstorming the initial idea to executing, the project called for a collection of Leadership Principles— from “customer obsession” to “thinking big.” Tomay reels off more of them with the zeal of a true believer: “There’s a ‘simplify’ part [and] there’s also the ‘invent’ part. ‘Dive deep’ too. Going super deep into what our topology looks like, and what our inbound inventory placement looks like.”</p>



<p>If mission statements and corporate values are viewed as empty slogans within many companies, at Amazon the Leadership Principles and special practices are embraced with genuine sincerity.&nbsp;</p>



<p>“It’s critically important for an organization to have something like this if they are actually meaningful,” said Stephan Meier, chair of the management division at Columbia Business School and author of the forthcoming book <em>The Employee Advantage</em>.&nbsp;</p>



<p>But, Meier adds, “if it’s not lived, if it’s not on top of people’s minds, if it doesn’t have any implications of how you would make decisions or treat each other, they are completely meaningless.”</p>



<p>It’s precisely this warning that made some Amazon insiders uneasy with what happened a few years ago.</p>



<h2>An erosion of trust</h2>



<p>On July 1, 2021, Amazon did something it hadn’t done in many years: It added two new leadership principles to its list. “Strive to be Earth’s best employer” was one new principle. “Success and scale bring broad responsibility” was the other.&nbsp;</p>



<p>When these were introduced, Amazon was facing intense media coverage over the swell of unionization efforts in its warehouse network, as well as antitrust and environmental scrutiny. And with <a href="https://fortune.com/2021/02/02/jeff-bezos-stepping-down-amazon-ceo-executive-chair-letter-to-employees-andy-jassy-replacement/" target="_self" aria-label="Go to https://fortune.com/2021/02/02/jeff-bezos-stepping-down-amazon-ceo-executive-chair-letter-to-employees-andy-jassy-replacement/">Bezos scheduled to hand over the CEO reins</a> a few days later, the introduction of the two new principles served as a convenient opportunity to demonstrate a company committed to progress under his successor.</p>



<p>Inside the company, though, the reaction among many employees was swift and brutal: “They are clearly a marketing ploy and they devalue the rest of the Leadership Principles,” one former senior manager of more than 10 years who left the company recently told <em>Fortune</em>. “Total bullshit,” opined a former longtime communications employee at Amazon who was still at the company at the time, and who summed up the new principles as “playing the reputational game versus guiding how you think.”</p>



<p>The problem, explained a former Amazon vice president, is that the pair of new leadership principles are so radically different from the other 14 that it makes it tougher for employees to grasp the essence of the overall principles and to act on them. “I’ve got to think that that’s somewhat challenging for the rank and file. The fact that there are so many LPs, and the fact that these last two are so abstract,” the former VP said.</p>


<div><p><img alt="" loading="lazy" width="1024" height="683" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1358788181-e1722366559811.jpg?w=1440&amp;q=75"></p><figcaption>A recent effort to “regionalize” Amazon’s warehouses leveraged multiple Leadership Principles and led to more environmentally friendly trucking routes, according the VP of transportation.</figcaption><p>Dan Kitwood—Getty Images</p></div>



<p>The expansion of the number of principles has coincided with what some Amazon insiders describe as an erosion of trust in the principles, or at least in the way their colleagues understand and apply the principles, which are meant to influence everything from new-product ideation to employee evaluations.</p>



<p>Several longtime managers told <em>Fortune</em> that they felt the overall intent of the leadership principles has now shifted in many situations from guidelines on how to make the right decision, to more punitive usages that come across mainly intended to point out flaws. Such weaponization of leadership rules to criticize or squash dissent has always been a reality to a certain extent. “Earns trust” has been especially problematic in this regard, <a href="https://www.vox.com/recode/2021/2/26/22297554/amazon-race-black-diversity-inclusion" target="_blank" aria-label="Go to https://www.vox.com/recode/2021/2/26/22297554/amazon-race-black-diversity-inclusion" rel="noopener">according to some women of color</a>, and a <a href="https://medium.com/@ezcoach1/weaponizing-amazon-leadership-principles-5e1c8d13a71" target="_blank" aria-label="Go to https://medium.com/@ezcoach1/weaponizing-amazon-leadership-principles-5e1c8d13a71" rel="noopener">former Amazon VP has written about leadership principles being weaponized</a> by leaders when “they lack the power to give orders” and thus resort to “a crude attempt to apply the LP not as intended, but as a way to ensure an outcome.”</p>



<p>Even knowing that, many who spoke to <em>Fortune</em> believe the issue has worsened in recent years as Amazon has hired many executives from outside the company. (Most of those who spoke to <em>Fortune</em> requested anonymity, either because they are not permitted to talk to the press without permission as current Amazon employees, or because they feared retaliation for speaking candidly even as former employees.) One current Amazon senior manager said they’ve consistently observed bosses new to the company use the principles “as weapons to put those who aren’t favorites in their place,” while employing other principles to build up their favorites.&nbsp;</p>



<p>“Sometimes I’ll hear, ‘It’s amazing you had this ‘bias for action’…and other times when I believe I’ve had ‘bias for action,’&nbsp;they will say you weren’t data-driven (from the leadership principle ‘Dive deep’) enough.”</p>



<p>Another employee, a longtime AWS manager, said his superiors over the last few years frequently wielded “Disagree and commit”—a maxim intended to prevent groupthink during project planning while ensuring unity once a plan has been agreed upon—as a cudgel to quash any level of pushback.</p>



<p>“The joke by the time I left [last year] was if you didn’t like something, you could disagree and commit or disagree and quit,” the employee said.</p>



<p>Callahan, the Amazon spokesperson, said that the two new principles are as important as&nbsp;the others, and that they all play a role in evaluating new hires as well as the performance of current employees.</p>



<p>But there are other signs of change within the organization too. Several current managers who spoke to <em>Fortune</em> said that PowerPoint presentations have supplanted written narratives in some cases over the last two years—not in a dominant way, but in a noticeable one nonetheless. In the Prime Video division, for example, new executives who have come to the company after long careers outside of Amazon have been known to chafe at the heavy focus on narratives.</p>



<p>“There’s a lot of resistance from outsiders at the executive level,” one current manager said.</p>



<p>Another senior manager who worked at Amazon for 15 years said his first 13 years at the company were marked by an overwhelming amount of writing, but that in the last two years that has shifted to PowerPoint decks.</p>



<p>“We have this S team that is very religious about Amazon’s culture and gets it,” he said, “but they brought in an enormous amount of senior execs in the level or two below the S team from [other] companies and they brought in their culture and were never given a real, ‘This is how we do things at Amazon.’”</p>



<p>New executives who joined right before or immediately after COVID-19 shutdowns also struggled to grasp the supreme importance of business review documents like the weekly, monthly, and quarterly business reviews that exist elsewhere in the business world but are foundational inside Amazon.</p>



<p>“There’s huge value in the QBR when everyone sits together and puts everything on the table,” a former director-level executive who left Amazon last year said. “But when you’re doing it over video and have to limit the number of attendees because there’s too many people, and you’re really worried about anything in there that’s too sensitive to be leaked, then the QBR becomes an onerous burden.”</p>


<div><p><img alt="" loading="lazy" width="1024" height="683" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1243927438-e1722366285183.jpg?w=1440&amp;q=75"></p><figcaption>Some Amazon insiders point to disruption caused by the pandemic as one reason for the changing work culture.</figcaption><p>Genaro Molina—Los Angeles Times/Getty Images</p></div>



<h2>Bezos was a guiding light and real-time model</h2>



<p>Some ascribe the fraying of Amazon’s distinct work culture in part to the change in the CEO suite, even while acknowledging Bezos’s wandering focus in this area during the final years of his tenure.&nbsp;</p>



<p>“In the last two years, Andy should have been more attuned to this,” one current Amazon manager who has spent 15 years at the company said in an interview.</p>



<p>As chief executive, Bezos for many years served as the guiding light of the Amazon Way, providing real-time lessons in how to interpret the leadership principles in different situations and how to know which ones to employ when.&nbsp;</p>



<p>The modeling was crucial for a set of principles which, as everyone who spoke to <em>Fortune</em> agreed, are often in tension with one another. How can you both “dive deep” while having a “bias for action”? How can you truly employ “customer obsession” if you also have to make sure that “frugality” is core to what you do?</p>



<p>Bezos excelled at explaining the mental models or logic he used to arrive at a decision, says Carr. He was able to articulate the “why” as much as the “what.”</p>



<p>“Jeff’s brain just doesn’t work like other people’s brains,” adds Carr, who experienced 15 years of firsthand observations before leaving the company in 2015, and who stressed that he could only speak about Amazon’s culture as it was during his time at the company. “By learning from him, then you could start to take those paths, too, and teach people about why that’s the path we would take.”</p>


<div><p><img alt="" loading="lazy" width="1024" height="682" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1193818193-e1722363304195.jpg?w=1440&amp;q=75"></p><figcaption>Amazon founder Jeff Bezos was instrumental in instilling Amazon’s special work culture within the company</figcaption><p>SAJJAD HUSSAIN/AFP via Getty Images</p></div>



<p>That would be a tough act for anyone to follow, even <a href="https://fortune.com/2021/07/05/andy-jassy-amazon-ceo-jeff-bezos/" target="_self" aria-label="Go to https://fortune.com/2021/07/05/andy-jassy-amazon-ceo-jeff-bezos/">a 27-year veteran like Jassy who</a> once served as Bezos’s “shadow,” a role similar to a chief of staff. That’s why many who spoke to <em>Fortune</em> don’t point to the Bezos-Jassy transition as the main fault line. The disruption caused by the pandemic, as well as the doubling of Amazon’s headcount in two years, was more to blame, they say.</p>



<p>Those who joined right before the pandemic, or during the madness of 2020 and 2021, had little time to learn and adapt. Learning through meeting interactions over videoconferencing, for example, was much less conducive to osmosis than in-person interactions, either planned or serendipitous run-ins, several sources said.</p>



<p>“The leadership we brought in from 2019 to 2021 at the director level and above never really were educated on the Amazon culture,” a senior manager of 15 years said.</p>



<p>“They really struggled to understand the culture, but that wasn’t on them,” said another, an Amazon director-level executive who left the company recently after nearly a decade. “That’s on the changing of times and remote work.”&nbsp;</p>



<p>Amazon’s Callahan said that for the last five years, new senior Amazon leaders at the director and vice president levels attend a three-day training on the company’s culture taught by peers, and are paired with other Amazon colleagues to help them adapt to the company in other ways. However, Callahan declined to respond to questions about whether this practice was put on hold during the pandemic and, if so, for how long.&nbsp;</p>



<p>Many longtime standard-bearers of the company’s DNA have also walked away in recent years. Jeff Wilke, Bezos’s longtime right hand and the CEO of Amazon’s core consumer business, left in 2021; Dave Clark, a longtime head of Amazon’s warehouse and delivery operations who eventually replaced Wilke, departed Amazon a little more than a year later, reportedly in part due to Jassy’s hands-on managing style.</p>



<p>“Culture takes active architecture and work,” said another former Amazon vice president who worked at the company for more than 15 years. “There was nobody else left to teach [that],” the former exec added, in a nod to all the top leaders who have left the company.&nbsp;</p>



<p>With so much change at the top, executives like Jamil Ghani are trying to step up. The global leader of Amazon Prime joined the company eight years ago and says that providing on-the-fly lessons and guidance about the leadership principles and Amazon customs, like written narratives, is an important part of his job.&nbsp;</p>



<p>“I often tell the team that the point of your work is not the doc; that the point of your work is to create a doc that can inspire the right meeting, the right discussion,” Ghani told <em>Fortune</em>. “In the best meetings, you actually don’t even talk about the document. Everybody has the same context and information and then you have a discussion.”</p>



<p>In the event that a leadership principle has been misinterpreted or misapplied—including, as he acknowledges occasionally occurs, in situations when one is being used punitively—Ghani swoops in.&nbsp;</p>



<p>“I’ve done this many times when it’s happened or, offline, kind of follow up with a peer or somebody else and be like, ‘Hey, I don’t think that’s quite right. And here’s why,’” he added. “And people can have a very level-headed conversation about it.”</p>


<div><p><img alt="" loading="lazy" width="1024" height="683" decoding="async" data-nimg="1" sizes="100vw" srcset="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=320&amp;q=75 320w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=384&amp;q=75 384w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=480&amp;q=75 480w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=576&amp;q=75 576w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=768&amp;q=75 768w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=1024&amp;q=75 1024w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=1280&amp;q=75 1280w, https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=1440&amp;q=75 1440w" src="https://fortune.com/img-assets/wp-content/uploads/2024/07/GettyImages-1797509756_81cda9-e1722365091257.jpg?w=1440&amp;q=75"></p><figcaption>The Amazon Way has led the ecommerce company to a $2 trillion valuation.</figcaption><p>DIMITAR DILKOFF/AFP via Getty Images</p></div>



<h2>A Bible with many religions</h2>



<p>One of the beauties of Amazon’s leadership principles has long been that they are detailed enough to serve as North Stars but broad enough for leaders to mold them as necessary depending on the type of decision or current environment.&nbsp;</p>



<p>“These are not processes that give you the answers,” says Carr, the former head of Prime Video. “They don’t tell you what to do. They don’t tell you whether to turn left or turn right, or to green-light this thing or not that thing. They’re management tools that give you the right frameworks to use to examine the problem.”</p>



<p>“Think of the LPs like the Bible,” a former member of Amazon’s exclusive senior executive team, known as the S-team, told <em>Fortune</em>. “Amazing how many religions are based off the same text.”</p>



<p>Three years into Jassy’s CEO tenure, the changes are becoming increasingly clear. The question now is whether this is evidence that the magic formula is getting diluted or a sign of the framework’s versatility.</p>



<p>Tomay, the VP of transportation, says staying nimble sometimes requires tweaking longtime practices. In the last year, she’s told her teams to reserve the six-page memo for only the most important meetings and encouraged them to craft a one-pager first. If there’s an alignment on the path forward after reviewing the one-pager in, say, a 30-minute meeting, that person or team will get the green light to go off and dive deep in creating a 6-pager.&nbsp;</p>



<p>“The company has shifted and grown,” she says, “so you have to keep adapting.”</p>



<p>With 1.5 million employees, Amazon is one of the largest employers in the world. And it has successfully expanded into lucrative markets like cloud computing, advertising, and entertainment. But with online retailers like China’s Shein and Temu gaining momentum, and AI threatening to reshape the entire business landscape, Amazon’s ability to adapt without losing what makes it special are sure to be tested in the years to come.</p>



<p>Business history can provide some unifying lessons. One key one: a strong culture and DNA, anchored in principles and practices that are talked about and lived out most working days, can help stabilize—even bolster—an organization during periods of significant change, whether CEO transitions or massive shifts in consumer or enterprise trends.&nbsp;</p>



<p>Meier, the Columbia Business School professor and author, points to <a href="https://fortune.com/company/toyota-tsusho/" target="_blank" aria-label="Go to https://fortune.com/company/toyota-tsusho/">Toyota</a> as one legacy corporation worth studying in this regard. “Toyota had those very clear principles on how to treat employees and make decisions, and I think it served them really well,” he says. “As a result, they sustained some of their success over transitions.”</p>



<p>The auto giant, whose stock hit an all-time high in March, is 87 years old, almost three times older than Amazon.&nbsp;</p>



<p>It’s currently on its 12th president.</p>



<p><em>Are you a current or former Amazon employee with thoughts on this topic or a tip to share? Contact Jason Del Rey at&nbsp;</em>jason.delrey@fortune.com<em>,&nbsp;</em>jasondelrey@protonmail.com<em>, or through secure messaging app Signal at&nbsp;</em>917-655-4267<em>. You can also message him&nbsp;</em><a href="https://www.linkedin.com/in/jasondelrey/" target="_blank" aria-label="Go to https://www.linkedin.com/in/jasondelrey/" rel="noreferrer noopener">on LinkedIn</a><em>&nbsp;or at&nbsp;</em><a href="https://twitter.com/DelRey" target="_blank" aria-label="Go to https://twitter.com/DelRey" rel="noreferrer noopener">@delrey</a><em>&nbsp;on&nbsp;</em><a href="https://fortune.com/company/twitter/" target="_self" aria-label="Go to https://fortune.com/company/twitter/">X</a><em>.</em></p></div><p><strong>Recommended Newsletter:</strong> The Fortune Next to Lead newsletter is a must-read for the next generation of C-suite leaders. Every Monday, the newsletter provides the strategies, resources, and expert insight needed to claim the most coveted positions in business. <a href="https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google" target="_self" aria-label="Go to https://fortune.com/newsletters/next-to-lead?&amp;itm_source=fortune&amp;itm_medium=article_tout&amp;itm_campaign=next_to_lead_v2&amp;itm_content=elon_amazon_google">Subscribe now</a>.</p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Why the CrowdStrike bug hit banks hard (155 pts)]]></title>
            <link>https://www.bitsaboutmoney.com/archive/crowdstrike-bug-hit-banks-hard/</link>
            <guid>41119874</guid>
            <pubDate>Wed, 31 Jul 2024 15:07:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bitsaboutmoney.com/archive/crowdstrike-bug-hit-banks-hard/">https://www.bitsaboutmoney.com/archive/crowdstrike-bug-hit-banks-hard/</a>, See on <a href="https://news.ycombinator.com/item?id=41119874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p><em><strong>Programming note</strong>: I recently launched a weekly podcast, </em><a href="https://www.complexsystemspodcast.com/" rel="noreferrer"><em>Complex Systems</em></a><em> with Patrick McKenzie. About 50% of the conversations cover Bits about Money's beat. The remainder will be on other interesting intersections of technology, incentives, culture, and organizational design. The first three episodes covered </em><a href="https://www.complexsystemspodcast.com/episodes/teaching-trading-ricki-heicklen/" rel="noreferrer"><em>teaching trading</em></a><em>, Byrne Hobart on the </em><a href="https://www.complexsystemspodcast.com/episodes/writing-history-byrne-hobart/" rel="noreferrer"><em>epistemology of financial firms</em></a><em>, and </em><a href="https://www.complexsystemspodcast.com/episodes/reporting-tech-kelsey-piper/" rel="noreferrer"><em>the tech industry vs. tech reporting divide</em></a><em>. Subscribe to it anywhere you listen to podcasts. If you enjoy it, writing a review (in your podcast app or to me via email) helps quite a bit.</em></p><p>On July 19th, a firm most people have sensibly never heard of knocked out a large portion of the routine operations at many institutions worldwide. This hit the banking sector particularly hard. It has been <a href="https://www.wsj.com/tech/microsoft-reports-major-service-outage-affecting-users-worldwide-328a2f40">publicly reported</a> that several of the largest U.S. banks were affected by the outage. I understand one of them to have idled tellers and bankers nationwide for the duration. (You’ll forgive me for not naming them, as it would cost me some points.) The issue affected institutions across the size spectrum, including large regionals and community banks.</p><p>You might sensibly ask why that happened and, for that matter, how it was possible it would happen.</p><p>You might be curious about how to quickly reconstitute the financial system from less legible sources of credit when it is down. (Which: probably less important as a takeaway, but it is quite colorful.)</p><h2 id="brief-necessary-technical-context">Brief necessary technical context</h2><p>Something like 20% of the readership of this column has an engineering degree. To you folks, I apologize in advance for the following handwaviness. (You <em>may</em> be better served by the <a href="https://www.crowdstrike.com/falcon-content-update-remediation-and-guidance-hub/" rel="noreferrer">Preliminary Post Incident Review</a>.)</p><p>Many operating systems have a distinction between the “kernel” supplied by the operating system manufacturer and all other software running on the computer system. For historical reasons, that area where almost everything executes is called “userspace.”</p><p>In modern software design, programs running in userspace (i.e. almost all programs) are <em>relatively</em> limited in what they can do. Programs running in kernelspace, on the other hand, get direct access to the hardware under the operating system. Certain bugs in kernel programming are very, very bad news for everything running on the computer.</p><p><a href="https://www.crowdstrike.com/platform/endpoint-security/">CrowdStrike Falcon</a> is endpoint monitoring software. In brief, “endpoint monitoring” is a service sold to enterprises which have tens or hundreds of thousands of devices (“endpoints”). Those devices are<em> illegible to the organization that owns them</em> due to sheer scale; no single person nor group of people understand what is happening on them. This means there are <em>highly variable</em> levels of how-totally-effed those devices might be at exactly this moment in time. The pitch for endpoint monitoring is that it gives your teams the ability to make those systems legible again while also benefitting from economies of scale, with you getting a continuously updated feed of threats to scan for from your provider.</p><p>One way an endpoint might be effed is if it was physically stolen from your working-from-home employee earlier this week. Another way is if it has recently joined a botnet orchestrated from a geopolitical adversary of the United States after one of your junior programmers decided to install warez because the six figure annual salary was too little to fund their video game habit. (No, I am not reading <em>your</em> incident reports, I clarify for every security team in the industry.)</p><p>In theory, you perform ongoing monitoring of <em>all</em> of your computers. Then, your crack security team responds to alerts generated by your endpoint monitoring solution. This will sometimes merit further investigation and sometimes call for immediate remedial work. The conversations range from “Did you really just install cracked Starcraft 2 on your work PC? … Please don’t do that.” to “The novel virus reported this morning compromised 32 computers in the wealth management office. Containment was achieved by 2:05 PM ET, by which point we had null routed every packet coming out of that subnet then physically disconnected power to the router just to be sure. We have engaged incident response to see what if any data was exfiltrated in the 47 minutes between detection and null routing. At this point we have no indications of compromise outside that subnet but we cannot rule out a threat actor using the virus as a beachhead or advanced persistent threats being deployed.”</p><p>(Yes, that does sound like a Tom Clancy novel. No, that is not a parody.)</p><h2 id="falcon-punched">Falcon punched</h2><p>Falcon <a href="https://www.crowdstrike.com/blog/falcon-update-for-windows-hosts-technical-details/">shipped a configuration bug</a>. In brief, this means that rather than writing new software (which, in modern development practice, hopefully goes through fairly extensive testing and release procedures), CrowdStrike sent a bit of data to systems with Falcon installed. That data was intended to simply update the set of conditions that Falcon scanned for. However, due to an error at CrowdStrike, it <em>actually</em> caused existing already-reviewed Falcon software to fail catastrophically.</p><p>Since that failure happened in kernelspace at a particularly vulnerable time, this resulted in Windows systems experiencing total failure beginning at boot. The user-visible symptom is sometimes called the <a href="https://support.microsoft.com/en-us/windows/resolving-blue-screen-errors-in-windows-60b01860-58f2-be66-7516-5c45a66ae3c6" rel="noreferrer">Blue Screen of Death</a>.</p><p>Configuration bugs are a disturbingly large portion of engineering decisions which cause outages. (Citation: let’s go with “general knowledge as an informed industry observer.” As always, while I’ve previously worked at Stripe, neither Stripe nor its security team necessarily endorses things I say in my personal spaces.)</p><p>However, because <em>this</em> configuration bug hit very widely distributed software running in kernelspace almost universally across machines used by the workforce of lynchpin institutions throughout society (most relevantly to this column, banks, but also <a href="https://www.delta.com/us/en/advisories/other-alerts/global-it-outage" rel="noreferrer">airlines</a>, etc etc), it had a blast radius much, much larger than typical configuration bugs.</p><p>Have I mentioned that IT security really likes military metaphors? “Blast radius” means “given a fault or failure in system X, how far afield from X will we see negative user impact.” I struggle to recall a bug with a broader direct blast radius than the Falcon misconfiguration.</p><p>Once the misconfiguration was rolled out, fixing it was complicated by the tiny issue that a lot of the people needed to fix it couldn’t access their work systems because their machine Blue Screen of Death’ed.</p><p>Why? Well, we put the vulnerable software on essentially all machines in a particular institution. You want to protect <em>all</em> the devices. That is the point of endpoint monitoring. It is literally someone’s job to figure out where the devices that aren’t endpoint monitored exist and then to bring them into compliance.</p><p>Why do we care about optimizing for endpoint monitoring coverage? Partly it is for genuinely good security reasons. But a major part of it is that small-c compliance is necessary for large-C Compliance. Your regulator will effectively demand that you do it.</p><h2 id="why-did-falcon-run-in-kernelspace-rather-than-userspace">Why did Falcon run in kernelspace rather than userspace?</h2><p>Falcon runs in kernelspace versus userspace in part because the most straightforward way to poke its nose in other programs’ business is to simply ignore the security guarantees that operating systems give to programs running in userspace. Poking your nose in another program’s memory is generally considered somewhere between rude and forbidden-by-very-substantial-engineering-work. However, endpoint monitoring software considers that other software running on the device <em>may be there at the direction of the adversary</em>. It therefore considers that software’s comfort level with its intrusion to be a distant secondary consideration.</p><p>Another reason Falcon ran in kernelspace was, as Microsoft told <a href="https://www.wsj.com/tech/cybersecurity/microsoft-tech-outage-role-crowdstrike-50917b90">the WSJ</a>, Microsoft was forbidden by an understanding with the European Commission from firmly demoting other security software developers down to userspace. This was because Microsoft both a) wrote security software and b) necessarily always had the option of writing it in kernelspace, because Microsoft controls Windows. The European Commission has <a href="https://www.euronews.com/next/2024/07/23/european-commission-denies-responsibility-for-massive-microsoft-it-outage#:~:text=A%20European%20Commission%20spokesperson%20has,Commission%20either%20before%20or%20after" rel="noreferrer">pushed back</a> against this characterization and pointed out that This Sentence Uses Cookies To Enable Essential Essay Functionality.</p><h2 id="regulations-which-strongly-suggest-particular-software-purchases">Regulations which strongly suggest particular software purchases</h2><p>It would be an overstatement to say that the United States federal government commanded U.S. financial institutions to install CrowdStrike Falcon and thereby embed a landmine into the kernels of all their employees’ computers. Anyone saying that has no idea how banking regulation works.</p><p>Life is much more subtle than that.</p><p>The United States has many, many different banking regulators. Those regulators have some desires for their banks which rhyme heavily, and so they have banded into a club to share resources. This lets them spend their limited brainsweat budgets on things banking regulators have more individualized opinions on than simple, common banking regulatory infrastructure.</p><p>One such club is the <a href="https://www.ffiec.gov/">Federal Financial Institutions Examination Council</a>. They wrote the tgreatest crossover event of all time if your interests are a) mandatory supervisory evaluations of financial institutions and b) IT risk management: the <a href="https://www.ffiec.gov/press/pdf/ffiec_it_handbook_information_security_booklet.pdf">FFIEC Information Technology Examination Handbook's Information Security Booklet</a>.</p><p>The modal consumer of this document is probably not a Linux kernel programmer with a highly developed mental model of kernelspace versus userspace. That would be an <em>unreasonable</em> expectation for a banking supervisor. They work for a <em>banking regulator</em>, not a software company, doing <em>important supervisory work</em>, not merely implementation. Later this week they might be working on capital adequacy ratios, but for right now, they’re asking your IT team about endpoint monitoring.</p><p>The FFEITC ITEH ISB (the acronym just rolls off the tongue) is not super prescriptive about exactly what controls you, a financial institution, have to have. This is common in many regulatory environments. HIPAA, to use a contrasting example, is unusual in that it describes a control environment that you can reduce to a checklist with Required or Optional next to each of them. (HIPAA spells that second category “Addressable”, for reasons outside the scope of this essay, but which I’ll mention because I don’t want to offend other former HIPAA Compliance Officers.)</p><p>To facilitate your institution’s conversation with the examiner who drew the short straw, you will conduct a risk analysis. Well, more likely, you’ll pay a consulting firm to conduct a risk analysis. In the production function that is scaled consultancies, this means that a junior employee will open U.S. Financial Institution IT Security Risk Analysis v3-edited-final-final.docx and add important client-specific context like a) their name and b) their logo.</p><p>That document will heavily reference the ITEH, because it exists to quickly shut down the line of questioning from the examiner. If you desire a career in this field, you will phrase that as “guiding the conversation towards areas of maximum mutual interest in the cause of 'advanc[ing] the nation’s monetary, financial, and payment systems to build a stronger economy for all Americans.'” (The internal quotation is lifted from a <a href="https://archive.is/P7Zsz#selection-1405.0-1405.69" rel="noreferrer">job description</a> at the Federal Reserve.)</p><p>Your consultants are going to, when they conduct the mandatory risk analysis, give you a shopping list. Endpoint monitoring is one item on that shopping list. Why? Ask your consultant and they’ll bill you for the answer, but you can get my opinion for free and it is worth twice what you paid for it: II.C.12 Malware Mitigation.</p><p>Does the FFEITC have a hugely prescriptive view of what you should be doing for malware monitoring? Well, no:</p><blockquote>Management should implement defense-in-depth to protect, detect, and respond to malware. The institution can use many tools to block malware before it enters the environment and to detect it and respond if it is not blocked. Methods or systems that management should consider include the following: [12 bullet points which vary in specificity from whitelisting allowed programs to port monitoring to user education].</blockquote><p>But your consultants will tell you that you want a very responsive answer to II.C.12 in this report and that, since you probably do not have Google’s ability to fill floors of people doing industry-leading security research, you should just buy something which says Yeah We Do That.</p><p>CrowdStrike’s sales reps will happily tell you <a href="https://crowdstrike.com/solutions/financial-services/">Yeah We Do That</a>. This web page exists as a result of a deterministic process co-owned by the Marketing and Sales departments at a B2B software company to create industry-specific “sales enablement” collateral. As a matter of fact, if you want to give CrowdStrike your email address and job title, they will even send you a document which is not titled <a href="https://www.crowdstrike.com/resources/reports/crowdstrike-falcon-and-ffiec-compliance/">Exact Wording To Put In Your Risk Assessment Including Which Five Objectives And Seventeen Controls Purchasing This Product Will Solve For</a>.</p><p>CrowdStrike is not, strictly speaking, the only vendor that you could have installed on every computer you owned to make your regulators happy with you. But, due to vagaries of how enterprise software sales teams work, they sewed up an awful lot of government-adjacent industries. This was in part because they aggressively pursued writing the <a href="https://www.crowdstrike.com/why-crowdstrike/crowdstrike-compliance-certification/" rel="noreferrer">sort of documents</a> you need if the people who read your project plans have national security briefs.</p><p>I’m not mocking the Federal Financial Institutions Examining Council for cosplaying as having a national security brief. (Goodness knows that that happens a lot in cybersecurity... and government generally. New York <em>City</em> likes to pretend it has an <a href="https://www.nyc.gov/site/nypd/bureaus/investigative/intelligence.page" rel="noreferrer">intelligence service</a>, which is absolutely not a patronage program designed to have taxpayers fund indefinite foreign vacations with minimal actual job duties.)</p><p>But money <em>is</em> core societal infrastructure, like the power grid and transportation systems are. It would be <em>really bad</em> if hackers working for a foreign government could just <em>turn off money</em>. That would be more damaging than a conventional missile being fired at random into New York City, and we might be more constrained in responding.</p><p>And so, we ended up in a situation where we invited an <a href="https://www.crowdstrike.com/cybersecurity-101/advanced-persistent-threat-apt/">advanced persistent threat</a> into kernelspace.</p><p>It is perhaps important to point out that security professionals understand  security tools to themselves introduce security vulnerabilities. Partly, the worry is that a monoculture could have a particular weakness that could be exploited in a particular way. Partly, it is that security tools (and security personnel!) frequently have more privileges than is typical, and therefore they can be directly compromised by the adversary. This observation is fractal in systems engineering: at every level of abstraction, if your control plane gets compromised, you lose. (Control plane has a <a href="https://www.cloudflare.com/learning/network-layer/what-is-the-control-plane/">specific meaning</a> in networking but for this purpose just round it to “operating system (metaphorical) that controls your operating systems (literal).”)</p><p>CrowdStrike <a href="https://x.com/George_Kurtz/status/1814235001745027317" rel="noreferrer">maintains</a> that they do not understand it to be the case that a bad actor intentionally tried to bring down global financial infrastructure and airlines by using them as a weapon. No, CrowdStrike did that themselves, on accident, of their own volition. But this demonstrates the problem pretty clearly: if a junior employee tripping over a power cord at your company brings down computers worldwide, the bad guys have a variety of options for achieving directionally similar aims by attacking directionally similar power cords.</p><h2 id="when-money-stops-money-ing">When money stops money-ing</h2><p>I found out about the CrowdStrike vulnerability in the usual fashion: Twitter. But then my friendly local bank branch cited it (as quote the Microsoft systems issue endquote) when I was attempting to withdraw cash from the teller window.</p><p>My family purchased a duplex recently and is doing renovation prior to moving in. For complex social reasons, a thorough recitation of which would make me persona non grata across the political spectrum, engaging a sufficient number of contractors in Chicago will result in one being asked to make frequent, sizable payments in cash.</p><p>This created a minor emergency for me, because it was an other-than-minor emergency for some contractors I was working with.</p><p>Many contractors are small businesses. Many small businesses are very thinly capitalized. Many employees of small businesses are extremely dependent on receiving compensation exactly on payday and not after it. And so, while <em>many</em> people in Chicago were basically unaffected on that Friday because <em>their</em> money kept working (on mobile apps, via Venmo/Cash App, via credit cards, etc), cash-dependent people got an enormous wrench thrown into their plans.</p><p>I personally tried withdrawing cash at three financial institutions in different weight classes, as was told it was absolutely impossible (in size) at all of them, owing to the Falcon issue.</p><p>At one, I was told that I couldn’t use the tellers but could use the ATM. Unfortunately, like many customers, I was attempting to take out more cash from the ATM than I ever had before. Fortunately, their system that flags potentially fraudulent behavior will let a customer unflag themselves by responding to an instant communication from the bank. Unfortunately, the subdomain that communication directs them to runs on a server apparently protected by CrowdStrike Falcon.</p><p>It was not impossible at <em>all</em> financial institutions. I am aware of a few around Chicago which ran out of physical cash on hand at some branches, because all demand for cash on a Friday was serviced by them versus by “all of the financial institutions.” (As always happens during widespread disturbances in infrastructure, there quickly arises a shadow economy of information trading which redirects relatively sophisticated people to the places that are capable of servicing them. This happens through offline social networks since time immemorial and online social networks since we invented those. The first is probably more impactful but the second is more <em>legible</em>, so banking regulators pretend this class of issues sprang fully formed from the tech industry just in time to bring down banks last year.)</p><p>I have some knowledge of the history of comprehensive failures of financial infrastructure, and so I considered doing the traditional thing when convertibility of deposits is suspended by industry-wide issues: <a href="https://theculturetrip.com/europe/ireland/articles/how-pubs-in-ireland-literally-saved-the-countrys-economy">head to the bar</a>.</p><p>A hopefully unnecessary disclaimer: the following is historical fact despite rhyming with stereotype.</p><p>Back in 1970, there was a widespread and sustained (six months!) strike in the Irish banking sector. Workers were unable to cash paychecks because tellers refused to work. So, as an accommodation for customers, operators of pubs would cash the checks from the till, trusting that <em>eventually</em> checks drawn on the accounts of local employers would be good funds again.&nbsp;</p><p>Some publicans even cashed personal checks, backed by the swift and terrible justice of the credit reporting bureau We Control Whether You Can Ever Enjoy A Pint With Your Friends Again. This kept physical notes circulating in the economy.</p><p>As I told my contractors, to their confusion, I was unable to simply go down to the local bar to get them cash with the banks down. I don’t have sufficient credit with the operator of the local bar, as I don’t drink.</p><p>I told them, to their <em>even greater</em> confusion, that I had considered going down to the parish and buying all their cash on hand with a personal check. Churches, much like bars, have much of their weekly income come through electronic payments but still do a substantial amount of cash management through the workweek heading into the weekend. I’m much more a known quantity at church than I am at the friendly neighborhood watering hole. (Also, when attempting to workaround financial infrastructure bugs to get workers their wages, consider relying on counterparties with common knowledge of <a href="https://bible.usccb.org/bible/james/5">James 5:4</a>.)</p><p>I eventually resolved the issue in a more boring fashion: I texted someone I reasonably assumed to have cash and asked them to bring it over.</p><p>Financial infrastructure normally functions to abstract away personal ties and replace favor-swapping with legibly-priced broadly-offered services.</p><p>Thankfully, while this outage was surprisingly deep and broad, banks were <em>mostly</em> back to normal on the following Monday.</p>

        

        <div>
          <h2>Want more essays in your inbox?</h2>
          <p>I write about the intersection of tech and finance, approximately biweekly. It's free.</p>
                  </div>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Launch HN: Martin (YC S23) – Using LLMs to Make a Better Siri (135 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=41119443</link>
            <guid>41119443</guid>
            <pubDate>Wed, 31 Jul 2024 14:24:27 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=41119443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><td><table>
        <tbody><tr id="41119443">
      <td><span></span></td>      <td><center><a id="up_41119443" href="https://news.ycombinator.com/vote?id=41119443&amp;how=up&amp;goto=item%3Fid%3D41119443"></a></center></td><td><span><a href="https://news.ycombinator.com/item?id=41119443">Launch HN: Martin (YC S23) – Using LLMs to Make a Better Siri</a></span></td></tr><tr><td colspan="2"></td><td><span>
          <span id="score_41119443">103 points</span> by <a href="https://news.ycombinator.com/user?id=darweenist">darweenist</a> <span title="2024-07-31T14:24:27"><a href="https://news.ycombinator.com/item?id=41119443">10 hours ago</a></span> <span id="unv_41119443"></span> | <a href="https://news.ycombinator.com/hide?id=41119443&amp;goto=item%3Fid%3D41119443">hide</a> | <a href="https://hn.algolia.com/?query=Launch%20HN%3A%20Martin%20(YC%20S23)%20%E2%80%93%20Using%20LLMs%20to%20Make%20a%20Better%20Siri&amp;type=story&amp;dateRange=all&amp;sort=byDate&amp;storyText=false&amp;prefix&amp;page=0">past</a> | <a href="https://news.ycombinator.com/fave?id=41119443&amp;auth=14110e6749d42d88b261a6cb53208e166a436a13">favorite</a> | <a href="https://news.ycombinator.com/item?id=41119443">83&nbsp;comments</a>        </span>
              </td></tr>
    <tr><td></td></tr><tr><td colspan="2"></td><td><div><p>Hey HN! Dawson here from Martin (<a href="https://www.trymartin.com/">https://www.trymartin.com</a>). Martin is a better Siri with an LLM brain and deeper integrations with everyday apps. See our demo here (<a href="https://youtu.be/jiJdfrWurvk" rel="nofollow">https://youtu.be/jiJdfrWurvk</a>). You can talk to Martin through voice in our iOS app. You can also text it via SMS, WhatsApp, or email. Currently, Martin can manage your calendar, set reminders, find information, send you daily briefings, and have text conversations with your contacts on your behalf (from its own phone number).</p><p>I’ve been a Siri power user for a long time, mainly because I’ve always liked using voice as an interface. But, legacy voice assistants like Siri, Google Assistant, and Alexa were never well integrated enough or reliable enough to actually save time. Maybe 1 in 5 commands end up executing as smoothly as you expected, but the most useful thing they do is play a song or set an alarm. The advent of LLMs seemed like a great opportunity to push the state of the art forward a notch or two!</p><p>Our goal is to do 2 things better:</p><p>1) Deeper integrations with productivity-related apps you use every day, like calendar, email, messages, whatsApp, and soon Google Docs, Slack, and phone calls.</p><p>2) Better memory of each user based on their past conversations and integrations, so Martin can start to anticipate parameters in the user’s commands (e.g. text the guy from yesterday about the plans we made this morning)</p><p>A great way that our early users use Martin is having morning syncs and evening debriefs with the software. At the start/end of each day, they’ll have a 5-10 minute sync about their TODOs for the next day, and Martin will brief them on upcoming tasks and news they’re typically interested in.</p><p>Something else Martin does which is unlike other voice assistants is it can have full text conversations with your contacts on your behalf from its own phone number. For example, you can tell it to plan a lunch with a friend, and it can text back and forth with that friend to figure out a time and place. After the text conversation between your friend and Martin is over, Martin reports back to you via a notification and a text. You can also monitor all of its messages with your contacts in the app.</p><p>We started building Martin exactly 1 year ago, during our YC batch. It’s definitely a hard product to “complete" because of the many unsolved technical challenges, but we’re making progress step by step. First was the voice interface, which Siri still hasn’t gotten right after more than a decade. We have 2 modes: push-to-talk and handsfree. Handsfree is great for obvious reasons. We’ve gotten our latency down to only a couple seconds max for most commands, and we’ve tuned our own voice activity detection model to minimize the chance of Martin cutting you off (a common problem with voiceGPTs). But, even then, Martin may still cut you off if you pause for 3-5 seconds in the middle of a thought, so we made a push-to-talk mode. For those cases where you want to describe something in detail or just brain-dump to Martin, you might need 20-30 seconds to finish speaking. So just hold down, speak, and release when you’re done—like a walkie talkie.</p><p>We’ve also had to tackle a very long tail of integrations, and we want to do each one well. For example, when we launched Google calendar, we wanted to make sure you could add a Google Meet link, invite your contacts to the events, and access secondary calendars. And, you should be able to say things like “set reminders leading up to the event” or “text Eric the details of this event.” So, we pretty much release one new major integration every month.</p><p>Finally, there’s the problem of personalization / LLM memory, which is still very unsolved. From each conversation that a user has with their Martin, we try to infer what the user is busy with, worried about, or looking forward to, so in their next “morning sync” or “evening debrief”, Martin can proactively suggest to-dos or goals/topics to discuss with the user. Right now, we use a few different LLMs and many chain-of-thought steps to extract clues from each conversation and have Martin “reflect” periodically to build its memory. But, with all that said we still have a lot of work to do here, and this is just a start!</p><p>You can try Martin by going to our website (<a href="https://www.trymartin.com/">https://www.trymartin.com</a>) and starting a 7 day free trial. Once you start your trial, you’ll get an access code emailed to you along with the download link for our iOS app. After you enter your access code into the app, you can integrate your calendar, contacts, etc. If you find Martin useful after the trial, we charge our early users (who are generally productivity gurus and prosumers with multiple AI subscriptions) a $30/month subscription.</p><p>We can’t wait to hear your thoughts. Any cool experiences with Siri, things you wish a voice assistant could do, or ideas about LLM memory, tool calling, etc. - I’d love to discuss any of these topics with you!</p></div></td></tr>        <tr><td></td></tr><tr><td colspan="2"></td><td><form action="comment" method="post"></form></td></tr>  </tbody></table>
  </td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How great was the Great Oxidation Event? (207 pts)]]></title>
            <link>https://eos.org/science-updates/how-great-was-the-great-oxidation-event</link>
            <guid>41119080</guid>
            <pubDate>Wed, 31 Jul 2024 13:40:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eos.org/science-updates/how-great-was-the-great-oxidation-event">https://eos.org/science-updates/how-great-was-the-great-oxidation-event</a>, See on <a href="https://news.ycombinator.com/item?id=41119080">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-225187">
	<div>

		
		
<p>If water is the key to life, then oxygen is the key to animal life. All animals breathe oxygen. Despite decades of research, however, scientists still don’t know when Earth’s atmosphere held enough free oxygen to support the planet’s early animals. Most geologists agree that oxygen first accumulated in the atmosphere <a href="https://eos.org/articles/early-life-learned-to-love-oxygen-long-before-it-was-cool" target="_blank" rel="noopener">around 2.4 billion years ago</a>. But they don’t agree on how much there was at that time or if it was enough for animals to thrive.</p>

<p>My colleagues and I recently found new clues to help answer these questions from an unlikely source: the acidic, metal-rich waters of Rio Tinto in southern Spain. The composition of these waters is considered extreme today, yet the sort of acid rock drainage that causes these conditions was widespread long ago, when newly available atmospheric oxygen first began interacting with sulfur minerals on land.</p>

<p>In our work, we showed that the chemistry occurring in these acidic waters can reconcile seemingly contradictory estimates of past levels of breathable oxygen determined from ancient sediments. Our data support growing evidence that enough oxygen was present for animals to have evolved nearly 2 billion years before they burst onto the scene.</p>

<h3>Earth’s First “Great Oxidation”</h3>

<figure><blockquote><p><em>When the single-celled ancestors of plants learned to combine carbon dioxide and water, these early innovators spat out a waste product formerly absent from their environment: free molecular oxygen.</em></p></blockquote></figure>

<p>A critical transition in our planet’s history occurred when the single-celled ancestors of plants learned to combine carbon dioxide and water—two chemicals found everywhere on Earth—to make their cells and produce energy. These early innovators spat out a waste product formerly absent from their environment: free molecular oxygen (O<sub>2</sub>). This highly reactive gas began to run rampant on Earth’s surface, leaving telltale signs of its activity in minerals and sediments.</p>

<p>It’s been more than 5 decades since scientists began deciphering these signs from the geologic record. Over that time, most scientists have come to agree that O<sub>2</sub> first reached appreciable concentrations in Earth’s atmosphere roughly 2.4 billion years ago, during the Great Oxidation Event (GOE) [<a href="https://doi.org/10.1016/B978-0-08-095975-7.01304-8" target="_blank" rel="noopener"><em>Farquhar et al.</em></a>, 2014]. Geologists who first described the GOE estimated that oxygen levels rose from near zero to about 10%–40% of what they are today (oxygen currently makes up 21% of the air we breathe). They also proposed that atmospheric O<sub>2</sub> remained at these levels until it reached modern levels more than 1.5 billion years later. This extended interval roughly coincided with the third and longest of the four geologic eons of Earth’s history, the Proterozoic.</p>

<p>Other researchers have since challenged those original estimates of Proterozoic O<sub>2</sub>. They suggest that oxygen concentrations rose to less than 0.1% of today’s level during the GOE and remained there, with only occasional short-term increases, through the ensuing eon. This substantial distinction—10% or more versus less than 0.1%—bears critically on the role of oxygen in animal evolution. Various forms of animal life require different minimum oxygen levels for survival, but even primitive animals like sponges require at least 0.25% of today’s atmospheric oxygen levels to metabolize [<a href="https://doi.org/10.1111/gbi.12382" target="_blank" rel="noopener"><em>Cole et al.</em></a>, 2020].</p>


<p>In the fossil record, paleontologists have found the oldest undisputed fossil eukaryotes, the single-celled precursors to animals, in marine sediments that accumulated about 1.7 billion years ago [<a href="https://doi.org/10.1126/sciadv.1603076" target="_blank" rel="noopener"><em>Knoll and Nowak</em></a>, 2017]. Despite the undisputed antiquity of eukaryotes, fossils of large multicellular life-forms representing putative animals don’t appear until more than a billion years later in the 0.57-billion-year-old Ediacaran biota, and undisputed animals don’t appear until the Cambrian period about 0.54 billion years ago.</p>

<figure><img decoding="async" width="780" height="384" src="https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?resize=780%2C384&amp;ssl=1" alt="A view of a museum display reproducing frond-shaped life forms from the Ediacaran period." srcset="https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?resize=1024%2C504&amp;ssl=1 1024w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?resize=480%2C236&amp;ssl=1 480w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?resize=768%2C378&amp;ssl=1 768w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?resize=400%2C197&amp;ssl=1 400w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display.jpg?w=1200&amp;ssl=1 1200w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/ediacaran-model-museum-display-1024x504.jpg?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1"><figcaption>Some of the earliest putative animals found in the fossil record are represented in this reproduction of life from the Ediacaran period (635–541 million years ago) at the Smithsonian National Museum of Natural History in Washington, D.C. Credit: <a href="https://commons.wikimedia.org/wiki/File:Ediacaran_ecosystem_diorama_NMNH.jpg" target="_blank" rel="noopener">Ryan Schwark/Wikimedia Commons</a>, <a href="https://creativecommons.org/publicdomain/zero/1.0/legalcode.en" target="_blank" rel="noopener">CC0 1.0 Universal</a></figcaption></figure>

<p>Paleontologists have also described a pronounced expansion of fossil eukaryotes around 0.8 billion years ago, coinciding with when atmospheric O<sub>2</sub> <a href="https://eos.org/articles/longer-days-likely-boosted-earths-early-oxygen" target="_blank" rel="noopener">reached near modern levels</a>. Some researchers hypothesize that this rise in O<sub>2</sub> allowed these early eukaryotes to diversify and eventually evolve into multicellular animals. But this simple cause-effect scenario relies heavily on debated claims that oxygen remained too low to sustain animal life for roughly 1.6 billion years prior.</p>

<h3>Controversial Clues from Chromium</h3>

<figure><blockquote><p>One problem with attempts to resolve the history of Earth’s breathable oxygen is that the data researchers use to estimate past levels have provided conflicting results.</p></blockquote></figure>

<p>One problem with attempts to resolve the history of Earth’s breathable oxygen is that the data researchers use to estimate past levels have provided conflicting results. The atmosphere doesn’t directly fossilize, so geochemists rely on indirect traces, or proxies, to tease out the gases it contained at different times.</p>

<p>One proxy that researchers have widely employed to estimate atmospheric O<sub>2</sub> levels in the Proterozoic involves the heavy metal chromium [<a href="https://doi.org/10.1016/j.chemgeo.2020.119570" target="_blank" rel="noopener"><em>Wei et al.</em></a>, 2020]. Like many elements, not all chromium atoms are created equal. Although all have 24 protons in their nuclei, they can have different numbers of neutrons; in other words, different isotopes of chromium exist.</p>

<p>These different chromium isotopes react at different rates, leading to fractionation, or a change in their ratios, when they undergo chemical reactions in the environment. For example, chromium isotopes are fractionated when they react with manganese oxide minerals. This reaction preferentially releases heavier isotopes of chromium into natural waters that become more concentrated in sediments as a result.</p>

<figure><blockquote><p>Scientists want to resolve these disparate scenarios to understand oxygen’s role in animal evolution on Earth and potentially on other planets too.</p></blockquote></figure>

<p>Manganese oxide minerals such as birnessite and todorokite are very common in modern environments, for example, in soils and fluvial settings and on the seafloor. Researchers have estimated that reactions with these minerals fractionate chromium isotopes when free O<sub>2</sub> is present at concentrations above 0.1% of modern atmospheric levels [<em><a href="https://doi.org/10.1126/science.1258410" target="_blank" rel="noopener">Planavsky et al.</a></em>, 2014]. So some scientists have argued that chromium isotope fractionation in ancient rocks provides an “oxygen signal,” indicating when O<sub>2</sub> exceeded 0.1% of current levels. They have also claimed the corollary, that a lack of chromium isotope fractionation in rocks indicates that oxygen levels at the time the rocks formed were below that threshold.</p>

<p>Geochemists who first measured chromium isotopes in Proterozoic rocks found that large chromium isotope fractionations didn’t appear until 0.8 billion years ago, suggesting O<sub>2</sub> levels were too low to support animals until late in the Proterozoic [<em><a href="https://doi.org/10.1126/science.1258410" target="_blank" rel="noopener">Planavsky et al.</a></em>, 2014]. However, researchers recently found large fractionations in chromium isotopes preserved in ancient soils and marine rocks as far back as 1.9 billion years ago. These researchers contended that Proterozoic O<sub>2</sub> levels were at least intermittently high enough for animals to evolve well before their first occurrence in the fossil record [<a href="https://doi.org/10.1038/s41467-018-05263-9" target="_blank" rel="noopener"><em>Canfield et al.</em></a>, 2018]. Scientists want to resolve these disparate scenarios to understand oxygen’s role in animal evolution on Earth and potentially on other planets too.</p>

<h3>Going to the Extreme</h3>

<p>Spain’s Rio Tinto flows roughly 100 kilometers through the southwest of the country, stained blood red from its headwaters north of the town of Nerva in the Sierra Moreno to its mouth at the Ria of Huelva estuary, where it spills into the Atlantic Ocean. Mining activities over millennia in the Iberian Pyrite Belt, one of the largest hydrothermal ore deposits in the world, have exposed large piles of the iron sulfide mineral pyrite in the headwaters of the river to attack by atmospheric O<sub>2</sub> at Earth’s surface. When pyrite reacts with O<sub>2</sub>, it produces sulfuric acid, which is responsible for the river’s very low pH of 2 (similar to the pH of lemon juice or stomach acid). The reaction and resulting acidity also release iron, which gives rise to the river’s characteristic red tint, and other heavy metals—including chromium—from surrounding rocks.</p>

<p>Today, Rio Tinto’s waters are an extreme environment. But such conditions were once far more common. Scientists have proposed that as a result of the GOE, newly liberated O<sub>2</sub> in the atmosphere attacked extensive pyrite deposits on the land surface. Like today’s rock weathering in southern Spain, this chemical attack released heavy metals and sulfuric acid, producing widespread acid rock drainage [<em><a href="https://doi.org/10.1038/nature10511" target="_blank" rel="noopener">Konhauser et al.</a></em>, 2011]. In the aftermath of the GOE, it’s likely that rivers like Rio Tinto were the norm rather than the exception.</p>

<figure><blockquote><p>Are scientists today similarly misinterpreting the lack of chromium isotope fractionation in rocks older than 0.8 billion years?</p></blockquote></figure>

<p>Despite the preponderance of acid rock drainage after the GOE, geochemists had not looked into how chromium isotopes fractionate in acidic natural waters. After nearly a decade of teaching geochemistry at Rio Tinto, I knew manganese oxides rarely form in similarly acidic waters. And I figured if manganese oxides are necessary for imparting the chromium isotopic oxygen signal into rocks, then a lack of these minerals might prevent the formation of the signal, even in today’s high-O<sub>2</sub> atmosphere.</p>

<p>To investigate this hypothesis, I teamed up with my longtime friend and colleague Kate Scheiderich, who was then at the U.S. Geological Survey and had set up a lab to measure chromium isotopes. Returning to Rio Tinto, I collected samples of river water, rocks, and sediment from different locations along the bank of the river. Then I shipped them to Kate’s lab for her and another colleague to analyze.</p>

<p>We found that the acidic headwaters of the Rio Tinto were, indeed, leaching chromium from the surrounding rocks, then carrying it downstream to the Atlantic, where it accumulated in sediments around the estuary. However, the river was simply too acidic for manganese oxide minerals to form, despite flowing in an atmosphere with 21% oxygen. The analytical results in our study confirmed that without any manganese oxides to react with, chromium isotopes in the estuary sediments remained unfractionated and the chromium isotope values were identical to those in the source rocks they came from upstream (Figure 1).</p>
<div>
<figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/eos.org\/wp-content\/uploads\/2024\/07\/chromium-isotope-ratios-water-sediments.png&quot;,&quot;figureClassNames&quot;:&quot;alignright size-large&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:&quot;wp-image-225193&quot;,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:1200,&quot;targetHeight&quot;:702,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image: Bar plot showing the ranges in chromium isotope ratios measured from various sources.&quot;,&quot;alt&quot;:&quot;Bar plot showing the ranges in chromium isotope ratios measured from various sources.&quot;}" data-wp-interactive="core/image"><img decoding="async" width="780" height="456" data-wp-init="callbacks.setButtonStyles" data-wp-on-async--click="actions.showLightbox" data-wp-on-async--load="callbacks.setButtonStyles" data-wp-on-async-window--resize="callbacks.setButtonStyles" src="https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?resize=780%2C456&amp;ssl=1" alt="Bar plot showing the ranges in chromium isotope ratios measured from various sources." srcset="https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?resize=1024%2C599&amp;ssl=1 1024w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?resize=480%2C281&amp;ssl=1 480w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?resize=768%2C449&amp;ssl=1 768w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?resize=400%2C234&amp;ssl=1 400w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments.png?w=1200&amp;ssl=1 1200w, https://i0.wp.com/eos.org/wp-content/uploads/2024/07/chromium-isotope-ratios-water-sediments-1024x599.png?w=370&amp;ssl=1 370w" sizes="(max-width: 780px) 100vw, 780px" data-recalc-dims="1"><figcaption>Fig. 1. Most sediments and waters today show a wide spread in chromium isotope ratios because the chromium they contain has been fractionated through reactions with manganese oxides. In contrast, because manganese oxides do not form in acidic waters, sediments from the Rio Tinto estuary show a very small spread in chromium isotope ratios that centers around a δ<sup>53</sup>Cr of 0‰, similar to the range measured in rocks supplying chromium to the river. The range of chromium isotope ratios measured in rocks older than 0.8 billion years is also relatively narrow and centers around a δ<sup>53</sup>Cr of 0‰, indicating that little chromium isotope fractionation is evident in these rocks. δ<sup>53</sup>Cr (in parts per thousand, ‰) represents depletion (negative values) or enrichment (positive values) of chromium-53 relative to chromium-52 in a sample compared to a standard reference material; δ<sup>53</sup>Cr = 1,000 × {[(<sup>53</sup>Cr/<sup>52</sup>Cr<sub>sample</sub>)/(<sup>53</sup>Cr/<sup>52</sup>Cr<sub>standard</sub>)] − 1}.</figcaption></figure></div>
<p>Millions of years from now, after these estuarine sediments have lithified into marine rocks, future geochemists—analyzing the rocks with the same techniques and understanding of the chromium isotope oxygen signal scientists have employed until now—might thus mistakenly infer that our current air was unbreathable. Are scientists today similarly misinterpreting the lack of chromium isotope fractionation in rocks older than 0.8 billion years?</p>

<p>We proposed that the prevalence of acid rock drainage on Proterozoic continents could have hindered development of the chromium isotope oxygen signal until 0.8 billion years ago (when, perhaps, most acid rock drainage had been consumed). This idea reconciles seemingly contradictory chromium isotope data and suggests O<sub>2</sub> in the atmosphere could have been elevated above 0.1% of modern levels far earlier in the Proterozoic [<em><a href="https://doi.org/10.1016/j.gca.2023.05.024" target="_blank" rel="noopener">Scheiderich et al.</a></em>, 2023].</p>

<h3>Why Did Animals Wait?</h3>

<p>As scientists increasingly focus on oxygen in the Proterozoic, more geochemical estimates [e.g., <a href="https://doi.org/10.1038/s41561-020-0558-5" target="_blank" rel="noopener"><em>Mänd et al.</em></a>, 2020] and atmospheric models [e.g., <a href="https://doi.org/10.1016/j.epsl.2021.116818" target="_blank" rel="noopener"><em>Gregory et al</em></a><em>.</em>, 2021] are suggesting that atmospheric O<sub>2</sub> concentrations were high enough for animals to have thrived more than 2 billion years before the early Cambrian. So why did it take so long for them to appear?</p>

<p>One possible explanation is that oxygen concentrations in the Proterozoic ocean fluctuated too much. Most scientists agree that shallow marine habitats, likely hotbeds for evolution, had oxygen levels high enough to support eukaryotes throughout the Proterozoic. But oxygen-free waters from the deep ocean routinely circulated upward, possibly diluting the oxygen oases at the surface. The instability of back-and-forth swings in oxygen in the surface ocean could have posed a big challenge to the evolution of early animals.</p>

<p>Some scientists suggest famine could also have held early animals back. The same protoplants that produced oxygen in the Proterozoic also formed the base of the food chain, so researchers have inferred that low oxygen and a low food supply went hand in hand. Animals could also have been starved for nutrients essential to life, such as nitrogen, which is found in nearly all biomolecules, including DNA, RNA, and proteins. Many geochemists have suggested nitrogen was scarce in the Proterozoic, when denitrifying microbes first started converting oxidized nitrogen (e.g., nitrate) into forms that animals can’t use (e.g., nitrogen gas).</p>

<p>Other researchers have proposed developmental hypotheses for the lag in animal evolution. They point out that it could have taken billions of years for the core set of genes found in all multicellular life to evolve in eukaryotes and that only after those genes emerged could animal life diversify greatly. Or perhaps, environmental and biological hurdles together slowed animal evolution.</p>

<p>For now, more answers to why animals only debuted at the end of the Proterozoic will have to wait. Whatever the explanations, recent research is seemingly making clear that it wasn’t for want of oxygen.</p>

<h3>References</h3>

<p>Canfield, D. E., et al. (2018), Highly fractionated chromium isotopes in Mesoproterozoic-aged shales and atmospheric oxygen, <em>Nat. Commun.</em>, <em>9</em>(1), 2871, <a href="https://doi.org/10.1038/s41467-018-05263-9" target="_blank" rel="noopener">https://doi.org/10.1038/s41467-018-05263-9</a>.</p>

<p>Cole, D. B., et al. (2020), On the co‐evolution of surface oxygen levels and animals, <em>Geobiology</em>, <em>18</em>(3), 260–281, <a href="https://doi.org/10.1111/gbi.12382" target="_blank" rel="noopener">https://doi.org/10.1111/gbi.12382</a>.</p>

<p>Farquhar, J., A. L. Zerkle, and A. Bekker (2014), Geologic and geochemical constraints on Earth’s early atmosphere, in <em>Treatise on Geochemistry</em>, 2nd ed., pp. 91–138, Elsevier, Amsterdam, <a href="https://doi.org/10.1016/B978-0-08-095975-7.01304-8" target="_blank" rel="noopener">https://doi.org/10.1016/B978-0-08-095975-7.01304-8</a>.</p>

<p>Gregory, B. S., M. W. Claire, and S. Rugheimer (2021), Photochemical modelling of atmospheric oxygen levels confirms two stable states, <em>Earth Planet. Sci. Lett.</em>, <em>561</em>, 116818, <a href="https://doi.org/10.1016/j.epsl.2021.116818" target="_blank" rel="noopener">https://doi.org/10.1016/j.epsl.2021.116818</a>.</p>

<p>Knoll, A. H., and M. A. Nowak (2017), The timetable of evolution, <em>Sci. Adv.</em>, <em>3</em>, e1603076, <a href="https://doi.org/10.1126/sciadv.1603076" target="_blank" rel="noopener">https://doi.org/10.1126/sciadv.1603076</a>.</p>

<p>Konhauser, K. O., et al. (2011), Aerobic bacterial pyrite oxidation and acid rock drainage during the Great Oxidation Event, <em>Nature</em>, <em>478</em>(7369), 369–373, <a href="https://doi.org/10.1038/nature10511" target="_blank" rel="noopener">https://doi.org/10.1038/nature10511</a>.</p>

<p>Mänd, K., et al. (2020), Palaeoproterozoic oxygenated oceans following the Lomagundi–Jatuli event, <em>Nat. Geosci</em>., <em>13</em>(4), 302–306, <a href="https://doi.org/10.1038/s41561-020-0558-5" target="_blank" rel="noopener">https://doi.org/10.1038/s41561-020-0558-5</a>.</p>

<p>Planavsky, N. J., et al. (2014), Low mid-Proterozoic atmospheric oxygen levels and the delayed rise of animals, <em>Science</em>, <em>346</em>(6209), 635–638, <a href="https://doi.org/10.1126/science.1258410" target="_blank" rel="noopener">https://doi.org/10.1126/science.1258410</a>.</p>

<p>Scheiderich, K., A. L. Zerkle, and D. Damby (2023), Chromium isotopes in an acidic fluvial system: Implications for modern and ancient Cr isotope records, <em>Geochim. Cosmochim. Acta</em>, <em>354</em>, 123–145, <a href="https://doi.org/10.1016/j.gca.2023.05.024" target="_blank" rel="noopener">https://doi.org/10.1016/j.gca.2023.05.024</a>.</p>

<p>Wei, W., et al. (2020), Biogeochemical cycle of chromium isotopes at the modern Earth’s surface and its applications as a paleo-environment proxy, <em>Chem. Geol.</em>, <em>541</em>, 119570, <a href="https://doi.org/10.1016/j.chemgeo.2020.119570" target="_blank" rel="noopener">https://doi.org/10.1016/j.chemgeo.2020.119570</a>.</p>

<h3>Author Information</h3>

<p>Aubrey Zerkle (<a href="mailto:aubrey.zerkle@bmsis.org" target="_blank" rel="noopener">aubrey.zerkle@bmsis.org</a>), Blue Marble Space Institute of Science, Seattle, Wash.</p>

<h5><strong>Citation:</strong> Zerkle, A. (2024), How great was the “Great Oxidation Event”?, <em>Eos, 105, </em><a href="https://doi.org/10.1029/2024EO240313" target="_blank" rel="noopener">https://doi.org/10.1029/2024EO240313</a>. Published on 30 July 2024.</h5>

<h6><strong>Text © 2024. The authors.&nbsp;<a href="https://creativecommons.org/licenses/by-nc-nd/3.0/us/" target="_blank" rel="noreferrer noopener">CC BY-NC-ND 3.0</a></strong><br><strong>Except where otherwise noted, images are subject to copyright. Any reuse without express permission from the copyright owner is prohibited.</strong></h6>

	</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]></description>
        </item>
    </channel>
</rss>