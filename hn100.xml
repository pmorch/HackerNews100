<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 23 Apr 2025 07:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Native visionOS platform support (169 pts)]]></title>
            <link>https://github.com/godotengine/godot/pull/105628</link>
            <guid>43768421</guid>
            <pubDate>Wed, 23 Apr 2025 03:37:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/godotengine/godot/pull/105628">https://github.com/godotengine/godot/pull/105628</a>, See on <a href="https://news.ycombinator.com/item?id=43768421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  
  <task-lists disabled="" sortable="">
    <div>
      <p dir="auto">Dear Godot community,</p>
<p dir="auto">I'm on Apple's visionOS engineering team, and we would like to contribute Vision Pro support to the Godot engine. This is the first PR that lays the foundation for that.</p>
<p dir="auto">First, I'd like to mention that we're really excited to be working with the Godot community on adding visionOS support. We've attempted to follow Godot's coding standards and a high-quality bar for our contributions. We hope that our contributions align with Godot's goals. Lastly, even though we have tried to split the changes into smaller self-contained PRs, we acknowledge that some of these PRs can be of considerable size.</p>
<p dir="auto">We're very happy to iterate on our PRs after receiving feedback and suggestions from the community.</p>
<h2 dir="auto">High Level Overview</h2>
<p dir="auto">The immediate goals of our contributions are:</p>
<ol dir="auto">
<li>To support current Godot games running natively on a planar window on visionOS.</li>
<li>To support creating Immersive experiences by using a new Godot's visionOS VR Plugin.</li>
</ol>
<p dir="auto">To achieve that, and in order to make reviewing easier, we have structured our contributions in three incremental PRs.</p>
<ol dir="auto">
<li>Add the native <code>visionOS</code> platform. Uses iOS as the starting point. Reuses as much code as possible between the iOS and Vision Pro platforms. (This PR).</li>
<li>Add ability to compile and link Swift files within Godot, and replace <code>main.mm</code> on the <code>visionOS</code> platform by the SwiftUI app lifecycle. This is a requirement to be able to launch Immersive scenes on visionOS.</li>
<li>Introduce Vision Pro VR plugin for Immersive support.</li>
</ol>
<p dir="auto">Even though we have a working version including points 2 and 3, those PRs are not up yet. Our current plan is to open them sequentially, after each of the previous PRs merge.</p>
<h2 dir="auto">Technical Discussion</h2>
<p dir="auto">This PR implements a new native <code>visionOS</code> platform.</p>
<p dir="auto">It's very close to the <code>iOS</code> platform in terms of implementation. In order to reuse as much code as possible, it introduces a new <code>drivers/apple_embedded</code> folder, to host code shared between the <code>iOS</code> and <code>visionOS</code> (but not <code>macOS</code>) platforms. We took inspiration from the new <code>drivers/apple</code> folder, which hosts code that applies to all Apple platforms.</p>
<p dir="auto">The platform-specific logic (including app instantiation, client code, display server, os support, and export plugin) was refactored, and now the bulk of the implementation is on <code>drivers/apple_embedded</code>. The platforms provide small subclasses that specialize the concrete aspects that are different between platforms. We did this refactor with care, trying not to alter the existing iOS functionality.</p>
<p dir="auto">The <code>visionOS</code> platform doesn't have OpenGL support, as it's not supported by visionOS.</p>
<p dir="auto">In order to make reviewing easier, we have tried to split this PR into individual self-contained commits when that made sense, and we have added detailed descriptions to most of them about what's contained in each commit. It's easier to review commit by commit, to see how the changes were incrementally implemented.</p>
<h3 dir="auto">Documentation Considerations</h3>
<p dir="auto">Now, the export plugin for <code>iOS</code> and <code>visionOS</code> share the majority of the code and most of their options (with the exception of launch storyboard support, which is iOS only; and specific platform icon support). Because of this, we have renamed <code>EditorExportPlatformIOS.xml</code> to <code>EditorExportPlatformAppleEmbedded.xml</code>, and moved it to <code>drivers/apple_embedded</code>.</p>
<p dir="auto">We'd like to ask the community if this is appropriate from the docs tooling perspective, and we're requesting further guidance on how to modify this file or the docs tooling to provide specific documentation for each of the platforms.</p>
<h2 dir="auto">Testing</h2>
<p dir="auto">We have been testing this PR mainly with the <a href="https://github.com/godotengine/godot-demo-projects/tree/master/3d/platformer">Platformer demo project</a>. We have verified the project continues to work on iOS, and it now runs natively on visionOS. We have tested both the Mobile and Forward+ renderers with the Metal rendering driver on both platforms.</p>
<h3 dir="auto">Open Questions</h3>
<p dir="auto">In all our tests, we exported an Xcode project using the corresponding export plugin and template, and we then ran this project directly to an iOS or visionOS device.</p>
<p dir="auto">We'd like to ask the community to provide guidance, or to help testing the following functionality:</p>
<ul dir="auto">
<li>We have not tested the ability of the iOS/visionOS export templates to embed and link plugins at export time. We tried to preserve this functionality on the <code>visionOS</code> platform, and we assume it will work in the same way it works on iOS. If anybody can attach a project using this functionality, we can help test it.</li>
<li>We have not been able to make direct Archive/IPA export, nor One-Click-Deploy to work, not even in <code>master</code>. There are some differences between our developer account and what external developers use, so it's a bit difficult to pinpoint the problem. We'd appreciate it if anybody that has One-Click-Deploy currently working is able to test on both platforms.</li>
<li>Likewise, we have not tested deploying directly to an iOS device using <code>ios_deploy</code> (used with Xcode versions prior to 14.0). If somebody has a working setup using this, we'd appreciate it if you could test this functionality still works. Alternatively, if <code>ios_deploy</code> support is no longer desired due to its age, we're happy to remove those codepaths for code simplicity.</li>
</ul>
<h2 dir="auto">Missing Functionality</h2>
<ul dir="auto">
<li>The DPI metrics on visionOS are hardcoded for now. They can change at runtime depending on how close the window is to the viewer. We'll address this in the PR adding SwiftUI, as the metrics come from SwiftUI APIs.</li>
<li>We have not implemented building a visionOS Icon Asset Catalog into the exporter. If somebody from the community can step in and implement it, that would be awesome. Otherwise, we may submit this as a later PRs. For now, you can work around this by manually creating your visionOS icon after exporting the Xcode project. <a href="https://developer.apple.com/design/human-interface-guidelines/app-icons" rel="nofollow">Here</a> you can read how visionOS icons work. And here's an example icon showing the Asset Catalog structure: <a href="https://github.com/user-attachments/files/19839704/visionOS-icon.xcassets.zip">visionOS-icon.xcassets.zip</a></li>
<li>The SVG logo for the visionOS platform is just text, it'd be good if somebody could come up with a nice graphic.</li>
</ul>
<hr>
<p dir="auto">We're happy to answer any questions or address any concerns. We're looking forward to collaborating with all of you.</p>
<p dir="auto"><a data-hovercard-type="user" data-hovercard-url="/users/BastiaanOlij/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/BastiaanOlij">@BastiaanOlij</a> <a data-hovercard-type="user" data-hovercard-url="/users/clayjohn/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/clayjohn">@clayjohn</a> <a data-hovercard-type="user" data-hovercard-url="/users/coppolaemilio/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/coppolaemilio">@coppolaemilio</a> <a data-hovercard-type="user" data-hovercard-url="/users/stuartcarnie/hovercard" data-octo-click="hovercard-link-click" data-octo-dimensions="link_type:self" href="https://github.com/stuartcarnie">@stuartcarnie</a> Feel free to mention anybody who would be interested in this change.</p>
    </div>
  </task-lists>
  
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google won't ditch third-party cookies in Chrome after all (108 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/</link>
            <guid>43766803</guid>
            <pubDate>Tue, 22 Apr 2025 22:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/">https://arstechnica.com/gadgets/2025/04/google-wont-ditch-third-party-cookies-in-chrome-after-all/</a>, See on <a href="https://news.ycombinator.com/item?id=43766803">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>Maintaining the status quo</h2>
<p>While Google's sandbox project is looking more directionless today, it is not completely ending the initiative. The team still plans to deploy promised improvements in Chrome's Incognito Mode, which has been re-architected to <a href="https://arstechnica.com/tech-policy/2024/04/google-agrees-to-delete-private-browsing-data-to-settle-incognito-mode-lawsuit/">preserve user privacy</a> after <a href="https://arstechnica.com/tech-policy/2023/12/google-agrees-to-settle-in-chrome-incognito-mode-class-action-lawsuit/">numerous complaints</a>. Incognito Mode blocks all third-party cookies, and later this year, it will gain IP protection, which masks a user's IP address to protect against cross-site tracking.</p>
<figure><p><iframe allow="fullscreen" loading="lazy" src="https://www.youtube.com/embed/BGSGlFP_Sk8?start=0&amp;wmode=transparent"></iframe></p><div>
    
    <p>
      What is Topics?

          </p>
  </div>
</figure>
<p>Chavez admits that this change will mean Google's Privacy Sandbox APIs will have a "different role to play" in the market. That's a kind way to put it. Google will continue developing these tools and will work with industry partners to find a path forward in the coming months. The company still hopes to see adoption of the Privacy Sandbox increase, but the industry is unlikely to give up on cookies voluntarily.</p>
<p>While Google focuses on how ad privacy has improved since it began working on the Privacy Sandbox, the changes in Google's legal exposure are probably more relevant. Since launching the program, Google has lost three antitrust cases, two of which are relevant here: the search case <a href="https://arstechnica.com/tech-policy/2025/04/chrome-on-the-chopping-block-as-googles-search-antitrust-trial-moves-forward/">currently in the remedy phase</a> and the newly decided <a href="https://arstechnica.com/tech-policy/2025/04/google-loses-ad-tech-monopoly-trial-faces-additional-breakups/">ad tech case</a>. As the government begins arguing that Chrome gives Google too much power, it would be a bad look to force a realignment of the advertising industry using the dominance of Chrome.</p>
<p>In some ways, this is a loss—tracking cookies are undeniably terrible, and Google's proposed alternative is better for privacy, at least on paper. However, universal adoption of the Privacy Sandbox could also give Google more power than it already has, and the supposed privacy advantages may never have fully materialized as Google continues to seek higher revenue.</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS Hell (115 pts)]]></title>
            <link>https://csshell.com/</link>
            <guid>43766715</guid>
            <pubDate>Tue, 22 Apr 2025 21:58:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://csshell.com/">https://csshell.com/</a>, See on <a href="https://news.ycombinator.com/item?id=43766715">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Atuin Desktop: Runbooks That Run (391 pts)]]></title>
            <link>https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</link>
            <guid>43766200</guid>
            <pubDate>Tue, 22 Apr 2025 20:54:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.atuin.sh/atuin-desktop-runbooks-that-run/">https://blog.atuin.sh/atuin-desktop-runbooks-that-run/</a>, See on <a href="https://news.ycombinator.com/item?id=43766200">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

    <article>

        <header>

                <a href="https://blog.atuin.sh/tag/news/">News</a>
            
                <p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p>

            <div>
                <p><a href="https://blog.atuin.sh/author/ellie/">
                                <img src="https://blog.atuin.sh/content/images/size/w160/2024/01/me2.jpg" alt="Ellie Huxtable">
                            </a>
                </p>
                
            </div>

            
        </header>

        <section>
            <figure data-kg-thumbnail="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg" data-kg-custom-thumbnail="">
            <div>
                <video src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final.mp4" poster="https://img.spacergif.org/v1/1852x1600/0a/spacer.png" width="1852" height="1600" loop="" autoplay="" muted="" playsinline="" preload="metadata"></video>
                
                <div>
                        <p>
                        
                        <span>0:00</span></p><p>
                            /<span>0:27</span>
                        </p>
                        </div>
            </div>
            
        <img src="https://blog.atuin.sh/content/media/2025/04/atuin-demo-final_thumb.jpg"></figure><p>Most infrastructure is held together by five commands someone remembers when shit breaks. Docs are out of date, if they exist. The real answers? Buried in Slack threads, rotting in Notion, or trapped in someone's shell history.</p><p><a href="https://atuin.sh/?ref=blog.atuin.sh" rel="noreferrer">Atuin CLI</a> fixed part of this, with synced, searchable shell history. But teams need more than history. They need workflows that don't live in someone's head (or their shell).</p><p>Set up. SSH in. Export some variables. Run some commands. Hope nothing breaks. Stuff we do every day, but still have to piece together from fragments of the past, or copy paste from some document somewhere.</p><p>That's why we built the next step.</p><h2 id="introducing-atuin-desktop"><strong>Introducing Atuin Desktop</strong></h2><blockquote>A local-first, executable runbook editor for real terminal workflows</blockquote><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png" width="1581" height="1382" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.28.30.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1000w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.28.30.png 1581w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png" width="1643" height="1386" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-15.27.40.png 1643w" sizes="(min-width: 720px) 720px"></p></div></figure><p>Built to make workflows repeatable, shareable, and reliable.</p><p>Runbooks should run. Workflows shouldn't live in someone's head. Docs shouldn't rot the moment you write them.</p><p>Atuin Desktop looks like a doc, but runs like your terminal. Script blocks, embedded terminals, database clients and prometheus charts - all in one place.</p><ul><li><strong>Kill context switching: </strong>chain shell commands, database queries and HTTP requests</li><li><strong>Docs that don't rot: </strong>execute directly + stay relevant</li><li><strong>Reusable automation: </strong>dynamic runbooks with Jinja-style templating</li><li><strong>Instant recall: </strong>autocomplete from your real shell history</li><li><strong>Local-first, CRDT-powered: </strong>if it runs in your terminal, it runs in a runbook</li><li><strong>Sync and share with Atuin Hub: </strong>up to date, across devices and teams</li></ul><h3 id="how-we-use-it-today">How we use it today</h3><p>We’re already running real-world workflows in Atuin Desktop:</p><ul><li>Releasing Atuin CLI (no more checklist hell)</li><li>Migrating infra safely between environments</li><li>Spinning up staging or prod with confidence</li><li>Managing and collaborating on live database queries</li></ul><p>This is how we ship, manage infra, and collaborate.</p><figure><div><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png" width="1693" height="1554" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.34.29@2x-1.png 1693w" sizes="(min-width: 720px) 720px"></p><p><img src="https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png" width="1688" height="1494" loading="lazy" alt="" srcset="https://blog.atuin.sh/content/images/size/w600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 600w, https://blog.atuin.sh/content/images/size/w1000/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1000w, https://blog.atuin.sh/content/images/size/w1600/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1600w, https://blog.atuin.sh/content/images/2025/04/CleanShot-2025-04-22-at-00.35.39@2x.png 1688w" sizes="(min-width: 720px) 720px"></p></div></figure><h3 id="what%E2%80%99s-next">What’s next</h3><ul><li>Team accounts: true collaborative ops</li><li>Generate runbooks from your shell history. Workflows that write themselves</li></ul><h3 id="get-early-access">Get early access</h3><p>We're rolling out Atuin Desktop now. If you're done copy-pasting from Notion and Slack, or spelunking through shell history, join the <a href="https://wt.ls/atuin?ref=blog.atuin.sh" rel="noreferrer">early access list</a>!</p>
        </section>

    </article>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How long does it take to create a new habit? (2015) (172 pts)]]></title>
            <link>https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/</link>
            <guid>43765084</guid>
            <pubDate>Tue, 22 Apr 2025 18:47:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/">https://thelogicaloptimist.com/index.php/2015/10/25/the-21-day-myth-create-new-habit/</a>, See on <a href="https://news.ycombinator.com/item?id=43765084">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
    	 
        
			<main id="main" role="main">

			
	<article id="post-2478"> 
	
		<div>
		<h3><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg"><img fetchpriority="high" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg" alt="21 day myth" width="954" height="584" srcset="https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth.jpg 954w, https://thelogicaloptimist.com/wp-content/uploads/2015/10/myth-300x184.jpg 300w" sizes="(max-width: 954px) 100vw, 954px"></a></h3>
<h3>In 1960, Dr. Maxwell Maltz published his bestseller book “Psycho-Cybernetics” in which he defines happiness as a habit and claims that “it usually requires a minimum of about 21 days” to form a new habit. The 21 day idea caught on, because 3 weeks is neither too short (that it’s unbelievable), nor too long (that it’s discouraging).</h3>
<p><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-1.jpg"><img decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-1.jpg" alt="21 day myth" width="179" height="267"></a>However, Dr. Maltz was simply making an observation as a plastic surgeon. He was not declaring a statement of fact that is based on research. Also, the phrase “it usually requires a minimum of about 21 days” was propagated without the words “usually”, “minimum” and “about”.</p>
<p><strong>So how long does it really take to create a new habit?</strong></p>
<p>Published in the October 2010 issue of the European Journal of Social Psychology, the research article “How habits are formed: Modelling habit formation in the real world” (Phillippa Lally, et al.) attempted to answer that question. The study examined the habits of 96 people over a period of 12 week, and the data was then analyzed to determine how long it took each person to go from starting a new behavior to automatically doing it. The answer? Not 21 days.</p>
<p>According to Lally’s study, implementing meaningful change in our lives requires 2 to 8 months. The variation is due to the type of habit in question, the person developing it and his/her circumstances. On average it takes 66 days, not just 21. However here’s the good news:</p>
<ol>
<li><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-2.jpg"><img loading="lazy" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-2.jpg" alt="21 day myth" width="337" height="222"></a>The study showed that if you miss an opportunity to perform an action that’s helping you build a habit, there is no significant impact on the habit formation process. In other words, if you fall off the wagon, it doesn’t mean you’ve failed … you can go back and continue trying.</li>
<li>Initially, it takes longer to form a habit and persevere it, but over time, it starts to happen more easily and it requires less effort.</li>
</ol>
<p><strong>So what does this all mean?&nbsp; Well, a couple of things:</strong></p>
<ol>
<li>If you’re trying a new diet, attempting to quit smoking or changing any daily routine, don’t expect new habits to be created in a week, or two or even three.&nbsp; Research suggests that the process requires 66 days (on average) and up to 8 months.</li>
<li>It also means, when trying to make lasting change in your life, be cautious of general claims such as the 21 day rule. False ideas become accepted as fact if repeated too often, but that doesn’t mean they’re true. So, do your research in order to set realistic expectations and avoid future disappointment.</li>
</ol>
<p><strong><a href="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg"><img loading="lazy" decoding="async" src="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg" alt="21 day myth" width="326" height="196" srcset="https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3.jpg 600w, https://thelogicaloptimist.com/wp-content/uploads/2015/10/21-day-3-300x180.jpg 300w" sizes="auto, (max-width: 326px) 100vw, 326px"></a>Change is what you make it out to be</strong></p>
<p>Personally, I would not concern myself with the 21 day rule or even the Lally study. Throughout my years of research on personal transformation, I realized that generalizations are often deceiving.&nbsp; At the end of the day, it doesn’t really matter if it takes you 21, 66 or even a thousand days to create a new habit. What matters is your dedication to making that change happen. Plus, we’re all different and our circumstances vary, so there can never be one timeline that works for every person, even if it’s only a guideline.</p>
<p>I tell my clients: irrespective of how chaotic and difficult life might be, you are the master of your own behaviours. You dictate the when, where and how your habits are created, so focus on the “why” and everything else will fall into place. New habits shouldn’t have timelines … none whatsoever.</p>

				</div><!-- .entry-content -->

		<!-- .entry-footer -->  
	</article><!-- #post-## -->
  

				<!-- .navigation -->
	
			
		
			</main><!-- #main -->
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sapphire: Rust based package manager for macOS (Homebrew replacement) (343 pts)]]></title>
            <link>https://github.com/alexykn/sapphire</link>
            <guid>43765011</guid>
            <pubDate>Tue, 22 Apr 2025 18:39:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alexykn/sapphire">https://github.com/alexykn/sapphire</a>, See on <a href="https://news.ycombinator.com/item?id=43765011">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Sapphire</h2><a id="user-content-sapphire" aria-label="Permalink: Sapphire" href="#sapphire"></a></p>
<blockquote>
<p dir="auto"><strong>WARNING: ALPHA SOFTWARE</strong> &gt; Sapphire is experimental, under heavy development, and may be unstable. Use at your own risk!</p>
<p dir="auto">Uninstalling a cask with brew then reinstalling it with Sapphire will have it installed with slightly different paths, your user settings etc. will not be migrated automatically.</p>
</blockquote>
<p dir="auto">Sapphire is a next‑generation, Rust‑powered package manager inspired by Homebrew. It installs and manages:</p>
<ul dir="auto">
<li><strong>Formulae:</strong> command‑line tools, libraries, and languages</li>
<li><strong>Casks:</strong> desktop applications and related artifacts on macOS</li>
</ul>
<blockquote>
<p dir="auto"><em>ARM only for now, might add x86 support eventually</em></p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ Project Structure</h2><a id="user-content-️-project-structure" aria-label="Permalink: ⚙️ Project Structure" href="#️-project-structure"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><strong>sapphire‑core</strong> Core library: fetching, dependency resolution, archive extraction, artifact handling (apps, binaries, pkg installers, fonts, plugins, zap/preflight/uninstall stanzas, etc.)</p>
</li>
<li>
<p dir="auto"><strong>sapphire‑cli</strong> Command‑line interface: <code>sapphire</code> executable wrapping the core library.</p>
</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚧 Current Status</h2><a id="user-content--current-status" aria-label="Permalink: 🚧 Current Status" href="#-current-status"></a></p>
<ul dir="auto">
<li>Bottle installation and uninstallation</li>
<li>Cask installation and uninstallation</li>
<li>Parallel downloads and installs for speed</li>
<li>Automatic dependency resolution and installation</li>
<li>Building Formulae from source (very early impl)</li>
</ul>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Roadmap</h2><a id="user-content--roadmap" aria-label="Permalink: 🚀 Roadmap" href="#-roadmap"></a></p>
<ol dir="auto">
<li><strong>Upgrade</strong> command to update installed packages</li>
<li><strong>Cleanup</strong> old downloads, versions, caches</li>
<li><strong>Reinstall</strong> command for quick re‑pours</li>
<li><strong>Prefix isolation:</strong> support <code>/opt/sapphire</code> as standalone layout</li>
<li><strong><code>sapphire init</code></strong> helper to bootstrap your environment</li>
<li><strong>Ongoing</strong> Bug fixes and stability improvements</li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 Usage</h2><a id="user-content--usage" aria-label="Permalink: 📦 Usage" href="#-usage"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Print help
sapphire --help

# Update metadata
sapphire update

# Search for packages
sapphire search <formula/cask>

# Get package info
sapphire info <formula/cask>

# Install bottles or casks
sapphire install <formula/cask>

# Build and install a formula from source
sapphire install --build-from-source <formula>

# Uninstall
sapphire uninstall <formula/cask>

# (coming soon)
sapphire upgrade [--all] <name>
sapphire cleanup
sapphire init"><pre><span><span>#</span> Print help</span>
sapphire --help

<span><span>#</span> Update metadata</span>
sapphire update

<span><span>#</span> Search for packages</span>
sapphire search <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Get package info</span>
sapphire info <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Install bottles or casks</span>
sapphire install <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> Build and install a formula from source</span>
sapphire install --build-from-source <span>&lt;</span>formula<span>&gt;</span>

<span><span>#</span> Uninstall</span>
sapphire uninstall <span>&lt;</span>formula/cask<span>&gt;</span>

<span><span>#</span> (coming soon)</span>
sapphire upgrade [--all] <span>&lt;</span>name<span>&gt;</span>
sapphire cleanup
sapphire init</pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🏗️ Building from Source</h2><a id="user-content-️-building-from-source" aria-label="Permalink: 🏗️ Building from Source" href="#️-building-from-source"></a></p>
<p dir="auto"><strong>Prerequisites:</strong> Rust toolchain (stable).</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone <repo-url>
cd sapphire
cargo build --release"><pre>git clone <span>&lt;</span>repo-url<span>&gt;</span>
<span>cd</span> sapphire
cargo build --release</pre></div>
<p dir="auto">The <code>sapphire</code> binary will be at <code>target/release/sapphire</code>. Add it to your <code>PATH</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<p dir="auto">Sapphire lives and grows by your feedback and code! We’re particularly looking for:</p>
<ul dir="auto">
<li>Testing and bug reports for Cask &amp; Bottle installation + <code>--build-from-source</code></li>
<li>Test coverage for core and cask modules</li>
<li>CLI UI/UX improvements</li>
<li>See <a href="https://github.com/alexykn/sapphire/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></li>
</ul>
<p dir="auto">Feel free to open issues or PRs. Every contribution helps!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<ul dir="auto">
<li><strong>Sapphire:</strong> BSD‑3‑Clause - see <a href="https://github.com/alexykn/sapphire/blob/main/LICENSE.md">LICENSE.md</a></li>
<li>Inspired by Homebrew BSD‑2‑Clause — see <a href="https://www.google.com/search?q=NOTICE.md" rel="nofollow">NOTICE.md</a></li>
</ul>
<hr>
<blockquote>
<p dir="auto"><em>Alpha software. No guarantees. Use responsibly.</em></p>
</blockquote>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ping, You've Got Whale: AI detection system alerts ships of whales in their path (129 pts)]]></title>
            <link>https://www.biographic.com/ping-youve-got-whale/</link>
            <guid>43764915</guid>
            <pubDate>Tue, 22 Apr 2025 18:28:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.biographic.com/ping-youve-got-whale/">https://www.biographic.com/ping-youve-got-whale/</a>, See on <a href="https://news.ycombinator.com/item?id=43764915">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><span>From inside a package about the size of a shoebox mounted to a ship’s deck, a set of highly stabilized heat-sensing cameras scans the ocean’s surface. Suddenly, against the misty waves far in the distance, they spot a small puff of white. And another. Now the algorithm catches on. A machine learning system snags the footage and runs it through a neural network trained on millions of similar snippets.&nbsp;&nbsp;</span></p><p><span>Comparing what it’s detecting against its training data, the artificial intelligence model makes a call: that small burst of heat in the distance is a spout of whale breath. The computer system pings a remote expert on standby who double-checks the machine’s work. Within a minute, the expert forwards the alert back to the ship, catching the captain’s attention with enough time for the crew to change course and, hopefully, avoid the whale becoming maritime roadkill.</span></p><p><span>This is WhaleSpotter, an artificial intelligence-powered whale detection system that aims to transmit real-time alerts to ships to prevent them from colliding with whales—a threat that leads to the injury or death of <a href="https://www.washington.edu/news/2024/11/21/whale-ship-collisions/">thousands of whales each year</a>.</span></p></div><div><p><span><em>Video courtesy of WhaleSpotter</em></span></p></div><div><p><span>Led by Daniel Zitterbart, a biophysicist at Woods Hole Oceanographic Institution in Massachusetts, scientists have been testing this new AI-powered but human-verified whale detection system on ferries, research vessels, and cruise ships, and from land-based installations along the east and west coasts of North America, as well as in parts of the Southern Ocean. </span><span>&nbsp;</span></p><p><span>Since WhaleSpotter first got underway during research trials in 2019, its capabilities have grown tremendously. Across its more than two dozen ship- and land-based installations, the global WhaleSpotter network made more than 51,000 marine mammal detections in 2024, up from just 78 its first year. All of those detections were automatically sent to a remote data center in real time, but only a few ships have opted in to receiving the 24/7 alerts.</span></p><p><span>But those ships are modestly sized. And in the quest to save whales from deadly collisions, one of the greatest challenges is protecting them from some of the biggest—and most common—vessels at sea: container ships. </span><span>&nbsp;</span></p><p><span>Strikes from container ships, which are massive and hard to maneuver, are one of the leading causes of death for large whales, according to Zitterbart. Peering out from a cargo ship’s bridge high above the waves, especially at night or in fog, a captain may struggle to see a whale soon enough to shift the course of the vessel, which can easily be 250 meters (800 feet) long. That’s why Zitterbart’s team recently began a research partnership with the Hawai‘i-based Matson Navigation Company to start adapting WhaleSpotter’s technology for this key class of vessels.</span><span>&nbsp;</span></p><p><span>Tailoring WhaleSpotter to work on container ships has required special considerations. Slower and harder to turn, container ships need more advance notice than other craft. However, container ships also tower over the ocean. Making use of the higher vantage point, Zitterbart and his team have been able to increase the distance at which their system can reliably spot whales. Testing longer-range cameras and adjusting the stabilization system on Matson’s container ships plying routes along Hawai‘i, Alaska, and the U.S. west coast, the team found that the technology can now reliably spot marine mammals up to 6 kilometers (nearly 4 miles) away. Matson’s ships are not yet receiving real-time alerts through WhaleSpotter’s systems, but Zitterbart and his colleagues continue fine-tuning their detection system to get it ready for prime time.</span><span>&nbsp;</span></p><p><span>“I think we’re almost there,” says Zitterbart. </span><span>&nbsp;</span></p><p><span>“We are excited by the early results,” adds Keoni Wagner, a Matson spokesperson. “Assuming the system achieves current expectations, we plan to expand use to our entire domestic fleet.”</span></p><p><span>From the perspective of John Calambokidis, a marine biologist with the nonprofit Cascadia Research Collective, there are, broadly, three strategies for reducing incidences of ships hitting whales: shift vessels’ routes, slow them down, and use real-time detection to avoid whales. Calambokidis says the third strategy has not received nearly enough attention, and that Zitterbart’s approach provides an important contribution. “That’s no simple feat,” he says of the expert-reviewed AI approach. He adds that the reliance on thermal cameras—which detect heat rather than light—makes the system particularly useful at night, when <a href="https://www.frontiersin.org/journals/marine-science/articles/10.3389/fmars.2019.00543/full">many whale species are more likely</a> to be near the surface than during the day. </span><span>&nbsp;</span></p><p><span>WhaleSpotter, which has just spun off into <a href="https://whalespotter.ai/">a for-profit company</a>, isn’t the only AI-enhanced thermal camera system able to detect whales. Awarion and SEA.AI can, too. But Zitterbart contends that what sets his technology apart is that WhaleSpotter is purpose-built for marine conservation. As such, he’s adamant about having humans validate the machine’s work. “Many people said, ‘Isn’t that overkill? Can’t we get rid of that?’” Zitterbart says. </span></p><p><span>While the AI system is designed to filter out false alarms—such as signals from birds, breaking waves, and boats—Zitterbart’s aim is for ship captains to receive zero false alerts, so that every ping truly requires their attention. Removing human oversight risks flooding ship captains with false reports, which could lead to frustration and alert fatigue. At risk is the very survival of species like the North Atlantic right whale, an endangered animal that has suffered heavily from ship strikes and has only 370 individuals left: “We cannot afford to ever miss an animal,” he says.</span></p><p><span>Calambokidis emphasizes that preventing collisions between whales and ships requires using multiple, complementary strategies. While Zitterbart readily agrees that WhaleSpotter is no silver bullet, he says it’s particularly suited to certain goals—like limiting the deaths of endangered species. </span></p><p><span>Ultimately, he wants more ships to carry WhaleSpotter cameras. “The true power will come to life once there are hundreds of vessels using this tech,” he says. “Then the collected information can be shared in real time with vessels not using the technology, too.” </span></p><p>Yet as he works to grow WhaleSpotter’s reach, Zitterbart’s focus remains on the animals: “Every single whale that is not struck because of the technology is a success.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The complex origin story of domestic cats (113 pts)]]></title>
            <link>https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html</link>
            <guid>43764771</guid>
            <pubDate>Tue, 22 Apr 2025 18:07:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html">https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html</a>, See on <a href="https://news.ycombinator.com/item?id=43764771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2025/domestic-cat.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2025/domestic-cat.jpg" data-sub-html="Credit: Pixabay/CC0 Public Domain">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2025/domestic-cat.jpg" alt="domestic cat" title="Credit: Pixabay/CC0 Public Domain" width="800" height="530">
             <figcaption>
                Credit: Pixabay/CC0 Public Domain
            </figcaption>        </figure>
    </div><p>Researchers looking into the origin of domestic cats have long considered that cats likely accompanied early farmers during the Neolithic, spreading through Europe alongside the adoption of agriculture.</p>


										      
																																	<p>Two new large-scale investigations, one led by the University of Rome Tor Vergata in collaboration with 42 institutions and another led by the University of Exeter with contributors from 37 institutions, reveal a more complex history than previously imagined. Both point to Tunisia as the likely origin of the domestic cat.</p>
<p>Both studies, which merge extensive genetic data with <a href="https://phys.org/tags/archaeological+evidence/" rel="tag">archaeological evidence</a>, challenge the timeline of European <a href="https://phys.org/tags/domestic+cats/" rel="tag">domestic cats</a>, and hint at cultural and religious factors that may have been pivotal in driving feline domestication and translocation.</p>
<p>Cats have long posed a puzzle for archaeologists. Their skeletal features and commonly used mitochondrial DNA markers can overlap significantly with those of their wild counterparts.</p>
<p>Researchers from the University of Rome Tor Vergata–led team conducted paleogenomic analyses of ancient cat specimens from 97 <a href="https://phys.org/tags/archaeological+sites/" rel="tag">archaeological sites</a> in Europe and Anatolia, as well as museum samples from Italy, Bulgaria, and North Africa.</p>
<p>In their study, "The dispersal of domestic cats from Northern Africa and their introduction to Europe over the last two millennia," <a href="http://biorxiv.org/lookup/doi/10.1101/2025.03.28.645893" target="_blank">published</a> on the <i>bioRxiv</i> preprint server , 70 low-coverage ancient genomes, 17 additional modern and museum genomes, and 37 radiocarbon-dated cat remains were analyzed.</p>

																																						
																																			<p>Results from these nuclear DNA analyses revealed that felines with domestic ancestry only appeared in Europe from around the 1st century CE onward, thousands of years later than traditional narratives suggest.</p>
<p>The Tor Vergata team also identified two introductory waves. An earlier one brought wildcats from Northwest Africa to Sardinia by the 2nd century BCE, giving rise to the island's present-day wild population. A subsequent wave, during the Roman Imperial period, introduced cats genetically similar to modern domestic lines across Europe, pointing towards Tunisia as a key center of early domestication.</p>
<p>In the University of Exeter collaboration study, "Redefining the timing and circumstances of cat domestication, their dispersal trajectories, and the extirpation of European wildcats," also <a href="https://www.biorxiv.org/content/10.1101/2025.03.28.645877v1" target="_blank">published</a> as a preprint on <i>bioRxiv</i>, a slightly different timeline is presented.</p>
<p>By analyzing 2,416 archaeological felid bones across 206 sites and cross-referencing morphological data with genetic findings, they concluded that domestic cats had already appeared in Europe by the early first millennium BCE, before the height of Roman expansion.</p>
<p>Distinct mitochondrial haplogroups were discovered in Britain by the 4th to 2nd centuries BCE, suggesting Iron Age contact, with subsequent waves of introduction occurring during the Roman, Late Antique, and Viking periods. Tunisia is also suggested as the origin point of domestic cats.</p>

																									
																																			<p>Whereas earlier models framed domestication as a primarily commensal relationship, cats as rodent control around <a href="https://phys.org/tags/human+populations/" rel="tag">human populations</a> and grain stores, religious and cultural dimensions emerge from both stories as a driving human interest in cats.</p>
<p>In Egypt, cats were venerated alongside deities such as Bastet, which may have fostered their mummification and movement via religious networks. Cats became symbols of Artemis and Diana in Greek/Roman <a href="https://phys.org/tags/religious+practice/" rel="tag">religious practice</a>, mirroring Bastet's significance in Egypt.</p>
<p>Norse mythology similarly featured cats linked to the goddess Freyja, implying that spiritual and ritual beliefs helped propel cats across wider geographies.</p>
<p>Both studies document admixture and competition between arriving domestic cats and Europe's native wildcats. Evidence points to a decline in wildcat populations beginning in the first millennium CE, potentially related to resource overlap, disease, and hybridization events.</p>
<p>Although the two investigations differ in their proposed arrival dates and dispersal routes for domestic cats, they share a key conclusion that the domestication and spread of cats in Europe happened more recently, and under more culturally driven circumstances, than once thought.</p>
<p>Findings dismantle the considerations that cats were ubiquitous in Neolithic settlements and underscore how previous reliance on mitochondrial markers alone can obscure the full picture of feline domestication.</p>
<p>Taken together, these studies significantly alter our understanding of one of humanity's most familiar companions. Rather than silently trailing behind <a href="https://phys.org/tags/early+farmers/" rel="tag">early farmers</a>, slinking ever closer to human activity and community, cats likely moved into Europe in multiple waves post-domestication from North Africa, propelled by human cultural practices, trade networks, and religious reverence.</p>

																																																					
																				<div>
																						<p><strong>More information:</strong>
												M. De Martino et al, The dispersal of domestic cats from Northern Africa and their introduction to Europe over the last two millennia, <i>biorxiv</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1101/2025.03.28.645893" target="_blank">DOI: 10.1101/2025.03.28.645893</a>
</p><p>Sean Doherty et al, Redefining the timing and circumstances of cat domestication, their dispersal trajectories, and the extirpation of European wildcats, <i>biorxiv</i> (2025). <a data-doi="1" href="https://dx.doi.org/10.1101/2025.03.28.645877" target="_blank">DOI: 10.1101/2025.03.28.645877</a></p>

																						
																						
																					</div>
                               											
																															 <p>
												  © 2025 Science X Network
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												The complex origin story of domestic cats: Research points to Tunisia (2025, April 16)
												retrieved 23 April 2025
												from https://phys.org/news/2025-04-complex-story-domestic-cats-tunisia.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[π0.5: A VLA with open-world generalization (149 pts)]]></title>
            <link>https://pi.website/blog/pi05</link>
            <guid>43764439</guid>
            <pubDate>Tue, 22 Apr 2025 17:29:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pi.website/blog/pi05">https://pi.website/blog/pi05</a>, See on <a href="https://news.ycombinator.com/item?id=43764439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p>Published</p><p>April 22, 2025</p><p>Email</p><p><span>research@physicalintelligence.company</span><span>Kevin Black, Noah Brown, James Darpinian, Karan Dhabalia, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Manuel Galliker, Dibya Ghosh, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Devin LeBlanc, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Allen Ren, Lucy Xiaoyang Shi, Laura Smith, Jost Tobias Springenberg, Kyle Stachowicz, James Tanner, Quan Vuong, Homer Walke, Anna Walling, Haohuan Wang, Lili Yu, Ury Zhilinsky</span></p><p>Paper</p></div>

<div><p>Robots have come a long way over the past few years—they can perform impressive acrobatic feats, dance on stage, follow language commands and, <a href="https://pi.website/blog/pi0">in some of our own results</a>, perform complex tasks like folding laundry or cleaning off a table. But the biggest challenge in robotics is not in performing feats of agility or dexterity, but generalization: the ability to figure out how to correctly perform even a simple task in a new setting or with new objects. Imagine a robot that needs to clean your home: every home is different, with different objects in different places. Generalization must occur at many levels. At the low level, the robot must understand how to pick up a spoon (by the handle) or plate (by the edge), even if it has not seen these specific spoons or plates before, and even if they are placed in a pile of dirty dishes. At a higher level, the robot must understand the semantics of each task—where to put clothes and shoes (ideally in the laundry hamper or closet, not on the bed), and what kind of tool is appropriate for wiping down a spill. This generalization requires both robust physical skills and a common-sense understanding of the environment, so that the robot can generalize at many levels at the same time, from physical, to visual, to semantic. This is made even harder by the limited availability of diverse data for such robotic systems.</p><p>This is why most commercial robots operate in tightly controlled environments like factories or warehouses: in a world where the robot never needs to venture outside of a single building and where the objects and their locations are predetermined, current robotic methods that provide for only weak generalization can be very successful. Even the impressive demonstrations of robotic agility and dexterity that have been shown in recent years are typically designed to work in a specific environment, often with data collected in the test scene or very similar settings. But if we want robots to be part of our everyday lives, working in our homes, grocery stores, offices, hospitals, and other "messy" environments, we need strong generalization.</p><p>We have been developing robotic foundation models that can generalize to such messy environments, building on our vision-language-action (VLA) model <span>π<sub>0</sub></span>. While both <span>π<sub>0</sub></span> and other recent VLAs are evaluated in environments that closely match training, we've developed a new model that we call <span>π<sub>0.5</sub></span> that exhibits meaningful generalization to entirely new environments. We believe that this represents a significant step forward toward truly generalizable physical intelligence. Our current model is far from perfect: its goal is not to accomplish new skills or exhibit high dexterity, but to generalize to new settings, such as cleaning up a kitchen or bedroom in a new home that was not seen in the training data. In our experiments, <span>π<sub>0.5</sub></span> can perform a variety of tasks in entirely new homes. It does not always succeed on the first try, but it often exhibits a hint of the flexibility and resourcefulness with which a person might approach a new challenge.</p><p>The individual tasks that <span>π<sub>0.5</sub></span> performs vary in difficulty, from rearranging objects (e.g., to put dishes in the sink) to much more intricate behaviors, such as using a sponge to wipe down a spill. We show some of the more complex stages in these tasks below, and the videos of the long-horizon behaviors <a href="#long-horizon-videos">later in the post</a>.</p></div>

<div><h3 id="how-does-it-work">How does it work?</h3><p>The main principle behind <span>π<sub>0.5</sub></span> is co-training on heterogeneous data: by training our VLA model on a variety of different data sources, we can teach it not only how to physically perform diverse skills, but also how to understand the semantic context of each skill (e.g., if the task is to clean the kitchen, what are appropriate objects to pick up and put away, and where to put them), infer the high-level structure of a task (e.g., the steps required to make a bed), and even transfer physical behaviors from other robots (e.g., simpler robots that have one arm or no mobile base, or data from robots in less diverse environments).</p><p>Co-training is conceptually straightforward: because VLAs are derived from general vision-language models (VLMs), they can be trained on examples that consist of any combination of actions, images, text, and other multimodal annotations such as bounding boxes. This includes general multimodal tasks, such as image captioning, visual question answering, or object detection, and robotic oriented tasks, such as robotic demonstrations with actions, and "high-level" robot examples, consisting of observations labeled with the appropriate semantic behavior (e.g., an observation of an unmade bed with the label "pick up the pillow"). We also include "verbal instruction" demonstrations, where a person coaches the robot through a complex task by telling it what to do step by step (with natural language). The model makes both high-level inferences about the next semantic step to perform, analogously to chain-of-thought inference, and low-level predictions to output motor commands to the robot's joints:</p></div>

<p>While the basic principles of co-training are not new, training a VLA that can generalize broadly requires the right mixture of co-training tasks. Just like a person needs an appropriate curriculum to teach them the conceptual and practical aspects of a new job, VLAs need a "curriculum" provided by the mixture of co-training tasks to enable generalization at all of the necessary levels of abstraction. In our experiments, we trained versions of the <span>π<sub>0.5</sub></span> model that exclude different parts of the full training mixture: the "no WD" version excludes multimodal <strong>W</strong>eb <strong>D</strong>ata (question-answering, captioning, and object detection), the "no ME" version excludes <strong>M</strong>ultiple <strong>E</strong>nvironment data collected with non-mobile robots (e.g., static robots placed into many other homes), the "no CE" version excludes <strong>C</strong>ross <strong>E</strong>mbodiment data collect as part of the original <span>π<sub>0</sub></span> training set, and the "no ME or CE" version excludes both sources of robot data, leaving only the mobile manipulation data collected with the same robots that we use in our experiments (about 400 hours).</p>
<div><div><div><p>In-distribution Follow Rate</p></div><div><p>In-distribution Success Rate</p></div></div><p>Evaluating the full <span>π<sub>0.5</sub></span> training mixture compared to ablations that exclude various sources of data. Web data (WD) makes the biggest difference for generalizing to out-of-distribution objects, while data from other robots (ME and CE) is important across all evaluation conditions.</p></div>
<div><p>We evaluated two experimental conditions: full cleaning tasks, such as putting away dishes in the sink or cleaning up items off the floor of a bedroom, and an out-of-distribution (OOD) evaluation that tasks the robot to move specific objects indicated in the prompt into a drawer. For both evaluations, we measure the success rate, averaged over individual subtasks (e.g., the percentage of objects that were moved into their proper place), as well as the language following rate, which indicates the fraction of cases where the robot's behavior correctly accords with the user's prompt. We can see that in all cases, data from other robots (ME and CE) makes a big difference in terms of policy performance. In the OOD case, we also see a significant difference from including web data (WD), which greatly improves the robot's ability to correctly identify new object categories that were not in the data. More details on these experiments are included in the <a href="https://pi.website/download/pi05.pdf">accompanying paper</a>.</p><p>To better quantify just how much generalization <span>π<sub>0.5</sub></span> can achieve, we conducted a scaling study where we vary the number of different environments seen in the training data. We also include a baseline model in these comparisons that was trained directly on data from the test environment in addition to all of the other data sources. This model (shown with a horizontal green line) provides a sense for how well a VLA could do in this scene if the challenge of generalizing to new environments is removed.</p></div>
<div><p>Evaluating how performance scales with the number of training environments, when co-training with the other datasets in our training mixture. When using all of the available training environments (rightmost point on the graph), our model (yellow) attains similar performance as a baseline that is trained directly on test environments (green).</p></div>
<div><p>These results not only show that the generalization performance of <span>π<sub>0.5</sub></span> steadily increases with the number of distinct environments in the training set, but that after only about 100 training environments, it actually approaches the performance of the baseline model that was trained on test environment directly. This suggests that our recipe can attain effective generalization using relatively accessible amounts of mobile manipulation training data.</p><h3 id="training-and-inference">Training and inference</h3><p><span>π<sub>0.5</sub></span> is based on the <span>π<sub>0</sub></span> VLA, but because it is co-trained on tasks that require outputting a variety of label types, including actions and text, we can use the same model to control the robot at both the high and low level. When we run <span>π<sub>0.5</sub></span>, we first ask it to output a "high level" action expressed in text, and then ask it to follow this high level action by choosing an appropriate robot motor command, in the form of a 50-step (1-second) "action chunk" of continuous low-level joint actions. This approach follows our recently developed <a href="https://pi.website/research/hirobot">Hi Robot</a> system, except that the same model is used for both the high-level decisions and low-level motor control in a kind of "chain of thought" process.</p><p>The model itself includes both discrete auto-regressive token decoding and continuous decoding via flow matching, as in <span>π<sub>0</sub></span>. The discrete decoding pathway is used for inferring high-level actions, while the continuous flow-matching pathway is used for low-level motor commands, as illustrated in the diagram below.</p></div>

<div><h3 id="generalization-to-new-homes">Generalization to new homes</h3><p>We evaluated <span>π<sub>0.5</sub></span> by asking it to control mobile manipulators to clean new homes that were never seen in the training data. This is an exceptionally difficult test for a VLA: while there have been impressive demonstrations of VLA generalization, such as following new semantic commands, interactively following human instructions, and chaining together distinct primitive skills, such demonstrations typically take place in the same or very similar environment as the training data. Our recent <a href="https://pi.website/research/fast"><span>π<sub>0</sub></span>-FAST model</a> was able to generalize to new environments with the DROID setup, but for relatively simple skills like moving individual objects. Our experiments involved placing a robot equipped with <span>π<sub>0.5</sub></span> into an entirely new home and asking it to put away dishes, make the bed, or clean up a bedroom floor. These are long tasks that require not only using complex behaviors (such as using a sponge to clean a spill), but also understanding the semantics of the task and breaking it down into individual parts, with each stage interacting with the correct object. We show example evaluations of <span>π<sub>0.5</sub></span> in the videos below.</p></div>
<div id="long-horizon-videos"><div><p>Examples of our model completing long-horizon tasks in new kitchens and bedrooms.<!-- --> </p><p><strong>All experiments were done in homes that were not in the training data.</strong></p></div></div>
<p>The policies are reactive, and can handle both variability in the environment and perturbations. In the videos below, we test what happens when people interfere with the robot.</p>

<p>Lastly, the <span>π<sub>0.5</sub></span> model can accept language commands at various levels of granularity, from high-level prompts like "put the dishes in the sink" to detailed individual commands instructing the model to pick up specific objects or move in specific directions. We show some examples of language following in the videos below.</p>
<div><div><p>Our model can follow language commands at various levels of granularity.<br><strong>Yes, you know it by now - all experiments were done in homes that were not in the training data.</strong></p></div><p>We include detailed videos from our rigorous empirical evaluation below, with examples of successful and failed episodes of our model. Importantly, as with all the videos on this page, none of the scenes in the videos below are from the training data. Complete results from all experiments can be found in the <a href="https://pi.website/download/pi05.pdf">full article</a>.</p><h3 id="where-do-we-go-from-here">Where do we go from here?</h3><p>We showed that VLAs can enable broad generalization even for complex and extended robotic skills, like cleaning a kitchen or bedroom. Our <span>π<sub>0.5</sub></span> model can enable a robot to clean a new home that was never seen in the training data. <span>π<sub>0.5</sub></span> is far from perfect, and it often makes mistakes both in terms of its high-level semantic deductions and motor commands. However, by allowing robots to learn from a variety of knowledge sources, we hope that the <span>π<sub>0.5</sub></span> recipe will bring us closer to broadly generalizable and flexible physical intelligence. There is a lot left to do: while our robots can improve from verbal feedback, they could also in the future utilize their autonomous experience to get better with even less supervision, or they could explicitly request help or advice in unfamiliar situations. There is also a lot left to do to improve transfer of knowledge, both in the technical aspects of how the models are structured, and in the diversity of data sources that our models can employ.</p><p>If you are interested in collaborating, please <a href="mailto:collaborate@physicalintelligence.company" target="_blank" data-state="closed">reach out</a>. We are particularly excited to work with companies scaling up data collection with robots deployed for real-world applications, who are looking to collaborate on autonomy.</p><p>We are also hiring! If you'd be interested in <a href="https://pi.website/join-us">joining us</a> please get in touch.</p><p>For researchers interested in our work, collaborations, or other queries, please write to <a href="mailto:research@physicalintelligence.company" target="_blank" data-state="closed">research@physicalintelligence.company</a>.</p></div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Are polynomial features the root of all evil? (2024) (162 pts)]]></title>
            <link>https://alexshtf.github.io/2024/01/21/Bernstein.html</link>
            <guid>43764101</guid>
            <pubDate>Tue, 22 Apr 2025 16:49:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://alexshtf.github.io/2024/01/21/Bernstein.html">https://alexshtf.github.io/2024/01/21/Bernstein.html</a>, See on <a href="https://news.ycombinator.com/item?id=43764101">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
    <h2 id="a-myth">A myth</h2>

<p>When fitting a non-linear model using linear regression, we typically generate new features using non-linear functions. We also know that any function, in theory, can be approximated by a sufficiently high degree polynomial. This result is known as <a href="https://en.wikipedia.org/wiki/Stone%E2%80%93Weierstrass_theorem">Weierstrass approximation theorem</a>. But many blogs, papers, and even books tell us that high polynomials should be avoided. They tend to oscilate and overfit, and regularization doesn’t help! They even scare us with images, such as the one below, when the polynomial fit using the data points (in red) is far away from the true function (in blue):
<img src="https://alexshtf.github.io/assets/poly_overfit.png" alt="Polynomial overfitting"></p>

<p>It turns out that it’s just a MYTH. There’s nothing inherently wrong with high degree polynomials, and in contrast to what is typically taught, high degree polynomials are easily controlled using standard ML tools, like regularization. The source of the myth stems mainly from two misconceptions about polynomials that we will explore here. In fact, not only they are great non-linear features, certain representations also provide us with powerful control over the shape of the function we wish to learn.</p>

<p>A colab notebook with the code for reproducing the above results is available <a href="https://github.com/alexshtf/alexshtf.github.io/blob/master/assets/polyfeatures.ipynb">here</a>.</p>

<h2 id="approximation-vs-estimation">Approximation vs estimation</h2>

<p>Vladimir Vapnik, in his famous book “The Nature of Statistical Learning Theory” which is cited more than 100,000 times as of today, coined the approximation vs. estimation balance. The approximation power of a model is its ability to represent the “reality” we would like to learn. Typically, approximation power increases with the complexity of the model - more parameters mean more power to represent any function to arbitrary precision. Polynomials are no different - higher degree polynomials can represent functions to higher accuracy. However, more parameters make it difficult to <em>estimate these parameters from the data</em>.</p>

<p>Indeed, higher degree polynomials have a higher capacity to approximate arbitrary functions. And since they have more coefficients, these coefficients are harder to estimate from data. But how does it differ from other non-linear features, such as the well-known <a href="https://en.wikipedia.org/wiki/Radial_basis_function">radial basis functions</a>? Why do polynomials have such a bad reputation? Are they truly hard to estimate from data?</p>

<p>It turns out that the primary source is the standard polynomial basis for n-degree polynomials \(\mathbb{E}_n = {1, x, x^2, ..., x^n}\). Indeed, any degree \(n\)  polynomial can be written as a linear combination of these functions:</p><p>

\[\alpha_0 \cdot 1 + \alpha_1 \cdot x + \alpha_2 \cdot x^2 + \cdots + \alpha_n x^n\]

</p><p>But the standard basis \(\mathbb{B}_n\) is <em>awful</em> for estimating polynomials from data. In this post we will explore other ways to represent polynomials that are appropriate for machine learning, and are readily available in standard Python packages. We note, that one advantage of polynomials over other non-linear feature bases is that the only hyperparameter is their <em>degree</em>. There is no “kernel width”, like in radial basis functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>.</p>

<p>The second source of their bad reputation is misunderstanding of Weierstrass’ approximation theorem. It’s usually cited as “polynomials can approximate arbitrary continuous functions”. But that’s not entrely true. They can approximate arbitrary continuous functions <strong>in an interval</strong>. This means that when using polynomial features, the data must be normalized to lie in an interval. It can be done using min-max scaling, computing empirical quantiles, or passing the feature through a sigmoid. But we should avoid the use of polynomials on raw un-normalized features.</p>

<h2 id="building-the-basics">Building the basics</h2>

<p>In this post we will demonstrate fitting the function</p><p>

\[f(x)=\sin(8 \pi x) / \exp(x)+x\]

</p><p>on the interval \([0, 1]\) by fitting to \(m=30\) samples corrupted by Gaussian noise. The following code implements the function and generates samples:</p>

<div><pre><code><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>def</span> <span>true_func</span><span>(</span><span>x</span><span>):</span>
  <span>return</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>8</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>x</span><span>)</span> <span>/</span> <span>np</span><span>.</span><span>exp</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>x</span>

<span>m</span> <span>=</span> <span>30</span>
<span>sigma</span> <span>=</span> <span>0.1</span>

<span># generate features
</span><span>np</span><span>.</span><span>random</span><span>.</span><span>seed</span><span>(</span><span>42</span><span>)</span>
<span>X</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>rand</span><span>(</span><span>m</span><span>)</span>
<span>y</span> <span>=</span> <span>true_func</span><span>(</span><span>X</span><span>)</span> <span>+</span> <span>sigma</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>m</span><span>)</span>
</code></pre></div>

<p>For function plotting, we will use uniformly-spaced points in \([0, 1]\). The following code plots the true function and the sample points:</p>

<div><pre><code><span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>

<span>plt_xs</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>,</span> <span>1000</span><span>)</span>
<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>
<span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_func.png" alt="polyfit_func"></p>

<p>Now let’s fit a polynomial to the sampled points using the standard basis. Namely, we’re given the set of noisy points \(\{ (x_i, y_i) \}_{i=1}^m\), and we need to find the coefficients \(\alpha_0, \dots, \alpha_n\) that minimize:</p><p>

\[\sum_{i=1}^m (\alpha_0 + \alpha_1 x_i + \dots + \alpha_n x_i^n - y_i)^2\]

</p><p>As expected, this is readily accomplished by transforming each sample \(x_i\) to a vector of features \(1, x_i, \dots, x_i^n\), and fitting a linear regression model to the resulting features. Fortunately, NumPy has the <code>numpy.polynomial.polynomial.polyvander</code>function. It takes a vector containing \(x_1, \dots, x_m\) and produces the matrix</p><p>

\[\begin{pmatrix}
1 &amp; x_1 &amp; x_1^2 &amp; \dots &amp; x_1^n \\
1 &amp; x_2 &amp; x_2^2 &amp; \dots &amp; x_2^n \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_m &amp; x_m^2 &amp; \dots &amp; x_m^n \\
\end{pmatrix}\]

</p><p>The name of the function comes from the name of the matrix - the Vandermonde matrix. Let’s use it to fit a polynomial of degree \(n=50\).</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>LinearRegression</span>
<span>import</span> <span>numpy.polynomial.polynomial</span> <span>as</span> <span>poly</span>

<span>n</span> <span>=</span> <span>50</span>
<span>model</span> <span>=</span> <span>LinearRegression</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>
</code></pre></div>

<p>The reason we use <code>fit_intercept=False</code> is because the ‘intercept’ is provided by the first column of the Vandermonde matrix. Now we can plot the function we just fit:</p>

<div><pre><code><span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>As expected, we got the “scary” image from the beginning of this post. Indeed, the standard basis is awful for model fitting! We hope that regularization provides a remedy, but it does not. Maybe adding some L2 regularization helps? Let’s use the <code>Ridge</code> class from the <code>sklearn.linear_model</code>  package to fit an L2 regularized model:</p>

<div><pre><code><span>from</span> <span>sklearn.linear_model</span> <span>import</span> <span>Ridge</span>

<span>reg_coef</span> <span>=</span> <span>1e-7</span>
<span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>reg_coef</span><span>)</span>
<span>model</span><span>.</span><span>fit</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

<span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                                    <span># plot the samples
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                          <span># plot the true function
</span><span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span><span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
<span>plt</span><span>.</span><span>show</span><span>()</span>
</code></pre></div>

<p>We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_standard_ridge.png" alt="polyfit_standard_ridge"></p>

<p>The regularization coefficient coefficient of \(\alpha=10^{-7}\) is large enough to break the model in \([0,0.8]\) but not large enough to avoid over-fitting in \([0.8, 1]\). Increasing the coefficient clearly won’t help - the model will be broken even further in \([0, 0.8]\).</p>

<p>Since we will be trying several polynomial bases, it makes sense to write a more generic function for our experiments that will accept various “Vandermonde” matrix functions of the basis of our choice, fit the polynomial using the <code>Ridge</code> class, and plot it with the original function and the sample points.</p>

<div><pre><code><span>def</span> <span>fit_and_plot</span><span>(</span><span>vander</span><span>,</span> <span>n</span><span>,</span> <span>alpha</span><span>):</span>
  <span>model</span> <span>=</span> <span>Ridge</span><span>(</span><span>fit_intercept</span><span>=</span><span>False</span><span>,</span> <span>alpha</span><span>=</span><span>alpha</span><span>)</span>
  <span>model</span><span>.</span><span>fit</span><span>(</span><span>vander</span><span>(</span><span>X</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>),</span> <span>y</span><span>)</span>

  <span>plt</span><span>.</span><span>scatter</span><span>(</span><span>X</span><span>.</span><span>ravel</span><span>(),</span> <span>y</span><span>.</span><span>ravel</span><span>())</span>                           <span># plot the samples
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>true_func</span><span>(</span><span>plt_xs</span><span>),</span> <span>'blue'</span><span>)</span>                 <span># plot the true function
</span>  <span>plt</span><span>.</span><span>plot</span><span>(</span><span>plt_xs</span><span>,</span> <span>model</span><span>.</span><span>predict</span><span>(</span><span>vander</span><span>(</span><span>plt_xs</span><span>,</span> <span>deg</span><span>=</span><span>n</span><span>)),</span> <span>'r'</span><span>)</span> <span># plot the fit model
</span>  <span>plt</span><span>.</span><span>ylim</span><span>([</span><span>-</span><span>5</span><span>,</span> <span>5</span><span>])</span>
  <span>plt</span><span>.</span><span>show</span><span>()</span>  
</code></pre></div>

<p>Now we can reproduce our latest experiment by invoking:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>poly</span><span>.</span><span>polyvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<h2 id="polynomial-bases">Polynomial bases</h2>

<p>It turns out that in our sister discipline, approximation theory, reseachers also encountered similar difficulties with the standard basis \(\mathbb{E}_n\), and developed a thoery for approximating functions by polynomials from different bases. Two prominent examples of bases of \(n\)-degree polynomials include, and their:</p>

<ol>
  <li>The <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> \(\mathbb{T}_n = \{ T_0, T_1, \dots, T_n \}\), implemented in the <code>numpy.polynomial.chebyshev</code> module.</li>
  <li>The <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomials</a> \(\mathbb{P}_n = \{ P_0, P_1, \dots, P_n \}\), implemented in the <code>numpy.polynomial.legendre</code> module.</li>
</ol>

<p>They are the computational workhorse of a large variety of numerical algorithms that are enabled by approximating a function using a polynomial, and are well-known for their advantages in approximating functions in the \([-1, 1]\) interval<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">2</a></sup>. In particular, the corresponding “Vandermonde” matrices are provided by the <code>chebvander</code> and <code>legvander</code> functions in corresponding modules above. Each row in these matrices contains the value of the basis functions at each point, just like the standard Vandermonde matrix of the standard basis. For example, the Chebyshev Vandermonde matrix is:</p><p>

\[\begin{pmatrix}
T_0(x_1) &amp; T_1(x_1) &amp; \dots &amp; T_n(x_1) \\
T_0(x_2) &amp; T_1(x_2) &amp; \dots &amp; T_n(x_2) \\
\vdots &amp; \vdots  &amp; \ddots&amp; \vdots  \\
T_0(x_m) &amp; T_1(x_m) &amp; \dots &amp; T_n(x_m) \\
\end{pmatrix}\]

</p><p>I will not elaborate their formulas and properties here for a reason that will immediately be revealed. However, I highly recomment Prof. Nick Trefethen’s “Approximation theory and approximation practice” <a href="https://people.maths.ox.ac.uk/trefethen/atapvideos.html">online video course</a> to get familiar with their advantages. His book with the same name is an excellent introduction to the subject.</p>

<p>It might be tempting to try fitting a Chebyshev polynomial using our <code>fit_and_plot</code> method above directly:</p>

<div><pre><code><span>import</span> <span>numpy.polynomial.chebyshev</span> <span>as</span> <span>cheb</span>

<span>fit_and_plot</span><span>(</span><span>cheb</span><span>.</span><span>chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1e-7</span><span>)</span>
</code></pre></div>

<p>However, that’s not the best thing to do. We aim to fit a function sampled from \([0, 1]\), but the Chebyshev basis “lives” in \([-1, 1]\). Therefore, we will add the transformation \(x \to 2x-1\) before invoking the <code>chebvander</code> function:</p>

<div><pre><code><span>def</span> <span>scaled_chebvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
  <span>return</span> <span>cheb</span><span>.</span><span>chebvander</span><span>(</span><span>2</span> <span>*</span> <span>x</span> <span>-</span> <span>1</span><span>,</span> <span>deg</span><span>=</span><span>deg</span><span>)</span>

<span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>1</span><span>)</span>
</code></pre></div>

<p>Note that a different basis requires a different regularization coefficient. We get the following result:</p>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg1.png" alt="polyfit_cheb_reg1"></p>

<p>Whoa! Seems even worse than the standard basis!. Maybe more regularization helps?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>scaled_chebvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>10</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_cheb_reg10.png" alt="polyfit_cheb_reg10"></p>

<p>Appears that our polynomial is both a bad fit for the function, and extremely oscilatory. Even worse when the standard basis! Interested readers can repeat the experiment with Legendre polynomials and see a slightly better, but similar result. So what’s wrong? Is everything that approximation theory tries to teach us about polynomials wrong?</p>

<p>The answer stems from the fundamental difference between two tasks:</p>

<ul>
  <li><strong>Interpolation</strong> - finding a polynomial that agrees with the approximated function \(f(x)\) <em>exactly</em> at a set of <em>carefully chosen</em> points</li>
  <li><strong>Fitting</strong> - finding a polynomial that agrees <em>approximately</em> with a given <em>noisy</em> set of points, which are <em>out of our control</em>.</li>
</ul>

<p>The Chebyshev and Legendre bases perform extremely well at the the interpolation task, but not at the fitting task. It turns out that the polynomial \(T_k\) in the Chebyshev basis, and the polynomial \(P_k\) in the Legendre basis, are both \(k\)-degree polynomials. For example, \(T_1\) is a linear function, whereas \(T_{50}\) is a polynomial of degree 50. These two functions are radically different. Thus, the coefficient of \(T_1\) and \(T_{50}\) have “different units”. This property is shared with the standard basis as well. Thus, we have two issues:</p>

<ol>
  <li>A small change of the coefficient of a high degree basis function, say the coefficient \(\alpha_{50}\), has a huge effect on the shape of the polynomial. Thus, a small perturbation in the input data, be it from noise or a slighly different data point \(x_i\), has a <em>huge</em> effect of the fit model.</li>
  <li>L2 regularization makes no sense! For reasonable functions, the coefficient \(\alpha_{50}\) should be much smaller than the coefficient \(\alpha_1\). This is regardless of the choice of the basis!</li>
</ol>

<p>Both properties show that for the fitting, rather the interpolation tasks we need something else.</p>

<h2 id="the-bernstein-basis">The Bernstein basis</h2>

<p>A remedy is provided by the <a href="https://en.wikipedia.org/wiki/Bernstein_polynomial">Bernstein basis</a> \(\mathbb{B}_n = \{  b_{0,n}, \dots, b_{n, n} \}\). These are \(n\)-degree polynomials defined by on \([0, 1]\) by:</p><p>

\[b_{i,n}(x) = \binom{n}{i} x^i (1-x)^{n-i}\]

</p><p>These polynomials are widely used in computer graphics to approximate curves and surfaces, but it appears that they’re less known in the machine learning community. In fact, all the text you see on the screen when reading this post is rendered using Bernstein polynomials<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">3</a></sup>. We will study them more in depth in the next posts, but at this stage I would like to point out two simple properties that give an intuitive explanation of why they’re useful in machine learning.</p>

<p>First, note that each \(b_{i,n}\) is an \(n\)-degree polynomial. Thus, when representing a polynomial using</p><p>

\[p_n(x) = \alpha_0 b_{0,n}(x) + \alpha_1 b_{1,n}(x) + \dots + \alpha_n b_{n,n}(x),\]

</p><p>all the coefficients have the same “units”.</p>

<p>If the formula of \(b_{i,n}(x)\) seems familiar - you are correct. It is exactly the probability mass function of the binomial distribution for obtaining \(i\) successes in a sequence of trials whose success probability is \(x\). Therefore, \(b_{i,n}(x) \geq 0\),  and \(\sum_{i=0}^n b_{i,n}(x) = 1\) for any \(x \in [0, 1]\). Consequently, the polynomial \(p_n(x)\) is just a weighted average of the coefficients \(\alpha_0, \dots, \alpha_n\). So not only the coefficients have the same “units”, their “units” are also the same as the model’s labels. Thus, they’re much easier to regularize - they’re all on the same “scale”.</p>

<p>Finally, due to the equivalence with the binomial distribution p.m.f, we can implement a “Vandermonde” matrix in Python using the <code>scipy.stats.binom.pmf</code> function.</p>

<div><pre><code><span>from</span> <span>scipy.stats</span> <span>import</span> <span>binom</span>

<span>def</span> <span>bernvander</span><span>(</span><span>x</span><span>,</span> <span>deg</span><span>):</span>
	<span>return</span> <span>binom</span><span>.</span><span>pmf</span><span>(</span><span>np</span><span>.</span><span>arange</span><span>(</span><span>1</span> <span>+</span> <span>deg</span><span>),</span> <span>deg</span><span>,</span> <span>x</span><span>.</span><span>reshape</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>1</span><span>))</span>
</code></pre></div>

<p>Let’s try and fit without regularization at all</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>0</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg0.png" alt="polyfit_bern_reg0"></p>

<p>We see our regular over-fitting. Now let’s see that they’re indeed easy to regularize. After trying several regularization coefficients, I came up with this:</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>50</span><span>,</span> <span>alpha</span><span>=</span><span>5e-7</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_reg5em4.png" alt="polyfit_bern_reg5em4"></p>

<p>Beautiful! This is a polynomial of degree 50! The fit is great, no oscillations, and the misfit near the right endpoint stems from the noise - I don’t believe there’s enough information in the data to convey the fact that it should “curve up” rather than “curve down”.</p>

<p>Let’s see what happens when we crank-up the degree. Can we produce a nice non-oscilating polynomial?</p>

<div><pre><code><span>fit_and_plot</span><span>(</span><span>bernvander</span><span>,</span> <span>n</span><span>=</span><span>100</span><span>,</span> <span>alpha</span><span>=</span><span>5e-4</span><span>)</span>
</code></pre></div>

<p><img src="https://alexshtf.github.io/assets/polyfit_bern_100_reg5em4.png" alt="polyfit_bern_100_reg5em4"></p>

<p>This is a polynomial of degree 100, that does not overfit!</p>

<h2 id="summary">Summary</h2>

<p>The notorious reputation of high-degree polynomials in the machine learning community is primarily a myth. Despite it, papers, books, and blog posts are based on this premise as if it was an axiom. Bernstein polynomials are little known in the machine learning community, but there are a few papers<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup><sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup> using them to represent polynomial features. Their main advantage is ease of use - we can use high degree polynomials to exploit their approximation power, and easily control model complexity with just one hyperparameter - the regularization coefficient.</p>

<p>In the following posts we will explore the Bernstein basis in more detail. We will use it to create polynomial features for real-world datasets and test it versus the standard basis. Moreover, we will see how to regularize the coefficients to control the shape of the function we aim to represent.. For example, what if we know that the function we’re aiming to fit is increasing? Stay tuned!</p>

<hr>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I should have loved biology too (206 pts)]]></title>
            <link>https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</link>
            <guid>43764076</guid>
            <pubDate>Tue, 22 Apr 2025 16:46:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too">https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too</a>, See on <a href="https://news.ycombinator.com/item?id=43764076">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>About a year ago, I came across James Somers’ blog post, </span><em><a href="https://jsomers.net/i-should-have-loved-biology/" rel="">I should have loved biology</a></em><span>. I began reading it and every sentence struck a chord: “I should have loved biology but found it a lifeless recitation of names”; “In textbooks, astonishing facts were presented without astonishment”; “In biology class, biology wasn’t presented as a quest for the secrets of life. The textbooks wrung out the questing.” In fact, the chord was so neatly stuck that I stopped reading about a quarter of the way through, and found myself falling into a memory. I was sitting in my 7th grade biology class, completely disinterested. Every time our teacher would turn her back to us to write on the blackboard, my friends and I would sling paper pellets at each other across the room, barely paying attention as she narrated wearily about cell walls or chloroplasts or mitochondria being the powerhouse of the cell. I liked math and physics and economics and even chemistry, to some extent (much less pellet slinging), but biology, with its endless memorization of definitions and regurgitation of facts – no, biology could go back under the soil it came from.</span></p><p>Now, I’m obsessed. I can’t get enough. I’ve read about fifteen books in the last year or so, watched countless YouTube videos, and started a bioinformatics course. And my list keeps growing. The first quarter of Somers’ post was so effective in making me consider my own disinterest-to-obsession journey – (I didn’t even read the rest until months later) – that I decided to look back and examine what caused this complete change of heart.</p><p><span>More than anything – nature documentaries, science shows, museum visits – it was great writing that allowed me to see the world of biology differently. My interest in biology, or rather the reversal of my disinterest in biology, began when I read </span><em>The Sixth Extinction</em><span> in 2016, during my second year of university. Elizabeth Kolbert’s gripping writing unveiled a completely different perspective of the subject, right alongside the scientists and researchers: driving through a Panamanian rainforest looking for golden frogs, searching a littered New Jersey creek for ammonites, scuba-diving in Castello Aragonese to inspect carbon dioxide rushing out of sea vents and in The Great Barrier Reef to look at octopi and coral reefs and blue starfish and leopard sharks and giant clams. Biology, suddenly, didn’t seem just a list of facts to memorize; it was an adventure.</span></p><p>I still remember how I felt after finishing her book: a strange mix of wonder and tragedy, awe and despair. That narrative structure – vivid reporting and meticulous research built on a foundation of context and history – changed how I saw science and scientists. No more dry paragraphs of definitions and explanations; every discovery had a story.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg" width="1000" height="667" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:667,&quot;width&quot;:1000,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1083159,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F736031ab-8053-410c-a5d3-819ed2ec8935_1000x667.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>The Great Barrier Reef, the world’s largest coral reef system. Elizabeth Kolbert occasionally reports about the impact of climate change there.</figcaption></figure></div><p><span>I wanted more books just like that, and luckily for me, several months later in an airport bookshop in Bangalore, I came across and picked up </span><em>The Gene</em><span>. I wasn’t aware of who Siddhartha Mukherjee was at the time (possibly the mention of Pulitzer Prize winner on the cover influenced me), and I had no prior interest in genetics, but that book would end up completely changing my worldview on biology and non-fiction writing. If Kolbert made a crack in the dam I had built around biology, Mukherjee would go on to smash the whole thing down to pieces.</span></p><p>One of the stories in the book, the discovery of the gene that caused Huntington’s disease, moved me tremendously when I first read it a few years ago. It’s the perfect example of the amount of effort that goes into a scientific discovery that then ends up as a single sentence in a textbook; in this case, that Huntington’s disease is a hereditary, neurodegenerative disorder caused by a mutation in a single gene.</p><p><span>The story of finding that mutation would make a thrilling movie: a young woman named Nancy Wexler, devastated by the news that her mother has been diagnosed with Huntignton’s and that she and her sister would have a 50-50 chance of getting it, decides to devote her life to solving this medical mystery. Her quest takes her from nursing homes in Los Angeles to interdisciplinary scientific workshops in Boston to stilt villages surrounding Lake Maracaibo in Venezuela. Her decade-long blood and skin sample collection efforts there would create the largest family tree with Huntington’s, leading to the first genetic test for the disease, followed by locating the precise genetic mutation that caused it</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-1-158089094" target="_self" rel="">1</a></span><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp" width="1456" height="970" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:970,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:231012,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F33d54e68-df2c-473f-83df-a735abf0c1bd_2048x1365.webp 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Dr. Nancy Wexler in 1990, with a family tree that traced the path of Huntington’s. Acey Harper/The LIFE Collection, via Getty Images. Taken from the New York Times.</figcaption></figure></div><p><span>The gene sequence had a strange repeating structure, CAGCAGCAG… continuing for 17 repeats on average (ranging between 10 to 35 normally), encoding a huge protein that’s found in neurons and testicular tissue (its exact function is still not well understood). The mutation that causes HD increases the number of repeats to more than forty – a “molecular stutter” – creating a longer huntingtin protein, which is believed to form abnormally sized clumps when enzymes in neural cells cut it. The more repeats there are, the sooner the symptoms occur and the higher the severity</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-2-158089094" target="_self" rel="">2</a></span><span>.</span></p><p>Nancy herself opted not to take the genetic test she helped create. “If the test showed I have the gene,” she wrote in 1991, “would I continue to feel the happiness, the passion, the occasional ecstasy I feel now? Is the chance of release from Huntington’s worth the risk of losing joy?”. In 2020, at the age of 74, she revealed that she had Huntington’s. The public acknowledgment was not a surprise for those close to her – for the last decade, they noticed her gait slowly deteriorate, speech slur, and limbs jerk in random directions, the same characteristics she saw in her mother half a century ago, and in the hundreds of Venezuelan patients she tended to ever since.</p><p>There’s still no cure for Huntington’s disease, but every time I hear about progress on cures, I feel a rush of emotions, like I have a personal stake in its invention. I really wish to see one found within Nancy Wexler’s lifetime; this movie deserves a happy ending.</p><p>Pick a field in biology, or a slice of history, and you’ll find countless stories just like this. Mischievous Watson and Crick figuring out the structure of DNA after getting a peek at Rosalind Franklin’s crisp x-ray crystallography photograph; Baruch Blumberg discovering hepatitis B after locating the antigen in the blood of an Australian Aboriginal, and beating NIH to its cure, the world’s first cancer vaccine; James Simpson systematically inhaling various vapors and recording its effects in the search for a better anesthetic, resulting in the discovery of chloroform; Andreas Vesalius taking prisoners’ corpses hanging in the gallows in 16th century Paris and, along with painter Andrea Mategna, publishing nearly 700 incredibly detailed drawings of the human anatomy.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg" width="1200" height="1678" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1678,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:161518,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe22ef74-a63b-41c9-82c1-8f5f0962f3c9_1200x1678.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>An illustration from </span><em>De Humani Corporis Fabrica</em><span> (On the Fabric of the Human Body), published in 1543 by Andreas Vesalius and Andrea Mategna. The first edition included over 200 high-detail anatomical illustrations. I particularly like this one.</span></figcaption></figure></div><p>History and stories may not be immediately applicable, but when used as a key ingredient it makes the discoveries more majestic, more impactful. That’s what I love about Mukherjee’s writing: it’s a unique stew of history, biography, experimental methods and results, scientific findings and their significance, seasoned well with personal anecdotes, and presented with the candor of a physician and the artistry of a poet. The context creates a kind of multiplier when the mind-shattering discoveries are explained – how a genotype gives rise to a phenotype, how cancer works, how a heart beats or a bone mends itself or a brain remembers a memory. Like the climax of a movie scene, the beauty and immensity of the discovery or the invention feels far more compelling after following the steps that got us there.</p><p><span>Every discovery might not have an entertaining backstory, but even when focusing on just the phenomenon, great technical writing has this striking ability to make you see the world differently. The same molecule or cell or organ, theory or experiment or discovery, suddenly seems monumental, like it’s the most important thing in the world. It makes you think: </span><em>why didn’t I learn about this before?</em></p><p><span>One of my favourites is the way Mukherjee describes how a neuron communicates in </span><em>The Song of the Cell</em><span>:</span></p><blockquote><p><em>Imagine the nerve, first, in its “resting” state. At rest, the internal milieu of the neuron contains a high concentration of potassium ions and a minimal concentration of sodium ions. This exclusion of sodium from the neuron’s interior is critical; we might imagine these sodium ions as a throng outside the citadel, locked out of the castle’s walls and banging at the gates to get inside. Natural chemical equilibrium would drive the influx of sodium into the neuron. In its resting state, the cell actively excludes sodium from entry, using energy to drive the ions out…</em></p><p><em>[...] The dendrites are the site within the neuron where the “input” of the signal originates. When a stimulus—typically a chemical called a “neurotransmitter”—arrives at one of the dendrites, it binds to a cognate receptor on the membrane. And it is at this point that the cascade of nerve conduction begins.</em></p><p><em>The binding of the chemical to the receptor causes channels in the membrane to open. The citadel’s gates are thrown ajar, and sodium floods into the cell. As more ions swarm in, the neuron’s net charge changes: every influx of ions generates a small positive pulse. And as more and more transmitters bind, and more such channels open, the pulse increases in amplitude. A cumulative charge courses through the cell body.</em></p></blockquote><p><span>The mental picture of a </span><em>throng</em><span> of sodium ions </span><em>locked out of the castle walls</em><span> is so helpful and convincing. I can see, in my mind’s eye, these shadowy ions</span><em> banging at the gates to get inside</em><span>, like an invading army</span><em>.</em><span> Then, after the neurotransmitter binds to the cognate receptor, the sodium ions don’t just enter, they </span><em>flood</em><span> and </span><em>swarm</em><span> in; the membrane doesn’t just open, its </span><em>gates are thrown ajar</em><span>. The metaphor makes the chemical process relatable without leaving out the details; the vivid language romanticizes it, creating a mental picture that not only stays with you, but makes you want to learn more.</span></p><p>A little later in the chapter, Mukherjee writes about neural connection in the fetus:</p><blockquote><p><em>Neural connections between the eyes and the brain are formed long before birth, establishing the wiring and the circuitry that allow a child to begin visualizing the world the minute she emerges from the womb. Long before the eyelids open, during the early development of the visual system, waves of spontaneous activity ripple from the retina to the brain, like dancers practicing their moves before a performance… This fetal warm-up act—the soldering of neural connections before the eyes actually function—is crucial to the performance of the visual system. The world has to be dreamed before it is seen.</em></p></blockquote><p><span>There’s something about this evocative language that leaves a sweet, lingering imprint on my mind — a new set of neural connections; my own </span><em>throng </em><span>of sodium ions </span><em>banging at the gates</em><span>, my own </span><em>ripples</em><span>. The details – which ions, the name of the receptor – might get murky after the passage of time, but the sweet feeling remains, like a memory of a heavenly meal; you may have forgotten the exact taste, but the feeling of satisfaction lingers, and occasionally, when it enters front and center, you might imagine visiting the restaurant (or home) once more. </span></p><p>That’s what I feel after reading books like this – the belief that I’ll revisit it, relive it, relearn it. It fills up a reservoir of curiosity, and every subsequent piece of stimulus – a neurology article or academic paper shared on Twitter, a documentary or YouTube video, another book (even textbooks) – opens the floodgates, and makes you want to explore a little more. I might not have the equipment to see this cell myself, but when written like this, this world too can be dreamed before it is seen.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg" width="1456" height="2176" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:2176,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1369914,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6fc1a45a-1e78-4f31-8ec1-fa70f76126e4_1927x2880.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Santiago Ramón y Cajal’s famous drawing of neurons, circa late 19th century. He would go on to create more than 2,900 drawings detailing the nervous system’s architecture. Image taken from Quanta Magazine</figcaption></figure></div><p><span>The more you explore, the more astonishing it gets. Suddenly, you’re surrounded by these facts that stop you in your tracks. Like the fact that there are 20-30 trillion red blood cells in our body, making up roughly 84% of all our cells, and 1.2 million are created in our bone marrow every second. Or the fact that our visual system is predictive, calculating where to move the hand to catch a ball before your visual system has fully registered its trajectory</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-3-158089094" target="_self" rel="">3</a></span><span>.</span></p><p><span>One of my favorite ‘sentences that stopped me in my tracks’ comes from Nick Lane’s book, </span><em>The Vital Question</em><span>. He starts with carefully explaining that all cells derive their energy from a single type of chemical reaction, the redox reaction, where electrons are transferred from one molecule to another. Rust is a redox reaction: iron donates electrons to oxygen, being </span><em>oxidized</em><span> in the process. Same with fire: oxygen (O</span><sub>2</sub><span>) is </span><em>reduced</em><span> to water after receiving two electrons (O</span><sup>2-</sup><span>) and then two protons (H</span><sub>2</sub><span>O), balancing the charges, and releasing heat in the process. Respiration — the process that turns our food into energy — does exactly this as well, except that it conserves </span><em>some</em><span> of the energy in the form of a molecule called adenosine triphosphate (ATP). Think of ATP as an energy currency, able to be stored or converted back into energy by splitting the molecule into ADP (adenosine diphosphate) and P</span><sub>i</sub><span> (phospate). And so, he writes, “</span><strong>in the end respiration and burning are equivalent; the slight delay in the middle is what we know as life</strong><em>.”</em></p><p>Wait, what? The slight delay in the middle is what we know as life? I think when I first read that I might have skipped a heartbeat. I learned about mitochondria and ATP and redox reactions and aerobic respiration in high school, but I never pictured it as millions of molecular fires that keep us alive. Actually, not a million; it’s at least a quadrillion – per second. </p><p>ATP is synthesized by the fabled mitochondria, but that’s not all they do. They also regulate metabolism, participate in cell growth and death, manage calcium levels, and are involved in detoxification, hormone production, and cellular signalling. They even have their own genetic code. In fact, your mitochondria come from your mother and your mother only; they’re not genetically recombined like the rest of you. They’re remarkably fascinating; even the universally memed “powerhouse” doesn’t quite cover its capabilities.</p><p>All of this is still merely scratching the surface of wonder. I’ve only really described three examples in biology, all of which relate to human cells. But we’re just one of the millions of organisms on this planet. Bacteria, plants, fungi, insects, birds, reptiles, mammals, and everything in between, are all made up of cells. And every level – ecological, species, organism, tissue, cellular, organelle, protein, genome – has its own stories, each its own magic.</p><p><span>In his blog post, Somers advised to learn in small, deep slices. But I took a different approach: I went shallow and wide. Kolbert, Mukherjee, and Lane inspired exploring adjacent domains, and so I read about epidemiology, drug discovery, gene editing, molecular biology, systems and synthetic biology, immunotherapy, and memoirs from surgeons, cancer patients, and “biology watchers”. Even my fiction choices started to exhibit a biology tinge: </span><em>The Shell Collector</em><span>, </span><em>The Covenant of Water</em><span>, </span><em>The Overstory</em><span>. Eventually, I started seeing biology everywhere — the roots of a sidewalk tree battling with concrete, a group of sparrows frolicking in a bush, a young woman in an air cast fiddling with her crutches — as if it escaped the pages and began whispering its presence wherever I went.</span></p><p>Last summer, I went scuba diving for the first time in my life. I’ve wanted to go since I was a teen, a desire amplified after reading Kolbert’s adventures and watching ocean documentaries. After years and years of postponing, I finally pulled the trigger and flew to Puerto Vallarta to get Open Water certified. I could fill an entire essay with just this certification experience — the anxiety-inducing pre-dive coursework that essentially just lists the many ways you can get seriously injured or die; the silly awkwardness of training in a Mexican hotel pool surrounded by curious onlookers; the ear injury I sustained after my first ocean dive, where a rupture caused by improper depressurization caused middle ear fluid to flood my right ear canal, leaving me with partial hearing loss for a week (even PADI’s intimidating coursework could only do so much) — but I will focus on just the experience of my second dive here.</p><p>It was a picture-perfect day in Puerto Vallarta: deep blue skies, fluffy cotton-candy clouds floating above, a momentary cool breeze tempering the unrelenting summer humidity. As our boat sped along to Playa Majahuitas, about a 40 minutes ride from the main pier, I watched the lush green hills roll by just behind the shore, the ocean shimmering as the sun flung silver disks across its surface. During the ride, I asked the couple sharing the boat about their scuba experiences, and, again, I got a common response I still couldn’t relate to: that it was meditative — it was where your problems of land disappear, and you get to be a visitor in the home of sea-life, a polite guest just observing. </p><p>Our dive spot looked like a painting: water so clear you could see schools of fish just by peering over the edge of the boat. Just before we began, we got a surprise visit from a manta ray – this enormous, ethereal creature silently gliding under the water, just flicking the tips of its wings above the surface, as if to say hello, and welcome us into its home.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg" width="1456" height="1941" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1941,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:2068990,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd786de1d-a8e2-4b8d-907f-91213b90e3b8_3024x4032.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The dive spot in Playa Majahuitas, Mexico</figcaption></figure></div><p>After the dive that day, I understood what the couple meant. I felt a lot more comfortable with my equipment second time around, and so, no longer apprehensive about buoyancy or breathing rate or how deep I was, I finally felt free to fully take in my surroundings. I fell into a gentle rhythm: inhale, listen to the hiss of the regulator, exhale, watch the bubbles float away. You’re distinctly aware of each and every moment, mind blank and in awe of the world around you: a large school of Cortez wrasses passing by; a camouflaged octopus hiding under the seabed; a moray eel sticking its neck out of a little hole, an angry look on its face, as if you’ve just disturbed its sleep; the vast, splendid diversity of corals – you can see it living, with little, wavy hand-like appendages collecting bits of floating food to eat, with tiny fish swimming in and out and around, as if playing a game of tag. </p><p>It was truly marvelous. Colors, too, are more vibrant underwater, as if the gods enhanced saturation as a gift to those that dare venture below. The body of spotted boxfish are a glittery blue, and the yellow speckled top shines in contrast. The corals too are rich: deep oranges, yellows, greens and browns. Even ocean documentaries, with their film-grade color editing, don’t capture the true shades.</p><p>During the boat ride back, I had this incredibly calming bliss completely take over my body. (Maybe that’s also what people attribute to its meditative quality, although meditative isn’t exactly the right word). For me, the whole experience would mark the start of a gradual realization that I wanted my role in biology to be more than just reading. My favorite science writers – Kolbert, Mukherjee, Lane, Lewis Thomas, Donald Kirsch – all wrote from experience, and if I wanted to write, or create, like that, I’d have to experience the world too. I began piecing together the things that had been swimming in my mind: namely, how to combine my past passion, interactive learning, with my latest obsession, biology. </p><p><span>I have since restarted working on my website, </span><a href="https://www.newtinteractive.com/" rel="">Newt Interactive</a><span>, to make interactive articles and accessible simulators for topics in biology. I too, like Somers mentions at the end of his blog post, want to bring the three dimensional nature of biology to life. The subject is teeming with fascinating phenomena that remain hidden or inaccessible to those outside scientific and research communities. Occasionally, I’ll come across something incredible — like a video of a molecular motor in action — but the sheer marvel of that just fundamentally doesn’t click unless you’re already well versed in the subject</span><span><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-4-158089094" href="https://nehalslearnings.substack.com/p/i-should-have-loved-biology-too#footnote-4-158089094" target="_self" rel="">4</a></span><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png" width="1456" height="851" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:851,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1749056,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://nehalslearnings.substack.com/i/158089094?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F46e08242-5854-4c59-9503-7ff62990aef3_3440x2010.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><span>My interactive simulator of a coherent type-1 feed forward loop, a common gene circuit. My hope is that these kinds of playgrounds can make complex topics more accessible. </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">Try it out on Newt Interactive</a></figcaption></figure></div><p><span>I hope to bridge this gap and make some of biology's intricate mechanisms comprehensible and awe-inspiring for everyone. I’ve started with an </span><a href="https://www.newtinteractive.com/series/systems-biology/transcription-network-basics-1" rel="">interactive series on systems biology</a><span> (and wrote about my idea and motivation behind it in a </span><a href="https://nehalslearnings.substack.com/p/a-new-interactive-series-for-systems" rel="">previous post</a><span>), as well as some standalone simulators for a few concepts: </span><a href="https://www.newtinteractive.com/blocks/c1-ffl" rel="">coherent type-1 feed forward loops</a><span> and </span><a href="https://www.newtinteractive.com/blocks/circuit-evolution" rel="">genetic circuit evolution</a><span>, for two. My goal is to work my way up to more sophisticated simulations, tools, and interactive articles that will help illustrate, and importantly, allow you to play with, more advanced concepts. In addition, I’d like to generally write and draw more as well (also started with this by making </span><a href="https://press.asimov.com/articles/gene-circuit" rel="">my first science graphic and biological math model for Asimov Press</a><span>).</span></p><p>Stories of science can elicit all kinds of emotions: joy, sadness, enchantment, heartbreak, optimism, valiance, apprehension, intrigue. I find, however, that one theme seems to be consistent among the characters: curiosity. This shouldn’t come as a surprise, of course, but what I hadn’t anticipated was how infectious it could be. Just reading about these scientists — their history, theories, efforts, mistakes and unwavering dedication to truth — kindled an active curiosity in me. I don’t think I have the patience to do what the scientists I read about did, experimenting day after day, week and week, year after year, exploring a small sliver in the “infinite vastness of biology”. And, since my curiosity started and ended with books, I didn’t think there was a meaningful role I could play. I couldn’t hear the calling.</p><p>But now I’m not so sure. I have this recurring desire to look down a microscope, and see a cell live its life, see its components swimming, squirming, dividing. I want to see a sequencing machine take in an organism’s DNA and spit out all its nucleotide bases; to hold a test-tube with genetic material that I edited with CRISPR-Cas9; to roam around a laboratory and peek at each bench’s weird collection of tools and equipment and liquids, slide my feet across the polished laboratory floor, smell the lingering scent of disinfectant; to go on more dives and hikes and explore the breathtaking diversity of life. It’s not quite a calling, more like hearing a faint ringtone in a distant room. You’re not sure if your phone’s ringing or your mind’s making the sound up. Maybe this time it’s worth taking a look.</p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Rowboat – Open-source IDE for multi-agent systems (112 pts)]]></title>
            <link>https://github.com/rowboatlabs/rowboat</link>
            <guid>43763967</guid>
            <pubDate>Tue, 22 Apr 2025 16:33:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rowboatlabs/rowboat">https://github.com/rowboatlabs/rowboat</a>, See on <a href="https://news.ycombinator.com/item?id=43763967">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/rowboatlabs/rowboat/blob/main/assets/banner.png"><img src="https://github.com/rowboatlabs/rowboat/raw/main/assets/banner.png" alt="ui"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Let AI build multi-agent workflows for you in minutes</h2><a id="user-content-let-ai-build-multi-agent-workflows-for-you-in-minutes" aria-label="Permalink: Let AI build multi-agent workflows for you in minutes" href="#let-ai-build-multi-agent-workflows-for-you-in-minutes"></a></p>

<ul dir="auto">
<li>✨ <strong>Start from an idea -&gt; copilot builds your multi-agent workflows</strong>
<ul dir="auto">
<li>E.g. "Build me an assistant for a food delivery company to handle delivery status and missing items. Include the necessary tools."</li>
</ul>
</li>
<li>🌐 <strong>Connect MCP servers</strong>
<ul dir="auto">
<li>Add the MCP servers in settings -&gt; import the tools into Rowboat.</li>
</ul>
</li>
<li>📞 <strong>Integrate into your app using the HTTP API or Python SDK</strong>
<ul dir="auto">
<li>Grab the project ID and generated API key from settings and use the API.</li>
</ul>
</li>
</ul>
<p dir="auto">Powered by OpenAI's Agents SDK, Rowboat is the fastest way to build multi-agents!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Set your OpenAI key</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=your-openai-api-key"><pre><span>export</span> OPENAI_API_KEY=your-openai-api-key</pre></div>
</li>
<li>
<p dir="auto">Clone the repository and start Rowboat docker</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone git@github.com:rowboatlabs/rowboat.git
cd rowboat
docker-compose up --build"><pre>git clone git@github.com:rowboatlabs/rowboat.git
<span>cd</span> rowboat
docker-compose up --build</pre></div>
</li>
<li>
<p dir="auto">Access the app at <a href="http://localhost:3000/" rel="nofollow">http://localhost:3000</a>.</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo</h2><a id="user-content-demo" aria-label="Permalink: Demo" href="#demo"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Create a multi-agent assistant with MCP tools by chatting with Rowboat</h4><a id="user-content-create-a-multi-agent-assistant-with-mcp-tools-by-chatting-with-rowboat" aria-label="Permalink: Create a multi-agent assistant with MCP tools by chatting with Rowboat" href="#create-a-multi-agent-assistant-with-mcp-tools-by-chatting-with-rowboat"></a></p>
<p dir="auto"><a href="https://youtu.be/YRTCw9UHRbU" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/30795890/436225856-c8a41622-8e0e-459f-becb-767503489866.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzODY1MDMsIm5iZiI6MTc0NTM4NjIwMywicGF0aCI6Ii8zMDc5NTg5MC80MzYyMjU4NTYtYzhhNDE2MjItOGUwZS00NTlmLWJlY2ItNzY3NTAzNDg5ODY2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIzVDA1MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlmM2QzMDY0NGExMGE5N2RkZGVjYjc2MTczZTNlZmM0MTliMGQyMGQ0MzQ3N2FmNThiZjIwYmRkMWZjOTVmZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.T9HThNk1WrCLJtewTpueh_T1h5MRkw6u0l-DHc2hEzk" alt="Screenshot 2025-04-23 at 00 25 31" secured-asset-link=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Integrate with Rowboat agents</h2><a id="user-content-integrate-with-rowboat-agents" aria-label="Permalink: Integrate with Rowboat agents" href="#integrate-with-rowboat-agents"></a></p>
<p dir="auto">There are 2 ways to integrate with the agents you create in Rowboat</p>
<ol dir="auto">
<li>
<p dir="auto">HTTP API</p>
<ul dir="auto">
<li>You can use the API directly at <a href="http://localhost:3000/api/v1/" rel="nofollow">http://localhost:3000/api/v1/</a></li>
<li>See <a href="https://docs.rowboatlabs.com/using_the_api/" rel="nofollow">API Docs</a> for details</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="curl --location 'http://localhost:3000/api/v1/<PROJECT_ID>/chat' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer <API_KEY>' \
--data '{
    &quot;messages&quot;: [
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;tell me the weather in london in metric units&quot;
        }
    ],
    &quot;state&quot;: null
}'"><pre>curl --location <span><span>'</span>http://localhost:3000/api/v1/&lt;PROJECT_ID&gt;/chat<span>'</span></span> \
--header <span><span>'</span>Content-Type: application/json<span>'</span></span> \
--header <span><span>'</span>Authorization: Bearer &lt;API_KEY&gt;<span>'</span></span> \
--data <span><span>'</span>{</span>
<span>    "messages": [</span>
<span>        {</span>
<span>            "role": "user",</span>
<span>            "content": "tell me the weather in london in metric units"</span>
<span>        }</span>
<span>    ],</span>
<span>    "state": null</span>
<span>}<span>'</span></span></pre></div>
</li>
<li>
<p dir="auto">Python SDK
You can use the included Python SDK to interact with the Agents</p>

<p dir="auto">See <a href="https://docs.rowboatlabs.com/using_the_sdk/" rel="nofollow">SDK Docs</a> for details. Here is a quick example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from rowboat import Client, StatefulChat
from rowboat.schema import UserMessage, SystemMessage

# Initialize the client
client = Client(
    host=&quot;http://localhost:3000&quot;,
    project_id=&quot;<PROJECT_ID>&quot;,
    api_key=&quot;<API_KEY>&quot;
)

# Create a stateful chat session (recommended)
chat = StatefulChat(client)
response = chat.run(&quot;What's the weather in London?&quot;)
print(response)

# Or use the low-level client API
messages = [
    SystemMessage(role='system', content=&quot;You are a helpful assistant&quot;),
    UserMessage(role='user', content=&quot;Hello, how are you?&quot;)
]

# Get response
response = client.chat(messages=messages)
print(response.messages[-1].content)"><pre><span>from</span> <span>rowboat</span> <span>import</span> <span>Client</span>, <span>StatefulChat</span>
<span>from</span> <span>rowboat</span>.<span>schema</span> <span>import</span> <span>UserMessage</span>, <span>SystemMessage</span>

<span># Initialize the client</span>
<span>client</span> <span>=</span> <span>Client</span>(
    <span>host</span><span>=</span><span>"http://localhost:3000"</span>,
    <span>project_id</span><span>=</span><span>"&lt;PROJECT_ID&gt;"</span>,
    <span>api_key</span><span>=</span><span>"&lt;API_KEY&gt;"</span>
)

<span># Create a stateful chat session (recommended)</span>
<span>chat</span> <span>=</span> <span>StatefulChat</span>(<span>client</span>)
<span>response</span> <span>=</span> <span>chat</span>.<span>run</span>(<span>"What's the weather in London?"</span>)
<span>print</span>(<span>response</span>)

<span># Or use the low-level client API</span>
<span>messages</span> <span>=</span> [
    <span>SystemMessage</span>(<span>role</span><span>=</span><span>'system'</span>, <span>content</span><span>=</span><span>"You are a helpful assistant"</span>),
    <span>UserMessage</span>(<span>role</span><span>=</span><span>'user'</span>, <span>content</span><span>=</span><span>"Hello, how are you?"</span>)
]

<span># Get response</span>
<span>response</span> <span>=</span> <span>client</span>.<span>chat</span>(<span>messages</span><span>=</span><span>messages</span>)
<span>print</span>(<span>response</span>.<span>messages</span>[<span>-</span><span>1</span>].<span>content</span>)</pre></div>
</li>
</ol>
<p dir="auto">Refer to <a href="https://docs.rowboatlabs.com/" rel="nofollow">Docs</a> to learn how to start building agents with Rowboat.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Morphik – Open-source RAG that understands PDF images, runs locally (155 pts)]]></title>
            <link>https://github.com/morphik-org/morphik-core</link>
            <guid>43763814</guid>
            <pubDate>Tue, 22 Apr 2025 16:18:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/morphik-org/morphik-core">https://github.com/morphik-org/morphik-core</a>, See on <a href="https://news.ycombinator.com/item?id=43763814">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/morphik-org/morphik-core/blob/main/assets/morphik_logo.png"><img alt="Morphik Logo" src="https://github.com/morphik-org/morphik-core/raw/main/assets/morphik_logo.png"></a>
</p>
<p dir="auto">
  <a href="http://makeapullrequest.com/" rel="nofollow"><img alt="PRs Welcome" src="https://camo.githubusercontent.com/3ceeb4c1fe10d0b3dae91b885b84eab5ac4c2fcd2bedd074977740d2ec833e96/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e7376673f7374796c653d736869656c6473" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=shields"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/edd81063d3a0381e47e639ce296ae283493de189db1b412b14e1430959413944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265"><img alt="GitHub commit activity" src="https://camo.githubusercontent.com/edd81063d3a0381e47e639ce296ae283493de189db1b412b14e1430959413944/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265" data-canonical-src="https://img.shields.io/github/commit-activity/m/morphik-org/morphik-core"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/3af2917bb9df9346f5c2321abee02d9d02dabcf450e095354c3030dfb40cf0b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265"><img alt="GitHub closed issues" src="https://camo.githubusercontent.com/3af2917bb9df9346f5c2321abee02d9d02dabcf450e095354c3030dfb40cf0b2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732d636c6f7365642f6d6f727068696b2d6f72672f6d6f727068696b2d636f7265" data-canonical-src="https://img.shields.io/github/issues-closed/morphik-org/morphik-core"></a>
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/9f3aa2be40465db6c4acfc39be5f427e3705b055b2bd737af277da7430bcd702/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d6f727068696b"><img alt="PyPI - Downloads" src="https://camo.githubusercontent.com/9f3aa2be40465db6c4acfc39be5f427e3705b055b2bd737af277da7430bcd702/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f6d6f727068696b" data-canonical-src="https://img.shields.io/pypi/dm/morphik"></a>
  <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow"><img alt="Discord" src="https://camo.githubusercontent.com/3863acac16ccb546452c8227bc440c26a19e45e59dbd7d436442f156e2be13d3/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313333363532343731323831373333323237363f6c6f676f3d646973636f7264266c6162656c3d646973636f7264" data-canonical-src="https://img.shields.io/discord/1336524712817332276?logo=discord&amp;label=discord"></a>
</p>


<p dir="auto">
  <a href="https://docs.morphik.ai/" rel="nofollow">Docs</a> - <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow">Community</a> - <a href="https://docs.morphik.ai/blogs/gpt-vs-morphik-multimodal" rel="nofollow">Why Morphik?</a> - <a href="https://github.com/morphik-org/morphik-core/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md">Bug reports</a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Morphik is an alternative to traditional RAG for highly technical and visual documents.</h2><a id="user-content-morphik-is-an-alternative-to-traditional-rag-for-highly-technical-and-visual-documents" aria-label="Permalink: Morphik is an alternative to traditional RAG for highly technical and visual documents." href="#morphik-is-an-alternative-to-traditional-rag-for-highly-technical-and-visual-documents"></a></p>
<p dir="auto"><a href="https://morphik.ai/" rel="nofollow">Morphik</a> provides developers the tools to ingest, search (deep and shallow), transform, and manage unstructured and multimodal documents. Some of our features include:</p>
<ul dir="auto">
<li><a href="https://docs.morphik.ai/concepts/colpali" rel="nofollow">Multimodal Search</a>: We employ techniques such as ColPali to build search that actually <em>understands</em> the visual content of documents you provide. Search over images, PDFs, videos, and more with a single endpoint.</li>
<li><a href="https://docs.morphik.ai/concepts/knowledge-graphs" rel="nofollow">Knowledge Graphs</a>: Build knowledge graphs for domain-specific use cases in a single line of code. Use our battle-tested system prompts, or use your own.</li>
<li><a href="https://docs.morphik.ai/concepts/rules-processing" rel="nofollow">Fast and Scalable Metadata Extraction</a>: Extract metadata from documents - including bounding boxes, labeling, classification, and more.</li>
<li><a href="https://docs.morphik.ai/integrations" rel="nofollow">Integrations</a>: Integrate with existing tools and workflows. Including (but not limited to) Google Suite, Slack, and Confluence.</li>
<li><a href="https://docs.morphik.ai/python-sdk/create_cache" rel="nofollow">Cache-Augmented-Generation</a>: Create persistent KV-caches of your documents to speed up generation.</li>
</ul>
<p dir="auto">The best part? Morphik has a <a href="https://www.morphik.ai/pricing" rel="nofollow">free tier</a> and is open source! Get started by signing up at <a href="https://www.morphik.ai/signup" rel="nofollow">Morphik</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#getting-started-with-morphik-recommended">Getting Started with Morphik</a></li>
<li><a href="#self-hosting-the-open-source-version">Self-hosting the open-source version</a></li>
<li><a href="#using-morphik">Using Morphik</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#open-source-vs-paid">Open source vs paid</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started with Morphik (Recommended)</h2><a id="user-content-getting-started-with-morphik-recommended" aria-label="Permalink: Getting Started with Morphik (Recommended)" href="#getting-started-with-morphik-recommended"></a></p>
<p dir="auto">The fastest and easiest way to get started with Morphik is by signing up for free at <a href="https://www.morphik.ai/signup" rel="nofollow">Morphik</a>. Your first 200 pages and 100 queries are on us! After this, you can pay based on usage with discounted rates for heavier use.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Self-hosting the open-source version</h2><a id="user-content-self-hosting-the-open-source-version" aria-label="Permalink: Self-hosting the open-source version" href="#self-hosting-the-open-source-version"></a></p>
<p dir="auto">If you'd like to self-host Morphik, you can find the dedicated instruction <a href="https://docs.morphik.ai/getting-started" rel="nofollow">here</a>. We offer options for direct isntallation and installation via docker.</p>
<p dir="auto"><strong>Important</strong>: Due to limited resources, we cannot provide full support for open-source deployments. We have an installation guide, and a <a href="https://discord.gg/BwMtv3Zaju" rel="nofollow">Discord community</a> to help, but we can't guarantee full support.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Using Morphik</h2><a id="user-content-using-morphik" aria-label="Permalink: Using Morphik" href="#using-morphik"></a></p>
<p dir="auto">Once you've signed up for Morphik, you can get started with ingesting and search your data right away.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Code (Example: Python SDK)</h3><a id="user-content-code-example-python-sdk" aria-label="Permalink: Code (Example: Python SDK)" href="#code-example-python-sdk"></a></p>
<p dir="auto">For programmers, we offer a <a href="https://docs.morphik.ai/python-sdk/morphik" rel="nofollow">Python SDK</a> and a <a href="https://docs.morphik.ai/api-reference/health-check" rel="nofollow">REST API</a>. Ingesting a file is as simple as:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from morphik import Morphik

morphik = Morphik(&quot;<your-morphik-uri>&quot;)
morphik.ingest_file(&quot;path/to/your/super/complex/file.pdf&quot;)"><pre><span>from</span> <span>morphik</span> <span>import</span> <span>Morphik</span>

<span>morphik</span> <span>=</span> <span>Morphik</span>(<span>"&lt;your-morphik-uri&gt;"</span>)
<span>morphik</span>.<span>ingest_file</span>(<span>"path/to/your/super/complex/file.pdf"</span>)</pre></div>
<p dir="auto">Similarly, searching and querying your data is easy too:</p>
<div dir="auto" data-snippet-clipboard-copy-content="morphik.query(&quot;What's the height of screw 14-A in the chair assembly instructions?&quot;)"><pre><span>morphik</span>.<span>query</span>(<span>"What's the height of screw 14-A in the chair assembly instructions?"</span>)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Morphik Console</h3><a id="user-content-morphik-console" aria-label="Permalink: Morphik Console" href="#morphik-console"></a></p>
<p dir="auto">You can also interact with Morphik via the Morphik Console. This is a web-based interface that allows you to ingest, search, and query your data. You can upload files, connect to different data sources, and chat with your data all within the same place.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Model Context Protocol</h3><a id="user-content-model-context-protocol" aria-label="Permalink: Model Context Protocol" href="#model-context-protocol"></a></p>
<p dir="auto">Finally, you can also access Morphik via MCP. Instructions are available <a href="https://docs.morphik.ai/using-morphik/mcp" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You're welcome to contribute to the project! We love:</p>
<ul dir="auto">
<li>Bug reports via <a href="https://github.com/morphik-org/morphik-core/issues">GitHub issues</a></li>
<li>Feature requests via <a href="https://github.com/morphik-org/morphik-core/issues">GitHub issues</a></li>
<li>Pull requests</li>
</ul>
<p dir="auto">Currently, we're focused on improving speed, integrating with more tools, and finding the research papers that provide the most value to our users. If you ahve thoughts, let us know in the discord or in GitHub!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Open source vs paid</h2><a id="user-content-open-source-vs-paid" aria-label="Permalink: Open source vs paid" href="#open-source-vs-paid"></a></p>
<p dir="auto">Certain features - such as Morphik Console - are not available in the open-source version. Any feature in the <code>ee</code> namespace is not available in the open-source version and carries a different license. Any feature outside that is open source under the MIT expat license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors</h2><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<p dir="auto">Visit our special thanks page dedicated to our contributors <a href="https://docs.morphik.ai/special-thanks" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">PS</h2><a id="user-content-ps" aria-label="Permalink: PS" href="#ps"></a></p>
<p dir="auto">We took inspiration from <a href="https://posthog.com/" rel="nofollow">PostHog</a> while writing this README. If you're from PostHog, thank you ❤️</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ClickHouse gets lazier (and faster): Introducing lazy materialization (278 pts)]]></title>
            <link>https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</link>
            <guid>43763688</guid>
            <pubDate>Tue, 22 Apr 2025 16:03:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization</a>, See on <a href="https://news.ycombinator.com/item?id=43763688">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine if you could skip packing your bags for a trip because you find out at the airport you’re not going. That’s what ClickHouse is doing with data now.</p>
<p>ClickHouse is one of the fastest analytical databases available, and much of that speed comes from avoiding unnecessary work. The less data it scans and processes, the faster queries run. Now it pushes this idea even further with a new optimization: lazy materialization, which delays reading column data until it’s actually needed.</p>
<p>This seemingly "lazy" behavior turns out to be extremely effective in real-world workloads, especially for <code>Top N</code> queries that sort large datasets and apply <code>LIMIT</code> clauses, a common pattern in observability and general analytics. In these scenarios, lazy materialization can dramatically accelerate performance, often by orders of magnitude.</p>
<blockquote>
<p><strong>Spoiler alert</strong>: We’ll show you how a ClickHouse query went from 219 seconds to just 139 milliseconds—<strong>a 1,576× speedup</strong>—without changing a single line of SQL. Same query. Same table. Same machine. The only thing that changed? When ClickHouse reads the data.</p>
</blockquote>
<p>In this post, we’ll walk through how lazy materialization works and how it fits into ClickHouse’s broader I/O optimization stack. To give a complete picture, we’ll also briefly demonstrate the other key building blocks of I/O efficiency in ClickHouse, highlighting not just what lazy materialization does, but how it differs from and complements the techniques already in place.</p>
<p>We’ll begin by describing the core I/O-saving techniques ClickHouse already uses, then run a real-world query through them, layer by layer, until lazy materialization kicks in and changes everything.</p>

<p>Over the years, ClickHouse has introduced a series of layered optimizations to aggressively reduce I/O. These techniques form the foundation of its speed and efficiency:</p>
<ul>
<li>
<p><strong><a href="https://clickhouse.com/docs/parts">Columnar storage</a></strong> allows skipping entire columns that aren’t needed for a query and also enables high compression by grouping similar values together, minimizing I/O during data loading.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/primary-indexes">Sparse primary indexes</a></strong>, <strong><a href="https://clickhouse.com/docs/optimize/skipping-indexes">secondary data-skipping indexes</a></strong>, and <strong><a href="https://clickhouse.com/docs/data-modeling/projections">projections</a></strong> prune irrelevant data by identifying which <strong>granules</strong> (row blocks) might match filters on <em>indexed columns</em>. These techniques operate at the granule level and can be used individually or in combination.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a></strong> checks matches also for filters on <em>non-indexed</em> columns to skip data early that would otherwise be loaded and discarded. It can work independently or refine the granules selected by indexes, complementing granule pruning by skipping rows that don’t match <em>all</em> column filters.</p>
</li>
<li>
<p><strong><a href="https://clickhouse.com/blog/introducing-the-clickhouse-query-condition-cache">The query condition cache (deep dive)</a></strong> speeds up repeated queries by remembering which granules matched all filters last time. ClickHouse can then skip reading and filtering granules that didn’t match, even if the query shape changes. Since it simply caches the result of index and PREWHERE filtering, we won’t cover it further here.  <strong>We disabled it in all tests below to avoid skewing results.</strong></p>
</li>
</ul>
<blockquote>
<p>These techniques, including the lazy materialization introduced below, reduce I/O <em>during</em> query processing, which is the focus of this post. An orthogonal approach is to reduce table size (and query work) upfront by precomputing results with <a href="https://clickhouse.com/docs/materialized-view/incremental-materialized-view">incremental</a> or <a href="https://clickhouse.com/docs/materialized-view/refreshable-materialized-view">refreshable</a> <strong>materialized views</strong>, which we won’t cover here.</p>
</blockquote>

<p>While the aforementioned I/O optimizations can significantly reduce data read, they still assume that all columns for rows passing the <code>WHERE</code> clause must be loaded before running operations like sorting, aggregation, or <code>LIMIT</code>. But what if some columns aren’t needed until later, or some data, despite passing the <code>WHERE</code> clause, is never needed at all?</p>
<p>That’s where <strong>lazy materialization</strong> comes in. An orthogonal enhancement that completes the I/O optimization stack:</p>
<ul>
<li>
<p>Indexing, together with PREWHERE, ensures that only rows matching column filters in the <code>WHERE</code> clause are processed.</p>
</li>
<li>
<p>Lazy materialization builds on this by deferring column reads until they’re actually required by the query execution plan. Even after filtering, only the columns needed for the next operation—such as sorting—are loaded immediately. Others are postponed and, due to <code>LIMIT</code>, are often read only partially, just enough to produce the final result. This makes lazy materialization especially powerful for <em>Top N</em> queries, where the final result may only require a handful of rows from certain, often large, columns.</p>
</li>
</ul>
<blockquote>
<p>This kind of fine-grained column processing is only possible because ClickHouse stores each column independently. In <a href="https://clickhouse.com/engineering-resources/what-is-columnar-database#row-based-vs-column-based">row-oriented</a> databases, where all columns are read together, this level of deferred I/O simply isn’t feasible.</p>
</blockquote>
<p>To demonstrate its impact, we’ll now walk through a real-world example and show how each layer of optimization plays a role.</p>

<p>We’ll use the <a href="https://clickhouse.com/docs/getting-started/example-datasets/amazon-reviews">Amazon customer reviews</a> dataset, which has around 150 million product reviews from 1995 to 2015.</p>
<p>
We’re running ClickHouse 25.4 on an AWS <code>m6i.8xlarge</code> EC2 instance with:<br>
• 32 vCPUs<br>
• 128 GiB RAM<br>
• 1 TiB gp3 SSD (with default settings: 3000 IOPS, 125 MiB/s max throughput 🐌)<br>
• Ubuntu Linux 24.04
</p>
<p>On that machine, we first created the Amazon reviews table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews
</span></span></span><span>(
<span></span></span><span><span>    `review_date` </span><span><span>Date</span><span> CODEC(ZSTD(</span><span>1</span><span>)),
</span></span></span><span><span>    `marketplace` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `customer_id` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_id` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_parent` UInt64 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_title` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `product_category` LowCardinality(String) CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `star_rating` UInt8 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `helpful_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `total_votes` UInt32 CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `vine` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `verified_purchase` Bool CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_headline` String CODEC(ZSTD(</span><span><span>1</span><span>)),
</span></span></span><span><span>    `review_body` String CODEC(ZSTD(</span><span><span>1</span><span>))
</span></span></span><span>)
<span></span></span><span><span>ENGINE </span><span><span>=</span><span> MergeTree
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> (review_date, product_category);</span></span></span></code></pre></div></pre>
<p>And then loaded the dataset from Parquet files hosted in our public example datasets S3 bucket:</p>
<pre><div><pre><code><span><span>INSERT</span><span><span> </span><span>INTO</span><span>  amazon.amazon_reviews
</span></span></span><span><span></span><span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> s3Cluster(</span><span>'default'</span><span>, </span><span>'https://datasets-documentation.s3.eu-west-3.amazonaws.com/amazon_reviews/amazon_reviews_*.snappy.parquet'</span><span>);</span></span></span></code></pre></div></pre>
<p>We check the table’s size after loading:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    formatReadableQuantity(</span><span><span>sum</span><span>(</span><span>rows</span><span>)) </span><span>AS</span><span> </span><span>rows</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.parts
</span></span></span><span><span></span><span><span>WHERE</span><span> active </span><span>AND</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─rows───────────┬─data_size─┬─compressed_size─┐
</span><span></span></span><span>│ 150.96 million │ 70.47 GiB │ 30.05 GiB       │
<span></span></span><span>└────────────────┴───────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>After loading, the table contains ~150 million rows and:</p>
<ul>
<li>70 GiB uncompressed data</li>
<li>~30 GiB compressed on disk using ZSTD(1)</li>
</ul>

<p>150 million rows is hardly a challenge for ClickHouse. For example, this query sorts all 150 million values in the <code>helpful_votes</code> column (which isn’t part of the table’s sort key) and returns the top 3, in just 70 milliseconds cold (with the OS filesystem cache <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cleared</a> beforehand) and a processing throughput of 2.15 billion rows/s:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> helpful_votes
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─helpful_votes─┐
</span><span></span></span><span>│         47524 │
<span></span></span><span>│         41393 │
<span></span></span><span>│         41278 │
<span></span></span><span>└───────────────┘
<span></span></span><span>
<span></span></span><span>3 rows in set. Elapsed: 0.070 sec. Processed 150.96 million rows, 603.83 MB (2.15 billion rows/s., 8.61 GB/s.)
<span></span></span><span>Peak memory usage: 3.59 MiB.<span></span></span></code></pre></div></pre>
<p>Note that the query doesn’t benefit from indexing, PREWHERE, or other I/O reduction techniques, since it has no filters. But thanks to columnar storage, ClickHouse only reads the <code>helpful_votes</code> column and skips the rest.</p>
<p>Here’s another example query that simply selects (with cold filesystem cache) all data from a single <code>review_body</code> column:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> review_body
</span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Query id: b9566386-047d-427c-a5ec-e90bee027b02
</span><span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 176.640 sec. Processed 150.96 million rows, 56.02 GB (854.61 thousand rows/s., 317.13 MB/s.)
<span></span></span><span>Peak memory usage: 733.14 MiB.<span></span></span></code></pre></div></pre>
<p>😱 Almost 3 minutes! Despite reading just a single column.</p>
<p>But the bottleneck wasn’t ClickHouse, it was the disk’s throughput. This query scanned a much larger column, 56 GB vs. 600 MB in the previous example. On our test machine, which has a <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#test-setup-dataset-and-machine">relatively slow disk</a> and 32 CPU cores, ClickHouse used 32 <a href="https://clickhouse.com/docs/optimize/query-parallelism">parallel streams</a> to read the data. The <a href="https://clickhouse.com/docs/operations/system-tables/query_log">query log</a> confirms that the majority of the 3-minute runtime was spent <a href="https://github.com/ClickHouse/ClickHouse/blob/9d60aa01a83346648eae5dc9572530388271f7b0/src/Common/ProfileEvents.cpp#L101">waiting on the read syscall</a>:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span> 
</span></span></span><span><span>  round(ProfileEvents[</span><span><span>'DiskReadElapsedMicroseconds'</span><span>] </span><span>/</span><span> </span><span>1e6</span><span>) </span><span>AS</span><span> disk_read_seconds,
</span></span></span><span><span>  ProfileEvents[</span><span><span>'ConcurrencyControlSlotsAcquired'</span><span>] </span><span>AS</span><span> parallel_streams,
</span></span></span><span><span>  formatReadableTimeDelta(round(disk_read_seconds </span><span><span>/</span><span> parallel_streams), </span><span>'seconds'</span><span>) </span><span>AS</span><span> time_per_stream
</span></span></span><span><span></span><span><span>FROM</span><span> system.query_log
</span></span></span><span><span></span><span><span>WHERE</span><span> query_id </span><span>=</span><span> </span><span>'b9566386-047d-427c-a5ec-e90bee027b02'</span><span> 
</span></span></span><span><span>  </span><span><span>AND</span><span> type </span><span>=</span><span> </span><span>'QueryFinish'</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─disk_read_seconds─┬─parallel_streams─┬─time_per_stream─┐
</span><span></span></span><span>│              5512 │               32 │ 172 seconds     │
<span></span></span><span>└───────────────────┴──────────────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>Clearly, brute-force scans aren’t ideal, especially with cold caches. Let’s give ClickHouse something to work with.</p>

<p>Despite the airport <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization">drama</a>, I’m still set on that beach holiday, and that means loading my eReader with only the best. So I ask ClickHouse to help me find the most helpful 5-star verified reviews for digital ebook purchases since 2010, showing the number of helpful votes, book title, review headline, and the review itself:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical;<span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   6376
<span></span></span><span>product_title:   Wheat Belly: Lose the Wheat, Lose the Weight, and Find Your Path Back to Health
<span></span></span><span>review_headline: Overweight? Diabetic? Got High Blood Pressure, Arthritis? Get this Book!
<span></span></span><span>review_body:     I've been following Dr. Davis' heart scan blog for the past ...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   4149
<span></span></span><span>product_title:   The Life-Changing Magic of Tidying Up: The Japanese Art of Decluttering and Organizing
<span></span></span><span>review_headline: Truly life changing
<span></span></span><span>review_body:     I rarely write reviews, but this book truly sparked somethin...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   2623
<span></span></span><span>product_title:   The Fast Metabolism Diet: Eat More Food and Lose More Weight
<span></span></span><span>review_headline: Fantastic Results **UPDATED 1/23/2015**
<span></span></span><span>review_body:     I have been on this program for 7 days so far.  I know it ma...<span></span></span></code></pre></div></pre>
<p>The query above selects four columns, including three (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) of the largest in the table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span><span>    name </span><span><span>as</span><span> </span><span>column</span><span>,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_uncompressed_bytes)) </span><span>AS</span><span> data_size,
</span></span></span><span><span>    formatReadableSize(</span><span><span>sum</span><span>(data_compressed_bytes)) </span><span>AS</span><span> compressed_size
</span></span></span><span><span></span><span><span>FROM</span><span> system.columns
</span></span></span><span><span></span><span><span>WHERE</span><span> database </span><span>=</span><span> </span><span>'amazon'</span><span> </span><span>AND</span><span> </span><span>table</span><span> </span><span>=</span><span> </span><span>'amazon_reviews'</span><span>
</span></span></span><span><span></span><span><span>GROUP</span><span> </span><span>BY</span><span> name
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>sum</span><span>(data_uncompressed_bytes) </span><span>DESC</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>┌─column────────────┬─data_size──┬─compressed_size─┐
</span><span></span></span><span>│ review_body       │ 51.13 GiB  │ 21.60 GiB       │
<span></span></span><span>│ product_title     │ 8.12 GiB   │ 3.53 GiB        │
<span></span></span><span>│ review_headline   │ 3.38 GiB   │ 1.58 GiB        │
<span></span></span><span>│ review_id         │ 2.07 GiB   │ 1.35 GiB        │
<span></span></span><span>│ product_id        │ 1.55 GiB   │ 720.97 MiB      │
<span></span></span><span>│ customer_id       │ 1.12 GiB   │ 524.35 MiB      │
<span></span></span><span>│ product_parent    │ 1.12 GiB   │ 571.63 MiB      │
<span></span></span><span>│ helpful_votes     │ 575.86 MiB │ 72.11 MiB       │
<span></span></span><span>│ total_votes       │ 575.86 MiB │ 83.50 MiB       │
<span></span></span><span>│ review_date       │ 287.93 MiB │ 239.43 KiB      │
<span></span></span><span>│ marketplace       │ 144.51 MiB │ 414.92 KiB      │
<span></span></span><span>│ product_category  │ 144.25 MiB │ 838.96 KiB      │
<span></span></span><span>│ star_rating       │ 143.96 MiB │ 41.99 MiB       │
<span></span></span><span>│ verified_purchase │ 143.96 MiB │ 20.50 MiB       │
<span></span></span><span>│ vine              │ 1.75 MiB   │ 844.89 KiB      │
<span></span></span><span>└───────────────────┴────────────┴─────────────────┘<span></span></span></code></pre></div></pre>
<p>The example query touches 60+ GiB of (uncompressed) data. As we showed earlier, even with 32 parallel streams, just reading that from the (relatively slow) disk would take 3+ minutes with a cold cache.</p>
<p>But the query includes filters on multiple columns (<code>review_date</code>, <code>product_category</code>, <code>verified_purchase</code>, and <code>star_rating</code>), plus a <code>LIMIT</code> applied after sorting by <code>helpful_votes</code>. This is the perfect setup for ClickHouse’s layered I/O optimizations:</p>
<ul>
<li>
<p><strong>Indexing</strong> prunes rows that don’t match filters on the primary/sorting key (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p><strong>PREWHERE</strong> pushes filtering deeper and prunes rows that don’t match <em>all</em> column filters.</p>
</li>
<li>
<p><strong>Lazy materialization</strong> delays loading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until they’re actually needed—after sorting and applying <code>LIMIT</code>. Ideally, most of that large column data is never read at all.</p>
</li>
</ul>
<p>Each layer cuts down I/O further. Together, they reduce data read, memory use, and query time. Let’s see how much of a difference that makes, one layer at a time.</p>

<p>In the following sections, we clear the OS-level filesystem (page) cache before each query run using</p>
<p><code>echo 3 | sudo tee /proc/sys/vm/drop_caches &gt;/dev/null</code>.</p>
<p>on the Linux command line. This simulates the worst-case scenario and ensures the results reflect actual disk reads, not cached data.</p>
<!-- -->

<p>Before we bring in the optimizations, let’s see what happens when ClickHouse runs the query without any shortcuts—no indexing, no PREWHERE, no lazy materialization.</p>
<p>To do this, we run the example query on a version of the table without a sorting/primary key, meaning it won’t benefit from any index-based optimizations. The following command creates that baseline table:</p>
<pre><div><pre><code><span><span>CREATE</span><span><span> </span><span>TABLE</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span>Engine </span><span><span>=</span><span> MergeTree 
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> ()
</span></span></span><span><span></span><span><span>AS</span><span> </span><span>SELECT</span><span> </span><span>*</span><span> </span><span>FROM</span><span> amazon.amazon_reviews;</span></span></span></code></pre></div></pre>
<p>Now we run the example query, with both PREWHERE and lazy materialization disabled, on the baseline table:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews_no_pk
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>3 rows in set. Elapsed: 219.508 sec. Processed 150.96 million rows, 72.13 GB (687.71 thousand rows/s., 328.60 MB/s.)
</span><span></span></span><span>Peak memory usage: 953.25 MiB.<span></span></span></code></pre></div></pre>
<p>The ① query streamed all 150 million rows—organized into <a href="https://clickhouse.com/docs/guides/best-practices/sparse-primary-indexes#data-is-organized-into-granules-for-parallel-data-processing">granules</a> (the smallest processing units in ClickHouse, each covering 8,192 rows by default)—of ② the 8 required columns from disk to ③ memory, processing 72 GB of data in 220 seconds and peaking at 953 MiB of memory usage:</p>

<blockquote>
<p>ClickHouse processes table data in a <a href="https://clickhouse.com/docs/optimize/query-parallelism">streaming fashion</a>, reading and operating on blocks of granules incrementally instead of loading all data into memory at once. That’s why, even for the query above which processed 72 GB of data, peak memory usage stayed under 1 GiB.</p>
</blockquote>
<p>With the baseline set, let’s see how the first layer of optimization improves things.</p>

<p>Obviously, scanning the entire dataset is far from optimal. Let’s start applying ClickHouse’s optimizations, beginning with the primary index. We run the example query, still with both PREWHERE and lazy materialization disabled, on the original table, which uses <code>(review_date, product_category)</code> as its compound sorting (primary) key:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>   optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>false</span><span>,
</span></span></span><span><span>   query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 95.865 sec. Processed 53.01 million rows, 27.67 GB (552.98 thousand rows/s., 288.68 MB/s.)
</span><span></span></span><span>Peak memory usage: 629.00 MiB.<span></span></span></code></pre></div></pre>
<p>Because the query includes ① filters on the table’s compound sorting (primary) key, ClickHouse ② loads and evaluates the <a href="https://clickhouse.com/docs/primary-indexes">sparse primary index</a> to ③ select only granules within the primary key columns that might contain matching rows. These potentially relevant granules are then ④ streamed into memory, along with positionally aligned granules from any other columns needed for the query. The remaining filters are applied after this step:</p>

<p>As a result, only 53 million rows from the eight required columns are streamed from disk to memory, processing 28 GB instead of 72 GB of data, and cutting runtime by more than half: 96 seconds vs. 220 seconds.</p>
<blockquote>
<p>The primary index prunes granules based on filters on the primary key columns.</p>
</blockquote>
<p>However, ClickHouse still loads all other column granules that are positionally aligned with the matching key column granules, even if filters on non-key columns exclude them later. That means unnecessary data is still being read and processed.</p>
<p>To fix that, we now enable PREWHERE.</p>

<p>We run the same query again, this time with <a href="https://clickhouse.com/docs/optimize/prewhere">PREWHERE</a> enabled (but still without lazy materialization). PREWHERE adds an additional layer of efficiency filtering out irrelevant data before reading non-filter columns from disk:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 61.148 sec. Processed 53.01 million rows, 16.28 GB (866.94 thousand rows/s., 266.24 MB/s.)
</span><span></span></span><span>Peak memory usage: 583.30 MiB.<span></span></span></code></pre></div></pre>
<p>With PREWHERE enabled, the query processed the same 53 million rows but read significantly less column data, 16.28 GB vs. 27.67 GB, and completed 36% faster (61 seconds vs. 96 seconds), while also slightly reducing peak memory usage.</p>
<p>To understand this improvement, let’s briefly walk through how PREWHERE changes the way ClickHouse processes the query.</p>
<p>Instead of streaming all selected column granules up front, ClickHouse begins PREWHERE processing by ① loading only the primary key column granules identified by the index analysis to check which ones actually contain matches. In this case, all selected granules do match, so ② the positionally aligned granules for the next filter column—<code>verified_purchase</code>—are selected to be loaded for further filtering:</p>

<p>Next, ClickHouse ① reads the selected <code>verified_purchase</code> column granules to evaluate the filter <code>verified_purchase</code> (which is a shortcut for <code>verified_purchase == True</code> ).</p>
<p>In this case, three out of four granules contain matching rows, so only ② their positionally aligned granules from the next filter column—<code>star_rating</code>—are selected for further processing:</p>

<p>Finally, ClickHouse reads the three selected granules from the <code>star_rating</code> column to evaluate the last filter <code>star_rating &gt; 4</code>.</p>
<p>Two of the three granules contain matching rows, so just the positionally aligned granules from the remaining columns—<code>helpful_votes</code>, <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code>—are selected to be loaded for further processing:</p>

<p>With that, PREWHERE processing is complete.</p>
<blockquote>
<p>Instead of loading all column granules selected by the primary index up front and then applying the remaining filters, PREWHERE pre-filters the selected data early—hence the name. ClickHouse evaluates filters one column at a time, using a <a href="https://clickhouse.com/docs/optimize/prewhere#prewhere-optimization-is-automatically-applied">cost-based approach</a>—typically starting with the cheapest column to read—and loads data only for rows that pass each step. This progressively narrows the dataset, reducing I/O before the query runs the main operations like sorting, aggregation, <code>LIMIT</code>, and <code>SELECT</code>.</p>
</blockquote>
<p>Note that PREWHERE can also work independently of indexing. If a query has only filters on non-indexed columns, it still helps reduce I/O by skipping non-matching rows early.</p>

<p>After PREWHERE filtering, ClickHouse proceeds to ① load the selected data, ② sort it, and ③ apply the LIMIT clause:</p>

<p>Each layer we’ve added so far has chipped away at the query time, skipping unnecessary data, reducing I/O, and streamlining the work.</p>
<p>From a full scan that took 220 seconds, we’re already down to 61 seconds. But we’re not done yet. One last layer brings the biggest reduction yet.</p>

<p>Let’s see what happens when lazy materialization joins the stack. We run the query one last time, with all I/O optimizations enabled, including lazy materialization.</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>WHERE</span><span> review_date </span><span>&gt;=</span><span> </span><span>'2010-01-01'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> product_category </span><span>=</span><span> </span><span>'Digital_Ebook_Purchase'</span><span>
</span></span></span><span><span></span><span><span>AND</span><span> verified_purchase
</span></span></span><span><span></span><span><span>AND</span><span> star_rating </span><span>&gt;</span><span> </span><span>4</span><span>
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span><span>FORMAT </span><span><span>Null</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    optimize_move_to_prewhere </span><span><span>=</span><span> </span><span>true</span><span>,
</span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>0 rows in set. Elapsed: 0.181 sec. Processed 53.01 million rows, 807.55 MB (292.95 million rows/s., 4.46 GB/s.)
</span><span></span></span><span>Peak memory usage: 3.88 MiB.<span></span></span></code></pre></div></pre>
<p>😮 From 61 seconds to 181 milliseconds, a 338× speedup.</p>
<p>ClickHouse processed the same 53 million rows but read 20× less column data, used 150× less memory, and finished before you could blink.</p>
<p>Let’s look under the hood to see how that happened.</p>
<p>The explanation is simple:</p>
<p>After PREWHERE filtering, ClickHouse doesn’t load all remaining columns <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#steps-after-prewhere-filtering">right away</a>.</p>
<p>Instead, it loads only what’s needed next. Since the next step is sorting by <code>helpful_votes</code> and applying the LIMIT, ClickHouse ① loads just the selected (and PREWHERE-filtered) <code>helpful_votes</code> granules, ② sorts their rows, ③ applies the LIMIT, and only then ④ loads the corresponding rows from the <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#a-more-realistic-querywhere-optimizations-matter">large</a> <code>product_title</code>, <code>review_headline</code>, and <code>review_body</code> columns:</p>

<p>And just like that, the final layer clicks into place, bringing execution time down from 220 seconds to just 181 milliseconds. Same query. Same table. Same machine. Same slow disk…just <strong>1,215× faster</strong>. All we changed was how and when data is read.</p>
<blockquote>
<p>In this example, lazy materialization delivers the biggest gain because the query selects large text columns, and thanks to lazy materialization, only 3 rows from them are needed in the end. But depending on the dataset and query shape, earlier optimizations like indexing or PREWHERE may yield greater savings. These techniques work together, each contributes to reducing I/O in a different way.</p>
</blockquote>
<p>Note: Lazy materialization is applied automatically for <code>LIMIT N</code> queries, but only up to a <code>N</code> threshold. This is controlled by the <a href="https://clickhouse.com/docs/operations/settings/settings#query_plan_max_limit_for_lazy_materialization">query_plan_max_limit_for_lazy_materialization</a> setting (default: 10). If set to 0, lazy materialization applies to all LIMIT values with no upper bound.</p>

<p>To benefit from indexing and PREWHERE, a query needs filters, on primary key columns for indexing, and on any columns for PREWHERE. As shown above, lazy materialization layers cleanly on top, but unlike the others, it can also speed up queries with no column filters at all.</p>
<p>To demonstrate this, we remove all filters from our example query to find the reviews with the highest number of helpful votes, regardless of date, product, rating, or verification status, returning the top 3 along with their title, headline, and full text.</p>
<p>We first run that query (with <a href="https://clickhouse.com/blog/clickhouse-gets-lazier-and-faster-introducing-lazy-materialization#with-cold-os-level-filesystem-cache">cold filesystem caches</a>) with lazy materialization disabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>false</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 219.071 sec. Processed 150.96 million rows, 71.38 GB (689.08 thousand rows/s., 325.81 MB/s.)
<span></span></span><span>Peak memory usage: 1.11 GiB.<span></span></span></code></pre></div></pre>
<p>Now we rerun the query (again with a cold filesystem cache), but this time with lazy materialization enabled:</p>
<pre><div><pre><code><span><span>SELECT</span><span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>FORMAT Vertical
<span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>Row 1:
</span><span></span></span><span>──────
<span></span></span><span>helpful_votes:   47524
<span></span></span><span>product_title:   Kindle: Amazon's Original Wireless Reading Device (1st generation)
<span></span></span><span>review_headline: Why and how the Kindle changes everything
<span></span></span><span>review_body:     This is less a \"pros and cons\" review than a hopefully use...
<span></span></span><span>
<span></span></span><span>Row 2:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41393
<span></span></span><span>product_title:   BIC Cristal For Her Ball Pen, 1.0mm, Black, 16ct (MSLP16-Blk)
<span></span></span><span>review_headline: FINALLY!
<span></span></span><span>review_body:     Someone has answered my gentle prayers and FINALLY designed ...
<span></span></span><span>
<span></span></span><span>Row 3:
<span></span></span><span>──────
<span></span></span><span>helpful_votes:   41278
<span></span></span><span>product_title:   The Mountain Kids 100% Cotton Three Wolf Moon T-Shirt
<span></span></span><span>review_headline: Dual Function Design
<span></span></span><span>review_body:     This item has wolves on it which makes it intrinsically swee...
<span></span></span><span>
<span></span></span><span>
<span></span></span><span>0 rows in set. Elapsed: 0.139 sec. Processed 150.96 million rows, 1.81 GB (1.09 billion rows/s., 13.06 GB/s.)
<span></span></span><span>Peak memory usage: 3.80 MiB.<span></span></span></code></pre></div></pre>
<p>Boom: a <strong>1,576× speedup</strong>—from 219 seconds to just 139 milliseconds—with 40× less data read and 300× lower memory usage.</p>
<p>This example highlights what makes lazy materialization unique among ClickHouse’s I/O optimizations.</p>
<blockquote>
<p>Lazy materialization doesn’t need column filters to deliver speedups. While indexing and PREWHERE rely on query predicates to skip data, lazy materialization improves performance purely by deferring work, loading only what’s needed, when it’s needed.</p>
</blockquote>

<p>We can observe the lazy materialization for the previous query by inspecting the query’s logical execution plan using the <a href="https://clickhouse.com/docs/sql-reference/statements/explain#explain-plan">EXPLAIN</a> clause:</p>
<pre><div><pre><code><span><span>EXPLAIN actions </span><span><span>=</span><span> </span><span>1</span><span>
</span></span></span><span><span></span><span><span>SELECT</span><span>
</span></span></span><span>    helpful_votes,
<span></span></span><span>    product_title,
<span></span></span><span>    review_headline,
<span></span></span><span>    review_body
<span></span></span><span><span></span><span><span>FROM</span><span> amazon.amazon_reviews
</span></span></span><span><span></span><span><span>ORDER</span><span> </span><span>BY</span><span> helpful_votes </span><span>DESC</span><span>
</span></span></span><span><span>LIMIT </span><span><span>3</span><span>
</span></span></span><span>SETTINGS
<span></span></span><span><span>    query_plan_optimize_lazy_materialization </span><span><span>=</span><span> </span><span>true</span><span>;</span></span></span></code></pre></div></pre>
<pre><div><pre><code><span><span>...
</span><span></span></span><span>Lazily read columns: review_headline, review_body, product_title 
<span></span></span><span>  Limit                    
<span></span></span><span>    Sorting                             
<span></span></span><span>      ReadFromMergeTree<span></span></span></code></pre></div></pre>
<p>We can read the operator plan from bottom to top and observe that ClickHouse defers reading the three large String columns until after sorting and limiting.</p>

<p>This journey began with a full-table scan: 220 seconds, 72 GB read, and 1 GiB memory used. Through ClickHouse’s layered I/O optimizations, we chipped away at runtime, one technique at a time:</p>
<ul>
<li>
<p>① The <strong>primary index</strong> pruned granules that didn’t match filters on indexed columns (<code>review_date</code>, <code>product_category</code>).</p>
</li>
<li>
<p>②  <strong>PREWHERE</strong> filtered out granules early that passed the index but failed filters on non-indexed columns (<code>verified_purchase</code>, <code>star_rating</code>), reducing unnecessary reads.</p>
</li>
<li>
<p>③  <strong>Lazy materialization</strong> deferred reading the large <code>SELECT</code> columns (<code>product_title</code>, <code>review_headline</code>, <code>review_body</code>) until after sorting by <code>helpful_votes</code> and applying <code>LIMIT</code>.</p>
</li>
</ul>

<p>Each layer helped, but for our dataset and query shape lazy materialization changed the game.</p>
<p>The result?</p>
<ul>
<li>From 220s → 0.18s = <strong>over 1,200× speedup</strong> on the filtered query</li>
<li>From 219s → 0.139s = <strong>over 1,500× speedup</strong> on a full-table Top N query</li>
</ul>
<p><strong>Same table. Same machine. Same SQL code.</strong> The only thing we changed? How and <em>when</em> ClickHouse reads the data.</p>
<p>Lazy materialization doesn’t just make ClickHouse faster, it completes the I/O optimization stack.
And the laziest part? It (and PREWHERE) are on by default. You get the speed without lifting a finger.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Algebraic Semantics for Machine Knitting (211 pts)]]></title>
            <link>https://uwplse.org/2025/03/31/Algebraic-Knitting.html</link>
            <guid>43763614</guid>
            <pubDate>Tue, 22 Apr 2025 15:55:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://uwplse.org/2025/03/31/Algebraic-Knitting.html">https://uwplse.org/2025/03/31/Algebraic-Knitting.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>As programming languages researchers, we’re entitled to a certain level of mathematical
rigor behind the languages we write and analyze. Programming languages have <em>semantics</em>, which are
definitions of what statements in the language mean. We can use those semantics to do all
sorts of useful things, like error checking, compiling for efficiency, code transformation,
and so on.</p>

<p>This blog post is about a programming domain that doesn’t yet enjoy the same level of rigor
in its semantics: machine knitting. People write programs to control massive arrays of needles
that manipulate yarn into useful 3D objects. In this blog post, I’ll run through the process
of finding “the right” semantics for machine knitting, touching on why we want semantics, connections
to traditional programming languages, and what we might use these semantics for in the future.
In our search, there are a surprising number of guest appearances by fields of study outside of programming languages:
algebraic topology, group theory, knot theory, category theory, and even quantum computing!</p>

<p>I’ll motivate semantics with a toy problem: can two given statements commute with each other?
Here’s an example where they can:</p>

<p>By “commute”, I mean that if I swapped the order of the lines, the program would do the same
thing. The commuting problem is important: a compiler might move around the order of instructions
to optimize memory usage by batching related instructions together, an analyzer might want
to see if two programs are equivalent, and we might also want to know whether we can run two instructions
in parallel. In the above example, we know that the statements commute because of the implied <em>semantics</em>
of the statements – they don’t have anything in common, so they shouldn’t affect each other!</p>

<p>Here are some more examples. These statements don’t commute because there’s a data dependency:</p>

<p>If we swapped those two statements, the statement assigning <code>x</code>’s value would use a potentially different
value for <code>y</code>.</p>

<p>Non-commuting statements might happen for reasons other than direct data dependencies. Imagine
we’re in C – do these function calls commute?</p>
<div><pre><code><span>x</span> <span>=</span> <span>f</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>);</span>
<span>y</span> <span>=</span> <span>f</span><span>(</span><span>c</span><span>,</span> <span>d</span><span>);</span>
</code></pre></div>
<p>We can’t be sure that they do – perhaps the <code>f</code> function mutates some counter variable
every time it’s called.</p>

<p>Apart from explicit mutable state, there’s one more C-like thing that commonly prevents commuting:</p>
<div><pre><code><span>*</span><span>x</span> <span>=</span> <span>*</span><span>x</span> <span>+</span> <span>3</span><span>;</span>
<span>*</span><span>y</span> <span>=</span> <span>*</span><span>y</span> <span>*</span> <span>2</span><span>;</span>
</code></pre></div>
<p>If the <code>x</code> and <code>y</code> pointers are the same, these statements don’t commute.</p>

<p>It’s notable that in a <em>pure</em> language, there’s no hidden mutable state or pointer
aliasing. Haskell is a popular language that’s very close to being pure – since
it supports IO operations like printing to the console and reading/writing files, it’s
not pure. In Haskell, these functions <em>do</em> commute, as long as there’s no IO monad malarkey:</p>


<p>The reason that Haskell’s commuting result is different than C is that its semantics are different – any time we want to
prove a property of a language’s behavior, we’ll have to turn to that language’s semantics. We know that proving properties
of machine knitting programs could be a powerful tool: <a href="https://doi.org/10.1145/3654777.3676405">a 2024 paper</a> showed massive
speedups using an optimizing compiler, using only a few program transformations that are <em>intuitively</em> correct. To scale that
result and prove the compiler’s accuracy, we’ll need to develop semantics for machine knitting.</p>

<h2 id="machine-knitting-background">Machine knitting background</h2>

<p>This introduction is only for the details of machine knitting that are relevant
to this blog post. Unfortunately, the mechanisms behind a machine that automatically
creates useful objects from spools of yarn are pretty complicated! If you’d like to read
more about machine knitting, <a href="https://doi.org/10.1145/3592449">this paper</a> has a good
introduction.</p>

<p>Knitting machines have an array of hundreds of needles, called a bed. This is analogous
to the memory of a traditional computer – registers hold values, and needles hold loops
of yarn. There are also <em>carrier strands</em> that move throughout the machine, winding through,
around, and past the loops of needles to create <em>stitches</em>, which I’ll later compare to basic operations
in traditional programming languages. Here’s how a basic stitch is formed in knitting:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_pre.svg" alt="A cyan carrier strand to the left of a loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_no_box.svg" alt="The carrier strand has been pulled through the loop, creating a new cyan loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/stitch_post.svg" alt="A box has been drawn around part of the previous image; the stitch takes a cyan carrier strand and gold loop
  in and returns a cyan loop and a cyan carrier strand">
</p>

<p>A carrier strand (in cyan) is pulled through a loop (in gold) to create a new loop.
Note how the bottom gold loop is held in place as long as the top cyan loop and carrier strand
are held up. After the stitch, the knitting machine drops the bottom loop, but the bottom
loop stays connected and stable. This is like a value falling out of scope, but since some in-scope
value points to it, it’s not garbage-collected (gravity is the garbage collector of machine knitting!).</p>

<p>There are many variants of stitches, but they all follow the same
input-output pattern: loops and carrier strands in, loops and carrier strands 
out. In that way, they’re kind of like basic operations we’re used to in computer science,
like addition or bitwise AND: values in, values out. The third image above draws a box around the
stitch to show its inputs and outputs: carrier strand and loop in, loop and carrier strand out.</p>

<p>There’s one more technicality in machine knitting: in order to do a stitch
involving some values, those values must be all adjacent to each other.
In the example below, we can’t immediately knit the cyan carrier on the far left with
the gold loop on the far right – instead, 
we have to move
the values next to each other before creating a stitch.</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_pre.svg" alt="A cyan carrier strand, red loop, and gold loop">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/move_post.svg" alt="The cyan carrier strand crosses over the red loop, and makes a stitch with the gold loop">
</p>

<p>This is also true for traditional computing – to compute the
boolean AND of two bits, we need to connect those two bits to an AND gate,
getting them right next to each other. Computer architects use complicated
routing mechanisms like multiplexers to do this; when we code in traditional
programming languages, we don’t have to worry about those constraints
because the computer architects have generously handled it for us.</p>

<p>The languages used for machine knitting don’t include many of the traditional
programming language features that make code hard to analyze: no <code>if</code>
statements (branching) or <code>for</code> loops, and no functions. Machine
knitting code is just a series of operations that perform stitches and
move carrier strands and loops around. This should make analyzing machine knitting
easier: there’s far less complexity than traditional programming languages.
In fact, for our specific question of whether two operations commute, the
problem seems almost trivial: similar to pure functional programming
languages, there’s no global state or aliasing in
machine knitting. However, there’s something tricky hiding in
machine knitting that isn’t a worry in traditional computing contexts:
since knitting is done in 3 dimensions, when strands cross, one goes over and
the other goes under. This can cause operations to snag on each other, even if
no strand directly connects them. I’ll illustrate this with some diagrams.</p>

<h2 id="diagrams">Diagrams</h2>

<p>Let’s start by carefully analyzing something core to traditional computing:
combinatorial boolean circuits. Here’s a simple example <code>myfunc</code> that maps
3 bits to 3 bits.</p>
<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span> <span>// split the wire in two</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p>It’s usually easier to reason about circuits when they’re drawn (forgive my very strange choices when drawing
the diagram; all will be clear once we get to knitting):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_pre.svg" alt="Circuit diagram for the above code">
</p>

<p>I pose the same question: can the
<code>dup</code> and <code>and</code> operations commute? Here, the answer is a definite yes:
global state and aliasing aren’t present, and there’s no data dependency.
Here is the same function with the operations commuted:</p>

<div><pre><code><span>fn</span> <span>myfunc</span><span>(</span><span>x1</span><span>,</span> <span>x2</span><span>,</span> <span>x3</span><span>)</span> <span>{</span>
    <span>y3</span> <span>=</span> <span>and</span><span>(</span><span>x3</span><span>,</span> <span>x1</span><span>);</span>
    <span>y1</span><span>,</span> <span>y2</span> <span>=</span> <span>dup</span><span>(</span><span>x2</span><span>);</span>

    <span>return</span> <span>y1</span><span>,</span> <span>y2</span><span>,</span> <span>y3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_circuit_post.svg" alt="Circuit diagram for the above code">
</p>

<p>Deciding whether two operations commute in a combinatorial circuit is easy
– they can commute if and only if there’s no directed path connecting them,
just like how two functions can commute in Haskell as long as there’s no data
dependency between them and no IO trickery.</p>

<h3 id="knitting-diagrams">Knitting diagrams</h3>

<p>Now, let’s try something similar for knitting. For simplicity, we’ll work in a
made-up machine knitting language that hides some of the technicalities
that aren’t important for this post. Our knitting function takes three strands as input,
does two stitches, and returns three new strands. I’ve taken the liberty to
simplify the diagrams by not drawing
the “internals” of the stitches (now they’re just boxes)
and I’m drawing both loops and carrier strands as single strands.</p>
<div><pre><code><span>fn</span> <span>myknit</span><span>(</span><span>s1</span><span>,</span> <span>s2</span><span>,</span> <span>s3</span><span>)</span> <span>{</span>
    <span>t1</span><span>,</span> <span>t2</span> <span>=</span> <span>stitch1</span><span>(</span><span>s2</span><span>);</span>
    <span>cross</span> <span>t1</span> <span>over</span> <span>s1</span><span>;</span>
    <span>cross</span> <span>s3</span> <span>over</span> <span>t2</span><span>;</span>
    <span>cross</span> <span>s1</span> <span>over</span> <span>s3</span><span>;</span>
    <span>t3</span> <span>=</span> <span>stitch2</span><span>(</span><span>s3</span><span>,</span> <span>s1</span><span>);</span>
    <span>cross</span> <span>t2</span> <span>over</span> <span>t3</span><span>;</span>

    <span>return</span> <span>t1</span><span>,</span> <span>t2</span><span>,</span> <span>t3</span><span>;</span>
<span>}</span>
</code></pre></div>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/diagram_knit.svg" alt="Diagram for the above knitting code. The stitch1 and stitch2 boxes aren't directly connected by a
  strand, but due to the way the strands have crossed, there is no way to move stitch2 below stitch1">
</p>

<p>Well, the diagram looks almost the same as the circuit diagram, but now every time two
strands cross, we have to specify which one goes on top of the other. This is extra noticeable
in the code: all crossings between strands are listed and annotated. We’re careful to record and
display these over/under crossings in machine knitting because they’re a feature of working in
a physical medium: the way strands cross affects how a knitted object looks and feels, and it can
drastically change the shape of the final object!</p>

<p>These over/under crossings are what make the commuting problem difficult for machine knitting.
In the above example, there’s no data dependency (i.e., no connecting strand) between the two
operations. However, because of how their strands are crossing, the operations “snag” on each other
so they can’t commute. It’s perhaps easy for humans to look at the above diagram and decide whether
two operations snag on each other, but how can we author an accurate algorithm to
apply automated analysis to these affairs? We need some way of formalizing these ideas so a computer
can reason about them… ah yes, those semantics we mentioned earlier.</p>

<p>Now is a good time to mention that there actually ARE semantics for machine knitting:
<a href="https://doi.org/10.1145/3592449">a 2023 paper</a> set up rigorous mathematical semantics for all of machine
knitting. However, these semantics are defined in <em>tangles</em> from knot theory. This is a natural way to
define knitted objects – they really are a tangle of strands in 3D space! However, the equivalences of
knot theory are defined by continuous deformations – two knots are equivalent whenever we can stretch, move,
expand, and contract one knot into the other without tearing strands. Since the goal is to write computer
programs that analyze machine knitting, the proposed semantics aren’t directly useful to computers. Computers don’t have
any notion of what a “continuous deformation” is, and they’re particularly bad at doing anything involving
continuous quantities. The semantics are useful for humans to do basic hand-written proofs and are a great
starting point, but we’d like to extend them so we can use computers to perform automatic analysis.</p>

<h3 id="aside-quantum-computing">Aside: quantum computing</h3>

<p>It should be noted that if we actually constructed the combinatorial circuit from earlier by
plugging wires into tangible logic gates, we would also have to make some decision for each
crossing as to which wire goes on top. However, this is simply not a concern for computer scientists:
it doesn’t matter which wire goes on top, because electrons don’t care whether they go above or below
other electrons – it doesn’t change the resulting computation.</p>

<p>Models in quantum physics allow for particles that <em>do</em> remember how they pass over
and under each other. This could have big effects in quantum computing, where a so-called topological
quantum computer using these particles could be far more resistant to decoherence than
conventional quantum computing. A team at Microsoft has
<a href="https://doi.org/10.1038/s41586-024-08445-2">recently published some experimental results in topological quantum computing</a>
using a setup to braid quasiparticles together in 2+1 dimensions
of space and time respectively. The methods, setup, and goals are certainly different than machine
knitting, but it’s quite satisfying to see the two seemingly unrelated topics of machine knitting and
quantum computing bound by similar mathematical ideas.</p>

<h2 id="algebraicizing-our-topology">Algebraicizing our topology</h2>

<p>As I hinted earlier, we’d like to formalize the previous diagrams so we can study their properties, using
something more computer-friendly than knot theory. Really, this is an exercise in algebraic topology –
representing a topology (like our deformations of 3D space) with algebra, which is a lot easier to work
with. The <em>braid group</em> is a great starter example of how mathematicians represent a topological object
with algebra.</p>

<h3 id="the-braid-group">The braid group</h3>

<p>For folks familiar with group theory, the braid group on \(n\) strands is</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2,\) and it represents the equivalence classes of \(n\) strands under ambient isotopy.
For the folks confused by this deluge of notation, read on!</p>

<p>A group is a set of elements \(G = \{x_1, x_2, \ldots \}\) with</p>

<ol>
  <li>Some way to <em>combine</em> or <em>compose</em> elements together, which I’ll represent
using a semicolon. For any \(x, y \in G,\) we have \(x ; y \in G.\)</li>
  <li>Some identity element that represents “nothing”. We’ll call that element
\(\text{id}\in G,\) and it has the property \(\text{id} ; x = x = x ; \text{id}.\)</li>
  <li>Some way to <em>invert</em> elements: for any \(x \in G,\) there’s some \(x^{-1} \in G\)
where \(x;x^{-1} = \text{id} = x^{-1} ; x.\)</li>
</ol>

<p>One group we’re all familiar with is the integers under addition: the composition of integers is
addition, the identity is \(0,\) and inverting is negation.</p>

<p>For any natural number \(n\) (let’s say \(n=5\)), the <em>braid group on \(n\) strands</em> is one of
these groups. There are infinite elements in that group, and every element is 5 strands,
oriented bottom-to-top, passing over/under each other. It’s good to think of braids as
nailed or glued down at either end, and two braids are <em>equivalent</em> whenever one can be transformed
into the other by shifting around strands, keeping the nailed-down ends fixed.
Here are two examples of braids on 5 strands; I’ll call the left one \(x\) and the right one \(y\):</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-2.svg" alt="Braid y = sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>Next, we’ll define what composition, the identity, and inverses are:</p>

<p>Composition is vertical concatenation, read bottom to top. So \(x ; y\) is \(x\) pasted
below \(y,\) with the strands connected in order:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_2^{-1} ; sigma_1 ; sigma_3^{-1} ; sigma_4 in B_5">
</p>

<p>The identity in the braid group is just \(n\) strands going straight:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/ident-5.svg" alt="5 vertical strands, none of them crossing">
</p>

<p>With the definition of composition being vertical concatenation, hopefully we can agree that
pasting on the identity at either end doesn’t really change anything, so that braid is indeed the identity.
Finally, inverses are mirror images about the horizontal line through the middle of the braid – below is \(x\) on the left and
\(x^{-1}\) on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv.svg" alt="Braid x^{-1} = sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>When we compose \(x ; x^{-1},\) we get a braid that untangles to be the identity:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-inv-concat.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} ; sigma_3 ; sigma_1^{-1} ; sigma_2^{-1} ; sigma_1 in B_5">
</p>

<p>This is all well and good, but we need some way to write braids down so computers can use them.
We’ll do this by listing their crossings in order, from bottom to top. We’ll use \(\sigma_i\) to
refer to the \(i\)th strand from the left crossing over the \((i+1)\)th strand, and \(\sigma_i^{-1}\)
for under. Then we can write the braid \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_1 ; \sigma_3^{-1}.\)</p>

<p>There’s one more complication: there’s more than one way to write down braids. For example, we could
write \(x\) as \(x = \sigma_1^{-1} ; \sigma_2 ; \sigma_3^{-1} ; \sigma_1\) instead – here’s the original \(x\)
diagram on the left and the new one on the right:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_1 ; sigma_3^{-1} in B_5">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/inter-5-syn.svg" alt="Braid x = sigma_1^{-1} ; sigma_2 ; sigma_3^{-1} ; sigma_1 in B_5">
</p>

<p>This diagram of \(x\) and the original are equivalent – by shifting the crossings up/down, we transform
one into the other. So the braid group has extra relations to account for this:
\(\sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}\) and \(\sigma_i ; \sigma_j = \sigma_j ; \sigma_i.\)
Here are those relations drawn out, with the left and right sides being equal in each row:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-1.svg" alt="A red strand passes over a cyan and green strand, then the cyan passes over the green">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/yb-2.svg" alt="Cyan passes over green, then red passes over green and cyan">
</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-1.svg" alt="Red over cyan, then green over purple">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/comm-2.svg" alt="Green over purple, then red over cyan">
</p>

<p>Physics note: the first equation is called the <a href="https://en.wikipedia.org/wiki/Yang%E2%80%93Baxter_equation">Yang-Baxter equation</a>, and
it appears in many more places than just the braid group!</p>

<p>It should be noted that the relation \(\sigma_i ; \sigma_i^{-1} = \text{id}\) is implicit in all groups:</p>

<p><img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-1.svg" alt="A red strand passes over a cyan strand, then over the cyan strand from the other side">
  <img src="https://uwplse.org/blog/images/2025-03-31-Algebraic-Knitting/braid/sc-2.svg" alt="The red and cyan strands don't cross">
</p>

<p>Now, we should all be on the same page for the braid group: the notation</p><p>

\[B_n = \langle \sigma_1, \ldots, \sigma_{n-1} | \sigma_i ; \sigma_{i+1} ; \sigma_i = \sigma_{i+1} ; \sigma_i ; \sigma_{i+1}, \sigma_i ; \sigma_j = \sigma_j ; \sigma_i \rangle\]

</p><p>for \(|i - j| \geq 2\)
tells us how to write braids down (with \(\sigma_1, \ldots, \sigma_{n-1}\)) and which words mean the same thing.</p>

<p>The braid group is well-studied and comes with some powerful algorithms. The presentation is canonicalizable in polynomial time,
meaning there are algorithms that we can run to efficiently tell whether two braids written down using \(\sigma_i\) are
equivalent. This is a great sign for our goal of computable semantics for machine knitting – mathematicians have taken a topological object
with a lot of the structure we want in machine knitting, boiled it down to something computer-friendly, and even authored
some useful algorithms! However, the braid group can only represent the pieces of machine knitting programs without stitches.
Stitches operate like functions on strands, with input and output strands. The count of inputs can be different
than the count of outputs, changing the count of strands as we perform the stitch. The braid group is limited to some fixed \(n\) strands, so it can’t represent
stitches. To get the complete picture of machine knitting, we’ll need to generalize our mathematical assumptions to include the boxes
that represent stitches.</p>

<h3 id="monoidal-categories-and-their-diagrams">Monoidal categories and their diagrams</h3>

<p>In programming languages research, category theory is best known for research in type theory.
I’ve spent all my math allowance for this blog post explaining the braid group so I won’t get into the nitty-gritty
of what categories are – in short, it’s an algebraic object, like a group, but more general: composition
doesn’t always have to be defined, and inverses don’t always have to exist.</p>

<p>Of particular note are the ideas of <a href="https://ncatlab.org/nlab/show/internal+logic">internal logics</a> and internal languages
of categories: correspondences between a category, some logic, and some theoretical programming language model. The
<a href="https://en.wikipedia.org/wiki/Curry%E2%80%93Howard_correspondence">Curry-Howard correspondence</a> describes the connection
between logic and programming languages, and these ideas add category theory to the party.</p>

<p>One such correspondence lies between <em>linear logic</em>, where values can only be used and must be used once, and
<em>symmetric monoidal categories</em>. All categories have composition, which I’m interpreting as vertical concatenation like in the braid
group; monoidal categories additionally have horizontal concatenation (like multiple values in scope, running two circuits in sequence,
or an array of needles holding loops). Symmetric monoidal categories
can be drawn as boxes connected by strands where the over/under-ness of
strand crossings isn’t recorded or drawn: exactly the diagrams we draw for combinatorial circuits! The symmetric
monoidal category gives notation and axioms for us to rigorously study those circuits, just like the braid group
gives notation and axioms for studying braids. <em>Symmetric</em> monoidal category is a great name because it’s closely
related to the symmetric group.</p>

<p>Following the same idea, <em>braided monoidal categories</em> generalize symmetric monoidal categories by recording
over/under crossings, and we draw our diagrams as such – just like our diagram for machine knitting!
Back in 1991 when braided monoidal categories were still young,
<a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street</a> showed that the axioms of braided monoidal categories
correspond with the topology of the diagrams we use for them. Since our diagrams really do represent physical topological
objects, this means that braided monoidal categories are perfect for machine knitting!</p>

<h2 id="actually-using-these-semantics">Actually using these semantics</h2>
<p>Now that we’ve identified an algebraic structure for machine knitting, we’d like to use that formalism to perform useful
analysis of machine knitting programs. One immediate goal is program equivalence: given two machine knitting programs, will
they produce the same object up to topological equivalence? We can reduce those programs to their braided monoidal category
representations and work with those. This is closely related to the braid group’s canonicalization I mentioned earlier – can we
extend that to the braided monoidal category? I’ve developed an algorithm that does just that in polynomial time, but it’s
too complicated to fit in a blog post. To borrow some language from Fermat, I’ve
<a href="https://en.wikipedia.org/wiki/Fermat's_Last_Theorem#Fermat's_conjecture">discovered a truly marvelous algorithm and proof of correctness, which this blog post’s margin is too narrow to contain</a>.
The algorithm works by using some new ideas to canonicalize the positions and order of stitches, and then uses the braid group canonicalization to canonicalize
the crossings between stitches.</p>

<p>We could use the canonicalization algorithm to compile and optimize machine knitting programs. Normal forms are important to compilers because they can greatly
simplify the language to be compiled – a canonical form builds on that by additionally providing a uniqueness guarantee. The axioms of braided monoidal categories
lay out exactly all the program transformations we should consider. Finally, I also have an interest in developing a user-facing programming language for machine knitting
that’s closer to the abstraction provided by category theory. The current machine knitting languages are closely tied to controlling knitting machines, so they require
the user to specify which needles on the machine hold strands (like how assembly requires users to specify which registers use values). On top of usability, a new programming
language might also come with features for performance, fabrication reliability, or modularity of programs.</p>

<p>Big thanks to my advisors at UW, Gilbert Bernstein and Adriana Schulz, for being flexible as a first-year PhD student learns category
theory and topology through the lens of machine knitting. This work is in part a collaboration with folks currently and previously at CMU,
including <a href="https://jlin98.github.io/">Jenny Lin</a>, <a href="https://t0mpr1c3.github.io/">Tom Price</a>, <a href="https://www.cs.cmu.edu/~jmccann/">Jim McCann</a>,
and <a href="https://www.cmu.edu/dietrich/philosophy/people/phd/hannah-fechtner.html">Hannah Fechtner</a>.</p>

<h2 id="further-reading">Further reading</h2>

<ol>
  <li><a href="https://doi.org/10.1145/3654777.3676405">KODA, the optimizing knitting compiler</a></li>
  <li><a href="https://doi.org/10.1145/3592449">Topological machine knitting semantics</a></li>
  <li><a href="https://doi.org/10.1038/s41586-024-08445-2">Microsoft’s experimental progress in topological quantum computing</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Braid_group">Wikipedia article for the braid group</a></li>
  <li><a href="https://ncatlab.org/nlab/show/internal+logic">nLab’s page on internal logics</a></li>
  <li><a href="https://doi.org/10.1016/0001-8708(91)90003-P">Joyal and Street’s paper connecting category theory diagrams and topology</a></li>
</ol>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Supabase raises $200M Series D at $2B valuation (307 pts)]]></title>
            <link>https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</link>
            <guid>43763225</guid>
            <pubDate>Tue, 22 Apr 2025 15:17:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html">https://finance.yahoo.com/news/exclusive-supabase-raises-200-million-112154867.html</a>, See on <a href="https://news.ycombinator.com/item?id=43763225">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>  <p><!-- HTML_TAG_START -->Paul Copplestone didn’t think things like this actually happened.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Then one day Accel’s Gonzalo Mocorrea asked for his New Zealand address—more than 7,000 miles from Silicon Valley.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Mocorrea “literally showed up on my doorstep in Wānaka, which is really not easy to get to,” said Copplestone, the CEO and cofounder of open source application development platform Supabase. “For the next two days, he’d pop in and we’d chat for a couple hours.”<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->After a few days in Wānaka—located on New Zealand's South Island and famous for its snow capped mountains overlooking a massive mirror of a lake—Accel’s Mocorrea called in backup, texting partner Arun Mathew.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“Arun said ‘alright, I’m coming,’” said Copplestone. “And I said, ‘Oh no, don’t come! We haven’t agreed to anything!’ But yeah, he came, we had dinner in Queenstown, another beautiful place. We caught up the next morning, and they offered a term sheet.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Accel’s Mathew had traveled more than 24 hours, across two flights and multiple car rides, to make the trip as the firm weighed its first investment in Supabase.<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“I needed to sit across the table, look him in the eye, and really believe he’s going to do something else,” Mathew told <em>Fortune</em>. “That’s necessary, certainly at this valuation…We know what greatness looks like, we believe that—and I’m obviously betting with my career.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->That term sheet became Supabase’s latest funding round, a $200 million Series D valuing the company at $2 billion, <em>Fortune</em> can exclusively report. Coatue, Y Combinator, Craft Ventures, and Felicis participated in the round, as did big-name angels like OpenAI Chief Product Officer Kevin Weil, Vercel CEO Guillermo Rauch, and <a href="https://fortune.com/2024/09/05/laravel-raises-57-million-series-a-from-accel/" rel="nofollow noopener" target="_blank" data-ylk="slk:Laravel CEO Taylor Otwell;elm:context_link;itc:0;sec:content-canvas">Laravel CEO Taylor Otwell</a>.<!-- HTML_TAG_END --></p>    <p><!-- HTML_TAG_START -->“The core thesis for us is that in every major platform shift, there's always value created at the database layer,” said Mathew. “It's part of the reason that Larry Ellison and <a href="https://fortune.com/europe/2025/03/17/oracle-uk-ai-boom-5-billion-cloud-investment-larry-ellison-trump-starmer/" rel="nofollow noopener" target="_blank" data-ylk="slk:Oracle;elm:context_link;itc:0;sec:content-canvas">Oracle</a> have held the same power for 40-plus years. It's partially why MongoDB is one of the most interesting enterprise software companies out there…The database layer has a lot of dead bodies, but it also has a number of companies that have created exceptional enterprise value.”<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->Supabase is currently used by two million developers who manage more than 3.5 million databases. The startup supports Postgres, the most popular developer database system that’s an alternative to Google’s Firebase. Supabase’s goal: To be a one-stop backend for developers and "vibe coders."<!-- HTML_TAG_END --></p>  <p><!-- HTML_TAG_START -->“I see our community, over the next decade, as something that will grow with us, and it’s for everyone from developers, all the way up to enterprise,” said Copplestone. “It’s more than just developers even now. Our sign-up rate just doubled in the past three months because of vibe coding—Bolt, Lovable, Cursor, all those.”<!-- HTML_TAG_END --></p> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I open-sourced my AI toy company that runs on ESP32 and OpenAI realtime (138 pts)]]></title>
            <link>https://github.com/akdeb/ElatoAI</link>
            <guid>43762409</guid>
            <pubDate>Tue, 22 Apr 2025 14:10:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/akdeb/ElatoAI">https://github.com/akdeb/ElatoAI</a>, See on <a href="https://news.ycombinator.com/item?id=43762409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🚀 ElatoAI: Realtime AI Speech for ESP32</h2><a id="user-content--elatoai-realtime-ai-speech-for-esp32" aria-label="Permalink: 🚀 ElatoAI: Realtime AI Speech for ESP32" href="#-elatoai-realtime-ai-speech-for-esp32"></a></p>
<p dir="auto">Realtime AI Speech powered by OpenAI Realtime API, ESP32, Secure WebSockets, and Deno Edge Functions for &gt;10-minute uninterrupted global conversations</p>
<p dir="auto"><a href="https://discord.gg/KJWxDPBRUj" rel="nofollow"><img src="https://camo.githubusercontent.com/a6bebe6b4fcd39437b9209e02e63af22ac414ffcfcf1bd0224924a924e113bd4/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f4b4a577844504252556a3f7374796c653d666c6174" alt="Discord Follow" data-canonical-src="https://dcbadge.vercel.app/api/server/KJWxDPBRUj?style=flat"></a>
<a href="https://www.gnu.org/licenses/gpl-3.0.en.html" rel="nofollow"><img src="https://camo.githubusercontent.com/bb4e5c0036a6a8cdbc59b38d44f09ad8f6dc722751dad34d3df5bf0ac61913c1/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d626c7565" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/license-MIT-blue"></a>   
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/da1334d6d7641a2f8b8a392848949968d3e2f74e04dd8f18e88b8274c5c288fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6f64652e6a732d32322e31332e302d79656c6c6f772e737667"><img src="https://camo.githubusercontent.com/da1334d6d7641a2f8b8a392848949968d3e2f74e04dd8f18e88b8274c5c288fc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6f64652e6a732d32322e31332e302d79656c6c6f772e737667" alt="Node.js" data-canonical-src="https://img.shields.io/badge/Node.js-22.13.0-yellow.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6011eef04208dc40ad937a7deb0e3267a39aeef1231389e35deb305d09443039/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6578742e6a732d31342e322e372d627269676874677265656e2e737667"><img src="https://camo.githubusercontent.com/6011eef04208dc40ad937a7deb0e3267a39aeef1231389e35deb305d09443039/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4e6578742e6a732d31342e322e372d627269676874677265656e2e737667" alt="Next.js" data-canonical-src="https://img.shields.io/badge/Next.js-14.2.7-brightgreen.svg"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/e10edb68f4e033e521165fdd24d654e3ac2f1d43cbdab9a8cf9b76319e27106f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d31382e322e302d626c75652e737667"><img src="https://camo.githubusercontent.com/e10edb68f4e033e521165fdd24d654e3ac2f1d43cbdab9a8cf9b76319e27106f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f52656163742d31382e322e302d626c75652e737667" alt="React" data-canonical-src="https://img.shields.io/badge/React-18.2.0-blue.svg"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Demo Video</h2><a id="user-content-demo-video" aria-label="Permalink: Demo Video" href="#demo-video"></a></p>
<details open="">
  <summary>
    
    <span aria-label="Video description Elato.open-source.conversational.AI.device.mp4">Elato.open-source.conversational.AI.device.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/20175219/435005042-aa60e54c-5847-4a68-80b5-5d6b1a5b9328.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzNTA1MDMsIm5iZiI6MTc0NTM1MDIwMywicGF0aCI6Ii8yMDE3NTIxOS80MzUwMDUwNDItYWE2MGU1NGMtNTg0Ny00YTY4LTgwYjUtNWQ2YjFhNWI5MzI4Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIyVDE5MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNjZTRiYTdhNWJlZWMzZTVjM2VlZWE2MmFiNDJjYjkwYmNkY2YxOTU2Y2VkZDMzMTMwYTBlNGEwOWFiYWEwNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.o_7HQusgVlfhCHbV1IOlzhYl5pD9NiBvrQw61HOxMrg" data-canonical-src="https://private-user-images.githubusercontent.com/20175219/435005042-aa60e54c-5847-4a68-80b5-5d6b1a5b9328.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDUzNTA1MDMsIm5iZiI6MTc0NTM1MDIwMywicGF0aCI6Ii8yMDE3NTIxOS80MzUwMDUwNDItYWE2MGU1NGMtNTg0Ny00YTY4LTgwYjUtNWQ2YjFhNWI5MzI4Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MjIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDIyVDE5MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTNjZTRiYTdhNWJlZWMzZTVjM2VlZWE2MmFiNDJjYjkwYmNkY2YxOTU2Y2VkZDMzMTMwYTBlNGEwOWFiYWEwNjUmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.o_7HQusgVlfhCHbV1IOlzhYl5pD9NiBvrQw61HOxMrg" controls="controls" muted="muted">

  </video>
</details>

<a href="https://www.youtube.com/watch?v=o1eIAwVll5I" rel="nofollow">
  <img src="https://camo.githubusercontent.com/c937f11455e973bb4d27d3cac0d9f79f64a49482daef0ead1c301e51844a16c7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f576174636825323044656d6f2d596f75547562652d7265643f7374796c653d666f722d7468652d6261646765266c6f676f3d796f7574756265" alt="Watch Demo on YouTube" data-canonical-src="https://img.shields.io/badge/Watch%20Demo-YouTube-red?style=for-the-badge&amp;logo=youtube">
</a>
<p dir="auto"><h2 tabindex="-1" dir="auto">⚡️ Hardware Design</h2><a id="user-content-️-hardware-design" aria-label="Permalink: ⚡️ Hardware Design" href="#️-hardware-design"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/akdeb/ElatoAI/blob/main/pcb-design.png"><img src="https://github.com/akdeb/ElatoAI/raw/main/pcb-design.png" alt="Hardware Setup" width="100%"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<ol dir="auto">
<li>Install <a href="https://supabase.com/docs/guides/local-development/cli/getting-started" rel="nofollow">Supabase CLI</a> and set up your Local Supabase Backend. From the root directory, run:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="brew install supabase/tap/supabase
supabase start # Starts your local Supabase server with the default migrations and seed data."><pre>brew install supabase/tap/supabase
supabase start <span><span>#</span> Starts your local Supabase server with the default migrations and seed data.</span></pre></div>
<ol start="2" dir="auto">
<li>Set up your NextJS Frontend. (<a href="https://github.com/akdeb/ElatoAI/blob/main/frontend-nextjs/README.md">See the Frontend README</a>) From the <code>frontend-nextjs</code> directory, run the following commands. (<strong>Login creds:</strong> Email: <a href="mailto:admin@elatoai.com">admin@elatoai.com</a>, Password: admin)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="cd frontend-nextjs
npm install

# Set your environment variables
cp .env.example .env.local
# NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
# OPENAI_API_KEY=<your_openai_api_key>

# Run the development server
npm run dev"><pre><span>cd</span> frontend-nextjs
npm install

<span><span>#</span> Set your environment variables</span>
cp .env.example .env.local
<span><span>#</span> NEXT_PUBLIC_SUPABASE_ANON_KEY=&lt;your_supabase_anon_key&gt;</span>
<span><span>#</span> OPENAI_API_KEY=&lt;your_openai_api_key&gt;</span>

<span><span>#</span> Run the development server</span>
npm run dev</pre></div>
<ol start="3" dir="auto">
<li>
<p dir="auto">Add your ESP32-S3 Device MAC Address to the <a href="http://localhost:3000/home/settings" rel="nofollow">Settings page</a> in the NextJS Frontend. This links your device to your account.
To find your ESP32-S3 Device's MAC Address, build and upload <code>test/print_mac_address_test.cpp</code> using PlatformIO.</p>
</li>
<li>
<p dir="auto">Add your OpenAI API Key in the <code>server-deno/.env</code> and <code>frontend-nextjs/.env.local</code> file.</p>
</li>
</ol>
<div data-snippet-clipboard-copy-content="OPENAI_API_KEY=<your_openai_api_key>"><pre><code>OPENAI_API_KEY=&lt;your_openai_api_key&gt;
</code></pre></div>
<ol start="5" dir="auto">
<li>Start the Deno server. (<a href="https://github.com/akdeb/ElatoAI/blob/main/server-deno/README.md">See the Deno server README</a>)</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Navigate to the server directory
cd server-deno

# Set your environment variables
cp .env.example .env
# NEXT_PUBLIC_SUPABASE_ANON_KEY=<your_supabase_anon_key>
# OPENAI_API_KEY=<your_openai_api_key>

# Run the server at port 8000
deno run -A --env-file=.env main.ts"><pre><span><span>#</span> Navigate to the server directory</span>
<span>cd</span> server-deno

<span><span>#</span> Set your environment variables</span>
cp .env.example .env
<span><span>#</span> NEXT_PUBLIC_SUPABASE_ANON_KEY=&lt;your_supabase_anon_key&gt;</span>
<span><span>#</span> OPENAI_API_KEY=&lt;your_openai_api_key&gt;</span>

<span><span>#</span> Run the server at port 8000</span>
deno run -A --env-file=.env main.ts</pre></div>
<ol start="5" dir="auto">
<li>
<p dir="auto">Set up your ESP32 Arduino Client. (<a href="https://github.com/akdeb/ElatoAI/blob/main/firmware-arduino/README.md">See the ESP32 README</a>) On PlatformIO, first <code>Build</code> the project, then <code>Upload</code> the project to your ESP32.</p>
</li>
<li>
<p dir="auto">The ESP32 should open an AP <code>ELATO-DEVICE</code> to connect to Wifi. Connect to it and go to <code>http://192.168.4.1</code> to configure the device wifi.</p>
</li>
<li>
<p dir="auto">Once your Wifi is configured, turn the device off and on again and it should connect to your Wifi and the Deno edge server.</p>
</li>
<li>
<p dir="auto">Now you can talk to your AI Character!</p>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Architecture</h2><a id="user-content-project-architecture" aria-label="Permalink: Project Architecture" href="#project-architecture"></a></p>
<p dir="auto">ElatoAI consists of three main components:</p>
<ol dir="auto">
<li><strong>Frontend Client</strong> (<code>Next.js</code> hosted on Vercel) - to create and talk to your AI agents and 'send' it to your ESP32 device</li>
<li><strong>Edge Server Functions</strong> (<code>Deno</code> running on Deno/Supabase Edge) - to handle the websocket connections from the ESP32 device and the OpenAI API calls</li>
<li><strong>ESP32 IoT Client</strong> (<code>PlatformIO/Arduino</code>) - to receive the websocket connections from the Edge Server Functions and send audio to the OpenAI API via the Deno edge server.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">🌟 Features</h2><a id="user-content--features" aria-label="Permalink: 🌟 Features" href="#-features"></a></p>
<ol dir="auto">
<li><strong>Realtime Speech-to-Speech</strong>: Instant speech conversion powered by OpenAI's Realtime APIs.</li>
<li><strong>Create Custom AI Agents</strong>: Create custom agents with different personalities and voices.</li>
<li><strong>Customizable Voices</strong>: Choose from a variety of voices and personalities.</li>
<li><strong>Secure WebSockets</strong>: Reliable, encrypted WebSocket communication.</li>
<li><strong>Server VAD Turn Detection</strong>: Intelligent conversation flow handling for smooth interactions.</li>
<li><strong>Opus Audio Compression</strong>: High-quality audio streaming with minimal bandwidth.</li>
<li><strong>Global Edge Performance</strong>: Low latency Deno Edge Functions ensuring seamless global conversations.</li>
<li><strong>ESP32 Arduino Framework</strong>: Optimized and easy-to-use hardware integration.</li>
<li><strong>Conversation History</strong>: View your conversation history.</li>
<li><strong>Device Management</strong>: Register and manage your devices.</li>
<li><strong>User Authentication</strong>: Secure user authentication and authorization.</li>
<li><strong>Conversations with WebRTC and Websockets</strong>: Talk to your AI with WebRTC on the NextJS webapp and with websockets on the ESP32.</li>
<li><strong>Volume Control</strong>: Control the volume of the ESP32 speaker from the NextJS webapp.</li>
<li><strong>Realtime Transcripts</strong>: The realtime transcripts of your conversations are stored in the Supabase DB.</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛠 Tech Stack</h2><a id="user-content--tech-stack" aria-label="Permalink: 🛠 Tech Stack" href="#-tech-stack"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Technology Used</th>
</tr>
</thead>
<tbody>
<tr>
<td>Frontend</td>
<td>Next.js, Vercel</td>
</tr>
<tr>
<td>Backend</td>
<td>Supabase DB</td>
</tr>
<tr>
<td>Edge Functions</td>
<td>Deno Edge Functions on Deno/Supabase</td>
</tr>
<tr>
<td>IoT Client</td>
<td>PlatformIO, Arduino Framework, ESP32-S3</td>
</tr>
<tr>
<td>Audio Codec</td>
<td>Opus</td>
</tr>
<tr>
<td>Communication</td>
<td>Secure WebSockets</td>
</tr>
<tr>
<td>Libraries</td>
<td>ArduinoJson, WebSockets, AsyncWebServer, ESP32_Button, Arduino Audio Tools, ArduinoLibOpus</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">🗺️ High-Level Flow</h2><a id="user-content-️-high-level-flow" aria-label="Permalink: 🗺️ High-Level Flow" href="#️-high-level-flow"></a></p>
<section data-identity="65c7f3cf-ab78-4f32-9c40-23a254c1c485" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;flowchart TD\n  User[User Speech] --&amp;gt; ESP32\n  ESP32[ESP32 Device] --&amp;gt;|WebSocket| Edge[Deno Edge Function]\n  Edge --&amp;gt;|OpenAI API| OpenAI[OpenAI Realtime API]\n  OpenAI --&amp;gt; Edge\n  Edge --&amp;gt;|WebSocket| ESP32\n  ESP32 --&amp;gt; User[AI Generated Speech]\n&quot;}" data-plain="flowchart TD
  User[User Speech] --> ESP32
  ESP32[ESP32 Device] -->|WebSocket| Edge[Deno Edge Function]
  Edge -->|OpenAI API| OpenAI[OpenAI Realtime API]
  OpenAI --> Edge
  Edge -->|WebSocket| ESP32
  ESP32 --> User[AI Generated Speech]
">
      <pre lang="mermaid" aria-label="Raw mermaid code">flowchart TD
  User[User Speech] --&gt; ESP32
  ESP32[ESP32 Device] --&gt;|WebSocket| Edge[Deno Edge Function]
  Edge --&gt;|OpenAI API| OpenAI[OpenAI Realtime API]
  OpenAI --&gt; Edge
  Edge --&gt;|WebSocket| ESP32
  ESP32 --&gt; User[AI Generated Speech]
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<section data-identity="c2843843-c98d-4ca7-bdf2-6a2332934d9e" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;graph TD\n  repo[ElatoAI]\n  repo --&amp;gt; frontend[Frontend Vercel NextJS]\n  repo --&amp;gt; deno[Deno Edge Function]\n  repo --&amp;gt; esp32[ESP32 Arduino Client]\n  deno --&amp;gt; supabase[Supabase DB]\n\n  frontend --&amp;gt; supabase\n  esp32 --&amp;gt; websockets[Secure WebSockets]\n  esp32 --&amp;gt; opus[Opus Codec]\n  esp32 --&amp;gt; audio_tools[arduino-audio-tools]\n  esp32 --&amp;gt; libopus[arduino-libopus]\n  esp32 --&amp;gt; ESPAsyncWebServer[ESPAsyncWebServer]\n&quot;}" data-plain="graph TD
  repo[ElatoAI]
  repo --> frontend[Frontend Vercel NextJS]
  repo --> deno[Deno Edge Function]
  repo --> esp32[ESP32 Arduino Client]
  deno --> supabase[Supabase DB]

  frontend --> supabase
  esp32 --> websockets[Secure WebSockets]
  esp32 --> opus[Opus Codec]
  esp32 --> audio_tools[arduino-audio-tools]
  esp32 --> libopus[arduino-libopus]
  esp32 --> ESPAsyncWebServer[ESPAsyncWebServer]
">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph TD
  repo[ElatoAI]
  repo --&gt; frontend[Frontend Vercel NextJS]
  repo --&gt; deno[Deno Edge Function]
  repo --&gt; esp32[ESP32 Arduino Client]
  deno --&gt; supabase[Supabase DB]

  frontend --&gt; supabase
  esp32 --&gt; websockets[Secure WebSockets]
  esp32 --&gt; opus[Opus Codec]
  esp32 --&gt; audio_tools[arduino-audio-tools]
  esp32 --&gt; libopus[arduino-libopus]
  esp32 --&gt; ESPAsyncWebServer[ESPAsyncWebServer]
</pre>
    </div>
  <span role="presentation">
    <span data-view-component="true">
      <span>Loading</span>
</span>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">⚙️ PlatformIO Configuration</h2><a id="user-content-️-platformio-configuration" aria-label="Permalink: ⚙️ PlatformIO Configuration" href="#️-platformio-configuration"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="[env:esp32-s3-devkitc-1]
platform = espressif32 @ 6.10.0
board = esp32-s3-devkitc-1
framework = arduino
monitor_speed = 115200

lib_deps =
    bblanchon/ArduinoJson@^7.1.0
    links2004/WebSockets@^2.4.1
    ESP32Async/ESPAsyncWebServer@^3.7.6
    https://github.com/esp-arduino-libs/ESP32_Button.git#v0.0.1
    https://github.com/pschatzmann/arduino-audio-tools.git#v1.0.1
    https://github.com/pschatzmann/arduino-libopus.git#a1.1.0"><pre><span>[env:esp32-s3-devkitc-1]</span>
<span>platform</span> = espressif32 @ 6.10.0
<span>board</span> = esp32-s3-devkitc-1
<span>framework</span> = arduino
<span>monitor_speed</span> = 115200

<span>lib_deps</span> =
    bblanchon/ArduinoJson@^7.1.0
    links2004/WebSockets@^2.4.1
    ESP32Async/ESPAsyncWebServer@^3.7.6
    https://github.com/esp-arduino-libs/ESP32_Button.git<span><span>#</span>v0.0.1</span>
    https://github.com/pschatzmann/arduino-audio-tools.git<span><span>#</span>v1.0.1</span>
    https://github.com/pschatzmann/arduino-libopus.git<span><span>#</span>a1.1.0</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">📊 Important Stats</h2><a id="user-content--important-stats" aria-label="Permalink: 📊 Important Stats" href="#-important-stats"></a></p>
<ul dir="auto">
<li>⚡️ <strong>Latency</strong>: &lt;1s round-trip globally</li>
<li>🎧 <strong>Audio Quality</strong>: Opus codec at 24kbps (high clarity)</li>
<li>⏳ <strong>Uninterrupted Conversations</strong>: Up to 10 minutes continuous conversations</li>
<li>🌎 <strong>Global Availability</strong>: Optimized with edge computing with Deno</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🛡 Security</h2><a id="user-content--security" aria-label="Permalink: 🛡 Security" href="#-security"></a></p>
<ul dir="auto">
<li>Secure WebSockets (WSS) for encrypted data transfers</li>
<li>Optional: API Key encryption with 256-bit AES</li>
<li>Supabase DB for secure authentication</li>
<li>Supabase RLS for all tables</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚫 Limitations</h2><a id="user-content--limitations" aria-label="Permalink: 🚫 Limitations" href="#-limitations"></a></p>
<ul dir="auto">
<li>3-4s Cold start time while connecting to edge server</li>
<li>Limited to upto 10 minutes of uninterrupted conversations</li>
<li>Edge server stops when wall clock time is exceeded</li>
<li>No speech interruption detection on ESP32</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🤝 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 🤝 Contributing" href="#-contributing"></a></p>
<ol dir="auto">
<li>Looking for Speech Interruption detection on ESP32</li>
<li>Adding Arduino IDE support</li>
<li>Adding tool calling support on Deno Edge</li>
</ol>
<p dir="auto">We welcome contributions</p>
<ul dir="auto">
<li>Fork this repository.</li>
<li>Create your feature branch (<code>git checkout -b feature/EpicFeature</code>).</li>
<li>Commit your changes (<code>git commit -m 'Add EpicFeature'</code>).</li>
<li>Push to the branch (<code>git push origin feature/EpicFeature</code>).</li>
<li>Open a PR</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - see the <a href="https://github.com/akdeb/ElatoAI/blob/main/LICENSE">LICENSE</a> file for details.</p>
<hr>
<p dir="auto"><strong>If you find this project interesting or useful, drop a GitHub ⭐️. It helps a lot!</strong></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Abusing DuckDB-WASM by making SQL draw 3D graphics (Sort Of) (180 pts)]]></title>
            <link>https://www.hey.earth/posts/duckdb-doom</link>
            <guid>43761998</guid>
            <pubDate>Tue, 22 Apr 2025 13:35:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.hey.earth/posts/duckdb-doom">https://www.hey.earth/posts/duckdb-doom</a>, See on <a href="https://news.ycombinator.com/item?id=43761998">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="__next"><article dir="ltr"><h2>Abusing DuckDB-WASM by making SQL draw 3D graphics (Sort Of)</h2><h2>Building a SQL-Powered Doom Clone in the Browser<span id="building-a-sql-powered-doom-clone-in-the-browser"></span><a href="#building-a-sql-powered-doom-clone-in-the-browser" aria-label="Permalink for this section"></a></h2>
<p>I had this slightly crazy idea: Could I ditch most of the conventional JavaScript game loop and rendering logic and build a 3D game engine where <strong>SQL queries</strong> did the heavy lifting? Naturally, I decided to try building a primitive, text-based Doom clone to see how far I could push it using <strong>DuckDB-WASM</strong>.</p>
<p><img alt="A screenshot of the text-based Doom clone, showing the 3D view and minimap" loading="lazy" width="922" height="536" decoding="async" data-nimg="1" srcset="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1080&amp;q=75 1x, https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1920&amp;q=75 2x" src="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.5f9e25b8.png&amp;w=1920&amp;q=75"></p>
<p>Spoiler: It <em>kind of</em> works, it was often painful, but I learned a ton about the surprising power (and quirks) of running an analytical database engine in the browser for tasks it was definitely not designed for.</p>
<h2>The Setup: SQL Isn't Just for <code dir="ltr">SELECT *</code> Anymore<span id="the-setup-sql-isnt-just-for-select--anymore"></span><a href="#the-setup-sql-isnt-just-for-select--anymore" aria-label="Permalink for this section"></a></h2>
<p>Forget managing game state in JavaScript objects or drawing pixels with Canvas/WebGL. My approach looked like this:</p>
<ol>
<li>
<p><strong>The Database is the World:</strong> The 16x16 map, player coordinates (<code dir="ltr">x</code>, <code dir="ltr">y</code>, <code dir="ltr">dir</code>), enemy/bullet positions, game settings – everything lives in DuckDB tables, right there in the browser tab.</p>

</li>
<li>
<p><strong>SQL Dictates Reality:</strong></p>
<ul>
<li>Want to move forward? <code dir="ltr">UPDATE player SET x = x + COS(dir)*step, y = y + SIN(dir)*step;</code></li>
<li>Bullet hits a wall? <code dir="ltr">DELETE FROM bullets WHERE EXISTS (SELECT 1 FROM map WHERE ...)</code></li>
<li>Enemy fragged? A <code dir="ltr">JOIN</code> between <code dir="ltr">bullets</code> and <code dir="ltr">enemies</code> followed by <code dir="ltr">DELETE</code> statements.</li>
</ul>

</li>
<li>
<p><strong>The Renderer is a SQL <code dir="ltr">VIEW</code>:</strong> This is where it gets wild. I defined a SQL <code dir="ltr">VIEW</code> named <code dir="ltr">render_3d_frame</code> that actually performs raycasting and renders the 3D scene. This beast uses recursive CTEs to cast rays for each screen column, calculates wall distances (with fish-eye correction!), determines the height of the wall slice for that column, and then uses <code dir="ltr">string_agg</code> to stitch together the characters (<code dir="ltr">' '</code>, <code dir="ltr">.</code>, <code dir="ltr">█</code>, <code dir="ltr">▓</code>, <code dir="ltr">▒</code>, <code dir="ltr">░</code>) for each row of the final text frame.</p>
<p>Here's the core of the raycasting algorithm in SQL:</p>

<p>Yes, SQL is calculating perspective and drawing characters. DuckDB's recursive CTE capabilities are unexpectedly powerful for this kind of work.</p>
</li>
<li>
<p><strong>JavaScript Glues It Together (and Handles Sprites):</strong> My JS code became the orchestrator. It handles keyboard input, runs the <code dir="ltr">setInterval</code> game loop, calls the SQL view to get the background frame, <em>then</em> fetches entity (bullet/enemy) positions and pre-calculated wall distances (from <em>another</em> SQL view!). It performs a quick Z-buffer check in JS to see if a sprite is closer than the wall at its projected screen column, draws it onto the background frame if it is, and finally outputs the resulting text onto a <code dir="ltr">&lt;pre&gt;</code> tag.</p>

</li>
</ol>
<p>Essentially, I took DuckDB-WASM – designed for fast analytics – and coerced it into acting like a state machine and a rudimentary rendering pipeline.</p>
<h2>The Gauntlet: My Battles with Bugs, Binders, and Browsers<span id="the-gauntlet-my-battles-with-bugs-binders-and-browsers"></span><a href="#the-gauntlet-my-battles-with-bugs-binders-and-browsers" aria-label="Permalink for this section"></a></h2>
<p>This wasn't exactly a smooth ride. Here's a log of some of the more... memorable... challenges and the fixes that eventually worked:</p>
<h3>1. The Initial Roadblock: DuckDB-WASM Just Wouldn't Load (404s)<span id="1-the-initial-roadblock-duckdb-wasm-just-wouldnt-load-404s"></span><a href="#1-the-initial-roadblock-duckdb-wasm-just-wouldnt-load-404s" aria-label="Permalink for this section"></a></h3>
<ul>
<li><strong>Pain Point:</strong> My first attempts using standard CDN links for the worker script just flat-out failed with <code dir="ltr">net::ERR_ABORTED 404</code>. Debugging WASM loading issues in the browser isn't always intuitive.</li>
<li><strong>The Fix:</strong> Digging into the DuckDB-WASM docs revealed the more robust initialization pattern: using their helper functions (<code dir="ltr">getJsDelivrBundles</code>) or explicitly selecting a bundle (<code dir="ltr">mvp</code> for max compatibility), creating the worker via <code dir="ltr">URL.createObjectURL(new Blob(...))</code>, and using the <code dir="ltr">+esm</code> CDN endpoint for the main module import.</li>
</ul>

<p>The lesson: When working with WASM libraries, always follow the recommended initialization patterns from the library authors.</p>
<h3>2. SQL Dialect Gotchas: <code dir="ltr">AUTOINCREMENT</code> vs. <code dir="ltr">SEQUENCE</code><span id="2-sql-dialect-gotchas-autoincrement-vs-sequence"></span><a href="#2-sql-dialect-gotchas-autoincrement-vs-sequence" aria-label="Permalink for this section"></a></h3>
<ul>
<li><strong>Pain Point:</strong> Muscle memory from SQLite/MySQL led me to use <code dir="ltr">AUTOINCREMENT</code> for the <code dir="ltr">bullets</code> table ID. DuckDB promptly slapped me with a <code dir="ltr">Parser Error: syntax error at or near "AUTOINCREMENT"</code>.</li>
<li><strong>The Fix:</strong> Remembering that DuckDB adheres more closely to standard SQL sequences. This meant <code dir="ltr">CREATE SEQUENCE my_seq;</code> and then <code dir="ltr">CREATE TABLE ... (id INTEGER PRIMARY KEY DEFAULT nextval('my_seq'), ...)</code>.</li>
</ul>

<p>This highlights an important point about DuckDB: it's not just SQLite in the browser. It has its own SQL dialect with nuances from PostgreSQL and standard SQL.</p>
<h3>3. Fighting the Query Planner (Binder Errors &amp; Table Functions)<span id="3-fighting-the-query-planner-binder-errors--table-functions"></span><a href="#3-fighting-the-query-planner-binder-errors--table-functions" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> This one drove me nuts for a while. I tried using <code dir="ltr">generate_series(0, settings.view_w - 1)</code> inside my rendering <code dir="ltr">VIEW</code>. The binder freaked out with errors like <code dir="ltr">Table function cannot contain subqueries</code> and even <code dir="ltr">Conversion Error: Could not convert string 's.view_w' to INT32</code>.</p>
</li>
<li>
<p><strong>The Fix:</strong> I had to restructure the view logic significantly. Instead of generating the exact range needed, I generated a <em>fixed, oversized</em> range (like 0-255) first, then added another CTE layer to <em>filter</em> that oversized range using the actual <code dir="ltr">view_w</code> from the settings CTE.</p>
</li>
</ul>

<p>I also initially forgot to alias the output of <code dir="ltr">generate_series</code>, leading to <code dir="ltr">Referenced column "value" not found</code> errors. Fixed with <code dir="ltr">generate_series(...) AS gs(col)</code>.</p>
<p>This approach satisfied the query planner, even though it's less elegant. It taught me that SQL query planners have strict rules about how and when references can be resolved, especially with table-generating functions.</p>
<h3>4. The Dreaded <code dir="ltr">async</code>/<code dir="ltr">setInterval</code> Race Condition<span id="4-the-dreaded-asyncsetinterval-race-condition"></span><a href="#4-the-dreaded-asyncsetinterval-race-condition" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> My game loop was simple: <code dir="ltr">setInterval(async () =&gt; { await tick(); await render(); }, 150)</code>. But because <code dir="ltr">tick()</code> and <code dir="ltr">render()</code> involved <code dir="ltr">async</code> database calls, sometimes a new interval would fire before the previous one finished. This was most obvious with the temporary <code dir="ltr">collisions</code> table used for bullet hits – I'd get rapid-fire "table <code dir="ltr">collisions</code> does not exist!" followed by "table <code dir="ltr">collisions</code> already exists!" errors.</p>
</li>
<li>
<p><strong>The Fix:</strong> A classic solution: a simple boolean lock (<code dir="ltr">isProcessingTick</code>). The interval callback now checks this flag; if true, it bails immediately. If false, it sets the flag, runs the async work in a <code dir="ltr">try...finally</code>, and clears the flag in the <code dir="ltr">finally</code> block, ensuring it's always released.</p>
</li>
</ul>

<p>This was a classic reminder that asynchronous timing with recurring events needs careful handling, especially when database operations are involved.</p>
<h3>5. Sprites: Beyond the SQL Background (Z-Buffer Logic)<span id="5-sprites-beyond-the-sql-background-z-buffer-logic"></span><a href="#5-sprites-beyond-the-sql-background-z-buffer-logic" aria-label="Permalink for this section"></a></h3>
<ul>
<li>
<p><strong>Pain Point:</strong> The SQL view rendered walls/floor/ceiling beautifully (well, beautifully for text mode). But enemies and bullets were just data. Drawing them required knowing <em>if they were hidden by a wall</em>.</p>
</li>
<li>
<p><strong>The Fix:</strong> A hybrid approach combining SQL and JavaScript. I created <em>another</em> SQL view (<code dir="ltr">column_distances</code>) specifically to output the distance to the nearest wall for each screen column:</p>
</li>
</ul>

<p>Then, in my JavaScript <code dir="ltr">render3d</code> function, I performed the Z-buffer check by comparing entity depth to wall depth for each screen column.</p>
<h2>Performance and Results<span id="performance-and-results"></span><a href="#performance-and-results" aria-label="Permalink for this section"></a></h2>
<p>How did it actually run? Surprisingly well, considering what we're asking SQL to do. On a modern laptop, I get about 6-7 FPS with the 150ms game loop interval. The most expensive operation is the SQL raycasting view, which takes about 80-100ms to execute. The sprite rendering in JavaScript is quite fast in comparison.</p>
<p><img alt="A GIF showing gameplay with player movement and shooting" loading="lazy" width="870" height="508" decoding="async" data-nimg="1" srcset="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1080&amp;q=75 1x, https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1920&amp;q=75 2x" src="https://www.hey.earth/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fduckdb-doom.3aba91f6.gif&amp;w=1920&amp;q=75"></p>
<p>Here's what the game looks like in action. The main view shows the 3D perspective with text-based graphics, while the smaller box in the corner shows a top-down minimap. You can see how the walls are rendered with different characters based on distance, giving a primitive 3D effect.</p>
<p>The movement feels responsive enough, and the SQL-based collision detection works well. There's something strangely satisfying about mowing down enemies with SQL <code dir="ltr">DELETE</code> statements.</p>
<h2>Pushing SQL to Its Limits: What I Learned<span id="pushing-sql-to-its-limits-what-i-learned"></span><a href="#pushing-sql-to-its-limits-what-i-learned" aria-label="Permalink for this section"></a></h2>
<p>This experiment taught me several important lessons about both SQL and browser-based development:</p>
<ol>
<li>
<p><strong>SQL is surprisingly powerful for non-traditional use cases.</strong> It's not just for data retrieval. The combination of recursive CTEs, window functions, and aggregate functions makes complex algorithms possible.</p>
</li>
<li>
<p><strong>DuckDB-WASM is impressively performant.</strong> Running an analytical database engine in the browser that can handle complex recursive queries 6-7 times per second is no small feat.</p>
</li>
<li>
<p><strong>The boundaries between languages can be blurred.</strong> This project combined SQL for game state and rendering fundamentals, with JavaScript for orchestration and sprite handling. Neither could have done the job alone.</p>
</li>
<li>
<p><strong>Debugging across language boundaries is challenging.</strong> When something went wrong, it wasn't always clear if the issue was in the JavaScript, the SQL, or at the interface between them. I added extensive logging to track the flow between components.</p>
</li>
<li>
<p><strong>Query planning is a complex art.</strong> I had to work around many limitations of how SQL planners work, especially around table function evaluation and CTEs.</p>
</li>
</ol>
<h2>Would I Recommend This Approach?<span id="would-i-recommend-this-approach"></span><a href="#would-i-recommend-this-approach" aria-label="Permalink for this section"></a></h2>
<p>For a production game? Absolutely not. It's a fun hack, but there are much better tools for game development.</p>
<p>But as a learning exercise? 100% yes. This project forced me to think deeply about:</p>
<ul>
<li>SQL query optimization and execution planning</li>
<li>Raycasting algorithms and 3D projection</li>
<li>Asynchronous JavaScript patterns</li>
<li>The capabilities and limitations of WASM in the browser</li>
</ul>
<h2>Try It Yourself!<span id="try-it-yourself"></span><a href="#try-it-yourself" aria-label="Permalink for this section"></a></h2>
<p>If you want to experiment with this SQL-powered monstrosity yourself, I've put the <a target="_blank" rel="noreferrer" href="https://github.com/patricktrainer/duckdb-doom">full source code on GitHub<span> (opens in a new tab)</span></a>. It's about 500 lines of code total, with roughly half being SQL and half JavaScript.</p>
<p>I'd love to see how far others can push this concept. Could you add textures? Implement a more complex game world? Add enemies that move and shoot back? The SQL rabbit hole goes deep!</p>
<h2>What's Next?<span id="whats-next"></span><a href="#whats-next" aria-label="Permalink for this section"></a></h2>
<p>This experiment has me wondering what other unconventional uses might exist for DuckDB-WASM in the browser. Physics simulations? Path finding algorithms? Full-text search engines?</p>
<p>Sometimes the most interesting projects come from using tools in ways they were never intended to be used. What weird DuckDB-WASM experiment would you like to see next?</p><small>not made by a 🤖</small></article><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The raccoons who made computer magazine ads great (141 pts)]]></title>
            <link>https://technologizer.com/home/2025/04/22/pc-connection-ads-raccoons/</link>
            <guid>43761633</guid>
            <pubDate>Tue, 22 Apr 2025 13:06:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://technologizer.com/home/2025/04/22/pc-connection-ads-raccoons/">https://technologizer.com/home/2025/04/22/pc-connection-ads-raccoons/</a>, See on <a href="https://news.ycombinator.com/item?id=43761633">Hacker News</a></p>
<div id="readability-page-1" class="page"><article id="post-6020" itemtype="https://schema.org/CreativeWork" itemscope="itemscope">

	
	
<div data-ast-blocks-layout="true" itemprop="text">

		
		
<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="768" height="636" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-pub-1.png?resize=768%2C636&amp;ssl=1" alt="PC Connection ad with raccoons in pub" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-pub-1.png?w=841&amp;ssl=1 841w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-pub-1.png?resize=300%2C249&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-pub-1.png?resize=768%2C636&amp;ssl=1 768w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Do you mean to tell me you never play Microsoft Flight Simulator at your local pub? Art by Erick Ingraham from a December 1984 PC Connection ad.</figcaption></figure>



<p>When I got my first job in technology journalism, my grandmother used to call the magazine where I worked “your catalog.” I winced. But in retrospect, she wasn’t that far off. Back then, if you wanted to buy a computer product—this was the early 1990s, before the web changed everything—the odds were pretty decent that you started by buying a computer magazine.</p>



<p>If you remember the <a href="https://technologizer.com/2023/04/15/the-end-of-computer-magazines-in-america/index.html">computer magazines of this era</a> at all, you recall how thick they were—hundreds and hundreds of pages an issue in the case of the most successful ones. The majority of those pages were ads, not editorial content. And a sizable chunk of those ads were catalog-y in the extreme. Pages and pages were devoted to lists of products and prices in teensy type, with 1-800 numbers you could call to place an order.</p>



<p>About a gazillion mail-order houses did business this way. The April 1991 <em>PC World</em>, for instance, includes advertisements for outfits such as Advanced Computer Products, Arlington Computer Products, Bulldog Computer Products, Computer Bazaar, Fast Micro, Kenosha Computer Center, NSI Computer Products, Paradise Computer Products, Telemart, and United Computer Express. Only the names and slightly varying levels of ad-design proficiency served to distinguish most of them.</p>



<p>But I regarded three of these companies as the industry’s giants. Whether they were the biggest, revenue-wise, I’m still not sure. It was their sustained prominence in major magazines, with multi-page spreads, that made them feel like behemoths.</p>



<p>One was The PC Zone, whose ads didn’t have <em>that </em>much of a distinct personality beyond a logo that vaguely evoked Rod Serling’s <em>The Twilight Zone</em>.</p>



<figure><img data-recalc-dims="1" decoding="async" width="719" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?resize=719%2C1024&amp;ssl=1" alt="PZ Zone ad" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?resize=719%2C1024&amp;ssl=1 719w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?resize=211%2C300&amp;ssl=1 211w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?resize=768%2C1094&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?resize=1078%2C1536&amp;ssl=1 1078w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/pczone.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 719px) 100vw, 719px"><figcaption>Most of these products are long, long gone, but a few still exist in 2025.</figcaption></figure>



<p>Then there was Micro Warehouse, best known for plastering its ads with photos of a winsome, headset-wearing sales rep named Kerry. I <em>think</em> she was a real person who actually worked there—if not, please don’t tell me.</p>



<figure><img data-recalc-dims="1" decoding="async" width="748" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?resize=748%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?resize=748%2C1024&amp;ssl=1 748w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?resize=768%2C1051&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?resize=1123%2C1536&amp;ssl=1 1123w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/microwareouse.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 748px) 100vw, 748px"><figcaption>I do hope that the NeXT computer Micro Warehouse gave away really did come with an image of Kerry.</figcaption></figure>



<p>But the crème de la mail-order crème was a company called PC Connection.</p>



<p>In a field where it was hard for any one merchant to stand out, PC Connection’s ads were vastly more distinctive than the competition’s. They might even one of the most memorable elements of any given issue of a magazine—yes, including the editorial material.</p>



<p>It wasn’t because of the portion dedicated to the business at hand. As you can see from this sample page from the October 29, 1991 <em>PC Magazine</em>, that aspect of a PC Connection advertisement was not radically different from a PC Zone or Micro Warehouse ad.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="748" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?resize=748%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?resize=748%2C1024&amp;ssl=1 748w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?resize=768%2C1052&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?resize=1121%2C1536&amp;ssl=1 1121w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2174.jpeg?w=1268&amp;ssl=1 1268w" sizes="auto, (max-width: 748px) 100vw, 748px"><figcaption>The “Going back to” is the first part of a headline spread over several pages.</figcaption></figure>



<p>No, what made PC Connection ads unique was the imagery of anthropomorphic raccoons, the work of an illustrator named Erick Ingraham. Here they are in that same 1991 <em>PC Magazine</em> ad.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="757" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?resize=757%2C1024&amp;ssl=1" alt="1991 PC Connection ad with raccoon making apple pies" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?resize=757%2C1024&amp;ssl=1 757w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?resize=222%2C300&amp;ssl=1 222w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?resize=768%2C1039&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?resize=1135%2C1536&amp;ssl=1 1135w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2176.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 757px) 100vw, 757px"><figcaption>The “Going back to” is the first part of a headline spread over several pages.</figcaption></figure>



<p>If you inspect the art closely enough, you’ll spot some boxes of vintage 1991 software, including The Microsoft Office (which, like TheFacebook.com, eventually lost its “The”). But they’re Easter eggs in a scene that is mostly about raccoons making pies—assisted by a bunny rabbit and a beaver—and playing what I assume is folk music. The piece looks like an illustration from a classy children’s book. That made sense, since Ingraham’s work in that field helped him secure his PC Connection assignment.</p>



<p>What on Earth was this beautifully done, homey scene—part Beatrix Potter, part Norman Rockwell—doing in a mail-order ad for computer products? The text below, by copywriter David Blistein, acknowledged that people might find it puzzling. It went on to explain that PC Connection was based in tiny Marlow, New Hampshire (population 567) and prided itself on good customer service. The point of the characters, it said, was to add “a human touch to high tech.”</p>



<p>It worked. And the fact that Ingraham’s art and Blistein’s copy changed in each new ad gave magazine readers a reason to stop and pay attention. (Even Micro Warehouse’s Kerry didn’t do anything but sit there leaning on a monitor.)</p>



<p>The golden age of PC Connection raccoon ads began in 1983 and ended well over thirty years ago. After that, the characters retained a diminished presence in the company’s marketing into the early years of this century. Then they almost wholly vanished. They have, however, remained lodged somewhere in the back of my brain. That was true even though I caught only the tail end of their heyday. (I was <a href="https://technologizer.com/2010/07/23/amiga/">an Amiga fanatic </a>until 1991, and made a point of ignoring the Microsoft-centric magazines where PC Connection advertised.)</p>



<p>Recently, I was shocked to find that nobody has ever told the raccoons’ story. Hence this article.</p>



<p>Behind the scenes, PC Connection really was a small-town success story. The company was founded by Patricia Gallup and David Hall, who’d met by chance in 1975 when both were hiking the Appalachian Trail. Gallup ended up working at Hall’s family business, a mail-order purveyor of professional audio components in Marlow. When the IBM PC came along in 1981, the company bought one to computerize its business. So did lots of other folks, creating a thriving market for software, peripherals, and various accessories.</p>



<p>In 1982, that inspired Gallup and Hall to start a new company dedicated to selling everything relating to IBM PCs but the PC itself. Bootstrapping their brainchild with $8,000 Gallup had saved, they called it PC Connection and set up shop in a former mill, colocated with the Hall family business.</p>



<p>Then they placed a nondescript ninth-of-a-page ad in <em>Byte</em> magazine, buried near the back where the space was cheaper.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="719" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/Screenshot-2025-01-30-at-11.00.58%E2%80%AFPM.png?resize=719%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/Screenshot-2025-01-30-at-11.00.58%E2%80%AFPM.png?resize=719%2C1024&amp;ssl=1 719w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/Screenshot-2025-01-30-at-11.00.58%E2%80%AFPM.png?resize=211%2C300&amp;ssl=1 211w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/Screenshot-2025-01-30-at-11.00.58%E2%80%AFPM.png?w=768&amp;ssl=1 768w" sizes="auto, (max-width: 719px) 100vw, 719px"></figure>



<p>By July of the following year, PC Connection had grown prominent enough that <em>PC Magazine</em> devoted four pages to an <a href="https://books.google.com/books?id=V2588uIxmAQC&amp;pg=PA188&amp;dq=%E2%80%9CDavid+hall%E2%80%9D&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiNz7_h2OWMAxVkF1kFHdbjBCQQ6AF6BAgEEAM#v=onepage&amp;q=%E2%80%9CDavid%2520hall%E2%80%9D&amp;f=false">interview</a> with Hall. The Q&amp;A covered the startup’s rural operation, generous shipping policy (a flat $2 per order except for “a heavy item such as a monitor, drive, or printer”), and the complications inherent in selling PC products in an era when many weren’t that easy to figure out and almost every customer was a newbie.</p>



<p>“If someone wants us to take him through every step of [Lotus] 1-2-3, that’s a lot to ask,” Hall told <em>PC Mag</em>‘s Corey Sandler. But “Let’s say someone buys a board, gets it home, and then realizes he doesn’t know what he’s doing. If he calls us on the phone, our technical man will step him right through the whole installation, tell him how to set the switches, and make sure he’s happy. That’s my idea of support.”</p>



<p>As PC Connection flourished, its marketing ambition and budget expanded. The November 1983 <em>PC Mag</em>a<em>zine </em>included a three-page ad, with two of those pages featuring the standard dense list of product names and prices. But the third showed a happy customer and emphasized the company’s toll-free support and speedy shipping, which it argued were more important than rock-bottom prices. By the standards of mail-order ads of the time, it was an ambitious branding effort.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="747" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?resize=747%2C1024&amp;ssl=1" alt="PC Connection ad" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?resize=747%2C1024&amp;ssl=1 747w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?resize=768%2C1053&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?resize=1120%2C1536&amp;ssl=1 1120w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/myconnection.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 747px) 100vw, 747px"></figure>



<p>In the next issue, PC Connection did even more to stand out. The company ran a three-page ad—wedged in the middle of an <a href="https://books.google.com/books?id=05wAGZQlo9QC&amp;lpg=PP1&amp;pg=PA196#v=onepage&amp;q&amp;f=false">interview</a> with software legend Grace Hopper—whose first page depicting a warmly-dressed raccoon, keyboard slung over his shoulder, huddling outside its headquarters, which at the time were in a rehabbed Marlow inn. I’m unsure if he’s seeking shelter from the snow or just wants to purchase some accoutrements for his computer. But it’s a striking image that plays up PC Connection’s remote location—“only a five day drive from Silicon Valley”—as a defining selling point.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="735" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?resize=735%2C1024&amp;ssl=1" alt="PC Connection “PC Paradise” ad" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?resize=735%2C1024&amp;ssl=1 735w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?resize=768%2C1071&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?resize=1102%2C1536&amp;ssl=1 1102w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2190.jpeg?w=1193&amp;ssl=1 1193w" sizes="auto, (max-width: 735px) 100vw, 735px"></figure>



<p>That “PC Paradise” ad and the ones to follow were the work of Church and Main, a New Hampshire ad agency—named after the intersection where its office stood—that had gotten its big break doing work for a manufacturer of ball bearings. Its prominence in the state led PC Connection cofounder Hall to challenge it during a brainstorming meeting at the company: How do you get people to not only buy PC products but buy them from a faceless, far-off mail-order operation?</p>



<p>Hall was open to possibilities that were “weird” and “non-traditional,” remembers Church and Main art director Michael Havey. As copywriter Blistein puts it, “Computers were very scary to people—and David wanted to make them less scary.”</p>



<p>Church and Main’s answer was a raccoon.</p>



<p>”You’re probably wondering, ‘Why a raccoon?’” Havey told me once I’d tracked him down, guessing correctly. “To tell you the truth, I don’t know whether I ever knew why.” There <em>is</em> an official PC Connection boilerplate story. Raccoons, it declares, “symbolized adaptability, innovation, and tenacity—traits that underlie the company’s remarkable success.” But that rationale may have been conjured up only in retrospect.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="300" height="252" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1947.jpeg?resize=300%2C252&amp;ssl=1" alt="Mole, Toad, and Rat by Ernest Shepard" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1947.jpeg?resize=300%2C252&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1947.jpeg?w=596&amp;ssl=1 596w" sizes="auto, (max-width: 300px) 100vw, 300px"><figcaption>Mole, Toad, and Rat, from <em>The Wind in the Willows</em></figcaption></figure>



<p>This much we do know: Blistein and his wife happened to be reading Kenneth Grahame’s 1908 book <em>The Wind in the Willows</em> to their young daughter. Originally published without pictures, Grahame’s work got its most familiar art in a 1931 edition with drawings by Ernest Shepard, who was even better known as the illustrator of A.A. Milne’s <em>Winnie the Pooh</em> books. Featuring the adventures of British motoring enthusiast Mr. Toad and his friends, the world Grahame and Shepard created was quaint, cozy, and charming. It had nothing to do with PCs, but it was the furthest thing from scary.</p>



<p>“I had this image—I <em>think</em> it was me—of a mole or an otter, whatever was in <em>The Wind in the Willows</em>, walking in with a computer over its shoulder,” says Blistein. The notion of animal characters led Havey to call in Ingraham, a local artist whose work included the award-winning illustrations for a children’s book called <em>Porcupine Stew</em>.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="238" height="300" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?resize=238%2C300&amp;ssl=1" alt="Porcupine Stew book" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?resize=238%2C300&amp;ssl=1 238w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?resize=813%2C1024&amp;ssl=1 813w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?resize=768%2C968&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?resize=1219%2C1536&amp;ssl=1 1219w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?w=1587&amp;ssl=1 1587w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/porcupinestew.jpeg?w=1536&amp;ssl=1 1536w" sizes="auto, (max-width: 238px) 100vw, 238px"><figcaption>Ingraham’s cover for the 1982 book <em>Porcupine Stew</em>.</figcaption></figure>



<p>“There were other illustrators who could have done it,” Havey says. “But&nbsp;there was no illustrator right here in rural New Hampshire, where PC Connection started, who had the time, the interest, the incredible ability that Erick had.”&nbsp;Ingraham’s first task was to turn the spark of an idea into exploratory sketches depicting a variety of animals.</p>



<p>That still doesn’t explain why the one they picked was a raccoon. For years, I thought it was because the masked foragers were particularly numerous in New Hampshire. But that seems not to be the case. Instead, PC Connection’s ads cemented the association between the animals and the state in my mind, and possibly others. Ingraham does remember their remarkably dextrous paws—perfect for typing on a computer keyboard—playing a role. “Basically, we wanted something that could use its hands,” he says.</p>



<p>As unique as the “PC Paradise” ad was, it wasn’t immediately apparent it wasn’t just a one-off. Over the next few issues of <em>PC Magazine</em>, PC Connection reran it a couple of times and placed other ads that consisted solely of products and prices. But in the May 1984 issue, the lone traveling raccoon from “PC Paradise” begat a trio of picnickers who’d brought their PC and dial-up modem—and a telephone with a very long cord.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="742" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?resize=742%2C1024&amp;ssl=1" alt="PC Connection ad with picnicking raccoons" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?resize=742%2C1024&amp;ssl=1 742w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?resize=217%2C300&amp;ssl=1 217w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?resize=768%2C1060&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?resize=1112%2C1536&amp;ssl=1 1112w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/may-1984.png?w=1187&amp;ssl=1 1187w" sizes="auto, (max-width: 742px) 100vw, 742px"><figcaption>Warning: Sitting on your dot-matrix printer probably voids the warranty.</figcaption></figure>



<p>From then on, “they continued to capitalize on that format and come up with scenario after scenario,” says Ingraham, who remembers spitballing ideas over lunch to pitch to PC Connection. In each ad, his art was accompanied by a few paragraphs of text by Blistein, full of terrible puns and sideways cultural allusions, celebrations of Marlow’s tininess, and reminders of the benefits of doing business with PC Connection. “Mostly, it was just ’Hey, these are nice people in New Hampshire—you don’t have to be afraid of computers,’” Blistein says.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="211" height="300" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?resize=211%2C300&amp;ssl=1" alt="Run magazine premiere issue" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?resize=211%2C300&amp;ssl=1 211w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?resize=721%2C1024&amp;ssl=1 721w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?resize=768%2C1091&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?resize=1081%2C1536&amp;ssl=1 1081w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_1926.jpeg?w=1148&amp;ssl=1 1148w" sizes="auto, (max-width: 211px) 100vw, 211px"><figcaption>Another Erick Ingraham computer-related assignment: <em>Run</em> magazine’s January 1984 premiere cover.</figcaption></figure>



<p>For years, painting raccoons for PC Connection ads was a commercial artist’s dream gig—enjoyable, steady, and well-paying. Ingraham took around 40 hours to complete each piece and settled on acrylic paints as his medium, in part because they dried more quickly than oils. “Everything was in crunch mode,” he remembers. “[Havey] would be coming at 8:00 in the morning to pick it up, and I’m working at 5:00”</p>



<p>Each of Ingraham’s illustrations—which got larger, lusher, and more lavishly detailed over time—showed raccoons (and, often, other animals) engaged in some activity, frequently in a visibly rural setting. Early examples did tend to give PCs and related products a prime spot. (Ingraham, not yet a computer user himself, worked off reference photos.) This one, showing a PC Connection customer on the phone with the company while unboxing a new computer—complete with Epson FX-100+ printer—may have been the most tech-centric of them all.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="702" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?resize=702%2C1024&amp;ssl=1" alt="June 1985 PC Connection ad with raccoon setting up computer products" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?resize=702%2C1024&amp;ssl=1 702w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?resize=206%2C300&amp;ssl=1 206w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?resize=768%2C1120&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?resize=1053%2C1536&amp;ssl=1 1053w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jun-9-1985.jpeg?w=1158&amp;ssl=1 1158w" sizes="auto, (max-width: 702px) 100vw, 702px"><figcaption>June 1985</figcaption></figure>



<p>Over time, however, the PCs receded into the background of Ingraham’s tableaus, sometimes literally. Most of the ads just depicted the critters living their lives, which seemed to be rich and fulfilling. It wouldn’t even occur to me to wonder if the Keebler Elves ever did anything other than bake cookies. But the PC Connection raccoons did just about everything human beings do, especially in small New England towns. (The ads rarely referred to the characters as raccoons, instead calling them “our mascots.”)</p>



<p>For example, they went off to college.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="729" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?resize=729%2C1024&amp;ssl=1" alt="PC Connection ad with raccoon in college" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?resize=729%2C1024&amp;ssl=1 729w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?resize=214%2C300&amp;ssl=1 214w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?resize=768%2C1079&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?resize=1094%2C1536&amp;ssl=1 1094w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-16-1984.jpg?w=1187&amp;ssl=1 1187w" sizes="auto, (max-width: 729px) 100vw, 729px"><figcaption>October 1984</figcaption></figure>



<p>They operated a French bakery.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="719" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?resize=719%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?resize=719%2C1024&amp;ssl=1 719w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?resize=211%2C300&amp;ssl=1 211w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?resize=768%2C1094&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?resize=1078%2C1536&amp;ssl=1 1078w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-19-1985.jpg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 719px) 100vw, 719px"><figcaption>March 1985</figcaption></figure>



<p>They taught school.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="764" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?resize=764%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?resize=764%2C1024&amp;ssl=1 764w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?resize=224%2C300&amp;ssl=1 224w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?resize=768%2C1030&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?resize=1146%2C1536&amp;ssl=1 1146w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2185.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 764px) 100vw, 764px"><figcaption>June 1986</figcaption></figure>



<p>They sought elected office.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="759" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?resize=759%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?resize=759%2C1024&amp;ssl=1 759w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?resize=222%2C300&amp;ssl=1 222w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?resize=768%2C1036&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?resize=1138%2C1536&amp;ssl=1 1138w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/mar-29-1988.jpg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 759px) 100vw, 759px"><figcaption>February 1988</figcaption></figure>



<p>They honored entrepreneurship (and apparently believed PC Connection’s founder to be neither Patricia Gallup nor David Hall, but one of their own).</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="750" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?resize=750%2C1024&amp;ssl=1" alt="PC Connection ad with statue of founder" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?resize=750%2C1024&amp;ssl=1 750w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?resize=220%2C300&amp;ssl=1 220w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?resize=768%2C1049&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?resize=1125%2C1536&amp;ssl=1 1125w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/sep-13-1988-2.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 750px) 100vw, 750px"></figure>



<p>They were visited by St. Nicholas.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="738" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?resize=738%2C1024&amp;ssl=1" alt="PC Connection ad with raccoon dressed as Santy Claus" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?resize=738%2C1024&amp;ssl=1 738w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?resize=216%2C300&amp;ssl=1 216w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?resize=768%2C1065&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?resize=1107%2C1536&amp;ssl=1 1107w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-31-1989.jpg?w=1256&amp;ssl=1 1256w" sizes="auto, (max-width: 738px) 100vw, 738px"><figcaption>January 1989</figcaption></figure>



<p>They built homes.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="740" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?resize=740%2C1024&amp;ssl=1" alt="PC Connection ad with raccoons building treehouse" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?resize=740%2C1024&amp;ssl=1 740w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?resize=217%2C300&amp;ssl=1 217w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?resize=768%2C1063&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?resize=1110%2C1536&amp;ssl=1 1110w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-31-1989.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 740px) 100vw, 740px"><figcaption>October 1989</figcaption></figure>



<p>They rang in the New Year.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="753" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?resize=753%2C1024&amp;ssl=1" alt="PC Connection ad with raccoons welcoming the new year" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?resize=753%2C1024&amp;ssl=1 753w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?resize=221%2C300&amp;ssl=1 221w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?resize=768%2C1044&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?resize=1130%2C1536&amp;ssl=1 1130w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/feb-1990.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 753px) 100vw, 753px"><figcaption>February 1990</figcaption></figure>



<p>They took themselves out to the ball game.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="737" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?resize=737%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?resize=737%2C1024&amp;ssl=1 737w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?resize=216%2C300&amp;ssl=1 216w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?resize=768%2C1067&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?resize=1105%2C1536&amp;ssl=1 1105w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/nov-13-1990.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 737px) 100vw, 737px"><figcaption>September 1990</figcaption></figure>



<p>They farmed. (Someone should tell that fellow on the right with the wagon about these newfangled things called “laptop computers.”)</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="738" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?resize=738%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?resize=738%2C1024&amp;ssl=1 738w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?resize=216%2C300&amp;ssl=1 216w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?resize=768%2C1065&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?resize=1108%2C1536&amp;ssl=1 1108w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-26-1990.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 738px) 100vw, 738px"><figcaption>June 1991</figcaption></figure>



<p>They cared about the environment.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="740" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?resize=740%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?resize=740%2C1024&amp;ssl=1 740w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?resize=217%2C300&amp;ssl=1 217w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?resize=768%2C1063&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?resize=1110%2C1536&amp;ssl=1 1110w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/nov-11-1996.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 740px) 100vw, 740px"><figcaption>May 1991</figcaption></figure>



<p>They got married—and hired an owl to officiate and mice to entertain.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="747" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?resize=747%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?resize=747%2C1024&amp;ssl=1 747w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?resize=768%2C1052&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?resize=1121%2C1536&amp;ssl=1 1121w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/02/jul-1991.jpg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 747px) 100vw, 747px"><figcaption>July 1991</figcaption></figure>



<p>They went snowshoeing, and possibly got lost doing it.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="765" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?resize=765%2C1024&amp;ssl=1" alt="PC Connection ad with skiing raccoon" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?resize=765%2C1024&amp;ssl=1 765w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?resize=224%2C300&amp;ssl=1 224w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?resize=768%2C1028&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?resize=1147%2C1536&amp;ssl=1 1147w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/jan-16-1992.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 765px) 100vw, 765px"><figcaption>January 1992</figcaption></figure>



<p>As you’ve probably already noticed, all the raccoon ads above except the first one offered a premium of some sort to customers who spent at least $500 (later raised to $750 and, in at least one case, $1,000). Most of these products featured Ingraham raccoons, too. There were shirts, shopping bags, hats, mugs, puzzles, baseball bats, maple syrup, apples, stuffed animals, pillowcases, and more—enough to fill a catalog of their own had the company chosen to issue one. Each ad included an additional piece of Ingraham art related to the current freebie. (I particularly like the stoic dignity of the ball player.)</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="522" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=522%2C1024&amp;ssl=1" alt="PC Connection products" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=522%2C1024&amp;ssl=1 522w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=153%2C300&amp;ssl=1 153w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=768%2C1508&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=782%2C1536&amp;ssl=1 782w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?resize=1043%2C2048&amp;ssl=1 1043w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/raccoon-products-1.png?w=1146&amp;ssl=1 1146w" sizes="auto, (max-width: 522px) 100vw, 522px"></figure>



<p>Scour eBay with enough devotion, and you may find vintage PC Connection swag for sale from time to time. Should an “Our Founder” statuette ever come up, please don’t bid against me.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1019" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?resize=768%2C1019&amp;ssl=1" alt="PC Connection “our founder” statuette" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?resize=772%2C1024&amp;ssl=1 772w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?resize=768%2C1019&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?resize=1157%2C1536&amp;ssl=1 1157w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1943.jpeg?w=1532&amp;ssl=1 1532w" sizes="auto, (max-width: 768px) 100vw, 768px"><figcaption>Via Flickr member <a href="https://www.flickr.com/photos/blakespot/12108415816">Blake Patterson</a></figcaption></figure>



<p>Some of Ingraham’s most extravagant art appeared not in magazine ads but in PC Connection’s catalogs—an advertising medium I assumed the company would have considered instrumental from the beginning. But it waited until 1990 to issue one titled <em>The First PC Connection Catalog</em>—produced, like the ads, by Church and Main. Ingraham’s cover wasn’t another typical scene of life in Marlow. Instead, his painting featured … a raccoon sphinx and raccoon hieroglyphics.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="733" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=733%2C1024&amp;ssl=1" alt="PC Connection catalog first cover" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=733%2C1024&amp;ssl=1 733w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=215%2C300&amp;ssl=1 215w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=768%2C1073&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=1100%2C1536&amp;ssl=1 1100w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?resize=1466%2C2048&amp;ssl=1 1466w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?w=1828&amp;ssl=1 1828w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-cover.jpg?w=1536&amp;ssl=1 1536w" sizes="auto, (max-width: 733px) 100vw, 733px"></figure>



<p>Inside, a foldout, “The Origin of the PCs,” pronounced Marlow to be “the center of civilization” and chronicled the history of its raccoon population from cave days until, I guess, the 1990s. (One character is using a cordless phone.) It turns out Marlow gave us all technological progress from the wheel onward, and it was all invented by PC Connection’s mascots. Now we know.</p>



<p>This foldout is the Sistine Chapel ceiling of Ingraham raccoon art, and you can inspect it (and Blistein’s text) in more detail by clicking the image below.</p>



<figure>
<figure><a href="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?ssl=1"><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="353" data-id="6128" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=768%2C353&amp;ssl=1" alt="Origin of the PCs" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=1024%2C471&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=300%2C138&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=768%2C353&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=1536%2C706&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?resize=2048%2C941&amp;ssl=1 2048w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/origin-spread.png?w=2304&amp;ssl=1 2304w" sizes="auto, (max-width: 768px) 100vw, 768px"></a></figure>
</figure>



<p>On the reverse of the foldout, PC Connection cofounder Pat Gallup explained how all this was connected—loosely—to the mail-order computer business, and noted that the company really did conduct archeological digs in Marlow.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="726" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?resize=726%2C1024&amp;ssl=1" alt="Pat Gallup intro to 1990 PC Connection catalog" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?resize=726%2C1024&amp;ssl=1 726w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?resize=213%2C300&amp;ssl=1 213w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?resize=768%2C1083&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?resize=1089%2C1536&amp;ssl=1 1089w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/first-catalog-gallup.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 726px) 100vw, 726px"></figure>



<p>Another masterpiece: Ingraham’s “Raccoona Lisa,” from a catalog published later that year. (She’s clutching a foam peanut because PC Connection had recently eliminated them in favor of more sustainable packing materials.)</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="759" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?resize=759%2C1024&amp;ssl=1" alt="PC Connection “Raccoona Lisa” catalog cover" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?resize=759%2C1024&amp;ssl=1 759w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?resize=222%2C300&amp;ssl=1 222w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?resize=768%2C1036&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?resize=1139%2C1536&amp;ssl=1 1139w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1951.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 759px) 100vw, 759px"></figure>



<p>Here’s another catalog cover, provided for this article by Ingraham himself. (So far, the only editions I’ve laid hands on myself are the two shown above—as you can imagine, most people did not hang onto these 30+ years ago, making surviving examples quite rare.)</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1019" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?resize=768%2C1019&amp;ssl=1" alt="1992 PC Connection catalog" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?resize=772%2C1024&amp;ssl=1 772w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?resize=768%2C1018&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?resize=1159%2C1536&amp;ssl=1 1159w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/1992-catalog.jpg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>I can’t resist sharing a few examples of the material that made up the bulk of each catalog: product listings, some accompanied by evocative photos of 1990s people and 1990s computing equipment.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="512" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops.jpeg?resize=768%2C512&amp;ssl=1" alt="PC Connection listing for Epson laptops" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?resize=1024%2C682&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?resize=768%2C512&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?resize=1536%2C1024&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?resize=2048%2C1365&amp;ssl=1 2048w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/epson-laptops-scaled.jpeg?w=2304&amp;ssl=1 2304w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1019" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?resize=768%2C1019&amp;ssl=1" alt="PageMaker listing from 1990 PC Connection catalog" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?resize=772%2C1024&amp;ssl=1 772w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?resize=768%2C1018&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?resize=1159%2C1536&amp;ssl=1 1159w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pagemaker-1.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="975" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye-807x1024.png?resize=768%2C975&amp;ssl=1" alt="PC Connection catalog page for 
Private Eye headset" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye.png?resize=807%2C1024&amp;ssl=1 807w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye.png?resize=236%2C300&amp;ssl=1 236w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye.png?resize=768%2C974&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye.png?resize=1211%2C1536&amp;ssl=1 1211w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/private-eye.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="759" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2187.jpeg?resize=768%2C759&amp;ssl=1" alt="PC Connection catalog listing for Norton products" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2187.jpeg?resize=1024%2C1012&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2187.jpeg?resize=300%2C297&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2187.jpeg?resize=768%2C759&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2187.jpeg?w=1200&amp;ssl=1 1200w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>Getting back to the magazine ads: In the spring of 1992, PC Connection marked its tenth anniversary. It celebrated with an ad showing the raccoons of Marlow putting on a parade, complete with a band, marchers dressed as floppy disks, a beauty queen, and a raccoon balloon.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="743" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?resize=743%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?resize=743%2C1024&amp;ssl=1 743w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?resize=218%2C300&amp;ssl=1 218w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?resize=768%2C1058&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?resize=1115%2C1536&amp;ssl=1 1115w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/april-1992.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 743px) 100vw, 743px"></figure>



<p>That ad turned out to be the final one in the familiar format. After more than eight years of raccoon ads, PC Connection began to tinker with the formula. It no longer played up its rural location or showed the raccoons in particularly homespun activities. The swag offers also went away.</p>



<p>It was subtle, but the pitches got more direct. By then, for example, PC Connection had branded its fast, cheap shipping as “Everything Overnight” and put it at the center of its brand identity. A flat $5 charge covered overnight delivery via Airborne Express regardless of how many items you ordered: You could even call until 3 a.m. and get same-<em>day</em> delivery. It was a triumph of logistical efficiency that presaged the Amazon age, and a major differentiator from the likes of PC Zone and Micro Warehouse.</p>



<p>And so PC Connection deployed its mascots in a memorable image devoted to promoting Everything Overnight.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="726" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?resize=726%2C1024&amp;ssl=1" alt="PC Connection “Everything Overnight” ad with flying raccoons" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?resize=726%2C1024&amp;ssl=1 726w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?resize=213%2C300&amp;ssl=1 213w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?resize=768%2C1083&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?resize=1089%2C1536&amp;ssl=1 1089w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/aug-92.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 726px) 100vw, 726px"></figure>



<p>Until I wrote this article, I’d forgotten another message that PC Connection really, <em>really</em> played up: It was a repeat winner of <em>PC World</em>’s World Class awards as the best mail-order company. (This fact had slipped my mind even though I worked at <em>PC World</em> from 1994-2008.) For most of their history, these awards were based on a reader poll; they reflected the popular sentiment of computer users, and PC Connection’s pride was understandable.</p>



<p>The accomplishment resulted in an image of a beaming raccoon wearing World Class medallions (which, as far as I know, we didn’t actually bestow), Olympics-style. The company used it frequently, with minor variations, for many years. (Havey, who marvels at the lush detail Ingraham was able to coax out of his brush, says it’s his favorite piece of raccoon art.)</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="736" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?resize=736%2C1024&amp;ssl=1" alt="PC Connection ad with raccoon wearing medals " srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?resize=736%2C1024&amp;ssl=1 736w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?resize=216%2C300&amp;ssl=1 216w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?resize=768%2C1069&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?resize=1104%2C1536&amp;ssl=1 1104w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/jan-26-1993.jpeg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 736px) 100vw, 736px"><figcaption>January 1993</figcaption></figure>



<p>The beastie in that ad might have looked less triumphant if it had known what was ahead. As the 1990s progressed, the raccoons slowly receded from the spotlight in PC Connection’s marketing. There was no tragic moment when they got the axe. They just appeared less consistently, less prominently, and less often in the form of new Ingraham artwork.</p>



<p>Maybe this was inevitable. Today, Havey and Blistein both recall the company losing interest in its quirky branding as the PC market grew more commoditized. ”It all became about price,” says Blistein. “<a href="https://dfarq.homeip.net/what-happened-to-egghead-software/">Egghead Software</a> was around then. And that’s when they pushed the raccoon to the back burner.”</p>



<p>In a June 1993 ad, the company seemed to address this shift more or less directly. “Some people think that just because we have the best-looking mascots in the business, our prices must be high,” read the copy. “No way!” The ad’s raccoon art remains delightful, but it’s been downsized to make room for giant-sized selling points that mattered a lot at the time: CUSTOM, COMPAQ, CHEAP, and OVERNIGHT. $5.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="753" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?resize=753%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?resize=753%2C1024&amp;ssl=1 753w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?resize=221%2C300&amp;ssl=1 221w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?resize=768%2C1045&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?resize=1129%2C1536&amp;ssl=1 1129w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/june-15-1993.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 753px) 100vw, 753px"><figcaption>June 1993</figcaption></figure>



<p>By the end of 1993, the mascots were deemphasized further. For instance, I had to look at this ad twice before I realized it had raccoons at all.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="758" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?resize=758%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?resize=758%2C1024&amp;ssl=1 758w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?resize=222%2C300&amp;ssl=1 222w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?resize=768%2C1037&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?resize=1137%2C1536&amp;ssl=1 1137w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/dec-7-1993.png?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 758px) 100vw, 758px"><figcaption>December 1993</figcaption></figure>



<p>Eventually, the wry, low-key feel that had distinguished PC Connection’s ads was replaced by splashiness, bright colors, and copious use of exclamation points. If you were lucky, one raccoon might be crammed in somewhere, possibly confusing anyone who didn’t remember the mascot’s heyday.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="736" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?resize=736%2C1024&amp;ssl=1" alt="1996 PC Connection ad with raccoon in the corner" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?resize=736%2C1024&amp;ssl=1 736w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?resize=216%2C300&amp;ssl=1 216w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?resize=768%2C1068&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?resize=1104%2C1536&amp;ssl=1 1104w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/oct-22-1996.png?w=1244&amp;ssl=1 1244w" sizes="auto, (max-width: 736px) 100vw, 736px"><figcaption>October 1996</figcaption></figure>



<p>Along with the price wars, PC Connection’s growing emphasis on burnishing its reputation among business clients may have contributed to the raccoons’ slow-roll retirement. Ingraham knew things were changing when the company asked for art depicting one wearing a necktie. “They tried to corporate ’em up a little bit,” he says. “I kind of went with the flow. But then, eventually, they were in a big building in Milford, and I’d call there to say, ‘Any raccoon sightings?’ ‘No, not really.’” (At some point along the way, the company parted ways with Church and Main, bringing its ads in-house.)</p>



<p>The fact that PC Connection had moved from Marlow to the comparatively bustling town of Milford (population approximately 12,000) in 1996 was a sign of its continued growth. Two years after that, it relocated to Merrimack, which was around twice Milford’s size. That was the same year the company went public, issuing stock certificates bearing an image of the medallion-wearing raccoon.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="513" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-connection-stock-certificate.jpg?resize=768%2C513&amp;ssl=1" alt="PC Connection stock certificate" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-connection-stock-certificate.jpg?resize=1024%2C684&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-connection-stock-certificate.jpg?resize=300%2C200&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-connection-stock-certificate.jpg?resize=768%2C513&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/pc-connection-stock-certificate.jpg?w=1280&amp;ssl=1 1280w" sizes="auto, (max-width: 768px) 100vw, 768px"><figcaption>Via <a href="https://scripophily.net/pc-connection-inc-ipo-certificate-raccoon-vignette-delaware/">Scripophily.com</a></figcaption></figure>



<p>And then there was the internet—which, as it became PC Connection’s primary sales channel, greatly reduced its reliance on the magazine advertising that had given us the raccoons in the first place.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="892" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/Screenshot-2025-03-22-at-10.29.16%E2%80%AFPM.png?resize=768%2C892&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/Screenshot-2025-03-22-at-10.29.16%E2%80%AFPM.png?resize=882%2C1024&amp;ssl=1 882w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/Screenshot-2025-03-22-at-10.29.16%E2%80%AFPM.png?resize=258%2C300&amp;ssl=1 258w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/Screenshot-2025-03-22-at-10.29.16%E2%80%AFPM.png?resize=768%2C891&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/Screenshot-2025-03-22-at-10.29.16%E2%80%AFPM.png?w=1208&amp;ssl=1 1208w" sizes="auto, (max-width: 768px) 100vw, 768px"><figcaption>PCConnection.com circa 1997</figcaption></figure>



<p>In the new century, PC Connection almost entirely scrubbed the raccoons from its public-facing image. But not quite. A largely anodyne 2010 catalog, for example, included one fingernail-sized picture of the mascot, alongside a mention that the company had been around since 1982.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1024" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?resize=768%2C1024&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?resize=768%2C1025&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?resize=1151%2C1536&amp;ssl=1 1151w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?resize=1535%2C2048&amp;ssl=1 1535w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1882.jpeg?w=1580&amp;ssl=1 1580w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>By this point, the company had invested 100% of its energy on being a reliable supplier of technology products to corporate accounts. For reasons so obvious I’m not going to bother to explain them, it removed the “PC” from its name in 2016. David Hall died in 2020. But Patricia Gallup–remains Connection’s board chair, 43 years after betting her $8,000 in savings on the proposition that people would buy computer products through the mail. They still are, to the tune of $2.8 billion in sales in the company’s most recent fiscal year. (I’d hoped to speak to Gallup for this article, but was told she no longer grants interviews.)</p>



<p>Today, Connection’s home page looks like this. Fair warning: There’s nary a raccoon on it.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="478" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1.jpeg?resize=768%2C478&amp;ssl=1" alt="PC Connection" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?resize=1024%2C637&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?resize=300%2C187&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?resize=768%2C478&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?resize=1536%2C955&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?resize=2048%2C1274&amp;ssl=1 2048w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1868-1-scaled.jpeg?w=2304&amp;ssl=1 2304w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>I was all ready to declare that the raccoons were entirely absent from the site until I stumbled upon a dinky, nearly unrecognizable one in the customer support section. He’s wearing a jetpack and bearing a delivery, somehow still doing his duty after all these years. Maybe he’s unaware he was canned years ago. Or simply doesn’t care.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="352" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?resize=768%2C352&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?resize=1024%2C469&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?resize=300%2C137&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?resize=768%2C352&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?resize=1536%2C703&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1953.jpeg?w=1963&amp;ssl=1 1963w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>Perhaps more important, a representative of the modern-day Connection pointed out to me that it does make a point of bringing its raccoons back for two annual traditions—though not with new art by Ingraham, I’m sorry to say. (He did his last work for the company in 1997.)</p>



<p>First, it still uses raccoons in its <a href="https://www.connection.com/content/holiday/2024-holiday-card">digital holiday cards</a>. Here’s 2024’s edition.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="1021" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?resize=768%2C1021&amp;ssl=1" alt="Connection 2024 holiday card with raccoon " srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?resize=770%2C1024&amp;ssl=1 770w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?resize=226%2C300&amp;ssl=1 226w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?resize=768%2C1022&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?resize=1155%2C1536&amp;ssl=1 1155w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/03/IMG_1932.jpeg?w=1535&amp;ssl=1 1535w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>Secondly, the Connection annual report continues to give the raccoons their due, if briefly. Each year, one appears on the bottom of the last page, like a <em>lagniappe</em> for long-time customers who remember them.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="226" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?resize=768%2C226&amp;ssl=1" alt="Raccoon from PC Connection annual report" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?resize=1024%2C301&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?resize=300%2C88&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?resize=768%2C225&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?resize=1536%2C451&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2192.jpeg?w=1802&amp;ssl=1 1802w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p>As for Erick Ingraham, David Blistein, and Michael Havey, I’m grateful for the fond memories they shared of the days when they helped PC Connection establish a brand that was at once off-beat and fabulously successful. “It was a once-in-a-lifetime chance for a marketing person like me to participate in that and see that it actually worked,” says Havey. “That was the tremendously fun part of it.”</p>



<p>I’m also impressed by how much they’ve done in the years since raccoons provided them with meal tickets. Ingraham remains a<a href="https://www.erickingraham.com/"> busy artist</a> whose work ranges from <a href="https://www.erickingraham.com/collected-works-summer-1">landscapes</a> to <a href="https://www.erickingraham.com/fantasy-work">fantasy</a> to portraits of <a href="https://www.erickingraham.com/portraits">people</a> and <a href="https://www.erickingraham.com/pet-portraits">pets</a> to <a href="https://www.erickingraham.com/logos-emblems">logos</a> and <a href="https://www.erickingraham.com/label-design">package design</a>. Stylistically and thematically, it can be far afield of his PC Connection paintings, but it’s easy to spot similarities, too: the warmth, the wit, the love of Americana. Blistein has written <a href="https://www.davidblistein.com/films/">documentaries</a> (some in collaboration with Ken Burns) and <a href="https://www.davidblistein.com/books/">books</a>; currently, he’s serializing a novel via his <a href="https://davidblistein.substack.com/">Substack</a>. Havey is still doing freelance art direction from his New Hampshire home and is also a <a href="https://www.imdb.com/name/nm5160220/">filmmaker</a> and <a href="https://vcphoto.org/michael-havey/">photographer</a>.</p>



<p>If someone were creating the 2025 equivalent of PC Connection today, would they promote it with rustic scenes of woodland creatures tilling the land, getting married, and throwing parades? Of course not. Lovingly handcrafted artwork doesn’t scale, which makes it a nonstarter on the web. Even if it did, sly charm has no place in online commerce, a medium that cares far more about shopping-cart workflows than branding. With rare exceptions such as <a href="http://www.meh.com/">Meh</a>, almost every merchant has exactly the same personality, which is to say no personality at all.</p>



<p>I’m not saying I’d go back to the old days when PC Connection had to sell skittish computer users on the very idea of mail-order shopping. In a way, we now live in a world the company helped create. Or at least its old slogan—“Everything Overnight”—now applies to almost anything we might want delivered to our doors, in any product category. And <a href="https://www.aboutamazon.com/news/amazon-prime/amazon-same-day-delivery">sometimes</a>, you don’t even have to wait overnight. 1990s me would be astounded. But damn it, I do miss those raccoons—and the whole era when tech marketing had some, well, character.</p>



<p>I could go on. But instead, I’ll leave you with three pieces of PC Connection-related miscellany.</p>



<p><strong>Miscellaneous item </strong>#1:</p>



<p>Though early PC Connection ads stressed that the company sold only products for the IBM PC, it quickly embraced the Macintosh. Even before it was ready to start fulfilling orders, a division called MacConnection ran an ad in the second issue of <em>Macworld</em>, a few months after Apple unveiled its groundbreaking machine in January 1984. That was the start of a long-running campaign, originally with ads that were also produced by Church and Main and clever in their own right. But they featured human Mac users, not raccoons, so someone else will have to write about them.</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="988" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2186.jpeg?resize=768%2C988&amp;ssl=1" alt="October 1985 MacConnection ad involving a woman who created a spreadsheet to track her knitting" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2186.jpeg?resize=796%2C1024&amp;ssl=1 796w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2186.jpeg?resize=233%2C300&amp;ssl=1 233w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2186.jpeg?resize=768%2C988&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/04/IMG_2186.jpeg?w=832&amp;ssl=1 832w" sizes="auto, (max-width: 768px) 100vw, 768px"><figcaption>October 1985</figcaption></figure>



<p><strong>Miscellaneous item #2:</strong></p>



<p>Immersing myself in PC Connection lore for this article prompted me to check my archive of ancient Lotus Notes email to see if I’d ever received any correspondence from the company when I worked at <em>PC World</em>. I do still have one such message, from 1999, and it’s kind of—oh, read it for yourself:</p>



<figure><img data-recalc-dims="1" loading="lazy" decoding="async" width="768" height="203" src="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470-1024x270.png?resize=768%2C203&amp;ssl=1" alt="" srcset="https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?resize=1024%2C270&amp;ssl=1 1024w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?resize=300%2C79&amp;ssl=1 300w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?resize=768%2C202&amp;ssl=1 768w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?resize=1536%2C404&amp;ssl=1 1536w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?resize=2048%2C539&amp;ssl=1 2048w, https://i0.wp.com/technologizer.com/home/wp-content/uploads/2025/01/Screenshot-2025-01-30-at-11.53.00%E2%80%AFPM-e1740118099470.png?w=2304&amp;ssl=1 2304w" sizes="auto, (max-width: 768px) 100vw, 768px"></figure>



<p><strong>Miscellaneous item #3:</strong></p>



<p>Back in the day, PC Connection took customer service so seriously that it began bundling free videotapes on topics such as installing hard disks with orders. This effort led to the company installing a satellite uplink and operating <em>PCTV</em>, a full-blown tech news service featuring experts such as my friends Mike Elgan and Jim Heid. I have a fuzzy memory of a colleague telling me I could probably appear myself if I was willing to make the trek from Boston to the <em>PCTV</em> studio in New Hampshire. I didn’t seize the opportunity. And now it’s gone forever.</p>



<p>As far as I know, the raccoons never appeared on <em>PCTV</em>. I’d be thrilled to be proven wrong.</p>



<figure><div>
<p><iframe loading="lazy" title="PCTV: Install Internal HD -- 1980s" width="768" height="576" src="https://www.youtube.com/embed/L3dv7ZJvQak?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>



<figure><div>
<p><iframe loading="lazy" title="Classic PC/TV - Windows Utilities - Wintune" width="768" height="576" src="https://www.youtube.com/embed/5rEG5EiXUTM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>



<figure><div>
<p><iframe loading="lazy" title="1995's Wonderful World of Multimedia" width="768" height="432" src="https://www.youtube.com/embed/OIz7ANuP-4Y?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
</div></figure>

		
		
			</div>

	
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Whistleblower: DOGE Siphoned NLRB Case Data (786 pts)]]></title>
            <link>https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/</link>
            <guid>43760801</guid>
            <pubDate>Tue, 22 Apr 2025 11:04:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/">https://krebsonsecurity.com/2025/04/whistleblower-doge-siphoned-nlrb-case-data/</a>, See on <a href="https://news.ycombinator.com/item?id=43760801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>A security architect with the <strong>National Labor Relations Board</strong> (NLRB) alleges that employees from <strong>Elon Musk</strong>‘s <strong>Department of Government Efficiency</strong> (DOGE) transferred gigabytes of sensitive data from agency case files in early March, using short-lived accounts configured to leave few traces of network activity. The NLRB whistleblower said the unusual large data outflows coincided with multiple blocked login attempts from an Internet address in Russia that tried to use valid credentials for a newly-created DOGE user account.</p>
<div id="attachment_71048"><p><img aria-describedby="caption-attachment-71048" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint.png" alt="" width="749" height="823" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint.png 786w, https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint-768x844.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/beruliscomplaint-782x860.png 782w" sizes="(max-width: 749px) 100vw, 749px"></p><p id="caption-attachment-71048">The cover letter from Berulis’s whistleblower statement, sent to the leaders of the Senate Select Committee on Intelligence.</p></div>
<p>The allegations came in an April 14 letter to the Senate Select Committee on Intelligence, signed by <strong>Daniel J. Berulis</strong>, a 38-year-old security architect at the NLRB.</p>
<p><strong>NPR</strong>, which was the <a href="https://www.npr.org/2025/04/15/nx-s1-5355896/doge-nlrb-elon-musk-spacex-security" target="_blank" rel="noopener">first to report</a> on Berulis’s whistleblower complaint, says NLRB is a small, independent federal agency that investigates and adjudicates complaints about unfair labor practices, and stores “reams of potentially sensitive data, from confidential information about employees who want to form unions to proprietary business information.”</p>
<p>The complaint documents a one-month period beginning March 3, during which DOGE officials reportedly demanded the creation of all-powerful “tenant admin” accounts in NLRB systems that were to be exempted from network logging activity that would otherwise keep a detailed record of all actions taken by those accounts.</p>
<p>Berulis said the new DOGE accounts had unrestricted permission to read, copy, and alter information contained in NLRB databases. The new accounts also could restrict log visibility, delay retention, route logs elsewhere, or even remove them entirely — top-tier user privileges that neither Berulis nor his boss possessed.</p>
<p>Berulis writes that on March 3, a black SUV accompanied by a police escort arrived at his building — the NLRB headquarters in Southeast Washington, D.C. The DOGE staffers did not speak with Berulis or anyone else in NLRB’s IT staff, but instead met with the agency leadership.</p>
<p>“Our acting chief information officer told us not to adhere to standard operating procedure with the DOGE account creation, and there was to be no logs or records made of the accounts created for DOGE employees, who required the highest level of access,” Berulis wrote of their instructions after that meeting.</p>
<p>“We have built in roles that auditors can use and have used extensively in the past but would not give the ability to make changes or access subsystems without approval,” he continued. “The suggestion that they use these accounts was not open to discussion.”</p>
<p>Berulis found that on March 3 one of the DOGE accounts created an opaque, virtual environment known as a “container,” which can be used to build and run programs or scripts without revealing its activities to the rest of the world. Berulis said the container caught his attention because he polled his colleagues and found none of them had ever used containers within the NLRB network.</p>
<p>Berulis said he also noticed that early the next morning — between approximately 3 a.m. and 4 a.m. EST on Tuesday, March 4&nbsp; — there was a large increase in outgoing traffic from the agency. He said it took several days of investigating with his colleagues to determine that one of the new accounts had transferred approximately 10 gigabytes worth of data from the NLRB’s <strong>NxGen</strong> case management system.</p>
<p>Berulis said neither he nor his co-workers had the necessary network access rights to review which files were touched or transferred — or even where they went. But his complaint notes the NxGen database contains sensitive information on unions, ongoing legal cases, and corporate secrets.</p>
<p>“I also don’t know if the data was only 10gb in total or whether or not they were consolidated and compressed prior,” Berulis told the senators. “This opens up the possibility that even more data was exfiltrated. Regardless, that kind of spike is extremely unusual because data almost never directly leaves NLRB’s databases.”</p>
<p>Berulis said he and his colleagues grew even more alarmed when they noticed nearly two dozen login attempts from a Russian Internet address (83.149.30,186) that presented valid login credentials for a DOGE employee account — one that had been created just minutes earlier. Berulis said those attempts were all blocked thanks to rules in place that prohibit logins from non-U.S. locations.</p>
<p>“Whoever was attempting to log in was using one of the newly created accounts that were used in the other DOGE related activities and it appeared they had the correct username and password due to the authentication flow only stopping them due to our no-out-of-country logins policy activating,” Berulis wrote. “There were more than 20 such attempts, and what is particularly concerning is that many of these login attempts occurred within 15 minutes of the accounts being created by DOGE engineers.”</p>
<p>According to Berulis, the naming structure of one Microsoft user account connected to the suspicious activity suggested it had been created and later deleted for DOGE use in the NLRB’s cloud systems: “<strong>DogeSA_2d5c3e0446f9@nlrb.microsoft.com</strong>.” He also found other new Microsoft cloud administrator accounts with nonstandard usernames, including “<strong>Whitesox, Chicago M.</strong>” and “<strong>Dancehall, Jamaica R</strong>.”</p>
<div id="attachment_71042"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71042" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png" alt="" width="749" height="556" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago.png 1072w, https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago-768x570.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/whitesoxchicago-782x581.png 782w" sizes="(max-width: 749px) 100vw, 749px"></a></p><p id="caption-attachment-71042">A screenshot shared by Berulis showing the suspicious user accounts.</p></div>
<p>On March 5, Berulis documented that a large section of logs for recently created network resources were missing, and a network watcher in <strong>Microsoft Azure</strong> was set to the “off” state, meaning it was no longer collecting and recording data like it should have.</p>
<p>Berulis said he discovered someone had downloaded three external code libraries from <strong>GitHub</strong> that neither NLRB nor its contractors ever use. A “readme” file in one of the code bundles explained it was created to rotate connections through a large pool of cloud Internet addresses that serve “as a proxy to generate pseudo-infinite IPs for web scraping and brute forcing.” Brute force attacks involve automated login attempts that try many credential combinations in rapid sequence.</p>
<p>The complaint alleges that by March 17 it became clear the NLRB no longer had the resources or network access needed to fully investigate the odd activity from the DOGE accounts, and that on March 24, the agency’s associate chief information officer had agreed the matter should be reported to <strong>US-CERT</strong>. Operated by the Department of Homeland Security’s <strong>Cybersecurity and Infrastructure Security Agency</strong> (CISA), US-CERT provides on-site cyber incident response capabilities to federal and state agencies.</p>
<p>But Berulis said that between April 3 and 4, he and the associate CIO were informed that “instructions had come down to drop the US-CERT reporting and investigation and we were directed not to move forward or create an official report.” Berulis said it was at this point he decided to go public with his findings.<span id="more-71035"></span></p>
<div id="attachment_71050"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/berulis-mar4-spike.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71050" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/berulis-mar4-spike.png" alt="" width="685" height="908"></a></p><p id="caption-attachment-71050">An email from Daniel Berulis to his colleagues dated March 28, referencing the unexplained traffic spike earlier in the month and the unauthorized changing of security controls for user accounts.</p></div>
<p><strong>Tim Bearese</strong>, the NLRB’s acting press secretary, told NPR that DOGE neither requested nor received access to its systems, and that “the agency conducted an investigation after Berulis raised his concerns but ‘determined that no breach of agency systems occurred.'” The NLRB did not respond to questions from KrebsOnSecurity.</p>
<p>Nevertheless, Berulis has shared a number of supporting screenshots showing agency email discussions about the unexplained account activity attributed to the DOGE accounts, as well as NLRB security alerts from Microsoft about network anomalies observed during the timeframes described.</p>
<p>As <strong>CNN</strong> <a href="https://www.cnn.com/2025/02/15/business/nlrb-trump-musk-workers/index.html#:~:text=Musk's%20SpaceX%20brought%20a%20case,it%20for%20firing%20some%20employees." target="_blank" rel="noopener">reported</a> last month, the NLRB has been effectively hobbled since <strong>President Trump</strong> fired three board members, leaving the agency without the quorum it needs to function.</p>
<p>“Despite its limitations, the agency had become a thorn in the side of some of the richest and most powerful people in the nation — notably Elon Musk, Trump’s key supporter both financially and arguably politically,” CNN wrote.</p>
<p>Both <strong>Amazon</strong> and Musk’s <strong>SpaceX</strong> have <a href="https://apnews.com/article/amazon-nlrb-unconstitutional-spacex-elon-musk-ab42977117d883e97110a7bf8e8b257f" target="_blank" rel="noopener">been suing</a> the NLRB over complaints the agency filed in disputes about workers’ rights and union organizing, arguing that the NLRB’s very existence is unconstitutional. On March 5, a U.S. appeals court <a href="https://www.reuters.com/legal/government/musks-spacex-loses-early-legal-challenge-us-labor-boards-powers-2025-03-05/" target="_blank" rel="noopener">unanimously rejected</a> Musk’s claim that the NLRB’s structure somehow violates the Constitution.</p>
<p>Berulis shared screenshots with KrebsOnSecurity showing that on the day the NPR published its story about his claims (April 14), the deputy CIO at NLRB sent an email stating that administrative control had been removed from all employee accounts. Meaning, suddenly none of the IT employees at the agency could do their jobs properly anymore, Berulis said.</p>
<div id="attachment_71043"><p><a href="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png" target="_blank" rel="noopener"><img aria-describedby="caption-attachment-71043" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png" alt="" width="750" height="377" srcset="https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb.png 1046w, https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb-768x386.png 768w, https://krebsonsecurity.com/wp-content/uploads/2025/04/noadmin-nlrb-782x393.png 782w" sizes="(max-width: 750px) 100vw, 750px"></a></p><p id="caption-attachment-71043">An email from the NLRB’s associate chief information officer Eric Marks, notifying employees they will lose security administrator privileges.</p></div>
<p>Berulis shared a screenshot of an agency-wide email dated April 16 from NLRB director <strong>Lasharn Hamilton</strong>&nbsp;saying DOGE officials had requested a meeting, and reiterating claims that the agency had no prior “official” contact with any DOGE personnel. The message informed NLRB employees that two DOGE representatives would be detailed to the agency part-time for several months.</p>
<div id="attachment_71041"><p><img aria-describedby="caption-attachment-71041" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2025/04/nlrb-dir-emailapril14.png" alt="" width="551" height="568"></p><p id="caption-attachment-71041">An email from the NLRB Director Lasharn Hamilton on April 16, stating that the agency previously had no contact with DOGE personnel.</p></div>
<p>Berulis told KrebsOnSecurity he was in the process of filing a support ticket with Microsoft to request more information about the DOGE accounts when his network administrator access was restricted. Now, he’s hoping lawmakers will ask Microsoft to provide more information about what really happened with the accounts.</p>
<p>“That would give us way more insight,” he said. “Microsoft has to be able to see the picture better than we can. That’s my goal, anyway.”</p>
<p>Berulis’s attorney told lawmakers that on April 7, while his client and legal team were preparing the whistleblower complaint, someone physically taped a threatening note to Mr. Berulis’s home door with photographs — taken via drone — of him walking in his neighborhood.</p>
<p>“The threatening note made clear reference to this very disclosure he was preparing for you, as the proper oversight authority,” reads a preface by Berulis’s attorney <strong>Andrew P. Bakaj</strong>. “While we do not know specifically who did this, we can only speculate that it involved someone with the ability to access NLRB systems.”</p>
<p>Berulis said the response from friends, colleagues and even the public has been largely supportive, and that he doesn’t regret his decision to come forward.</p>
<p>“I didn’t expect the letter on my door or the pushback from [agency] leaders,” he said. “If I had to do it over, would I do it again? Yes, because it wasn’t really even a choice the first time.”</p>
<p>For now, Mr. Berulis is taking some paid family leave from the NLRB. Which is just as well, he said, considering he was stripped of the tools needed to do his job at the agency.</p>
<p>“They came in and took full administrative control and locked everyone out, and said limited permission will be assigned on a need basis going forward” Berulis said of the DOGE employees. “We can’t really do anything, so we’re literally getting paid to count ceiling tiles.”</p>
<p>Further reading: <a href="https://whistlebloweraid.org/wp-content/uploads/2025/04/2025_0414_Berulis-Disclosure-with-Exhibits.s.pdf" target="_blank" rel="noopener">Berulis’s complaint</a> (PDF).</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SerenityOS is a love letter to '90s user interfaces (176 pts)]]></title>
            <link>https://serenityos.org/</link>
            <guid>43760626</guid>
            <pubDate>Tue, 22 Apr 2025 10:24:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://serenityos.org/">https://serenityos.org/</a>, See on <a href="https://news.ycombinator.com/item?id=43760626">Hacker News</a></p>
<div id="readability-page-1" class="page">
<img src="https://serenityos.org/banner2.png" alt="SerenityOS">

<b>A graphical Unix-like operating system for desktop computers!</b>

<p>SerenityOS is a love letter to '90s user interfaces with a custom Unix-like core. It flatters with sincerity by stealing beautiful ideas from various other systems.</p>

<p>Roughly speaking, the goal is a marriage between the aesthetic of late-1990s productivity software and the power-user accessibility of late-2000s *nix.</p>

<p>This is a system by us, for us, based on the things we like.</p>

<p><b>Project:</b></p>
<ul>
    <li><a href="https://github.com/SerenityOS/serenity">SerenityOS on GitHub</a></li>
    <li><a href="https://discord.gg/serenityos">SerenityOS Discord Server</a> <span color="red">(join here to chat!)</span></li>
    <li><a href="https://man.serenityos.org/">SerenityOS man pages</a></li>
    <li><a href="https://serenityos.org/faq/">Frequently asked questions</a></li>
    <li><a href="https://serenityos.org/bounty/">Bug bounty program</a></li>
</ul>

<p><b>Birthday posts:</b></p>
<ul>
    <li><a href="https://serenityos.org/happy/5th/">Happy 5th birthday, SerenityOS!</a></li>
    <li><a href="https://serenityos.org/happy/4th/">Happy 4th birthday! The 4th year of SerenityOS</a></li>
    <li><a href="https://serenityos.org/happy/3rd/">Happy 3rd birthday! SerenityOS: Year 3 in review</a></li>
    <li><a href="https://serenityos.org/happy/2nd/">Happy 2nd birthday! SerenityOS: The second year</a></li>
    <li><a href="https://serenityos.org/happy/1st/">Happy 1st birthday! SerenityOS: From zero to HTML in a year</a></li>
</ul>

<p><b>Screenshot:</b></p>

<img src="https://serenityos.org/screenshot-b36968c.png">



</div>]]></description>
        </item>
    </channel>
</rss>