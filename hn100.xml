<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 17 Oct 2024 03:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Should We Chat, Too? Security Analysis of WeChat's Mmtls Encryption Protocol (103 pts)]]></title>
            <link>https://citizenlab.ca/2024/10/should-we-chat-too-security-analysis-of-wechats-mmtls-encryption-protocol/</link>
            <guid>41863278</guid>
            <pubDate>Wed, 16 Oct 2024 20:06:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://citizenlab.ca/2024/10/should-we-chat-too-security-analysis-of-wechats-mmtls-encryption-protocol/">https://citizenlab.ca/2024/10/should-we-chat-too-security-analysis-of-wechats-mmtls-encryption-protocol/</a>, See on <a href="https://news.ycombinator.com/item?id=41863278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="container"> <!--TODO move to stylesheet -->
		<main id="main" role="main" itemscope="" itemprop="mainContentOfPage" itemtype="http://schema.org/Blog">
			<section id="content">


						
							

     <article id="post-81063" dir="ltr" 81063role="article" itemscope="" itemprop="blogPost" itemtype="http://schema.org/BlogPosting">

        <header>
          <span dir="ltr"><a href="https://citizenlab.ca/category/research/"></a><a href="https://citizenlab.ca/category/research/">Research</a><a href="https://citizenlab.ca/category/research/app-privacy-and-security/">App Privacy and Controls</a></span>
            
            

          <!-- Display the link for the PDF version of the post -->
          
        </header>         
                <section itemprop="articleBody">
                  

<h2 id="key-contributions">Key contributions</h2>
<ul>
<li>We performed the first public analysis of the security and privacy properties of MMTLS, the main network protocol used by WeChat, an app with over one billion monthly active users.</li>
<li>We found that MMTLS is a modified version of TLS 1.3, with many of the modifications that WeChat developers made to the cryptography introducing weaknesses.</li>
<li>Further analysis revealed that earlier versions of WeChat used a less secure, custom-designed protocol that contains multiple vulnerabilities, which we describe as “Business-layer encryption”. This layer of encryption is still being used in addition to MMTLS in modern WeChat versions.</li>
<li>Although we were unable to develop an attack to completely defeat WeChat’s encryption, the implementation is inconsistent with the level of cryptography you would expect in an app used by a billion users, such as its use of deterministic IVs and lack of forward secrecy.</li>
<li>These findings contribute to a larger body of work that suggests that apps in the Chinese ecosystem fail to adopt cryptographic best practices, opting instead to invent their own, often problematic systems.</li>
<li>We are releasing technical tools and further documentation of our technical methodologies in an accompanying <a href="https://github.com/citizenlab/wechat-security-report/" target="_blank" rel="noopener">Github repository</a>. These tools and documents, along with this main report, will assist future researchers to study WeChat’s inner workings.</li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>WeChat, with over <a href="https://www.messengerpeople.com/global-messenger-usage-statistics" target="_blank" rel="noopener"><u>1.2 billion monthly active users</u></a>, stands as the most popular messaging and social media platform in China and third globally. As indicated by market research, WeChat’s network traffic <a href="https://walkthechat.com/wechat-impact-report-2016/" target="_blank" rel="noopener"><u>accounted for 34%</u></a> of Chinese mobile traffic in 2018. WeChat’s dominance has monopolized messaging in China, making it increasingly unavoidable for those in China to use. With an ever-expanding array of features, WeChat has also grown beyond its original purpose as a messaging app.</p>
<p>Despite the universality and importance of WeChat, there has been little study of the proprietary network encryption protocol, MMTLS, used by the WeChat application. This knowledge gap serves as a barrier for researchers in that it hampers additional security and privacy study of such a critical application. In addition, <a href="https://citizenlab.ca/2016/02/privacy-security-issues-baidu-browser/"><u>home</u></a>–<a href="https://citizenlab.ca/2016/03/privacy-security-issues-qq-browser/"><u>rolled</u></a> <a href="https://arxiv.org/abs/1802.03367" target="_blank" rel="noopener"><u>cryptography</u></a> <a href="https://citizenlab.ca/2015/05/a-chatty-squirrel-privacy-and-security-issues-with-uc-browser/"><u>is</u></a> <a href="https://citizenlab.ca/2016/08/a-tough-nut-to-crack-look-privacy-and-security-issues-with-uc-browser/"><u>unfortunately</u></a> <a href="https://www.usenix.org/conference/foci16/workshop-program/presentation/knockel" target="_blank" rel="noopener"><u>common</u></a> <a href="https://citizenlab.ca/2020/04/move-fast-roll-your-own-crypto-a-quick-look-at-the-confidentiality-of-zoom-meetings/"><u>in</u></a> <a href="https://citizenlab.ca/2022/01/cross-country-exposure-analysis-my2022-olympics-app/"><u>many</u></a> incredibly popular Chinese applications, and there have historically <a href="https://citizenlab.ca/2023/08/vulnerabilities-in-sogou-keyboard-encryption/"><u>been</u></a> <a href="https://citizenlab.ca/2024/04/vulnerabilities-across-keyboard-apps-reveal-keystrokes-to-network-eavesdroppers/"><u>issues</u></a> with cryptosystems developed independently of well-tested standards such as TLS.</p>
<p>This work is a deep dive into the mechanisms behind MMTLS and the core workings of the WeChat program. We compare the security and performance of MMTLS to TLS 1.3 and discuss our overall findings. We also provide public documentation and tooling to decrypt WeChat network traffic. These tools and documents, along with our report, will assist future researchers to study WeChat’s privacy and security properties, as well as its other inner workings.</p>
<p>This report consists of a technical description of <a href="#launching-a-wechat-network-request">how WeChat launches a network request</a> and its <a href="#wechat-network-request-encryption">encryption protocols</a>, followed by a <a href="#security-issues">summary of weaknesses in WeChat’s protocol</a>, and finally a <a href="#discussion">high-level discussion</a> of WeChat’s design choices and their impact. The report is intended for privacy, security, or other technical researchers interested in furthering the privacy and security study of WeChat. For non-technical audiences, we have summarized our findings in this FAQ.</p>
<h3 id="prior-work-on-mmtls-and-wechat-transport-security">Prior work on MMTLS and WeChat transport security</h3>
<p>Code internal to the WeChat mobile app refers to its proprietary TLS stack as MMTLS (MM is short for MicroMessenger, which is a direct translation of 微信, the Chinese name for WeChat) and uses it to encrypt the bulk of its traffic.</p>
<p>There is limited public documentation of the MMTLS protocol. This <a href="https://github.com/WeMobileDev/article/blob/master/%E5%9F%BA%E4%BA%8ETLS1.3%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%AE%89%E5%85%A8%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AEmmtls%E4%BB%8B%E7%BB%8D.md" target="_blank" rel="noopener"><u>technical document</u></a> from WeChat developers describes in which ways it is similar and different from TLS 1.3, and attempts to justify various decisions they made to either simplify or change how the protocol is used. In this document, there are various key differences they identify between MMTLS and TLS 1.3, which help us understand the various modes of usage of MMTLS.</p>
<p><a href="https://wenku.baidu.com/view/67762def4b35eefdc9d33374.html" target="_blank" rel="noopener"><u>Wan et al.</u></a> conducted the most comprehensive study of WeChat transport security in 2015 using standard security analysis techniques. However, this analysis was performed before the deployment of MMTLS, WeChat’s upgraded security protocol. In 2019, <a href="https://link.springer.com/chapter/10.1007/978-3-030-24268-8_27" target="_blank" rel="noopener"><u>Chen et al.</u></a> studied the login process of WeChat and specifically studied packets that are encrypted with TLS and not MMTLS.</p>
<p>As for MMTLS itself, in 2016 WeChat developers published <a href="https://github.com/WeMobileDev/article/blob/master/%E5%9F%BA%E4%BA%8ETLS1.3%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%AE%89%E5%85%A8%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AEmmtls%E4%BB%8B%E7%BB%8D.md" target="_blank" rel="noopener"><u>a document</u></a> describing the design of the protocol at a high level that compares the protocol with TLS 1.3. Other MMTLS publications focus on <a href="https://ieeexplore.ieee.org/abstract/document/8711267" target="_blank" rel="noopener"><u>website fingerprinting-type</u></a> <a href="https://ieeexplore.ieee.org/abstract/document/8456067" target="_blank" rel="noopener"><u>attacks</u></a>, but none specifically perform a security evaluation. A few <a href="https://github.com/anonymous5l/mmtls" target="_blank" rel="noopener"><u>Github repositories</u></a> and <a href="https://bbs.pediy.com/thread-257942.htm" target="_blank" rel="noopener"><u>blog posts</u></a> look briefly into the wire format of MMTLS, though none are comprehensive. Though there has been little work studying MMTLS specifically, previous Citizen Lab reports have discovered security flaws of <a href="https://citizenlab.ca/2016/03/privacy-security-issues-qq-browser/"><u>other</u></a> <a href="https://arxiv.org/abs/1802.03367" target="_blank" rel="noopener"><u>cryptographic</u></a> protocols designed and implemented by Tencent.</p>
<h2 id="methodology">Methodology</h2>
<p>We analyzed two versions of WeChat Android app:</p>
<ul>
<li>Version 8.0.23 (APK “versionCode” 2160) released on May 26, 2022, downloaded from the WeChat website.</li>
<li>Version 8.0.21 (APK “versionCode” 2103) released on April 7, 2022, downloaded from Google Play Store.</li>
</ul>
<p>All findings in this report apply to both of these versions.</p>
<p>We used an account registered to a U.S. phone number for the analysis, which changes the behavior of the application compared to a mainland Chinese number. Our setup may not be representative of all WeChat users, and the full limitations are discussed further below.</p>
<p>For dynamic analysis, we analyzed the application installed on a rooted Google Pixel 4 phone and an emulated Android OS. We used <a href="https://frida.re/" target="_blank" rel="noopener"><u>Frida</u></a> to hook the app’s functions and manipulate and export application memory. We also performed network analysis of WeChat’s network traffic using <a href="https://www.wireshark.org/" target="_blank" rel="noopener"><u>Wireshark</u></a>. However, due to WeChat’s use of nonstandard cryptographic libraries like MMTLS, standard network traffic analysis tools that might work with HTTPS/TLS do not work for all of WeChat’s network activity. Our use of Frida was paramount for capturing the data and information flows we detail in this report. These Frida scripts are designed to intercept WeChat’s request data immediately before WeChat sends it to its MMTLS encryption module. The Frida scripts we used are published in <a href="https://github.com/citizenlab/wechat-report-data" target="_blank" rel="noopener"><u>our Github repository</u></a>.</p>
<p>For static analysis, we used <a href="https://github.com/skylot/jadx" target="_blank" rel="noopener"><u>Jadx</u></a>, a popular Android decompiler, to decompile WeChat’s Android Dex files into Java code. We also used <a href="https://ghidra-sre.org/" target="_blank" rel="noopener"><u>Ghidra</u></a> and <a href="https://hex-rays.com/ida-pro/" target="_blank" rel="noopener"><u>IDA Pro</u></a> to decompile the native libraries (written in C++) bundled with WeChat.</p>
<h2 id="notation">Notation</h2>
<p>In this report, we reference a lot of code from the WeChat app. When we reference any code (including file names and paths), we will style the text using <code>monospace fonts</code> to indicate it is code. If a function is referenced, we will add empty parentheses after the function name, like this: <code>somefunction()</code>. The names of variables and functions that we show may come from one of the three following:</p>
<ol type="1">
<li>The original decompiled name.</li>
<li>In cases where the name cannot be decompiled into a meaningful string (e.g., the symbol name was not compiled into the code), we rename it according to how the nearby internal log messages reference it.</li>
<li>In cases where there is not enough information for us to tell the original name, we name it according to our understanding of the code. In such cases, we will note that these names are given by us.</li>
</ol>
<p>In the cases where the decompiled name and log message name of functions are available, they are generally consistent. Bolded or italicized terms can refer to higher-level concepts or parameters we have named.</p>
<h2 id="utilization-of-open-source-components">Utilization of open source components</h2>
<p>We also identified open source components being used by the project, the two largest being <a href="https://openssl-library.org/" target="_blank" rel="noopener"><u>OpenSSL</u></a> and <a href="https://github.com/Tencent/mars" target="_blank" rel="noopener"><u>Tencent Mars</u></a>. Based on our analysis of decompiled WeChat code, large parts of its code are identical to Mars. Mars is an “infrastructure component” for mobile applications, providing common features and abstractions that are needed by mobile applications, such as networking and logging.</p>
<p>By compiling these libraries separately with debug symbols, we were able to import function and class definitions into Ghidra for further analysis. This helped tremendously to our understanding of other non-open-source code in WeChat. For instance, when we were analyzing the network functions decompiled from WeChat, we found a lot of them to be highly similar to the open source Mars, so we could just read the source code and comments to understand what a function was doing. What was not included in open source Mars are encryption related functions, so we still needed to read decompiled code, but even in these cases we were aided by various functions and structures that we already know from the open source Mars.</p>
<h3 id="matching-decompiled-code-to-its-source">Matching decompiled code to its source</h3>
<p>In the internal logging messages of WeChat, which contain source file paths, we noticed three top level directories, which we have highlighted below:</p>
<ul>
<li><code>/home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/<mark>mars</mark>/</code></li>
<li><code>/home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/<mark>mars-wechat</mark>/</code></li>
<li><code>/home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/<mark>mars-private</mark>/</code></li>
</ul>
<p>The source files under “mars” can all be found in the <a href="https://github.com/Tencent/mars" target="_blank" rel="noopener"><u>open source Mars repository</u></a> as well, while source files in the other two top level directories cannot be found in the open source repository. To illustrate, below is a small section of decompiled code from <code>libwechatnetwork.so</code> :</p>
<div>
<pre>    XLogger::XLogger((XLogger *)&amp;local_2c8,5,"mars::stn",

"/home/android/devopsAgent/workspace/p-e118ef4209d745e1b9ea0b1daa0137ab/src/mars/mars/stn/src/longlink.cc"
                ,"Send",0xb2,false,(FuncDef0 *)0x0);
    XLogger::Assert((XLogger *)&amp;local_2c8,"tracker_.get()");
    XLogger::~XLogger((XLogger *)&amp;local_2c8);
</pre>
</div>
<p>From its similarity, is highly likely that this section of code was compiled from <a href="https://github.com/Tencent/mars/blob/1583548111ed055836bdc2a344e45084ec775e6d/mars/stn/src/longlink.cc#L178" target="_blank" rel="noopener"><u>this line</u></a> in the Send() function, defined in longlink.cc file from the open source repository:</p>
<p><code>xassert2(tracker_.get());</code></p>
<p>Reusing this observation, whenever our decompiler is unable to determine the name of a function, we can use logging messages within the compiled code to determine its name. Moreover, if the source file is from open source Mars, we can read its source code as well.</p>
<h3 id="three-parts-of-mars">Three parts of Mars</h3>
<p>In a few articles on the <a href="https://github.com/Tencent/mars/wiki" target="_blank" rel="noopener"><u>Mars wiki</u></a>, Tencent developers provided the following motivations to develop Mars:</p>
<ul>
<li>The need for a <a href="https://cloud.tencent.com/developer/article/1005495" target="_blank" rel="noopener"><u>cross-platform</u></a> networking library, to reduce the development and maintenance costs of two separate network libraries on Android and iOS.</li>
<li>The need to <a href="http://mp.weixin.qq.com/s?__biz=MzAwNDY1ODY2OQ==&amp;mid=2649286458&amp;idx=1&amp;sn=320f690faa4f97f7a49a291d4de174a9&amp;chksm=8334c3b8b4434aae904b6d590027b100283ef175938610805dd33ca53f004bd3c56040b11fa6#rd" target="_blank" rel="noopener"><u>customize parameters of the TCP handshake process</u></a>, in order for faster connection establishment.</li>
</ul>
<p>According to its developers, Mars and its STN module are comparable to networking libraries such as <a href="https://github.com/AFNetworking/AFNetworking" target="_blank" rel="noopener"><u>AFNetworking</u></a> and <a href="https://square.github.io/okhttp/" target="_blank" rel="noopener"><u>OkHttp</u></a>, which are widely used in other mobile apps.</p>
<p><a href="https://github.com/WeMobileDev/article/blob/master/%E5%BE%AE%E4%BF%A1%E7%BB%88%E7%AB%AF%E8%B7%A8%E5%B9%B3%E5%8F%B0%E7%BB%84%E4%BB%B6%20Mars%20%E7%B3%BB%E5%88%97%20-%20%E6%88%91%E4%BB%AC%E5%A6%82%E7%BA%A6%E8%80%8C%E8%87%B3.md?plain=1" target="_blank" rel="noopener"><u>One of the technical articles</u></a> released by the WeChat development team wrote about the process of open-sourcing Mars. According to the article, they had to separate WeChat-specific code, which was kept private, from the general use code, which was open sourced. In the end, three parts were separated from each other:</p>
<ul>
<li>mars-open: to be open sourced, independent repository.</li>
<li>mars-private: potentially open sourced, depends on mars-open.</li>
<li>mars-wechat: WeChat business logic code, depends on mars-open and mars-private.</li>
</ul>
<p>These three names match the top level directories we found earlier if we take “mars-open” to be in the “mars” top-level directory. Using this knowledge, when reading decompiled WeChat code, we could easily know whether it was WeChat-specific or not. From our reading of the code, mars-open contains basic and generic structures and functions, for instance, <a href="https://github.com/Tencent/mars/blob/master/mars/comm/autobuffer.cc" target="_blank" rel="noopener"><u>buffer structures</u></a>, <a href="https://github.com/Tencent/mars/blob/6c71f72ff770f8a2b111ef27f1ccf72511801bbd/mars/comm/ini.h#L60" target="_blank" rel="noopener"><u>config stores</u></a>, <a href="https://github.com/Tencent/mars/tree/6c71f72ff770f8a2b111ef27f1ccf72511801bbd/mars/comm/unix/thread" target="_blank" rel="noopener"><u>thread management</u></a> and, most importantly, the module named “STN” responsible for network transmission. (We were unable to determine what STN stands for.) On the other hand, mars-wechat contains the MMTLS implementation, and mars-private is not closely related to the features within our research scope.</p>
<p>As a technical side note, the open source Mars <a href="https://github.com/Tencent/mars/wiki/Mars-Android-%E6%8E%A5%E5%85%A5%E6%8C%87%E5%8D%97#%E6%9C%AC%E5%9C%B0%E7%BC%96%E8%AF%91" target="_blank" rel="noopener"><u>compiles</u></a> to just one object file named “libmarsstn.so”. However, in WeChat, multiple shared object files reference code within the open source Mars, including the following:</p>
<ul>
<li><code>libwechatxlog.so</code></li>
<li><code>libwechatbase.so</code></li>
<li><code>libwechataccessory.so</code></li>
<li><code>libwechathttp.so</code></li>
<li><code>libandromeda.so</code></li>
<li><code>libwechatmm.so</code></li>
<li><code>libwechatnetwork.so</code></li>
</ul>
<p>Our research focuses on the transport protocol and encryption of WeChat, which is implemented mainly in libwechatmm.so and libwechatnetwork.so. In addition, we inspected libMMProtocalJni.so, which is not part of Mars but contains functions for cryptographic calculations. We did not inspect the other shared object files.</p>
<h3 id="matching-mars-versions">Matching Mars versions</h3>
<p>Despite being able to find open source code to parts of WeChat, in the beginning of our research, we were unable to pinpoint the specific version of the source code of mars-open that was used to build WeChat. Later, we found version strings contained in <code>libwechatnetwork.so</code>. For WeChat 8.0.21, searching for the string “MARS_” yielded the following:</p>
<p>MARS_BRANCH: HEAD<br>
MARS_COMMITID: d92f1a94604402cf03939dc1e5d3af475692b551<br>
MARS_PRIVATE_BRANCH: HEAD<br>
MARS_PRIVATE_COMMITID: 193e2fb710d2bb42448358c98471cd773bbd0b16<br>
MARS_URL:<br>
MARS_PATH: HEAD<br>
MARS_REVISION: d92f1a9<br>
MARS_BUILD_TIME: 2022-03-28 21:52:49<br>
MARS_BUILD_JOB: rb/2022-MAR-p-e118ef4209d745e1b9ea0b1daa0137ab-22.3_1040</p>
<p>The specific MARS_COMMITID (d92f1a…) exists in the open source Mars repository. This version of the source code also matches the decompiled code.</p>
<p>Pinpointing the specific source code version helped us tremendously with Ghidra’s decompilation. Since a lot of the core data structures used in WeChat are from Mars, by importing the known data structures, we can observe the non-open-sourced code accessing structure fields, and inferring its purpose.</p>
<h2 id="limitations">Limitations</h2>
<p>This investigation only looks at client behavior and is therefore subject to other common limitations in privacy research that can only perform client analysis. Much of the data that the client transmits to WeChat servers may be required for functionality of the application. For instance, WeChat servers can certainly see chat messages since WeChat can censor them according to their content. We cannot always measure what Tencent is doing with the data that they collect, but we can make inferences about what is possible. <a href="https://citizenlab.ca/2020/05/we-chat-they-watch/"><u>Previous work</u></a> has made certain limited inferences about data sharing, such as that messages sent by non-mainland-Chinese users are used to train censorship algorithms for mainland Chinese users. In this report, we focus on the version of WeChat for non-mainland-Chinese users.</p>
<p>Our investigation was also limited due to legal and ethical constraints. It has become increasingly difficult to obtain Chinese phone numbers for investigation due to the strict phone number and associated government ID requirements. Therefore, we did not test on Chinese phone numbers, which causes WeChat to behave differently. In addition, without a mainland Chinese account, the types of interaction with certain features and Mini Programs were limited. For instance, we did not perform financial transactions on the application.</p>
<p>Our primary analysis was limited to analyzing only two versions of WeChat Android (8.0.21 and 8.0.23). However, we also re-confirmed our tooling works on WeChat 8.0.49 for Android (released April 2024) and that the MMTLS network format matches that used by WeChat 8.0.49 for iOS. Testing different versions of WeChat, the backwards-compatibility of the servers with older versions of the application, and testing on a variety of Android operating systems with variations in API version, are great avenues for future work.</p>
<p>Within the WeChat Android app, we focused on its networking components. Usually, within a mobile application (and in most other programs as well), all other components will defer the work of communicating over the network to the networking components. Our research is not a complete security and privacy audit of the WeChat app, as even if the network communication is properly protected, other parts of the app still need to be secure and private. For instance, an app would not be secure if the server accepts any password to an account login, even if the password is confidentially transmitted.</p>

<p>In the <a href="https://github.com/citizenlab/wechat-security-report/" target="_blank" rel="noopener"><u>Github repository</u></a>, we have released tooling that can log keys using Frida and decrypt network traffic that is captured during the same period of time, as well as samples of decrypted payloads. In addition, we have provided additional documentation and our reverse-engineering notes from studying the protocol. We hope that these tools and documentation will further aid researchers in the study of WeChat.</p>
<h2 id="launching-a-wechat-network-request">Launching a WeChat network request</h2>
<p>As with any other apps, WeChat is composed of various components. Components within WeChat can invoke the networking components to send or receive network transmissions. In this section, we provide a highly simplified description of the process and components surrounding sending a network request in WeChat. The actual process is much more complex, which we explain in more detail in a <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/networking_components.md" target="_blank" rel="noopener"><u>separate document</u></a>. The specifics of data encryption is discussed in the next section “WeChat network request encryption”.</p>
<p>In the WeChat source code, each API is referred to as a different “Scene”. For instance, during the registration process, there is one API that submits all new account information provided by the user, called <code>NetSceneReg</code>. <code>NetSceneReg</code> is referred to by us as a “Scene class”, Other components could start a network request towards an API by calling the particular Scene class. In the case of <code>NetSceneReg</code>, it is usually invoked by a click event of a button UI component.</p>
<p>Upon invocation, the Scene class would prepare the request data. The structure of the request data (as well as the response) is defined in “RR classes”. (We dub them RR classes because they tend to have “ReqResp” in their names.) Usually, one Scene class would correspond to one RR class. In the case of <code>NetSceneReg</code>, it corresponds to the RR class <code>MMReqRespReg2</code>, and contains fields like the desired username and phone number. For each API, its RR class also defines a unique internal URI (usually starting with “/cgi-bin”) and a “request type” number (an approximately 2–4 digit integer). The internal URI and request type number is often used throughout the code to identify different APIs. Once the data is prepared by the Scene class, it is sent to <code>MMNativeNetTaskAdapter</code>.</p>
<p><code>MMNativeNetTaskAdapter</code> is a task queue manager, it manages and monitors the progress of each network connection and API requests. When a Scene Class calls <code>MMNativeNetTaskAdapter</code>, it places the new request (a task) onto the task queue, and calls the req2Buf() function. req2Buf() serializes the request <a href="https://protobuf.dev/" target="_blank" rel="noopener"><u>Protobuf</u></a> object that was prepared by the Scene Class into bytes, then encrypts the bytes using <em>Business-layer Encryption</em>.</p>
<p>Finally, the resultant ciphertext from Business-layer encryption is sent to the “STN” module, which is part of Mars. STN then encrypts the data again using <em>MMTLS Encryption</em>. Then, STN establishes the network transport connection, and sends the MMTLS Encryption ciphertext over it. In STN, there are two types of transport connections: <em>Shortlink</em> and <em>Longlink</em>. Shortlink refers to an HTTP connection that carries MMTLS ciphertext. Shortlink connections are closed after one request-response cycle. Longlink refers to a long-lived TCP connection. A Longlink connection can carry multiple MMTLS encrypted requests and responses without being closed.</p>
<h2 id="wechat-network-request-encryption">WeChat network request encryption</h2>
<p>WeChat network requests are encrypted twice, with different sets of keys. Serialized request data is first encrypted using what we call the <em>Business-layer Encryption</em>, as internal encryption is referred to in this <a href="https://github.com/WeMobileDev/article/blob/master/%E5%9F%BA%E4%BA%8ETLS1.3%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%AE%89%E5%85%A8%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AEmmtls%E4%BB%8B%E7%BB%8D.md" target="_blank" rel="noopener"><u>blog post</u></a> as occurring at the <strong>“</strong>Business-layer<strong>”</strong>. The Business-layer Encryption has two modes: <em>Symmetric Mode</em> and <em>Asymmetric Mode</em>. The resultant Business-layer-encrypted ciphertext is appended to metadata about the Business-layer request. Then, the Business-layer requests (i.e., request metadata and inner ciphertext) are additionally encrypted, using <em>MMTLS Encryption</em>. The final resulting ciphertext is then serialized as an <em>MMTLS Request</em> and sent over the wire.</p>
<p>WeChat’s network encryption system is disjointed and seems to still be a combination of at least three different cryptosystems. The encryption process described in the Tencent documentation mostly matches our findings about MMTLS Encryption, but the document does not seem to describe in detail the Business-layer Encryption<strong>,</strong> whose operation differs when <strong>logged-in</strong> and when <strong>logged-out</strong>. Logged-in clients use Symmetric Mode while logged-out clients use Asymmetric Mode. We also observed WeChat utilizing HTTP, HTTPS, and QUIC to transmit large, static resources such as translation strings or transmitted files. The endpoint hosts for these communications are different from MMTLS server hosts. Their domain names also suggest that they belong to <a href="https://en.wikipedia.org/wiki/Content_delivery_network" target="_blank" rel="noopener"><u>CDNs</u></a>. However, the endpoints that are interesting to us are those that download dynamically generated, often confidential resources (i.e., generated by the server on every request) or endpoints where users transmit, often confidential, data to WeChat’s servers. These types of transmissions are made using MMTLS.</p>
<p>As a final implementation note, WeChat, across all these cryptosystems, uses internal OpenSSL bindings that are compiled into the program. In particular, the libwechatmm.so library seems to have been compiled with <a href="https://mta.openssl.org/pipermail/openssl-announce/2021-August/000206.html" target="_blank" rel="noopener"><u>OpenSSL version 1.1.1l</u></a>, though the other libraries that use OpenSSL bindings, namely <code>libMMProtocalJni.so</code> and <code>libwechatnetwork.so</code> were not compiled with the OpenSSL version strings. We note that OpenSSL internal APIs can be confusing and are often <a href="https://www.cs.utexas.edu/~shmat/shmat_ccs12.pdf" target="_blank" rel="noopener"><u>misused</u></a> by well-intentioned developers. Our full notes about each of the OpenSSL APIs that are used can be found in the <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/reversing-notes.md" target="_blank" rel="noopener"><u>Github repository</u></a>.</p>
<p>In Table 1, we have summarized each of the relevant cryptosystems, how their keys are derived, how encryption and authentication are achieved, and which libraries contain the relevant encryption and authentication functions. We will discuss cryptosystem’s details in the coming sections.</p>
<figure><table>
<thead>
<tr>
<th></th>
<th><strong>Key derivation</strong></th>
<th><strong>Encryption</strong></th>
<th><strong>Authentication</strong></th>
<th><strong>Library</strong></th>
<th><strong>Functions that perform the symmetric encryption</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>MMTLS, Longlink</strong></td>
<td>Diffie-Hellman (DH)</td>
<td>AES-GCM</td>
<td>AES-GCM tag</td>
<td><code>libwechatnetwork.so</code></td>
<td><code>Crypt()</code></td>
</tr>
<tr>
<td><strong>MMTLS, Shortlink</strong></td>
<td>DH with session resumption</td>
<td>AES-GCM</td>
<td>AES-GCM tag</td>
<td><code>libwechatnetwork.so</code></td>
<td><code>Crypt()</code></td>
</tr>
<tr>
<td><strong>Business-layer, Asymmetric Mode</strong></td>
<td>Static DH with fresh client keys</td>
<td>AES-GCM</td>
<td>AES-GCM tag</td>
<td><code>libwechatmm.so</code></td>
<td><code>HybridEcdhEncrypt(),</code> <code>AesGcmEncryptWithCompress()</code></td>
</tr>
<tr>
<td><strong>Business-layer, Symmetric Mode</strong></td>
<td>Fixed key from server</td>
<td>AES-CBC</td>
<td>Checksum + MD5</td>
<td><code>libMMProtocalJNI.so</code></td>
<td><code>pack(), EncryptPack(), genSignature()</code></td>
</tr>
</tbody>
</table></figure>
<p><em>Table 1: Overview of different cryptosystems for WeChat network request encryption, how keys are derived, how encryption and authentication are performed, and which libraries perform them.</em></p>
<h2 id="mmtls-wire-format">1. MMTLS Wire Format</h2>
<p>Since MMTLS can go over various transports, we refer to an <em>MMTLS packet</em> as a unit of correspondence within MMTLS. Over Longlink, MMTLS packets can be split across multiple TCP packets. Over Shortlink, MMTLS packets are generally contained within an HTTP POST request or response body.<a id="fnref1" role="doc-noteref" href="#fn1"><sup>1</sup></a></p>
<p>Each MMTLS packet contains one or more <em>MMTLS records</em> (which are similar in structure and purpose to <a href="https://datatracker.ietf.org/doc/html/rfc8446#section-5" target="_blank" rel="noopener"><u>TLS records</u></a>). Records are units of messages that carry handshake data, application data, or alert/error message data within each MMTLS packet.</p>
<h3 id="a.-mmtls-records">1A. MMTLS Records</h3>
<p>Records can be identified by different <em>record headers</em>, a fixed 3-byte sequence preceding the record contents. In particular, we observed 4 different record types, with the corresponding <em>record headers</em>:</p>
<figure><table>
<tbody>
<tr>
<td>Handshake-Resumption Record</td>
<td><code>19 f1 04</code></td>
</tr>
<tr>
<td>Handshake Record</td>
<td><code>16 f1 04</code></td>
</tr>
<tr>
<td>Data Record</td>
<td><code>17 f1 04</code></td>
</tr>
<tr>
<td>Alert Record</td>
<td><code>15 f1 04</code></td>
</tr>
</tbody>
</table></figure>
<p><em>Handshake</em> records contain metadata and the key establishment material needed for the other party to derive the same shared session key using Diffie-Hellman. <em>Handshake-Resumption</em> record contains sufficient metadata for “resuming” a previously established session, by re-using previously established key material. <em>Data</em> records can contain encrypted ciphertext that carries meaningful WeChat request data. Some <em>Data</em> packets simply contain an encrypted no-op heartbeat. <em>Alert</em> records signify errors or signify that one party intends to end a connection. In MMTLS, all non-handshake records are encrypted, but the key material used differs based on which stage of the handshake has been completed.</p>
<p>Here is an annotated MMTLS packet from the server containing a <em>Handshake</em> record:<br>
<a href="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record.png&amp;nocache=1"><img decoding="async" src="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record.png&amp;nocache=1" alt="" width="331" height="63" title="Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol 1" srcset="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record.png&amp;nocache=1 331w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record-300x57.png&amp;nocache=1 300w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record-297x57.png&amp;nocache=1 297w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/handshake-record-180x34.png&amp;nocache=1 180w" sizes="(max-width: 331px) 100vw, 331px"></a><br>
Here is an example of a <strong>Data</strong> record sent from the client to the server:<br>
<a href="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record.png&amp;nocache=1"><img decoding="async" src="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record.png&amp;nocache=1" alt="" width="331" height="33" title="Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol 2" srcset="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record.png&amp;nocache=1 331w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record-300x30.png&amp;nocache=1 300w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record-297x30.png&amp;nocache=1 297w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/data-record-180x18.png&amp;nocache=1 180w" sizes="(max-width: 331px) 100vw, 331px"></a></p>
<p>To give an example of how these records interact, generally the client and server will exchange <em>Handshake</em> records until the Diffie-Hellman handshake is complete and they have established shared key material. Afterwards, they will exchange <em>Data</em> records, encrypted using the shared key material. When either side wants to close the connection, they will send an <em>Alert</em> record. More illustrations of each record type’s usage will be made in the following section.</p>
<h3 id="b.-mmtls-extensions">1B. MMTLS Extensions</h3>
<p>As MMTLS’ wire protocol is heavily modeled after TLS, we note that it has also borrowed the wire format of “<a href="https://datatracker.ietf.org/doc/html/rfc6066" target="_blank" rel="noopener"><u>TLS Extensions</u></a>” to exchange relevant encryption data during the handshake. Specifically, MMTLS uses the same format as TLS Extensions for the Client to communicate their key share (i.e. the client’s public key) for Diffie-Hellman, similar to TLS 1.3’s <a href="https://datatracker.ietf.org/doc/html/rfc8446#section-4.2.8" target="_blank" rel="noopener"><em><u>key_share</u></em></a> extension, and to communicate session data for session resumption (similar to TLS 1.3’s <a href="https://datatracker.ietf.org/doc/html/rfc8446#section-4.2.11" target="_blank" rel="noopener"><em><u>pre_shared_key</u></em></a> extension). In addition, MMTLS has support for <a href="https://datatracker.ietf.org/doc/html/rfc8446#section-4.3.1" target="_blank" rel="noopener"><em><u>Encrypted Extensions</u></em></a>, similar to TLS, but they are currently not used in MMTLS (i.e., the <em>Encrypted Extensions</em> section is always empty).</p>
<h2 id="mmtls-encryption">2. MMTLS Encryption</h2>
<p>This section describes the outer layer of encryption, that is, what keys and encryption functions are used to encrypt and decrypt the ciphertexts found in the <strong>“</strong>MMTLS Wire Format” section, and how the encryption keys are derived.</p>
<p>The encryption and decryption at this layer occurs in the STN module, in a separate spawned “com.tencent.mm:push”<a id="fnref2" role="doc-noteref" href="#fn2"><sup>2</sup></a> process on Android. The spawned process ultimately transmits and receives data over the network. The code for all of the MMTLS Encryption and MMTLS serialization were analyzed from the library <code>libwechatnetwork.so</code>. In particular, we studied the <code>Crypt()</code> function, a central function used for all encryption and decryption whose name we derived from debug logging code. We also hooked all calls to <a href="https://github.com/OneSignal/openssl/blob/main/crypto/kdf/hkdf.c#L26" target="_blank" rel="noopener"><u>HKDF_Extract</u></a>() and <a href="https://github.com/OneSignal/openssl/blob/main/crypto/kdf/hkdf.c#L31" target="_blank" rel="noopener"><u>HKDF_Expand</u></a>(), the OpenSSL functions for <a href="https://en.wikipedia.org/wiki/HKDF" target="_blank" rel="noopener"><u>HKDF</u></a>, in order to understand how keys are derived.</p>
<p>When the “:push” process is spawned, it starts an event loop in HandshakeLoop(), which processes all outgoing and incoming MMTLS Records. We hooked all functions called by this event loop to understand how each MMTLS Record is processed. The code for this study, as well as the internal function addresses identified for the particular version of WeChat we studied, can be found in the <a href="https://github.com/citizenlab/wechat-security-report/tree/main" target="_blank" rel="noopener"><u>Github repository</u></a>.</p>
<figure><p><a href="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2.png&amp;nocache=1"><img fetchpriority="high" decoding="async" src="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2.png&amp;nocache=1" alt="" width="861" height="473" title="Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol 3" srcset="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2.png&amp;nocache=1 861w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-300x165.png&amp;nocache=1 300w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-768x422.png&amp;nocache=1 768w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-605x332.png&amp;nocache=1 605w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-297x163.png&amp;nocache=1 297w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-500x275.png&amp;nocache=1 500w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image2-180x99.png&amp;nocache=1 180w" sizes="(max-width: 861px) 100vw, 861px"></a></p><figcaption>Figure 1: Network requests: MMTLS encryption connection over longlink and over shortlink. Each box is an MMTLS Record, and each arrow represents an “MMTLS packet” sent over either Longlink (i.e., a single TCP packet) or shortlink (i.e., in the body of HTTP POST). Once both sides have received the DH keyshare, all further records are encrypted.</figcaption></figure>
<h3 id="a.-handshake-and-key-establishment">2A. Handshake and key establishment</h3>
<p>In order for Business-layer Encryption to start sending messages and establish keys, it has to use the MMTLS Encryption tunnel. Since the key material for the MMTLS Encryption has to be established first, the handshakes in this section happen before any data can be sent or encrypted via Business-layer Encryption. The end goal of the MMTLS Encryption handshake discussed in this section is to establish a common secret value that is known only to the client and server.</p>
<p>On a fresh startup of WeChat, it tries to complete one MMTLS handshake over Shortlink, and one MMTLS handshake over Longlink, resulting in two MMTLS encryption tunnels, each using different sets of encryption keys. For Longlink, after the handshake completes, the same Longlink (TCP) connection is kept open to transport future encrypted data. For Shortlink, the MMTLS handshake is completed in the first HTTP request-response cycle, then the first HTTP connection closes. The established keys are stored by the client and server, and when data needs to be sent over Shortlink, those established keys are used for encryption, then sent over a newly established Shortlink connection. In the remainder of this section, we describe details of the handshakes.</p>
<h4 id="clienthello">ClientHello</h4>
<p>First, the client generates keypairs on the <a href="https://neuromancer.sk/std/secg/secp256r1" target="_blank" rel="noopener"><u>SECP256R1</u> <u>elliptic curve</u></a>. Note that these elliptic curve keys are entirely separate pairs from those generated in the Business-layer Encryption section. The client also reads some Resumption Ticket data from a file stored on local storage named <strong><code>psk.key</code>,</strong> if it exists. The <code><strong>psk.key</strong></code> file is written to after the first ServerHello is received, so, on a fresh install of WeChat, the resumption ticket is omitted from the ClientHello.</p>
<p>The client first simultaneously sends a ClientHello message (contained in a Handshake record) over both the Shortlink and Longlink. The first of these two handshakes that completes successfully is the one that the initial Business-layer Encryption handshake occurs over (details of Business-layer Encryption are discussed in Section 4). Both Shortlink and Longlink connections are used afterwards for sending other data.</p>
<p>In both the initial Shortlink and Longlink handshake, each ClientHello packet contains the following data items:</p>
<ul>
<li>ClientRandom (32 bytes of randomness)</li>
<li>Resumption Ticket data read from psk.key, if available</li>
<li>Client public key</li>
</ul>
<p>An abbreviated version of the MMTLS ClientHello is shown below.</p>
<div>
<pre><span>16 f1 04 (Handshake Record header) . . .</span>
01 04 f1 (ClientHello) . . .
08 cd 1a 18 f9 1c . . . (ClientRandom) . . .
00 0c c2 78 00 e3 . . . (Resumption Ticket from psk.key) . . .
04 0f 1a 52 7b 55 . . . (Client public key) . . .
</pre>
</div>
<p>Note that the client generates <strong>a separate keypair</strong> for the Shortlink ClientHello and the Longlink ClientHello. The Resumption Ticket sent by the client is the same on both ClientHello packets because it is always read from the same psk.key file. On a fresh install of WeChat, the Resumption Ticket is omitted since there is no psk.key file.</p>
<h4 id="serverhello">ServerHello</h4>
<p>The client receives a ServerHello packet in response to each ClientHello packet. Each contains:</p>
<ul>
<li>A record containing ServerRandom and Server public key</li>
<li>Records containing <strong>encrypted</strong> server certificate, new resumption ticket, and a ServerFinished message.</li>
</ul>
<p>An abbreviated version of the MMTLS ServerHello is shown below; a full packet sample with labels can be found in the <a href="https://docs.google.com/document/d/1Ub195WcLUY8YGJoGKW5IlhIIGaUWFzcM7aovNWqnFL4/edit" target="_blank" rel="noopener"><u>annotated network capture</u></a>.</p>
<div>
<pre><span>16 f1 04 (Handshake Record header) . . .</span>
02 04 f1 (ServerHello) . . .
2b a6 88 7e 61 5e 27 eb . . . (ServerRandom) . . .
04 fa e3 dc 03 4a 21 d9 . . . (Server public key) . . .
<span>16 f1 04 (Handshake Record header) . . .</span>
<span>b8 79 a1 60 be 6c</span> . . . (<strong>ENCRYPTED</strong> server certificate) . . .
<span>16 f1 04 (Handshake Record header) . . .</span>
<span>1a 6d c9 dd 6e f1</span> . . . (<strong>ENCRYPTED</strong> NEW resumption ticket) . . .
<span>16 f1 04 (Handshake Record header) . . .</span>
<span>b8 79 a1 60 be 6c </span>. . . (<strong>ENCRYPTED</strong> ServerFinished) . . .
</pre>
</div>
<p>On receiving the server public key, the client generates</p>
<p><code>secret = ecdh(client_private_key, server_public_key).</code></p>
<p>Note that since each MMTLS encrypted tunnel uses a different pair of client keys, the shared secret, and any derived keys and IVs will be different between MMTLS tunnels. This also means Longlink handshake and Shortlink handshake each compute a different shared secret.</p>
<p>Then, the shared secret is used to derive several sets of cryptographic parameters via HKDF, a mathematically secure way to transform a short secret value into a long secret value. In this section, we will focus on the <em>handshake parameters</em>. Alongside each set of keys, <a href="https://www.techtarget.com/whatis/definition/initialization-vector-IV" target="_blank" rel="noopener"><u>initialization vectors (IVs)</u></a> are also generated. The IV is a value that is needed to initialize the <a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode" target="_blank" rel="noopener"><u>AES-GCM</u></a> encryption algorithm. IVs do not need to be kept secret. However, they need to be random and not reused.</p>
<p>The <em>handshake parameters</em> are generated using HKDF (“handshake key expansion” is a constant string in the program, as well as other monotype double quoted strings in this section):</p>
<p><code>key_enc, key_dec, iv_enc, iv_dec = HKDF(secret, 56, “handshake key expansion”)</code></p>
<p>Using <code>key_dec</code> and <code>iv_dec</code>, the client can decrypt the remainder of the ServerHello records. Once decrypted, the client validates the server certificate. Then, the client also saves the new Resumption Ticket to the file <code>psk.key</code>.</p>
<p>At this point, since the shared <code>secret</code> has been established, the MMTLS Encryption Handshake is considered completed. To start encrypting and sending data, the client derives other sets of parameters via HKDF from the shared secret. The details of which keys are derived and used for which connections are fully specified in <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/outer-crypto.md#full-key-derivation-details" target="_blank" rel="noopener"><u>these notes</u></a> where we annotate the keys and connections created on WeChat startup.</p>
<h3 id="b.-data-encryption">2B. Data encryption</h3>
<p>After the handshake, MMTLS uses AES-GCM with a particular key and IV, which are tied to the particular MMTLS tunnel, to encrypt data. The IV is incremented by the number of records previously encrypted with this key. This is important because re-using an IV with the same key destroys the confidentiality provided in AES-GCM, as it can lead to a key recovery attack using the known tag.</p>
<p><code>ciphertext, tag = AES-GCM(input, key, iv+n)</code><br>
<code>ciphertext = ciphertext | tag</code></p>
<p>The 16-byte tag is appended to the end of the ciphertext. This tag is authentication data computed by <a href="https://en.wikipedia.org/wiki/Galois/Counter_Mode" target="_blank" rel="noopener"><u>AES-GCM</u></a>; it functions as a <a href="https://en.wikipedia.org/wiki/Message_authentication_code" target="_blank" rel="noopener"><u>MAC</u></a> in that when verified properly, this data provides authentication and integrity. In many cases, if this is a Data record being encrypted, <code>input</code> contains metadata and ciphertext that has already been encrypted as described in the Business-layer Encryption section.</p>
<p>We separately discuss data encryption in Longlink and Shortlink in the following subsections.</p>
<h4 id="b1.-longlink">2B1. Longlink</h4>
<p>Client-side Encryption for Longlink packets is done using AES-GCM with <strong>key_enc</strong> and <strong>iv_enc</strong> derived earlier in the handshake. Client-side Decryption uses <strong>key_dec</strong> and <strong>iv_dec</strong>. Below is a sample Longlink (TCP) packet containing a single data record containing an encrypted heartbeat message from the server<a id="fnref3" role="doc-noteref" href="#fn3"><sup>3</sup></a>:</p>
<div>
<pre><span>17 f1 04</span>     RECORD HEADER (of type “DATA”)
00 20                                           RECORD LENGTH
<span>e6 55 7a d6 82 1d a7 f4 2b 83 d4 b7 78 56 18 f3</span>         <span>ENCRYPTED DATA</span>
<span>1b 94 27 e1 1e c3 01 a6 f6 23 6a bc 94 eb 47 39</span>             <span>TAG (MAC)</span>
</pre>
</div>
<p>Within a long-lived Longlink connection, the IV is incremented for each record encrypted. If a new Longlink connection is created, the handshake is restarted and new key material is generated.</p>
<h4 id="b2.-shortlink">2B2. Shortlink</h4>
<p>Shortlink connections can only contain a single MMTLS packet request and a single MMTLS packet response (via HTTP POST request and response, respectively). After the initial Shortlink ClientHello sent on startup, WeChat will send ClientHello with Handshake Resumption packets. These records have the header 19 f1 04 instead of the 16 f1 04 on the regular ClientHello/ServerHello handshake packets.</p>
<p>An abbreviated sample of a Shortlink request packet containing Handshake Resumption is shown below.</p>
<div>
<pre><span>19 f1 04 (Handshake Resumption Record header) . . .</span>
01 04 f1 (ClientHello) . . .
9b c5 3c 42 7a 5b 1a 3b . . . (ClientRandom) . . .
71 ae ce ff d8 3f 29 48 . . . (NEW Resumption Ticket) . . .
<span>19 f1 04 (Handshake Resumption Record header) . . .</span>
<span>47 4c 34 03 71 9e</span> . . . (<strong>ENCRYPTED</strong> Extensions) . . .
<span>17 f1 04 (Data Record header) . . .</span>
<span>98 cd 6e a0 7c 6b</span> . . . (<strong>ENCRYPTED</strong> EarlyData) . . .
<span>15 f1 04 (Alert Record header)</span> . . .
<span>8a d1 c3 42 9a 30</span> . . . (<strong>ENCRYPTED</strong> Alert (ClientFinished)) . . .
</pre>
</div>
<p>Note that, based on our understanding of the MMTLS protocol, the ClientRandom sent in this packet is not used at all by the server, because there is no need to re-run Diffie-Hellman in a resumed session. The Resumption Ticket is used by the server to identify which prior-established shared secret should be used to decrypt the following packet content.</p>
<p>Encryption for Shortlink packets is done using AES-GCM with the <em>handshake parameters</em> <strong>key_enc</strong> and <strong>iv_enc</strong>. (Note that, despite their identical name, <strong>key_enc</strong> and <strong>iv_enc</strong> here are different from those of the Longlink, since Shortlink and Longlink each complete their own handshake using different elliptic curve client keypair.) The <strong>iv_enc</strong> is incremented for each record encrypted. Usually, EarlyData records sent over <strong>S</strong>hortlink contain ciphertext that has been encrypted with Business-layer Encryption as well as associated metadata. This metadata and ciphertext will then be additionally encrypted at this layer.</p>
<p>The reason this is referred to as EarlyData internally in WeChat is likely due to it being borrowed from <a href="https://datatracker.ietf.org/doc/html/rfc8446#section-4.2.10" target="_blank" rel="noopener"><u>TLS</u></a>; typically, it refers to the data that is encrypted with a key derived from a pre-shared key, before the establishment of a regular session key via Diffie-Hellman. However, in this case, when using Shortlink, there is no data sent “after the establishment of a regular session key”, so almost all Shortlink data is encrypted and sent in this EarlyData section.</p>
<p>Finally, <code>ClientFinished</code> indicates that the client has finished its side of the handshake. It is an encrypted Alert record with a fixed message that always follows the EarlyData Record. From our reverse-engineering, we found that the handlers for this message referred to it as <code>ClientFinished</code>.</p>
<h2 id="business-layer-request">3. Business-layer Request</h2>
<p>MMTLS Data Records either carry an “Business-layer request” or heartbeat messages. In other words, if one decrypts the payload from an MMTLS Data Record, the result will often be messages described below.</p>
<p>This Business-layer request contains several metadata parameters that describe the purpose of the request, including the internal URI and the request type number, which we briefly described in the “Launching a WeChat network request” section.</p>
<p>When logged-in, the format of a Business-layer request looks like the following:</p>
<div>
<pre><span>00 00 00 7b</span>                 (total data length)
<span>00 24</span>                       (URI length)
/cgi-bin/micromsg-bin/...   (URI)
<span>00 12</span>                       (hostname length)
sgshort.wechat.com          (hostname)
<span>00 00 00 3D</span>                 (length of rest of data)
<span>BF B6 5F</span>                    (request flags)
<span>41 41 41 41</span>                 (user ID)
<span>42 42 42 42</span>                 (device ID)
<span>FC 03 48 02 00 00 00 00</span>     (cookie)
<span>1F 9C 4C 24 76 0E 00</span>        (cookie)
<span>D1 05 varint</span>                (request_type)
<span>0E 0E 00 02</span>                 (4 more varints)
<span>BD 95 80 BF 0D varint</span>       (signature)
<span>FE</span>                          (flag)
<span>80 D2 89 91</span>
<span>04 00 00</span>                    (marks start of data)
<span>08 A6 29 D1 A4 2A CA F1</span> ... (ciphertext)
</pre>
</div>
<p>Responses are formatted very similarly:</p>
<div>
<pre><span>bf b6 5f</span>                    (flags)
<span>41 41 41 41</span>                 (user ID)
<span>42 42 42 42</span>                 (device ID)
<span>fc 03 48 02 00 00 00 00</span>     (cookie)
<span>1f 9c 4c 24 76 0e 00</span>        (cookie)
<span>fb 02 varint</span>                (request_type)
<span>35 35 00 02 varints</span>
<span>a9 ad 88 e3 08 varint</span>       (signature)
<span>fe</span>
<span>ba da e0 93</span>
<span>04 00 00</span>                    (marks start of data)
<span>b6 f8 e9 99 a1 f4 d1 20</span> . . . ciphertext
</pre>
</div>
<p>This request then contains another encrypted ciphertext, which is encrypted by what we refer to as Business-layer Encryption. Business-layer Encryption is separate from the system we described in the <strong>MMTLS Encryption</strong> section. The <code>signature</code> mentioned above is the output of <code>genSignature()</code>, which is discussed in the “Integrity check” section. Pseudocode for the serialization schemes and more samples of WeChat’s encrypted request header can be found in our <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/wechat-encrypted-request-format.md" target="_blank" rel="noopener"><u>Github repository</u></a>.</p>
<h2 id="business-layer-encryption">4. Business-layer Encryption</h2>
<p><a href="https://docs.google.com/drawings/d/1WSZY_R8XBliTDrb3tSkmoZpaq3lsud0sBaWRuygGuJo/edit" target="_blank" rel="noopener"><u>WeChat Crypto diagrams (inner layer)</u></a></p>
<p>This section describes how the Business-layer requests described in <strong>Section 3</strong> are encrypted and decrypted, and how the keys are derived. We note that the set of keys and encryption processes introduced in this section are completely separate from those referred to in the MMTLS Encryption section. Generally, for Business-layer Encryption, much of the protocol logic is handled in the Java code, and the Java code calls out to the C++ libraries for encryption and decryption calculations. Whereas for MMTLS Encryption everything is handled in C++ libraries, and occurs on a different process entirely. There is very little interplay between these two layers of encryption.</p>
<p>The Business-layer Encryption has two modes using different cryptographic processes: <em>Asymmetric Mode</em> and <em>Symmetric Mode</em>. To transition into Symmetric Mode, WeChat needs to perform an <em>Autoauth</em> request. Upon startup, WeChat typically goes through the three following stages:</p>
<ol type="1">
<li>Before the user logs in to their account, Business-layer Encryption first uses asymmetric cryptography to derive a shared secret via <a href="https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange#Ephemeral_and/or_static_keys" target="_blank" rel="noopener"><u>static Diffie-Hellman</u></a> (static DH), then uses the shared secret as a key to AES-GCM encrypt the data. We name this Asymmetric Mode. In Asymmetric Mode, the client derives a new shared secret for each request.</li>
<li>Using Asymmetric Mode, WeChat can send an Autoauth request, to which the server would return an Autoauth response, which contains a <code><strong>session_key</strong></code>.</li>
<li>After the client obtains <code>session_key</code>, Business-layer Encryption uses it to <a href="https://docs.anchormydata.com/docs/what-is-aes-256-cbc" target="_blank" rel="noopener"><u>AES-CBC</u></a> encrypt the data. We name this Symmetric Mode since it only uses symmetric cryptography. Under Symmetric Mode, the same <code>session_key</code> can be used for multiple requests.</li>
</ol>
<p>For <em>Asymmetric Mode</em>, we performed dynamic and static analysis of C++ functions in libwechatmm.so; in particular the <code>HybridEcdhEncrypt()</code> and <code>HybridEcdhDecrypt()</code> functions, which call <code>AesGcmEncryptWithCompress()</code> / <code>AesGcmDecryptWithUncompress()</code>, respectively.</p>
<p>For <em>Symmetric Mode</em>, the requests are handled in <code>pack()</code>, <code>unpack()</code>, and <code>genSignature()</code> functions in <code>libMMProtocalJNI.so</code>. Generally, <code>pack()</code> handles outgoing requests, and <code>unpack()</code> handles incoming responses to those requests. They also perform encryption/decryption. Finally, <code>genSignature()</code> computes a checksum over the full request. In the Github repository, we’ve uploaded pseudocode for <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/reversing-notes.md#pack-notes" target="_blank" rel="noopener"><u>pack</u></a>, <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/reversing-notes.md#aesencrypt-cbc" target="_blank" rel="noopener"><u>AES-CBC</u></a> encryption, and the <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/reversing-notes.md#gensignature" target="_blank" rel="noopener"><u>genSignature</u></a> routine.</p>
<p>The Business-layer Encryption is also tightly integrated with WeChat’s user authentication system. The user needs to log in to their account before the client is able to send an Autoauth request. For clients that have not logged in, they exclusively use Asymmetric Mode. For clients that have already logged in, their first Business-layer packet would most often be an Autoauth request encrypted using Asymmetric Mode, however, the second and onward Business-layer packets are encrypted using Symmetric Mode.</p>
<figure><p><a href="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3.png&amp;nocache=1"><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3.png&amp;nocache=1" alt="" width="842" height="363" title="Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol 4" srcset="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3.png&amp;nocache=1 842w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-300x129.png&amp;nocache=1 300w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-768x331.png&amp;nocache=1 768w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-605x261.png&amp;nocache=1 605w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-297x128.png&amp;nocache=1 297w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-500x216.png&amp;nocache=1 500w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image3-180x78.png&amp;nocache=1 180w" sizes="(max-width: 842px) 100vw, 842px"></a></p><figcaption><strong>Figure 2: Business-layer encryption, logged-out, logging-in, and logged-in:</strong> Swimlane diagrams showing at a high-level what Business-layer Encryption requests look like, including which secrets are used to generate the key material used for encryption. 🔑secret is generated via DH(static server public key, client private key), and 🔑<strong>new_secret</strong> is DH(server public key, client private key). 🔑<strong>session</strong> is decrypted from the first response when logged-in. Though it isn’t shown above, 🔑<strong>new_secret</strong> is also used in <strong>genSignature()</strong> when logged-in; this signature is sent with request and response metadata.</figcaption></figure>
<h3 id="a.-business-layer-encryption-asymmetric-mode">4A. Business-layer Encryption, Asymmetric Mode</h3>
<p>Before the user logs in to their WeChat account, the Business-layer Encryption process uses a <em>static server public key</em>, and generates new client keypair to agree on a static Diffie-Hellman shared secret for every WeChat network request. The shared secret is run through the HKDF function and any data is encrypted with AES-GCM and sent alongside the generated client public key so the server can calculate the shared secret.</p>
<p>For each request, the client generates a public, private keypair for use with <a href="https://en.wikipedia.org/wiki/Elliptic-curve_Diffie%E2%80%93Hellman" target="_blank" rel="noopener"><u>ECDH</u></a>. We also note that the client has a static server public key pinned in the application. The client then calculates an initial secret.</p>
<p><code>secret = <a href="https://github.com/openssl/openssl/blob/79c8dcf3985a7b75eac8e53eb8652728af6c5d3d/crypto/ec/ec_kmeth.c#L151" target="_blank" rel="noopener"><u>ECDH</u></a>(static_server_pub, client_priv)</code><br>
<code>hash = sha256(client_pub)</code><br>
<code>client_random = &lt;32 randomly generated bytes&gt;</code><br>
<code>derived_key = HKDF(secret)</code></p>
<p><code>derived_key</code> is then used to AES-GCM encrypt the data, which we describe in detail in the next section.</p>
<h3 id="b.-business-layer-encryption-obtaining-session_key">4B. Business-layer Encryption, obtaining session_key</h3>
<p>If the client is logged-in (i.e., the user has logged in to a WeChat account on a previous app run), the first request will be a very large data packet authenticating the client to the server (referred to as Autoauth in WeChat internals) which also contains key material. We refer to this request as the Autoauth request. In addition, the client pulls a locally-stored key <code>autoauth_key</code>, which we did not trace the provenance of, since it does not seem to be used other than in this instance. The key for encrypting this initial request (<code>authrequest_data</code>) is derived_key, calculated in the same way as in Section 4A. The encryption described in the following is the Asymmetric Mode encryption, albeit a special case where the data is the <code>authrequest_data</code>.</p>
<p>Below is an abbreviated version of a serialized and encrypted Autoauth request:</p>
<div>
<pre>    08 01 12 . . . [Header metadata]
    04 46 40 96 4d 3e 3e 7e [client_publickey] . . .
    fa 5a 7d a7 78 e1 ce 10 . . . [ClientRandom encrypted w secret]
    a1 fb 0c da . . .               [IV]
    9e bc 92 8a 5b 81 . . .         [tag]
    db 10 d3 0f f8 e9 a6 40 . . . [ClientRandom encrypted w autoauth_key]
    75 b4 55 30 . . .               [IV]
    d7 be 7e 33 a3 45 . . .         [tag]
    c1 98 87 13 eb 6f f3 20 . . . [<strong>authrequest_data</strong> encrypted w derived_key]
    4c ca 86 03 . .                 [IV]
    3c bc 27 4f 0e 7b . . .         [tag]
</pre>
</div>
<p>A full sample of the Autoauth request and response at each layer of encryption can be found in the <a href="https://github.com/citizenlab/wechat-security-report/tree/main/data" target="_blank" rel="noopener"><u>Github repository</u></a>. Finally, we note that the <code>autoauth_key</code> above does not seem to be actively used outside of encrypting in this particular request. We suspect this is vestigial from a legacy encryption protocol used by WeChat.</p>
<p>The client encrypts here using AES-GCM with a randomly generated IV, and uses a SHA256 hash of the preceding message contents as <a href="https://datatracker.ietf.org/doc/html/rfc5084#section-1.4" target="_blank" rel="noopener"><u>AAD</u></a>. At this stage, the messages (including the ClientRandom messages) are always <a href="https://en.wikipedia.org/wiki/Zlib" target="_blank" rel="noopener"><u>ZLib</u></a> compressed before encryption.</p>
<p><code>iv = &lt;12 random bytes&gt;<br>
compressed = zlib_compress(plaintext)<br>
ciphertext, tag = AESGCM_encrypt(compressed, aad = hash(previous), derived_key, iv)<br>
</code></p>
<p>In the above, previous is the header of the request (i.e. all header bytes preceding the 04 00 00 marker of data start). The client appends the 12-byte IV, then the 16-byte tag, onto the ciphertext. This tag can be used by the server to verify the integrity of the ciphertext, and essentially functions as a <a href="https://en.wikipedia.org/wiki/Message_authentication_code" target="_blank" rel="noopener"><u>MAC</u></a>.</p>
<h4 id="b1.-obtaining-session_key-autoauth-response">4B1. Obtaining session_key: Autoauth Response</h4>
<p>The response to autoauth is serialized similarly to the request:</p>
<div>
<pre>08 01 12 . . . [Header metadata]
04 46 40 96 4d 3e 3e 7e [new_server_pub] . . .
c1 98 87 13 eb 6f f3 20 . . . [<strong>authresponse_data</strong> encrypted w new_secret]
4c ca 86 03 . . [IV]
3c bc 27 4f 0e 7b . . . [tag]
</pre>
</div>
<p>With the newly received server public key (<code>new_server_pub</code>), which is different from the <code>static_server_pub</code> hardcoded in the app, the client then derives a new secret (<code>new_secret</code>). new_secret is then used as the key to AES-GCM decrypt <code>authresponse_data</code>. The client can also verify <code>authresponse_data</code> with the given tag.</p>
<p><code>new_secret = <a href="https://github.com/openssl/openssl/blob/79c8dcf3985a7b75eac8e53eb8652728af6c5d3d/crypto/ec/ec_kmeth.c#L151" target="_blank" rel="noopener"><u>ECDH</u></a>(new_server_pub, client_privatekey)<br>
authresponse_data= AESGCM_decrypt(aad = hash(authrequest_data),<br>
new_secret, iv)<br>
</code></p>
<p><code>authresponse_data</code> is a serialized Protobuf containing a lot of important data for WeChat to start, starting with a helpful <strong>“</strong><code>Everything is ok</code><strong>”</strong> status message. A full sample of this Protobuf can be found in the <a href="https://github.com/citizenlab/wechat-security-report/blob/main/data/autoauth-response.json" target="_blank" rel="noopener"><u>Github repository</u></a>. Most importantly, <code>authresponse_data</code> contains <code><strong>session_key</strong></code>, which is the key used for future AES-CBC encryption under Symmetric Mode. From here on out, <code>new_secret</code> is only used in <code>genSignature()</code>, which is discussed below in Section 4C2 Integrity Check.</p>
<p>We measured the entropy of the session_key provided by the server, as it is used for future encryption. This key exclusively uses printable ASCII characters, and is thus limited to around ~100 bits of entropy.</p>
<p>The WeChat code refers to three different keys: <em>client_session</em>, <em>server_session</em>, and <em>single_session</em>. Generally, <em>client_session</em> refers to the <code>client_publickey</code>, <code>server_session</code> refers to the <em>shared secret key</em> generated using ECDH i.e. <code>new_secret</code>, and <code>single_session</code> refers to the <code>session_key</code> provided by the server.</p>
<h3 id="c.-business-layer-encryption-symmetric-mode">4C. Business-layer Encryption, Symmetric Mode</h3>
<p>After the client receives session_key from the server, future data is encrypted using Symmetric Mode. Symmetric Mode encryption is mostly done using AES-CBC instead of AES-GCM, with the exception of some large files being encrypted with <code>AesGcmEncryptWithCompress()</code>. As <code>AesGcmEncryptWithCompress()</code> requests are the exception, we focus on the more common use of AES-CBC.</p>
<p>Specifically, the Symmetric Mode uses AES-CBC with PKCS-7 padding, with the session_key as a symmetric key:</p>
<p><code>ciphertext = AES-CBC(PKCS7_pad(plaintext), session_key, iv = session_key)<br>
</code></p>
<p>This <code>session_key</code> is doubly used as the IV for encryption.</p>
<h4 id="c1.-integrity-check">4C1. Integrity check</h4>
<p>In Symmetric Mode, a function called <code>genSignature()</code> calculates a pseudo-integrity code on the plaintext. This function first calculates the <strong>MD5 hash</strong> of WeChat’s assigned user ID for the logged-in user (<code><span>uin</span></code>), <code><span>new_secret</span></code>, and the plaintext length. Then, genSignature() uses <a href="https://en.wikipedia.org/wiki/Adler-32" target="_blank" rel="noopener"><strong><u>Adler32</u></strong></a>, a checksumming function, on the MD5 hash concatenated with the plaintext.</p>
<div>
<pre>signature = adler32(md5(uin | new_secret | plaintext_len) |
            plaintext)
</pre>
</div>
<p>The result from Adler32 is concatenated to the ciphertext as metadata (see Section 3A for how it is included in the request and response headers), and is referred to as a <code>signature</code> in WeChat’s codebase. We note that though it is referred to as a <code>signature</code>, it does not provide any cryptographic properties; details can be found in the Security Issues section. The full pseudocode for this function can also be found in <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/reversing-notes.md#gensignature" target="_blank" rel="noopener"><u>the Github repository</u></a>.</p>
<h2 id="protobuf-data-payload">5. Protobuf data payload</h2>
<p>The input to Business-layer Encryption is generally a serialized Protobuf, optionally compressed with Zlib. When logged-in, many of the Protobufs sent to the server contain the following header data:</p>
<div>
<pre>"1": {
    "1": "\u0000",
    "2": "1111111111", # User ID (assigned by WeChat)
    "3": "AAAAAAAAAAAAAAA\u0000", # Device ID (assigned by WeChat)
    "4": "671094583", # Client Version
    "5": "android-34", # Android Version
    "6": "0"
    },
</pre>
</div>
<p>The Protobuf structure is defined in each API’s corresponding RR class, as we previously mentioned in the “Launching a WeChat network request” section.</p>
<h2 id="putting-it-all-together">6. Putting it all together</h2>
<p>In the below diagram, we demonstrate the network flow for the most common case of opening the WeChat application. We note that in order to prevent further complicating the diagram, HKDF derivations are not shown; for instance, when “🔑<code>mmtls</code>” is used, HKDF is used to derive a key from “🔑<code>mmtls</code>”, and the derived key is used for encryption. The specifics of how keys are derived, and which derived keys are used to encrypt which data, can be found in <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/outer-crypto.md#full-key-derivation-details" target="_blank" rel="noopener"><u>these notes</u></a>.</p>
<figure><p><a href="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1.png&amp;nocache=1"><img loading="lazy" decoding="async" src="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1.png&amp;nocache=1" alt="" width="914" height="1331" title="Should We Chat, Too? Security Analysis of WeChat’s MMTLS Encryption Protocol 5" srcset="https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1.png&amp;nocache=1 914w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-206x300.png&amp;nocache=1 206w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-703x1024.png&amp;nocache=1 703w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-768x1118.png&amp;nocache=1 768w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-233x340.png&amp;nocache=1 233w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-137x199.png&amp;nocache=1 137w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-190x277.png&amp;nocache=1 190w, https://citizenlab.ca/wp-content/webpc-passthru.php?src=https://citizenlab.ca/wp-content/uploads/2024/10/image1-180x262.png&amp;nocache=1 180w" sizes="(max-width: 914px) 100vw, 914px"></a></p><figcaption>Figure 3: Swimlane diagram demonstrating the encryption setup and network flow of the most common case (user is logged in, opens WeChat application).</figcaption></figure>
<p>We note that other configurations are possible. For instance, we have observed that if the Longlink MMTLS handshake completes first, the Business-layer “Logging-in” request and response can occur over the Longlink connection instead of over several <strong>shortlink</strong> connections. In addition, if the user is logged-out, Business-layer requests are simply encrypted with 🔑secret (resembling <strong>Shortlink 2</strong> requests)</p>
<h2 id="security-issues">Security issues</h2>
<p>In this section, we outline potential security issues and privacy weaknesses we identified with the construction of the <strong>MMTLS encryption</strong> and <strong>Business-layer</strong> encryption layers. There could be other issues as well.</p>
<h2 id="issues-with-mmtls-encryption">Issues with MMTLS encryption</h2>
<p>Below we detail the issues we found with WeChat’s MMTLS encryption.</p>
<h3 id="deterministic-iv">Deterministic IV</h3>
<p>The MMTLS encryption process generates a single IV once per connection. Then, they increment the IV for each subsequent record encrypted in that connection. Generally, NIST <a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf" target="_blank" rel="noopener"><u>recommends</u></a> not using a wholly deterministic derivation for IVs in AES-GCM since it is easy to accidentally re-use IVs. In the case of AES-GCM, reuse of the (key, IV) tuple is catastrophic as it <a href="https://csrc.nist.gov/csrc/media/projects/block-cipher-techniques/documents/bcm/comments/800-38-series-drafts/gcm/joux_comments.pdf" target="_blank" rel="noopener"><u>allows key recovery</u></a> from the AES-GCM authentication tags. Since these tags are appended to AES-GCM ciphertexts for authentication, this enables plaintext recovery from as few as 2 ciphertexts encrypted with the same key and IV pair.</p>
<p>In addition, <a href="https://eprint.iacr.org/2016/564.pdf" target="_blank" rel="noopener"><u>Bellare and Tackmann</u></a> have shown that the use of a deterministic IV can make it possible for a powerful adversary to brute-force a particular (key, IV) combination. This type of attack applies to powerful adversaries, if the crypto system is deployed to a very large (i.e., the size of the Internet) pool of (key, IV) combinations being chosen. Since WeChat has over a billion users, this order of magnitude puts this attack within the realm of feasibility.</p>
<h3 id="lack-of-forward-secrecy">Lack of forward secrecy</h3>
<p>Forward secrecy is <a href="https://github.com/ssllabs/research/wiki/SSL-and-TLS-Deployment-Best-Practices" target="_blank" rel="noopener"><u>generally expected</u></a> of modern communications protocols to reduce the importance of session keys. Generally, TLS itself is forward-secret by design, except in the case of the first packet of a “resumed” session. This first packet is encrypted with a “pre-shared key”, or PSK established during a previous handshake.</p>
<p>MMTLS makes heavy use of PSKs by design. Since the Shortlink transport format only supports a single round-trip of communication (via a single HTTP POST request and response), any encrypted data sent via the transport format is encrypted with a pre-shared key. Since leaking the shared `PSK_ACCESS` secret would enable a third-party to decrypt any EarlyData sent across multiple MMTLS connections, data encrypted with the pre-shared key is not forward secret. The vast majority of records encrypted via MMTLS are sent via the Shortlink transport, which means that the majority of network data sent by WeChat is not forward-secret between connections. In addition, when opening the application, WeChat creates a single long-lived Longlink connection. This long-lived Longlink connection is open for the duration of the WeChat application, and any encrypted data that needs to be sent is sent over the same connection. Since most WeChat requests are either encrypted using (A) a session-resuming PSK or (B) the application data key of the long-lived Longlink connection, WeChat’s network traffic often does not retain forward-secrecy between network requests.</p>
<h2 id="issues-with-business-layer-encryption">Issues with Business-layer encryption</h2>
<p>On its own, the business-layer encryption construction, and, in particular the Symmetric Mode, AES-CBC construction, has many severe issues. Since the requests made by WeChat are double-encrypted, and these concerns only affect the inner, business layer of encryption, we did not find an immediate way to exploit them. However, in older versions of WeChat which exclusively used business-layer encryption, these issues would be exploitable.</p>
<h3 id="metadata-leak">Metadata leak</h3>
<p>Business-layer encryption does not encrypt metadata such as the user ID and request URI, as shown in the “Business-layer request” section. This issue is also <a href="https://cloud.tencent.com/developer/article/1005518" target="_blank" rel="noopener"><u>acknowledged</u></a> by the WeChat developers themselves to be one of the motivations to develop MMTLS encryption.</p>
<h3 id="forgeable-gensignature-integrity-check">Forgeable genSignature integrity check</h3>
<p>While the purpose of the <code>genSignature</code> code is not entirely clear, if it is being used for authentication (since the <code>ecdh_key</code> is included in the MD5) or integrity, it fails on both parts. A valid forgery can be calculated with any known <code>plaintext</code> without knowledge of the <code>ecdh_key</code>. If the client generates the following for some known plaintext message <code>plaintext</code>:</p>
<p><code>sig = adler32(md5(uin | ecdh_key | plaintext_len) | plaintext)</code></p>
<p>We can do the following to forge the signature <code>evil_sig</code> for some <code>evil_plaintext</code> with length <code>plaintext_len</code>:</p>
<p><code>evil_sig = sig - adler32(plaintext) + adler32(evil_plaintext)</code></p>
<p>Subtracting and adding from <code>adler32</code> checksums is achievable by solving for a system of equations <a href="https://en.wikipedia.org/wiki/Adler-32#Weakness" target="_blank" rel="noopener"><u>when the message is short</u></a>. Code for subtracting and adding to <code>adler32</code> checksum, thereby forging this integrity check, can be found in <code>adler.py</code> in <a href="https://github.com/citizenlab/wechat-security-report/blob/main/code/adler.py" target="_blank" rel="noopener"><u>our Github repository</u></a>.</p>
<h3 id="possible-aes-cbc-padding-oracle">Possible AES-CBC padding oracle</h3>
<p>Since AES-CBC is used alongside <a href="https://en.wikipedia.org/wiki/PKCS_7" target="_blank" rel="noopener"><u>PKCS7</u></a> padding, it is possible that the use of this encryption on its own would be susceptible to an <a href="https://en.wikipedia.org/wiki/Padding_oracle_attack" target="_blank" rel="noopener"><u>AES-CBC padding oracle</u></a>, which can lead to recovery of the encrypted plaintext. Earlier this year, we found that another custom cryptography scheme developed by a Tencent company was <a href="https://citizenlab.ca/2023/08/vulnerabilities-in-sogou-keyboard-encryption/"><u>susceptible to this exact attack</u></a>.</p>
<h3 id="key-iv-re-use-in-block-cipher-mode">Key, IV re-use in block cipher mode</h3>
<p>Re-using the key as the IV for AES-CBC, as well as re-using the same key for all encryption in a given session (i.e., the length of time that the user has the application opened) introduces some privacy issues for encrypted plaintexts. For instance, since the key and the IV provide all the randomness, re-using both means that if two plaintexts are identical, they will encrypt to the same ciphertext. In addition, due to the use of <a href="https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_block_chaining_(CBC)" target="_blank" rel="noopener"><u>CBC mode</u></a> in particular, two plaintexts with identical N block-length prefixes will encrypt to the same first N ciphertext blocks.</p>
<h3 id="encryption-key-issues">Encryption key issues</h3>
<p>It is highly unconventional for the server to choose the encryption key used by the client. In fact, we note that the encryption key generated by the server (the “session key”) exclusively uses printable ASCII characters. Thus, even though the key is 128 bits long, the entropy of this key is at most 106 bits.</p>
<h3 id="no-forward-secrecy">No forward secrecy</h3>
<p>As mentioned in the previous section, forward-secrecy is a standard property for modern network communication encryption. When the user is logged-in, all communication with WeChat, at this encryption layer, is done with the exact same key. The client does not receive a new key until the user closes and restarts WeChat.</p>
<h2 id="other-versions-of-wechat">Other versions of WeChat</h2>
<p>To confirm our findings, we also tested our decryption code on WeChat 8.0.49 for Android (released April 2024) and found that the MMTLS network format matches that used by WeChat 8.0.49 for iOS.</p>
<h2 id="previous-versions-of-wechat-network-encryption">Previous versions of WeChat network encryption</h2>
<p>To understand how WeChat’s complex cryptosystems are tied together, we also briefly reverse-engineered an older version of WeChat that did not utilize MMTLS. The newest version of WeChat that did not utilize MMTLS was v6.3.16, released in 2016. Our full notes on this reverse-engineering can be found <a href="https://github.com/citizenlab/wechat-security-report/blob/main/docs/wechat-v6.3.16.md" target="_blank" rel="noopener"><u>here</u></a>.</p>
<p>While logged-out, requests were largely using the Business-layer Encryption cryptosystem, using RSA public-key encryption rather than static Diffie-Hellman plus symmetric encryption via AES-GCM. We observed requests to the internal URIs <code>cgi-bin/micromsg-bin/encryptcheckresupdate</code> and <code>cgi-bin/micromsg-bin/getkvidkeystrategyrsa</code>.</p>
<p>There was also another encryption mode used, DES with a static key. This mode was used for sending crash logs and memory stacks; POST requests to the URI <code>/cgi-bin/mmsupport-bin/stackreport</code> were encrypted using DES.</p>
<p>We were not able to login to this version for dynamic analysis, but from our static analysis, we determined that the encryption behaves the same as Business-layer Encryption when logged-in (i.e. using a <code>session_key</code> provided by the server for AES-CBC encryption).</p>
<h2 id="discussion">Discussion</h2>
<h3 id="why-does-business-layer-encryption-matter">Why does Business-layer encryption matter?</h3>
<p>Since Business-layer encryption is wrapped in MMTLS, why should it matter whether or not it is secure? First, from our study of previous versions of WeChat, Business-layer encryption was the sole layer of encryption for WeChat network requests until 2016. Second, from the the fact that Business-layer encryption exposes internal request URI unencrypted, one of the possible architectures for WeChat would be to host different internal servers to handle different types of network requests (corresponding to different “requestType” values and different cgi-bin request URLs). It could be the case, for instance, that after MMTLS is terminated at the front WeChat servers (handles MMTLS decryption), the inner WeChat request that is forwarded to the corresponding internal WeChat server is not re-encrypted, and therefore solely encrypted using Business-layer encryption. A network eavesdropper, or network tap, placed within WeChat’s intranet could then attack the Business-layer encryption on these forwarded requests. However, this scenario is purely conjectural. <span>Tencent’s response to our disclosure is concerned with issues in Business-layer encryption and implies they are slowly migrating from the more problematic AES-CBC to AES-GCM, so Tencent is also concerned with this.</span></p>
<h3 id="why-not-use-tls">Why not use TLS?</h3>
<p>According to <a href="https://docs.google.com/document/d/14Gsqi3vWjXLhF3odeTjhq_njtTk4aFPr-LptPwuzMsw/edit" target="_blank" rel="noopener"><u>public documentation</u></a> and confirmed by our own findings, MMTLS (the “Outer layer” of encryption) is based heavily on TLS 1.3. In fact, the document demonstrates that the architects of MMTLS have a decent understanding of asymmetric cryptography in general.</p>
<p>The document contains reasoning for not using TLS. It explains that the way WeChat uses network requests necessitates something like <a href="https://www.haproxy.com/glossary/what-is-zero-round-trip-time-resumption-0-rtt" target="_blank" rel="noopener"><u>0-RTT</u></a> session resumption, because the majority of WeChat data transmission needs only one request-response cycle (i.e., Shortlink). MMTLS only required one round-trip handshake to establish the underlying TCP connection before any application data can be sent; according to this document, introducing another round-trip for the TLS 1.2 handshake was a non-starter.</p>
<blockquote><p>Fortunately, TLS1.3 proposes a 0-RTT (no additional network delay) method for the protocol handshake. In addition, the protocol itself provides extensibility through the version number, CipherSuite, and Extension mechanisms. However, TLS1.3 is still in draft phases, and its implementation may still be far away. TLS1.3 is also a general-purpose protocol for all apps, given the characteristics of WeChat, there is great room for optimization. Therefore, at the end, we chose to design and implement our own secure transport protocol, MMTLS, based on the TLS1.3 draft standard. [originally written in Chinese]</p></blockquote>
<p>However, even at the time of writing in 2016, TLS 1.2 did provide an option for <a href="https://blog.cloudflare.com/tls-session-resumption-full-speed-and-secure/" target="_blank" rel="noopener"><u>session resumption</u></a>. In addition, since WeChat controls both the servers and the clients, it doesn’t seem unreasonable to deploy the fully-fledged TLS 1.3 implementations that were being tested at the time, even if the IETF draft was incomplete.</p>
<p>Despite the architects of MMTLS’ best effort, generally, the security protocols used by WeChat seem both less performant and less secure than TLS 1.3. Generally speaking, designing a secure and performant transport protocol is no easy feat.</p>
<p>The issue of performing an extra round-trip for a handshake has been a perennial issue for application developers. The TCP and TLS handshake each require a single round-trip, meaning each new data packet sent requires two round-trips. Today, TLS-over-QUIC combines the transport-layer and encryption-layer handshakes, requiring only a single handshake. QUIC provides the best of both worlds, both strong, forward-secret encryption, and halving the number of round-trips needed for secure communication. <strong>Our recommendation would be for WeChat to migrate to a standard QUIC implementation.</strong></p>
<p>Finally, there is also the issue of client-side performance, in addition to network performance. Since WeChat’s encryption scheme performs two layers of encryption per request, the client is performing double the work to encrypt data, than if they used a single standardized cryptosystem.</p>
<h3 id="the-trend-of-home-rolled-cryptography-in-chinese-applications">The trend of home-rolled cryptography in Chinese applications</h3>
<p>The findings here contribute to much of <a href="https://citizenlab.ca/2024/04/vulnerabilities-across-keyboard-apps-reveal-keystrokes-to-network-eavesdroppers/"><u>our</u></a> <a href="https://citizenlab.ca/2016/03/privacy-security-issues-qq-browser/"><u>prior</u></a> <a href="https://citizenlab.ca/2015/05/a-chatty-squirrel-privacy-and-security-issues-with-uc-browser/"><u>research</u></a> that suggests the popularity of home-grown cryptography in Chinese applications. In general, the avoidance of TLS and the preference for proprietary and non-standard cryptography is a departure from cryptographic best practices. While there may have been many legitimate reasons to distrust TLS in 2011 (like <a href="https://www.usenix.org/legacy/events/sec11/tech/slides/eckersley.pdf" target="_blank" rel="noopener"><u>EFF</u></a> and <a href="https://www.accessnow.org/wp-content/uploads/archive/docs/Weakest_Link_in_the_Chain.pdf" target="_blank" rel="noopener"><u>Access Now</u></a>’s concerns over the certificate authority ecosystem), the TLS ecosystem has largely <a href="https://letsencrypt.org/stats/" target="_blank" rel="noopener"><u>stabilized</u></a> since then, and is more auditable and <a href="https://certificate.transparency.dev/" target="_blank" rel="noopener"><u>transparent</u></a>. Like MMTLS, all the proprietary protocols we have researched in the past contain weaknesses relative to TLS, and, in some cases, could even be <a href="https://citizenlab.ca/2024/04/vulnerabilities-across-keyboard-apps-reveal-keystrokes-to-network-eavesdroppers/"><u>trivially decrypted</u></a> by a network adversary. This is a growing, concerning trend unique to the Chinese security landscape as the global Internet progresses towards technologies like QUIC or TLS to protect data in transit.</p>
<h3 id="anti-dns-hijacking-mechanisms">Anti-DNS-hijacking mechanisms</h3>
<p>Similar to how Tencent wrote their own cryptographic system, we found that in Mars they also wrote a proprietary domain lookup system. This system is part of STN and has the ability to support domain name to IP address lookups over HTTP. This feature is referred to as “NewDNS” in Mars. Based on our dynamic analysis, this feature is regularly used in WeChat. At first glance, NewDNS duplicates the same functions already provided by DNS (Domain Name System), which is already built into nearly all internet-connected devices.</p>
<p>WeChat is not the only app in China that utilizes such a system. Major cloud computing providers in China such as <a href="https://cn.aliyun.com/product/httpdns?from_alibabacloud=" target="_blank" rel="noopener"><u>Alibaba Cloud</u></a> and <a href="https://cloud.tencent.com/developer/article/2180368" target="_blank" rel="noopener"><u>Tencent Cloud</u></a> both offer their own DNS over HTTP service. A VirusTotal search for apps that tries to contact <a href="https://github.com/TencentCloud/httpdns-sdk-android" target="_blank" rel="noopener"><u>Tencent Cloud’s DNS over HTTP service endpoint (119.29.29.98)</u></a> yielded <a href="https://www.virustotal.com/gui/search/behavior_network%253A%2522119.29.29.98%2522/files" target="_blank" rel="noopener"><u>3,865 unique results</u></a>.</p>
<p>One likely reason for adopting such a system is that ISPs in China often implement <a href="https://en.wikipedia.org/wiki/DNS_hijacking" target="_blank" rel="noopener"><u>DNS hijacking</u></a> to insert ads and redirect web traffic to perform <a href="https://www.oracle.com/uk/advertising/measurement/ad-fraud-invalid-traffic/" target="_blank" rel="noopener"><u>ad fraud</u></a>. The problem was so serious that six Chinese internet giants <a href="https://www.thepaper.cn/newsDetail_forward_1413110" target="_blank" rel="noopener"><u>issued a joint statement in 2015</u></a> urging ISPs to improve. According to the news article, about 1–2% of traffic to Meituan (an online shopping site) suffers from DNS hijacking. Ad fraud by Chinese ISPs seems to remain a <a href="https://web.archive.org/web/20240131063911/https://www.v2ex.com/t/651746" target="_blank" rel="noopener"><u>widespread</u></a> <a href="https://web.archive.org/web/20240131063930/https://m.thepaper.cn/baijiahao_15406173" target="_blank" rel="noopener"><u>problem</u></a> in recent years.</p>
<p>Similar to their MMTLS cryptographic system, Tencent’s NewDNS domain lookup system was motivated by trying to meet the needs of the Chinese networking environment. DNS proper over the years has proven to have multiple <a href="https://en.wikipedia.org/w/index.php?title=Domain_Name_System&amp;oldid=1232087380#Security_issues" target="_blank" rel="noopener"><u>security</u></a> and <a href="https://en.wikipedia.org/w/index.php?title=Domain_Name_System&amp;oldid=1232087380#Privacy_and_tracking_issues" target="_blank" rel="noopener"><u>privacy</u></a> issues. Compared to TLS, we found that WeChat’s MMTLS has additional deficiencies. However, it remains an open question as to, when compared to DNS proper, whether NewDNS is more or less problematic. We leave this question for future work.</p>
<h3 id="use-of-mars-stn-outside-wechat">Use of Mars STN outside WeChat</h3>
<p>We speculate that there is a widespread adoption of Mars (mars-open) outside of WeChat, based on the following observations:</p>
<ul>
<li>There are numerous <a href="https://github.com/Tencent/mars/issues" target="_blank" rel="noopener"><u>issues</u></a> opened on the Mars GitHub repository.</li>
<li>There are <a href="http://www.li5jun.com/article/662.html" target="_blank" rel="noopener"><u>plenty</u></a> <a href="https://blog.csdn.net/BunnyCoffer/article/details/80051766" target="_blank" rel="noopener"><u>of</u></a> technical <a href="https://segmentfault.com/a/1190000016558538" target="_blank" rel="noopener"><u>articles</u></a> outlining building instant messaging systems using Mars.</li>
<li>There is already <a href="https://docs.wildfirechat.cn/" target="_blank" rel="noopener"><u>a white-label instant messaging system product</u></a> that is based on Mars.</li>
</ul>
<p>The adoption of Mars outside of WeChat is concerning because Mars by default does not provide any transport encryption. As we have mentioned in the “Three Parts of Mars” section, the MMTLS encryption used in WeChat is part of mars-wechat, which <a href="https://github.com/Tencent/mars/issues/1023" target="_blank" rel="noopener"><u>is not open source</u></a>. The Mars developers <a href="https://github.com/Tencent/mars/issues/81" target="_blank" rel="noopener"><u>also have no plans to add support of TLS, and expect other developers using Mars to implement their own encryption in the upper layers</u></a>. To make matters worse, implementing TLS within Mars <a href="https://github.com/Tencent/mars/issues/184" target="_blank" rel="noopener"><u>seems to require a fair bit of architectural changes</u></a>. Even though it would not be unfair for Tencent to keep MMTLS proprietary, MMTLS is still the main encryption system that Mars was designed for, leaving MMTLS proprietary would mean other developers using Mars would have to either devote significant resources to integrate a different encryption system with Mars, or leave everything unencrypted.</p>
<p>Mars is also lacking in documentation. The official <a href="https://github.com/Tencent/mars/wiki/" target="_blank" rel="noopener"><u>wiki</u></a> only contains a few, old articles on how to integrate with Mars. Developers using Mars often resort to <a href="https://github.com/Tencent/mars/issues/639" target="_blank" rel="noopener"><u>asking questions on GitHub</u></a>. The lack of documentation means that developers are more prone to making mistakes, and ultimately reducing security.</p>
<p>Further research is needed in this area to analyze the security of apps that use Tencent’s Mars library.</p>
<h3 id="tinker-a-dynamic-code-loading-module">“Tinker”, a dynamic code-loading module</h3>
<p>In this section, we tentatively refer to the APK downloaded from the Google Play Store as “WeChat APK”, and the APK downloaded from WeChat’s official website as “Weixin APK”. The distinction between WeChat and Weixin seems blurry. The WeChat APK and Weixin APK contain partially different code, as we will later discuss in this section. However, when installing both of these APKs to an English-locale Android Emulator, they both show their app names as “WeChat”. Their application ID, which is used by the Android system and Google Play Store to identify apps, are also both “com.tencent.mm”. We were also able to login to our US-number accounts using both APKs.</p>
<p>Unlike the WeChat APK, we found that the Weixin APK contains Tinker, <a href="https://github.com/Tencent/tinker" target="_blank" rel="noopener"><u>“a hot-fix solution library”</u></a>. Tinker allows the developer to update the app itself without calling Android’s system APK installer by using a technique called “dynamic code loading”. In an earlier report we found a similar <a href="https://citizenlab.ca/2021/03/tiktok-vs-douyin-security-privacy-analysis/"><u>distinction</u></a> between TikTok and Douyin, where we found Douyin to have a similar dynamic code-loading feature that was not present in TikTok. This feature raises three concerns:</p>
<ol type="1">
<li>If the process for downloading and loading the dynamic code does not sufficiently authenticate the downloaded code (e.g., that it is cryptographically signed with the correct public key, that it is not out of date, and that it is the code intended to be downloaded and not other cryptographically signed and up-to-date code), an attacker might be able to exploit this process to run malicious code on the device (e.g., by injecting arbitrary code, by performing a downgrade attack, or by performing a sidegrade attack). Back in 2016, we found such instances in <a href="https://citizenlab.ca/2016/02/privacy-security-issues-baidu-browser/"><u>other</u></a> <a href="https://citizenlab.ca/2016/03/privacy-security-issues-qq-browser/"><u>Chinese</u></a> <a href="https://citizenlab.ca/2016/08/a-tough-nut-to-crack-look-privacy-and-security-issues-with-uc-browser/"><u>apps</u></a>.</li>
<li>Even if the code downloading and loading mechanism contains no weaknesses, the dynamic code loading feature still allows the application to load code without notifying the user, bypassing users’ consent to decide what program could run on their device. For example, the developer may push out an unwanted update, and the users do not have a choice to keep using the old version. Furthermore, a developer may selectively target a user with an update that compromises their security or privacy. In 2016, a Chinese security analyst <a href="https://web.archive.org/web/20160330060941/news.boxun.com/news/gb/china/2016/02/201602231542.shtml" target="_blank" rel="noopener"><u>accused</u></a> Alibaba of pushing dynamically loaded code to Alipay to surreptitiously take photos and record audio on his device.</li>
<li>Dynamically loading code deprives app store reviewers from reviewing all relevant behavior of an app’s execution. As such, the <a href="https://support.google.com/googleplay/android-developer/answer/14906471?hl=en" target="_blank" rel="noopener"><u>Google Play Developer Program Policy</u></a> does not permit apps to use dynamic code loading.</li>
</ol>
<p>When analyzing the WeChat APK, we found that, while it retains some components of Tinker. The component which seems to handle the downloading of app updates is present, however the core part of Tinker that handles loading and executing the downloaded app updates has been replaced with “no-op” functions, which perform no actions. We did not analyze the WeChat binaries available from other third party app stores.</p>
<p>Further research is needed to analyze the security of Tinker’s app update process, whether WeChat APKs from other sources contain the dynamic code loading feature, as well as any further differences between the WeChat APK and Weixin APK.</p>
<h2 id="recommendations">Recommendations</h2>
<p>In this section, we make recommendations based on our findings to relevant audiences.</p>
<h3 id="to-application-developers">To application developers</h3>
<p>Implementing proprietary encryption is more expensive, less performant, and <a href="https://www.schneier.com/blog/archives/2011/04/schneiers_law.html" target="_blank" rel="noopener"><u>less secure</u></a> than using well-scrutinized standard encryption suites. Given the sensitive nature of data that can be sent by applications, we encourage application developers to use tried-and-true encryption suites and protocols and to avoid rolling their own crypto. SSL/TLS has seen almost three decades of various improvements as a result of rigorous public and academic scrutiny. TLS configuration is now easier than ever before, and the advent of QUIC-based TLS has dramatically improved performance.</p>
<h3 id="to-tencent-and-wechat-developers">To Tencent and WeChat developers</h3>
<p>Below is a copy of the recommendations we sent to WeChat and Tencent in our disclosure. The full disclosure correspondence can be found in the <a href="#appendix">Appendix</a>.</p>
<blockquote><p>In <a href="https://github.com/WeMobileDev/article/blob/master/%E5%9F%BA%E4%BA%8ETLS1.3%E7%9A%84%E5%BE%AE%E4%BF%A1%E5%AE%89%E5%85%A8%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AEmmtls%E4%BB%8B%E7%BB%8D.md" target="_blank" rel="noopener"><u>this post from 2016</u></a>, WeChat developers note that they wished to upgrade their encryption, but the addition of another round-trip for the TLS 1.2 handshake would significantly degrade WeChat network performance, as the application relies on many short bursts of communication. At that time, TLS 1.3 was not yet an RFC (though session resumption extensions were available for TLS 1.2), so they opted to “roll their own” and incorporate TLS 1.3’s session resumption model into MMTLS.</p>
<p>This issue of performing an extra round-trip for a handshake has been a perennial issue for application developers around the world. The TCP and TLS handshake each require a single round-trip, meaning each new data packet sent requires two round-trips. Today, TLS-over-QUIC combines the transport-layer and encryption-layer handshakes, requiring only a single handshake. QUIC was developed for this express purpose, and can provide both strong, forward-secret encryption, while halving the number of round-trips needed for secure communication. We also note that WeChat seems to already use QUIC for some large file downloads. <strong>Our recommendation would be for WeChat to migrate entirely to a standard TLS or QUIC+TLS implementation.</strong></p>
<p>There is also the issue of client-side performance, in addition to network performance. Since WeChat’s encryption scheme performs two layers of encryption per request, the client is performing double the work to encrypt data than if WeChat used a single standardized cryptosystem.</p></blockquote>
<h3 id="to-operating-systems">To operating systems</h3>
<p>On the web, client-side browser <a href="https://security.googleblog.com/2016/09/moving-towards-more-secure-web.html" target="_blank" rel="noopener"><u>security</u></a> <a href="https://blog.mozilla.org/security/2017/01/20/communicating-the-dangers-of-non-secure-http/" target="_blank" rel="noopener"><u>warnings</u></a> and the use of HTTPS as <a href="https://developers.google.com/search/blog/2014/08/https-as-ranking-signal" target="_blank" rel="noopener"><u>a ranking factor</u></a> in search engines contributed to widespread TLS adoption. We can draw loose analogies to the mobile ecosystem’s operating systems and application stores.</p>
<p>Is there any platform or OS-level permission model that can indicate regular usage of standard encrypted network communications? As we mentioned in our prior work studying proprietary cryptography in <a href="https://citizenlab.ca/2024/04/vulnerabilities-across-keyboard-apps-reveal-keystrokes-to-network-eavesdroppers/"><u>Chinese IME keyboards</u></a>, OS developers could consider device permission models that surface whether applications use lower-level system calls for network access.</p>
<h3 id="to-high-risk-users-with-privacy-concerns">To high-risk users with privacy concerns</h3>
<p>Many WeChat users use it out of necessity rather than choice. For users with privacy concerns who are using WeChat out of necessity, our recommendations from <a href="https://citizenlab.ca/2023/06/privacy-in-the-wechat-ecosystem-full-report/"><u>the previous report</u></a> still hold:</p>
<ul>
<li>Avoid features delineated as “Weixin” services if possible. We note that many core “Weixin” services (such as Search, Channels, Mini Programs) as delineated by the Privacy Policy perform more tracking than core “WeChat” services.</li>
<li>When possible, prefer web or applications over Mini Programs or other such embedded functionality.</li>
<li>Use stricter device permissions and update your software and OS regularly for security features.</li>
</ul>
<p>In addition, due to the risks introduced by dynamic code loading in WeChat downloaded from the official website, we recommend users to instead download WeChat from the Google Play Store whenever possible. For users who have already installed WeChat from the official website, removing and re-installing the Google Play Store version would also mitigate the risk.</p>
<h3 id="to-security-and-privacy-researchers">To security and privacy researchers</h3>
<p>As WeChat has over one billion users, we posit that the order of magnitude of global MMTLS users is on a similar order of magnitude as global TLS users. Despite this, there is little-to-no third-party analysis or scrutiny of MMTLS, as there is in TLS. At this scale of influence, MMTLS deserves similar scrutiny as TLS. We implore future security and privacy researchers to build on this work to continue the study of the MMTLS protocol, as from our correspondences, Tencent insists on continuing to use and develop MMTLS for WeChat connections.</p>
<h2><span>Acknowledgments</span></h2>
<p><span>We would like to thank Jedidiah Crandall, Jakub Dalek, Prateek Mittal, and Jonathan Mayer for their guidance and feedback on this report. Research for this project was supervised by Ron Deibert.</span></p>
<h2 id="appendix">Appendix</h2>
<p>In this appendix, we detail our disclosure to Tencent concerning our findings and their response.</p>
<h2 id="april-24-2024-our-disclosure">April 24, 2024 — Our disclosure</h2>
<p>To Whom It May Concern:</p>
<p>The Citizen Lab is an academic research group based at the Munk School of Global Affairs &amp; Public Policy at the University of Toronto in Toronto, Canada.</p>
<p>We analyzed WeChat v8.0.23 on Android and iOS as part of our ongoing work analyzing popular mobile and desktop apps for security and privacy issues. We found that WeChat’s proprietary network encryption protocol, MMTLS, contains weaknesses compared to modern network encryption protocols, such as TLS or QUIC+TLS. For instance, the protocol is not forward-secret and may be susceptible to replay attacks. We plan on publishing a documentation of the MMTLS network encryption protocol and strongly suggest that WeChat, which is responsible for the network security of over 1 billion users, switch to a strong and performant encryption protocol like TLS or QUIC+TLS.</p>
<p>For further details, please see the <a href="https://citizenlab.ca/wp-content/uploads/2024/10/CL-Disclosure-042424.docx"><strong>attached document</strong></a>.</p>
<p><strong>Timeline to Public Disclosure</strong></p>
<p>The Citizen Lab is committed to research transparency and will publish details regarding the security vulnerabilities it discovers in the context of its research activities, absent exceptional circumstances, on its website: https://citizenlab.ca/.</p>
<p>The Citizen Lab will publish the details of our analysis no sooner than 45 calendar days from the date of this communication.</p>
<p>Should you have any questions about our findings please let us know. We can be reached at this email address: <a href="https://citizenlab.ca/cdn-cgi/l/email-protection" data-cfemail="7e1a170d1d12110d0b0c1b3e1d170a121f1c500b0a110c11100a11501d1f">[email&nbsp;protected]</a>.</p>
<p>Sincerely,</p>
<p>The Citizen Lab</p>
<h2 id="may-17-2024-tencents-response">May 17, 2024 — Tencent’s response</h2>
<p>Thank you for your report.Since receiving your report on April 25th, 2024, we have conducted a careful evaluation.The core of WeChat’s security protocol is outer layer mmtls encryption, currently ensuring that outer layer mmtls encryption is secure. On the other hand, the encryption issues in the inner layer are handled as follows: the core data traffic has been switched to AES-GCM encryption, while other traffic is gradually switching from AES-CBC to AES-GCM.If you have any other questions, please let us know.thanks.</p>
<section id="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn1">The terms “shortlink” and “longlink” do not seem to be specific to WeChat, since it was also mentioned in <a href="http://www.52im.net/thread-3908-1-1.html" target="_blank" rel="noopener"><u>other technical blogs</u></a>.<a role="doc-backlink" href="#fnref1">↩︎</a></li>
<li id="fn2">On Android, the main process is named after the app ID, “com.tencent.mm”. (The process name can be seen using the ps command in adb shell.) When an app starts a new process, it assigns a name. The assigned name will be added to the app ID to form the full name of the new process. So the “:push” process’s full name is “com.tencent.mm:push”.<a role="doc-backlink" href="#fnref2">↩︎</a></li>
<li id="fn3">This server heartbeat is a reply to a prior client-sent heartbeat.<a role="doc-backlink" href="#fnref3">↩︎</a></li>
</ol>
</section>

                </section>
                                 
              </article> 
						
												

			</section>
		</main>
			 </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI PCs Aren't Good at AI: The CPU Beats the NPU (279 pts)]]></title>
            <link>https://github.com/usefulsensors/qc_npu_benchmark</link>
            <guid>41863061</guid>
            <pubDate>Wed, 16 Oct 2024 19:44:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/usefulsensors/qc_npu_benchmark">https://github.com/usefulsensors/qc_npu_benchmark</a>, See on <a href="https://news.ycombinator.com/item?id=41863061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet</h2><a id="user-content-benchmarking-qualcomms-npu-on-the-microsoft-surface-tablet" aria-label="Permalink: Benchmarking Qualcomm's NPU on the Microsoft Surface Tablet" href="#benchmarking-qualcomms-npu-on-the-microsoft-surface-tablet"></a></p>
<p dir="auto">TL;DR - We see 1.3% of Qualcomm's NPU 45 Teraops/s claim when benchmarking Windows AI PCs</p>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#installation">Installation</a>
<ul dir="auto">
<li><a href="#python">Python</a></li>
<li><a href="#cmake">Cmake</a></li>
<li><a href="#visual-studio">Visual Studio</a></li>
<li><a href="#pip-packages">Pip Packages</a></li>
</ul>
</li>
<li><a href="#benchmark">Benchmark</a>
<ul dir="auto">
<li><a href="#running">Running</a></li>
<li><a href="#understanding-the-output">Understanding the Output</a></li>
<li><a href="#what-the-benchmark-measures">What the Benchmark Measures</a></li>
<li><a href="#possible-confounding-factors">Possible Confounding Factors</a>
<ul dir="auto">
<li><a href="#compute-bound">Compute Bound</a></li>
<li><a href="#power-settings">Power Settings</a></li>
<li><a href="#model-topology">Model Topology</a></li>
<li><a href="#configuration-errors">Configuration Errors</a></li>
<li><a href="#onnx-framework">Onnx Framework</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#interpreting-the-results">Interpreting the Results</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto">Microsoft now offers Surface tablets that run Windows on a Qualcomm Arm-based
SoC. These are marketed as AI PCs, due to their ability to run machine learning
models faster and more efficiently than other systems. We are fans of
Qualcomm's hardware, and its NPU in particular, so we've invested a lot of time
and resources into porting our third-party app to this plaform.</p>
<p dir="auto">Unfortunately there  aren't many code examples or benchmarks available to
demonstrate how to achieve fast results as an external developer, so we've put
together a small standalone project to show the performance we're seeing. It's
significantly below what we'd hoped for, so we're publishing this benchmark to
see if we can get ideas on how to achieve lower latency. I'm hopeful there will
be software changes, either at the application, framework, or driver level,
that will improve these results in the future, since I've seen the underlying
hardware perform very effectively on other platforms like Android.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>
<p dir="auto">We're using Python to run our test scripts, and on Windows <a href="https://docs.python.org/3/using/windows.html" rel="nofollow">there are several ways to install the language</a>.
As of October 2nd, 2024, the Python available on the Microsoft Store doesn't
support the Arm architecture, and so it's not suitable for running the packages
we need to access Qualcomm's NPU. Instead, you should use <a href="https://www.python.org/downloads/" rel="nofollow">the official Python dot org installer</a>.
For the results reported here I used <a href="https://www.python.org/ftp/python/3.11.9/python-3.11.9-arm64.exe" rel="nofollow">version 3.11.9</a>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Cmake</h3><a id="user-content-cmake" aria-label="Permalink: Cmake" href="#cmake"></a></p>
<p dir="auto">We'll also need the cmake build tool to compile Onnx (since prebuilt packages
aren't yet available for Windows on Arm). To do this I ran the following
command from a Powershell:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Visual Studio</h3><a id="user-content-visual-studio" aria-label="Permalink: Visual Studio" href="#visual-studio"></a></p>
<p dir="auto">The build process also requires Visual Studio for the compiler. Download Visual
Studio Community Edition (not Code!) from <a href="https://visualstudio.microsoft.com/downloads/" rel="nofollow">visualstudio.microsoft.com/downloads/</a>.</p>
<p dir="auto">During the installation you will be prompted to select <code>Workload</code> from several options: select <code>Desktop C++ Development</code> checkbox then press install.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Pip Packages</h3><a id="user-content-pip-packages" aria-label="Permalink: Pip Packages" href="#pip-packages"></a></p>
<p dir="auto">You can install all the required Python packages by running the following
from within this folder:</p>
<div data-snippet-clipboard-copy-content="py -m pip install -r requirements.txt"><pre><code>py -m pip install -r requirements.txt
</code></pre></div>
<p dir="auto">This includes a couple of custom packages. The first is <a href="https://github.com/petewarden/onnx/tree/rel-1.16.2">my branch of Onnx</a>,
which has <a href="https://github.com/onnx/onnx/pull/6407" data-hovercard-type="pull_request" data-hovercard-url="/onnx/onnx/pull/6407/hovercard">a fix for compiling using the official <code>py</code> launcher</a>
backported to Onnx version 1.16, since the Qualcomm Onnx Runtime doesn't work
with newer Onnx versions (giving an <code>Unsupported model IR version</code> error).</p>
<p dir="auto">I also grab <a href="https://aiinfra.pkgs.visualstudio.com/2692857e-05ef-43b4-ba9c-ccf1c22c437c/_packaging/7982ae20-ed19-4a35-a362-a96ac99897b7/pypi/download/ort-nightly-qnn/1.20.dev20240928001/ort_nightly_qnn-1.20.0.dev20240928001-cp311-cp311-win_arm64.whl#sha256=3b12e3882d1afadf66c2349b2a167dfcbb9ae7a332dc98e0fd51c101d34ddf6e" rel="nofollow">a nightly build</a>
of <a href="https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html" rel="nofollow">Qualcomm's Onnx Runtime package</a>.
If you want to install a more recent version, there's <a href="https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/ORT-Nightly/pypi/simple/ort-nightly-qnn/" rel="nofollow">a list here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Benchmark</h2><a id="user-content-benchmark" aria-label="Permalink: Benchmark" href="#benchmark"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running</h3><a id="user-content-running" aria-label="Permalink: Running" href="#running"></a></p>
<p dir="auto">To execute the benchmark, run:</p>

<p dir="auto"><h3 tabindex="-1" dir="auto">Understanding the Output</h3><a id="user-content-understanding-the-output" aria-label="Permalink: Understanding the Output" href="#understanding-the-output"></a></p>
<p dir="auto">The Onnx runtime initially generates a lot of log spam, including:</p>
<div data-snippet-clipboard-copy-content="Error in cpuinfo: Unknown chip model name 'Snapdragon(R) X 12-core X1E80100 @ 3.40 GHz'.
Please add new Windows on Arm SoC/chip support to arm/windows/init.c!
unknown Qualcomm CPU part 0x1 ignored"><pre><code>Error in cpuinfo: Unknown chip model name 'Snapdragon(R) X 12-core X1E80100 @ 3.40 GHz'.
Please add new Windows on Arm SoC/chip support to arm/windows/init.c!
unknown Qualcomm CPU part 0x1 ignored
</code></pre></div>
<p dir="auto">and</p>
<div data-snippet-clipboard-copy-content="Starting stage: Finalizing Graph Sequence
Completed stage: Finalizing Graph Sequence (115919 us)
Starting stage: Completion
Completed stage: Completion (1025 us)"><pre><code>Starting stage: Finalizing Graph Sequence
Completed stage: Finalizing Graph Sequence (115919 us)
Starting stage: Completion
Completed stage: Completion (1025 us)
</code></pre></div>
<p dir="auto">After all those messages, you should see the actual benchmark
results at the end, something like this:</p>
<div dir="auto" data-snippet-clipboard-copy-content="************ Benchmark Results ************
NPU quantized compute, float I/O accuracy difference is 0.0100
NPU quantized compute and I/O accuracy difference is 0.0060
CPU took 8.42ms, 821,141,860,688 ops per second
NPU (quantized compute, float I/O) took 30.63ms, 225,667,671,183 ops per second
NPU (quantized compute and I/O) took 12.05ms, 573,475,650,364 ops per second"><pre><span>************</span> Benchmark Results <span>************</span>
NPU quantized compute, float I/O accuracy difference is 0.0100
NPU quantized compute and I/O accuracy difference is 0.0060
CPU took 8.42ms, 821,141,860,688 ops per second
NPU (quantized compute, float I/O) took 30.63ms, 225,667,671,183 ops per second
NPU (quantized compute and I/O) took 12.05ms, 573,475,650,364 ops per second</pre></div>
<p dir="auto">The first two lines confirm that the numerical results of the operations match
between the CPU and the NPU. The final three show the latency of the three
approaches to running a simple model. The latency is the wall time it took to
execute the model from start to finish, and the ops per second is calculated
from that latency to indicate the equivalent computational throughput.</p>
<p dir="auto">In this example, we see the CPU is capable of running 821 billion ops/second
(821 Gigaops), the first NPU approach gives us 225 Gigaops, and the second 573
Gigaops.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">What the Benchmark Measures</h3><a id="user-content-what-the-benchmark-measures" aria-label="Permalink: What the Benchmark Measures" href="#what-the-benchmark-measures"></a></p>
<p dir="auto">This benchmark is designed to resemble some real world models we depend on,
running 6 large matrix multiplications that are similar to the most
time-consuming layers in transformer models like OpenAI's Whisper. The shapes
are (6, 1500, 256) X (6, 256, 1500), producing a (6, 1500, 1500) result. The
model we running consists of a single MatMul node with two inputs and one
output.</p>
<p dir="auto">The models are created on the fly using the Onnx model framework, and then fed
into the Onnx runtime. The control model is a pure float version that runs
entirely on the CPU.</p>
<p dir="auto">The NPU mostly requires quantized models to run effectively (though it has
limited support for float16). The first approach we took to quantization used
<a href="https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html#static-quantization" rel="nofollow">the official ORT <code>quantize_static()</code> method</a>.
For convenience this leaves the input and output tensors in 32-bit float and
performs runtime conversions at the start and end of the graph so that the rest
of the computation happens in eight-bit.</p>
<p dir="auto">Unfortunately we discovered that the conversion operations as implemented on
the NPU were extremely slow, much slower than the main matrix multiplication
in fact. You can see the results in the <code>npu_quant_profile.csv</code> file in this
repository, with conversions taking over 75% of the time.</p>
<p dir="auto">To work around this, we constructed an equivalent model graph programmatically
with eight-bit inputs and outputs This is the second "quantized compute and
I/O" approach mentioned in the results. This is usually around three times
faster than the float I/O version, and profiling shows most of the time is
going on the matrix multiplication, as we'd hope.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Possible Confounding Factors</h3><a id="user-content-possible-confounding-factors" aria-label="Permalink: Possible Confounding Factors" href="#possible-confounding-factors"></a></p>
<p dir="auto">There are a lot of variables involved in measuring performance. Here are some
of the assumptions we've made:</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Compute Bound</h4><a id="user-content-compute-bound" aria-label="Permalink: Compute Bound" href="#compute-bound"></a></p>
<p dir="auto">Modern transformer models are based around large matrix multiplications, unlike
older convolutional models. One potential issue is that accelerators could
become memory bound if the layers start to resemble matrix times vectors, since
that doesn't allow reuse of many of the weights, and performance becomes bottle
necked on fetching values from DRAM. We've tried to avoid that by making both
the input matrices more square, so that tiling and reuse should be possible.</p>
<p dir="auto">The original matrices from the tiny Whisper model had a k dimension of only 64,
so in case that was too small we bumped it up to 256 in this benchmark to give
as much room for SIMD optimizations as possible.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Power Settings</h4><a id="user-content-power-settings" aria-label="Permalink: Power Settings" href="#power-settings"></a></p>
<p dir="auto">Windows has a lot of different configuration options around energy usage, so we
tried to ensure that all of the settings were on "Best Performance" and that we
ran the benchmark with the tablet connected to mains power. There's also a
session option on the Qualcomm Onnx Runtime, <code>htp_performance_mode</code>, that we
set to <code>sustained_high_performance</code>, since that seemed to give the lowest
overall latency in our experiments.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Model Topology</h4><a id="user-content-model-topology" aria-label="Permalink: Model Topology" href="#model-topology"></a></p>
<p dir="auto">We wanted to create a graph of operations that reflected modern AI models, but
was simple enough to easily interpret. We could have added multiple layers, or
used convolutions, or static weights, but settled for a single matrix
multiplication operation with dynamic inputs, since that reflected the
transformer architectures that are widely used for LLMs and other modern
models.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Configuration Errors</h4><a id="user-content-configuration-errors" aria-label="Permalink: Configuration Errors" href="#configuration-errors"></a></p>
<p dir="auto">It's possible that the way we build and run our models causes them to fall off
the fast path of the drivers or accelerator implementation. For example, we're
using unsigned eight-bit quantization, with qdq elements in the graph. We've
attempted to follow best practice from the documentation, but we'd welcome ways
to improve performance, especially since these would improve the performance of
our actual applications.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Onnx Framework</h4><a id="user-content-onnx-framework" aria-label="Permalink: Onnx Framework" href="#onnx-framework"></a></p>
<p dir="auto">There are multiple different ways to access AI acceleration on Windows. We
looked at DirectML, but it only seems to support GPU access. OpenVino doesn't
run on our Arm hardware, as far as we can tell. We've seen similar performance
results to those shown here using the <a href="https://www.qualcomm.com/developer/software/neural-processing-sdk-for-ai" rel="nofollow">Qualcomm QNN SDK</a>
directly. TensorFlow Lite isn't supported on Windows for Arm. From this
research and our experiments, Onnx is supported by both Microsoft and Qualcomm,
and seems to be the best framework to use to get accelerated performance from
the NPU, but we're interested in learning if other APIs would be more
appropriate.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Interpreting the Results</h2><a id="user-content-interpreting-the-results" aria-label="Permalink: Interpreting the Results" href="#interpreting-the-results"></a></p>
<p dir="auto">The results shown here are current as of October 2nd, 2024, when running on a
Microsoft Surface Pro 11th Edition, with a Snapdragon(R) X 12-core X1E80100
clocked at 3.40 GHz. The first obvious thing is that the NPU results, even
without float conversion, are slower than the CPU. This is not ideal for an
accelerator, even though it could still potentially offer energy or sustained
performance advantages that make it worth using.</p>
<p dir="auto">The second conclusion is that the measured performance of 573 billion
operations per second is only 1.3% of the 45 trillion ops/s that <a href="https://www.microsoft.com/en-us/surface/devices/surface-pro-11th-edition" rel="nofollow">the marketing material</a>
promises.</p>
<p dir="auto">By contrast, running the same model on an Nvidia Geforce RTX 4080 Laptop GPU
runs in 3.2ms, an equivalent of 2,160 billion operations per second, almost
four times the throughput.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[We outsmarted CSGO cheaters with IdentityLogger (158 pts)]]></title>
            <link>https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/</link>
            <guid>41862028</guid>
            <pubDate>Wed, 16 Oct 2024 18:18:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/">https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/</a>, See on <a href="https://news.ycombinator.com/item?id=41862028">Hacker News</a></p>
Couldn't get https://mobeigi.com/blog/gaming/how-we-outsmarted-csgo-cheaters-with-identitylogger/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Ireland's big school secret: how a year off-curriculum changes teenage lives (164 pts)]]></title>
            <link>https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum</link>
            <guid>41861628</guid>
            <pubDate>Wed, 16 Oct 2024 17:36:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum">https://www.theguardian.com/lifeandstyle/2024/oct/16/ireland-school-secret-transition-year-off-curriculum</a>, See on <a href="https://news.ycombinator.com/item?id=41861628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>‘I</span>f you know your Flann O’Brien, you’ll know that bike maintenance and philosophy go arse-on-saddle in this country,” Niall Hare, the 63-year-old headteacher at Kishoge community college in Dublin, told me. He was running through what his students do on their “transition year”, which is the missing fourth year (a year 11 in England, Wales, year 12 in Northern <a href="https://www.theguardian.com/world/ireland" data-link-name="in body link" data-component="auto-linked-tag">Ireland</a> or S4 in Scotland) of the Irish education system. Even the way it’s named has a magical, secret-compartment quality, like Platform 9 3/4 in Harry Potter, or the 7 1/2th floor in Being John Malkovich.</p><p>In Ireland, secondary school starts with the three-year junior cycle, beginning at age 12 or 13, and concluding with a Junior Certificate (roughly equivalent to a GCSE in England, Wales and Northern Ireland or Nationals in Scotland). Then you can either go straight into the two-year senior cycle to start preparing for the Leaving Certificate (roughly equivalent to A-levels or the International Baccalaureate), or you can have a transition year (TY) first – so you could think of it as a kind of gap year, halfway through secondary school.</p><p>There’s no curriculum for any part of TY, but core subjects – Irish, English, maths, PE – have to be covered in some form, for two hours a week. Work experience is recommended at two to four weeks a year; career guidance and social, personal and health education (SPHE) for an hour a week. Otherwise, schools decide for themselves what to do.</p><p>Hare canters through what’s going on in his TY for 2024-25: nine weeks each of Chinese, folklore and law; nine weeks of BodyRight, a consent, relationships and friendship workshop devised by Dublin Rape Crisis Centre. Then there’s everything from aviation to arts, coding to car maintenance, political engagement to boxing. There’s a young scientist programme, with two separate blocks of work experience. As part of a Stem module, two former police officers set up a crime scene and show kids how to run an investigation.</p><p>Even though you’re not graded, you do have to participate: Paul Mescal recalled being dragged into musicals on his TY at his Maynooth post-primary. He ended up being cast as the lead in their production of Phantom of the Opera. “I know for a fact I probably wouldn’t have auditioned because of the masculinity that I’d been prescribed by being on a sports team,” he later said. “But since we all <em>had</em> to audition, I was, like, ‘Well, I may as well put my best foot forward.’”</p><p>Cillian Murphy also became an actor during his TY, via a theatre workshop that not only fostered a passion for the stage but introduced him to the artistic director Pat Kiernan, who later cast him in his breakthrough production, Disco Pigs. “I remember loving it,” Murphy <a href="https://www.thesun.ie/tvandshowbiz/5020549/cillian-murphy-raising-kids-peaky-blinders/" data-link-name="in body link">later said</a>. “It felt like a real oasis between the junior cycle and the senior cycle.”</p><figure id="c93c3584-9e57-4a0a-a88a-a48bd4a5414d" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="A teacher and three students during a school’s anti-racism week" src="https://i.guim.co.uk/img/media/6800b05b8b0c2666a16dcc166ec09283d877a913/108_412_6005_3603/master/6005.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A teacher and students during anti-racism week.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>It’s not always the razzle-dazzle stuff that students talk about. Kacey, who is 17 and in her final senior year at Kishoge, is studying for her driving theory test. “I’m terrified of the road,” she says. “If I hop in a car, I’m crashing into a wall. But in the modules, seeing that it’s not so easy for everyone else – it’s a slow work-up, knowing how stuff works.” Stuff like: what do you put on a CV? How do you acclimatise your parents to the new reality that you’re a young adult? How do you use a bus timetable? How do you address a citizens’ assembly on the subject of drug abuse? How do you make a burrito? “TY says, ‘OK, you need to know this soon. Sit down, we’re going to teach it to you, we’re not just going to expect you to guess.’”</p><p>Transition year is either 50 years old this year, or 30, depending on whether you date it from the first pilot schools in 1974, or the national rollout in 1994. Now, 99% of schools offer TY programmes, and almost 80% of students choose it.</p><p>It was the brainchild of Richard Burke, a passionate internationalist who joined the Fine Gael party to deepen Ireland’s relationship with <a href="https://www.theguardian.com/world/europe-news" data-link-name="in body link" data-component="auto-linked-tag">Europe</a>, but arguably made his greatest impact with his maverick views on education and child development. “The original idea was to create a space for kids where they could take a year out, and appreciate some of the finer arts – classical music, great literature, that sort of thing,” says Burke’s son David, a barrister. Burke, who died in 2016, had grown up in rural Tipperary in a large, extremely poor family, fatherless as a result of the second world war. What he really wanted to close was the cultural gap between rich and poor – the fact that, as seriously as education has always been taken in Ireland, it had a grindstone quality, every moment maximised for some measurable self-improvement. Gerry Jeffers, a semi-retired researcher and lecturer who was a driving force in rolling out TY in the 90s, said the idea was to “take a break from the treadmill. A bit of the spirit of that lovely poem: ‘What is this life if, full of care, we have no time to stand and stare?’”</p><p>It started in three schools, in Dublin, Limerick and County Galway, and it was a little wild, to be honest. Sheelagh Hare, Niall’s sister who now lives in Australia, did her school’s pilot TY in 1978 and, she says, “We didn’t do anything like they do now. There was none of that zip-lining.” Instead, they did six UK O-levels, when they’d just come out of Junior Certification, so ended up with a bunch of random sort-of duplicated qualifications. “The teachers didn’t really know what to do with us. But I was quite young in my mindset, so I got a lot out of just having an extra year.”</p><p>That, emphatically, would not have been what Burke had in mind. And there would be elements of even the best of a modern transition year which he wouldn’t be thrilled about either, David says: “I think he’d be a little bit disappointed, although not terribly, by the fact that kids are using part of the year for work experience.” If the TY was initially conceived as a pause in the commodification of the human experience, the way it has evolved reveals a lot about our changing expectations of the market, what we’ve surrendered to it and what we still hope to preserve.</p><figure id="23ea7e47-80ff-42f6-ad21-feccc8df5445" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="An overhead shot of students at Kishoge community college" src="https://i.guim.co.uk/img/media/6df07b02e80cf6e95a440dac92583b92a78acefb/0_339_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Kishoge community college.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>The pilot scheme was enough of a success that the government put some money behind it in the 1990s – approximately £50 a student, Jeffers remembers – and it was expanded to almost every school, to considerable resistance from educators, who thought parents wouldn’t have it, which initially they didn’t. “Regularly on radio phone-ins in the 90s, people would say, ‘It’s a waste of time,’” says Jeffers. “My attitude was: let people have their say. If this thing is working, parents are soon going to phone in with the other side of the story. When they experienced it, they saw it as fantastic – they could see their youngsters growing and developing and maturing and gaining confidence.”</p><p>What comes up now on those phone-ins is still that it’s a “doss year”, plus objections to the fact that kids can be 19 before they finish school, so – in the memorable image of <a href="https://www.tiktok.com/@newstalkfm/video/7403284261609983265" data-link-name="in body link">one radio DJ</a> – “you see fellas with full beards now in sixth year”. “Every transition year is different,” Niall tells me, walking through the high-ceilinged corridors of his school, which opened in 2014. It’s anti-racism week, and downstairs, mid-morning, people are fixing up a pot luck lunch. Students have brought in the cuisine of their forebears. The place smells delicious. Hare says “it’s a myth that it’s a doss year”, in his experience, and “the second myth is that the kids lose the habit of study”.</p><p>After TY comes two years of the senior cycle culminating in the Leaving Cert, scored out of a maximum of 625 and highly deterministic of what university and course you can apply for (another way to string out your school career until you have a full beard is to retake that for a higher score). An <a href="https://www.esri.ie/publications/the-transition-year-programme-an-assessment" data-link-name="in body link">ESRI study</a>, albeit 20 years old, found that students who did a transition year got an average of 40 more points that those who went straight into the senior cycle, while repeating students only got an average of five more points.</p><p>The data is complicated by the fact that TY is meant to be an escape from “all the pressure on points, points, points”, Jeffers says, exasperated. “Transfer rates to tertiary institutions. What’s a good school? Is it how many of those people went off to Trinity, or did the students discover something about themselves?” (If we want to get “points, points, points” about it, though, Ireland performs far <a href="https://www.oecd.org/en/publications/pisa-2022-results-volume-i-and-ii-country-notes_ed6fbcc5-en/ireland_01173012-en.html" data-link-name="in body link">above the OECD average</a> in maths and science, and in literacy, it is second only to Singapore.)</p><p>Those discoveries students make about themselves are completely idiosyncratic. Scott, 17, went in to TY thinking he wanted to be a coder and came out wanting to study psychology. Jess, 17, says “before TY I was really nose-in-books, always English/theoretical based. I did the coding module, and as a result of that, I’ve ended up doing computer science.” Niamh, 18, discovered hiking is not as bad as it looks. Sive, 18, did a module on drug abuse and has since addressed a citizens’ assembly, and has spoken to the Irish finance minister “to increase the drug prevention budget and try to increase the personal budget”. Oh, also, “I’m changing a tyre, I’m cooking. There was one teacher, I didn’t peep a word in his class. After TY, now I’m in fifth year, I’ll sit in his room and eat my lunch.”</p><figure id="75681756-3111-484d-b754-5c5cd0cdca33" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=620&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=620&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=605&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=605&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=2&amp;s=none&amp;crop=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" media="(min-width: 320px)"><img alt="Learning cycling skills" src="https://i.guim.co.uk/img/media/cc9367750db22eb29a433d782b2af88125a79c43/0_0_6480_3888/master/6480.jpg?width=445&amp;dpr=1&amp;s=none&amp;crop=none" width="445" height="267" loading="lazy"></picture></div><figcaption data-spacefinder-role="inline"><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Learning cycling skills.</span> Photograph: Bríd O’Donovan/The Guardian</figcaption></figure><p>That is echoed in the teachers’ experience: they say TY deepens their relationships with students, and, freed from a curriculum, they can explore their own passions. Dale McCarthy, 37, says he emigrated to Ireland from England, having taught in Manchester and two large London comprehensives. “When I was in the UK, the class’s grades were mine. Now, they don’t feel like my results. They belong to an individual. I was blown away by that: ‘Oh right, the students are in charge of their own learning.’ As teachers, we’re trusted. The levels of bureaucracy are much lower. No one’s checking to see if I taught my lessons. If I was in the room, I taught it.” In London, he was burnt out and doubted he’d be teaching till he was 50; now, he says, he’s probably a lifer. Teaching has a much higher status in Ireland, and transition year both recognises and contributes to that.</p><p>Against all that positivity, though, transition year doesn’t happen in a bell jar. Kishoge is one of 118 “<a href="https://www.educatetogether.ie/" data-link-name="in body link">Educate Together</a>” schools in Ireland – part of a drive to break the stranglehold the Catholic church has had over education. Its founding values are that it’s democratically run, equality-based, learner-centred and co-educational, and it has special educational needs provision where kids with disabilities can dip in and out of mainstream education, including TY. “It’s not that complicated, to go between sensory needs support and horticulture,” Eve Brennan, the SEN coordinator, says.</p><p>Kishoge isn’t, in other words, necessarily representative of the wider social experience. <a href="https://www.oco.ie/app/uploads/2024/09/OCO-In-Focus-Fair-Access-to-Transition-Year-2.pdf" data-link-name="in body link">A report</a> this year by Ireland’s ombudsman for children registered “complaints about equitable access” and “inconsistencies in admission” to TY in schools around the country. Kids could be excluded for behavioural incidents that they had no idea would have major repercussions, for example (in one memorable case study, a boy was refused a place because he’d been bullied in third year).</p><p>Then there is the financial aspect of TY: some parents just can’t afford it. Although the government covers the baseline costs of the teachers, plus offering extra funding per student and grants that are means-tested, the cost to parents can be prohibitive, at anywhere between €100 and €900. The ombudsman has castigated this, saying all children have a right to participate, and calling for “a specific child’s rights framework with guiding principles on how schools should administer admission to this highly desirable and beneficial year in school”.</p><p>Mid-afternoon outside Kishoge, Michael Manners is showing the transition year class how to mend a bike puncture and cycle a roundabout. Their skills vary wildly, and make me think back to the first time I cycled a roundabout, which was a total guess. (I didn’t even know you gave way to the right; I thought the rule was “whoever’s the bravest”.) As much as the principle that all kids have a right to participate might shine an unflattering light on contextual inequalities, the scheme is still a good one. It’s great to find your calling during Phantom of the Opera. It’s also great if you know how to cycle a roundabout.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Optimizing the Ion compiler back end (109 pts)]]></title>
            <link>https://spidermonkey.dev/blog/2024/10/16/75x-faster-optimizing-the-ion-compiler-backend.html</link>
            <guid>41861442</guid>
            <pubDate>Wed, 16 Oct 2024 17:15:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spidermonkey.dev/blog/2024/10/16/75x-faster-optimizing-the-ion-compiler-backend.html">https://spidermonkey.dev/blog/2024/10/16/75x-faster-optimizing-the-ion-compiler-backend.html</a>, See on <a href="https://news.ycombinator.com/item?id=41861442">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
      <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In September, machine learning engineers at Mozilla filed <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1916442">a bug report</a> indicating that Firefox was consuming excessive memory and CPU resources while running Microsoft’s <a href="https://github.com/microsoft/onnxruntime">ONNX Runtime</a> (a machine learning library) compiled to WebAssembly.</p>

<p>This post describes how we addressed this and some of our longer-term plans for improving WebAssembly performance in the future.</p>

<h2 id="the-problem">The problem</h2>

<p>SpiderMonkey has two compilers for WebAssembly code. First, a Wasm module is compiled with the Wasm Baseline compiler, a compiler that generates decent machine code very quickly. This is good for startup time because we can start executing Wasm code almost immediately after downloading it. Andy Wingo wrote a nice <a href="https://wingolog.org/archives/2020/03/25/firefoxs-low-latency-webassembly-compiler">blog post</a> about this Baseline compiler.</p>

<p>When Baseline compilation is finished, we compile the Wasm module with our more advanced Ion compiler. This backend produces faster machine code, but compilation time is a lot higher.</p>

<p>The issue with the ONNX module was that the Ion compiler backend took a long time and used a lot of memory to compile it. On my Linux x64 machine, Ion-compiling this module took about 5 minutes and used more than 4 GB of memory. Even though this work happens on background threads, this was still too much overhead.</p>



<p>When we investigated this, we noticed that this Wasm module had some extremely large functions. For the largest one, Ion’s MIR control flow graph contained 132856 <a href="https://en.wikipedia.org/wiki/Basic_block">basic blocks</a>. This uncovered some performance cliffs in our compiler backend.</p>

<h3 id="virtualregister-live-ranges">VirtualRegister live ranges</h3>

<p>In Ion’s register allocator, each <code>VirtualRegister</code> has a list of <code>LiveRange</code> objects. We were using a linked list for this, sorted by start position. This caused quadratic behavior when allocating registers: the allocator often splits live ranges into smaller ranges and we’d have to iterate over the list for each new range to insert it at the correct position to keep the list sorted. This was very slow for virtual registers with thousands of live ranges.</p>

<p>To address this, I tried a few different data structures. The <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1916442#c17">first attempt</a> was to use an AVL tree instead of a linked list and that was a big improvement, but the performance was still not ideal and we were also worried about memory usage increasing even more.</p>

<p>After this we <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1918970">realized</a> we could store live ranges in a vector (instead of linked list) that’s optionally sorted by decreasing start position. We also <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1917817">made some changes</a> to ensure the initial live ranges are sorted when we create them, so that we could just append ranges to the end of the vector.</p>

<p>The observation here was that the core of the register allocator, where it assigns registers or stack slots to live ranges, doesn’t actually require the live ranges to be sorted. We therefore now just append new ranges to the end of the vector and mark the vector unsorted. Right before the final phase of the allocator, where we again rely on the live ranges being sorted, we do a single <code>std::sort</code> operation on the vector for each virtual register with unsorted live ranges. Debug assertions are used to ensure that functions that require the vector to be sorted are not called when it’s marked unsorted.</p>

<p>Vectors are also better for cache locality and they let us use binary search in a few places. When I was discussing this with Julian Seward, he pointed out that Chris Fallin also <a href="https://cfallin.org/blog/2022/06/09/cranelift-regalloc2/">moved away</a> from linked lists to vectors in Cranelift’s port of Ion’s register allocator. It’s always good to see convergent evolution :)</p>

<p>This change from sorted linked lists to optionally-sorted vectors made Ion compilation of this Wasm module about 20 times faster, down to 14 seconds.</p>

<h3 id="semi-nca">Semi-NCA</h3>

<p>The next problem that stood out in performance profiles was the Dominator Tree Building compiler pass, in particular a function called <code>ComputeImmediateDominators</code>. This function determines the <a href="https://en.wikipedia.org/wiki/Dominator_/(graph_theory/)">immediate dominator</a> block for each basic block in the MIR graph.</p>

<p>The algorithm we used for this (based on <em>A Simple, Fast Dominance Algorithm</em> by Cooper et al) is relatively simple but didn’t scale well to very large graphs.</p>

<p>Semi-NCA (from <em>Linear-Time Algorithms for Dominators and Related Problems</em> by Loukas Georgiadis) is a different algorithm that’s also used by LLVM and the Julia compiler. I prototyped this and was surprised to see how much faster it was: it got our total compilation time down from 14 seconds to less than 8 seconds. For a single-threaded compilation, it reduced the time under <code>ComputeImmediateDominators</code> from 7.1 seconds to 0.15 seconds.</p>

<p>Fortunately it was easy to run both algorithms in debug builds and assert they computed the same immediate dominator for each basic block. After a week of fuzz-testing, no problems were found and we <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1919025">landed a patch</a> that removed the old implementation and enabled the <a href="https://searchfox.org/mozilla-central/rev/d56687458d4e6e8882c4b740e78413a0f0a69d59/js/src/jit/DominatorTree.cpp#19">Semi-NCA code</a>.</p>

<h3 id="sparse-bitsets">Sparse BitSets</h3>

<p>For each basic block, the register allocator allocated a (dense) <a href="https://en.wikipedia.org/wiki/Bit_array">bit set</a> with a bit for each virtual register. These bit sets are used to check which virtual registers are live at the start of a block.</p>

<p>For the largest function in the ONNX Wasm module, this used a lot of memory: 199477 virtual registers x 132856 basic blocks is at least 3.1 GB just for these bit sets! Because most virtual registers have short live ranges, these bit sets had relatively few bits set to 1.</p>

<p>We <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1920430">replaced</a> these dense bit sets with a new <a href="https://searchfox.org/mozilla-central/source/js/src/jit/SparseBitSet.h"><code>SparseBitSet</code></a> data structure that uses a hashmap to store 32 bits per entry. Because most of these hashmaps contain a small number of entries, it uses an <code>InlineMap</code> to optimize for this: it’s a data structure that stores entries either in a small inline array or (when the array is full) in a hashmap. We also <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1920433">optimized</a> <code>InlineMap</code> to use a variant (a union type) for these two representations to save memory.</p>

<p>This saved at least 3 GB of memory but also improved the compilation time for the Wasm module to 5.4 seconds.</p>

<h3 id="faster-move-resolution">Faster move resolution</h3>

<p>The last issue that showed up in profiles was a function in the register allocator called <code>createMoveGroupsFromLiveRangeTransitions</code>. After the register allocator assigns a register or stack slot to each live range, this function is responsible for connecting pairs of live ranges by inserting <em>moves</em>.</p>

<p>For example, if a value is stored in a register but is later spilled to memory, there will be two live ranges for its virtual register. This function then inserts a move instruction to copy the value from the register to the stack slot at the start of the second live range.</p>

<p>This function was slow because it had a number of loops with quadratic behavior: for a move’s destination range, it would do a linear lookup to find the best source range. We <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1920951">optimized</a> the main two loops to run in linear time instead of being quadratic, by taking more advantage of the fact that live ranges are sorted.</p>

<p>With these changes, Ion can compile the ONNX Wasm module in less than 3.9 seconds on my machine, more than 75x faster than before these changes.</p>

<h2 id="adobe-photoshop">Adobe Photoshop</h2>

<p>These changes not only improved performance for the ONNX Runtime module, but also for a number of other WebAssembly modules. A large Wasm module downloaded from the free online <a href="https://photoshop.adobe.com/discover">Adobe Photoshop demo</a> can now be Ion-compiled in 14 seconds instead of 4 minutes.</p>

<p>The JetStream 2 benchmark has a HashSet module that was <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1918970#c14">affected</a> by the quadratic move resolution code. Ion compilation time for it improved from 2.8 seconds to 0.2 seconds.</p>

<h2 id="new-wasm-compilation-pipeline">New Wasm compilation pipeline</h2>

<p>Even though these are great improvements, spending at least 14 seconds (on a fast machine!) to fully compile Adobe Photoshop on background threads still isn’t an <em>amazing</em> user experience. We expect this to only get worse as more large applications are compiled to WebAssembly.</p>

<p>To address this, our WebAssembly team is making great progress rearchitecting the Wasm compiler pipeline. This work will make it possible to Ion-compile individual Wasm functions as they warm up instead of compiling everything immediately. It will also unlock exciting new capabilities such as (speculative) inlining.</p>

<p>Stay tuned for updates on this as we start rolling out these changes in Firefox.</p>

<p>- Jan de Mooij, engineer on the SpiderMonkey team</p>


  </div>

  
</article>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Winamp deletes entire GitHub source code repo after a rocky few weeks (327 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/</link>
            <guid>41861056</guid>
            <pubDate>Wed, 16 Oct 2024 16:34:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/">https://arstechnica.com/gadgets/2024/10/winamp-really-whips-open-source-coders-into-frenzy-with-its-source-release/</a>, See on <a href="https://news.ycombinator.com/item?id=41861056">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>Winamp, through its Belgian owner Llama Group, posted the source for its "Legacy Player Code" on September 24 so that developers could "contribute their expertise, ideas, and passion to help this iconic software evolve."</p>
<p>Less than a month later, that <a href="https://github.com/WinampDesktop">repository has been entirely deleted</a>, after it either bumped up against or broke its strange hodgepodge of code licenses, seemingly revealed the source code for other non-open software packages, and made a pretty bad impression on the open-source community.</p>
<h2>"Collaborative" licensing</h2>
<p>Winamp's code was made available in late September, but not very open. Under the "<a href="https://github.com/WinampDesktop/winamp?tab=License-1-ov-file#readme">Winamp Collaborative License (WCL) Version 1.0.1</a>," you may not "distribute modified versions of the software" in source or binary, and "only the maintainers of the official repository are allowed to distribute the software and its modifications." Anyone may contribute, in other words, but only to Winamp's benefit.</p>
<p>Justin Frankel, a key developer of the original Winamp and founder of Nullsoft, which also made SHOUTcast streaming software, was <a href="https://www.askjf.com/index.php?q=7357s">asked on his Q&amp;A site</a> about contributing to the code. Frankel responded that, even if he had some desire, the license terms "are completely absurd in the way they are written." Even taking them "as they are likely intended," Frankel wrote, "they are terrible. No thank you."</p>
<p>Despite how this license would seem to bar forks, or perhaps <em>because</em> of that, the code has been <a href="https://github.com/WinampDesktop/winamp/forks">forked at least 2,600 times as of this writing</a>. In forking and examining the source when first released, coders have noticed some, shall we say, anomalies:</p>
<ul>
<li>Large portions of <a href="https://github.com/WinampDesktop/winamp/issues/265">other projects' code</a>, offered under other, more robust licenses, were seemingly included (<a href="https://github.com/WinampDesktop/winamp/commit/e721b2e039742c12c1f9c93b1b779ca3b7fc061e">if later deleted</a>) from Winamp's repository</li>
<li>The original Winamp code may have <a href="https://github.com/WinampDesktop/winamp/issues/11">leaked the source code for SHOUTcast server software</a></li>
<li>In seeking to remove offending files with a simple deletion instead of a rebase, <a href="https://github.com/WinampDesktop/winamp/issues/11#issuecomment-2371838502">Winamp kept it available</a> to those who know Git mechanics</li>
<li>Proprietary packages from Intel and Microsoft were also seemingly <a href="https://github.com/WinampDesktop/winamp/pull/1378">included</a> in the release's build tools</li>
</ul>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ArchiveBox is evolving: the future of self-hosted internet archives (471 pts)]]></title>
            <link>https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement</link>
            <guid>41860909</guid>
            <pubDate>Wed, 16 Oct 2024 16:18:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement">https://docs.sweeting.me/s/archivebox-plugin-ecosystem-announcement</a>, See on <a href="https://news.ycombinator.com/item?id=41860909">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <div id="doc">

&lt;center&gt;

&lt;img src="https://docs.monadical.com/uploads/213b6618-e133-4b6b-a74a-267de68606aa.png" style="width: 140px"&gt;

    
# Big changes are coming to ArchiveBox!

*New features coming to the future of self-hosting internet archives: a full plugin ecosystem, P2P sharing between instances, Cloudflare/CAPTCHA solving, auto-logins, and more...*.
    

&lt;/center&gt;
&lt;hr/&gt;

In the wake of the [recent attack](https://www.theverge.com/2024/10/9/24266419/internet-archive-ddos-attack-pop-up-message) against Archive.org, [ArchiveBox](https://archivebox.io) has been getting some increased attention from people wondering how to **self-host their own internet archives**.

![](https://docs.monadical.com/uploads/23a752d2-2a25-4e9b-98e9-81ee6fd94601.png)


ArchiveBox is a strong supporter of Archive.org and their mission to preserve all of human knowledge. We've been donating for years, and we urge you to do the same, they provide an invaluable service for all of humanity. 

We completely condemn the DDoS and defacement of their site, and hope it never happens again. Realistically though, they are an attractive target for people who want to supress information or [start IP lawsuits](https://blog.archive.org/2024/07/01/what-happened-last-friday-in-hachette-v-internet-archive/), and this may not be the last time this happens...

&lt;br/&gt;

![](https://docs.monadical.com/uploads/0fe1c7e3-0788-4cfc-a23e-b1ff02321a7c.png)

&lt;br/&gt;

&gt; We envision a future where the world has both a robust centralized archive through Archive.org, and a widespread network of decentralized ArchiveBox.io instances.

&lt;center&gt;
&lt;a href="https://github.com/ArchiveBox/ArchiveBox"&gt;&lt;img src="https://docs.monadical.com/uploads/bac22f63-0fc9-4634-8fb8-67d29806e49c.png" style="max-width: 380px; border: 4px #915656 solid; border-radius: 15px; box-shadow: 4px 4px 4px rgba(0,0,0,0.09)"/&gt;&lt;/a&gt;
&lt;/center&gt;

&lt;br/&gt;

![](https://docs.monadical.com/uploads/96dbfd23-5592-4ea2-b9a0-5b379da564bf.png)


&lt;br/&gt;

### The Limits of Public Archives

In an era where fear of public scrutiny is very tangible, people are afraid of archiving things for eternity. As a result, people choose not to archive at all, effectively erasing that history forever.

We think people should have the power to archive what *matters to them*, on an individual basis. We also think people should be able to *share* these archives with only the people they want.

The modern web is a different beast than it was in the 90's and people don't necessarily want everything to be public anymore. Internet archiving tooling should keep up with the times and provide solutions to archive private and semi-private content in this changing landscape.

---

#### Who cares about saving stuff?

All of us have content that we care about, that we want to see preserved, but privately:

- families might want to preserve their photo albums off Facebook, Flickr, Instagram
- individuals might want to save their bookmarks, social feeds, or chats from Signal/Discord
- companies might want to save their internal documents, old sites, competitor analyses, etc.

&lt;sub&gt;*Archiving private content like this [has some inherent security challenges](https://news.ycombinator.com/item?id=41861455), and should be done with care.&lt;br/&gt;(e.g. how do you prevent the cookies used to access the content from being leaked in the archive snapshots?)*&lt;/sub&gt;

---

#### What if the content is evil?

There is also content that unfairly benefits from the existence of free public archives like Archive.org, because they act as a mirror/amplifier when original sites get taken down.

There is value in preserving racism, violence, and hate speech for litigation and historical record, but is there a way we can do it without effectively providing free *public* hosting for it?

![](https://docs.monadical.com/uploads/6eb36b1d-7a0f-4ffe-8d4d-20a74683ee04.png)

---

&lt;br/&gt;

&lt;center&gt;

## ✨ Introducing ArchiveBox's New Plugin Ecosystem ✨
    
&lt;/center&gt;

&lt;br/&gt;

[ArchiveBox v0.8](https://github.com/ArchiveBox/ArchiveBox/releases) is shaping up to be the [**biggest release in the project's history**](https://github.com/ArchiveBox/ArchiveBox/pull/1311). We've completely re-architected the internals for speed and performance, and we've opened up access to allow for a new plugin ecosystem to provide community-supported features.

![](https://docs.monadical.com/uploads/e2ae70b1-2c9c-42b7-a2ca-a0a2b1bd1ae1.png)


We want to follow in the footsteps of great projects like [NextCloud](https://apps.nextcloud.com/) and [Home Assistant](https://www.home-assistant.io/addons/), and provide a robust "app store" for functionality around bookmark management, web scraping, capture, and sharing.

#### 🧩 Here's just a taste of some of the first plugins that will be provided:

- `yt-dlp` for video, audio, subtitles, from Youtube, Soundcloud, YouKu, and more...
- `papers-dl` for automatic download of scientific paper PDFs when DOI numbers are seen
- `gallery-dl` to download photo galleries from Flickr, Instagram, and more
- `forum-dl` for download of older forums and deeply nested comment threads
- `readability` for article text extraction to .txt, .md, .epub
- **`ai`** to send page screenshot + text w/ a custom prompt to an LLM + save the response
- **`webhooks`** trigger any external API, ping Slack, N8N, etc. whenever some results are saved
- and [many more...](https://github.com/ArchiveBox/ArchiveBox/tree/dev/archivebox/plugins_extractor)

If you're curious, the plugin system is based on the excellent, well-established libraries [pluggy](https://pluggy.readthedocs.io/en/stable/index.html) and [pydantic](https://pydantic-docs.helpmanual.io/). It was a fun challenge to develop a plugin system without over-engineering it, and it took a few iterations to get right!

&gt; I'm excited for the future this will bring! It will allow us to keep the **core** lean and high-quality while getting community help supporting a **wide periphery** of plugins.

&lt;br/&gt;

#### ✨ Other things in the  works:

- There is an all-new [`REST API`](https://demo.archivebox.io/api) built with `django-ninja`, already [available in BETA](https://github.com/ArchiveBox/ArchiveBox/releases)
- [Support for external storage](https://github.com/ArchiveBox/ArchiveBox/wiki/Setting-Up-Storage) (AWS/B2/GCP/Google Drive/etc.) (via `rclone`) was added
- We've started adding the beginnings of a content-addressable store system with unique "ABID"s (identifiers based on URL + timestamp) that can be shared between instances. This will help us build BitTorrent/IPFS-backed P2P sharing between instances in the future.
- We've added a background job system using [`huey`](https://huey.readthedocs.io/)
- new auto-install system `archivebox install` (no more complex `apt` dependencies)
  *(plugin's cross-platform runtime dependencies are very hard to package and maintain, check out our new [`pydantic-pkgr`](https://github.com/ArchiveBox/pydantic-pkgr) library that solves this and use it in your projects!)*

&gt; ArchiveBox is designed to be local-first with [**SQLite**](https://www.sqlite.org/famous.html), P2P will always be optional.

&lt;br/&gt;


#### 🔢 For the minimalists who just want something simple:

If you're an existing ArchiveBox user and feel like this is more than you need, don't worry, we're also releasing a new tool called `abx-dl` that will work like like `yt-dlp` or `gallery-dl`.

It will provide a one-shot CLI to quickly download *all* the content on any URL you provide it without having to worry about complex configuration, plugins, setting up a collection, etc.

&lt;br/&gt;

---

&lt;br/&gt;

### 🚀 Try out the new BETA now!

```bash
pip install archivebox==0.8.5rc44
archivebox install
# or
docker pull archivebox/archivebox:dev
```
📖 *Read the release notes for the new BETAs on our [Releases](https://github.com/ArchiveBox/ArchiveBox/releases) page on Github.*

💬 *[Join the discussion on HN](https://news.ycombinator.com/item?id=41860909) or over on our [Zulip forum](https://zulip.archivebox.io/).*

💁‍♂️ *Or [hire us](https://github.com/ArchiveBox/archivebox#-professional-integration) to provide digital preservation for your org (we provide CAPTCHA/Cloudflare bypass, popup/ad hiding, on-prem/cloud, SAML/SSO integration, audit logging, and more).*


&lt;br/&gt;&lt;br/&gt;

&lt;img src="https://docs.monadical.com/uploads/a790d511-db5c-49ae-a3d9-db41e4100f20.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/4233a584-3903-4610-9016-06d1b59ac682.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/63a73bfc-f028-40c4-885c-ad011c7e191a.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/e621d80f-87d4-4ade-8fb9-9e0e6ab42a7f.png" style="width: 19.9%"/&gt;&lt;img src="https://docs.monadical.com/uploads/26285bd6-f240-41e3-99b7-70d50463e3b7.png" style="width: 19.9%"/&gt;

&lt;center&gt;

[Donate to ArchiveBox](https://hcb.hackclub.com/donations/start/archivebox) &lt;sup&gt;(tax-deductible!)&lt;/sup&gt; to support our open-source development.&lt;br/&gt;&lt;br/&gt;Remember to also donate to [Archive.org](https://help.archive.org/help/how-do-i-donate-to-the-internet-archive/) &lt;sup&gt;(not affiliated)&lt;/sup&gt; to help them with the attack!

&lt;/center&gt;</div>
    
    
    










</div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's not enough for a program to work – it has to work for the right reasons (110 pts)]]></title>
            <link>https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/</link>
            <guid>41860135</guid>
            <pubDate>Wed, 16 Oct 2024 15:20:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/">https://buttondown.com/hillelwayne/archive/be-suspicious-of-success/</a>, See on <a href="https://news.ycombinator.com/item?id=41860135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                
                    <date>
                        
                            October 16, 2024
                        </date>
                
                
                
                    <h2>
                        Successful software is buggy software.
                    </h2>
                

                

                
                    
                        <p>From Leslie Lamport's <em>Specifying Systems</em>:</p>
<blockquote>
<p>You should be suspicious if [the model checker] does not find a violation of a liveness property... you should also be suspicious if [it] finds no errors when checking safety properties. </p>
</blockquote>
<p>This is specifically in the context of model-checking a formal specification, but it's a widely applicable software principle. It's not enough for a program to work, it has to work for the <em>right reasons</em>. Code working for the wrong reasons is code that's going to break when you least expect it. And since "correct for right reasons" is a much narrower target than "correct for any possible reason", we can't assume our first success is actually our intended success.</p>
<p>Hence, BSOS: <strong>Be Suspicious of Success</strong>.</p>
<h3>Some useful BSOS practices</h3>
<p>The standard way of dealing with BSOS is verification. Tests, static checks, model checking, etc. We get more confident in our code if our verifications succeed. But then we also have to be suspicious of <em>that</em> success, too! How do I know whether my tests are passing because they're properly testing correct code or because they're failing to test incorrect code?</p>
<p>This is why test-driven development gurus tell people to write a failing test first. Then at least we know the tests are doing <em>something</em> (even if they still might not be testing what they want).</p>
<p>The other limit of verification is that it can't tell us <em>why</em> something succeeds. Mainstream verification methods are good at explaining why things <em>fail</em>— expected vs actual test output, type mismatches, specification error traces. Success isn't as "information-rich" as failure. How do you distinguish a faithful implementation of <a href="https://en.wikipedia.org/wiki/Collatz_conjecture" target="_blank"><code>is_collatz_counterexample</code></a> from <code>return false</code>?</p>
<p>A broader technique I follow is <em>make it work, make it break</em>. If code is working for the right reasons, I should be able to predict how to break it. This can be either a change in the runtime (this will livelock if we 10x the number of connections), or a change to the code itself (commenting out <em>this</em> line will cause property X to fail). <sup id="fnref:superproperties"><a href="#fn:superproperties">1</a></sup> If the code still works even after the change, my model of the code is wrong and it was succeeding for the wrong reasons.</p>
<h3>Happy and Sad Paths</h3>

<p>A related topic (possibly subset?) is "happy and sad paths". The happy path of your code is the behavior when everything's going right: correct inputs, preconditions are satisfied, the data sources are present, etc. The sad path is all of the code that handles things going wrong. Retry mechanisms, insufficient user authority, database constraint violation, etc. In most software, the code supporting the sad paths dwarfs the code in the happy path.</p>
<p>BSOS says that I can't just show code works in the happy path, I also need to check it works in the sad path. </p>
<p>BSOS also says that I have to be suspicious when the sad path works properly, too. </p>
<p>Say I add a retry mechanism to my code to handle the failure mode of timeouts. I test the code and it works. Did the retry code actually <em>run</em>? Did it run <em>regardless</em> of the original response? Is it really doing exponential backoff? Will stop after the maximum retry limit? Is the sad path code <em>after</em> the maximum retry limit working properly?</p>
<p><a href="https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf" target="_blank">One paper</a> found that 35% of catastrophic distributed system failures were caused by "trivial mistakes in error handlers" (pg 9). These were in mature, battle-hardened programs. Be suspicious of success. Be more suspicious of sad path success.</p>
<hr>
<h2>Blog Rec</h2>
<p>This week's blog rec is <a href="https://www.redblobgames.com/" target="_blank">Red Blob Games</a>!<sup id="fnref:blogs-vs-articles"><a href="#fn:blogs-vs-articles">2</a></sup> While primarily about computer game programming, the meat of the content is beautiful, interactive guides to general CS algorithms. Some highlights:</p>
<ul>
<li><a href="https://www.redblobgames.com/pathfinding/a-star/introduction.html" target="_blank">Introduction to the A* Algorithm</a> was really illuminating when I was a baby programmer.</li>
<li>I'm sure this <a href="https://www.redblobgames.com/articles/noise/introduction.html" target="_blank">overview of noise functions</a> will be useful to me <em>someday</em>. Maybe for test data generation?</li>
<li>If you're also an explainer type he has a lot of great stuff on <a href="https://www.redblobgames.com/making-of/line-drawing/" target="_blank">his process</a> and his <a href="https://www.redblobgames.com/making-of/little-things/" target="_blank">little tricks</a> to make things more understandable.</li>
</ul>
<p>(I don't think his <a href="https://www.redblobgames.com/blog/posts.xml" target="_blank">rss feed</a> covers new interactive articles, only the <a href="https://www.redblobgames.com/blog/" target="_blank">blog</a> specifically.)</p>

                    
                

                
                    <p><em>If you're reading this on the web, you can subscribe <a href="https://buttondown.com/hillelwayne" target="_blank">here</a>. Updates are once a week. My main website is <a href="https://www.hillelwayne.com/" target="_blank">here</a>.</em></p>
<p><em>My new book, </em>Logic for Programmers<em>, is now in early access! Get it <a href="https://leanpub.com/logic/" target="_blank">here</a>.</em></p>
                

            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Efficient high-resolution image synthesis with linear diffusion transformer (150 pts)]]></title>
            <link>https://nvlabs.github.io/Sana/</link>
            <guid>41859805</guid>
            <pubDate>Wed, 16 Oct 2024 14:56:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nvlabs.github.io/Sana/">https://nvlabs.github.io/Sana/</a>, See on <a href="https://news.ycombinator.com/item?id=41859805">Hacker News</a></p>
<div id="readability-page-1" class="page">
<!--    <div style="overflow: hidden; background-color: #6699cc;">-->
<!--      <div class="container">-->
<!--        <a href="https://www.nvidia.com/" style="float: left; color: black; text-align: center; padding: 12px 16px; text-decoration: none; font-size: 16px;"><img width="100%" src="https://nv-tlabs.github.io/3DStyleNet/assets/nvidia.svg"></a>-->
<!--        <a href="https://github.com/Efficient-Large-Model/" style="float: left; color: black; text-align: center; padding: 14px 16px; text-decoration: none; font-size: 16px;"><strong>Efficient AI Group</strong></a>-->
<!--      </div>-->
<!--    </div>-->
    <div>
        <div>
            <p><img src="https://nvlabs.github.io/Sana/asset/logo.jpg" alt="Logo"></p>
        </div>
        <h2>Efficient High-Resolution Image Synthesis <br>
            with Linear Diffusion Transformer</h2>
        <p>Exploring the Frontiers of Efficient Generative Foundation Models</p>

        <!-- Add author and institution information -->
        <div>
            <p>
                <a href="https://xieenze.github.io/" target="_blank">Enze Xie</a><sup>1*</sup>,
                <a href="https://lawrence-cj.github.io/" target="_blank">Junsong Chen</a><sup>1*</sup>,
                <a href="https://scholar.google.com.hk/citations?hl=zh-CN&amp;user=mWdYMZ8AAAAJ" target="_blank">Junyu Chen</a><sup>2,3</sup>,
                <a href="https://han-cai.github.io//" target="_blank">Han Cai</a><sup>1</sup>,
                <a href="http://kentang.net/" target="_blank">Haotian Tang</a><sup>2</sup>,<br>
                <a href="https://yujunlin.com//" target="_blank">Yujun Lin</a><sup>2</sup>,
                <a href="https://hanlab.mit.edu/team/zhekai-zhang/" target="_blank">Zhekai Zhang</a><sup>2</sup>,
                <a href="https://lmxyy.me//" target="_blank">Muyang Li</a><sup>2</sup>,
                <a href="https://lzhu.me//" target="_blank">Ligeng Zhu</a><sup>1</sup>,
                <a href="https://scholar.google.com/citations?user=OI7zFmwAAAAJ&amp;hl=en/" target="_blank">Yao Lu</a><sup>1</sup>,
                <a href="https://hanlab.mit.edu/songhan/" target="_blank">Song Han</a><sup>1,2</sup>
            </p>
            <p>
                <sup>1</sup>NVIDIA, <sup>2</sup>MIT, <sup>3</sup>Tsinghua University
                <br>
                *Project co-lead
            </p>
        </div>
<!--        <div style="overflow: hidden; background-color: #6699cc;">-->
        

        <p><a href="https://arxiv.org/abs/2410.10629">Paper</a>
        <a href="https://github.com/NVlabs/Sana">Code (Coming soon)</a>
    </p></div>

    

    <!-- The Modal -->
    <div id="modal" onclick="this.style.display='none'">
      <p><img id="modal-img" src=""></p> <!-- Text for description -->
    </div>

    <section>
        <div>
          <h2>About Sana</h2>
          <p>We introduce Sana, a text-to-image framework that can efficiently generate images up to 4096 × 4096 resolution.
                    Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed,
                    deployable on laptop GPU. Core designs include:
                    <strong>Deep compression autoencoder: </strong> unlike traditional AEs, which compress images only 8×,
                        we trained an AE that can compress images 32×, effectively reducing the number of latent tokens.
                    <strong>Linear DiT: </strong> we replace all vanilla attention in DiT with linear attention, which is more efficient at high resolutions without sacrificing quality.
                    <strong>Decoder-only text encoder: </strong> we replaced T5 with modern decoder-only small LLM as the text encoder and designed
                        complex human instruction with in-context learning to enhance the image-text alignment.
                    <strong>Efficient training and sampling: </strong> we propose Flow-DPM-Solver to reduce sampling steps,
                        with efficient caption labeling and selection to accelerate convergence.<br>
                    As a result, Sana-0.6B is very competitive with modern giant diffusion model (e.g. Flux-12B),
                    being 20 times smaller and 100+ times faster in measured throughput.
                    Moreover, Sana-0.6B can be deployed on a 16GB laptop GPU, taking less than 1 second to generate a 1024 × 1024 resolution image.
                    Sana enables content creation at low cost.</p>
        </div>

        <!-- Insert your image here -->
        <p><img src="https://nvlabs.github.io/Sana/asset/content/latency_compare.jpg" alt="latency comparison with SOTA methods">

        </p>

        <div>
          <h2>Several Core Design Details for Efficiency</h2>
          <p>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp;  <strong>Deep Compression Autoencoder: </strong>
              We introduce a new Autoencoder (AE) that aggressively increases the scaling factor to 32.
              Compared with AE-F8, our AE-F32 outputs 16× fewer latent tokens, which is crucial for efficient training
              and generating ultra-high-resolution images, such as 4K resolution.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Efficient Linear DiT: </strong>
              We introduce a new linear DiT, replacing vanilla quadratic attention and reducing complexity from O(N<span><sup>2</sup></span>) to O(N)
              Mix-FFN, with 3×3 depth-wise convolution in MLP, enhances the local information of tokens.
              Linear attention achieves comparable results to vanilla, improving 4K generation by 1.7× in latency.
              Mix-FFN also removes the need for positional encoding (NoPE) without quality loss, marking the first DiT without positional embedding.<br>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Decoder-only Small LLM as Text Encoder: </strong>
              We use Gemma, a decoder-only LLM, as the text encoder to enhance understanding and reasoning in prompts.
              Unlike CLIP or T5, Gemma offers superior text comprehension and instruction-following.
              We address training instability and design complex human instructions (CHI) to leverage Gemma’s in-context learning,
              improving image-text alignment.<br>
          </p>
        </div>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/model-incremental.jpg" alt="pipeline for Sana">
        </p>

        <p>
              &nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;&nbsp; <strong>Efficient Training and Inference Strategy: </strong>
              We propose automatic labeling and training strategies to improve text-image consistency.
              Multiple VLMs generate diverse re-captions, and a CLIPScore-based strategy selects high-CLIPScore captions to enhance convergence and alignment.
              Additionally, our <strong>Flow-DPM-Solver</strong> reduces inference steps from 28-50 to 14-20 compared to the Flow-Euler-Solver, with better performance.
            </p>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/sampler.jpg" alt="flow-dpms vs flow-euler">
        </p>

        <div>
          <h2>Overall Performance</h2>
            <p>We compare Sana with the most advanced text-to-image diffusion models in Table 1. For 512 × 512 resolution,
                Sana-0.6 demonstrates a throughput that is 5× faster than PixArt-Σ, which has a similar model size,
                and significantly outperforms it in FID, Clip Score, GenEval, and DPG-Bench. For 1024 × 1024 resolution,
                Sana is considerably stronger than most models with &lt;3B parameters and excels in inference latency.
                Our models achieve competitive performance even when compared to the most advanced large model FLUX-dev.
                For instance, while the accuracy on DPG-Bench is equivalent and slightly lower on GenEval,
                Sana-0.6B’s throughput is 39× faster, and Sana-1.6B is 23× faster.</p>
        </div>

        <p><img src="https://nvlabs.github.io/Sana/asset/content/performance.jpg" alt="Sana performance">
        </p>

        <!-- Video Section -->
        <p>
            <h2>Sana-0.6B is Deployable on Laptop GPU</h2>
        </p>
        <p>
            <video controls="">
                <source src="https://nvlabs.github.io/Sana/asset/video/Sana-0.6B-laptop.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </p>
        <!-- End Video Section -->

        <div>
            <h2>Our Mission</h2>
            <p>Our mission is to develop <strong>efficient, lightweight, and accelerated</strong>
                AI technologies that address practical challenges and deliver fast, open-source solutions.</p>
        </div>

        <!--BibTex citation -->
        <p>
            <h2>BibTeX</h2>
        </p>
        <div id="BibTeX">
                <pre><code>@misc{xie2024sana,
      title={Sana: Efficient High-Resolution Image Synthesis with Linear Diffusion Transformer},
      author={Enze Xie and Junsong Chen and Junyu Chen and Han Cai and Haotian Tang and Yujun Lin and Zhekai Zhang and Muyang Li and Ligeng Zhu and Yao Lu and Song Han},
      year={2024},
      eprint={2410.10629},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2410.10629},
    }</code></pre>
            </div>

    </section>
    <!--End BibTex citation -->

    <!-- Footer Section -->
    
    <!-- End Footer -->

    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Un Ministral, Des Ministraux (179 pts)]]></title>
            <link>https://mistral.ai/news/ministraux/</link>
            <guid>41859466</guid>
            <pubDate>Wed, 16 Oct 2024 14:31:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mistral.ai/news/ministraux/">https://mistral.ai/news/ministraux/</a>, See on <a href="https://news.ycombinator.com/item?id=41859466">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2 id="introducing-the-worlds-best-edge-models">Introducing the world’s best edge models</h2><p>On the first anniversary of the release of Mistral 7B, the model that revolutionized independent frontier AI innovation for millions, we are proud to introduce two new state-of-the-art models for on-device computing and at-the-edge use cases. We call them les Ministraux: Ministral 3B and Ministral 8B.</p><p>These models set a new frontier in knowledge, commonsense, reasoning, function-calling, and efficiency in the sub-10B category, and can be used or tuned to a variety of uses, from orchestrating agentic workflows to creating specialist task workers. Both models support up to 128k context length (currently 32k on vLLM) and Ministral 8B has a special interleaved sliding-window attention pattern for faster and memory-efficient inference.</p><h3 id="use-cases">Use cases</h3><p>Our most innovative customers and partners have increasingly been asking for local, privacy-first inference for critical applications such as on-device translation, internet-less smart assistants, local analytics, and autonomous robotics. Les Ministraux were built to provide a compute-efficient and low-latency solution for these scenarios. From independent hobbyists to global manufacturing teams, les Ministraux deliver for a wide variety of use cases.</p><p>Used in conjunction with larger language models such as Mistral Large, les Ministraux are also efficient intermediaries for function-calling in multi-step agentic workflows. They can be tuned to handle input parsing, task routing, and calling APIs based on user intent across multiple contexts at extremely low latency and cost.</p><h3 id="benchmarks">Benchmarks</h3><p>We demonstrate the performance of les Ministraux across multiple tasks where they consistently outperform their peers. We re-evaluated all models with our internal framework for fair comparison.</p><h4 id="pretrained-models">Pretrained Models</h4><p><img src="https://mistral.ai/images/news/ministraux/pretrain_table.png" alt="Pretrained model comparison table" width="80%"></p><p><b>Table 1:</b> Ministral 3B and 8B models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B and Mistral 7B on multiple categories</p><p><img src="https://mistral.ai/images/news/ministraux/pretrain_with_gemma.png" alt="Pretrained model comparison graph" width="80%"></p><p><b>Figure 1:</b> Ministral 3B and 8B base models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B and Mistral 7B</p><h4 id="instruct-models">Instruct Models</h4><p><img src="https://mistral.ai/images/news/ministraux/instruct_table_with_gemma.png" alt="Instruct model comparison table" width="80%"></p><p><b>Table 2:</b> Ministral 3B and 8B Instruct models compared to Gemma 2 2B, Llama 3.2 3B, Llama 3.1 8B, Gemma 2 9B and Mistral 7B on different evaluation categories.</p><p><img src="https://mistral.ai/images/news/ministraux/instruct_plot_3b_no_qwen_with_mistral_logo.png" alt="3B Instruct model comparison graph" width="80%"></p><p><b>Figure 2:</b> A comparison of the 3B family of Instruct models - Gemma 2 2B, Llama 3.2 3B and Ministral 3B. The figure showcases the improvements of Ministral 3B over the much larger Mistral 7B.</p><p><img src="https://mistral.ai/images/news/ministraux/instruct_plot_8b_with_mistral_logo.png" alt="8B Instruct model comparison graph" width="80%"></p><p><b>Figure 3:</b> A comparison of the 8B family of Instruct models - Gemma 2 9B, Llama 3.1 8B, Mistral 7B and Ministral 8B.</p><h3 id="availability-and-pricing">Availability and pricing</h3><p>Both models are available starting today.</p><table><thead><tr><th>Model</th><th>API</th><th>Pricing on la Plateforme</th><th>License</th></tr></thead><tbody><tr><td>Ministral 8B</td><td>ministral-8b-latest</td><td>$0.1 / M tokens (input and output)</td><td>Mistral Commercial License<br>Mistral Research License</td></tr><tr><td>Ministral 3B</td><td>ministral-3b-latest</td><td>$0.04 / M tokens (input and output)</td><td>Mistral Commercial License</td></tr></tbody></table><p>For self-deployed use, <a href="https://mistral.ai/contact/">please reach out to us</a> for commercial licenses. We will also assist you in lossless quantization of the models for your specific use-cases to derive maximum performance.</p><p>The model weights for <a href="https://huggingface.co/mistralai/Ministral-8B-Instruct-2410">Ministral 8B Instruct</a> are available for research use. Both models will be available from our <a href="https://docs.mistral.ai/deployment/cloud/overview/">cloud partners</a> shortly.</p><h3 id="more-to-come">More to come</h3><p>At Mistral AI, we continue pushing the state-of-the-art for frontier models. It’s been only a year since the release of Mistral 7B, and yet our smallest model today (Ministral 3B) already outperforms it on most benchmarks. We can’t wait for you to try out les Ministraux and give us feedback.</p><p><img src="https://mistral.ai/images/news/ministraux/meme_cropped.png" alt="More to come" width="50%"></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon reveals first color Kindle, new Kindle Scribe, and more (157 pts)]]></title>
            <link>https://www.aboutamazon.com/news/devices/new-kindle-color-scribe-paperwhite-entry</link>
            <guid>41859047</guid>
            <pubDate>Wed, 16 Oct 2024 13:52:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.aboutamazon.com/news/devices/new-kindle-color-scribe-paperwhite-entry">https://www.aboutamazon.com/news/devices/new-kindle-color-scribe-paperwhite-entry</a>, See on <a href="https://news.ycombinator.com/item?id=41859047">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Our e-reader lineup also features a reimagined Kindle Scribe and the fastest Kindle Paperwhite ever.</p><div><article><div><p><span><p><span>There’s never been a better time to pick up a Kindle. Amazon is introducing </span><a target="_blank" href="https://www.amazon.com/kindlefamily"><span>an entirely new lineup of Kindle devices</span></a><span>, including the first-ever color Kindle, a reimagined Kindle Scribe, the fastest Kindle Paperwhite ever, and a new entry Kindle in a fun, new Matcha color.</span></p></span></p></div><div><p><span><p><span>Let’s get to know the newest Kindle devices.</span><br></p></span></p></div><div><p><h2>Introducing Kindle Colorsoft Signature Edition</h2></p></div><div><p><img alt="Amazon Kindle Colorsoft displaying book cover and highlighted text" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/f002870/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2Fae%2Fcb%2F768e417f48e3975ce7f13a6dfe2a%2Faa-oct24-kindlecolorsoft-standard-inline-v1-400kb-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>The all-new </span><a target="_blank" href="https://www.amazon.com/kindlecolorsoft"><span>Kindle Colorsoft</span></a><span> brings color to Kindle without compromise. It has everything customers love about Kindle today—high contrast, fast page turns, an auto-adjusting front light, and weeks of battery life. It adds color that is vibrant yet easy on the eyes. Now, you can browse covers in color in your Kindle Library or Store; see book photos and images in color; or add color highlights that you can easily search later.</span></p></span></p></div><div data-testid="RelatedContent"><p><a href="https://www.aboutamazon.com/news/devices/kindle-color-specs-price-announce"><img alt="Color Kindle with highlighted text in front of an airplane window" height="200" role="" src="https://assets.aboutamazon.com/dims4/default/feef579/2147483647/strip/true/crop/1350x900+130+0/resize/300x200!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F42%2F80%2Fdcfbccc2454982c78f022b82fdd7%2Faa-oct2024-kindle-seabreeze-standard-inline-v4-1600x900.jpg" width="300"></a></p></div><div><p><span><p><span>Everything about Kindle Colorsoft was meticulously designed to deliver rich, paper-like color. It uses an oxide backplane with custom waveforms for fast performance and a higher contrast on both color and black-and-white content. Its custom Colorsoft display includes a new light-guide with nitride LEDs that, when combined with our custom algorithms, enhances color and increases brightness, all without washing out details. You can zoom in on images without worrying about pixelation, and you can choose between standard or vibrant color styles. Kindle Colorsoft comes with wireless charging, up to eight weeks of battery life, and is waterproof so you can bring it with you in the bath or take it to the beach without having to worry.</span><br></p></span></p></div><div><p><h2>The new Kindle Scribe, with in-book writing and an AI-powered notebook</h2></p></div><div><p><img alt="Notes written on Kindle Scribe" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/8802301/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2Fc7%2F3f%2F05ac92204002b0f11c46f8e5c183%2Faa-oct24-kindlescribe-standard-inline-v2-400kb-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>The all-new </span><a target="_blank" href="https://www.amazon.com/dp/B0CZ9VFQ2P?th=1"><span>Kindle Scribe</span></a><span> combines all the benefits of Kindle with a powerful notetaking device. The display has new white borders, and the screen has a smooth, paper-like texture that makes it look and feel like you’re writing on a sheet of paper. Plus, at 300 ppi, text looks crisp and clear when you’re writing or reading. The Premium Pen is finely crafted to deliver just the right heft and balance, so it feels like holding an actual pen, and the new soft-tipped eraser feels like a pencil—you’ll think you have to brush the screen clean after erasing.</span></p></span></p></div><div data-testid="RelatedContent"><p><a href="https://www.aboutamazon.com/news/devices/fun-kindle-features"><img alt="Prime Student" height="200" role="" src="https://assets.aboutamazon.com/dims4/default/fa0dffb/2147483647/strip/true/crop/1350x900+125+0/resize/300x200!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F93%2F98%2F6b4f877441aa99dcd13974f5629e%2Fheres-everything-you-get-with-prime-student-beyond-the-regular-prime-membership-inline-v2-kindle-unlimited.jpg" width="300"></a></p></div><div><p><span><p><span>The new Kindle Scribe offers a first-of-its-kind in-book writing experience and a more powerful notetaking experience. With Active Canvas, you can write your thoughts directly in the book when inspiration strikes. Your note becomes part of the page, and the book text dynamically flows around it—if you increase the font size, change the font style, or the book layout changes, the note remains visible exactly where you want it so you never lose any meaning or context. Coming soon, you’ll also be able to write your notes in the side panel and easily hide them when you are done. The all-new, built-in AI-powered notebook enables you to quickly summarize pages and pages of notes into concise bullets in a script font that can be easily shared directly from the notebook tab. You can also refine your notes into a script font, so it becomes legible while maintaining the look and feel of handwriting.</span><br></p></span></p></div><div><p><h2>The fastest Kindle ever: The all-new Kindle Paperwhite</h2></p></div><div><p><img alt="Woman relaxing with Kindle and coffee, Kindle e-reader, colorful Kindle cases" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/1e32613/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2Fdb%2Fee%2Fe9a43a714bd3a7d572f2883eabca%2Faa-oct24-kindlepaperwhite-standard-inline-v2-400kb-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>Since its debut in 2012, customers have made Kindle Paperwhite our best-selling Kindle—and the all-new </span><a target="_blank" href="https://www.amazon.com/kindlepaperwhite"><span>Kindle Paperwhite</span></a><span> is our fastest yet. Scrolling through your Kindle Library or Store is snappy and responsive with 25% faster page turns. The display uses an oxide thin-film transistor, which gives it the highest contrast ratio of any Kindle, so text and images pop off the screen. A larger, 7-inch display is a first for Kindle Paperwhite—and yet, it is also the thinnest Kindle Paperwhite ever with up to three months of battery life.</span></p></span></p></div><div data-testid="RelatedContent"><p><a href="https://www.aboutamazon.com/news/devices/how-to-use-kindle-paperwhite"><img alt="Kindle Paperwhite." height="200" role="" src="https://assets.aboutamazon.com/dims4/default/fd25989/2147483647/strip/true/crop/1620x1080+150+0/resize/300x200!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F39%2F5d%2Ffecd31c9434a913d40a92c55dd0b%2Fpaperwhite-hero-v1.jpeg" width="300"></a></p></div><div><p><span><p><span>Kindle Paperwhite is waterproof with 16 GB of storage for thousands of books, and comes in Raspberry, Jade, and Black. </span><a target="_blank" href="https://www.amazon.com/kindlepaperwhitesignature"><span>Kindle Paperwhite Signature Edition</span></a><span>, which comes with 32 GB of storage, optional wireless charging, and auto-adjusting front light, comes in Metallic Raspberry, Metallic Jade, and Metallic Black.</span><br></p></span></p></div><div><p><h2>The new Kindle—our most compact Kindle, now in Matcha</h2></p></div><div><p><img alt="Amazon Kindle e-reader device in matcha color" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/7ccf710/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2Fbd%2Fa9%2Fd591291f4fe5bb449cba44c356f6%2Faa-oct24-kindlematcha-standard-inline-v1-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>Weighing in at just 158g, the </span><a target="_blank" href="https://www.amazon.com/kindle"><span>new entry-level Kindle</span></a><span> is small enough to fit in your hand or carry in your back pocket—and it’s packed with premium Kindle features. It has a 300 ppi, glare-free display, now with faster page turns, higher contrast ratio, and a front light that is 25% brighter at max setting—as bright as Kindle Paperwhite. It comes in a fun and fresh new Matcha color, offers weeks of battery life from a single charge, and has 16 GB of storage for holding thousands of books—all of which make it the ideal device for reading anywhere the day takes you.</span><br></p></span></p></div><div><p><h2>For the youngest readers—thousands of books and audiobooks</h2></p></div><div><p><img alt="Child reading Kindle e-reader in cozy blanket fort, Kindle with colorful covers displayed on light background" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/ef1ce4e/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F50%2Feb%2F065e42924650aa480627818ffdad%2Faa-oct24-kindlekids-standard-inline-v1-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>With Kindle Kids, parents can help their kids cultivate a love of reading at a young age—in fact, when a kid sits down with a Kindle, they read, on average, more than an hour a day. The new entry </span><a target="_blank" href="https://www.amazon.com/kindlekids"><span>Kindle Kids</span></a><span> is available with an included cover in one of the following designs: Space Whale, Ocean Explorer, and Unicorn Valley; and the new </span><a target="_blank" href="https://www.amazon.com/kindlepaperwhitekids"><span>Kindle Paperwhite Kids</span></a><span> comes with a Cyber City, Starfish, or </span><span><span>Diary of a Wimpy Kid</span></span><span> cover, designed by international bestselling author Jeff Kinney. Both devices come with a 2-year worry free guarantee and six months of </span><a target="_blank" href="https://www.amazon.com/ftu/home?ref_=ftu_kindle_friendly"><span>Amazon Kids+</span></a><span> included, a kid-friendly subscription service that provides access to thousands of age-appropriate books and audiobooks.</span></p></span></p></div><div data-testid="RelatedContent"><p><a href="https://www.aboutamazon.com/news/devices/what-is-amazon-kids-plus-subscription"><img alt="An image of two kids playing on the floor looking at an Amazon Kids tablet. " height="200" role="" src="https://assets.aboutamazon.com/dims4/default/8ddb3a1/2147483647/strip/true/crop/1688x1125+156+0/resize/300x200!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F7d%2F44%2Fed65c7284ca6bc97c318c296291e%2Famazonkids-hero-2.jpg" width="300"></a></p></div><div><p><h2>Discover your next favorite read</h2></p></div><div><p><img alt="Hands holding Kindle displaying book covers in cozy home setting" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/a3a6a84/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F1d%2F95%2F298a26504a4f85c0c3fa1322a5df%2Faa-oct24-kindlepaperwhite-standard-inline-v1-400kb-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>All Kindle devices come with access to the world’s best e-book store, and an included 3-month subscription to </span><a target="_self" href="https://www.aboutamazon.com/news/devices/what-is-kindle-unlimited"><span>Kindle Unlimited</span></a><span>, which provides an extensive library of digital books, audiobooks, comics, and magazines that span a myriad of genres, including popular series, best sellers, and more. From mystery and romance to nonfiction and memoir, members can read as many books as they’d like with a monthly membership. Learn more about how to sign up for Kindle Unlimited at </span><a target="_blank" href="https://www.amazon.com/kindle-dbs/hz/subscribe/ku"><span>amazon.com/kindleunlimited</span></a><span>.</span><br></p></span></p></div><div><p><h2>Sustainability, pricing, and availability</h2></p></div><div><p><img alt="Amazon Kindle Colorsoft device displaying image from book" height="431" role="" src="https://assets.aboutamazon.com/dims4/default/75bb014/2147483647/strip/true/crop/1600x900+0+0/resize/767x431!/quality/90/?url=https%3A%2F%2Famazon-blogs-brightspot.s3.amazonaws.com%2F15%2F80%2Fd6d497584d6a955e0cc02bedd579%2Faa-oct24-kindlecolorsoft-standard-inline-v2-400kb-1600x900.jpg" width="767"><span></span></p></div><div><p><span><p><span>Kindle is </span><a target="_blank" href="https://amzn.to/4eOox5w"><span>available now</span></a><span> starting at $109.99. Kindle Paperwhite is </span><a target="_blank" href="https://amzn.to/3UeVmAi"><span>available now</span></a><span> starting at $159.99, and Kindle Paperwhite Signature Edition is </span><a target="_blank" href="https://amzn.to/3zQQQB5"><span>available</span></a><span> for $199.99. Kindle Colorsoft Signature Edition will ship on October 30 and is available now for </span><a target="_blank" href="https://amzn.to/3UzH915"><span>pre-order</span></a><span> at $279.99. The new Kindle Scribe will ship on December 4 and is available now for </span><a target="_blank" href="https://amzn.to/48egU5F"><span>pre-order</span></a><span> starting at $399.99. Our new Kindle lineup is packaged in 100% recyclable device packaging that features a new box design that uses more recycled fiber content, averages 99% wood fiber-based materials, and uses less ink.</span></p></span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Traveling with Apple Vision Pro (347 pts)]]></title>
            <link>https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/</link>
            <guid>41859012</guid>
            <pubDate>Wed, 16 Oct 2024 13:48:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/">https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/</a>, See on <a href="https://news.ycombinator.com/item?id=41859012">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>The Vision Pro has quickly become an essential item that I take onto every flight.</p>



<p>It’s a fantastic device to travel with—Be it by train or by plane, it offers an unparalleled opportunity to selectively tune out your environment and sink into an engaging activity like watching a movie or just working on your laptop.&nbsp;</p>



<p>In this blog post, I’ll outline what I’ve learned about the Vision Pro while traveling, explain some of the functionality, shine light onto its drawbacks, as well as assess how it fares against solutions like a phone or a laptop.&nbsp;</p>



<p>For context, most of the traveling where I’ve brought my Vision Pro along has been on airplanes, but this applies to traveling by train as well.&nbsp;</p>



<hr>



<h2 id="table-of-contents">Table of Contents</h2>



<details><summary>Expand </summary>
<ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#table-of-contents">Table of Contents</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#packing-travel-setup">Packing / Travel Setup</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#user-experience">User Experience</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#airport-security-line">Airport Security Line</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#travel-mode">Travel Mode</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#battery-life-charging">Battery Life &amp; Charging</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#physical-comfort">Physical Comfort</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#social-comfort">Social Comfort</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#passthrough">Passthrough</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#ui-interaction">UI Interaction&nbsp;</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#virtual-environment-depth-collision-mitigation">Virtual Environment / Depth Collision Mitigation</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#airpods-pros-vision-pro">AirPods Pros + Vision Pro</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#eating-snacking">Eating/Snacking</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#works-in-complete-darkness">Works in Complete Darkness</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#watching-movies">Watching Movies</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#apps">Apps</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#visuals">Visuals</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#cinema-environment">Cinema Environment</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#benefits-of-privacy">Benefits of Privacy</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#special-film-formats">Special film formats </a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#audio">Audio</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#caveat-when-videos-doesn-t-play">Caveat: when videos doesn’t play</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#mac-virtual-display">Mac Virtual Display</a><ol><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#no-more-laptop-screen-tilt-limitations">No More Laptop Screen Tilt Limitations </a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#higher-resolution-more-real-estate">Higher Resolution + More Real Estate </a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#privacy">Privacy</a></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#iphone-mirroring">iPhone Mirroring</a></li></ol></li><li><a href="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/#conclusion">Conclusion</a></li></ol>
</details>



<hr>



<h2 id="packing-travel-setup">Packing / Travel Setup</h2>



<p>First and foremost, space in my suitcase or backpack while traveling is the most valuable commodity. Whenever I’m packing for a trip, anything that adds unnecessary bulk to my setup is immediately discarded.&nbsp;</p>



<p>For that reason, I highly recommend that you <strong>do NOT purchase</strong> the behemoth of the $200 Vision Pro “<a href="https://www.apple.com/shop/product/MW2F3LL/A/apple-vision-pro-travel-case">travel case</a>” from Apple. It’s unnecessarily massive and doesn’t fit into ANYTHING. Avoid it at all costs unless you absolutely need a crazy amount of protection from the elements (but at that point, might as well buy a Pelican case!).</p>



<figure><img loading="lazy" data-attachment-id="239" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-4/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg" data-orig-size="1926,1122" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=1024" tabindex="0" role="button" width="1024" height="596" src="https://azadux.blog/wp-content/uploads/2024/10/screenshot-2024-10-03-at-10.32.53e280afam.jpeg?w=1024" alt=""><figcaption><em>The size of the official AVP Travel case size is wayy too big. (image credit: <a href="https://twitter.com/DanMillerDev/status/1814320337271583012">Dan Miller on Twitter)</a></em></figcaption></figure>



<p>My travel setup is super simple and minimal. </p>



<p>To protect the front glass, I use the “Vision Pro Cover” that comes by default with the headset and on the inside, I use this affordable, generic <a href="https://www.amazon.com/dp/B0CW9C6WF8?ref=ppx_pop_mob_ap_share">VR lens protector cover</a> to prevent anything from scratching the lenses. I then throw it into my backpack, face-first, sitting above the other items.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img loading="lazy" data-attachment-id="235" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/avp-packing2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AVP Packing2" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=768" tabindex="0" role="button" width="768" height="1024" data-id="235" src="https://azadux.blog/wp-content/uploads/2024/10/avp-packing2.jpeg?w=768" alt=""><figcaption><em>Side view of my travel setup</em></figcaption></figure>



<figure><img data-attachment-id="234" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/avp-packing/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg" data-orig-size="3024,4032" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="AVP Packing" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="234" src="https://azadux.blog/wp-content/uploads/2024/10/avp-packing.jpeg?w=768" alt=""><figcaption><em>Lens protection</em></figcaption></figure>



<figure><img data-attachment-id="238" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_1702-large/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1727017651&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.7&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;39.876122222222&quot;,&quot;longitude&quot;:&quot;-75.242325&quot;}" data-image-title="IMG_1702 Large" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="238" src="https://azadux.blog/wp-content/uploads/2024/10/img_1702-large.jpeg?w=768" alt=""><figcaption><em>In my backpack</em></figcaption></figure>
</figure>



<p>I even use the space between the Solo strap and the headset itself as a place to put my rolled up puffer jacket or quarter-zip. This way, the only amount of space that it actually takes up is the thickness of the headset itself!&nbsp;</p>



<p>As for the battery pack, after charging it to 100%, I disconnect the battery, roll up the cord (while being aware of not adding extra stress to the connector) and throw into my backpack (either into a pocket or have it sit on the bottom).&nbsp;</p>



<p><strong>With this setup, I haven’t scratched or damaged the headset itself at all</strong> over the 5-10 flights that I’ve taken it on. Works quite well!</p>



<hr>



<h2 id="user-experience">User Experience</h2>



<h3 id="airport-security-line">Airport Security Line</h3>



<p>At the airport security line, I typically pull out my laptop and the Vision Pro from my backpack. Thankfully, it seems like the Vision Pro doesn’t look suspicious at all while being x-rayed as I haven’t been questioned about it yet.&nbsp;</p>



<h3 id="travel-mode">Travel Mode</h3>



<p>The Vision Pro’s 6DoF tracking system is built on a combination of IMU’s + SLAM cameras (same as any other VR headsets). Unlike other VR headsets, however, it has a native “Travel Mode” which accounts for the fact that using a 6DoF VR headset in a moving vehicle will lead to massive drift and tracking issues.</p>



<p>The Vision Pro’s Travel Mode was specifically designed to account for these tracking issues (essentially relying entirely on the SLAM cameras and ignoring the IMU data).</p>



<p>As I put on the headset, if the plane is a bit unstable, the Vision Pro detects that I’m on a plane and will suggest to turn on Travel Mode with an actionable notification, which is great because it eliminates any need to prepare the headset prior to boarding/take-off! This was a very deliberate design choice by Apple and is a <em>very</em> welcome one.&nbsp;</p>



		<figure>
			
			<figcaption><em>Vision Pro prompting me to activate Travel Mode</em> <em>based on tracking issues</em> <em>in moving vehicle</em>.</figcaption>
			
		</figure>
		


<p>I should mention that since the IMU data is ignored, the way the horizon is determined in Travel Mode tracking is purely by the orientation/rotation of your head. If your head is titled, so will all your virtual apps/windows. To fix this, you can cover your vision pro with your hands (to lock the cameras) and when you re-initialize, recenter your apps so that they adhere to the newly-determined horizon.</p>



<p>This might seem like a minor detail, but I find it immensely annoying if my windows are not parallel to the airplane’s ground plane.&nbsp;</p>



<h3 id="battery-life-charging">Battery Life &amp; Charging</h3>



<p>The 2.5-3 hr battery life of Apple Vision Pro is… fine.</p>



<p>It’s enough to watch a 90-120 minute movie and mayyybe an episode of a TV show. For short flights, this is perfectly adequate but for longer, transatlantic/transpacific flights, it’s obviously very much limited.&nbsp;</p>



<p>The best option to extend its battery life is if your plane seat has a 120/240V power outlet. Given that you have a minimum 30W charging adapter, you’ll be able to keep your Vision Pro charged indefinitely.&nbsp;</p>



<p>The next best option is having a high power output battery bank. I use a single 12k mAh Anker <a href="https://www.anker.com/products/a1335-130w-power-bank?variant=42691850797206">battery bank</a> (which can output up to 60W), so recharging the Vision Pro <em>does</em> eat up the entirety of the battery bank’s capacity. This is something to keep in mind if you need to keep your phone charged as well.</p>



<p>I should mention that I prioritize keeping my phone charged over my Vision Pro. A 12k mAh battery bank will recharge my phone 3-4 times while providing me the ability to watch multiple times more movies/TV shows, listen to podcasts, etc. If I have a long flight and I’m not sure that my seat will have a proper power outlet, I don’t rely on my Vision Pro to be my only form of entertainment for the entirety of the flight.</p>



<p>By the way, I typically place the battery pack in the pouch by my knees. The cable is the perfect length for it to reach my head without it feeling too long or too short. Nice! </p>



<figure><img data-attachment-id="281" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/cable/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg" data-orig-size="1280,960" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728219640&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.019607843137255&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;53.424605555556&quot;,&quot;longitude&quot;:&quot;-6.2563888888889&quot;}" data-image-title="cable" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="768" src="https://azadux.blog/wp-content/uploads/2024/10/cable.jpeg?w=1024" alt=""><figcaption><em>The cable is the perfect length when the battery is placed in the seat pouch.</em></figcaption></figure>



<h3 id="physical-comfort">Physical Comfort</h3>



<p>Now, if you’re like me and find the Vision Pro’s ergonomics and weight distribution to be utterly shit, I will highly recommend that you try to find a comfortable setup before you embark on your journey.&nbsp;</p>



<p>Having gone through <a href="https://twitter.com/Azadux/status/1757469190095781900">quite</a> <a href="https://twitter.com/Azadux/status/1771973928526967195">a</a> <a href="https://twitter.com/Azadux/status/1810071506107633870">few</a> <a href="https://twitter.com/Azadux/status/1760097753294942557">head</a> strap setups, I now use the <a href="https://vrcover.com/item/universal-headset-support-strap/">VR Cover Universal Headset Support Strap</a> exclusively. It offers quite a lot of comfort without adding any bulk to the portability of the headset. It helps by removing pressure off your cheeks and distributing the weight onto the front area of the top of your head (similar to a typical VR headset halo strap). It’s not perfect but I find it to be “good enough” for now.&nbsp;</p>



<figure><img data-attachment-id="303" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/cover1-copy/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg" data-orig-size="993,713" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728219440&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;5.7&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;53.424177777778&quot;,&quot;longitude&quot;:&quot;-6.24665&quot;}" data-image-title="cover1 copy" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=993" tabindex="0" role="button" loading="lazy" width="993" height="713" src="https://azadux.blog/wp-content/uploads/2024/10/cover1-copy.jpeg?w=993" alt=""><figcaption><em>Using AVP with the <a href="https://vrcover.com/item/universal-headset-support-strap/">VR Cover Support Strap</a></em></figcaption></figure>



<p>While they’re might be better head strap solutions, the <em>bulk </em>that they add to the travel setup is a dealbreaker for me.&nbsp;</p>







<p>Another aspect of comfort is… social comfort. When I’m wearing a VR headset around people, I don’t know whether they’re looking at me, or where they are, what they’re doing, etc. Here, the combination of Passthrough + EyeSight offers a great way of remaining aware of your surroundings.&nbsp;</p>



<h4 id="passthrough">Passthrough</h4>



<p>Thankfully, it seems like one of the few places where it’s currently socially acceptable to wear a Vision Pro <em>is</em> on a plane. Of the 5-10 times that I’ve worn it on planes, I haven’t had the feeling of people staring at me suspiciously, whispering about me (at least to my knowledge), or asking me about what I’m doing. I do typically feel self-conscious about using VR in public (so I almost never do it), so the fact that I feel almost entirely comfortable wearing it on a plane says something. Everyone does something to pass the time on a plane, so people are much more forgiving seeing a nerd wearing a face-computer.&nbsp;</p>



<p>Passthrough + EyeSight, as pitched by Apple in their initial announcement of Apple Vision Pro <em>does</em> work quite well when it comes to staying aware of your surroundings and interacting with others (especially flight attendants for those delicious snacks).&nbsp;</p>



<p>While I’m not entirely sure if EyeSight is active when I’m speaking with the flight attendants, the fact that I see them approaching my aisle, that I turn to look and engage with them, and that they see that I am hearing and seeing them (somehow, despite the fact that both my eyes and ears and covered), means that they treat me as any other passenger.&nbsp;</p>



<figure><figcaption><em>Video of me ordering tea from a flight attendant while wearing a Vision Pro</em>.</figcaption></figure>



<p>I’m serious that I haven’t had any real issues interacting with flight attendants while wearing my Vision Pro.</p>



<p>One caveat is that, out of respect, if the conversation is more than the “what would you like? Tea please” deal, I do remove the headset to make direct eye contact with them. I feel that it would be sort of odd to have a full-on conversation with someone if they’re wearing a headset (like bro, just take it off and let’s talk like humans).</p>



<h4 id="ui-interaction"><strong>UI Interaction&nbsp;</strong></h4>



<p>One underrated aspect of VisionOS’s interaction system is that it requires very minimal “hand wavy-ness” to interact with the system. This is a stark difference when compared Quest’s OS (or as it’s now called Meta Horizon OS) which requires you to either use a controller or your hand to point and aim at a screen.</p>



<p>The fact that you just <em>look</em> at the buttons that you’d like to interact with and pinch your fingers while your hand is resting on your lap is a massive plus for not looking like a dweeb. </p>



		<figure>
			
			<figcaption><em>Interacting with the visionOS via tapping + eye tracking is pretty discrete (compared to other VR headsets).</em> </figcaption>
			
		</figure>
		


<p>I mention this because I <em>have</em> used a Quest on a plane (briefly, to capture <a href="https://twitter.com/PuzzlingPlaces/status/1536726744618639363">marketing footage</a> of Puzzling Places in Passthrough). I <em>really</em> felt self conscious about trying to minimize the amount of arm movements I had to do to navigate the OS, menus, etc. I held my elbow tight against my body and tried to only rotate my wrist around, which was quite uncomfortable.</p>



<p>So once again, the eye+pinch UI interaction system is a wonder when it comes to minimizing the amount of physical movement required to navigate the OS, remaining <em>cool</em> and <em>discrete</em> while wearing a face computer (right? right??). </p>



<h4 id="virtual-environment-depth-collision-mitigation"><strong>Virtual Environment / </strong>Depth Collision Mitigation</h4>



<p>One of the biggest issues of Passthrough Mixed Reality is the fact that depending on where you are, you might have a chair or a wall in front of you that presents a “collision” with a virtual screen in your Vision Pro.</p>



<p>In the case of flying on a plane, the chair in front of you is quite close, so if you’d like to set your virtual movie screen to be large and 10 ft away, the chair and the movie screen create a “depth collision”, which can be quite uncomfortable.</p>



<p>Of course, one way to mitigate this is to immerse yourself into a fully virtual world, but that comes at the expense of spatial awareness.</p>



<p>The wonderful thing about visionOS is that you can use a “partial” virtual environment, carefully dialing in just how much of a virtual environment you’d like to use. </p>



		<figure>
			
			<figcaption><em>Showcasing the incongruity of the “depth collision” between a virtual object (Mac window) and IRL object (chair) and its mitigation with a partial virtual environment.</em></figcaption>
			
		</figure>
		


<p>In this case, it’s a perfect fix for opening a portal or a window to a serene landscape to place your large movie screen in, while still being able to see the plane around you. </p>



<p>It works great and is one of the best features of visionOS for using VR in public. </p>



<h3 id="airpods-pros-vision-pro"><strong>AirPods Pros + Vision Pro</strong></h3>



<p>A match made in heaven. </p>



<p>The AirPod Pros are a fantastic set of earphones to wear with the Vision Pro on a plane, offering top-of-the-line active noise cancellation (ANC) but also, “adaptive” and “transparency” modes which allow you to selectively hear voices/sounds around you, depending on the situation.&nbsp;</p>



<p>I use the AirPods Pro 2 with USB-C, which are special in that they offer uncompressed audio with low latency specifically for the Vision Pro. While they do work quite well, according to audiophile reviews, the difference in audio quality between the regular AirPods Pro 2s and the USB-C version with uncompressed audio <a href="https://youtu.be/eOH33sWgds8?t=1392">is minimal</a>, so keep that in mind if you already own an older pair.&nbsp; &nbsp;</p>



<p>The AirPod Pro 2s also feature “Spatial Audio” which output the surround sound mix of movies in a spatial format. By default, the sound is contextually spatialized and head-tracked, meaning, the Vision Pro tries to simulate the room acoustics of the space that you’re in. Typically, this works well enough in a room, but on a dark plane, I find that the spatial acoustics are a bit too different from the raw audio output of the movie itself. </p>



<p>Thankfully, you <em>can</em> change this by disabling the Spatial Audio output from Control Center while watching a movie, where you get the raw sound mix of the movie piped to your AirPods <em>with</em> surround sound still (meaning, sound cues that are behind you will still sound like they’re behind you). The fact that both virtual surround sound and contextual spatialization are called Spatial Audio is definitely a bit confusing.&nbsp;</p>



<figure><img data-attachment-id="300" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_0805/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png" data-orig-size="472,390" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_0805" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=472" tabindex="0" role="button" loading="lazy" width="472" height="390" src="https://azadux.blog/wp-content/uploads/2024/10/img_0805.png?w=472" alt=""><figcaption><em>Toggling the contextually spatialized and head-tracked Spatial Audio to hear the pure surround sound mix.</em></figcaption></figure>



<p>Either way, if you have a Vision Pro, get the AirPod Pro 2s!! You will absolutely not regret it.</p>



<h3 id="eating-snacking"><strong>Eating/Snacking</strong></h3>



<p>Speaking of flight attendants, when you’re ready to have your in-flight meal, I find that the Vision Pro’s Travel mode tracking perform at its worst, particularly in dark cabin environments (much less so when it’s bright).</p>



<p>The problem is that for meals that require eyesight to coordinate (aka using a fork to pick up food from a plate), as soon as you look down at your food, the tracking often gets lost. This causes the movie to stop playing and for you to have to look forward for the tracking to re-initialize.</p>



<p>Additionally, the Vision Pro’s field of view is more horizontal than vertical (unlike most other VR headsets) which can make eating challenging, requiring me to fully tilt my head down to look at my food.  </p>



<p>In most cases, unless I have a sandwich in my hand that I can eat without looking at, I take my headset off to eat my meal, then return to my movie.&nbsp;</p>



<h3 id="works-in-complete-darkness">Works in Complete Darkness</h3>



<p>One of the drawbacks of VR systems that use cameras for 6DoF tracking is the need to have the room lights on for the headset to function! </p>



<p>Thankfully, Apple Vision Pro <em>does </em>work in pitch dark environments (albeit with some caveats). </p>



<p>While the 6DoF tracking gets reduced to 3DoF, the OS and all of the UI interactions still function in 6DoF. The hand and finger tracking continue to work in 6DoF (a bit more slowly, as the depth sensor being used to track your hands likely has a slower refresh rate than the cameras), so you can still use the full OS and grab windows to move them closer/further away. </p>



<p>The 3DoF movement limitation isn’t an issue for watching movies and using the Mac Virtual Display.  </p>



<p>This is a very unique feature to the Vision Pro. No other all-in-one headset can natively function in the dark to this extent. </p>



<hr>



<h2 id="watching-movies">Watching Movies</h2>



<p>Once Vision Pros start to become more affordable, I foresee regular travelers buying Vision Pros just to have an amazing in-flight entertainment system. It’s truly that amazing.</p>



		<figure>
			
			<figcaption><em>Watching movies in Apple Vision Pro—The video player is fantastic.</em></figcaption>
			
		</figure>
		


<p>Here are some of the things I’ve learned while watching movies on planes.</p>



<h3 id="apps">Apps</h3>



<p>The way you’ll want to watch movies and shows is through native VisionOS apps (Apple TV, Disney+, Max) as they will play videos in their native aspect ratios, offer the highest quality visuals and audio, and have a much easier UI built for AVP.</p>



<p>Apple TV is my preferred app to watch movies with. In my opinion, it provides the highest quality video and audio playback, the ability to buy or rent movies without needing to subscribe, and overall, has the simplest and cleanest UI. </p>



<p><span>Note</span>: Recently, Apple combined the iTunes Movie Store with the Apple TV streaming service into just “Apple TV”.</p>



<p>As for Prime Video and other video streaming apps which don’t have visionOS apps, you can use their iPad apps. The aspect ratio of the app window, will be the same as an iPad, however, so movies will play in a letterboxed mode with black bars above and below.</p>



<figure><img data-attachment-id="305" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/img_0814/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png" data-orig-size="1491,948" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="IMG_0814" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="651" src="https://azadux.blog/wp-content/uploads/2024/10/img_0814.png?w=1024" alt=""><figcaption><em>Watching videos through iPad apps always have black bars on top and bottom (the video itself was blacked out when capturing the screenshot). </em></figcaption></figure>



<p>It’s obviously not ideal, but hey, at least I was able to watch Rings of Power comfortably on the plane, on a large screen! </p>



<h3 id="visuals">Visuals</h3>



<p>The movies that play in virtual screens are native to the films’ aspect ratios, which can vary movie to movie, eliminating the black bars of “letterboxing” and “pillarboxing” you typically have on iPads, iPhones, or MacBooks.</p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img data-attachment-id="328" data-permalink="https://azadux.blog/screenshot-10/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg" data-orig-size="1080,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1080" height="1080" data-id="328" src="https://azadux.blog/wp-content/uploads/2024/10/img_0819-edited.jpeg" alt=""><figcaption>4:3 aspect ratio</figcaption></figure>



<figure><img data-attachment-id="324" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-9/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="576" data-id="324" src="https://azadux.blog/wp-content/uploads/2024/10/img_0818.jpeg?w=1024" alt=""><figcaption>16:9 aspect ratio</figcaption></figure>



<figure><img data-attachment-id="329" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-11/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg" data-orig-size="1827,1073" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;1728416249&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="601" data-id="329" src="https://azadux.blog/wp-content/uploads/2024/10/img_0823-1.jpeg?w=1024" alt=""><figcaption>2.40:1 aspect ratio</figcaption></figure>
</figure>



<p>They make great use of the high-res displays of the Vision Pro, its wide color gamut, and its bright HDR capabilities. In fact, of all the screens and displays in my house, my Vision Pro is hands down the highest quality display that I own, so I very much look forward to watching visually compelling movies in it.</p>



<p>One small detail worth mentioning is that the Vision Pro bumps up the frame rate from 90 to 96 fps to provide a smooth playback for 24 fps movies (4:4 pulldown). I really appreciate that level of detail that Apple has put into providing a quality movie-watching experience.</p>



<p>As all VR headset optics go, Apple Vision Pro’s optics are <em>not</em> perfect in the sense that they’re free of glare. Compared to older Fresnel lenses, Vision Pro’s unique concave pancake lenses are some of the best I’ve seen at mitigating god-rays/lens flaring/smearing from high contrast elements. </p>



<p>My advice here is to <em>not</em> use a pitch black environment like the “Moon” or the “Cinema” but rather, use the Dark version of “White Sands”.</p>



<h4 id="cinema-environment">Cinema Environment</h4>



<p>As mentioned in the Virtual Environment section, Apple has created 8 virtual environments, each with “Light” and “Dark” variants.</p>



<p>What’s special is that every environment even has a unique “Cinema” mode where the video playback window gets pushed back and expanded to become 100ft or so, maximizing the field of view of the headset and give the film the “center stage”. </p>



		<figure>
			
			<figcaption><em>Transitioning to an environment’s cinematic mode.</em></figcaption>
			
		</figure>
		


<p>As of VisionOS2, all video apps can take advantage of the Cinema environments that Apple has provided for each virtual environment. Using them gives you a truly massive, immersive (meaning, no multi-tasking) screen to watch your movies on. The environment is also reactive to the lighting of the video, much like the emission of a projector screen. </p>



<p>While some of the environments like Mount Hood have impressive reflective water features underneath the cinematic video playback window, I find them to be a <em>bit</em> too distracting for my taste.</p>



<p>I always go back to the White Sands environment using either the light or dark environment, depending on my mood or time of day.  </p>



<p>I should mention that I <em>don’t</em> always use the immersive cinematic environments. Although as of VisionOS2, you can recenter to adjust the tilt of the cinematic window, I find that it still doesn’t provides as much granular control as I’d like over where I would like to place my movie window. I find myself just making the normal window bigger, pushing it back, and placing it wherever would be most comfortable for me to look at.   </p>



<h4 id="benefits-of-privacy">Benefits of Privacy</h4>



<p>A big bonus for watching movies in VR on a plane is the fact that you don’t need to conscious about movies that contain graphic scenes. You don’t need to turn down the brightness and rotate the screen away from children! </p>



<p>And speaking of brightness, if you’re on a long red-eye flight with the cabin lights off (with your seat neighbor asleep), you don’t need to worry about the brightness of your movie bothering them. </p>



<h4 id="special-film-formats">Special film formats </h4>



<p>Apple TV also contains the largest catalogue of 3D movies (some that are event entirely exclusive to the service, never released on Blu-Ray). I have an in-depth post about the <a href="https://azadux.blog/2024/09/15/vision-pro-movie-formats/">Vision Pro is a revolution for home video formats</a> by offering stereo 3D movies in 4k + HDR, high frame rate, as well as providing a platform for IMAX to offer films in their native 1.43:1 aspect ratio.</p>



<h3 id="audio">Audio</h3>



<p>Using AirPods Pro 2s with active noice canceling is the best way to watch movies with Vision Pro. </p>



<p>In terms of “Spatial Audio”, I’m still a torn on whether I should use the “contextual spatialization” of the surround sound mix of the movie (which is on by default) as it does change the output quite a bit. I find that it’s quite inaccurate when you’re watching the movie in pitch darkness, as the room scanning that the contextual spatialization is based on isn’t mapping the shape of the plane cabin accurately.</p>



<p>Thankfully, you can turn off Spatial Audio and have the native surround mix piped to your AirPods. I believe this output mode still simulates surround sound too! </p>



<h3 id="caveat-when-videos-doesn-t-play">Caveat: when videos doesn’t play</h3>



<p>Similar to iOS streaming apps, I <em>have</em> encountered issues with downloaded purchased and rented shows and movies not being able to play without a network connection. This is truly a “godfuckingdamnit” situation especially when that movie might’ve been the only form of entertainment that I brought onboard. </p>



<figure><img data-attachment-id="268" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-5/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg" data-orig-size="1170,980" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;1727290669&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="857" src="https://azadux.blog/wp-content/uploads/2024/10/img_1841.jpg?w=1024" alt=""><figcaption><em>Playback error of a download Prime Video episode on my phone.</em></figcaption></figure>



<p>The only time encountered the error with a purchased item was when I had downloaded a movie months ago (likely a few OS updates ago) and I wanted to watch it on a plane. </p>



<p>Rentals can be tricky, especially because you need to keep track of when they were rented and when you’re trigger the start of its playback. Typically, they have worked fine for me, but I <em>do</em> worry a bit every time I board the plane on whether a rental will play or not (at least on planes without Wifi).</p>



<hr>



<h2 id="mac-virtual-display">Mac Virtual Display</h2>



<p>The other major use case of Apple Vision Pro on plane is… to work! I don’t mean working with the silly little iPad apps but rather, connect it to your MacBook and turn its tiny little screen into a battle-station. </p>



		<figure>
			
			<figcaption><em>Writing this blog post on a plane using a 13in MacBook Air and Mac Virtual Display.</em></figcaption>
			
		</figure>
		


<p>Mac Virtual Display is a native way for your Mac to stream its screen to the Vision Pro wirelessly <em>without</em> needing a Wifi or network connection. This is noteworthy as most virtual desktop software for VR headsets require either a cabled connection or a local network. With Mac Virtual Display, the Mac and Vision Pro connect to each directly (via Apple magic, likely using <a href="https://www.wi-fi.org/discover-wi-fi/wi-fi-direct">Wifi Direct</a>).</p>



<p>Here are a few things worth mentioning about using my Vision Pro as a virtual monitor for my MacBook.</p>



<h3 id="no-more-laptop-screen-tilt-limitations">No More Laptop Screen Tilt Limitations </h3>



<p>if you’ve tried to work on a plane with a laptop, you know just how restricting the angle of the plane seat in front of you can be. Even 13 inch laptops feel “large” when you can barely tilt the screen enough to actually do some work. It’s doubly worse if the seat in front reclines all the way, making it entirely unusable.  </p>



<figure data-carousel-extra="{&quot;blog_id&quot;:230036551,&quot;permalink&quot;:&quot;https:\/\/azadux.blog\/2024\/10\/08\/traveling-with-apple-vision-pro\/&quot;}">
<figure><img data-attachment-id="277" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/angletight1/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728221693&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;56.234541666667&quot;,&quot;longitude&quot;:&quot;-7.5241472222222&quot;}" data-image-title="angleTight1" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="277" src="https://azadux.blog/wp-content/uploads/2024/10/angletight1.jpeg?w=768" alt=""></figure>



<figure><img data-attachment-id="278" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/angletight2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg" data-orig-size="960,1280" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 13 Pro&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1728221699&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;1.57&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.014285714285714&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;,&quot;latitude&quot;:&quot;56.234541666667&quot;,&quot;longitude&quot;:&quot;-7.5241472222222&quot;}" data-image-title="angletight2" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=225" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=768" tabindex="0" role="button" loading="lazy" width="768" height="1024" data-id="278" src="https://azadux.blog/wp-content/uploads/2024/10/angletight2.jpeg?w=768" alt=""></figure>
<figcaption><em>Not much fun trying to use a laptop when the seat in front has reclined.</em></figcaption></figure>



<p>Here, it doesn’t matter what my front seat neighbor does, I can just tilt my screen down, place the laptop on my lap or tray, pull up a virtual monitor, and get to work.</p>



<h3 id="higher-resolution-more-real-estate">Higher Resolution + More Real Estate </h3>



<p>A very underrated aspect of Mac Virtual Display is that the virtual display isn’t merely a mirror of your laptop screen but an entirely new “display” with its own specifications and attributes.</p>



<p>In my case, using a M2 13 inch MacBook Air, Mac Virtual Display actually <em>increases</em> the resolution of my laptop going from the <em>1710 x 1112</em> to <em>2560 x 1440</em> giving me way more screen real estate to work with!</p>



<p>Here’s what I mean: On the left is what my desktop looks like when I’m writing this blog post on my MacBook by default (I’m even using the highest resolution available). On the right is what my desktop looks like with Mac Virtual Display. Notice how much more real estate there is around my browser window.</p>



<figure><img data-attachment-id="293" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/mac-virt-res-2/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg" data-orig-size="2628,1020" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mac virt res" data-image-description="" data-image-caption="" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="397" src="https://azadux.blog/wp-content/uploads/2024/10/mac-virt-res.jpg?w=1024" alt=""><figcaption><em>Comparing the relative sizes and resolution of my MacBook’s display vs Mac Virtual Display in Vision Pro.</em></figcaption></figure>



<p>With VisionOS2, I’m anxiously waiting for the ultra-wide virtual displays (and higher resolutions) to become available which will only make the experience of using a small laptop to do “big work” more viable. </p>



<p>I do hope that in the future individual apps and windows from a Mac can be streamed into the Vision Pro, allowing each app to take whatever shape and size that it would best benefit from (rather than streaming the full desktop).</p>



<h3 id="privacy">Privacy</h3>



<p>I often see frequent flyers who do sensitive work on planes use privacy filters on their laptop screens to block out others from seeing their work. With it, also comes the cost of screen clarity, text sharpness, color accuracy, and narrow viewing angles (obviously) which hinder the fantastic qualities of MacBook displays.</p>



<p>When using Mac Virtual Display, your MacBook screen is blacked out, allowing only you to be able to see you virtual screen. It’s quite handy for sensitive work! </p>



<h3 id="iphone-mirroring">iPhone Mirroring</h3>



<p>This one’s a little bonus: Apple recently announced that you can stream (screen mirror) your iPhone to Mac and Vision Pro, giving you a smooth, high quality virtual display of your phone.</p>



<p>Unlike on MacOS, however, iPhone screen mirroring isn’t intractable, so you’ll still have to hold the phone in your hand and scroll/type. It also has issues with video playback, so if you’re planning to watch downloaded shows/movies or even YouTube videos on your phone, you’ll encounter AirPlay issues.</p>



<p>The reason you’d stream your phone while watching a movie in Vision Pro is because trying to use your phone via the Passthrough is less than ideal, especially in low light.</p>



<figure><img data-attachment-id="296" data-permalink="https://azadux.blog/2024/10/08/traveling-with-apple-vision-pro/screenshot-8/" data-orig-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg" data-orig-size="1920,1080" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;Screenshot&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;Screenshot&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Screenshot" data-image-description="" data-image-caption="<p>Screenshot</p>
" data-medium-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=300" data-large-file="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=1024" tabindex="0" role="button" loading="lazy" width="1024" height="576" src="https://azadux.blog/wp-content/uploads/2024/10/img_0672.jpeg?w=1024" alt=""><figcaption><em>Screen mirroring my iPhone to my Vision Pro while watching a video </em></figcaption></figure>



<p>It’s not the most useful feature, but I did enjoy scrolling through Twitter in pitch darkness when my seat-mate was asleep.</p>



<hr>



<h2 id="conclusion">Conclusion</h2>



<p>I’ll try to summarize my thoughts on Apple Vision Pro as as traveling device.</p>



<p>The first generation Vision Pro is an incredibly vivid showcase of how Apple sees its power users connecting all the devices within their ecosystem to provide a high quality, private, immersive experience, especially in environments that are outside of their typical home/work spaces. </p>



<p>As a travel device, it’s a fantastic platform for watching movies and expanding my MacBook workspace. It has many flaws, which power users (like myself) who are motivated enough to make the most out of their device will find ways of alleviating.</p>



<p>As it stands, as a first generation product that’s heavy, very expensive, and has a very underbaked OS and app ecosystem, I have a tough time recommending anyone to go out and buy one. That being said, I’m taking it on every flight I go on.</p>



<p>But damn, based on how well it all works now, you can just tell by the 4th or 5th generation, Apple Vision Pro will be on the face of every frequent flyer.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Douglas Hofstadter on Lisp (1983) (310 pts)]]></title>
            <link>https://gist.github.com/jackrusher/5139396</link>
            <guid>41858975</guid>
            <pubDate>Wed, 16 Oct 2024 13:44:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://gist.github.com/jackrusher/5139396">https://gist.github.com/jackrusher/5139396</a>, See on <a href="https://news.ycombinator.com/item?id=41858975">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    Hofstadter on Lisp: Atoms and Lists, re-printed in Metamagical Themas.
  </p><div id="file-gistfile1-md">
    <article itemprop="text">
<p dir="auto"><em>In the mid-80s, while reading through my roommate's collection of Scientific American back issues, I encountered this introduction to Lisp written by Douglas Hofstadter. I found it very charming at the time, and provide it here (somewhat illegally) for the edification of a new generation of Lispers.</em></p>
<p dir="auto"><em>In a testament to the timelessness of Lisp, you can still run all the examples below in emacs if you install these aliases:</em></p>
<div dir="auto"><pre>(defalias <span>'</span>plus <span>#'</span><span>+</span>)
(defalias <span>'</span>quotient <span>#'</span><span>/</span>)
(defalias <span>'</span>times <span>#'</span><span>*</span>)
(defalias <span>'</span>difference <span>#'</span><span>-</span>)</pre></div>
<p dir="auto"><h2 dir="auto">Lisp: Atoms and Lists</h2><a id="user-content-lisp-atoms-and-lists" aria-label="Permalink: Lisp: Atoms and Lists" href="#lisp-atoms-and-lists"></a></p>
<p dir="auto">February, 1983</p>
<p dir="auto">IN previous columns I have written quite often about the field of
artificial intelligence - the search for ways to program computers so
that they might come to behave with flexibility, common sense,
insight, creativity, self awareness, humor, and so on. The quest for
AI started in earnest over two decades ago, and since then has
bifurcated many times, so that today it is a very active and
multifaceted research area. In the United States there are perhaps a
couple of thousand people professionally involved in AI, and there are
a similar number abroad. Although there is among these workers a
considerable divergence of opinion concerning the best route to AI,
one thing that is nearly unanimous is the choice of programming
language. Most AI research efforts are carried out in a language
called "Lisp". (The name is not quite an acronym; it stands for "list
processing".)</p>
<p dir="auto">Why is most AI work done in Lisp? There are many reasons, most of
which are somewhat technical, but one of the best is quite simple:
Lisp is crisp. Or as Marilyn Monroe said in The Seven-Year Itch, "I
think it's just elegant!" Every computer language has arbitrary
features, and most languages are in fact overloaded with them. A few,
however, such as Lisp and Algol, are built around a kernel that seems
as natural as a branch of mathematics. The kernel of Lisp has a
crystalline purity that not only appeals to the esthetic sense, but
also makes Lisp a far more flexible language than most others. Because
of Lisp's beauty and centrality in this important area of modern
science, then, I have decided to devote a trio of columns to some of
the basic ideas of Lisp.</p>
<p dir="auto">The deep roots of Lisp lie principally in mathematical logic.
Mathematical pioneers such as Thoralf Skolem, Kurt Godel, and Alonzo
Church contributed seminal ideas to logic in the 1920's and 1930's
that were incorporated decades later into Lisp. Computer programming
in earnest began in the 1940's, but so-called "higher-level"
programming languages (of which Lisp is one) came into existence only
in the 1950's. The earliest list-processing language was not Lisp but
IPL ("Information Processing Language"), developed in the mid-1950's
by Herbert Simon, Allen Newell, and J. C. Shaw. In the years 1956-58,
John McCarthy, drawing on all these previous sources, came up with an
elegant algebraic list-processing language he called Lisp. It caught
on quickly with the young crowd around him at the newly-formed MIT
Artificial Intelligence Project, was implemented on the IBM 704,
spread to other AI groups, infected them, and has stayed around all
these years. Many dialects now exist, but all of them share that
central elegant kernel.</p>
<p dir="auto">Let us now move on to the way Lisp really works. One of the most
appealing features of Lisp is that it is interactive, as contrasted
with most other higher-level languages, which are noninteractive. What
this means is the following. When you want to program in Lisp, you sit
down at a terminal connected to a computer and you type the word
"lisp" (or words to that effect). The next thing you will see on your
screen is a so-called "prompt" - a characteristic symbol such as an
arrow or asterisk. I like to think of this prompt as a greeting spoken
by a special "Lisp genie", bowing low and saying to you, "Your wish is
my command - and now, what is your next wish?" The genie then waits
for you to type something to it. This genie is usually referred to as
the Lisp interpreter, and it will do anything you want but you have to
take great care in expressing your desires precisely, otherwise you
may reap some disastrous effects. Shown below is the prompt, showing
that the Lisp genie is ready to do your bidding:</p>

<p dir="auto">The genie is asking us for our heart's desire, so let us type in a
simple expression:</p>

<p dir="auto">and then a carriage return. (By the way, all Lisp expressions and
words will be printed in Helvetica in this and the following two
chapters.) Even non-Lispers can probably anticipate that the Lisp
genie will print in return. the value 4. Then it will also print a
fresh prompt, so that the screen will now appear this way:</p>

<p dir="auto">The genie is now ready to carry out our next command - or, more
politely stated, our next wish - should we have one. The carrying-out
of a wish expressed as a Lisp statement is called evaluation of that
statement. The preceding short interchange between human and computer
exemplifies the behavior of the Lisp interpreter: it reads a
statement, evaluates it, prints the appropriate value, and then
signals its readiness to read a new statement. For this reason, the
central activity of the Lisp interpreter is referred to as the
read-eval-print loop.</p>
<p dir="auto">The existence of this Lisp genie (the Lisp interpreter) is what makes
Lisp interactive. You get immediate feedback as soon as you have typed
a "wish" - a complete statement - to Lisp. And the way to get a bunch
of wishes carried out is to type one, then ask the genie to carry it
out, then type another, ask the genie again, and so on.</p>
<p dir="auto">By contrast, in many higher-level computer languages you must write
out an entire program consisting of a vast number of wishes to be
carried out in some specified order. What's worse is that later wishes
usually depend strongly on the consequences of earlier wishes - and of
course, you don't get to try them out one by one. The execution of
such a program may, needless to say, lead to many unexpected results,
because so many wishes have to mesh perfectly together. If you've made
the slightest conceptual error in designing your wish list, then a
total foul-up is likely - in fact, almost inevitable. Running a
program of this sort is like launching a new space probe, untested:
you can't possibly have anticipated all the things that might go
wrong, and so all you can do is sit back and watch, hoping that it
will work. If it fails, you go back and correct the one thing the
failure revealed, and then try another launch. Such a gawky, indirect,
expensive way of programming is in marked contrast to the direct,
interactive, one-wish-at-atime style of Lisp, which allows
"incremental" program development and debugging. This is another major
reason for the popularity of Lisp.</p>
<p dir="auto">What sorts of wishes can you type to the Lisp genie for evaluation,
and what sorts of things will it print back to you? Well, to begin
with, you can type arithmetical expressions expressed in a rather
strange way, such as <code>(times (plus 6 3) (difference 6 3))</code>. The answer
to this is 27, since <code>(plus 6 3)</code> evaluates to <code>9</code>, and <code>(difference 6 3)</code>
evaluates to 3, and their product is 27. This notation, in which each
operation is placed to the left of its operands, was invented by the
Polish logician Jan Lukasiewicz before computers existed.
Unfortunately for Lukasiewicz, his name was too formidable-looking for
most speakers of English, and so this type of notation came to be
called Polish notation. Here is a simple problem in this notation for
you, in which you are to play the part of the Lisp genie:</p>
<div dir="auto"><pre><span>&gt;</span> (quotient (plus <span>2113</span>) (difference <span>23</span> (times <span>2</span> (difference <span>7</span> (plus <span>2</span> <span>2</span>)))))</pre></div>
<p dir="auto">Perhaps you have noticed that statements of Lisp involve parentheses.
A profusion of parentheses is one of the hallmarks of Lisp. It is not
uncommon to see an expression that terminates in a dozen right
parentheses! This makes many people shudder at first - and yet once
you get used to their characteristic appearance, Lisp expressions
become remarkably intuitive, even, charming, to the eye, especially
when pretty printed, which means that a careful indentation scheme is
followed that reveals their logical structure. All of the expressions
in displays in this article have been pretty-printed.</p>
<p dir="auto">The heart of Lisp is its manipulable structures. All programs in Lisp
work by creating, modifying, and destroying structures. Structures
come in two types: atomic and composite, or, as they are usually
called, atoms and lists. Thus, every Lisp object is either an atom or
a list (but not both). The only exception is the special object called
nil, which is both an atom and a list. More about nil in a moment.
What are some other typical Lisp atoms? Here are a few:</p>
<p dir="auto"><em>hydrogen, helium, j-s-bach, 1729, 3.14159, pi,
arf, foo, bar, baz, buttons-&amp;-bows</em></p>
<p dir="auto">Lists are the flexible data structures of Lisp. A list is pretty much
what it sounds like: a collection of some parts in a specific order.
The parts of a list are usually called its elements or members. What
can these members be? Well, not surprisingly, lists can have atoms as
members. But just as easily, lists can contain lists as members, and
those lists can in turn contain other lists as members, and so on,
recursively. Oops! I jumped the gun with that word. But no harm done.
You certainly understood what I meant, and it will prepare you for a
more technical definition of the term to come later.</p>
<p dir="auto">A list printed on your screen is recognizable by its parentheses. In
Lisp, anything bounded by matching parentheses constitutes a list. So,
for instance, <code>(zonk blee strill (croak flonk))</code> is a four-element list
whose last element is itself a two-element list. Another short list is
<code>(plus 2 2)</code>, illustrating the fact that Lisp statements themselves are
lists. This is important because it means that the Lisp genie, by
manipulating lists and atoms, can actually construct new wishes by
itself. Thus the object of a wish can be the construction - and
subsequent evaluation - of a new wish!</p>
<p dir="auto">Then there is the empty list - the list with no elements at all. How
is this written down? You might think that an empty pair of
parentheses - () - would work. Indeed, it will work - but there is a
second way of indicating the empty list, and that is by writing nil.
The two notations are synonymous, although nil is more commonly
written than () is. The empty list, nil, is a key concept of Lisp; in
the universe of lists, it is what zero is in the universe of numbers.
To use another metaphor for nil, it is like the earth in which all
structures are rooted. But for you to understand what this means, you
will have to wait a bit.</p>
<p dir="auto">The most commonly exploited feature of an atom is that it has (or can
be given) a value. Some atoms have permanent values, while others are
variables. As you might expect, the value of the atom 1729 is the
integer 1729, and this is permanent. (I am distinguishing here between
the atom whose print name or pname is the four-digit string 1729, and
the eternal Platonic essence that happens to be the sum of two cubes
in two different ways - i.e., the number 1729.) The value of nil is
also permanent, and it is - nil! Only one other atom has itself as its
permanent value, and that is the special atom t.</p>
<p dir="auto">Aside from t, nil, and atoms whose names are numerals, atoms are
generally variables, which means that you can assign values to them
and later change their values at will. How is this done? Well, to
assign the value 4 to the atom pie, you can type to the Lisp genie
<code>(setq pie 4)</code>. Or you could just as well type <code>(setq pie (plus 2 2))</code> -
or even <code>(setq pie (plus 1 1 1 1))</code>. In any of these cases, as soon as
you type your carriage return, pie's value will become 4, and so it
will remain forevermore - or at least until you do another setq
operation on the atom pie.</p>
<p dir="auto">Lisp would not be crisp if the only values atoms could have were
numbers. Fortunately, however, an atom's value can be set to any kind
of Lisp object - any atom or list whatsoever. For instance, we might
want to make the value of the atom pi be a list such as <code>(a b c)</code> or
perhaps <code>(plus 2 2)</code> instead of the number 4. To do the latter, we again
use the setq operation. To illustrate, here follows a brief
conversation with the genie:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> pie (plus <span>2</span> <span>2</span>))
<span>4</span>
<span>&gt;</span> (<span>setq</span> <span>pi</span> <span>'</span>(plus <span>2</span> <span>2</span>))
(plus <span>2</span> <span>2</span>)</pre></div>
<p dir="auto">Notice the vast difference between the values assigned to the atoms
pie and pi as a result of these two wishes asked of the Lisp genie,
which differ merely in the presence or absence of a small but critical
quote mark in front of the inner list <code>(plus 2 2)</code>. In the first wish,
containing no quote mark, that inner <code>(plus 2 2)</code> must be evaluated.
This returns 4, which is assigned to the variable pie as its new
value. On the other hand, in the second wish, since the quote mark is
there, the list <code>(plus 2 2)</code> is never executed as a command, but is
treated merely as an inert lump of Lispstuff, much like meat on a
butcher's shelf. It is ever so close to being "alive", yet it is dead.
So the value of pi in this second case is the list <code>(plus 2 2)</code>, a
fragment of Lisp code. The following interchange with the genie
confirms the values of these atoms.</p>
<div dir="auto"><pre><span>&gt;</span> pie
<span>4</span>
<span>&gt;</span> <span>pi</span>
(plus <span>2</span> <span>2</span>)
<span>&gt;</span> (<span>eval</span> <span>pi</span>)
<span>4</span>
<span>&gt;</span></pre></div>
<p dir="auto">What is this last step? I wanted to show how you can ask the genie to
evaluate the value of an expression, rather than simply printing the
value of that expression. Ordinarily, the genie automatically performs
just one level of evaluation, but by writing eval, you can get a
second stage of evaluation carried out. (And of course, by using eval
over and over again, you can carry this as far as you like.) This
feature often proves invaluable, but it is a little too advanced to
discuss further at this stage.</p>
<p dir="auto">Every list but nil has at least one element. This first element is
called the list's Car. Thus the car of <code>(eval pi)</code> is the atom eval. The
cars of the lists <code>(plus 2 2)</code>, <code>(setq x 17)</code>, <code>(eval pi)</code>, and <code>(car pi)</code> are
all names of operations, or, as they are more commonly called in Lisp,
functions. The car of a list need not be the name of a function; it
need not even be an atom. For instance, <code>((1)(2 2) (3 3 3))</code> is a
perfectly fine list. Its car is the list <code>(1)</code>, whose car in turn is not
a function name but merely a numeral.</p>
<p dir="auto">If you were to remove a list's car, what would remain? A shorter list.
This is called the list's cdr, a word that sounds about halfway
between "kidder" and "could'er". (The words "car" and "cdr" are quaint
relics from the first implementation of Lisp on the IBM 704. The
letters in "car" stand for "Contents of the Address part of Register"
and those in "cdr" for "Contents of the Decrement part of Register
referring to specific hardware features of that machine, now long
since irrelevant.) The cdr of <code>(a b c d)</code> is the list <code>(b c d)</code>, whose cdr
is <code>(c d)</code>, whose cdr is <code>(d)</code>, whose cdr is nil. And nil has no cdr, just
as it has no car. Attempting to take the car or cdr of nil causes (or
should cause) the Lisp genie to cough out an error message, just as
attempting to divide by zero should evoke an error message.</p>
<p dir="auto">Here is a little table showing the car and cdr of a few lists, just to
make sure the notions are unambiguous.</p>
<div dir="auto"><pre><span>list</span>                <span>car</span>          <span>cdr</span>
((a) b (c))         (a)          (b (c))
(plus <span>2</span> <span>2</span>)          plus         (<span>2</span> <span>2</span>)
((<span>car</span> x) (<span>car</span> y))   (<span>car</span> x)      ((<span>car</span> y))
(<span>nil</span> <span>nil</span> <span>nil</span> <span>nil</span>)   <span>nil</span>          (<span>nil</span> <span>nil</span> <span>nil</span>)
(<span>nil</span>)               <span>nil</span>          <span>nil</span>
<span>nil</span>                 **ERROR**    **ERROR**</pre></div>
<p dir="auto">Just as car and cdr are called functions, so the things that they
operate on are called their arguments. Thus in the command <code>(plus pie 2)</code>,
plus is the function name, and the arguments are the atoms pie and
2. In evaluating this command (and most commands), the genie figures
out the values of the arguments, and then applies the function to
those values. Thus, since the value of the atom pie is 4, and the
value of the atom 2 is 2, the genie returns the atom 6.</p>
<hr>
<p dir="auto">Suppose you have a list and you'd like to see a list just like it,
only one element longer. For instance, suppose the value of the atom x
is <code>(cake cookie)</code> and you'd like to create a new list called y just
like x, except with an extra atom-say pie - at the front. You can then
use the function called cons (short for "construct"), whose effect is
to make a new list out of an old list and a suggested car. Here's a
transcript of such a process:</p>
<div dir="auto"><pre><span>&gt;</span>(<span>setq</span> x <span>'</span>(cake cookie))
(cake cookie)
<span>&gt;</span>(<span>setq</span> y (<span>cons</span> <span>'</span>pie x))
(pie cake cookie)
<span>&gt;</span> x
(cake cookie)</pre></div>
<p dir="auto">Two things are worth noticing here. I asked for the value of x to be
printed out after the cons operation, so you could see that x itself
was not changed by the cons. The cons operation created a new list and
made that list be the value of y, but left x entirely alone. The other
noteworthy fact is that I used that quote mark again, in front of the
atom pie. What if I had not used it? Here's what would have happened.</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> z (<span>cons</span> pie x))
(<span>4</span> cake cookie)</pre></div>
<p dir="auto">Remember, after all, that the atom pie still has the value 4, and
whenever the genie sees an unquoted atom inside a wish, it will always
use the value belonging to that atom, rather than the atom's name.
(Always? Well, almost always. I'll explain in a moment. In the
meantime, look for an exception - you've already encountered it.)</p>
<p dir="auto">Now here are a few exercises - some a bit tricky - for you. Watch out
for the quote marks! Oh, one last thing: I use the function reverse,
which produces a list just like its argument, only with its elements
in reverse order. For instance, the genie, upon being told <code>(reverse '((a b) (c d e)))</code> will write <code>((c d e) (a b))</code>. The genie's lines in
this dialogue are given afterward.</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> w (<span>cons</span> pie <span>'</span>(<span>cdr</span> z)))
<span>&gt;</span> (<span>setq</span> v (<span>cons</span> <span>'</span>pie (<span>cdr</span> z)))
<span>&gt;</span> (<span>setq</span> u (<span>reverse</span> v))
<span>&gt;</span> (<span>cdr</span> (<span>cdr</span> u))
<span>&gt;</span> (<span>car</span> (<span>cdr</span> u))
<span>&gt;</span> (<span>cons</span> (<span>car</span> (<span>cdr</span> u)) u)
<span>&gt;</span> u
<span>&gt;</span> (<span>reverse</span> <span>'</span>(<span>cons</span> (<span>car</span> u) (<span>reverse</span> (<span>cdr</span> u))))
<span>&gt;</span> (<span>reverse</span> (<span>cons</span> (<span>car</span> u) (<span>reverse</span> (<span>cdr</span> u))))
<span>&gt;</span> u
<span>&gt;</span> (<span>cons</span> <span>'</span>cookie (<span>cons</span> <span>'</span>cake (<span>cons</span> <span>'</span>pie <span>nil</span>)))</pre></div>
<p dir="auto">Answers (as printed by the genie):</p>
<div dir="auto"><pre>(<span>4</span> <span>cdr</span> z)
(pie cake cookie)
(cookie cake pie)
(pie)
cake
(cake cookie cake pie)
(cookie cake pie)
((<span>reverse</span> (<span>cdr</span> u)) (<span>car</span> u) <span>cons</span>)
(cake pie cookie)
(cookie cake pie)
(cookie cake pie)</pre></div>
<p dir="auto">The last example, featuring repeated use of cons, is often called, in
Lisp slang "consing up a list". You start with nil, and then do
repeated cons operations. It is analogous to building a positive
integer by starting at zero and then performing the successor
operation over and over again. However, whereas at any stage in the
latter process there is a unique way of performing the successor
operation, given any list there are infinitely many different items
you can cons onto it, thus giving rise to a vast branching tree of
lists instead of the unbranching number line. It is on account of this
image of a tree growing out of the ground of nil and containing all
possible lists that I earlier likened nil to "the earth in which all
structures are rooted".</p>
<p dir="auto">As I mentioned a moment ago, the genie doesn't always replace
(unquoted) atoms by their values. There are cases where a function
treats its arguments, though unquoted, as if quoted. Did you go back
and find such a case? It's easy. The answer is the function setq. In
particular, in a setq command, the first atom is taken straight-not
evaluated. As a matter of fact, the q in setq stands for "quote",
meaning that the first argument is treated as if quoted. Things can
get quite tricky when you learn about set, a function similar to setq
except that it does evaluate its first argument. Thus, if the value of
the atom x is the atom k, then saying <code>(set x 7)</code> will not do anything
to x-its value will remain the atom k-but the value of the atom k will
now become 7. So watch closely:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>setq</span> a <span>'</span>b)
<span>&gt;</span> (<span>setq</span> b <span>'</span>c)
<span>&gt;</span> (<span>setq</span> c <span>'</span>a)
<span>&gt;</span> (<span>set</span> a c)
<span>&gt;</span> (<span>set</span> c b)</pre></div>
<p dir="auto">Now tell me: What are the values of the atoms a, b, and c? Here comes
the answer, so don't peek. They are, respectively: a, a, and a. This
may seem a bit confusing. You may be reassured to know that in Lisp,
set is not very commonly used, and such confusions do not arise that
often.</p>
<p dir="auto">Psychologically, one of the great powers of programming is the ability
to define new compound operations in terms of old ones, and to do this
over and over again, thus building up a vast repertoire of ever more
complex operations. It is quite reminiscent of evolution, in which
ever more complex molecules evolve out of less complex ones, in an
ever-upward spiral of complexity and creativity. It is also quite
reminiscent of the industrial revolution, in which people used very
simple early machines to help them build more complex machines, then
used those in turn to build even more complex machines, and so on,
once again in an ever-upward spiral of complexity and creativity. At
each stage, whether in evolution or revolution, the products get more
flexible and more intricate, more "intelligent" and yet more
vulnerable to delicate "bugs" or breakdowns.</p>
<p dir="auto">Likewise with programming in Lisp, only here the "molecules" or
"machines" are now Lisp functions defined in terms of previously known
Lisp functions. Suppose, for instance, that you wish to have a
function that will always return the last element of a list, just as
car always returns the first element of a list. Lisp does not come
equipped with such a function, but you can easily create one. Do you
see how? To get the last element of a list called lyst, you simply do
a reverse on lyst and then take the car of that: <code>(car (reverse lyst))</code>.
To dub this operation with the name rac (car backwards), we use the
def function, as follows:</p>
<div dir="auto"><pre><span>&gt;</span> (def rac (<span>lambda</span> (lyst) (<span>car</span> (<span>reverse</span> lyst))))</pre></div>
<p dir="auto">Using def this way creates a function definition. In it, the word
lambda followed by (lyst) indicates that the function we are defining
has only one parameter, or dummy variable, to be called lyst. (It
could have been called anything; I just happen to like the atom lyst.)
In general, the list of parameters (dummy variables) must immediately
follow the word lambda. After this "def wish" has been carried out,
the rac function is as well understood by the genie as is car. Thus
<code>(rac '(your brains))</code> will yield the atom <code>brains</code>. And we can use rac
itself in definitions of yet further functions. The whole thing
snowballs rather miraculously, and you can quickly become overwhelmed
by the power you wield.</p>
<p dir="auto">Here is a simple example. Suppose you have a situation where you know
you are going to run into many big long lists and you know it will
often be useful to form, for each such long list, a short list that
contains just its car and rac. We can define a one-parameter function
to do this for you:</p>
<div dir="auto"><pre><span>&gt;</span> (def readers-digest-condensed-version
    (<span>lambda</span> (biglonglist)
     (<span>cons</span> (<span>car</span> biglonglist) (<span>cons</span> (rac biglonglist) <span>nil</span>))))</pre></div>
<p dir="auto">Thus if we apply our new function readers-digest-condensed-version to
the entire text of James Joyce's Finnegans Wake (treating it as a big
long list of words), we will obtain the shorter list <code>(riverrun the)</code>.
Unfortunately, reapplying the condensation operator to this new list
will not simplify it any further.</p>
<p dir="auto">It would be nice as well as useful if we could create an inverse
operation to readers-digest-condensed-version called rejoyce that,
given any two words, would create a novel beginning and ending with
them, respectively - and such that James Joyce would have written it
(had he thought of it). Thus execution of the Lisp statement
<code>(rejoyce 'Stately 'Yes)</code> would result in the Lisp genie generating from
scratch the entire novel Ulysses. Writing this function is left as an
exercise for the reader. To test your program, see what it does with
<code>(rejoyce 'karma 'dharma)</code>.</p>
<p dir="auto">One goal that has seemed to some people to be both desirable and
feasible using Lisp and related programming languages is (1) to make
every single statement return a value and (2) to have it be through
this returned value and only through it that the statement has any
effect. The idea of (1) is that values are handed "upward" from the
innermost function calls to the outermost ones, until the full
statement's value is returned to you. The idea of (2) is that during
all these calls, no atom has its value changed at all (unless the atom
is a dummy variable). In all dialects of Lisp known to me, (1) is
true, but (2) is not necessarily true.</p>
<p dir="auto">Thus if x is bound to <code>(a b c d e)</code> and you say <code>(car (cdr (reverse x)))</code>,
the first thing that happens is that <code>(reverse x)</code> is calculated; then
this value is handed "up" to the cdr function, which calculates the
cdr of that list; finally, this shorter list is handed to the car
function, which extracts one element-namely the atom d-and returns it.
In the meantime, the atom x has suffered no damage; it is still bound
to <code>(a b c d e)</code>.</p>
<p dir="auto">It might seem that an expression such as <code>(reverse x)</code> would change the
value of x by reversing it, just as carrying out the oral command
"Turn your sweater inside out" will affect the sweater. But actually,
carrying out the wish <code>(reverse x)</code> no more changes the value of x than
carrying out the wish <code>(plus 2 2)</code> changes the value of 2. Instead,
executing <code>(reverse x)</code> causes a new (unnamed) list to come into being,
just like x, only reversed. And that list is the value of the
statement; it is what the statement returns. The value of x itself,
however, is untouched. Similarly, evaluating <code>(cons 5 pi)</code> will not
change the list named pi in the slightest; it merely returns a new
list with 5 as its car and whatever pi's value is as its cdr.</p>
<p dir="auto">Such behavior is to be contrasted with that of functions that leave
"side effects" in their wake. Such side effects are usually in the
form of changed variable bindings, although there are other
possibilities, such as causing input or output to take place. A
typical "harmful" command is a setq, and proponents of the
"applicative" school of programming - the school that says you should
never make any side effects whatsoever - are profoundly disturbed by
the mere mention of setq. For them, all results must come about purely
by the way that functions compute their values and hand them to other
functions.</p>
<p dir="auto">The only bindings that the advocates of the applicative style approve
of are transitory "lambda bindings" - those that arise when a function
is applied to its arguments. Whenever any function is called, that
function's dummy variables temporarily assume "lambda bindings". These
bindings are just like those caused by a setq, except that they are
fleeting. That is, the moment the function is finished computing, they
go away - vanishing without a trace. For example, during the
computation of <code>(rac '(a b c))</code>, the lambda binding of the dummy
variable lyst is the list <code>(a b c)</code>; but as soon as the answer c is
passed along to the function or person that requested the rac, the
value of the atom lyst used in getting that answer is totally
forgotten. The Lisp interpreter will tell you that lyst is an "unbound
atom" if you ask for its value. Applicative programmers much prefer
lambda bindings to ordinary setq bindings.</p>
<p dir="auto">I personally am not a fanatic about avoiding setq's and other
functions that cause side effects. Though I find the applicative style
to be jus-telegant, I find it impractical when it comes to the
construction of large AI-style programs. Therefore I shall not
advocate the applicative style here, though I shall adhere to it when
possible. Strictly speaking, in applicative programming, you cannot
even define new functions, since a def statement causes a permanent
change to take place in the genie's memory - namely, the permanent
storage in memory of the function definition. So the ideal applicative
approach would have functions, like variable bindings, being created
only temporarily, and their definitions would be discarded the moment
after they had been used. But this is extreme "applicativism".</p>
<p dir="auto">For your edification, here are a few more simple function definitions.</p>
<div dir="auto"><pre><span>&gt;</span> (def rdc (<span>lambda</span> (lyst) (<span>reverse</span> (<span>cdr</span> (<span>reverse</span> lyst)))))
<span>&gt;</span> (def snoc (<span>lambda</span> (x lyst) (<span>reverse</span> (<span>cons</span> x (<span>reverse</span> lyst)))))
<span>&gt;</span> (def twice (<span>lambda</span> (n) (plus n n)))</pre></div>
<p dir="auto">The functions rdc and snoc are analogous to cdr and cons, only
backwards. Thus, the rdc of <code>(a b c d e)</code> is <code>(a b c d)</code>, and if you type
<code>(snoc 5 '(1 2 3 4))</code>, you will get <code>(1 2 3 4 5)</code> as your answer.</p>
<p dir="auto">All of this is mildly interesting so far, but if you want to see the
genie do anything truly surprising, you have to allow it to make some
decisions based on things that happen along the way. These are
sometimes called "conditional wishes". A typical example would be the
following:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>cond</span> ((<span>eq</span> x <span>1</span>) <span>'</span>land) ((<span>eq</span> x <span>2</span>) <span>'</span>sea))</pre></div>
<p dir="auto">The value returned by this statement will be the atom land if x has
value 1, and the atom sea if x has value 2. Otherwise, the value
returned will be nil (i.e., if x is 5). The atom eq (pronounced "eek")
is the name of a common Lisp function that returns the atom t
(standing for "true") if its two arguments have the same value, and
nil (for "no" or "false") if they do not.</p>
<p dir="auto">A cond statement is a list whose car is the function name cond,
followed by any number of cond clauses, each of which is a two-element
list. The first element of each clause is called its condition, the
second element its result. The clauses' conditions are checked out by
the Lisp genie one by one, in order; as soon as it finds a clause
whose condition is "true" (meaning that the condition returns anything
other than nil!), it begins calculating that clause's result, whose
value gets returned as the value of the whole cond statement. None of
the further clauses is even so much as glanced at! This may sound more
complex than it ought to. The real idea is no more complex than saying
that it looks for the first condition that is satisfied, then it
returns the corresponding result.</p>
<p dir="auto">Often one wants to have a catch-all clause at the end whose condition
is sure to be satisfied, so that, if all other conditions fail, at
least this one will be true and the accompanying result, rather than
nil, will be returned. It is easy as pie to make a condition whose
value is non-nil; just choose it to be t for instance, as in the
following:</p>
<div dir="auto"><pre>(<span>cond</span> ((<span>eq</span> x <span>1</span>) <span>'</span>land)
      ((<span>eq</span> x <span>2</span>) <span>'</span>sea)
       (<span>t</span> <span>'</span>air))</pre></div>
<p dir="auto">Depending on what the value of x is, we will get either land, sea, or
air as the value of this cond, but we'll never get nil. Now here are a
few sample cond statements for you to play genie to:</p>
<div dir="auto"><pre><span>&gt;</span> (<span>cond</span> ((<span>eq</span> (oval <span>pi</span>) pie) (oval (snot pie <span>pi</span>)))
(<span>t</span> (<span>eval</span> (snoc (rac <span>pi</span>) <span>pi</span>))))
<span>&gt;</span> (<span>cond</span> ((<span>eq</span> <span>2</span> <span>2</span>) <span>2</span>) ((<span>eq</span> <span>3</span> <span>3</span>) <span>3</span>))
<span>&gt;</span> (<span>cond</span> (<span>nil</span> <span>'</span>no-no-no)
((<span>eq</span> <span>'</span>(<span>car</span> <span>nil</span>) <span>'</span>(<span>cdr</span> <span>nil</span>)) <span>'</span>hmmm)
(<span>t</span> <span>'</span>yes-yes-yes))</pre></div>
<p dir="auto">The answers are: 8, 2, and yes-yes-yes. Did you notice that <code>(car nil)</code>
and <code>(cdr nil)</code> were quoted?</p>
<p dir="auto">I shall close this portion of the column by displaying a patterned
family of function definitions, so obvious in their pattern that you
would think that the Lisp genie would just sort of "get the hang of
it" after seeing the first few... Unfortunately, though, Lisp genies
are frustratingly dense (or at least they play at being dense), and
they will not jump to any conclusion unless it has been completely
spelled out. Look first at the family:</p>
<div dir="auto"><pre><span>&gt;</span> (def square (<span>lambda</span> (k) (times k k)))
<span>&gt;</span> (def cube (<span>lambda</span> (k) (times k (square k))))
<span>&gt;</span> (def 4th-power (<span>lambda</span> (k) (times k (cube k))))
<span>&gt;</span> (def 5th-power (<span>lambda</span> (k) (times k (4th-power k))))
<span>&gt;</span> (def 6th-power (<span>lambda</span> (k) (times k (5th-power k))))
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span>
<span>&gt;</span> <span>.</span></pre></div>
<p dir="auto">My question for you is this: Can you invent a definition for a two
parameter function that subsumes all of these in one fell swoop? More
concretely, the question is: How would one go about defining a
two-parameter function called power such that, for instance, <code>(power 9 3)</code>
yields 729 on being evaluated, and <code>(power 7 4)</code> yields 2,401 ? I
have supplied you, in this column, with all the necessary tools to do
this, provided you exercise some ingenuity.</p>
<p dir="auto">I thought I would end this column with a newsbreak about a freshly
discovered beast - the homely Glazunkian porpuquine, so called because
it is found only on the island of Glazunkia (claimed by Upper Bitbo,
though it is just off the coast of Burronymede). And what is a
porpuquine, you ask? Why, it's a strange breed of porcupine, whose
quills - of which, for some reason, there are always exactly nine (in
Outer Glazunkia) or seven (in Inner Glazunkia) - are smaller
porpuquines. Oho! This would certainly seem to be an infinite regress!
But no. It's just that I forgot to mention that there is a smallest
size of porpuquine: the zero-inch type, which, amazingly enough, is
totally bald of quills. So, quite luckily (or perhaps unluckily,
depending on your point of view), that puts a stop to the threatened
infinite regress. This remarkable beast is shown in a rare photograph
in Figure 17-1.</p>
<p dir="auto">Students of zoology might be interested to learn that the quills on
5-inch porpuquines are always 4-inch porpuquines, and so on down the
line. And students of anthropology might be equally intrigued to know
that the residents of Glazunkia (both Outer and Inner) utilize the
nose (yes, the nose) of the zero-inch porpuquine as a unit of barter -
an odd thing to our minds; but then, who are you and I to question the
ancient wisdom of the Outer and Inner Glazunkians? Thus, since a
largish porpuquine - say a 3-incher or 4-incher - contains many, many
such tiny noses, it is a most valuable commodity. The value of a
porpuquine is sometimes referred to as its "buying power", or just
"power" for short. For instance, a 2-incher found in Inner Glazunkia
is almost twice as powerful as a 2-incher found in Outer Glazunkia. Or
did I get it backward? It's rather confusing!</p>
<p dir="auto">Anyway, why am I telling you all this? Oh, I just thought you'd like
to hear about it. Besides, who knows? You just might wind up visiting
Glazunkia (Inner or Outer) one of these fine days. And then all of
this could come in mighty handy.</p>
<hr>
<p dir="auto"><em>I hope you enjoyed Hofstadter's idiosyncratic tour of Lisp. You can find more like this re-printed in his book <a href="https://en.wikipedia.org/wiki/Metamagical_Themas" rel="nofollow">Metamagical Themas</a>.</em></p>
</article>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon buys stake in nuclear energy developer in push to power data centres (124 pts)]]></title>
            <link>https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911</link>
            <guid>41858863</guid>
            <pubDate>Wed, 16 Oct 2024 13:32:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911">https://www.ft.com/content/00776191-b010-4104-add4-8dc430386911</a>, See on <a href="https://news.ycombinator.com/item?id=41858863">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><a data-trackable="a11y-skip-to-help" href="https://www.ft.com/accessibility">Accessibility help</a><a data-trackable="a11y-skip-to-navigation" href="#site-navigation">Skip to navigation</a><a data-trackable="a11y-skip-to-content" href="#site-content">Skip to content</a><a data-trackable="a11y-skip-to-footer" href="#site-footer">Skip to footer</a></p><div id="barrier-page"><div id="heroOffer-Hero offer-9e54fac2-5972-41eb-b33d-6fa67be1b59b" data-component="heroOffer" data-component-unique-name="Hero offer"><div data-o-grid-colspan="12 L6"><p><span></span><span></span><span></span><span>Subscribe to unlock this article</span><span></span></p></div><div data-o-grid-colspan="12 L6"><p><h2><span>Limited time offer</span></h2><h2><strong><span>Save 50% on Standard Digital</span></strong></h2></p><p><span>was </span><span>CHF660</span><span> </span><span>now </span><span>CHF329</span><span> for your first year, equivalent to </span><span>CHF27.42</span><span> per month.
Make up your own mind. Build robust opinions with the FT’s trusted journalism.
Take this offer before 24 October.</span></p></div></div><div id="recommendedOffers-Recommended offers-6615b5d2-334c-4624-9cac-70c882e3db14" data-component="recommendedOffers" data-component-unique-name="Recommended offers"><p><h2 data-o-grid-colspan="12">Explore more offers.</h2></p><div data-o-grid-colspan="12"><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_trial.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF1</span><span> for 4 weeks</span></p><p><span>Then </span><span>CHF85</span><span> per month. Complete digital access to quality FT journalism. Cancel anytime during your trial.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_weekend_premium.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF85</span><span> per month</span></p><p><span>Get Premium &amp; FT Weekend Print edition for the price of Premium. Complete digital access to quality analysis and expert insights, complemented with our award-winning Weekend Print edition.</span></p></div><div data-o-grid-colspan="12"><div><p><img src="https://www.ft.com/__origami/service/image/v2/images/raw/https://barrier-page-components.s3.eu-west-1.amazonaws.com/assets/icons/primary_product_icon_print.svg?source=next-barrier-page&amp;format=svg" alt=""></p></div><p><span>CHF345</span><span> for your first year</span></p><p><span>FT newspaper delivered Monday-Saturday, plus FT Digital Edition delivered to your device Monday-Saturday.</span></p></div></div></div><div data-component="subscriptionOptions" data-component-unique-name="Subscription options"><h2>Explore our full range of subscriptions.</h2><div><div><p>Discover all the plans currently available in your country</p></div><div><p>Digital access for organisations. Includes exclusive features and content.</p></div></div></div><div data-component="whyFT" data-component-unique-name="Why FT"><div><h2>Why the FT?</h2><p>See why over a million readers pay to read the Financial Times.</p></div><p><a href="https://subs.ft.com/whytheft?ft-content-uuid=00776191-b010-4104-add4-8dc430386911">Find out why</a></p></div></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FTC Announces "Click-to-Cancel" Rule Making It Easier to Cancel Subscriptions (1288 pts)]]></title>
            <link>https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring</link>
            <guid>41858665</guid>
            <pubDate>Wed, 16 Oct 2024 13:09:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring">https://www.ftc.gov/news-events/news/press-releases/2024/10/federal-trade-commission-announces-final-click-cancel-rule-making-it-easier-consumers-end-recurring</a>, See on <a href="https://news.ycombinator.com/item?id=41858665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The Federal Trade Commission today announced a <a href="https://www.ftc.gov/legal-library/browse/federal-register-notices/negative-option-rule-final-rule" data-entity-type="node" data-entity-uuid="f9ee6fe1-5b17-4316-8a19-52ae35e0302e" data-entity-substitution="canonical">final “click-to-cancel” rule</a> that will require sellers to make it as easy for consumers to cancel their enrollment as it was to sign up. Most of the final rule’s provisions will go into effect 180 days after it is published in the Federal Register.</p><p>“Too often, businesses make people jump through endless hoops just to cancel a subscription,” said Commission Chair Lina M. Khan. “The FTC’s rule will end these tricks and traps, saving Americans time and money. Nobody should be stuck paying for a service they no longer want.”</p><a href="https://www.ftc.gov/system/files/ftc_gov/images/negoptions-1page-oct2024-thumb-v2_0.png">
<article>
  
      
  </article>
</a><p>The Commission’s updated rule will apply to almost all negative option programs in any media. The rule also will prohibit sellers from misrepresenting any material facts while using negative option marketing; require sellers to provide important information before obtaining consumers’ billing information and charging them; and require sellers to get consumers’ informed consent to the negative option features before charging them.</p><p>The final rule announced today is part of the FTC’s ongoing review of its 1973 Negative Option Rule, which the agency is modernizing to combat unfair or deceptive practices related to subscriptions, memberships, and other recurring-payment programs in an increasingly digital economy where it’s easier than ever for businesses to sign up consumers for their products and services.</p><p>Commission approval and publication follows the&nbsp;<a href="https://www.ftc.gov/news-events/news/press-releases/2023/03/federal-trade-commission-proposes-rule-provision-making-it-easier-consumers-click-cancel-recurring">March 2023 announcement of a notice of proposed rulemaking</a> which resulted in more than 16,000 comments from consumers and federal and state government agencies, consumer groups, and trade associations.</p><p>While negative option marketing programs can be convenient for&nbsp;sellers and consumers,&nbsp;the FTC receives thousands of complaints about negative option and recurring subscription practices each year. The number of complaints has been steadily increasing over the past five years and in 2024 the Commission received nearly 70 consumer complaints per day on average, up from 42 per day in 2021.</p><p>The final rule will provide a consistent legal framework by prohibiting sellers from:</p><ul><li>misrepresenting any material fact made while marketing goods or services with a negative option feature;</li><li>failing to clearly and conspicuously disclose material terms prior to obtaining a consumer’s billing information in connection with a negative option feature;</li><li>failing to obtain a consumer’s express informed consent to the negative option feature before charging the consumer; and</li><li>failing to provide a simple mechanism to cancel the negative option feature and immediately halt charges.</li></ul><p>Following an evaluation of public comments, the Commission has voted to adopt a final rule with certain changes, most notably dropping a requirement that sellers provide annual reminders to consumers of the negative option feature of their subscription, and dropping a prohibition on sellers telling consumers seeking to cancel their subscription about plan modifications or reasons to keep to their existing agreement without first asking if they want to hear about them.</p><p>The Commission vote approving publication of the final rule in the Federal Register was&nbsp;3-2, with Commissioners Melissa&nbsp;Holyoak and Andrew N.&nbsp;Ferguson voting no. Commissioner Rebecca Kelly Slaughter <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/statement-commissioner-rebecca-kelly-slaughter-regarding-final-trade-regulation-rule-concerning" data-entity-type="node" data-entity-uuid="55347a75-1471-4b9c-b8bf-060d50eb8cd9" data-entity-substitution="canonical">issued a separate statement</a> and Commissioner Holyoak <a href="https://www.ftc.gov/legal-library/browse/cases-proceedings/public-statements/dissenting-statement-commissioner-melissa-holyoak-re-negative-option-rule" data-entity-type="node" data-entity-uuid="744ff40f-0d01-47d6-be80-78cf755c20cc" data-entity-substitution="canonical">issued a separate dissenting statement</a>.</p><p>FTC staff has developed a&nbsp;<a href="https://www.ftc.gov/system/files/ftc_gov/pdf/NegOptions-1page-Oct2024-v2.pdf">fact sheet</a> summarizing the changes to the rule.&nbsp;The primary staffer on this matter is Katherine Johnson in the FTC’s Bureau of Consumer Protection.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Internet Archive is back online (320 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/</link>
            <guid>41857754</guid>
            <pubDate>Wed, 16 Oct 2024 11:09:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/">https://arstechnica.com/tech-policy/2024/10/the-internet-archive-and-its-916-billion-saved-webpages-are-back-online/</a>, See on <a href="https://news.ycombinator.com/item?id=41857754">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Last week, hackers defaced the Internet Archive website with a message that said, "Have you ever felt like the Internet Archive runs on sticks and is constantly on the verge of suffering a catastrophic security breach? It just happened. See 31 million of you on HIBP!"</p>
<p>HIBP is a reference to <a href="https://haveibeenpwned.com/">Have I Been Pwned</a>, which was created by security researcher Troy Hunt and provides information and notifications on data breaches. The hacked Internet Archive data was sent to Have I Been Pwned and "contains authentication information for registered members, including their email addresses, screen names, password change timestamps, Bcrypt-hashed passwords, and other internal data," <a href="https://www.bleepingcomputer.com/news/security/internet-archive-hacked-data-breach-impacts-31-million-users/">BleepingComputer wrote</a>.</p>
<p>Kahle <a href="https://x.com/brewster_kahle/status/1844183111514603812">said on October 9</a> that the Internet Archive fended off a DDoS attack and was working on upgrading security in light of the data breach and website defacement. The next day, he <a href="https://x.com/brewster_kahle/status/1844326137499177312">reported</a> that the "DDoS folks are back" and had knocked the site offline. The Internet Archive "is being cautious and prioritizing keeping data safe at the expense of service availability," he added.</p>
<p>"Services are offline as we examine and strengthen them... Estimated Timeline: days, not weeks," he <a href="https://x.com/brewster_kahle/status/1844790609573277792">wrote</a> on October 11. "Thank you for the offers of pizza (we are set)."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Floss/fund: $1M per year for free and open source projects (376 pts)]]></title>
            <link>https://floss.fund/blog/announcing-floss-fund/</link>
            <guid>41857032</guid>
            <pubDate>Wed, 16 Oct 2024 09:02:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://floss.fund/blog/announcing-floss-fund/">https://floss.fund/blog/announcing-floss-fund/</a>, See on <a href="https://news.ycombinator.com/item?id=41857032">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    
    <article>
      <div>
        <div>
              <p><img src="https://avatars1.githubusercontent.com/u/547147?s=64&amp;v=4" alt="Kailash Nadh photo">
              </p>
              <div>
                <p><span>Kailash Nadh</span>
                <span>CTO @ Zerodha</span></p><p><a href="https://nadh.in/"><img src="https://floss.fund/static/ico-www.svg" alt="Homepage link"></a>
                  
                  
                    <a href="https://github.com/knadh"><img src="https://floss.fund/static/ico-github.svg" alt="GitHub link"></a>
                  
                </p>
              </div>
            </div><!-- meta -->

        <div>
          
          <p>15 Oct 2024</p>

          <p>TLDR; <a href="https://dir.floss.fund/submit">Apply now</a></p>
<hr>
<p>We are excited to announce the launch of a dedicated fund aimed at providing financial assistance to Free/Libre and Open Source Software (FOSS/FLOSS) projects globally, with an annual commitment of $1 million. I will use the FOSS acronym in this post hereafter.</p>
<p>This has been in the works for some time at Zerodha<sup><a href="https://zerodha.com/">[↗]</a></sup>, where we have been developing financial technology products and services built on an ever-growing FOSS stack. Without the high-quality FOSS projects that we have freely downloaded and used to build our organisation, products, and services, we would not exist as we do today—free as in both cost and freedom. A significant portion of our success and growth is owed to FOSS, encompassing everything from programming languages to operating systems, to databases, web servers, frontend frameworks, productivity tools, code editors, and absolutely everything. It goes without saying that this holds true for nearly every technology company founded in the last decade, whether it is publicly acknowledged or not.</p>
<p>And yet, funding and financial sustainability, the lack thereof really, has been an increasingly hot topic over the last many years. Well, at least since <em>cloud</em> companies began making massive profits directly repackaging FOSS projects built by hobbyists and communities. The rise of the "open core" model and the unfortunate license changes in many good open projects recently, are clear signs of this growing turmoil. Many potential solutions seem to be emerging and evoling—commercial services, Venture Capital (VC) funding, and programs like GitHub Sponsors<sup><a href="https://github.com/sponsors">[↗]</a></sup>, Open Collective<sup><a href="https://opencollective.com/">[↗]</a></sup>, FUTO<sup><a href="https://futo.org/">[↗]</a></sup>, Polar<sup><a href="https://polar.sh/">[↗]</a></sup>, and <em>Buy me a coffee</em><sup><a href="https://buymeacoffee.com/">[↗]</a></sup>, amongst others. That said, Python libraries raising massive amounts of VC funding in quick time does not look like a healthy trend.</p>
<p>Why are we here, though? The fundamental tenets of FOSS, the spirit of hacking, liberty, and reciprocity, while they have worked beautifully with code, have translated poorly into the highly commercial <em>BigTech</em> era. So far, it has been nearly impossible to quantify and structure ideas of goodwill and reciprocity into financial sustenance for FOSS projects. I recall the log4j incident from a couple of years ago which unleashed a spate of philosophical debates around  FOSS, in which I also participated<sup><a href="https://nadh.in/blog/open-source-is-not-broken/">[↗]</a></sup>, rather ideologically.</p>
<p>For us, FLOSS/fund is about hacker goodwill, reciprocity, and common sense business strategy. We invite you to <a href="https://dir.floss.fund/submit">apply for funding</a>. If you would like to understand the motivations behind this, a bit of storytelling lies ahead.</p>
<h2 id="prelude">Prelude</h2>
<p>The very first thing I did when we started Zerodha Tech more than a decade ago was to install Python and start scripting and automating time-consuming, mundane organisational tasks. Then came Postgres for building a small data warehouse, followed by PHP and WordPress for managing our website. From there, as we slowly grew the organisation, our technology stack expanded one piece of FOSS at a time, eventually leading to us becoming the largest stock broker in India several years later. Personally, my mental markup as a software developer and hacker is rooted in the simple act of copy-pasting open source code from the internet to hack, tinker, learn, and solve problems. An alternate vision is very difficult for me to comprehend, and a non-FOSS path to building technology, let alone an organisation, has never seemed logical.</p>
<p>At Zerodha, over the years, we have contributed upstream to many projects that we use, as well as spun off and released several small and large FOSS projects<sup><a href="https://zerodha.tech/">[↗]</a></sup> from our work. In 2019, we made a sizeable investment in ERPNext<sup><a href="https://erpnext.com/">[↗]</a></sup>, a FOSS ERP that we had begun using extensively. In 2020, we co-founded the FOSS United Foundation<sup><a href="https://fossunited.org/">[↗]</a></sup>, which works on developing the FOSS ecosystem in India, and backed the creation of TinkerSpace<sup><a href="https://www.tinkerhub.org/tinkerspace">[↗]</a></sup>, a physical hackerspace and community center that hosts FOSS tinkering for young people. In 2023, we were a founding member of OASIS (Open-Source Alliance for Social Innovation and Sustainability)<sup><a href="https://oasishq.org/">[↗]</a></sup>, which focuses on FOSS capacity building and adoption in social sector non-profit organisations. Many of us from our team also volunteer at non-profits, helping drive meaningful FOSS adoption in the development sector, where even basic technological requirements are woefully unmet. We fund many of these initiatives with long-term commitments.</p>
<p>In addition, we have given out many sizeable grants to FOSS projects and organisations in India. While funding projects outside India involves significant paperwork and operational overhead, we have reached out to several small and large projects that we use at work and have managed to pay them. This highly ad hoc approach is something that has increasingly bugged me though.</p>
<p>While it is good to provide financial support to FOSS-aligned activities, most importantly, money ought to go directly to the source—invaluable FOSS projects. We have managed to build a commercially successful business on top of FOSS that we have freely, in both cost and freedom, adopted from all over the world. Therefore, "ad hoc" and "reaching out" simply do not suffice—we have to shut up or put up.</p>
<h2 id="thus-structure">Thus, structure.</h2>
<p>And that is how the idea of a structured, dedicated fund for FOSS projects globally, was born. We spent several months speaking to various banks, payment processors, and lawyers to finally arrive at a reasonably streamlined process. The fund will:</p>
<ul>
<li>Have a small, dedicated team to operate it properly in a non-adhoc manner, functioning like an OSPO (Open Source Program Office) but focused on funding projects—an OSFO (Open Source Funding Office), perhaps?</li>
<li>Put money where the mouth is—a minimum of $10,000 and up to $100,000 for a single recipient, totaling $1 million per year, which we will increase once we understand the dynamics of running the fund.</li>
<li>Source applications globally, relying on incoming applications through for discovering projects in need of support rather than the limited visibility we have as a small team.</li>
<li>Form an interim internal selection committee to make discretionary selections. Once potential edge cases and any gotchas in running the program are handled, we will attempt to establish a public selection committee from the FOSS ecosystem with a community voting process for applications.</li>
</ul>
<h2 id="more-structure-funding-json">More structure: funding.json</h2>
<p>Expanding a bit on "ad hoc" and "reaching out" I mentioned earlier, the  majority of our experience paying projects has transpired like this:</p>
<p>On a random day, we realise that a certain FOSS project has become very useful to us. After a bit of online searching, we find the developer's email address. We write to the developer, thanking them for their work, explaining how useful we find it, and expressing our interest in financially supporting it. They respond, thanking us but stating that they have not thought of any specific numbers. After a bit of friendly back and forth, we suggest an arbitrary amount, followed by more discussion about logistics and paperwork. This process of arriving at numbers over personal e-mails is awkward for both parties. It addition, it typically takes weeks, requiring time, commitment, and bandwidth from both the developer and the donor to complete a single transaction. Models like Open Collective and GitHub Sponsors address this to some extent, but there is no open, decentralized mechanism for discovering projects in need of financial assistance nor gaining insights into their specific needs.</p>
<p>Any attempt on funding FOSS projects generally warrants clarity on several questions.</p>
<ul>
<li>Does the project under consideration need financial assistance?</li>
<li>Or perhaps it is not just one particular project, but a developer or a group of developers who maintain several projects that need assistance.</li>
<li>What kind and quantum of financial assistance are needed, and for what activities? Is there a structured support plan that the developers offer?</li>
<li>Has the project received any funding in the past? Is it in dire need of support, or is it doing reasonably well?</li>
<li>What payment methods are accepted? Is there a payment link or address that can be used without manual contact, or is something like a bank wire that is required?</li>
<li>Once there is enough context, and a conversation is warranted, how does one reach out to the right person who address financial or logistical queries?</li>
<li>That's about one project. But what about a particular category of projects? Maybe it is an emerging or critical area, and it would make sense to support multiple projects there. How does one discover them?</li>
</ul>
<p>What if the answers to such questions could be structured in a machine readable format, which could be crawled, indexed, catalogued, and made discoverable—similar to a <code>robots.txt</code> or <code>package.json</code> or <code>sitemap.xml</code>, but for funding. In the process, eliminating a lot of awkwardness and apprehension that would be otherwise transpire over back-and-forth personal e-mails discussing financial matters.</p>
<p>How about a standardised <code>funding.json</code> manifest file that can be added to project repositories and websites signalling their financial needs? Something like this:</p>
<pre data-lang="python"><code data-lang="python"><span>{
</span><span>    </span><span>"version"</span><span>: </span><span>"v1.0.0"</span><span>,
</span><span>    </span><span>"entity"</span><span>: {
</span><span>        </span><span>"type"</span><span>: </span><span>"individual"</span><span>,
</span><span>        </span><span>"role"</span><span>: </span><span>"maintainer"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"The One (demo)"</span><span>,
</span><span>        </span><span>"email"</span><span>: </span><span>"<a href="https://floss.fund/cdn-cgi/l/email-protection" data-cfemail="e48a818ba4819c8589948881ca878b89">[email&nbsp;protected]</a>"</span><span>,
</span><span>        </span><span>"phone"</span><span>: </span><span>""</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"I'm a developer interested in preserving digital freedoms and the decentralised and open nature of the internet. I like breaking down barriers in the cyberspace with FOSS technologies.</span><span>\n\n</span><span>Sometimes I can't shake the feeling that the system we're living in isn't quite what it seems. That there is no spoon.</span><span>\n\n</span><span>PS: This is a dummy listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://example.com"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>""
</span><span>        }
</span><span>    },
</span><span>    </span><span>"projects"</span><span>: [{
</span><span>        </span><span>"guid"</span><span>: </span><span>"zombo-app"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"Zombo App (demo)"</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"The Zombo App is a database application that solves many problems and makes anything possible. Anything at all. Its possibilities are only limited by the user's own imagination.</span><span>\n\n</span><span>It has been in active development for a decade and is used by millions of people worldwide. It is the next frontier.</span><span>\n\n</span><span>PS: This is a dummy demo listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://example.com/projects/zombo"
</span><span>        },
</span><span>        </span><span>"repositoryUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://github.com/example/zombo-app"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://github.com/example/zombo-app/blob/main/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"licenses"</span><span>: [</span><span>"spdx:AGPL-3.0"</span><span>],
</span><span>        </span><span>"tags"</span><span>: [</span><span>"database"</span><span>, </span><span>"columnar-database"</span><span>, </span><span>"high-performance"</span><span>, </span><span>"key-value-store"</span><span>]
</span><span>    },
</span><span>    {
</span><span>        </span><span>"guid"</span><span>: </span><span>"vb-gooey"</span><span>,
</span><span>        </span><span>"name"</span><span>: </span><span>"VB Gooey IP tracer (demo)"</span><span>,
</span><span>        </span><span>"description"</span><span>: </span><span>"Using quantum-entangled packet sniffers, this cutting-edge Visual Basic GUI IP Tracer employs hyper-threaded blockchain algorithms to decrypt the target's digital DNA signature. The system's neural network of overclocked RAM crystals generates a real-time holographic map of cyberspace, pinpointing the perp's location with nanosecond precision.</span><span>\n\n</span><span>In addition, its turbo-encabulated flux capacitor and multi-dimensional firewall penetrator, allows any hyper-dimensional air-gapped network to be broken into with ease.</span><span>\n\n\n\n</span><span>PS: This is a dummy demo listing."</span><span>,
</span><span>        </span><span>"webpageUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://vb-gooey-ip-tracer.net"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://vb-gooey-ip-tracer.net/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"repositoryUrl"</span><span>: {
</span><span>            </span><span>"url"</span><span>: </span><span>"https://github.com/example/vb-gooey-ip-tracer"</span><span>,
</span><span>            </span><span>"wellKnown"</span><span>: </span><span>"https://github.com/example/vb-gooey-ip-tracer/blob/main/.well-known/funding-manifest-urls"
</span><span>        },
</span><span>        </span><span>"licenses"</span><span>: [</span><span>"spdx:MIT"</span><span>],
</span><span>        </span><span>"tags"</span><span>: [</span><span>"high-performance"</span><span>, </span><span>"security"</span><span>, </span><span>"gui"</span><span>, </span><span>"networking"</span><span>]
</span><span>    }],
</span><span>    </span><span>"funding"</span><span>: {
</span><span>        </span><span>"channels"</span><span>: [
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"mybank"</span><span>,
</span><span>                </span><span>"type"</span><span>: </span><span>"bank"</span><span>,
</span><span>                </span><span>"address"</span><span>: </span><span>""</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Will accept direct bank transfers. Please e-mail me for details."
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"mypay"</span><span>,
</span><span>                </span><span>"type"</span><span>: </span><span>"payment-provider"</span><span>,
</span><span>                </span><span>"address"</span><span>: </span><span>"https://example.com/payme/@myid"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Pay with your debit/credit card through this gateway and setup recurring subscriptions."
</span><span>            }
</span><span>        ],
</span><span>        </span><span>"plans"</span><span>: [
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"hosting-monthly"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Hosting support"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"This will cover the monthly server hosting costs for the projects."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>250</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"monthly"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mypay"</span><span>]
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"developer-time"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Developer compensation"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"This will cover the cost of one developer working part-time on the projects."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>1000</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"monthly"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mybank"</span><span>]
</span><span>            },
</span><span>            {
</span><span>                </span><span>"guid"</span><span>: </span><span>"angel-plan"</span><span>,
</span><span>                </span><span>"status"</span><span>: </span><span>"active"</span><span>,
</span><span>                </span><span>"name"</span><span>: </span><span>"Goodwill plan"</span><span>,
</span><span>                </span><span>"description"</span><span>: </span><span>"Pay anything you wish to show your goodwill for the project."</span><span>,
</span><span>                </span><span>"amount"</span><span>: </span><span>0</span><span>,
</span><span>                </span><span>"currency"</span><span>: </span><span>"USD"</span><span>,
</span><span>                </span><span>"frequency"</span><span>: </span><span>"one-time"</span><span>,
</span><span>                </span><span>"channels"</span><span>: [</span><span>"mybank"</span><span>, </span><span>"mypay"</span><span>]
</span><span>            }
</span><span>        ],
</span><span>        </span><span>"history"</span><span>: [
</span><span>            {</span><span>"year"</span><span>: </span><span>2020</span><span>, </span><span>"income"</span><span>: </span><span>10000</span><span>, </span><span>"expenses"</span><span>: </span><span>2000</span><span>, </span><span>"taxes"</span><span>: </span><span>200</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>"Started accepting donations for the first time."</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2021</span><span>, </span><span>"income"</span><span>: </span><span>15000</span><span>, </span><span>"expenses"</span><span>: </span><span>5000</span><span>, </span><span>"taxes"</span><span>: </span><span>500</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>""</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2022</span><span>, </span><span>"income"</span><span>: </span><span>30000</span><span>, </span><span>"expenses"</span><span>: </span><span>10000</span><span>, </span><span>"taxes"</span><span>: </span><span>2000</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>""</span><span>},
</span><span>            {</span><span>"year"</span><span>: </span><span>2023</span><span>, </span><span>"income"</span><span>: </span><span>25000</span><span>, </span><span>"expenses"</span><span>: </span><span>15000</span><span>, </span><span>"taxes"</span><span>: </span><span>1500</span><span>, </span><span>"currency"</span><span>: </span><span>"USD"</span><span>, </span><span>"description"</span><span>: </span><span>"There was a dip, but we see this improving."</span><span>}
</span><span>        ]
</span><span>    }
</span><span>}
</span><span>
</span></code></pre>
<p>To initiate and give this experiment a serious shot, FLOSS/fund will accept funding requests from projects through a publicly accessible <code>funding.json</code> file hosted on their respositories or websites. This file is not meant to convey everything there is to know—an impossible task—but to solicit interest and communicate enough to ensure discoverability which would not be possible otherwise. Refer to the <a href="https://floss.fund/funding-manifest">funding.json docs</a> to know more.</p>
<p>Applications that come through to the FLOSS/fund will be indexed and published on the <a href="https://dir.floss.fund/">dir.floss.fund</a> directory / portal, making them publicly discoverable by anyone interested in supporting projects. This is going to be an interesting experiment. Fingers crossed!</p>
<h2 id="motivations">Motivations</h2>
<p>What are the motivations behind the fund? On a personal level, it is common sense, goodwill, and reciprocity—the spirit of FOSS. From a for-profit enterprise perspective, however, terms like "goodwill" and "reciprocity" are notoriously problematic, and most likely fundamentally incompatible with their very nature. But, that is a separate philosophical debate altogether.</p>
<p>Setting philosophies aside, it makes perfect logical sense for a business that relies on FOSS to support it, directly or indirectly, when they freely tap into a global ecosystem of unlimited FOSS innovation—free in both cost and freedom. How many technology companies today could even exist without the massive amounts of FOSS they use? Ensuring that this ecosystem thrives, without inadvertently turning parts of it into a classic tragedy of the commons, everything aside, is good, logical business strategy. At the very least, a profitable business should allocate a tiny fraction of its profits to support the projects it is directly reliant on. When many startups have advertising and marketing budgets that often put public spending to shame, one would be hard-pressed to find a reason not to give a bit of money  to the projects they depend on for their very existence.</p>
<p>Thus, FLOSS/fund's motivations are to:</p>
<ul>
<li>Exercise our goodwill and reciprocity on a personal level as FOSS hackers.</li>
<li>Exercise our organisational business sense and strategy to help the FOSS ecosystem thrive, without which our business cannot exist.</li>
<li>Encourage and apply a bit of peer-pressure on other businesses to setup structured financial support programmes for FOSS.</li>
<li>Contribute to existing FOSS funding models and to the sustainability conversations and debates.</li>
<li>As a bonus: Explore whether the <code>funding.json</code> manifest experiment can bring discoverability to the financial needs of FOSS projects on a large scale.</li>
</ul>
<p>Let us see how this goes.</p>


        </div><!-- post -->
      </div>
    </article>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mullvad VPN: macOS sometimes leaks traffic after system updates (374 pts)]]></title>
            <link>https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates</link>
            <guid>41856883</guid>
            <pubDate>Wed, 16 Oct 2024 08:37:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates">https://mullvad.net/en/blog/macos-sometimes-leaks-traffic-after-system-updates</a>, See on <a href="https://news.ycombinator.com/item?id=41856883">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!-- HTML_TAG_START --><p>We have found that you could be leaking traffic on macOS after system updates. To our current knowledge a reboot resolves it. We are currently investigating this and will follow up with more information.</p>
<h2>The current state</h2>
<p>In this scenario the macOS firewall does not seem to function correctly and is disregarding firewall rules. Most traffic will still go inside the VPN tunnel since the routing table specifies that it should. Unfortunately apps are not required to respect the routing table and can send traffic outside the tunnel if they try to. Some examples of apps that do this are Apple’s own apps and services since macOS 14.6, up until a recent 15.1 beta.</p>
<h2>What’s next?</h2>
<p>We’ve reported this to Apple and hopefully we’ll see a fix in the near future. In the meanwhile we will continue to investigate this to be able to provide more information to Apple and to see if there are any workarounds that we can implement in the app.</p>
<h2>Check if you are affected</h2>
<p>Run the following commands in a terminal to check if you are affected:</p>
<p>&nbsp;1. Add a firewall rule that blocks all traffic</p>
<pre><code>echo "block drop quick all" | sudo pfctl -ef -</code></pre>
<p>2. Try to send traffic outside the tunnel</p>
<pre><code>curl https://am.i.mullvad.net/connected</code></pre>
<p>To clean up after the experiment, disable the firewall and clear all rules.</p>
<pre><code>sudo pfctl -d</code><br><code>sudo pfctl -f /etc/pf.conf</code></pre>
<p>It is also possible to check if our app is leaking by doing the following:</p>
<p>1. Make sure you are not connected to a VPN<br>2. Find the default interface by running the following command in a terminal</p>
<pre><code>route get mullvad.net | sed -nE 's/.*interface: //p'</code></pre>
<p>3. Connect to a VPN server using our app<br>4. Run the following command (replace “&lt;interface&gt;” with the interface from step 2)</p>
<pre><code>curl --interface &lt;interface&gt; https://am.i.mullvad.net/connected</code></pre>
<p>5. The request should time out if everything is working properly. If there is a response then you are leaking.</p><!-- HTML_TAG_END --></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Self-Hosted Llama 3.2 with Coolify on My Home Server (210 pts)]]></title>
            <link>https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide</link>
            <guid>41855886</guid>
            <pubDate>Wed, 16 Oct 2024 05:26:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide">https://geek.sg/blog/how-i-self-hosted-llama-32-with-coolify-on-my-home-server-a-step-by-step-guide</a>, See on <a href="https://news.ycombinator.com/item?id=41855886">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Inspired by numerous people migrating their Next.js applications from Vercel to self-hosted VPS on Hetzner due to pricing concerns, I decided to explore self-hosting some of my non-critical applications. Additionally, I wanted to push my technical boundaries by running Llama 3.2 using Ollama and making its API available to power AI applications for my business, Wisp.</p><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/f532cf09-87ff-435b-bede-be0677b4419f.jpg/public" alt="Home server as a step stool"></p><p>The objective was to breathe new life into an old home server that once ran high-frequency trading and MEV algorithms but had since become a step stool for my daughter to climb onto the TV console.</p><p>This blog post chronicles my journey of setting up Coolify to run Ollama (using Llama 3.2) on my home server, with a particular focus on the challenges and triumphs of enabling GPU acceleration using the CUDA toolkit.</p><p>(Update)</p><p>Since some of you are curious, this is how Llama 3.2 3B perform on a GeForce RTX 2060:</p><p><iframe allowfullscreen="true" src="https://www.youtube.com/embed/3vhJ6fNW8AI"></iframe></p><h2>My Goals</h2><p>The primary idea was to leverage my home server, previously gathering dust, to perform valuable tasks. Specifically, I wanted it to host and automate AI-related functions. Additionally, this setup would provide a centralized location to run Supabase for storing various data. The broader goal includes:</p><ul><li><p><strong>Serving a Next.js website</strong>: This site should be live on the public Internet, auto-deploy from the master branch, work with a public subdomain, and maintain no open public ports for security.</p></li><li><p><strong>Running Llama 3.2</strong>: Utilizing the GPU for agentic tasks and making a locally accessible API.</p></li><li><p><strong>Wildcard domain</strong>: Enabling new services to spin up effortlessly under varied subdomains.</p></li></ul><h2>Overall Experience</h2><p>Setting up this environment was no small feat, but each step was a valuable learning experience. Here's a walkthrough of my journey:</p><ol><li><p><strong>Installing Ubuntu 24</strong>: This was a breeze, requiring only a single reboot.</p></li><li><p><strong>Coolify Installation</strong>: The process was smooth thanks to the handy install script, which ensured most prerequisites were met. A minor hiccup was resolved by running commands as root to avoid permission issues with the <code>/data</code> directory.</p></li><li><p><strong>Configuring Coolify</strong>: Initially, setting the server as <a target="_blank" href="http://localhost/">localhost</a> prevented assigning a domain via Cloudflare Tunnel. The fix involved adding the host as a second 'server'. Moreover, configuring the tunnel and SSL correctly took time but was crucial for security and functionality.</p></li><li><p><strong>Cloudflare Tunnel</strong>: Patience was key here. The wildcard domain setup was essential, and understanding the nuances of Cloudflare’s free SSL certificate coverage saved time and money.</p></li><li><p><strong>Deployment Wins</strong>: Successfully hosting my personal blog using Coolify over a Cloudflare Tunnel was a significant morale boost, fueling the energy needed to proceed with the Ollama setup.</p></li><li><p><strong>Running Ollama</strong>: Coolify made deploying the Ollama service straightforward. However, initial trials showed slow inference speeds and heavy CPU usage.</p></li><li><p><strong>Enabling GPU</strong>: Ubuntu 24 had the NVIDIA drivers pre-installed, but CUDA toolkit installation and configuration posed challenges. Persistent efforts led to discovering the need for the <code>nvidia-container-toolkit</code> and Docker service configuration modifications to enable GPU usage. The results were remarkable, reducing inference time by over 10x.</p></li><li><p><strong>API Exposure</strong>: Securing the LLM API with an API key became the next challenge. After unsuccessful attempts with nginx, I found potential solutions by using Caddy. Something I'll work on next after writing this post.</p></li></ol><h2><strong>Server Specifications</strong></h2><p>For context, here are the specifications of my home server:</p><ul><li><p><strong>CPU</strong>: AMD Ryzen 9 5950X 16-Core</p></li><li><p><strong>GPU</strong>: GeForce RTX 2060</p></li><li><p><strong>RAM</strong>: 4 x 16GB DDR4 3200 MT/s</p></li><li><p><strong>SSD</strong>: 2TB SSD + 8TB SSD</p></li></ul><h2><strong>Step-by-Step Guide</strong></h2><h3><strong>1. Install Ubuntu (For a New Setup)</strong></h3><p>Start by installing Ubuntu on your home server. Follow the detailed guide available on the <a target="_blank" href="https://ubuntu.com/tutorials/install-ubuntu-desktop"><strong>official Ubuntu website</strong></a>.</p><p><strong>Important Settings:</strong></p><ul><li><p>Avoid using LVM or disk encryption for a smoother reboot experience and easier server management. Note that this trade-off means anyone with physical access can read your data.</p></li><li><p>Ensure the installation of third-party drivers to automatically get the NVIDIA driver.</p></li></ul><h3><strong>Install SSH</strong></h3><p>Enable SSH to access your server remotely, which is especially useful if you’re managing it from another machine on your local network. Refer to this <a target="_blank" href="https://linuxize.com/post/how-to-enable-ssh-on-ubuntu-20-04/"><strong>SSH setup guide for Ubuntu 20.04</strong></a>, suitable for Ubuntu 24 as well.</p><h3><strong>Update and Upgrade APT</strong></h3><p>Always perform an update and upgrade for your packages:</p><pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y</code></pre><h3>Useful Commands</h3><p>Here are some additional commands for printing information about your machine and setup:</p><ul><li><p>View CPU usage: <code>htop</code></p></li><li><p>List NVIDIA graphics card information: <code>lspci | grep -i nvidia</code></p></li><li><p>Print architecture, OS distro, release: <code>uname -m &amp;&amp; cat /etc/*release</code></p></li><li><p>Print physical RAM installed: <code>sudo dmidecode --type memory | less</code></p></li><li><p>Print processor info: <code>cat /proc/cpuinfo | grep 'name'| uniq</code></p></li><li><p>Check NVIDIA driver information: <code>nvidia-smi</code></p></li></ul><h3><strong>2. Installing Coolify</strong></h3><p><a target="_blank" href="https://coolify.io/">Coolify</a> is an open-source platform designed to make deploying and managing your applications on self-hosted environments easier. Its key feature is allowing users to manage full-stack applications, databases, and services without relying on complex Kubernetes setups. Coolify streamlines deployments through a user-friendly interface, supporting services like Docker, GitHub, and GitLab.</p><p>To install Coolify, follow the automated installation instructions from <a target="_blank" href="https://coolify.io/docs/installation/">their documentation</a>:</p><pre><code>curl -fsSL https://cdn.coollabs.io/coolify/install.sh | bash</code></pre><p><strong>Important Notes</strong>:</p><ul><li><p>Ensure you’re logged in as the root user to avoid permission issues.</p></li><li><p>The installation script checks prerequisites, but you may need to troubleshoot some dependency errors if they arise.</p></li></ul><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/43c2d6eb-aba3-45ab-aad9-0f47e8895fa5.png/public" alt="Coolify onboarding screen"></p><p>Once Coolify is installed:</p><ul><li><p><strong>Visit the coolify dashboard</strong> at <code>http://localhost:8000</code> . This is also available on the network. Replace localhost with the ip address of the server if you are accessing it from another machine.</p></li><li><p><strong>Set up an admin account</strong> - this is stored locally on your server.</p></li><li><p><strong>Create your first project</strong> by adding a resource and deploying it to <code>localhost</code>. In my case, I deployed my personal blog first to test the setup.</p></li></ul><h3><strong>3. Setting Up a Cloudflare Tunnel on Coolify</strong></h3><p>Cloudflare Tunnel is a secure way to expose services running on your local network to the public internet without having to open ports on your router. For my setup, this was a key feature, as I wanted to keep my server behind a firewall while still allowing external access to some services.</p><p>Cloudflare’s Zero Trust platform ensures that all traffic is encrypted and routed securely, preventing unauthorized access.</p><p>To set up a Cloudflare Tunnel, follow this instructions on Coolify’s <a target="_blank" href="https://coolify.io/docs/knowledge-base/cloudflare/tunnels">official documentation</a>. The key is to focus on setting up <strong>wildcard subdomains</strong> for all your services.</p><p>A few key caveats:</p><ol><li><p><strong>Localhost Server Issue</strong>: You cannot assign a domain to the pre-created <code>localhost</code> server directly. To solve this, add your host as a second server within Coolify, using the IP address <code>172.17.0.1</code> for <code>host.docker.internal</code> (since coolify will show an error that <code>host.docker.internal</code> has already been assigned to a server).</p></li><li><p><strong>Wildcard Domain Setup</strong>: Make sure you use a top-level domain like <code>*.example.com</code>. If you use a wildcard on a subdomain, Cloudflare will not provide a free SSL certificate, unless you opt for the ACM plan.</p></li></ol><p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/4c338964-bf9d-4466-975a-fca268f56795.png/public"></p><p>After setting up the Cloudflare Tunnel:</p><ul><li><p>Deploy your resources to the newly added server.</p></li><li><p>Change the domain in the service configuration to match your new subdomain.</p></li><li><p>Once everything is deployed, you should be able to access your service live from its custom domain.</p></li></ul><h3><strong>4. Deploying Ollama</strong></h3><p>Once you’ve set up your Coolify project, the next step is to deploy Ollama. This service allows you to run large language models (LLMs) like Llama 3.2 on your server with a web-based interface.</p><ol><li><p><strong>Add a New Resource</strong>: In your Coolify project, select "Add Resource" and choose <strong>Ollama with Open WebUI</strong> as the service you want to deploy to your new server.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/2b634b6c-17db-4f5c-afba-615b4cc1cef0.png/public" alt="Deploying Ollama in Coolify"></li><li><p><strong>Configure the Domain</strong>: After adding Ollama, configure the domain for the Open WebUI service. Assign a domain from the wildcard domain you set up earlier through Cloudflare Tunnel. This will allow you to access the Ollama WebUI directly from the internet.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/d7eb2920-5e28-47b9-9d02-9cb3740ca3b5.png/public" alt="Configuring domain on Coolify resource"></li><li><p><strong>Deploy the Service</strong>: Once everything is set up, click on "Deploy."</p><p>You should now be able to access the Open WebUI via the assigned domain. Upon your first login, you'll be prompted to create an admin account. This is important for managing models and access through the UI.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/69c5be6f-4570-4bea-b334-123c5b9cb25f.png/public" alt="WebUI for Ollama"></li><li><p><strong>Install Llama 3.2</strong>: With your admin account set up, you can now install the latest Llama model. Head to <a target="_blank" href="https://ollama.com/library">Ollama's library</a> and search for the Llama model you want to use. I opted for <strong>Llama 3.2</strong>, which can be installed using the tag <code>llama3.2</code>.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/6d081703-a0eb-4412-97d0-05bb765f3afc.png/public" alt="Downloading models using WebUI with Ollama"></li><li><p><strong>Try Your First Chat</strong>: Once installed, initiate your first chat with Llama 3.2 via the web interface. During this phase, your model will likely run on the CPU, so expect to hear your machine working hard (with increased CPU fan noise).</p><p>To monitor your machine’s performance during this, use the following commands:</p><ul><li><p><code>htop</code> to keep an eye on <strong>CPU usage</strong>.</p></li><li><p><code>watch -n 0.5 nvidia-smi</code> to track <strong>GPU usage</strong> (though at this stage, GPU may not be utilized yet).</p></li></ul><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/6052bfb2-63bb-49cf-a75b-c4f643dee830.png/public" alt="Crazy CPU usage when Llama 3.2 runs using CPU"></li></ol><h3><strong>5. Configuring Ollama to Use GPU</strong></h3><p>Large language models (LLMs) like Llama 3.2 perform significantly better with GPU acceleration. GPUs, particularly those from NVIDIA, are optimized for the heavy parallel computations involved in AI workloads, which is where CUDA (Compute Unified Device Architecture) comes into play. The CUDA toolkit enables direct GPU acceleration for applications like Ollama, drastically reducing inference time and CPU load.</p><p>This is arguably the most challenging step in setting up Ollama on your server, but here’s a breakdown of the process:</p><ol><li><p><strong>(Already Done)</strong>: Install the NVIDIA driver (this should have been handled during your Ubuntu installation).</p></li><li><p><strong>Install the NVIDIA CUDA Toolkit</strong>: This toolkit is necessary to unlock GPU acceleration.</p></li><li><p><strong>(Optional)</strong>: Test that the CUDA toolkit is working correctly.</p></li><li><p><strong>Install the NVIDIA Container Toolkit</strong>: This will allow Docker containers (like Ollama) to access the GPU.</p></li><li><p><strong>Enable the Ollama service in Coolify to use the GPU</strong>.</p></li></ol><p><strong>Install the NVIDIA CUDA Toolkit</strong></p><p>Follow NVIDIA’s official <a target="_blank" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">installation guide</a> to install the CUDA toolkit for your system. I recommend using the <strong>network repository installation method</strong> for the most flexibility and ease of updates.</p><ol><li><p>Install the new <code>cuda-keyring</code> package:</p><pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/&lt;distro&gt;/&lt;arch&gt;/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb</code></pre><p>Replace <code>&lt;distro&gt;/&lt;arch&gt;</code> with the appropriate value for your distribution and architecture:</p><ul><li><p><code>ubuntu2004/arm64</code></p></li><li><p><code>ubuntu2004/sbsa</code></p></li><li><p><code>ubuntu2004/x86_64</code></p></li><li><p><code>ubuntu2204/sbsa</code></p></li><li><p><code>ubuntu2204/x86_64</code></p></li><li><p><code>ubuntu2404/sbsa</code></p></li><li><p><code>ubuntu2404/x86_64</code></p></li></ul></li><li><p>Update the APT repository cache:</p><pre><code>sudo apt-get update</code></pre></li><li><p>Install the CUDA SDK:</p><pre><code>sudo apt-get install cuda-toolkit</code></pre></li><li><p>Set up the environment for CUDA by adding its binaries to your PATH:</p><pre><code>export PATH=/usr/local/cuda-12.6/bin${PATH:+:${PATH}}</code></pre></li><li><p>Reboot the system to ensure all configurations take effect:</p><pre><code>sudo reboot</code></pre></li></ol><p><strong>(Optional) Test that CUDA Toolkit Works</strong></p><p>To ensure that your system is correctly configured for GPU acceleration, test the CUDA installation by compiling and running sample programs provided by NVIDIA (<a target="_blank" href="https://github.com/nvidia/cuda-samples">https://github.com/nvidia/cuda-samples</a>).</p><ol><li><p>First, install the necessary build tools:</p><pre><code>sudo apt install build-essential</code></pre></li><li><p>Clone the CUDA sample repository and build the sample projects:</p><pre><code>git clone https://github.com/nvidia/cuda-samples
cd cuda-samples
make</code></pre></li><li><p>Navigate to the compiled binaries and run the <code>deviceQuery</code> tool to verify your GPU and CUDA installation:</p><pre><code>cd bin/x86_64/linux/release
./deviceQuery</code></pre><p>You should see detailed information about your GPU and CUDA environment, confirming that the toolkit is working correctly.</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/fba84378-4c3c-4712-9230-ba2476654826.png/public" alt="deviceQuery showing CUDA Capable device(s)"></li></ol><p><strong>Install NVIDIA Container Toolkit</strong></p><p>To enable Docker containers to access your GPU, you'll need to install the NVIDIA Container Toolkit. This toolkit allows Docker to offload GPU-intensive operations to your NVIDIA GPU, essential for speeding up tasks like model inference with Ollama.</p><p>Follow the steps below from <a target="_blank" href="https://hub.docker.com/r/ollama/ollama">Ollama docker docs</a> to install the NVIDIA Container Toolkit:</p><ol><li><p><strong>Configure the repository</strong>:</p><pre><code>curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey \
    | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list \
    | sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' \
    | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update</code></pre></li><li><p><strong>Install the NVIDIA Container Toolkit packages</strong>:</p><pre><code>sudo apt-get install -y nvidia-container-toolkit</code></pre></li></ol><p>With the container toolkit installed, Docker will now be able to use your GPU.</p><p><strong>Enable Ollama Service in Coolify to Use GPU</strong></p><p>To enable GPU support for the Ollama service in Coolify, you'll need to modify the Docker Compose file to allow access to all the GPUs on the host machine.</p><ol><li><p><strong>Edit the Compose File</strong>: Navigate to the Ollama service in Coolify and select "Edit Compose File."</p><img src="https://imagedelivery.net/lLmNeOP7HXG0OqaG97wimw/clwdlsohu0000v1qer09du8mo/b3cff181-410b-49fc-82fe-6bfbe0280854.png/public" alt="Edit compose file in Coolify"></li><li><p><strong>Add GPU Configuration</strong>: Append the following configuration under the <code>ollama-api</code> resource. This enables Docker to utilize all GPUs available on the host system:</p><pre><code>    deploy:
      resources:
        reservations:
          devices:
            -
              driver: nvidia
              count: all
              capabilities:
                - gpu</code></pre></li><li><p><strong>Restart the Service</strong>: After saving the changes, restart the Ollama service by clicking the "Restart" button in Coolify.</p></li></ol><p>Once restarted, Ollama will now leverage your GPU for model inference. You can verify that it's using the GPU by running:</p><ul><li><p><code>htop</code> to check CPU usage (it should remain low).</p></li><li><p><code>watch -n 0.5 nvidia-smi</code> to see the GPU usage in action.</p></li></ul><p><strong>Testing GPU Performance</strong></p><p>Try initiating another conversation with Llama 3.2 via the web UI. This time, you should notice a significant reduction in CPU load, as the GPU will handle the inference tasks.</p><p>Congratulations! You’ve successfully configured Ollama to use GPU acceleration through Coolify on your home server!</p><h3><strong>Next Steps</strong></h3><p>The final step in securing your setup is to expose the LLM API to the internet while ensuring it’s protected by an API key. Using Caddy, you can enforce API key access for the Ollama service.</p><p>For a detailed guide, refer to this <a target="_blank" href="https://github.com/ollama/ollama/issues/849">discussion</a>.</p><h2>Conclusion</h2><p>In this post, I detailed my journey of setting up Llama 3.2 on my home server, utilizing GPU acceleration to handle AI workloads efficiently. Starting from a simple Ubuntu setup, I navigated the complexities of installing NVIDIA drivers, configuring Docker for GPU support, and deploying Ollama using Coolify. With this setup, I now have a powerful AI system running locally, handling agentic tasks with ease.</p><p>This guide walks through the entire process, from software installations to troubleshooting, and provides a blueprint for anyone looking to do the same.</p><h3><strong>References</strong></h3><ul><li><p><a target="_blank" href="https://www.reddit.com/r/ollama/comments/1c8ddv8/ollama_doesnt_use_gpu_pls_help/">Reddit: Ollama Not Using GPU</a></p></li><li><p><a target="_blank" href="https://www.reddit.com/r/LocalLLaMA/comments/1cew9fb/is_ollama_supposed_to_run_on_your_gpu/">Reddit: Is Ollama Supposed to Run on GPU?</a></p></li><li><p><a target="_blank" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/">NVIDIA CUDA Installation Guide</a></p></li><li><p><a target="_blank" href="https://hub.docker.com/r/ollama/ollama">Ollama Docker Hub</a></p></li><li><p><a target="_blank" href="https://stackoverflow.com/questions/70761192/docker-compose-equivalent-of-docker-run-gpu-all-option">StackOverflow: Docker Compose GPU Setup</a></p></li></ul><p><small><a target="_blank" href="https://www.wisp.blog/?utm_source=web&amp;utm_campaign=attribution&amp;utm_content=cm2bbhb1u000111hp13ioe9i3">Powered by wisp</a></small></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Let Google decide (151 pts)]]></title>
            <link>https://cupofsquid.com/post/not-real/</link>
            <guid>41855512</guid>
            <pubDate>Wed, 16 Oct 2024 04:07:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://cupofsquid.com/post/not-real/">https://cupofsquid.com/post/not-real/</a>, See on <a href="https://news.ycombinator.com/item?id=41855512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	<article>
		
		

		<div>
			<h2 id="when-personhood-is-decided-by-the-big-five">When “personhood” is decided by the Big Five</h2>
<p>My partner and I recently moved states in order to benefit from lower rent and a
more affordable living environment. We found a place on Craigslist for the
winter that was not only scam-free, but extremely cute. We visited it in person,
met the landlord, and agreed to tenancy until April after the threat of frost.
The process, despite its rushed quality, was rather straightforward.</p>
<p>However, we started running into problems when we began updating our address.
Google, it seemed, never heard of our road let alone the fact that there were
houses on it.</p>
<p>I first noticed this issue when I went to update my address with my online
credit union. I was told, in no uncertain terms that the street didn’t exist
after I overrode the Google Maps autocomplete. When I switched to our PO Box
number, an error message popped up and said that “PO Boxes were not appropriate
addresses.”</p>
<p>And so our saga began.</p>
<p>The town, thankfully, knew of the road and gave us no problems when it came to
hyper-local needs like car registration at the downtown office. Signing up for a
new phone service left us both screaming at the computer, then eventually
settling with putting our address as the post office (because, again, PO boxes
aren’t “appropriate addresses”). We just hoped that the town being small enough
would make it so they would know where to put mail should something ever come
from the phone company or any other service that used Google to verify
addresses.</p>
<p>Getting a license was also difficult, since mail was rarely delivered to our
physical address. Instead, both of us needed to sign an affadavit…to prove
that the other person lived with us or at least wasn’t lying about living in the
state.</p>
<p>Which, when you think about it, is weird, right?</p>
<p>Go in with enough random people to say you lived at a place and that was more
legitimate than a letter with your address on top from a propane company that
served half the state.</p>
<p>The letter, you see, doesn’t count because it wasn’t a bill with the account
number on it, even though the mysterious street address was. But of course new
tenants wouldn’t have a bill with the account number on it yet since they had
only just moved in! Proof of car insurance wasn’t enough either because it only
had our mailing address, which is a PO Box…and well, we know what Serious
Institutions think of PO Boxes.</p>
<p>And while we have figured at least some of this out, we also had difficulty
discerning where to begin. Since, to get the PO Box at all, USPS had to know
where we lived and that we had proof of living in the town we wanted the PO Box
at…which caused a headache with Google Maps autocomplete again. Because of
Google, our address wasn’t even present for the USPS, who should have more say
than Google about what is and isn’t an address! It took a sympathetic postmaster
to help us out in person, since everyone in that office had delivered local mail
to our address previously, so knew we weren’t making things up.</p>
<p>This entire debacle is worth mentioning in as full of detail as possible for two
reasons: (1) It shows the extent to which Google can dictate our lives and how
we get to live it. (2) Proof of address is needed for so many things, down to the
basic necessities to be legal within this country.</p>
<p>If I don’t have an address, I cannot have a bank account. I cannot get a
driver’s license, register my car, vote in my town. I cannot even get a library
card.</p>
<p>For an entire week, I was a non-person to this country’s bureaucracy, which in
some respects <em>should</em> feel freeing, but in the end was a massive pain in the
ass. It was frightening to consider that something as simple as an address not
showing up on the world’s most popular maps app meant that, without the
intervention of locals who understood what it meant to live in a largely
unmarked rural area, this non-personhood would’ve potentially been permanent.</p>
<p>On a larger scale, it made me concerned for the use of AI in these kinds of
situations. What if I wasn’t able to intercept a human postmaster who could then
look at my documents and say that I was able to have a PO Box to receive mail
from outside of town? Or talk to a DMV associate who could see that my partner
was right beside me and could vouch for my legitimacy as a state resident?</p>
<p>Technology, of course, is falliable. It cannot account for all cases, all
possibilities. And forbid the thought of politics entering into it. These tools
can easily be manipulated further to label anyone outside of the white,
heteronormative, cisgender conglomerate as a non-person in the eyes of the
larger system. All they need is a huge company like Google to “not recognize” a
few key factors like whole neighborhoods in redlined areas or a gender marker
(as compared to a birth certificate or something).</p>
<p>If nothing else, I learned that nothing beats talking to a real, live human
being, especially those that are just down the street.</p>

		</div>
	</article>
</div></div>]]></description>
        </item>
    </channel>
</rss>