<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 15 Feb 2026 17:30:11 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Amazon, Google Unwittingly Reveal the Severity of the U.S. Surveillance State (387 pts)]]></title>
            <link>https://greenwald.substack.com/p/amazons-ring-and-googles-nest-unwittingly</link>
            <guid>47023238</guid>
            <pubDate>Sun, 15 Feb 2026 12:42:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://greenwald.substack.com/p/amazons-ring-and-googles-nest-unwittingly">https://greenwald.substack.com/p/amazons-ring-and-googles-nest-unwittingly</a>, See on <a href="https://news.ycombinator.com/item?id=47023238">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MwWG!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MwWG!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 424w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 848w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 1272w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MwWG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic" width="1456" height="971" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1996048,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/heic&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://greenwald.substack.com/i/187789911?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MwWG!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 424w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 848w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 1272w, https://substackcdn.com/image/fetch/$s_!MwWG!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1e3e6373-e7bb-4397-8e93-a5ad524ee4cf_4000x2667.heic 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em>One of Google’s Nest surveillance cameras, whose recordings can be accessed          by Google even if users don’t subscribe to the security firm’s services.                   </em><span>CC Photo Lab / Shutterstock</span></figcaption></figure></div><p><strong>That the U.S. Surveillance State is</strong><span> rapidly growing to the point of ubiquity has been demonstrated over the past week by seemingly benign events. While the picture that emerges is grim, to put it mildly, at least Americans are again confronted with crystal clarity over how severe this has become.</span></p><p><span>The latest round of valid panic over privacy began during the Super Bowl held on Sunday. During the game, Amazon ran </span><a href="https://www.youtube.com/watch?v=OheUzrXsKrY" rel="">a commercial</a><span> for its Ring camera security system. The ad manipulatively exploited people’s love of dogs to induce them to ignore the consequences of what Amazon was touting. It seems that trick did not work.</span></p><p>The ad highlighted what the company calls its “Search Party” feature, whereby one can upload a picture, for example, of a lost dog. Doing so will activate multiple other Amazon Ring cameras in the neighborhood, which will, in turn, use AI programs to scan all dogs, it seems, and identify the one that is lost. The 30-second commercial was full of heart-tugging scenes of young children and elderly people being reunited with their lost dogs.</p><p>But the graphic Amazon used seems to have unwittingly depicted how invasive this technology can be. That this capability now exists in a product that has long been pitched as nothing more than a simple tool for homeowners to monitor their own homes created, it seems, an unavoidable contrast between public understanding of Ring and what Amazon was now boasting it could do.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!0JUB!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!0JUB!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 424w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 848w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 1272w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!0JUB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png" width="2424" height="1243" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1243,&quot;width&quot;:2424,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:5364048,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://greenwald.substack.com/i/187789911?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd64d01cc-601f-4649-bf9d-c537edb2bff8_2968x1522.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!0JUB!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 424w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 848w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 1272w, https://substackcdn.com/image/fetch/$s_!0JUB!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F82e6327a-fa3c-4292-b929-8f1c12444f41_2424x1243.png 1456w" sizes="100vw"></picture></div></a><figcaption><em>Amazon’s Super Bowl ad for Ring and its “Search Party” feature.</em></figcaption></figure></div><p>Many people were not just surprised but quite shocked and alarmed to learn that what they thought was merely their own personal security system now has the ability to link with countless other Ring cameras to form a neighborhood-wide (or city-wide, or state-wide) surveillance dragnet. That Amazon emphasized that this feature is available (for now) only to those who “opt-in” did not assuage concerns.</p><p><span>Numerous media outlets sounded the alarm. The online privacy group Electronic Frontier Foundation (EFF) </span><a href="https://abc7chicago.com/post/ring-flock-partnership-amazon-scraps-surveillance-company-safety-super-bowl-commercial-backlash/18596207/" rel="">condemned</a><span> Ring’s program as previewing “a world where biometric identification could be unleashed from consumer devices to identify, track, and locate anything — human, pet, and otherwise.”</span></p><p><span>Many private citizens who previously used Ring also reacted negatively. “Viral videos online show people removing or destroying their cameras over privacy concerns,” </span><a href="https://www.usatoday.com/story/news/nation/2026/02/10/ring-super-bowl-ad-dog-camera-privacy/88606738007/" rel="">reported</a><span> USA Today. The backlash became so severe that, just days later, Amazon — seeking to assuage public anger — </span><a href="https://abc7chicago.com/post/ring-flock-partnership-amazon-scraps-surveillance-company-safety-super-bowl-commercial-backlash/18596207/" rel="">announced</a><span> the termination of a partnership between Ring and Flock Safety, a police surveillance tech company (while Flock is unrelated to Search Party, public backlash made it impossible, at least for now, for Amazon to send Ring’s user data to a police surveillance firm).</span></p><p>The Amazon ad seems to have triggered a long-overdue spotlight on how the combination of ubiquitous cameras, AI, and rapidly advancing facial recognition software will render the term “privacy” little more than a quaint concept from the past. As EFF put it, Ring’s program “could already run afoul of biometric privacy laws in some states, which require explicit, informed consent from individuals before a company can just run face recognition on someone.”</p><p>Those concerns escalated just a few days later in the context of the Tucson disappearance of Nancy Guthrie, mother of long-time TODAY Show host Savannah Guthrie. At the home where she lives, Nancy Guthrie used Google’s Nest camera for security, a product similar to Amazon’s Ring.</p><p><span>Guthrie, however, did not pay Google for a subscription for those cameras, instead solely using the cameras for real-time monitoring. As CBS News </span><a href="https://www.cbsnews.com/news/cybersecurity-experts-nancy-guthrie-surveillance-footage-recovery/" rel="">explained</a><span>, “with a free Google Nest plan, the video should have been deleted within 3 to 6 hours — long after Guthrie was reported missing.” Even professional privacy advocates have understood that customers who use Nest without a subscription will not have their cameras connected to Google’s data servers, meaning that no recordings will be stored or available for any period beyond a few hours.</span></p><p><span>For that reason, Pima County Sheriff Chris Nanos </span><a href="https://fortune.com/2026/02/11/privacy-concerns-nancy-guthrie-google-nest-camera-footage-kidnapping/" rel="">announced</a><span> early on “that there was no video available in part because Guthrie didn’t have an active subscription to the company.” Many people, for obvious reasons, prefer to avoid permanently storing comprehensive daily video reports with Google of when they leave and return to their own home, or who visits them at their home, when, and for how long.</span></p><p>Despite all this, FBI investigators on the case were somehow magically able to “recover” this video from Guthrie’s camera many days later. FBI Director Kash Patel was essentially forced to admit this when he released still images of what appears to be the masked perpetrator who broke into Guthrie’s home. (The Google user agreement, which few users read, does protect the company by stating that images may be stored even in the absence of a subscription.)</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!OWb9!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!OWb9!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 424w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 848w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 1272w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!OWb9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png" width="920" height="642" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:642,&quot;width&quot;:920,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:689574,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://greenwald.substack.com/i/187789911?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!OWb9!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 424w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 848w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 1272w, https://substackcdn.com/image/fetch/$s_!OWb9!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F36f93214-f835-4323-841f-53de4ae5f0ce_920x642.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>Image obtained through Nancy Guthrie’s unsubscribed Google Nest camera and released by the FBI.</em></figcaption></figure></div><p>While the “discovery” of footage from this home camera by Google engineers is obviously of great value to the Guthrie family and law enforcement agents searching for Guthrie, it raises obvious yet serious questions about why Google, contrary to common understanding, was storing the video footage of unsubscribed users. A former NSA data researcher and CEO of a cybersecurity firm, Patrick Johnson, told CBS: “There's kind of this old saying that data is never deleted, it's just renamed.”</p><p><strong>It is rather remarkable that</strong><span> Americans are being led, more or less willingly, into a state-corporate, Panopticon-like domestic surveillance state with relatively little resistance, though the widespread reaction to Amazon’s Ring ad is encouraging. Much of that muted reaction may be due to a lack of realization about the severity of the evolving privacy threat. Beyond that, privacy and other core rights can seem abstract and less of a priority than more material concerns, at least until they are gone.</span></p><p>It is always the case that there are benefits available from relinquishing core civil liberties: allowing infringements on free speech may reduce false claims and hateful ideas; allowing searches and seizures without warrants will likely help the police catch more criminals, and do so more quickly; giving up privacy may, in fact, enhance security.</p><p>But the core premise of the West generally, and the U.S. in particular, is that those trade-offs are never worthwhile. Americans still all learn and are taught to admire the iconic (if not apocryphal) 1775 words of Patrick Henry, which came to define the core ethos of the Revolutionary War and American Founding: “Give me liberty or give me death.” It is hard to express in more definitive terms on which side of that liberty-versus-security trade-off the U.S. was intended to fall.</p><p><span>These recent events emerge in a broader context of this new Silicon Valley-driven destruction of individual privacy. Palantir’s federal contracts for domestic surveillance and domestic data management continue to expand rapidly, with more and more intrusive data about Americans consolidated under the control of this </span><a href="https://www.youtube.com/watch?v=JypG_o7HWT0" rel="">one sinister corporation</a><span>.</span></p><p><span>Facial recognition technology — now fully in use for an array of purposes from Customs and Border Protection at airports to ICE’s patrolling of American streets — means that fully tracking one’s movements in public spaces is easier than ever, and is becoming easier by the day. It was only three years ago that we </span><a href="https://x.com/systemupdate_/status/1712828792320778590" rel="">interviewed</a><span> </span><em>New York Times</em><span> reporter Kashmir Hill about her new book, “Your Face Belongs to Us.” The warnings she issued about the dangers of this proliferating technology have not only come true with startling speed but also appear already beyond what even she envisioned.</span></p><p>On top of all this are advances in AI. Its effects on privacy cannot yet be quantified, but they will not be good. I have tried most AI programs simply to remain abreast of how they function.</p><p>After just a few weeks, I had to stop my use of Google’s Gemini because it was compiling not just segregated data about me, but also a wide array of information to form what could reasonably be described as a dossier on my life, including information I had not wittingly provided it. It would answer questions I asked it with creepy, unrelated references to the far-too-complete picture it had managed to create of many aspects of my life (at one point, it commented, somewhat judgmentally or out of feigned “concern,” about the late hours I was keeping while working, a topic I never raised).</p><p>Many of these unnerving developments have happened without much public notice because we are often distracted by what appear to be more immediate and proximate events in the news cycle. The lack of sufficient attention to these privacy dangers over the last couple of years, including at times from me, should not obscure how consequential they are.</p><p><span>All of this is particularly remarkable, and particularly disconcerting, since we are barely more than a decade removed from the disclosures about mass domestic surveillance enabled by the courageous whistleblower Edward Snowden. Although most of our reporting focused on state surveillance, one of </span><a href="https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data" rel="">the first stories</a><span> featured the joint state-corporate spying framework built in conjunction with the U.S. security state and Silicon Valley giants.</span></p><p><span>The Snowden stories sparked years of anger, attempts at reform, changes in diplomatic relations, and even genuine (albeit forced) </span><a href="https://www.nytimes.com/2019/11/19/technology/end-to-end-encryption.html" rel="">improvements</a><span> in Big Tech’s user privacy. But the calculation of the U.S. security state and Big Tech was that at some point, attention to privacy concerns would disperse and then virtually evaporate, enabling the state-corporate surveillance state to march on without much notice or resistance. At least as of now, the calculation seems to have been vindicated.</span></p></div></article></div><div><div id="discussion"><h4>Discussion about this post</h4></div><div><h3>Ready for more?</h3></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Fixed Windows Native Development (378 pts)]]></title>
            <link>https://marler8997.github.io/blog/fixed-windows/</link>
            <guid>47022891</guid>
            <pubDate>Sun, 15 Feb 2026 11:25:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://marler8997.github.io/blog/fixed-windows/">https://marler8997.github.io/blog/fixed-windows/</a>, See on <a href="https://news.ycombinator.com/item?id=47022891">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Imagine you’re maintaining a native project. You use Visual Studio for building on Windows, so you do the responsible thing and list it as a dependency</p><blockquote><p>Build Requirements: Install Visual Studio</p></blockquote><p>If you’re lucky enough not to know this yet, I envy you.  Unfortunately, at this point even Boromir knows…</p><figure><img src="https://marler8997.github.io/SimplyInstallVs.png">
<figcaption>Well put Boromir</figcaption></figure><p>What you may not realize is, you’ve actually signed up to be unpaid tech support for Microsoft’s “Visual Studio Installer”. You might notice GitHub Issues becoming less about your code and more about broken builds, specifically on Windows. You find yourself explaining to a contributor that they didn’t check the “Desktop development with C++” workload, but specifically the v143 build tools and the 10.0.22621.0 SDK. No, not that one, the <em>other</em> one. You spend less time on your project because you’re too busy being a human-powered dependency resolver for a 50GB IDE.</p><p>Saying “Install Visual Studio” is like handing contributors a choose-your-own-adventure book riddled with bad endings, some of which don’t let you go back. I’ve had to re-image my entire OS more than once over the years.</p><h3>Why is this tragedy unique to Windows?</h3><p>On <strong>Linux</strong>, the toolchain is usually just a package manager command away. On the other hand, “Visual Studio” is thousands of components. It’s so vast that Microsoft distributes it with a sophisticated GUI installer where you navigate a maze of checkboxes, hunting for which “Workloads” or “Individual Components” contain the actual compiler. Select the wrong one and you might lose hours installing something you don’t need. Miss one, like “Windows 10 SDK (10.0.17763.0)” or “Spectre-mitigated libs,” and your build fails three hours later with a cryptic error like <code>MSB8101</code>. And heaven help you if you need to downgrade to an older version of the build tools for a legacy project.</p><p>The Visual Studio ecosystem is built on a legacy of ‘all-in-one’ monoliths. It conflates the editor, the compiler, and the SDK into a single, tangled web. When we list ‘Visual Studio’ as a dependency, we’re failing to distinguish between the tool we use to write code and the environment required to compile it.</p><p>The pain compounds quickly:</p><ul><li><strong>Hours-long waits</strong>: You spend an afternoon watching a progress bar download 15GB just to get a 50MB compiler.</li><li><strong>Zero transparency</strong>: You have no idea which files were installed or where they went. Your registry is littered with cruft and background update services are permanent residents of your Task Manager.</li><li><strong>No version control</strong>: You can’t check your compiler into Git. If a teammate has a slightly different Build Tools version, your builds can silently diverge.</li><li><strong>The “ghost” environment</strong>: Uninstalling is never truly clean. Moving to a new machine means repeating the entire GUI dance, praying you checked the same boxes.</li></ul><p>Even after installation, compiling a single C file from the command line requires finding the Developer Command Prompt. Under the hood, this shortcut invokes <code>vcvarsall.bat</code>, a fragile batch script that globally mutates your environment variables just to locate where the compiler is hiding this week.</p><p>Ultimately, you end up with build instructions that look like a legal disclaimer:</p><blockquote><p>“Works on my machine with VS 17.4.2 (Build 33027.167) and SDK 10.0.22621.0. If you have 17.5, please see Issue #412. If you are on ARM64, godspeed.”</p></blockquote><p>On Windows, this has become the “cost of doing business”. We tell users to wait three hours for a 20GB install just so they can compile a 5MB executable. <strong>It’s become an active deterrent to native development</strong>.</p><h2>A new way</h2><p>I’m not interested in being a human debugger for someone else’s installer. I want the MSVC toolchain to behave like a modern dependency: versioned, isolated, declarative.</p><p>I spent a few weeks building an open source tool to make things better. It’s called <a href="https://github.com/marler8997/msvcup" target="_blank">msvcup</a>. It’s a small CLI program. On good network/hardware, it can install the toolchain/SDK in a few minutes, including everything to cross-compile to/from ARM. Each version of the toolchain/SDK gets its own isolated directory. It’s idempotent and fast enough to invoke every time you build. Let’s try it out.</p><p>Create <code>hello.c</code> and <code>build.bat</code>:</p><pre><code><span>#include</span> <span>&lt;stdio.h&gt;</span>
<span>int</span> <span>main</span>() { <span>printf</span>(<span>"Hello, World\n"</span>)<span>;</span> }
</code></pre>
<pre><code>@setlocal

@if not exist msvcup.exe (
    echo msvcup.exe: installing...
    curl -L -o msvcup.zip https://github.com/marler8997/msvcup/releases/download/v2026_02_07/msvcup-x86_64-windows.zip
    tar xf msvcup.zip
    del msvcup.zip
) else (
    echo msvcup.exe: already installed
)
@if not exist msvcup.exe exit /b 1

set MSVC=msvc-14.44.17.14
set SDK=sdk-10.0.22621.7

msvcup install --lock-file msvcup.lock --manifest-update-off %MSVC% %SDK%
@if %errorlevel% neq 0 (exit /b %errorlevel%)

msvcup autoenv --target-cpu x64 --out-dir autoenv %MSVC% %SDK%
@if %errorlevel% neq 0 (exit /b %errorlevel%)

.\autoenv\cl hello.c
</code></pre><p>And we’re done.</p><p>Believe it or not, this <code>build.bat</code> script replaces the need to “Install Visual Studio”. This script should run on any Windows system since Windows 10 (assuming it has curl/tar which have been shipped since 2018). It installs the MSVC toolchain, the Windows SDK and then compiles our program.</p><p>For my fellow Windows developers, go ahead and take a moment. Visual Studio can’t hurt you anymore. The <code>build.bat</code> above isn’t just a helper script; it’s a declaration of independence from the Visual Studio Installer. Our dependencies are fully specified, making builds reproducible across machines. And when those dependencies are installed, they won’t pollute your registry or lock you into a single global version.</p><p>Also note that after the first run, the <code>msvcup</code> commands take milliseconds, meaning we can just leave these commands in our build script and now we have a fully self-contained script that can build our project on virtually any modern Windows machine.</p><h2>How?</h2><p>msvcup is inspired by a <a href="https://gist.github.com/mmozeiko/7f3162ec2988e81e56d5c4e22cde9977" target="_blank">small Python script</a> written by Mārtiņš Možeiko. The key insight is that Microsoft publishes JSON manifests describing every component in Visual Studio, the same manifests the official installer uses. msvcup parses these manifests, identifies just the packages needed for compilation (the compiler, linker, headers, and libraries), and downloads them directly from Microsoft’s CDN. Everything lands in versioned directories under <code>C:\msvcup\</code>. For details on lock files, cross-compilation, and other features, see the <a href="https://github.com/marler8997/msvcup" target="_blank">msvcup README.md</a>.</p><p>The astute will also notice that our <code>build.bat</code> script never sources any batch files to set up the “Developer Environment”. The script contains two msvcup commands. The first installs the toolchain/SDK, and like a normal installation, it includes “vcvars” scripts to set up a developer environment. Instead, our <code>build.bat</code> leverages the <code>msvcup autoenv</code> command to create an “Automatic Environment”. This creates a directory that contains wrapper executables to set the environment variables on your behalf before forwarding to the underlying tools. It even includes a <code>toolchain.cmake</code> file which will point your CMake projects to these tools, allowing you to build your CMake projects outside a special environment.</p><p>At <a href="https://tuple.app/" target="_blank">Tuple</a> (a pair-programming app), I integrated msvcup into our build system and CI, which allowed us to remove the requirement for the user/CI to pre-install Visual Studio. Tuple compiles hundreds of C/C++ projects including WebRTC. This enabled both x86_64 and ARM builds on the CI as well as keeping the CI and everyone on the same toolchain/SDK.</p><p>The benefits:</p><ul><li><strong>Everything installs into a versioned directory.</strong> No problem installing versions side-by-side. Easy to remove or reinstall if something goes wrong.</li><li><strong>Cross-compilation enabled out of the box.</strong> msvcup currently always downloads the tools for all supported cross-targets, so you don’t have to do any work looking for all the components you need to cross-compile.</li><li><strong>Lock file support.</strong> A self-contained list of all the payloads/URLs. Everyone uses the same packages, and if Microsoft changes something upstream, you’ll know.</li><li><strong>Blazing fast.</strong> The <code>install</code> and <code>autoenv</code> commands are idempotent and complete in milliseconds when there’s no work to do.</li></ul><p>No more “it works on my machine because I have the 2019 Build Tools installed.” No more registry-diving to find where <code>cl.exe</code> is hiding this week. With msvcup, your environment is defined by your code, portable across machines, and ready to compile in milliseconds.</p><h3>Limitations</h3><p>msvcup focuses on the core compilation toolchain. If you need the full Visual Studio IDE, MSBuild-based project systems, or components like the C++/CLI compiler, you’ll still need the official installer. For most native development workflows, though, it covers what you actually need.</p><h2>A Real-World Example: Building Raylib</h2><p>Let’s try this on a real project. Here’s a script that builds <a href="https://github.com/raysan5/raylib" target="_blank">raylib</a> from scratch on a clean Windows system. In this case, we’ll just use the SDK without the autoenv:</p><pre><code>@setlocal

set TARGET_CPU=x64

@if not exist msvcup.exe (
    echo msvcup.exe: installing...
    curl -L -o msvcup.zip https://github.com/marler8997/msvcup/releases/download/v2026_02_07/msvcup-x86_64-windows.zip
    tar xf msvcup.zip
    del msvcup.zip
)

set MSVC=msvc-14.44.17.14
set SDK=sdk-10.0.22621.7

msvcup.exe install --lock-file msvcup.lock --manifest-update-off %MSVC% %SDK%
@if %errorlevel% neq 0 (exit /b %errorlevel%)

@if not exist raylib (
    git clone https://github.com/raysan5/raylib -b 5.5
)

call C:\msvcup\%MSVC%\vcvars-%TARGET_CPU%.bat
call C:\msvcup\%SDK%\vcvars-%TARGET_CPU%.bat

cmd /c "cd raylib\projects\scripts &amp;&amp; build-windows"
@if %errorlevel% neq 0 (exit /b %errorlevel%)

@echo build success: game exe at:
@echo .\raylib\projects\scripts\builds\windows-msvc\game.exe
</code></pre><p>No Visual Studio installation. No GUI. No prayer. Just a script that does exactly what it says.</p><p>P.S. <a href="https://marler8997.github.io/build-zig/windows.html" target="_blank">Here</a> is a page that shows how to use msvcup to build LLVM and Zig from scratch on Windows.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Two different tricks for fast LLM inference (119 pts)]]></title>
            <link>https://www.seangoedecke.com/fast-llm-inference/</link>
            <guid>47022329</guid>
            <pubDate>Sun, 15 Feb 2026 09:27:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.seangoedecke.com/fast-llm-inference/">https://www.seangoedecke.com/fast-llm-inference/</a>, See on <a href="https://news.ycombinator.com/item?id=47022329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><header></header><section><p><a href="https://platform.claude.com/docs/en/build-with-claude/fast-mode">Anthropic</a> and <a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/">OpenAI</a> both recently announced “fast mode”: a way to interact with their best coding model at significantly higher speeds.</p>
<p>These two versions of fast mode are very different. Anthropic’s <a href="https://platform.claude.com/docs/en/build-with-claude/fast-mode#how-fast-mode-works">offers</a> up to 2.5x tokens per second (so around 170, up from Opus 4.6’s 65). OpenAI’s offers more than 1000 tokens per second (up from GPT-5.3-Codex’s 65 tokens per second, so 15x). So OpenAI’s fast mode is six times faster than Anthropic’s<sup id="fnref-1"><a href="#fn-1">1</a></sup>.</p>
<p>However, Anthropic’s big advantage is that they’re serving their actual model. When you use their fast mode, you get real Opus 4.6, while when you use OpenAI’s fast mode you get GPT-5.3-Codex-Spark, not the real GPT-5.3-Codex. Spark is indeed much faster, but is a notably less capable model: good enough for many tasks, but it gets confused and messes up tool calls in ways that vanilla GPT-5.3-Codex would never do.</p>
<p>Why the differences? The AI labs aren’t advertising the details of how their fast modes work, but I’m pretty confident it’s something like this: <strong>Anthropic’s fast mode is backed by <em>low-batch-size</em> inference, while OpenAI’s fast mode is backed by special monster Cerebras chips</strong>. Let me unpack that a bit.</p>
<h3>How Anthropic’s fast mode works</h3>
<p>The tradeoff at the heart of AI inference economics is <em>batching</em>, because the main bottleneck is <em>memory</em>. GPUs are very fast, but moving data onto a GPU is not. Every inference operation requires copying all the tokens of the user’s prompt<sup id="fnref-2"><a href="#fn-2">2</a></sup> onto the GPU before inference can start. Batching multiple users up thus increases overall throughput at the cost of making users wait for the batch to be full.</p>
<p>A good analogy is a bus system. If you had zero batching for passengers - if, whenever someone got on a bus, the bus departed immediately - commutes would be much faster <em>for the people who managed to get on a bus</em>. But obviously overall throughput would be much lower, because people would be waiting at the bus stop for hours until they managed to actually get on one.</p>
<p>Anthropic’s fast mode offering is basically a bus pass that guarantees that the bus immediately leaves as soon as you get on. It’s six times the cost, because you’re effectively paying for all the other people who could have got on the bus with you, but it’s way faster<sup id="fnref-3"><a href="#fn-3">3</a></sup> because you spend <em>zero</em> time waiting for the bus to leave.</p>
<p>edit: I want to thank a reader for emailing me to point out that the “waiting for the bus” cost is really only paid for the first token, so that won’t affect <em>streaming</em> latency (just latency per turn or tool call). It’s thus better to think of the performance impact of batch size being mainly that smaller batches require fewer flops and thus execute more quickly. In my analogy, maybe it’s “lighter buses drive faster”, or something.</p>
<p>Obviously I can’t be fully certain this is right. Maybe they have access to some new ultra-fast compute that they’re running this on, or they’re doing some algorithmic trick nobody else has thought of. But I’m pretty sure this is it. Brand new compute or algorithmic tricks would likely require changes to the model (see below for OpenAI’s system), and “six times more expensive for 2.5x faster” is right in the ballpark for the kind of improvement you’d expect when switching to a low-batch-size regime.</p>
<h3>How OpenAI’s fast mode works</h3>
<p>OpenAI’s fast mode does not work anything like this. You can tell that simply because they’re introducing a new, worse model for it. There would be absolutely no reason to do that if they were simply tweaking batch sizes. Also, they told us in the announcement <a href="https://openai.com/index/introducing-gpt-5-3-codex-spark/">blog post</a> exactly what’s backing their fast mode: Cerebras.</p>
<p>OpenAI <a href="https://openai.com/index/cerebras-partnership/">announced</a> their Cerebras partnership a month ago in January. What’s Cerebras? They build “ultra low-latency compute”. What this means in practice is that they build <em>giant chips</em>. A H100 chip (fairly close to the frontier of inference chips) is just over a square inch in size. A Cerebras chip is <em>70</em> square inches.</p>
<p><span>
      <a href="https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/d165a/cerebras.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="cerebras" title="cerebras" src="https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/1c72d/cerebras.jpg" srcset="https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/a80bd/cerebras.jpg 148w,
https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/1c91a/cerebras.jpg 295w,
https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/1c72d/cerebras.jpg 590w,
https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/a8a14/cerebras.jpg 885w,
https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/fbd2c/cerebras.jpg 1180w,
https://www.seangoedecke.com/static/a32e19a54795813e122dcbc1a5e013ef/d165a/cerebras.jpg 1400w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p>
<p>You can see from pictures that the Cerebras chip has a grid-and-holes pattern all over it. That’s because silicon wafers this big are supposed to be broken into dozens of chips. Instead, Cerebras etches a giant chip over the entire thing.</p>
<p>The larger the chip, the more internal memory it can have. The idea is to have a chip with SRAM large enough <em>to fit the entire model</em>, so inference can happen entirely in-memory. Typically GPU SRAM is measured in the tens of <em>megabytes</em>. That means that a lot of inference time is spent streaming portions of the model weights from outside of SRAM into the GPU compute<sup id="fnref-4"><a href="#fn-4">4</a></sup>. If you could stream all of that from the (much faster) SRAM, inference would a big speedup: fifteen times faster, as it turns out!</p>
<p>So how much internal memory does the latest Cerebras chip have? <a href="https://arxiv.org/html/2503.11698v1#:~:text=Most%20recently%2C%20the%20Wafer%20Scale,of%2021%20petabytes%20per%20second.">44GB</a>. This puts OpenAI in kind of an awkward position. 44GB is enough to fit a small model (~20B params at fp16, ~40B params at int8 quantization), but clearly not enough to fit GPT-5.3-Codex. That’s why they’re offering a brand new model, and why the Spark model has a bit of “small model smell” to it: it’s a smaller <a href="https://en.wikipedia.org/wiki/Knowledge_distillation">distil</a> of the much larger GPT-5.3-Codex model<sup id="fnref-5"><a href="#fn-5">5</a></sup>.</p>
<h3>OpenAI’s version is much more technically impressive</h3>
<p>It’s interesting that the two major labs have two very different approaches to building fast AI inference. If I had to guess at a conspiracy theory, it would go something like this:</p>
<ul>
<li>OpenAI partner with Cerebras in mid-January, obviously to work on putting an OpenAI model on a fast Cerebras chip</li>
<li>Anthropic have no similar play available, but they know OpenAI will announce some kind of blazing-fast inference in February, and they want to have something in the news cycle to compete with that</li>
<li>Anthropic thus hustles to put together the kind of fast inference they <em>can</em> provide: simply lowering the batch size on their existing inference stack</li>
<li>Anthropic (probably) waits until a few days before OpenAI are done with their much more complex Cerebras implementation to announce it, so it looks like OpenAI copied them</li>
</ul>
<p>Obviously OpenAI’s achievement here is more technically impressive. Getting a model running on Cerebras chips is not trivial, because they’re so weird. Training a 20B or 40B param distil of GPT-5.3-Codex that is still kind-of-good-enough is not trivial. But I commend Anthropic for finding a sneaky way to get ahead of the announcement that will be largely opaque to non-technical people. It reminds me of OpenAI’s mid-2025 sneaky introduction of the Responses API to help them <a href="https://www.seangoedecke.com/responses-api">conceal their reasoning tokens</a>.</p>
<h3>Is fast AI inference the next big thing?</h3>
<p>Seeing the two major labs put out this feature might make you think that fast AI inference is the new major goal they’re chasing. I don’t think it is. If my theory above is right, Anthropic don’t care <em>that</em> much about fast inference, they just didn’t want to appear behind OpenAI. And OpenAI are mainly just exploring the capabilities of their new Cerebras partnership. It’s still largely an open question what kind of models can fit on these giant chips, how useful those models will be, and if the economics will make any sense.</p>
<p>I personally don’t find “fast, less-capable inference” particularly useful. I’ve been playing around with it in Codex and I don’t like it. The usefulness of AI agents is dominated by <em>how few mistakes they make</em>, not by their raw speed. Buying 6x the speed at the cost of 20% more mistakes is a bad bargain, because most of the user’s time is spent handling mistakes instead of waiting for the model<sup id="fnref-6"><a href="#fn-6">6</a></sup>.</p>
<p>However, it’s certainly possible that fast, less-capable inference becomes a core lower-level primitive in AI systems. Claude Code already uses <a href="https://github.com/anthropics/claude-code/issues/1098#issuecomment-2884244872">Haiku</a> for some operations. Maybe OpenAI will end up using Spark in a similar way.</p>
</section><hr><p>If you liked this post, consider<!-- --> <a href="https://buttondown.com/seangoedecke" target="_blank">subscribing</a> <!-- -->to email updates about my new posts, or<!-- --> <a href="https://news.ycombinator.com/submitlink?u=https://www.seangoedecke.com/fast-llm-inference/&amp;t=Two%20different%20tricks%20for%20fast%20LLM%20inference" target="_blank">sharing it on Hacker News</a>.<!-- --> Here's a preview of a related post that shares tags with this one.</p><blockquote><p>How does AI impact skill formation?</p><div><p>Two days ago, the Anthropic Fellows program released a paper called <a href="https://arxiv.org/pdf/2601.20245"><em>How AI Impacts Skill Formation</em></a>. Like <a href="https://www.seangoedecke.com/your-brain-on-chatgpt">other</a> <a href="https://www.seangoedecke.com/real-reasoning">papers</a> on AI before it, this one is being <a href="https://www.reddit.com/r/ExperiencedDevs/comments/1qqy2ro/anthropic_ai_assisted_coding_doesnt_show/">treated</a> as proof that AI makes you slower and dumber. Does it prove that?</p><p>The structure of the paper is sort of similar to the 2025 MIT study <a href="https://arxiv.org/pdf/2506.08872"><em>Your Brain on ChatGPT</em></a>. They got a group of people to perform a cognitive task that required learning a new skill: in this case, the Python Trio library. Half of those people were required to use AI and half were forbidden from using it. The researchers then quizzed those people to see how much information they retained about Trio.<br><a href="https://www.seangoedecke.com/how-does-ai-impact-skill-formation/">Continue reading...</a></p></div></blockquote><hr></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Oat – Ultra-lightweight, semantic, zero-dependency HTML UI component library (284 pts)]]></title>
            <link>https://oat.ink/</link>
            <guid>47021980</guid>
            <pubDate>Sun, 15 Feb 2026 08:17:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oat.ink/">https://oat.ink/</a>, See on <a href="https://news.ycombinator.com/item?id=47021980">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<section>
  <p>
    <a href="https://oat.ink/"><img src="https://oat.ink/logo.svg" alt="Oat UI"></a>
  </p>

  
  <h3>Semantic, minimal, zero dependencies. ~8KB CSS and JS.</h3>

  <p>
    Oat is an ultra-lightweight HTML + CSS, semantic UI component library with zero dependencies.
    No framework, build, or dev complexity. Just include the tiny CSS and JS files and you are good to go building
    decent looking web applications with most commonly needed components and elements.
  </p>
  <p>
    Semantic tags and attributes are styled contextually out of the box without classes, forcing best practices, and reducing
    markup class pollution. A few dynamic components are WebComponents and use minimal JavaScript.
  </p>
  <br>
  
</section>

<section>
  <article>
    <header>
      <h3>Light like an oat flake</h3>
    </header>
    <p><strong>6KB</strong> CSS, <strong>2.2KB</strong> JS, minified + gzipped.</p>
    <p>That's it.</p>
  </article>

  <article>
    <header>
      <h3>Zero dependencies</h3>
    </header>
    <p>Fully-standalone with no dependencies on any JS or CSS frameworks or libraries.
      No Node.js ecosystem garbage or bloat.
    </p>
  </article>

  <article>
    <header>
      <h3>Semantic HTML</h3>
    </header>
    <p>Native elements like <code>&lt;button&gt;</code>, <code>&lt;input&gt;</code>, <code>&lt;dialog&gt;</code> and
      semantic attributes like <code>role="button"</code> are styled directly. No classes.</p>
  </article>

  <article>
    <header>
      <h3>Accessibility</h3>
    </header>
    <p>Semantic HTML and ARIA roles are used (and forced in many places) throughout.
      Proper keyboard navigation support for all components and elements.</p>
  </article>

  <article>
    <header>
      <h3>Easy customization</h3>
    </header>
    <p>Easily customize the overall theme by overriding a handful of CSS variables. <code>data-theme="dark"</code> on body
      automatically uses the bundled dark theme.</p>
  </article>
</section>

<br>

<section>
  <h2>Why?</h2>
  <p>
    This was made after the unending frustration with the over-engineered bloat, complexity, and dependency-hell of pretty much every Javascript UI library and framework out there. Done with the continuous PTSD of rug-pulls and lockins of the Node.js ecosystem trash.
    <sup><a href="https://nadh.in/blog/javascript-ecosystem-software-development-are-a-hot-mess/">[1]</a></sup>
    I've published this, in case other Node.js ecosystem trauma victims find it useful.
  </p>
  <p>
    My goal is a simple, minimal, vanilla, standards-based UI library that I can use in my own projects for the long term without having to worry about Javascript ecosystem trash. Long term because it's just simple vanilla CSS and JS.
    The look and feel are influenced by the shadcn aesthetic.
  </p>
</section>



      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discord Distances Itself from Peter Thiel's Palantir Age Verification Firm (173 pts)]]></title>
            <link>https://kotaku.com/discord-palantir-peter-thiel-persona-age-verification-2000668951</link>
            <guid>47021421</guid>
            <pubDate>Sun, 15 Feb 2026 06:00:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kotaku.com/discord-palantir-peter-thiel-persona-age-verification-2000668951">https://kotaku.com/discord-palantir-peter-thiel-persona-age-verification-2000668951</a>, See on <a href="https://news.ycombinator.com/item?id=47021421">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
              
              <p><span>Last July was the cut-off date for major digital platforms to comply with the UK’s Online Safety Act (OSA). In an attempt to block access between minors and material deemed “harmful” by the government, platforms like Reddit, Spotify, and X began tougher age verification for their users, such as facial scans or, in some cases, even needing to see government ID. At the top of those <a href="https://kotaku.com/discord-age-verification-ai-hack-nitro-boycott-2000667358">stumbling to do so was Discord</a>, whose system is not only </span><a href="https://www.pcgamer.com/hardware/someone-has-already-made-a-free-in-browser-3d-model-to-bypass-discord-age-verification-that-works-on-any-potato-computer/"><span>easy to game</span></a><span> but also not impossible to compromise, with one major security breach </span><a href="https://www.theguardian.com/media/2025/oct/09/hack-age-verification-firm-discord-users-id-photos"><span>exposing some 70,000 users’ IDs shortly after</span></a><span>. Now Discord is </span><a href="https://kotaku.com/discord-will-force-you-to-scan-your-face-or-id-to-unlock-all-of-its-features-2000666884"><span>looking to enforce age verification globally</span></a><span>. A firm Discord at one point worked with to do so may be even more controversial than the decision itself.</span></p> <p><span>While the roll-out is aimed for March, </span><a href="https://www.pcgamer.com/software/platforms/oh-good-discords-age-verification-rollout-has-ties-to-palantir-co-founder-and-panopticon-architect-peter-thiel/"><i><span>PC Gamer</span></i><span> reports</span></a><span> that some Discord users have already been prompted for new age verification, this time using the third-party service Persona. Started in 2018, Persona develops identity detection and anti-fraud technologies. They’ve been having an absolute field day since the OSA, being implemented to verify user ID across Reddit and Roblox. One sticking point, however, is who’s backing the company: Peter Thiel, the cofounder of ICE-approved surveillance firm Palantir.&nbsp;</span></p>

 <blockquote data-width="500" data-dnt="true"> <p lang="en" dir="ltr">managed to catch it <a href="https://t.co/Yyu0FaoDJ7">pic.twitter.com/Yyu0FaoDJ7</a></p> <p>— Folf (@itsfolf) <a href="https://twitter.com/itsfolf/status/2021749585111069152?ref_src=twsrc%5Etfw">February 12, 2026</a></p></blockquote>  <p><span>One of Persona’s biggest investors is the Founders Fund, valuing the company at $1.5 billion and </span><a href="https://www.bloomberg.com/news/articles/2021-09-15/founders-fund-values-identity-startup-persona-at-1-5-billion"><span>rallying $150 million towards it in 2021</span></a><span>. The Founders Fund began in the mid-2000s and made key early investments in the likes of SpaceX, AirBNB, OpenAI and Polymarket. All your favorite tech things “disrupting” the modern world. And who would unleash such a monetary power unto civilization? Why, none other than your friend and mine, <a href="https://kotaku.com/hulk-hogan-sex-tape-gawker-lawsuit-kotaku-go-media-1851787000">the anti-humanist, antichrist-awaiting Thiel</a>.&nbsp;</span></p> <p><span>Thiel, of course, is known for many things. A co-founder of PayPal, Thiel is now more closely affiliated with Palantir, a company specializing in digital surveillance and exploiting user information. Palantir, named after the crystal balls that allow communication across Middle-earth in <em>The </em><em>Lord of the Rings</em>,&nbsp;has been around since 2003 but has kept plenty busy lately. </span><a href="https://www.404media.co/elite-the-palantir-app-ice-uses-to-find-neighborhoods-to-raid/"><i><span>404</span></i><span> uncovered</span></a><span> how the company has been developing ELITE, an instrument to monitor user information for the purpose of conducting ICE raids. Elsewhere, the recent, massive disclosure of Epstein emails had </span><a href="https://www.wired.com/story/epstein-files-tech-elites-gates-thiel-musk/"><span>reoccurring correspondence</span></a><span> between the world’s most active user information broker and the world’s most famous sex trafficker. The two discussed the lawsuit to <a href="https://aftermath.site/jeffrey-epstein-files-kotick-thiel-xbox-rockstar/">end</a> </span><a href="https://aftermath.site/jeffrey-epstein-files-kotick-thiel-xbox-rockstar/"><i><span>Gawker</span></i></a><span><a href="https://aftermath.site/jeffrey-epstein-files-kotick-thiel-xbox-rockstar/"> and how to best balkanize the planet</a>.&nbsp;</span></p>

 <p><span>Having the Founders Fund so close to expanded data-capturing across Discord, one of the more private places to have a public conversation online, </span><a href="https://piunikaweb.com/2026/02/12/discord-uk-age-verification-persona-vendor-shift/"><span>has made users a little itchy</span></a><span>. The platform has not been entirely clear about how it aims to rapidly expand its age verification process, stating a mix of mandatory scanning but also </span><a href="https://www.pcgamer.com/hardware/discord-clarifies-it-is-not-requiring-everyone-to-complete-a-face-scan-or-upload-an-id-and-will-confirm-your-age-group-using-information-we-already-have/"><span>using existing user data to guesstimate</span></a><span> if a user is in their 30s (which is great news for everyone who communicates through </span><i><span>Simpsons</span></i><span> quotes). </span></p>

 <p><a href="https://support.discord.com/hc/en-us/articles/30326565624343-How-to-Complete-Age-Assurance-on-Discord"><span>In an official update</span></a><span>, Discord suggested users who encountered prompts from Persona are part of “an experiment” and that the information will only be stored for seven days. How the tech will be used in the long term is yet to be known. When asked for comment, Discord told <em>Kotaku</em> its work with Persona was part of a “limited test” which has since been concluded.&nbsp;</span></p> <p><span>Regardless, I will see you on the forums.</span></p>
                          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flashpoint Archive – Over 200k web games and animations preserved (255 pts)]]></title>
            <link>https://flashpointarchive.org</link>
            <guid>47021354</guid>
            <pubDate>Sun, 15 Feb 2026 05:43:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flashpointarchive.org">https://flashpointarchive.org</a>, See on <a href="https://news.ycombinator.com/item?id=47021354">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                <p><span>Welcome</span></p><hr>
<p>
    <iframe src="https://www.youtube.com/embed/0nIbn3vvvMc" frameborder="0" allowfullscreen=""></iframe>
</p><p>

Flashpoint Archive is a community effort to preserve games and animations from the web.</p><p>

Internet history and culture is important, and the web is evolving at such a rapid pace that what might be commonplace today could be obsolete tomorrow. This project is dedicated to preserving as many experiences from these platforms as possible, so that they aren't lost to time. Since December 2017, <a href="https://flashpointproject.github.io/flashpoint-database/statistics/">over 200,000 games and animations</a> have been preserved across more than a hundred browser plugins and web technologies.</p><p>

In addition to our preservation efforts, we also provide a highly flexible software package for reliable navigation and playback of preserved content. Among the software that powers Flashpoint is <a href="https://github.com/FlashpointProject/launcher">a fully-featured launcher</a> that acts as a frontend for the collection, <a href="https://github.com/FlashpointProject/FlashpointProxy">a proxy</a> that tricks games into thinking they're running on the live web, and <a href="https://github.com/FlashpointProject/FlashpointSecureTools">a sandbox</a> that allows for secure playback of plugin-enabled content - all of which are <a href="https://flashpointarchive.org/source">open-source software</a>.</p>

<p><a href="https://flashpointarchive.org/images/launcher.png"><img src="https://flashpointarchive.org/images/launcher_thumb.png"></a>
</p><p>

The project <a href="https://flashpointarchive.org/news#starting-date">was originally started</a> by BlueMaxima in an attempt to outrun the disappearance of webgames prior to the death of Flash. It has since evolved into a major undertaking involving hundreds of community contributors from around the world, encompassing both games and animations created for numerous internet plugins, frameworks, and standards.</p><p>

Flashpoint Archive operates as non-profit with the goal of furthering efforts in the preservation and accessibility of games, animations and other digital interactive experiences from the web. If you wish to support us or find out more about how we're funded and where these funds are spent, please use the Donate button in the left sidebar or visit our <a href="https://opencollective.com/flashpointarchive">Open Collective page</a>.
</p>
            </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NewPipe: YouTube client without vertical videos and algorithmic feed (306 pts)]]></title>
            <link>https://newpipe.net/</link>
            <guid>47020218</guid>
            <pubDate>Sun, 15 Feb 2026 01:24:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://newpipe.net/">https://newpipe.net/</a>, See on <a href="https://news.ycombinator.com/item?id=47020218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text-1">
                        <p><strong>Do you like watching videos on YouTube but want an intuitive, feature-rich and privacy friendly app for that?</strong></p>
                        <p><span>NewPipe</span> has been created with the purpose of getting the original YouTube experience on your smartphone without annoying ads and questionable permissions.</p>
                        <p>The application is open source and you can check on it at <a href="https://github.com/TeamNewPipe/NewPipe/">GitHub</a>.</p>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I love the work of the ArchWiki maintainers (763 pts)]]></title>
            <link>https://k7r.eu/i-love-the-work-of-the-archwiki-maintainers/</link>
            <guid>47020191</guid>
            <pubDate>Sun, 15 Feb 2026 01:20:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://k7r.eu/i-love-the-work-of-the-archwiki-maintainers/">https://k7r.eu/i-love-the-work-of-the-archwiki-maintainers/</a>, See on <a href="https://news.ycombinator.com/item?id=47020191">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>For this year's <a href="https://ilovefs.org/">"I love Free Software Day"</a> I
would like to thank the maintainers of Free Software documentation, and
here especially the maintainers of the
<a href="https://wiki.archlinux.org/">ArchWiki</a>. Maintainers in general, and
maintainers of documentation most of the time get way too little
recognition for their contributions to software freedom.</p>
<p><img alt="Myself, Arch Project Leader Levente, ArchWiki maintainer Ferdinand, and FSFE's vice president Heiki at FOSDEM 2025 after I handed them over some hacker chocolate" src="https://k7r.eu/i-love-the-work-of-the-archwiki-maintainers/ilovefs-archwiki-reduced.jpg"></p>
<p><em>Myself, Arch Project Leader Levente, ArchWiki maintainer Ferdinand
(Alad), and FSFE's vice president Heiki at FOSDEM 2026 after I handed
them over some hacker chocolate.</em></p>
<p>The ArchWiki is a resource, I myself and many people around me regularly
consult - no matter if it is actually about Arch or another Free Software
distribution. There are countless times, when I read articles there to
get a better understanding of the tools I daily use, like e-mail
programs, editors, or all kinds of window managers I used over time. It
helped me to discover some handy features or configuration tips that
were difficult for me to find in the documentation of the software
itself.</p>
<p>Whenever I run into issues setting up a GNU/Linux distribution for
myself or family and friends, the ArchWiki had my back!</p>
<p>Whenever I want to better understand a software, the ArchWiki is most
often the first page I end up consulting.</p>
<p><em>You are one of the pearls of the internet!</em> Or in Edward Snowden's
words:</p>
<blockquote>
<p>"Is it just me, or have search results become absolute garbage for
  basically every site? It's nearly impossible to discover useful
  information these days (outside the ArchWiki). "
  <a href="https://x.com/Snowden/status/1460666075033575425">https://x.com/Snowden/status/1460666075033575425</a></p>
</blockquote>
<p>Thank you, to all the ArchWiki contributors for gathering all the
knowledge to help others in society to better understand technology and for
the ArchWiki maintainers to ensure the long term availability and
reliability of this crucial resource.</p>
<p>If you also appreciated the work of the ArchWiki maintainers for our
society, tell them as well, and I encourage you to make a <a href="https://archlinux.org/donate/">donation to
Arch</a>.</p>
<p>PS: Thanks also to Morton for connecting me with Ferdinand and Levente
at FOSDEM.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Off Grid – Run AI text, image gen, vision offline on your phone (112 pts)]]></title>
            <link>https://github.com/alichherawalla/off-grid-mobile</link>
            <guid>47019133</guid>
            <pubDate>Sat, 14 Feb 2026 22:39:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/alichherawalla/off-grid-mobile">https://github.com/alichherawalla/off-grid-mobile</a>, See on <a href="https://news.ycombinator.com/item?id=47019133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/alichherawalla/off-grid-mobile/blob/main/src/assets/logo.png"><img src="https://github.com/alichherawalla/off-grid-mobile/raw/main/src/assets/logo.png" alt="Off Grid Logo" width="120"></a></p><p dir="auto"><h2 tabindex="-1" dir="auto">Off Grid</h2><a id="user-content-off-grid" aria-label="Permalink: Off Grid" href="#off-grid"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">The Swiss Army Knife of On-Device AI</h3><a id="user-content-the-swiss-army-knife-of-on-device-ai" aria-label="Permalink: The Swiss Army Knife of On-Device AI" href="#the-swiss-army-knife-of-on-device-ai"></a></p>
<p dir="auto"><strong>Chat. Generate images. See. Listen. All on your phone. All offline. Zero data leaves your device.</strong></p>
<p dir="auto"><a href="https://github.com/alichherawalla/off-grid-mobile"><img src="https://camo.githubusercontent.com/2fedb9df35f66630c39bc2d0e858164cf11030436dd463435f5df5626a4b3269/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f616c6963686865726177616c6c612f6f66662d677269642d6d6f62696c653f7374796c653d736f6369616c" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/alichherawalla/off-grid-mobile?style=social"></a>
<a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/08cef40a9105b6526ca22088bc514fbfdbc9aac1ddbf8d4e6c750e3a88a44dca/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d626c75652e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-blue.svg"></a>
<a href="#install"><img src="https://camo.githubusercontent.com/340ee545988881f9af9e17d65b855afcd45e802753e1f41eacc93d6e6d598c6d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506c6174666f726d2d416e64726f6964253230253743253230694f532d677265656e2e737667" alt="Platform" data-canonical-src="https://img.shields.io/badge/Platform-Android%20%7C%20iOS-green.svg"></a></p>
</div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Not just another chat app</h2><a id="user-content-not-just-another-chat-app" aria-label="Permalink: Not just another chat app" href="#not-just-another-chat-app"></a></p>
<p dir="auto">Most "local LLM" apps give you a text chatbot and call it a day. Off Grid is a <strong>complete offline AI suite</strong> — text generation, image generation, vision AI, voice transcription, and document analysis, all running natively on your phone's hardware.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">What can it do?</h2><a id="user-content-what-can-it-do" aria-label="Permalink: What can it do?" href="#what-can-it-do"></a></p>

<p dir="auto"><strong>Text Generation</strong> — Run Qwen 3, Llama 3.2, Gemma 3, Phi-4, and any GGUF model. Streaming responses, thinking mode, 15-30 tok/s on flagship devices. Bring your own <code>.gguf</code> files too.</p>
<p dir="auto"><strong>Image Generation</strong> — On-device Stable Diffusion with real-time preview. NPU-accelerated on Snapdragon (5-10s per image), Core ML on iOS. 20+ models including Absolute Reality, DreamShaper, Anything V5.</p>
<p dir="auto"><strong>Vision AI</strong> — Point your camera at anything and ask questions. SmolVLM, Qwen3-VL, Gemma 3n — analyze documents, describe scenes, read receipts. ~7s on flagship devices.</p>
<p dir="auto"><strong>Voice Input</strong> — On-device Whisper speech-to-text. Hold to record, auto-transcribe. No audio ever leaves your phone.</p>
<p dir="auto"><strong>Document Analysis</strong> — Attach PDFs, code files, CSVs, and more to your conversations. Native PDF text extraction on both platforms.</p>
<p dir="auto"><strong>AI Prompt Enhancement</strong> — Simple prompt in, detailed Stable Diffusion prompt out. Your text model automatically enhances image generation prompts.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Performance</h2><a id="user-content-performance" aria-label="Permalink: Performance" href="#performance"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Task</th>
<th>Flagship</th>
<th>Mid-range</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text generation</td>
<td>15-30 tok/s</td>
<td>5-15 tok/s</td>
</tr>
<tr>
<td>Image gen (NPU)</td>
<td>5-10s</td>
<td>—</td>
</tr>
<tr>
<td>Image gen (CPU)</td>
<td>~15s</td>
<td>~30s</td>
</tr>
<tr>
<td>Vision inference</td>
<td>~7s</td>
<td>~15s</td>
</tr>
<tr>
<td>Voice transcription</td>
<td>Real-time</td>
<td>Real-time</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Tested on Snapdragon 8 Gen 2/3, Apple A17 Pro. Results vary by model size and quantization.</p>
<hr>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install</h2><a id="user-content-install" aria-label="Permalink: Install" href="#install"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Android — Download APK</h3><a id="user-content-android--download-apk" aria-label="Permalink: Android — Download APK" href="#android--download-apk"></a></p>
<p dir="auto">Grab the latest APK from <a href="https://github.com/alichherawalla/off-grid-mobile/releases/latest"><strong>GitHub Releases</strong></a>, install, and start chatting in under 2 minutes.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Build from source</h3><a id="user-content-build-from-source" aria-label="Permalink: Build from source" href="#build-from-source"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/alichherawalla/off-grid-mobile.git
cd off-grid-mobile
npm install

# Android
cd android &amp;&amp; ./gradlew clean &amp;&amp; cd ..
npm run android

# iOS
cd ios &amp;&amp; pod install &amp;&amp; cd ..
npm run ios"><pre>git clone https://github.com/alichherawalla/off-grid-mobile.git
<span>cd</span> off-grid-mobile
npm install

<span><span>#</span> Android</span>
<span>cd</span> android <span>&amp;&amp;</span> ./gradlew clean <span>&amp;&amp;</span> <span>cd</span> ..
npm run android

<span><span>#</span> iOS</span>
<span>cd</span> ios <span>&amp;&amp;</span> pod install <span>&amp;&amp;</span> <span>cd</span> ..
npm run ios</pre></div>
<blockquote>
<p dir="auto">Requires Node.js 20+, JDK 17 / Android SDK 36 (Android), Xcode 15+ (iOS). See <a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/ARCHITECTURE.md#building-from-source">full build guide</a>.</p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Documentation</h2><a id="user-content-documentation" aria-label="Permalink: Documentation" href="#documentation"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Document</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/ARCHITECTURE.md">Architecture &amp; Technical Reference</a></td>
<td>System architecture, design patterns, native modules, performance tuning</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/standards/CODEBASE_GUIDE.md">Codebase Guide</a></td>
<td>Comprehensive code walkthrough</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/design/DESIGN_PHILOSOPHY_SYSTEM.md">Design System</a></td>
<td>Brutalist design philosophy, theme system, tokens</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/design/VISUAL_HIERARCHY_STANDARD.md">Visual Hierarchy Standard</a></td>
<td>Visual hierarchy and layout standards</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/test/TEST_FLOWS.md">Test Flows</a></td>
<td>End-to-end test flows</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/test/TEST_COVERAGE_REPORT.md">Test Coverage Report</a></td>
<td>Current test coverage status</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/test/TEST_PRIORITY_MAP.md">Test Priority Map</a></td>
<td>Test prioritization guide</td>
</tr>
<tr>
<td><a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/test/TEST_SPEC_FORMAT.md">Test Spec Format</a></td>
<td>Test specification format reference</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">Contributions welcome! Fork, branch, PR. See <a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/ARCHITECTURE.md#contributing">development guidelines</a> for code style and the <a href="https://github.com/alichherawalla/off-grid-mobile/blob/main/docs/standards/CODEBASE_GUIDE.md">codebase guide</a> for patterns.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Acknowledgments</h2><a id="user-content-acknowledgments" aria-label="Permalink: Acknowledgments" href="#acknowledgments"></a></p>
<p dir="auto">Built on the shoulders of giants:
<a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> | <a href="https://github.com/ggerganov/whisper.cpp">whisper.cpp</a> | <a href="https://github.com/mybigday/llama.rn">llama.rn</a> | <a href="https://github.com/mybigday/whisper.rn">whisper.rn</a> | <a href="https://github.com/nicenemo/local-dream">local-dream</a> | <a href="https://github.com/apple/ml-stable-diffusion">ml-stable-diffusion</a> | <a href="https://github.com/alibaba/MNN">MNN</a> | <a href="https://huggingface.co/" rel="nofollow">Hugging Face</a></p>
<hr>
<div dir="auto">
<p dir="auto"><strong>Off Grid</strong> — Your AI, your device, your data.</p>
<p dir="auto"><em>No cloud. No subscription. No data harvesting. Just AI that works anywhere.</em></p>
</div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Threat Radar – Live cyber threat intelligence dashboard (223 pts)]]></title>
            <link>https://radar.offseq.com/</link>
            <guid>47018888</guid>
            <pubDate>Sat, 14 Feb 2026 22:09:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://radar.offseq.com/">https://radar.offseq.com/</a>, See on <a href="https://news.ycombinator.com/item?id=47018888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content"><div><p>Real-time view of cyber threats affecting European countries and beyond</p></div><div><div><p><span>Updated <span>02/14/2026, 22:30:30 UTC</span></span></p></div><div><p>Severity Distribution</p><h2><span>4928</span> Critical</h2></div></div><section><div><p><span>Pro Console Lifetime</span></p><div><h3>Stop chasing alerts. Route them.</h3><p>Start free, then upgrade once to turn Radar into an automated delivery engine for your security stack.</p></div></div><div><div><p>Custom feeds</p><p>Build private feeds with layered filters and curated intel views.</p></div><div><p>Automations + integrations</p><p>Email alerts, webhooks, Slack, and routes into SIEMs or MISPs.</p></div><div><p>API access (baseline limits)</p><p>Unlock API v1 access; subscriptions increase rate limits.</p></div></div></section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You can't trust the internet anymore (211 pts)]]></title>
            <link>https://nicole.express/2026/not-my-casual-hobby.html</link>
            <guid>47017727</guid>
            <pubDate>Sat, 14 Feb 2026 19:51:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nicole.express/2026/not-my-casual-hobby.html">https://nicole.express/2026/not-my-casual-hobby.html</a>, See on <a href="https://news.ycombinator.com/item?id=47017727">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
    This is a "byte" post. It may not be as detailed as other posts.
  </p><div itemprop="articleBody">
    <p>I like things that are strange and a bit obscure. It’s a habit of mine, and a lot of this blog is to document things I haven’t heard of before, because I wanted to learn about them. I mean, jeez, I’m certainly not writing blog posts about <a href="https://nicole.express/2026/put-your-clothes-back-on.html">strip </a><a href="https://nicole.express/2026/spooky-ghost-stories.html">mahjong</a> because the people demand it. But I can’t stop seeing misinformation everywhere, and I have to say something. This post is just a rant.</p>

<h2 id="phantasy-star-fukkokuban"><em>Phantasy Star Fukkokuban</em></h2>

<p>This is <em>Phantasy Star Fukkokuban</em>, a Japanese Sega Genesis game released in 1994 to commemorate the release of <em>Phantasy Star IV</em> by re-releasing the original. It has an interesting component: it is the Master System game, just packaged into a Genesis cart. The PCB wires the Genesis lines the same way your Power Base Converter would. My guess is the reason for this is because the Master System wasn’t very popular in Japan, and <em>Phantasy Star IV</em> tied together the whole series with a lot of tiebacks to the first one in particular.</p>

<p><img src="https://nicole.express/assets/img/2sega/fuk.jpeg" title="You know, Sega could've included the FM soundtrack, if they had shelled out for a YM2413 in the cart" alt="Phantasy Star Fukkokuban, which uses the Phantasy Star box art on a Japanese cartridge shell."></p>

<p>As a Master System game disguised as a Genesis one, this game is technically interesting. Some Genesis consoles can’t play Master System games, and those ones can’t play this game either. Also, I love the <em>Phantasy Star</em> series; even if 2 is my favorite. This makes this cartridge a perfect subject for my interest, so I’ve talked about it before and will talk about it again. In fact, I have a post I’m working on where I mention it.</p>

<p><img src="https://nicole.express/assets/img/ai-is-bad/ps1987.png" title="taken on my mega drive 2" alt="Phantasy Star title screen. (C) SEGA 1987"></p>

<p>So there I was, writing a blog post, and wanted to look up the release date. The first result I found in DuckDuckGo, my search engine?</p>

<p><img src="https://nicole.express/assets/img/ai-is-bad/results.png" title="all results are personalized these days I assume" alt="DuckDuckGo search results. First, GameFAQs. Second, TCRF. Third, Press Start Gaming. An abandonware site is at the bottom"></p>

<p><a href="https://gamefaqs.gamespot.com/genesis/570415-phantasy-star-fukkokuban">GameFAQs</a> is at the top; a titan since the 1990’s. The second result is <a href="https://tcrf.net/Phantasy_Star">The Cutting Room Floor</a>, a wiki much beloved by myself. And then the third result is <a href="https://pressstartgaming.com/phantasy-star-fukkokuban-a-classic-reimagined/">“Press Start Gaming”</a>.</p>

<p><img src="https://nicole.express/assets/img/ai-is-bad/start.png" title="finally, a console for my horrifying NES-Genesis hybrid" alt="Welcome to Press Start Gaming, your ultimate destination for gaming and tech enthusiasts! Founded with a passion for exploring the ever-evolving worlds of gaming and technology, we aim to deliver high-quality reviews, insightful articles, and the latest industry news to help you stay informed and inspired. Whether you’re a casual gamer, a tech aficionado, or a seasoned pro, we have something for everyone."></p>

<p>And here’s a thing about me. I want to trust new websites. I have a bias towards clicking on articles from sites I don’t know, because to be quite honest, I’ve read the TCRF page on <em>Phantasy Star</em> a thousand times. How else do you learn something new?</p>

<p><img src="https://nicole.express/assets/img/ai-is-bad/ps1988.png" title="ALSO taken on my mega drive 2! what a twist" alt="Phantasy Star title screen. (C) SEGA 1988"></p>

<p>Also, I clicked it because the headline was “Phantasy Star Fukkokuban: A Classic Reimagined”. Because here’s the thing. It talks about how the graphics were improved:</p>

<blockquote>
  <p>Phantasy Star Fukkokuban breathes new life into the classic with its updated graphics and sound design. The visual overhaul retains the charm of the original’s 8-bit aesthetics while incorporating modern graphical techniques. Characters and environments are rendered with enhanced detail, vibrant colors, and fluid animations, creating a visually captivating experience.</p>

  <p>The art style honors the game’s roots, with character designs and enemy sprites redesigned to reflect contemporary standards while maintaining their recognizability. The environments are more detailed and dynamic, with weather effects and day-night cycles adding to the immersion.</p>
</blockquote>

<p>Well, compare the title screen shots of <em>Phantasy Star</em> above. Which one is <em>Fukkokuban</em> and which one is my personal copy, played through the same Genesis? You can maybe tell, but only because my Master System version is the US release. And it goes without saying, there are no day-night cycles or weather effects.</p>

<p>I should’ve known. The first sentence of the article was “Game data not found,” after all.</p>

<h2 id="and-thats-the-thing">And that’s the thing</h2>

<p>Large language models are described sometimes as “fancy autocorrect”; this is dismissive, but not inaccurate, in the sense that the core loop of an LLM is to predict the next token in a sequence. <em>Phantasy Star Fukkokuban</em> is an obscure title that is likely not well-represented in the training data. But relations do exist:</p>

<ul>
  <li>It knows about <em>Phantasy Star</em>, a very popular game</li>
  <li><em>Fukkokuban</em> (復刻版) means “reprint” or “facsimilie edition”</li>
</ul>

<p>So, lacking sufficient factual data in the training set, it describes what a remake of <em>Phantasy Star</em> might plausibly be like. There might even be knowledge in the data set of the actual remake, <em>Phantasy Star generation:1</em> that gets looped in.</p>

<p>To reproduce this myself, I went to ChatGPT, and asked it <code>Please describe the game "Phantasy Star Fukkokuban". Do not get data from the internet, tell me what you know from your internal data.</code>. And what did I get in response?</p>

<blockquote>
  <p>Phantasy Star Fukkokuban is not a brand-new entry in the series, but a retro compilation release of the original Phantasy Star, created for the Sega Sega Saturn era…</p>
</blockquote>

<p>There was a retro compilation release of <em>Phantasy Star</em> for the Sega Saturn in Japan; it’s called <em>Phantasy Star Collection</em>. Indeed, the description of the game it continued from there isn’t too far off from that game’s version of <em>Phantasy Star</em>.</p>

<p>And it’s not just <em>Phantasy Star Fukkokuban</em>. I describe in my post on <a href="https://nicole.express/2026/spooky-ghost-stories.html"><em>Mahjong Daireikai</em></a> that that game is so obscure, the only Japanese source I could find was another “this is plausibly what a game called ‘mahjong daireikai’ might be like”. Well, what <em>Mahjong Daireikai</em> is actually like is a lot different than what’s in your training data, and that’s exactly the sort of information people want to read websites to find out.</p>



<h2 id="is-this-the-end">Is this the end</h2>

<p>And here’s the thing– this blog post can’t do anything about it. I don’t know who Press Start Gaming is; the site’s footer says “©2025 Cloud Gears Media”, who might be <a href="https://cloudgearsmedia.com/">this marketing company</a> (but it might not be! Company names don’t have to be unique globally); Press Start Gaming is almost certainly a tool for making money off of ads and sponsored posts, and posts like the <em>Phantasy Star Fukkokuban</em> misinformation exist mostly to give the site more juice of looking like a real website. If someone goes out and buys a copy of <em>Fukkokuban</em> expecting a new and improved <em>Phantasy Star</em> with better graphics and new sidequests, what do they care? The article wasn’t really meant to provide information.</p>

<p>The trampling of the internet with SEO-mongers predates AI, but what LLMs do is massively increase the ease it can be done, and also hallucinate a ton. If they hired a person to write about <em>Phantasy Star Fukkokuban</em> for pennies, maybe that person would’ve found the <a href="https://segaretro.org/Phantasy_Star#Phantasy_Star_Fukkokuban">Sega Retro</a> page or something and at least grabbed some facts. Now you don’t need to do even that. And no one making these decisions reads <em>Nicole Express</em>, or even cares about actually providing information with their sites. That’s not what they’re for.</p>

<p>Anyways, eventually models will do a better job integrating <em>Nicole Express</em>, and will know more information about <em>Phantasy Star Fukkokuban</em>. And is this the worst thing the AI boom is doing? <a href="https://www.aol.com/news/naacp-threatens-sue-musk-xai-233138040.html">No,</a> <a href="https://www.yahoo.com/news/articles/groups-threaten-suit-over-xai-223759493.html">not</a> <a href="https://www.cnn.com/2025/08/26/tech/openai-chatgpt-teen-suicide-lawsuit">even</a> <a href="https://www.reuters.com/world/us/americans-fear-ai-permanently-displacing-workers-reutersipsos-poll-finds-2025-08-19/">close.</a> Even the <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">fully automated hit piece</a> against an open-source developer is probably worse than this.</p>

<p>But it’s a real shame. The commons of the internet are probably already lost, and while I might want to learn new things from new sites, I’ll just have to stick to those with pre-LLM reptuations that I trust. Well, until those sites burn their reputations to make a few extra pennies with AI, like <a href="https://mastodon.gamedev.place/@xot/116065688012051690"><em>Ars Technica</em></a> seems to just have. (link goes to a Mastodon thread in lieu of a better source for now)</p>

<p>This post is just a rant. Thanks for listening, at least.</p>



  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 3 Deep Think drew me a good SVG of a pelican riding a bicycle (130 pts)]]></title>
            <link>https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/</link>
            <guid>47017682</guid>
            <pubDate>Sat, 14 Feb 2026 19:47:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/">https://simonwillison.net/2026/Feb/12/gemini-3-deep-think/</a>, See on <a href="https://news.ycombinator.com/item?id=47017682">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-deep-think/">Gemini 3 Deep Think</a></strong> (<a href="https://news.ycombinator.com/item?id=46991240" title="Hacker News">via</a>) New from Google. They say it's "built to push the frontier of intelligence and solve modern challenges across science, research, and engineering".</p>
<p>It drew me a <em>really good</em> <a href="https://gist.github.com/simonw/7e317ebb5cf8e75b2fcec4d0694a8199">SVG of a pelican riding a bicycle</a>! I think this is the best one I've seen so far - here's <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">my previous collection</a>.</p>
<p><img alt="This alt text also generated by Gemini 3 Deep Think: A highly detailed, colorful, flat vector illustration with thick dark blue outlines depicting a stylized white pelican riding a bright cyan blue bicycle from left to right across a sandy beige beach with white speed lines indicating forward motion. The pelican features a light blue eye, a pink cheek blush, a massive bill with a vertical gradient from yellow to orange, a backward magenta cap with a cyan brim and a small yellow top button, and a matching magenta scarf blowing backward in the wind. Its white wing, accented with a grey mid-section and dark blue feather tips, reaches forward to grip the handlebars, while its long tan leg and orange foot press down on an orange pedal. Attached to the front handlebars is a white wire basket carrying a bright blue cartoon fish that is pointing upwards and forwards. The bicycle itself has a cyan frame, dark blue tires, striking neon pink inner rims, cyan spokes, a white front chainring, and a dark blue chain. Behind the pelican, a grey trapezoidal pier extends from the sand toward a horizontal band of deep blue ocean water detailed with light cyan wavy lines. A massive, solid yellow-orange semi-circle sun sits on the horizon line, setting directly behind the bicycle frame. The background sky is a smooth vertical gradient transitioning from soft pink at the top to warm golden-yellow at the horizon, decorated with stylized pale peach fluffy clouds, thin white horizontal wind streaks, twinkling four-pointed white stars, and small brown v-shaped silhouettes of distant flying birds." src="https://static.simonwillison.net/static/2026/gemini-3-deep-think-pelican.png"></p>
<p>(And since it's an FAQ, here's my answer to <a href="https://simonwillison.net/2025/Nov/13/training-for-pelicans-riding-bicycles/">What happens if AI labs train for pelicans riding bicycles?</a>)</p>
<p>Since it did so well on my basic <code>Generate an SVG of a pelican riding a bicycle</code> I decided to try the <a href="https://simonwillison.net/2025/Nov/18/gemini-3/#and-a-new-pelican-benchmark">more challenging version</a> as well:</p>
<blockquote>
<p><code>Generate an SVG of a California brown pelican riding a bicycle. The bicycle must have spokes and a correctly shaped bicycle frame. The pelican must have its characteristic large pouch, and there should be a clear indication of feathers. The pelican must be clearly pedaling the bicycle. The image should show the full breeding plumage of the California brown pelican.</code></p>
</blockquote>
<p>Here's <a href="https://gist.github.com/simonw/154c0cc7b4daed579f6a5e616250ecc8">what I got</a>:</p>
<p><img alt="Also described by Gemini 3 Deep Think: A highly detailed, vibrant, and stylized vector illustration of a whimsical bird resembling a mix between a pelican and a frigatebird enthusiastically riding a bright cyan bicycle from left to right across a flat tan and brown surface. The bird leans horizontally over the frame in an aerodynamic racing posture, with thin, dark brown wing-like arms reaching forward to grip the silver handlebars and a single thick brown leg, patterned with white V-shapes, stretching down to press on a black pedal. The bird's most prominent and striking feature is an enormous, vividly bright red, inflated throat pouch hanging beneath a long, straight grey upper beak that ends in a small orange hook. Its head is mostly white with a small pink patch surrounding the eye, a dark brown stripe running down the back of its neck, and a distinctive curly pale yellow crest on the very top. The bird's round, dark brown body shares the same repeating white V-shaped feather pattern as its leg and is accented by a folded wing resting on its side, made up of cleanly layered light blue and grey feathers. A tail composed of four stiff, straight dark brown feathers extends directly backward. Thin white horizontal speed lines trail behind the back wheel and the bird's tail, emphasizing swift forward motion. The bicycle features a classic diamond frame, large wheels with thin black tires, grey rims, and detailed silver spokes, along with a clearly visible front chainring, silver chain, and rear cog. The whimsical scene is set against a clear light blue sky featuring two small, fluffy white clouds on the left and a large, pale yellow sun in the upper right corner that radiates soft, concentric, semi-transparent pastel green and yellow halos. A solid, darker brown shadow is cast directly beneath the bicycle's wheels on the minimalist two-toned brown ground." src="https://static.simonwillison.net/static/2026/gemini-3-deep-think-complex-pelican.png"></p>




</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Descent, ported to the web (287 pts)]]></title>
            <link>https://mrdoob.github.io/three-descent/</link>
            <guid>47017545</guid>
            <pubDate>Sat, 14 Feb 2026 19:33:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mrdoob.github.io/three-descent/">https://mrdoob.github.io/three-descent/</a>, See on <a href="https://news.ycombinator.com/item?id=47017545">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Internet Increasingly Becoming Unarchivable (538 pts)]]></title>
            <link>https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/</link>
            <guid>47017138</guid>
            <pubDate>Sat, 14 Feb 2026 18:46:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/">https://www.niemanlab.org/2026/01/news-publishers-limit-internet-archive-access-due-to-ai-scraping-concerns/</a>, See on <a href="https://news.ycombinator.com/item?id=47017138">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>Jan.  28, 2026, 3:09 p.m.</p><p>Outlets like The Guardian and The New York Times are scrutinizing digital archives as potential backdoors for AI crawlers.</p><div id="content_div-247528">


<p>As part of its mission to preserve the web, the Internet Archive operates crawlers that capture webpage snapshots. Many of these snapshots are accessible through its public-facing tool, the <a href="https://web.archive.org/">Wayback Machine</a>. But as AI bots scavenge the web for training data to feed their models, the Internet Archive’s commitment to free information access has turned its digital library into a potential liability for some news publishers.</p>
<p>When The Guardian took a look at who was trying to extract its content, access logs revealed that the Internet Archive was a frequent crawler, said <a href="https://www.linkedin.com/in/robert-hahn-08b45719/">Robert Hahn</a>, head of business affairs and licensing. The publisher decided to limit the Internet Archive’s access to published articles, minimizing the chance that AI companies might scrape its content via the nonprofit’s repository of over one trillion webpage snapshots.</p>

<p>Specifically, Hahn said The Guardian has taken steps to exclude itself from the Internet Archive’s APIs and filter out its article pages from the Wayback Machine’s URLs interface. The Guardian’s regional homepages, topic pages, and other landing pages will continue to appear in the Wayback Machine.</p>
<p>In particular, Hahn expressed concern about the <a href="https://archive.org/help/wayback_api.php">Internet Archive’s APIs</a>. </p>
<p>“A lot of these AI businesses are looking for readily available, structured databases of content,” he said. “The Internet Archive’s API would have been an obvious place to plug their own machines into and suck out the IP.” (He admits the Wayback Machine itself is “less risky,” since the data is not as well-structured.)</p>
<p>As news publishers try to safeguard their contents from AI companies, the Internet Archive is also getting caught in the crosshairs. The Financial Times, for example, blocks any bot that tries to scrape its paywalled content, including bots from OpenAI, Anthropic, Perplexity, and the Internet Archive. The majority of FT stories are paywalled, according to director of global public policy and platform strategy <a href="https://www.linkedin.com/in/mattrogerson/">Matt Rogerson</a>. As a result, usually only unpaywalled FT stories appear in the Wayback Machine because those are meant to be available to the wider public anyway.</p>
<p>“Common Crawl and Internet Archive are widely considered to be the ‘good guys’ and are used by ‘the bad guys’ like OpenAI,” <a href="https://www.linkedin.com/in/michaellloydnelson/">said Michael Nelson</a>, a computer scientist and professor at Old Dominion University. “In everyone’s aversion to not be controlled by LLMs, I think the good guys are collateral damage.”</p>

<p>The Guardian hasn’t documented specific instances of its webpages being scraped by AI companies via the Wayback Machine. Instead, it’s taking these measures proactively and is working directly with the Internet Archive to implement the changes. Hahn says the organization has been receptive to The Guardian’s concerns.</p>
<p>The outlet stopped short of an all-out block on the Internet Archive’s crawlers, Hahn said, because it supports the nonprofit’s mission to democratize information, though that position remains under review as part of its routine bot management. </p>
<p>“[The decision] was much more about compliance and a backdoor threat to our content,” he said.</p>
<p>When asked about The Guardian’s decision, Internet Archive founder Brewster Kahle said that “if publishers limit libraries, like the Internet Archive, then the public will have less access to the historical record.” It’s a prospect, he implied, that could undercut the organization’s work countering “<a href="https://firstdraftnews.org/training/information-disorder/">information disorder</a>.”</p>

<p>The Guardian isn’t alone in reevaluating its relationship to the Internet Archive. The New York Times confirmed to Nieman Lab that it’s actively “hard blocking” the Internet Archive’s crawlers. At the <a href="https://web.archive.org/web/20251223163226/http://nytimes.com/robots.txt" target="_blank">end of 2025</a>, the Times also added one of those crawlers — archive.org_bot — to its <a href="https://www.nytimes.com/robots.txt" target="_blank">robots.txt file</a>, disallowing access to its content.</p>
<p>“We believe in the value of The New York Times’s human-led journalism and always want to ensure that our IP is being accessed and used lawfully,” said a Times spokesperson. “We are blocking the Internet Archive’s bot from accessing the Times because the Wayback Machine provides unfettered access to Times content — including by AI companies — without authorization.”</p>
<p>Last August, <a href="https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit">Reddit announced</a> that it would block the Internet Archive, whose digital libraries include countless archived Reddit forums, comments sections, and profiles. This content is not unlike what Reddit now licenses to <a href="https://www.cjr.org/analysis/reddit-winning-ai-licensing-deals-openai-google-gemini-answers-rsl.php">Google as AI training data for tens of millions of dollars</a>.</p>
<p>“[The] Internet Archive provides a service to the open web, but we’ve been made aware of instances where AI companies violate platform policies, including ours, and scrape data from the Wayback Machine,” a Reddit spokesperson <a href="https://www.theverge.com/news/757538/reddit-internet-archive-wayback-machine-block-limit">told The Verge</a> at the time. “Until they’re able to defend their site and comply with platform policies…we’re limiting some of their access to Reddit data to protect redditors.”</p>
<p>Kahle has also alluded to steps the Internet Archive is taking to restrict bulk access to its libraries. In a <a href="https://mastodon.archive.org/@brewsterkahle/115368911896794707">Mastodon post</a> last fall, he wrote that “there are many collections that are available to users but not for bulk downloading. We use internal rate-limiting systems, filtering mechanisms, and network security services such as Cloudflare.”</p>
<p>Currently, however, the Internet Archive does not disallow any specific crawlers through its robots.txt file, including those of major AI companies. As of January 12, the robots.txt file for <a href="http://archive.org/">archive.org</a> read: “​​Welcome to the Archive! Please crawl our files. We appreciate it if you can crawl responsibly. Stay open!” Shortly after we inquired about this language, it was changed. The file now reads, simply, “Welcome to the Internet Archive!”</p>

<p>There is evidence that the Wayback Machine, generally speaking, has been used to train LLMs in the past. An <a href="https://www.washingtonpost.com/technology/interactive/2023/ai-chatbot-learning/">analysis of Google’s C4 dataset</a> by the Washington Post in 2023 showed that the Internet Archive was among millions of websites in the training data used to build Google’s T5 model and Meta’s Llama models. Out of the 15 million domains in the C4 dataset, the domain for the Wayback Machine (<a href="http://web.archive.org/">web.archive.org</a>) was ranked as the 187th most present.</p>
<p>In May 2023, the Internet Archive went <a href="https://blog.archive.org/2023/05/29/let-us-serve-you-but-dont-bring-us-down/">offline</a> temporarily after an AI company caused a server overload, Wayback Machine director <a href="https://www.linkedin.com/in/markjohngraham/">Mark Graham</a> told Nieman Lab this past fall. The company sent tens of thousands of requests per second from virtual hosts on Amazon Web Services to extract text data from the nonprofit’s public domain archives. The Internet Archive blocked the hosts twice before putting out a public call to “respectfully” scrape its site.</p>
<p>“We got in contact with them. They ended up giving us a donation,” Graham said. “They ended up saying that they were sorry and they stopped doing it.”</p>
<p>“Those wanting to use our materials in bulk should start slowly, and ramp up,” <a href="https://blog.archive.org/2023/05/29/let-us-serve-you-but-dont-bring-us-down/">wrote Kahle in a blog post</a> shortly after the incident. “Also, if you are starting a large project please contact us …we are here to help.”</p>
<p>The Guardian’s moves to limit the Internet Archive’s access made us wonder whether other news publishers were taking similar actions. We looked at publishers’ robots.txt pages as a way to measure potential concern over the Internet Archive’s crawling.</p>
<p>A website’s robots.txt page tells bots which parts of the site they can crawl, acting like a “<a href="https://www.youtube.com/watch?v=qRlQ965pGCA&amp;t=0">doorman</a>,” telling visitors who is and isn’t allowed in the house and which parts are off limits. Robots.txt pages aren’t legally binding, so the companies running crawling bots aren’t obligated to comply with them, but they indicate where the Internet Archive is unwelcome.</p>
<p>For example, in addition to “hard blocking,” The New York Times and The Athletic include the archive.org_bot in their robots.txt file, though they do not currently disallow other bots operated by the Internet Archive. </p>
<p>To explore this issue, Nieman Lab used journalist <a href="https://www.linkedin.com/in/palewire/">Ben Welsh</a>‘s <a href="https://palewi.re/docs/news-homepages/openai-gptbot-robotstxt.html">database of 1,167 news websites</a> as a starting point. As part of a larger side project to archive news sites’ homepages, Welsh runs crawlers that regularly scrape the robots.txt files of the outlets in his database. In late December, we downloaded a spreadsheet from Welsh’s site that displayed all the bots disallowed in the robots.txt files of those sites. We identified four bots that the AI user agent watchdog service <a href="https://darkvisitors.com/">Dark Visitors</a> has associated with the Internet Archive. (The Internet Archive did not respond to requests to confirm its ownership of these bots.) </p>
<p>This data is not comprehensive, but exploratory. It does not represent global, industry-wide trends — 76% of sites in the Welsh’s publisher list are based in the U.S., for example — but instead begins to shed light on which publishers are less eager to have their content crawled by the Internet Archive.</p>
<p>In total, 241 news sites from nine countries explicitly disallow at least one out of the four Internet Archive crawling bots. </p>
<p>Most of those sites (87%) are owned by USA Today Co., the largest newspaper conglomerate in the United States formerly known as Gannett. (Gannett sites only make up 18% of Welsh’s original publishers list.) Each Gannett-owned outlet in our dataset disallows the same two bots: “archive.org_bot” and “ia_archiver-web.archive.org”. These bots were added to the robots.txt files of Gannett-owned publications in 2025.</p>
<p>Some Gannett sites have also taken stronger measures to guard their contents from Internet Archive crawlers. <a href="https://web.archive.org/web/20260000000000*/desmoinesregister.com">URL searches for the Des Moines Register in the Wayback Machine</a> return a message that says, “Sorry. This URL has been excluded from the Wayback Machine.”</p>
<p>“USA Today Co. has consistently emphasized the importance of safeguarding our content and intellectual property,” a company spokesperson said via email. “Last year, we introduced new protocols to deter unauthorized data collection and scraping, redirecting such activity to a designated <a href="https://www.usatoday.com/bot-detection">page</a> outlining our licensing requirements.”</p>
<p>Gannett declined to comment further on its relationship with the Internet Archive. In an October 2025 <a href="https://www.investing.com/news/transcripts/earnings-call-transcript-gannett-cos-q3-2025-digital-focus-amid-revenue-dip-93CH-4320263">earnings call</a>, CEO Mike Reed spoke to the company’s anti-scraping measures. </p>
<p>“In September alone, we blocked 75 million AI bots across our local and USA Today platforms, the vast majority of which were seeking to scrape our local content,” Reed said on that call. “About 70 million of those came from OpenAI.” (<a href="https://www.usatodayco.com/pr/gannett-i-usa-today-network-and-perplexity-announce-strategic-ai-content-licensing-ageement/#:~:text=Gannett%20I%20USA%20TODAY%20Network,available%20for%20a%20broader%20audience.">Gannett signed a content licensing agreement with Perplexity in July 2025</a>.)</p>
<p>About 93% (226 sites) of publishers in our dataset disallow two out of the four Internet Archive bots we identified. Three news sites in the sample disallow three Internet Archive crawlers: Le Huffington Post, Le Monde, and Le Monde in English, all of which are owned by Group Le Monde.</p>

<p>The news sites in our sample aren’t only targeting the Internet Archive. Out of the 241 sites that disallow at least one of the four Internet Archive bots in our sample, 240 sites disallow Common Crawl — another nonprofit internet preservation project that has been <a href="https://www.wired.com/story/the-fight-against-ai-comes-to-a-foundational-data-set/">more closely linked to commercial LLM development</a>. Of our sample, 231 sites all disallow bots operated by OpenAI, Google AI, and Common Crawl.</p>
<p>As we’ve <a href="https://www.niemanlab.org/2025/10/the-wayback-machines-snapshots-of-news-homepages-plummet-after-a-breakdown-in-archiving-projects/">previously reported</a>, the Internet Archive has taken on the Herculean task of preserving the internet, and many news organizations aren’t equipped to save their own work. In December, Poynter <a href="https://www.poynter.org/business-work/2025/poynter-ire-and-internet-archive-launch-todays-news-for-tomorrow-a-project-to-help-newsrooms-preserve-their-digital-footprint/">announced</a> a joint initiative with the Internet Archive to train local news outlets on how to preserve their content. Archiving initiatives like this, while urgently needed, are  few and far between. Since there is no federal mandate that requires internet content to be preserved, the Internet Archive is the most robust archiving initiative in the United States.</p>
<p>“The Internet Archive tends to be good citizens,” Hahn said. “It’s the law of unintended consequences: You do something for really good purposes, and it gets abused.”</p>
<p>Photo of Internet Archive homepage by <a href="https://stock.adobe.com/images/houston-usa-july-7-2025-internet-archive-digital-library-and-web-preservation-website-with-logo-visible-on-computer-screen-in-web-browser/1571353025">SDF_QWE</a> used under an Adobe Stock license.</p>







<p><a href="https://www.niemanlab.org/author/adeck">Andrew Deck</a> is a staff writer covering AI at Nieman Lab. Have tips about how AI is being used in your newsroom? You can reach Andrew via <a href="https://www.niemanlab.org/cdn-cgi/l/email-protection#9bfaf5ffe9feecc4fffef8f0dbf3fae9edfae9ffb5feffee">email</a>, <a href="https://web-cdn.bsky.app/profile/andrewdeck.bsky.social">Bluesky</a>, or Signal (+1 203-841-6241).</p>





















</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[uBlock filter list to hide all YouTube Shorts (1049 pts)]]></title>
            <link>https://github.com/i5heu/ublock-hide-yt-shorts/</link>
            <guid>47016443</guid>
            <pubDate>Sat, 14 Feb 2026 17:36:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/i5heu/ublock-hide-yt-shorts/">https://github.com/i5heu/ublock-hide-yt-shorts/</a>, See on <a href="https://news.ycombinator.com/item?id=47016443">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">uBlock filter list to hide all YouTube Shorts</h2><a id="user-content-ublock-filter-list-to-hide-all-youtube-shorts" aria-label="Permalink: uBlock filter list to hide all YouTube Shorts" href="#ublock-filter-list-to-hide-all-youtube-shorts"></a></p>
<p dir="auto">A maintained <a href="https://github.com/gorhill/uBlock">uBlock Origin</a> filter list to hide all traces of YouTube shorts videos.</p>
<p dir="auto">Copy the link below, go to uBlock Origin &gt; Dashboard &gt; Filter lists, scroll to the bottom, and paste the link underneath the 'Import...' heading:<br>
<code>https://raw.githubusercontent.com/i5heu/ublock-hide-yt-shorts/master/list.txt</code></p>
<p dir="auto">&gt; uBlock Origin subscribe link &lt; (does not work on GitHub)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Bonus: hide YouTube Comments</h2><a id="user-content-bonus-hide-youtube-comments" aria-label="Permalink: Bonus: hide YouTube Comments" href="#bonus-hide-youtube-comments"></a></p>
<p dir="auto"><code>https://raw.githubusercontent.com/i5heu/ublock-hide-yt-shorts/master/comments.txt</code></p>
<p dir="auto">&gt; uBlock Origin subscribe link &lt; (does not work on GitHub)</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Maintancance</h2><a id="user-content-maintancance" aria-label="Permalink: Maintancance" href="#maintancance"></a></p>
<p dir="auto">After the initial createor of this list <a href="https://github.com/gijsdev">@gijsdev</a> is now vanished for half a year, i ( <a href="https://heidenstedt.org/" rel="nofollow">i5heu</a> ) took it on me to maintain this list.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">No affiliation to Alphabet, YouTube or Google</h2><a id="user-content-no-affiliation-to-alphabet-youtube-or-google" aria-label="Permalink: No affiliation to Alphabet, YouTube or Google" href="#no-affiliation-to-alphabet-youtube-or-google"></a></p>
<p dir="auto">This project is an independent, open-source initiative and is not affiliated with, endorsed by, sponsored by, or associated with Alphabet Inc., Google LLC, or YouTube.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/i5heu/ublock-hide-yt-shorts/blob/master/CONTRIBUTING.md">CONTRIBUTING.md</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">See <a href="https://github.com/i5heu/ublock-hide-yt-shorts/blob/master/LICENSE.md">LICENSE.md</a></p>
</article></div></div>]]></description>
        </item>
    </channel>
</rss>