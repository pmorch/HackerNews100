<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 02 Jun 2024 17:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[New head of one of the world’s oldest universities organized a citation cartel (152 pts)]]></title>
            <link>https://english.elpais.com/science-tech/2024-05-31/internal-messages-show-how-the-new-head-of-one-of-the-worlds-oldest-universities-organized-a-citation-cartel.html</link>
            <guid>40554394</guid>
            <pubDate>Sun, 02 Jun 2024 14:21:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://english.elpais.com/science-tech/2024-05-31/internal-messages-show-how-the-new-head-of-one-of-the-worlds-oldest-universities-organized-a-citation-cartel.html">https://english.elpais.com/science-tech/2024-05-31/internal-messages-show-how-the-new-head-of-one-of-the-worlds-oldest-universities-organized-a-citation-cartel.html</a>, See on <a href="https://news.ycombinator.com/item?id=40554394">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-dtm-region="articulo_cuerpo"><p>Three years ago, Juan Manuel Corchado boasted of being <a href="https://web.archive.org/web/20220928161336/https://corchado.net/2021/05/25/el-trabajo-en-equipo-sigue-dando-sus-frutos/" target="_blank">the fourth best scientist</a> in Spain and one of the 250 best on the planet in the field of computing, but he achieved this brilliant rise in the rankings <a href="https://english.elpais.com/science-tech/2024-03-20/the-aspiring-university-rector-who-wrote-a-four-paragraph-paper-and-cited-himself-100-times.html">by cheating on an industrial scale.</a> The academic official, who has just been appointed rector of the University of <a href="https://english.elpais.com/elpais/2018/10/26/inenglish/1540554903_326526.html">Salamanca</a> (the equivalent of university president in the U.S.), became one of the most cited scientists in the world because, among other fraudulent practices, he organized what is known as a citation cartel: a group of scientists colluding to cite one another in their papers. EL PAÍS has had access to internal messages from Corchado’s group that reveal their bad practices.</p><p>Their tricks are so crude that anyone who takes a look can easily spot them. In science, references included at the end of papers work like currency. The more other scientists cite you in their work, the greater your prestige, which leads to promotions, salary increases and even million-dollar projects. Corchado is quoted a lot, but only by a few close collaborators. On January 9, 2019, the mathematician Roberto Casado Vara <a href="https://link.springer.com/chapter/10.1007/978-3-319-99608-0_57" target="_blank">signed a paper</a> on computer security in electrical distribution networks, and 94% of the references (29 out of 31) were citations of Corchado’s work, even if it had nothing to do with the paper’s subject matter: the references included studies on the risk of bladder cancer, CO₂ in the ocean, oil spills, and red tides of microalgae.</p><p>For years, Corchado has been instructing his workers to include in each publication references to himself or to the journal that he edits: <a href="https://revistas.usal.es/cinco/index.php/2255-2863/" target="_blank"><i>Advances in Distributed Computing and Artificial Intelligence Journal</i></a> (<i>ADCAIJ</i>). In this way he falsified his own scientific impact and that of his journal in the rankings. On June 7, 2017, one of Corchado’s assistants wrote this message to her subordinates: “Collect everything you have (master’s thesis, final projects, dissertations, etc.) and include in them 20 references from among those that I have attached in the Word document as well as 10 articles from <i>ADCAIJ.</i>” The attached file included almost 50 Corchado publications. The aide later insisted: “As I know that we are all working hard now, to make it easier, I am attaching the references to just copy and paste.”</p><p>Similar messages were constant. On July 26, 2017, a different aide wrote to the group: “Hello everyone. Please, Juan Manuel tells me that we should reference these articles of his in the next papers that we send to magazines or conferences. I’ve attached the list here, don’t forget to add some.” Next, she attached a list of Corchado’s works, headed by one about oil spills.</p><p>On January 9, 2019, Roberto Casado Vara published <a href="https://link.springer.com/chapter/10.1007/978-3-319-99608-0_58" target="_blank">three papers</a> in which between <a href="https://link.springer.com/chapter/10.1007/978-3-319-99608-0_56" target="_blank">97% and 100%</a> of his references cited Corchado or <i>ADCAIJ</i>. Corchado, born in Salamanca 53 years ago, is one of the most cited scientists in the world according to Stanford University’s annual list. The most surprising thing is that Casado Vara, who is much younger, <a href="https://www.ubu.es/noticias/siete-profesores-de-la-ubu-en-el-ranking-de-la-universidad-de-stanford" target="_blank">also entered</a> that prestigious classification in 2022, just three years after defending his doctoral dissertation with Corchado as <a href="https://investigacion.ubu.es/documentos/5e4e724d2999524eaa950c54" target="_blank">his research supervisor</a>. This newspaper has asked both about these practices, without receiving a response.</p><p>The messages were often multitudinous. On February 1, 2018, the instructions from one of the assistants was: “Corchado has asked me to tell you to cite articles from <i>ADCAIJ</i> when you write your articles, whatever they are (conferences, master’s final projects, magazine articles, etc.). On March 12, 2018, one of the professor’s closest collaborators sent an email message to 40 people with instructions to manipulate publications from recent conferences organized by themselves: “We will tell you this week what acknowledgments, references and final authors you have to upload in the Camera_ready [print-ready] versions.” Corchado was in copy in all these messages. Dozens of the recipients, many of whom felt coerced, ended up leaving the group.</p><figure><span><img alt="The mathematician Roberto Casado Vara authored a publication on computer security in electrical distribution networks, in which 94% of the references (29 out of 31) are citations to works by Corchado, including some on cancer and ocean CO₂." decoding="auto" height="166" srcset="https://imagenes.elpais.com/resizer/v2/AKA575FUGBHGRKFHTJVDMFPNMA.jpg?auth=e59886b534228e1e01d012d23a26a5607f6d7d94caec635d33c7fe858777709f&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/AKA575FUGBHGRKFHTJVDMFPNMA.jpg?auth=e59886b534228e1e01d012d23a26a5607f6d7d94caec635d33c7fe858777709f&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/AKA575FUGBHGRKFHTJVDMFPNMA.jpg?auth=e59886b534228e1e01d012d23a26a5607f6d7d94caec635d33c7fe858777709f&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/AKA575FUGBHGRKFHTJVDMFPNMA.jpg?auth=e59886b534228e1e01d012d23a26a5607f6d7d94caec635d33c7fe858777709f&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/AKA575FUGBHGRKFHTJVDMFPNMA.jpg?auth=e59886b534228e1e01d012d23a26a5607f6d7d94caec635d33c7fe858777709f&amp;width=414" loading="lazy"><svg viewBox="0 0 40 40"><use xlink:href="#svg-ampliar"></use></svg></span><figcaption><span>The mathematician Roberto Casado Vara authored a publication on computer security in electrical distribution networks, in which 94% of the references (29 out of 31) are citations to works by Corchado, including some on cancer and ocean CO₂.</span></figcaption></figure><p>The professor used the conference records published by the Springer publishing house as a way to include strings of self-quotes. Informed by this newspaper, Springer Nature’s Research Integrity Director, <a href="https://group.springernature.com/la/group/media/press-releases/springer-nature-announces-chris-graf-research-integrity-director/19745290" target="_blank">Chris Graf</a>, stated that they are going to “very carefully” examine the case of the Salamanca professor. “If appropriate, we will take editorial action once this investigation has concluded,” Graf said. Another publisher, Elsevier, has already <a href="https://www.sciencedirect.com/science/article/pii/S0952197618300563" target="_blank">retracted a study</a> published by Corchado and three collaborators in 2019 for plagiarizing a master’s thesis.</p><p>The researcher cheated in different ways to rig various rankings. He published documents full of self-citations in the scientific repository of the University of Salamanca, so that they would be indexed by the Google Scholar search engine, which in turn feeds rankings such as Guide2Research, in which Corchado was close <a href="https://web.archive.org/web/20220928161336/https://corchado.net/2021/05/25/el-trabajo-en-equipo-sigue-dando-sus-frutos/" target="_blank">to the top position</a> at the national level. “Occupying fourth place in Spain and 247th worldwide fills me with pride, as it represents the good work we are doing as a group,” <a href="https://x.com/corchadojm/status/1397120628818419717?t=Dc0nmN_9TlGCGNTAqMErTA&amp;s=08" target="_blank">he posted</a> on May 25, 2021 on his social media accounts. Corchado once published <a href="https://core.ac.uk/reader/428434752" target="_blank">a single paragraph </a>with 227 self-quotes and another 139 references to his magazine <i>ADCAIJ</i>.</p><p>After EL PAÍS began publishing news stories about his practices in March, the Spanish Research Ethics Committee <a href="https://elpais.com/ciencia/2024-05-17/el-ministerio-de-ciencia-pide-una-investigacion-sobre-el-nuevo-rector-de-la-universidad-de-salamanca.html" target="_blank">opened an investigation</a> into Corchado, as announced on Friday, May 17, by the Ministry of Science. That same day, Corchado used the official channel of the University of Salamanca to issue <a href="https://twitter.com/usal/status/1791564922008068564" target="_blank">an unsigned statement</a>, at 10:22 p.m., in which he defended his “honorability and scientific integrity” and encouraged people to assess the impact of his publications in two of the databases most widely used by the scientific community: Scopus, from the Dutch publisher Elsevier, and Web of Science, from the London multinational Clarivate.</p><p>An analysis of who cites Corchado in Scopus reveals that in only 75 publications, his collaborators mentioned the Salamanca professor almost 1,700 times and referenced his magazine <i>ADCAIJ</i> 520 times. One of these papers is signed by <a href="https://produccioncientifica.usal.es/investigadores/56986/detalle" target="_blank">Pedro Tomás Nevado-Batalla</a>, who teaches law at the University of Salamanca and is a former regional government official of the Spanish region of Extremadura, where he served under a Popular Party (PP) administration. In his study, which dealt with the need to modernize public administration, there were <a href="https://link.springer.com/chapter/10.1007/978-3-319-99608-0_61" target="_blank">42 citations to Corchado’s work</a> and seven to <i>ADCAIJ</i>, including studies on bladder cancer, oil spills and microalgae tides. Fully 92% of the citations in that paper are to Corchado’s work or else to his magazine. Nevado-Batalla has stated that he was unaware that these references had been added to his work, and said that he is going to request clarification. “There must necessarily be some explanation for something so extravagant as this,” he said.</p><figure><span><img alt="Juan Manuel Corchado" decoding="auto" height="276" srcset="https://imagenes.elpais.com/resizer/v2/QCWVEKSDORHKRP4OOBVLOOD4PU.jpg?auth=34315188714fa32bc4a0c7d4a128b3c6b20a15328e316cf61168a40f2aec62e9&amp;width=414 414w,https://imagenes.elpais.com/resizer/v2/QCWVEKSDORHKRP4OOBVLOOD4PU.jpg?auth=34315188714fa32bc4a0c7d4a128b3c6b20a15328e316cf61168a40f2aec62e9&amp;width=828 640w,https://imagenes.elpais.com/resizer/v2/QCWVEKSDORHKRP4OOBVLOOD4PU.jpg?auth=34315188714fa32bc4a0c7d4a128b3c6b20a15328e316cf61168a40f2aec62e9&amp;width=980 1000w,https://imagenes.elpais.com/resizer/v2/QCWVEKSDORHKRP4OOBVLOOD4PU.jpg?auth=34315188714fa32bc4a0c7d4a128b3c6b20a15328e316cf61168a40f2aec62e9&amp;width=1960 1960w" width="414" sizes="(min-width:1199px) 1155px,(min-width:1001px) calc(100vw - 44px),(min-width:768px) 767px, 100vw" src="https://imagenes.elpais.com/resizer/v2/QCWVEKSDORHKRP4OOBVLOOD4PU.jpg?auth=34315188714fa32bc4a0c7d4a128b3c6b20a15328e316cf61168a40f2aec62e9&amp;width=414" loading="lazy"><svg viewBox="0 0 40 40"><use xlink:href="#svg-ampliar"></use></svg></span><figcaption><span>Juan Manuel Corchado, wearing glasses, standing next to Salamanca Mayor Carlos García Carbayo (right), at a public event in that city on May 23. </span><span>Raquel J. Santos / USAL</span></figcaption></figure><p>The mathematician <a href="https://www.uvigo.gal/es/universidad/administracion-personal/pdi/domingo-docampo-amoedo" target="_blank">Domingo Docampo</a>, former rector of the University of Vigo and an expert in <a href="https://www.chronicle.com/article/the-dark-world-of-citation-cartels" target="_blank">citation cartels</a>, expresses indignation. “It is petty and despicable. “They are insubstantial publications, without any real content, that constitute vehicles for citations in a network that clearly shows the pyramidal nature of a citation farm headed by someone who has influence over those who sign the papers,” he laments. “Corchado should never have run for a position of this category, to represent an institution as prestigious as the University of Salamanca,” he says about an institution that was founded in 1218.</p><p>The solemn inauguration ceremony of the new rector took place on Friday at the university auditorium. Corchado <a href="https://elpais.com/ciencia/2024-05-07/juan-manuel-corchado-gana-las-elecciones-a-rector-de-la-universidad-de-salamanca-con-la-mitad-del-profesorado-en-contra.html" target="_blank">won the elections</a> on May 7, after taking advantage of the strange surprise resignation of the previous rector, and presenting himself as the only candidate. He received the support of 6.5% of the 33,000 university members who were called to vote, with half of the faculty voting blank as a sign of protest. In 2018, the professor created the <a href="https://air-institute.com/" target="_blank">AIR Institute</a>, a private entity that manages projects worth <a href="http://noticias.aytosalamanca.es/noticias/es/hemeroteca/noticia_10496_1711159205064" target="_blank">millions of euros</a> awarded by the regional government of Castilla y León.</p><p>Docampo urges the Ministry of Science, Innovation and Universities, academic authorities and individuals responsible for scientific journals to take action. “We have a serious problem. We must protect the careers of the youngest students, who can be contaminated. <a href="https://english.elpais.com/science-tech/2023-11-25/the-list-of-the-worlds-most-cited-scientists-excludes-1000-researchers-over-fraudulent-practices.html">This is happening worldwide</a>,” he warns.</p><p>The epidemiologist <a href="https://www.usc.gal/saudep/personnel/alberto-ruano-ravina/" target="_blank">Alberto Ruano</a>, an expert in scientific misconduct, is adamant: “This is a textbook case of a citation cartel.” Ruano, a professor at the University of Santiago de Compostela, also urges Corchado to resign. “It is likely that he will have to resign, because he is damaging the institution he represents, a damage that affects the credibility of the University of Salamanca and is also affecting all Spanish university professors,” says the epidemiologist, who urges the Ministry and the Conference of Rectors of Spanish Universities (CRUE) to take measures to avoid cases like this one.</p><blockquote><p>This is a textbook case of a citation cartel</p><cite>Alberto Ruano, professor at University of Santiago de Compostela</cite></blockquote><p>In addition to adding thousands of self-citations to his own publications and requiring his workers to also cite him, Corchado has benefited from a multitude of false online accounts of non-existent scientists, such as <a href="https://www.researchgate.net/publication/324477069_Designing_complex_environments_with_artificial_intelligence" target="_blank">Devika Rout</a> and <a href="https://www.researchgate.net/publication/324210396_Modeling_the_ocean_with_intelligence_real_time_systems_with_a_Case-Based_Reasoning_system" target="_blank">Marcus Ress</a>, dedicated to compulsively mentioning Corchado’s studies in the ResearchGate repository. Since March, Corchado has carried out a massive deletion of these fraudulent profiles, and he has also deleted the publications with obvious tricks that he had uploaded to the Gredos scientific repository of the University of Salamanca.</p><p>Since April 23, Corchado has denied multiple requests from EL PAÍS to explain his practices, but on March 13 he did grant an interview to this newspaper. In that telephone conversation, the professor from Salamanca stated that there were “20 or 30” false online accounts dedicated to citing him and, in just two minutes, he <a href="https://english.elpais.com/science-tech/2024-04-26/the-seven-lies-of-the-ai-expert-who-cited-himself-thousands-of-times-on-scientific-papers.html">offered two contradictory explanations</a>: that they had been created by former disgruntled workers to harm him, and that “a young man” had created them to demonstrate that ResearchGate could be rigged. Next, Corchado assured that he had deleted those profiles thanks to his knowledge in cybersecurity. A ResearchGate spokesperson, however, explained that they are not aware of any computer attack and that only the creator of a profile can delete it with their password.</p><p>One of the international leaders in scientific evaluation methods, <a href="https://www.cwts.nl/people/ismael-rafols" target="_blank">Ismael Ràfols</a>, points to the system. “This corruption occurs because there is an evaluation system that values publishing a lot and being cited often. In Europe we have started a reform process and Spain still has a lot of work ahead of it,” says Ràfols, from the University of Leiden (Netherlands).</p><p>The watchdog agency of the Spanish university system is the National Agency for Quality Assessment and Accreditation (ANECA), directed for a year now by a new director, <a href="https://elpais.com/educacion/universidad/2023-02-28/una-catedratica-de-geografia-humana-nueva-directora-de-la-agencia-de-evaluacion-de-las-universidades-aneca.html" target="_blank">Pilar Paneque</a>, who is promoting changes to stop measuring researchers based on production volume. “ANECA is going in the right direction, but it faces resistance from traditional professors who have reached the top, like this man. The Corchado case is like a parody, and it shows that it is necessary to reform the evaluation system that generates the corruption,” says Ràfols.</p><p>Pilar Paneque herself believes that her reforms will discourage bad practices and reduce pressure on researchers, especially the younger ones. “We have a lot of progress to make towards scientific integrity and ethics in research, and everything has to start with the commitment and control of each institution. Every university knows perfectly well what each of its researchers produces and can easily detect any type of anomalous behavior,” says Paneque. In the case of Corchado, Friday was his coronation as rector of the University of Salamanca.</p><p><i>Sign up for </i><a href="https://plus.elpais.com/newsletters/lnp/1/333/?lang=en"><i><u>our weekly newsletter</u></i></a> <i>to get more English-language news coverage from EL PAÍS USA Edition</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[PyCon US 2024 Recap (134 pts)]]></title>
            <link>https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html</link>
            <guid>40552621</guid>
            <pubDate>Sun, 02 Jun 2024 09:03:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html">https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html</a>, See on <a href="https://news.ycombinator.com/item?id=40552621">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="pycon-us-2024-recap" role="main">

<section id="table-of-contents">
<h2>Table of Contents<a href="#table-of-contents" title="Link to this heading">¶</a></h2>
<ul>
<li><p><a href="#intro"><span>Intro</span></a></p></li>
<li><p><a href="#wednesday"><span>Wednesday</span></a></p>
<ul>
<li><p><a href="#sightseeing-downtown"><span>Sightseeing Downtown</span></a></p></li>
<li><p><a href="#allegheny-riverfront"><span>Allegheny Riverfront</span></a></p></li>
<li><p><a href="#fig-and-ash"><span>Fig and Ash</span></a></p></li>
</ul>
</li>
<li><p><a href="#thursday"><span>Thursday</span></a></p>
<ul>
<li><p><a href="#noticeable-sightings-at-the-conference-center"><span>Noticeable Sightings at the Conference Center</span></a></p></li>
<li><p><a href="#andy-warhol-museum"><span>Andy Warhol Museum</span></a></p></li>
<li><p><a href="#heinz-history-center"><span>Heinz History Center</span></a></p></li>
<li><p><a href="#duquesne-incline"><span>Duquesne Incline</span></a></p></li>
<li><p><a href="#opening-reception-at-the-expo-hall"><span>Opening Reception at the Expo Hall</span></a></p></li>
<li><p><a href="#expo-hall-booths-thursday-and-friday"><span>Expo Hall Booths Thursday and Friday</span></a></p></li>
</ul>
</li>
<li><p><a href="#friday"><span>Friday</span></a></p>
<ul>
<li><p><a href="#breakfast"><span>Breakfast</span></a></p></li>
<li><p><a href="#k-jay-miller-keynote"><span>K. Jay Miller Keynote</span></a></p></li>
<li><p><a href="#hallway-track-and-expo-hall"><span>Hallway Track and Expo Hall</span></a></p></li>
<li><p><a href="#photos-and-tea"><span>Photos and Tea</span></a></p></li>
<li><p><a href="#condado-tacos"><span>Condado Tacos</span></a></p></li>
</ul>
</li>
<li><p><a href="#saturday"><span>Saturday</span></a></p>
<ul>
<li><p><a href="#breakfast"><span>Breakfast</span></a></p></li>
<li><p><a href="#simon-willison-keynote"><span>Simon Willison Keynote</span></a></p></li>
<li><p><a href="#hallway-track"><span>Hallway Track</span></a></p></li>
<li><p><a href="#overcoming-gil-with-subinterpreters-and-immutability"><span>Overcoming GIL with subinterpreters and immutability</span></a></p></li>
<li><p><a href="#measuring-the-performance-of-cpython"><span>Measuring the performance of CPython</span></a></p></li>
<li><p><a href="#psf-members-luncheon"><span>PSF Members Luncheon</span></a></p></li>
<li><p><a href="#profile-pic"><span>Profile Pic</span></a></p></li>
<li><p><a href="#juggling"><span>Juggling</span></a></p></li>
<li><p><a href="#hallway-track-and-expo-hall-1"><span>Hallway Track and Expo Hall</span></a></p></li>
<li><p><a href="#pyladies-auction"><span>PyLadies Auction</span></a></p></li>
</ul>
</li>
<li><p><a href="#sunday"><span>Sunday</span></a></p>
<ul>
<li><p><a href="#posters"><span>Posters</span></a></p></li>
<li><p><a href="#ethan-smith"><span>Ethan Smith</span></a></p></li>
<li><p><a href="#pyladies-lunch"><span>PyLadies Lunch</span></a></p></li>
<li><p><a href="#building-a-jit-compiler-for-cpython"><span>Building a JIT compiler for CPython</span></a></p></li>
<li><p><a href="#unlocking-the-parallel-universe-subinterpreters-and-free-threading-in-python-313"><span>Unlocking the Parallel Universe: Subinterpreters and Free-Threading in Python 3.13</span></a></p></li>
<li><p><a href="#sync-vs-async-in-python-tools-benchmarks-and-asgiwsgi-explained"><span>Sync vs. Async in Python: Tools, Benchmarks, and ASGI/WSGI Explained</span></a></p></li>
<li><p><a href="#sumana-harihareswara-keynote"><span>Sumana Harihareswara Keynote</span></a></p></li>
<li><p><a href="#steering-council-updates"><span>Steering Council Updates</span></a></p>
<ul>
<li><p><a href="#barry-warsaw-steering-council-overview"><span>Barry Warsaw: Steering Council Overview</span></a></p></li>
<li><p><a href="#gregory-p-smith-steering-council-expenditures-update"><span>Gregory P. Smith: Steering Council Expenditures Update</span></a></p></li>
<li><p><a href="#emily-morehouse-councils-and-working-groups-update"><span>Emily Morehouse: Councils and Working Groups Update</span></a></p></li>
<li><p><a href="#thomas-wouters-overview-of-python-313"><span>Thomas Wouters: Overview of Python 3.13</span></a></p></li>
</ul>
</li>
<li><p><a href="#dinner-and-ice-cream"><span>Dinner and Ice Cream</span></a></p></li>
</ul>
</li>
<li><p><a href="#monday"><span>Monday</span></a></p></li>
<li><p><a href="#until-next-time"><span>Until Next Time</span></a></p></li>
</ul>
</section>
<section id="intro">
<h2>Intro<a href="#intro" title="Link to this heading">¶</a></h2>
<p>Disclaimer: the content of this post is a reflection of my career journey and not specific to my work at JPMorgan Chase &amp; Co.</p>
<p>PyCon US 2024 was truly incredible. If you ever have the chance to attend, I highly recommend it.</p>
<p>I am thankful for and proud of my friend Mariatta (PyCon US Chair) who oversaw it.</p>
<p>This was my second time attending an in-person PyCon US. My first one was in 2019. I remember being awestruck by the ocean of people. I was glad that I had already attended DjangoCon US and some regional conferences. I recognized some people in the crowd, and it made it feel like a smaller event.</p>
<p>This time, I was better prepared. I knew what to expect and leveraged my time better, all while having a ton of fun.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="wednesday">
<h2>Wednesday<a href="#wednesday" title="Link to this heading">¶</a></h2>
<section id="sightseeing-downtown">
<h3>Sightseeing Downtown<a href="#sightseeing-downtown" title="Link to this heading">¶</a></h3>
<p>I arrived on Wednesday, settled in, and immediately took some time to see the <a href="https://www.pittsburghcc.com/">David L. Lawrence Convention Center</a> and the downtown.</p>
<p>This was my first time in Pittsburgh, and I didn’t know what to expect. Downtown Pittsburgh, with its many steel bridges and brick buildings surrounded by riverfront, was a surprisingly gorgeous scene.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/david-l-lawrence-convention-center-rooftop-terrace.jpg">
David L. Lawrence Convention Center Rooftop Terrace</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/tenth-street-water-feature.jpg">
10th Street Water Feature</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="allegheny-riverfront">
<h3>Allegheny Riverfront<a href="#allegheny-riverfront" title="Link to this heading">¶</a></h3>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/allegheny-river-bridge.jpg">
Standing on a bridge on the Allegheny River with a view of the downtown and one of the many other bridges</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="fig-and-ash">
<h3>Fig and Ash<a href="#fig-and-ash" title="Link to this heading">¶</a></h3>
<p>After a busy day, I was tempted to get some cheap takeaway for supper, but I thought twice, and decided I should enjoy the best this city has to offer. So, I googled “best restaurant in Pittsburgh.” The top result was <a href="https://figandashpgh.com/">Fig &amp; Ash</a>, a short walk away. I went there and had an incredible meal.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/fig-and-ash-spaghetti.jpg">
Spaghetti with Maine lobster cream, crab, nantucket bay scallops, arugula</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/fig-and-ash-brownie.jpg">
A piping hot cast iron Kahlua fudge brownie with coffee ice cream and sea salt for dessert</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="thursday">
<h2>Thursday<a href="#thursday" title="Link to this heading">¶</a></h2>
<p>I took the day off to sightsee.</p>
<p>As I was walking down the riverfront, I saw a man taking photos. He looked familiar. I was pretty sure we had been following each other on social media for a while. I couldn’t resist approaching him. It was Peter Wang (Anaconda Co-founder). It was really fun to meet him, and I found out that he and my friend Andy Fundinger had been consultants at JPMorgan Chase years ago.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
<section id="noticeable-sightings-at-the-conference-center">
<h3>Noticeable Sightings at the Conference Center<a href="#noticeable-sightings-at-the-conference-center" title="Link to this heading">¶</a></h3>
<p>I couldn’t resist stopping at the convention center to see what was going on.</p>
<p>Once inside, I soon saw Guido van Rossum (Python Creator and BDFL) walking nearby. He sat down next to me, and I had the chance to chat with him about life and work. I thanked him for spending the time, and he thanked me. I’ve had the chance to spend time with him at three conferences now, and it’s always fun. The Python community is lucky to have a BDFL who actively engages with us and cares.</p>
<p>I was thrilled to catch up with some of my DjangoCon US friends: Afi Gbagado (DjangoCon US), Abigail Mesrenyame Dogbe (Technology Chief of Staff and Open Source Founder), Noah Alorwu (Marygold and Co.), Felipe de Morais (AfroPython), Jeff Triplett (RevSys, DEFNA Board Member), Eric Matthes (Author of <a href="https://nostarch.com/python-crash-course-3rd-edition">Python Crash Course</a>), and Trey Hunner (Python Trainer, Python Morsels). I made a new friend Amanda Viera (AfroPython).</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/me-and-abigail1.jpg">
Me and Abigail Mesrenyame Dogbe</p>
<p>As usual, Trey had an interesting gaggle of people around him that included Marie Roald and Yngve Mardal Moe (<a href="https://turtlethread.com/">Turtle Thread</a>) and Rodrigo Girão Serrão (<a href="https://mathspp.com/">Python Math Teacher</a>).</p>
<p>It was good to chat with Mason Eggers (PyTexas Chair), Kevin Horn (Dallas Fortworth Pythoneers Co-founder and PyTexas Organizer), Josh Schneider (PyTexas Organizer), Andy Fundinger (Bloomberg), and Heather Crawford (Bloomberg) again so soon after seeing them at the wonderful PyTexas conference I attended in April. Andy and I first met at PyGotham, another one of my favorite conferences.</p>
<p>Inspired by Andy, Mason and I later talked PyTexas sponsorships.</p>
<p>Although they were hard at work, I also got to see Deb Nicholson (Python Software Foundation Executive Director) for the first time again since DjangoCon US 2023, Ee Durbin (PSF Director of Infrastructure), Christopher Ngeuebauer (PSF Board Member), and Mariatta. :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="andy-warhol-museum">
<h3>Andy Warhol Museum<a href="#andy-warhol-museum" title="Link to this heading">¶</a></h3>
<p>On the way to the <a href="https://www.warhol.org/">Andy Warhol Museum</a>, I saw my friend Andy Knight (Automation Panda), and we walked there together. Andy had given a tutorial “<a href="https://us.pycon.org/2024/schedule/presentation/37/">def test_crash_course_with_pytest():</a>”.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/andy.jpg">
Andy wearing an Andy Warhol-inspired shirt</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/andy-warhol-museum.jpg">
A favorite from the Andy Warhol Museum</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="heinz-history-center">
<h3>Heinz History Center<a href="#heinz-history-center" title="Link to this heading">¶</a></h3>
<p>When I heard that the <a href="https://heinzhistorycenter.org/">Heinz History Center</a> has the Mister Rogers set, I had to go.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/heinz-museum-mr-rogers.jpg">
Mr. Rogers Neighborhood set</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="duquesne-incline">
<h3>Duquesne Incline<a href="#duquesne-incline" title="Link to this heading">¶</a></h3>
<p>I had all of my travel plans in place to attend PyCon US 2020 in Pittsburgh and planned to ride the <a href="https://www.duquesneincline.org/">Duquesne Incline</a>, but the in-person conference was canceled due to Covid. I finally had the chance to ride it!</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/duquesne-incline-bottom.jpg">
View from the station at the bottom</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/duquesne-incline-view.jpg">
View from the Duquesne Incline Observation Deck</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="opening-reception-at-the-expo-hall">
<h3>Opening Reception at the Expo Hall<a href="#opening-reception-at-the-expo-hall" title="Link to this heading">¶</a></h3>
<p>I gave my first conference talk at the first conference I ever attended. It was DjangoCon US 2017 in Spokane, Washington. I distinctly remember that Roger Masse (United States Senate) and Mark Lavin (Nvidia) attended my talk. At the PyCon US 2024 opening reception, while catching up with Jon Banafato (PyGotham Chair), I saw Mark walking by and couldn’t resist stopping him to introduce myself and thank him years later for going to my first talk. :)</p>
<p>After years of following each other on social media, it was wonderful to meet Anthony Shaw (Microsoft) in person. Along with Iqbal Abdullah (LaLoka Labs, PyCon JP), we talked about the <a href="https://realpython.com/products/cpython-internals-book/">CPython Internals</a> book Anthony wrote and my desire to understand CPython better. Anthony later suggested that I submit to the CfP next year, and I have to admit that it’s tempting.</p>
<p>It was a pleasure to chat with Simon Willison (Django Co-founder) again briefly before he left to work on his keynote. I knew he would nail it.</p>
<p>I got to hang out with Meagan Voss (Wagtail) and Nic James (DjangoCon US 2019 Chair) and talk about our work.</p>
<p>It was so good to see my friend Jess Garson (Elastic, formerly Twitter) at the Elastic booth and meet Philip Krenn (Elastic). Jess and I first met at PyGotham 2019, and she introduced me to many aspects of the Twitter Developer Program. :)</p>
<p>The night finished with a bear hug from Carol Willing (CPython Core Developer, Python Steering Committee) who told me I am awesome. :)</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/expo-hall.jpg">
Expo Hall in full swing</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="expo-hall-booths-thursday-and-friday">
<h3>Expo Hall Booths Thursday and Friday<a href="#expo-hall-booths-thursday-and-friday" title="Link to this heading">¶</a></h3>
<p>In the Expo hall, I did a tour of database companies and other fun tools.</p>
<p>At Datadog booth, Julian Levi Hernandez (Datadog, formerly CockroachDB) gave me a demo of a dashboard using Cockroach audit logs to further drill down into metrics.</p>
<p>At the Edge DB booth, Yury Selivanov (Edge DB Co-founder) told me that Django will be supported in a few months and showed me the impressive performance improvement created by Edge DB. Looking forward to learning more!</p>
<p>At the Oracle booth, Gary Brenner (Oracle Senior Cloud Engineer) told me about Oracle Cloud and self-managing Oracle databases.</p>
<p>At MongoDB booth, I caught up with my friend Mark Smith (MongoDB) and obtained some <a href="https://www.mongodb.com/developer/events/pycon-us-2024/">learning resources</a> from Rita Rodrigues (Director of Developer Relations at MongoDB).</p>
<p>At Snowflake booth, I learned about <a href="https://quickstarts.snowflake.com/">Snowflake Quickstarts</a> and using Snowflake tasks for orchestration.</p>
<p>At the Crunch Data booth, I met Elizabeth Garrett Christensen. I know of Elizabeth through the talks she has given at DjangoCon US: “<a href="https://2022.djangocon.us/talks/how-to-be-a-postgres-dba-in-a-pinch/">How to Be a Postgres DBA in a Pinch</a>” and “<a href="https://2023.djangocon.us/talks/postgres-performance-from-slow-to-pro/">Postgres Performance: From Slow to Pro</a>”. Crunch Data provides Enterprise PostgreSQL support, including fully managed Postgres as a Service.</p>
<p>As a fellow Lawrence native, Elizabeth seems to be hoping for a Lawrence Django conference as much as I am. :) I missed the <a href="https://lawrencetechconference.splashthat.com/">Lawrence Technology Conference</a> this year, but hope to make it next year at least, if there is one.</p>
<p>At the PostgreSQL community booth, I obtained some learning resources, including a paper version of <a href="https://www.postgresql.org/about/press/faq/">PostgreSQL FAQs</a>.</p>
<p>At the <a href="https://www.coiled.io/">Coiled</a> booth, I learned about using Dask for parallel computing. Dask was a projects cited in the Measuring the performance of CPython.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/swag.jpg">
EdgeDB, Oracle, Dask, Streamlit socks, MongoDB socks?</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="friday">
<h2>Friday<a href="#friday" title="Link to this heading">¶</a></h2>
<section id="breakfast">
<h3>Breakfast<a href="#breakfast" title="Link to this heading">¶</a></h3>
<p>At breakfast, I met Loren Crary (PSF) for the first time after following each other on social media for quite some time and saw Al Sweigart (Author of <a href="https://nostarch.com/automate-boring-stuff-python-3rd-edition">Automate the Boring Stuff with Python</a>), one of my favorite authors and presenters, again. I also finally met Tania Allard (Quansight, formerly Microsoft) and learned more about her work, including consulting at JPMorgan Chase. It was a pleasure to meet Daniel Graham (SauceLabs) and Jing Cao (National Microbiome Data Collaborative), too.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="k-jay-miller-keynote">
<h3>K. Jay Miller Keynote<a href="#k-jay-miller-keynote" title="Link to this heading">¶</a></h3>
<p>Jay knows two staff developer advocates who are Black and he is one of them. When he sees another Black developer on stage, it’s not just another Pythonista.</p>
<p>Jay talked about beautiful moments from DjangoCon US 2023 in Durham, North Carolina: Black leaders, from all around the world, getting on stage, getting in front of their booths. They showed up and showed out for who they were.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/black-python-devs-durham.png">
Black Python Devs at DjangoCon US 2023</p>
<p>Jay was happy to not be the first Black person keynoting PyCon US. But, at PyCon US 2022, Jay counted only 12 Black people among thousands. He talked to them. They had to have a reason to be there. He thought of the keynoters who came before him. They came, they spoke, they left. He wondered if “the juice wasn’t worth the squeeze.”</p>
<p>Many people go to conferences to hang out with their friends. If you don’t have that kind of experience, there’s no reason to attend.</p>
<p>Jay asked, how do we get more black people to experience the PyCon community, build friendship, and become repeat attendees?</p>
<p>Jay decided to create something that would serve as a Wakanda for Black Python devs. Something that would be worth staying for. It’s called <a href="https://blackpythondevs.com/">Black Python Devs</a>.</p>
<p>Jay listened to people in the community who had experience running non-profits, starting communities, running conferences: Marlene, Dawn, Kojo. He needed to make the community safe, equitable, accessible. This goes beyond a code of conduct to issues that Black people think about everyday like physical safety in public. He also wants to prevent burnout.</p>
<p>Jay started working behind the scenes to get as many Black people as possible to PyCon US 2023. There were 3x more than in 2022. They were able to be in the same room together and talk about the experiences they have as Black Python devs that others can’t comprehend, not about how to increase diversity.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/black-python-devs-31.png">
3x attendance at PyCon US 2022</p>
<p>Five members launched a discord. There are 427 members now. Their only plan was to be there for each other.</p>
<p>They are now officially a non-profit powered by the GNOME Foundation.</p>
<p>The leadership model is “diversity by inclusion.” Global leaders are represented at the table: from many countries, speaking different languages, 50/50 gender parity. It’s members are people who are already around you in PSF, DFS, Djangonauts, Pylades, DjangoGirls. Because the community came from Africa, its leaders do too.</p>
<p>“Your reach may extend beyond your grasp.” Kojo Idressa</p>
<p>The Python community can extend the reach further and Black Python Devs can help change perceptions in communities.</p>
<p>A few examples of solidarity</p>
<ul>
<li><p>Facilitating four leaders traveling to their first PyCon US</p></li>
<li><p>Converting community sponsorship into tickets for first time attendees who are Black Python Devs members</p></li>
<li><p>Providing 75 student tickets to Python Nigeria</p></li>
<li><p>Convening leaders from across the globe at conference lunchtime to help understand the situation happening in Africa and what could be done to assist</p></li>
<li><p>Helped Vice Chair Velda Kiara on stage when her laptop didn’t work</p></li>
<li><p>Supporting a Django Girls event that gave not just Black women devs, but Black girls a wonderful first interaction with the Python community</p></li>
</ul>
<p>“Say it loud.” Everything they do is out in the open, proudly showing up for each other, saying, we’ve got this, and celebrating.</p>
<p>Black Python devs had a goal of sponsoring seven local conferences in Black communities and hoped to raise $5,000 at PyCon US. They raised over $15,300 from 282 donations.</p>
<p>Things you can do to help</p>
<ul>
<li><p>Donate money</p></li>
<li><p>Donate time, mentor</p></li>
<li><p>Connect with Black Python Devs</p></li>
<li><p>Open doors, have conversations, make connections</p></li>
</ul>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="hallway-track-and-expo-hall">
<h3>Hallway Track and Expo Hall<a href="#hallway-track-and-expo-hall" title="Link to this heading">¶</a></h3>
<p>At PyCon US 2019, Pablo Galindo Salgado (CPython Release Manager, Bloomberg) was one of the first people I met as a wide-eyed newcomer. It was the Thursday night before the conference talks began, and I was at the conference hall for the swag stuffing, which is a great place to meet people. Scientists had recently photographed a black hole for the first time. Pablo, a physicist, invited me to a table nearby where he demoed some Python astronomy software for me. I later met Barry Warsaw (Python Steering Committee, Nvidia) at the sprints and talked to him about my career. At the time, I was a part-time open source maintainer of Pinax.</p>
<p>I saw Pablo and Barry together at the PyCon US 2024 Opening Reception. It was wonderful to be able to share with them five years later how my career has taken off.</p>
<p>It was great to see Andrew Godwin (Django Async Architecture) and Dave Forgac (PyOhio) again.</p>
<p>I had the chance to say hello to Sarah Kuchinsky (PyCon US Organizer) for the first time since PyCon US 2019. She was recently the technical reviewer for Al Sweigart’s great book about recursion called “<a href="https://inventwithpython.com/recursion/">The Recursive Book of Recursion</a>”. I really enjoyed it!</p>
<p>I found out that Julia Ferraioli (AWS Open Source) was at the conference. I was ecstatic and hurried over to meet her. I had hoped to meet Julia in person for years. In March of 2021, I reached the final round of a Twitter Open Source Program Manager interview process. I was disappointed when I was not offered the job, but later found out that I had been considered alongside Julie and was honored. In a twist of fate, in August of 2022, Julia kindly met with me via Zoom and gave me excellent career advice.</p>
<p>It was also a pleasure to meet Brianne Wilhelmi (Springboard) and Aaron Clark (Hamilton Beach) at lunch, and see Ashia Zawaduk (Muck Rack) again after PyCascades 2020.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="photos-and-tea">
<h3>Photos and Tea<a href="#photos-and-tea" title="Link to this heading">¶</a></h3>
<p>Earlier this year, I created a <a href="https://katherinemichel.github.io/portfolio/favorite-conference-snapshots.html">page of favorite conference snapshots</a>. Benedict Kofi Amofah (Python Ghana, DjangoCon US) tweeted to me that he’d be in the gallery soon. I took him up on it. :)</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/me-and-benedict.jpg">
Me and Benedict</p>
<p>Abdur-Rahmaan Janhangeer (Python Usergroup of Mauritius (PyMUG)) and I have been following each other on social media for quite some time, but I didn’t know what he looked like. Fortunately, he found me and gave me a wonderful gift of Chartreuse tea, the best selling tea in Mauritius. Thank you!</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/chartreuse-tea.jpg">
Chartreuse Tea!</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="condado-tacos">
<h3>Condado Tacos<a href="#condado-tacos" title="Link to this heading">¶</a></h3>
<p>After my incredible meal on Thursday night at Fig and Ash, I wanted to do something simple for supper. Based on a tip from another conference attendee, I ended up across the street from the convention center at <a href="https://condadotacos.com/">Condado Tacos</a>. The food was pretty good, but the best part was sitting and chatting with Bloomberg Python Trainers Heather Crawford and Scott Irwin. I met Scott at PyGotham 2018 where I attended a talk he gave “<a href="https://www.youtube.com/watch?v=zHY1oaYxxjA">Dataclasses are here. Now what?</a>”. I met Heather at PyTexas 2024 where she did an awesome talk “<a href="https://www.youtube.com/watch?v=RdkhRfRizf0">Python Code Versus Pythonic Code: What Experienced Developers Find Challenging About Learning Python</a>”, which she also gave at PyCon US.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="saturday">
<h2>Saturday<a href="#saturday" title="Link to this heading">¶</a></h2>
<section id="id1">
<h3>Breakfast<a href="#id1" title="Link to this heading">¶</a></h3>
<p>Koushik Krishnan (Microsoft Azure Cosmos DB Engineer) gave his talk “<a href="https://youtu.be/HWIPkipolUk?si=ozxHi5N7RwY19hVh">Rest Easy with Jupyrest: Deploy notebooks as web services</a>” at PyTexas. When I saw during the talk that he works on <a href="https://azure.microsoft.com/en-us/products/cosmos-db">Microsoft Azure Cosmo DB</a>, I was keen to meet him and did. He gave the talk at PyCon US too. It was a pleasure to have the chance to chat with him about different databases over breakfast. I also had the chance to promote <a href="https://2023.barcampphilly.org/">Bar Camp Philly</a>, organized by Tim Allen and now Dawn Wages’ wife.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="simon-willison-keynote">
<h3>Simon Willison Keynote<a href="#simon-willison-keynote" title="Link to this heading">¶</a></h3>
<p>Simon talked about Large Language Models such as Chat GPT, Google Gemini, Claude, and Llama.</p>
<p>He does not think of them as Artificial Intelligence. He thinks of them as Imitation Intelligence. They predict the next word in a sentence. When they get good at that, it’s spooky what they can do. He acknowledged that they are flawed, but just because a tool is flawed, doesn’t mean it’s not useful.</p>
<p>When evaluating a new technology, Simon asks, what can I build with this that I couldn’t have built with it before? LLMs open up new options unlike anything he has ever seen.</p>
<p>How can we tell which of these models works best? Vibes. Simon recommends using <a href="https://arena.lmsys.org/">LMSYS Org Chatbot Arena</a>. You vote on which model gave the best response to a prompt, then they are scored using Elo rating system. Simon is relieved, because “openly” licensed models are beginning to rank.</p>
<p>LLMs can be run on smartphones now, even with no internet connection. An app called MLC Chat will give you access to Mistral, one of the best openly licensed models.</p>
<p>Simon has deep respect for what is known as prompt engineering. It’s not easy to get LLMs to do what you want them to do. Building something simple is easy. Building something production ready can take months and is much harder than people expect.</p>
<p>A few tricks</p>
<ul>
<li><p>Chat prompting</p></li>
<li><p>Retrieval Augmented Generate (RAG)</p></li>
<li><p>Function calling (“tools”) in a loop</p></li>
</ul>
<p>Simon coined the term “Prompt Injection” after SQL Injection. He believes that we are not seeing digital assistants, because no one knows how to build them securely. 99% effective isn’t good enough. Never mix untrusted text with access to tools.</p>
<p>Simon showed how he gave the LLM a GeoJSON file with different line segments and prompted it to turn it into a single polygon. This “side project” took 3 1/2 minutes to complete</p>
<p>Simon showed how he had created a counter that incremented each time he said AI or artificial intelligence. It took 6 minutes to get to prototype and 20 minutes to get it polished.</p>
<p>Simon walked through how he passed structured data from the PSF Board Resolutions page into an LLM to parse it into a structured data table that could be filtered. He used a plugin he had been developing called llm.datasette.io.</p>
<p>Simon has been able to use LLM to more quickly build things that he couldn’t justify spending the time to build by hand.</p>
<p>Tips</p>
<ul>
<li><p>Ask it to give options (it’s more likely to give a better answer)</p></li>
<li><p>It will rarely get the answer right. Ask it to “do better.”</p></li>
</ul>
<p>LLMs make mistakes. It’s up to you to verify. The tool gets you 90% of the way there.</p>
<p>Rather than Generative AI, Simon likes to think of these tools as Transformative AI.</p>
<p>Personal AI ethics: Simon came across the term “slop” and likes it. Similar to spam, ask yourself, am I creating unwanted junk or am I using these tools in a responsible way?</p>
<p>Simon pondered if using LLMs is cheating. We care if students cheat, because it hurts them and they have an unfair advantage.</p>
<p>LLMs feel different. Simon’s whole career has been about getting things done more quickly, including by using open source code.</p>
<p>A few rules of thumb</p>
<ul>
<li><p>Never commit any code that you couldn’t actively explain to someone else</p></li>
<li><p>LLMs are good at explaining code. Give it code in a language you don’t understand and it will explain it with 90% accuracy</p></li>
<li><p>Then, help people understand how you did it!</p></li>
</ul>
<p>He said software engineers are uniquely positioned to take advantage of LLMs, because LLMs are good at generating code, and you can check the code by running it.</p>
<p>Simon is optimistic. You need to have a CS degree or spend a lot of time learning to do the simplest of computer tasks.</p>
<p>LLMs opens programming up to a much wider community. Simon believes that we have a responsibility to not leave anyone behind.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="hallway-track">
<h3>Hallway Track<a href="#hallway-track" title="Link to this heading">¶</a></h3>
<p>It was wonderful to see Moshe Zadka at PyTexas where he gave a talk “<a href="https://www.youtube.com/watch?v=WMK7pTOdECQ">Iterate, iterate, iterate</a>” and again at PyCon US where he gave me a Moleskin journal from Anthropic for recording convo starters for next-generation AI assistant <a href="https://www.anthropic.com/news/introducing-claude">Claude</a>.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/moshe-convo-starters.jpg">
Moleskin from Moshe</p>
<p>At DjangoCon US 2023, Marc Gibbons gave a wonderful talk called “<a href="https://2023.djangocon.us/talks/empathetic-testing-developing-with-compassion-and-humility/">Empathetic testing: Developing with compassion and humility</a>”. Not only was it his first conference talk, but after 44 chemo treatments, 15 fractions of radiation, and a stem cell transplant to treat Hodgkin Lymphoma, he had been given a clean bill of health the week before. It was wonderful to have the chance to catch up with him at PyCon US.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="overcoming-gil-with-subinterpreters-and-immutability">
<h3>Overcoming GIL with subinterpreters and immutability<a href="#overcoming-gil-with-subinterpreters-and-immutability" title="Link to this heading">¶</a></h3>
<p>Yury Selivanov showed a screen with a single Python process running 10 async IO event loops saturating the 10 CPU cores on his laptop, all sharing memory and exchanging values between them from 1 million keys and values and done fairly efficiently. Yury said it is possible to build fast things with Python.</p>
<p>Yury kind of likes the GIL. When he tries to do free-threading or multi-thread programming, bad things happen.</p>
<p>Free-threading will take a couple of years to be stable. Python subinterpreters are relatively new. You can run these subinterpreters in the same process, side-by-side, isolated from each other, each with its own GIL and occupying one CPU core, sharing the same memory space.</p>
<p>One of the subinterpreters will be the main one and will spawn workers and perhaps can have queues between workers and spawn tasks.</p>
<p>What if we could safety share state between the subinterpreters with the potential for lots of it and without using pickle, because it’s slow?</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/yury-shared-state-no-pickle.png">
Safe shared state… no pickle</p>
<p>Yury has created a minimal library called <a href="https://github.com/edgedb/memhive">memhive</a> that enables efficient data sharing between isolated subinterpreters.</p>
<p>He showed a code snippet.</p>
<p>Architecture</p>
<ul>
<li><p>Level 1: simple protocol that enables you to send Python data across subinterpreter boundary</p></li>
<li><p>Level 2: higher level API (queues and sychronization primitives)</p></li>
<li><p>Level 3: async IO bridge</p></li>
</ul>
<p>Create memhive and define the async workers that will be running in each separate subinterpreter, each with its own async IO loop. They can access shared state, listen to messages, send messages, spawn worker subinterpreters. The main interpreter will initialize the shared state, broadcast signals to all subinterpreters, push work so that one starts working on a task, listen to messages.</p>
<p>Rather than how it works, Yury felt it was more important to talk about how it’s implemented.</p>
<p>3 things to talk about</p>
<ul>
<li><p>Immutability</p></li>
<li><p>Efficient immutability</p></li>
<li><p>How we can benefit from it</p></li>
</ul>
<p>Immutability</p>
<ul>
<li><p>Python has immutable types: str, int, floates, bytes, tuples</p></li>
<li><p>You cannot change an existing object. You have to create a new object out of the existing object.</p></li>
<li><p>There is no immutable dictionary or mapping in CPython, which Yury says is a shame.</p></li>
</ul>
<p>Efficient immutability</p>
<ul>
<li><p>Creating a new tuple out of an existing one is efficient (O(n)), but you are not usually dealing with a lot of records.</p></li>
<li><p>The same inefficiency would be very bad for a dictionary, because we are potentially putting millions of items in them.</p></li>
<li><p>Dictionaries can be used as caches, but rebuilding it every time would be unacceptably slow.</p></li>
<li><p>Fortunately smart people created a nice algorithm that can implement this with O(log n)</p></li>
</ul>
<p>The trick Yury would show used trees behind the scenes.</p>
<p>As keys and values are added to an empty root node of the tree, when a key conflict happens, another node on the second level is created and the key is added to it instead. The tree will get bigger and bigger as items are added.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/yury-efficient-immutability.png">
Linking a second level node by reference</p>
<p>Imagine that we want to mutate this tree. We run the algorithm to figure out where to put the key, then need to copy the root node (it’s immutable, so we can’t mutate it).</p>
<p>This is where the magic happens.</p>
<p>We don’t have to copy the second level of the tree. We can re-use it. We just need the reference.</p>
<p>In a mapping with billions of keys, perhaps five nodes out of 10,000 change.</p>
<p>This is called structured sharing. The algorithm is called HAMT (Hash Array Mapped Trie). Yury implemented it in the Python Standard Library. It can be found in contextvars module. The <a href="https://github.com/python/cpython/blob/13a5fdc72f701c053b96abea48cd8f2775e9418e/Python/hamt.c">hamt.c file</a> has a 200 line comment explaining in detail how this data structure works.</p>
<p>How we can benefit from it</p>
<ul>
<li><p>All subinterpreters run in the same OS process so they share the same memory space</p></li>
<li><p>If we want to access this tree from the main subinterpreter, we just look into the memory directly. It is immutable and will not change.</p></li>
<li><p>If we want to add a key, we don’t have to copy the entire tree, we just create the missing new branches and reference others</p></li>
<li><p>If we have a tree with billions of keys, we just create a couple of tree nodes in a worker subinterpreter, the rest can be re-used.</p></li>
<li><p>Key: using immutable things, we can access the underlying memory safely without locks, as long as we can guarantee that the data would not be garbage collected.</p></li>
<li><p>memcopy is used and is really fast.</p></li>
</ul>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/yury-node-copy.png">
Create tree nodes in the worker subintrepreter and re-use the rest</p>
<p>Yury performed a benchmark. Structured sharing is significantly faster than using pickle, potentially 6x to 150,000x faster.</p>
<p>Yury talked about some of the implementation details icluding incref and decref. incref keeps Python objects alive when the ref count goes to zero. The data sharing mechanism has to guarantee safety.</p>
<p>The hard part of this is implemented in memhive, but some bugs need to be fixed. Do not use it in production.</p>
<p>Yury is building this for Edge DB to optimize cloud deployments.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="measuring-the-performance-of-cpython">
<h3>Measuring the performance of CPython<a href="#measuring-the-performance-of-cpython" title="Link to this heading">¶</a></h3>
<p>“Measuring the Performance of CPython” by Michael Droettboom (Microsoft CPython Performance Engineering Team, Faster CPython Team)</p>
<p>I did not watch this full talk, because I left early to go to the PSF Members Luncheon.</p>
<p>A few key takeaways from what I did watch:</p>
<ul>
<li><p>The Faster CPython Team has made Python 3.11 20-60% faster depending on what you are doing</p></li>
<li><p>This talk was born out of a need to benchmark in order to determine if they were working on the right things to impact Python performance</p></li>
<li><p>In the Python world, benchmarks are in pyperformance suite (a little over 100 benchmarks, some 30 or 40 years old)</p></li>
<li><p>Not all benchmarks are created equal</p></li>
</ul>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-benchmarking-faster-python.png">
Other projects that have aimed to make faster Pythons over the years</p>
<p><a href="https://www.amazon.com/Computer-Architecture-Quantitative-Approach-Kaufmann/dp/0128119055">Computer Architecture: A Quantitative Approach</a> has a useful chapter for looking at benchmarks and categorizing what they are useful for</p>
<ul>
<li><p>Toy benchmarks: simple, less than 100 lines of code, cool, but not a common use case</p></li>
<li><p>Real applications: take some code that runs in production, maybe on a massive scale and running it in a benchmark suite</p></li>
<li><p>Microbenchmarks (not in the textbook): measuring a narrow feature of the language</p></li>
</ul>
<p>Sub-topics of real applications benchmarks:</p>
<ul>
<li><p>Modified application: change it slightly to make it better as a benchmark</p></li>
<li><p>Application kernel: taking one subsystem of application and benchmarking that specifically</p></li>
</ul>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="psf-members-luncheon">
<h3>PSF Members Luncheon<a href="#psf-members-luncheon" title="Link to this heading">¶</a></h3>
<p>I attended the PSF Members Luncheon.</p>
<p>I sat at a table that included Naomi Cedar (Author of <a href="https://www.manning.com/books/the-quick-python-book-third-edition">The Quick Python Book</a>), Tres Seaver (Zope), Chris Brousseau (PyBay), and Phebe Polk (PyBay Piggies).</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/psf-members-luncheon.jpg">
I really enjoyed the presentation.</p>
<p>At the luncheon, I had the chance to chat with Jannis Leidel (Anaconda) again. At PyCon US 2019, I met him serendipitously while I was working at the PyLadies booth. Once upon a time, he worked on Pinax, an open source library that I later helped maintained. I was able to learn more about the history of the project from him.</p>
<p>I later went over to Hynek Schlawack (prolific open source maintainer) who remembered we had met at PyGotham 2019 where I attended a talk he gave! While chatting with him, he introduced me to Hugo van Kemenade, the CPython 3.14 and 3.15 Release Manager. It was very cool to meet him, and it turns out that he maintains <a href="https://pillow.readthedocs.io/en/stable/">Pillow</a> package. I am a big fan of Pillow. I used it to create my Twitter art bot which is very special to me. :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="profile-pic">
<h3>Profile Pic<a href="#profile-pic" title="Link to this heading">¶</a></h3>
<p>My friend Melanie Arbor (O’Reilly Media) takes great profile pics. At DjangoCon US 2017, she took my pic, and I loved it. I’ve used it as my social media profile pic since then, but it’s getting a bit dated. I saw her at PyCon US and asked her if she would be willing to take a new profile pic of me. It turned out that she had already created a “Profile Pic Palooza” open space for Saturday at 3 pm. As a bonus, I got to catch up with Chalmer Lowe (Google) for the first time since PyCon 2019.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/me-by-melanie.jpg">
New profile pic :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="juggling">
<h3>Juggling<a href="#juggling" title="Link to this heading">¶</a></h3>
<p>Not only does Ned Batchelder (<a href="https://coverage.readthedocs.io/">coverage.py</a> Maintainer) maintain a powerful Python package and give popular conference talks (check out <a href="https://nedbatchelder.com/text/key23.html">People: The API User’s Guide</a>), he is also a juggling enthusiast. When I saw his juggling open space in progress, I couldn’t resist stopping. I juggled for the first time in probably decades! It was also great to catch up with Paul Ganssle (Google, CPython Core Dev, pytz maintainer), and meet Rob Ludwick (Bank of NY Mellon) and William Higgins (Consumer Financial Protection Bureau).</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/me-juggling.png"></p>
<p><a href="https://www.youtube.com/shorts/TJfENk2653c">Video</a> of me juggling!</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="id2">
<h3>Hallway Track and Expo Hall<a href="#id2" title="Link to this heading">¶</a></h3>
<p>It was great to see Jacob Kaplan-Moss (early Django Engineer) and Frank Wiles (RevSys, former DSF President) again.</p>
<p>I saw Glyph Kefkowitz’s badge and immediately knew he was probably the same Glyph (<a href="https://twisted.org/">Twisted</a> Project Leader) I’d come across on social media. I learned more about Twisted when Amber Brown gave a keynote at DjangoCon US US 2019 “<a href="https://2019.djangocon.us/talk/keynote-amber-brown/">The Natural State of Computers</a>”. Glyph and I talked about the role of Twisted in the async world and the possibility of using Twisted for async orchestration.</p>
<p>Speaking of my DjangoCon US 2017 talk, Russell Keith-Magee (Beeware Founder, former DSF President, prolific public speaker) was my speaker mentor at the time. At PyCon US 2024, I had the chance to catch up with him before the PyLadies Auction. I congratulated him on the acceptance of <a href="https://peps.python.org/pep-0730">PEP 730: Adding iOS as a supported platform</a>. Python now runs on iOS without a patch! Russell’s <a href="https://beeware.org/">Beeware</a> Project enables you to write an app in Python and release it on multiple platforms, including desktop and mobile! Check out his PyCon US 2019 <a href="https://www.youtube.com/watch?v=ftP5BQh1-YM">Python Black Swans Keynote</a>) and many Beeware talks.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="pyladies-auction">
<h3>PyLadies Auction<a href="#pyladies-auction" title="Link to this heading">¶</a></h3>
<p>The <a href="https://us.pycon.org/2024/events/pyladies-auction/">PyLadies Auction</a> is always a roaring good time.</p>
<p>Not long after I sat down, I was excited to see Reuven Lerner (<a href="https://lerner.co.il/">Python Trainer</a>) walking past. He sat down next to me, and it was a pleasure to get to know him. I also enjoyed chatting with Danielle Casper (Amazon) about systems engineering and with Scott Karlin (Princeton).</p>
<p>A cuckoo clock donated by Capital One sold for $3,400. A “stupid” pen sold for $700.</p>
<p>The auction raised $60,000, $15,000 more than it ever had before. The community showed up in a big way!</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/hats.jpg">
<a href="https://www.youtube.com/watch?v=PGZPSWZSkJI">CPython Release Stream</a> participants showing off their hats</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/giant-guido.jpg">
A miniature cutout of Guido for selfies and rubber duck debugging :)</p>
<p>Thank you to my friends Jackie Kazil (Bana Solutions, Project Mesa), Lorena Mesa (Netflix, PyLadies Chicago), and Lynn Root (Spotify) for all of the hard work they put into the auction this year and every year, and to Doug Napoleone for emceeing and Kushal Das for taking pics!</p>
<p>A PyLadies Grant helped me attend PyCon US 2019.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/me-and-jackie.jpeg">
Me and Jackie Kazil :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="sunday">
<h2>Sunday<a href="#sunday" title="Link to this heading">¶</a></h2>
<section id="posters">
<h3>Posters<a href="#posters" title="Link to this heading">¶</a></h3>
<p>I started Sunday morning by checking out all of the posters.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="ethan-smith">
<h3>Ethan Smith<a href="#ethan-smith" title="Link to this heading">¶</a></h3>
<p>Ethan Smith (Nvidia, formerly Sentry) and I have been following each other on social media for a while. We met in person and talked about his packaging work at Nvidia.</p>
<p>He was working on a draft Packaging PEP (Python Enhancement Proposal) “Supporting Symlinks in Wheels” sponsored by Barry Warsaw.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="pyladies-lunch">
<h3>PyLadies Lunch<a href="#pyladies-lunch" title="Link to this heading">¶</a></h3>
<p>On Sunday, I attended the <a href="https://us.pycon.org/2024/events/pyladies-lunch/">PyLadies Luncheon</a>. It was wonderful, as usual.</p>
<p>Thank you to Marie Roald, Sydney Runkle (Pydantic), Kim Tendulkar, Erika Ambrosio (Tampa Bay Lightning), Sierra Brown, Grace (Muck Rack) (and a few others whose names I did not catch) for a really wonderful conversation over lunch.</p>
<p>I learned from Sydney who leads open source at Pydantic that <a href="https://docs.pydantic.dev/latest/">Pydantic</a> is often used with Django Rest Framework. I am looking forward to learning more! Check out Sydney’s PyCon US talk “<a href="https://us.pycon.org/2024/schedule/presentation/84/">Pydantic Power-up: Performance Tips for Lightning-Fast Python Applications</a>”.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/pyladies-luncheon.jpg">
Lynn Root, PyLadies Global Council, addressing the crowd</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/pyladies.jpg">
PyLadies Booth in the Expo Hall</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/pyladies-t-shirt.jpg">
Beautiful PyLadies t-shirt :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="building-a-jit-compiler-for-cpython">
<h3>Building a JIT compiler for CPython<a href="#building-a-jit-compiler-for-cpython" title="Link to this heading">¶</a></h3>
<p>Brandt Bucher (Microsoft CPython Performance Engineering Team)</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-compiler-background.png">
Updates that provided the foundation for a copy and patch JIT Compiler.</p>
<p>In Python 3.13, a <a href="https://peps.python.org/pep-0744/">JIT Compiler</a> was implemented. This was only possible, because of the work done in Python 3.11 and 3.12.</p>
<p>In Python 3.11, a <a href="https://peps.python.org/pep-0659/">Specializing Adaptive Interpreter</a> was implemented that brought a 25% performance improvement on average. At PyCon US 2023, Brandt gave a talk about it “<a href="https://www.youtube.com/watch?v=shQtrn1v7sQ">Inside CPython 3.11’s new specializing, adaptive interpreter</a>”.</p>
<p>In Python 3.12, infrastructure was implemented to automatically generate an interpreter from a DSL spec. This allowed for some repetitive, tedious, error-prone boilerplate to be removed from the main interpreter loop and different bytecode instructions to be analyzed.</p>
<p>In Python 3.13, a second <a href="https://github.com/faster-cpython/ideas/issues/580">“micro-op” interpreter</a> was implemented. It’s an entirely separate execution pipeline that detects hot code paths and lowers them to a new bytecode format called “micro-ops.” They are optimized and executed in another dedicated interpreter.</p>
<p>Brandt showed how the pipeline works using a Fibonacci function as an example. He showed the code, the code’s bytecode, and the stack.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-compiler-fibonacci.png">
Fibonacci code</p>
<p>This is where specialized bytecode comes in. If the operation is generalized to accommodate many use cases, but the code’s actual use case is simple, the bytecode can be “specialized” to fit that simpler use case. The resulting bytecode instructions are more specific to the the actual values, types of the code.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-compiler-specialized-bytecode.png">
Implementing specialized bytecode</p>
<p>These instructions will now be broken down into smaller, more easily optimized parts called “micro-op traces.” Instructions that are necessary in some cases, but not this case, can be removed. The result will be the essential instructions to execute the code.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-compiler-micro-op-traces.png">
“micro-op traces”</p>
<p>Unfortunately, this new instruction format is more complex than basic bytecode instruction. Although each instruction is doing less work, there are more instructions. This is 20% slower than if we’d done nothing. Decoding each individual instruction in the micro-op interpreter is a lot more expensive.</p>
<p>That is where JIT compilation comes in.</p>
<p>Rather than decoding individual instructions in the interpreter, we can compile these optimized traces directly into machine code.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-just-in-time-compilation.png">
Just-in-time compilation</p>
<p>Python frame objects live out in heap memory. Instead, the stack can be moved to the register where it is immediately available and there is no latency. Rather than having a generic interpreter that needs to handle every possible micro-op, the hot code path can be transformed in a straight line sequence of the exact code needed.</p>
<p>Although we want to make the faster, we need to trade peak performance for implementation simplicity that can enable Python to run in many places with few runtime dependencies and be easily maintained, improved, and extended upon by volunteers.</p>
<p>While JIT compilers are historically complex, copy and patch compilation meets these requirements satisfying way.</p>
<p>The technique is explained in a 30 page paper “<a href="https://sillycross.github.io/assets/copy-and-patch.pdf">Copy and Patch Compilation</a>” and a blog post “<a href="https://sillycross.github.io/2023/05/12/2023-05-12/">Building a baseline JIT for Lua</a>” by the same author.</p>
<p>In a nutshell, it’s a way of automatically turning a C interpreter into a fast template JIT compiler</p>
<p>Copy and patch can enable us to take a sequence of bytecode instructions and translate it into fast machine code as quickly as possible.</p>
<p>At runtime, walk over a sequence of bytecode instructions. For each, we can do something we have long been able to do when linking or reloading a relocatable object file</p>
<ul>
<li><p>Copy some static, pre-compiled machine code into executable memory</p></li>
<li><p>Patch up instructions that need to have runtime data encoded into them (things like relocation records for extern symbols)</p></li>
</ul>
<p>Brandt walked through an example of how to go from micro op instruction to code we JIT at runtime.</p>
<p>At build time, when we are building the Python interpreter, the body of the instruction is extracted. It is put inside of its own function to be compiled in isolation. It won’t compile yet, because we are accessing objects with no values. These can be dynamically passed into the function as arguments. In terms of the “undefined locals” that will be the same once JIT-ed, and the frame and pointer that needs to be passed on so that we can JIT any additional micro-ops that we are JIT-ing, copy and patch gives an elegant solution for handling these: externs. Externs are similar to Python imports. You trust them to be defined at runtime.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit-externs.png">
externs</p>
<p>When compile this in Clang, the ELF file will have the raw bytes of machine code to execute the micro-op instruction and exactly where and how to patch values.</p>
<p>We then have the opportunity to perform some localized optimizations until it is the essential micro-op. This can be parsed out of the ELF file and put directly into code generated in a C header file. We have a function that can be called and it will JIT the instruction for us by copying bytes and patching the load.</p>
<p>This is super fast.</p>
<p>Because <a href="https://llvm.org/">LLVM</a> is used, there is a lot of platform support out of the box.</p>
<p>In order to build this yourself, you need to have LLVM 18 installed and follow the instructions in the CPython repo.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="unlocking-the-parallel-universe-subinterpreters-and-free-threading-in-python-3-13">
<h3>Unlocking the Parallel Universe: Subinterpreters and Free-Threading in Python 3.13<a href="#unlocking-the-parallel-universe-subinterpreters-and-free-threading-in-python-3-13" title="Link to this heading">¶</a></h3>
<p>Anthony Shaw created a <a href="https://gist.github.com/tonybaloney/24d545ed855a3c90f844209152835f07">gist</a> with the excellent pre-requisites for his talk.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/anthony-parallel-execution-in-python.png">
Parallel execution options in Python; In concurrency, multiple tasks share the same resource, while in parallelism, multiple resources execute multiple tasks.</p>
<p>In Python 3.11, the GIL lived in the interpreter and we had one GIL per Python process. Multi-processing was used to achieve parallel code execution. If a task were split in half, it would take twice as long, because only one process could run at a time.</p>
<p>In Python 3.12, because of a new API, the GIL is per interpreter. We can have multiple interpreters running at the same time with multiple threads. The operating system will figure out which core is available and schedule so they run in parallel.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/anthony-speed-differences.png">
Speed differences</p>
<p>Quick conclusion: a subinterpreter is like “multiprocessing with less overhead and shared memory”</p>
<p>In Python 3.13, we can disable the GIL and have a single interpreter running multiple threads at the same time. A task split in half will run more quickly now, because it will run in parallel.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/anthony-gil-removal-steps.png">
Steps to remove GIL</p>
<p>Free-threading introduces a new ABI that requires special wheels and a special build for CPython, creating compatibility issues. The ABI (application binary interface) is used to load a module that is being compiled in a language like C.</p>
<p>The GIL exists for thread-safety. We need to fix all of the C code that assumed the GIL existed and is not thread safe.</p>
<p>If everything is in pure Python, the Python team has full control over the interpreter. C extension compatibility poses a major challenge. Ironically, we have so many C extensions, because people optimized code, because they couldn’t run it in parallel.</p>
<p>At the moment, disabling the GIL generally makes Python code run slower. There are optimizations that have been disabled when the GIL is turned off, because they need to be made thread-safe before they can be used.</p>
<p>Anthony gave a demo followed by some closing thoughts with Terms and Conditions.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/anthony-terms-and-conditions.png">
Terms and conditions</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="sync-vs-async-in-python-tools-benchmarks-and-asgi-wsgi-explained">
<h3>Sync vs. Async in Python: Tools, Benchmarks, and ASGI/WSGI Explained<a href="#sync-vs-async-in-python-tools-benchmarks-and-asgi-wsgi-explained" title="Link to this heading">¶</a></h3>
<p>This talk by Arun Suresh Kamar was going on while I was in Anthony’s talk. It is at the top of my list to watch on demand.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="sumana-harihareswara-keynote">
<h3>Sumana Harihareswara Keynote<a href="#sumana-harihareswara-keynote" title="Link to this heading">¶</a></h3>
<p>“Untold Stories from Six Years Working on Python Packaging”</p>
<p>I met Sumana (Changeset Consulting, Python packaging, Recurse Center) at PyGotham 2017 and attended the <a href="https://pycon-archive.python.org/2019/hatchery/artofpython/">Art of Python</a> miniature arts festival that she organized at PyCon US 2019. It was wonderful to see her in her element at PyCon US 2024, on stage talking about Python packaging.</p>
<p>From 2017 to 2022, Sumana was a paid packaging project manager. She worked on things we use a lot, like pip.</p>
<p>Key takeaways</p>
<ul>
<li><p>A chance meeting led Sumana to help obtain funding from Mozilla and overhall PyPI to Warehouse, finishing on time and on budget and unblocking more improvements</p></li>
<li><p>The strength of weak ties, cross pollination are possible because of the kind of conversations that happen at places like PyCon US</p></li>
<li><p>Infrastructure is hard, it’s often invisible. People depend on it, but don’t know that they depend on it. Sumana compared it to being a water user.</p></li>
<li><p>If volunteers try to get the word out about changes and even ask for your feedback, treat them like people. We are all in this together.</p></li>
<li><p>When PSF gets funding, it gets results (see a list in the <a href="https://pypi.org/sponsors/">PyPI sponsors page</a>)</p></li>
<li><p>Organizations that rely on this infrastructure (and may have entitled opinions) can do a lot more to help</p></li>
<li><p>What seems like failure can prepare the ground for success: building organization, networks, knowledge, skill can be crucial for future successes you can’t foresee at the time</p></li>
<li><p>Sumana revised a bill to the NY City Council until it passed: The HEART Act to make Automated External Defibrillators more accessible to New Yorkers.</p></li>
<li><p>She wasn’t a Python packaging expert, but also wasn’t a public health expert. She planned and asked the right question until she got an answer.</p></li>
<li><p>You too can be the paddles that revive something that is stuck, in open source, local government</p></li>
</ul>
<p>Homework</p>
<ul>
<li><p>Renew a connection: reply to an old friend or colleague</p></li>
<li><p>Practice <a href="#volunteeramnestyday.net"><span>Volunteer Responsibility Amnesty Day</span></a>: on June 20th have a 20 minute meeting with yourself to think about your choices</p></li>
<li><p>Consider solidarity</p></li>
</ul>
<p>Sumana created a page with all of her excellent <a href="https://harihareswara.net/posts/2024/references-pycon-us-keynote/">keynote references</a>.</p>
<p>I got to say hello after the keynote and also had the chance to meet her husband Leonard Richardson, who authored <a href="https://beautiful-soup-4.readthedocs.io/en/latest/">Beautiful Soup</a>, another one of my favorite packages. :)</p>
<p>Leonard handed me a mini-zine called “Tool Safety” that he had written. After I got home and started looking through it, I saw that it had a beautiful message. You can see the online version <a href="https://www.crummy.com/software/BeautifulSoup/zine/">here</a>.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/tool-safety-zine.jpg">
Tool Safety mini-zine cover and page 3</p>
<p>As a bonus, before the talk began, I met Brian Walker who was sitting in my row. He’s a “Digital Billboard Jedi Master” software engineer working at Watchfire.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="steering-council-updates">
<h3>Steering Council Updates<a href="#steering-council-updates" title="Link to this heading">¶</a></h3>
<p>Current Python Steering Council Members: Emily Morehouse (Cuttlesoft), Barry Warsaw, Pablo Galindo Salgado, Thomas Wouters (Google), Gregory P. Smith (To be determined)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
<section id="barry-warsaw-steering-council-overview">
<h4>Barry Warsaw: Steering Council Overview<a href="#barry-warsaw-steering-council-overview" title="Link to this heading">¶</a></h4>
<p>The steering council is a five-person elected governance body responsible for the technical direction of Python: the evolution of the Python language, the CPython interpreter, and standard library. Elections happen annually, roughly aligned with Python releases.</p>
<p>Steering council members serve for one year and can run for re-election with no term limits. They are typically nominated and elected by CPython Core Devs, but you don’t have to be a CPython Core Dev to serve. No more than two members can work for the same company.</p>
<p>The steering council meets almost every week for 90 minutes. They are regularly joined by Deb Nicholson and Łukasz Langa. They discuss many topics which often come to their attention through the public GitHub tracker. A few of their important tasks: determining release cycle, choosing next release manager, pronouncing PEPs. The steering council has the final say on PEPs.</p>
<p><a href="https://peps.python.org/pep-0013/">PEP 13</a> outlines how the Python Steering Council operates.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="gregory-p-smith-steering-council-expenditures-update">
<h4>Gregory P. Smith: Steering Council Expenditures Update<a href="#gregory-p-smith-steering-council-expenditures-update" title="Link to this heading">¶</a></h4>
<p>How the steering council has spent PSF money to improve CPython</p>
<ul>
<li><p>Developer in Residence (team of 3 now: Łukasz Langa, Petr Viktorin, Serhiy Storchaka)</p></li>
<li><p>Security Developer in Residence: Seth Michael Larson</p></li>
<li><p>Steering Council Secretary: offer recently extended to Velda Kiara</p></li>
<li><p>Annual Core Developer Sprints</p></li>
</ul>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="emily-morehouse-councils-and-working-groups-update">
<h4>Emily Morehouse: Councils and Working Groups Update<a href="#emily-morehouse-councils-and-working-groups-update" title="Link to this heading">¶</a></h4>
<p>Firstly, Emily explained their role. As Python evolves, the requirements for helping change. Councils and working group members are experts in complex, specialized subjects. These groups report to the steering council and are able to help with decision making and management, such as reviewing and pre-approving PEPs.</p>
<p>Three working group changes</p>
<ul>
<li><p><a href="https://peps.python.org/pep-0732/">PEP 732: The Python Documentation Editorial Board</a></p></li>
<li><p><a href="https://peps.python.org/pep-0731/">PEP 731: C API Working Group Charter</a> (CPython’s API exposes certain aspects of Python internals and gives direct access to the Python interpreter from C and C++)</p></li>
<li><p><a href="https://peps.python.org/pep-0729/">PEP 729: Typing Governance Process</a></p></li>
</ul>
<p>The C API Working Group has a new <a href="https://github.com/capi-workgroup">repo</a>.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="thomas-wouters-overview-of-python-3-13">
<h4>Thomas Wouters: Overview of Python 3.13<a href="#thomas-wouters-overview-of-python-3-13" title="Link to this heading">¶</a></h4>
<p>Thomas Wouters, Python 3.12 and 3.13 Release Manager, gave an overview of 3.13</p>
<p>Breaking changes</p>
<ul>
<li><p><a href="https://peps.python.org/pep-0594/">PEP 594: Removing dead batteries from the standard library</a> (might put some back if too disruptive)</p></li>
<li><p>Removed many deprecated functions and classes</p></li>
<li><p>“Removed” many private C functions</p></li>
</ul>
<p>Type Annotation</p>
<ul>
<li><p><a href="https://peps.python.org/pep-0696">PEP 696: Type Defaults for Type Parameters</a> (James Hilton-Balfe)</p></li>
<li><p><a href="https://peps.python.org/pep-0702/">PEP 702: Marking deprecations using the type system</a> (Jelle Zijlstra)</p></li>
<li><p><a href="https://peps.python.org/pep-0705/">PEP 705: TypedDict: Read-only items</a> (Alice Purcell)</p></li>
<li><p><a href="https://peps.python.org/pep-0742">PEP 742: Narrowing types with Typels</a> (Jelle Zijlstra)</p></li>
</ul>
<p>Platform Support</p>
<ul>
<li><p><a href="https://peps.python.org/pep-0602/">PEP 602: Annual Release Cycle for Python</a> (Łukasz Langa)</p></li>
<li><p><a href="https://peps.python.org/pep-0730/">PEP 730: Adding iOS as a supported platform</a> (Russell Keith-Magee)</p></li>
<li><p><a href="https://peps.python.org/pep-0738/">PEP 738: Adding Android as a supported platform</a> (Malcolm Smith)</p></li>
<li><p>macOS on Apple Silicon (M1/M2/M3) is now Tier 1</p></li>
</ul>
<p>Despite saying there are no major new features in Python 3.13, Thomas acknowledged some exciting new developments.</p>
<ul>
<li><p>A new interactive interpreter based on PyPY’s, with color, multi-line editing, and paste support</p></li>
<li><p><a href="https://peps.python.org/pep-0744/">PEP 744: JIT Compilation</a> (Brandt Bucher)</p></li>
<li><p><a href="https://peps.python.org/pep-0703/">PEP 703: Making the Global Interpreter Lock Optional in CPython</a> (Sam Gross)</p></li>
</ul>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/jit.png"></p>
<p>Why even upgrade?</p>
<ul>
<li><p>Improved error messages (again)</p></li>
<li><p>Many bug fixes (not all of them can be backported to 3.12)</p></li>
<li><p>Many new features in standard lib modules</p></li>
<li><p>Stepping stone for future improvements</p></li>
<li><p>Discover what newly deprecated APIs you are using</p></li>
</ul>
<p>The 3.13 beta is out now! See the full release notes at <a href="https://bit.ly/python313">What’s New in Python 3.13</a>.</p>
<p>Thomas noted that incoming release manager Hugo van Kemenade has proposed switching to CalVer. He gave a talk “<a href="https://hugovk.github.io/python-calver/">Should Python adopt CalVer</a>” at the Language Summit.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="pablo-galindo-salgado-free-threading-update-a-k-a-no-gil">
<h4>Pablo Galindo Salgado: Free-Threading Update (a.k.a. No GIL)<a href="#pablo-galindo-salgado-free-threading-update-a-k-a-no-gil" title="Link to this heading">¶</a></h4>
<p>Pablo outlined the free-threading plan.</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-free-threading-the-plan.png">
The plan</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-free-threading-phase-1.png">
Experimental phase</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-free-threading-phase-2.png">
Supported, but not default</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-free-threading-phase-3.png">
Making it default</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-free-threading-community-support.png">
Community</p>
<p>Closing thoughts</p>
<ul>
<li><p>The CPython Core Team will regularly assess progress and work to prevent prolonged backward compatibility struggle</p></li>
<li><p>If things become problematic, it can be called off</p></li>
<li><p>Lessons have been learned. This will be neither Python 2 to 3, nor Python 4.</p></li>
<li><p>Free-threading is available on Python 3.13 with an optional flag and environmental variable</p></li>
</ul>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/python-steering-council-one-more-thing.png"></p>
<p>This thing is really happening. It feels like we went from Brett Cannon’s “put up or shut up” to this pretty quickly, lol.</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="dinner-and-ice-cream">
<h3>Dinner and Ice Cream<a href="#dinner-and-ice-cream" title="Link to this heading">¶</a></h3>
<p>After the conference ended on Sunday night, I found myself chatting with a group of old friends and new friends. They invited me to dinner, and I decided to join. It was a wonderful time, as you can tell from the photo. :)</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/sunday-night.jpeg">
Tammy Do (Code Fellows), Velda Kiara (DEFNA Board Member, Python Steering Council Secretary), Jim Anderson (Motorola Solutions, Real Python), Ngazetungue Muheue (LaLoka Labs, DjangoCon Africa), Kudzayi Bamhare, Benedict Kofi Amofah, me, Afi Gbagado, and Catherine Devlin (Corning, formerly Disney)</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/chocolate-bar.jpg">
Chocolate bar made by a Ghanian company and given to me by Afi :)</p>
<p>PyCon US had a <a href="https://us.pycon.org/2024/about/pycon-us-challenge/">challenge</a>. You could get points for completing certain activities and redeem them for an ice cream card. I was able to complete the challenge, because I had organized a Python-related conference (DjangoCon US 2023) and attended a regional Python conference (PyTexas 2024) since last PyCon US. After dinner, I went to <a href="https://www.millieshomemade.com/location/market-square/">Milley’s Homemade Ice Cream at Market Square</a> and used the ice cream card. I had Best Chocolate. Yummy!</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/ice-cream.jpg">
Best Chocolate :)</p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section>
<section id="monday">
<h2>Monday<a href="#monday" title="Link to this heading">¶</a></h2>
<p>At PyCon US 2019, on my last night in Cleveland, I spontaneously joined Sviatoslav Sydorenko (Ansible Core Developer), Stéphane Wirtel (CPython Core Developer), and a few other conference attendees at Flannery’s Pub for dinner. It was magical.</p>
<p>On the first day of the PyCon US 2024 Sprints, Sviatoslav Sydorenko and I found each other for a catch up. I suddenly made the connection that he is a core developer of <a href="https://github.com/ansible">Ansible</a>, a tool that I use. Mind blown. :) He gave me some insight about being a programmer versus engineer and distributed systems. It was a very enlightening conversation for me.</p>
<p>I also met Seth Michael Larson (PSF Security Developer in Residence) in person in the packaging sprints room. I have been following his security work, which has included <a href="https://sethmlarson.dev/security-developer-in-residence-weekly-report-9">Visualizing the CPython release process</a>, <a href="https://pyfound.blogspot.com/2024/02/software-bill-of-materials-now-available-for-cpython.html">making CPython source release Software Bill-of-Materials (SBOMs) available</a>, and <a href="https://www.cve.org/Media/News/item/news/2023/08/29/Python-Software-Foundation-Added-as-CNA">getting the PSF set up as a CVE Numbering Authority</a>. He told me more about his background and work. His <a href="https://sethmlarson.dev/">blog</a> is an awesome source of info, and I highly recommend following him for news!</p>
<p>Interactions like these brought to mind a post by Frank Wiles:</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/frank-post.png"></p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
<section id="until-next-time">
<h2>Until Next Time<a href="#until-next-time" title="Link to this heading">¶</a></h2>
<p>Thank you to everyone for making this a truly epic experience. The talk replays should be public soon.</p>
<p>If you are looking for another conference experience, check out the mega-regional conference list in the closing presentation.</p>
<p>After chatting with a PSF Staff Member a few years ago about location selection, I assumed that PyCon US would never be held in a high cost of living city.</p>
<p>It was announced that PyCon US 2026 will be in Long Beach, California.</p>
<p>Last year, I treated myself by taking <a href="https://katherinemichel.github.io/portfolio/los-angeles-2023.html">my dream Los Angeles vacation</a> in December. I loved it, and I can’t wait to go back for PyCon US! :)</p>
<p>In the meantime, I hope to see you all in Pittsburgh next year!</p>
<p><img alt="" src="https://katherinemichel.github.io/portfolio/_images/badge1.jpg"></p>
<p>🔝 <sub><a href="#table-of-contents"><span><strong>back to top</strong></span></a></sub></p>
</section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[If A.I. Can Do Your Job, Maybe It Can Also Replace Your CEO (102 pts)]]></title>
            <link>https://www.msn.com/en-us/news/us/if-a-i-can-do-your-job-maybe-it-can-also-replace-your-c-e-o/ar-BB1nbdAX</link>
            <guid>40552398</guid>
            <pubDate>Sun, 02 Jun 2024 08:16:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.msn.com/en-us/news/us/if-a-i-can-do-your-job-maybe-it-can-also-replace-your-c-e-o/ar-BB1nbdAX">https://www.msn.com/en-us/news/us/if-a-i-can-do-your-job-maybe-it-can-also-replace-your-c-e-o/ar-BB1nbdAX</a>, See on <a href="https://news.ycombinator.com/item?id=40552398">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Parable of the Sofa (438 pts)]]></title>
            <link>https://www.tbray.org/ongoing/When/202x/2024/06/01/Parable-of-the-Sofa</link>
            <guid>40551725</guid>
            <pubDate>Sun, 02 Jun 2024 05:57:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.tbray.org/ongoing/When/202x/2024/06/01/Parable-of-the-Sofa">https://www.tbray.org/ongoing/When/202x/2024/06/01/Parable-of-the-Sofa</a>, See on <a href="https://news.ycombinator.com/item?id=40551725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="centercontent">
<p itemprop="description">When Lauren was pregnant with a child who’s now turning 25, we purchased a comfy dark-brown
    leather sofa which fits our living room nicely.  
    What with kids and relatives and
    employees and cats and Standards Comittees and friends and book clubs and socials, the butt-support cushions had, a quarter
    century later, worn out. So we had them replaced, at a fair price, by a small local business. Which is something that modern
    capitalism is trying to make impossible.</p>

<p><img alt="Worn leather with a phone for scale" title="Worn leather with a phone for scale" src="https://www.tbray.org/ongoing/When/202x/2024/06/01/worn.png"></p><p>I’ll be honest; when we realized how ratty the sofa was getting, my first thought was “crap, gonna have to buy a sofa”. But
    Lauren said “No, because new sofas suck. Also, Luxcious.”</p>

<p>I’ll get to Luxcious in a bit, but it turns out that new sofas, by and large, really do. Why would that be? Well, check out
    <a href="https://www.dwell.com/article/dtc-sofa-crisis-32304b9e">Why Are (Most) Sofas So Bad?</a> in <cite>Dwell</cite>
    magazine which has a weirdly-intermittent paywall, here’s <a href="https://archive.is/deGMX">another version</a>.</p>

<p>From early in the piece: “Sofas made in the past 15 years or so are absolute garbage, constructed of
    sawdust compressed and bonded with cheap glue, simple brackets in place of proper joinery, substandard spring design, flimsy
    foam, and a lot of staples.” It’s excellent, well-written, and will take you some surprising places.</p>

<p>But the subtext is
    drearily familiar. Globalization: Check. Cheap-labor arbitrage: Check. Tax engineering: Check. High profits:
    Check. Flat-packing: Check. Late Capitalism: Check check fucking check.</p>

<p>But, quality furniture is expensive to make, and
    should be, but doesn’t wear out fast, thus deserves extended maintenance.</p>

<p id="p-1"><span>Luxcious</span> · 
Its
    <a href="https://luxciousupholstery.ca/">Web site</a> (“Breathe new life into old furniture”) is way prettier than its location,
    in an old and extremely miscellaneous high-traffic zone: auto-body shops, hipster lounges, self-storage, beauty supplies…</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/06/01/-big/PXL_20240528_195945287.jpg.html"><img alt="Luxcious on Main Street" title="Luxcious on Main Street" src="https://www.tbray.org/ongoing/When/202x/2024/06/01/PXL_20240528_195945287.png"></a></p>
<p>They’re family-run and idiosyncratic. You have to know how to find the sketchy rear parking lot and walk in the back
    door. But they’re friendly and competent. Here’s the new leather they bought for the cushions.</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/06/01/-big/PXL_20240522_202346949.jpg.html"><img alt="One cow’s worth of leather" title="One cow’s worth of leather" src="https://www.tbray.org/ongoing/When/202x/2024/06/01/PXL_20240522_202346949.png"></a></p>
<p>And here’s the sofa with the re-covered cushions in place.</p>

<p><a href="https://www.tbray.org/ongoing/When/202x/2024/06/01/-big/PXL_20240528_204400696.jpg.html"><img alt="Sofa with refinished cushions" title="Sofa with refinished cushions" src="https://www.tbray.org/ongoing/When/202x/2024/06/01/PXL_20240528_204400696.png"></a></p>
<p>Yes, from this angle, the new cushions make the sofa’s back look shabby, but it’s not as obvious to the naked eye and after a
    decade or so we’ll never notice it.</p>

<p>The whole job cost us $1100 Canadian.
    Given that the sofa cost three-thousand-plus 1999 dollars and new leather sofas of the “not flat-packed sawdust and
    glue” variety quickly get into five figures, the choice was a no-brainer.</p>

<p id="p-2"><span>“Lifestyle”</span> · 
This kind of transaction is exactly what modern capitalism is trying to stamp out.</p>

<p>A single-location family-owned business that provides a living for a few people? With no plans to load up on debt or
    other financial
    engineering? Or for growth into unicorn status? No GenAI dimension? No marketing or public-relations people?</p>

<p>In conversation with venture capitalists, you hear the phrase “lifestyle business”, meaning one that is doing nicely
    and rewarding the people who run it and which isn’t planning for unbounded growth.  The words “lifestyle business” are always, of
    course, uttered in a voice dripping with contempt. Luxcious is a lifestyle business.</p>

<p>It seems blindingly obvious that an economy with a higher proportion of lifestyle businesses is going to be more resilient,
    more humane, and immensely more pleasant than the one that the Leaders Of Industry are trying to build.</p>

<p>How would we get there from here?  I’m not smart enough to figure out what the regulatory regime is that would ban most of what
    private-equity does and tilt the playing field in favor of resilient lifestyle businesses.</p>

<p>But I’d sure vote for a political party that convinced me it was trying to achieve that.</p>

<hr>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Signal: Will leave the EU market rather than undermine our privacy guarantees (503 pts)]]></title>
            <link>https://twitter.com/mer__edith/status/1796508893822238881</link>
            <guid>40551260</guid>
            <pubDate>Sun, 02 Jun 2024 04:11:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/mer__edith/status/1796508893822238881">https://twitter.com/mer__edith/status/1796508893822238881</a>, See on <a href="https://news.ycombinator.com/item?id=40551260">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Unlocking the Duron and Athlon using the pencil (2007) (102 pts)]]></title>
            <link>http://computer-communication.blogspot.com/2007/06/unlocking-duron-and-athlon-using-pencil_08.html</link>
            <guid>40551112</guid>
            <pubDate>Sun, 02 Jun 2024 03:29:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://computer-communication.blogspot.com/2007/06/unlocking-duron-and-athlon-using-pencil_08.html">http://computer-communication.blogspot.com/2007/06/unlocking-duron-and-athlon-using-pencil_08.html</a>, See on <a href="https://news.ycombinator.com/item?id=40551112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <h2><span>Introduction<o:p></o:p></span></h2>   <p><img alt="" src="http://www.motherboards.org/images/articles/guides/thumbs/41_p1_1.jpg"></p><p>The best and most stable way to overclock your Athlon and Duron CPU is through changing the CPU clock multiplier. Overclocking can be done by changing the FSB (front side bus) of the motherboard, but the Athlon doesn't respond well to overclocking that particular way. To get your Athlon CPU ready to be overclocked requires a slight modification of the CPU called "The Pencil Trick".<br>The Pencil Trick unlocks the full potential of your CPU. Overclocking the Intel series of CPUs is different than that of an Athlon, and was done mainly by tweaking the FSB of the CPU on the motherboard. FSB overclocking methods, such as running your 300A Celeron set to run at 450MHz by setting the FSB to 100MHz x 4.5 instead of the factory setting of 4.5 x 66MHz, were done very easily. This resulted in a stable overclocked CPU at 450MHz. If you tried overclocking your Athlon in such a way, your system would never POST because the Athlon is not designed like the Intel chip to be compatible at the higher frequencies of an increased FSB. The only drawback to this is that the potential for customers to be ripped of by untrustworthy dealers selling overclocked CPUs to the public at the price of the actual CPU speed is increased by a large margin. Intel long ago locked the multiplier of their CPUs to keep such things from happening with their processors. So with the Intel, chip adjustment of the FSB was the only available option for overclocking.<br>The Athlon CPU is not designed to handle a high frequency FSB, but will allow you to reconnect the L1 bridges, allowing the processor to be set at any clock frequency, making overclocking an easy task. In the first releases of the Athlon/Duron motherboards you had to not only modify the processor, but you had to modify the motherboard to be able to adjust the Vcore and voltage settings to get a stable overclocked system. But manufacturers soon got the point and started to include those features on their motherboards, making the CPU the only modification you need to make. This works, and is very risk free. The room for error is not great, so even the not-so-mechanically-inclined can take on this task and be successful. I have always been against too much modification, because it can result in the loss of equipment. I wholeheartedly believe in this procedure, as the modification is very minimal and the chance of ruining your equipment is almost zero.<br></p> <p>Contents<br>1. Introduction<br>2. Setup<br>3. Step 1<br>4. Step 2<br>5. Step 3<br>6. Conclusion<br>Setup<br>You will need a very small-tip pencil, preferably a 0.5mm-type mechanical pencil such as the one made by Ritter, as the tool for this procedure. People think this is absolutely a crazy idea, but it actually works great, and is very easy to do. Lead will not burn at the frequencies running along it, so there is no fear of that happening, as is suggested by some. The L1 Bridges on The Athlon/Duron CPUs are the bridges that lock the multiplier. These bridges are cut off by laser at the factory to lock the CPU at a certain clock frequency, but can be reconnected by using the graphite of the pencil lead to conduct electricity across the bridge, effectively unlocking a locked processor. This is safe and relatively simple to do. Just take your time and follow a few simple procedures</p> <center><img height="64" src="http://www.motherboards.org/images/articles/guides/ritterpencil.gif" width="468"></center><p><span>  Step 1</span></p> <p>Remove your processor from your system and find a well-lit and flat working area. Set your CPU on something that won't damage the pins of the processor. Locate the L1 bridges on the CPU and get your mechanical pencil ready for action. Both the Athlon and Duron processors have the same L1 connecting bridges and are done in the same way.<br></p><p>  Step 2</p>  <p><br>Hold your CPU in your left hand and look very closely at the CPU, so as to clearly see the L1 bridges. Use a business card to separate the bridges so that you do not connect the L1 bridges to each other. Work your way across the bridges from left to right (using a business card as a separation tool) and connect the bridges by rubbing the pencil back and forth over the bridges about twenty times until it is dark black, not the normal gold color. Make sure that all the bridges are reconnected, but not touching each other, and you are on your way. I know it sounds incredible, but that is actually all there is to it. Your processor, if done correctly, is ready to be overclocked. It can now be set to run at different clock frequencies, eliminating the need to increase the FSB.</p><center><img height="292" src="http://www.motherboards.org/images/articles/guides/unlock.jpg" width="440"></center> <p><span>Step 3</span><br>Reinstall your processor back into your system. Make sure you use a good cooling solution, such as the Silver Orb by Thermaltake or an equivalent, as the CPU will need to have better cooling in an overclocked state. Use thermal grease if you have it, preferably a silver-based compound. You can see some good stuff at www.arcticsilver.com. It is messy, but it is very necessary when you are overclocking your CPU, as it makes a seal with the cooling solution for better heat dissipation. You may need to adjust the voltage in order to obtain a stable overclocked CPU. I had to increase the voltage by .05 percent, but then everything ran stable. I was able to run a 650MHz Duron at 800MHz and a 700MHz Athlon at 900MHz just by using a pencil and a few BIOS adjustments. This is a very easy task and can be done by just about anyone who has access to a pencil. I like the mechanical pencil, but a sharp There are many motherboards out currently on the market that support overclocking and have good features to insure you have a properly running, stable system.<br>  </p><center><img height="163" src="http://www.motherboards.org/images/articles/guides/silverorb.gif" width="150"></center><p><br><span>  Conclusion</span><br>This is the simplest and easiest way to modify a CPU that I have ever seen. You can gain a significant amount of increased processor power for the cost of about five cents of pencil lead. Those who are still reluctant, let me tell you I was too, until one day I just gave it a shot, and it was so simple I had to laugh at myself for waiting so long to try it. The Athlon and Duron Processors respond very well to this, and can be set to run at many different speeds with the right combination of settings. All I have to say in closure is take a chance. Grab your Athlon/Duron processor, get a pencil, and unlock that CPU of yours. Then you can get the most performance out of it.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How do our brains adapt to control an extra body part? (203 pts)]]></title>
            <link>https://www.cam.ac.uk/stories/third-thumb</link>
            <guid>40551070</guid>
            <pubDate>Sun, 02 Jun 2024 03:17:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cam.ac.uk/stories/third-thumb">https://www.cam.ac.uk/stories/third-thumb</a>, See on <a href="https://news.ycombinator.com/item?id=40551070">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="section-BH3xLMAV1a" data-effects="eyJ0ZXh0UGVyTGluZSI6ZmFsc2UsImhhc0VmZmVjdHMiOmZhbHNlLCJuZWVkc0JhY2tncm91bmRDbG9uZSI6ZmFsc2UsImVuY29kZWQiOiIifQ==">
                <h2><span><strong>In 2022, the team had the opportunity to test the Third Thumb at the annual Royal Society Summer Science Exhibition, where members of the public of all ages were able to use the device during different tasks. </strong></span></h2>
                <p>The results are published today <span>in <em>Science Robotics</em>.</span></p>
                <p>Over the course of five days, the team tested 596 participants, ranging in age from three to 96 years old and from a wide range of demographic backgrounds. Of these, only four were unable to use the Third Thumb, either because it did not fit their hand securely, or because they were unable to control it with their feet (the pressure sensors developed specifically for the exhibition were not suitable for very lightweight children).</p>
                <figure data-lazyload-container="true" data-lazyload-trigger="true">
                  
                  <figcaption>
                    <p>The Third Thumb team at the Royal Society Summer Exhibition</p>
                    <p>The Third Thumb team at the Royal Society Summer Exhibition</p>
                  </figcaption>
                </figure>
                <p>Participants were given up to a minute to familiarise themselves with the device, during which time the team explained how to perform one of two tasks.</p>
                <p>The first task involved picking up pegs from a pegboard one at a time with just the Third Thumb and placing them in a basket. Participants were asked to move as many pegs as possible in 60 seconds. 333 participants completed this task.</p>
                <p>The second task involved using the Third Thumb together with the wearer’s biological hand to manipulate and move five or six different foam objects. The objects were of various shapes that required different manipulations to be used, increasing the dexterity of the task. Again, participants were asked to move as many objects as they could into the basket within a maximum of 60 seconds. 246 participants completed this task.</p>
                <p>Almost everyone was able to use the device straightaway. 98% of participants were able to successfully manipulate objects using the Third Thumb during the first minute of use, with only 13 participants unable to perform the task.</p>
                <p>Ability levels between participants were varied, but there were no differences in performance between genders, nor did handedness change performance – despite the Thumb always being worn on the right hand. There was no definitive evidence that people who might be considered ‘good with their hands’ – for example, they were learning to play a musical instrument, or their jobs involved manual dexterity – were any better at the tasks.</p>
                <p>Older and younger adults had a similar level of ability when using the new technology, though further investigation just within the older adults age bracket revealed a decline in performance with increasing age. The researchers say this effect could be due to the general degradation in sensorimotor and cognitive abilities that are associated with ageing and may also reflect a generational relationship to technology.</p>
                <p>Performance was generally poorer among younger children. Six out of the 13 participants that could not complete the task were below the age of 10 years old, and of those that did complete the task, the youngest children tended to perform worse compared to older children. But even older children (aged 12-16 years) struggled more than young adults.</p>
                <figure data-lazyload-container="true" data-lazyload-trigger="true">
                  
                  <figcaption>
                    
                    
                  </figcaption>
                </figure>
                <p><strong>Dani Clode </strong>said: "<span>Augmentation is about designing a new relationship with technology—creating something that extends beyond being merely a tool to becoming an extension of the body itself.</span></p>
                <p><span>"Given the diversity of bodies, it's crucial that the design stage of wearable technology is as inclusive as possible. It's equally important that these devices are accessible and functional for a wide range of users. Additionally, they should be easy for people to learn and use quickly."</span></p>
                <p>Co-author <strong>Lucy Dowdall</strong>, also from the MRC Cognition and Brain Science Unit, added: "If motor augmentation – and even broader human-machine interactions – are to be successful, they’ll need to integrate seamlessly with the user’s motor and cognitive abilities.</p>
                <p>"We’ll need to factor in different ages, genders, weight, lifestyles, disabilities – as well as people’s cultural, financial backgrounds, and even likes or dislikes of technology. Physical testing of large and diverse groups of individuals is essential to achieve this goal."</p>
              </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Python notebooks for fundamentals of music processing (152 pts)]]></title>
            <link>https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html</link>
            <guid>40550830</guid>
            <pubDate>Sun, 02 Jun 2024 02:20:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html">https://www.audiolabs-erlangen.de/resources/MIR/FMP/C0/C0.html</a>, See on <a href="https://news.ycombinator.com/item?id=40550830">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Information on Current Status:</h2><p>

We work continuously on the FMP notebooks and provide updates on a regular basis (current version: 1.2.6). With the static HTML version of the FMP notebooks you can browse through the content right away. To run the Python code, please go to <a href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B_GetStarted.html">Get Started</a> for instructions. For comments, please email me (<a href="https://www.audiolabs-erlangen.de/fau/professor/mueller">Meinard Müller</a>). I am grateful for feedback and suggestions.
<br>
</p></div><div>
<h2 id="About">About<a href="#About">¶</a></h2><p>The FMP notebooks are a collection of educational material for teaching and learning  <a href="http://www.music-processing.de/">Fundamentals of Music Processing (FMP)</a> with a particular focus on the audio domain. Covering well-established topics in <a href="https://www.ismir.net/">Music Information Retrieval (MIR)</a> as motivating application scenarios, the FMP notebooks provide detailed textbook-like explanations of central techniques and algorithms in combination with Python code examples that illustrate how to implement the theory. All components including the introductions of MIR scenarios, illustrations, sound examples, technical concepts, mathematical details, and code examples are integrated into a consistent and comprehensive framework based on <a href="http://jupyter.org/">Jupyter notebooks</a>. The FMP notebooks are suited for studying the theory and practice, for generating educational material for lectures, as well as for providing baseline implementations for many MIR tasks, thus addressing students, teachers, and researchers.</p>
<p><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/C0/FMP_copyright_border.png" width="150" alt="CC"></a></p>
<p>The text and figures of these notebooks are licensed under a <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
Attribution-NonCommercial-ShareAlike 4.0 International License</a> (see the file <a href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/LICENSE"><code>LICENSE</code></a>).
The Python package <code>libfmp</code> (i.e., the content of the directory <code>libfmp</code>) is licensed under the <a href="https://opensource.org/licenses/MIT">MIT license</a> (see file <a href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/libfmp_LICENSE"><code>libfmp_LICENSE</code></a>) and is available at <a href="https://github.com/meinardmueller/libfmp">GitHub</a>. As for the audio material, the respective original licenses apply. This site contains material (text passages, figures) from the book <a href="http://www.music-processing.de/">Fundamentals of Music Processing</a>. If you use code or material from this site, please give reference to this book (e.g.  Figure 1.1 from <a href="http://www.music-processing.de/">[Müller, FMP, Springer 2021]</a>). If you publish results obtained or using these Python notebooks, please consider the following references:</p>
<p><a href="https://www.springer.com/gp/book/9783030698072"><img src="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/Cover_Mueller_FMP_Springer2021.jpg" alt="FMP_Cover" width="100"></a>
</p><ul>
<li><span>
Meinard Müller: <strong>Fundamentals of Music Processing – Using Python and Jupyter Notebooks.</strong> 2nd edition, Springer Verlag, 2021.
<br>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/bibtex/FMP_bibtex_Mueller21_FMP_SPRINGER.txt"> Bibtex </a>
<a type="button" target="_blank" href="https://www.springer.com/gp/book/9783030698072"> Link </a>
</span></li>
<li><span>
Meinard Müller and Frank Zalkow: <strong>FMP Notebooks: Educational Material for Teaching and Learning Fundamentals of Music Processing.</strong> Proceedings of the International Conference on Music Information Retrieval (ISMIR), Delft, The Netherlands, 2019.
<br>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/bibtex/FMP_bibtex_MuellerZ19_FMP_ISMIR.txt"> Bibtex </a>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/C0/2019_MuellerZalkow_FMP_ISMIR.pdf"> PDF </a>
</span></li>
<li><span>
Meinard Müller and Frank Zalkow: <strong>libfmp: A Python Package for Fundamentals of Music
Processing.</strong> The Journal of Open Source Software (JOSS), 6(63), 2021.
<br>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/bibtex/FMP_bibtex_MuellerZ21_libfmp_JOSS.txt"> Bibtex </a>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/C0/2021_MuellerZalkow_libfmp_JOSS.pdf"> PDF </a>
<a type="button" target="_blank" href="https://github.com/meinardmueller/libfmp"> GitHub </a>
</span></li>
<li><span>
Meinard Müller: <strong>An Educational Guide Through the FMP Notebooks for Teaching and Learning Fundamentals of Music Processing.</strong> Signals, 2(2):245-285, 2021.
<br>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/bibtex/FMP_bibtex_Mueller21_FMP_Signals.txt"> Bibtex </a>
<a type="button" target="_blank" href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/data/C0/2021_Mueller_FMP_Signals.pdf"> PDF </a>
</span></li>
</ul><p>The FMP notebooks are maintained by <a href="https://www.audiolabs-erlangen.de/fau/professor/mueller">Meinard Müller</a>. For comments, please email <a href="mailto:meinard.mueller@audiolabs-erlangen.de">meinard.mueller@audiolabs-erlangen.de</a>. I am grateful for feedback and suggestions.</p>

</div><div>
<h2 id="Get-Started">Get Started<a href="#Get-Started">¶</a></h2><p>If a static view of the FMP notebooks is enough for you, the exported HTML versions can be used right away without any installation. All material including the explanations, the figures, and the audio examples can be accessed by just following the <strong>HTML links</strong>. If you want to <strong>execute</strong> the Python code cells, you have to download the notebooks (along with the data), create an environment, and start a Jupyter server. You then need to follow the <strong>IPYNB links</strong> within the Jupyter session. The necessary steps are explained in detail in the <a href="https://www.audiolabs-erlangen.de/resources/MIR/FMP/B/B_GetStarted.html">FMP notebook on how to get started</a>.</p>

</div><div>
<h2 id="Acknowledgment">Acknowledgment<a href="#Acknowledgment">¶</a></h2><p>
The notebooks are based on results, material, and insights that have been obtained in close collaboration with different people. I would like to express my gratitude to my former and current students, collaborators, and colleagues who have influenced and supported me in creating these notebooks. Also, various people have contributed to the code examples of the notebooks; credits are given in the notebooks' acknowledgement sections. Here, I will confine myself to only mentioning the names of the main contributors in alphabetical order:

</p><ul>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/arifi-mueller">Vlora Arifi-Müller</a></li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/balke">Stefan Balke</a></li>
<li><a href="http://mta.mit.edu/person/eran-egozy">Eran Egozy</a></li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/krause">Michael Krause</a></li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/lopez">Patricio López-Serrano</a></li>
<li><a href="https://bmcfee.github.io/">Brian McFee</a></li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/rosenzweig">Sebastian Rosenzweig</a></li>
<li><a href="https://www.stevetjoa.com/">Steve Tjoa</a></li>
<li>Angel Villar-Corrales</li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/weiss">Christof Weiß</a></li>
<li><a href="https://www.audiolabs-erlangen.de/fau/assistant/zalkow">Frank Zalkow</a></li>
<li>Tim Zunner</li>
</ul>
<p>
Furthermore, some of the code examples have been inspired or are based on code provided by other code collections. In particular, I want to mention the following excellent sources:
</p><ul>
<li> The python package <a href="https://librosa.org/">LibROSA</a> maintained by <a href="https://bmcfee.github.io/">Brian McFee</a> provides many building blocks to create music information retrieval systems. It also contains a <a href="https://librosa.org/librosa_gallery/">gallery</a> of more advanced examples.
</li>
<li>
The website <a href="https://musicinformationretrieval.com/">Notes on Music Information Retrieval</a> maintained by <a href="https://www.stevetjoa.com/">Steve Tjoa</a> is a collection of instructional material for MIR.
</li>
<li> The course <a href="http://musictech.mit.edu/fmp">Fundamentals of Music Processing</a> by <a href="http://mta.mit.edu/person/eran-egozy">Eran Egozy</a> comprises many Python code examples.
</li>
</ul><!--

## References

<br />

<div>
<a href="http://www.springer.com/gp/book/9783319219448"><img src="../data/FMP_Cover.png" alt="FMP_Cover" width="80"  style="float:right;"></a>
</div>

<div style="float:left;">
<a href="https://www.audiolabs-erlangen.de/fau/professor/mueller">Meinard Müller</a> <br />
Fundamentals of Music Processing &ndash; Audio, Analysis, Algorithms, Applications  <br />
ISBN: 978-3-319-21944-8<br />
483 p., <a href="http://www.springer.com/gp/book/9783319219448">Springer</a>, 2015  <br />
<a href="http://www.music-processing.de">www.music-processing.de</a>    <br />
<a href="https://www.audiolabs-erlangen.de/fau/professor/mueller/bookFMP">Accompanying Website</a>
</div>
-->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[84–24 (132 pts)]]></title>
            <link>https://84-24.org/</link>
            <guid>40550556</guid>
            <pubDate>Sun, 02 Jun 2024 01:09:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://84-24.org/">https://84-24.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40550556">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="hero"><h2>How much memory do you need today?</h2><p>The tale of restoring an ’80s timeless classic, harking back<br>to an era when <strong>128KB</strong> were deemed more than sufficient.</p><nav>Disponibile anche in <a href="https://84-24.org/it">Italiano</a>.</nav><p><a data-slow="2" href="#introduction"><i></i>Click to start</a> <small>or simply scroll down.</small></p></div><div id="introduction"><h3>Midlife crisis</h3><p>I understand that you may be feeling a bit perplexed at this point, so let me begin anew, or at least with the medical condition I’ve self-diagnosed to rationalize everything: the <strong>midlife crisis</strong>.</p><p>I acknowledge that, at “only” <strong>36 years old</strong>, with the advancements in scientific progress extending the average life expectancy well beyond 70 years, It may seem premature to begin contemplating about it. However, I contend that the <i>relentless pace of our lives</i> has accelerated this moment of reflection, prompting us to nostalgically revisit past moments and rediscover the allure of <strong>childhood possessions</strong> — whether acquired, lost, or long-dreamt of.</p><p>In my case, I can affirm that I was enticed by the notion of an improbable mission: the restoration and repair of an <strong>iconic computer from the past</strong>, armed with no specific technical expertise other than a robust and innate passion for computers. The chosen endeavor revolved around a genuine instant classic in the realms of computer science and industrial design: the original <mark>Macintosh</mark>.</p><h4>The Macintosh</h4><p>Originally overseen by <strong>Jeff Raskin</strong>, the “Macintosh” project was envisioned as Apple’s inaugural computer, specifically targeted at <strong>families</strong> and marketed with a price tag <strong>below $1,000</strong> <sup>01</sup>.</p><p>However, the trajectory took an unexpected turn in 1980 when Apple, citing <strong>Steve Jobs</strong>’ <strong>intense perfectionism</strong> and limited team-building skills, decided to reassign him from the helm of the flagship “Lisa” project.</p><blockquote>Apple’s strategy was to shift Jobs to a project of lesser prominence like the Macintosh, one deemed less pivotal to the company’s future, where his disposition could be more constrained.</blockquote><p>Jobs found himself transitioning from the design of a <strong>groundbreaking computer</strong> like the Lisa, Apple’s first professional workstation featuring an operating system with an iconographic interface and mouse-operable windows — to the Macintosh, a more <strong>traditional, budget-friendly computer</strong> with a text-based operating system, targeting families.</p><h4>Jobs’s leadership</h4><p>Under Jobs’s leadership, his initial response was to distance Raskin and <strong>decisively reshape the project</strong>. While the Macintosh was intended to be an economically accessible computer, Jobs believed it couldn’t be solely from a financial perspective.</p><p>Recognizing the need to cater to individuals unfamiliar with computers, the Macintosh couldn’t compromise on the user-friendly experience offered by a <strong>graphical interface and a mouse</strong>. Jobs envisioned the computer being prominently displayed in homes, akin to any other household appliance, and insisted on a design that was nothing short of “<mark>insanely great</mark>”.</p><p>This new trajectory, coupled with an exceptional marketing campaign, propelled the project into <strong>unprecedented levels of hype</strong> <sup>01</sup>. However, it also led to a substantial increase in the costs associated with design, production, and promotion.</p><div><ul><li><figure><span> <video width="1080" height="1080" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/01_01.bfcf8e8b.mp4" type="video/mp4"></video> </span><figcaption><strong>Apple “1984” Super Bowl Commercial directed by Ridley Scott</strong> © All original content Copyright &amp; TM Retro Recipes™ LLC 1988-present. <i>Via YouTube <a target="_blank" href="https://www.youtube.com/watch?v=ErwS24cBZPc">Retro Recipes</a></i></figcaption></figure></li><li><figure><span> <video width="1080" height="1080" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/01_02.60317902.mp4" type="video/mp4"></video> </span><figcaption><strong>Steve Jobs introduces the Macintosh</strong> © All original content copyright and Computer History Museum. <i>Via YouTube <a target="_blank" href="https://www.youtube.com/watch?v=1tQ5XwvjPmA">Computer History Museum</a></i></figcaption></figure></li><li></li></ul></div><p>The Macintosh made its debut on <strong>January 24, 1984</strong> <sup>02</sup>, hitting American shelves with a price tag of <strong>$2,495</strong>.</p><p>Despite its competitive pricing, especially when considering the initial positioning of the Lisa at $9,995 and the incorporation of numerous new technologies and features inherited from it, the Macintosh still entailed <strong>hardware compromises</strong>. Its placement in that price range proved challenging for the average American family.</p><p>While the goal of bringing the concept of a graphical interface and mouse to a broad user base was partially achieved, thanks to widespread promotion and adoption of the Macintosh in <strong>educational</strong> (schools, universities) and professional environments (constituting 90% of total sales), it fell short of reaching the intended consumer market <sup>02</sup> <sup>03</sup>.</p><p>The Macintosh became a <strong>topic of conversation</strong> for everyone, but it was <strong>not yet accessible</strong> to everyone, and sales never fully met expectations. Jobs bore the brunt of this setback, to the extent that he was ousted from the company he co-founded before the year’s end.</p><ol><li><a href="https://en.wikipedia.org/wiki/Steve_Jobs_(book)" target="blank">Steve Jobs (Book)</a> - Walter Isaacson (2011)</li><li><a target="blank" href="https://www.lebow.drexel.edu/news/when-mac-came-market-street">When the Mac Came to Market Street</a> - LeBow College of Business Drexel University (2014)</li><li><a target="blank" href="https://www.nytimes.com/1984/12/10/nyregion/computer-makers-find-rich-market-in-schools.html">Computer makers find rich market in schools</a> - New York Times (1984)</li></ol></div><div id="right"><h3>Let the search begin</h3><p>Okay, let’s begin with the obvious. The original Macintosh (128K <sup>04</sup>) hasn’t been available for over three decades. Obtaining one now requires finding someone willing to part with it <del>or, as my wife puts it, “<strong>to get rid of it</strong>”</del>.</p><p>While I’m sure there are numerous sales channels and opportunities in the United States, in Italy, aside from a stroke of luck at a vintage electronics market, the primary option is <mark>eBay</mark>.</p><h4>Key considerations</h4><p>I must concede that I may have overstated in the introduction: even at the time, 128KB of RAM wasn’t quite sufficient, a realization users came to fairly quickly <sup>05</sup>.</p><p>A few months later, Apple took evasive action by <strong>quadrupling the RAM</strong> with the 512K model. Many early adopters opted to upgrade, undergoing a <strong>complete motherboard replacement</strong> as the RAM was soldered onto the PCB. This approach proved more cost-effective than the alternative, which involved bearing the expense of RAM in addition to specialized labor for individually replacing all (16) chips.</p><p>Despite being a mass-produced industrial product on a global scale, with hundreds of thousands in circulation, the <strong>rush to upgrade</strong> (justifiable at the time) and the subsequent need for maintenance or component replacement over the years have rendered intact units a rarity.</p><h4>The market</h4><p>Machines that remain entirely original and operational are currently being sold at prices ranging <strong>from $2,000 to $4,000</strong> <sup>06</sup>. This extensive range is frequently attributed to the aesthetic state of different components, the production week indicated by the serial number, and the inclusion of accessories and accompanying software.</p><p>Fortunately, <strong>the value experiences a sharp decline</strong> when, under similar conditions and equipment, the computer is marketed as non-functional, often due to a <strong>problem</strong> identified to varying degrees by the seller.</p><h4>The right problem</h4><p>The notion of acquiring one for restoration, akin to reviving an old vintage car that no longer runs, <strong>intrigued me</strong>. The immediate allure of substantial cost savings persuaded me to delve deeper (unaware that I would eventually spend the equivalent of obtaining a fully operational unit in the ensuing months). My requirements were:</p><ul><li>A Macintosh with a <strong>commonly documented issue</strong>.<ul><li>A problem complex enough to require attention but not beyond my capabilities.</li><li>An issue seemingly confined and identifiable through a photograph or an error code.</li></ul></li><li>A Macintosh complete with <strong>essential accessories</strong>: keyboard, mouse, power cable, and boot floppy.</li><li>An <strong>aesthetically pleasing Macintosh</strong>, serving as a <del>paperweight</del> decorative item if repair proved unsuccessful.</li></ul><p>After months of research and numerous rejected purchase proposals, I found the ideal synthesis of these requirements in an eBay auction by a vintage electronics store in <strong>Tucson, Arizona</strong>.</p><p>Adding to the myriad variables inherent in acquiring a non-functioning item from almost four decades ago was the challenge of an <strong>intercontinental journey</strong>. Despite the uncertainties, I decided to take the leap: a deep breath, closed eyes, and a click on the “<mark>Buy it now</mark>” button <sup>03</sup>.</p><blockquote>Over the ensuing three weeks, I cycled through various emotions, from pure excitement to regret and occasional despair.</blockquote><p>Then, it arrived. Finally, the courier at the door. Unboxing time. Yes! That’s it! What a beauty! <sup>05-06</sup>.</p><p>Admittedly, it’s a bit dirty with signs of weathering, but try spending three decades in an attic, crossing a continent, and presenting yourself like this for a <strong>first date</strong>.</p><ol><li><a target="blank" href="https://lowendmac.com/1984/macintosh-128k/">Macintosh 128K</a> - lowendmac.com</li><li><a target="blank" href="https://web.archive.org/web/20150726175452/http://www.mac-history.net/top/2011-01-24/the-history-of-the-apple-macintosh">The history of the Apple Macintosh</a> - mac-history.net</li><li>eBay auction closing period from July to December 2022 for a functional Macintosh 128K.</li></ol></div><div id="boot"><p><h3>First boot</h3></p></div><div id="boot-2"><p><h3>Sad Mac</h3></p></div><div id="sadmac"><h3>We have a problem.</h3><p>Okay, the initial attempt to boot didn’t go as planned, but I shouldn’t have expected anything different.</p><p>After swiftly unpacking, connecting a voltage reducer to the socket, and powering up the computer <sup>07</sup>, I hear a familiar [beep], as anticipated from all the repair videos on YouTube that I’ve watched to prepare myself.</p><h4>The Devil’s Interval</h4><p>This is the renowned Apple <strong>boot sound</strong>, still present in the current lineup across all Mac products. However, the complete and reassuring sound we hear in today’s Macs is the result of subsequent work <sup>07</sup> initiated in 1988 by <a target="_blank" href="https://reekes.net/">Jim Reekes</a>, a sound engineer.</p><p>In 1984, hardware limitations prevented achieving such sophisticated sounds. Consequently, it had to be simplified into something much more basic: a three-note chord with sounds that were far from soothing, historically known even in the 1800s as the “<strong>devil’s interval</strong>” <sup>07</sup>.</p><div><ul><li><figure><span> <video width="1080" height="1080" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/03_01.04f4ecfe.mp4" type="video/mp4"></video> </span><figcaption><strong>First tests</strong> Failed boot attempt and Sad Mac.</figcaption></figure></li><li><figure><span> <img loading="lazy" src="https://84-24.org/03_02.80449c91.jpg" alt=""> </span><figcaption><strong>Motherboard detail</strong> Location of RAM chips inside the motherboard.</figcaption></figure></li><li></li></ul></div><h4>Sad Mac</h4><p>Displayed on the screen is the <mark>Sad Mac</mark>, one of the legendary icons from the original set designed by <a href="https://kareprints.com/" target="_blank">Susan Kare</a> specifically for the first Macintosh. While it stands as a genuine pixel art manifesto <sup>08</sup>, unfortunately, in my case, this icon identifies an <strong>error</strong>, and a <strong>big one</strong> at that.</p><p>During this boot phase, the computer conducts tests on various components, and the memory is filled with data for a subsequent consistency check. The failure of this test indicates a hardware malfunction, identified by a specific <strong>error code</strong> displayed immediately below the Sad Mac icon.</p><p>The code I won is <code>04040A</code>.</p><p>In the 80s and 90s, detailed information to decipher these error codes wasn’t extensively provided even in the <strong>technical service manuals</strong> for installers and repairers <sup>09</sup>. For Sad Mac, the suggested generic process often involved replacing the entire logic board.</p><p>Fortunately, with the advent of the Internet, Apple has digitized and publicly shared <a target="_blank" href="https://web.archive.org/web/20211224234010/https://support.apple.com/kb/TA46376?locale=en_US">more detailed indications</a>, allowing users to interpret the code comprehensively and pinpoint the problem to more specific components.</p><blockquote>The table at this link serves as my Rosetta Stone for decoding the error.</blockquote><h4>It’s a memory trap!</h4><p>Finally, the code is “clear”. The first two characters (04) represent the type of failed test, “<mark>Memory Mod3 test</mark>”, while each of the next four characters (040A) identifies the status of a set composed of four memory chips, totaling 16 chips.</p><p>The specific damaged chips within a set are identified by a number (1, 2, 4, or 8), corresponding to a <strong>pair of coordinates</strong> with a letter (F or G) and a number (from 5 to 12), determining their precise location on the motherboard <sup>08</sup>.</p><table><tbody><tr><th><span>0</span></th><th><span>4</span></th><th><span>0</span></th><th><span>A</span></th></tr><tr><td><span>1</span><code>G9</code></td><td><span>1</span><code>G5</code></td><td><span>1</span><code>F9</code></td><td><span>1</span><code>F5</code></td></tr><tr><td><span>2</span><code>G10</code></td><td><span>2</span><code>G6</code></td><td><span>2</span><code>F10</code></td><td><span>2</span><code>F6</code></td></tr><tr><td><span>4</span><code>G11</code></td><td><span>4</span><code>G7</code></td><td><span>4</span><code>F11</code></td><td><span>4</span><code>F7</code></td></tr><tr><td><span>8</span><code>G12</code></td><td><span>8</span><code>G8</code></td><td><span>8</span><code>F12</code></td><td><span>8</span><code>F8</code></td></tr></tbody></table><p>If you’ve stuck with me this far, under the assumption that each character can only have a value of 1, 2, 4, or 8, the question you’ve likely pondered is: why <del>the hell</del> is there an A in my error code?</p><p>The answer came to light through the experience of <a target="_blank" href="https://68kmla.org/bb/index.php?threads/mac-128k-unlisted-error-code.37876/post-410052">a user on the 68kmla.org forum</a>, who, like me, encountered an error code with an unexpected character. Each character identifies the faulty chip within a set of 4 chips. However, when more than one defective chip exists in the same set, the character corresponds to the <strong>sum of each in hexadecimal format</strong>.</p><p>The <code>A</code> (10 in decimal format) in the last character of my error code, therefore, represents the sum of the <code>2</code> + <code>8</code> chips, corresponding to positions <code>F6</code> and <code>F8</code> inside the motherboard.</p><ol><li><a target="blank" href="https://www.wired.com/2014/10/apple-mac-startup-sound/">Hear the Evolution of Apple’s Iconic Startup Sound for the Mac</a> - Wired (2014)</li><li><a target="_blank" href="https://www.newyorker.com/culture/cultural-comment/the-woman-who-gave-the-macintosh-a-smile"> The Woman Who Gave the Macintosh a Smile</a> - The New Yorker (2018)</li><li><a target="blank" href="https://vintageapple.org/macbooks/pdf/Service_Guide_Macintosh_Computers_March_1991.pdf">Apple Service Guide for Macintosh Computers</a> - Apple <sup>(1991)</sup></li></ol></div><div id="ram"><h3>We can do it</h3><p>We have successfully identified the three malfunctioning memory chips and their locations on the motherboard. These are the <strong>MT4264</strong> <sup>10</sup>, a <strong>64Kbit</strong> DRAM chip manufactured by <i>Micron Technology</i>, which was practically a standard in computers of that era, albeit under various names and codes depending on the manufacturer <sup>11</sup>.</p><p>This integrated circuit, no longer in production for many years, is now only obtainable through private sellers offering used parts or from suppliers specializing in <strong>vintage components</strong>.</p><p>Despite numerous eBay auctions being geographically closer, I chose to rely on <strong>Jameco</strong> <sup>12</sup>, a well-known Californian retailer. This decision was influenced by recommendations from specialized forums during my preliminary research <sup>11</sup>.</p><h4>Let’s open it!</h4><p>Okay, I understand that the disassembly process might look straightforward and quick on this animation, but the reality involves dealing with screws, cables, dust, and cathode ray tubes that can hold <strong>extremely high electrical voltages</strong> (up to 10kV), even several minutes after being powered off <sup>13</sup>.</p><p>As the first computer created with non-professional users in mind, the Macintosh 128K was deliberately designed to <mark>discourage self-repair</mark>, thereby making even the simple act of opening its casing a significant challenge.</p><p>For its exterior, <strong>Torx T15</strong> security screws, which were quite rare at that time, were used. These screws were deeply set near the upper “handle”, necessitating the use of an extendable or sufficiently long screwdriver for access <sup>14</sup>.</p><blockquote>Unlike any other computer of its era, the Macintosh was deliberately “armored”.</blockquote><p>However, as of 2024, the situation has greatly simplified. All necessary tools are readily available in <strong>hardware stores</strong>. With <strong>basic manual skills</strong>, removing the motherboard and its damaged chips is straightforward, especially with detailed guides like the <a target="_blank" href="https://www.ifixit.com/Teardown/Macintosh+128K+Teardown/21422">iFixit detailed teardown</a> available.</p><h4>Open heart surgery</h4><p>At this juncture, I’d love to claim that I channeled my inner <strong>MacGyver</strong> and replaced the damaged chips on the board using nothing more than a banana and <a target="_blank" href="https://www.youtube.com/watch?v=09UlB17cgKw">a paperclip</a>. However, my modest soldering skills dissuaded me from attempting repairs on a board that is not only older than myself but also holds great sentimental value.</p><p>Yes, I cheated. My family includes several individuals far more adept with hardware than I am, and I couldn’t pass up the opportunity to <strong>entrust the task</strong> to my cousin, <a target="_blank" href="https://www.linkedin.com/in/luca-giorgi-hts-srls-19971434/">Luca Giorgi</a>. Luca is a professional electronic designer and has always been accommodating of my caprices.</p><p>With patience and precision, Luca desoldered each pin, using a <strong>tin suction pump</strong> to carefully remove the solder, thereby liberating each damaged chip from its position <sup>09</sup>. Following the thorough cleaning of the area <sup>10</sup>, he skillfully resoldered the <strong>16-pin sockets</strong> onto the board and installed the newly acquired chips <sup>12</sup>.</p><p>Now, the moment of truth: crossing our fingers and attempting to <mark>power it on once more</mark>.</p><p>The boot sound remains that familiar, uncomforting tone, but this time, the monitor shows signs of life. Contrary to the previous “Sad Mac” screen of darkness, we are greeted with a lit screen, revealing the full luminosity of the monitor for the first time.</p><p>The central icon confirms a successful start-up, indicating that the system is <strong>awaiting a floppy disk</strong> to proceed. We might not be fully prepared for this stage yet, but the most crucial problem has been resolved. The only word that comes to mind is “bellissimo” ~ “beautiful” <sup>13</sup>.</p><ol><li><a target="_blank" href="https://tvsat.com.pl/PDF/M/MT4264.pdf">Micron MT4264 Technical sheet</a> - Micron Technology - tvsat.com.pl (1991)</li><li><a target="blank" href="https://minuszerodegrees.net/memory/4164.htm">Examples of 4164 class RAM chips</a> - minuszerodegrees.net</li><li><a target="_blank" href="https://www.jameco.com/z/4164-150-Major-Brands-IC-4164-150-DRAM-65-536-Bit-65-536x1-150ns-with-Page-Mode-DIP-16_41662.html">Jameco IC 4164 product page</a> - jameco.com</li><li><a target="_blank" href="https://lowendmac.com/2007/the-truth-about-crts-and-shock-danger/">The Truth About CRTs and Shock Danger</a> - Daniel Knight - lowendmac.com (2007)</li><li><a target="_blank" href="https://www.ifixit.com/Teardown/Macintosh+128K+Teardown/21422">Macintosh 128K Teardown</a> - iFixit (2014)</li></ol></div><div id="floppy"><h3>Hard disk?<br>Which hard disk?</h3><p>I’m sure that when asked, “How much memory do you need today?” you might immediately think of the capacity of your <strong>hard drive</strong>, SSD, or your general permanent storage device.</p><p>Here’s an interesting fact: Apart from a small ROM for basic software, the Macintosh 128K has <mark>no permanent storage</mark>. Beyond its 128KB of RAM, there’s no additional internal memory capable of preserving data through a computer restart.</p><p>This makes the floppy drive <strong>exceedingly important</strong>, as it’s essentially the only means not only for saving your work but also for simply <strong>loading the operating system</strong> to start a Macintosh.</p><h4>Floppy drive</h4><p>The <strong>3.5-inch floppy drive</strong> featured in the Macintosh 128K was groundbreaking at the time. Apple was one of the pioneers in adopting this new format, which would later become the <strong>standard across the whole computer industry</strong>.</p><div><ul><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_01.b0536436.mp4" type="video/mp4"></video> </span><figcaption><strong>Sony OA-D34V</strong> Floppy drive installed on every 128K Macintosh.</figcaption></figure></li><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_02.5cc50e54.mp4" type="video/mp4"></video> </span><figcaption><strong>Drive maintenance</strong> Removal and cleaning of solidified lubrication grease.</figcaption></figure></li><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_08.8f7e6bd5.mp4" type="video/mp4"></video> </span><figcaption><strong>Drive maintenance</strong> Relubrication of mechanical components with new grease.</figcaption></figure></li><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_03.fb751348.mp4" type="video/mp4"></video> </span><figcaption><strong>DIY Testing</strong> Manual disc ejection test.</figcaption></figure></li><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_04.fcf4023a.mp4" type="video/mp4"></video> </span><figcaption><strong>Hallelujah (spoiler)</strong> First successful boot of the operating system.</figcaption></figure></li><li><figure><span> <video width="595" height="335" preload="none" muted="" loop="" playsinline=""><source src="https://84-24.org/05_05.98380525.mp4" type="video/mp4"></video> </span><figcaption><strong>Eject disk</strong> Disk ejection successful!</figcaption></figure></li><li></li></ul></div><p>The compact size and sturdy casing of the floppy disk not only protected its integrity and surface from accidental damage but also transformed it into an aesthetically pleasing object and a “<strong>perfect example of good design</strong>” <sup>15</sup>.</p><p>However, this initial version had its limitations. While the new standard by Sony already allowed for double-sided floppies with a formatted capacity of 720KB, the drive could only read and write on one side, effectively <strong>reducing its total capacity by half</strong>. Additionally, Apple introduced a unique hardware formatting standard that enabled saving up to 400KB on a single side, but this format was <strong>incompatible with any other systems</strong> <sup>16</sup>.</p><h4>Maintenance</h4><p>Amidst the sea of uncertainties that come with restoring a retro computer, there’s one thing you can count on: <strong>your floppy drive will require maintenance</strong>.</p><p>Distinct from the purely electronic components inside the machine, the drive is primarily made up of <mark>mechanical parts</mark> that are responsible for sliding, housing, and ejecting the disk. These elements require <strong>proper lubrication</strong> to function correctly, and there is nothing worse than a lubricating grease left to dry in an attic for 40 years, as it can completely obstruct their functionality.</p><blockquote>My Macintosh was no exception. The first floppy disk I attempted to insert struggled to even pass the entry threshold.</blockquote><h4>Let’s get our hands dirty</h4><p>Once the Macintosh casing is opened, the disassembly of the floppy drive is <strong>almost immediate</strong>: just unscrewing a couple of screws releases the unit from its lower support, which also houses the motherboard.</p><p>As expected, what is in front of us is a drive whose side guides are completely jammed by the now <strong>solidified 1984 lubricating grease</strong>. Despite the daunting appearance, restoring the mobility of all mechanical components was straightforward:</p><ul><li>Cleaning each joint of the solidified lubricating grease with a cotton swab dipped in alcohol <sup>15</sup></li><li>Reapplying fresh lubricating grease <sup>16</sup></li><li>Manually testing the mechanical sliding movement <sup>17</sup></li></ul><p>Simple, right? Especially when you have access to a step-by-step <a target="_blank" href="https://www.youtube.com/watch?v=Se10T6gPl-c">video guide</a> like the one <strong>JDW</strong> created on their YouTube channel.</p><p>Now, all that’s left is to reassemble the computer, insert the boot floppy <sup>18</sup>, and once again, <strong>cross our fingers</strong>...</p><ol><li><a target="_blank" href="https://en.wikipedia.org/wiki/The_Design_of_Everyday_Things">The Design of Everyday Things</a> - Donald Norman (1988)</li><li><a target="_blank" href="https://en.wikipedia.org/wiki/Macintosh_External_Disk_Drive">Macintosh External Disk Drive</a> - Wikipedia</li><li><a target="_blank" href="https://retroviator.com/apple-macintosh-128k/">Apple Macintosh (128K)</a> - Retroviator (2021)</li></ol></div><div id="reassembly"><p><h3>Reassembly</h3></p></div><div id="power-on"><p><h3>Power on</h3></p></div><div id="boot-success"><p><h3>Hallelujah</h3></p></div><div id="cosmetics"><h3>Not old. Vintage.</h3><p>I must admit, this chapter was not originally part of my plan. For a while, I had considered my restoration project complete:</p><ul><li>All the damaged components were <strong>repaired</strong>.</li><li>The computer was <strong>operational and usable</strong>.</li><li>I had found the <a target="_blank" href="https://www.ikea.com/it/it/p/bekant-elemento-contenitore-con-rotelle-rete-bianco-s59282535/"><strong>ideal furniture</strong></a> at Ikea to showcase and use the Macintosh, occupying minimal space in the house <del>and thereby avoiding being kicked out by my wife</del>.</li><li>Additionally, I had just discovered the <a target="_blank" href="https://shop.bigmessowires.com/products/floppy-emu-model-c-bundle"><strong>Floppy Emu</strong></a>, a <strong>floppy emulator</strong> that would enable me to explore all the software ever created for the Macintosh 128K without further financial strain.</li></ul><p>So, what more could I have asked for? Yes, it’s true, the casing was still somewhat <strong>dirty and had yellowed</strong> over time, but wasn’t this a perfect reflection of its history and the character of this iconic machine?</p><p>For a while, I convinced myself of this <mark>romanticized view</mark> and thought it unnecessary to risk reopening and completely disassembling a Macintosh that had just begun working again, merely for cosmetic reasons. That was until my timeline started to be filled with articles and videos about <strong>retrobright</strong>, and a new doubt started to <a target="_blank" href="https://www.youtube.com/watch?v=ksjTWm9XaII">take root in my mind</a>.</p><h4>Retrobright</h4><p>This mixture was developed by <strong>Dave Stevenson</strong>, an English chemist with a passion for retrocomputers <sup>18</sup>. Its purpose is to restore the original color of ABS plastics <sup>19</sup>, a material extensively used in the casings of various electronic devices over the past 50 years.</p><p>Stevenson hypothesized that the yellowing was not due to the ABS itself, but rather to <strong>bromine</strong>, an element added to ABS for its flame-retardant properties. When exposed to UV rays from the sun, bromine naturally tends to revert to its original brown color, thereby causing the entire plastic to yellow <sup>20</sup>.</p><p>The Retrobright formula was made public in 2008 and consists of a blend of <strong>high-concentration hydrogen peroxide</strong> (10%–15%), active oxygen, and thickeners to create a spreadable product.</p><blockquote>The outcome of this formula is a gel. When applied to plastics and exposed to UV rays, it is intended to return the oxygen molecule to the bromine, thereby it should reverse the yellowing process.</blockquote><p>I use the conditional tense because, since 2008, the community of enthusiasts has continuously experimented with and modified the compound, leading to the creation of <strong>numerous variations</strong> <sup>21</sup>. Over the years, there have been documented instances of failures and long-term effects on plastics. These findings have <strong>raised questions</strong> about both the role of bromine and UV rays in the yellowing process, as well as the effectiveness and safety of the mixture and method itself <sup>22</sup>.</p><p>I confess that despite the <strong>wealth of information available</strong> for research, my complete lack of knowledge in chemistry, combined with the overwhelming number of highly positive reviews, led me to <strong>overlook any potential risks</strong> or negative aspects. I <del>wanted</del> had to try!</p><h4>Everything under control</h4><p>For my experiment, I selected one of the <strong>brightest (and hottest) days of the year</strong>, considering the significance of UV rays in the process. Prior to starting, I removed any labels, logos, or tags that might get damaged <sup>20</sup>. Each piece of plastic was thoroughly washed to eliminate any dirt or dust residue from the surface <sup>21-22</sup>.</p><p>I prepared about a liter of Retrobright and gradually transferred it to a basin for application on each plastic piece <sup>23</sup>. To <strong>prevent the mixture</strong> from evaporating quickly under the sun, I followed several tutorial suggestions and covered each piece with a film <sup>24</sup>. In hindsight, this was <mark>the first of many mistakes</mark>.</p><p>After approximately 2 hours of exposure, I decided to check the results of this initial attempt, and that’s when I encountered my <strong>first major setback</strong>. Despite the film covering, the gel had almost entirely evaporated and had done so unevenly, following the creases of the film. <strong>The outcome was disheartening</strong>. The gel had only managed to lighten certain areas of the plastic, creating stains and streaks across all surfaces <sup>25-26</sup>.</p><h4>Panic</h4><p>Following that setback, I embarked on a <strong>series of hasty attempts</strong>, hoping that another application might even out the coloration. Initially, I repeated the process without the film, refreshing the mixture <strong>every 20 minutes</strong> throughout an entire morning to prevent evaporation. Subsequently, I replicated the procedure in an environment with <strong>controlled UV light</strong> <sup>27</sup>.</p><p>In both instances, I managed only to <strong>lighten the different areas proportionally</strong>. The darker parts became lighter, but so did the already light areas, which further intensified and essentially preserved the initial streaks.</p><hr data-text="Happy ending"><h4>Plan B</h4><p>It dawned on me that any further attempts would be futile, only serving to <strong>further degrade plastics</strong> already stressed by various treatments. This realization was followed by a few weeks of discouragement, during which I hesitantly returned to eBay to browse through auctions for exorbitantly priced spare parts. Eventually, I settled on the only viable option: <strong>painting the plastics</strong>.</p><p>Interestingly, <strong>Apple had abandoned the practice</strong> of painting plastics with the introduction of the Macintosh. They believed that using ABS plastic already colored appropriately would prevent the natural variation in paint color when exposed to sunlight. Ironically, the <strong>opposite occurred</strong>: all the painted plastics from earlier models withstood the test of time much better <sup>23</sup>.</p><p>This time, <del>thank God,</del> I decided it was best to directly consult professionals. My sole task was to find the correct color reference <sup>24</sup>. I entrusted the job to a local body shop specializing in <strong>plastic painting</strong>, and they executed the work with great precision and care <sup>28-29</sup>.</p><p>What can I say? The Macintosh had not only become “presentable” but had almost turned into a <mark>showpiece</mark> <sup>31</sup>, and I had finally run out of ways to potentially compromise its safety again.</p><p>The restoration could at last be considered complete. Just in time to celebrate the <strong>40th anniversary of the Mac</strong>!</p><ol><li><a href="http://retr0bright.com/" target="_blank">The “Retr0bright” Project</a> - retr0bright.com (2008)</li><li><a href="https://en.wikipedia.org/wiki/Acrylonitrile_butadiene_styrene" target="_blank">Acrylonitrile butadiene styrene</a> - Wikipedia</li><li><a href="https://www.vecchicomputer.com/retr0bright/" target="_blank">Retr0Bright: how to restore yellowed plastics</a> (IT) - Giacomo Vernoni</li><li><a href="https://www.youtube.com/watch?v=qZYbchvSUDY" target="_blank">New retrobrite techniques</a> - The 8-Bit Guy</li><li><a href="https://www.classic-computers.org.nz/blog/2013-01-15-retr0bright-only-temporary.htm" target="_blank">RetroBright treated plastics re-yellowing even with minimal light exposure?</a> - Terry Stewart’s (Tezza’s) Blog</li><li><a href="https://bzotto.medium.com/what-color-was-apple-beige-acd14bca0c1a" target="_blank">What color was “Apple Beige”?</a> - Ben Zotto</li><li><a href="https://68kmla.org/bb/index.php?threads/mac-128k-color.12107/" target="_blank">Mac 128k color</a> - 68kMLA Forum</li></ol></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CSS written in pure Go (101 pts)]]></title>
            <link>https://github.com/AccentDesign/gcss</link>
            <guid>40550218</guid>
            <pubDate>Sun, 02 Jun 2024 00:04:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/AccentDesign/gcss">https://github.com/AccentDesign/gcss</a>, See on <a href="https://news.ycombinator.com/item?id=40550218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a href="https://github.com/AccentDesign/gcss/actions/workflows/go-test.yml"><img src="https://github.com/AccentDesign/gcss/actions/workflows/go-test.yml/badge.svg" alt="Test"></a>
<a href="https://goreportcard.com/report/github.com/AccentDesign/gcss" rel="nofollow"><img src="https://camo.githubusercontent.com/fb19322a704b22c9e2fdded2aa8a8760c7b60b65f58739512ad4434465ba8d31/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f416363656e7444657369676e2f67637373" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/AccentDesign/gcss"></a>
<a href="https://pkg.go.dev/github.com/AccentDesign/gcss" rel="nofollow"><img src="https://camo.githubusercontent.com/401129d86773a0c772a69ce3855a9560ed75f9b4791709622d59fc5ace1eefd9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63756d656e746174696f6e2532306f6e2d706b672e676f2e6465762d626c75652e737667" data-canonical-src="https://img.shields.io/badge/Documentation%20on-pkg.go.dev-blue.svg"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/AccentDesign/gcss/blob/main/banner.jpg"><img src="https://github.com/AccentDesign/gcss/raw/main/banner.jpg" alt="banner"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">gcss</h2><a id="user-content-gcss" aria-label="Permalink: gcss" href="#gcss"></a></p>
<p dir="auto">CSS written in Pure Go.</p>
<p dir="auto">No JS builders, no preprocessors, no linters, no frameworks, no classes, no variables, no overrides, no plugins, no dependencies, no javascript, no templates, no bs, no nothing.</p>
<p dir="auto">Just Go.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Motivation</h2><a id="user-content-motivation" aria-label="Permalink: Motivation" href="#motivation"></a></p>
<p dir="auto">This is really just a bit of fun and a way to write CSS in Go. I wanted to see if it was possible and it is with ease.
I wanted to find a way to easily control the CSS from the server side and not have to worry about pre-building the css to take variables and stuff.
I didnt want to use UI libraries that are written for JS frameworks and I didn't want to use preprocessors or linters that add more steps to the build process.</p>
<p dir="auto">Could I just use CSS? Yes of course and I will, but I wanted to see if I could write CSS in Go as this is what is compiling the rest of the project.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gopher</h2><a id="user-content-gopher" aria-label="Permalink: Gopher" href="#gopher"></a></p>
<p dir="auto">No it looks nothing like the Go gopher, but it's a gopher and I like it. It's the best I could get from the LM without giving up, <a href="https://ideogram.ai/g/E-5MQp7QTPO4uyF9PvERzw/3" rel="nofollow">ideogram.ai (1400097641)</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Next steps</h2><a id="user-content-next-steps" aria-label="Permalink: Next steps" href="#next-steps"></a></p>
<p dir="auto">The next steps for this project are to add more features to the CSS package.
This includes adding support for more CSS properties and maybe mixins.
What I don't want to do is to add support for all CSS functionality as some things are better in CSS, but I do want to be able to create
a few UI components that are configurable using Go.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What I don't need</h2><a id="user-content-what-i-dont-need" aria-label="Permalink: What I don't need" href="#what-i-dont-need"></a></p>
<ul dir="auto">
<li>I don't need UI libs that are written for the purpose of JS frameworks.</li>
<li>I don't need linters when I have Go's static typing.</li>
<li>I don't need javascript to generate CSS.</li>
<li>I don't need templates with 400 css classes in them.</li>
<li>I don't need css with more variables in them than actual css properties.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">What I do need</h2><a id="user-content-what-i-do-need" aria-label="Permalink: What I do need" href="#what-i-do-need"></a></p>
<ul dir="auto">
<li>Go's static typing.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go get github.com/AccentDesign/gcss"><pre>go get github.com/AccentDesign/gcss</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">There are multiple ways you can use <code>gcss</code> in your project. For examples of property values, see the <code>style_test.go</code> file.</p>
<p dir="auto">Writing css to a file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;github.com/AccentDesign/gcss&quot;
	&quot;github.com/AccentDesign/gcss/props&quot;
	&quot;github.com/AccentDesign/gcss/variables&quot;
	&quot;os&quot;
)

type Stylesheet []gcss.Style

var styles = Stylesheet{
	{
		Selector: &quot;html&quot;,
		Props: gcss.Props{
			FontFamily: props.FontFamilySans,
		},
	},
	{
		Selector: &quot;.button&quot;,
		Props: gcss.Props{
			BackgroundColor: variables.Zinc800,
			Border: props.Border{
				Width: props.UnitPx(1),
				Style: props.BorderStyleSolid,
				Color: variables.Zinc900.Alpha(128),
			},
			BorderRadius:  variables.Size1H,
			Color:         variables.White,
			FontSize:      variables.Size4,
			PaddingBottom: variables.Size3,
			PaddingLeft:   variables.Size5,
			PaddingRight:  variables.Size5,
			PaddingTop:    variables.Size3,
		},
	},
	{
		Selector: &quot;.button:hover&quot;,
		Props: gcss.Props{
			BackgroundColor: variables.Zinc900,
		},
	},
}

func main() {
	file, err := os.Create(&quot;stylesheet.css&quot;)
	if err != nil {
		panic(err)
	}
	defer file.Close()

	for _, style := range styles {
		if err := style.CSS(file); err != nil {
			panic(err)
		}
	}
}"><pre><span>package</span> main

<span>import</span> (
	<span>"github.com/AccentDesign/gcss"</span>
	<span>"github.com/AccentDesign/gcss/props"</span>
	<span>"github.com/AccentDesign/gcss/variables"</span>
	<span>"os"</span>
)

<span>type</span> <span>Stylesheet</span> []gcss.<span>Style</span>

<span>var</span> <span>styles</span> <span>=</span> <span>Stylesheet</span>{
	{
		<span>Selector</span>: <span>"html"</span>,
		<span>Props</span>: gcss.<span>Props</span>{
			<span>FontFamily</span>: <span>props</span>.<span>FontFamilySans</span>,
		},
	},
	{
		<span>Selector</span>: <span>".button"</span>,
		<span>Props</span>: gcss.<span>Props</span>{
			<span>BackgroundColor</span>: <span>variables</span>.<span>Zinc800</span>,
			<span>Border</span>: props.<span>Border</span>{
				<span>Width</span>: <span>props</span>.<span>UnitPx</span>(<span>1</span>),
				<span>Style</span>: <span>props</span>.<span>BorderStyleSolid</span>,
				<span>Color</span>: <span>variables</span>.<span>Zinc900</span>.<span>Alpha</span>(<span>128</span>),
			},
			<span>BorderRadius</span>:  <span>variables</span>.<span>Size1H</span>,
			<span>Color</span>:         <span>variables</span>.<span>White</span>,
			<span>FontSize</span>:      <span>variables</span>.<span>Size4</span>,
			<span>PaddingBottom</span>: <span>variables</span>.<span>Size3</span>,
			<span>PaddingLeft</span>:   <span>variables</span>.<span>Size5</span>,
			<span>PaddingRight</span>:  <span>variables</span>.<span>Size5</span>,
			<span>PaddingTop</span>:    <span>variables</span>.<span>Size3</span>,
		},
	},
	{
		<span>Selector</span>: <span>".button:hover"</span>,
		<span>Props</span>: gcss.<span>Props</span>{
			<span>BackgroundColor</span>: <span>variables</span>.<span>Zinc900</span>,
		},
	},
}

<span>func</span> <span>main</span>() {
	<span>file</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>Create</span>(<span>"stylesheet.css"</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>panic</span>(<span>err</span>)
	}
	<span>defer</span> <span>file</span>.<span>Close</span>()

	<span>for</span> <span>_</span>, <span>style</span> <span>:=</span> <span>range</span> <span>styles</span> {
		<span>if</span> <span>err</span> <span>:=</span> <span>style</span>.<span>CSS</span>(<span>file</span>); <span>err</span> <span>!=</span> <span>nil</span> {
			<span>panic</span>(<span>err</span>)
		}
	}
}</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">The benefit of all this are</h2><a id="user-content-the-benefit-of-all-this-are" aria-label="Permalink: The benefit of all this are" href="#the-benefit-of-all-this-are"></a></p>
<ul dir="auto">
<li>Keeps the css free of variables.</li>
<li>Keeps html free of classes like <code>bg-gray-50 text-black dark:bg-slate-800 dark:text-white</code> and eliminates the need to remember to add the dark variant.</li>
<li>I recently saw a button component on an html page 10 times with over 1800 characters in the class attribute of each. This is not maintainable nor debuggable.</li>
<li>Keeps the css clean and easy to debug with no overrides like the above.</li>
<li>Allows for easy theming based on server side logic.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">For example usage see the <a href="https://github.com/AccentDesign/gcss/blob/main/examples">examples</a> directory that include:</p>
<ul dir="auto">
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/css-resets">CSS resets</a> - A simple example collection of css resets.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/integration-templ">Templ integration</a> - An example of how to load styles from gcss with the <a href="https://templ.guide/" rel="nofollow">templ</a> package.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/themed-multiple-http-handlers">Themed CSS using multiple HTTP handlers</a> - An example of how to use multiple http handlers to serve different themes.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/themed-single-http-handler">Themed CSS using a single HTTP handler</a> - An example of how to use a single http handler to serve different themes using media queries.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/to-file">Write to a file</a> - An example of how to write to a file.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/to-http-handler">Write to an HTTP handler</a> - An example of how to write to an http handler.</li>
<li><a href="https://github.com/AccentDesign/gcss/blob/main/examples/to-stdout">Write to stdout</a> - An example of how to write to stdout.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">If you would like to contribute to this project, please open an issue or a pull request. We welcome all contributions and ideas.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Mix it up with other CSS frameworks</h2><a id="user-content-mix-it-up-with-other-css-frameworks" aria-label="Permalink: Mix it up with other CSS frameworks" href="#mix-it-up-with-other-css-frameworks"></a></p>
<p dir="auto">You can mix <code>gcss</code> with other CSS frameworks like <code>tailwindcss</code> for example:</p>
<p dir="auto">separate the css files into base and utils:</p>
<div dir="auto" data-snippet-clipboard-copy-content="/* base.css */
@tailwind base;"><pre><span>/* base.css */</span>
<span>@tailwind</span> base;</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="/* utils.css */
@tailwind utilities;"><pre><span>/* utils.css */</span>
<span>@tailwind</span> utilities;</pre></div>
<p dir="auto">Then add the <code>gcss</code> styles in between in your html:</p>
<div dir="auto" data-snippet-clipboard-copy-content="<link rel=&quot;stylesheet&quot; href=&quot;base.css&quot; />
<link rel=&quot;stylesheet&quot; href=&quot;gcss-styles.css&quot; />
<link rel=&quot;stylesheet&quot; href=&quot;utils.css&quot; />"><pre><span>&lt;</span><span>link</span> <span>rel</span>="<span>stylesheet</span>" <span>href</span>="<span>base.css</span>" /&gt;
<span>&lt;</span><span>link</span> <span>rel</span>="<span>stylesheet</span>" <span>href</span>="<span>gcss-styles.css</span>" /&gt;
<span>&lt;</span><span>link</span> <span>rel</span>="<span>stylesheet</span>" <span>href</span>="<span>utils.css</span>" /&gt;</pre></div>
<p dir="auto">Try to keep the specificity of the <code>gcss</code> styles to 1 by using single classes this will ensure any <code>tailwindcss</code> utilities
will be able to overwrite your styles where required.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Open-source load balancer for llama.cpp (113 pts)]]></title>
            <link>https://github.com/distantmagic/paddler</link>
            <guid>40550059</guid>
            <pubDate>Sat, 01 Jun 2024 23:35:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/distantmagic/paddler">https://github.com/distantmagic/paddler</a>, See on <a href="https://news.ycombinator.com/item?id=40550059">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Paddler</h2><a id="user-content-paddler" aria-label="Permalink: Paddler" href="#paddler"></a></p>
<p dir="auto">Paddler is an open-source load balancer and reverse proxy designed specifically for optimizing servers running <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">Typical strategies like round robin or least connections are not effective for <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> servers, which need slots for continuous batching and concurrent requests.</p>
<p dir="auto">Paddler overcomes this by maintaining a stateful load balancer that is aware of each server's available slots, ensuring efficient request distribution. Additionally, Paddler uses agents to monitor the health of individual <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> instances, providing feedback to the load balancer for optimal performance. Paddler also supports the dynamic addition or removal of <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> servers, enabling integration with autoscaling tools.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How it Works</h2><a id="user-content-how-it-works" aria-label="Permalink: How it Works" href="#how-it-works"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Registering llama.cpp Instances</h3><a id="user-content-registering-llamacpp-instances" aria-label="Permalink: Registering llama.cpp Instances" href="#registering-llamacpp-instances"></a></p>
<p dir="auto">The sequence repeats for each agent. Agents should be installed alongside llama.cpp instance to report their health status to the load balancer.</p>
<section data-identity="76e32045-ddb4-4e89-b10c-ea1be403a482" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div dir="auto" data-json="{&quot;data&quot;:&quot;sequenceDiagram\n    participant loadbalancer as Paddler Load Balancer\n    participant agent as Paddler Agent\n    participant llamacpp as llama.cpp\n\n    agent-&amp;gt;&amp;gt;llamacpp: Hey, are you alive?\n    llamacpp--&amp;gt;&amp;gt;agent: Yes, this is my health status\n    agent--&amp;gt;&amp;gt;loadbalancer: llama.cpp is still working\n    loadbalancer-&amp;gt;&amp;gt;llamacpp: I have a request for you to handle\n&quot;}" data-plain="sequenceDiagram
    participant loadbalancer as Paddler Load Balancer
    participant agent as Paddler Agent
    participant llamacpp as llama.cpp

    agent->>llamacpp: Hey, are you alive?
    llamacpp-->>agent: Yes, this is my health status
    agent-->>loadbalancer: llama.cpp is still working
    loadbalancer->>llamacpp: I have a request for you to handle
">
      <pre lang="mermaid" aria-label="Raw mermaid code">sequenceDiagram
    participant loadbalancer as Paddler Load Balancer
    participant agent as Paddler Agent
    participant llamacpp as llama.cpp

    agent-&gt;&gt;llamacpp: Hey, are you alive?
    llamacpp--&gt;&gt;agent: Yes, this is my health status
    agent--&gt;&gt;loadbalancer: llama.cpp is still working
    loadbalancer-&gt;&gt;llamacpp: I have a request for you to handle
</pre>
    </div>
  <span role="presentation">
    <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" data-view-component="true">
  <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
  <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>
  </span>
</section>

<p dir="auto"><h2 tabindex="-1" dir="auto">Tutorials</h2><a id="user-content-tutorials" aria-label="Permalink: Tutorials" href="#tutorials"></a></p>
<ul dir="auto">
<li><a href="https://github.com/distantmagic/paddler/blob/main/infra/tutorial-installing-llamacpp-aws-cuda.md">Installing llama.cpp on AWS EC2 CUDA Instance</a></li>
<li><a href="https://github.com/distantmagic/paddler/blob/main/tutorial-installing-llamacpp-aws-ec2-image-builder.md">Installing llama.cpp with AWS EC2 Image Builder</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">You can download the latest release from the
<a href="https://github.com/distantmagic/paddler/releases">releases page</a>.</p>
<p dir="auto">Alternatively you can build the project yourself. You need <code>go&gt;=1.21</code> and
<code>nodejs</code> (for dashboard's front-end code) to build the project.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ git clone git@github.com:distantmagic/paddler.git
$ cd paddler
$ pushd ./management
$ make esbuild # dashboard front-end
$ popd
$ go build -o paddler"><pre>$ git clone git@github.com:distantmagic/paddler.git
$ <span>cd</span> paddler
$ <span>pushd</span> ./management
$ make esbuild <span><span>#</span> dashboard front-end</span>
$ <span>popd</span>
$ go build -o paddler</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running Agents</h3><a id="user-content-running-agents" aria-label="Permalink: Running Agents" href="#running-agents"></a></p>
<p dir="auto">The agent should be installed in the same host as <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a>.</p>
<p dir="auto">It needs a few pieces of information:</p>
<ol dir="auto">
<li><code>external-*</code> tells how the load balancer can connect to the llama.cpp instance</li>
<li><code>local-*</code> tells how the agent can connect to the llama.cpp instance</li>
<li><code>management-*</code> tell where the agent should report the health status</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./paddler agent \
    --external-llamacpp-host 127.0.0.1 \
    --external-llamacpp-port 8088 \
    --local-llamacpp-host 127.0.0.1 \
    --local-llamacpp-port 8088 \
    --management-host 127.0.0.1 \
    --management-port 8085"><pre>./paddler agent \
    --external-llamacpp-host 127.0.0.1 \
    --external-llamacpp-port 8088 \
    --local-llamacpp-host 127.0.0.1 \
    --local-llamacpp-port 8088 \
    --management-host 127.0.0.1 \
    --management-port 8085</pre></div>
<p dir="auto">Replace hosts and ports with your own server addresses when deploying.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running Load Balancer</h3><a id="user-content-running-load-balancer" aria-label="Permalink: Running Load Balancer" href="#running-load-balancer"></a></p>
<p dir="auto">Load balancer collects data from agents and exposes reverse proxy to the outside world.</p>
<p dir="auto">It requires two sets of flags:</p>
<ol dir="auto">
<li><code>management-*</code> tells where the load balancer should listen for updates from agents</li>
<li><code>reverseproxy-*</code> tells how load balancer can be reached from the outside hosts</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="./paddler balancer \
    --management-host 127.0.0.1 \
    --management-port 8085 \
    --reverseproxy-host 196.168.2.10 \
    --reverseproxy-port 8080"><pre>./paddler balancer \
    --management-host 127.0.0.1 \
    --management-port 8085 \
    --reverseproxy-host 196.168.2.10 \
    --reverseproxy-port 8080</pre></div>
<p dir="auto"><code>management-host</code> and <code>management-port</code> in agents should be the same as in the load balancer.</p>
<p dir="auto">You can enable dashboard to see the status of the agents with
<code>--management-dashboard-enable=true</code> flag. If enabled it is available at the
management server address under <code>/dashboard</code> path.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Changelog</h2><a id="user-content-changelog" aria-label="Permalink: Changelog" href="#changelog"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">v0.1.0</h3><a id="user-content-v010" aria-label="Permalink: v0.1.0" href="#v010"></a></p>
<ul dir="auto">
<li>New feature: <a href="https://github.com/distantmagic/paddler/releases/tag/v0.1.0">Aggregated Health Status Responses</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Roadmap</h2><a id="user-content-roadmap" aria-label="Permalink: Roadmap" href="#roadmap"></a></p>
<ul>
<li> <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> reverse proxy</li>
<li> Basic load balancer</li>
<li> Circuit breaker</li>
<li> <a href="https://opentelemetry.io/" rel="nofollow">OpenTelemetry</a> observer</li>
<li> Integration with AWS Auto Scaling (and other cloud providers) - out of
the box endpoint with a custom metric to scale up/down</li>
<li> Queueing requests</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Community</h2><a id="user-content-community" aria-label="Permalink: Community" href="#community"></a></p>
<p dir="auto">Discord: <a href="https://discord.gg/kysUzFqSCK" rel="nofollow">https://discord.gg/kysUzFqSCK</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lisp: Icing or Cake? (196 pts)]]></title>
            <link>https://dthompson.us/posts/lisp-icing-or-cake.html</link>
            <guid>40549250</guid>
            <pubDate>Sat, 01 Jun 2024 21:32:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dthompson.us/posts/lisp-icing-or-cake.html">https://dthompson.us/posts/lisp-icing-or-cake.html</a>, See on <a href="https://news.ycombinator.com/item?id=40549250">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>The <a href="https://itch.io/jam/spring-lisp-game-jam-2024">Spring Lisp Game Jam
2024</a> ended one week
ago.  48 games were submitted, a new record for the jam!  This past
week has been a time for participants to play and rate each other’s
games.  As I explored the entries, I noticed two distinct
meta-patterns in how people approached building games with Lisp.  I
think these patterns apply more broadly to all applications of Lisp.
Let’s talk about these patterns in some detail, with examples.</p><h2>But first!</h2><p>Here’s the breakdown of the <a href="https://itch.io/jam/spring-lisp-game-jam-2024/entries">jam
submissions</a> by
language:</p><pre><code>lang       entries    % (rounded)
----       -------    -----------
guile      15         31
fennel     10         21
clojure    5          10
cl         5          10
racket     4          8
elisp      4          8
s7         3          6
kawa       1          2
owl        1          2</code></pre><p>I haven’t rolled up the various Schemes (Guile, Racket, S7, Kawa) into
a general <code>scheme</code> category because Scheme is so minimally specified
and they are all very distinct implementations for different purposes,
not to mention that Racket has a lot more going on than just Scheme.</p><p>For the first time ever, <a href="https://gnu.org/software/guile">Guile</a> came
out on top with the most submissions!  There’s a very specific reason
for this outcome.  11 out of the 15 Guile games were built for the web
with <a href="https://spritely.institute/hoot">Hoot</a>, a Scheme-to-WebAssembly
compiler that I work on at the <a href="https://spritely.institute/">Spritely
Institute</a>.  2 of those 11 were official
Spritely projects.  We <a href="https://spritely.institute/news/make-a-game-with-hoot-for-the-lisp-game-jam.html">put out a
call</a>
for people to try making games with Hoot before the jam started, and a
lot of people took us up on it!  Very cool!</p><p>The next most popular language, which is typically <em>the</em> most popular
language in these jams, is <a href="https://fennel-lang.org/">Fennel</a>.  Fennel
is a Lisp that compiles to Lua.  It’s very cool, too!</p><p>Also of note, at least to me as a Schemer, is that three games used
<a href="https://ccrma.stanford.edu/software/snd/snd/s7.html">S7</a>.  Hmm, there
might be something relevant to this post going on there.</p><p>The patterns I’m about to talk about could sort of be framed as “The
Guile Way vs. The Fennel Way”, but I don’t want to do that.  It's not
an “us vs. them” thing.  It’s wonderful that there are so many flavors
of Lisp these days that anyone can find a great implementation that
suits their preferences.  Not only that, but many of these
implementations can be used to make games that anyone can easily play
in their web browser!  That was <em>not</em> the case several years ago.
Incredible!</p><p>I want to preface the rest of this post by saying that <strong>both patterns
are valid</strong>, and while I prefer one over the other, that is not to say
that the other is inferior.  I'll also show how these patterns can be
thought of as two ends of a spectrum and how, in the end, compromises
must be made.  Okay, let’s get into it!</p><h2>Lisp as icing</h2><p>The icing pattern is using Lisp as a “scripting” language on top of a
cake that is made from C, Rust, and other static languages.  The
typical way to do this is by embedding a Lisp interpreter into the
larger program.  If you’re most interested in writing the high-level
parts of an application in Lisp then this pattern is the fastest way
to get there.  All you need is a suitable interpreter/compiler and a
way to add the necessary hooks into your application.  Since the
program is mainly C/Rust/whatever, you can then use emscripten to
compile it to WebAssembly and deploy to the web.  Instant
gratification, but strongly tied to static languages and their
toolchains.</p><p>S7 is an example of an embeddable Scheme.  Guile is also used for
extending C programs, though typically that involves dynamically
linking to libguile rather than embedding the interpreter into the
program’s executable.  Fennel takes a different approach, recognizing
that there are many existing applications that are already extensible
through Lua, and provides a lispy language that <em>compiles to</em> Lua.</p><h2>Lisp as cake</h2><p>The cake pattern is using Lisp to implement as much of the software
stack as possible.  It’s Lisp all the way down... sorta.  Rather than
embedding Lisp into a non-Lisp program, the cake pattern does the
inverse: the majority of the program is written in Lisp.  When
necessary, shared libraries can be called via a foreign function
interface, but this should be kept to a minimum.  This approach takes
longer to yield results.  Time is spent implementing missing libraries
for your Lisp of choice and writing wrappers around the C shared
libraries you can’t avoid using.  Web deployment gets trickier, too,
since the project is not so easily emscriptenable.</p><p>(You may recognize this as the classic embed vs. extend debate.
You’re correct!  I'm just adding my own thoughts and applying it
specifically to some real-world Lisp projects.)</p><p>I mentioned Guile as an option for icing, but Guile really shines best
as cake.  The initial vision for Guile was to Emacsify other programs
by adding a Scheme interpreter to them.  These days, the best practice
is to write your program in Scheme to begin with.  Common Lisp is
probably the best example, though.  Implementations like SBCL have
good C FFIs and can compile efficient native executables, minimizing
the desire to use some C for performance reasons.</p><h2>Case studies</h2><p>Let’s take a look at some of the languages and libraries used for the
Lisp Game Jam and evaluate their icing/cake-ness.</p><h3>Fennel + love2d</h3><p><a href="https://love2d.org/">love2d</a> has been a popular choice for solo or
small team game development for many years.  It is a C++ program that
embeds a Lua interpreter, which means it’s a perfect target for
Fennel.  Most Linux distributions package love2d, so it’s easy to run
<code>.love</code> files natively.  Additionally, thanks to emscripten, love2d
games can be deployed to the web.  Thus most Fennel games use love2d.
<a href="https://jleightcap.itch.io/sokobin">./soko.bin</a> and <a href="https://alexjgriffith.itch.io/gnomic-vengeance">Gnomic
Vengeance</a> are two
games that use this stack.</p><p>Fennel + love2d is a perfect example of Lisp as icing.  Fennel sits at
the very top of the stack, but there’s not really a path to spread
Lisp into the layers below.  It is also the most successful Lisp game
development stack to date.</p><h3>S7 + raylib</h3><p>This stack is new to me, but two games used it this time around:
<a href="https://gcmas.itch.io/ghosthop">GhostHop</a> and <a href="https://illusion-fisherman.itch.io/life-predictor">Life
Predictor</a>.  (You
really gotta play GhostHop, btw.  It’s a great little puzzle game and
it is playable on mobile devices.)  <a href="https://www.raylib.com/">Raylib</a>
is a C library with bindings for many higher-level languages that has
become quite popular in recent years.  S7 is also implemented in C and
is easily embeddable.  This makes the combination easy to deploy on
the web with emscripten.</p><p>S7 + raylib is another example of Lisp as icing.  I’m curious to see
if this stack becomes more popular in future jams.</p><h3>Guile + Chickadee</h3><p>This is the stack that I helped build.
<a href="https://dthompson.us/projects/chickadee.html">Chickadee</a> is a game library for Guile that
implements almost all of the interesting parts in Scheme, including
rendering.  Two games were built with Chickadee in the most recent
jam: <a href="https://etenil.itch.io/turbo-racer-3000">Turbo Racer 3000</a> and
<a href="https://snamellit.itch.io/bloatrunner">Bloatrunner</a>.</p><p>Guile + Chickadee is an example of Lisp as cake.  Chickadee wraps some
C libraries for low-level tasks such as loading images, audio, and
fonts, but it is written in pure Scheme.  All the matrix and vector
math is in Scheme.  Chickadee comes with a set of rendering primitives
comparable to love2d and raylib but they’re all implemented in Scheme.
I’ve even made progress on rendering vector graphics with Scheme,
whereas most other Lisp game libraries use a C library such as
<a href="https://github.com/memononen/nanosvg">nanosvg</a>.  Chickadee has pushed
the limits of Guile’s compiler and virtual machine, and Guile has been
improved as a result.  But it’s the long road.  Chickadee is mostly
developed by me, alone, in my very limited spare time.  It is taking a
long time to reach feature parity with more popular game development
libraries, but it works quite well for what it is.</p><h3>Hoot + HTML5 canvas</h3><p>I also helped build this one.  Hoot is a Scheme-to-WebAssembly
compiler.  Rather than compile the Guile VM (written in C) to Wasm
using emscripten, Hoot implements a complete Wasm toolchain and a new
backend for Guile’s compiler that emits Wasm directly.  Hoot is
written entirely in Scheme.  Unlike C programs compiled with
emscripten that target Wasm 1.0 with linear memory, Hoot targets Wasm
2.0 with GC managed heap types.  This gives Hoot a significant
advantage: Hoot binaries <strong>do not ship a garbage collector</strong> and thus
are much smaller than Lisp runtimes compiled via emscripten.  The Wasm
binary for my game weighs in at &lt; 2MiB whereas the love2d game I
checked had a nearly 6MiB <code>love.wasm</code>.  Hoot programs can also easily
interoperate with JavaScript.  Scheme objects can easily be passed to
JavaScript, and vice versa, as they are managed in the same heap.
With all of the browser APIs just a Wasm import away, an obvious
choice for games was the built-in HTML5 canvas API for easy 2D
rendering.</p><p>11 games used Hoot in the jam, including (shameless plug)
<a href="https://davexunit.itch.io/cirkoban">Cirkoban</a> and <a href="https://fluxharmonic.itch.io/lambda-dungeon">Lambda
Dungeon</a>.</p><p>Hoot + HTML5 canvas is mostly dense cake with a bit of icing.  On one
hand, it took a year and significant funding to <a href="https://wingolog.org/archives/2024/05/16/on-hoot-on-boot">boot
Hoot</a>.  We
said “no” to emscripten, built <a href="https://wingolog.org/archives/2024/05/24/hoots-wasm-toolkit">our own
toolchain</a>,
and extended Guile’s compiler.  It's Lisp all the way until you hit
the browser runtime!  We even have a Wasm interpreter that runs on the
Guile VM!  Hoot rules!  It was a risk but it paid off.  On the other
hand, the canvas API is very high-level.  The more cake thing to do
would be to use Hoot’s JS FFI to call WebGL and/or WebGPU.  Indeed,
this is the plan for the future!  Wasm GC needs some improvements to
make this feasible, but my personal goal is to get Chickadee ported to
Hoot.  I want Chickadee games to be easy to play natively and in
browsers, just like love2d games.</p><h2>The cake/icing spectrum</h2><p>I must acknowledge the limitations of the cake approach.  We’re not
living in a world of Lisp machines, but a world of glorified PDP-11s.
Even the tallest of Lisp cakes sits atop an even larger cake made
mostly of C.  All modern Lisp systems bottom out at some point.  Emacs
rests on a C core.  Guile’s VM is written in C.  Hoot runs on mammoth
JavaScript engines written in C++ like V8.  Games on Hoot currently
render with HTML5 canvas rather than WebGL/WebGPU.  Good luck using
OpenGL without libGL; Chickadee uses guile-opengl which uses the C FFI
to call into libGL.  Then there’s libpng, FreeType, and more.  Who the
heck wants to rewrite all this in Lisp?  Who even has the resources?
Does spending all this time taking the scenic route matter at all, or
are we just deluding ourselves because we have fun writing Lisp code?</p><p>I think it <em>does</em> matter.  Every piece of the stack that can be
reclaimed from the likes of C is a small victory.  The parts written
in Lisp are much easier to hack on, and some of those things become
<strong>live hackable</strong> while our programs are running.  They are also
memory safe, typically, thanks to GC managed runtimes.  Less FFI calls
means less overhead from traversing the Lisp/C boundary and more
safety.  As more of the stack becomes Lisp, it starts looking less
like icing and more like cake.</p><p>Moving beyond games, we can look to the <a href="https://guix.gnu.org/">Guix</a>
project as a great example of just how tasty the cake can get.  Guix
took the functional packaging model from the Nix project and made a
fresh implementation, replacing the Nix language with Guile.  Why?
For code staging, code sharing, and improved hackability.  Guix also
uses an init system written in Guile rather than systemd.  Why?  For
code staging, code sharing, and improved hackability.  These are real
advantages that make the trade-off of not using the industry-standard
thing worth it.</p><p>I’ve been using Guix since the early days, and back then it was easy
to make the argument that Guix was just reinventing wheels for no
reason.  But now, over 10 years later, the insistence on maximizing
the usage of Lisp has been key to the success of the project.  As a
user, once you learn the Guix idioms and a bit of Guile, you unlock
extraordinary power to craft your OS to your liking.  It’s the closest
thing you can get to a Lisp machine on modern hardware.  The cake
approach paid off for Guix, and it could pay off for other projects,
too.</p><p>If Common Lisp is more your thing, and even if it isn’t, you’ll be
amazed by the <a href="https://shirakumo.github.io/trial/">Trial</a> game engine
and how much of it is implemented in Common Lisp rather than wrapping
C libraries.</p><p>There’s also projects like <a href="https://prescheme.org/">Pre-Scheme</a> that
give me hope that one day the layers below the managed GC runtime can
be implemented in Lisp.  Pre-Scheme was developed and successfully
used for <a href="https://s48.org/">Scheme 48</a> and I am looking forward to a
modern revival of it thanks to an <a href="https://nlnet.nl/project/Pre-Scheme/">NLnet
grant</a>.</p><h2>I'm a cake boy</h2><p>That’s right, I said it: I’m a cake boy.  I want to see projects
continue to push the boundaries of what Lisp can do.  When it comes to
the Lisp Game Jam, what excites me most are not the games themselves,
but the small advances made to reclaim another little slice of the
cake from stale, dry C.  I intend to keep pushing the limits for Guile
game development with my Chickadee project.</p><p>It’s <em>not</em> a piece of cake to bake a lispy cake, and the way is often
hazy, but I know we can’t be lazy and just do the cooking by the book.
Rewrite it in Rust?  No way!  Rewrite it in Lisp!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[LLMs aren't "trained on the internet" anymore (173 pts)]]></title>
            <link>https://allenpike.com/2024/llms-trained-on-internet</link>
            <guid>40549021</guid>
            <pubDate>Sat, 01 Jun 2024 20:59:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://allenpike.com/2024/llms-trained-on-internet">https://allenpike.com/2024/llms-trained-on-internet</a>, See on <a href="https://news.ycombinator.com/item?id=40549021">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>A path to continued model improvement.</p><div>
<p>I often see a misconception when people try to reason about the capability of LLMs, and in particular how much future improvement to expect.</p>

<p>It’s frequently said that that LLMs are “trained on the internet,” and so they’ll always be bad at producing content that is rare on the web. A recent <a href="https://news.ycombinator.com/item?id=40333672">example from Hacker News</a>:</p>

<blockquote>
  <p>LLMs are mostly trained on Internet posts, so they are Internet simulators.</p>
</blockquote>

<p>Wikipedia also <a href="https://en.wikipedia.org/wiki/Large_language_model">frames LLM training this way</a>:</p>

<blockquote>
  <p>LLMs are trained on increasingly large corpora of text largely scraped from the web.</p>
</blockquote>

<p>Even former Apple SVP of Engineering – and famously sharp computer scientist – Bertrand Serlet explains them thus, in his recent video <a href="https://www.youtube.com/watch?v=QwtyIDmhxh4">Why AI Works</a>:</p>

<blockquote>
  <p>[An LLM has] been trained on the entire internet, so it has packed all this knowledge that’s in the internet, but also all the reasoning patterns that can be found [there.]</p>
</blockquote>

<p>Admittedly, this used to be true! And is still <em>mostly</em> true. But it’s increasingly becoming less true.</p>

<p>Because it’s becoming less true, the idea of an “internet simulator” is not a useful way to predict how GPT-5 and beyond will work. New models are already exceeding this definition, and the shift is only beginning.</p>

<h2 id="the-data-wall">The Data Wall</h2>

<p>Way back in 2020, OpenAI’s <a href="https://arxiv.org/pdf/2005.14165">GPT-3 paper</a> described their training dataset in some detail. GPT-3 was, basically, trained on the internet.</p>

<div>
<p><img src="https://allenpike.com/images/2024/gpt3-data.png"></p><p>An artifact from a bygone era, when frontier AI was open.</p>
</div>

<p>By 2022, LLMs were being <a href="https://arxiv.org/abs/2203.02155">trained to follow instructions</a> using custom human feedback. Since then, frontier model labs like OpenAI have gotten very cagey about what they’re adding to their training datasets. We don’t know what GPT-4o was trained on, let alone Sora or GPT-5.</p>

<p>But we do know <strong>it’s not just the internet</strong>.</p>

<p>Recently, LLM trainers have hit a “<a href="https://www.theverge.com/2024/4/1/24117828/the-internet-may-not-be-big-enough-for-the-llms">data wall</a>”. More data generally improves model training, but OpenAI already has roughly all the data on the web – even inconvenient-to-access data like <a href="https://www.theverge.com/2024/4/6/24122915/openai-youtube-transcripts-gpt-4-training-data-google">Youtube video transcriptions</a>. So other than training ever-larger models on the same internet data, how can they make better LLMs?</p>

<p>The answer, for labs with money, is acquiring and creating non-public data. At first, their focus was making existing training data more useful, or adding existing non-public data to the training pool. For example:</p>

<ol>
  <li><strong>Annotation and filtering</strong>: Researchers have been creating annotations for their training data for years. Good annotations let them focus LLM training on the highest value data, which allows for better (or smaller) models.</li>
  <li><strong>RLHF</strong>: Labs also have humans rate model outputs. They use this data to fine-tune the models, and encourage useful behaviours like instruction-following and refusing to say naughty things.</li>
  <li><strong>Usage data</strong>: ChatGPT is <a href="https://www.interconnects.ai/p/the-data-wall">said to</a> generate on the order of 10 billion tokens of data per day – even before they opened their more compelling GPT-4o model to free users.</li>
  <li><strong>Data acquisition</strong>: While a lot of humanity’s data is on the internet, much of it is not. Emails, chat logs, proprietary manuals and procedures, JIRA tickets, phone recordings, internal reports, and contracts are all useful data. While examples exist on the internet, model trainers can cut deals to add more of these to their training data.</li>
</ol>

<p>So that’s all helpful.</p>

<p>But none of these techniques are a complete solution to a famous weakness of current models: the “<strong>LLMs suck at producing outputs that don’t look like existing data</strong>” problem.</p>

<p>Here are some of the many things that LLMs are bad at doing, in part because there isn’t a lot of text online that demonstrates them:</p>

<ol>
  <li>Expressing doubt or uncertainty in one’s answer</li>
  <li>Having long conversations without repeating phrasings or looping</li>
  <li>Making high-level plans for LLM agents to pursue</li>
  <li>Reasoning like a Principal Engineer about a massive legacy codebase</li>
  <li>Reliably following extremely long or complex prompts</li>
</ol>

<p>While improved architectures and more parameters might help with these limitations, you can bet your butt that OpenAI, Meta, Google, and/or Microsoft are paying big money to fill some of these gaps in a simpler way: <strong>creating novel examples to train on</strong>.</p>

<h2 id="llms-are-now-being-trained-on-custom-data">LLMs are now being trained on custom data</h2>

<p>A recent example of the rise of custom data is Microsoft’s <a href="https://arxiv.org/abs/2404.14219">Phi-3 Technical Report</a>, published in April. phi-3-mini is only 3.8 billion parameters – a waif in LLM terms – but claims performance competitive with the impressive but much-heavier Mixtral model. The paper credits some of this improvement to including high-quality synthetic data, generated by larger LLMs, in the training data. Synthetic data allows them to fill gaps in the internet-sourced data, and improves model performance for a given size.</p>

<p>Now, synthetic data is a hot topic in LLM research. It’s not yet clear how far you can go with training LLMs on their own output before things <a href="https://arxiv.org/abs/2404.01413">go horribly wrong</a>, like a giant neural snake eating its own tail.</p>

<p>At the minimum, though, synthetic data will help fill the kind of gaps that arise simply from LLMs behaving like “internet simulators.” For example, if your model is hallucinating because you don’t have enough training examples of people expressing uncertainty, or biased because it has unrepresentative data, then generate some better examples!</p>

<p>Still, creating great synthetic data with LLMs is a challenging problem, and will have its limits. That’s why there’s one last huge source of non-internet data inbound: Humans.</p>

<h2 id="how-much-data-can-you-create-for-1byr">How much data can you create for $1B/yr?</h2>

<p>It turns out that if you pay people money, they’re willing to make data for you. <a href="https://scale.ai/">Scale.ai</a>, which bills itself as “the data foundry for AI,” operates a service where labs pay humans to do just this. Reportedly, AI companies are paying more than $1B a year for Scale’s services already. While some of this is for annotation and ratings on data that came from the web or LLMs, they also <a href="https://fortune.com/2024/05/21/scale-ai-funding-valuation-ceo-alexandr-wang-profitability/">create new training data whole-hog</a>:</p>

<blockquote>
  <p>The company has shifted its focus to more highly-specialized workers such as Ph.D-level academics, lawyers, accountants, poets, authors, and those fluent in specific languages. These workers, who help train and test models for companies from OpenAI and Cohere to Anthropic and&nbsp;Google, also work through a third-party, often another Scale subsidiary called Outlier, but are paid higher hourly wages.</p>
</blockquote>

<p>Not only can companies like OpenAI pay to have professionals create new, good data that fills holes in the internet-sourced data, they then keep that data to train subsequent models. A dataset like “50,000 examples of Ph.Ds expressing thoughtful uncertainty when asked questions they don’t know the answer to” could be worth a lot more than it costs to produce.</p>

<p>So yes, LLMs were originally trained on the internet. Yes, we can understand a lot of their early weaknesses as stemming from the foibles of whatever crap people post on the web.</p>

<p>However. As the size and impact of custom training data increases, we should expect LLMs to markedly exceed “internet simulation”. In particular, they’ll continue to get better at things that aren’t on the internet, but can be demonstrated in $1B+ of custom data creation.</p>

<p>That is to say: this train will keep rollin’ for a while yet.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[X is justifiably slow (2022) (106 pts)]]></title>
            <link>https://zeux.io/2024/05/31/justifiably-slow/</link>
            <guid>40547933</guid>
            <pubDate>Sat, 01 Jun 2024 18:23:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://zeux.io/2024/05/31/justifiably-slow/">https://zeux.io/2024/05/31/justifiably-slow/</a>, See on <a href="https://news.ycombinator.com/item?id=40547933">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<p><span>

31 May 2024

</span></p><p>I regularly hear or read statements like this: “X is slow but this is to be expected because it needs to do a lot of work”. It can be said about an application or a component in a larger system, and can refer to other resources that aren’t time. I often find these profoundly unhelpful as they depend much more on the speaker’s intuition and understanding of the problem, than X itself.</p>

<!--more-->

<blockquote>
  <p>This post is much shorter than usual, and it was originally written in 2022 and published <a href="https://cohost.org/zeux/post/357091-x-is-justifiably-slo">on Cohost</a>. I’m going to experiment with posting shorter technical content like this more regularly in the coming months, including reposting my earlier Cohost posts (of which this is one of).</p>
</blockquote>

<p>X<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> may be slow because it’s using an inefficient algorithm. When a database query takes a while to return a large volume of results, it may be because there’s no index for that query - the query engine might be relatively well optimized, but the poor algorithmic complexity wins.</p>

<p>X may be slow because it’s using an inefficient implementation of an algorithm. It’s common to see 10x gaps or more between different implementations of the same idea, and without profiling the code it’s hard to know whether something unexpected is taking the majority of time.</p>

<p>X may be slow because it’s not taking advantage of the hardware. Modern hardware is incredibly fast, and many people don’t have a good intuition for just how fast computers they use day to day are. The performance deficit between a reasonable serial implementation and code that uses efficient SIMD and multithreading can be significant - it’s not particularly outlandish to see 100x delta on modern multi core chips with wide SIMD on computationally intensive problems - and replacing drastically cache inefficient algorithms with cache efficient ones can also yield dramatic speedups.</p>

<p>X may be slow because it’s actually doing the work, but doing the work isn’t necessary. Maybe X has no cache in front of it, or the cache hit rate is 10x worse than it should be, or maybe the cache retrieval itself is slow even though it doesn’t need to be.</p>

<p>X may not even use the right framing for a problem. C++ compilers are notoriously slow, but it’s not because the process of code compilation is fundamentally slow - it’s because every element of the stack often carries profound inefficiencies that can be corrected by reframing the problem (which may require significant changes to the formulation - maybe instead of C++ you need to compile a different language!).</p>

<p>And yet there are cases when “X is slow because it’s doing a lot of work” is actually probably right - when the problem has been well explored and can’t be reframed, when the implementation is thoroughly profiled and optimized, and especially when you can do some sort of speed of light calculation<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>, eg “on this system we can’t read memory faster than 50 GB/s, and yes we do need to read this much memory because we’ve already compressed the data to the extent feasible”.</p>

<p>It can be very difficult to tell the difference, which is why I get annoyed a little bit every time I hear this, because the odds that enough analysis has been done on the particular implementation of the particular solution on the specific hardware and the exact data that’s being processed before the statement is made are slim.</p>








	</div></div>]]></description>
        </item>
    </channel>
</rss>