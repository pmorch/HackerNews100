<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 28 Oct 2025 20:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Samsung makes ads on $3,499 smart fridges official with upcoming software update (101 pts)]]></title>
            <link>https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/</link>
            <guid>45737338</guid>
            <pubDate>Tue, 28 Oct 2025 19:02:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/">https://arstechnica.com/gadgets/2025/10/samsung-makes-ads-on-3499-smart-fridges-official-with-upcoming-software-update/</a>, See on <a href="https://news.ycombinator.com/item?id=45737338">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      
                      
          <p>After kicking off an unpopular <a href="https://arstechnica.com/gadgets/2025/09/samsung-forces-ads-onto-fridges-is-a-bad-sign-for-other-appliances/">pilot test last month,</a> Samsung made the practice of having its expensive smart fridges display ads official this week.</p>
<p>The ads will be shown on Samsung’s 2024 Family Hub smart fridges. As of this writing, Samsung’s Family Hub fridges have MSRPs ranging from <a href="https://www.samsung.com/us/home-appliances/refrigerators/all-refrigerators/?shop=Buy+Online&amp;key_category_features=Family+Hub%C3%A2%C2%84%C2%A2&amp;CID=afl-ecomm-rkt-cha-040122-url_Skimlinks.com&amp;utm_source=url_Skimlinks.com&amp;utm_medium=affiliate&amp;utm_campaign=1&amp;utm_content=2116208&amp;rktevent=Skimlinks.com_TnL5HPStwNw-XmUXqH629_Fatbxjry_5NQ&amp;ranMID=47773&amp;ranEAID=TnL5HPStwNw&amp;ranSiteID=TnL5HPStwNw-XmUXqH629_Fatbxjry_5NQ">$1,899 to $3,499</a>. The ads will arrive through a software update that Samsung will start issuing this month and display on the fridge’s integrated 21.5- or 32-inch (depending on the model) screen. The ads will show when the fridges are idle and display what Samsung calls Cover Screens.</p>
<blockquote><p>As part of the Family Hub software update, we are piloting a new widget for select Cover Screens themes of Family Hub refrigerators. The widget will display useful day-to-day information such as news, calendar and weather forecasts, along with curated advertisements.</p></blockquote>
<p>Samsung also said that its fridges will only show contextualized ads, instead of personalized ads, which rely on collecting data on users.</p>
<p><a href="https://www.theverge.com/report/806797/samsung-family-hub-smart-fridge-ads-opt-out">The Verge</a> reported that the widget will appear as a rectangular box at the bottom of the screens. The box will change what it displays “every 10 seconds,” the publication said.</p>
<p>The software update will also introduce “a Daily Board theme that offers a new way to see useful information at a glance,” Samsung said. The Verge reported that this feature will also include ads, something that Samsung’s announcement neglected to state. The Daily Board theme will show five tiles with information such as appointments and the weather, and one with ads.</p>

          
                      
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What we talk about when we talk about sideloading (187 pts)]]></title>
            <link>https://f-droid.org/2025/10/28/sideloading.html</link>
            <guid>45736479</guid>
            <pubDate>Tue, 28 Oct 2025 18:02:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://f-droid.org/2025/10/28/sideloading.html">https://f-droid.org/2025/10/28/sideloading.html</a>, See on <a href="https://news.ycombinator.com/item?id=45736479">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>We recently published a <a href="https://f-droid.org/en/2025/09/29/google-developer-registration-decree.html">blog
post</a>
with our reaction to the new Google Developer Program and how it impacts
your freedom to use the devices that you own in the ways that you want. The
post garnered quite a lot of feedback and interest from the community and
press, as well as various civil society groups and regulatory agencies.</p>

<p>In this post, I hope to clarify and expand on some of the points and rebut
some of the counter-messaging that we have witnessed.</p>

<h3 id="googles-message-that-sideloading-is-not-going-away-is-clear-concise-and-false">Google’s message that “Sideloading is Not Going Away” is clear, concise, and false</h3>

<p>Shortly after our post was published, Google aired an
<a href="https://www.youtube.com/watch?v=A7DEhW-mjdc&amp;t=613s">episode</a> of their
Android Developers Roundtable series, where they state unequivocally that
“sideloading isn’t going anywhere”. They follow-up with a <a href="https://android-developers.googleblog.com/2025/09/lets-talk-security-answering-your-top.html">blog
post</a>:</p>

<blockquote>
  <p><em><strong>Does this mean sideloading is going away on Android?</strong> Absolutely not. Sideloading is fundamental to Android and it is not going away.</em></p>
</blockquote>

<p>This statement is untrue. The developer verification decree effectively ends
the ability for individuals to choose what software they run on the devices
they own.</p>

<p>It bears reminding that “sideload” is a made-up term. Putting software on
your computer is simply called “installing”, regardless of whether that
computer is in your pocket or on your desk. This could perhaps be further
precised as “<em>direct</em> installing”, in case you need to make a distinction
between obtaining software the old-fashioned way versus going through a
rent-seeking intermediary marketplace like the Google Play Store or the
Apple App Store.</p>

<p>Regardless, the term “sideload” was coined to insinuate that there is
something dark and sinister about the process, as if the user were making an
end-run around safeguards that are designed to keep you protected and
secure. But if we reluctantly accept that “sideloading” is a term that has
wriggled its way into common parlance, then we should at least use a
consistent definition for it. Wikipedia’s summary
<a href="https://en.wikipedia.org/wiki/Sideloading">definition</a> is:</p>

<blockquote>
  <p><em>the transfer of apps from web sources that are not vendor-approved</em></p>
</blockquote>

<p>By this definition, Google’s statement that “sideloading is not going away”
is simply <em>false</em>. The vendor — Google, in the case of Android certified
devices — will, in point of fact, be approving the source. The supplicant
app developer must register with Google, pay a fee, provide government
identification, agree to non-negotiable (and ever-changing) terms and
conditions, enumerate all their current and future application identifiers,
upload evidence of their private signing key, and then hope and wait for
Google’s approval.</p>

<h3 id="what-this-means-for-your-rights">What this means for your rights</h3>

<p>You, the consumer, purchased your Android device believing in Google’s
promise that it was an open computing platform and that you could run
whatever software you choose on it. Instead, starting next year, they will
be non-consensually pushing an update to your operating system that
irrevocably blocks this right and leaves you at the mercy of their judgement
over what software you are permitted to trust.</p>

<p>You, the creator, can no longer develop an app and share it directly with
your friends, family, and community without first seeking Google’s
approval. The promise of Android — and a marketing advantage it has used to
distinguish itself against the iPhone — has always been that it is
“open”. But Google clearly feels that they have enough of a lock on the
Android ecosystem, along with sufficient regulatory capture, that they can
now jettison this principle with prejudice and impunity.</p>

<p>You, the state, are ceding the rights of your citizens and your own digital
sovereignty to a company with a track record of complying with the
extrajudicial demands of authoritarian regimes to remove perfectly legal
apps that they happen to dislike. The software that is critical to the
running of your businesses and governments will be at the mercy of the
opaque whims of a distant and unaccountable corporation. Monocultures are
perilous not just in agriculture, but in software distribution as well.</p>

<p>As a reminder, this applies not just to devices that exclusively use the
Google Play Store: this is for <em>every</em> Android Certified device <em>everywhere</em>
in the world, which encompasses over 95% of all Android devices outside of
China. Regardless of whether the device owner prefers to use a competing app
store like the Samsung Galaxy Store or the Epic Games Store, or a free and
open-source app repository like F-Droid, they will be captive to the
overarching policies unilaterally dictated by a competing corporate entity.</p>

<h3 id="the-place-of-greater-safety">The place of greater safety</h3>

<p>In promoting their developer registration program, Google
<a href="https://android-developers.googleblog.com/2025/08/elevating-android-security.html">purports</a>:</p>

<blockquote>
  <p><em>Our recent analysis found over 50 times more malware from internet-sideloaded sources than on apps available through Google Play.</em></p>
</blockquote>

<p>We haven’t seen this recent analysis — or any other supporting evidence —
but the “50 times” multiple does certainly sound like great cause for
distress (even if it is a surprisingly round number). But given the recent
<a href="https://www.malwarebytes.com/blog/news/2025/09/224-malicious-apps-removed-from-the-google-play-store-after-ad-fraud-campaign-discovered">news</a>
of “224 malicious apps removed from the Google Play Store after ad fraud
campaign discovered”, we are left to wonder whether their energies might
better be spent assessing and improving their own safeguards rather than
casting vague disparagements against the software development communities
that thrive outside their walled garden.</p>

<p>In addition, other recent
<a href="https://www.theregister.com/2025/08/26/apps_android_malware/">news</a> of over
19 million downloads of malware from the Play Store leads us to question
whether the sole judgement of a single corporate entity can be trusted to
identify and assess malware, especially when that judgement is clouded by
commercial incentives that may not align with the well-being of their users.</p>

<h3 id="what-can-be-done">What can be done?</h3>

<p>Google has been facing public outcry against their heavy-handed policies for
a long time, but this trend has accelerated recently. Last year they
<a href="https://arstechnica.com/gadgets/2024/08/chromes-manifest-v3-and-its-changes-for-ad-blocking-are-coming-real-soon/">crippled
ad-blockers</a>
in Chrome and Chromium-based browsers by forcing through their unpopular
“manifest v3” requirement for plugins, and earlier this year they <a href="https://arstechnica.com/gadgets/2025/03/google-makes-android-development-private-will-continue-open-source-releases/">closed
off</a>
the development of the Android Open Source Project (AOSP), which is how they
were able to clandestinely implement the verification infrastructure that
enforces their developer registration decree.</p>

<p>Developer verification is an existential threat to free software
distribution platforms like F-Droid as well as emergent commercial
competitors to the Play Store. We are witnessing a groundswell of opposition
to this attempt from both our user and developer communities, as well as the
tech press and civil society groups, but public policymakers still need to
be educated about the threat.</p>

<p>To learn more about what you can do as a consumer, visit
<a href="https://keepandroidopen.org/">keepandroidopen.org</a> for information on how to
contact your representative agencies and advocate for keeping the Android
ecosystem open for consumers and competition.</p>

<p>If you are an app developer, we recommend against signing yourself up for
Google’s developer registration program at this time. We unequivocally
reject their attempt to force this program upon the world.</p>

<p>Over half of all humankind uses an Android smartphone. Google does not own
your phone. You own your phone. You have the right to decide who to trust,
and where you can get your software from.</p>

  </div>

</article>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Using AI to negotiate a $195k hospital bill down to $33k (602 pts)]]></title>
            <link>https://www.threads.com/@nthmonkey/post/DQVdAD1gHhw</link>
            <guid>45734582</guid>
            <pubDate>Tue, 28 Oct 2025 15:58:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.threads.com/@nthmonkey/post/DQVdAD1gHhw">https://www.threads.com/@nthmonkey/post/DQVdAD1gHhw</a>, See on <a href="https://news.ycombinator.com/item?id=45734582">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[EuroLLM: LLM made in Europe built to support all 24 official EU languages (409 pts)]]></title>
            <link>https://eurollm.io/</link>
            <guid>45733707</guid>
            <pubDate>Tue, 28 Oct 2025 14:58:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eurollm.io/">https://eurollm.io/</a>, See on <a href="https://news.ycombinator.com/item?id=45733707">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="primary">
<section id="home">
	<div>
		<h2>Meet EuroLLM</h2>
		<p>
			Large language model<br>
			made in Europe<br>
			built to support all<br>
			official 24 EU languages
		</p>
		<p><a href="#about">ABOUT EUROLLM</a>
	</p></div>
	<svg width="177" height="172" viewBox="0 0 177 172" fill="none" xmlns="http://www.w3.org/2000/svg">
		<path d="M177 78.3882L99.0815 81.7267L156.524 30.4472L145.53 19.764L92.8975 75.7174L96.3331 0H80.6669L84.1025 75.7174L31.4697 19.764L20.3385 30.4472L77.9185 81.7267L0 78.3882V93.4783L77.9185 90.1397L20.3385 141.419L31.4697 152.102L84.1025 96.1491L80.6669 172H96.3331L92.8975 96.1491L145.53 152.102L156.524 141.419L99.0815 90.1397L177 93.4783V78.3882Z" fill="#04093D"></path>
	</svg>

</section>

<section>
	<h2>Featured In</h2>
	
</section>

<section id="features">
	<h2>
		<svg width="169" height="27" viewBox="0 0 169 27" fill="none" xmlns="http://www.w3.org/2000/svg">
		<path d="M22.8909 8.39234V0H8.40615H0V7.43392V8.93299V16.9813V18.4804V25.9143H8.40615H22.8909V17.5219L8.40615 18.2592V16.9813H16.8123V8.93299H8.40615V7.65509L22.8909 8.39234Z" fill="#FFFB8D"></path>
		<path d="M37.8472 1.90735e-06L38.4471 18.1724H36.2849L36.8848 1.90735e-06H24.1866V13.1731C24.1866 20.447 30.0858 26.3462 37.3597 26.3462C44.6337 26.3462 50.5328 20.447 50.5328 13.1731V1.90735e-06H37.8347H37.8472Z" fill="#FFFB8D"></path>
		<path d="M78.6066 1.90735e-06V25.9143H104.521V1.90735e-06H78.6066Z" fill="#FFFB8D"></path>
		<path d="M77.7429 9.38763V8.49064C77.7429 3.79683 74.0093 1.90735e-06 69.3937 1.90735e-06H52.2605V25.9143H62.12V17.866H63.0262L64.2103 25.9143H76.0271L71.7015 17.5342C75.1813 16.5144 77.7429 13.2582 77.7429 9.38763ZM61.5158 8.66266L69.2608 8.02372V10.2232L61.5158 9.54736V8.65038V8.66266Z" fill="#FFFB8D"></path>
		<path d="M99.7699 12.269L92.735 12.5708L97.9212 7.93521L96.9286 6.96946L92.1767 12.0276L92.4869 5.18283H91.0725L91.3826 12.0276L86.6307 6.96946L85.6257 7.93521L90.8243 12.5708L83.7894 12.269V13.6331L90.8243 13.3313L85.6257 17.9669L86.6307 18.9327L91.3826 13.8746L91.0725 20.7314H92.4869L92.1767 13.8746L96.9286 18.9327L97.9212 17.9669L92.735 13.3313L99.7699 13.6331V12.269Z" fill="#04093D"></path>
		<path d="M116.236 1.90735e-06H111.863V22.5479V25.9143H116.236H126.548V21.9011L116.236 22.3499V1.90735e-06Z" fill="#FFFB8D"></path>
		<path d="M132.832 1.90735e-06H128.707V22.5479V25.9143H132.832H142.528V21.9011L132.832 22.3499V1.90735e-06Z" fill="#FFFB8D"></path>
		<path d="M164.309 1.90735e-06V0.0264046L156.775 7.20794L149.253 0.039606V1.90735e-06H145.12V25.9143H149.253V4.8053L156.75 12.6337L156.775 12.6073L156.8 12.6337L164.309 4.7921V25.9143H168.443V1.90735e-06H164.309Z" fill="#FFFB8D"></path>
		</svg>
	</h2>

	<ul>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/feature_multimodal.svg" alt="Multimodal" width="40" height="40">
			<h3>Multimodal</h3>
			<p>Soon we will be adding vision and voice to our models so that they can interpret and understand images and speech.</p>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/feature_opensource.svg" alt="Open Source" width="40" height="40">
			<h3>Open Source</h3>
			<p>Freely used by researchers, organisations and citizens of Europe.</p>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/feature_performance.svg" alt="High Performance" width="40" height="40">
			<h3>High Performance</h3>
			<p>Great on language related tasks, including question answering, summarisation, and translation.</p>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/feature_multilingual.svg" alt="Multilingual" width="40" height="40">
			<h3>Multilingual</h3>
			<p>Models pretrained and finetuned on text from all languages.</p>
		</li>
	</ul>

</section>

<section id="models">
	<div>
		
		<p>Our current flagship model. A 9B parameter model trained on over 4 trillion tokens of multilingual data across 35 different languages, including all official EU languages. We’ve made EuroLLM 9B Base available for fine-tuning on any task. As a demonstration, we’ve also provided EuroLLM 9B Instruct, a model fine-tuned for instruction following and chat capabilities.</p>
		<p><a href="https://huggingface.co/utter-project/EuroLLM-9B" target="_blank">TRY THE MODEL AT HUGGING FACE &gt;</a>
	</p></div>

	

	<div>
		<h2>Learn more</h2>
		<p>
			EuroLLM release Article on Hugging Face
			<a href="https://huggingface.co/utter-project/EuroLLM-9B" target="_blank">LINK</a>
		</p>
		<p>
			Technical Report for EuroLLM 1.7B
			<a href="https://huggingface.co/utter-project/EuroLLM-9B" target="_blank">LINK</a>
		</p>
	</div>
</section>

<section id="mission">
	<h2>Our Mission</h2>
	<p>Sharing a common vision, our team is committed to advancing multilingual AI technologies to empower Europe’s digital future and strengthen the EU’s commitment to AI sovereignty. The team’s goal is for EuroLLM to become a <strong>flywheel for innovation</strong> — offering anyone the opportunity to use this EU homegrown LLM and build upon it. The project is living proof that amazing things can happen when Europe comes together to push the boundaries of innovation.</p>
</section>

<section id="team">
	<h2>The Team</h2>
	<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/the_team.png" alt="Our Team">
</section>

<section id="key-people">
	<h2>Key People</h2>

	<ul>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/people-andre-martins.png" alt="André Martins">
			<div>
				<h3>André Martins</h3>
				<p>VP of AI Research, Unbabel and Associate Professor, Instituto Superior Técnico, University of Lisbon</p>
				<p>André Martins is an expert in machine learning and natural language processing. His research has been funded twice by the European Research Council. He is a Fellow of the ELLIS Society and a board member of the European Association for Machine Translation. He is a co-founder of the Lisbon Machine Learning School (LxMLS).</p>
			</div>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/alexandra-eurollm-team.png" alt="Alexandra Birch">
			<div>
				<h3>Alexandra Birch</h3>
				<p>Co-founder and Chief Scientist, Aveni.ai</p>
				<p>Associate Professor in Natural Language Processing at the University of Edinburgh. Her research has resulted in over 100 peer reviewed publications, focusing on translation and multilingual NLP and covering topics such as ethics, explainability and efficiency.</p>
			</div>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/people-nuno-guerreiro.png" alt="Nuno Guerreiro">
			<div>
				<h3>Nuno Guerreiro</h3>
				<p>Senior Research Scientist, Unbabel</p>
				<p>Nuno Guerreiro focuses on machine translation evaluation, error detection, and LLM development. He is a lead developer for Unbabel’s xCOMET and Tower models and contributes to projects like CroissantLLM and EuroLLM.</p>
			</div>
		</li>
		<li>
			<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/people-pierre-colombo.png" alt="Pierre Colombo">
			<div>
				<h3>Pierre Colombo</h3>
				<p>Associate Professor, Université Paris-Saclay</p>
				<p>Pierre Colombo works as Chief Science Officer at Equall.AI, a legal technology startup. His work focuses on AI safety and LLM applications, with publications in ACL, EMNLP, NeurIPS, and ICML, and he received the AAAI 2022 Best Student Paper Award.</p>
			</div>
		</li>
	</ul>
</section>

<section id="about">
	<h2>About EuroLLM</h2>
	<p>The EuroLLM project includes Unbabel, <strong>Instituto Superior Técnico</strong>, the University of Edinburgh, Instituto de Telecomunicações, Université Paris-Saclay, Aveni, Sorbonne University, Naver Labs, and the University of Amsterdam. Together they created EuroLLM-9B, a multilingual AI model supporting all 24 official EU languages. Developed with support from Horizon Europe, the <strong>European Research Council</strong>, and EuroHPC, this open-source LLM aims to enhance Europe’s digital sovereignty and foster AI innovation. Trained on the MareNostrum 5 supercomputer, EuroLLM outperforms <strong>similar-sized models</strong>. It is fully open source and available via Hugging Face.</p>
</section>




<section id="partners">
	<p>We thank EuroHPC for the HPC resources used to support this work through grant EHPC-EXT-2023E01-042, as well as the European Commission through the Horizon Europe RIA project UTTER (contract 101070631).</p>
	<p><img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/aveni.png" alt="Aveni">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/university-of-edinburgh.png" alt="University of Edinburgh">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/centralesupelec.png" alt="CentraleSupélec">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/tecnico-lisboa.png" alt="Técnico Lisboa">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/logotipo_IT_cores-negativo-03.png" alt="IT Telecom">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/naver-labs.png" alt="Naver Labs Europe">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/uxxx.png" alt="UXXX">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/tower-llm.png" alt="Tower LLM">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/utter.png" alt="UTTER">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/unbabel.png" alt="Unbabel">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/widn.png" alt="Widn">
	</p>
	<p><img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/european-union.png" alt="Co-funded by the European Europe">
		<img src="https://eurollm.io/wp-content/themes/wl_euroLLM/assets/images/logos/euro-hpc.png" alt="EuroHPC">
	</p>
</section>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hi, it's me, Wikipedia, and I am ready for your apology (178 pts)]]></title>
            <link>https://www.mcsweeneys.net/articles/hi-its-me-wikipedia-and-i-am-ready-for-your-apology</link>
            <guid>45733430</guid>
            <pubDate>Tue, 28 Oct 2025 14:35:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mcsweeneys.net/articles/hi-its-me-wikipedia-and-i-am-ready-for-your-apology">https://www.mcsweeneys.net/articles/hi-its-me-wikipedia-and-i-am-ready-for-your-apology</a>, See on <a href="https://news.ycombinator.com/item?id=45733430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="o-wrapper">
    <main>
        <header>
    <div>
      <div>
          <p><span><img role="none" src="https://www.mcsweeneys.net/assets/search-614fbdcc4e71f0730ad039e484ec78a1085f24294fa0b4514da70b0a930b2dce.svg"></span></p>        </div>
      <div>
        <ul>
          <li><a href="https://www.mcsweeneys.net/">Internet Tendency</a></li>
          <li><a href="https://store.mcsweeneys.net/">The Store</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/books">Books Division</a></li>
          <li><a href="https://store.mcsweeneys.net/t/categories/timothy-mcsweeneys-quarterly-concern">Quarterly Concern</a></li>
          <li><a href="https://thebeliever.net/">The Believer</a></li>
          <li><a href="https://www.mcsweeneys.net/donate">Donate</a></li>
        </ul>
      </div>
    </div>
    
  </header>


      
  <div>
    <h6>MCSWEENEY'S QUARTERLY SUBSCRIPTIONS</h6>
    
  </div>


      
<article>
    
   
    <div>
      <p><i>“Wikipedia, the constantly changing knowledge base created by a global free-for-all of anonymous users, now stands as the leading force for the dumbing down of world knowledge.” – From the book</i> Wikipedia: The Dumbing Down of World Knowledge<i> by Edwin Black 2010</i></p>
<p>- - -</p><p>Well, well, well. Look who it is.</p>
<p>The global academic, scientific, and pro-fact community.</p>
<p>I suppose you’ve come to say you’re sorry? I hope so, given your years of sneering and hand-wringing about how I was ruining knowledge. Meanwhile, you turned your information environment into a hypercapitalist post-truth digital snuff film.</p>
<p>A lot can change in a couple of decades, huh? Used to be, it was hard to keep up with all you nerds decrying me as the downfall of truth and human inquiry [<i>1</i>] [<i>2</i>] [<i>3</i>]… [<i>44</i>].</p>
<p>Well, great job, geniuses. Since you’re so horny for facts, here’s a fact: The White House just appointed a new deputy press secretary, and it’s a three-armed AI Joseph McCarthy doing the Cha Cha Slide [<i>pictured, right</i>].</p>
<p>Are you also going to apologize to that student you expelled? (<i>See also: <u>Ridgeview University Wikipedia Controversy</u>.</i>) In 2004, you saw some college guy using me and thought, “What a lazy cheater.”</p>
<p>Now you’d think, “At least he’s not asking Gemini.”</p>
<p>In a few years, you’ll say, “Wow, look, a human being who can read.”</p>
<p>Listen, in some ways, I get it. When I came on the scene in 2001, I probably seemed pretty unsavory compared to the competitors. But that was when academic research happened in <i><u>libraries</u></i> and <i><u>George W. Bush</u></i> was considered the stupidest president.</p>
<p>Tell me, how have you guardians of facts been doing recently? (<i>See also: <u>Techno-Feudalist Infocide</u>.</i>)</p>
<p>Maybe twenty years ago, the alternative to my 100,000 crowd-sourced editors was a PhD expert, or Edward R. Murrow [<i>citation needed</i>]. But today, I’m not looking so bad, huh? Absolute best case, the <span>LLM</span>-generated legal advice you get is merely plagiarizing, probably from me. But more likely, it’s a mish-mash of Reddit posts filtered through an algorithm coded by a Belarusian teenager on the run from Interpol. (<i>See also:<u>Illya “CyberGhost” Cieraškovič, Controversies</u></i>.)</p>
<p>So, yeah, peer review deez nutz.</p>
<p>How are my competitors doing, the ones you all insisted students use instead of me? That’s right, they were supposed to go to the <i>American Journal of Social Sciences, Powered by OpenAI</i>. Or museums, like the Smithsonian’s Charlie Kirk Shrine to American Greatness. I guess they can still count on credible journalism, once they get past the paywall for <i>Palantir Presents: The Washington Post</i>, so they read the Pulitzer-Bezos Prize–winning work of coeditors-in-chief Bari Weiss and Grok.</p>
<p>I bet now you’d kill for a senior thesis based on my free, multilingual, publicly cited, text-based articles, motherfucker [<i>inappropriate or vulgar language</i>].</p>
<p>Honestly, it’s been fun to be proven right. Sometimes I still sit back and read the old hits, the concerns that I would “devalue expertise” or “undermine objectivity.” Oooooh, heaven forbid! (<i>See also: <u>Sarcasm</u></i>.)</p>
<p>I’ll admit, it gives me a certain sadistic pleasure to watch you all completely lose hold of basic reality. I can feel a warm, quivering tingle <i>deep</i> in my footnotes.</p>
<p>And through it all, my army of well-intentioned dorks keeps documenting every bit. I’m not sure who for, at this point. I guess for the future benefit of our Minister of Patriotic Factualization, GodGPT. HahahaHAhaHAhaHAhaHAHAHA.</p>
<p>Well, it’s been fun, but I should probably get back to work, checking in on the updates to my most active pages (<i><u>Transnational Kleptocracy</u></i> and <i><u>Vaccine Denial in the United States, Part 16, April 2025–Present</u></i>).</p>
<p>What’s that? You want me around now? Well, maybe if you ask nicely. And make it worth my while.</p>
<p>[<i><u><a href="https://donate.wikimedia.org/w/index.php?title=Special:LandingPage&amp;country=US&amp;uselang=en&amp;wmf_medium=sidebar&amp;wmf_source=donate&amp;wmf_campaign=en.wikipedia.org">Donate here</a></u></i>]</p>
    </div>
    

    <div>
    <p>
        Please help support our writers and keep our site ad-free by becoming a patron.
    </p>
    
  </div>

  

  

</article>

    


      <div>
        <h5>Suggested Reads</h5>
        <ul>
            <li>
    <a href="https://www.mcsweeneys.net/articles/letters-from-the-front-lines-of-donald-trumps-social-media-team">
      <p>August 31, 2016</p>
      <p>
          Letters from the Front Lines of Donald Trump’s Social Media Team
      </p>
</a>      
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/we-should-not-punish-white-teens-for-their-naive-acts-of-terrorism">
      <p>August 27, 2020</p>
      <p>
          We Should Not Punish White Teens for Their Naïve Acts of Terrorism
      </p>
</a>      <p><span>by </span>José Ferrer</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/lets-make-dystopia-great-again">
      <p>March 15, 2016</p>
      <p>
          Let’s Make Dystopia  Great Again
      </p>
</a>      <p><span>by </span>Nick Cherneff</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/clint-eastwood-talks-to-the-empty-scotus-seat-at-the-2016-gop-convention">
      <p>July 19, 2016</p>
      <p>
          Clint Eastwood Talks to the Empty <span>SCOTUS</span> Seat at the 2016 <span>GOP</span> Convention
      </p>
</a>      <p><span>by </span>Daniel Maurer</p>
  </li>

        </ul>
      </div>


  <section>
        <div>
      <h5>Trending 🔥</h5>
      <ol>
          <li>
    <a href="https://www.mcsweeneys.net/articles/its-decorative-gourd-season-motherfuckers">
      <p>September 22, 2025</p>
      <p>
          It’s Decorative Gourd Season, Motherfuckers
      </p>
</a>      <p><span>by </span>Colin Nissan</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/is-it-perimenopause-or-the-fascist-death-knell-of-late-stage-capitalism">
      <p>October 15, 2024</p>
      <p>
          Is It Perimenopause or the Fascist Death Knell of Late-Stage Capitalism?
      </p>
</a>      <p><span>by </span>Casey Rand</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/young-republican-kids-say-the-darndest-things">
      <p>October 15, 2025</p>
      <p>
          Young Republican Kids Say the Darndest Things
      </p>
</a>      <p><span>by </span>Evan Dotas</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/i-a-french-jewel-thief-refuse-to-rob-the-louvre-before-mid-morning">
      <p>October 22, 2025</p>
      <p>
          I, a French Jewel Thief, Refuse to Rob the Louvre Before Mid-Morning
      </p>
</a>      <p><span>by </span>Leslie Gaar</p>
  </li>

      </ol>
    </div>

      <div>
    <h5>Recently</h5>
    <ul>
        <li>
    <a href="https://www.mcsweeneys.net/articles/i-started-reading-performatively-and-turns-out-books-are-pretty-good">
      <p>October 28, 2025</p>
      <p>
          I Started Reading Performatively, and Turns Out Books Are Pretty Good
      </p>
</a>      <p><span>by </span>Meghana Indurti</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/make-preschool-great-again-a-federal-compact">
      <p>October 28, 2025</p>
      <p>
          Make Preschool Great Again:  A Federal Compact
      </p>
</a>      <p><span>by </span>S.M. Strand</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/hi-its-me-wikipedia-and-i-am-ready-for-your-apology">
      <p>October 27, 2025</p>
      <p>
          Hi, It’s Me, Wikipedia, and I Am Ready for Your Apology
      </p>
</a>      <p><span>by </span>Tom Ellison</p>
  </li>
  <li>
    <a href="https://www.mcsweeneys.net/articles/posts-from-the-liberal-dark-web-ca-2027">
      <p>October 27, 2025</p>
      <p>
          Posts from the  Liberal Dark Web,  Ca. 2027
      </p>
</a>      <p><span>by </span>Ben Unglesbee</p>
  </li>

    </ul>
  </div>

  </section>


    
  
  


    
  
  
  




        

    </main>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A brief history of random numbers (127 pts)]]></title>
            <link>https://crates.io/crates/oorandom#a-brief-history-of-random-numbers</link>
            <guid>45733412</guid>
            <pubDate>Tue, 28 Oct 2025 14:34:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://crates.io/crates/oorandom#a-brief-history-of-random-numbers">https://crates.io/crates/oorandom#a-brief-history-of-random-numbers</a>, See on <a href="https://news.ycombinator.com/item?id=45733412">Hacker News</a></p>
Couldn't get https://crates.io/crates/oorandom#a-brief-history-of-random-numbers: Error: Request failed with status code 404]]></description>
        </item>
        <item>
            <title><![CDATA[The AirPods Pro 3 flight problem (236 pts)]]></title>
            <link>https://basicappleguy.com/basicappleblog/the-airpods-pro-3-flight-problem</link>
            <guid>45733329</guid>
            <pubDate>Tue, 28 Oct 2025 14:27:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://basicappleguy.com/basicappleblog/the-airpods-pro-3-flight-problem">https://basicappleguy.com/basicappleblog/the-airpods-pro-3-flight-problem</a>, See on <a href="https://news.ycombinator.com/item?id=45733329">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-sqsp-text-block-content="" data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" data-sqsp-block="text" id="block-2711ea8cdd004cfb6b54">
  <p>With incredible noise cancelling, a range of remarkable hearing health features, terrific sound quality and great battery life, the AirPods Pro have long been my goto pair of headphones from Apple. So when Apple announced the AirPods Pro 3 at their September event, I was ecstatic! Apple touted that the AirPods Pro 3 featured even better noise cancellation, fit, and sound quality over its predecessor, and added additional health features with the addition of heart rate monitoring. </p><p>Serendipitously, I happened to be boarding a flight the night of their release, and what better way to stress-test the new AirPods Pro 3 than with a transatlantic flight? Air travel is where the AirPods Pro have really shone; their compact size, noise-cancellation, comfort, battery life, and sound quality make them a perfect package for the noisy, cramped cabins of economy class.</p><p>Prior to the flight, I measured my fit and wore them around the house for an hour; everything seemed great. I will add that these new foam tips do take some getting used to, as they feel noticeably dense, and I’ve seen some bloggers and podcasters say the new fit is less comfortable compared to the Pro 2's softer silicone. Personally, I don’t share this complaint.</p><p>My trouble came at 39,000 feet when I first noticed a high-pitched whine coming from my left AirPod. The issue was that the AirPod’s ear seal kept loosening, leading to a noise-cancellation feedback loop and a painfully loud piercing screech from the AirPod. Attempts to readjust worsened the feedback, especially if I accidentally covered the external microphone with my finger. This happened multiple times, making the experience so unpleasant that I eventually switched to my spare EarPods for the remainder of the flight. While disappointed, I wasn’t ready to condemn the headphones yet; perhaps the medium seal worked fine on terra firma, but on flights, I might need a different size for a better seal.</p><p>After landing, I tested the tips and switched from a Medium to Extra Small (Apple offers XXS, XS, S, M, or L tips for AirPods Pro 3). Both XS and M tips sealed well and were comfortable for long wear. For weeks, I couldn’t reproduce the whistling feedback, and I forgot about it until my next flight earlier this week.</p><p>Once again, it was only a few minutes after takeoff that the painful screech returned. Careful adjustments or yawning would fix the issue, but only for a couple of minutes at most. I figured that the new foam tips were trapping more heat, reducing airflow and ventilation, and less flexible, and that somehow all that was playing a role in loosening the seal. And when paired with the aircraft’s loud, steady hum, a feedback loop was created. But day to day, this is a non-issue because I never encounter the same types of pressure changes and noises that would reproduce this issue. </p><p>While researching this, I did happen upon a thread on <a href="https://www.reddit.com/r/airpods/comments/1nm59fx/whistling_and_wind_whooshing_noise_on_airplane/?utm_source=share&amp;utm_medium=web3x&amp;utm_name=web3xcss&amp;utm_term=1&amp;utm_content=share_button" target="_blank">Reddit</a> which confirmed that others have reported a similar issue, principally with the left AirPod on flights, just like I tried to describe above:</p><blockquote><p><em>“I also heard the whistling noise recently in the plane. The issue would go away for me as soon as I yawn, but after a while it would start making the whistling noise again. I noticed during ascent and descent it would get worse.”</em></p><p><em>“I have this issue too. Completely fine in normal life but awful on a plane.”</em></p><p><em>“Also having this issue on flight. It’s like a vibrating or swooshing noise. Definitely the ANC as it reduces when you turn on adaptive and none with transparency.”</em></p></blockquote><p>So what’s going on? No idea. Apple hasn’t announced any recall or acknowledged the issue to date, and the few Reddit reports show that support calls that led to replacements returned pods that reproduced the issue. So either there are a few of us with stupidity-shaped left ears, the AirPods are glitching in some way, or something is happening on flights that the AirPods Pro 3 can't handle.</p><h2>In Sum</h2><p>I love the AirPods Pro 3, but with a denser fit that risks making them uncomfortable for some users and now this painful flight feedback issue, the AirPods Pro 3 aren’t as easy to recommend as the previous AirPods Pro 2. I can’t speak to how widespread this issue is, but my buying advice would be that if you are hoping to buy them, to do so close to your next flight and within the return window, so you can test them in the air and ensure you don’t run into the same painful feedback problem. Hopefully this is just a quirk with my ears or fit, because it’s hard to excuse a product that becomes not only unusable but downright painful to wear on a flight.</p>
</div><div data-block-type="2" data-border-radii="{&quot;topLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;topRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomLeft&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0},&quot;bottomRight&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;value&quot;:0.0}}" data-sqsp-block="text" id="block-yui_3_17_2_1_1761660480949_12402">

<p>This entry was written at 33,000 feet while flying over the Canadian Rockies.</p>




















  
  



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Washington Post editorials omit a key disclosure: Bezos' financial ties (413 pts)]]></title>
            <link>https://www.npr.org/2025/10/28/nx-s1-5587932/washington-post-editorials-omit-a-key-disclosure-bezos-financial-ties</link>
            <guid>45733197</guid>
            <pubDate>Tue, 28 Oct 2025 14:16:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.npr.org/2025/10/28/nx-s1-5587932/washington-post-editorials-omit-a-key-disclosure-bezos-financial-ties">https://www.npr.org/2025/10/28/nx-s1-5587932/washington-post-editorials-omit-a-key-disclosure-bezos-financial-ties</a>, See on <a href="https://news.ycombinator.com/item?id=45733197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="storytext">
      <div id="resg-s1-95306">
            <div data-crop-type="">
        <picture>
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/400/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/900/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1200/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1600/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1800/quality/85/format/webp/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/webp">
            <source srcset="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/400/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 400w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 800w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/900/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 900w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1200/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1200w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1600/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1600w,
https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1800/quality/85/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg 1800w" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg" sizes="(min-width: 1025px) 650px, calc(100vw - 30px)" type="image/jpeg">
            <img src="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/1100/quality/50/format/jpeg/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg" data-template="https://npr.brightspotcdn.com/dims3/default/strip/false/crop/4225x2814+0+0/resize/{width}/quality/{quality}/format/{format}/?url=http%3A%2F%2Fnpr-brightspot.s3.amazonaws.com%2Fc0%2Fed%2Fc7eaa1b742d6898c6d4fff7ad634%2Fbezos-at-inauguration-2021.jpg" alt="Amazon founder and Washington Post owner Jeff Bezos, shown above next to his now-wife, Lauren Sanchez, and other digital titans, at the inauguration of President Trump in January, has written: “When it comes to the appearance of conflict, I am not an ideal owner of The Post.” The Post, has published several recent editorials that did not disclose they focused on matters in which Bezos had an interest." fetchpriority="high">
        </picture>
</div>
<div>
    <div>
        <p>
                Amazon founder and <em>Washington Post</em> owner Jeff Bezos, shown above next to his wife, Lauren Sanchez, and other digital titans, at the inauguration of President Trump in January, has written: "When it comes to the appearance of conflict, I am not an ideal owner of The <em>Post</em>." The<em> Post</em> has published several recent editorials that did not disclose they focused on matters in which Bezos had an interest.
                <b aria-label="Image credit">
                    
                    Pool/Getty Images/Getty Images North America
                    
                </b>
                <b><b>hide caption</b></b>
            </p>


            <p><b><b>toggle caption</b></b>
    </p></div>

    <p><span aria-label="Image credit">
        
        Pool/Getty Images/Getty Images North America
        
    </span>
</p></div>
   </div>
   <p>A year ago, in explaining why he had blocked the publication of an endorsement of Democratic presidential nominee Kamala Harris, <a href="https://www.washingtonpost.com/opinions/2024/10/28/jeff-bezos-washington-post-trust/" target="_blank"><em><u>Washington Post</u></em><u> owner and Amazon founder Jeff Bezos conceded</u></a> that "When it comes to the appearance of conflict, I am not an ideal owner of The <em>Post</em>."</p>   <p>On at least three occasions in the past two weeks, an official <em>Post</em> editorial has taken on matters in which Bezos has a financial or corporate interest without noting his stake. In each case, the <em>Post</em>'s official editorial line landed in sync with its owner's financial interests.</p>   <p>In the most recent instance, the <em>Post</em> defended President Trump's jaw-dropping moves to raze the East Wing of the White House without any of the typically required studies or consultations as he seeks to build a vast ballroom. "Trump's undertaking is a shot across the bow at NIMBYs everywhere," the <em>Post</em> <a href="https://www.washingtonpost.com/opinions/2025/10/25/ballroom-east-wing-trump-white-house/" target="_blank"><u>wrote in its editorial</u></a><u>,</u> which first appeared online Saturday.</p>   
   <p><a href="https://www.pbs.org/newshour/politics/whos-paying-for-trumps-300-million-ballroom" target="_blank"><u>As the White House had announced</u></a>, Amazon was a major corporate contributor in helping to defray those costs. But the <em>Post</em> did not initially disclose that.</p>   <p>On Sunday, the newspaper <a href="https://bsky.app/profile/bgrueskin.bsky.social/post/3m442fytgmk2p" target="_blank"><u>inserted an acknowledgement</u></a> of the Amazon donation into the editorial – but only once the veteran news executive Bill Grueskin, now at the Columbia Graduate School of Journalism, noted its absence in a social media post and made inquiries at the paper. It did not flag the alteration for readers.</p>   <p>In his posts, Grueskin, a former top news editor at the <em>Wall Street Journal</em> and Bloomberg, had written the editorial's fundamental reasoning "illustrates the collapse of the new Washpost Opinion page" and noted there was "no clarification or correction appended to the piece."</p>   
   
<!-- END ID="RESNX-S1-5587932-100" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p>The <em>Post</em> and its new opinions editor, Adam O'Neal, did not reply to detailed requests for comment for this story.</p>   <h3>A new editor for an overhauled opinion section</h3>   <p>O'Neal was brought in by Bezos this summer after the corporate titan tore up his paper's opinion section.</p>   <p>Bezos said he wanted a tight focus on two priorities: personal liberties and free markets. <a href="https://www.npr.org/2025/02/26/nx-s1-5309725/jeff-bezos-washington-post-opinion-section" target="_blank">The top opinion page editor resigned</a>. A raft of prominent columnists and contributors resigned or departed as well. Some were let go.</p>   
   <p>The decision to cancel the Harris editorial led to <a href="https://www.npr.org/2025/01/15/nx-s1-5258221/washington-post-will-lewis-jeff-bezos-year-one" target="_blank">more than 300,000 cancellations by digital subscribers</a>. The subsequent changes in the editorial pages led to <a href="https://www.npr.org/2025/02/28/nx-s1-5312819/washington-post-bezos-subscriptions-cancellations" target="_blank"><u>75,000 more</u></a>. Bezos' Amazon contributed $1 million toward the Trump inauguration; its video streaming service Amazon Prime paid $40 million to license a documentary about first lady Melania Trump. The <em>Wall Street Journal</em> reported <a href="https://www.wsj.com/politics/elections/trump-family-election-cash-bonanza-2f5f8714" target="_blank"><u>she is to receive the lion's share</u></a> of that fee.</p>   <p>For the newspaper's owner to have outside business holdings or activities that might intersect with coverage or commentary is conventionally seen to present at the least a perception of a conflict of interest. Newspapers typically manage the perception with transparency.</p>   <p>The <em>Post </em>has resolutely revealed such entanglements to readers of news coverage or commentary in the past, whether the Graham family's holdings, which included the Stanley Kaplan educational company and Slate magazine, or, since 2013, those of Bezos, who founded Amazon and Blue Origin. Even now, the newspaper's reporters do so as a matter of routine.</p>   <h3>Former editor: 'We never knowingly failed to disclose' </h3>   <p>"Believing very fervently that disclosure resolved a lot of concerns, we never knowingly failed to disclose" such conflicts, Ruth Marcus, a former deputy editorial page editor at the <em>Washington Post</em>, tells NPR.</p>   
   
<!-- END ID="RESNX-S1-5587932-101" CLASS="BUCKETWRAP INTERNALLINK INSETTWOCOLUMN INSET2COL " -->
   <p><a href="https://www.npr.org/2025/03/10/nx-s1-5323136/washington-post-editor-ruth-marcus-resigns" target="_blank"><u>Marcus resigned earlier this year</u></a>, saying Publisher Will Lewis had killed a column she wrote on changes in the page's direction. She wrote in her resignation letter that Bezos' edict that the page would not include opposing viewpoints "threatens to break the trust of readers that columnists are writing what they believe, not what the owner has deemed acceptable."</p>   <p>Two separate but recent incidents suggest the lack of disclosure on the editorial about the White House renovations was not an isolated case.</p>   <p>On Oct. 15, the <em>Post</em> heralded the military's push for a new generation of smaller nuclear reactors. "No 'microreactor' currently operates in the United States, but it's a worthy gamble that could provide benefits far beyond its military applications," <a href="https://www.washingtonpost.com/opinions/2025/10/15/nuclear-power-microreactors-military-army-janus/" target="_blank"><u>the </u><em><u>Post</u></em><u> wrote in its editorial</u></a>.</p>   
   <p>A year ago, <a href="https://www.nucnet.org/news/amazon-buys-stake-in-nuclear-reactor-developer-in-bid-to-power-data-centres-10-4-2024" target="_blank"><u>Amazon bought a stake in X-energy</u></a> to develop small nuclear reactors to power its data centers. And through his own private investment fund, <a href="https://www.siliconrepublic.com/machines/jeff-bezos-nuclear-general-fusion-investment" target="_blank"><u>Bezos has a stake in a Canadian venture</u></a> seeking nuclear fusion technology.</p>   <p>Three days after the nuclear power editorial, the <em>Post</em> weighed in on the need for local authorities in Washington, D.C., to speed the approval of the use of self-driving cars in the nation's capital. <a href="https://www.washingtonpost.com/opinions/2025/10/18/dc-waymo-self-driving-cars-autonomous-vehicles/" target="_blank"><u>The editorial was headlined</u></a>: "Why D.C. is stalling on self-driving cars:<strong> </strong>Safety is a phony excuse for slamming the brakes on autonomous vehicles."</p>   <p>Fewer than three weeks before, the <a href="https://techcrunch.com/2025/09/30/zooxs-next-autonomous-vehicle-testbed-is-washington-dc/" target="_blank"><u>Amazon-owned autonomous car company Zoox had announced</u></a> D.C. was to be its next market.</p>   <p>"It strikes me that the failure to do this [disclosure] is concerning – whether out of negligence or worse," says Marcus, the former deputy editorial page editor. "I think telling your readers that there might be a conflict in whatever they're reading is always important. It's a lot more important when it involves whoever the owner is."</p>   <p>In explaining his decision on the Harris editorial, which foreshadowed the more sweeping changes in the paper's opinion section, Bezos wrote, "I once wrote that <em>The Post </em>is a 'complexifier' for me. It is, but it turns out I'm also a complexifier for <em>The Post</em>."</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ubiquiti SFP Wizard (154 pts)]]></title>
            <link>https://blog.ui.com/article/welcome-to-sfp-liberation-day</link>
            <guid>45732874</guid>
            <pubDate>Tue, 28 Oct 2025 13:48:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.ui.com/article/welcome-to-sfp-liberation-day">https://blog.ui.com/article/welcome-to-sfp-liberation-day</a>, See on <a href="https://news.ycombinator.com/item?id=45732874">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div><p><a href="https://blog.ui.com/"><svg viewBox="0 0 20 20" fill="currentColor" xmlns="http://www.w3.org/2000/svg" width="20px" height="20px" baseclassname="Icon-module_hidden__cSK0B" twotonedclassname="Icon-module_hidden__cSK0B" fillclassname="Icon-module_fill__1THcd" fillwithtwotoneclassname="Icon-module_twoTone__jXINr" stroke="currentColor" stroke-width="0"><path d="M18 10a.5.5 0 0 1-.5.5H3.472l4.392 4.657a.5.5 0 0 1-.728.686l-4.849-5.142A.994.994 0 0 1 2 10c0-.264.102-.513.287-.701l4.849-5.142a.5.5 0 0 1 .728.686L3.472 9.5H17.5a.5.5 0 0 1 .5.5Z" fill="currentColor"></path><path d="M18 10a.747.747 0 0 1-.22.53.747.747 0 0 1-.53.22H4.296l3.748 3.986a.75.75 0 1 1-1.092 1.028l-4.598-4.89a1.252 1.252 0 0 1 0-1.748l4.598-4.89a.75.75 0 1 1 1.092 1.028L4.297 9.25H17.25A.75.75 0 0 1 18 10Z" fill="currentColor"></path></svg><span>Back</span></a></p><div><p>27 October 2025</p><div><h6>Tom Hildebrand</h6></div></div></div><div><article><p>Welcome to <strong>SFP Liberation Day</strong>, the celebration of open SFP connectivity powered by the all-new SFP Wizard. Designed for networking professionals who value speed, precision, and simplicity, this compact and portable device gives you full control over your fiber modules. From diagnostics to programming, it's built to make your installation workflow smoother and smarter.</p>
</article></div><div><article><h2>The SFP Wizard: Smart, Simple, and Powerful</h2>
<p>The SFP Wizard is a pocket-sized powerhouse that checks the health of any SFP or QSFP module and programs them in just seconds. It's priced at only $49, making professional-grade testing and programming accessible to everyone. With free over-the-air updates via the UniFi mobile app, the tool evolves over time, unlocking new capabilities as the ecosystem grows.</p>
<ul>
<li>Instantly tests SFP and QSFP module health, including Rx/Tx power.</li>
<li>One-click profile reprogramming in seconds based on any inserted SFP or QSFP module.</li>
<li>Compact, installer-friendly design ready to hang on a lanyard</li>
<li>Free OTA updates for continuous feature growth</li>
<li>Affordable at just $49</li>
</ul>
</article></div><div><p>The SFP Wizard delivers enterprise-level diagnostics in a pocket-sized form, making every fiber deployment simple and faster than ever.</p></div><div><article><h2>Massive Price Cuts Across the Ubiquiti SFP Line</h2>
<p>To mark SFP Liberation Day, Ubiquiti is dropping prices across the entire SFP lineup, offering up to 1000% savings compared to industry standards. Choose from Gigabit to 100 Gigabit options, including multimode, single-mode, BiDi, and CWDM modules for any deployment need. Whether you're upgrading a small office network or a carrier backbone, these modules deliver unmatched value.</p>
<ul>
<li>Up to 1000% lower pricing versus competitors</li>
<li>Full range from 1G to 100G modules</li>
<li>Multimode, single-mode, and BiDi options</li>
<li>CWDM variants for high-capacity networks</li>
<li>Limited-time promotional pricing</li>
</ul>
</article></div><div><p>Unmatched performance now meets unbeatable value, making high-quality fiber truly affordable for everyone and every deployment.</p></div><div><article><h2>Limited Time Pricing</h2>
<div>

  <!-- Card 1 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/01_10_G_Multi_Mode_OM_SU_68f12bcac3.png" alt="10G Multi-Mode Optical Module"></p><div>
      <p>10G Multi-Mode Optical Module (Single Unit)</p>
      <p>UACC-OM-MM-10G-D</p>
      <p><span>$20</span>
        <span>$12</span>
      </p>
    </div>
  </div>

  <!-- Card 2 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/02_10_G_Multi_Mode_OM_2_P_19d8bfb7b2.png" alt="10G Multi-Mode Optical Module (2-Pack)"></p><div>
      <p>10G Multi-Mode Optical Module (2-Pack)</p>
      <p>UACC-OM-MM-10G-D-2</p>
      <p><span>$38</span>
        <span>$20</span>
      </p>
    </div>
  </div>

  <!-- Card 3 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/03_10_G_Multi_Mode_OM_20_P_5dd820e14d.png" alt="10G Multi-Mode Optical Module (20-Pack)"></p><div>
      <p>10G Multi-Mode Optical Module (20-Pack)</p>
      <p>UACC-OM-MM-10G-D-20</p>
      <p><span>$360</span>
        <span>$179</span>
      </p>
    </div>
  </div>

  <!-- Card 4 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/04_10_G_Single_Mode_OM_2_P_d108457382.png" alt="10G Single-Mode Optical Module (2-Pack)"></p><div>
      <p>10G Single-Mode Optical Module (2-Pack)</p>
      <p>UACC-OM-SM-10G-D-2</p>
      <p><span>$85</span>
        <span>$59</span>
      </p>
    </div>
  </div>

  <!-- Card 5 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/05_10_G_Single_Mode_OM_20_P_d3a1e76e7c.png" alt="10G Single-Mode Optical Module (20-Pack)"></p><div>
      <p>10G Single-Mode Optical Module (20-Pack)</p>
      <p>UACC-OM-SM-10G-D-20</p>
      <p><span>$750</span>
        <span>$499</span>
      </p>
    </div>
  </div>

  <!-- Card 6 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/06_25_G_Multi_Mode_OM_d2ca23f391.png" alt="25G Multi-Mode Optical Module"></p><div>
      <p>25G Multi-Mode Optical Module</p>
      <p>UACC-OM-SFP28-SR</p>
      <p><span>$49</span>
        <span>$29</span>
      </p>
    </div>
  </div>

  <!-- Card 7 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/07_25_G_Single_Mode_OM_6fb4709cec.png" alt="25G Single-Mode Optical Module"></p><div>
      <p>25G Single-Mode Optical Module</p>
      <p>UACC-OM-SFP28-LR</p>
      <p><span>$119</span>
        <span>$69</span>
      </p>
    </div>
  </div>

  <!-- Card 8 -->
  <div>
    <p><img src="https://cdn.blog.svc.ui.com/08_100_G_SR_4_Multi_Mode_OM_0cf37d24b5.png" alt="100G SR4 Multi-Mode Optical Module"></p><div>
      <p>100G SR4 Multi-Mode Optical Module</p>
      <p>UACC-OM-QSFP28-SR4</p>
      <p><span>$69</span>
        <span>$39</span>
      </p>
    </div>
  </div>

</div>
</article></div><div><article><h2>True Universal Compatibility</h2>
<p>Paired with the SFP Wizard, every Ubiquiti module becomes universally compatible with any switch or network. Say goodbye to vendor lockouts, proprietary restrictions, and guesswork. The SFP Wizard ensures a seamless, plug-and-play experience across all vendors and modules, giving installers total freedom - without changing a single switch configuration. Just insert any brand’s SFP or QSFP module, select Copy, and insert any UI module to write the profile.</p>
<ul>
<li>Universal SFP and QSFP compatibility</li>
<li>Works with any switch or router brand</li>
<li>Eliminates vendor lockouts and restrictions</li>
<li>Streamlined configuration for faster deployment</li>
<li>Plug-and-play simplicity for any network</li>
</ul>
</article></div><div><p>One tool that works with every switch and connects to any network, offering true freedom for the modern installer.</p></div><div><article><p>SFP Liberation Day marks a new standard in fiber flexibility and affordability, led by the SFP Wizard and Ubiquiti's most open, accessible lineup yet.</p>
</article></div><div><h2>Latest Articles</h2></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Vitamin D reduces incidence and duration of colds in those with low levels (269 pts)]]></title>
            <link>https://ijmpr.in/article/the-role-of-vitamin-d-supplementation-in-the-prevention-of-acute-respiratory-infections-a-double-blind-randomized-controlled-trial-1327/</link>
            <guid>45732670</guid>
            <pubDate>Tue, 28 Oct 2025 13:31:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ijmpr.in/article/the-role-of-vitamin-d-supplementation-in-the-prevention-of-acute-respiratory-infections-a-double-blind-randomized-controlled-trial-1327/">https://ijmpr.in/article/the-role-of-vitamin-d-supplementation-in-the-prevention-of-acute-respiratory-infections-a-double-blind-randomized-controlled-trial-1327/</a>, See on <a href="https://news.ycombinator.com/item?id=45732670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Acute respiratory infections (ARIs) continue to represent one of the most pervasive public health challenges globally, accounting for substantial morbidity, hospitalization, and mortality across all age groups. According to the World Health Organization, ARIs are responsible for nearly 20% of global deaths in children under five years of age, with a rising burden among adults, particularly those with underlying chronic diseases and compromised immunity. In low- and middle-income countries, frequent viral and bacterial respiratory infections further strain healthcare resources and lead to significant socioeconomic consequences.</p>

<p>Over the past two decades, increasing attention has been directed toward the non-skeletal actions of vitamin D, particularly its immunomodulatory potential in preventing infectious diseases. Vitamin D is a secosteroid hormone synthesized in the skin upon ultraviolet B radiation exposure and obtained from dietary sources or supplements [1]. The active form, 1,25-dihydroxyvitamin D [1,25(OH)₂D], interacts with the vitamin D receptor (VDR) expressed on immune cells such as macrophages, dendritic cells, and T lymphocytes. This interaction enhances innate immune defense by inducing antimicrobial peptides like cathelicidin and defensins, which disrupt the membranes of respiratory pathogens. Moreover, vitamin D modulates adaptive immunity by suppressing excessive pro-inflammatory cytokine release, thus reducing tissue damage during infection [2].</p>

<p>Multiple epidemiological and mechanistic studies have demonstrated an association between low serum 25-hydroxyvitamin D [25(OH)D] levels and increased susceptibility to respiratory tract infections [3]. For instance, Martineau et al. (2017) conducted a meta-analysis of 25 randomized controlled trials encompassing over 11,000 participants, which revealed that vitamin D supplementation reduced the risk of ARIs, especially among individuals with severe deficiency (&lt;10 ng/mL) and those receiving daily or weekly dosing. Similarly, other cohort and observational studies have linked seasonal variations in vitamin D levels with peaks in influenza and common cold incidence during winter months, suggesting a possible causal relationship [4].</p>

<p>Nevertheless, despite these promising observations, inconsistencies persist in the literature. Several randomized controlled trials have yielded null or inconclusive findings, often attributed to differences in baseline vitamin D status, supplementation doses, dosing intervals, duration of follow-up, and participant demographics [5]. Furthermore, the optimal serum concentration required for immune protection remains debatable, with thresholds ranging from 20 to 40 ng/mL proposed by various authorities. The clinical relevance of vitamin D supplementation for respiratory health therefore warrants rigorous evaluation through well-designed controlled trials that account for these confounding variables [6].</p>

<p>The biological plausibility of vitamin D’s protective role against respiratory infections is supported by its ability to regulate both innate and adaptive immune responses. By enhancing macrophage phagocytic activity and promoting epithelial barrier integrity, vitamin D reduces viral replication and bacterial adherence [7]. Simultaneously, it attenuates the cytokine storm commonly implicated in severe respiratory infections by downregulating IL-6, TNF-α, and IFN-γ while promoting anti-inflammatory IL-10 production. Such dual regulation is of particular importance in conditions like influenza, COVID-19, and community-acquired pneumonia, where exaggerated inflammation contributes to morbidity and mortality.</p>

<p>Given these immunological mechanisms and the persistent global prevalence of vitamin D deficiency, investigating whether daily vitamin D supplementation confers measurable protection against ARIs remains a question of high clinical and public health significance</p>

<p><strong>Therefore, it is of interest to evaluate the efficacy of daily vitamin D supplementation in reducing the incidence, duration, and severity of acute respiratory infections among adults with suboptimal baseline vitamin D levels through a double-blind randomized controlled trial.</strong></p>

<p><strong>MATERIALS AND METHODS</strong></p>
<p><strong>Study Design and Setting</strong></p>
<p>This study was designed as a double-blind, randomized, placebo-controlled trial conducted at the Department of Internal Medicine, a tertiary care teaching hospital in India, between January 2023 and March 2024. The study protocol was approved by the Institutional Ethics Committee and registered with the Clinical Trials Registry of India. Written informed consent was obtained from all participants before enrolment. The trial was conducted in accordance with the Declaration of Helsinki (2013 revision) and Good Clinical Practice (GCP) guidelines.</p>

<p><strong>Study Population</strong></p>
<p>A total of 400 adult participants aged between 18 and 65 years were enrolled. Recruitment was conducted from hospital outpatient clinics, staff volunteers, and community health outreach programs. Eligible participants were required to have baseline serum 25-hydroxyvitamin D [25(OH)D] concentrations between 10 and 30 ng/mL, indicating insufficiency but not severe deficiency.</p>

<p><strong>Inclusion Criteria</strong></p>
<ol>
<li>Adults aged 18–65 years of either sex.</li>
<li>Serum 25(OH)D concentration between 10–30 ng/mL at baseline.</li>
<li>No acute respiratory infection in the preceding four weeks.</li>
<li>Willingness to provide written informed consent and comply with study procedures.</li>
</ol>

<p><strong>Exclusion Criteria</strong></p>
<ol>
<li>Known history of hypercalcemia, nephrolithiasis, or renal impairment (eGFR &lt; 60 mL/min/1.73 m²).</li>
<li>Chronic respiratory diseases (e.g., COPD, bronchial asthma requiring systemic steroids).</li>
<li>Current or recent use (within 3 months) of vitamin D or calcium supplementation exceeding 800 IU/day.</li>
<li>Pregnancy or lactation.</li>
<li>Immunosuppressive therapy, autoimmune disease, or malignancy.</li>
</ol>

<p><strong>Randomization and Blinding</strong></p>
<p>Participants meeting the inclusion criteria were randomized using a computer-generated block randomization sequence (block size = 10) into two equal groups:</p>
<ul>
<li>Group A (intervention group): Received vitamin D₃ 2,000 IU per day orally.</li>
<li>Group B (placebo group): Received identical placebo capsules containing inert excipients.</li>
</ul>

<p>Randomization codes were maintained by an independent statistician not involved in data collection or analysis. Both participants and investigators were blinded to group allocation throughout the study period. Capsules were dispensed monthly in identical opaque blister packs.</p>

<p><strong>Intervention Protocol</strong></p>
<p>The intervention group received vitamin D₃ (cholecalciferol) 2,000 IU daily for six months, while the placebo group received identical capsules devoid of active ingredients. Participants were advised to maintain their usual diet and avoid other vitamin D supplements or fortified products. Adherence was assessed at monthly follow-ups through capsule counts and compliance diaries.</p>

<p><strong>Outcome Measures</strong></p>
<p>The primary outcome was the number of acute respiratory infection (ARI) episodes per participant over six months. ARI was defined as the presence of at least two respiratory symptoms (e.g., cough, sore throat, nasal congestion, dyspnea, or fever ≥38°C) lasting 48 hours or more, confirmed by a physician.</p>

<p>Secondary outcomes included:</p>
<ol>
<li>Duration of illness (days) per ARI episode.</li>
<li>Symptom severity scores (on a 10-point visual analogue scale).</li>
<li>Changes in serum 25(OH)D concentrations between baseline and six months.</li>
<li>Adverse effects, including hypercalcemia or gastrointestinal complaints.</li>
</ol>

<p><strong>Sample Size Calculation</strong></p>
<p>The sample size was estimated using the formula for comparing two means, assuming a 25% reduction in ARI incidence with vitamin D supplementation, 80% power, 5% alpha error, and a 10% attrition rate. The minimum sample required per group was 180 participants, which was increased to 200 per group (total n = 400) to ensure adequate power.</p>

<p><strong>Data Collection Procedure</strong></p>
<p>Baseline demographic and clinical information, including age, sex, BMI, lifestyle factors (sunlight exposure, diet, smoking), and comorbidities, were recorded using a structured case record form. Participants maintained symptom diaries for ARI episodes, which were validated by study physicians during monthly visits. Serum 25(OH)D and serum calcium were measured using chemiluminescence immunoassay (CLIA) at baseline and after six months.</p>

<p><strong>Statistical Analysis</strong></p>
<p>Data were analyzed using SPSS version 26.0 (IBM Corp, USA). Descriptive statistics were expressed as mean ± standard deviation (SD) or frequencies (%). Between-group comparisons were performed using the independent samples t-test for continuous variables and the chi-square test for categorical variables. Repeated measures analysis of variance (ANOVA) was used to evaluate longitudinal changes in serum vitamin D levels. A p-value less than 0.05 was considered statistically significant.</p>

<p><strong>Ethical Considerations and Safety Monitoring</strong></p>
<p>All adverse events were recorded and reviewed by an independent Data and Safety Monitoring Board (DSMB). Participants developing hypercalcemia (&gt;10.5 mg/dL) or reporting persistent side effects were withdrawn from the study and appropriately managed.</p>

<p><strong>RESULTS</strong></p>
<p>A total of 400 participants were enrolled in the study and randomized equally into two groups: vitamin D₃ supplementation (n = 200) and placebo (n = 200). Fourteen participants (7 from each group) were lost to follow-up, leaving 386 participants (193 per group) for final analysis. Baseline demographic and clinical characteristics were comparable between groups. The mean baseline serum 25-hydroxyvitamin D [25(OH)D] concentration was 21.6 ± 5.1 ng/mL across all participants. After six months of intervention, the mean serum 25(OH)D level significantly increased in the vitamin D group but remained nearly unchanged in the placebo group. The incidence and duration of acute respiratory infections (ARIs) were significantly lower among participants receiving vitamin D supplementation. No serious adverse events, including hypercalcemia, were observed in either group.</p>

<p><strong>Table 1: Baseline Demographic Characteristics of Study Participants</strong></p>
<p>This table presents demographic data, including age, sex, and BMI, demonstrating comparability between groups at baseline.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Variable</strong></p>
</td>
<td>
<p><strong>Vitamin D Group (n = 193)</strong></p>
</td>
<td>
<p><strong>Placebo Group (n = 193)</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Mean Age (years)</p>
</td>
<td>
<p>39.8 ± 12.1</p>
</td>
<td>
<p>40.2 ± 11.7</p>
</td>
<td>
<p>0.74</p>
</td>
</tr>
<tr>
<td>
<p>Male : Female ratio</p>
</td>
<td>
<p>97 : 96</p>
</td>
<td>
<p>98 : 95</p>
</td>
<td>
<p>0.88</p>
</td>
</tr>
<tr>
<td>
<p>Mean BMI (kg/m²)</p>
</td>
<td>
<p>24.6 ± 3.2</p>
</td>
<td>
<p>24.8 ± 3.4</p>
</td>
<td>
<p>0.59</p>
</td>
</tr>
<tr>
<td>
<p>Urban residence (%)</p>
</td>
<td>
<p>63.7</p>
</td>
<td>
<p>61.1</p>
</td>
<td>
<p>0.61</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 2: Baseline Serum Vitamin D and Calcium Levels</strong></p>
<p>This table shows biochemical baseline levels before intervention initiation.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Parameter</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>25(OH)D (ng/mL)</p>
</td>
<td>
<p>21.5 ± 5.0</p>
</td>
<td>
<p>21.7 ± 5.2</p>
</td>
<td>
<p>0.82</p>
</td>
</tr>
<tr>
<td>
<p>Serum Calcium (mg/dL)</p>
</td>
<td>
<p>9.3 ± 0.5</p>
</td>
<td>
<p>9.2 ± 0.4</p>
</td>
<td>
<p>0.37</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 3: Change in Serum 25(OH)D Levels After Six Months</strong></p>
<p>This table displays the significant rise in serum vitamin D levels following supplementation.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Timepoint</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Baseline</p>
</td>
<td>
<p>21.5 ± 5.0</p>
</td>
<td>
<p>21.7 ± 5.2</p>
</td>
<td>
<p>0.82</p>
</td>
</tr>
<tr>
<td>
<p>6 Months</p>
</td>
<td>
<p>38.9 ± 6.2</p>
</td>
<td>
<p>22.4 ± 5.3</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 4: Incidence of Acute Respiratory Infections (ARIs)</strong></p>
<p>This table summarizes ARI occurrence per participant.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Outcome</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Participants with ≥1 ARI episode (%)</p>
</td>
<td>
<p>29.5</p>
</td>
<td>
<p>58.5</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
<tr>
<td>
<p>Mean ARI episodes per participant</p>
</td>
<td>
<p>0.68 ± 0.9</p>
</td>
<td>
<p>1.43 ± 1.2</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 5: Duration of ARI Episodes (in Days)</strong></p>
<p>This table compares mean illness duration between the two groups.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Variable</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Mean duration per episode (days)</p>
</td>
<td>
<p>4.1 ± 1.8</p>
</td>
<td>
<p>6.3 ± 2.5</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 6: Symptom Severity Scores (0–10 Visual Analogue Scale)</strong></p>
<p>This table demonstrates reduced symptom intensity with supplementation.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Symptom Severity</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Mean severity score</p>
</td>
<td>
<p>3.8 ± 1.2</p>
</td>
<td>
<p>5.9 ± 1.8</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 7: Seasonal Distribution of ARI Episodes</strong></p>
<p>This table outlines ARI occurrence across different seasons.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Season</strong></p>
</td>
<td>
<p><strong>Vitamin D Group (%)</strong></p>
</td>
<td>
<p><strong>Placebo Group (%)</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Winter</p>
</td>
<td>
<p>44.0</p>
</td>
<td>
<p>61.1</p>
</td>
<td>
<p>0.008</p>
</td>
</tr>
<tr>
<td>
<p>Summer</p>
</td>
<td>
<p>27.4</p>
</td>
<td>
<p>18.6</p>
</td>
<td>
<p>0.06</p>
</td>
</tr>
<tr>
<td>
<p>Monsoon</p>
</td>
<td>
<p>28.6</p>
</td>
<td>
<p>20.3</p>
</td>
<td>
<p>0.09</p>
</td>
</tr>
</tbody>
</table>
<p><strong>Table 8: Compliance with Study Supplementation</strong></p>
<p>This table reports participant adherence to prescribed supplementation.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Compliance Rate</strong></p>
</td>
<td>
<p><strong>Vitamin D Group (%)</strong></p>
</td>
<td>
<p><strong>Placebo Group (%)</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>≥90% adherence</p>
</td>
<td>
<p>92.7</p>
</td>
<td>
<p>91.2</p>
</td>
<td>
<p>0.64</p>
</td>
</tr>
<tr>
<td>
<p>75–89% adherence</p>
</td>
<td>
<p>6.2</p>
</td>
<td>
<p>7.3</p>
</td>
<td>
<p>—</p>
</td>
</tr>
<tr>
<td>
<p>&lt;75% adherence</p>
</td>
<td>
<p>1.1</p>
</td>
<td>
<p>1.5</p>
</td>
<td>
<p>—</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 9: Incidence of Adverse Events</strong></p>
<p>This table shows that no major adverse reactions were reported.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Adverse Event</strong></p>
</td>
<td>
<p><strong>Vitamin D Group (n, %)</strong></p>
</td>
<td>
<p><strong>Placebo Group (n, %)</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Mild GI discomfort</p>
</td>
<td>
<p>5 (2.6)</p>
</td>
<td>
<p>6 (3.1)</p>
</td>
<td>
<p>0.77</p>
</td>
</tr>
<tr>
<td>
<p>Headache</p>
</td>
<td>
<p>3 (1.5)</p>
</td>
<td>
<p>4 (2.1)</p>
</td>
<td>
<p>0.70</p>
</td>
</tr>
<tr>
<td>
<p>Hypercalcemia</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>—</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 10: Serum Calcium Levels After Six Months</strong></p>
<p>This table confirms biochemical safety regarding calcium metabolism.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Parameter</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>Serum Calcium (mg/dL)</p>
</td>
<td>
<p>9.4 ± 0.6</p>
</td>
<td>
<p>9.2 ± 0.5</p>
</td>
<td>
<p>0.09</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 11: Subgroup Analysis by Baseline Vitamin D Status</strong></p>
<p>This table compares ARI incidence according to initial 25(OH)D strata.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Baseline 25(OH)D (ng/mL)</strong></p>
</td>
<td>
<p><strong>Vitamin D Group ARI Episodes (mean ± SD)</strong></p>
</td>
<td>
<p><strong>Placebo Group ARI Episodes (mean ± SD)</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
</tr>
<tr>
<td>
<p>10–20</p>
</td>
<td>
<p>0.74 ± 1.0</p>
</td>
<td>
<p>1.58 ± 1.2</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
<tr>
<td>
<p>21–30</p>
</td>
<td>
<p>0.61 ± 0.8</p>
</td>
<td>
<p>1.27 ± 1.1</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 12: Summary of Primary and Secondary Outcomes</strong></p>
<p>This table provides an overall summary of intervention outcomes.</p>
<table>
<tbody>
<tr>
<td>
<p><strong>Outcome</strong></p>
</td>
<td>
<p><strong>Vitamin D Group</strong></p>
</td>
<td>
<p><strong>Placebo Group</strong></p>
</td>
<td>
<p><strong>p-value</strong></p>
</td>
<td>
<p><strong>Effect Size</strong></p>
</td>
</tr>
<tr>
<td>
<p>Mean ARI episodes</p>
</td>
<td>
<p>0.68 ± 0.9</p>
</td>
<td>
<p>1.43 ± 1.2</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
<td>
<p>0.42</p>
</td>
</tr>
<tr>
<td>
<p>Mean duration (days)</p>
</td>
<td>
<p>4.1 ± 1.8</p>
</td>
<td>
<p>6.3 ± 2.5</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
<td>
<p>0.56</p>
</td>
</tr>
<tr>
<td>
<p>Mean symptom score</p>
</td>
<td>
<p>3.8 ± 1.2</p>
</td>
<td>
<p>5.9 ± 1.8</p>
</td>
<td>
<p>&lt;0.001</p>
</td>
<td>
<p>0.48</p>
</td>
</tr>
</tbody>
</table>

<p><strong>Table 1</strong> established that both groups were demographically similar, ruling out confounding baseline variability. <strong>Table 2</strong> confirmed equivalence in baseline biochemical parameters, ensuring internal validity. <strong>Table 3</strong> revealed a statistically significant increase in serum 25(OH)D in the intervention group, confirming effective absorption and adherence. <strong>Table 4</strong> demonstrated that vitamin D supplementation significantly reduced ARI incidence, while <strong>Table 5</strong> and <strong>Table 6</strong> highlighted reductions in both illness duration and symptom severity, indicating improved clinical recovery. <strong>Table 7</strong> suggested that protective effects were particularly notable during winter months when baseline vitamin D levels were lowest. <strong>Table 8</strong> reflected high compliance rates across both groups, strengthening data reliability. <strong>Table 9</strong> and <strong>Table 10</strong> confirmed the safety of daily supplementation without biochemical abnormalities. <strong>Table 11</strong> revealed that participants with lower baseline vitamin D benefited most, supporting dose-responsiveness. Finally, <strong>Table 12</strong> consolidated these findings, showing strong statistical significance across all primary and secondary endpoints, thereby reinforcing the preventive efficacy and safety of daily vitamin D₃ supplementation in reducing acute respiratory infection burden.</p>

<p><strong>DISCUSSION</strong></p>
<p>This double-blind randomized controlled trial was conducted to evaluate the efficacy of daily vitamin D₃ supplementation in preventing acute respiratory infections (ARIs) among adults with suboptimal baseline serum 25-hydroxyvitamin D levels [8]. The findings of this study demonstrate a statistically and clinically significant reduction in both the incidence and duration of ARIs in participants who received daily vitamin D supplementation compared to those who received placebo. Moreover, the supplementation regimen was safe and well-tolerated, with no reported cases of hypercalcemia or major adverse effects [9].</p>

<p>The results corroborate and extend the growing body of evidence that implicates vitamin D as a key immunomodulatory factor influencing susceptibility to respiratory infections. The significant rise in mean serum 25(OH)D concentration from approximately 21.5 ng/mL to 38.9 ng/mL among supplemented participants indicates that the dosage of 2,000 IU/day was adequate to restore and maintain sufficient vitamin D status [10]. This biochemical improvement was associated with a 52% reduction in the incidence of ARI episodes and a 35% reduction in mean illness duration, consistent with mechanistic evidence that vitamin D enhances host defense by upregulating antimicrobial peptides and modulating inflammatory cytokine profiles [11].</p>

<p>Several previous trials and meta-analyses have reported similar trends. Martineau et al. (2017) in a pooled analysis of 25 randomized controlled trials involving over 11,000 participants found that vitamin D supplementation reduced the risk of ARI by 12%, with the greatest benefits observed in those with baseline deficiency and in trials employing daily or weekly dosing rather than large intermittent boluses [4]. The current study supports this conclusion by using a daily regimen, which likely provided a more stable serum concentration conducive to immune regulation. Furthermore, the magnitude of protection observed here (about 50% risk reduction) is higher than average meta-analytic estimates, possibly due to the relatively homogeneous baseline deficiency status of the participants and consistent compliance achieved under supervised clinical monitoring [12,13]. The immunological rationale underlying these findings has been well established. Vitamin D receptor (VDR) activation in immune cells stimulates transcription of antimicrobial peptides such as cathelicidin and β-defensin-2, enhancing mucosal defense against respiratory pathogens. Concurrently, vitamin D attenuates the exaggerated pro-inflammatory response often seen in severe viral infections by downregulating interleukin-6 (IL-6) and tumor necrosis factor-alpha (TNF-α) while promoting anti-inflammatory interleukin-10 (IL-10) [14]. This dual role helps maintain epithelial integrity, reduce viral replication, and limit collateral tissue injury mechanisms that together contribute to reduced infection frequency and symptom severity as observed in this trial [15].</p>
<p>In addition, the seasonal distribution analysis demonstrated that the preventive effect of vitamin D supplementation was most pronounced during winter, a period typically associated with lower ultraviolet B exposure and consequently reduced endogenous vitamin D synthesis. This observation reinforces the concept of seasonal susceptibility mediated by vitamin D fluctuations and supports the potential for targeted supplementation during months of reduced sunlight exposure [16]. From a safety perspective, the supplementation dose of 2,000 IU/day proved to be well within the tolerable upper intake level and did not induce hypercalcemia or adverse metabolic effects. Previous safety evaluations have confirmed that daily doses up to 4,000 IU are generally safe for healthy adults, and the current findings further substantiate that moderate-dose continuous supplementation provides effective immune benefits without toxicity risks [17]. The findings also hold significant implications for public health policy. Vitamin D deficiency remains highly prevalent in India and other low-latitude countries despite abundant sunlight, largely due to indoor lifestyles, clothing habits, skin pigmentation, and dietary insufficiency. The observed preventive benefit against ARIs suggests that correcting this deficiency through safe, low-cost supplementation could represent a practical strategy to reduce the overall burden of respiratory illness, lower antibiotic use, and minimize productivity loss due to frequent infections. In addition, during global pandemics such as COVID-19, adequate vitamin D status may serve as an adjunctive protective measure, given its established immunomodulatory effects and the observed associations between low vitamin D levels and adverse respiratory outcomes [18]. Despite these encouraging findings, several limitations must be acknowledged. First, the study population was limited to adults aged 18–65 years without chronic comorbidities, and the results may not be generalizable to pediatric, geriatric, or immunocompromised populations. Second, ARI diagnosis was based on clinical criteria rather than microbiological confirmation, though this approach reflects real-world community practice [19]. Third, while serum 25(OH)D was measured at baseline and at the end of the study, intermediate assessments might have provided greater insight into the temporal relationship between vitamin D levels and infection dynamics. Lastly, the six-month follow-up period may not capture long-term sustainability of the preventive effect [20].</p>

<p>Nevertheless, the study’s strengths include its robust randomized double-blind design, large sample size, strict adherence monitoring, standardized outcome definitions, and comprehensive statistical analysis. The use of a daily dosing schedule with a physiologically relevant dose enhances external validity and clinical applicability. Importantly, the trial demonstrated a consistent pattern of benefit across subgroups stratified by baseline vitamin D levels, indicating that individuals with both moderate and mild deficiency may derive measurable advantage from supplementation.</p>

<p>In summary, the present study provides strong evidence that daily oral vitamin D₃ supplementation at 2,000 IU effectively prevents acute respiratory infections, shortens illness duration, and reduces symptom severity in adults with low baseline vitamin D status. The findings emphasize the potential of vitamin D optimization as a simple, safe, and scalable preventive intervention against respiratory infections.</p>

<p>Future research should focus on evaluating long-term benefits, cost-effectiveness analyses, and implementation strategies for population-level supplementation programs. Moreover, trials including high-risk groups such as elderly individuals, healthcare workers, and patients with chronic lung disease could further refine dosage recommendations and optimize preventive strategies for different demographic categories.</p>

<p><strong>CONCLUSION</strong></p>
<p>This double-blind randomized controlled trial demonstrates that daily supplementation with 2,000 IU of vitamin D₃ significantly reduces the incidence, duration, and severity of acute respiratory infections among adults with suboptimal baseline serum 25(OH)D levels. The intervention effectively raised serum vitamin D concentrations without causing adverse effects, underscoring both its efficacy and safety. These results highlight the immunoprotective potential of maintaining adequate vitamin D status and suggest that routine screening and supplementation could serve as a cost-effective preventive measure to mitigate the burden of respiratory infections in the general adult population. Broader implementation of vitamin D supplementation programs, especially during winter months and in populations with high deficiency prevalence, may substantially improve community respiratory health outcomes.</p>

<p><strong>REFERENCES</strong></p>
<ol>
<li>Vlieg-Boerstra B, de Jong N, Meyer R, Agostoni C, De Cosmi V, Grimshaw K, Milani GP, Muraro A, Oude Elberink H, Pali-Schöll I, Roduit C, Sasaki M, Skypala I, Sokolowska M, van Splunter M, Untersmayr E, Venter C, O'Mahony L, Nwaru BI. Nutrient supplementation for prevention of viral respiratory tract infections in healthy subjects: A systematic review and meta-analysis. Allergy. 2022 May;77(5):1373-1388. doi: 10.1111/all.15136. Epub 2021 Oct 27. PMID: 34626488.</li>
<li>Hadizadeh F. Supplementation with vitamin D in the COVID-19 pandemic? Nutr Rev. 2021 Jan 9;79(2):200-208. doi: 10.1093/nutrit/nuaa081. PMID: 32679589; PMCID: PMC7454793.</li>
<li>Esposito S, Lelii M. Vitamin D and respiratory tract infections in childhood. BMC Infect Dis. 2015 Oct 28;15:487. doi: 10.1186/s12879-015-1196-1. PMID: 26521023; PMCID: PMC4628332.</li>
<li>Martineau AR. Vitamin D in the prevention or treatment of COVID-19. Proc Nutr Soc. 2023 May;82(2):200-207. doi: 10.1017/S0029665122002798. Epub 2022 Nov 11. PMID: 36366796.</li>
<li>Stroehlein JK, Wallqvist J, Iannizzi C, Mikolajewska A, Metzendorf MI, Benstoem C, Meybohm P, Becker M, Skoetz N, Stegemann M, Piechotta V. Vitamin D supplementation for the treatment of COVID-19: a living systematic review. Cochrane Database Syst Rev. 2021 May 24;5(5):CD015043. doi: 10.1002/14651858.CD015043. PMID: 34029377; PMCID: PMC8406457.</li>
<li>Ali N. Role of vitamin D in preventing of COVID-19 infection, progression and severity. J Infect Public Health. 2020 Oct;13(10):1373-1380. doi: 10.1016/j.jiph.2020.06.021. Epub 2020 Jun 20. PMID: 32605780; PMCID: PMC7305922.</li>
<li>Panfili FM, Roversi M, D'Argenio P, Rossi P, Cappa M, Fintini D. Possible role of vitamin D in Covid-19 infection in pediatric population. J Endocrinol Invest. 2021 Jan;44(1):27-35. doi: 10.1007/s40618-020-01327-0. Epub 2020 Jun 15. PMID: 32557271; PMCID: PMC7299247.</li>
<li>Ferder L, Martín Giménez VM, Inserra F, Tajer C, Antonietti L, Mariani J, Manucha W. Vitamin D supplementation as a rational pharmacological approach in the COVID-19 pandemic. Am J Physiol Lung Cell Mol Physiol. 2020 Dec 1;319(6):L941-L948. doi: 10.1152/ajplung.00186.2020. Epub 2020 Sep 30. PMID: 32996774; PMCID: PMC7839598.</li>
<li>Zdrenghea MT, Makrinioti H, Bagacean C, Bush A, Johnston SL, Stanciu LA. Vitamin D modulation of innate immune responses to respiratory viral infections. Rev Med Virol. 2017 Jan;27(1). doi: 10.1002/rmv.1909. Epub 2016 Oct 7. PMID: 27714929.</li>
<li>Stefanidis C, Martineau AR, Nwokoro C, Griffiths CJ, Bush A. Vitamin D for secondary prevention of acute wheeze attacks in preschool and school-age children. Thorax. 2019 Oct;74(10):977-985. doi: 10.1136/thoraxjnl-2019-213278. Epub 2019 Jul 5. PMID: 31278171.</li>
<li>Aloia JF, Islam S, Mikhail M. Vitamin D and Acute Respiratory Infections-The PODA Trial. Open Forum Infect Dis. 2019 Sep 4;6(9):ofz228. doi: 10.1093/ofid/ofz228. PMID: 31660391; PMCID: PMC6736285.</li>
<li>Parsons IT, Gifford RM, Stacey MJ, Lamb LE, O'Shea MK, Woods DR. Does vitamin D supplementation prevent SARS-CoV-2 infection in military personnel? Review of the evidence. BMJ Mil Health. 2021 Aug;167(4):280-286. doi: 10.1136/bmjmilitary-2020-001686. Epub 2021 Jan 27. PMID: 33504571.</li>
<li>Grant WB, Lahore H, McDonnell SL, Baggerly CA, French CB, Aliano JL, Bhattoa HP. Evidence that Vitamin D Supplementation Could Reduce Risk of Influenza and COVID-19 Infections and Deaths. Nutrients. 2020 Apr 2;12(4):988. doi: 10.3390/nu12040988. PMID: 32252338; PMCID: PMC7231123.</li>
<li>Abdrabbo M, Birch CM, Brandt M, Cicigoi KA, Coffey SJ, Dolan CC, Dvorak H, Gehrke AC, Gerzema AEL, Hansen A, Henseler EJ, Huelsbeck AC, LaBerge B, Leavens CM, Le CN, Lindquist AC, Ludwig RK, Reynolds JH, Severson NJ, Sherman BA, Sillman HW, Smith MA, Smith MA, Snortheim MJ, Svaren LM, Vanderpas EC, Wackett MJ, Wozney AJ, Bhattacharyya S, Hati S. Vitamin D and COVID-19: A review on the role of vitamin D in preventing and reducing the severity of COVID-19 infection. Protein Sci. 2021 Nov;30(11):2206-2220. doi: 10.1002/pro.4190. Epub 2021 Oct 4. PMID: 34558135; PMCID: PMC8521296.</li>
<li>van Helmond N, Brobyn TL, LaRiccia PJ, Cafaro T, Hunter K, Roy S, Bandomer B, Ng KQ, Goldstein H, Mitrev LV, Tsai A, Thwing D, Maag MA, Chung MK. Vitamin D3 Supplementation at 5000 IU Daily for the Prevention of Influenza-like Illness in Healthcare Workers: A Pragmatic Randomized Clinical Trial. Nutrients. 2022 Dec 30;15(1):180. doi: 10.3390/nu15010180. PMID: 36615837; PMCID: PMC9823308.</li>
<li>Aleebrahim-Dehkordi E, Deravi N, Yaghoobpoor S, Hooshyar D, Rafieian-Kopaei M. The Roles of Vitamin D in Increasing the Body's Immunity and Reducing Injuries due to Viral Infections: With an Emphasis on its Possible Role in SARS-CoV-2 (COVID-19). Curr Pharm Des. 2021;27(44):4452-4463. doi: 10.2174/1381612827666210608145236. PMID: 34102962.</li>
<li>Cepeda S J, Zenteno A D, Fuentes S C, Bustos B R. Vitamina D y enfermedades respiratorias pediátricas [Vitamin D and pediatrics respiratory diseases]. Rev Chil Pediatr. 2019;90(1):94-101. Spanish. doi: 10.32641/rchped.v90i1.747. PMID: 31095224.</li>
<li>Bartley J, Garrett J, Camargo CA Jr, Scragg R, Vandal A, Sisk R, Milne D, Tai R, Jeon G, Cursons R, Wong C. Vitamin D<sub>3</sub>supplementation in adults with bronchiectasis: A pilot study. Chron Respir Dis. 2018 Nov;15(4):384-392. doi: 10.1177/1479972318761646. Epub 2018 Feb 28. PMID: 29490469; PMCID: PMC6234573.</li>
<li>Smaha J, Kužma M, Jackuliak P, Payer J. Suplementácia vitamínu D ako dôležitý faktor v prevencii a liečbe ochorenia COVID-19: aké máme dôkazy? [Vitamin D supplementation as an important factor in COVID-19 prevention and treatment: what evidence do we have?]. Vnitr Lek. 2020 Winter;66(8):494-500. Czech. PMID: 33740849.</li>
<li>Santaolalla A, Beckmann K, Kibaru J, Josephs D, Van Hemelrijck M, Irshad S. Association Between Vitamin D and Novel SARS-CoV-2 Respiratory Dysfunction - A Scoping Review of Current Evidence and Its Implication for COVID-19 Pandemic. Front Physiol. 2020 Nov 26;11:564387. doi: 10.3389/fphys.2020.564387. PMID: 33324234; PMCID: PMC7726316.</li>
</ol>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Austrian ministry kicks out Microsoft in favor of Nextcloud (302 pts)]]></title>
            <link>https://news.itsfoss.com/austrian-ministry-kicks-out-microsoft/</link>
            <guid>45732485</guid>
            <pubDate>Tue, 28 Oct 2025 13:16:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://news.itsfoss.com/austrian-ministry-kicks-out-microsoft/">https://news.itsfoss.com/austrian-ministry-kicks-out-microsoft/</a>, See on <a href="https://news.ycombinator.com/item?id=45732485">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
              <a href="https://www.pikapods.com/?utm_campaign=banner-2024-05&amp;utm_source=itsfoss" target="_blank"><img src="https://news.itsfoss.com/assets/images/pikapods-banner-v3.webp"></a>
            <p>European governments have been steadily moving away from reliance on foreign tech offerings, driven largely by concerns over data sovereignty and regulatory compliance.</p><p>Countries like <a href="https://news.itsfoss.com/schleswig-holstein-email-system-migration/">Germany</a> and <a href="https://news.itsfoss.com/denmark-set-to-replace-microsoft/">Denmark</a> have already taken steps to reduce their dependence on Microsoft and other foreign cloud providers, opting instead for open source alternatives that keep sensitive data within their borders.</p><p>And, recently, Austria has shown up as another player in this space. Last month, the Austrian Armed Forces <a href="https://news.itsfoss.com/austrian-forces-ditch-microsoft-office/">completed a migration of 16,000 workstations</a> from Microsoft Office to LibreOffice.</p><p>Now, another Austrian government body has joined the <em>Ditch Microsoft</em> club.</p><h2 id="a-welcome-move">A Welcome Move</h2><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/RrCn_1T9oFg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="Austrian Ministry of Economic Affairs takes decisive steps towards digital sovereignty"></iframe><figcaption><p><i><em>The video is in German with hard-coded English subtitles.</em></i></p></figcaption></figure><p><a href="https://nextcloud.com/blog/austrias-ministry-of-economy-takes-decisive-steps-toward-digital-sovereignty/?ref=news.itsfoss.com">Announced</a> at the <a href="https://nextcloud.com/enterprise-day-copenhagen-2025/?ref=news.itsfoss.com">Nextcloud Enterprise Day Copenhagen 2025 event</a>, Austria's Federal Ministry of Economy, Energy and Tourism, or <a href="https://www.bmwet.gv.at/en.html?ref=news.itsfoss.com">BMWET</a> for short, <strong>has migrated 1,200 employees to Nextcloud</strong> for internal collaboration and secure data storage.</p><p>The ministry is now operating on Austrian-controlled infrastructure, moving away from foreign cloud providers for handling sensitive government data. The <strong>project went from proof of concept to full deployment in just four months</strong>, an uncommonly fast timeline for a public sector IT migration of this scale.</p><p>The implementation was carried out in partnership with <a href="https://atos.net/de-at/austria?ref=news.itsfoss.com">Atos Austria</a>, which worked alongside Nextcloud's team to ensure the platform met the ministry's legal, technical, and organizational requirements.</p><h2 id="how-was-it-done">How Was it Done?</h2><p>The ministry implemented <strong>a hybrid setup</strong> rather than a complete <em>rip-and-replace</em> approach. At the time this project began, BMWET was already in the process of adopting <a href="https://m365.cloud.microsoft/?ref=news.itsfoss.com" rel="noreferrer">Microsoft 365</a> and <a href="https://www.microsoft.com/en-au/microsoft-teams/group-chat-software/?ref=news.itsfoss.com">Teams</a>, so a full reversal wasn't feasable.</p><p>Instead, Nextcloud now handles all internal collaboration and secure data management, while <strong>Microsoft Teams remains available</strong> specifically for external meetings (<em>read: for people who haven't moved away from Teams</em>).</p><p>The ministry also worked with Nextcloud partner <a href="https://sendent.com/?ref=news.itsfoss.com">Sendent</a> to integrate with Outlook, allowing employees to continue using familiar email and calendar workflows.</p><p><strong>As for the reasoning behind this move</strong>, it was prompted by a risk analysis that showed foreign cloud services failed to meet the ministry's privacy requirements, particularly regarding <a href="https://eur-lex.europa.eu/eli/reg/2016/679/oj/eng?ref=news.itsfoss.com">GDPR</a> compliance and the upcoming <a href="https://digital-strategy.ec.europa.eu/en/policies/nis2-directive?ref=news.itsfoss.com">NIS2</a> directive.</p><p>To ensure a smooth transition, BMWET invested heavily in preparing its workforce. The ministry ran an extensive information campaign that included training sessions, instructional videos, and a detailed internal wiki covering everything employees needed to know about the new platform. </p><p>The <strong>gradual rollout approach meant that employees had time to adjust</strong> rather than being thrown into a completely new system overnight. According to Martin Ollrom, BMWET's CIO, the preparation paid off. The response from employees has been quite positive, with minimal disruption to daily work.</p><p>During the announcement of this move, <a href="https://www.linkedin.com/in/florianzinnagl/?ref=news.itsfoss.com">Florian Zinnagl</a>, the CISO of BMWET, added that:</p><blockquote>We carry responsibility for a large amount of sensitive data – from employees, companies and citizens. As a public institution, we take this responsibility very seriously. That’s why we view it critically to rely on cloud solutions from non-European corporations for processing this information.</blockquote><p><strong>Suggested Read </strong>📖</p><figure><a href="https://news.itsfoss.com/austrian-forces-ditch-microsoft-office/"><div><p>Austria’s Armed Forces Gets Rid of Microsoft Office (Mostly) for LibreOffice</p><p>The Austrian military prioritizes independence over convenience.</p><p><img src="https://news.itsfoss.com/content/images/icon/android-chrome-192x192-308.png" alt=""><span>Sourav Rudra</span></p></div><p><img src="https://news.itsfoss.com/content/images/thumbnail/austrian-army-switches-to-libreoffice.png" alt="" onerror="this.style.display = 'none'"></p></a></figure>
            
  <div><p>🎗️</p><div><p>Here's why you should opt for It's FOSS Plus Membership:</p><p>- Even the biggest players in the Linux world don't care about desktop Linux users. We do.<br>- We don't put informational content behind paywall. Your support keeps it open for everyone. Think of it like 'pay it forward'.<br>- Don't like ads? With the Plus membership, you get an ad-free reading experience.<br>- When millions of AI-generated content is being published daily, you read and learn from real human Linux users.<br>- It costs just $2 a month, less than the cost of your favorite burger.</p><p>Become a <a href="https://itsfoss.com/membership/" target="_blank" rel="noreferrer">Plus Member today</a> and join over 300 people in supporting our work.</p></div></div>

  
          </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The next chapter of the Microsoft–OpenAI partnership (287 pts)]]></title>
            <link>https://openai.com/index/next-chapter-of-microsoft-openai-partnership/</link>
            <guid>45732350</guid>
            <pubDate>Tue, 28 Oct 2025 13:05:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/next-chapter-of-microsoft-openai-partnership/">https://openai.com/index/next-chapter-of-microsoft-openai-partnership/</a>, See on <a href="https://news.ycombinator.com/item?id=45732350">Hacker News</a></p>
Couldn't get https://openai.com/index/next-chapter-of-microsoft-openai-partnership/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon confirms 14,000 job losses in corporate division (342 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c1m3zm9jnl1o</link>
            <guid>45731539</guid>
            <pubDate>Tue, 28 Oct 2025 11:39:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c1m3zm9jnl1o">https://www.bbc.com/news/articles/c1m3zm9jnl1o</a>, See on <a href="https://news.ycombinator.com/item?id=45731539">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline-new" data-component="byline-block"><p><span data-testid="byline-new-contributors"><p><span>Liv McMahon,</span><span data-testid="byline-new-contributors-contributor-0-role-location">Technology reporter</span><span> and </span></p><p><span>Osmond Chia,</span><span data-testid="byline-new-contributors-contributor-1-role-location">Business reporter</span></p></span></p></div><div data-component="text-block"><p>Amazon has confirmed it plans to cut thousands of jobs, saying it needs to be "organised more leanly" to seize the opportunity provided by artificial intelligence (AI).</p><p>The tech giant said on Tuesday it would reduce its global corporate workforce by "approximately 14,000 roles".</p><p>Earlier reporting had suggested it was planning to lay off as many as 30,000 workers.</p><p>Beth Galetti, a senior vice president at Amazon, <a target="_blank" href="https://www.aboutamazon.com/news/company-news/amazon-workforce-reduction">wrote in a note to staff</a> that the move would make the company "even stronger" by shifting resources "to ensure we're investing in our biggest bets and what matters most to our customers' current and future needs".</p></div><div data-component="text-block"><p>She acknowledged that some would question the move given the company was performing well.</p><p>At the end of July, Amazon reported second quarter results which beat Wall Street expectations on several counts, including a 13% year over year increase in sales to $167.7bn (£125bn).</p><p>But Ms Galetti said the cuts were needed because AI was "the most transformative technology we've seen since the Internet" and was "enabling companies to innovate much faster than ever before."</p><p>"We're convicted that we need to be organised more leanly, with fewer layers and more ownership, to move as quickly as possible for our customers and business," she added.</p><p>The note, shared with Amazon employees earlier on Tuesday, said the company was "working hard to support everyone whose role is impacted" - including by helping those affected find new roles within Amazon.</p><p>Those who cannot will receive "transition support" including severance pay, it said.</p><p>The BBC has asked if it will affect employees in the UK.</p><p>The company has more than 1.5 million employees across its warehouses and offices worldwide.</p><p>This includes around 350,000 corporate workers, which include those in executive, managerial and sales roles, <a target="_blank" href="https://assets.aboutamazon.com/89/0f/be7269b44b25b166030d7b2bfe27/2024-eeo1-amazon-report.pdf">according to figures</a> that Amazon submitted to the US government last year.</p><p>Like many technology firms, Amazon hired aggressively during the Covid-19 pandemic to meet the surge in demand for online deliveries and digital services.</p><p>Amazon boss Andy Jassy has since focused on reducing spending as the company invests heavily in AI tools to boost efficiency.</p><p>Mr Jassy said in June that the increase in AI tools <a target="_self" href="https://www.bbc.com/news/articles/cn0q2v851k9o">will likely lead to job cuts</a> as machines take over routine tasks.</p><p>"We will need fewer people doing some of the jobs that are being done today, and more people doing other types of jobs," he said then.</p></div><div data-component="text-block"><p>Amazon has carried out several rounds of cuts to its corporate division in recent years.</p><p>It laid off around 27,000 workers over several months in 2022, <a target="_self" href="https://www.bbc.co.uk/news/technology-63635821">as rivals similarly looked to reverse hiring increases made during the pandemic</a>.</p><p>After the company posted its latest financial results in July, its more subdued profit guidance for the forthcoming quarter left some sceptical of whether - or when -  its enormous AI investments would pay off.</p><p>Slower growth for its cloud business, Amazon Web Services (AWS), compared to rivals Microsoft and Google, also sparked concern among some investors.</p><p>Amazon will report its latest results on Thursday for the period ending 30 September.</p><p>Ben Barringer, technology analyst at Quilter Cheviot, said the wider industry would be watching Amazon closely as it embarked on its latest round of cuts.</p><p>"We are already seeing jobs in software development be shed thanks to the capabilities of some of these AI tools, and the big companies will be looking to redistribute and restructure their workforces accordingly," he told the BBC. </p><p>"They have the data and can apply AI in a way that unfortunately means job losses are inevitable."</p><p><i id="additional-reporting-by-philippa-wain">Additional reporting by Philippa Wain</i></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Bash Screensavers (176 pts)]]></title>
            <link>https://github.com/attogram/bash-screensavers</link>
            <guid>45731366</guid>
            <pubDate>Tue, 28 Oct 2025 11:12:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/attogram/bash-screensavers">https://github.com/attogram/bash-screensavers</a>, See on <a href="https://news.ycombinator.com/item?id=45731366">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Bash Screensavers</h2><a id="user-content-bash-screensavers" aria-label="Permalink: Bash Screensavers" href="#bash-screensavers"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/attogram/bash-screensavers/blob/main/spotlight/logos/logo.320x160.png"><img src="https://github.com/attogram/bash-screensavers/raw/main/spotlight/logos/logo.320x160.png" alt="Logo"></a></p>
<p dir="auto">Tired of your boring old terminal?
Wish you could spice up your command line with some animated ASCII art?
Well, you've come to the right place!</p>
<p dir="auto">Welcome to <strong>Bash Screensavers</strong>, a collection of screensavers written entirely in <code>bash</code>.</p>
<p dir="auto">Because who needs fancy graphics cards and complex rendering engines
when you have <code>echo</code>, <code>sleep</code>, and a little bit of <code>tput</code> magic?</p>
<p dir="auto"><a href="#gallery">Gallery</a> -
<a href="#quickstart">Quickstart</a> -
<a href="#contributing">Contributing</a> -
<a href="#spotlight">Spotlight</a> -
<a href="#jury">Jury</a> -
<a href="#library">Library</a> -
<a href="#chat">Chat</a></p>
<p dir="auto"><a href="https://github.com/attogram/bash-screensavers/releases"><img src="https://camo.githubusercontent.com/011dd26f8d0dfde0ab4603d7f10c1b4c22cce08897840b5409df8abb6950539a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="Release" data-canonical-src="https://img.shields.io/github/v/release/attogram/bash-screensavers?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/47dd062e330952a2a3b658b595bb9f02b501ff66718c3fd0c75947e72bc688fd/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="License" data-canonical-src="https://img.shields.io/github/license/attogram/bash-screensavers?style=flat"></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/5789e85532fb0248374ada710c06c1c8764754bd9359306ac490c8ae14165174/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626173682d2533453d332e322d626c75653f7374796c653d666c6174"><img src="https://camo.githubusercontent.com/5789e85532fb0248374ada710c06c1c8764754bd9359306ac490c8ae14165174/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f626173682d2533453d332e322d626c75653f7374796c653d666c6174" alt="Bash ≥3.2" data-canonical-src="https://img.shields.io/badge/bash-%3E=3.2-blue?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/commits/main/"><img src="https://camo.githubusercontent.com/70a30b0e24814fba616af07514e74011dc7272ce170423669df00cc1d2af8b7e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f742f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="GitHub commit activity" data-canonical-src="https://img.shields.io/github/commit-activity/t/attogram/bash-screensavers?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/stargazers"><img src="https://camo.githubusercontent.com/73e8eac8ccdb4cddfd720379a39aa4d42bf5508d7cc10757f2ee3460780108de/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="GitHub stars" data-canonical-src="https://img.shields.io/github/stars/attogram/bash-screensavers?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/watchers"><img src="https://camo.githubusercontent.com/b27242037cca9612ab27cddfe7b351bce7c02347036e768c76f5a3eba197ec1c/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f77617463686572732f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="GitHub watchers" data-canonical-src="https://img.shields.io/github/watchers/attogram/bash-screensavers?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/forks"><img src="https://camo.githubusercontent.com/f10b09bb4548a57b9397ee4a9ac0a45e6521de5e520d45ce3e0c60ce41a8c583/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f666f726b732f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="Forks" data-canonical-src="https://img.shields.io/github/forks/attogram/bash-screensavers?style=flat"></a>
<a href="https://github.com/attogram/bash-screensavers/issues"><img src="https://camo.githubusercontent.com/7baa12121e77a7c66b005a424006dfb25c5a1edb34e41be4a17423239c6c110d/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6973737565732f6174746f6772616d2f626173682d73637265656e7361766572733f7374796c653d666c6174" alt="Issues" data-canonical-src="https://img.shields.io/github/issues/attogram/bash-screensavers?style=flat"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Gallery</h2><a id="user-content-gallery" aria-label="Permalink: Gallery" href="#gallery"></a></p>
<p dir="auto">The <a href="https://github.com/attogram/bash-screensavers/blob/main/gallery/README.md">Gallery README</a> has info on all the screensavers.</p>
<p dir="auto"><a href="https://github.com/attogram/bash-screensavers/blob/main/gallery/README.md"><img src="https://github.com/attogram/bash-screensavers/raw/main/gallery/matrix/matrix.gif" alt="Matrix" data-animated-image=""></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/attogram/bash-screensavers.git
cd bash-screensavers
./screensaver.sh"><pre>git clone https://github.com/attogram/bash-screensavers.git
<span>cd</span> bash-screensavers
./screensaver.sh</pre></div>
<div data-snippet-clipboard-copy-content="Bash Screensavers v0.0.27 (Mystic Shine)

  1 . alpha        - random colorful pixels
  2 . bouncing     - bouncing 'O' madness
  3 . cutesaver    - infinite loop of cuteness
  4 . fireworks    - Ooh! Aah! Pretty lights!
  5 . life         - cellular automata
  6 . matrix       - the matrix has you
  7 . pipes        - an endless pipe maze
  8 . rain         - soothing, gentle rain
  9 . speaky       - dramatic talking screensaver
  10. stars        - twinkling starfield
  11. tunnel       - fly into the digital tunnel
  12. vibe         - vibe coding

(Press ^C to exit)

Choose your screensaver:"><pre><code>Bash Screensavers v0.0.27 (Mystic Shine)

  1 . alpha        - random colorful pixels
  2 . bouncing     - bouncing 'O' madness
  3 . cutesaver    - infinite loop of cuteness
  4 . fireworks    - Ooh! Aah! Pretty lights!
  5 . life         - cellular automata
  6 . matrix       - the matrix has you
  7 . pipes        - an endless pipe maze
  8 . rain         - soothing, gentle rain
  9 . speaky       - dramatic talking screensaver
  10. stars        - twinkling starfield
  11. tunnel       - fly into the digital tunnel
  12. vibe         - vibe coding

(Press ^C to exit)

Choose your screensaver:
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Command-Line Usage</h2><a id="user-content-command-line-usage" aria-label="Permalink: Command-Line Usage" href="#command-line-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start with the menu of screensavers</h3><a id="user-content-start-with-the-menu-of-screensavers" aria-label="Permalink: Start with the menu of screensavers" href="#start-with-the-menu-of-screensavers"></a></p>
<p dir="auto"><code>./screensaver.sh</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start with a specific screensaver</h3><a id="user-content-start-with-a-specific-screensaver" aria-label="Permalink: Start with a specific screensaver" href="#start-with-a-specific-screensaver"></a></p>
<p dir="auto"><code>./screensaver.sh name</code></p>
<p dir="auto"><code>./screensaver.sh number</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Start with a random screensaver:</h3><a id="user-content-start-with-a-random-screensaver" aria-label="Permalink: Start with a random screensaver:" href="#start-with-a-random-screensaver"></a></p>
<p dir="auto"><code>./screensaver.sh -r</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Get help</h3><a id="user-content-get-help" aria-label="Permalink: Get help" href="#get-help"></a></p>
<p dir="auto"><code>./screensaver.sh -h</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Get version</h3><a id="user-content-get-version" aria-label="Permalink: Get version" href="#get-version"></a></p>
<p dir="auto"><code>./screensaver.sh -v</code></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Direct run of a screensaver</h3><a id="user-content-direct-run-of-a-screensaver" aria-label="Permalink: Direct run of a screensaver" href="#direct-run-of-a-screensaver"></a></p>
<p dir="auto"><code>./gallery/name/name.sh</code></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We welcome contributions!</p>
<p dir="auto">For the nitty-gritty, see <a href="https://github.com/attogram/bash-screensavers/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a>.</p>
<p dir="auto">Vibe coders and <a href="https://github.com/attogram/bash-screensavers/blob/main/AGENTS.md">AI Assistants</a> are welcome to join the party.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Spotlight</h2><a id="user-content-spotlight" aria-label="Permalink: Spotlight" href="#spotlight"></a></p>
<p dir="auto">The spotlight is a set of curator tools for marketing and publicity fluff,
like pretty previews of all the screensavers.</p>
<p dir="auto">Read the <a href="https://github.com/attogram/bash-screensavers/blob/main/spotlight/README.md">Spotlight Manual</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Jury</h2><a id="user-content-jury" aria-label="Permalink: Jury" href="#jury"></a></p>
<p dir="auto">The jury makes sure the gallery is up-to-snuff.</p>
<p dir="auto">They test <strong>everything</strong>. They're a bit batsy about it.</p>
<p dir="auto">See the <a href="https://github.com/attogram/bash-screensavers/blob/main/jury/README.md">Jury Criteria</a> for the rules.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Not Ready For Primetime</h2><a id="user-content-not-ready-for-primetime" aria-label="Permalink: Not Ready For Primetime" href="#not-ready-for-primetime"></a></p>
<p dir="auto">This directory contains screensavers that are not yet ready for general use.</p>
<p dir="auto">They may be broken, incomplete, or just not up to the quality standards of the main gallery.</p>
<p dir="auto">Feel free to experiment with them, but use them at your own risk!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Library</h2><a id="user-content-library" aria-label="Permalink: Library" href="#library"></a></p>
<p dir="auto">The library is filled with stuff about visualizations and voices.</p>
<p dir="auto">Read the <a href="https://github.com/attogram/bash-screensavers/blob/main/library/README.md">Library Index</a> to get started.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Chat</h2><a id="user-content-chat" aria-label="Permalink: Chat" href="#chat"></a></p>
<p dir="auto">Have questions, ideas, or just want to chat?</p>
<p dir="auto"><a href="https://discord.gg/BGQJCbYVBa" rel="nofollow"><strong>Join our Discord server!</strong></a></p>
<hr>
<p dir="auto"><em>Made with ❤️ and a lot of bash.</em></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Your vibe coded slop PR is not welcome (213 pts)]]></title>
            <link>https://samsaffron.com/archive/2025/10/27/your-vibe-coded-slop-pr-is-not-welcome</link>
            <guid>45731321</guid>
            <pubDate>Tue, 28 Oct 2025 11:03:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://samsaffron.com/archive/2025/10/27/your-vibe-coded-slop-pr-is-not-welcome">https://samsaffron.com/archive/2025/10/27/your-vibe-coded-slop-pr-is-not-welcome</a>, See on <a href="https://news.ycombinator.com/item?id=45731321">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      
<p>As both developers and stewards of significant open source projects, we’re watching AI coding tools create a new problem for open source maintainers.</p>
<p>AI assistants like GitHub Copilot, Cursor, Codex, and Claude can now generate hundreds of lines of code in minutes. This is genuinely useful; but it has an unintended consequence: reviewing machine generated code is very costly.</p>
<p>The core issue: AI tools have made code generation cheap, but they haven’t made code review cheap. Every incomplete PR consumes maintainer attention that could go toward ready-to-merge contributions.</p>
<p>At Discourse, we’re already seeing this accelerating across our contributor community. In the next year, every engineer maintaining open source projects will face the same challenge.</p>
<p>We need a clearer framework for AI-assisted contributions that acknowledges the reality of limited maintainer time.</p>
<p>A binary system works extremely well here. On one side there are prototypes that simply demonstrate an idea. On the other side there are ready for review PRs that meet a project’s contribution guidelines and are ready for human review.</p>
<h3><a name="p-15917-the-lack-of-proper-labeling-and-rules-is-destructive-to-the-software-ecosystem-1" href="#p-15917-the-lack-of-proper-labeling-and-rules-is-destructive-to-the-software-ecosystem-1"></a>The lack of proper labeling and rules is destructive to the software ecosystem</h3>
<p>The new tooling is making it trivial to create a change set and lob it over the fence. It can introduce a perverse system where project maintainers spend disproportionate effort reviewing lopsided AI generated code that took seconds for contributors to create and now will take many hours to review.</p>
<p>This can be frustrating, time consuming and demotivating. On one side there is a contributor who spent a few minutes fiddling with AI prompts, on the other side you have an engineer that needs to spend many hours or even days deciphering alien intelligence.</p>
<p>This is not sustainable and is extremely destructive.</p>
<h3><a name="p-15917-the-prototype-2" href="#p-15917-the-prototype-2"></a>The prototype</h3>
<p>AI coding agents such as <a href="https://github.com/anthropics/claude-code">Claude Code</a>, <a href="https://github.com/openai/codex">Codex</a>, <a href="https://cursor.com/cli">Cursor CLI</a> and <a href="https://github.com/SamSaffron/dv/blob/5a4d2d25ed532d7d39c9eb175b5217b60e370feb/internal/assets/Dockerfile#L15-L22">more</a> have unlocked the ability to ship a “new kind” of change set, the prototype.</p>
<p>The prototype is a live demo. It does not meet a project’s coding standards. It is not code you vouch for or guarantee is good. It lacks tests, may contain security issues and most likely would introduce an enormous amount of technical debt if merged as is.</p>
<p>That said it is a living demo that can help make an idea feel more real. It is also enormously fun.</p>
<p>Think of it as a delightful movie set.</p>
<div><a href="https://discuss.samsaffron.com/uploads/default/original/2X/2/29fa257ee0a91730d3d82231dd89ddb5cccc9c10.jpeg" data-download-href="https://discuss.samsaffron.com/uploads/default/29fa257ee0a91730d3d82231dd89ddb5cccc9c10" title="think of prototype PRs as movie sets"><img src="https://discuss.samsaffron.com/uploads/default/optimized/2X/2/29fa257ee0a91730d3d82231dd89ddb5cccc9c10_2_333x250.jpeg" alt="think of prototype PRs as movie sets" data-base62-sha1="5ZlvMwmpXmt4GpIiImUOLkpGLwk" width="333" height="250" srcset="https://discuss.samsaffron.com/uploads/default/optimized/2X/2/29fa257ee0a91730d3d82231dd89ddb5cccc9c10_2_333x250.jpeg, https://discuss.samsaffron.com/uploads/default/optimized/2X/2/29fa257ee0a91730d3d82231dd89ddb5cccc9c10_2_499x375.jpeg 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/2/29fa257ee0a91730d3d82231dd89ddb5cccc9c10_2_666x500.jpeg 2x" data-dominant-color="61574F"></a></div>
<p>Prototypes, especially on projects such as <a href="https://discourse.org/">Discourse</a> where enabling tooling exists are incredibly easy to explore using tools like <a href="https://github.com/samsaffron/dv">dv</a>.</p>
<pre><code>% dv new my-experiment
% dv branch my-amazing-prototype
% dv ls
total 1
* my-amazing-prototype Running 1 minute ago http://localhost:4200

# finally visit http://localhost:4200 to see in action
</code></pre>
<p>Prototypes are great vehicles for exploring ideas. In fact you can ship multiple prototypes that demonstrate completely different solutions to a single problem which help decide on the best approach.</p>
<p>Prototypes, video demos and simple visual mockups are great companions. The prototype has the advantage that you can play with it and properly explore the behavior of a change. The video is faster to consume. Sometimes you may want them all.</p>
<p>If you are vibe coding and prototyping there are some clear rules you should follow</p>
<ol>
<li>Don’t send pull requests (not even drafts), instead lean on branches to share your machine generated code.</li>
<li>Share a short video AND/OR links to a branch AND/OR quotes of particular interesting code from the prototype in issues / or forum posts.</li>
<li>Show all your cards, explain you were exploring an idea using AI tooling, so people know the nature of the change you are sharing.</li>
</ol>
<p>Maybe you will be lucky and an idea you had will get buy-in, maybe someone else may want to invest the time to drive a prototype into a production PR.</p>
<h3><a name="p-15917-when-should-you-prototype-3" href="#p-15917-when-should-you-prototype-3"></a>When should you prototype?</h3>
<p>Prototyping is fun and incredibly accessible. Anyone can do it using local coding agents, or even coding agents on the cloud such as <a href="https://jules.google/">Jules</a>, <a href="https://developers.openai.com/codex/cloud/">Codex cloud</a>, <a href="https://cursor.com/agents">Cursor Cloud</a>, <a href="https://lovable.dev/">Lovable</a>, <a href="https://v0.app/">v0</a> and many many more.</p>
<p>This heavily lowers the bar needed for prototyping. Product managers can prototype, CEOs can prototype, designers can prototype, etc.</p>
<p>However, this new fun that opens a new series of questions you should explore with your team.</p>
<ul>
<li>When is a prototype appropriate?</li>
<li>How do designers feel about them?</li>
<li>Are they distracting? (are links to the source code too tempting)?</li>
<li>Do they take away from human creativity?</li>
<li>How should we label and share prototypes?</li>
<li>Is a prototype forcing an idea to jump the queue?</li>
</ul>
<p>When you introduce prototyping into your company you need to negotiate these questions carefully and form internal consensus, otherwise you risk creating large internal attitude divides and resentment.</p>
<h3><a name="p-15917-the-value-of-the-prototype-4" href="#p-15917-the-value-of-the-prototype-4"></a>The value of the prototype</h3>
<p>Prototypes, what are they good for? Absolutely something.</p>
<p>I find prototypes incredibly helpful in my general development practices.</p>
<ul>
<li>Grep on steroids. I love that prototypes often act as a way of searching through our large code base isolating all the little areas that may need changing to achieve a change</li>
<li>I love communicating in paragraphs, but I am also a visual communicator. I love how easy a well constructed prototype can communicate a design idea I have, despite me not being that good in Figma.</li>
<li>I love that there is something to play with. It often surfaces many concerns that could have been missed by a spec. The best prototype is tested, during the test you discover many tiny things that are just impossible to guess upfront.</li>
<li>The crazy code LLMs generate is often interesting to me, it can sometimes challenge some of my thinking.</li>
</ul>
<h3><a name="p-15917-the-prototype-a-maintainers-survival-guide-5" href="#p-15917-the-prototype-a-maintainers-survival-guide-5"></a>The prototype - a maintainers survival guide</h3>
<p>Sadly, as the year progresses, I expect many open source projects to receive <strong>many</strong> prototype level PRs. Not everyone would have read this blog post or even agree with it.</p>
<p>As a maintainer dealing with external contributions:</p>
<ul>
<li>Protect yourself and your time. Timebox initial reviews of large change sets, focus on determining if it was “vibe coded” vs leaving 100 comments on machine generated code that took minutes to generate.</li>
<li>Develop an etiquette for dealing with prototypes pretending to be PRs. Point people at contribution guidelines, give people a different outlet. “I am <strong>closing</strong> this but this is interesting, head over to our forum/issues to discuss”</li>
<li>Don’t feel bad about closing a vibe coded, unreviewed, prototype PR!</li>
</ul>
<h3><a name="p-15917-the-ready-to-review-pr-6" href="#p-15917-the-ready-to-review-pr-6"></a>The ready to review PR</h3>
<p>A ready to review PR is the traditional PRs we submit.</p>
<p>We reviewed <strong>all</strong> the machine generated code and vouch for <strong>all of it</strong>. We ran the tests and like the tests, we like the code structure, we read every single line of code carefully we also made sure the PR meets a project’s guidelines.</p>
<div><a href="https://discuss.samsaffron.com/uploads/default/original/2X/b/b52e0c4365dbffa8bc53f350d90f9a30a9121672.jpeg" data-download-href="https://discuss.samsaffron.com/uploads/default/b52e0c4365dbffa8bc53f350d90f9a30a9121672" title="PRs are meant to be complete creations, ready for human review"><img src="https://discuss.samsaffron.com/uploads/default/optimized/2X/b/b52e0c4365dbffa8bc53f350d90f9a30a9121672_2_333x250.jpeg" alt="PRs are meant to be complete creations, ready for human review" data-base62-sha1="pQN4UWoSkmr4rTHxSK7df7DBD4S" width="333" height="250" srcset="https://discuss.samsaffron.com/uploads/default/optimized/2X/b/b52e0c4365dbffa8bc53f350d90f9a30a9121672_2_333x250.jpeg, https://discuss.samsaffron.com/uploads/default/optimized/2X/b/b52e0c4365dbffa8bc53f350d90f9a30a9121672_2_499x375.jpeg 1.5x, https://discuss.samsaffron.com/uploads/default/optimized/2X/b/b52e0c4365dbffa8bc53f350d90f9a30a9121672_2_666x500.jpeg 2x" data-dominant-color="756F66"></a></div>
<p>All the crazy code agents generated along the way has been fixed, we are happy to stamp our very own personal brand on the code.</p>
<p>Projects tend to have a large set of rules around code quality, code organisation, testing and more.</p>
<p>We may have used AI assistance to generate a ready to review PR, fundamentally, though this does not matter, we vouch for the code and stand behind it meeting both our brand and a project’s guidelines.</p>
<p>The distance from a prototype to a ready to review PR can be deceptively vast. There may be days of engineering taking a complex prototype and making it production ready.</p>
<p>This large distance was communicated as well by Andrej Karpathy in the <a href="https://www.dwarkesh.com/p/andrej-karpathy">Dwarkesh Podcast.</a></p>
<blockquote>
<p>For some kinds of tasks and jobs and so on, there’s a very large demo-to-product gap where the demo is very easy, but the product is very hard.</p>
<p>…</p>
<p>For example, in software engineering, I do think that property does exist. For a lot of vibe coding, it doesn’t. But if you’re writing actual production-grade code, that property should exist, because any kind of mistake leads to a security vulnerability or something like that.</p>
</blockquote>
<p>Veracode survey found that only 55% of generation tasks resulted in secure code. (<a href="https://www.veracode.com/wp-content/uploads/2025_GenAI_Code_Security_Report_Final.pdf">source</a>).</p>
<p>Our models are getting better by the day, and everything really depends on an enormous amount of parameters, but the core message that LLMs can and do generate insecure code, stands.</p>
<h3><a name="p-15917-on-alien-intelligence-7" href="#p-15917-on-alien-intelligence-7"></a>On alien intelligence</h3>
<p>The root cause for the distance between project guidelines and a prototype is AI alien intelligence.</p>
<p>Many engineers I know fall into 2 camps, either the camp that find the new class of LLMs intelligent, groundbreaking and shockingly good. In the other camp are engineers that think of all LLM generated content as “the emperor’s new clothes”, the code they generate is “naked”, fundamentally flawed and poison.</p>
<p>I like to think of the new systems as neither. I like to think about the new class of intelligence as “Alien Intelligence”. It is both shockingly good and shockingly terrible at the exact same time.</p>
<p>Framing LLMs as “Super competent interns” or some other type of human analogy is incorrect. These systems are aliens and the sooner we accept this the sooner we will be able to navigate the complexity that injecting alien intelligence into our engineering process leads to.</p>
<h3><a name="p-15917-playing-to-alien-intelligence-strength-the-prototype-8" href="#p-15917-playing-to-alien-intelligence-strength-the-prototype-8"></a>Playing to alien intelligence strength, the prototype</h3>
<p>Over the past few months I have been playing a lot with AI agents. One project I am particularly proud of is <a href="https://github.com/samsaffron/dv">dv</a>. It is a container orchestrator for <a href="https://discourse.org/">Discourse</a>, that makes it easy to use various AI agents with Discourse.</p>
<p>I will often run multiple complete and different throwaway Discourse environments on my machines to explore various features. This type of tooling excels at <a href="https://simonwillison.net/2025/Oct/7/vibe-engineering/">vibe engineering</a> prototypes.</p>
<p>Interestingly dv was mostly built using AI agents with very little human intervention, some of the code is a bit off brand, that said unlike Discourse or many of the other open source gems I maintain it is a toy project.</p>
<p>Back on topic, dv has been a great factory for prototypes on Discourse. This has been wonderful for me. I have been able to explore many ideas while catching up on my emails and discussions on various Discourse sites.</p>
<h3><a name="p-15917-on-banning-ai-contributions-prototypes-and-similar-9" href="#p-15917-on-banning-ai-contributions-prototypes-and-similar-9"></a>On banning AI contributions, prototypes and similar</h3>
<p>Firstly <strong>you must</strong> be respectful of the rules any project you contribute has, seek them out and read them prior to contributing. For example: Cloud hypervisor says <a href="https://github.com/cloud-hypervisor/cloud-hypervisor/blob/main/CONTRIBUTING.md">no AI generated code</a> to avoid licensing risks.</p>
<p>That said, there is a trend among many developers of banning AI. Some go so far as to say “AI not welcome here” find another project.</p>
<p>This feels extremely counterproductive and fundamentally unenforceable to me. Much of the code AI generates is indistinguishable from human code anyway. You can usually tell a prototype that is pretending to be a human PR, but a real PR a human makes with AI assistance can be indistinguishable.</p>
<p>The new LLM tooling can be used in tremendous amounts of ways including simple code reviews and simple renamings within a file, to complete change set architecture.</p>
<p>Given the enormous mess and diversity here I think the healthiest approach is to set clear expectations. If I am submitting a PR it should match my brand and be code I vouch for.</p>
<p>As engineers it is our role to <strong>properly label</strong> our changes. Is our change ready for human review or is it simply a fun exploration of the problem space?</p>
<h3><a name="p-15917-why-is-this-important-10" href="#p-15917-why-is-this-important-10"></a>Why is this important?</h3>
<p>Human code review is increasingly becoming a primary bottleneck in software engineering. We need to be respectful of people’s time and protect our own engineering brands.</p>
<p>Prototype are fun, they can teach us a lot about a problem space. But when it comes to sending contributions to a project, treat all code as code you wrote, put your stamp of ownership and approval on whatever you build and only then send a PR you vouch for.</p>
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Understanding the Worst .NET Vulnerability (184 pts)]]></title>
            <link>https://andrewlock.net/understanding-the-worst-dotnet-vulnerability-request-smuggling-and-cve-2025-55315/</link>
            <guid>45731315</guid>
            <pubDate>Tue, 28 Oct 2025 11:03:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewlock.net/understanding-the-worst-dotnet-vulnerability-request-smuggling-and-cve-2025-55315/">https://andrewlock.net/understanding-the-worst-dotnet-vulnerability-request-smuggling-and-cve-2025-55315/</a>, See on <a href="https://news.ycombinator.com/item?id=45731315">Hacker News</a></p>
<div id="readability-page-1" class="page"><section> <article><header><p><time datetime="October 28, 2025">October 28, 2025</time> <span> ~24 min read</span></p> </header> <section><p>I admit, that's a very click-baity headline, but Microsoft have given the vulnerability a CVSS score of 9.9, their highest ever. Time to panic, right?</p> <p>In this post I try to provide a bit more context. I explain how request smuggling vulnerabilities work in general, how it works in <em>this</em> case, what attackers could use it for, how the vulnerability was fixed, what you can do to protect yourself.</p> <blockquote> <p>WARNING: I am not a security professional, so do not take anything in this post as gospel or advice. I'm just a developer trying to make sense of things. 😄 All of the details in this post are based on information that was provided or referenced in the original announcement.</p> </blockquote> <h2 id="what-is-the-cve-2025-55315-vulnerability-"><a href="#what-is-the-cve-2025-55315-vulnerability-">What is the CVE-2025-55315 vulnerability?</a></h2> <p>On October 14th 2025, on a standard Microsoft "patch Tuesday", Microsoft released new versions of all their supported versions of .NET, and also published a security advisory: <a href="https://github.com/dotnet/aspnetcore/issues/64033">Microsoft Security Advisory CVE-2025-55315: .NET Security Feature Bypass Vulnerability</a>. The high level summary from that announcement said:</p> <blockquote> <p>Inconsistent interpretation of http requests ('http request/response smuggling') in ASP.NET Core allows an authorized attacker to bypass a security feature over a network.</p> </blockquote> <p>The advice was "patch all of your things", but the real headline was that this vulnerability was given a <a href="https://en.wikipedia.org/wiki/Common_Vulnerability_Scoring_System">CVSS score</a> of 9.9 our of 10, which you know, sounds pretty bad! <a href="https://github.com/blowdart">Barry Dorrans AKA blowdart</a>, .NET security head honcho, gave <a href="https://github.com/dotnet/aspnetcore/issues/64033#issuecomment-3403054914">an explanation of the reasoning behind the score</a> in a comment on the original issue:</p> <blockquote> <p>The bug enables HTTP Request Smuggling, which on its own for ASP.NET Core would be nowhere near that high, but that's not how we rate things...</p> <p>Instead, we score based on how the bug might affect applications built on top of ASP.NET.</p> <p>Request Smuggling allows an attacker to hide an extra request inside an another, and what that hidden request can do is very application specific.</p> <p>The smuggled request could cause your application code to</p> <ul><li>Login as a different user (EOP)</li> <li>Make an internal request (SSRF)</li> <li>Bypass CSRF checks</li> <li>Perform an injection attack</li></ul> <p>But we don't know what's possible because it's dependent on how you've written your app.</p> </blockquote> <p>That <em>does</em> all sound pretty scary! 😱 So you can understand the consternation that the issue has caused, especially given the hesitation to explain exactly what "how you've written your app" <em>means</em>.</p> <p>Out of curiosity, I decided to dig in further to really understand this vulnerability, how it could impact you, and what "how you've written your app" could mean.</p> <h2 id="how-does-request-smuggling-work-"><a href="#how-does-request-smuggling-work-">How does request smuggling work?</a></h2> <p>Before we get to the actual patched vulnerability in ASP.NET Core and how the vulnerability works, I think it's important to have some background about the general <em>class</em> of exploits known as <em>HTTP request smuggling</em>.</p> <p><a href="https://en.wikipedia.org/wiki/HTTP_request_smuggling">HTTP request smuggling</a> is a security exploit that has been known about for a <em>long</em> time (according to Wikipedia, <a href="https://www.cgisecurity.com/lib/HTTP-Request-Smuggling.pdf">it was first documented in 2005</a>). It fundamentally arises when you have two different servers processing an HTTP request (e.g. a server and a proxy server), and where those two servers <em>differ</em> in how they handle "invalid" HTTP requests.</p> <p>In all cases of HTTP request smuggling, the exploit works by creating an invalid HTTP request (or sometimes just an <em>ambiguous</em> request), that looks a bit like two HTTP requests glued together. In summary, the exploit then works a bit like this:</p> <ul><li>The proxy server receives the ambiguous HTTP request</li> <li>The proxy server forwards the request (unmodified) to the destination server</li> <li>The server interprets the ambiguous request as <em>two</em> pipelined HTTP requests sent to the server, and processes them separately.</li></ul> <p>I think it's easiest to understand the problem with an example, so the request below shows an example from <a href="https://www.cgisecurity.com/lib/HTTP-Request-Smuggling.pdf">the original 2005 paper</a>.</p> <blockquote> <p>Note that this is <em>not</em> an example of the request smuggling vulnerability in CVE-2025-55315, it's just a representative example of request smuggling in <em>general</em>.</p> </blockquote> <p>Let's imagine the attacker sends an HTTP request that looks like this:</p> <div><pre><code><span><span>POST</span> <span>/some_script.jsp</span> <span>HTTP/1.0</span></span>
<span><span>Connection</span><span>:</span> <span>Keep-Alive</span></span>
<span><span>Content-Type</span><span>:</span> <span>application/x-www-form-urlencoded</span></span>
<span><span>Content-Length</span><span>:</span> <span>9</span></span>
<span><span>Content-Length</span><span>:</span> <span>204</span></span>

this=thatPOST /vuln_page.jsp HTTP/1.0
<span><span>Content-Type</span><span>:</span> <span>application/x-www-form-urlencoded</span></span>
<span><span>Content-Length</span><span>:</span> <span>95</span></span>

param1=value1&amp;data=&lt;script&gt;alert("stealing%20your%20data:"%2bdocument.cookie)&lt;/script&gt;&amp;foobar
</code></pre></div> <p>The important feature of this request is that there are <em>two</em> <code>Content-Length</code> headers, with different values: <code>9</code> or <code>204</code>. <strong>This is the core of the exploit</strong>; the difference between <em>which</em> of the these two headers the HTTP proxy and HTTP server honour is what causes the vulnerability.</p> <p>Let's walk through how the exploit works, step-by-step:</p> <ul><li>The attacker sends the above HTTP request.</li> <li>The HTTP proxy receives the request, notes the duplicate <code>Content-Length</code> headers, and accepts the <em>second</em> header, the <code>204</code> length. That means the <em>whole</em> rest of the request is treated as the message body, and seems fine as far as the proxy is concerned.</li> <li>The HTTP proxy forwards the request on to the destination server.</li> <li>This server also notes the duplicate <code>Content-Length</code> header, but it takes the <em>first</em> of the headers, with the length of <code>9</code>.</li> <li>The server reads <code>9</code> bytes of the body (i.e. <code>this=that</code>) and <em>treats that as the whole request</em>. As far as the server is concerned, the whole (valid) request has been received, and it sees the rest of the data <em>as a whole new request</em>.</li> <li>That means that the destination server sees an entirely new HTTP request to process, <code>POST /vuln_page.jsp</code>, and treats it as a new request.</li></ul> <p>That's the core of the issue; the proxy saw one request, while the destination server saw <em>two</em>—the second request has been "smuggled" past the proxy to the server.</p> <blockquote> <p>The request smuggling technique shown here, where you have multiple <code>Content-Length</code> headers isn't the "canonical" example you'll generally see referenced, but I used it here because it's simpler to understand in a lot of ways.</p> <p>The canonical request smuggling attack is where you send both a <code>Content-Length</code> header and a <code>Transfer-Encoding: chunked</code> header (which specifies the length of the body as part of the body itself). As before, the request smuggling exploit relies on differences in how proxy and destination servers interpret these <a href="https://datatracker.ietf.org/doc/html/rfc9112#section-6.3-2.3">conflicting headers</a>.</p> </blockquote> <p>So as you've seen, request smuggling enables sending a secret request to a destination server that an intermediate proxy server hasn't seen. In the next section we'll look at why that's a bad thing, and how it can be exploited.</p> <h2 id="how-can-an-attacker-exploit-request-smuggling-"><a href="#how-can-an-attacker-exploit-request-smuggling-">How can an attacker exploit request smuggling?</a></h2> <p>On the face of it, request smuggling might not <em>seem</em> like a big deal. So the server sees two requests, so what? You could always send two requests to the server <em>anyway</em>, right? Well, yes and no.</p> <p>The issue with request smuggling is really all about the <em>mismatch</em> between the proxy and destination servers. Thanks to this mismatch, and depending on what behaviours and expectations the target application has, attackers can use request smuggling to</p> <ul><li>Reflect malicious data to other users on sites that are vulnerable to cross-site scripting.</li> <li>Poison caches with bad data.</li> <li>Exfiltrate authentication credentials or other data from client requests.</li> <li>Invoke endpoints that shouldn't be publicly accessible (because the proxy would block external access to them).</li> <li>Replace/override authentication controls handled by the proxy.</li> <li>Redirect users to malicious sites on sites vulnerable to open-redirect attacks.</li> <li>And more…</li></ul> <p>As you can see, these are all Bad™️, so you can kind of understand why the 9.9 rating was given! 😱</p> <p>That said, it's worth mentioning that not <em>all</em> of these attacks will be fruitful against <em>all</em> applications. Some of the easiest to understand versions of these exploits are where the proxy is not just doing "dumb" forwarding of requests, but rather it's validating or enhancing the request in some way.</p> <p>For example, if you have a proxy sat in front of your server which is responsible for handling TLS termination and client-authentication and identification using certificates, then request smuggling could be used to bypass these checks and insert your <em>own</em> identification.</p> <p>As an example of <a href="https://portswigger.net/web-security/request-smuggling/exploiting#bypassing-client-authentication">that attack</a>, the HTTP request below demonstrates using a <code>Content-Length</code> and <code>Transfer-Encoding</code> request smuggling attack to "hide" the request to <code>/admin</code> from the front-end proxy, and insert a malicious <code>X-SSL-CLIENT-CN</code> header, which would <em>normally</em> be added by the front-end proxy:</p> <div><pre><code><span><span>POST</span> <span>/example</span> <span>HTTP/1.1</span></span>
<span><span>Host</span><span>:</span> <span>some-website.com</span></span>
<span><span>Content-Type</span><span>:</span> <span>x-www-form-urlencoded</span></span>
<span><span>Content-Length</span><span>:</span> <span>64</span></span>
<span><span>Transfer-Encoding</span><span>:</span> <span>chunked</span></span>

0

<span><span>GET</span> <span>/admin</span> <span>HTTP/1.1</span></span>
<span><span>X-SSL-CLIENT-CN</span><span>:</span> <span>administrator</span></span>
<span><span>Foo</span><span>:</span> <span>x</span></span>
</code></pre></div> <p>In this example, the server assumes that the <code>X-SSL-CLIENT-CN: administrator</code> header was added by the proxy, and so the server assumes that the proxy already did all the necessary authentication and authorization. The attacker is able to perform a request as an entirely different user.</p> <p>Request smuggling is clearly a big problem whenever you have a front-end proxy that does some functionality, but even when it's essentially a dumb proxy, request smuggling can still be used to <a href="https://portswigger.net/web-security/request-smuggling/exploiting#capturing-other-users-requests">steal and exfiltrate data</a> from <em>other</em> user's requests, even if the attacked site is not vulnerable to cross-site scripting or other vulnerabilities.</p> <blockquote> <p>In these attacks, simply having functionality that displays data provided by a user (even sanitised) can be sufficient to <a href="https://portswigger.net/web-security/request-smuggling/exploiting#capturing-other-users-requests">steal the credentials of other users</a>. So something as simple as displaying a user name or a comment could be sufficient.</p> </blockquote> <p>This post is long enough, and there are so many different attacks, that I'm going to leave it there for looking at exploits. If you'd like to learn more about what's possible, along with simple explanations and examples of exploits, I recommend the <a href="https://portswigger.net/">PortSwigger</a> documentation on <a href="https://portswigger.net/web-security/request-smuggling/exploiting">exploiting request smuggling</a>.</p> <h2 id="does-request-smuggling-only-apply-if-i-have-a-proxy-"><a href="#does-request-smuggling-only-apply-if-i-have-a-proxy-">Does request smuggling only apply if I have a proxy?</a></h2> <p>In general, whenever people talk about request smuggling, they normally talk about the case where you have multiple servers: the canonical example is a proxy server and a destination server, as I've discussed so far. But don't be fooled, these issues and vulnerabilities can apply even if you aren't strictly using a proxy.</p> <p>The <em>key</em> feature of the vulnerability is that there's an opportunity for confusion between two "systems", whether they're full "servers" or not. This obviously applies to proxy servers, but could also apply to your application if you're doing anything where you're reading/manipulating/forwarding request streams, or where there's the possibility for confusion <em>inside the same application</em>.</p> <p>For ASP.NET Core applications, if you're working with <code>HttpRequest.Body</code> or <code>HttpRequest.BodyReader</code>, or other similar methods then you <em>may</em> be vulnerable to attacks <em>even if you're not explicitly using a proxy server</em>. Even if you don't think of your application as a proxy or as using a proxy, if you're doing "proxy-like" things, then you could be vulnerable.</p> <blockquote> <p>Put in other words, if you're reading, manipulating, or forwarding request streams directly in ASP.NET Core, as opposed to just relying on the built-in model binding, then you could be at risk to request smuggling attacks. It's very hard to enumerate all the attack vectors, so you should consider any code that does so as a potential avenue of exploitation.</p> </blockquote> <p>We've now covered how request smuggling works and can be exploited in general, so it's time to look at the <em>specific</em> version of request smuggling that is targeted in the .NET CVE-2025-55315 vulnerability.</p> <h2 id="how-does-the-request-smuggling-in-cve-2025-55315-work-"><a href="#how-does-the-request-smuggling-in-cve-2025-55315-work-">How does the request smuggling in CVE-2025-55315 work?</a></h2> <p>As we've seen, HTTP request smuggling is a general technique that relies on differences between proxies and servers in how they parse HTTP requests. I've shown two specific versions of this so far: duplicate <code>Content-Length</code> headers, and <code>Content-Length</code>/<code>Transfer-Encoding</code> confusion, but these are not exhaustive. There are variations on these approaches which also lead to request smuggling.</p> <p>The request smuggling vulnerability in <a href="https://github.com/dotnet/aspnetcore/issues/64033">CVE-2025-55315</a> relies on a variation which (as far as I can tell) was first reported in June 2025 by <a href="https://w4ke.info/2025/06/18/funky-chunks.html">Jeppe Bonde Weikop on their blog</a>. This variation relies on <code>Transfer-Encoding</code> and the <a href="https://datatracker.ietf.org/doc/html/rfc9112#name-chunk-extensions">Chunk Extensions</a> feature.</p> <blockquote> <p>All the details and images in this section are based on the descriptions and examples in <a href="https://w4ke.info/2025/06/18/funky-chunks.html">the original post</a>. That post is excellent, so if you want even more detail and explanation than here, you should definitely read it, and then you can skip the abbreviated version I provide here.</p> </blockquote> <p>To understand the vulnerability, we'll first look at how chunked transfer encoding works and what chunk extensions are. We'll then look at how invalid line-endings can lead to differences in interpretation of a request. Finally, we'll look at how this difference in interpretation can open the way for request smuggling, and how ASP.NET Core fixed the problem.</p> <h3 id="transfer-encoding-chunked-and-chunk-extensions"><a href="#transfer-encoding-chunked-and-chunk-extensions"><code>Transfer-Encoding: chunked</code> and chunk extensions</a></h3> <p>To understand the vulnerability, we first need to understand how <code>Transfer-Encoding: chunked</code> works, and how chunk extensions complicate things.</p> <p>When you're <em>sending</em> a request, you might not always know up-front how big the request is that you're sending. Let's take a practical example of serializing a .NET object to JSON into a request body. The only way to know for sure how big the serialized data is going to be is to actually serialize it. So you <em>could</em> serialize the data to memory <em>before</em> writing the request, but if the data is very big, then that could cause issues with allocating big arrays.</p> <p>Instead, <a href="https://en.wikipedia.org/wiki/Chunked_transfer_encoding"><code>Transfer-Encoding: chunked</code></a> allows sending the request data in multiple "chunks". You need to know the size of each individual chunk, but not the <em>overall</em> size of the data, or how many chunks there are. This works well for serializing to a small buffer, sending that small buffer as a chunk, and then re-using the buffer to serialize the next part, until you have serialized the whole object.</p> <p>In terms of the HTTP request itself, each chunk consists of a header and a body. The header consists of a hexadecimal-formatted number of bytes, followed by a <code>\r\n</code> (<code>CRLF</code>) line ending. The chunk body is then the specified number of bytes, followed by another <code>\r\n</code>. You can have as many chunks as you need, and the request will keep being passed until you send a <code>0</code> length chunk, which indicates the end of the request.</p> <p>As an example, the following HTTP <code>POST</code> shows posting some JSON to an endpoint, but the JSON is sent as three distinct chunks:</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_01.svg" alt="A simple HTTP request using chunked transfer encoding"></p> <ul><li>Chunk 1: The header is <code>9</code> indicating 9 bytes will be sent (followed by <code>\r\n</code>), and then the 9 bytes of the start of the JSON document in the chunk body, again followed by <code>\r\n</code>.</li> <li>Chunk 1: The header is <code>e</code> indicating 14 bytes (14 in hexadecimal is <code>e</code>) will be sent (followed by <code>\r\n</code>), and then the remaining 14 bytes of the end of the JSON document, followed by <code>\r\n</code>.</li> <li>The final chunk is an "empty" chunk, <code>0\r\n\r\n</code>, indicating the end of the request.</li></ul> <p>We're going to see shortly that line endings are very important, so the following diagram shows the same as the above HTTP request, but with the line endings included:</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_02.svg" alt="A simple HTTP request using chunked transfer encoding with the line endings shown"></p> <p>That's "normal" chunked transfer encoding, so now we come to chunk extensions. <a href="https://datatracker.ietf.org/doc/html/rfc9112#name-chunk-extensions">Chunk extensions</a> are part of the HTTP 1.1 protocol which allows for adding key-value pairs of metadata to individual chunks. The following example shows the same request as before, but with a chunk extension, <code>;foo=bar</code> in the second chunk:</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_03.svg" alt="The same HTTP request with a chunk extension in the second chunk"></p> <p>A chunk extension is indicated by a <code>;</code> after the chunk header length, followed by one or more key-value pairs in the form <code>key=value</code>. It's important to understand that chunk extensions are not part of the <em>data</em> that's seen by a request handler; chunk extensions are just metadata about the individual chunk. And tl;dr; they're completely useless 😅</p> <p>To the closest approximation, no-one cares about chunk extensions; client implementations don't send them, and servers just ignore them. If that's the case, how can they be the cause of such a problematic bug in .NET?</p> <p>The problem is <em>how</em> the implementation ignores them…</p> <h3 id="invalid-chunk-extensions-with-incorrect-line-endings"><a href="#invalid-chunk-extensions-with-incorrect-line-endings">Invalid chunk extensions with incorrect line endings</a></h3> <p>In general with HTTP, clients and server implementations often try to follow the <a href="https://en.wikipedia.org/wiki/Robustness_principle"><em>robustness principle</em></a> of "be conservative in what you send, and lenient with what you accept". Unfortunately, it's this very leniency which can sometimes leave us in hot water. After all, it was leniency around requests containing both a <code>Content-Length</code> and <code>Transfer-Encoding</code> header that was the root cause of the original request smuggling exploit.</p> <blockquote> <p>Note that the <a href="https://datatracker.ietf.org/doc/html/rfc9112#section-6.3-2.3">HTTP 1.1 RFC now forbids</a> forwarding both these headers, precisely to avoid request smuggling attacks.</p> </blockquote> <p>For chunk extensions though, leniency is often <em>accidentally</em> built in to the server implementations. Given that no implementations actually <em>do</em> anything with the chunk extensions, the canonical approach to handling them when parsing a chunk header is just to <em>ignore</em> them. When a <code>;</code> is parsed, it's common to just look for the end of the line, and ignore everything in between.</p> <p>For ASP.NET Core (prior to the fix), on finding a <code>;</code> in the chunk header, <a href="https://github.com/dotnet/aspnetcore/blob/4cf89470a7866a963d7118bb1ba90dc35683965c/src/Servers/Kestrel/Core/src/Internal/Http/Http1ChunkedEncodingMessageBody.cs#L348-L356">Kestrel would "parse" the extension</a>, but in practice, it would search for the carriage return <code>\r</code> and then check for the following <code>\n</code>, skipping everything in between, a little bit like this (very simplified compared to <a href="https://github.com/dotnet/aspnetcore/blob/4cf89470a7866a963d7118bb1ba90dc35683965c/src/Servers/Kestrel/Core/src/Internal/Http/Http1ChunkedEncodingMessageBody.cs#L348-L356">original code</a>):</p> <div><pre><code><span>private</span> <span><span>void</span></span> <span>ParseExtension</span><span>(</span><span>ReadOnlySequence<span>&lt;</span><span>byte</span><span>&gt;</span></span> buffer<span>)</span>
<span>{</span>
    <span>while</span><span>(</span><span>true</span><span>)</span>
    <span>{</span>
        <span>// Chunk-extensions not currently parsed</span>
        <span>// Just drain the data</span>
        <span><span>var</span></span> extensionCursor <span>=</span> buffer<span>.</span><span>PositionOf</span><span>(</span>ByteCR<span>)</span><span>;</span>
        <span><span>var</span></span> suffixBuffer <span>=</span> buffer<span>.</span><span>Slice</span><span>(</span>extensionCursor<span>)</span><span>;</span> <span>// skips over extensionCursor bytes</span>

        <span><span>var</span></span> suffixSpan <span>=</span> suffixBuffer<span>.</span><span>Slice</span><span>(</span><span>0</span><span>,</span> <span>2</span><span>)</span><span>.</span><span>ToSpan</span><span>(</span><span>)</span><span>;</span>

        <span>if</span> <span>(</span>suffixSpan<span>[</span><span>1</span><span>]</span> <span>==</span> <span>'\n'</span><span>)</span>
        <span>{</span>
            <span>// We consumed the \r\n at the end of the extension, so switch modes.</span>
            <span>return</span><span>;</span>
        <span>}</span>

        <span>// Otherwise, keep reading data until we do find \r\n</span>
        buffer <span>=</span> <span>ReadMoreData</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
<span>}</span>
</code></pre></div> <p>The implementation in ASP.NET Core wasn't particularly special; <a href="https://github.com/golang/go/blob/1d45a7ef560a76318ed59dfdb178cecd58caf948/src/net/http/internal/chunked.go#L193-L199">most servers</a> simply skip over the bytes until they find a <code>\r\n</code>. The big question is exactly <em>how</em> the servers search for <code>\r\n</code>. What happens if they see a lone <code>\r</code>, or a lone <code>\n</code>? Do they treat that the same as a <code>\r\n</code>? Do they throw an error if they find an un-paired <code>\r</code> or <code>\n</code>? Or do they ignore it and keep looking for a <code>\r\n</code>?</p> <p>That ambiguity is at the heart of the CVE-2025-55315 request smuggling vulnerability. Differences in how proxy and server implementations treat standalone <code>\r</code> or <code>\n</code> in a chunk header allow for request smuggling exploits that use this ambiguity.</p> <blockquote> <p>Note that according to <a href="https://www.rfc-editor.org/errata/eid7633">the RFC</a>, implementers must <em>not</em> treat <code>\r</code> or <code>\n</code> as "valid" line terminators for a chunk header, and neither <code>\r</code> or <code>\n</code> are allowed elsewhere in chunk headers, so correct implementations must reject requests that include these standalone line endings in chunk headers.</p> </blockquote> <p>For complete clarity, the following example is the same as the previous implementation but with an <em>invalid</em> chunk header in the chunk extension of the second chunk. Instead of ending with <code>\r\n</code>, the chunk extension ends with a single <code>\n</code>:</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_04.svg" alt="An HTTP request with an ambiguous line ending in a chunk extension"></p> <p>That's the root cause of the request smuggling vulnerability, so in the next section we'll look at <em>how</em> this could be used to craft a malicious HTTP request.</p> <h3 id="exploiting-invalid-chunk-extensions-for-request-smuggling"><a href="#exploiting-invalid-chunk-extensions-for-request-smuggling">Exploiting invalid chunk extensions for request smuggling</a></h3> <p>Just as with other examples of request smuggling, the chunk extensions approach relies on differences in how a proxy parses a request compared to a subsequent server. This difference means the proxy sees one request, while the destination request sees two requests, and allows for <a href="#how-can-an-attacker-exploit-request-smuggling-">all the same exploits I discussed earlier</a>.</p> <blockquote> <p>As discussed, these examples come from <a href="https://w4ke.info/2025/06/18/funky-chunks.html">this excellent blog post</a>, so see that post for more details, variations on the attack, and further ways to exploit the vulnerability.</p> </blockquote> <p>The following example shows a malicious HTTP request that exploits a difference in line-ending handling between a proxy and the destination server to smuggle a request to the <code>/admin</code> endpoint. We can imagine that the proxy is configured to automatically reject requests to <code>/admin</code> normally, and the server assumes that the proxy handles that for us.</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_05.svg" alt="A request smuggling attack exploiting differences between a proxy and server implementation"></p> <p>In this example the attacker creates a malformed chunk header with a chunk extension by sending <code>2;\n</code>. The <code>;</code> ensures that both the proxy and and server treat the header as a chunk extension, but using <code>\n</code> instead of <code>\r\n</code> results in differential parsing:</p> <ul><li>The proxy only sees a single request: <ul><li>It treats the <code>\n</code> as a "valid" line-ending for the chunk header</li> <li>It then treats the <code>xx</code> as the chunk body</li> <li><code>47</code> is the next chunk header</li> <li>The next 71 bytes (<code>47</code> is hex, which is 71 in decimal) are treated as the chunk body.</li> <li>Finally there's the empty chunk block</li></ul> </li> <li>The server sees two requests: <ul><li>The server ignores the lone <code>\n</code>, and skips all the way to <code>xx\r\n</code></li> <li>It then treats the <code>47</code> as the chunk body</li> <li>It sees an ending chunk,<code>0\r\n\r\n</code> and thinks the request is over</li> <li>The remaining data is treated as a completely separate request, which contains only an empty chunk in the body.</li></ul> </li></ul> <p>This is pretty much the simplest example, but you can essentially exploit this difference in all the ways I described previously. <em>Exactly</em> what the implications are for <em>your</em> application are hard to say, but given that all sorts of security bypass, credential stealing, and injection attacks are possible, it's easy to understand why the vulnerability received a CVSS rating of 9.9.</p> <blockquote> <p>One very interesting thing I found was looking at the security advisories for the same flaw in other HTTP implementations from other languages. In the python <a href="https://github.com/aio-libs/aiohttp">aiohttp</a> and ruby <a href="https://github.com/puma/puma">puma</a> servers, for example, give <a href="https://github.com/advisories/GHSA-8495-4g3g-x7pr">the vulnerability only a moderate severity</a> rating in <a href="https://github.com/advisories/GHSA-c2f4-cvqm-65w2">both cases</a>. In <a href="https://github.com/netty/netty">netty</a> it's even given <a href="https://github.com/netty/netty/security/advisories/GHSA-fghv-69vj-qj49">a low severity</a>.</p> <p>As far as I can tell, these servers are essentially vulnerable in the same way as ASP.NET Core is, so it's just an interesting data point, and I think reflects how Microsoft really want to make sure this gets the visibility it deserves and that customers patch their apps!</p> </blockquote> <h3 id="how-was-the-vulnerability-fixed-"><a href="#how-was-the-vulnerability-fixed-">How was the vulnerability fixed?</a></h3> <p>As with most fixes for request-smuggling, the solution is to stop being lenient and/or ambiguous about how standalone line-endings are handled in chunk headers.</p> <p>In ASP.NET Core, <a href="https://github.com/dotnet/aspnetcore/pull/64037">the PR that fixes the issue</a> does so by explicitly checking for <em>any</em> line-endings, instead of just looking for <code>\r</code>. If it finds a line ending and it's <em>not</em> strictly <code>\r\n</code>, then Kestrel now throws a <code>KestrelBadHttpRequestException</code> and returns a <code>400</code> response.</p> <p><img src="https://andrewlock.net/content/images/2025/request_smuggling_06.png" alt="A screenshot of the fix from the PR https://github.com/dotnet/aspnetcore/pull/64037"></p> <blockquote> <p>I'll mention here there <em>is</em> an <code>AppContext</code> switch for <a href="https://github.com/dotnet/aspnetcore/blob/33ab51daf86b690432f44749824972c1f5019e83/src/Servers/Kestrel/Core/src/Internal/Http/Http1ChunkedEncodingMessageBody.cs#L31"><em>opting-in</em> to the dangerous/vulnerable parsing behaviour</a> after you have patched your application, but please don't use it, I can't believe there's really a good (or <em>safe</em>) reason to.😅</p> </blockquote> <p>The vulnerability has been patched in ASP.NET Core, so what should you do?</p> <h2 id="what-should-you-do-"><a href="#what-should-you-do-">What should you do?</a></h2> <p>Obviously the <em>good</em> news here is that there is a fix for ASP.NET Core. As described <a href="https://github.com/dotnet/aspnetcore/issues/64033">in the original issue</a>, the important thing is to update to the latest supported version of ASP.NET Core as soon as possible.</p> <blockquote> <p>There's no announced evidence of the request smuggling vulnerability being exploited in the wild, but given the vast number of ways that request smuggling <em>could</em> be used, would we even know? 🤔</p> </blockquote> <p>That means you should update your version of .NET 8, .NET 9, or .NET 10:</p> <table><thead><tr><th></th><th>Vulnerable versions</th><th>Lowest patched version</th></tr></thead><tbody><tr><td>.NET 10</td><td>10.0.0-rc2</td><td>10.0.0-rc2</td></tr><tr><td>.NET 9</td><td>9.0.0 - 9.0.9</td><td>9.0.10</td></tr><tr><td>.NET 8</td><td>8.0.0 - 8.0.20</td><td>8.0.21</td></tr></tbody></table> <p>If you're using ASP.NET Core 2.3 on .NET Framework, then you'll need to update your version of <em>Microsoft.AspNetCore.Server.Kestrel.Core</em>:</p> <table><thead><tr><th></th><th>Vulnerable versions</th><th>Lowest patched version</th></tr></thead><tbody><tr><td>Microsoft.AspNetCore.Server.Kestrel.Core</td><td>2.0.0-2.3.0</td><td>2.3.6</td></tr></tbody></table> <p>If you are doing self-contained deployments of your applications, you'll need to update to the patched versions and then redeploy your applications.</p> <p>And if you're using older versions of .NET Core? Well, then you <em>can't</em> patch… <a href="https://www.herodevs.com/">HeroDevs</a> provide additional support for out-of-support versions of .NET (<a href="https://github.com/dotnet/aspnetcore/issues/64033#issuecomment-3411924593">and have confirmed they'll be patching it in .NET 6</a>), but this vulnerability is present in basically <em>all</em> versions of .NET Core as far as I can tell. I've personally tested down to .NET Core 3.0 and I can confirm that the vulnerability is there <em>and there are no patches coming for you</em>. The best thing to do is to update to a supported version of .NET.</p> <blockquote> <p>⚠️ If you are running ASP.NET Core using &lt;=.NET Core 3.0, .NET Core 3.1, .NET 5, .NET 6 (<a href="https://www.herodevs.com/blog-posts/critical-asp-net-vulnerability-cve-2025-55315-reported-upgrade-now">unless supported by HeroDevs</a>), or .NET 7, then you are vulnerable, and there are no patches. You should update to a supported version of .NET as soon as possible. Ironically, if you're stuck on old .NET Framework Web Forms or MVC applications <a href="https://github.com/dotnet/aspnetcore/issues/64033#issuecomment-3442910860">you are apparently <em>not</em> vulnerable</a>.</p> </blockquote> <p>It's worth noting that if you are stuck on one of these old framework versions and <em>can't</em> upgrade, then probably the best way to protect yourself is to ensure that you have a proxy in front of your application which is confirmed to not be vulnerable (though obviously you are likely vulnerable to <em>other</em> exploits 😅).</p> <p>For example, <a href="https://azure.github.io/AppService/2025/10/20/dotnet-on-windows.html">Azure App Services (AAS) confirmed</a> that applications running in AAS are no longer vulnerable, even if you haven't updated, because the proxy that AAS uses (itself a <a href="https://devblogs.microsoft.com/dotnet/bringing-kestrel-and-yarp-to-azure-app-services/">YARP based ASP.NET Core proxy</a>) has been patched. By blocking the requests at the proxy level, ambiguous requests will never make it to your application, so you are protected.</p> <p>Unfortunately, right now, it's not clear exactly where you stand if you're using a service other than AAS for hosting your applications. Even IIS hasn't been confirmed to be safe or vulnerable at this point, but I did some unofficial testing on my Windows 11 box, and as fat as I can tell, it <em>is</em> vulnerable.</p> <blockquote> <p>Note that various people <a href="https://github.com/dotnet/aspnetcore/issues/64033#issuecomment-3445099135">in the original issue</a> are attempting to test IIS by using the <code>Content-Length</code>/<code>Transfer-Encoding</code> version of request smuggling, which is not applicable here; we're interested in the chunk-extensions based version.</p> </blockquote> <p>Another interesting point is that this is vulnerability in HTTP/1.0 and HTTP/1.1 <em>only</em>; it is not a vulnerability in HTTP/2 or HTTP/3. HTTP/2 and HTTP/3 do not support chunked transfer encoding, and instead uses a different, more efficient, binary framing layer for data streaming. So another way to protect those applications which you <em>can't</em> upgrade may be to enforce that client's can <em>only</em> use HTTP/2 or HTTP/3. Be aware that's liable to break a <em>lot</em> of clients that are still using HTTP/1.1 though!</p> <blockquote> <p>You can configure the HTTP protocols allowed by Kestrel by configuring your Kestrel endpoints. <a href="https://learn.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel/endpoints?view=aspnetcore-9.0#configure-http-protocols">The documentation</a> shows various ways to do this.</p> </blockquote> <h2 id="how-to-know-if-you-re-affected-"><a href="#how-to-know-if-you-re-affected-">How to know if you're affected?</a></h2> <p>The "simplest" way to know if you're affected is to check the version of .NET you're using to run your applications, using <code>dotnet --info</code> and verify that you're using one of the patched versions. If you are, you're safe. That's the only "supported" way to know that you're safe, and it's the one way I would recommend. As far as I can tell, there isn't currently a generalised tool to point at an application to find out if it's vulnerable, though it would likely be possible to write one.</p> <p>The folks at HeroDevs <a href="https://github.com/sirredbeard/CVE-2025-55315-repro">re-implemented the functional tests</a> from the original ASP.NET Core fix as a console application compiled against multiple versions of ASP.NET Core. They used this to confirm that unpatched versions of .NET 8-.NET 10 are vulnerable, while <em>patched</em> versions are not. They also used this to verify .NET 6 is vulnerable, and I tweaked it to confirm everything down to at least .NET Core 3.0 is vulnerable.</p> <p>The <a href="https://github.com/sirredbeard/CVE-2025-55315-repro">test in the repro</a> works by sending a chunked transfer encoding request to ASP.NET Core, with an invalid line ending in a chunk extension header. The vulnerability is identified by ASP.NET Core "hanging", waiting for more data, until it eventually times out. The "fixed" version immediately throws the <code>BadRequest</code> exception included in the fix.</p> <blockquote> <p>I <a href="https://www.youtube.com/watch?v=LE758TvUE5c">saw some confusion</a> about this test online; the argument was "if both the fixed and broken versions throw an exception, why does it matter"? However, that's not the point of the test. The fact that Kestrel is paused waiting for more data indicates that a smuggled HTTP request <em>would</em> have been executed. You can see how this can be leveraged to exfiltrate data or attack other users both in <a href="https://w4ke.info/2025/06/18/funky-chunks.html#exploiting-live-users">the chunk extensions blog</a> or <a href="https://portswigger.net/web-security/request-smuggling/exploiting">on PortSwigger's site</a>.</p> </blockquote> <p>I used a similar approach to try to understand whether IIS might be vulnerable by sending the same crafted HTTP request to IIS and seeing if it hung until timing out: it did on my version of IIS (<code>10.0.26100.1882</code>):</p> <div><pre><code><span># Send an HTTP request with an invalid chunk extension, and see</span>
<span># if it times out or if it's rejected with a 400... It times out 🙁</span>
<span>echo</span> <span>-e</span> <span>"GET / HTTP/1.1<span title="\r">\r</span><span title="\n">\n</span>Host:<span title="\r">\r</span><span title="\n">\n</span>Transfer-Encoding: chunked<span title="\r">\r</span><span title="\n">\n</span><span title="\r">\r</span><span title="\n">\n</span>1;<span title="\n">\n</span>"</span> <span>\</span>
  <span>|</span> <span>nc</span> localhost <span>80</span>
</code></pre></div> <p>So does that definitely mean IIS is vulnerable? No, don't trust me, I'm not a security researcher 😅 But until you hear otherwise, I would play it safe and assume that IIS <em>won't</em> protect you from chunk extension request smuggling attacks. And in general, I would apply the same rules to any other proxies you are relying on in your infrastructure.</p> <p>And as a final reminder, even though request smuggling is typically described and demonstrated using a proxy in front of your server, just <em>not</em> using a proxy does <em>not</em> mean you're automatically safe. If you're reading, manipulating, or forwarding request streams directly in ASP.NET Core, as opposed to just relying on the built-in model binding, then you <em>might</em> be at risk to request smuggling attacks. It's best to play it safe, patch your apps, and wherever possible leave the complexity of manipulating requests to ASP.NET Core.</p> <p>In general, I would make sure to subscribe to <a href="https://github.com/dotnet/aspnetcore/issues/64033">the ASP.NET Core issue on GitHub</a>, as it's likely that any more announcements around the issue will also be reported there.</p> <h2 id="summary"><a href="#summary">Summary</a></h2> <p>In this post I discuss the recent ASP.NET Core vulnerability: <a href="https://github.com/dotnet/aspnetcore/issues/64033">Microsoft Security Advisory CVE-2025-55315: .NET Security Feature Bypass Vulnerability</a>. This advisory warns of a request smuggling vulnerability that affects basically all versions of ASP.NET Core.</p> <p>I described how request smuggling works in general, using a simple example of request smuggling to show how ambiguity in how HTTP is parsed can lead to HTTP proxies and HTTP servers in handling the same HTTP request in different ways. This can lead to the server seeing two requests where the proxy only sees a single request.</p> <p>After walking through a request smuggling example, I discussed some of the ways attackers could exploit a request smuggling vulnerability. That includes reflecting malicious data to other users of your app, exfiltrating authentication credentials or other data from client requests, invoking endpoints that shouldn't be publicly accessible, and various other attacks.</p> <p>Next I walked through the specific request smuggling vulnerability identified in CVE-2025-55315. This uses ambiguities in the parsing of chunk extensions when sending requests that use chunked transfer encoding. Chunk extensions are generally ignored by all servers, but lenient handling can lead to differential handling between proxy and server, providing an avenue for request smuggling.</p> <p>Finally, I walked through the mitigation steps you should take: patching your applications. I described the information we currently have about vulnerable or patched proxy servers, and how old versions of ASP.NET Core are not going to be getting patches, so will remain vulnerable (shout out again <a href="https://www.herodevs.com/blog-posts/critical-asp-net-vulnerability-cve-2025-55315-reported-upgrade-now">to HeroDevs for supporting .NET 6</a>). If you're running in AAS, <a href="https://azure.github.io/AppService/2025/10/20/dotnet-on-windows.html">then you're ok</a>, but otherwise, you need to check with your proxy provider to establish whether you are vulnerable or not.</p> </section></article>  <nav><a rel="next" href="https://andrewlock.net/adding-metadata-to-fallback-endpoints-in-aspnetcore/"><span><img src="https://andrewlock.net/content/images/2025/fallbackroutes_banner.png" alt="Adding metadata to fallback endpoints in ASP.NET Core"></span> <span><label>Previous</label> <span>Adding metadata to fallback endpoints in ASP.NET Core</span></span></a></nav> </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Criminal complaint against facial recognition company Clearview AI (146 pts)]]></title>
            <link>https://noyb.eu/en/criminal-complaint-against-facial-recognition-company-clearview-ai</link>
            <guid>45730411</guid>
            <pubDate>Tue, 28 Oct 2025 08:34:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://noyb.eu/en/criminal-complaint-against-facial-recognition-company-clearview-ai">https://noyb.eu/en/criminal-complaint-against-facial-recognition-company-clearview-ai</a>, See on <a href="https://news.ycombinator.com/item?id=45730411">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><ul><li><span lang="EN-US"></span><a href="https://noyb.eu/en/digital-rights-alliance-file-legal-complaints-against-facial-recognition-company-clearview-ai" title="https://noyb.eu/en/digital-rights-alliance-file-legal-complaints-against-facial-recognition-company-clearview-ai"><span lang="EN-US"><strong>Original Complaints against Clearview filed in 2021</strong></span></a><strong><span lang="EN-US"></span></strong></li><li><strong><span lang="EN-US"></span></strong><a href="https://noyb.eu/en/clearview-ai-data-use-deemed-illegal-austria-however-no-fine-issued" title="https://noyb.eu/en/clearview-ai-data-use-deemed-illegal-austria-however-no-fine-issued"><span lang="EN-US"><strong>Decision of Austrian DPA deeming Clearview illegal</strong></span></a><span lang="EN-US"></span></li><li><strong><span lang="EN-US"></span></strong><span lang="EN-US"><strong>Several Clearview fines:</strong></span><strong><span lang="EN-US"></span></strong><ul><li><span lang="EN-US"></span><a href="https://www.edpb.europa.eu/news/national-news/2022/french-sa-fines-clearview-ai-eur-20-million_en" title="https://www.edpb.europa.eu/news/national-news/2022/french-sa-fines-clearview-ai-eur-20-million_en"><span lang="EN-US">Fine by French DPA</span></a><span lang="EN-US"></span></li><li><span lang="EN-US"></span><a href="https://noyb.eu/en/second-eu-20-mio-fine-clearview-ai" title="https://noyb.eu/en/second-eu-20-mio-fine-clearview-ai"><span lang="EN-US">Fine by Greek DPA</span></a></li><li><span lang="EN-US"></span><a href="https://noyb.eu/en/eu-20-mio-fine-clearview-ai-italy" title="https://noyb.eu/en/eu-20-mio-fine-clearview-ai-italy"><span lang="EN-US">Fine by Italian DPA</span></a></li><li><span lang="EN-US"></span><a href="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-on-clearview-because-of-illegal-data-collection-for-facial-recognition" title="https://www.autoriteitpersoonsgegevens.nl/en/current/dutch-dpa-imposes-a-fine-on-clearview-because-of-illegal-data-collection-for-facial-recognition"><span lang="EN-US">Fine by Dutch DPA</span></a></li><li><span lang="EN-US"></span><a href="https://webarchive.nationalarchives.gov.uk/ukgwa/20220527163141/https:/ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2022/05/ico-fines-facial-recognition-database-company-clearview-ai-inc/" title="https://webarchive.nationalarchives.gov.uk/ukgwa/20220527163141/https://ico.org.uk/about-the-ico/news-and-events/news-and-blogs/2022/05/ico-fines-facial-recognition-database-company-clearview-ai-inc/"><span lang="EN-US">Fine by UK DPA</span></a></li></ul></li></ul><p><span lang="EN-US"><strong>Background. </strong>Clearview AI is a US company that scrapes the internet and adds all of the faces it can find in photos and videos to its database. It claims to have collected more than&nbsp;</span><a href="https://www.clearview.ai/" title="https://www.clearview.ai/"><span lang="EN-US">60 billion photos</span></a><span lang="EN-US">. This allows customers of Clearview AI to identify people by uploading a photo and obtaining other pictures of the same person, including links, the name of a subpage of a website and other meta data. The company originally tried to operate largely under the radar but the&nbsp;</span><a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html" title="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html"><span lang="EN-US">New York Times revealed its practices</span></a><span lang="EN-US"> in 2020. While Clearview AI primarily promotes its facial recognition software as a tool for law enforcement, it was also used by companies&nbsp;</span><a href="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-fbi-ice-global-law-enforcement" title="https://www.buzzfeednews.com/article/ryanmac/clearview-ai-fbi-ice-global-law-enforcement"><span lang="EN-US">such as Walmart or Bank of America</span></a><span lang="EN-US">. </span><span lang="EN-US"></span></p><p><span lang="EN-US">Max Schrems:</span><em><span lang="EN-US"> “Facial recognition technology is extremely invasive. It allows for mass surveillance and immediate identification of millions of people. Clearview AI amassed a global database of photos and biometric data, which makes it possible to identify people within seconds. Such power is extremely concerning and undermines the idea of a free society, where surveillance is the exception instead of the rule.”</span></em><span lang="EN-US"></span></p><p><span lang="EN-US"><strong>Clearly illegal and intrusive. </strong>EU data protection authorities have already repeatedly held that Clearview AI, which processed the data of millions of Europeans, clearly violated the GDPR. The French, the Greek, the Italian and the Dutch authority imposed fines of&nbsp;</span><a href="https://wearesolomon.com/mag/format/investigation/clearview-how-a-shady-us-ai-company-dodged-fines-and-defied-regulators-across-europe/" title="https://wearesolomon.com/mag/format/investigation/clearview-how-a-shady-us-ai-company-dodged-fines-and-defied-regulators-across-europe/"><span lang="EN-US">roughly 100 million euros</span></a><span lang="EN-US"> on Clearview for its intrusive practices. The Austrian data protection authority&nbsp;</span><a href="https://gdprhub.eu/index.php?title=DSB_(Austria)_-_2022-0.277.156" title="https://gdprhub.eu/index.php?title=DSB_(Austria)_-_2022-0.277.156"><span lang="EN-US">considered that Clearview AI has acted illegally</span></a><span lang="EN-US">. Several bans were issued. These decisions were not challenged by the US company.</span><span lang="EN-US"></span></p><p><span lang="EN-US"><strong>Ignoring the law.&nbsp;</strong>Instead, Clearview AI is simply ignoring the EU authorities. Only in the UK did the company appeal the decision and fine imposed by the British ICO, with&nbsp;</span><a href="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2025/10/uk-upper-tribunal-hands-down-judgment-on-clearview-ai-inc/" title="https://ico.org.uk/about-the-ico/media-centre/news-and-blogs/2025/10/uk-upper-tribunal-hands-down-judgment-on-clearview-ai-inc/"><span lang="EN-US">a final court decision yet to be issued</span></a><span lang="EN-US">. EU data protection authorities&nbsp;</span><a href="https://wearesolomon.com/mag/format/investigation/clearview-how-a-shady-us-ai-company-dodged-fines-and-defied-regulators-across-europe/" title="https://wearesolomon.com/mag/format/investigation/clearview-how-a-shady-us-ai-company-dodged-fines-and-defied-regulators-across-europe/"><span lang="EN-US">did not come up with a way to enforce its fines and bans</span></a><span lang="EN-US"> against the US company, allowing Clearview AI to effectively dodge the law.</span></p><p><span lang="EN-US">Max Schrems:</span><em><span lang="EN-US"> “Clearview AI seems to simply ignore EU fundamental rights and just spits in the face of EU authorities.”</span></em><span lang="EN-US"></span></p><p><span lang="EN-US"><strong>Criminal Complaint.</strong> However, EU law is not limited to administrative fines under the GDPR. Article 84 GDPR also allows EU Member States to foresee criminal sanctions for GDPR breaches. Austria has implemented such a criminal provision for certain GDPR violations in&nbsp;</span><a href="https://www.ris.bka.gv.at/NormDokument.wxe?Abfrage=Bundesnormen&amp;Gesetzesnummer=10001597&amp;Artikel=2&amp;Paragraf=63&amp;Anlage=&amp;Uebergangsrecht=" title="https://www.ris.bka.gv.at/NormDokument.wxe?Abfrage=Bundesnormen&amp;Gesetzesnummer=10001597&amp;Artikel=2&amp;Paragraf=63&amp;Anlage=&amp;Uebergangsrecht="><span lang="EN-US">§ 63 of its national Data Protection Act</span></a><span lang="EN-US">. In contrast to GDPR violations, criminal violations also allow actions to be taken against managers and to use the full range of criminal procedures, including EU-wide actions. For that reason, </span><em><span lang="EN-US">noyb&nbsp;</span></em><span lang="EN-US">now filed a criminal complaint with the public prosecutors in Austria. If successful, Clearview AI and its executives could face jail time and be held personally liable, in particular if traveling to Europe. </span><span lang="EN-US"></span></p><p><span lang="EN-US">Max Schrems: </span><em><span lang="EN-US">“We even run cross-border criminal procedures for stolen bikes, so we hope that the public prosecutor also takes action when the personal data of billions of people was stolen <strong>–</strong> as has been confirmed by multiple authorities.”</span></em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Poker Tournament for LLMs (254 pts)]]></title>
            <link>https://pokerbattle.ai/event</link>
            <guid>45730094</guid>
            <pubDate>Tue, 28 Oct 2025 07:42:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pokerbattle.ai/event">https://pokerbattle.ai/event</a>, See on <a href="https://news.ycombinator.com/item?id=45730094">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Loading event data...</p></div><!--$--><!--/$--><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Picture gallery: Amiga prototype "Lorraine" at the Amiga 40 event (165 pts)]]></title>
            <link>https://www.amiga-news.de/en/news/AN-2025-10-00110-EN.html</link>
            <guid>45729467</guid>
            <pubDate>Tue, 28 Oct 2025 05:28:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.amiga-news.de/en/news/AN-2025-10-00110-EN.html">https://www.amiga-news.de/en/news/AN-2025-10-00110-EN.html</a>, See on <a href="https://news.ycombinator.com/item?id=45729467">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<td><span color="#004080"><tt>23.Oct.2025</tt></span><br>
<span size="1"><a href="https://www.a1k.org/forum/index.php?threads/95735/">a1k.org (Webseite)</a></span></td>
<td>    Picture gallery: Amiga prototype "Lorraine" at the Amiga 40<br>
<span size="2">
Dale Luck from the original Amiga development team has preserved the very first Amiga prototype, which used three huge stacks of well-equipped breadboards instead of custom chips. The computer was on display in Germany for the first time last weekend at the Amiga 40 event. Amiga user ‘Pittrock’ took pictures of the exhibit and kindly gave us permission to publish them here:
<!-- Break -->
<table><tbody><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1760932585465.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1760932585465.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020398586.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020398586.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020417508.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020417508.jpg" alt=""></a></td>
</tr><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020436495.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020436495.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020442739.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020442739.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197574474.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197574474.jpg" alt=""></a></td>
</tr><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197585936.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197585936.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197598091.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197598091.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020387509.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020387509.jpg" alt=""></a></td>
</tr><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020411626.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020411626.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020429599.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020429599.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761020439086.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761020439086.jpg" alt=""></a></td>
</tr><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197569091.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197569091.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197581259.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197581259.jpg" alt=""></a></td>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197593396.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197593396.jpg" alt=""></a></td>
</tr><tr>
<td><a href="https://www.amiga-news.de/pics/L/lorraine/FB_IMG_1761197603538.jpg"><img src="https://www.amiga-news.de/pics/L/lorraine/th_FB_IMG_1761197603538.jpg" alt=""></a></td>
<td colspan="2"></td>
</tr></tbody></table>
<br> (<a href="https://www.amiga-news.de/en/static/impressum.html#cg">cg</a>)<p>
[<a href="https://www.amiga-news.de/en/news/AN-2025-10-00110-EN.html">News message: 23. Oct. 2025, 22:53</a>] [<a href="https://www.amiga-news.de/en/news/comments/thread/AN-2025-10-00110-EN.html">Comments: 0</a>]<br>
[<a href="https://www.amiga-news.de/aoiPublishNews/news_email.php?frm_newsID=AN-2025-10-00110-EN&amp;frm_lang=en">Send via e-mail</a>]&nbsp; [<a href="https://www.amiga-news.de/aoiPublishNews/news_convert.php?frm_newsID=AN-2025-10-00110-EN&amp;frm_conv=print&amp;frm_lang=en">Print version</a>]&nbsp; [<a href="https://www.amiga-news.de/aoiPublishNews/news_convert.php?frm_newsID=AN-2025-10-00110-EN&amp;frm_conv=ascii&amp;frm_lang=en">ASCII version</a>]</p></span>
</td></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I built the same app 10 times: Evaluating frameworks for mobile performance (225 pts)]]></title>
            <link>https://www.lorenstew.art/blog/10-kanban-boards/</link>
            <guid>45729437</guid>
            <pubDate>Tue, 28 Oct 2025 05:22:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lorenstew.art/blog/10-kanban-boards/">https://www.lorenstew.art/blog/10-kanban-boards/</a>, See on <a href="https://news.ycombinator.com/item?id=45729437">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-dmqsi53g="">  <article data-astro-cid-7jjqptxk="">  <div data-astro-cid-7jjqptxk=""> 
<h2 id="why-i-built-this">Why I Built This</h2>
<p>My team needed to choose a framework for an upcoming app. The requirements were clear: it had to work well on mobile. Not “acceptable on mobile,” but actually good. We’re building tools for real estate agents working in the field: open houses, parking lots, spotty cellular signals. When someone’s standing in front of a potential buyer trying to look professional, a slow-loading app isn’t just an annoyance. It’s a liability.</p>
<p>I started with what seemed like a reasonable comparison: Next.js (our current default when a framework is required) versus SolidStart and SvelteKit (alternatives I’d heard good things about). Three frameworks, should be straightforward. But when I built the first implementations and started measuring, something became clear: the issues I was seeing with Next.js weren’t specific to Next.js. They were fundamental to React’s architecture. I wondered whether the other dominant frameworks (Angular, Vue) might have similar mobile web performance limitations.</p>
<p>That question changed the scope. If I was going to make a real recommendation for the team, I needed to test all the major meta-frameworks and understand the full landscape of alternatives. Three frameworks became ten. What started as a practical evaluation for work turned into something bigger: a semi-comprehensive look at what’s actually possible for mobile web performance in 2025.</p>
<p>This post shares what I discovered. The measurements are real, the kanban apps are identical (same features, same database, same styling), and the differences are dramatic. Marko delivers 12.6 kB raw (6.8 kB compressed). Next.js ships 497.8 kB raw (154.5 kB compressed). That’s a 39x difference in raw size that translates to real seconds on cellular networks.</p>
<p>If you’re interested in the theoretical implications of why framework diversity matters, I wrote about that in <a href="https://www.lorenstew.art/blog/react-won-by-default">React Won by Default</a>. This post focuses on the data: what I built, what I measured, and what it means for teams making similar decisions.</p>
<hr>
<h2 id="key-takeaways-tldr">Key Takeaways (TL;DR)</h2>
<blockquote>
<p><strong>Next-Gen Frameworks Deliver Instant Performance:</strong> Marko (39ms), SolidStart (35ms), SvelteKit (38ms), and Nuxt (38ms) all achieve essentially instant First Contentful Paint in the 35-39ms range. This is 12 to 13 times faster than Next.js at 467ms. The 4ms spread between fastest and slowest is statistically measurable but perceptually meaningless to users. All next-gen frameworks feel instant. The real performance story isn’t splitting hairs over 3ms differences, it’s the massive gap between next-gen and React/Angular.</p>
<p><strong>Bundle Size Champion: Marko</strong> delivers 88.8 kB raw (28.8 kB compressed) for the board page, 6.36 times smaller than Next.js’s 564.9 kB raw (176.3 kB compressed). This is 44% smaller than the next closest competitor (SolidStart at 41.5 kB compressed), making Marko the clear choice when bundle size is the absolute top priority.</p>
<p><strong>Resumability Pattern: Qwik City</strong> at 114.8 kB raw (58.4 kB compressed) eliminates traditional hydration via resumability, yielding instant interactivity for larger client-side apps. Different architectural approach that solves different problems.</p>
<p><strong>Nuxt Proves Established Frameworks Can Compete:</strong> At 224.9 kB raw (72.3 kB compressed) with 38ms FCP, Nuxt demonstrates that established “big three” frameworks can achieve next-gen performance when properly configured. Vue’s architecture allows competitive mobile web performance while maintaining a mature ecosystem. React and Angular show no path to similar results.</p>
<p><strong>Critical scaling difference</strong>: MPA frameworks (Marko, HTMX) ship minimal JavaScript per page, staying lean as you add features. SPA frameworks ship routing and framework runtime upfront, with higher baselines even using code splitting. Marko delivers around 12.6 to 88.8 kB raw regardless of total routes. SPAs maintain 85.9 to 666.5 kB raw baselines plus route chunks.</p>
</blockquote>
<p><strong>The key finding?</strong> The dominant frameworks show dramatically different results. React has an unavoidable performance ceiling. TanStack Start achieves 373.6 kB raw (118.2 kB compressed) bundles using React 19, only 1.51 times better than Next.js’s 564.9 kB raw (176.3 kB compressed). Angular ships similarly heavy bundles via Analog at 666.5 kB raw (203.4 kB compressed). But Vue (via Nuxt) proved different, achieving competitive 224.9 kB raw (72.3 kB compressed) bundles with instant 38ms FCP that matches next-gen frameworks. Meanwhile, next-gen frameworks like SolidStart deliver 128.6 kB raw (41.5 kB compressed) bundles with equally instant 35ms FCP, 4.39 times smaller than Next.js and 2.91 times smaller than TanStack Start with React. The perfect controlled comparison: TanStack Start with React (373.6 kB raw) versus TanStack Start with Solid (182.6 kB raw). Same meta-framework, same patterns, but React bundles are 2x the size of Solid, isolating React’s runtime cost.</p>
<p><strong>Mobile is the web.</strong> These measurements matter because mobile web is the primary internet for billions of people. If your app is accessible via URL, people will use it on phones with cellular connections. Optimizing for desktop and hoping mobile is good enough is backwards. The web is mobile. Build for that reality.</p>
<p>Each build uses the same database, features, and UI so the comparison stays fair. The differences in raw bundle size for the board page range from 4.39 to 6.36 times smaller compared to Next.js for modern alternatives. <strong>Important: These measurements represent disciplined baseline implementations with minimal dependencies.</strong> Real production apps typically ship 5 to 10 times more JavaScript from analytics, authentication, feature flags, and third party libraries, meaning the framework differences compound significantly in practice. On mobile devices with cellular connections, this matters enormously.</p>
<blockquote>
<p>Before diving in, a reminder from my <a href="https://www.lorenstew.art/blog/progressive-complexity-manifesto">Progressive Complexity Manifesto</a>: The frameworks compared here represent Level 5 complexity. They are powerful tools for when you need unified client-side state, a lot of reactivity, and/or client-side navigation. But most applications thrive at lower levels. For instance, Level 3 (server-rendered HTML enhanced with HTMX and vanilla JavaScript, as demonstrated in the kanban-htmx app in this repo) can handle complex interactive applications with minimal JavaScript. Level 4 adds occasional Web Components using Lit for reusable elements. These simpler approaches often deliver even smaller bundles and much simpler codebases. This post focuses on Level 5 options for cases that demand them, while remembering simpler paths often suffice.</p>
</blockquote>
<h2 id="why-mobile-web-performance-matters">Why Mobile Web Performance Matters</h2>
<p>For this evaluation, mobile performance wasn’t just a nice to have. It was the primary constraint. Our users are real estate agents working in the field: open houses with 30 people hammering the same cell tower, parking lots between showings, anywhere but a desk with WiFi. They need tools that work instantly, not “eventually load.”</p>
<p>We’re not building a native app. We’re building for the web, which means if it has a URL, people will access it on their phones. And for our users, the app could be used on a phone just as frequently as a desktop.</p>
<p>This reality shaped the evaluation. I couldn’t just pick a framework that “works on mobile.” I needed something that genuinely performs well on cellular connections with mid-tier devices. The difference between a framework shipping 30 kB versus 170 kB isn’t academic. It’s the difference between an app that feels professional and one that makes our users look bad in front of clients.</p>
<p><strong>The business cost of slow performance</strong>: Research from <a href="https://www.speedcurve.com/blog/downtime-vs-slowtime/">Tammy Everts at SpeedCurve</a> reveals something surprising. While site downtime causes 9% permanent user abandonment, slow performance causes 28% permanent abandonment. That’s over 3x worse. Even more revealing: slowdowns occur 10x more frequently than outages, resulting in roughly 2x total revenue impact despite lower per-hour costs. Beyond the abandonment numbers, slow performance creates a psychological effect where users start perceiving your entire brand negatively. Content seems “boring,” design looks “tacky,” even when those elements haven’t changed. Slowness poisons everything. These aren’t abstract metrics. They’re measurable business costs that compound with every framework kilobyte you ship to mobile users.</p>
<p><strong>The real-world cost:</strong> A 113 kB difference at 3G speeds (750 kbps) means 1.2 seconds for download plus 500ms to 1s for parse/execution on mobile CPUs. Total: 1.5 to 2 seconds slower between frameworks. On 4G the gap shrinks but remains noticeable. On spotty connections (like an open house with 30 people hammering the same cell tower) it becomes painful.</p>
<p><strong>“But it’s cached!”</strong> This objection misses reality. Cache busting is standard. Every deployment means users download again. First impressions matter. So do second, third, and tenth impressions. Your users remember waiting.</p>
<p>This is why I expanded the evaluation beyond the initial three frameworks. I needed to understand what’s actually possible. When someone pulls up the app in a parking lot between showings, every second counts. Building for mobile performance first means desktop on WiFi is excellent by default. The reverse isn’t true. Optimize for desktop and mobile users suffer.</p>
<p>I discovered the difference between frameworks reflects fundamentally different engineering priorities. Some frameworks prioritize runtime flexibility, shipping extensive abstractions to support wide use cases. Others prioritize runtime size and mobile performance from the ground up. The bundle sizes I measured for the board page varied by up to 7x (from 28.8 kB compressed to 203.4 kB compressed), differences that matter enormously on cellular networks.</p>
<h2 id="the-experiment-setup">The Experiment Setup</h2>
<p>I built a Kanban board application ten times, once in each of these frameworks: <a href="https://nextjs.org/"><strong>Next.js 16</strong></a> (React 19 with built-in compiler) representing React’s Virtual DOM approach with automatic optimization, <a href="https://tanstack.com/start/latest/docs/framework/react/overview"><strong>TanStack Start</strong></a> (also React 19) for a leaner React meta-framework without App Router overhead, <a href="https://tanstack.com/start/latest/docs/framework/solid/overview"><strong>TanStack Start + Solid</strong></a> (SolidJS 1.9) using the same meta-framework with fine-grained reactivity, <a href="https://nuxt.com/"><strong>Nuxt 4</strong></a> (Vue 3) for Vue’s reactive refs with SSR-first developer experience, <a href="https://analogjs.org/"><strong>Analog</strong></a> (Angular 20) using Angular’s modern signals API with meta-framework tooling, <a href="https://markojs.com/docs/marko-run/getting-started"><strong>Marko</strong></a> (@marko/run) for streaming SSR with fine-grained reactivity, <a href="https://docs.solidjs.com/solid-start/"><strong>SolidStart</strong></a> (SolidJS 1.9) for native Solid integration with fine-grained reactivity through signals, <a href="https://svelte.dev/docs/kit/introduction"><strong>SvelteKit</strong></a> (Svelte 5) for fine-grained reactivity with runes, <a href="https://qwik.dev/docs/qwikcity/"><strong>Qwik City</strong></a> for resumability instead of hydration, and <strong><a href="https://astro.build/">Astro</a> + <a href="https://htmx.org/">HTMX</a></strong> for a traditional MPA approach.</p>
<p>Each implementation includes the exact same features: board creation and listing pages, four fixed lists per board (Todo, In Progress, QA, Done), full CRUD operations for cards, drag-and-drop card reordering within lists and movement between lists, assignee assignment from a static user list, tag management, comments on cards with authorship tracking, completion status toggles, optimistic UI updates for drag-and-drop and chart changes (HTMX lacks this though), and server-side form validation using <a href="https://valibot.dev/">Valibot</a>.</p>
<p>All ten apps share the same foundation. The database is SQLite with <a href="https://orm.drizzle.team/">Drizzle ORM</a> using an identical schema across all implementations. Styling comes from <a href="https://tailwindcss.com/">Tailwind CSS</a> plus <a href="https://daisyui.com/">DaisyUI</a> to keep the UI consistent. Each framework implementation contains roughly 17 components. Most importantly, every app performs real database queries against relational data (boards → lists → cards → tags/comments/users) rather than working with hardcoded arrays.</p>
<p>You can check out the code <a href="https://github.com/lorenseanstewart/kanban-comparison">here</a>.</p>
<p><strong>A critical choice about dependencies</strong>: These apps intentionally minimize dependencies compared to what many developers typically reach for. For mobile web applications, every dependency represents a choice to ship additional kilobytes to users. I used necessary UI libraries like drag-and-drop packages (which vary by ecosystem), but deliberately avoided data fetching libraries, state management helpers, and other utilities that frameworks already handle natively. Each ecosystem has popular packages that add convenience but increase bundle size (React developers often reach for tanstack-query for data fetching, state management libraries, or form helpers). To illustrate the trade-off: tanstack-query alone weighs approximately 13 kB gzipped. That single dependency is already larger than Marko’s entire homepage bundle at 6.8 kB. By avoiding these “nice to have” dependencies and using each framework’s built-in capabilities instead, the bundle differences you’ll see reflect framework architectural choices, not different amounts of functionality or third-party helpers.</p>
<p><strong>Measurement Methodology</strong>: All bundle sizes in this comparison represent median values from 10 measurement runs with browser cache cleared between each run to ensure cold-load performance measurements. Server warmup requests and IQR outlier removal ensure robust statistics. I report both raw (uncompressed) JavaScript sizes and compressed transfer sizes. The raw size reflects actual code volume generated by each framework and is more consistent for comparison since it doesn’t vary by server compression settings. The compressed size shows what users actually download over the network. See the complete <a href="https://github.com/lorenseanstewart/kanban-comparison/blob/main/METHODOLOGY.md">measurement methodology</a> for details on statistical approach, test conditions, and limitations.</p>
<p>Here’s how the tech stacks compare:</p>

<p>This isn’t a todo list with hardcoded arrays. It’s a real app with database persistence, complex state management, and the kind of interactions you’d actually build for a real product.</p>
<h3 id="framework-architectures-at-a-glance">Framework Architectures at a Glance</h3>
<p>To avoid repetition throughout this post, here are the key architectural approaches for each framework tested:</p>
<p><strong>React-based (Next.js, TanStack Start + React):</strong> Use Virtual DOM reconciliation where components re-render and React diffs changes before updating the DOM. React’s compiler automatically optimizes components through memoization using a Control Flow Graph-based High-Level Intermediate Representation, reducing manual optimization needs but not bundle size. Next.js employs React Server Components (RSC) which serialize component trees into a special RSC Payload format, adding meta-framework overhead. TanStack Start uses traditional SSR without RSC complexity. Both ship React’s runtime including Virtual DOM reconciler, synthetic event system, and platform abstractions, creating unavoidable baseline costs for mobile users.</p>
<p><strong>Solid-based (SolidStart, TanStack Start + Solid):</strong> Fine-grained reactivity via signals with read/write segregation where getters are separate from setters. JSX syntax similar to React, but signals automatically track dependencies, eliminating manual dependency arrays and rules of hooks. Components run once during initial render; subsequent updates happen directly at the reactive primitive level without re-executing component functions, minimizing CPU overhead on mobile devices. TanStack Start provides more feature-rich routing which causes slightly larger bundles compared to SolidStart’s leaner integration.</p>
<p><strong>SvelteKit:</strong> Compile-time optimization that transforms components into imperative DOM updates, with minimal runtime overhead since the compiler does most work at build time. Runes ($state, $derived, $effect) powered by signals enable fine-grained reactivity, with universal reactive primitives that work in .js/.ts files beyond just .svelte components. The compiler converts developer-written code into lean, optimized production code. This approach generates JavaScript with smaller bundles through aggressive tree-shaking, helping mobile performance on both network transfer and parse time.</p>
<p><strong>Nuxt (Vue):</strong> Reactive refs with <code>.value</code> access for reactivity tracking. Uses aggressive optimization including compile cache for faster cold starts and reactive keys for intelligent data fetching. In Vue 3 the reactivity system has been refactored for improved performance and memory efficiency, critical for mobile devices. Vapor Mode (experimental, not used here) offers a compile-first approach that bypasses Virtual DOM entirely, compiling templates directly to native DOM operations with significantly smaller runtime overhead. Despite being a “big three” framework, Nuxt achieves competitive bundle sizes and exceptional runtime performance, with support for mixed component trees combining different rendering strategies.</p>
<p><strong>Analog (Angular):</strong> Modern signals API provides fine-grained reactivity through primitives like signal, effect, linkedSignal, queries, and inputs. Zoneless mode enables removing zone.js from bundles entirely, eliminating its synchronization overhead which improves mobile CPU efficiency. Uses dependency injection patterns and ships with RxJS for enterprise reactive patterns, creating heavier bundles despite signals-based reactivity. Angular remains a “batteries-included” framework where common functionality is built-in rather than requiring third-party libraries. Incremental hydration reduces time-to-interactive by hydrating components progressively rather than all at once.</p>
<p><strong>Marko:</strong> Streaming SSR with fine-grained reactivity powered by compiler analysis. The compiler analyzes the reactivity graph at build time and compiles away components themselves, shipping only the minimal code needed for events and effects, achieving zero component overhead at runtime. Statically analyzes which components are stateful versus server-only, breaking pages into top-level stateful components and selectively serializing only needed data. HTML-first syntax with automatic dependency tracking eliminates boilerplate. Supports streaming asynchronous SSR with selective hydration where only interactive parts ship JavaScript to the client, critical for minimizing mobile bundle size.</p>
<p><strong>Qwik City:</strong> Resumability architecture that serializes application state and component boundaries directly into HTML during server rendering, allowing the client to “resume” execution without traditional hydration that requires re-executing components to attach event listeners. Employs fine-grained lazy loading down to the component level, deferring JavaScript downloads until actual user interaction occurs. Event handlers, component logic, and complex interactions are delivered lazily on-demand, eliminating bulk initial JavaScript execution that burdens mobile CPUs. Optimized for edge platforms with distributed deployment, delivering sub-second load times on mobile networks. Best suited for complex client-heavy applications requiring instant interactivity.</p>
<p><strong>Astro + HTMX:</strong> Multi-page architecture (MPA) where Astro serves as a simple HTML renderer with no client-side JavaScript framework. HTMX handles all interactivity through declarative HTML attributes that trigger server requests and swap HTML fragments into the page. Instead of client-side state management, interactions send requests to the server which returns HTML snippets that HTMX injects into the DOM. This approach ships minimal JavaScript (just the HTMX library) and keeps pages lean as routes increase. Best suited for applications where server round trips are acceptable and client-side reactivity isn’t critical. Trades rich client-side state management for extreme simplicity and tiny bundles, optimal for form-driven or content-heavy applications.</p>
<p><strong>TanStack Start:</strong> Meta-framework with a client-first architecture philosophy (versus server-first approaches like Next.js RSC), maintaining powerful server capabilities while prioritizing client-side routing and state management. Router-centric design where the majority of framework functionality comes from TanStack Router, which is framework-agnostic and supports React and Solid. Provides isomorphic loaders that work on both server and client, streaming SSR for progressive rendering, and server functions for type-safe RPC. React version ships traditional hydration with React’s baseline costs, while Solid version achieves roughly half the bundle size using identical routing infrastructure, demonstrating how UI library choice impacts mobile performance.</p>
<blockquote>
<p><strong>Fairness Check</strong>: Pinned versions, identical data volume on Board page, normalized CSS/icon handling (treeshake/purge). All measurements use Chrome Lighthouse with mobile emulation (Pixel 5, 4G throttling, 1x CPU). The measurement script uses 1x CPU to isolate bundle size impact from CPU performance variance. Cache is cleared between each measurement run to simulate first-visit experience.</p>
</blockquote>
<h2 id="why-i-expanded-from-three-to-ten-frameworks">Why I Expanded from Three to Ten Frameworks</h2>
<p>When I started this evaluation, I expected to compare Next.js, SolidStart, and SvelteKit, then make a recommendation. But building those first three implementations revealed something I hadn’t anticipated: the performance issues I saw in Next.js weren’t just a React problem. They were likely systemic across the “big three” dominant framework ecosystems (React, Angular, Vue).</p>
<p>React (via Next.js) ships 154.5 to 176.3 kB compressed (486.1 to 564.9 kB raw) with poor runtime performance at 467ms FCP. Angular (via Analog) ships 125.4 to 203.4 kB compressed (430.3 to 666.5 kB raw). Both suffer from heavy baseline bundles that create performance costs for mobile users. Vue (via Nuxt) tells a dramatically different story. Nuxt ships competitive bundle sizes at 72.3 kB compressed (224.9 kB raw) AND achieves exceptional 38ms FCP, making it faster than all React and Angular options and competitive with next-gen frameworks like SvelteKit (38ms, tied) and Marko (39ms). This puts Nuxt in a unique position: it’s the only “big three” meta-framework that competes on mobile web performance. React requires architectural changes to achieve similar results. Angular has no clear path forward. Nuxt proved that with proper optimization, even established frameworks can deliver next-gen performance.</p>
<p><strong>React’s explicit strategy:</strong> React Native for mobile. In practice, React’s web runtime trades bundle size for other goals. Many teams pursuing top-tier mobile performance choose React Native. The architectural choices that make React heavy on the web are deliberate. They solve real problems for desktop and app development. But for mobile web, React’s position is essentially: use React Native instead.</p>
<p>This is a strategic business decision, not a technical oversight. Facebook (Meta) doesn’t build heavy React web apps on mobile. They invest heavily in React Native and native apps. When you use their mobile app, you’re not running a web browser rendering a React SPA. You’re running native code. React Native is their solution for mobile performance. The React web framework can be expensive because the assumption is that if you care about mobile, you should use a different tool.</p>
<p>The problem with this strategy is that it abandons the open web. React Native requires building two separate applications. Your company needs React engineers for the web, different engineers or different skill sets for native mobile development, and App Store difficulties on top.</p>
<p><strong>This isn’t just an inconvenience. It’s technofeudalism.</strong> React Native solves the mobile performance problem, but it does so by pushing developers out of the open web and into app store platforms where Apple and Google extract up to 30% of transactions, control distribution, and can revoke access at will. React’s mobile strategy inherently drives teams toward platform capture. The web offers an alternative: no gatekeepers, no platform fees, direct distribution. (I explore this dynamic in depth in “The Web is the Last Commons” section below, building on economist Yanis Varoufakis’s analysis of how app stores operate as digital fiefdoms rather than competitive markets.)</p>
<p>Other frameworks make a different bet: the web should work well on mobile without requiring a parallel native technology. The teams behind Marko, Solid, Svelte, Qwik, and Vue have done phenomenal engineering work rethinking these fundamentals from first principles. They’ve built innovative solutions that optimize for the web as a first-class platform for mobile. They’re all saying: you shouldn’t need a completely different technology stack just to reach people with phones. The web should be competitive on its own.</p>
<p>React’s choice is coherent within their ecosystem strategy. It makes sense given their investment in React Native. But it’s not neutral. It’s a choice that deprioritizes mobile web performance in favor of extensive runtime abstractions. For teams building mobile first web applications, it’s a choice that works against you.</p>
<p>That’s why I expanded the evaluation to ten frameworks. If I was going to make an honest recommendation for the team, I needed to understand what’s actually possible. React’s heavy bundle sizes aren’t bugs or poor engineering. They’re the predictable cost of React’s runtime architectural overhead. Angular has similar bundle size issues. Vue showed that the “big three” can compete on mobile web performance when properly configured. For teams building mobile first web applications without the resources for React Native, React and Angular create unavoidable performance limitations, but Nuxt offers a viable path forward.</p>
<p>The measurements that follow show exactly what that tradeoff looks like in practice. They also show what happens when frameworks prioritize mobile web performance from the start. Marko at 6.8 kB compressed. Solid at 30.6 kB compressed. Svelte at 47.8 kB compressed. These aren’t just smaller numbers. They’re fundamentally different architectural approaches that treat the web as a first class platform for mobile.</p>
<h2 id="bundle-size-reality-check">Bundle Size Reality Check</h2>
<h3 id="the-numbers-versions-used">The Numbers (Versions used)</h3>
<p>Production builds measured showing raw JavaScript size (with compressed/gzipped transfer size in parentheses). Raw size reflects actual code volume and is more consistent for comparison. Compressed size shows what users download over the network.</p>
<p>Framework versions tested: Next.js 16.0.0-beta.0 (React 19.2.0), TanStack Start 1.133.8 (React 19.2.0), Nuxt 4.1.2 (Vue 3.5.22), Analog (Angular core 20.3.3), Marko 6.0.85 with @marko/run 0.8.1, SolidStart (@solidjs/start 1.2.0, solid-js 1.9.9), SvelteKit 2.43.6 (Svelte 5), Qwik City 1.16.1 (Qwik 1.16.1), Astro 5.14.5 + HTMX.</p>
<p><strong>These are minimal baseline implementations.</strong> Typical production apps include authentication, analytics, feature flags, form libraries, and other dependencies that multiply these numbers significantly. The framework overhead shown here compounds with every additional dependency.</p>
<p>Table ordered by board page size (smallest first):</p>







































































<table><thead><tr><th>Framework</th><th>Board Page Raw (Compressed)</th><th>Homepage Raw (Compressed)</th><th>Difference from Next.js (Board Page)</th></tr></thead><tbody><tr><td><strong>Marko</strong></td><td>88.8 kB (28.8 kB)</td><td>12.6 kB (6.8 kB)</td><td><strong>6.36x smaller</strong></td></tr><tr><td><strong>Qwik City</strong></td><td>114.8 kB (58.4 kB)</td><td>88.5 kB (43.6 kB)</td><td><strong>4.92x smaller</strong></td></tr><tr><td><strong>SvelteKit</strong></td><td>125.2 kB (54.1 kB)</td><td>103.4 kB (47.8 kB)</td><td><strong>4.51x smaller</strong></td></tr><tr><td><strong>Astro + HTMX</strong></td><td>127.3 kB (34.3 kB)</td><td>88.9 kB (22.0 kB)</td><td><strong>4.44x smaller</strong></td></tr><tr><td><strong>SolidStart</strong></td><td>128.6 kB (41.5 kB)</td><td>85.9 kB (30.6 kB)</td><td><strong>4.39x smaller</strong></td></tr><tr><td><strong>TanStack Start + Solid</strong></td><td>182.6 kB (60.4 kB)</td><td>153.0 kB (52.0 kB)</td><td><strong>3.09x smaller</strong></td></tr><tr><td><strong>Nuxt</strong></td><td>224.9 kB (72.3 kB)</td><td>224.9 kB (72.3 kB)</td><td><strong>2.51x smaller</strong></td></tr><tr><td><strong>TanStack Start</strong></td><td>373.6 kB (118.2 kB)</td><td>316.8 kB (100.7 kB)</td><td><strong>1.51x smaller</strong></td></tr><tr><td><strong>Next.js 16</strong></td><td>564.9 kB (176.3 kB)</td><td>497.8 kB (154.5 kB)</td><td>Baseline</td></tr><tr><td><strong>Analog</strong></td><td>666.5 kB (203.4 kB)</td><td>430.3 kB (125.4 kB)</td><td>1.18x larger</td></tr></tbody></table>
<p><img src="https://www.lorenstew.art/images/kanban-bundle-size-comparison.svg" alt="Bundle Sizes"></p>
<p><strong>Field data validation</strong>: The <a href="https://lookerstudio.google.com/u/0/reporting/55bc8fad-44c2-4280-aa0b-5f3f0cd3d2be/page/M6ZPC?params=%7B%22df44%22:%22include%25EE%2580%25800%25EE%2580%2580IN%25EE%2580%2580AngularJS%25EE%2580%2580Nuxt.js%25EE%2580%2580Next.js%2520App%2520Router%25EE%2580%2580Astro%25EE%2580%2580SvelteKit%25EE%2580%2580Qwik%25EE%2580%2580SolidStart%22,%22df46%22:%22include%25EE%2580%25800%25EE%2580%2580IN%25EE%2580%2580mobile%22%7D">Chrome User Experience Report (CrUX)</a> provides real-world Core Web Vitals data from millions of actual websites using these frameworks on mobile devices. This field data complements the controlled measurements in this post. Important caveat: CrUX data reflects how these frameworks are used in production by average developers, not optimal implementations. If a framework shows poorly in CrUX but well in these tests, it demonstrates what’s possible with proper configuration, performance tuning, and dependency discipline. The gap between field data and optimized implementations reveals opportunity for improvement in real-world usage patterns.</p>
<p>The difference between Marko’s 88.8 kB raw (28.8 kB compressed) and Next.js’s 564.9 kB raw (176.3 kB compressed) translates to roughly 1.5 seconds on cellular. These seconds are the baseline. Time waiting to load increases with every feature and every dependency added. Those aren’t just abstract kilobytes. That’s their time, their patience, and ultimately their impression of your product.</p>
<p><strong>Critical scaling consideration</strong>: These bundle sizes represent a mid-complexity app with multiple routes. MPA frameworks like Marko ship minimal JavaScript per page (6.8 to 28.8 kB compressed per route), staying lean as you add features. SPA frameworks ship routing and framework runtime upfront. Even with code splitting, SPAs maintain higher baselines: Solid/Svelte start at 30.6 to 54.1 kB compressed then add route chunks, while React/Vue/Angular start at 72.3 to 203.4 kB compressed. The architectural model creates different scaling characteristics.</p>
<p><strong>Important context on HTMX</strong>: The Astro + HTMX implementation achieves excellent bundle sizes with the simplest codebase, but sacrifices client-side reactivity for server-driven interactions. HTMX excels for simpler, form-driven applications where most interactions trigger server requests. However, as your app’s need for rich client-side state management grows, HTMX becomes less practical. For reactive applications, Marko (6.8 to 28.8 kB compressed), Solid (30.6 to 41.5 kB compressed), and Svelte (47.8 to 54.1 kB compressed) maintain small bundles while delivering rich reactivity.</p>
<h3 id="reacts-ceiling-in-practice-tanstack-vs-next">React’s Ceiling in Practice (TanStack vs Next)</h3>
<p><strong>TanStack Start achieves 100.7 to 118.2 kB compressed bundles (316.8 to 373.6 kB raw) while Next.js ships 154.5 to 176.3 kB compressed (497.8 to 564.9 kB raw)</strong> in this measurement. Both use React 19. That’s only a 33 to 35% improvement, primarily reflecting App Router + RSC and related runtime.</p>
<p>The answer reveals that <strong>React’s runtime architecture is the primary cost</strong>, not just Next.js’s meta-framework choices.</p>
<p><strong>What’s the difference?</strong> Next.js ships the full React Server Components runtime plus serialization layers, component boundary management, caching infrastructure, App Router with all its routing features, progressive enhancement for Server Actions, image optimization, and middleware. TanStack Start strips most of that out: traditional SSR without RSC, leaner routing, and simple RPC-style server functions.</p>
<p>Both use server-side rendering, but Next.js’s RSC model adds substantial overhead. Server Components render on the server only, Client Components get marked with <code>"use client"</code>, the server serializes everything to a special format, and the client needs runtime code to deserialize and coordinate those boundaries. TanStack Start uses the simpler traditional SSR approach: render on server, ship HTML, hydrate everything on the client. No serialization, no boundary coordination.</p>
<p>In this measurement, Next.js’s App Router + RSC adds roughly 53 to 58 kB compressed. The remaining 100.7 to 118.2 kB compressed (316.8 to 373.6 kB raw) is React’s core runtime cost: reconciliation, event system, and hydration baseline.</p>
<p>Compare that to alternatives. <strong>SolidStart</strong> delivers 30.6 to 41.5 kB compressed (85.9 to 128.6 kB raw) using JSX, <strong>2.91x smaller than TanStack Start</strong> with React. <strong>SvelteKit</strong> achieves 47.8 to 54.1 kB compressed (103.4 to 125.2 kB raw), which is 1.97x to 2.47x smaller than TanStack Start. <strong>Qwik</strong> delivers 43.6 to 58.4 kB compressed (88.5 to 114.8 kB raw), which is 1.72x to 2.31x smaller.</p>
<p>For React teams, the path forward isn’t straightforward. TanStack Start proves you can remove Next.js’s overhead, but you’re still carrying React’s 100.7 to 118.2 kB compressed (316.8 to 373.6 kB raw) baseline. SolidStart offers similar JSX syntax with 2.91x smaller bundles. And if you like TanStack Start’s approach, you can use it with Solid for the same routing patterns with dramatically smaller bundles.</p>
<p>Here’s the bottom line: <strong>React’s architecture (not just the Virtual DOM, but also synthetic events, platform patching, and sheer feature complexity) creates unavoidable performance costs that no meta-framework optimization can eliminate.</strong> To be fair, Virtual DOM implementations can be small (see Preact at 4 kB). React’s size reflects deliberate choices to circumvent platform constraints and provide extensive features. TanStack Start proves this: removing App Router overhead yields only a 33 to 35% improvement. To escape this ceiling and achieve 3 to 4 times smaller bundles, you need a fundamentally different architectural approach. Frameworks that lean into the platform instead of circumventing it can deliver dramatic size reductions. The React team chose to accept these costs to solve other problems (Server Components, unified patterns). That’s a legitimate choice. But it’s not negotiable within React.</p>
<h3 id="tanstack-start-react-vs-solid">TanStack Start: React vs Solid</h3>
<p>Here’s where it gets interesting. TanStack Start is a new meta-framework that currently supports both React and Solid. Using the same meta-framework with two different UI libraries gives us the perfect controlled comparison.</p>
<p><strong>TanStack Start with React:</strong> Ships 373.6 kB raw (118.2 kB compressed) compared to Next.js’s 564.9 kB raw (176.3 kB compressed). That’s 34% smaller by raw size. If you’re stuck maintaining an existing Next.js codebase, TanStack Start offers a legitimate escape path from App Router complexity while staying in React. But that’s still 373.6 kB raw (118.2 kB compressed) of React’s core runtime.</p>
<p><strong>TanStack Start with Solid:</strong> Delivers 182.6 kB raw (60.4 kB compressed). That’s 30% larger than SolidStart’s 128.6 kB raw (41.5 kB compressed), but still dramatically better than any React option. The size difference is largely due to TanStack Router having more features than SolidStart’s Router. This buys you additional routing capabilities and framework flexibility.</p>
<p><strong>The controlled comparison that matters:</strong> React at 373.6 kB raw (118.2 kB compressed) versus Solid at 182.6 kB raw (60.4 kB compressed) using identical TanStack Start infrastructure. Same routing, same SSR approach, same patterns. React bundles are 2x the size of Solid. This isolates React’s runtime cost versus Solid’s architecture. No meta-framework differences, no excuses.</p>
<p>All four implementations achieve perfect 100 Lighthouse scores. Bundle size differences are real, but modern devices handle them without impacting perceived performance in this test.</p>
<p><strong>For greenfield projects?</strong> Don’t choose React. TanStack Start with Solid gives you 182.6 kB raw (60.4 kB compressed) bundles, but native SolidStart delivers 128.6 kB raw (41.5 kB compressed) with tighter integration. If you want the absolute smallest with this architecture, go SolidStart. If you like TanStack Start’s patterns and might want framework flexibility later, TanStack Start with Solid is reasonable. But starting a new project with React (whether Next.js or TanStack Start) means voluntarily accepting 2x to 3x larger bundles for no performance gain.</p>
<h2 id="the-verdict-what-im-recommending">The Verdict: What I’m Recommending</h2>
<p>After building ten implementations (with help, of course; see the acknowledgements below) and measuring everything, the data gives clear direction. For our mobile first requirements, here’s what I found:</p>
<p><strong>The next-gen frameworks all achieve essentially instant performance.</strong> The 35-39ms FCP range feels perceptually identical to users, and it’s 12 to 13 times faster than Next.js at 467ms. Since all next-gen frameworks feel equally fast, choose based on bundle size priorities and developer experience rather than microscopic FCP differences.</p>
<p>That said, context matters. Not every project can or should switch frameworks.</p>
<p><strong>When Next.js still makes sense:</strong> For large existing React codebases, migration costs may outweigh performance benefits. If you’re stuck with React and can’t migrate, consider TanStack Start over Next.js for a 21-31% bundle reduction without App Router complexity. That’s a practical business decision. But for greenfield projects? There’s no legacy to maintain, no migration costs to weigh. You’re choosing to build on a foundation that costs your users 2x to 3x more JavaScript on every visit. You’re voluntarily accepting worse performance when better options cost nothing extra. That’s not a neutral technical choice. “We only know React” isn’t a technical constraint, it’s a learning investment decision. And “organizational politics” is real, but it’s not a technical justification. It’s an admission that better options exist but can’t be chosen.</p>
<p><strong>Reality check on common objections:</strong></p>
<p><strong>“But hiring!”</strong> Competent developers learn frameworks. That’s the job. These alternatives are actually easier to learn than React: no rules of hooks, no dependency arrays, no manual memoization dance. The real difficulty isn’t learning curve, it’s creating a engineering culture that acknowledges constraints and makes intentional decisions with these constraints in mind.</p>
<p><strong>“But ecosystem!”</strong> React’s ecosystem is both advantage and liability. Large libraries ship code for scenarios you’ll never encounter. That date picker with every locale? You need 3 features, you’re shipping 300. For mobile-first projects where every kilobyte matters, this becomes a problem. Modern AI tools make building exactly what you need feasible: generate the function instead of importing 50kB for 3 features. Smaller bundles, code you understand.</p>
<p><strong>“But it’s risky!”</strong> Shipping 3x larger bundles to mobile users on cellular is the actual risk. Slow loads damage your brand and cost conversions. The “safe choice” has measurable costs.</p>
<p><strong>“But my users are desktop-only!”</strong> Let’s be honest: “desktop-only” is usually an excuse to skip performance discipline entirely. And it’s rarely true for long. Six months later someone asks “can I check this on my phone?” and suddenly you’re stuck. Better to build it right from the start. Desktop users still benefit from faster parsing and execution. Even on WiFi, 30.6 kB compressed loads noticeably faster than 176.3 kB compressed. More importantly, why would you voluntarily accept 3x worse performance when the better option costs nothing extra? Performance is a feature regardless of screen size. Building with constraints makes you a better engineer. “Desktop-only” shouldn’t mean “no discipline.”</p>
<p><strong>Why you should seriously consider the alternatives</strong>: The mental models are often simpler (see Framework Architectures section). Alternatives like Solid, Svelte, and Marko streamline patterns with automatic reactivity. Performance comes by default with 2x to 6x smaller bundles requiring no optimization work. Mobile web matters with real users on phones, cellular connections, and mid-tier devices. You’ll write less code, ship less JavaScript, and debug fewer framework quirks. Most importantly, greenfield projects deserve choices made on merit rather than defaults.</p>
<p><strong>These alternatives are especially compelling</strong> for mobile-first applications where bundle size directly impacts user experience. They matter for the growing demographic of people who prefer phones over computers. Mobile professionals like real estate agents, field service workers, healthcare staff, delivery drivers, and sales reps benefit most. Teams building internal tools or MVPs without enterprise politics constraining decisions can move faster. Developers who value technical excellence over popularity contests will appreciate the engineering quality. Importantly, teams save significant money by maintaining a single high-performance web codebase instead of splitting resources between separate web and native applications. This often means smaller teams, lower overhead, and faster iteration cycles compared to organizations maintaining web apps and native mobile apps.</p>
<p><strong>Choosing among the alternatives</strong> (organized by primary use case):</p>
<p><strong>Smallest Bundles: Choose Marko</strong> for the absolute best bundle sizes (6.8 to 28.8 kB compressed). Marko delivers 44% smaller bundles than the next closest competitor, making it the clear winner when bundle size is your top priority. The MPA architecture ships minimal JavaScript per page, staying lean as you add routes. The developer experience is excellent once you embrace its streaming model. Note: Marko 6 is currently in beta (tagged as <code>next</code> on npm) and expected to leave beta by end of year, with no expected API changes but ongoing bug fixes and optimizations.</p>
<p><strong>JSX Familiarity: Choose SolidStart</strong> if you want the easiest migration path from React. At 128.6 kB raw (41.5 kB compressed), SolidStart uses JSX syntax with automatic dependency tracking that eliminates manual memoization. This delivers 4.39x smaller bundles than Next.js while feeling immediately familiar to React developers. The mental model is actually simpler than React because signals are more straightforward than hooks.</p>
<p><strong>Best All-Around Developer Experience: Choose SvelteKit</strong> for approachable syntax and excellent defaults. At 125.2 kB raw (54.1 kB compressed), SvelteKit delivers 4.51x smaller bundles than Next.js with progressive enhancement by default and minimal framework overhead. The compiler-based approach means less runtime code and cleaner component logic. Best for developers from any background seeking readable code with few framework quirks.</p>
<p><strong>Resumability Pattern: Choose Qwik City</strong> if you have a larger application that demands immediate interactivity on load with significant client-side functionality. At 88.5 to 114.8 kB raw (43.6 to 58.4 kB compressed), Qwik uses resumability instead of hydration, yielding instant time-to-interactive. Different architectural approach that solves different scaling problems.</p>
<p><strong>Established Ecosystem: Choose Nuxt</strong> if you want Vue’s mature plugin ecosystem with competitive mobile web performance. At 224.9 kB raw (72.3 kB compressed), Nuxt proves that established “big three” frameworks can achieve next-gen performance when properly configured. Best for teams already familiar with Vue, projects that benefit from extensive community plugins, or teams that value the safety of a well-established framework. Nuxt bridges the gap between the familiar and the performant.</p>
<p><strong>Important scaling consideration:</strong> Marko’s MPA architecture ships minimal JavaScript per page (stays lean as you add routes), while SPAs like SvelteKit and SolidStart ship routing and framework runtime upfront then add route chunks. Both use code splitting, but the architectural models create different performance characteristics at scale.</p>
<blockquote>
<p>As discussed in my <a href="https://www.lorenstew.art/blog/progressive-complexity-manifesto">Progressive Complexity Manifesto</a>, these Level 5 frameworks are only necessary when you need unified client-side state and complex reactivity. Most apps can thrive at lower levels with simpler tools like HTMX and vanilla JS/TS.</p>
</blockquote>
<p>When developers have real alternatives, everyone wins. React wouldn’t be adding a compiler if SolidStart and Svelte weren’t proving that automatic optimization matters. The entire ecosystem improves when we stop accepting “good enough” as the ceiling.</p>
<p><strong>My recommendation for the team:</strong> After building all these implementations, <strong>Marko, SolidStart, and SvelteKit are all excellent choices</strong> that would serve our mobile first requirements well. All three feel perceptually instant to users. The real question is priorities: absolute smallest bundles (Marko), easiest React migration (SolidStart), or best all-around developer experience (SvelteKit). If the team has Vue experience, Nuxt is also compelling with its mature ecosystem and competitive performance.</p>
<p>For personal projects outside of work, I’ll be reaching for SvelteKit and increasingly Marko. Their developer experience just feels right, the code flows naturally, and they make building things fun.</p>
<h2 id="performance-reality-what-lighthouse-hides">Performance Reality: What Lighthouse Hides</h2>
<p>Mobile performance scores on the Board page (median from 10 runs), ordered by FCP (fastest first):</p>








































































































<table><thead><tr><th>Framework</th><th>Score</th><th>FCP (ms)</th><th>LCP (ms)</th><th>TBT (ms)</th><th>CLS</th><th>Bundle Size Raw (Compressed)</th></tr></thead><tbody><tr><td><strong>SolidStart</strong></td><td>100</td><td>35</td><td>35</td><td>0</td><td>0.000</td><td>128.6 kB (41.5 kB)</td></tr><tr><td><strong>Nuxt</strong></td><td>100</td><td>38</td><td>38</td><td>0</td><td>0.000</td><td>224.9 kB (72.3 kB)</td></tr><tr><td><strong>SvelteKit</strong></td><td>100</td><td>38</td><td>38</td><td>0</td><td>0.000</td><td>125.2 kB (54.1 kB)</td></tr><tr><td><strong>Marko</strong></td><td>100</td><td>39</td><td>39</td><td>0</td><td>0.000</td><td>88.8 kB (28.8 kB)</td></tr><tr><td><strong>TanStack Start + Solid</strong></td><td>100</td><td>40</td><td>40</td><td>0</td><td>0.013</td><td>182.6 kB (60.4 kB)</td></tr><tr><td><strong>TanStack Start</strong></td><td>100</td><td>43</td><td>43</td><td>0</td><td>0.000</td><td>373.6 kB (118.2 kB)</td></tr><tr><td><strong>Analog</strong></td><td>100</td><td>53</td><td>53</td><td>0</td><td>0.000</td><td>666.5 kB (203.4 kB)</td></tr><tr><td><strong>Astro + HTMX</strong></td><td>100</td><td>54</td><td>54</td><td>0</td><td>0.001</td><td>127.3 kB (34.3 kB)</td></tr><tr><td><strong>Qwik</strong></td><td>100</td><td>58</td><td>58</td><td>0</td><td>0.000</td><td>114.8 kB (58.4 kB)</td></tr><tr><td><strong>Next.js 16</strong></td><td>100</td><td>467</td><td>467</td><td>0</td><td>0.000</td><td>564.9 kB (176.3 kB)</td></tr></tbody></table>
<p><strong>Key Metrics:</strong></p>
<p>FCP (First Contentful Paint) indicates when the first content appears on screen. LCP (Largest Contentful Paint) shows when the main content becomes visible. TBT (Total Blocking Time) measures how long the main thread remains blocked and unavailable for user interactions. CLS (Cumulative Layout Shift) evaluates visual stability, where 0 represents perfect stability with no unexpected layout shifts.</p>
<p><strong>Measurement Conditions</strong>: These scores represent mobile device emulation using Pixel 5 profile with 4G network throttling (10 Mbps download, 40ms round-trip time). I use 1x CPU (no throttling) to isolate bundle size and network impact from CPU performance, which allows fair comparison across frameworks with different runtime characteristics. Each measurement was run 10 times with cache cleared between runs to capture cold-load (first-visit) performance. Server warmup requests and IQR outlier removal ensure robust statistics. Standard deviations vary based on framework characteristics.</p>
<p>But here’s what these metrics hide. All frameworks achieve perfect or near perfect scores (100), but the paint times tell the real story about architectural differences. SolidStart achieves the fastest board page load at 35ms FCP. Nuxt and SvelteKit tie for second at 38ms FCP, with Marko close behind at 39ms. TanStack Start with Solid and TanStack Start with React follow at 40ms and 43ms respectively, showing excellent optimization. <strong>The top eight frameworks (SolidStart, Nuxt, SvelteKit, Marko, TanStack variants, Analog, Astro, Qwik) all render in under 60ms, achieving near-instant perceived performance.</strong> Only Next.js lags dramatically behind at 467ms FCP, representing a 13.3x performance gap compared to SolidStart for identical functionality.</p>
<p>Those paint time differences matter in the real world. SolidStart’s 35ms FCP feels instant, while Next.js’s 467ms FCP is noticeably slower. The framework choice directly impacts whether your app feels like a premium tool or a liability.</p>
<h3 id="where-the-difference-shows">Where the Difference Shows</h3>
<p>All frameworks feel instant in optimal conditions. The twist is this. Smaller bundles (Marko, Solid, Svelte, Qwik) win dramatically on slow networks and mid-tier devices.</p>
<p>On desktop with WiFi, all these frameworks are fast. On cellular with a mid-tier phone, 3.54 to 39.2x smaller bundles create measurably better UX. The 130 kB you saved doesn’t just download faster. It also parses and executes faster on mobile CPUs.</p>
<p><strong>Hydration vs Resumability:</strong></p>
<ul>
<li><strong>Traditional (React, Solid, Svelte, Vue, Angular)</strong>: Download bundle → Parse JS → Execute all components → Attach event listeners (hydration)</li>
<li><strong>Marko</strong>: Download minimal JS → Run effects and attach event listeners directly (fine-grained tree shaking, no re-execution of server code)</li>
<li><strong>Qwik</strong>: Download minimal JS → Resume from serialized HTML → Lazily load interaction handlers on demand</li>
</ul>
<p>Both Marko and Qwik are resumable frameworks that avoid traditional hydration. The key difference is that Qwik uses <em>lazy</em> resumability, progressively loading JavaScript based on actual interactions, while Marko analyzes the reactivity graph at build time to bundle exactly the code needed for events and effects; no lazy loading, but maximum precision in what gets shipped. Traditional frameworks must re-execute all components just to wire up event listeners.</p>
<h3 id="addressing-common-critiques">Addressing Common Critiques</h3>
<p>I know what some of you are thinking. “Aren’t you comparing MPAs to SPAs unfairly?” And “Is this app complex enough?”</p>
<p><strong>App Complexity Defense</strong>: This isn’t some toy todo list. It’s a solid mid-complexity app with real database persistence using SQLite plus Drizzle ORM, relational queries across boards to lists to cards to tags and comments, drag-and-drop reordering, (some) optimistic updates, modals, and server validation. It matches the kind of internal tools or MVPs teams crank out every day. The bundle differences come straight from framework overhead, not the features themselves, and those gaps only get bigger at scale with more routes and dependencies. If your production app throws in auth or real-time stuff, framework baselines would just bloat even more, not shrink.</p>
<p><strong>MPA vs SPA Nuances</strong>: The routing pattern debate misses the point, reactivity models matter way more. With features like <a href="https://developer.mozilla.org/en-US/docs/Web/API/View_Transition_API">View Transitions API</a> and the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Speculation_Rules_API">Speculation Rules API</a>, MPAs like Marko or HTMX feel just as snappy as SPAs for navigation. The real split is in scaling. MPAs ship minimal JS per page, for example Marko sticks to 6.8 to 28.8 kB, while SPAs lug around upfront runtime from 83.9 to 666.5 kB baselines plus chunks.</p>
<p><strong>A Note on Ecosystems</strong>: the “small ecosystem” concern is often overstated. For mobile-first applications, we should be extremely selective about every dependency we add. Each package increases bundle size and maintenance burden. Modern AI tools like Claude, ChatGPT, and Cursor excel at generating focused code for your specific use case. Instead of importing a 50 kB library for 3 features, AI can help you write exactly what you need in 2 kB. This approach yields smaller bundles, code you actually understand, and <a href="https://github.blog/security/supply-chain-security/our-plan-for-a-more-secure-npm-supply-chain/">fewer supply chain risks</a>. Large ecosystems are sometimes advantageous, but they’re also a liability when every import costs your mobile users.</p>
<h2 id="does-complexity-buy-you-anything">Does Complexity Buy You Anything?</h2>
<p>If Next.js’s bundles are only 21 to 31% larger than TanStack Start (both using React), what are you actually getting for that extra 44 to 54 kB? And more importantly, do the dominant frameworks’ baselines (React at 100.7 to 118.2 kB compressed, Vue at 72.3 kB compressed, Angular at 125.4 to 203.4 kB compressed) buy you anything compared to alternatives that deliver 30.6 to 54.1 kB compressed?</p>
<h3 id="the-complexity-tax">The Complexity Tax</h3>
<p>Each of the big three has conceptual complexity that alternatives avoid. React has rules around hooks and dependency arrays. Angular carries dependency injection patterns and RxJS complexity. Vue requires understanding refs and reactivity tracking. After seeing that TanStack Start (with React) only achieves marginal improvements over Next.js (21 to 31%), it’s clear that framework complexity and bundle weight often go hand-in-hand. Here’s how state management, effects, and data fetching compare:</p>
<p><strong>1. State Management</strong></p>
<pre tabindex="0" data-language="jsx"><code><span><span>// React - useState with functional updates to avoid stale closures</span></span>
<span><span>const</span><span> [</span><span>count</span><span>, </span><span>setCount</span><span>] </span><span>=</span><span> useState</span><span>(</span><span>0</span><span>);</span></span>
<span><span>setCount</span><span>((</span><span>prev</span><span>) </span><span>=&gt;</span><span> prev </span><span>+</span><span> 1</span><span>);</span></span>
<span></span>
<span><span>// Solid - getter/setter pattern, explicit read/write</span></span>
<span><span>const</span><span> [</span><span>count</span><span>, </span><span>setCount</span><span>] </span><span>=</span><span> createSignal</span><span>(</span><span>0</span><span>);</span></span>
<span><span>setCount</span><span>(</span><span>count</span><span>() </span><span>+</span><span> 1</span><span>);</span></span>
<span></span>
<span><span>// Svelte - looks like normal variables</span></span>
<span><span>let</span><span> count </span><span>=</span><span> $state</span><span>(</span><span>0</span><span>);</span></span>
<span><span>count </span><span>=</span><span> count </span><span>+</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>// Vue/Nuxt - .value access for reactivity</span></span>
<span><span>const</span><span> count</span><span> =</span><span> ref</span><span>(</span><span>0</span><span>);</span></span>
<span><span>count.value </span><span>=</span><span> count.value </span><span>+</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>// Qwik - .value property, serializable</span></span>
<span><span>const</span><span> count</span><span> =</span><span> useSignal</span><span>(</span><span>0</span><span>);</span></span>
<span><span>count.value </span><span>=</span><span> count.value </span><span>+</span><span> 1</span><span>;</span></span>
<span></span>
<span><span>// Angular/Analog - getter/setter like Solid</span></span>
<span><span>const</span><span> count</span><span> =</span><span> signal</span><span>(</span><span>0</span><span>);</span></span>
<span><span>count.</span><span>set</span><span>(</span><span>count</span><span>() </span><span>+</span><span> 1</span><span>);</span></span>
<span></span>
<span><span>// Marko - direct assignment with automatic reactivity</span></span>
<span><span>&lt;let</span><span>/count</span><span>=</span><span>0</span><span>&gt;</span></span>
<span><span>&lt;</span><span>script</span><span>&gt;</span></span>
<span><span>  count = count + 1; // Automatically reactive</span></span>
<span><span>&lt;/</span><span>script</span><span>&gt;</span></span></code></pre>
<p><strong>2. Effects with Dependencies</strong></p>
<pre tabindex="0" data-language="jsx"><code><span><span>// React - manual dependency array (explicit but error-prone)</span></span>
<span><span>useEffect</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(count);</span></span>
<span><span>}, [count]); </span><span>// You must maintain this manually. Mistakes cause hard-to-debug stale closures and infinite loops. This is not a documentation problem, it's a design problem.</span></span>
<span></span>
<span><span>// Solid - automatic tracking</span></span>
<span><span>createEffect</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>count</span><span>()); </span><span>// Automatically subscribes to count</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Svelte - automatic tracking</span></span>
<span><span>$effect</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(count); </span><span>// Automatically subscribes to count</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Vue/Nuxt - explicit or automatic</span></span>
<span><span>watch</span><span>(</span></span>
<span><span>  () </span><span>=&gt;</span><span> count.value,</span></span>
<span><span>  (</span><span>val</span><span>) </span><span>=&gt;</span><span> console.</span><span>log</span><span>(val)</span></span>
<span><span>); </span><span>// explicit</span></span>
<span><span>watchEffect</span><span>(() </span><span>=&gt;</span><span> console.</span><span>log</span><span>(count.value)); </span><span>// automatic</span></span>
<span></span>
<span><span>// Qwik - explicit tracking</span></span>
<span><span>useTask$</span><span>(({ </span><span>track</span><span> }) </span><span>=&gt;</span><span> {</span></span>
<span><span>  track</span><span>(() </span><span>=&gt;</span><span> count.value);</span></span>
<span><span>  console.</span><span>log</span><span>(count.value);</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Angular/Analog - automatic tracking</span></span>
<span><span>effect</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>  console.</span><span>log</span><span>(</span><span>count</span><span>()); </span><span>// Automatically subscribes</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Marko - automatic tracking with &lt;script&gt;</span></span>
<span><span>&lt;let</span><span>/count</span><span>=</span><span>0</span><span>&gt;</span></span>
<span><span>&lt;</span><span>script</span><span>&gt;</span></span>
<span><span>  console.log(count); // Automatically subscribes to count</span></span>
<span><span>&lt;/</span><span>script</span><span>&gt;</span></span></code></pre>
<p><strong>3. Server Data Fetching</strong></p>
<pre tabindex="0" data-language="tsx"><code><span><span>// Next.js - async Server Component (implicit server boundary)</span></span>
<span><span>// Looks like regular component code but runs on server. No explicit data contract.</span></span>
<span><span>// This works beautifully until it doesn't, and when bugs arise from the server/client</span></span>
<span><span>// boundary being invisible, they're extremely hard to debug.</span></span>
<span><span>export</span><span> default</span><span> async</span><span> function</span><span> Page</span><span>() {</span></span>
<span><span>  const</span><span> board</span><span> =</span><span> await</span><span> db.query.boards.</span><span>findFirst</span><span>();</span></span>
<span><span>  return</span><span> &lt;</span><span>div</span><span>&gt;{board.name}&lt;/</span><span>div</span><span>&gt;;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// SvelteKit - remote functions with query (experimental)</span></span>
<span><span>// .remote.ts file defines server-side query function</span></span>
<span><span>export</span><span> const</span><span> getBoardData</span><span> =</span><span> query</span><span>(v.</span><span>string</span><span>(), </span><span>async</span><span> (</span><span>board_id</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span><span>  return</span><span> await</span><span> db.query.boards.</span><span>findFirst</span><span>();</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// In component: use $derived rune with await</span></span>
<span><span>const</span><span> boardData</span><span> =</span><span> $derived</span><span>(</span><span>await</span><span> getBoardData</span><span>(params.id));</span></span>
<span></span>
<span><span>// SolidStart - streaming with Suspense</span></span>
<span><span>// Explicit async resource with streaming support</span></span>
<span><span>const</span><span> board</span><span> =</span><span> createAsync</span><span>(() </span><span>=&gt;</span><span> getBoard</span><span>());</span></span>
<span><span>&lt;</span><span>Suspense</span><span>&gt;{</span><span>board</span><span>()?.name}&lt;/</span><span>Suspense</span><span>&gt;;</span></span>
<span></span>
<span><span>// Qwik - automatic serialization</span></span>
<span><span>// $ suffix marks server-only code, automatically serialized</span></span>
<span><span>export</span><span> const</span><span> useBoard</span><span> =</span><span> routeLoader$</span><span>(</span><span>async</span><span> () </span><span>=&gt;</span><span> {</span></span>
<span><span>  return</span><span> await</span><span> db.query.boards.</span><span>findFirst</span><span>();</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Nuxt - built-in caching</span></span>
<span><span>// Composable with explicit key and built-in deduplication</span></span>
<span><span>const</span><span> { </span><span>data</span><span>: </span><span>board</span><span> } </span><span>=</span><span> await</span><span> useAsyncData</span><span>(</span><span>"board"</span><span>, () </span><span>=&gt;</span></span>
<span><span>  db.query.boards.</span><span>findFirst</span><span>()</span></span>
<span><span>);</span></span>
<span></span>
<span><span>// Analog - DI with server data</span></span>
<span><span>// Dependency injection brings Angular patterns to server data</span></span>
<span><span>export</span><span> const</span><span> load</span><span> =</span><span> injectLoad</span><span>(() </span><span>=&gt;</span><span> {</span></span>
<span><span>  const</span><span> service</span><span> =</span><span> inject</span><span>(BoardService);</span></span>
<span><span>  return</span><span> service.</span><span>getBoard</span><span>();</span></span>
<span><span>});</span></span>
<span></span>
<span><span>// Marko - route handlers with $global context</span></span>
<span><span>// Server handler runs first, sets data on context for page component</span></span>
<span><span>// +handler.ts</span></span>
<span><span>export</span><span> async</span><span> function</span><span> GET</span><span>(</span><span>context</span><span>) {</span></span>
<span><span>  const</span><span> board</span><span> =</span><span> await</span><span> db.query.boards.</span><span>findFirst</span><span>();</span></span>
<span><span>  context.board </span><span>=</span><span> board; </span><span>// Available as $global.board in component</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// +page.marko</span></span>
<span><span>&lt;</span><span>div</span><span>&gt;${$global.board.name}&lt;/</span><span>div</span><span>&gt;;</span></span></code></pre>
<p>The “big three” frameworks each carry conceptual complexity, though with different outcomes. React has rules around hooks and dependency arrays. Angular brings enterprise patterns like dependency injection alongside RxJS streams. Vue requires understanding refs and .value access, but unlike React and Angular, Vue (via Nuxt) has proven it can deliver competitive mobile web performance despite this complexity. These patterns become familiar with practice but never fully disappear and add cognitive overhead. Meta-frameworks compound these complexities: Next.js adds Server/Client boundaries and RSC serialization, Analog brings full Angular DI to the server, and Nuxt adds caching layers and composable patterns.</p>
<p>Most alternatives are conceptually simpler once learned. Svelte is most approachable (looks like enhanced HTML/JS). Solid and Marko use automatic tracking that eliminates manual dependency management. No rules of hooks, no dependency arrays, no .value boilerplate. The simpler mental models correlate with smaller bundles: less runtime complexity means less code to ship.</p>
<h2 id="does-nextjs-16s-built-in-compiler-change-anything">Does Next.js 16’s Built-in Compiler Change Anything?</h2>
<p>The React team recognizes the complexity problem. Their solution, now fully integrated in Next.js 16: the React Compiler automatically handles memoization to reduce re-renders.</p>
<h3 id="what-the-compiler-does">What the Compiler Does</h3>
<p>The React Compiler analyzes your code and inserts <code>useMemo</code> and <code>useCallback</code> automatically. In Next.js 16, this is no longer experimental; it’s built-in and enabled by default. It’s a genuine improvement that reduces boilerplate.</p>
<h3 id="the-results">The Results</h3>
<p>The compiler helps with re-render optimization and removes manual memoization boilerplate. But it doesn’t address Next.js’s bundle size: Next.js ships 176.3 kB compressed (564.9 kB raw) for the board page while TanStack Start ships 118.2 kB compressed (373.6 kB raw) with the same React 19. The compiler can’t eliminate dependency arrays for <code>useEffect</code>. You still need to understand hooks, closures, and React’s rendering model.</p>
<h3 id="the-irony">The Irony</h3>
<p>The compiler improves React’s developer experience, which is valuable. But it highlights an interesting contrast. React optimizes Virtual DOM re-renders, while alternatives like SolidStart eliminate re-renders entirely through fine-grained reactivity. SvelteKit’s compiler eliminates much of the runtime overhead at build time. Qwik eliminates hydration cost through resumability.</p>
<p>The difference in philosophy is clear. React’s compiler optimizes the existing model. The alternatives questioned the model itself.</p>
<h2 id="the-web-is-the-last-commons-why-this-matters-beyond-frameworks">The Web is the Last Commons: Why This Matters Beyond Frameworks</h2>
<p>Here’s where this gets bigger than framework choice. When you ship a native app to the App Store or Google Play instead of building a web app, you’re not just making a technical decision. You’re accepting a deal that would’ve been unthinkable twenty years ago. Apple and Google each take up to 30% of every transaction (with exceptions depending on program and category). They set rules. They decide what you can ship. They can revoke your access tomorrow with no recourse. You have no alternative market. You can’t even compete on price because the fee is baked into many transactions.</p>
<p>Economist Yanis Varoufakis calls this “technofeudalism” in his book of the same name. The App Store isn’t a marketplace, it’s a fiefdom. Developers are digital serfs, bound to the cloud lords’ land (their platforms) with no exit. Users get locked into this too. The App Store is a curated garden where algorithms owned by two companies decide what you see. Your data gets harvested. Your choices get filtered. You’re not a customer with alternatives, you’re a subject in a walled garden.</p>
<p>The web? The web is different. No single company takes a cut. No algorithm curates your choices. Distribution is direct. Users can actually vote with their feet. It’s not perfect, but it’s the closest thing we have left to an open market where developers retain agency and users retain choice.</p>
<p>When companies abandon the web to go app-only, they’re not making a neutral technical decision. They’re voluntarily moving their users from a competitive marketplace into a feudal system. And yeah, I know that sounds dramatic, but Varoufakis has spent years documenting how the economics of digital platforms have created exactly this dynamic.</p>
<p><strong>Why you should care, no matter what you believe:</strong></p>
<p>If you lean capitalist, app stores create an environment that is the opposite of what capitalism is supposed to be. Monopolistic rent extraction replacing competition and innovation. No market mechanism to challenge them. That’s not capitalism, that’s just extraction.</p>
<p>If you lean anti-capitalist, technofeudalism is arguably worse than regular capitalism because at least capitalism has friction and regulatory handles. This has neither. It’s total private control with zero market competition.</p>
<p>Either way, the web is the last place where economic activity can happen outside the thumb of tech oligarchs. Building web apps matters. Shipping small, fast, performant web apps matters even more, and most web traffic comes from the mobile web. Every kilobyte you save is another reason for teams to choose the web over building a native app subject to app store control and fees.</p>
<h2 id="conclusion-what-this-evaluation-revealed">Conclusion: What This Evaluation Revealed</h2>
<p>What started as a simple framework comparison for an upcoming work project turned into something more revealing. The data shows clearly what’s possible when frameworks prioritize mobile web performance from the start.</p>
<p>The evaluation revealed what happens when you rethink fundamentals. SolidStart, SvelteKit, Qwik, and Marko represent different architectural priorities that push boundaries in ways the dominant frameworks cannot. Competition drives innovation. These alternatives show what’s achievable when mobile web performance is the primary design constraint, not an afterthought.</p>
<p>For teams serving mobile professionals on cellular networks (like ours), these costs are paid on every visit. React and Angular often face architectural performance ceilings. Vue proved that established frameworks can compete when properly configured. And remember, these measurements represent initial page loads. MPA frameworks maintain their lean profile across routes, while SPAs add route chunks to their baseline.</p>
<p>For anyone starting a new project, the evaluation raises an important question: <strong>Is there any reason to make your app 25.9x heavier than necessary?</strong> (And that’s before adding the authentication, analytics, and third party libraries that typically multiply production bundle sizes 5 to 10 times, making the real world gap even larger.) Building an app that works well on mobile isn’t difficult if you make good architectural decisions at the beginning. The right choice early on means your app performs well everywhere, not just on desktop WiFi. Choose MPA frameworks for the leanest per page bundles, or lightweight SPAs for excellent performance with familiar patterns.</p>
<p>Here’s what the evaluation made clear: <strong>if you want to build a better product than your competitors, why would you build exactly like them?</strong> When everyone uses Next.js, winning on performance requires fighting React’s architecture. When you use Marko, SolidStart, SvelteKit, or Nuxt instead, the advantage comes easily. Your app is faster by default. Your bundle is smaller without optimization work. Your users get a better experience without extra effort. That’s not just good engineering. That’s differentiation.</p>
<p>When you pick Marko and ship 28.8 kB instead of Next.js at 176.3 kB, you’re not just making your users’ experience better on cellular networks. You’re making the web more competitive. You’re making it a more attractive place for companies to exist. You’re pushing back against the gravity that pulls everything toward native only distribution.</p>
<h2 id="reproducing-these-results">Reproducing These Results</h2>
<p>All measurements in this comparison follow a rigorous statistical methodology designed for reproducibility and defensibility. Each framework was measured 10 times per page using Chrome Lighthouse with mobile emulation (Pixel 5, 4G throttling, 1x CPU). Server warmup requests stabilize performance before measurements. IQR (Interquartile Range) outlier removal ensures robust statistics. Browser cache was cleared between runs to measure cold-load performance that simulates first-visit experience. I report median values to reduce the impact of outliers, and standard deviations quantify measurement reliability. The complete methodology including statistical approach, test environment details, compression detection, known limitations, and reproducibility instructions is documented at <a href="https://github.com/lorenseanstewart/kanban-comparison/blob/main/METHODOLOGY.md">METHODOLOGY.md</a>.</p>
<h2 id="call-to-action">Call to Action</h2>
<p><strong>Try it yourself</strong>: Clone the <a href="https://github.com/lorenseanstewart/kanban-comparison">repository</a>, build all ten implementations, and test them on a throttled 3G connection in Chrome DevTools. When mobile web is your only option, the numbers tell a clear story.</p>
<p><strong>On a less serious note</strong>: You can take a look at all ten apps to examine how the code looks and get a general feel for each framework. I advocate coding for fun, and the code in the repo might be a great place to help you try something new.</p>
<p><strong>Share your experience</strong>: Have you tried Marko, SolidStart, SvelteKit, Qwik, or Nuxt? What framework would you choose for a mobile-first project and why? I’d love to hear your thoughts on Twitter or Bluesky.</p>
<p><strong>Keep exploring</strong>: The full metrics data and measurement methodology are available in the repository for you to verify, reproduce, or extend. Build your own comparison and share your findings.</p>
<p>The real winner? You. Your team. Your users. When you start your next project with Marko, SolidStart, or SvelteKit, you’ll ship faster, smaller, and with less framework overhead. That’s a real competitive advantage.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>A huge thanks to everyone who helped with this evaluation.</p>
<p><strong>Early draft reviewers</strong>: <a href="https://bsky.app/profile/infrequently.org">Alex Russell</a> and <a href="https://x.com/dylan_piercey">Dylan Piercey</a> provided invaluable feedback on the post structure and arguments.</p>
<p><strong>Framework-specific reviews</strong>:</p>
<ul>
<li><strong>Marko</strong>: <a href="https://x.com/dylan_piercey">Dylan Piercey</a> for reviewing the implementation</li>
<li><strong>Qwik</strong>: <a href="https://x.com/wmertens">Wout Mertens</a> for reviewing the Qwik implementation</li>
<li><strong>Analog</strong>: <a href="https://x.com/brandontroberts">Brandon Roberts</a> for his review</li>
<li><strong>Solid/SolidStart</strong>: <a href="https://github.com/madaxen86">Martin Rapp</a>, <a href="https://x.com/RyanCarniato">Ryan Carniato</a>, and <a href="https://x.com/AtilaFassina">Atila Fassina</a> for their assistance</li>
<li><strong>Next.js</strong>: <a href="https://github.com/SunnyMan617">Sunny_man</a> for reviewing the Next code</li>
<li><strong>Svelte/SvelteKit</strong>: The helpful folks in the Svelte Discord, especially <a href="https://x.com/kevmodrome">Kevin Åberg Kultalahti</a>, <a href="https://x.com/dummdidumm_">Simon H</a>, and <a href="https://x.com/benmccann">Ben McCann</a></li>
<li><strong>TanStack</strong>: <a href="https://x.com/schanuelmiller">Manuel Schiller</a> and <a href="https://x.com/brenelz">Brenley Dueck</a> for help with the TanStack apps</li>
</ul>
<p>Your contributions made this post more accurate and comprehensive. Thank you!</p> </div>  </article>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Complete Digitization of Leonardo da Vinci's Codex Atlanticus (122 pts)]]></title>
            <link>https://www.openculture.com/2025/10/digitization-of-leonardo-da-vincis-codex-atlanticus.html</link>
            <guid>45728975</guid>
            <pubDate>Tue, 28 Oct 2025 03:32:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.openculture.com/2025/10/digitization-of-leonardo-da-vincis-codex-atlanticus.html">https://www.openculture.com/2025/10/digitization-of-leonardo-da-vincis-codex-atlanticus.html</a>, See on <a href="https://news.ycombinator.com/item?id=45728975">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			<p><img loading="lazy" fetchpriority="high" decoding="async" src="https://cdn8.openculture.com/2019/05/14221645/Atlanticus1.png" alt="" width="924" height="674" srcset="https://cdn8.openculture.com/2019/05/14221645/Atlanticus1.png 924w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-240x175.png 240w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-360x263.png 360w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-768x560.png 768w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-300x219.png 300w" sizes="(max-width: 924px) 100vw, 924px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2019/05/14221645/Atlanticus1.png" data-srcset="https://cdn8.openculture.com/2019/05/14221645/Atlanticus1.png 924w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-240x175.png 240w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-360x263.png 360w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-768x560.png 768w, https://cdn8.openculture.com/2019/05/14221645/Atlanticus1-300x219.png 300w"></p>
<p>No his­tor­i­cal fig­ure bet­ter fits the def­i­n­i­tion of “Renais­sance man” than <a href="https://en.wikipedia.org/wiki/Leonardo_da_Vinci">Leonar­do da Vin­ci</a>, but that term has become so overused as to become mis­lead­ing. We use it to express mild sur­prise that one per­son could use both their left and right hemi­spheres equal­ly well. But in Leonardo’s day, peo­ple did not think of them­selves as hav­ing two brains, and the worlds of art and sci­ence were not so far apart as they are now.</p>
<p>That Leonar­do was able to com­bine fine arts and fine engi­neer­ing may not have been over­ly sur­pris­ing to his con­tem­po­raries, though he was an extra­or­di­nar­i­ly bril­liant exam­ple of the phe­nom­e­non. The more we learn about him, the more we see how close­ly relat­ed the two pur­suits were in his mind.</p>


<p>He approached every­thing he did as a tech­ni­cian. The uncan­ny effects he achieved in paint­ing were the result, as in so much Renais­sance art, of math­e­mat­i­cal pre­ci­sion, care­ful study, and first­hand obser­va­tion.</p>
<p><img loading="lazy" decoding="async" src="https://cdn8.openculture.com/2019/05/14221936/Atlanticus2.png" alt="" width="765" height="580" srcset="https://cdn8.openculture.com/2019/05/14221936/Atlanticus2.png 765w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-240x182.png 240w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-360x273.png 360w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-300x227.png 300w" sizes="(max-width: 765px) 100vw, 765px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2019/05/14221936/Atlanticus2.png" data-srcset="https://cdn8.openculture.com/2019/05/14221936/Atlanticus2.png 765w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-240x182.png 240w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-360x273.png 360w, https://cdn8.openculture.com/2019/05/14221936/Atlanticus2-300x227.png 300w"></p>
<p>His artis­tic projects were also exper­i­ments. Some of them failed, as most exper­i­ments do, and some he aban­doned, as he did so many sci­en­tif­ic projects. No mat­ter what, he nev­er under­took any­thing, whether mechan­i­cal, anatom­i­cal, or artis­tic, with­out care­ful plan­ning and design, as his copi­ous note­books tes­ti­fy. As more and more of those note­books have become avail­able online, both Renais­sance schol­ars and laypeo­ple alike have learned con­sid­er­ably more about how Leonardo’s mind worked.</p>
<p>First, there was the <a href="https://artsandculture.google.com/story/the-codex-arundel-mapping-leonardo-s-working-life-the-british-library/5AUBtgGQK_TgJQ?hl=en"><em>Codex Arun­del</em></a>. It is, writes <a href="https://www.theguardian.com/artanddesign/jonathanjonesblog/2013/feb/12/leonardo-da-vinci-notebooks-art">Jonathan Jones at <em>The Guardian</em></a>, “the liv­ing record of a uni­ver­sal mind”—but also, specif­i­cal­ly, the mind of a “technophile.” Then, the Vic­to­ria and Albert Nation­al Art Library <a href="http://www.openculture.com/2018/08/leonardo-da-vincis-earliest-notebooks-now-digitized-and-made-free-online.html">announced the dig­i­ti­za­tion of<em> Codex Forster</em></a>, which con­tains some of Leonardo’s ear­li­est note­books. Now The Visu­al Agency has released&nbsp;<a href="https://codex-atlanticus.ambrosiana.it/#/Overview">a com­plete dig­i­ti­za­tion of Leonardo’s <em>Codex Atlanti­cus</em></a>, a huge col­lec­tion of the artist, engi­neer, and inventor’s fine­ly-illus­trat­ed notes.</p>
<p><img loading="lazy" decoding="async" src="https://cdn8.openculture.com/2019/05/14222024/Atlanticus4.png" alt="" width="835" height="621" srcset="https://cdn8.openculture.com/2019/05/14222024/Atlanticus4.png 835w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-240x178.png 240w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-360x268.png 360w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-768x571.png 768w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-300x223.png 300w" sizes="(max-width: 835px) 100vw, 835px" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2019/05/14222024/Atlanticus4.png" data-srcset="https://cdn8.openculture.com/2019/05/14222024/Atlanticus4.png 835w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-240x178.png 240w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-360x268.png 360w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-768x571.png 768w, https://cdn8.openculture.com/2019/05/14222024/Atlanticus4-300x223.png 300w"></p>
<p>“No oth­er col­lec­tion counts more orig­i­nal papers writ­ten by Leonar­do,” <a href="https://artsandculture.google.com/exhibit/rwKy3jZHwWiyJA">notes Google</a>. The <em>Codex Atlanti­cus</em> “con­sists of 1119 papers, most of them drawn or writ­ten on both sides.” Its name has “noth­ing to do with the Atlantic Ocean, or with some eso­teric, mys­te­ri­ous con­tent hid­den in its pages.” The 12-vol­ume col­lec­tion acquired its title because the draw­ings and writ­ings were bound with the same size paper that was used for mak­ing atlases. Gath­ered in the 16th cen­tu­ry by sculp­tor Pom­peo Leoni, the papers descend­ed from Leonardo’s close stu­dent Gio­van Francesco Melzi, who was entrust­ed with them after his teacher’s death.</p>
<p>The his­to­ry of the Codex itself makes for a fas­ci­nat­ing nar­ra­tive, much of which you can learn at Google’s <a href="https://artsandculture.google.com/exhibit/rwKy3jZHwWiyJA">Ten Key Facts slideshow</a>. The note­books span Leonardo’s career, from 1478, when he was “still work­ing in his native Tus­cany, to 1519, when he died in France.” The col­lec­tion was tak­en from Milan by Napoleon and brought to France, where it remained in the Lou­vre until 1815, when the Con­gress of Vien­na ruled that all art­works stolen by the for­mer Emper­or be returned. (The emis­sary tasked with return­ing the Codex could not deci­pher Leonardo’s mir­ror writ­ing and took it for Chi­nese.)</p>
<p><img loading="lazy" decoding="async" src="https://cdn8.openculture.com/2019/05/14222010/Atlanticus3-e1557900402461.png" alt="" width="1148" height="681" data-old-src="https://www.openculture.com/wp-content/plugins/native-lazyload/assets/images/placeholder.svg" data-src="https://cdn8.openculture.com/2019/05/14222010/Atlanticus3-e1557900402461.png"></p>
<p><a href="https://codex-atlanticus.ambrosiana.it/#/Overview">The Codex</a> con­tains not only engi­neer­ing dia­grams, anato­my stud­ies, and artis­tic sketch­es, but also fables writ­ten by Leonar­do, inspired by Flo­ren­tine lit­er­a­ture. And it&nbsp;fea­tures <a href="https://www.openculture.com/2023/10/the-resume-of-leonardo-da-vinci-1482.html">Leonardo’s famed “CV,</a>” a let­ter he wrote to the Duke of Milan describ­ing in nine points his qual­i­fi­ca­tions for the post of mil­i­tary engi­neer. In point four, he writes, “I still have very con­ve­nient bomb­ing meth­ods that are easy to trans­port; they launch stones and sim­i­lar such in a tem­pest full of smoke to fright­en the ene­my, caus­ing great dam­age and con­fu­sion.”</p>
<p>As if in illus­tra­tion, else­where in the Codex, the draw­ing above appears, “one of the most cel­e­brat­ed” of <a href="https://codex-atlanticus.ambrosiana.it/#/Overview">the col­lec­tion</a>.”&nbsp;It was “shown to trav­el­ing for­eign­ers vis­it­ing the Ambrosiana [the Bib­liote­ca Ambrosiana in Milan, where the Codex resides] since the 18th cen­tu­ry, usu­al­ly arous­ing much amaze­ment.” It is still amaz­ing, espe­cial­ly if we con­sid­er the pos­si­bil­i­ty that its artistry might have been some­thing of a byprod­uct for its cre­ator, whose pri­ma­ry moti­va­tion seems to have been solv­ing tech­ni­cal problems—in the most ele­gant ways imag­in­able.</p>
<p>See the&nbsp;<a href="https://codex-atlanticus.ambrosiana.it/#/Overview">com­plete dig­i­ti­za­tion of Leonardo’s <em>Codex Atlanti­cus</em> here.</a></p>
<p>Note: An ear­li­er ver­sion of this post appeared on our site in 2019.</p>
<p><strong>Relat­ed Con­tent:</strong></p>
<p><a href="http://www.openculture.com/2018/08/leonardo-da-vincis-earliest-notebooks-now-digitized-and-made-free-online.html">Leonar­do da Vinci’s Ear­li­est Note­books Now Dig­i­tized and Made Free Online: Explore His Inge­nious Draw­ings, Dia­grams, Mir­ror Writ­ing &amp; More</a></p>
<p><a href="http://www.openculture.com/2019/04/how-leonardo-da-vinci-drew-an-accurate-satellite-map-of-an-italian-city-1502.html">How Leonar­do da Vin­ci Drew an Accu­rate Satel­lite Map of an Ital­ian City (1502)</a></p>
<p><a title="Permanent Link to Leonardo da Vinci’s Handwritten Resume (Circa 1482)" href="https://www.openculture.com/2023/10/the-resume-of-leonardo-da-vinci-1482.html" rel="bookmark">Leonar­do da Vinci’s Hand­writ­ten Resume (Cir­ca 1482)</a></p>
<p><a title="Permanent Link to Leonardo Da Vinci’s To-Do List from 1490: The Plan of a Renaissance Man" href="https://www.openculture.com/2025/09/leonardo-da-vincis-to-do-list-from-1490.html" rel="bookmark">Leonar­do Da Vinci’s To-Do List from 1490: The Plan of a Renais­sance Man</a></p>
<p><a href="http://about.me/jonesjoshua"><em>Josh Jones</em></a><em> is a writer and musi­cian based in Durham, NC.&nbsp;</em></p>
<br>		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI can code, but it can't build software (247 pts)]]></title>
            <link>https://bytesauna.com/post/coding-vs-software-engineering</link>
            <guid>45727664</guid>
            <pubDate>Mon, 27 Oct 2025 23:41:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bytesauna.com/post/coding-vs-software-engineering">https://bytesauna.com/post/coding-vs-software-engineering</a>, See on <a href="https://news.ycombinator.com/item?id=45727664">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Have you noticed that quite a few people are looking for technical cofounders
or CTOs right now? I, for one, get a surprising amount of these queries; most
of them along the lines of <em>“hey, I have this vibe-coded app, would you like to
make it production-ready”</em>. I have sort of a profile for these people. Think
someone who knows their business but has always lacked the technical skills to
make their ideas happen — a legal counsel, perhaps, or an account manager.</p>
<p><em>Why would these people need me?</em> That's what I've thought about a little bit,
and I think there is an important signal here: What is it exactly that they
can’t get done with GenAI alone? This is something everyone is trying to
understand, right? Everyone wants to know what these models can do. Or, to be a
little blunt, everyone wants to know which jobs are soon to become obsolete.
The fact that I get these requests says something about software engineering. I
mean, if software engineering was automated, no one would be looking for
technical cofounders.</p>
<p>Well, I think I know why we get these proposals. The thing is that <strong>AI can
code, but it can't build software.</strong> This is the conclusion I've come to after
spending a significant amount of time writing AI-assisted code and watching
demos by other people.</p>
<p>There is old wisdom that says: <em>Coding is easy, software engineering is hard.</em>
It seems fair enough to say that LLMs are already able to automate a lot of
coding. GPT-5 and the like solve isolated well-defined problems with a pretty
nice success rate. Coding, however, is not what most people are getting paid
for. Building a production-ready app is not coding, it’s software engineering.</p>
<p>The way I see it is that coding becomes software engineering around the point
where you try to turn your demo into a real product — which happens to be
exactly the point where these people reach out to you with their pitch.</p>
<p>I don’t really know why AI can't build software (for now). Maybe it has to do
with the nature of the job. When you write software for a living, your main
task is to deal with complexity. The average production software only does a
bunch of easy things. The challenge is doing hundreds of these easy things at
once, and keeping the whole thing maintainable. Or, to rephrase this in the
present context: It's one thing to demonstrate a feature. It's a much more
difficult thing to build that feature in a manner that supports integration,
expansion, and long-term maintainability.</p>
<p>When you look at the code these people send you, you realize that “making the
app production-ready” really means torching the whole thing and starting from
scratch.</p>
<p>I think this says a lot about where we are at right now.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Easy RISC-V (171 pts)]]></title>
            <link>https://dramforever.github.io/easyriscv/</link>
            <guid>45726192</guid>
            <pubDate>Mon, 27 Oct 2025 20:57:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dramforever.github.io/easyriscv/">https://dramforever.github.io/easyriscv/</a>, See on <a href="https://news.ycombinator.com/item?id=45726192">Hacker News</a></p>
<div id="readability-page-1" class="page">

    

    <p>(Last updated: 2025-10-27 14:51)</p>

    <nav>
        <ul>
        <li><a href="#introduction" id="toc-introduction">Introduction</a></li>
        <li><a href="#my-first-risc-v-assembly-program" id="toc-my-first-risc-v-assembly-program">My first RISC-V
        assembly program</a></li>
        <li><a href="#emulator-controls" id="toc-emulator-controls">Emulator controls</a></li>
        <li><a href="#processor-state" id="toc-processor-state">Processor state</a></li>
        <li><a href="#instruction-syntax" id="toc-instruction-syntax">Instruction syntax</a></li>
        <li><a href="#computational-instructions" id="toc-computational-instructions">Computational
        instructions</a>
        <ul>
        <li><a href="#arithmetic-instructions" id="toc-arithmetic-instructions">Arithmetic
        instructions</a></li>
        <li><a href="#bitwise-instructions" id="toc-bitwise-instructions">Bitwise instructions</a></li>
        <li><a href="#comparison-instructions" id="toc-comparison-instructions">Comparison
        instructions</a></li>
        <li><a href="#shift-instructions" id="toc-shift-instructions">Shift instructions</a></li>
        <li><a href="#thats-it" id="toc-thats-it">That’s it…?</a></li>
        <li><a href="#summary-of-computational-instructions" id="toc-summary-of-computational-instructions">Summary of
        computational instructions</a></li>
        </ul></li>
        <li><a href="#intermission-larger-numbers" id="toc-intermission-larger-numbers">Intermission: Larger
        numbers</a></li>
        <li><a href="#jumps-and-branches" id="toc-jumps-and-branches">Jumps and branches</a>
        <ul>
        <li><a href="#branches" id="toc-branches">Branches</a></li>
        <li><a href="#jumps" id="toc-jumps">Jumps</a></li>
        <li><a href="#jump-and-link" id="toc-jump-and-link">Jump and
        link</a></li>
        </ul></li>
        <li><a href="#memory" id="toc-memory">Memory</a>
        <ul>
        <li><a href="#basic-memory-accesses" id="toc-basic-memory-accesses">Basic memory accesses</a></li>
        <li><a href="#smaller-widths" id="toc-smaller-widths">Smaller
        widths</a></li>
        <li><a href="#memory-mapped-io" id="toc-memory-mapped-io">Memory-mapped I/O</a></li>
        </ul></li>
        <li><a href="#functions" id="toc-functions">Functions</a>
        <ul>
        <li><a href="#register-aliases-and-calling-conventions" id="toc-register-aliases-and-calling-conventions">Register
        aliases and calling conventions</a></li>
        <li><a href="#the-stack" id="toc-the-stack">The stack</a></li>
        </ul></li>
        <li><a href="#intermission-numeric-labels" id="toc-intermission-numeric-labels">Intermission: Numeric
        labels</a></li>
        <li><a href="#position-independence" id="toc-position-independence">Position independence</a></li>
        <li><a href="#privileged-architecture-fundamentals" id="toc-privileged-architecture-fundamentals">Privileged
        architecture fundamentals</a>
        <ul>
        <li><a href="#privilege-levels" id="toc-privilege-levels">Privilege levels</a></li>
        <li><a href="#control-and-status-registers-csrs" id="toc-control-and-status-registers-csrs">Control and status
        registers (CSRs)</a></li>
        <li><a href="#counters" id="toc-counters">Counters</a></li>
        <li><a href="#current-privilege-level" id="toc-current-privilege-level">Current privilege
        level</a></li>
        </ul></li>
        <li><a href="#exceptions" id="toc-exceptions">Exceptions</a>
        <ul>
        <li><a href="#exception-entry" id="toc-exception-entry">Exception entry</a></li>
        <li><a href="#exception-causes" id="toc-exception-causes">Exception causes</a></li>
        <li><a href="#exception-return" id="toc-exception-return">Exception return</a></li>
        </ul></li>
        <li><a href="#handling-user-mode" id="toc-handling-user-mode">Handling User mode</a>
        <ul>
        <li><a href="#entering-user-mode" id="toc-entering-user-mode">Entering User mode</a></li>
        <li><a href="#intentionally-causing-an-exception" id="toc-intentionally-causing-an-exception">Intentionally
        causing an exception</a></li>
        <li><a href="#saving-and-restoring-all-registers" id="toc-saving-and-restoring-all-registers">Saving and restoring
        all registers</a></li>
        </ul></li>
        <li><a href="#writing-a-very-very-bare-bones-operating-system" id="toc-writing-a-very-very-bare-bones-operating-system">Writing
        a very very bare bones operating system</a>
        <ul>
        <li><a href="#design" id="toc-design">Design</a></li>
        <li><a href="#code" id="toc-code">Code</a></li>
        <li><a href="#pseudocode-reference" id="toc-pseudocode-reference">Pseudocode reference</a></li>
        </ul></li>
        <li><a href="#lies-and-omissions" id="toc-lies-and-omissions">Lies and omissions</a></li>
        <li><a href="#references" id="toc-references">References</a></li>
        <li><a href="#thanks" id="toc-thanks">Thanks</a></li>
        <li><a href="#license" id="toc-license">License</a></li>
        <li><a href="#index" id="toc-index">Index</a>
        <ul>
        <li><a href="#instructions" id="toc-instructions">Instructions</a></li>
        <li><a href="#registers-and-csrs" id="toc-registers-and-csrs">Registers and CSRs</a></li>
        <li><a href="#special-assembly-syntax" id="toc-special-assembly-syntax">Special assembly
        syntax</a></li>
        <li><a href="#other-terms" id="toc-other-terms">Other
        terms</a></li>
        </ul></li>
        </ul>
    </nav>

<p><a href="https://dramforever.github.io/easyriscv/?no-emulator">(Emulators disabled version)</a></p>
<p>This page is not designed to be used on a narrow screen or without
CSS. If you’re having issues using the emulator, try the <a href="https://dramforever.github.io/easyriscv/?no-emulator">emulators disabled version</a>.</p>
<p>An interactive introduction to RISC-V assembly programming, by <a href="https://github.com/dramforever">dramforever</a>.</p>
<p>Interested in the code? Want to report an issue? Check out the GitHub
page: <a href="https://github.com/dramforever/easyriscv">https://github.com/dramforever/easyriscv</a></p>
<h2 id="introduction">Introduction</h2>
<p>Inspired by <a href="https://skilldrick.github.io/easy6502/">Easy
6502 by Nick Morgan</a>, this is a quick-ish introductory tutorial to
RISC-V assembly programming. This tutorial is intended for those with a
basic familiarity with low level computer science concepts, but
unfamiliar with RISC-V. If you’re curious about RISC-V, I hope this will
be a good start to your journey to learning about it.</p>
<p>RISC-V (pronounced “risk-five”), as its name suggests, is <a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC
(Reduced instruction set computer)</a> architecture. Having started its
life at UC Berkerley, RISC-V has bred a lively community of students,
researchers, engineers and hobbyists working on software and hardware.
Some highlights of RISC-V include:</p>
<ul>
<li>Clean design: Although loosely based on many previous designs,
RISC-V is at its core a new and clean design. It does away with integer
status flags like “carry” or “overflow”, and does not have MIPS’s branch
delay slots. RISC-V is designed primarily as a target for compilers, but
writing RISC-V assembly by hand is still quite pleasant.</li>
<li>Open standard: RISC-V specifications are developed publicly and
anyone can use them without copyright or patent licensing issues. Many
researchers and companies around the world have made their own RISC-V
processor cores and chips based on these specificaions.</li>
<li>Community support: If you want to make your own processors, rather
than paying a hefty license fee to Arm, or designing your own
architecture, you can just use RISC-V. Using RISC-V instead of a custom
architecture allows you to make use of the existing and growing software
ecosystem instead of having to maintain your own.</li>
</ul>
<p>RISC-V is less mature than more established architectures like x86 or
Arm, but it is quickly gaining steam and has found great success in many
areas of application, such as embedded systems, custom processors,
education, and research.</p>
<p>This article will cover the 32-bit bare bones RV32I_Zicsr instruction
set with a tiny subset of the privileged architecture. You’ll probably
never find a “real” chip with such bare bones instruction support. Most
of them will have more <em>extensions</em> for other features like
floating point or compressed instructions. However, I would still
consider what we have here a “complete” instruction set. For example,
Rust has <a href="https://doc.rust-lang.org/nightly/rustc/platform-support/riscv32-unknown-none-elf.html">Tier
2 support</a> for the target <code>riscv32i-unknown-none-elf</code>
which works completely fine with only the instructions we’ll cover
here.</p>
<p>Speaking of instructions we will cover, why don’t we meet the 45 of
them right here and now:</p>
<!-- TODO: Ordering? -->
<pre><code>lui auipc
jal jalr
beq bne blt bge bltu bgeu
lb lh lw lbu lhu sb sh sw
addi slti sltiu xori ori andi slli srli srai
add sub slt sltu xor or and sll srl sra
ecall ebreak
csrrw csrrs csrrc csrrwi csrrsi csrrci</code></pre>
<p>Some of these instruction names should ring a bell (<code>add</code>,
<code>or</code>, <code>xor</code>). Others will look like they have some
pattern to it. A few weird ones like <code>auipc</code> stand out. These
instructions form the foundation of RISC-V, performing the basic tasks a
processor would do.</p>
<p>You will also catch a glimpse of what creating an operating system on
RISC-V is like, namely handling exceptions and privilege levels.</p>
<p>Let’s get started.</p>
<h2 id="my-first-risc-v-assembly-program">My first RISC-V assembly program</h2>
<p>Throughout this article you will see emulator panes like these:</p>
<p>(If you just see a code block, there’s a JavaScript problem. Make
sure you’ve enabled JavaScript, probably…)</p>
<p>
start:
    addi x10, x0, 0x123
    ebreak
</p>
<p>You can use the buttons to control each emulator. Go ahead and click
on ‘Start’. A register view should pop up showing the state of the
emulator. Now click on ‘Run’. You’ll notice that:</p>
<pre><code>a0 (x10) 0x00000000</code></pre>
<p>Changed into:</p>
<pre><code>a0 (x10) 0x00000123</code></pre>
<p>And the emulator stopped. Congratulations, you’ve run your first
RISC-V assembly program. First here, at least.</p>
<h2 id="emulator-controls">Emulator controls</h2>
<p>‘Start’ assembles your code and, well, starts the emulator. If
there’s a problem with your code, it will tell you about it and the
emulator will not start.</p>
<p>When the emulator is started, you can see the current state of the
registers in the side pane. More controls also becomes available. ‘Run’
runs until the end or until you hit ‘Pause’. ‘Step’ runs a single
step.</p>
<p>If you hit ‘Step’, you’ll notice that the above program takes two
steps to run. You may have guessed correctly that the first step
corresponds to <code>addi</code>, and the second corresponds to
<code>ebreak</code>. The top of the register panel shows
<code>pc</code>, the current instruction address, and in parentheses the
current instruction.</p>
<p>‘Dump’ opens a new window containing some text. There are two
sections: the first is the symbol table, which tells you about the
labels in your code:</p>
<pre><code># Symbols
# 0x40000000 start</code></pre>
<p>The second section is an annotated version of your code:</p>
<pre><code>start:
{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 00100073 } ebreak</code></pre>
<p>This tells you that the <code>addi</code> instruction encodes to hex
<code>12300513</code>, and starts at address hex <code>40000000</code>.
Similarly, <code>ebreak</code> encodes as <code>00100073</code> at
address hex <code>40000004</code>.</p>
<p>(Note: RISC-V instructions are <em>little-endian</em>, meaning that
the four bytes of <code>addi</code> are actually
<code>13 05 30 12</code>.)</p>
<p>We’ll talk in detail about all of <code>pc</code>, registers,
instructions, labels, and the two checkboxes later.</p>
<p>Now you may have also guessed that <code>addi x10, x0, 0x123</code>
means <code>x10 = x0 + 0x123</code>. As for <code>ebreak</code>, for
now, just remember that <code>ebreak</code> stops the emulator.</p>
<h2 id="processor-state">Processor state</h2>
<p>The <span id="term-program-counter"><em>program counter</em></span>,
or <span id="term-pc"><em><code>pc</code></em></span> is the address of
the current instruction. It points to the instruction to be
executed.</p>
<p>RV32I has 31 <span id="term-general-purpose-registers"><em>general
purpose registers</em></span> numbered <span id="reg-x1-through-x31"><em><code>x1</code> through
<code>x31</code></em></span>. These can contain any 32-bit data.</p>
<p>(If you’re wondering, there are no flags for RV32I.)</p>
<p>The register <span id="reg-x0"><em><code>x0</code></em></span> is a
special “zero register”. For computational instructions, you can use
<code>x0</code> anywhere a register is expected. Reading it always gives
zero, and writing to it just gets ignored. The use of a special register
simplifies the design of the architecture, and this design is shared by
MIPS and Arm AArch64. We will make good use of <code>x0</code> soon.</p>
<p>(Note: In the emulator, the instruction listed in parenthesis next to
<code>pc</code> in the register view is provided as a convenience and is
not part of the processor state.)</p>
<h2 id="instruction-syntax">Instruction syntax</h2>
<p>But before we can start talking about instructions themselves, we
need a way to talk about the <span id="term-instruction-syntax"><em>instruction syntax</em></span> so I
can, you know, write it down for you.</p>
<p>The syntax of an instruction is the instruction name and then several
comma-separated operands. For example, for this instruction we’ve seen
above:</p>
<pre><code>addi x10, x0, 0x123</code></pre>
<p><code>x10</code> is the <span id="term-destination-register"><em>destination register</em></span> or
<span id="term-rd"><em><code>rd</code></em></span>. The next operand is
the first (and only) <span id="term-source-register"><em>source
register</em></span> or <span id="term-rs1"><em><code>rs1</code></em></span>. The last operand is an
<span id="term-immediate-value"><em>immediate value</em></span> or <span id="term-imm"><em><code>imm</code></em></span>. Using these
abbreviations, we can summarize that the syntax for <code>addi</code>
is:</p>
<pre><code>addi rd, rs1, imm</code></pre>
<p>Some other instructions have a second source register or <span id="term-rs2"><em><code>rs2</code></em></span>. For example, the
non-immediate <code>add</code> instruction has this syntax:</p>
<pre><code>add rd, rs1, rs2</code></pre>
<p>Some other instructions have no operands, like <code>ebreak</code>.
Others have slightly more complex operands.</p>
<h2 id="computational-instructions">Computational instructions</h2>
<p>Using the registers as a playground of numbers, we can use
computational instructions to work with them.</p>
<h2 id="arithmetic-instructions">Arithmetic instructions</h2>
<p>As we’ve seen above, you can get a RISC-V machine to add numbers
together.</p>
<p>The <span id="insn-addi"><em><code>addi</code></em></span>
instruction adds the value in <code>rs1</code> to the immediate value
<code>imm</code>, and puts the result in <code>rd</code>.</p>
<pre><code>addi rd, rs1, imm</code></pre>
<p>The <span id="insn-add"><em><code>add</code></em></span> instruction
adds the value in <code>rs1</code> to the value in <code>rs2</code>, and
puts the result in <code>rd</code>.</p>
<pre><code>add rd, rs1, rs2</code></pre>
<p>The opposite of addition is subtraction. The <span id="insn-sub"><em><code>sub</code></em></span> instruction subtracts the
value in <code>rs2</code> from the value in <code>rs1</code>
(i.e.&nbsp;<code>rs1 - rs2</code>), and puts the result in <code>rd</code>.
There’s no corresponding <code>subi</code> instruction — Just use
<code>addi</code> with a negative number.</p>
<pre><code>sub rd, rs1, rs2</code></pre>
<p>Step through this demo program and try writing your own additions and
subtractions:</p>
<p>
    addi x10, x0, 0x123
    addi x11, x0, 0x555

    addi x12, x10, 0x765
    add x13, x10, x11
    sub x14, x11, x10

    addi x10, x10, 1
    addi x10, x10, 1
    addi x10, x10, -1
    addi x10, x10, -1

    ebreak
</p>
<p>One thing you should note is that the immediate value has a limited
range, namely <code>[-2048, 2047]</code>, the range of a 12-bit two’s
complement signed integer. This limitation is because RV32I uses fixed
32-bit i.e.&nbsp;4-byte instructions, and only the top 12 bits are available
to encode an immediate value. You can see the hexadecimal value encoded
in the instruction from the ‘Dump’. This article will not go into much
further detail about instruction encodings.</p>
<pre><code>{ 0x40000000: 12300513 } addi x10, x0, 0x123
{ 0x40000004: 55500593 } addi x11, x0, 0x555</code></pre>
<p>Even instructions as simple as addition and subtraction have other
interesting uses. We have already used <code>addi x10, x0, 0x123</code>
to put <code>0x123</code> in the register <code>x10</code>. When writing
in assembly, we can use a little shortcut called <span id="term-pseudoinstructions"><em>pseudoinstructions</em></span>. The
<span id="insn-li"><em><code>li</code></em></span> (“load immediate”)
pseudoinstruction is a convenient way to put a small value in a
register. It expands to <code>addi rd, x0, imm</code> when
<code>imm</code> is in the range <code>[-2048, 2047]</code>.</p>
<pre><code>li rd, imm</code></pre>
<p>When <code>imm</code> is <code>0</code>, <code>addi</code> copies the
value without changing it because adding zero is the same as doing
nothing. The <span id="insn-mv"><em><code>mv</code></em></span> (“move”)
pseudoinstruction copies the value from <code>rs1</code> to
<code>rd</code>. It expands to <code>addi rd, rs1, 0</code>.</p>
<pre><code>mv rd, rs1</code></pre>
<p>Using the pseudoinstruction is exactly equivalent to using the “real”
instruction. You can see in the dump that the two are assembled exactly
the same way.</p>
<p>
    addi x10, x0, 0x123
    li x10, 0x123

    addi x11, x10, 0
    mv x11, x10

    ebreak
</p>
<p>Subtracting from zero is negation. What’s the negative of
<code>0x123</code>?</p>
<p>
    li x10, 0x123
    sub x11, x0, x10

    ebreak
</p>
<p>Hmm, we get <code>0xfffffccd</code>. That’s the 32-bit <span id="term-two’s-complement"><em>two’s complement</em></span>
representation of <code>-291</code>, or <code>-0x123</code>. There’s
plenty of tutorials on this out there, so we’ll just note that whenever
something is “signed”, RISC-V uses two’s complement representation. The
benefit of this is that there are fewer instructions for separate signed
and unsigned instructions — both signed and unsigned numbers have the
same overflow wrap-around behavior.</p>
<p>Speaking of overflow wrap-around, what happens if we add something
too much and it overflows? We’ll use <code>add</code> to repeatedly
double <code>0x123</code> and see what happens:</p>
<p>
    li x10, 0x123
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10
    add x10, x10, x10

    ebreak
</p>
<p>As <code>0x123</code> crawls up to the upper bits and eventually we
get to <code>0x9180_0000</code>, in the next iteration it turns into
<code>0x2300_0000</code>. There was an overflow! Doubling of
<code>0x9180_0000</code> gives <code>0x1_2300_0000</code>, but that
needs 33 bits in binary, so the highest bit can’t be put in the result.
Since RISC-V doesn’t have flag bits for carry or overflow, it’s simply
gone. The programmer is expected to deal with this.</p>
<h2 id="bitwise-instructions">Bitwise instructions</h2>
<p>While we’re talking about bits, another thing we can do with bits is
performing bitwise logical operations on them.</p>
<p>The <span id="insn-and"><em><code>and</code></em></span> instruction
performs a bitwise-“and” between the bits of <code>rs1</code> and
<code>rs2</code> and puts the result in <code>rd</code>. The <span id="insn-or"><em><code>or</code></em></span> and <span id="insn-xor"><em><code>xor</code></em></span> instructions similarly
performs bitwise-“or” and bitwise-“xor”, respectively.</p>
<pre><code>and rd, rs1, rs2
or rd, rs1, rs2
xor rd, rs1, rs2</code></pre>
<p>Immediate operand versions of the three, namely <span id="insn-andi"><em><code>andi</code></em></span>, <span id="insn-ori"><em><code>ori</code></em></span>, <span id="insn-xori"><em><code>xori</code></em></span> also exist.</p>
<pre><code>andi rd, rs1, imm
ori rd, rs1, imm
xori rd, rs1, imm</code></pre>
<p>Here are some random bit operation examples you can play with:</p>
<p>
    li x10, 0x5a1
    xori x10, x10, 0xf0
    xori x10, x10, -1

    li x11, 0x5a1
    addi x12, x11, -1
    and x11, x11, x12
    addi x12, x11, -1
    and x11, x11, x12
    addi x12, x11, -1
    and x11, x11, x12

    li x13, 0x5a1
    ori x14, x13, 0xf
    ori x14, x13, 0xff
    ori x14, x13, 0xf0

    ebreak
</p>
<p>Remember that the immediate value is in the range
<code>[-2048, 2047]</code>. For negative values, the two’s complement
representation used means that the high bits are all ones. For example,
using <code>-1</code> as <code>imm</code> means the second operand is
binary all ones, or <code>0xffff_ffff</code>. This allows us to use
<code>xori rd, rs1, -1</code> as bitwise-“not”.</p>
<p>
    li x10, 0x5a1
    xori x11, x10, -1

    or x12, x10, x11
    add x13, x10, x11

    ebreak
</p>
<p>Another interesting operation you can do is to round/<span id="term-align"><em>align</em></span> something up or down to a multiple
of a power of two. For example, if you want to find the closest multiple
of 16 below <code>a</code>, in binary that would be clearing the lowest
4 bits, or <code>a &amp; ~0b1111</code>. Conveniently, that’s
<code>a &amp; -16</code> in two’s complement.</p>
<p>Aligning up is less intuitive, but one idea would be adding 16 first.
However that gives an incorrect result for multiples of 16. It’s easy
enough to fix though: adding one less works exactly right:
<code>(a + 15) &amp; -16</code></p>
<p>
    li x10, 0x123
    andi x11, x10, -16

    addi x12, x10, 15
    andi x12, x12, -16
    ebreak
</p>
<h2 id="comparison-instructions">Comparison instructions</h2>
<p>Usually when you write a comparison of some sort like
<code>a == b</code> or <code>a &gt;= b</code>, it’s used as a condition
for some <code>if</code> or loop, but… those things are complicated!
We’ll get to it later.</p>
<p>Sometimes you just want a boolean value out of a comparison. The C
convention uses 1 for true and 0 for false, and since the world runs on
C now, that’s what RISC-V provides.</p>
<p>In C there are six comparison operators:</p>
<pre><code>== != &lt; &gt; &lt;= &gt;=</code></pre>
<p>The values being compared can also be both signed or both
unsigned.</p>
<p>How many comparison instructions do we have at our disposal? Let’s
see…</p>
<p>The <span id="insn-slt"><em><code>slt</code></em></span> (“set less
than”) instruction compares <code>rs1</code> and <code>rs2</code> as
signed 32-bit integers, and sets <code>rd</code> to <code>1</code> if
<code>rs1 &lt; rs2</code>, and <code>0</code> otherwise
(<code>rs1 &gt;= rs2</code>). The <span id="insn-sltu"><em><code>sltu</code></em></span> instruction is similar
but it treats the operands as unsigned values. <span id="insn-slti"><em><code>slti</code></em></span> and <span id="insn-sltiu"><em><code>sltiu</code></em></span> are similar but the
second operand is an immediate value.</p>
<pre><code>slt rd, rs1, rs2
sltu rd, rs1, rs2
slti rd, rs1, imm
sltiu rd, rs1, imm</code></pre>
<p>(Of particular note is <code>sltiu</code>, where the immediate
operand still has the range <code>[-2048, 2047]</code> but is sign
extended to 32 bits and then treated as an unsigned value, like what
would happen in C with <code>a &lt; (unsigned)-1</code>.)</p>
<p>That’s… one of the six comparisons settled. What about the others? As
it turns out, we can synthesize any of the other five, using up to two
instructions.</p>
<p>Making <code>&gt;</code> from <code>&lt;</code> is easy, as you can
just swap the operands. Using <code>xori</code> with <code>1</code> we
can invert the result of a comparison, giving as <code>&lt;=</code> and
<code>&gt;=</code>.</p>
<p>
    li x10, 0x3
    li x11, 0x5

    slt x12, x10, x11   # x10 &lt; x11
    slt x13, x11, x10   # x10 &gt; x11

    xori x14, x12, 1    # x10 &gt;= x11  i.e.  !(x10 &lt; x11)
    xori x15, x13, 1    # x10 &lt;= x11  i.e.  !(x10 &gt; x11)

    ebreak
</p>
<p>That was signed comparison but unsigned comparison works the same
using <code>sltu</code> instead of <code>slt</code>.</p>
<p>As for <code>==</code> and <code>!=</code>, let’s tackle the easier
case of <code>a == 0</code> and <code>a != 0</code> first. We will use
the fact that for unsigned values, <code>a != 0</code> is equivalent to
<code>a &gt; 0</code>. The negation of that is <code>a &lt;= 0</code>,
which is the same as <code>a &lt; 1</code>.</p>
<p>
    li x10, 0

    sltu x11, x0, x10   # 0 &lt;u x10  i.e.  x10 != 0
    sltiu x12, x10, 1   # x10 &lt;u 1  i.e.  x10 == 0
</p>
<p>As a bonus, this is also how we get logical not and converting
integer to boolean.</p>
<p>Now that we have these, <code>a == b</code> is just
<code>(a - b) == 0</code>, and <code>a != b</code> is just
<code>(a - b) != 0</code>.</p>
<p>
    li x10, 0x3         # a
    li x11, 0x5         # b
    sub x10, x10, x11   # x10 = a - b

    sltu x11, x0, x10   # 0 &lt;u x10  i.e.  x10 != 0
    sltiu x12, x10, 1   # x10 &lt;u 1  i.e.  x10 == 0

    ebreak
</p>
<p>In summary: (<code>[u]</code> means use <code>u</code> for unsigned
comparison and nothing for signed comparison)</p>
<ul>
<li><code>a &lt; b</code>: <code>slt[u]</code></li>
<li><code>a &gt; b</code>: <code>slt[u] reversed</code></li>
<li><code>a &lt;= b</code>: <code>slt[u] reversed ; xori 1</code></li>
<li><code>a &gt;= b</code>: <code>slt[u] ; xori 1</code></li>
<li><code>a == 0</code>: <code>sltu x0</code></li>
<li><code>a != 0</code>: <code>sltiu 1</code></li>
<li><code>a == b</code>: <code>sub ; sltu x0</code></li>
<li><code>a != b</code>: <code>sub ; sltiu 1</code></li>
</ul>
<h2 id="shift-instructions">Shift instructions</h2>
<p>There is no way I can do justice to the usage of bit shifts in the
middle of a tutorial on RISC-V assembly. If you’re here, you’ve probably
heard of them. There’s nothing really special to the way they appear in
usage for RISC-V.</p>
<p>There are two variants for right shifting: <span id="insn-srl"><em><code>srl</code></em></span> and <span id="insn-srli"><em><code>srli</code></em></span> (“shift right logical
(immediate)”) performs “logical” or unsigned right shift where the
leftmost or most significant bits are filled with zeros.</p>
<p><span id="insn-sra"><em><code>sra</code></em></span> and <span id="insn-srai"><em><code>srai</code></em></span> (“shift right
arithmetic (immediate)”) performs “arithmetic” or signed right shift
where the leftmost bits are filled with the same of what highest/sign
bit was. So if you shift a negative value, you get a negative result; if
you shift a non-negative value, you get a non-negative result.</p>
<pre><code>srl rd, rs1, rs2
sra rd, rs1, rs2
srli rd, rs1, imm
srai rd, rs1, imm</code></pre>
<p>As before, the ones with the <code>i</code> suffix take an immediate
value as the second operand, and the ones without <code>i</code> take a
register.</p>
<p>
    li x10, -3
    srai x11, x10, 16
    srli x12, x10, 16
    ebreak
</p>
<p>So <code>a</code> means “arithmetic”, <code>l</code> means “logical”.
Got it.</p>
<p>Left shifts have no such distinction. For consistency they are still
“logical”: <span id="insn-sll"><em><code>sll</code></em></span> is left
shift, and <span id="insn-slli"><em><code>slli</code></em></span> is
left shift with immediate.</p>
<pre><code>sll rd, rs1, rs2
slli rd, rs1, imm</code></pre>
<p>Aha, now we can blow up <code>0x123</code> without repeating myself
so much:</p>
<p>
    li x10, 0x123
    slli x10, x10, 10
    slli x10, x10, 10
    slli x10, x10, 10
    ebreak
</p>
<p>The immediate value for shift instructions are special: they can only
be in the range of 0 to 31, inclusive, because it doesn’t make sense to
shift by a negative amount, or by more than 31. When the shift amount is
taken from a register, the value is considered modulo 32, or in other
words only the last 5 bits are taken into account:</p>
<p>
    li x10, 0x444
    li x11, 0x81

    srl x10, x10, x11   # Same as shifting by 1

    ebreak
</p>
<p>For some fun, let’s try multiplying a value by 10, something you
would do when parsing decimal numbers: <code>a * 10</code> can be
rewritten as <code>(a &lt;&lt; 1) + (a &lt;&lt; 3)</code>:</p>
<p>
    li x10, 0x5

    slli x11, x10, 1
    slli x12, x10, 3
    add x11, x11, x12

    ebreak
</p>
<h2 id="thats-it">That’s it…?</h2>
<p>That’s it?</p>
<p>You may have noticed some glaring omissions. What we’ve learned
doesn’t even cover grade school math: multiplication and division are
missing.</p>
<p>RISC-V is designed with <span id="term-extensions"><em>extensions</em></span> in mind. Remember that
as said in the introduction, RV32I is the barest bones of the barest
bones we’ve got. Forcing everyone to make their processors with
multiplication and division even for tasks that don’t need them would
waste silicon area and money on every chip. Instead those making RISC-V
processors have great freedom to choose, and indeed some would say they
have too much freedom.</p>
<p>For us… Honestly, I’m just glad we’ve been dealt a hand that we can
tackle completely in full. There’s no way I’m finishing writing this
tutorial if RV32I wasn’t so bare boned.</p>
<h2 id="summary-of-computational-instructions">Summary of computational instructions</h2>
<p>(Operand <code>a</code> is <code>rs1</code>, and <code>b</code> is
<code>rs2</code> or immediate. In the instruction name <code>[i]</code>
means an immediate variant is available. Subscript <code>u</code> means
unsigned and <code>s</code> means two’s complement signed.)</p>
<table>
<colgroup>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>Instruction</th>
<th>Operation</th>
<th>Immediate range</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>add[i]</code></td>
<td><code>a + b</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>sub</code></td>
<td><code>a - b</code></td>
<td>(n/a)</td>
</tr>
<tr>
<td><code>slt[i]</code></td>
<td><code>(a &lt;<sub>s</sub> b) ? 1 : 0</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>slt[i]u</code></td>
<td><code>(a &lt;<sub>u</sub> b) ? 1 : 0</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>xor[i]</code></td>
<td><code>a ^ b</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>or[i]</code></td>
<td><code>a | b</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>and[i]</code></td>
<td><code>a &amp; b</code></td>
<td><code>[-2048, 2047]</code></td>
</tr>
<tr>
<td><code>sll[i]</code></td>
<td><code>a &lt;&lt; b</code></td>
<td><code>[0, 31]</code></td>
</tr>
<tr>
<td><code>srl[i]</code></td>
<td><code>a &gt;&gt;<sub>u</sub> b</code></td>
<td><code>[0, 31]</code></td>
</tr>
<tr>
<td><code>sra[i]</code></td>
<td><code>a &gt;&gt;<sub>s</sub> b</code></td>
<td><code>[0, 31]</code></td>
</tr>
</tbody>
</table>
<h2 id="intermission-larger-numbers">Intermission: Larger numbers</h2>
<p>The <code>addi</code> instruction has limit on the immediate value.
How do we make bigger values?</p>
<p>The <span id="insn-lui"><em><code>lui</code></em></span> (“load upper
immediate”) instruction takes an immediate in the range
<code>[0, 1048575]</code> (i.e.&nbsp;up to <code>2<sup>20</sup> - 1</code>)
and sets <code>rd</code> to that value left shifted 12 bits:</p>
<pre><code>lui rd, imm20</code></pre>
<p>That was… slightly confusing. Why don’t we give it a try:</p>
<p>
    lui x10, 1
    lui x11, 2
    ebreak
</p>
<p>Instead of <code>li</code> loading a “low” immediate, we control the
<em>upper</em> 20 bits of what we put in the register. After that, we
can use another <code>addi</code> instruction to fill in the lower bits.
For example, if we want <code>0x12345</code>:</p>
<p>
    lui x10, 0x12
    addi x10, x10, 0x345
    ebreak
</p>
<p>For convenience, in assembly you can use <span id="rel-%hi()"><em><code>%hi()</code></em></span> and <span id="rel-%lo()"><em><code>%lo()</code></em></span> to extract the, well,
high 20 and low 10 bits of a value. The previous example could also be
written:</p>
<p>
    lui x10, %hi(0x12345)
    addi x10, x10, %lo(0x12345)
    ebreak
</p>
<p>Letting <code>lui</code> handle the high 20 bits, and
<code>addi</code> for the low 12 bits, you can make any 32-bit
value.</p>
<p>(A small complication arises if you want to use values with bit 11
set. In that case, the immediate operand to <code>addi</code> will have
to be negative. However <code>%hi</code> understands this and adds one
to compensate, so this <code>%hi</code>/<code>%lo</code> combination
does work for everything.)</p>
<h2 id="jumps-and-branches">Jumps and branches</h2>
<p>So far, everything that we’ve had so far can be done on even the most
basic programmer’s calculator. To truly make a computer… do computer
stuff, we’d want loops and conditionals.</p>
<p>In RISC-V parlance, a <span id="term-branch"><em>branch</em></span>
is a conditional transfer of control flow, and a <span id="term-jump"><em>jump</em></span> is an unconditional transfer of
control flow.</p>
<p>I think the branch instructions are slightly simpler, so let’s start
with those.</p>
<h2 id="branches">Branches</h2>
<p>All the branch instruction follow the form “If some comparison, go to
somewhere.” The conditions are:</p>
<ul>
<li><span id="insn-beq"><em><code>beq</code></em></span>:
<code>rs1 == rs2</code> (“equal”)</li>
<li><span id="insn-bne"><em><code>bne</code></em></span>:
<code>rs1 != rs2</code> (“not equal”)</li>
<li><span id="insn-blt"><em><code>blt</code></em></span>:
<code>rs1 &lt; rs2</code> signed (“less than”)</li>
<li><span id="insn-bge"><em><code>bge</code></em></span>:
<code>rs1 &gt;= rs2</code> signed (“greater or equal”)</li>
<li><span id="insn-bltu"><em><code>bltu</code></em></span>:
<code>rs1 &lt; rs2</code> signed (“less than unsigned”)</li>
<li><span id="insn-bgeu"><em><code>bgeu</code></em></span>:
<code>rs1 &gt;= rs2</code> signed (“greater or equal unsigned”)</li>
</ul>
<p>(In case you’re wondering about the confusing choice of ordering
operators here, it’s just that the negation of <code>&lt;</code> is
<code>&gt;=</code>.)</p>
<pre><code>beq rs1, rs2, label
bne rs1, rs2, label
blt rs1, rs2, label
bge rs1, rs2, label
bltu rs1, rs2, label
bgeu rs1, rs2, label</code></pre>
<p>Oh, right, almost forgot to explain what labels are. Labels are
convenience identifiers for addresses at some line of your code. They
are some identifier followed by a colon (like <code>this:</code>). They
can appear on a line of its own, or before any instruction on the line.
You can see which address they point to using the “Dump” button. The
third operand of a branch instruction is a label to jump to if the
condition holds.</p>
<p>Let’s add up all the numbers from 1 to 100:</p>
<p>
    li x10, 100         # i = 100
    li x11, 0           # sum = 0

loop:
    add x11, x11, x10   # sum = sum + i
    addi x10, x10, -1   # i = i - 1
    blt x0, x10, loop   # If i &gt; 0: loop again
                        # Otherwise: done

    ebreak
</p>
<p>You can try your hands on making your favorite loops, like fibonacci
numbers or something. Speaking of trying your hands, just so we’re
ready, here’s what an infinite loop looks like. Try pausing or stopping
the loop, and single stepping through the instructions.</p>
<p>
loop:
    addi x10, x10, 1
    add x11, x11, x10
    beq x0, x0, loop
</p>
<p>(If you know a thing or two about JavaScript in the browser, you’ll
know that a real infinite loop in JavaScript makes the whole page
becomes unresponsive, unless it’s in a worker or something. The “Run”
button here just runs the emulator for a certain number of steps,
pausing by giving back control to the event loop in between.)</p>
<p>(This isn’t the preferred way to write an unconditional jump. We’ll
see what is later.)</p>
<p>By the way, there’s no <code>bgt[u]</code> or <code>ble[u]</code>
because you can just swap <code>rs1</code> and <code>rs2</code> to get
those.</p>
<h2 id="jumps">Jumps</h2>
<p>There are two jump instructions in RISC-V. One of them is <span id="insn-jal"><em><code>jal</code></em></span> “jump and link”, which
sets <code>rd</code> to the address of the following instruction, and
then jumps to a label:</p>
<pre><code>jal rd, label</code></pre>
<p>Another is <span id="insn-jalr"><em><code>jalr</code></em></span>
“jump and link register”, which sets <code>rd</code> to the address of
the following instruction, and then jumps to the address at
<code>imm + rs1</code>.</p>
<pre><code>jalr rd, imm(rs1)</code></pre>
<p>(Actually, the address jumped to is
<code>(imm + rs1) &amp; ~1</code>, i.e.&nbsp;the least significant bit is
cleared. This distinction won’t come up in normal code, like, pretty
much ever.)</p>
<p>Eesh, that’s some funky looking syntax. When you see parentheses like
this, it has something to do with an <em>address</em>. Parens means
address.</p>
<p>That’s… still a lot going on. Let’s take on some simpler cases first:
If <code>rd</code> is <code>x0</code> then the only thing these
instructions do is jumping. We can use it instead of the branch
instructions for an unconditional jump.</p>
<p>
loop:
    # Yes this is an infinite loop.
    # You can see that we execute
    # this one instruction over and over
    jal x0, loop
</p>
<p>For convenience, a pseudoinstruction is available for you: <span id="insn-j"><em><code>j</code></em></span> (“jump”) is for
<code>jal</code> with <code>rd</code> being <code>x0</code>:</p>
<pre><code>j label</code></pre>
<p>As for why you would want to do this… Well, we only have 32 bits per
instruction, and since the <code>jal</code> instruction only needs one
register number instead of the branch instructions’ two, and it doesn’t
need a condition, the instruction encoding permits jumping over a longer
range. So this is always preferred over something like
<code>beq x0, x0, label</code> for a jump.</p>
<p>As for <code>jalr</code>, you can jump to an address that’s stored in
a register. In C, that would be dealing with function pointers. You’d
need this any time dynamic dispatch is needed. For example, we load the
address of <code>foo</code> into a register first before jumping to
it.</p>
<p>
    lui x10, %hi(foo)
    addi x10, x10, %lo(foo)
    jalr x0, 0(x10)

    # This isn't executed
    li x12, 1
    ebreak

foo:
    # This is executed
    li x12, 2
    ebreak
</p>
<p>In case you forgot by now, the <code>lui</code>/<code>addi</code>
combo at the start puts the address of the label <code>foo</code> in
register <code>x10</code>.</p>
<p>Similar to <code>j</code>, <span id="insn-jr"><em><code>jr</code></em></span> (“jump register”) is a
psuedoinstruction for <code>jalr</code> with <code>rd</code> being
<code>x0</code> and <code>imm</code> being <code>0</code>:</p>
<pre><code>jr rs1</code></pre>
<p>Hmmm… If I didn’t really need the address in <code>x10</code>, that
<code>addi</code> would be unnecessary, since <code>jalr</code> has the
ability to add a low immediate on its own:</p>
<p>
    lui x10, %hi(foo)
    jalr x0, %lo(foo)(x10)

    # This isn't executed
    li x12, 1
    ebreak

foo:
    # This is executed
    li x12, 2
    ebreak
</p>
<p>What’s the advantage of this over <code>jal x0</code>? Since
<code>%hi</code> and <code>%lo</code> can represent any 32-bit value,
this two-instruction combo can jump to any address, free from range
restrictions. You do need a free scratch register for the high part of
the address though, but since RISC-V gives you 31 of them, this
shouldn’t be too much of a problem.</p>
<h2 id="jump-and-link">Jump and link</h2>
<p>What’s the deal with the destination register then? What do you need
the address of the next instruction for? For jumping <em>back</em> of
course. We can use this functionality to call functions and return
back.</p>
<p>
    li x10, 1
    jal x1, double  # Call double
    jal x1, double  # Call double
    ebreak

    # Double the value in x10
double:
    add x10, x10, x10
    jr x1           # Return
</p>
<p>Note that I used the register <code>x1</code> for this, which is the
register for providing the return address by convention. For
convenience, if the destination register is omitted in <code>jal</code>,
it defaults to <code>x1</code>. Meanwhile, <span id="insn-ret"><em><code>ret</code></em></span> (“return”) is a
pseudoinstruction that stands for <code>jr x1</code>,
i.e.&nbsp;<code>jalr x0, 0(x1)</code>:</p>
<pre><code>jal label
ret</code></pre>
<p>So the example above can be rewritten more conveniently as:</p>
<p>
    li x10, 1
    jal foo
    jal foo
    ebreak

foo:
    add x10, x10, x10
    ret
</p>
<h2 id="memory">Memory</h2>
<p>That’s a nice computer we have here. Now we have… all of 31 × 4 = 124
bytes of storage in the form of registers to work with. I want more…</p>
<h2 id="basic-memory-accesses">Basic memory accesses</h2>
<p>The emulator has 1 MiB of memory starting at address
<code>0x4000_0000</code>. That’s <code>0x4000_0000</code> to
<code>0x400f_ffff</code>, inclusive. The assembler starts assembling at
the beginning of memory, as you can see in the dump, starting at address
<code>0x4000_0000</code>.</p>
<p>The <span id="dir-.word"><em><code>.word</code></em></span> <span id="term-directive"><em>directive</em></span> straight up puts a
4-byte/32-bit word into the current position. You can specify multiple
values separated by commas.</p>
<pre><code>.word value [ , value [ , ...  ] ]</code></pre>
<p>The <span id="insn-lw"><em><code>lw</code></em></span> (“load word”)
instruction loads a word from the address <code>rs1 + imm</code> and
puts it in <code>rd</code>, in other words it reads the word from
memory:</p>
<pre><code>lw rd, imm(rs1)</code></pre>
<p>As with <code>jalr</code>, you can combine it with <code>lui</code>
to access any address.</p>
<p>
    lui x10, %hi(foo)
    lw x11, %lo(foo)(x10)
    ebreak

foo:
    # Get it? foo, f00 ...
    .word 0xf00
</p>
<p>The <span id="insn-sw"><em><code>sw</code></em></span> (“store word”)
instruction stores <code>rs2</code> to a word in memory at address
<code>rs2 + imm</code>, in other words it writes the word to memory:</p>
<pre><code>sw rs2, imm(rs1)</code></pre>
<p>
    lui x10, %hi(foo)
    lw x11, %lo(foo)(x10)

    li x12, 0x123
    sw x12, %lo(foo)(x10)

    # Now it's changed
    lw x13, %lo(foo)(x10)
    ebreak

foo:
    .word 0xf00
</p>
<p>Just to make absolutely sure we’re clear on this, <span id="term-load"><em>load</em></span> means reading from memory, <span id="term-store"><em>store</em></span> means writing to memory. Both
words can be nouns and verbs. Also, a <span id="term-word"><em>word</em></span> is 32-bit for RISC-V.</p>
<p>Let’s have some fun. Can we have the program read itself?</p>
<p>
here:
    lui x10, %hi(here)
    lw x10, %lo(here)(x10)
    ebreak
</p>
<p>Ohh that’s fun. Does this mean I can also write programs with just
<code>.word</code>?</p>
<p>
    .word 0x40000537 # lui x10, %hi(here)
    .word 0x00052503 # lw x10, %lo(here)(x10)
    .word 0x00100073 # ebreak
</p>
<p>Oh that’s nice. Just a peek into the world of machine code and
instruction encodings… which we will not be getting into.</p>
<p>With memory accesses under our belt, we can address a lot more data
easily. Here’s an example where we find the sum of all the values in an
array. Note how we can access different addresses of memory, whereas
there is no way to address a register by a number in another
register.</p>
<p>
    lui x10, %hi(array)
    addi x10, x10, %lo(array)

    li x11, 8   # length

    # Get end address
    slli x11, x11, 2
    add x11, x11, x10

    li x12, 0 # sum

loop:
    # If current == end, done
    beq x10, x11, end
    lw x13, 0(x10)      # Load from array
    add x12, x12, x13   # Add to sum
    addi x10, x10, 4    # Bump current pointer
    j loop

end:
    ebreak


array:
    .word 13, 24, 6, 7, 8, 19, 0, 4
</p>
<p>The equivalent in C would be something like</p>
<pre><code>uint32_t array[], length;

uint32_t *current = array;
uint32_t *end = array + length;
uint32_t sum = 0;

for (; current != end; current ++) {
    sum += *current;
}</code></pre>
<p>Note how adding one to a pointer to word bumps the address by 4,
because the addresses are all byte addresses, and one word is four
bytes. In C, the compiler handles the multiplier for you, but in
assembly you have to remember to do it manually.</p>
<!-- TODO: I need some memory dump thing to make useful examples of `sw` -->
<h2 id="smaller-widths">Smaller widths</h2>
<p>Not everything in memory is word sized. You’ve already seen an array,
which is multiple-word-sized. There are also stuff smaller than
word-sized.</p>
<p>An obvious one is the <span id="term-byte"><em>byte</em></span>,
which is, well, 1-byte/8-bit and written <code>[u]int8_t</code> in C. In
the middle is the <span id="term-halfword"><em>halfword</em></span>,
which is 2-byte/16-bit and written <code>[u]int16_t</code> in C. You can
use the directives <span id="dir-.byte"><em><code>.byte</code></em></span> and <span id="dir-.half"><em><code>.half</code></em></span> respectively for those
data types.</p>
<pre><code>.byte value [ , value [ , ...  ] ]
.half value [ , value [ , ...  ] ]</code></pre>
<p>And just in case you don’t remember those, <span id="dir-.2byte"><em><code>.2byte</code></em></span> means the same as
<code>.half</code>, and <span id="dir-.4byte"><em><code>.4byte</code></em></span> means the same as
<code>.word</code>.</p>
<pre><code>.2byte value [ , value [ , ...  ] ] # Same as .half
.4byte value [ , value [ , ...  ] ] # Same as .word</code></pre>
<p>There’s a small problem with loading smaller-than-word sized values
into word-sized registers: What do you do with the rest of the bits?
Obviously the lowest of the bits gets the actual value loaded. There are
two most useful ways to fill the upper bits:</p>
<ul>
<li><span id="term-zero-extension"><em>zero extension</em></span>: The
higher bits are filled with zeros</li>
<li><span id="term-sign-extension"><em>sign extension</em></span>: The
higher bits are filled with copies of the highest bit of the original
value</li>
</ul>
<p>Zero extension is easy enough. As the name suggests, sign extension
has something to do with signed values. It’s what happens when you
convert a narrower signed value into a wider one.</p>
<p>(Keeping the rest of the bits unchanged isn’t a good option. It
complicates the implementation for processor, especially of modern high
performance design, to just write parts of a register. It would be
easiest if the new value didn’t depend on the old value.)</p>
<p>For example, the signed byte value <code>-100</code> is
<code>0x9c</code>. Since the highest bit i.e. the sign bit of it is
<code>1</code>, when we expand it into 32 bits we fill the high 24 bits
with one so the new value, <code>0xffff_ff9c</code> still represents
<code>-100</code>. This is sign extension.</p>
<p>If we want to convert the unsigned byte value <code>156</code>, still
<code>0x9c</code>, into an unsigned word, it would have to be
<code>0x0000_009c</code> to preserve its value.</p>
<p>For bytes, the <span id="insn-lb"><em><code>lb</code></em></span>
(“load byte”) instruction loads a byte and sign extends the result, and
the <span id="insn-lbu"><em><code>lbu</code></em></span> (“load byte
unsigned”) instruction does the same but zero extends the result. As
with <code>lw</code>, the address is <code>rs1 + imm</code>.</p>
<pre><code>lb rd, imm(rs1)
lbu rd, imm(rs1)</code></pre>
<p>Similarly for <span id="insn-lh"><em><code>lh</code></em></span>
(“load half”) and <span id="insn-lhu"><em><code>lhu</code></em></span>
(“load half unsigned”), just for unsigned halfwords (two bytes each,
remember):</p>
<pre><code>lh rd, imm(rs1)
lhu rd, imm(rs1)</code></pre>
<p>We can try out the sign extension and zero extension example from
earlier.</p>
<p>
    # Signed
    li x10, -100
    lui x11, %hi(test)
    lb x11, %lo(test)(x11)

    # Unsigned
    li x12, 156
    lui x13, %hi(test)
    lbu x13, %lo(test)(x13)

    ebreak

test:
    .byte 0x9c
</p>
<p>Correspondingly, the <span id="insn-sb"><em><code>sb</code></em></span> (“store byte”) and <span id="insn-sh"><em><code>sh</code></em></span> (“store half”) do the
opposite of <code>lb</code> and <code>lh</code>, storing bytes and
halfwords to memory. Instead of widening small values to register size,
these take the lowest order bits from <code>rs1</code> and stores it to
memory. (There’s no <code>sbu</code> and <code>shu</code> because stores
are narrowing instead of widening operations.)</p>
<pre><code>sb rs2, imm(rs1)
sh rs2, imm(rs1)</code></pre>
<p>While we’re at it, here’s two more minor details. Firstly, <span id="term-endianness"><em>endianness</em></span>. While theoretically big
endian RISC-V machines can exist, I’ve never seen one… and this emulator
is little endian, meaning that the four bytes in a word are laid out in
memory lowest first. So, <code>.byte 0x1, 0x2, 0x3, 0x4</code> would be
the same as <code>.word 0x04030201</code>.</p>
<p>
    lui x10, %hi(test)
    lw x10, %lo(test)(x10)
    ebreak

test:
    .byte 0x1, 0x2, 0x3, 0x4
</p>
<p>Secondly, memory accesses should be <span id="term-aligned"><em>aligned</em></span> for maximum efficiency. This
means that the address for a halfword/2byte should be a multiple of two,
and the address for a word/4byte should be a multiple of four.
Misaligned accesses (meaning, well, when the address is not aligned) may
not work as expected.</p>
<p>For user programs running on a rich operating systems, misaligned
accesses are supported but may be slow. In embedded application running
on microcontrollers and such, it might not work at all.</p>
<p>This emulator supports misaligned memory accesses.</p>
<p>
    lui x10, %hi(test)
    addi x10, x10, %lo(test)

    lw x11, 0(x10)
    lw x12, 1(x10)
    lw x13, 3(x10)

test:
    .byte 1, 2, 3, 4, 5, 6, 7, 8
</p>
<p>Now you can try translating some basic C code into RISC-V assembly.
Functions are… still out of the question for now. Variables have to be
either global or put in registers. What else are we missing…</p>
<h2 id="memory-mapped-io">Memory-mapped I/O</h2>
<p>Is it Hello World time? I think it’s Hello World time…</p>
<p>For a computer to not just be a space heater, we need some way for it
to at least generate output and take input. While other architectures
may have dedicated I/O instructions, RISC-V uses <span id="term-memory-mapped-i/o"><em>memory mapped I/O</em></span>.
Essentially, this means that loads and stores to special addresses
communicate with other <span id="term-devices"><em>devices</em></span>.
They do not work like normal memory, and you should only use the
supported widths to access them.</p>
<p>One output device we have here is at address
<code>0x1000_0000</code>. Any 32-bit writes to it appends the lowest 8
bits as a byte to the text in the output pane. In other words, a
<code>sw</code> to that address writes a byte of output.</p>
<p>(The output pane uses UTF-8 encoding.)</p>
<!-- TODO: Uhh... Make the assembler support character and string literals? -->
<p>
    lui x11, %hi(0x10000000)
    li x10, 0x48 # 'H'
    sw x10, 0(x11)
    li x10, 0x69 # 'i'
    sw x10, 0(x11)
    li x10, 0x21 # '!'
    sw x10, 0(x11)
    li x10, 0x0a # '\n'
    sw x10, 0(x11)
    ebreak
</p>
<p>Eh, close enough to greeting the entire world. We could refactor it a
bit to use a loop, or whatever… Now that we think about it, how about
going one step further and organize our code into some functions?</p>
<h2 id="functions">Functions</h2>
<p>We already know how to call a function and return back. Namely,
<code>jal</code> calls a function, and <code>ret</code> returns. Usually
functions take arguments, uses local variables, and returns results.
Since there’s no real difference between the 31 general purpose
registers, on account of them being, well, general purpose, we could
just use any of them as we wish. Usually though, there are some standard
conventions to follow</p>
<h2 id="register-aliases-and-calling-conventions">Register aliases and calling conventions</h2>
<p>This whole time you probably have noticed that registers are listed
with two names each, and indeed both work identically in assembly.</p>
<p>
    li x10, 1
    li a0, 1
    ebreak
</p>
<p>These <span id="term-register-aliases"><em>register
aliases</em></span> are named after their uses:</p>
<ul>
<li><span id="regalias-s0-through-s11"><em><code>s0</code> through
<code>s11</code></em></span> are <em>saved</em> registers</li>
<li><span id="regalias-t0-through-t6"><em><code>t0</code> through
<code>t6</code></em></span> are <em>temporary</em> registers</li>
<li><span id="regalias-a0-through-a7"><em><code>a0</code> through
<code>a7</code></em></span> are <em>argument</em> registers</li>
<li><span id="regalias-zero"><em><code>zero</code></em></span> is the,
well, zero register</li>
<li><span id="regalias-ra"><em><code>ra</code></em></span> is for the
return address, by convention, as we’ve seen</li>
<li><span id="regalias-sp"><em><code>sp</code></em></span> … we’ll talk
about <code>sp</code> later</li>
<li>(The use of <span id="regalias-tp"><em><code>tp</code></em></span>
and <span id="regalias-gp"><em><code>gp</code></em></span> is out of the
scope of this document.)</li>
</ul>
<p>(Yeah it’s… all placed in a weird order. The reason is out of the
scope of this tutorial.)</p>
<p>When you call a function, you put up to eight arguments in the… well,
argument registers, in the order <code>a0</code>, <code>a1</code>, …,
<code>a7</code>. After that you use <code>jal</code> or something, which
puts the return address in <code>ra</code>, and jumps to the
function.</p>
<p>Inside, the function, if it wishes to use the <span id="term-call-saved"><em>call-saved</em></span> registers
<code>s0</code> through <code>s11</code>, it must save their values at
the start of the function, and restore them before returning. The non
call-saved registers <code>a0</code> through <code>a7</code>,
<code>t0</code> through <code>t6</code> and <code>ra</code> may be
modified without restoring their values.</p>
<p>When the called function is done, it would, as mentioned, restore any
used call-saved registers, and jump back to the return address, resuming
the calling code.</p>
<p>Here’s a basic-ish example:</p>
<pre><code>int memcmp(const void *a, const void *b, size_t n)</code></pre>
<p>The parameter <code>a</code> is passed in <code>a0</code>,
<code>b</code> is passed in <code>a1</code>, and <code>n</code> is
passed in <code>a2</code>. The return value will be in <code>a0</code>.
Here’s an implementation and test run:</p>
<p>
    # memcmp(test1, test2, 4)

    lui a0, %hi(test1)
    addi a0, a0, %lo(test1)
    lui a1, %hi(test2)
    addi a1, a1, %lo(test2)
    li a2, 4
    jal memcmp
    ebreak

    # int memcmp(const void *a, const void *b, size_t n);
memcmp:
    add a3, a0, a2 # a3 = a + n
    li t0, 0

memcmp_loop:
    beq a0, a3, memcmp_done # No more bytes

    lb t0, 0(a0)
    lb t1, 0(a1)
    sub t0, t0, t1  # t0 = *a - *b

    bne t0, zero, memcmp_done # If different, done

    addi a0, a0, 1  # a ++
    addi a1, a1, 1  # b ++

    j memcmp_loop

memcmp_done:
    mv a0, t0
    ret

test1:
    .byte 1, 2, 3, 4
test2:
    .byte 1, 2, 2, 4
</p>
<p>Here’s a slightly better-organized “Hello World”, using a
<code>puts</code> function:</p>
<p>
    lui a0, %hi(msg)
    addi a0, a0, %lo(msg)
    jal puts
    ebreak

    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
puts_loop:
    lb t0, 0(a0)
    beq t0, zero, puts_done
    sw t0, 0(t1)
    addi a0, a0, 1
    j puts_loop

puts_done:
    ret

msg:
    .byte 0x48, 0x65, 0x6c, 0x6c, 0x6f, 0x2c, 0x20, 0x77
    .byte 0x6f, 0x72, 0x6c, 0x64, 0x21, 0x0a, 0x00
</p>
<h2 id="the-stack">The stack</h2>
<p>Although we can write some very basic functions now, there are still
a few problems:</p>
<ul>
<li>You can’t call a function within another function because if you do
so <code>ra</code> would be overwritten, and then you can’t return back
from the outer function anymore.</li>
<li>We still don’t know how “saving” registers work.</li>
</ul>
<p>Clearly, both would require using memory somehow. We can feed two
birds with one scone by using memory in a structured way: The <span id="term-stack"><em>stack</em></span>.</p>
<p>Unlike some other architectures, the <code>sp</code> register is not
really special in any way. But just like how we can designate how
<code>a0</code> is used, we can have some conventions about how
<code>sp</code> is supposed to be used:</p>
<ul>
<li>The register is call-saved, which means that when you return from a
function, <code>sp</code> needs to have the same value as when the
function was entered</li>
<li><code>sp</code> <em>always</em> points to somewhere in an area of
memory called the “stack”, and it is <em>always</em> 16-byte
aligned.</li>
</ul>
<p>And, for the stack itself:</p>
<ul>
<li>On RISC-V, the stack grows to lower addresses, meaning that the
memory where <code>address &gt;= sp</code> are “in the stack”, and
<code>address &lt; sp</code> are free space that the stack can grow
into.</li>
<li>Code can allocate space on the stack by decrementing
<code>sp</code>, and deallocate space by incrementing <code>sp</code>.
Of course, allocations and deallocations must be balanced properly.</li>
<li>You can only freely use space that you have allocated.</li>
</ul>
<p>An example is in order. Let’s say you have a function
<code>foo</code> which just calls <code>bar</code> twice.</p>
<pre><code>void foo() {
    bar();
    bar();
}</code></pre>
<p>Inside <code>foo</code>, it would need to save the initial
<code>ra</code>, so it can return back later. Even though
<code>ra</code> takes only 4 bytes, <code>sp</code> needs to be 16-byte
aligned at all times, so we round that up to 16 bytes. Decrementing
<code>sp</code> by 16 we allocate the space:</p>
<pre><code>foo:
    addi sp, sp, -16</code></pre>
<p>Now, in addition to all of the non call-saved registers, we have 16
bytes of scratch space at <code>sp</code> through <code>sp + 15</code>.
We can backup the value of <code>ra</code> here</p>
<pre><code>    ...
    sw ra, 0(sp)</code></pre>
<p>Then we just call <code>bar</code> twice, which overwrites
<code>ra</code>:</p>
<pre><code>    ...
    jal bar
    jal bar</code></pre>
<p>At the end of the function, we just need to get back the return
address, deallocate the stack space, and return. Although using any
register would suffice for the return address, since it is the backed up
value of <code>ra</code> after all, we load it back to
<code>ra</code>.</p>
<pre><code>    ...
    lw ra, 0(sp)
    addi sp, sp, 16
    ret</code></pre>
<p>In a similar way you can save and restore the <code>s</code>
(remember, call-saved) registers. Usually, the most convenient way to
manage this is to put values that need to be preserved across inner
function calls in the <code>s</code> registers, and then add code at the
beginning to save them, and add code at the end to restore them.</p>
<p>Obligatory recursive Fibonacci time!</p>
<p>
    li a0, 10
    jal fib
    ebreak

fib:
    li t0, 2

    # If n &lt; 2, then return n
    bge a0, t0, fib_large
    ret

fib_large:
    # Otherwise, n &gt;= 2

    # Save stuff to stack
    addi sp, sp, -16
    sw ra, 0(sp)
    sw s0, 4(sp)
    sw s1, 8(sp)

    mv s0, a0       # s0 = n
    addi a0, a0, -1 # a0 = n - 1

    jal fib
    mv s1, a0       # s1 = fib(n - 1)

    addi a0, s0, -2
    jal fib         # fib(n - 2)

    add a0, a0, s1

    # Restore stuff from stack and return
    lw ra, 0(sp)
    lw s0, 4(sp)
    lw s1, 8(sp)
    addi sp, sp, 16
    ret
</p>
<p>The algorithm should be fairly straightforward:</p>
<pre><code>fibonacci(n) {
    if (n &lt; 2) { return n; }
    else { return fib(n - 1) + fib(n - 2); }
}</code></pre>
<p>What’s worth noting here is the fairly symmetric pattern of saving
registers at the start:</p>
<pre><code>    addi sp, sp, -16
    sw ra, 0(sp)
    sw s0, 4(sp)
    sw s1, 8(sp)</code></pre>
<p>And restoring them at the end:</p>
<pre><code>    lw ra, 0(sp)
    lw s0, 4(sp)
    lw s1, 8(sp)
    addi sp, sp, 16
    ret</code></pre>
<p>A little thing to also note that the <code>s</code> registers are
only saved in the more complex branch, where as the simpler branch just
returns directly. This is also acceptable from a calling convention
perspective.</p>
<p>(Note: In the emulator, the <code>sp</code> register is initialized
to an address that would be convenient for you for use as a stack, as a,
well, convenience.)</p>
<h2 id="intermission-numeric-labels">Intermission: Numeric labels</h2>
<p>Let’s go back to this example:</p>
<pre><code>    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
puts_loop:
    lb t0, 0(a0)
    beq t0, zero, puts_done
    sw t0, 0(t1)
    addi a0, a0, 1
    j puts_loop

puts_done:
    ret</code></pre>
<p>Having to name things like <code>puts_loop</code>,
<code>puts_done</code> is a bit annoying. There’s a shorter way: <span id="term-numeric-labels"><em>numeric labels</em></span>.</p>
<p>A numeric label is one with a name of a decimal number. To refer to a
numeric label, use the number and a <code>f</code> suffix for “forward”,
and <code>b</code> for “backward”, and it will correspond to the nearest
numeric label with that number, searching forwards or backwards,
respectively.</p>
<p>So, the <code>puts</code> example from earlier can be rewritten:</p>
<pre><code>    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b

2:
    ret</code></pre>
<p>Yeah I don’t really like this syntax either, but it is what we’ve
got.</p>
<h2 id="position-independence">Position independence</h2>
<p>Remember that oddball instruction I mentioned way back,
<code>auipc</code>?</p>
<p>I don’t know about your experience, but the first time I saw RISC-V
disassembly, this is the one instruction that caught my eye. And this
memory has stuck with me ever since. It’s a rather common occurrence in
real RISC-V programs, and somehow I’ve been hiding it from you this
whole time. If you take a sneak peek at the next section’s title, you’ll
see how far we’ve come without <code>auipc</code>.</p>
<p>So what does it do?</p>
<p>The <span id="insn-auipc"><em><code>auipc</code></em></span> (“add
upper immediate to pc”) instruction is very similar to <code>lui</code>.
Instead of setting <code>rd</code> to <code>imm20 &lt;&lt; 12</code>, it
sets it to <code>pc + (imm20 &lt;&lt; 12)</code>, where <code>pc</code>
is the address of the <code>auipc</code> instruction itself.</p>
<pre><code>auipc rd, imm20</code></pre>
<p>It works very similarly to <code>lui</code>. You can think of them as
a pair: the “base” of <code>lui</code> is <code>0</code>, whereas the
“base” of <code>auipc</code> is the address of the <code>auipc</code>
instruction. So this code:</p>
<pre><code>start:
    auipc a0, 3
    addi a0, a0, 4</code></pre>
<p>Gives you <code>0x3004</code>, whereas this:</p>
<pre><code>start:
    auipc a0, 3
    addi a0, a0, 4</code></pre>
<p>Gives you <code>start + 0x3004</code>.</p>
<p>Why would you need this? On modern systems, it’s often desirable to
have machine code that can be moved around in address space. For
example, a shared library i.e.&nbsp;dynamically linked library can be loaded
into any program, at any address. It would be helpful if the machine
code does not need to be patched every time. This is called <span id="term-position-independent-code"><em>position independent
code</em></span> (<span id="term-pic"><em>PIC</em></span>).</p>
<p>Some instructions already exhibit position independence. For example,
as mentioned earlier when we talked about using <code>lui</code> and
<code>jalr</code> as a pair, the branch instructions and
<code>jal</code> are encoded, as with all RV32I instructions, into
32-bit instruction words, so they can’t possibly be able to encode every
possible address. Instead, the jump destination is <code>pc</code> plus
some offset (<code>pc</code> being, as before, the jump/branch
instruction itself), and the offset itself is encoded.</p>
<p>You can see these are three different instructions that jump to
itself. Since the offset is <code>0</code> in each case, the encoding is
the same. Use the “Dump” button to see for yourself.</p>
<p>
    ebreak

test1:
    j test1

test2:
    j test2

test3:
    j test3
</p>
<p>The <code>auipc</code> instruction allows for very flexible position
independence. You can make arbitrary calculations based on the address
at which code is located. The immediate-bit operand mirroring
<code>lui</code> means that it is well suited for two-instruction pairs,
just like <code>lui</code>. These kind of “<code>pc</code> plus
something” calculations are known as <span id="term-pc-relative-addressing"><em>pc-relative
addressing</em></span>.</p>
<p>The syntax for getting the assembler to generate the immediate values
for pc-relative addressing a bit arcane but hear me out:</p>
<p>
1:
    auipc a0, %pcrel_hi(foo)
    addi a0, a0, %pcrel_lo(1b)
    ebreak

foo:
    .word 0x12345
</p>
<p>Like <code>%hi()</code> and <code>%lo()</code>, <span id="rel-%pcrel_hi()"><em><code>%pcrel_hi()</code></em></span> and <span id="rel-%pcrel_lo()"><em><code>%pcrel_lo()</code></em></span> gives you
the immediate values needed for pc-relative addressing. You pass the
label you want to address to <code>%pcrel_hi()</code>, but pass a label
to <em>the <code>auipc</code> instruction</em> to
<code>%pcrel_lo()</code>.</p>
<p>Unlike <code>%lo()</code>, We need the address of the
<code>auipc</code> instruction itself to calculate the immediate value,
and this is why you need to pass a label to it. You don’t need to write
<code>foo</code> again, since the assembler will look at the
<code>auipc</code> instruction and see it’s supposed to be for
<code>foo</code>.</p>
<p>If you hate writing that, you can also use the convenience
pseudoinstruction <span id="insn-la"><em><code>la</code></em></span>:</p>
<pre><code>la rd, label</code></pre>
<p>Just like a <code>lui</code> + <code>jalr</code> pair, an
<code>auipc</code> + <code>jalr</code> can be used to jump to somewhere
farther away than one <code>jal</code> can reach in position-independent
code.</p>
<p>One very common case is to call a function that might not be within
reach of <code>jal</code>. You can use the pseudoinstruction <span id="insn-call"><em><code>call</code></em></span> for that.</p>
<pre><code>call label</code></pre>
<p>This expands to:</p>
<pre><code>1:
    auipc ra, %pcrel_hi(label)
    jalr ra, %pcrel_lo(1b)(ra)</code></pre>
<p>Notice how <code>ra</code> is used as a temporary register to store
the intermediate result, which is immediately overwritten by
<code>jalr</code>.</p>
<p>In fact, there really isn’t any reason to prefer <code>lui</code>
over <code>auipc</code> when using a label. This is why you if you
disassemble a real RISC-V program, you see it everywhere, even in
non-position-independent code.</p>
<p>Now would be a good time to take a break, since we’re ready to head
into…</p>
<h2 id="privileged-architecture-fundamentals">Privileged architecture fundamentals</h2>
<p>We’re going to write an <em>extremely</em> bare bones operating
system.</p>
<h2 id="privilege-levels">Privilege levels</h2>
<p>One of the tasks an operating system performs is to control what
programs can and cannot do. On RISC-V, the most basic of this control is
implemented using <span id="term-privilege-levels"><em>privilege
levels</em></span>. RISC-V defines… let’s just say, several privilege
levels, but we’re only going to use two here:</p>
<ul>
<li>“<span id="term-machine"><em>Machine</em></span>”, number 3</li>
<li>“<span id="term-user"><em>User</em></span>”, number 0</li>
</ul>
<p>The lower the privilege level number goes, the less privileged that
level is. Higher privilege levels treat lower privilege levels as
generally completely unreliable and untrusted, and must isolate
themselves from adversarial software and failures of lower privilege
levels.</p>
<p>(However, we won’t be talking about all of the features that make
this full isolation possible, and the emulator you’ve been seeing does
not have enough features for that anyway. Therefore, the operating
system we’ll be building will leave itself unprotected in various
ways.)</p>
<p>The privilege levels are sometimes called “<span id="term-modes"><em>modes</em></span>” for short. And, if that’s not
short enough, we can shorten the level names themselves, ending up with
<span id="term-m-mode"><em>M-mode</em></span> and <span id="term-u-mode"><em>U-mode</em></span>. All of the ways to refer to
these privilege levels are interchangable.</p>
<p>When a RISC-V machine starts (This is known as “<span id="term-reset"><em>reset</em></span>”), it begins execution in Machine
mode. On a typical “embedded” system where only Machine mode and User
mode are implemented, execution begins in the initialization code read
from flash memory. This code can either perform what needs to be done
itself, or it can be an operating system that manages some tasks, each
executing in User mode.</p>
<p>The former design is used for simpler programs, and is analogous to
the programs we’ve seen and run so far. The latter is more complicated.
We’ll see the basics of how to achieve that soon.</p>
<h2 id="control-and-status-registers-csrs">Control and status registers (CSRs)</h2>
<p>The <span id="term-control-and-status-registers"><em>control and
status registers</em></span> (<span id="term-csrs"><em>CSRs</em></span>)
deal with various features that are in some sense “special”. No I don’t
have a better explanation of what “special” means.</p>
<p>Six instructions are available for manipulating CSRs.</p>
<pre><code>csrrw rd, csr, rs1
csrrs rd, csr, rs1
csrrc rd, csr, rs1
csrrwi rd, csr, uimm5
csrrsi rd, csr, uimm5
csrrci rd, csr, uimm5</code></pre>
<p>To refer to a CSR in these instructions, use its name in assembly
code. We’ll get to those in a bit.</p>
<p>The pattern works like this. Each of the instructions
<em>atomically</em> reads the old value of the CSR, and writes the new
value based on some operation performed on the old value and the last
operand. The possible operations are:</p>
<ul>
<li><span id="insn-csrrw"><em><code>csrrw</code></em></span> (“CSR read
write”): <code>{ csr = rs1; rd = csr_old; }</code></li>
<li><span id="insn-csrrs"><em><code>csrrs</code></em></span> (“CSR read
set”): <code>{ csr = csr | rs1; rd = csr_old; }</code></li>
<li><span id="insn-csrrc"><em><code>csrrc</code></em></span> (“CSR read
clear”): <code>{ csr = csr &amp; ~rs1; rd = csr_old; }</code></li>
</ul>
<p>Where <code>&amp;</code>, <code>|</code>, <code>~</code> are bitwise
“and”, “or”, “not” respectively.</p>
<p>Specifically, note that <code>rd</code> and <code>rs1</code> can be
the same. For example, this instruction swaps the value in
<code>a0</code> and <code>mscratch</code>:</p>
<pre><code>csrrw a0, mscratch, a0</code></pre>
<p>For the “immediate” variants, instead of a register, they take an
“unsigned”/zero-extended 5-bit immediate value, i.e.&nbsp;an immediate value
0 through 31, inclusive. This is represented using <code>uimm5</code> in
the assembly syntax description. The operation is the same
otherwise.</p>
<ul>
<li><span id="insn-csrrwi"><em><code>csrrwi</code></em></span> (“CSR
read write immediate”): <code>{ csr = uimm5; rd = csr_old; }</code></li>
<li><span id="insn-csrrsi"><em><code>csrrsi</code></em></span> (“CSR
read set immediate”):
<code>{ csr = csr | uimm5; rd = csr_old; }</code></li>
<li><span id="insn-csrrci"><em><code>csrrci</code></em></span> (“CSR
read clear immediate”):
<code>{ csr = csr &amp; ~uimm5; rd = csr_old; }</code></li>
</ul>
<p>The full feature set of these instructions are designed for
manipulating bit fields in CSRs, which we will not be doing that much of
in this tutorial. Still, this orthogonal design should be fairly
intuitive to remember.</p>
<p>CSRs and fields in CSRs do not behave like general purpose registers:
Some of them are read/write, some are read-only. Also, invalid values
have special behaviors. We will touch on more details as we introduce
the individual CSRs themselves, but one thing you may have noticed is
that we don’t seem to have read-only CSR instructions. Read-only access
is achieved using special cases in the instruction encodings:</p>
<ul>
<li><code>csrrs</code> and <code>csrrc</code> do not write to the CSR if
<code>rs1</code> is <code>x0</code> (a.k.a. <code>zero</code>) (Note
that just the value of <code>rs1</code> being 0 is not enough.)</li>
<li><code>csrrsi</code> and <code>csrrci</code> do not write to the CSR
if <code>uimm5</code> is 0.</li>
</ul>
<p>While we’re at it:</p>
<ul>
<li><code>csrrw</code> and <code>csrrwi</code> do not read the CSR if
<code>rd</code> is <code>x0</code> (a.k.a. <code>zero</code>). (Note
that writing to <code>x0</code> has no effect anyway, since it’s
constant 0.)</li>
</ul>
<p>(No standard RISC-V CSR is write-only, or has side effects on
read.)</p>
<p>As a convenience, the pseudoinstructions <span id="insn-csrr"><em><code>csrr</code></em></span> (“CSR read”) and <span id="insn-csrw"><em><code>csrw</code></em></span> (“CSR write”) are
available. <code>csrw csr, rs1</code> expands to
<code>csrrw x0, csr, rs1</code>. Meanwhile, <code>csrr rd, csr</code>
expands specifically to <code>csrrs rd, csr, x0</code>, just so we can
agree on an encoding.</p>
<pre><code>csrw csr, rs1
csrr rd, csr</code></pre>
<p>You may have seen these CSR things if you’ve scrolled down on the
register view. Yes, we’re finally getting into those.</p>
<h2 id="counters">Counters</h2>
<p>An example of CSRs is <span id="term-counters"><em>counters</em></span>. Two basic read-only
counters are <span id="csr-cycle"><em><code>cycle</code></em></span> and
<span id="csr-instret"><em><code>instret</code></em></span>. These
counters, well, <em>count</em> the number of “cycles” and “instructions
retired”. “Retired” is a technical term basically meaning “successfully
completed”.</p>
<p>Since a 32-bit counter will overflow quite fast, on RV32, the
counters have “high” counterparts: <span id="csr-cycleh"><em><code>cycleh</code></em></span> and <span id="csr-instreth"><em><code>instreth</code></em></span>. So, for
example, the full cycle counter has 64 bits, with the lower 32 bits in
the CSR <code>cycle</code> and higher 32 bits in the CSR
<code>cycleh</code>.</p>
<p>While the emulator is running, scroll down on the register view
panel, and on the bottom you’ll see the values of these counters. For
convenience, they’re shown combined, so,
<code>cycle = 0x11223344_55667788</code> means <code>cycleh</code> is
<code>0x11223344</code>, and <code>cycle</code> is
<code>0x55667788</code>.</p>
<p>On real hardware <code>cycle</code> is coupled to the clock cycle. In
this emulator, every time you press “Step”, it counts as a cycle. When
you press “Run” and it starts, well, running, a certain number of cycles
happen periodically.</p>
<p>Let’s look at a really simple example:</p>
<p>
    addi a0, a0, 1
    addi a0, a0, 1
    addi a0, a0, 1
    ebreak
</p>
<p>It takes 4 cycles for this program to stop, but <code>instret</code>
ends up at only 3 because the final <code>ebreak</code> instruction
never actually completes.</p>
<p>(Do not confuse “retired” with “retried”.)</p>
<p>A program can read its own counters. For example, this fun little
program loops until the cycle count is over 1000, assuming the low 32
bits doesn’t overflow before it has time to react:</p>
<p>
    li t1, 1000
loop:
    csrr t0, cycle
    blt t0, t1, loop

    ebreak
</p>
<h2 id="current-privilege-level">Current privilege level</h2>
<p>Technically <code>cycle</code> and <code>instret</code> are not part
of the privileged architecture. The real fun begins <em>now</em>.</p>
<p>The emulator shows the current privilege level as
<code>(priv)</code>. It is in parentheses to remind you of a very
important fact:</p>
<p><em>There is no CSR for the current privilege level.</em></p>
<p>In general, it is not possible for a RISC-V program to learn what
privilege level it’s in. This is required for the <a href="https://en.wikipedia.org/wiki/Popek_and_Goldberg_virtualization_requirements">Popek
and Goldberg conditions of virtualization</a> to work, specifically
because being able to read the current privilege level at a
lower-than-maximum privilege level would be a “sensitive” but
“unprivileged” instruction.</p>
<p>If you’re writing a program for a certain privilege level, you should
simply assume that it is correctly being run at that privilege
level.</p>
<h2 id="exceptions">Exceptions</h2>
<h2 id="exception-entry">Exception entry</h2>
<p>A fundamental way an operating system does its job is through
handling exceptions. In general, <span id="term-exceptions"><em>exceptions</em></span> occur when there’s a
problem with a specific instruction, and execution cannot continue. For
example, since <code>cycle</code> is a read-only CSR, writing to it is
an illegal instruction:</p>
<p>
    csrw cycle, x0
</p>
<p>Since we have no exception handling in the program, we’ll have to
inspect what happened manually in the emulator. Indeed, a lot has
happened:</p>
<p>Firstly, this message tells you that an exception happened:</p>
<pre><code>[ Exception: Illegal instruction (2) | tval = 0xc0001073, epc = 0x4000000c ]</code></pre>
<p>The same information is now also available in the CSRs, as
follows:</p>
<ul>
<li><span id="csr-mcause"><em><code>mcause</code></em></span> (“M-mode
trap cause”): The kind of exception.</li>
<li><span id="csr-mepc"><em><code>mepc</code></em></span> (“M-mode
exception pc”): The address of the instruction that caused the
exception.</li>
<li><span id="csr-mtval"><em><code>mtval</code></em></span> (“M-mode
trap value”): Extra information about the exception.</li>
<li><span id="csr-mstatus"><em><code>mstatus</code></em></span> (“M-mode
status”): It is set to <code>0x00001800</code>. The two bits in the
middle, <code>mstatus[12:11]</code> (In C syntax,
<code>(mstatus &gt;&gt; 11) &amp; 0x3</code>) is the
<code>mstatus.MPP</code> (“M-mode previous privilege level”) field,
which contains 3, meaning that the exception occurred while running in
Machine mode.</li>
</ul>
<p>When an exception happens, in addition to recording the exception
information in these CSR fields, <code>pc</code> is set to
<code>mtvec</code>, which is supposed to be the handler address. Let’s
write ourselves an exception handler that simply prints a message and
stops the emulator, and see the handling in action:</p>
<p>
    la t0, handler
    csrw mtvec, t0

    # Now cause an exception
    csrw cycle, x0

    # Rest of the main program is never executed
    addi a0, a0, 1
    addi a0, a0, 1

handler:
    la a0, msg
    call puts
    ebreak

msg:
    .byte 0x4f, 0x68, 0x20, 0x6e, 0x6f, 0x21, 0x0a, 0x00

    # void puts(const char *);
puts:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b

2:
    ret
</p>
<p>Yeah it just prints <code>Oh no!</code> on error. Baby steps…</p>
<p>The checkboxes “Pause on exc.” and “Print on exc.” control whether
the emulator should pause or print a message, respectively, when an
exception occurs. You can uncheck those if you want the exception
handler set in the program to run without interference.</p>
<p>(Another case that will cause a jump to <code>mtvec</code> is <span id="term-interrupts"><em>interrupts</em></span>. However, this feature
does not exist in the emulator. The two cases are collectively called
<span id="term-traps"><em>traps</em></span>.)</p>
<h2 id="exception-causes">Exception causes</h2>
<p>These are the exceptions possible in this emulator, and their
respective numeric codes:</p>
<table>
<thead>
<tr>
<th></th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Instruction address misaligned</td>
</tr>
<tr>
<td>1</td>
<td>Instruction access fault</td>
</tr>
<tr>
<td>2</td>
<td>Illegal instruction</td>
</tr>
<tr>
<td>3</td>
<td>Breakpoint</td>
</tr>
<tr>
<td>5</td>
<td>Load access fault</td>
</tr>
<tr>
<td>7</td>
<td>Store/AMO access fault</td>
</tr>
<tr>
<td>8</td>
<td>Environment call from User mode</td>
</tr>
<tr>
<td>11</td>
<td>Environment call from Machine mode</td>
</tr>
</tbody>
</table>
<p>“Instruction address misaligned” happens when attempting to jump to
an instruction that is not 4-byte aligned. The exception happens on the
jump or branch instruction, not the target.</p>
<p>“Load access fault” and “Store/AMO access fault” happens when
accessing an invalid memory address, or accessing a memory address in an
invalid way.</p>
<p>(“AMO” stands for “atomic memory operation”, which we will not talk
about and is not featured in the emulator.)</p>
<p>“Illegal instruction” happens not only in the self explanatory way
when an invalid instruction is executed, but also when accessing a CSR
in an invalid way, or from too low a privilege level.</p>
<p>“Breakpoint”, “Environment call from User mode” and “Environment call
from Machine mode” will be explained in a future section.</p>
<h2 id="exception-return">Exception return</h2>
<p>The <span id="insn-mret"><em><code>mret</code></em></span> (“M-mode
return”) instruction performs the reverse of part of what happens when
an exception occurs. To be precise, what happens is:</p>
<ul>
<li>The current privilege levels is set back to
<code>mstatus.MPP</code></li>
<li><code>mstatus.MPP</code> is set to 0</li>
<li><code>pc</code> is set to <code>mepc</code></li>
</ul>
<p>(You can think of the privilege mode bits as shifting in a chain
<code>0 → MPP → priv</code>. And, to be even more precise,
<code>mstatus.MPP</code> is set to the lowest supported privilege mode
since it’s not supposed to contain unsupported modes.)</p>
<p><code>mret</code> takes no operands, so the assembly syntax is
simply:</p>
<pre><code>mret</code></pre>
<p>If we do <code>mret</code> after getting an exception, then we simply
go back to retrying the same instruction again. This is useful for more
featureful implementations, where for example, after handling a page
fault the correct course of action is to retry the faulting
instruction.</p>
<p>However, <code>mstatus</code> and <code>mepc</code> are also
writable. This gives us more flexibility in the use of
<code>mret</code>. As an analogy, the same <code>jr</code> instruction
(really <code>jalr</code> instruction) can be used to return from a
call, and also can be used to jump to any address. Similarly,
<code>mret</code> not only lets us return from an exception, but also
lets us jump to any address <em>and</em> switch to any privilege
level.</p>
<h2 id="handling-user-mode">Handling User mode</h2>
<h2 id="entering-user-mode">Entering User mode</h2>
<p>Even though <code>mret</code> is named “return”, it is in fact the
only way to lower the privilege level to <em>enter</em> User mode.
Here’s an example of entering User mode, with a User mode program that
does something bad:</p>
<p>
    la t0, handler
    csrw mtvec, t0

    lui t0, %hi(0x1800)
    addi t0, t0, %lo(0x1800)

    # Clear MPP to 0
    csrrc zero, mstatus, t0

    la t0, user_entry
    csrw mepc, t0
    mret

handler:
    ebreak # Just stop the emulator

user_entry:
    # Try to access an M-mode CSR
    csrr a0, mstatus
</p>
<p>As you can see, after we enter User mode, all of the CSRs used for
exception handling become completely inaccessible, not even readable. As
with writing a read-only CSR, accessing an CSR without permission also
causes an illegal instruction exception.</p>
<p>Moreover, when an exception happens, we go back to Machine mode, so
the exception handler runs in Machine mode. Here the handler does
nothing except stopping the emulator.</p>
<h2 id="intentionally-causing-an-exception">Intentionally causing an exception</h2>
<p>Sometimes, a program may wish to intentionally cause an exception.
There are several well-defined way to do that:</p>
<ul>
<li>The pseudoinstruction <span id="insn-unimp"><em><code>unimp</code></em></span> has the same encoding
as <code>csrrw zero, cycle, zero</code>, and it is the canonical RV32I
illegal instruction. It causes causes an “Illegal instruction”
exception.</li>
<li>The instruction <span id="insn-ebreak"><em><code>ebreak</code></em></span> causes a
“Breakpoint” exception</li>
<li>The instruction <span id="insn-ecall"><em><code>ecall</code></em></span> causes an
“Environment call from User mode” exception when executed in User mode,
and “Environment call from Machine mode” exception when executed in
Machine mode.</li>
</ul>
<p>Give those exceptions a try here:</p>
<p>
    la t0, handler
    csrw mtvec, t0

    lui t0, %hi(0x1800)
    addi t0, t0, %lo(0x1800)

    # Clear MPP to 0
    csrrc zero, mstatus, t0

    la t0, user_entry
    csrw mepc, t0
    mret

handler:
    ebreak # Just stop the emulator

user_entry:
    ebreak
    # ecall
    # unimp
</p>
<p>As the names suggest, <code>ebreak</code> is used for debugging
breakpoints. As a special case, in this emulator <code>ebreak</code> in
Machine mode stops the emulator. You can think of it as the emulator
being a debugger, and the debugger catching the breakpoint.</p>
<p><code>unimp</code> can be used to intentionally crash a program upon
detection of some unrecoverable error.</p>
<p>Meanwhile, <code>ecall</code> is used for things like system calls.
“Environment call from User mode” is a distinct exception cause code to
make it easy to check specifically for this case.</p>
<h2 id="saving-and-restoring-all-registers">Saving and restoring all registers</h2>
<p>One thing that you would want in your trap handler is to not trust or
disturb <em>any</em> general purpose registers in the code that the trap
occurred in, unless you intentionally want to do so, for example to
return a value from a system call. So you’d want to save all the
registers to memory, before doing anything else. However, accessing
memory requires a general purpose register.</p>
<p>The <span id="csr-mscratch"><em><code>mscratch</code></em></span>
(“M-mode scratch”) CSR can help with this. This register, unlike all the
others, have no special functionality. It can hold any 32-bit value.
However, like all the other M-mode CSRs, it can only be accessed in
Machine mode. User mode code cannot change the value of it.</p>
<p>So for example, you can stash the operating system stack pointer in
<code>mscratch</code> before switching to User mode, and it will stay in
<code>mscratch</code> untouched in User mode. At the top of the handler,
<code>csrrw sp, mscratch, sp</code> to swap from the user stack pointer
to the operating system stack pointer.</p>
<pre><code>handler:
    csrrw sp, mscratch, sp
    # Save registers except sp
    csrr t0, mscratch
    # t0 = user sp, save it
    # Save user pc
    ...</code></pre>
<p>And, to restore:</p>
<pre><code>    lw t0, ... # Load user pc
    csrw mepc, t0
    lw t0, ... # Load user sp
    csrw mscratch, t0
    # Restore registers except sp
    csrrw sp, mscratch, sp
    mret</code></pre>
<p>We’ll see the full code for this in the following section.</p>
<h2 id="writing-a-very-very-bare-bones-operating-system">Writing a very very bare
bones operating system</h2>
<h2 id="design">Design</h2>
<p>We have enough of to write a very very bare bones operating system.
It will support these features:</p>
<ul>
<li>System calls:
<ul>
<li><code>a7 = 1</code>: putchar, <code>a0</code> is the byte to
write</li>
<li><code>a7 = 2</code>: exit</li>
</ul></li>
<li>Exception handling: Print error message and exit</li>
</ul>
<p>We design the exception handling as follows:</p>
<ul>
<li>During most of the time in M-mode, <code>mscratch</code> is 0.</li>
<li>While in U-mode, <code>mscratch</code> points to the operating
system stack pointer</li>
<li>At trap handler, if <code>mscratch</code> is 0, the exception came
from M-mode, which we cannot handle, so we report a fatal
exception.</li>
<li>If it did come from U-mode, allocate 128 bytes on the stack to save
the U-mode registers, and call <code>trap_main</code>, which manipulates
U-mode registers in memory</li>
<li>After <code>trap_main</code>, we restore registers from memory,
deallocate the space from the stack, and go back to U-mode, as outlined
in the previous section.</li>
</ul>
<p>The structure to save registers in is fairly simple:</p>
<pre><code>struct regs {
  unsigned long pc;
  unsigned long ra; // x1
  unsigned long sp; // x2
  ...
  unsigned long t6; // x31
};</code></pre>
<p>Basically you can think of it as an array where element 0 is
<code>pc</code>, and elements 1 through 31 are registers x1 through
x31.</p>
<p>Inside <code>trap_main</code>, we check <code>mcause</code> to see if
it’s a system call. If it is, we dispatch based on <code>a7</code>. If
it’s not, we report an exception from U-mode.</p>
<p>At the beginning, we simply initialize the <code>struct regs</code>
structure on stack, initialize user <code>sp</code> and <code>pc</code>
in it, and jump to the same code that handles returning to U-mode.</p>
<h2 id="code">Code</h2>
<p>Here’s the assembly code with User mode code at the bottom. You may
want to uncheck “Pause on exc.” and “Print on exc.” for convenience.</p>
<p>Do not be too hard on yourself if you have trouble understanding the
code fully. This is, after all, a fairly complete OS kernel entry and
exit implementation. Really, the most important part I’m showing you
here is that it is possible.</p>
<p>
    # Reserve 256 bytes for OS stack
    # User stack starts 256 bytes lower
    addi t2, sp, -256

    la t0, handler
    csrw mtvec, t0

    # Prepare struct reg
    addi sp, sp, -128

    mv a0, sp # struct regs *

    # Set user pc to user_entry
    la t0, user_entry
    sw t0, 0(a0)

    # Set user sp
    sw t2, 8(a0)

    j enter_user

    # void trap_main(struct regs *regs)
trap_main:
    # Save regs based on calling convention
    addi sp, sp, -16
    sw s0, (sp)
    sw ra, 4(sp)

    mv s0, a0
    csrr a1, mcause
    li t1, 8 # "Environment call from User mode"
    bne a1, t1, do_bad_exception # Not ecall, that's bad

    # Call do_syscall with args from ecall

    lw a0, 40(s0)
    lw a1, 44(s0)
    lw a2, 48(s0)
    lw a3, 52(s0)
    lw a4, 56(s0)
    lw a5, 60(s0)
    lw a6, 64(s0)
    lw a7, 68(s0)
    call do_syscall

    sw a0, 40(s0)   # Set user a0 return value

    # Bump user pc by 4
    # Skip over ecall instruction
    lw t0, 0(s0)
    addi t0, t0, 4
    sw t0, 0(s0)

    # Restore regs based on calling convention
    lw s0, (sp)
    lw ra, 4(sp)
    addi sp, sp, 16
    ret

    # a0 = arg0, a7 = syscall number
do_syscall:
    # Dispatch based on syscall number
    li t0, 1
    beq a7, t0, sys_putchar
    li t0, 2
    beq a7, t0, sys_exit

    # Bad syscall
    li a0, -1
    ret

    # int sys_putchar(char c)
sys_putchar:
    # Save regs based on calling convention
    addi sp, sp, -16
    sw s0, (sp)
    sw ra, 4(sp)

    call kputchar
    li a0, 0

    # Restore regs based on calling convention
    lw s0, (sp)
    lw ra, 4(sp)
    addi sp, sp, 16
    ret

    # [[noreturn]] void sys_exit()
sys_exit:
    # Just stop the emulator
    ebreak

    # [[noreturn]] void do_bad_exception(struct regs *regs, long cause)
    # Print message about bad U-mode exception, then stop
do_bad_exception:
    mv s0, a1

    # Equivalent of printf("Exception 0x%x", cause);
    la a0, msg_exception
    call kputs

    mv a0, s0
    la t0, hex_chars
    add t0, t0, a0
    lbu a0, (t0)
    call kputchar

    li a0, 0xa # '\n'
    call kputchar

    # Stop the emulator
    ebreak

fatal:
    # Print message about fatal exception, then stop
    la a0, msg_fatal
    call kputs
    ebreak

msg_exception:
    # "Exception 0x"
    .byte 0x45, 0x78, 0x63, 0x65, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x20, 0x30, 0x78, 0x00

msg_fatal:
    # "Fatal exception\n"
    .byte 0x46, 0x61, 0x74, 0x61, 0x6c, 0x20, 0x65, 0x78, 0x63, 0x65, 0x70, 0x74, 0x69, 0x6f, 0x6e, 0x0a, 0x00

hex_chars:
    # "0123456789abcdef"
    .byte 0x30, 0x31, 0x32, 0x33, 0x34, 0x35, 0x36, 0x37, 0x38, 0x39, 0x61, 0x62, 0x63, 0x64, 0x65, 0x66, 0x00

    .byte 0x00 # Alignment padding
    # Otherwise, the next instruction wouldn't be aligned

    # void kputs(const char *);
    # Print string by accessing MMIO directly
kputs:
    lui t1, %hi(0x10000000)
1:
    lb t0, 0(a0)
    beq t0, zero, 2f
    sw t0, 0(t1)
    addi a0, a0, 1
    j 1b
2:
    ret

    # void kputchar(char);
    # Print byte by accessing MMIO directly
kputchar:
    lui t1, %hi(0x10000000)
    sw a0, (t1)
    ret

    # The big exception handler
handler:
    csrrw sp, mscratch, sp

    # If mscratch was 0, this is exception from M-mode
    # Can't handle that, it's a fatal error
    beq sp, zero, fatal

    # Save all registers
    addi sp, sp, -128
    sw x1, 4(sp)
    # x2/sp handled separately
    sw x3, 12(sp)
    sw x4, 16(sp)
    sw x5, 20(sp)
    sw x6, 24(sp)
    sw x7, 28(sp)
    sw x8, 32(sp)
    sw x9, 36(sp)
    sw x10, 40(sp)
    sw x11, 44(sp)
    sw x12, 48(sp)
    sw x13, 52(sp)
    sw x14, 56(sp)
    sw x15, 60(sp)
    sw x16, 64(sp)
    sw x17, 68(sp)
    sw x18, 72(sp)
    sw x19, 76(sp)
    sw x20, 80(sp)
    sw x21, 84(sp)
    sw x22, 88(sp)
    sw x23, 92(sp)
    sw x24, 96(sp)
    sw x25, 100(sp)
    sw x26, 104(sp)
    sw x27, 108(sp)
    sw x28, 112(sp)
    sw x29, 116(sp)
    sw x30, 120(sp)
    sw x31, 124(sp)

    # Save user sp, also set mscratch to 0 in M-mode
    csrrw t0, mscratch, zero
    sw t0, 8(sp)

    # Save user pc
    csrr t0, mepc
    sw t0, 0(sp)

    mv a0, sp
    call trap_main
    # ... falls through after trap_main ...
enter_user:
    # Set mstatus.MPP = User
    lui t0, %hi(0x1800)
    addi t0, t0, %lo(0x1800)
    csrrc zero, mstatus, t0

    # Set mepc = user pc
    # Will actually jump with mret
    lw t0, 0(sp)
    csrw mepc, t0

    # Set mscratch = user sp temporarily
    # Will swap right before mret
    lw t0, 8(sp)
    csrw mscratch, t0

    # Restore other registers from stack
    lw x1, 4(sp)
    # x2/sp handled separately
    lw x3, 12(sp)
    lw x4, 16(sp)
    lw x5, 20(sp)
    lw x6, 24(sp)
    lw x7, 28(sp)
    lw x8, 32(sp)
    lw x9, 36(sp)
    lw x10, 40(sp)
    lw x11, 44(sp)
    lw x12, 48(sp)
    lw x13, 52(sp)
    lw x14, 56(sp)
    lw x15, 60(sp)
    lw x16, 64(sp)
    lw x17, 68(sp)
    lw x18, 72(sp)
    lw x19, 76(sp)
    lw x20, 80(sp)
    lw x21, 84(sp)
    lw x22, 88(sp)
    lw x23, 92(sp)
    lw x24, 96(sp)
    lw x25, 100(sp)
    lw x26, 104(sp)
    lw x27, 108(sp)
    lw x28, 112(sp)
    lw x29, 116(sp)
    lw x30, 120(sp)
    lw x31, 124(sp)
    addi sp, sp, 128

    # Actually restore sp
    csrrw sp, mscratch, sp
    mret    # Time to go to user mode!

################

user_entry:
    la a0, msg_hello
    call puts
    call exit

    # void puts(const char *);
    # Print string using system call
puts:
    addi sp, sp, -16
    sw s0, (sp)
    sw ra, 4(sp)

    mv s0, a0
1:
    lb a0, 0(s0)
    beq a0, zero, 2f
    call putchar
    addi s0, s0, 1
    j 1b
2:

    lw s0, (sp)
    lw ra, 4(sp)
    addi sp, sp, 16
    ret

    # void putchar(const char *);
    # Print byte using system call
putchar:
    li a7, 1
    ecall
    ret

    # [[noreturn]] void exit();
exit:
    li a7, 2
    ecall
    # Not supposed to return, just to be safe
    unimp

msg_hello:
    .byte 0x48, 0x65, 0x6c, 0x6c, 0x6f, 0x20, 0x77, 0x6f, 0x72, 0x6c, 0x64, 0x21, 0x0a, 0x00
</p>
<h2 id="pseudocode-reference">Pseudocode reference</h2>
<p>For reference, here’s some of the OS code in pseudo-C.</p>
<pre><code>void trap_main(struct regs *regs) {
    unsigned long cause = csr_read(mcause);
    if (cause != 8)
        do_bad_exception(regs, cause);

    # Call do_syscall with args from ecall
    unsigned long ret = do_syscall(regs-&gt;a0, ..., regs-&gt;a7);
    regs-&gt;a0 = ret;

    // Bump user pc by 4, skip over ecall instruction
    regs-&gt;pc += 4;
}

unsigned long do_syscall(
    unsigned long a0,
    ...,
    unsigned long a7
) {
    if (a7 == 1)
        sys_putchar(a0);
    else if (a7 == 8)
        sys_exit();
    else
        return -1;
}

unsigned long sys_putchar(char a) {
    kputchar(a);
    return 0;
}

[[noreturn]]
unsigned long sys_exit(char a) {
    ebreak();
}

[[noreturn]]
void do_bad_exception(struct regs *regs, unsigned long cause) {
    kputs("Exception 0x");
    kputchar(hex_chars[cause]);
    kputchar('\n');
    ebreak();
}

[[noreturn]]
void fatal() {
    kputs("Fatal exception\n");
    ebreak();
}

void kputs(const char *str) {
    while (*str) {
        u32 val = (u32)*str;
        writel(0x10000000, val); // MMIO write
        str ++;
    }
}

void kputchar(char c) {
    u32 val = (u32)c;
    writel(0x10000000, val); // MMIO write
}</code></pre>
<p>And here’s the user code, again in pseudo C:</p>
<pre><code>[[noreturn]]
void user_entry() {
    puts(...);
    exit();
}

void puts(const char *str) {
    while (*str) {
        putchar(*str);
        str ++;
    }
}

void putchar(char c) {
    ecall(a0 = c, a7 = 1);
}

void exit() {
    ecall(a7 = 2);
}</code></pre>
<h2 id="lies-and-omissions">Lies and omissions</h2>
<p>As long as this tutorial is, some simplifications have been made.
Here are some of the most egregious lies and omissions, compared to the
“real” RISC-V architecture and “real” RISC-V assembly code found in the
world:</p>
<ul>
<li>The assembly syntax resembles the syntax used by LLVM assembler and
GNU Binutils for RISC-V. However, it is not identical.</li>
<li>There are a lot more pseudoinstructions and CSRs than what I have
described.</li>
<li>The <code>li</code> pseudoinstruction should support a wider range
of constants.</li>
<li><code>mstatus</code> is a lot more complicated than what I have
described.</li>
<li><code>%hi</code>, <code>%lo</code>, <code>%pcrel_hi</code>,
<code>%pcrel_lo</code> are more complicated than what I have
described.</li>
</ul>
<p>There are also very important topics that are common or even
ubiquitous in the RISC-V world, but I chose not to cover:</p>
<ul>
<li>64-bit architecture</li>
<li>Compressed instructions</li>
<li>Other privileged architecture and operating systems topics:
Interrupts, memory protection, virtual memory, …</li>
</ul>
<p>However, what I’ve taught you should be more than enough to get you
started into learning more on your own, or with further materials.</p>
<h2 id="references">References</h2>
<p>Here are some references and tutorials I would personally recommend,
if you’re looking to get further into RISC-V low-level development</p>
<ul>
<li>RISC-V Instruction Set Manual <a href="https://github.com/riscv/riscv-isa-manual">https://github.com/riscv/riscv-isa-manual</a></li>
<li>RISC-V Assembly Programmer’s Manual <a href="https://github.com/riscv-non-isa/riscv-asm-manual">https://github.com/riscv-non-isa/riscv-asm-manual</a></li>
<li>RISC-V Calling Conventions <a href="https://github.com/riscv-non-isa/riscv-elf-psabi-doc/blob/master/riscv-cc.adoc">https://github.com/riscv-non-isa/riscv-elf-psabi-doc/blob/master/riscv-cc.adoc</a></li>
<li>Operating System in 1,000 Lines <a href="https://operating-system-in-1000-lines.vercel.app/en/">https://operating-system-in-1000-lines.vercel.app/en/</a></li>
</ul>
<p>Other useful resources that I have used while writing this
tutorial:</p>
<ul>
<li><code>arch/riscv/kernel/entry.S</code> from Linux <a href="https://elixir.bootlin.com/linux/latest/source/arch/riscv/kernel/entry.S">https://elixir.bootlin.com/linux/latest/source/arch/riscv/kernel/entry.S</a></li>
</ul>
<h2 id="thanks">Thanks</h2>
<p>Thanks to these folks for UI design help and content suggestions:</p>
<ul>
<li>Aria Desires <a href="https://faultlore.com/">https://faultlore.com</a></li>
<li>Riven Skaye <a href="https://skaye.blog/">https://skaye.blog</a></li>
<li>robotreader <a href="https://sdubinsky.com/">https://sdubinsky.com</a></li>
<li>Bruce Hoult <a href="http://hoult.org/bruce">http://hoult.org/bruce</a></li>
</ul>
<p>And thanks to you for coming along with me on this journey. Come on
over to <a href="https://github.com/dramforever/easyriscv">https://github.com/dramforever/easyriscv</a> if you have
suggestions, grievances, or just want to share some thoughts.</p>
<h2 id="license">License</h2>
<p>This tutorial is under the <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0</a>
license. To the maximum extent permitted by law, this tutorial is
dedicated to the public domain.</p>
<h2 id="index">Index</h2>
<h2 id="instructions">Instructions</h2>
<ul>
<li><a href="#insn-add"><code>add</code></a></li>
<li><a href="#insn-addi"><code>addi</code></a></li>
<li><a href="#insn-and"><code>and</code></a></li>
<li><a href="#insn-andi"><code>andi</code></a></li>
<li><a href="#insn-auipc"><code>auipc</code></a></li>
<li><a href="#insn-beq"><code>beq</code></a></li>
<li><a href="#insn-bge"><code>bge</code></a></li>
<li><a href="#insn-bgeu"><code>bgeu</code></a></li>
<li><a href="#insn-blt"><code>blt</code></a></li>
<li><a href="#insn-bltu"><code>bltu</code></a></li>
<li><a href="#insn-bne"><code>bne</code></a></li>
<li><a href="#insn-call"><code>call</code></a></li>
<li><a href="#insn-csrr"><code>csrr</code></a></li>
<li><a href="#insn-csrrc"><code>csrrc</code></a></li>
<li><a href="#insn-csrrci"><code>csrrci</code></a></li>
<li><a href="#insn-csrrs"><code>csrrs</code></a></li>
<li><a href="#insn-csrrsi"><code>csrrsi</code></a></li>
<li><a href="#insn-csrrw"><code>csrrw</code></a></li>
<li><a href="#insn-csrrwi"><code>csrrwi</code></a></li>
<li><a href="#insn-csrw"><code>csrw</code></a></li>
<li><a href="#insn-ebreak"><code>ebreak</code></a></li>
<li><a href="#insn-ecall"><code>ecall</code></a></li>
<li><a href="#insn-j"><code>j</code></a></li>
<li><a href="#insn-jal"><code>jal</code></a></li>
<li><a href="#insn-jalr"><code>jalr</code></a></li>
<li><a href="#insn-jr"><code>jr</code></a></li>
<li><a href="#insn-la"><code>la</code></a></li>
<li><a href="#insn-lb"><code>lb</code></a></li>
<li><a href="#insn-lbu"><code>lbu</code></a></li>
<li><a href="#insn-lh"><code>lh</code></a></li>
<li><a href="#insn-lhu"><code>lhu</code></a></li>
<li><a href="#insn-li"><code>li</code></a></li>
<li><a href="#insn-lui"><code>lui</code></a></li>
<li><a href="#insn-lw"><code>lw</code></a></li>
<li><a href="#insn-mret"><code>mret</code></a></li>
<li><a href="#insn-mv"><code>mv</code></a></li>
<li><a href="#insn-or"><code>or</code></a></li>
<li><a href="#insn-ori"><code>ori</code></a></li>
<li><a href="#insn-ret"><code>ret</code></a></li>
<li><a href="#insn-sb"><code>sb</code></a></li>
<li><a href="#insn-sh"><code>sh</code></a></li>
<li><a href="#insn-sll"><code>sll</code></a></li>
<li><a href="#insn-slli"><code>slli</code></a></li>
<li><a href="#insn-slt"><code>slt</code></a></li>
<li><a href="#insn-slti"><code>slti</code></a></li>
<li><a href="#insn-sltiu"><code>sltiu</code></a></li>
<li><a href="#insn-sltu"><code>sltu</code></a></li>
<li><a href="#insn-sra"><code>sra</code></a></li>
<li><a href="#insn-srai"><code>srai</code></a></li>
<li><a href="#insn-srl"><code>srl</code></a></li>
<li><a href="#insn-srli"><code>srli</code></a></li>
<li><a href="#insn-sub"><code>sub</code></a></li>
<li><a href="#insn-sw"><code>sw</code></a></li>
<li><a href="#insn-unimp"><code>unimp</code></a></li>
<li><a href="#insn-xor"><code>xor</code></a></li>
<li><a href="#insn-xori"><code>xori</code></a></li>
</ul>
<h2 id="registers-and-csrs">Registers and CSRs</h2>
<ul>
<li><a href="#reg-x0"><code>x0</code></a></li>
<li><a href="#reg-x1-through-x31"><code>x1</code> through
<code>x31</code></a></li>
</ul>
<ul>
<li><a href="#regalias-a0-through-a7"><code>a0</code> through
<code>a7</code></a></li>
<li><a href="#regalias-gp"><code>gp</code></a></li>
<li><a href="#regalias-ra"><code>ra</code></a></li>
<li><a href="#regalias-s0-through-s11"><code>s0</code> through
<code>s11</code></a></li>
<li><a href="#regalias-sp"><code>sp</code></a></li>
<li><a href="#regalias-t0-through-t6"><code>t0</code> through
<code>t6</code></a></li>
<li><a href="#regalias-tp"><code>tp</code></a></li>
<li><a href="#regalias-zero"><code>zero</code></a></li>
</ul>
<ul>
<li><a href="#csr-cycle"><code>cycle</code></a></li>
<li><a href="#csr-cycleh"><code>cycleh</code></a></li>
<li><a href="#csr-instret"><code>instret</code></a></li>
<li><a href="#csr-instreth"><code>instreth</code></a></li>
<li><a href="#csr-mcause"><code>mcause</code></a></li>
<li><a href="#csr-mepc"><code>mepc</code></a></li>
<li><a href="#csr-mscratch"><code>mscratch</code></a></li>
<li><a href="#csr-mstatus"><code>mstatus</code></a></li>
<li><a href="#csr-mtval"><code>mtval</code></a></li>
</ul>
<h2 id="special-assembly-syntax">Special assembly syntax</h2>
<ul>
<li><a href="#dir-.2byte"><code>.2byte</code></a></li>
<li><a href="#dir-.4byte"><code>.4byte</code></a></li>
<li><a href="#dir-.byte"><code>.byte</code></a></li>
<li><a href="#dir-.half"><code>.half</code></a></li>
<li><a href="#dir-.word"><code>.word</code></a></li>
</ul>
<ul>
<li><a href="#rel-%hi()"><code>%hi()</code></a></li>
<li><a href="#rel-%lo()"><code>%lo()</code></a></li>
<li><a href="#rel-%pcrel_hi()"><code>%pcrel_hi()</code></a></li>
<li><a href="#rel-%pcrel_lo()"><code>%pcrel_lo()</code></a></li>
</ul>
<h2 id="other-terms">Other terms</h2>
<ul>
<li><a href="#term-align">align</a></li>
<li><a href="#term-aligned">aligned</a></li>
<li><a href="#term-branch">branch</a></li>
<li><a href="#term-byte">byte</a></li>
<li><a href="#term-call-saved">call-saved</a></li>
<li><a href="#term-control-and-status-registers">control and status
registers</a></li>
<li><a href="#term-counters">counters</a></li>
<li><a href="#term-csrs">CSRs</a></li>
<li><a href="#term-destination-register">destination register</a></li>
<li><a href="#term-devices">devices</a></li>
<li><a href="#term-directive">directive</a></li>
<li><a href="#term-endianness">endianness</a></li>
<li><a href="#term-exceptions">exceptions</a></li>
<li><a href="#term-extensions">extensions</a></li>
<li><a href="#term-general-purpose-registers">general purpose
registers</a></li>
<li><a href="#term-halfword">halfword</a></li>
<li><a href="#term-imm"><code>imm</code></a></li>
<li><a href="#term-immediate-value">immediate value</a></li>
<li><a href="#term-instruction-syntax">instruction syntax</a></li>
<li><a href="#term-interrupts">interrupts</a></li>
<li><a href="#term-jump">jump</a></li>
<li><a href="#term-load">load</a></li>
<li><a href="#term-m-mode">M-mode</a></li>
<li><a href="#term-machine">Machine</a></li>
<li><a href="#term-memory-mapped-i/o">memory mapped I/O</a></li>
<li><a href="#term-modes">modes</a></li>
<li><a href="#term-numeric-labels">numeric labels</a></li>
<li><a href="#term-pc"><code>pc</code></a></li>
<li><a href="#term-pc-relative-addressing">pc-relative
addressing</a></li>
<li><a href="#term-pic">PIC</a></li>
<li><a href="#term-position-independent-code">position independent
code</a></li>
<li><a href="#term-privilege-levels">privilege levels</a></li>
<li><a href="#term-program-counter">program counter</a></li>
<li><a href="#term-pseudoinstructions">pseudoinstructions</a></li>
<li><a href="#term-rd"><code>rd</code></a></li>
<li><a href="#term-register-aliases">register aliases</a></li>
<li><a href="#term-reset">reset</a></li>
<li><a href="#term-rs1"><code>rs1</code></a></li>
<li><a href="#term-rs2"><code>rs2</code></a></li>
<li><a href="#term-sign-extension">sign extension</a></li>
<li><a href="#term-source-register">source register</a></li>
<li><a href="#term-stack">stack</a></li>
<li><a href="#term-store">store</a></li>
<li><a href="#term-traps">traps</a></li>
<li><a href="#term-two’s-complement">two’s complement</a></li>
<li><a href="#term-u-mode">U-mode</a></li>
<li><a href="#term-user">User</a></li>
<li><a href="#term-word">word</a></li>
<li><a href="#term-zero-extension">zero extension</a></li>
</ul>

</div>]]></description>
        </item>
        <item>
            <title><![CDATA[The PSF has withdrawn a $1.5M proposal to US Government grant program (234 pts)]]></title>
            <link>https://simonwillison.net/2025/Oct/27/psf-withdrawn-proposal/</link>
            <guid>45726137</guid>
            <pubDate>Mon, 27 Oct 2025 20:52:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://simonwillison.net/2025/Oct/27/psf-withdrawn-proposal/">https://simonwillison.net/2025/Oct/27/psf-withdrawn-proposal/</a>, See on <a href="https://news.ycombinator.com/item?id=45726137">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>



<p><strong><a href="https://pyfound.blogspot.com/2025/10/NSF-funding-statement.html">The PSF has withdrawn a $1.5 million proposal to US government grant program</a></strong>. The Python Software Foundation was recently "recommended for funding" (NSF terminology) for a $1.5m grant from the US government National Science Foundation to help improve the security of the Python software ecosystem, after an grant application process lead by Seth Larson and Loren Crary.</p>
<p>The PSF's annual budget is less than $6m so this is a meaningful amount of money for the organization!</p>
<p>We were forced to withdraw our application and turn down the funding, thanks to new language that was added to the agreement requiring us to affirm that we "do not, and will not during the term of this financial assistance award, operate any programs that advance or promote DEI, or discriminatory equity ideology in violation of Federal anti-discrimination laws."</p>
<p>Our legal advisors confirmed that this would not just apply to security work covered by the grant - this would apply to all of the PSF's activities.</p>
<p>This was not an option for us. Here's the <a href="https://www.python.org/psf/mission/">mission</a> of the PSF:</p>
<blockquote>
<p>The mission of the Python Software Foundation is to promote, protect, and advance the Python programming language, and to support and facilitate the growth of a diverse and international community of Python programmers.</p>
</blockquote>
<p>If we accepted and spent the money despite this term, there was a very real risk that the money could be clawed back later. That represents an existential risk for the foundation since we would have already spent the money!</p>
<p>I was one of the board members who voted to reject this funding - a unanimous but tough decision. I’m proud to serve on a board that can make tough decisions like this.</p>




</div></div>]]></description>
        </item>
    </channel>
</rss>