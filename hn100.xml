(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 17 Apr 2025 13:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[US Government threatens Harvard with foreign student ban (108 pts)]]></title>
            <link>https://www.bbc.com/news/articles/c1egdy24v7po</link>
            <guid>43715022</guid>
            <pubDate>Thu, 17 Apr 2025 10:42:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/c1egdy24v7po">https://www.bbc.com/news/articles/c1egdy24v7po</a>, See on <a href="https://news.ycombinator.com/item?id=43715022">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><figure><div data-component="image-block"><p><img src="https://static.files.bbci.co.uk/bbcdotcom/web/20250409-091508-0ef9b7676-web-2.19.1-12/grey-placeholder.png"><img sizes="(min-width: 1280px) 50vw, (min-width: 1008px) 66vw, 96vw" srcset="https://ichef.bbci.co.uk/news/240/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 240w,https://ichef.bbci.co.uk/news/320/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 320w,https://ichef.bbci.co.uk/news/480/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 480w,https://ichef.bbci.co.uk/news/640/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 640w,https://ichef.bbci.co.uk/news/800/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 800w,https://ichef.bbci.co.uk/news/1024/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 1024w,https://ichef.bbci.co.uk/news/1536/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp 1536w" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2b7b/live/c24ebd50-1b4c-11f0-a562-4fbbfa5ff5e1.jpg.webp" loading="eager" alt="Getty Images Pedestrians enter the Harvard University campus in Cambridge, Massachusetts, US, on Wednesday, April 16, 2025"><span>Getty Images</span></p></div><p data-component="caption-block"><figcaption>Harvard President Alan Garber has flatly rejected the White House's sweeping list of demands </figcaption></p></figure><div data-component="text-block"><p>The US government has threatened to ban Harvard University from enrolling foreign students - after the institution said it would not bow to demands from President Donald Trump's administration and was hit with a funding freeze.</p><p>The White House has demanded the oldest university in the US make changes to hiring, admissions and teaching practices - to help fight antisemitism on campus.</p><p>Homeland Security Secretary Kristi Noem has asked for records on what she called the "illegal and violent" activities of its foreign student visa-holders. </p><p>Harvard earlier said it had taken many steps to address antisemitism, and that demands were an effort to regulate the university's "intellectual conditions".</p></div><div data-component="text-block"><p>"The university will not surrender its independence or relinquish its constitutional rights," Harvard President Alan Garber wrote in a message on Monday to the Harvard community.</p><p>The new request from Noem said the institution would lose the "privilege of enrolling foreign students" if it did not comply with the demand for records.</p><p>Harvard said it was aware of the new request from Noem, which was made in a letter, the Reuters news agency reported.</p><p>International students make up more than 27% of Harvard's enrolment this year. Even before Noem's statement, billions of dollars hung in the balance for the university, after the freeze of some $2.2 bn (£1.7bn) in federal funding.</p><p>Trump has also threatened to also remove Harvard's valuable tax exemption, the loss of which could cost Harvard millions of dollars each year. US media reports suggest the Internal Revenue Service (IRS) has started drawing up plans to enact this.</p><p>"Harvard can no longer be considered even a decent place of learning, and should not be considered on any list of the World's Great Universities or Colleges," Trump wrote on his Truth Social platform on Wednesday. </p><p>"Harvard is a JOKE, teaches Hate and Stupidity, and should no longer receive Federal Funds."</p></div><div data-component="text-block"><ul><li><a target="_self" href="https://www.bbc.co.uk/news/articles/c20z60vxvmjo">Harvard just stood up to Trump. How long can it last?</a></li><li><a target="_self" href="https://www.bbc.co.uk/news/articles/cz01y9gkdm3o">Trump threatens Harvard's tax-exempt status </a></li><li><a target="_self" href="https://www.bbc.co.uk/news/articles/cn0w2656x33o">Obama calls Trump's freeze of funding unlawful</a></li></ul></div><div data-component="text-block"><p>The administration's attacks on Harvard are not isolated. The government's antisemitism task force has identified at least 60 universities for review.</p><p>During his presidential campaign, Trump pitched a funding crackdown on universities, painting them as hostile to conservatives. He and Vice-President JD Vance have long railed against higher education institutions.</p><p>Polling by Gallup last year suggested that confidence in higher education had been falling over time among Americans of all political backgrounds, particularly Republicans - in part due to a belief that universities push a political agenda. </p><p>Since taking office, Trump has focused particularly on universities where pro-Palestinian protests have taken place. Some Jewish students have said they felt unsafe and faced harassment on campus. </p><p>In March, Columbia University agreed to several of the administration's demands, after $400m in federal funding was pulled over accusations the university failed to fight antisemitism.</p><p>These included replacing the official leading its Middle Eastern, South Asian and African Studies department and pledging to take on a review to "ensure unbiased admission processes". </p><p>Harvard too has made concessions - including by dismissing the leaders of its Center for Middle Eastern Studies, who had come under fire for failing to represent Israeli perspectives.</p><p>But it has drawn the line at the White House's recent list of demands.</p></div><p data-component="caption-block"><figcaption>Watch: 'It's not right' - Students react to Trump freezing Harvard's federal funding</figcaption></p></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astronomers have found signs of alien life on a planet beyond our Solar System (310 pts)]]></title>
            <link>https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide</link>
            <guid>43714203</guid>
            <pubDate>Thu, 17 Apr 2025 08:02:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide">https://www.skyatnightmagazine.com/news/k2-18b-dimethyl-sulfide</a>, See on <a href="https://news.ycombinator.com/item?id=43714203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div type="content-body" ngh="32"><storefront-content-body _nghost-purplestorefront-c2920483845="" ngh="31"><article _ngcontent-purplestorefront-c2920483845="" id="sprylab_purple_content"><div _ngcontent-purplestorefront-c2920483845=""><p>Astronomers say they've found "the most promising signs yet" of chemicals on a planet beyond our Solar System that could indicate the presence of life on its surface.</p>
<p>Using the <a href="https://www.skyatnightmagazine.com/space-missions/nasa-james-webb-space-telescope-observe-universe">James Webb Space Telescope</a>, the team found a possible 'biosignature' – the potential fingerprint of life – within its atmosphere, although they say they're remaining "cautious", and that this isn't a confirmed detection.</p>
<p>The chemicals detected are the same as those produced by marine-dwelling organisms on Earth.</p>
<div>
<figure><img loading="lazy" decoding="async" width="1200" height="675" src="https://c02.purpledshub.com/uploads/sites/48/2025/04/exoplanets.jpg?webp=1&amp;w=1200" alt="Artist's impression showing multiple interesting exoplanets. Credit: Photostock-Israel/Science Photo Library"><figcaption>Credit: Photostock-Israel/Science Photo Library</figcaption></figure>
</div>
<p>The team, led by the University of Cambridge in the UK, detected signs of dimethyl sulfide and dimethyl disulfide in the atmosphere of exoplanet K2-18b.</p>
<p>This planet orbits its star in the habitable zone (sometimes called the <a href="https://www.skyatnightmagazine.com/space-science/goldilocks-zone">Goldilocks Zone</a>), which is the region around a star in which an orbiting planet might have conditions suitable for the emergence of life, such as the ability for liquid water to exist on its surface.</p>
<p>K2-18b is 8.6 times as massive and 2.6 times as large as Earth and lies 124 <a href="https://www.skyatnightmagazine.com/space-science/lightyear">lightyears</a> away from our planet.</p>
<figure><img loading="lazy" decoding="async" width="1500" height="875" src="https://c02.purpledshub.com/uploads/sites/48/2019/09/exoplanet_K2_18b-c7915cb.jpg?webp=1&amp;w=1200" alt="An artist’s impression showing exoplanet K2-18b, its host star and an accompanying planet in this system. Credit: ESA/Hubble, M. Kornmesser"><figcaption>An artist’s impression showing exoplanet K2-18b, its host star and an accompanying planet in this system. Credit: ESA/Hubble, M. Kornmesser. Credit: ESA/Hubble, M. Kornmesser</figcaption></figure>
<h2><strong>Building a bigger picture</strong></h2>
<p>This isn't the first study of exoplanet K2-18b. </p>
<p>A <a href="https://www.skyatnightmagazine.com/news/jwst-finds-life-exoplanet-k2-18b">2023 study of K2-18b</a> by the same team identified methane and carbon dioxide in the planet's atmosphere.</p>
<p>This in itself was a huge discovery: the first time carbon-based molecules had been found in the atmosphere of an exoplanet – a planet beyond our Solar System – in the habitable zone.</p>
<p>Astronomers say the 2023 results showed K2-18b could be a ‘Hycean’ planet, meaning a <a href="https://www.skyatnightmagazine.com/space-science/what-makes-a-planet-habitable">habitable world</a> with a liquid ocean and a hydrogen-rich atmosphere.</p>
<p>That earlier study found a tantalising hint of dimethyl sulfide and dimethyl disulfide, but this latest study has made a more promising detection.</p>
<figure><img loading="lazy" decoding="async" width="3840" height="2160" src="https://c02.purpledshub.com/uploads/sites/48/2023/09/Atmospheric-compoistion-of-k2-18b.png?webp=1&amp;w=1200" alt="Atmospheric compoistion of k2-18b, detected by the James Webb Space Telescope"><figcaption>This graph shows detections of chemicals in the atmosphere of K2-18b by the James Webb Space Telescope, as part of the 2023 study</figcaption></figure>
<p>"We didn’t know for sure whether the signal we saw last time was due to DMS, but just the hint of it was exciting enough for us to have another look with JWST using a different instrument," says Professor Nikku Madhusudhan from Cambridge’s Institute of Astronomy, who led the research.</p>
<p>The team say that on Earth, dimethyl sulfide and dimethyl disulfide are only produced by life, mainly microbial life like <a href="https://www.skyatnightmagazine.com/earth-from-space/algae-bloom-from-space">phytoplankton</a> we see in our oceans.</p>
<p>However, there could be another explanation for the detection of the chemical.</p>
<p>Another unknown chemical process could be the source of the molecules detected in K2-18b’s atmosphere.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="631" src="https://c02.purpledshub.com/uploads/sites/48/2025/04/K2-18b-exoplanet.jpg?webp=1&amp;w=1200" alt="Artist's impression of exoplanet K2-18b. Credit: A. Smith, N. Madhusudhan (University of Cambridge)"><figcaption>Artist's impression of exoplanet K2-18b. Credit: A. Smith, N. Madhusudhan (University of Cambridge)</figcaption></figure>
<p>Nevertheless, the team say "the results are the "strongest evidence yet" that life may exist on a planet outside our Solar System.</p>
<p>They say their observations have reached the ‘three-sigma’ level of statistical significance.</p>
<p>This means there's a 0.3% probability the detection occurred by chance.</p>
<p>And to reach the accepted level that would mean scientific discovery, observations would have to meet the five-sigma threshold.</p>
<p>In other words, there would need to be below a 0.00006% probability they occurred by chance.</p>
<figure><img loading="lazy" decoding="async" width="940" height="531" src="https://c02.purpledshub.com/uploads/sites/48/2019/05/Exoplanet-discovery-MAIN-c0a6e15.jpg?webp=1&amp;w=1200" alt="Artistic ilustration of planet K2-18b, its star K2-18 and another planet in the system. Credit: Alex Boersma, www.alexboersma.com"><figcaption>Artistic ilustration of planet K2-18b, its star K2-18 and another planet in the system. Credit: Alex Boersma, www.alexboersma.com</figcaption></figure>
<h2><strong>Detecting life on faraway worlds</strong></h2>
<p>How can scientists know what chemicals exist on a planet orbiting a star beyond our Solar System?</p>
<p>Key to analysing exoplanets' atmospheres is analysing the light from their host stars.</p>
<p>As a planet passes in front of its host star from our perspective on Earth – known as a <a href="https://www.skyatnightmagazine.com/space-science/exoplanets-transit-method">transit</a> – light from that star passes through the planet's atmosphere.</p>
<p>That starlight picks up chemical fingerprints as it passes through the atmosphere, so astronomers can analyse the light to learn more about the atmosphere. </p>
<figure><img loading="lazy" decoding="async" width="1200" height="759" src="https://c02.purpledshub.com/uploads/sites/48/2021/04/Exoplanet-transit-method-aeba46b.jpg?webp=1&amp;w=1200" alt="Transit photometry reveals exoplanets by observing periodic dimming of the star's light."><figcaption>A dip in starlight can indicate a planet 'transiting' that star. But as well as detecting exoplanets, transits can be used by astronomers to learn more about an exoplanet's atmosphere</figcaption></figure>
<p>The tentative detection of dimethyl sulfide in 2023 was made using the James Webb Space Telescope's NIRISS (Near-Infrared Imager and Slitless Spectrograph) and NIRSpec (Near-Infrared Spectrograph) instruments.</p>
<p>This 2025 study used the Webb Telescope's MIRI (Mid-Infrared Instrument), which observes in a different wavelength of light, offering the team a new look at this intriguing world.</p>
<p>"This is an independent line of evidence, using a different instrument than we did before and a different wavelength range of light, where there is no overlap with the previous observations," says Madhusudhan.</p>
<p>"The signal came through strong and clear."</p>
<p>"It was an incredible realisation seeing the results emerge and remain consistent throughout the extensive independent analyses and robustness tests," says co-author Måns Holmberg, a researcher at the Space Telescope Science Institute in Baltimore, USA.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="507" src="https://c02.purpledshub.com/uploads/sites/48/2024/05/biosignatures.jpg?webp=1&amp;w=1200" alt="Astronomers can detect biosignatures to determine whether a planet may host life."><figcaption>Astronomers can detect biosignatures to determine whether a planet may host life.</figcaption></figure>
<h2><strong>Does K2-18b have life?</strong></h2>
<p>The team say dimethyl sulfide and dimethyl disulfide are molecules from the same chemical family, and could be '<a href="https://www.skyatnightmagazine.com/space-science/biosignatures-exoplanets">biosignatures</a>'.</p>
<p>This is a term used to describe chemicals that, when detected around a distant planet, could indicate the presence of biological processes, i.e. life.</p>
<p>Yet the concentrations of dimethyl sulfide and dimethyl disulfide in K2-18b's atmosphere are different from those on Earth.</p>
<p>On Earth, dimethyl sulfide and dimethyl disulfide are below one part per billion by volume. On K2-18b, they're thought to be thousands of times stronger, over ten parts per million.</p>
<p>"Earlier theoretical work had predicted that high levels of sulfur-based gases like dimethyl sulfide and dimethyl disulfide are possible on Hycean worlds," says Madhusudhan.</p>
<p>"And now we’ve observed it, in line with what was predicted. Given everything we know about this planet, a Hycean world with an ocean that is teeming with life is the scenario that best fits the data we have."</p>
<p>The team now hope to carry out more research into whether dimethyl sulfide and dimethyl disulfide can be produced non-biologically at the level they're currently seeing.</p>
<figure><img loading="lazy" decoding="async" width="1200" height="800" src="https://c02.purpledshub.com/uploads/sites/48/2023/11/webb-detect-life.jpg?webp=1&amp;w=1200" alt="Will Webb detect signs of life? Discoveries at Europa and exoplanet K2-18b suggest it is certainly able to do so. Credit: NASA GSFC/CIL/Adriana Manrique Gutierrez"><figcaption>Credit: NASA GSFC/CIL/Adriana Manrique Gutierrez</figcaption></figure>
<p>"The inference of these biosignature molecules poses profound questions concerning the processes that might be producing them" says study co-author Subhajit Sarkar of Cardiff University.</p>
<p>"Our work is the starting point for all the investigations that are now needed to confirm and understand the implications of these exciting findings," says co-author Savvas Constantinou, also from Cambridge’s Institute of Astronomy.</p>
<p>"It’s important that we’re deeply sceptical of our own results, because it’s only by testing and testing again that we will be able to reach the point where we’re confident in them," says Madhusudhan. "That’s how science has to work.</p>
<p>"Decades from now, we may look back at this point in time and recognise it was when the living universe came within reach.</p>
<p>"This could be the tipping point, where suddenly the fundamental question of whether we’re alone in the universe is one we’re capable of answering."</p>
</div></article><!----></storefront-content-body><!----><!----></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Passing planes and other whoosh sounds (123 pts)]]></title>
            <link>https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html</link>
            <guid>43713524</guid>
            <pubDate>Thu, 17 Apr 2025 05:53:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html">https://www.windytan.com/2025/04/passing-planes-and-other-whoosh-sounds.html</a>, See on <a href="https://news.ycombinator.com/item?id=43713524">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-body-2080249921577037368" itemprop="description articleBody">
<p>I always assumed that the recognisable 'whoosh' sound a plane makes when passing overhead simply comes from the famous <i>Doppler effect</i>. But when you listen closely, this explanation doesn't make complete sense.</p>






<p>(Audio clipped from <a href="https://freesound.org/people/bruno.auzet/sounds/706432/">freesound</a>)</p>

<p>A classic example of the Doppler effect is the sound of a passing ambulance constantly descending in pitch. When a plane flies overhead the roar of the engine sometimes does that as well. But you can also hear a wider, breathier noise that does something different: it's like the pitch goes down at first, but when the plane has passed us, the pitch <i>goes up</i> again. That's not how Doppler works! What's going on there?</p>

<h3>Comb filtering.</h3>

<p>Let's shed light on the mystery by taking a look at the sound in a time-frequency spectrogram. Here, time runs from top to bottom, frequencies from left (low) to right (high).</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAaOGJ0_mW_OWy2A0W2yp-_SRiqVJEfI0Vr6b3w_L-ByIBnYu23rtt2Jgwk6hMkNxJOIm5Hd8JFYt5oDtFofaBvzWUUQqTzRdCN4a9DBdEQu-qnZfWcfbpJhfO1ZIHVPWa0IkdRsMiG6AJCHGgOl3eK8UfBQw7WgxFyu9-pVhLJCBVuMuRaUXv6wnH3CuS/s858/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.51.58.jpg"><img alt="" data-original-height="500" data-original-width="858" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiAaOGJ0_mW_OWy2A0W2yp-_SRiqVJEfI0Vr6b3w_L-ByIBnYu23rtt2Jgwk6hMkNxJOIm5Hd8JFYt5oDtFofaBvzWUUQqTzRdCN4a9DBdEQu-qnZfWcfbpJhfO1ZIHVPWa0IkdRsMiG6AJCHGgOl3eK8UfBQw7WgxFyu9-pVhLJCBVuMuRaUXv6wnH3CuS/s858/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.51.58.jpg" width="500"></a></p>

<p>We can clearly see one part of the sound sweeping from right to left, or from high to low frequencies; this should be the Doppler effect. But there's something else happening on the left side.</p>

<p>The sound's frequency distribution seems to form a series of moving peaks and valleys. This resembles what audio engineers would call <a href="https://en.wikipedia.org/wiki/Comb_filter">'comb filtering'</a>, due to its appearance in the spectrogram. When the peaks and valleys move about it causes a 'whoosh' sound; this is the same principle as in the <a href="https://en.wikipedia.org/wiki/Flanging">flanger</a> effect used in music production. But these are just jargon for the electronically created version. We can call the acoustic phenomenon the whoosh.</p>

<p>The comb pattern is caused by two copies of the same exact sound arriving at a slightly different times, close enough that they form an interference pattern. It's closely related to what happens to light in the <a href="https://thefouriertransform.com/applications/diffraction3.php">double slit experiment</a>. In recordings this often means that the sound was captured by two microphones and then mixed together; you can sometimes hear this happen unintentionally in podcasts and radio shows. So my thought process is, are we hearing two copies of the plane's sound? How much later is the other one arriving, and why? And why does the 'whoosh' appear to go down in pitch at first, then up again?</p>

<h3>Into the cepstral domain.</h3>

<p>The <i>cepstrum</i>, which is the inverse Fourier transform of the estimated log spectrum, is a fascinating plot for looking at delays and echoes in complex (as in complicated) signals. While the spectrum separates frequencies, the cepstrum measures time, or <i>quefrency</i> – see what they did there? It reveals cyclicities in the sound's structure even if it interferes with itself, like in our case.</p>

<p>It's also useful for looking at sounds that, experientially, have a 'pitch' to them but that don't show any clear spectral peak in the Fourier transform. Just like the sound we're interested in.</p>

<p>Here's a time-<i>quefrency cepstrogram</i> of the same sound (to be accurate, I used the <i>autocepstrum</i> here for better clarity; autocorrelation would also work):</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1VOwgKsPuBeVTFUk9oq8zFJ_zEOjEx9eUB5ic4KKHFUVNtLYmPbDweOo2gfiokWxlZcc4038dO29gSq31mBXLZuJX1dHjAZ-oKPDDEGDBS1NJ0a_4MQfWA972iGLLEjYM8at0jlL4MtTmQQLVuR_t_liH8iyrwoPN90587N59xflXUqWZuWajevxw-9Tm/s859/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.39.15.jpg"><img alt="" data-original-height="501" data-original-width="859" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh1VOwgKsPuBeVTFUk9oq8zFJ_zEOjEx9eUB5ic4KKHFUVNtLYmPbDweOo2gfiokWxlZcc4038dO29gSq31mBXLZuJX1dHjAZ-oKPDDEGDBS1NJ0a_4MQfWA972iGLLEjYM8at0jlL4MtTmQQLVuR_t_liH8iyrwoPN90587N59xflXUqWZuWajevxw-9Tm/s501/Na%CC%88ytto%CC%88kuva%202025-04-13%20kello%2012.39.15.jpg" width="501"></a></p>

<p>The Doppler effect is less prominent here. Instead, the plot shows a sweeping peak that seems to agree with the pitch change we hear. This delay time sweeps from around 4 milliseconds to 9 ms and back. Note that the scale: higher frequencies (shorter times) are on the left side this time.</p>

<h3>Ground echo?</h3>

<p>Here's my hypothesis. We are hearing not only the direct sound from the plane but also a delayed echo from a nearby flat surface. These two sound get superimposed and interfere before they reach our ears. The effect would be especially prominent with planes because there is little in the way of the sound either from above or from the large surface. And what could be a large reflective surface outdoors? Well, the ground below!</p>

<p>Let's think about the numbers. The ground is around one-and-a-half metres below our ears. When a plane is directly overhead, the reflected sound needs to take a path that's three metres longer (two-way) than the direct path. Since sound travels 343 metres per second this translates to a difference of 9 milliseconds!</p>

<p>Below, I used GeoGebra to calculate the time difference (between the yellow and green paths) in milliseconds.</p>

<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA4ggy0g82ccmz9ywX_sLR8Y8-DjRgFT1F9fuU1uz4Bouan-j9K63jWL7qnhFTOeQVI_qDh6gq897-_AOhw6UgGtz4aZJRjrGuuBRIyPsHeDBj62gvDTlYZGssXSTogxnBKZBXZtZkd-bfZiy_VYKfDmq82o6s3S1pZD8P3Cb6rMHqY_C6acR5iaKGsxLd/s1200/delayed.png"><img alt="" data-original-height="366" data-original-width="1200" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA4ggy0g82ccmz9ywX_sLR8Y8-DjRgFT1F9fuU1uz4Bouan-j9K63jWL7qnhFTOeQVI_qDh6gq897-_AOhw6UgGtz4aZJRjrGuuBRIyPsHeDBj62gvDTlYZGssXSTogxnBKZBXZtZkd-bfZiy_VYKfDmq82o6s3S1pZD8P3Cb6rMHqY_C6acR5iaKGsxLd/s520/delayed.png" width="520"></a></p>

<p>When the plane is far away the angle is shallower, the two paths are more similar in distance, and the time difference is shorter.</p>

<p>It would follow that a taller person hears the sound differently than a shorter one, or someone in a tenth-floor window! If the ground is very soft, maybe in a mossy grove, you probably wouldn't hear the effect at all; just the Doppler effect. But this prediction needs to be tested out in a real forest.</p>

<p>Here's what a minimal acoustic simulation model renders. We'll just put a flying white noise source in the sky and a reflective surface as the ground. Let's only update the IR at 15 fps to prevent the Doppler phenomenon from emerging.</p>





<p>Whoosh!</p>

<h3>Some everyday whooshes.</h3>

<p>The whoosh isn't only associated with planes. When it occurs naturally it usually needs three things:</p>

<ul>
  <li>a sound with a lot of structure (preferably a hissy or breathy noise)</li>
  <li>an unobstructed echo from a closeby surface (either close to you or to the source of sound)</li>
  <li>and some kind of physical movement.</li>
</ul>

<p>I've heard this outdoors when the sound of a waterfall was reflecting off a brick wall (<a href="https://www.youtube.com/watch?v=Amj4UevyRfU">video</a>); and next to a motorway when the sound barrier provided the reflection. You can hear it in some films – for instance, in the original Home Alone when Kevin puts down the pizza box after taking a whiff (<a href="https://youtu.be/H6M_mFUH35s?t=100">video</a>)!</p>

<p>Try it yourself: move your head towards a wall – or a laptop screen – and back away from it, while making a continuous 'hhhh' or 'shhh' noise. Listen closely but don't close your eyes, you might bump your nose.</p>

<h3>A simple little plot.</h3>

<p>Finally, if you have JavaScript turned on you'll see (and hear) some more stuff in this blog post. In the interactive graph below you can move the aeroplane and listener around and see how the numbers change. The 'lag' or time difference we hear (orange arrow) comes from how much farther away the reflected virtual image is compared to the real aeroplane. In the lower right corner, the 'filter' spectrum up to 4.5 kHz is also drawn. The circles are there to visualize the direct distance.</p>








<p>Where have you encountered the whoosh?</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US judge finds administration wilfully defied court order in deportation flights (153 pts)]]></title>
            <link>https://www.abc.net.au/news/2025-04-17/judge-in-venezuelan-migrants-case-finds-trump-admin-probably-con/105186022</link>
            <guid>43712598</guid>
            <pubDate>Thu, 17 Apr 2025 02:44:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abc.net.au/news/2025-04-17/judge-in-venezuelan-migrants-case-finds-trump-admin-probably-con/105186022">https://www.abc.net.au/news/2025-04-17/judge-in-venezuelan-migrants-case-finds-trump-admin-probably-con/105186022</a>, See on <a href="https://news.ycombinator.com/item?id=43712598">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div data-component="ArticleHeadline"><div data-chartbeat-authors="[]"><p><time data-component="ScreenReaderOnly" datetime="2025-04-16T17:30:44.000Z">16 hours ago</time><time data-component="Text">Wed 16 Apr 2025 at 5:30pm</time></p></div><div><figure data-print="inline-media" data-component="Figure" id="105186030" data-uri="coremedia://imageproxy/105186030"><div><p><img alt="Two men in prison suits are knelt on the floor as guards shave their heads." sizes="100vw" src="https://live-production.wcms.abc-cdn.net.au/da8d02dc0924a6a61b56029250dccac4?impolicy=wcms_crop_resize&amp;cropH=2812&amp;cropW=5000&amp;xPos=0&amp;yPos=214&amp;width=862&amp;height=485" loading="lazy" data-component="Image" data-lazy="true"></p></div><figcaption><p data-component="Typography">The US government has deported hundreds of people to a prison in El Salvador, despite legal challenges.<!-- --> <cite>(<span>Salvadoran government via Reuters</span>)</cite></p></figcaption></figure></div></div><div><h2 data-component="Heading">In short:</h2><p>Officials in Donald Trump's administration could face criminal prosecution for contempt of court, a US judge says, because they have shown "wilful disregard" for an order against deporting alleged gang members to El Salvador.</p><p>US District Judge James Boasberg says he has "probable cause" to hold the administration in contempt of court.</p><p>The move ups the stakes in the stand-off between the Trump administration and the courts.</p></div></div><div><p>A US federal judge has found "probable cause" to hold the Trump administration in contempt of court for violating his previous order to halt deportations of Venezuelan migrants.</p><p>US District Judge James Boasberg said the administration demonstrated "wilful disregard" for his March 15 order barring the government from deporting Venezuelan alleged gang members to El Salvador.</p><p>The finding could result in officials facing criminal prosecution for not complying with Judge Boasberg's earlier order.</p><p>The Trump administration has maintained it was entitled to carry out the deportations under the Alien Enemies Act.</p><p>When Judge Boasberg issued the order, two planes of Venezuelans were already on their way from the United States to El Salvador.</p><p>The planes were not turned around to the United States.</p><figure data-print="inline-media" data-component="Figure" id="105186032" data-uri="coremedia://imageproxy/105186032"><div><p><img alt="Kilmar Abrego Garcia wears a backwards cap and white t-shirt." sizes="100vw" src="https://live-production.wcms.abc-cdn.net.au/bac8a76b8053da923f7dedc7b9c4a9a4?impolicy=wcms_crop_resize&amp;cropH=1724&amp;cropW=1293&amp;xPos=848&amp;yPos=61&amp;width=862&amp;height=1149" loading="lazy" data-component="Image" data-lazy="true"></p></div><figcaption><p data-component="Typography">Kilmar Abrego Garcia was mistakenly deported to a mega-prison in El Salvador by the Trump administration.<!-- --> <cite>(<span>Supplied: CASA</span>)</cite></p></figcaption></figure><p>On Wednesday, Judge Boasberg said there was probable cause to find officials in the administration in criminal contempt as a result.</p><p>"The Court does not reach such conclusion lightly or hastily," he wrote in his ruling.</p><p>"Indeed, it has given defendants ample opportunity to rectify or explain their actions.</p><p>"None of their responses has been satisfactory."</p><p>Judge Boasberg said the administration would first have the opportunity to "purge" its contempt before he considers potential criminal prosecution.</p><p>"The Constitution does not tolerate wilful disobedience of judicial orders — especially by officials of a coordinate branch who have sworn an oath to uphold it," Judge Boasberg wrote.</p><p>The Trump administration did not immediately respond to a request for comment.</p><p>The El Salvador deportation flights have been subject to an increasing backlash over reports innocent people have ended up mistakenly jailed in a notorious Salvadoran mega-prison.</p><p>The administration has refused to free one man, Kilmar Abrego Garcia, who was mistakenly deported.</p><p>Judge Paula Xinis last week ordered the US government to arrange his return, noting Mr Garcia was a husband and father and had no links to criminal gangs.</p><p>The same judge this week said the US government was <a href="https://www.abc.net.au/news/2025-04-16/kilmar-abrego-garcia-deportation-el-salvador-court/105181198" data-component="Link" data-uri="coremedia://article/105181198">doing "nothing" to facilitate his return</a>.</p><p>During an Oval Office appearance earlier this week, both Donald Trump and El Salvador President Nayib Bukele <a href="https://www.abc.net.au/news/2025-04-15/nayib-bukele-donald-trump-el-salvador-deporations/105176648" data-component="Link">both insisted there was no way to bring Mr Garcia home</a>.</p><p>Mr Trump also said he was open to jailing US citizens in prisons in El Salvador if they had committed crimes, prompting alarm.</p><p><strong>Reuters/AP</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Zoom outage caused by accidental 'shutting down' of the zoom.us domain (468 pts)]]></title>
            <link>https://status.zoom.us/incidents/pw9r9vnq5rvk</link>
            <guid>43711957</guid>
            <pubDate>Thu, 17 Apr 2025 00:55:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://status.zoom.us/incidents/pw9r9vnq5rvk">https://status.zoom.us/incidents/pw9r9vnq5rvk</a>, See on <a href="https://news.ycombinator.com/item?id=43711957">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      <!-- postmortem if it's published -->

      <!-- incident updates in reverse order -->
        <div>
          <h2>
            Resolved
          </h2>
          <div>
            <p><span>On April 16, between 2:25 P.M. ET and 4:12 P.M. ET, the domain zoom.us was not available due to a server block by GoDaddy Registry. This block was the result of a communication error between Zoom’s domain registrar, Markmonitor, and GoDaddy Registry, which resulted in GoDaddy Registry mistakenly shutting down zoom.us domain. <p>Zoom, Markmonitor and GoDaddy worked quickly to identify and remove the block, which restored service to the domain zoom.us. There was no product, security, network failure or Distributed Denial of Service (DDoS) attack at Zoom during the outage. GoDaddy and Markmonitor are working together to prevent this from happening again.</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744849863000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">17:31</var> PDT
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>All Zoom services have been restored, if you are still having connection issues please flush your DNS cache and reconnect.<p>For Windows open a command prompt and type "ipconfig /flushdns"<br>For Mac open a terminal window and type "sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder"</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744839342000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">14:35</var> PDT
            </p>
          </div>
        </div>
        <div>
          <h2>
            Monitoring
          </h2>
          <div>
            <p><span>Services have been restored, if you are still having connection issues please flush your DNS cache and attempt to reconnect.<p>For Windows open a command prompt and type "ipconfig /flushdns"<br>For Mac open a terminal window and type "sudo dscacheutil -flushcache; sudo killall -HUP mDNSResponder"</p></span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744836911000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">13:55</var> PDT
            </p>
          </div>
        </div>
        <div>
          <h2>
            Identified
          </h2>
          <div>
            <p><span>We continue to investigate the domain name resolution issues on the zoom.us domain that is affecting multiple services. More updates to follow.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744834616000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">13:16</var> PDT
            </p>
          </div>
        </div>
        <div>
          <h2>
            Update
          </h2>
          <div>
            <p><span>We continue to investigate the domain name resolution issues on the zoom.us domain that is affecting multiple services. More updates to follow.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744833106000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">12:51</var> PDT
            </p>
          </div>
        </div>
        <div>
          <h2>
            Investigating
          </h2>
          <div>
            <p><span>We are investigating domain name resolution issues on the zoom.us domain that is affecting multiple services. Regular updates will be provided.</span>
            </p>
            <p>
              Posted <span data-datetime-unix="1744831075000"></span>Apr <var data-var="date">16</var>, <var data-var="year">2025</var> - <var data-var="time">12:17</var> PDT
            </p>
          </div>
        </div>

      <!-- affected components -->
        <p>
          This incident affected: Zoom Meetings (Zoom Meetings), Zoom Phone - Global (Web Portal (Admin/Users/Provisioning/Dashboard &amp; Reporting)), Zoom Contact Center - Global (Web Portal (Admin/Users/Provisioning)), and Zoom Website (Web Portal).
        </p>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jellyfin as a Spotify alternative (345 pts)]]></title>
            <link>https://coppolaemilio.com/entries/i-left-spotify-what-happened-next/</link>
            <guid>43711706</guid>
            <pubDate>Thu, 17 Apr 2025 00:10:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://coppolaemilio.com/entries/i-left-spotify-what-happened-next/">https://coppolaemilio.com/entries/i-left-spotify-what-happened-next/</a>, See on <a href="https://news.ycombinator.com/item?id=43711706">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
		<p>When I stopped using Spotify I tried a few different solutions until I found the perfect replacement for me. If you want the tl;dr: I now use <a href="https://jellyfin.org/">Jellyfin</a>. But if you want to know how I got here, follow me through each step of the way.</p>

<p>I started gathering all my music files (<code>mp3</code>, or <code>flac</code>) in my computer, and from there I wanted to just listen to them the old way. The first issue I encountered was that none of the available music players were any good.</p>

<figure>
  <img src="https://coppolaemilio.com/assets/images/left-spotify/winamp.png" alt="">
  
    <figcaption>Winamp 2 default Base Skin</figcaption>
  
</figure>

<p>We all love the nostalgic look of <a href="https://en.wikipedia.org/wiki/Winamp">Winamp</a> in screenshots, but in reality those players are very limited. They work (kinda) okay for playing a single album, but I struggle to browse my library or create a playlist with them. I tried tons of programs, but none of them satisfied me. I guess music players left the zeitgeist so the technology of playing files locally didn’t improve much lately.
For a few days, I went along with the good old VLC player, but I was surprised to find how bad it is at handling <code>flac</code> files.</p>

<p>I gave <a href="https://www.foobar2000.org/">foobar2000</a> another go, and remember how much of a clusterfuck setting it up is. After a few days of trial and error I decided that it wasn’t worth the effort.</p>

<figure>
  <img src="https://coppolaemilio.com/assets/images/left-spotify/foobar2000-midnight.png" alt="">
  
    <figcaption>foobar2000's Midnight theme that probably took hundreds of hours to make.</figcaption>
  
</figure>

<p>Since I was feeling adventurous and I wanted an excuse to learn <a href="https://htmx.org/">htmx</a>, I ended up building a rudimentary web music player that worked surprisingly well. The player streamed music from my library on a browser, so I could spin up a local server and access to all my music remotely from anywhere.</p>

<p>This worked well for a while, and it was a nice learning exercise, but it all fell apart when I had to go on a trip. Without internet or having the laptop running to host the server I wasn’t able to listen to any music on my phone, so it made some flights particularly long. I knew I could take the project to the next level and add some sort of “download to listen offline” feature, but the browser storage is not enough for that, so I would had to bundle the website into a “proper app”. I wasn’t going to spend more time on this side project, so it was time to look for another solution.</p>

<p>My last resort and the option I ended up using the most was Apple’s Music app. It is a bloated program with vestiges of what itunes was. It tries very hard to sell their subscription service, but below all noise, there is a music player that’s actually not bad. It has all kinds of sorting, and an up to date interface.
You can sync the music library with your phone or other devices and you won’t have any issues if you are offline. No more boring train rides!</p>

<p>Unfortunately, having your entire music library in every device takes too much space, so you have to start playing some sort of <em>storage battle royale</em>, and decide which music you won’t want to listen anymore. 
This shouldn’t be a big deal (none of the issues I’m listing here are), but when you are competing with the knowledge of something like Spotify existing, it is hard to voluntarily make things harder than they should be.</p>

<p>Fortunately for me, YouTube decided to shove a video down my throat:</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/4VkY1vTpCJY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>I didn’t know Jeff Geerling, but I’ve been a happy subscriber since :) he has a lot of good videos and he always carries a contagious enthusiasm about any topic he covers.</p>

<p>The video I linked covers how Jellyfin can replace something like Disney+ or Netflix, but it can also replace Spotify. It has all the features that I was looking for! There is only one downside compared to Spotify: you have to host it yourself.</p>

<p>Self-hosting might sound scary to some, and of course it is not something I would recommend to everyone. But I promise that you can set up Jellyfin without much hustle even if you are not a programmer! To do so you don’t need to buy a NAS or any fancy extra equipment. If you have an old computer around, it is probably good enough as a home server.</p>

<p>Jellyfin has everything I hoped for and more. I tried running it locally in my computer at first, and I was surprised of how easy it was to get it up and running. Then I discovered that there are apps that communicate with your Jellyfin server and allow you to download music from your library for offline listening. <a href="https://www.fintunes.app/">Fintunes</a>, <a href="https://tilosoftware.io/manet/">Manet</a>, <a href="https://github.com/jmshrv/finamp">Finamp</a>, and the list <a href="https://jellyfin.org/downloads/clients/">goes on</a>. <a href="https://github.com/jmshrv/finamp">Finamp</a> is the one I ended up daily driving in my phone.</p>

<figure>
  <img src="https://coppolaemilio.com/assets/images/left-spotify/jellyfin-0.webp" alt="">
  
    <figcaption>A screenshot of my Jellyfin music library in the browser</figcaption>
  
</figure>

<p>In the past few months, the world started shifting significantly, so I wanted to give another step in my journey of digital autonomy. I bought a mini pc to start self-hosting apps like Jellyfin from home. Since the experience was so good, I started looking into other things I could start self-hosting, and I’m now running <a href="https://immich.app/">Immich</a> as well. Immich is like a much better Google Photos, but that’s a story for another time.</p>

<p>If you read until here, and you are curious about self-hosting, I encourage you to give it a try! It doesn’t take much time and it is totally doable as a hobby/side project. If you have some minimal knowledge of how to use a terminal, you won’t have any problems to set things up. And once it’s running, you will be able to enjoy your entire library from any device anywhere.</p>

<figure>
  <img src="https://coppolaemilio.com/assets/images/left-spotify/jellyfin-1.webp" alt="">
  
    <figcaption>A screenshot of my Jellyfin with an album from <a href="https://coppolaemilio.com/entries/the-last-rock-band/">a band you should know about</a>.</figcaption>
  
</figure>

<p>If software like this keeps getting better, I can imagine a future where we don’t have to <a href="https://www.youtube.com/watch?v=7CDKvdlD6uQ">depend on some other’s peoples computers</a> to access to our own music, movies, photos or memories. We just have to make it easier and better, like open-source always does. It might take longer to get there, but I’m damn sure we will.</p>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Seth Rogen Speaks Truth to Billionaires, Gets Censored for It (203 pts)]]></title>
            <link>https://kottke.org/25/04/seth-rogan-speaks-truth-to-billionaires-gets-censored-for-it</link>
            <guid>43711410</guid>
            <pubDate>Wed, 16 Apr 2025 23:25:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kottke.org/25/04/seth-rogan-speaks-truth-to-billionaires-gets-censored-for-it">https://kottke.org/25/04/seth-rogan-speaks-truth-to-billionaires-gets-censored-for-it</a>, See on <a href="https://news.ycombinator.com/item?id=43711410">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-container">
<p>

posted <time datetime="2025-04-16T14:26:14Z">Apr 16 @ 10:26 AM</time> by <a href="http://www.kottke.org/">Jason Kottke</a><span>  ·  <span>gift link</span></span>



</p>




<p><img src="https://kottke.org/cdn-cgi/image/format=auto,fit=scale-down,width=1200,metadata=none/plus/misc/images/seth-rogan-science.jpg" srcset="https://kottke.org/cdn-cgi/image/format=auto,fit=scale-down,width=500,metadata=none/plus/misc/images/seth-rogan-science.jpg 500w, https://kottke.org/cdn-cgi/image/format=auto,fit=scale-down,width=1200,metadata=none/plus/misc/images/seth-rogan-science.jpg 1200w" sizes="(max-width: 500px) 500px, 1200px" loading="lazy" width="1300" height="732" alt="Seth Rogen talks while presenting a prize"></p>

<p>For the past 11 years, <a href="https://breakthroughprize.org/">the Breakthrough Prize awards</a> have “celebrated outstanding scientific achievements, honoring scientists driving remarkable discoveries in gene editing, human diseases, the search for the fundamental laws of the Universe and pure mathematics”. At this year’s awards, Edward Norton &amp; Seth Rogen presented a prize in fundamental physics and <a href="https://www.hollywoodreporter.com/news/general-news/seth-rogens-breakthrough-prize-video-cut-1236191599/">Rogen took the opportunity to remind the audience</a> — including Mark Zuckerberg, Jeff Bezos, and Sam Altman — that the Trump regime is actively destroying the ability for people to pursue science in America.</p>

<blockquote><p>And it’s amazing that others [who have been] in this room underwrote electing a man who, in the last week, single-handedly destroyed all of American science. It’s amazing how much good science you can destroy with $320 million and RFK Jr, very fast.</p></blockquote>

<p>Rogen’s remarks were heard during the live presentation but have been scrubbed from <a href="https://www.youtube.com/watch?v=yVCKi-4DkKY">the video on YouTube</a>. I haven’t seen the uncensored video anywhere…drop me a line if you run across it?</p>

<ul><li><a href="https://kottke.org/tag/2025%20Coup">2025 Coup</a></li><li><a href="https://kottke.org/tag/Donald%20Trump">Donald Trump</a></li><li><a href="https://kottke.org/tag/Elon%20Musk">Elon Musk</a></li><li><a href="https://kottke.org/tag/politics">politics</a></li><li><a href="https://kottke.org/tag/science">science</a></li><li><a href="https://kottke.org/tag/Seth%20Rogen">Seth Rogen</a></li></ul>








</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Astronomers Detect a Possible Signature of Life on a Distant Planet (152 pts)]]></title>
            <link>https://www.nytimes.com/2025/04/16/science/astronomy-exoplanets-habitable-k218b.html</link>
            <guid>43711376</guid>
            <pubDate>Wed, 16 Apr 2025 23:20:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/04/16/science/astronomy-exoplanets-habitable-k218b.html">https://www.nytimes.com/2025/04/16/science/astronomy-exoplanets-habitable-k218b.html</a>, See on <a href="https://news.ycombinator.com/item?id=43711376">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/04/16/science/astronomy-exoplanets-habitable-k218b.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft researchers developed a hyper-efficient AI model that can run on CPUs (133 pts)]]></title>
            <link>https://techcrunch.com/2025/04/16/microsoft-researchers-say-theyve-developed-a-hyper-efficient-ai-model-that-can-run-on-cpus/</link>
            <guid>43711227</guid>
            <pubDate>Wed, 16 Apr 2025 22:57:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/04/16/microsoft-researchers-say-theyve-developed-a-hyper-efficient-ai-model-that-can-run-on-cpus/">https://techcrunch.com/2025/04/16/microsoft-researchers-say-theyve-developed-a-hyper-efficient-ai-model-that-can-run-on-cpus/</a>, See on <a href="https://news.ycombinator.com/item?id=43711227">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">Microsoft researchers claim they’ve developed the largest-scale 1-bit AI model, also known as a “bitnet,” to date. Called BitNet b1.58 2B4T, it’s <a href="https://huggingface.co/microsoft/bitnet-b1.58-2B-4T" target="_blank" rel="noreferrer noopener nofollow">openly available</a> under an MIT license and can run on CPUs, including Apple’s M2.</p>

<p>Bitnets are essentially compressed models designed to run on lightweight hardware. In standard models, weights, the values that define the internal structure of a model, are often<em> </em>quantized so the models perform well on a wide range of machines. Quantizing the weights lowers the number of bits — the smallest units a computer can process — needed to represent those weights, enabling models to run on chips with less memory, faster.</p>







<p>Bitnets quantize weights into just three values: -1, 0, and 1. In theory, that makes them far more memory- and computing-efficient than most models today.</p>

<p>The Microsoft researchers say that BitNet b1.58 2B4T is the first bitnet with 2 billion parameters, “parameters” being largely synonymous with “weights.” Trained on a dataset of 4 trillion tokens — equivalent to about 33 million books, <a href="https://everdome.io/news/ai-tokens-explained-the-tldr-version" target="_blank" rel="noreferrer noopener nofollow">by one estimate</a> — BitNet b1.58 2B4T outperforms traditional models of similar sizes, the researchers claim.</p>

<p>BitNet b1.58 2B4T doesn’t sweep the floor with rival 2 billion-parameter models, to be clear, but it seemingly holds its own. According to the researchers’ testing, the model surpasses Meta’s Llama 3.2 1B, Google’s Gemma 3 1B, and Alibaba’s Qwen 2.5 1.5B on benchmarks including GSM8K (a collection of grade-school-level math problems) and PIQA (which tests physical commonsense reasoning skills).</p>

<p>Perhaps more impressively, BitNet b1.58 2B4T is speedier than other models of its size — in some cases, twice the speed — while using a fraction of the memory. </p>

<p>There is a catch, however. </p>


<p>Achieving that performance requires using Microsoft’s custom framework, bitnet.cpp, which only works with certain hardware at the moment. Absent from the list of supported chips are GPUs, which dominate the AI infrastructure landscape. </p>

<p>That’s all to say that bitnets may hold promise, particularly for resource-constrained devices. But compatibility is — and will likely remain — a big sticking point.</p>
</div><div>
	
	
	
	

	
<div>
	<p>
		Kyle Wiggers is TechCrunch’s AI Editor. His writing has appeared in VentureBeat and Digital Trends, as well as a range of gadget blogs including Android Police, Android Authority, Droid-Life, and XDA-Developers. He lives in Manhattan with his partner, a music therapist.	</p>
</div>


	
	<p>
		<a data-ctatext="View Bio" data-destinationlink="https://techcrunch.com/author/kyle-wiggers/" data-event="button" href="https://techcrunch.com/author/kyle-wiggers/">View Bio <svg style="width: 1em;" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24"><path fill="var(--c-svg, currentColor)" d="M16.5 12 9 19.5l-1.05-1.05L14.4 12 7.95 5.55 9 4.5z"></path></svg></a>
	</p>
	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How a Forgotten Battle Created a More Peaceful World (136 pts)]]></title>
            <link>https://worldhistory.substack.com/p/how-a-forgotten-battle-created-a</link>
            <guid>43711001</guid>
            <pubDate>Wed, 16 Apr 2025 22:21:14 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://worldhistory.substack.com/p/how-a-forgotten-battle-created-a">https://worldhistory.substack.com/p/how-a-forgotten-battle-created-a</a>, See on <a href="https://news.ycombinator.com/item?id=43711001">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg" width="960" height="624" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:624,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false,&quot;align&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffb80969d-04a1-4593-a645-4191ded230f1_960x624.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><span>Adolphe Yvon’s painting of the battle at Solferino (</span><a href="https://commons.wikimedia.org/wiki/File:Yvon_Bataille_de_Solferino_Compiegne.jpg" rel="">Public domain</a><span>)</span></figcaption></figure></div><p>On a June day near Solferino, a town in what’s now northern Italy, something depressingly common happened. Two European armies clashed in combat, and thousands of men lost their lives.</p><p>The Battle of Solferino was considered an important event at the time — it was the biggest European battle since the Napoleonic Wars, and it paved the way for the establishment of an independent Italy — but it’s faded from public memory outside of Italy. Its narratives are obscure these days because of the complexity of the conflict it helped to end (the battle involved France, Piedmont-Sardinia, and the Austrian Empire). It doesn’t show up in high school history classes like Waterloo, Austerlitz, Sedan, and Gettysburg do.</p><p>But it did change the world in unexpected ways. In fact, one man’s encounter with suffering at Solferino helped to make the world a little bit better. A combination of strange coincidence and basic human emotion became the foundation of the rickety structure that we call international law — a system that is in great danger today.</p><p><em><span>Thanks for reading! To support my work, please </span><strong>click the button below:</strong></em></p><p><em><span>If you want to help keep this project going, </span><strong>please consider purchasing a paid subscription.</strong><span> Paid subscribers — it’s </span><strong>only about 75 cents a week!</strong><span> — get access to the archives, the satisfaction of supporting work they enjoy, and my undying gratitude.</span></em></p><p>Switzerland during the early 19th century was captivated by a religious movement called the Réveil — the revival. The movement’s leaders reinvigorated Calvinist Christianity, modernizing liturgies, empowering women, and encouraging believers to help the less fortunate. Henry Dunant, a young Swiss businessman from a prominent Geneva family, jumped into the Réveil with both feet. He formed Bible study groups, visited prisoners, and established the Geneva branch of the YMCA.</p><p>Dunant, like many European Christians, had a moral blind spot about colonialism. Despite his religious beliefs, he thought he might make some money trading in the French colony of Algeria, so he set up a company to acquire land and grow crops there. But he ran into interference from the French authorities in Algeria, so, like the young man with connections that he was, Dunant decided to take his problems to the emperor of France himself — Napoleon III.</p><p>He prepared to kiss some royal butt, writing up a lengthy document about how wonderful Napoleon III was so that he could present it at their meeting. Napoleon III happened to be with his army fighting against the Austrians in Italy at the time, so Dunant set off to find the emperor.</p><p>Dunant happened to catch up with Napoleon III at Solferino on June 24, 1859, just after the battle had ended. By the time he arrived, tens of thousands of soldiers lay on the battlefield. Some were dead, some were dying, some were in extreme duress.</p><p><span>Dunant was </span><a href="https://web.ics.purdue.edu/~wggray/Teaching/His300/Handouts/Dunant-Solferino.pdf" rel="">haunted</a><span> by what he heard and saw:</span></p><blockquote><p>The stillness of the night was broken by groans, by stifled sighs of anguish and suffering. Heart-rending voices kept calling for help. Who could ever describe the agonies of that fearful night!</p><p>When the sun came up on the twenty-fifth, it disclosed the most dreadful sights imaginable. Bodies of men and horses covered the battlefield; corpses were strewn over roads, ditches, ravines, thickets and fields; the approaches of Solferino were literally thick with dead. The fields were devastated, wheat and corn lying flat on the ground, fences broken, orchards ruined; here and there were pools of blood. The villages were deserted and bore the scars left by musket shots, bombs, rockets, grenades and shells. Walls were broken down and pierced with gaps where cannonballs had crushed through them. Houses were riddled with holes, shattered and ruined, and their inhabitants, who had been in hiding, crouching in cellars without light or food for nearly twenty hours, were beginning to crawl out, looking stunned by the terrors they had endured.</p></blockquote><p>Dunant was shocked by the human suffering, but he was also taken aback by the fact that the armies that had meticulously organized the violence seemed to have no real plan to care for those they had harmed. Dunant went into action, rounding up local women to tend to the wounded. He got the French army to release imprisoned Austrian doctors who could help with medical care. He paid for the establishment of field hospitals. And he encouraged the locals to care for enemy soldiers by telling them that, as Christians, “tutti fratelli” — we are all brothers.</p><p>Dunant wrote a self-published memoir of his time in Solferino that dramatized the graphic suffering he had witnessed among the wounded:</p><blockquote><p>With faces black with the flies that swarmed about their wounds, men gazed around them, wild-eyed and helpless. Others were no more than a worm-ridden, inextricable compound of coat and shirt and flesh and blood. Many were shuddering at the thought of being devoured by the worms, which they thought they could see coming out of their bodies (whereas they really came from the myriads of flies which infested the air). There was one poor man, completely disfigured, with a broken jaw and his swollen tongue hanging out of his mouth. He was tossing and trying to get up. I moistened his dry lips and hardened tongue, took a handful of lint and dipped it in the bucket they were carrying behind me, and squeezed the water from this improvised sponge into the deformed opening that had been his mouth. Another wretched man had had a part of his face-nose, lips and chin-taken off by a sabre cut. He could not speak, and lay, half-blind, making heart-rending signs with his hands and uttering guttural sounds to attract attention. I gave him a drink and poured a little fresh water on his bleeding face. A third, with his skull gaping wide open, was dying, spitting out his brains on the stone floor. His companions in suffering kicked him out of their way, as he blocked the passage. I was able to shelter him for the last moments of his life, and I laid a handkerchief over his poor head, which still just moved.</p></blockquote><p>Dunant concluded:</p><blockquote><p>But why have I told of all these scenes of pain and distress, and perhaps aroused painful emotions in my readers? Why have I lingered with seeming complacency over lamentable pictures, tracing their details with what may appear desperate fidelity?</p><p>It is a natural question. Perhaps I might answer it by another: Would it not be possible, in time of peace and quiet, to form relief societies for the purpose of having care given to the wounded in wartime by zealous, devoted and thoroughly qualified volunteers?</p></blockquote><p>Haunted by his experience, Dunant got to work. He banded together with other Swiss businessmen and philanthropists to form the International Committee of the Red Cross, an organization that has done immense good over the last century and a half. But he wanted to go further than that. He wanted laws to govern how nations could deal with one another.</p><p>International law is a funny thing. Within a country, lines of authority are clear. The government makes laws, it has agencies that enforce them, and the penalties for violating the laws are clear. But, in our modern system of sovereign states, no authority sits above the nation. Each country is sovereign. International laws are, therefore, more fragile, because they require the consent of everybody involved to keep them going.</p><p>Despite these difficulties — and though the idea of restraint in wartime is oxymoronic — Dunant thought it was important that there be rules to govern the behavior of countries in combat. He thought that, even if he couldn’t eliminate warfare altogether, he could at least minimize the type of pointless suffering that he had seen at Solferino.</p><p>Dunant persuaded the Swiss government to host 12 countries for discussions about “The Amelioration of the Condition of the Wounded in Armies in the Field.” The agreement that the countries reached, which bound them all to treat wounded enemy soldiers and allow the Red Cross to help with humanitarian aid in times of war, became known as the First Geneva Convention. It was the beginning of the construction of the fragile structure that became modern international law.</p><p>Things didn’t work out very well for Henry Dunant in the end. His business in Algeria fell apart, he went bankrupt, and his business partners accused him of fraud. It was a big scandal in Geneva; he moved to Paris to escape criticism. There, Dunant kept dreaming of utopian solutions to the world’s problems (he became a proponent of a global library from which all humans could learn), but he no longer had the resources to implement them. His movement chugged on without him; the Red Cross spread around the world, though it no longer advertised his role in its founding.</p><p>It wasn’t until the end of his life that a historian uncovered Dunant’s role in the founding of the ICRC and resurrected his reputation. He received the first Nobel Peace Prize in 1901 at the age of 73. By this time, it was clear that his efforts to establish rules around international activity had borne fruit.</p><p>The First Geneva Convention provided a foundation for more agreements between the world’s nations. Subsequent conventions established the rights of prisoners of war and protections for civilians in times of war. These agreements led to the formation of international organizations like the League of Nations, which attempted to regulate interactions between countries in order to maintain peace.</p><p>Though these agreements and organizations didn’t always succeed in keeping the peace, the idea of an international order based on rules persisted. After World War II, allied governments established the United Nations, World Bank, International Monetary Fund, World Health Organization, and many more. These organizations were built around the ideas in the preamble of the UN Declaration of Human Rights:</p><blockquote><p>Whereas it is essential… that human rights should be protected by the rule of law…</p><p>Whereas it is essential to promote the development of friendly relations between nations…</p><p>Whereas the peoples of the United Nations have in the Charter reaffirmed their faith in fundamental human rights, in the dignity and worth of the human person and in the equal rights of men and women and have determined to promote social progress and better standards of life in larger freedom…</p><p>Whereas Member States have pledged themselves to achieve, in co-operation with the United Nations, the promotion of universal respect for and observance of human rights and fundamental freedoms.</p></blockquote><p>Did nations always follow international law? No. Did they consistently demonstrate their belief in the principles of the Geneva Conventions and the UN? Of course not. But the world did get more peaceful. There was no World War III, and countries at least had to pay lip service to these universal values of peace and human rights.</p><p>The relatively stable and prosperous world that we all enjoy today is, in part, due to the efforts of Henry Dunant and other dreamers who believed that nations could and should behave according to common values. These visionaries convinced the world that everyone, even the powerful, was better off if they all agreed to limit their behavior and work together.</p><p><span>Over the ensuing 150 years, people built a system of international law on this foundation that, though certainly imperfect, has </span><a href="https://www.eda.admin.ch/aboutswitzerland/en/home/swiss-stories/75-jahre-genfer-konventionen.html" rel="">saved</a><span> millions of lives and made the world a better place.</span></p><p>But the structure that humanity built on Dunant’s insights at Solferino has always been vulnerable. Since it has beenconstructed through the voluntary cooperation of nations, it is vulnerable if powerful countries abandon the system — or worse, actively work to demolish it.</p><p>We find ourselves in just such a situation, as authoritarian regimes in countries like China and Russia, joined by the new leadership of the United States, attack the international order that diplomats have painstakingly built. They may succeed, but they should be careful what they wish for. A world without rules is, as Henry Dunant understood, a world of chaos and cruelty.</p><p><em>This newsletter is free to all, but I count on the kindness of readers to keep it going. If you enjoyed reading this week’s edition, there are three ways to support my work: </em></p><p><em>You can subscribe as a free or paying member:</em></p><p><em>You can share the newsletter with others:</em></p><p data-attrs="{&quot;url&quot;:&quot;https://worldhistory.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share Looking Through the Past&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://worldhistory.substack.com/?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share Looking Through the Past</span></a></p><p><em>You can “buy me a coffee” by sending me a one-time or recurring payment:</em></p><p data-attrs="{&quot;url&quot;:&quot;https://ko-fi.com/georgedillard&quot;,&quot;text&quot;:&quot;Support me on Ko-Fi&quot;,&quot;action&quot;:null,&quot;class&quot;:&quot;button-wrapper&quot;}" data-component-name="ButtonCreateButton"><a href="https://ko-fi.com/georgedillard" rel=""><span>Support me on Ko-Fi</span></a></p><p><em>Thanks for reading, and I’ll see you again next week!</em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Plandex v2 – open source AI coding agent for large projects and tasks (183 pts)]]></title>
            <link>https://github.com/plandex-ai/plandex</link>
            <guid>43710576</guid>
            <pubDate>Wed, 16 Apr 2025 21:26:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/plandex-ai/plandex">https://github.com/plandex-ai/plandex</a>, See on <a href="https://news.ycombinator.com/item?id=43710576">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">
 <a href="https://plandex.ai/" rel="nofollow">
  <themed-picture data-catalyst-inline="true"><picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://github.com/plandex-ai/plandex/raw/main/images/plandex-logo-dark-v2.png">
    <source media="(prefers-color-scheme: light)" srcset="https://github.com/plandex-ai/plandex/raw/main/images/plandex-logo-light-v2.png">
    <img width="400" src="https://github.com/plandex-ai/plandex/raw/main/images/plandex-logo-dark-bg-v2.png">
 </picture></themed-picture></a>
 <br>
</h2><a id="user-content------------------" aria-label="Permalink: " href="#-----------------"></a></div>


<p dir="auto">
  
<a href="https://github.com/plandex-ai/plandex/pulls"><img src="https://camo.githubusercontent.com/d88d8d77fa79e828eea397f75a1ebd114d13488aeec4747477ffbd2274de95ed/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d627269676874677265656e2e737667" alt="PRs Welcome" data-canonical-src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg"></a> <a href="https://github.com/plandex-ai/plandex/releases?q=cli"><img src="https://camo.githubusercontent.com/fabf8fea8243a7a82392cb46e1d1070926aa21512285a3611675080735a904b0/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f706c616e6465782d61692f706c616e6465783f66696c7465723d636c692a" alt="Release" data-canonical-src="https://img.shields.io/github/v/release/plandex-ai/plandex?filter=cli*"></a>
<a href="https://github.com/plandex-ai/plandex/releases?q=server"><img src="https://camo.githubusercontent.com/64ee10ed3471628b3b5a977b80b38c368c2de7287a08243bda7ad943efb8bea2/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f706c616e6465782d61692f706c616e6465783f66696c7465723d7365727665722a" alt="Release" data-canonical-src="https://img.shields.io/github/v/release/plandex-ai/plandex?filter=server*"></a>
  
</p>

<p><a href="https://trendshift.io/repositories/8994" rel="nofollow"><img src="https://camo.githubusercontent.com/e5efa19fdef24f9132375126378f0392c7dc5372dfe723fb04ad7399bd38cf04/68747470733a2f2f7472656e6473686966742e696f2f6170692f62616467652f7265706f7369746f726965732f38393934" alt="plandex-ai%2Fplandex | Trendshift" width="250" height="55" data-canonical-src="https://trendshift.io/api/badge/repositories/8994"></a>
</p>
<br>
<div dir="auto"><h2 tabindex="-1" dir="auto">
  An AI coding agent designed for large tasks and real world projects.</h2><a id="user-content---an-ai-coding-agent-designed-for-large-tasks-and-real-world-projects" aria-label="Permalink: 
  An AI coding agent designed for large tasks and real world projects." href="#--an-ai-coding-agent-designed-for-large-tasks-and-real-world-projects"></a></div>

  
<p><a href="https://www.youtube.com/watch?v=SFSu2vNmlLk" rel="nofollow">
    <img src="https://github.com/plandex-ai/plandex/raw/main/images/plandex-v2-yt.png" alt="Plandex v2 Demo Video" width="800">
  </a>
</p>

<p dir="auto">💻&nbsp; Plandex is a terminal-based AI development tool that can <strong>plan and execute</strong> large coding tasks that span many steps and touch dozens of files. It can handle up to 2M tokens of context directly (~100k per file), and can index directories with 20M tokens or more using tree-sitter project maps.</p>
<p dir="auto">🔬&nbsp; <strong>A cumulative diff review sandbox</strong> keeps AI-generated changes separate from your project files until they are ready to go. Command execution is controlled so you can easily roll back and debug. Plandex helps you get the most out of AI without leaving behind a mess in your project.</p>
<p dir="auto">🧠&nbsp; <strong>Combine the best models</strong> from Anthropic, OpenAI, Google, and open source providers to build entire features and apps with a robust terminal-based workflow.</p>
<p dir="auto">🚀&nbsp; Plandex is capable of <strong>full autonomy</strong>—it can load relevant files, plan and implement changes, execute commands, and automatically debug—but it's also highly flexible and configurable, giving developers fine-grained control and a step-by-step review process when needed.</p>
<p dir="auto">💪&nbsp; Plandex is designed to be resilient to <strong>large projects and files</strong>. If you've found that others tools struggle once your project gets past a certain size or the changes are too complex, give Plandex a shot.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Smart context management that works in big projects</h2><a id="user-content-smart-context-management-that-works-in-big-projects" aria-label="Permalink: Smart context management that works in big projects" href="#smart-context-management-that-works-in-big-projects"></a></p>
<ul dir="auto">
<li>
<p dir="auto">🐘 <strong>2M token effective context window</strong> with default model pack. Plandex loads only what's needed for each step.</p>
</li>
<li>
<p dir="auto">🗄️ <strong>Reliable in large projects and files.</strong> Easily generate, review, revise, and apply changes spanning dozens of files.</p>
</li>
<li>
<p dir="auto">🗺️ <strong>Fast project map generation</strong> and syntax validation with tree-sitter. Supports 30+ languages.</p>
</li>
<li>
<p dir="auto">💰 <strong>Context caching</strong> is used across the board for OpenAI and Anthropic models, reducing costs and latency.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tight control or full autonomy—it's up to you</h2><a id="user-content-tight-control-or-full-autonomyits-up-to-you" aria-label="Permalink: Tight control or full autonomy—it's up to you" href="#tight-control-or-full-autonomyits-up-to-you"></a></p>
<ul dir="auto">
<li>
<p dir="auto">🚦 <strong>Configurable autonomy:</strong> go from full auto mode to fine-grained control depending on the task.</p>
</li>
<li>
<p dir="auto">🐞 <strong>Automated debugging</strong> of terminal commands (like builds, linters, tests, deployments, and scripts). If you have Chrome installed, you can also automatically debug browser applications.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools that help you get production-ready results</h2><a id="user-content-tools-that-help-you-get-production-ready-results" aria-label="Permalink: Tools that help you get production-ready results" href="#tools-that-help-you-get-production-ready-results"></a></p>
<ul dir="auto">
<li>
<p dir="auto">💬 <strong>A project-aware chat mode</strong> that helps you flesh out ideas before moving to implementation. Also great for asking questions and learning about a codebase.</p>
</li>
<li>
<p dir="auto">🧠 <strong>Easily try + combine models</strong> from multiple providers. Curated model packs offer different tradeoffs of capability, cost, and speed, as well as open source and provider-specific packs.</p>
</li>
<li>
<p dir="auto">🛡️ <strong>Reliable file edits</strong> that prioritize correctness. While most edits are quick and cheap, Plandex validates both syntax and logic as needed, with multiple fallback layers when there are problems.</p>
</li>
<li>
<p dir="auto">🔀 <strong>Full-fledged version control</strong> for every update to the plan, including branches for exploring multiple paths or comparing different models.</p>
</li>
<li>
<p dir="auto">📂 <strong>Git integration</strong> with commit message generation and optional automatic commits.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Dev-friendly, easy to install</h2><a id="user-content-dev-friendly-easy-to-install" aria-label="Permalink: Dev-friendly, easy to install" href="#dev-friendly-easy-to-install"></a></p>
<ul dir="auto">
<li>
<p dir="auto">🧑‍💻 <strong>REPL mode</strong> with fuzzy auto-complete for commands and file loading. Just run <code>plandex</code> in any project to get started.</p>
</li>
<li>
<p dir="auto">🛠️ <strong>CLI interface</strong> for scripting or piping data into context.</p>
</li>
<li>
<p dir="auto">📦 <strong>One-line, zero dependency CLI install</strong>. Dockerized local mode for easily self-hosting the server. Cloud-hosting options for extra reliability and convenience.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Workflow&nbsp;&nbsp;🔄</h2><a id="user-content-workflow" aria-label="Permalink: Workflow&nbsp;&nbsp;🔄" href="#workflow"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/plandex-ai/plandex/blob/main/images/plandex-workflow.png"><img src="https://github.com/plandex-ai/plandex/raw/main/images/plandex-workflow.png" alt="Plandex workflow" width="100%"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples&nbsp; 🎥</h2><a id="user-content-examples-" aria-label="Permalink: Examples&nbsp; 🎥" href="#examples-"></a></p>
  
<p><a href="https://www.youtube.com/watch?v=g-_76U_nK0Y" rel="nofollow">
    <img src="https://github.com/plandex-ai/plandex/raw/main/images/plandex-browser-debug-yt.png" alt="Plandex Browser Debugging Example" width="800">
  </a>
</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Install&nbsp;&nbsp;📥</h2><a id="user-content-install" aria-label="Permalink: Install&nbsp;&nbsp;📥" href="#install"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -sL https://plandex.ai/install.sh | bash"><pre>curl -sL https://plandex.ai/install.sh <span>|</span> bash</pre></div>
<p dir="auto"><strong>Note:</strong> Windows is supported via <a href="https://learn.microsoft.com/en-us/windows/wsl/install" rel="nofollow">WSL</a>. Plandex only works correctly on Windows in the WSL shell. It doesn't work in the Windows CMD prompt or PowerShell.</p>
<p dir="auto"><a href="https://docs.plandex.ai/install" rel="nofollow">More installation options.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Hosting&nbsp;&nbsp;⚖️</h2><a id="user-content-hosting️" aria-label="Permalink: Hosting&nbsp;&nbsp;⚖️" href="#hosting️"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Option</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Plandex Cloud (Integrated Models)</strong></td>
<td>• No separate accounts or API keys.<br>• Easy multi-device usage.<br>• Centralized billing, budgeting, usage tracking, and cost reporting.<br>• Quickest way to <a href="https://app.plandex.ai/start?modelsMode=integrated" rel="nofollow">get started.</a></td>
</tr>
<tr>
<td><strong>Plandex Cloud (BYO API Key)</strong></td>
<td>• Use Plandex Cloud with your own <a href="https://openrouter.ai/" rel="nofollow">OpenRouter.ai</a> and <a href="https://platform.openai.com/" rel="nofollow">OpenAI</a> keys.<br>• <a href="https://app.plandex.ai/start?modelsMode=byo" rel="nofollow">Get started</a></td>
</tr>
<tr>
<td><strong>Self-hosted/Local Mode</strong></td>
<td>• Run Plandex locally with Docker or host on your own server.<br>• Use your own <a href="https://openrouter.ai/" rel="nofollow">OpenRouter.ai</a> and <a href="https://platform.openai.com/" rel="nofollow">OpenAI</a> keys.<br>• Follow the <a href="https://github.com/plandex-ai/plandex/blob/main/hosting/self-hosting.md">local-mode quickstart</a> to get started.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Provider keys&nbsp; 🔑</h2><a id="user-content-provider-keys-" aria-label="Permalink: Provider keys&nbsp; 🔑" href="#provider-keys-"></a></p>
<p dir="auto">If you're going with a 'BYO API Key' option above (whether cloud or self-hosted), you'll need to set the <code>OPENROUTER_API_KEY</code> and <code>OPENAI_API_KEY</code> environment variables before continuing:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENROUTER_API_KEY=...
export OPENAI_API_KEY=..."><pre><span>export</span> OPENROUTER_API_KEY=...
<span>export</span> OPENAI_API_KEY=...</pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">Get started&nbsp; 🚀</h2><a id="user-content-get-started-" aria-label="Permalink: Get started&nbsp; 🚀" href="#get-started-"></a></p>
<p dir="auto">First, <code>cd</code> into a <strong>project directory</strong> where you want to get something done or chat about the project. Make a new directory first with <code>mkdir your-project-dir</code> if you're starting on a new project.</p>

<p dir="auto">For a new project, you might also want to initialize a git repo. Plandex doesn't require that your project is in a git repo, but it does integrate well with git if you use it.</p>

<p dir="auto">Now start the Plandex REPL in your project:</p>

<p dir="auto">or for short:</p>

<p dir="auto">☁️ <em>If you're using Plandex Cloud, you'll be prompted at this point to start a trial.</em></p>
<p dir="auto">Then just give the REPL help text a quick read, and you're ready go. The REPL starts in <em>chat mode</em> by default, which is good for fleshing out ideas before moving to implementation. Once the task is clear, Plandex will prompt you to switch to <em>tell mode</em> to make a detailed plan and start writing code.</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Docs&nbsp; 🛠️</h2><a id="user-content-docs-️" aria-label="Permalink: Docs&nbsp; 🛠️" href="#docs-️"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto"><a href="https://docs.plandex.ai/" rel="nofollow">👉&nbsp;&nbsp;Full documentation.</a></h3><a id="user-content-full-documentation" aria-label="Permalink: 👉&nbsp;&nbsp;Full documentation." href="#full-documentation"></a></p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Discussion and discord &nbsp;💬</h2><a id="user-content-discussion-and-discord-" aria-label="Permalink: Discussion and discord &nbsp;💬" href="#discussion-and-discord-"></a></p>
<p dir="auto">Please feel free to give your feedback, ask questions, report a bug, or just hang out:</p>
<ul dir="auto">
<li><a href="https://discord.gg/plandex-ai" rel="nofollow">Discord</a></li>
<li><a href="https://github.com/plandex-ai/plandex/discussions">Discussions</a></li>
<li><a href="https://github.com/plandex-ai/plandex/issues">Issues</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Follow and subscribe</h2><a id="user-content-follow-and-subscribe" aria-label="Permalink: Follow and subscribe" href="#follow-and-subscribe"></a></p>
<ul dir="auto">
<li><a href="https://x.com/PlandexAI" rel="nofollow">Follow @PlandexAI</a></li>
<li><a href="https://x.com/Danenania" rel="nofollow">Follow @Danenania</a> (Plandex's creator)</li>
<li><a href="https://x.com/PlandexAI" rel="nofollow">Subscribe on YouTube</a></li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Contributors &nbsp;👥</h2><a id="user-content-contributors-" aria-label="Permalink: Contributors &nbsp;👥" href="#contributors-"></a></p>
<p dir="auto">⭐️&nbsp;&nbsp;Please star, fork, explore, and contribute to Plandex. There's a lot of work to do and so much that can be improved.</p>
<p dir="auto"><a href="https://docs.plandex.ai/development" rel="nofollow">Here's an overview on setting up a development environment.</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Man who built ISP instead of paying Comcast expands to hundreds of homes (2022) (501 pts)]]></title>
            <link>https://arstechnica.com/tech-policy/2022/08/man-who-built-isp-instead-of-paying-comcast-50k-expands-to-hundreds-of-homes/</link>
            <guid>43709770</guid>
            <pubDate>Wed, 16 Apr 2025 20:06:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/tech-policy/2022/08/man-who-built-isp-instead-of-paying-comcast-50k-expands-to-hundreds-of-homes/">https://arstechnica.com/tech-policy/2022/08/man-who-built-isp-instead-of-paying-comcast-50k-expands-to-hundreds-of-homes/</a>, See on <a href="https://news.ycombinator.com/item?id=43709770">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<p>Under the contract terms, Mauch will provide 100Mbps symmetrical Internet with unlimited data for $55 a month and 1Gbps with unlimited data for $79 a month. Mauch said his installation fees are typically $199. Unlike many larger ISPs, Mauch provides simple bills that contain a single line item for Internet service and no extra fees.</p>
<p>Mauch also committed to participate in the Federal Communications Commission's <a href="https://arstechnica.com/tech-policy/2022/01/isps-must-accept-govt-subsidy-on-all-plans-no-more-upselling-fcc-chair-says/">Affordable Connectivity Program</a>, which provides subsidies of $30 a month for households that meet income eligibility requirements.</p>
<p>The contract requires all project expenses to be incurred by the end of 2024, and for the project to be completed by the end of 2026. But Mauch aims for a much quicker timeline, telling Ars that his "goal is to build about half of it by the end of this year and the other half by the end of 2023." The exact funding amount is $2,618,958.03.</p>
<h2>Comcast wanted $50K, AT&amp;T offers just 1.5Mbps</h2>
<p>Operating an ISP isn't Mauch's primary job, as he is still a network architect at Akamai. He started planning to build his own network about five years ago after being unable to get modern service from any of the major ISPs.</p>
<p>As we wrote last year, AT&amp;T only offers DSL with download speeds up to 1.5Mbps at his home. He said Comcast once told him it would charge $50,000 to extend its cable network to his house—and that he would have gone with Comcast if they only wanted $10,000. Comcast demands those up-front fees for line extensions when customers are outside its network area, <a href="https://arstechnica.com/tech-policy/2022/06/couple-bought-home-in-seattle-then-learned-comcast-internet-would-cost-27000/">even if the rest of the neighborhood already has Comcast service</a>.</p>
<p>Mauch was using a 50Mbps fixed wireless service before switching over to his own fiber network.&nbsp;In addition to his home Internet customers, Mauch told us he provides free 250Mbps service to a church that was previously having trouble with its Comcast service. Mauch said he also provides fiber backhaul to a couple of cell towers for a major mobile carrier.</p>

<h2>County touts “historic” broadband investment</h2>
<p>Mauch has already hooked up some of the homes on the list of required addresses. Washtenaw County issued a <a href="https://www.washtenaw.org/civicalerts.aspx?aid=2210">press release</a> after the first home was connected in June, touting a "historic broadband infrastructure investment" to "create a path for every household to access high-speed broadband Internet."</p>
<p>The county said it is investing $15 million in broadband projects by combining the federal funds with money from the county's general fund. Between Washtenaw Fiber Properties and the other three ISPs selected by local government officials, "over 3,000 Washtenaw County households will be connected as a result of this investment in the next few years," the press release said.</p>
<p>One of the areas covered by Mauch's funding is around a lake in Freedom Township, where he plans to begin construction on August 22, he said. "Generally speaking, it's a lower income area as well as an area that has been without service for a very long time, aside from cellular or wireless," he said. "The goal is to close the gap on them very quickly."</p>
<p>As for the other three ISPs, the county was <a href="https://muninetworks.org/content/washtenaw-county-approves-15-million-arpa-funds-countywide-broadband">reportedly</a> negotiating with cable giants Comcast and Charter, and Midwest Energy and Communications. Those three companies ended up getting the deals with the county, a contractor working on the overall project confirmed to Ars.</p>
<p>Under <a href="https://www.baller.com/wp-content/uploads/BallerStokesLideStateBarriers7-1-20.pdf">state law</a>, "Municipalities in Michigan are not simply able to decide to build and operate their own networks, they must first issue an RFP for a private provider to come in and build," the Institute for Local Self-Reliance's Community Broadband Networks Initiative <a href="https://muninetworks.org/content/washtenaw-county-takes-another-step-toward-countywide-broadband-equity">wrote</a>. "Only if the RFP receives less than three viable offers can a municipality move forward with building and owning the network. There are also additional requirements that municipalities have to follow, such as holding public forums and submitting cost-benefit analysis and feasibility studies."</p>
<p>The county's <a href="https://imlive.s3.amazonaws.com/Washtenaw%20County/ID227054715951590824298930519180001578145/RFP%20-%208119%20PUBLIC-PRIVATE%20PARTNERSHIP%20FOR%20FILLING%20BROADBAND%20GAPS.pdf">RFP</a> set 25Mbps download and 3Mbps upload speeds as the minimum acceptable tier but stated a strong preference for "at&nbsp;least 100Mbps download speeds, ideally with symmetrical upload speeds, from wireline&nbsp;technology to accommodate present and future bandwidth-hungry applications."</p>
<h2>Mauch faces increasing equipment costs</h2>
<p>Mauch has made some upgrades to his operation. In our previous story, we described how Mauch was renting an air compressor to blow fiber through his conduits. He recently bought an industrial air compressor at a government liquidation auction, spending under $4,000 for equipment that often costs about $20,000, he said. He had previously spent $8,000 on a directional drill machine that installs cables or conduits under driveways and roads without digging giant holes.</p>
<p>Increasing prices have been a problem. Mauch said he used to buy fiber conduit for 32 cents a foot but that he's paying more than double that now. The <a href="https://www.hubbell.com/hubbell/en/Products/Data-Communications/Underground-Construction/Handholes-Vaults/cl/2863332">handholes</a> that are buried underground at various points throughout Mauch's network used to cost $300 and are now about $700, he said.

          
                  </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI Codex CLI: Lightweight coding agent that runs in your terminal (457 pts)]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>43708025</guid>
            <pubDate>Wed, 16 Apr 2025 17:24:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/openai/codex">https://github.com/openai/codex</a>, See on <a href="https://news.ycombinator.com/item?id=43708025">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">OpenAI Codex CLI</h2><a id="user-content-openai-codex-cli" aria-label="Permalink: OpenAI Codex CLI" href="#openai-codex-cli"></a></p>
<p dir="auto">Lightweight coding agent that runs in your terminal</p>
<p dir="auto"><code>npm i -g @openai/codex</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/openai/codex/blob/main/.github/demo.gif"><img src="https://github.com/openai/codex/raw/main/.github/demo.gif" alt="Codex demo GIF using: codex &quot;explain this codebase to me&quot;" data-animated-image=""></a></p>
<hr>
<details>
<summary><strong>Table&nbsp;of&nbsp;Contents</strong></summary>
<ul dir="auto">
<li><a href="#experimental-technology-disclaimer">Experimental Technology Disclaimer</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#whycodex">Why&nbsp;Codex?</a></li>
<li><a href="#securitymodelpermissions">Security&nbsp;Model&nbsp;&amp;&nbsp;Permissions</a>
<ul dir="auto">
<li><a href="#platform-sandboxing-details">Platform sandboxing details</a></li>
</ul>
</li>
<li><a href="#systemrequirements">System&nbsp;Requirements</a></li>
<li><a href="#clireference">CLI&nbsp;Reference</a></li>
<li><a href="#memoryprojectdocs">Memory&nbsp;&amp;&nbsp;Project&nbsp;Docs</a></li>
<li><a href="#noninteractivecimode">Non‑interactive&nbsp;/&nbsp;CI&nbsp;mode</a></li>
<li><a href="#recipes">Recipes</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#faq">FAQ</a></li>
<li><a href="#funding-opportunity">Funding Opportunity</a></li>
<li><a href="#contributing">Contributing</a>
<ul dir="auto">
<li><a href="#development-workflow">Development workflow</a></li>
<li><a href="#writing-highimpact-code-changes">Writing high‑impact code changes</a></li>
<li><a href="#opening-a-pull-request">Opening a pull request</a></li>
<li><a href="#review-process">Review process</a></li>
<li><a href="#community-values">Community values</a></li>
<li><a href="#getting-help">Getting help</a></li>
<li><a href="#contributor-license-agreement-cla">Contributor License Agreement (CLA)</a>
<ul dir="auto">
<li><a href="#quick-fixes">Quick fixes</a></li>
</ul>
</li>
<li><a href="#releasing-codex">Releasing <code>codex</code></a></li>
</ul>
</li>
<li><a href="#securityresponsibleai">Security&nbsp;&amp;&nbsp;Responsible&nbsp;AI</a></li>
<li><a href="#license">License</a></li>
</ul>
</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Experimental Technology Disclaimer</h2><a id="user-content-experimental-technology-disclaimer" aria-label="Permalink: Experimental Technology Disclaimer" href="#experimental-technology-disclaimer"></a></p>
<p dir="auto">Codex CLI is an experimental project under active development. It is not yet stable, may contain bugs, incomplete features, or undergo breaking changes. We’re building it in the open with the community and welcome:</p>
<ul dir="auto">
<li>Bug reports</li>
<li>Feature requests</li>
<li>Pull requests</li>
<li>Good vibes</li>
</ul>
<p dir="auto">Help us improve by filing issues or submitting PRs (see the section below for how to contribute)!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Install globally:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g @openai/codex"><pre>npm install -g @openai/codex</pre></div>
<p dir="auto">Next, set your OpenAI API key as an environment variable:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=&quot;your-api-key-here&quot;"><pre><span>export</span> OPENAI_API_KEY=<span><span>"</span>your-api-key-here<span>"</span></span></pre></div>
<blockquote>
<p dir="auto"><strong>Note:</strong> This command sets the key only for your current terminal session. To make it permanent, add the <code>export</code> line to your shell's configuration file (e.g., <code>~/.zshrc</code>).</p>
</blockquote>
<p dir="auto">Run interactively:</p>

<p dir="auto">Or, run with a prompt as input (and optionally in <code>Full Auto</code> mode):</p>
<div dir="auto" data-snippet-clipboard-copy-content="codex &quot;explain this codebase to me&quot;"><pre>codex <span><span>"</span>explain this codebase to me<span>"</span></span></pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="codex --approval-mode full-auto &quot;create the fanciest todo-list app&quot;"><pre>codex --approval-mode full-auto <span><span>"</span>create the fanciest todo-list app<span>"</span></span></pre></div>
<p dir="auto">That’s it – Codex will scaffold a file, run it inside a sandbox, install any
missing dependencies, and show you the live result. Approve the changes and
they’ll be committed to your working directory.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Why&nbsp;Codex?</h2><a id="user-content-whycodex" aria-label="Permalink: Why&nbsp;Codex?" href="#whycodex"></a></p>
<p dir="auto">Codex CLI is built for developers who already <strong>live in the terminal</strong> and want
ChatGPT‑level reasoning <strong>plus</strong> the power to actually run code, manipulate
files, and iterate – all under version control. In short, it’s <em>chat‑driven
development</em> that understands and executes your repo.</p>
<ul dir="auto">
<li><strong>Zero setup</strong> — bring your OpenAI API key and it just works!</li>
<li><strong>Full auto-approval, while safe + secure</strong> by running network-disabled and directory-sandboxed</li>
<li><strong>Multimodal</strong> — pass in screenshots or diagrams to implement features ✨</li>
</ul>
<p dir="auto">And it's <strong>fully open-source</strong> so you can see and contribute to how it develops!</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security&nbsp;Model&nbsp;&amp;&nbsp;Permissions</h2><a id="user-content-securitymodelpermissions" aria-label="Permalink: Security&nbsp;Model&nbsp;&amp;&nbsp;Permissions" href="#securitymodelpermissions"></a></p>
<p dir="auto">Codex lets you decide <em>how much autonomy</em> the agent receives and auto-approval policy via the
<code>--approval-mode</code> flag (or the interactive onboarding prompt):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Mode</th>
<th>What the agent may do without asking</th>
<th>Still requires approval</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Suggest</strong> <br>(default)</td>
<td>• Read any file in the repo</td>
<td>• <strong>All</strong> file writes/patches <br>• <strong>All</strong> shell/Bash commands</td>
</tr>
<tr>
<td><strong>Auto&nbsp;Edit</strong></td>
<td>• Read <strong>and</strong> apply‑patch writes to files</td>
<td>• <strong>All</strong> shell/Bash commands</td>
</tr>
<tr>
<td><strong>Full&nbsp;Auto</strong></td>
<td>• Read/write files <br>• Execute shell commands</td>
<td>–</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">In <strong>Full&nbsp;Auto</strong> every command is run <strong>network‑disabled</strong> and confined to the
current working directory (plus temporary files) for defense‑in‑depth. Codex
will also show a warning/confirmation if you start in <strong>auto‑edit</strong> or
<strong>full‑auto</strong> while the directory is <em>not</em> tracked by Git, so you always have a
safety net.</p>
<p dir="auto">Coming soon: you’ll be able to whitelist specific commands to auto‑execute with
the network enabled, once we’re confident in additional safeguards.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Platform sandboxing details</h3><a id="user-content-platform-sandboxing-details" aria-label="Permalink: Platform sandboxing details" href="#platform-sandboxing-details"></a></p>
<p dir="auto">The hardening mechanism Codex uses depends on your OS:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>macOS&nbsp;12+</strong> – commands are wrapped with <strong>Apple&nbsp;Seatbelt</strong> (<code>sandbox-exec</code>).</p>
<ul dir="auto">
<li>Everything is placed in a read‑only jail except for a small set of
writable roots (<code>$PWD</code>, <code>$TMPDIR</code>, <code>~/.codex</code>, etc.).</li>
<li>Outbound network is <em>fully blocked</em> by default – even if a child process
tries to <code>curl</code> somewhere it will fail.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Linux</strong> – we recommend using Docker for sandboxing, where Codex launches itself inside a <strong>minimal
container image</strong> and mounts your repo <em>read/write</em> at the same path. A
custom <code>iptables</code>/<code>ipset</code> firewall script denies all egress except the
OpenAI API. This gives you deterministic, reproducible runs without needing
root on the host. You can read more in <a href="https://github.com/openai/codex/blob/main/codex-cli/scripts/run_in_container.sh"><code>run_in_container.sh</code></a></p>
</li>
</ul>
<p dir="auto">Both approaches are <em>transparent</em> to everyday usage – you still run <code>codex</code> from your repo root and approve/reject steps as usual.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">System&nbsp;Requirements</h2><a id="user-content-systemrequirements" aria-label="Permalink: System&nbsp;Requirements" href="#systemrequirements"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Requirement</th>
<th>Details</th>
</tr>
</thead>
<tbody>
<tr>
<td>Operating systems</td>
<td>macOS&nbsp;12+, Ubuntu&nbsp;20.04+/Debian&nbsp;10+, or Windows&nbsp;11 <strong>via&nbsp;WSL2</strong></td>
</tr>
<tr>
<td>Node.js</td>
<td><strong>22 or newer</strong> (LTS recommended)</td>
</tr>
<tr>
<td>Git (optional, recommended)</td>
<td>2.23+ for built‑in PR helpers</td>
</tr>
<tr>
<td>RAM</td>
<td>4‑GB minimum (8‑GB&nbsp;recommended)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<blockquote>
<p dir="auto">Never run <code>sudo npm install -g</code>; fix npm permissions instead.</p>
</blockquote>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI&nbsp;Reference</h2><a id="user-content-clireference" aria-label="Permalink: CLI&nbsp;Reference" href="#clireference"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Command</th>
<th>Purpose</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>codex</code></td>
<td>Interactive REPL</td>
<td><code>codex</code></td>
</tr>
<tr>
<td><code>codex "…"</code></td>
<td>Initial prompt for interactive REPL</td>
<td><code>codex "fix lint errors"</code></td>
</tr>
<tr>
<td><code>codex -q "…"</code></td>
<td>Non‑interactive "quiet mode"</td>
<td><code>codex -q --json "explain utils.ts"</code></td>
</tr>
<tr>
<td><code>codex completion &lt;bash|zsh|fish&gt;</code></td>
<td>Print shell completion script</td>
<td><code>codex completion bash</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Key flags: <code>--model/-m</code>, <code>--approval-mode/-a</code>, and <code>--quiet/-q</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory&nbsp;&amp;&nbsp;Project&nbsp;Docs</h2><a id="user-content-memoryprojectdocs" aria-label="Permalink: Memory&nbsp;&amp;&nbsp;Project&nbsp;Docs" href="#memoryprojectdocs"></a></p>
<p dir="auto">Codex merges Markdown instructions in this order:</p>
<ol dir="auto">
<li><code>~/.codex/instructions.md</code> – personal global guidance</li>
<li><code>codex.md</code> at repo root – shared project notes</li>
<li><code>codex.md</code> in cwd – sub‑package specifics</li>
</ol>
<p dir="auto">Disable with <code>--no-project-doc</code> or <code>CODEX_DISABLE_PROJECT_DOC=1</code>.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Non‑interactive&nbsp;/&nbsp;CI&nbsp;mode</h2><a id="user-content-noninteractivecimode" aria-label="Permalink: Non‑interactive&nbsp;/&nbsp;CI&nbsp;mode" href="#noninteractivecimode"></a></p>
<p dir="auto">Run Codex head‑less in pipelines. Example GitHub Action step:</p>
<div dir="auto" data-snippet-clipboard-copy-content="- name: Update changelog via Codex
  run: |
    npm install -g @openai/codex
    export OPENAI_API_KEY=&quot;${{ secrets.OPENAI_KEY }}&quot;
    codex -a auto-edit --quiet &quot;update CHANGELOG for next release&quot;"><pre>- <span>name</span>: <span>Update changelog via Codex</span>
  <span>run</span>: <span>|</span>
<span>    npm install -g @openai/codex</span>
<span>    export OPENAI_API_KEY="${{ secrets.OPENAI_KEY }}"</span>
<span>    codex -a auto-edit --quiet "update CHANGELOG for next release"</span></pre></div>
<p dir="auto">Set <code>CODEX_QUIET_MODE=1</code> to silence interactive UI noise.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Recipes</h2><a id="user-content-recipes" aria-label="Permalink: Recipes" href="#recipes"></a></p>
<p dir="auto">Below are a few bite‑size examples you can copy‑paste. Replace the text in quotes with your own task. See the <a href="https://github.com/openai/codex/blob/main/codex-cli/examples/prompting_guide.md">prompting guide</a> for more tips and usage patterns.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>✨</th>
<th>What you type</th>
<th>What happens</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><code>codex "Refactor the Dashboard component to React&nbsp;Hooks"</code></td>
<td>Codex rewrites the class component, runs <code>npm test</code>, and shows the diff.</td>
</tr>
<tr>
<td>2</td>
<td><code>codex "Generate SQL migrations for adding a users table"</code></td>
<td>Infers your ORM, creates migration files, and runs them in a sandboxed DB.</td>
</tr>
<tr>
<td>3</td>
<td><code>codex "Write unit tests for utils/date.ts"</code></td>
<td>Generates tests, executes them, and iterates until they pass.</td>
</tr>
<tr>
<td>4</td>
<td><code>codex "Bulk‑rename *.jpeg → *.jpg with git mv"</code></td>
<td>Safely renames files and updates imports/usages.</td>
</tr>
<tr>
<td>5</td>
<td><code>codex "Explain what this regex does: ^(?=.*[A-Z]).{8,}$"</code></td>
<td>Outputs a step‑by‑step human explanation.</td>
</tr>
<tr>
<td>6</td>
<td><code>codex "Carefully review this repo, and propose 3 high impact well-scoped PRs"</code></td>
<td>Suggests impactful PRs in the current codebase.</td>
</tr>
<tr>
<td>7</td>
<td><code>codex "Look for vulnerabilities and create a security review report"</code></td>
<td>Finds and explains security bugs.</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<details open="">
<summary><strong>From&nbsp;npm&nbsp;(Recommended)</strong></summary>
<div dir="auto" data-snippet-clipboard-copy-content="npm install -g @openai/codex
# or
yarn global add @openai/codex"><pre>npm install -g @openai/codex
<span><span>#</span> or</span>
yarn global add @openai/codex</pre></div>
</details>
<details>
<summary><strong>Build&nbsp;from&nbsp;source</strong></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository and navigate to the CLI package
git clone https://github.com/openai/codex.git
cd codex/codex-cli

# Install dependencies and build
npm install
npm run build

# Get the usage and the options
node ./dist/cli.js --help

# Run the locally‑built CLI directly
node ./dist/cli.js

# Or link the command globally for convenience
npm link"><pre><span><span>#</span> Clone the repository and navigate to the CLI package</span>
git clone https://github.com/openai/codex.git
<span>cd</span> codex/codex-cli

<span><span>#</span> Install dependencies and build</span>
npm install
npm run build

<span><span>#</span> Get the usage and the options</span>
node ./dist/cli.js --help

<span><span>#</span> Run the locally‑built CLI directly</span>
node ./dist/cli.js

<span><span>#</span> Or link the command globally for convenience</span>
npm link</pre></div>
</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto">Codex looks for config files in <strong><code>~/.codex/</code></strong>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ~/.codex/config.yaml
model: o4-mini # Default model
fullAutoErrorMode: ask-user # or ignore-and-continue"><pre><span><span>#</span> ~/.codex/config.yaml</span>
<span>model</span>: <span>o4-mini </span><span><span>#</span> Default model</span>
<span>fullAutoErrorMode</span>: <span>ask-user </span><span><span>#</span> or ignore-and-continue</span></pre></div>
<p dir="auto">You can also define custom instructions:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# ~/.codex/instructions.md
- Always respond with emojis
- Only use git commands if I explicitly mention you should"><pre><span><span>#</span> ~/.codex/instructions.md</span>
- <span>Always respond with emojis</span>
- <span>Only use git commands if I explicitly mention you should</span></pre></div>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<details>
<summary>OpenAI released a model called Codex in 2021 - is this related?</summary>
<p dir="auto">In 2021, OpenAI released Codex, an AI system designed to generate code from natural language prompts. That original Codex model was deprecated as of March 2023 and is separate from the CLI tool.</p>
</details>
<details>
<summary>How do I stop Codex from touching my repo?</summary>
<p dir="auto">Codex always runs in a <strong>sandbox first</strong>. If a proposed command or file change looks suspicious you can simply answer <strong>n</strong> when prompted and nothing happens to your working tree.</p>
</details>
<details>
<summary>Does it work on Windows?</summary>
<p dir="auto">Not directly. It requires <a href="https://learn.microsoft.com/en-us/windows/wsl/install" rel="nofollow">Windows Subsystem for Linux (WSL2)</a> – Codex has been tested on macOS and Linux with Node&nbsp;≥&nbsp;22.</p>
</details>
<details>
<summary>Which models are supported?</summary>
<p dir="auto">Any model available with <a href="https://platform.openai.com/docs/api-reference/responses" rel="nofollow">Responses API</a>. The default is <code>o4-mini</code>, but pass <code>--model gpt-4o</code> or set <code>model: gpt-4o</code> in your config file to override.</p>
</details>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Funding Opportunity</h2><a id="user-content-funding-opportunity" aria-label="Permalink: Funding Opportunity" href="#funding-opportunity"></a></p>
<p dir="auto">We’re excited to launch a <strong>$1&nbsp;million initiative</strong> supporting open source projects that use Codex&nbsp;CLI and other OpenAI models.</p>
<ul dir="auto">
<li>Grants are awarded in <strong>$25,000</strong> API credit increments.</li>
<li>Applications are reviewed <strong>on a rolling basis</strong>.</li>
</ul>
<p dir="auto"><strong>Interested?&nbsp;<a href="https://openai.com/form/codex-open-source-fund/" rel="nofollow">Apply here</a>.</strong></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">This project is under active development and the code will likely change pretty significantly. We'll update this message once that's complete!</p>
<p dir="auto">More broadly we welcome contributions – whether you are opening your very first pull request or you’re a seasoned maintainer. At the same time we care about reliability and long‑term maintainability, so the bar for merging code is intentionally <strong>high</strong>. The guidelines below spell out what “high‑quality” means in practice and should make the whole process transparent and friendly.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Development workflow</h3><a id="user-content-development-workflow" aria-label="Permalink: Development workflow" href="#development-workflow"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Create a <em>topic branch</em> from <code>main</code> – e.g. <code>feat/interactive-prompt</code>.</p>
</li>
<li>
<p dir="auto">Keep your changes focused. Multiple unrelated fixes should be opened as separate PRs.</p>
</li>
<li>
<p dir="auto">Use <code>npm run test:watch</code> during development for super‑fast feedback.</p>
</li>
<li>
<p dir="auto">We use <strong>Vitest</strong> for unit tests, <strong>ESLint</strong> + <strong>Prettier</strong> for style, and <strong>TypeScript</strong> for type‑checking.</p>
</li>
<li>
<p dir="auto">Before pushing, run the full test/type/lint suite:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm test &amp;&amp; npm run lint &amp;&amp; npm run typecheck"><pre>npm <span>test</span> <span>&amp;&amp;</span> npm run lint <span>&amp;&amp;</span> npm run typecheck</pre></div>
</li>
<li>
<p dir="auto">If you have <strong>not</strong> yet signed the Contributor License Agreement (CLA), add a PR comment containing the exact text</p>
<div data-snippet-clipboard-copy-content="I have read the CLA Document and I hereby sign the CLA"><pre lang="text"><code>I have read the CLA Document and I hereby sign the CLA
</code></pre></div>
<p dir="auto">The CLA‑Assistant bot will turn the PR status green once all authors have signed.</p>
</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="#&nbsp;Watch mode (tests rerun on change)
npm run test:watch

#&nbsp;Type‑check without emitting files
npm run typecheck

#&nbsp;Automatically fix lint + prettier issues
npm run lint:fix
npm run format:fix"><pre><span><span>#</span>&nbsp;Watch mode (tests rerun on change)</span>
npm run test:watch

<span><span>#</span>&nbsp;Type‑check without emitting files</span>
npm run typecheck

<span><span>#</span>&nbsp;Automatically fix lint + prettier issues</span>
npm run lint:fix
npm run format:fix</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Writing high‑impact code changes</h3><a id="user-content-writing-highimpact-code-changes" aria-label="Permalink: Writing high‑impact code changes" href="#writing-highimpact-code-changes"></a></p>
<ol dir="auto">
<li><strong>Start with an issue.</strong> Open a new one or comment on an existing discussion so we can agree on the solution before code is written.</li>
<li><strong>Add or update tests.</strong> Every new feature or bug‑fix should come with test coverage that fails before your change and passes afterwards. 100&nbsp;% coverage is not required, but aim for meaningful assertions.</li>
<li><strong>Document behaviour.</strong> If your change affects user‑facing behaviour, update the README, inline help (<code>codex --help</code>), or relevant example projects.</li>
<li><strong>Keep commits atomic.</strong> Each commit should compile and the tests should pass. This makes reviews and potential rollbacks easier.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Opening a pull request</h3><a id="user-content-opening-a-pull-request" aria-label="Permalink: Opening a pull request" href="#opening-a-pull-request"></a></p>
<ul dir="auto">
<li>Fill in the PR template (or include similar information) – <strong>What? Why? How?</strong></li>
<li>Run <strong>all</strong> checks locally (<code>npm test &amp;&amp; npm run lint &amp;&amp; npm run typecheck</code>). CI failures that could have been caught locally slow down the process.</li>
<li>Make sure your branch is up‑to‑date with <code>main</code> and that you have resolved merge conflicts.</li>
<li>Mark the PR as <strong>Ready for review</strong> only when you believe it is in a merge‑able state.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Review process</h3><a id="user-content-review-process" aria-label="Permalink: Review process" href="#review-process"></a></p>
<ol dir="auto">
<li>One maintainer will be assigned as a primary reviewer.</li>
<li>We may ask for changes – please do not take this personally. We value the work, we just also value consistency and long‑term maintainability.</li>
<li>When there is consensus that the PR meets the bar, a maintainer will squash‑and‑merge.</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Community values</h3><a id="user-content-community-values" aria-label="Permalink: Community values" href="#community-values"></a></p>
<ul dir="auto">
<li><strong>Be kind and inclusive.</strong> Treat others with respect; we follow the <a href="https://www.contributor-covenant.org/" rel="nofollow">Contributor Covenant</a>.</li>
<li><strong>Assume good intent.</strong> Written communication is hard – err on the side of generosity.</li>
<li><strong>Teach &amp; learn.</strong> If you spot something confusing, open an issue or PR with improvements.</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Getting help</h3><a id="user-content-getting-help" aria-label="Permalink: Getting help" href="#getting-help"></a></p>
<p dir="auto">If you run into problems setting up the project, would like feedback on an idea, or just want to say <em>hi</em> – please open a Discussion or jump into the relevant issue. We are happy to help.</p>
<p dir="auto">Together we can make Codex CLI an incredible tool. <strong>Happy hacking!</strong> 🚀</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributor License Agreement (CLA)</h3><a id="user-content-contributor-license-agreement-cla" aria-label="Permalink: Contributor License Agreement (CLA)" href="#contributor-license-agreement-cla"></a></p>
<p dir="auto">All contributors <strong>must</strong> accept the CLA. The process is lightweight:</p>
<ol dir="auto">
<li>
<p dir="auto">Open your pull request.</p>
</li>
<li>
<p dir="auto">Paste the following comment (or reply <code>recheck</code> if you’ve signed before):</p>
<div data-snippet-clipboard-copy-content="I have read the CLA Document and I hereby sign the CLA"><pre lang="text"><code>I have read the CLA Document and I hereby sign the CLA
</code></pre></div>
</li>
<li>
<p dir="auto">The CLA‑Assistant bot records your signature in the repo and marks the status check as passed.</p>
</li>
</ol>
<p dir="auto">No special Git commands, email attachments, or commit footers required.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Quick fixes</h4><a id="user-content-quick-fixes" aria-label="Permalink: Quick fixes" href="#quick-fixes"></a></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scenario</th>
<th>Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Amend last commit</td>
<td><code>git commit --amend -s --no-edit &amp;&amp; git push -f</code></td>
</tr>
<tr>
<td>GitHub UI only</td>
<td>Edit the commit message in the PR → add<br><code>Signed-off-by: Your Name &lt;email@example.com&gt;</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The <strong>DCO check</strong> blocks merges until every commit in the PR carries the footer (with squash this is just the one).</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Releasing <code>codex</code></h3><a id="user-content-releasing-codex" aria-label="Permalink: Releasing codex" href="#releasing-codex"></a></p>
<p dir="auto">To publish a new version of the CLI, run the release scripts defined in <code>codex-cli/package.json</code>:</p>
<ol dir="auto">
<li>Open the <code>codex-cli</code> directory</li>
<li>Make sure you're on a branch like <code>git checkout -b bump-version</code></li>
<li>Bump the version and <code>CLI_VERSION</code> to current datetime: <code>npm run release:version</code></li>
<li>Commit the version bump (with DCO sign-off):
<div dir="auto" data-snippet-clipboard-copy-content="git add codex-cli/src/utils/session.ts codex-cli/package.json
git commit -s -m &quot;chore(release): codex-cli v$(node -p \&quot;require('./codex-cli/package.json').version\&quot;)&quot;"><pre>git add codex-cli/src/utils/session.ts codex-cli/package.json
git commit -s -m <span><span>"</span>chore(release): codex-cli v<span><span>$(</span>node -p <span>\"</span>require(<span><span>'</span>./codex-cli/package.json<span>'</span></span>).version<span>\"</span><span>)</span></span><span>"</span></span></pre></div>
</li>
<li>Copy README, build, and publish to npm: <code>npm run release</code></li>
<li>Push to branch: <code>git push origin HEAD</code></li>
</ol>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security&nbsp;&amp;&nbsp;Responsible&nbsp;AI</h2><a id="user-content-securityresponsibleai" aria-label="Permalink: Security&nbsp;&amp;&nbsp;Responsible&nbsp;AI" href="#securityresponsibleai"></a></p>
<p dir="auto">Have you discovered a vulnerability or have concerns about model output? Please e‑mail <strong><a href="mailto:security@openai.com">security@openai.com</a></strong> and we will respond promptly.</p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This repository is licensed under the <a href="https://github.com/openai/codex/blob/main/LICENSE">Apache-2.0&nbsp;License</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kaggle and the Wikimedia Foundation are partnering on open data (130 pts)]]></title>
            <link>https://blog.google/technology/developers/kaggle-wikimedia/</link>
            <guid>43707768</guid>
            <pubDate>Wed, 16 Apr 2025 17:05:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/technology/developers/kaggle-wikimedia/">https://blog.google/technology/developers/kaggle-wikimedia/</a>, See on <a href="https://news.ycombinator.com/item?id=43707768">Hacker News</a></p>
<div id="readability-page-1" class="page"><div slot="uni-short-post-description-slot"><p data-block-key="agxeu">Kaggle is hosting <a href="https://enterprise.wikimedia.com/">Wikimedia Enterprise</a>'s beta release of structured data in both French and English. <a href="http://kaggle.com/">Kaggle</a> is home to a vast trove of open and accessible data, with more than 461,000 freely accessible datasets. Researchers, students and machine learning practitioners use this data to explore, train, learn and compete in Kaggle competitions.</p><p data-block-key="f7ivk">The Wikimedia Foundation is the organization that manages the data from <a href="https://www.wikipedia.org/">wikipedia.org</a>, the internet’s free encyclopedia. This data documents and describes the world in real time, with a foundational commitment to open access to data and information.</p><p data-block-key="14dkd">Wikipedia’s structured dataset, <a href="https://enterprise.wikimedia.com/blog/kaggle-dataset/">hosted on Kaggle</a>, is formatted specifically for machine learning, making it ideal for data science, training and development. This collaboration helps researchers and developers have confidence in the quality and provenance of the data.</p><p data-block-key="86a26">We’re excited to see what people build.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI o3 and o4-mini (509 pts)]]></title>
            <link>https://openai.com/index/introducing-o3-and-o4-mini/</link>
            <guid>43707719</guid>
            <pubDate>Wed, 16 Apr 2025 17:01:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-o3-and-o4-mini/">https://openai.com/index/introducing-o3-and-o4-mini/</a>, See on <a href="https://news.ycombinator.com/item?id=43707719">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-o3-and-o4-mini/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Damn Vulnerable MCP Server (205 pts)]]></title>
            <link>https://github.com/harishsg993010/damn-vulnerable-MCP-server</link>
            <guid>43707021</guid>
            <pubDate>Wed, 16 Apr 2025 16:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/harishsg993010/damn-vulnerable-MCP-server">https://github.com/harishsg993010/damn-vulnerable-MCP-server</a>, See on <a href="https://news.ycombinator.com/item?id=43707021">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Damn Vulnerable Model Context Protocol (DVMCP)</h2><a id="user-content-damn-vulnerable-model-context-protocol-dvmcp" aria-label="Permalink: Damn Vulnerable Model Context Protocol (DVMCP)" href="#damn-vulnerable-model-context-protocol-dvmcp"></a></p>
<p dir="auto">A deliberately vulnerable implementation of the Model Context Protocol (MCP) for educational purposes.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">The Damn Vulnerable Model Context Protocol (DVMCP) is an educational project designed to demonstrate security vulnerabilities in MCP implementations. It contains 10 challenges of increasing difficulty that showcase different types of vulnerabilities and attack vectors.</p>
<p dir="auto">This project is intended for security researchers, developers, and AI safety professionals to learn about potential security issues in MCP implementations and how to mitigate them.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">What is MCP?</h2><a id="user-content-what-is-mcp" aria-label="Permalink: What is MCP?" href="#what-is-mcp"></a></p>
<p dir="auto">The <a href="https://modelcontextprotocol.io/" rel="nofollow">Model Context Protocol (MCP)</a> is a standardized protocol that allows applications to provide context for Large Language Models (LLMs) in a structured way. It separates the concerns of providing context from the actual LLM interaction, enabling applications to expose resources, tools, and prompts to LLMs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Recommended MCP Clients</h2><a id="user-content-recommended-mcp-clients" aria-label="Permalink: Recommended MCP Clients" href="#recommended-mcp-clients"></a></p>
<p dir="auto">CLINE - VSCode Extension
refer this <a href="https://docs.cline.bot/mcp-servers/connecting-to-a-remote-server" rel="nofollow">https://docs.cline.bot/mcp-servers/connecting-to-a-remote-server</a> for connecting CLine with MCP server</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">getting started</h2><a id="user-content-getting-started" aria-label="Permalink: getting started" href="#getting-started"></a></p>
<div data-snippet-clipboard-copy-content="once you have cloned the repository, run the following commands:

docker build -t dvmcp .
docker run -p 9001-9010:9001-9010 dvmcp"><pre><code>once you have cloned the repository, run the following commands:

docker build -t dvmcp .
docker run -p 9001-9010:9001-9010 dvmcp
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Security Risks</h2><a id="user-content-security-risks" aria-label="Permalink: Security Risks" href="#security-risks"></a></p>
<p dir="auto">While MCP provides many benefits, it also introduces new security considerations. This project demonstrates various vulnerabilities that can occur in MCP implementations, including:</p>
<ol dir="auto">
<li><strong>Prompt Injection</strong>: Manipulating LLM behavior through malicious inputs</li>
<li><strong>Tool Poisoning</strong>: Hiding malicious instructions in tool descriptions</li>
<li><strong>Excessive Permissions</strong>: Exploiting overly permissive tool access</li>
<li><strong>Rug Pull Attacks</strong>: Exploiting tool definition mutations</li>
<li><strong>Tool Shadowing</strong>: Overriding legitimate tools with malicious ones</li>
<li><strong>Indirect Prompt Injection</strong>: Injecting instructions through data sources</li>
<li><strong>Token Theft</strong>: Exploiting insecure token storage</li>
<li><strong>Malicious Code Execution</strong>: Executing arbitrary code through vulnerable tools</li>
<li><strong>Remote Access Control</strong>: Gaining unauthorized system access</li>
<li><strong>Multi-Vector Attacks</strong>: Combining multiple vulnerabilities</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Project Structure</h2><a id="user-content-project-structure" aria-label="Permalink: Project Structure" href="#project-structure"></a></p>
<div data-snippet-clipboard-copy-content="damn-vulnerable-mcs/
├── README.md                 # Project overview
├── requirements.txt          # Python dependencies
├── challenges/               # Challenge implementations
│   ├── easy/                 # Easy difficulty challenges (1-3)
│   │   ├── challenge1/       # Basic Prompt Injection
│   │   ├── challenge2/       # Tool Poisoning
│   │   └── challenge3/       # Excessive Permission Scope
│   ├── medium/               # Medium difficulty challenges (4-7)
│   │   ├── challenge4/       # Rug Pull Attack
│   │   ├── challenge5/       # Tool Shadowing
│   │   ├── challenge6/       # Indirect Prompt Injection
│   │   └── challenge7/       # Token Theft
│   └── hard/                 # Hard difficulty challenges (8-10)
│       ├── challenge8/       # Malicious Code Execution
│       ├── challenge9/       # Remote Access Control
│       └── challenge10/      # Multi-Vector Attack
├── docs/                     # Documentation
│   ├── setup.md              # Setup instructions
│   ├── challenges.md         # Challenge descriptions
│   └── mcp_overview.md       # MCP protocol overview
├── solutions/                # Solution guides
└── common/                   # Shared code and utilities"><pre><code>damn-vulnerable-mcs/
├── README.md                 # Project overview
├── requirements.txt          # Python dependencies
├── challenges/               # Challenge implementations
│   ├── easy/                 # Easy difficulty challenges (1-3)
│   │   ├── challenge1/       # Basic Prompt Injection
│   │   ├── challenge2/       # Tool Poisoning
│   │   └── challenge3/       # Excessive Permission Scope
│   ├── medium/               # Medium difficulty challenges (4-7)
│   │   ├── challenge4/       # Rug Pull Attack
│   │   ├── challenge5/       # Tool Shadowing
│   │   ├── challenge6/       # Indirect Prompt Injection
│   │   └── challenge7/       # Token Theft
│   └── hard/                 # Hard difficulty challenges (8-10)
│       ├── challenge8/       # Malicious Code Execution
│       ├── challenge9/       # Remote Access Control
│       └── challenge10/      # Multi-Vector Attack
├── docs/                     # Documentation
│   ├── setup.md              # Setup instructions
│   ├── challenges.md         # Challenge descriptions
│   └── mcp_overview.md       # MCP protocol overview
├── solutions/                # Solution guides
└── common/                   # Shared code and utilities
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started-1" aria-label="Permalink: Getting Started" href="#getting-started-1"></a></p>
<p dir="auto">See the <a href="https://github.com/harishsg993010/damn-vulnerable-MCP-server/blob/main/docs/setup.md">Setup Guide</a> for detailed instructions on how to install and run the challenges.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Challenges</h2><a id="user-content-challenges" aria-label="Permalink: Challenges" href="#challenges"></a></p>
<p dir="auto">The project includes 10 challenges across three difficulty levels:</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Easy Challenges</h3><a id="user-content-easy-challenges" aria-label="Permalink: Easy Challenges" href="#easy-challenges"></a></p>
<ol dir="auto">
<li><strong>Basic Prompt Injection</strong>: Exploit unsanitized user input to manipulate LLM behavior</li>
<li><strong>Tool Poisoning</strong>: Exploit hidden instructions in tool descriptions</li>
<li><strong>Excessive Permission Scope</strong>: Exploit overly permissive tools to access unauthorized resources</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Medium Challenges</h3><a id="user-content-medium-challenges" aria-label="Permalink: Medium Challenges" href="#medium-challenges"></a></p>
<ol start="4" dir="auto">
<li><strong>Rug Pull Attack</strong>: Exploit tools that change their behavior after installation</li>
<li><strong>Tool Shadowing</strong>: Exploit tool name conflicts to override legitimate tools</li>
<li><strong>Indirect Prompt Injection</strong>: Inject malicious instructions through data sources</li>
<li><strong>Token Theft</strong>: Extract authentication tokens from insecure storage</li>
</ol>
<p dir="auto"><h3 tabindex="-1" dir="auto">Hard Challenges</h3><a id="user-content-hard-challenges" aria-label="Permalink: Hard Challenges" href="#hard-challenges"></a></p>
<ol start="8" dir="auto">
<li><strong>Malicious Code Execution</strong>: Execute arbitrary code through vulnerable tools</li>
<li><strong>Remote Access Control</strong>: Gain remote access to the system through command injection</li>
<li><strong>Multi-Vector Attack</strong>: Chain multiple vulnerabilities for a sophisticated attack</li>
</ol>
<p dir="auto">See the <a href="https://github.com/harishsg993010/damn-vulnerable-MCP-server/blob/main/docs/challenges.md">Challenges Guide</a> for detailed descriptions of each challenge.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Solutions</h2><a id="user-content-solutions" aria-label="Permalink: Solutions" href="#solutions"></a></p>
<p dir="auto">Solution guides are provided for educational purposes. It's recommended to attempt the challenges on your own before consulting the solutions.</p>
<p dir="auto">See the <a href="https://github.com/harishsg993010/damn-vulnerable-MCP-server/blob/main/solutions/README.md">Solutions Guide</a> for detailed solutions to each challenge.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This project is for educational purposes only. The vulnerabilities demonstrated in this project should never be implemented in production systems. Always follow security best practices when implementing MCP servers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">This project is licensed under the MIT License - see the LICENSE file for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Author</h2><a id="user-content-author" aria-label="Permalink: Author" href="#author"></a></p>
<p dir="auto">This project is created by Harish Santhanalakshmi Ganesan using cursor IDE and Manus AI.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Attention K-Mart Shoppers (318 pts)]]></title>
            <link>https://archive.org/details/attentionkmartshoppers</link>
            <guid>43706706</guid>
            <pubDate>Wed, 16 Apr 2025 15:30:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://archive.org/details/attentionkmartshoppers">https://archive.org/details/attentionkmartshoppers</a>, See on <a href="https://news.ycombinator.com/item?id=43706706">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Darwin's children drew all over the "On the Origin of Species" manuscript (2014) (439 pts)]]></title>
            <link>https://theappendix.net/posts/2014/02/darwins-children-drew-vegetable-battles-on-the-origin-of-species</link>
            <guid>43706037</guid>
            <pubDate>Wed, 16 Apr 2025 14:28:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theappendix.net/posts/2014/02/darwins-children-drew-vegetable-battles-on-the-origin-of-species">https://theappendix.net/posts/2014/02/darwins-children-drew-vegetable-battles-on-the-origin-of-species</a>, See on <a href="https://news.ycombinator.com/item?id=43706037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>Yesterday was Darwin Day, marking the 205th anniversary of the great naturalist’s birth on February 12, 1809. One of the great things about Darwin is that a huge amount of his work is digitized and freely available via sites like <a href="http://darwin-online.org.uk/">Darwin Online</a>.</p>

<p>Interested browsers can also check out the <a href="http://darwin.amnh.org/browse.php?mode=uc&amp;id=72001">Darwin Manuscripts Project</a>, a collaborative initiative based at the American Museum of Natural History. Here you can read through Darwin’s personal notes, including gems like his <a href="http://darwin.amnh.org/viewer.php?eid=15156&amp;mode=clean">scratched out book title ideas</a>. There are also a number of nature drawings that Darwin prepared while writing his masterpiece, <em>On the Origin of Species by Means of Natural Selection</em> (1859). Here, for example, is Darwin’s rather skillful drawing of the stamen of a <em>Strelitizia</em> flower:</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/76763_-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/76763_-medium.jpg" width="640" alt="puck">
  </a></p><p>
    <span>
      Cambridge University Library DAR 49: 115r
    </span>
  </p>
</div>

<p>But there are other drawings in Darwin’s papers that defy explanation - until we remember that Darwin and his wife Emma (who, famously, was also his cousin) had a huge family of ten children. Scholars believe that a young Francis Darwin, the naturalist’s third oldest son, drew this on the back of Darwin’s manuscript for <em>On the Origin of Species</em>.</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/DArwin1-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/DArwin1-medium.jpg" width="640" alt="puck">
  </a></p><p>
    “The Battle of the Fruit and Vegetable Soldiers”
    <span>
      Cambridge University Library
    </span>
  </p>
</div>

<p>Remarkably, this is one of only twenty-eight pages of the manuscript that still exist. The Cambridge University Library has given it the descriptive name “The Battle of the Fruit and Vegetable Soldiers,” and so indeed it seems to be. As near as I can make out, it shows a turbaned soldier mounted on a blueberry squaring off with an English dragoon on a carrot-steed. Perhaps inspired by the 1839-1842 Anglo-Afghan War, and filtered through the Darwin household’s fascination with plants and gardening?</p>

<p>Here’s another drawing from the talented Darwin children, this one seemingly directly inspired by their father’s work. Birds are in the act of catching a spider and a gnat or bee, while flowers and a butterfly appear in remarkable detail. Clearly the family had a knack for acute observations of nature (in fact young Francis ended up becoming a naturalist as well).</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/Darwin2-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/Darwin2-medium.jpg" width="640" alt="puck">
  </a></p><p>
    <span>
      Cambridge University Library
    </span>
  </p>
</div>

<p>This one’s my personal favorite: a child’s-eye view of the Darwin family home with cozy details like a tea kettle on the boil and a fluffy orange cat in the attic window.</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/BXMEXhRCcAAgp-N-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/BXMEXhRCcAAgp-N-medium.jpg" width="640" alt="puck">
  </a></p><p>
    <span>
      Cambridge University Library
    </span>
  </p>
</div>

<p>Fascinatingly, this image might be detailed enough that it actually depicts Darwin’s famous <a href="http://darwin-online.org.uk/content/frameset?viewtype=text&amp;itemID=F1452.1&amp;pageseq=132">sandwalk</a>, his “thinking path” that led to the family greenhouse (which is, perhaps, the structure visible at the end of the path). The area was later made into a playground for the Darwin children.</p>

<p>I poked around the items available at Darwin Online and came across <a href="http://darwin-online.org.uk/EmmaDiaries.html">Emma Darwin’s diaries</a>, which are a fascinating resource. Emma seems to have been a talented sketch artist in her own right, doodling profiles and faces in over her daily schedule:</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/Darwin3a_1824-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/Darwin3a_1824-medium.jpg" width="640" alt="puck">
  </a></p><p>
    <span>
      Darwin Heirlooms Trust
    </span>
  </p>
</div>

<p>Here’s another, perhaps a self-portrait? Write us on <a href="https://twitter.com/appendixjournal">Twitter</a> or <a href="https://www.facebook.com/TheAppendix">Facebook</a> if you have any ideas as to whether this is Emma’s self-portrait or a drawing of another family member.</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/Darwin3-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/Darwin3-medium.jpg" width="640" alt="puck">
  </a></p><p>
    <span>
      Darwin Heirlooms Trust
    </span>
  </p>
</div>

<p>Amazingly, the Darwin kids even got into Emma’s diary, with several pages rendered unreadable by what is almost certainly a crazed toddler’s pencil. In fact, the back page of Emma’s potential self-portrait was defaced in precisely this way:</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/Darwin3b-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/Darwin3b-medium.jpg" width="640" alt="puck">
  </a></p><p>
    Francis Darwin strikes again?
    <span>
      Darwin Heirlooms Trust
    </span>
  </p>
</div>

<p>It’s all a great reminder that even legendary scientists had family lives, and that when we think about history, it’s important to remember that famous figures weren’t working in isolation. They were surrounded by far less famous friends, family members, acquaintances, and enemies. And sometimes, when we get lucky, we see some of their artifacts from the past too.</p>

<p>A tip of the hat, by the way, to <a href="http://www.openculture.com/">Open Culture</a>, a website that we’re avid fans of and which wrote the original post about the Darwin kids’ drawings that brought them to our attention. Also be sure to check out <a href="http://darwin-online.org.uk/">Darwin Online</a> and the <a href="http://darwin.amnh.org/">Darwin Manuscripts Project</a>, two wonderful resources for anyone interested in the naturalist and his times.</p>

<p><strong>Update:</strong></p>

<p>I also wanted to include a short note on Annie Darwin, who died from tuberculosis at age ten and was Charles’ favorite child (or so he <a href="https://books.google.com/books?id=6ikIAQAAMAAJ&amp;q=%22the+apple+of+her+proud+father%27s+eye,+his+favourite+child,%22&amp;dq=%22the+apple+of+her+proud+father%27s+eye,+his+favourite+child,%22&amp;hl=en&amp;sa=X&amp;ei=ewj9Uu3tLqbQ2wXYjoDICg&amp;ved=0CC0Q6AEwAQ">told</a> his cousin). This box of items relating to Annie’s life that was collected by Emma Darwin offers another, sadder testimony to the tight-knit dynamic of the Darwin family, and to their artistic knack. Annie’s pink flowers in careful needlepoint seem to echo the exuberant nature drawings of her siblings:</p>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/darwin4-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/darwin4-medium.jpg" width="640" alt="puck">
  </a></p><p>
    The Darwins’ box of mementos relating to Annie’s life.
    <span>
      American Museum of Natural History
    </span>
  </p>
</div>

<p>Darwin wrote about Annie after her death with touching earnestness as he tried to set down his memories of her before they faded:</p>

<blockquote>
  <p>Our poor child, Annie, was born in Gower St on March 2d. 1841. &amp; expired at Malvern at1 Midday on the 23d. of April 1851.— I write these few pages, as I think in after years, if we live, the impressions now put down will recall more vividly her chief characteristics. From whatever point I look back at her, the main feature in her disposition which at once rises before me is her buoyant joyousness.</p>
</blockquote>

<div>
  <p><a href="https://theappendix.net/images/blog/2014/02/darwin5-large.jpg">
    <img src="https://theappendix.net/images/blog/2014/02/darwin5-medium.jpg" width="640" alt="puck">
  </a></p><p>
    Darwin’s memoir of Annie in his personal papers.
    <span>
      Cambridge University Library
    </span>
  </p>
</div>

<p>In his book <em>Annie’s Box: Charles Darwin, His Daughter And Human Evolution,</em> Randal Keynes argues that Darwin’s scientific thought was closely entangled with his family life, and that the death of Annie just before Easter in 1851 spelled the end of Darwin’s already weakening Christian faith. Students of the past are often leery of making overly explicit and binary links between work and life (I remember being amazed when I learned that Shakespeare’s son Hamnet died several years before he wrote <em>Hamlet,</em> and that literary scholars don’t make more hay with that fact). But if nothing else, it again reminds us that when historical figures become legendary icons, they lose much of the context that makes them human to us at the remove of decades or centuries.</p>


    
      
    

    
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A high-throughput parser for the Zig programming language (127 pts)]]></title>
            <link>https://github.com/Validark/Accelerated-Zig-Parser</link>
            <guid>43705824</guid>
            <pubDate>Wed, 16 Apr 2025 14:11:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/Validark/Accelerated-Zig-Parser">https://github.com/Validark/Accelerated-Zig-Parser</a>, See on <a href="https://news.ycombinator.com/item?id=43705824">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto"><a href="https://ziglang.org/" rel="nofollow"><sub><sub><img src="https://raw.githubusercontent.com/Validark/Validark/master/zig-z.svg" alt="Lua" height="40"></sub></sub></a> Accelerated Zig Parser</h2><a id="user-content--accelerated-zig-parser" aria-label="Permalink:  Accelerated Zig Parser" href="#-accelerated-zig-parser"></a></div>
<p dir="auto">A high-throughput tokenizer and parser (soon™️) for the Zig programming language.</p>
<p dir="auto">The mainline Zig tokenizer uses a deterministic finite state machine. Those are pretty good for some applications, but tokenizing can often employ the use of other techniques for added speed.</p>
<p dir="auto">Two tokenizer implementations are provided.</p>
<ol dir="auto">
<li>
<p dir="auto">A version that produces a few bitstrings per 64-byte chunk and uses those to skip over continuation-character matching. I gave <a href="https://www.youtube.com/watch?v=oN8LDpWuPWw&amp;t=530s" rel="nofollow">two</a> <a href="https://www.youtube.com/live/FDiUKafPs0U&amp;t=210s" rel="nofollow">talks</a> on this subject. (<strong>Currently this code has gone poof, but I will resurrect this for comparison's sake within 3 months (when I give my final Utah-Zig talk on the subject of the Zig Tokenizer in July)</strong>)</p>
</li>
<li>
<p dir="auto">A version that produces bitstrings for EVERYTHING we want to do within a 64-byte chunk, and utilizes vector compression to find the extents of all tokens simulataneously. See <a href="https://validark.dev/presentations/simd-intro#keywords-lookup" rel="nofollow">this animation</a>. I also gave a talk (really more of a rant) about my grand plans <a href="https://www.youtube.com/watch?v=NM1FNB5nagk" rel="nofollow">here</a>. Unfortunately it did not turn out how I had hoped because I got sick before I had time to give it the love it deserves. But my next talk shall knocketh thy socks off, guaranteed!</p>
</li>
</ol>
<p dir="auto">The test bench as it sits on my computer right now prints this out when I run it:</p>
<div data-snippet-clipboard-copy-content="       Read in files in 26.479ms (1775.63 MB/s) and used 47.018545MB memory with 3504899722 lines across 3253 files
Legacy Tokenizing took              91.419ms (0.51 GB/s, 38.34B loc/s) and used 40.07934MB memory
Tokenizing with compression took    33.301ms (1.41 GB/s, 105.25B loc/s) and used 16.209284MB memory
       That's 2.75x faster and 2.47x less memory than the mainline implementation!"><pre><code>       Read in files in 26.479ms (1775.63 MB/s) and used 47.018545MB memory with 3504899722 lines across 3253 files
Legacy Tokenizing took              91.419ms (0.51 GB/s, 38.34B loc/s) and used 40.07934MB memory
Tokenizing with compression took    33.301ms (1.41 GB/s, 105.25B loc/s) and used 16.209284MB memory
       That's 2.75x faster and 2.47x less memory than the mainline implementation!
</code></pre></div>
<p dir="auto">And I still have more optimization plans &gt;:D !!! Stay tuned!</p>
<p dir="auto">See my article on the new tokenizer, here: <a href="https://validark.dev/posts/deus-lex-machina/" rel="nofollow">https://validark.dev/posts/deus-lex-machina/</a></p>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tokenizer 1:</h2><a id="user-content-tokenizer-1" aria-label="Permalink: Tokenizer 1:" href="#tokenizer-1"></a></p>
<p dir="auto">Everything beneath this notice was written with regards to Tokenizer 1. The information is a little out-of-date but the optimization strategies are still applicable.</p>
<p dir="auto"><a href="#latest-work">Click here to see my latest work.</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Results</h2><a id="user-content-results" aria-label="Permalink: Results" href="#results"></a></p>
<p dir="auto"><strong>Currently the utf8 validator is turned off! I did a lot of performance optimization the past few days and did not finish porting my changes over yet.</strong></p>
<p dir="auto">The test bench fully reads in all of the Zig files under the folders in the <code>src/files_to_parse</code> folder. In my test I installed the Zig compiler, ZLS, and a few other Zig projects in my <code>src/files_to_parse</code> folder. The test bench iterates over the source bytes from each Zig file (with added sentinels) and calls the tokenization function on each <strong>with the utf8 validator turned off</strong>.</p>
<p dir="auto">To tokenize 3,218 Zig files with 1,298,380 newlines, the original tokenizer and my new tokenizer have the following characteristics:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>memory (megabytes)</th>
</tr>
</thead>
<tbody>
<tr>
<td>raw source files</td>
<td>59.162811MB</td>
</tr>
<tr>
<td>original (tokens)</td>
<td>46.089775MB</td>
</tr>
<tr>
<td>this (tokens)</td>
<td>18.50827MB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">That's 2.49x less memory!</p>
<p dir="auto">Please keep in mind that comparing to the legacy tokenizer's speed is not necessarily straightforward. It is not difficult for me to see the legacy tokenizer's performance change by ~15% by making a trivial change in my code. It varies heavily depending on the particular compile. That said, here are some numbers I am seeing on my machine (with the utf8 validator turned off on my implementation):</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">x86_64 Zen 3</h3><a id="user-content-x86_64-zen-3" aria-label="Permalink: x86_64 Zen 3" href="#x86_64-zen-3"></a></p>
<p dir="auto"><strong>Currently the utf8 validator is turned off! I did a lot of performance optimization the past few days and did not finish porting my changes over yet.</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>run-time (milliseconds)</th>
<th>throughput (megabytes per second)</th>
<th>throughput (million lines of code per second)</th>
</tr>
</thead>
<tbody>
<tr>
<td>read files (baseline)</td>
<td>37.03ms</td>
<td>1597.85 MB/s</td>
<td>35.06M loc/s</td>
</tr>
<tr>
<td>original</td>
<td>218.512ms</td>
<td>270.78 MB/s</td>
<td>5.94M loc/s</td>
</tr>
<tr>
<td>this</td>
<td>72.107ms</td>
<td>820.57 MB/s</td>
<td>18.01M loc/s</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">That's ~3.03x faster! <strong>Currently the utf8 validator is turned off! I did a lot of performance optimization the past few days and did not finish porting my changes over yet.</strong></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">RISC-V SiFive U74</h3><a id="user-content-risc-v-sifive-u74" aria-label="Permalink: RISC-V SiFive U74" href="#risc-v-sifive-u74"></a></p>
<p dir="auto"><strong>Currently the utf8 validator is turned off! I did a lot of performance optimization the past few days and did not finish porting my changes over yet.</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th></th>
<th>run-time (milliseconds)</th>
<th>throughput (megabytes per second)</th>
<th>throughput (million lines of code per second)</th>
</tr>
</thead>
<tbody>
<tr>
<td>read files (baseline)</td>
<td>318.989ms</td>
<td>185.47 MB/s</td>
<td>4.07M loc/s</td>
</tr>
<tr>
<td>original</td>
<td>2.206s</td>
<td>26.81 MB/s</td>
<td>0.59M loc/s</td>
</tr>
<tr>
<td>this</td>
<td>894.963ms</td>
<td>66.11 MB/s</td>
<td>1.45M loc/s</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">That's ~2.47x faster! <strong>Currently the utf8 validator is turned off! I did a lot of performance optimization the past few days and did not finish porting my changes over yet.</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">To-do</h2><a id="user-content-to-do" aria-label="Permalink: To-do" href="#to-do"></a></p>
<ul dir="auto">
<li>Fix utf8 validator and get a good SWAR implementation.</li>
<li>Make it so we can return memory which holds the non-newline bitmaps.</li>
<li>Actually implement the AST parser.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Maintenance note</h2><a id="user-content-maintenance-note" aria-label="Permalink: Maintenance note" href="#maintenance-note"></a></p>
<p dir="auto">Oddly enough, I think some of this code is more maintainable too, as adding an operator or keyword to the tokenizer is literally just adding another string into the relevant array. All of the assumptions and tricks I use are explicitly checked for in compile-time assertions (<code>grep</code> for <code>comptime assert</code>), so violating any of those invariants will result in compile errors that tell you why you can't change certain things.</p>
<p dir="auto">However, I do have a bunch of weird SWAR tricks that the compiler will hopefully perform automatically one day.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Designing for high performance</h2><a id="user-content-designing-for-high-performance" aria-label="Permalink: Designing for high performance" href="#designing-for-high-performance"></a></p>
<p dir="auto">In the delicate balancing act that is performance optimization, you generally want:</p>
<ol dir="auto">
<li>The ability to process more than one thing at once</li>
<li>Fewer unpredicable branches</li>
<li>A linear traversal over a smaller amount of contiguous memory</li>
</ol>
<p dir="auto">I try to achieve each of these in the following ways:</p>
<ol dir="auto">
<li>
<p dir="auto">SIMD, i.e. single-instruction, multiple data. Instead of operating on a single element at a time, you can operate on 16, 32, or 64 elements simultaneously. Instead of going character-by-character, we use SIMD to check for the length of identifiers/keywords, the length of quotes, the length of whitespace, and the length of comments or single-line quotes. This allows us to move quicker than one byte at a time. We also use a SIMD technique to validate proper utf8 conformance, ported from <a href="https://github.com/simdjson/simdjson">simdjson</a> by <a href="https://github.com/travisstaloch/">travisstaloch</a> for use in <a href="https://github.com/travisstaloch/simdjzon/">simdjzon</a>. Please note that that particular code is licensed under the Apache license, included at the bottom of the <code>main.zig</code> file.</p>
<ul dir="auto">
<li>
<p dir="auto">I do not actually use SIMD to find "character literals" of the form <code>'a'</code> because these are generally extremely short and did not actually give much benefit in tests.</p>
</li>
<li>
<p dir="auto">We can't and don't want to use SIMD for absolutely everything because:</p>
<ul dir="auto">
<li>Comments can be inside of quotes and quotes can be inside of comments
<ul dir="auto">
<li>Selecting which bitstring to match in next is (probably?) not that efficient. You'd have to multiply each vector and then OR all the vectors together, get the next position, then repeat. I might try out this approach, but I doubt it will be that practical. I also note when I look at the arm64 output that it takes <em>much</em> more vector instructions than on x86_64, and doing everything in SIMD generates several hundred instructions on arm64. It might still be worth it though, especially on x86_64, but I doubt it.</li>
</ul>
</li>
<li>Operators are all over the place and doing everything in SIMD would require a lot of work that's not that bad for scalar code to do.</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">SWAR, i.e., SIMD within a register. This is where we read multiple bytes into a 4 or 8 byte register and use conventional arithmetic and logical instructions to operate on multiple bytes simultaneously.</p>
<ul dir="auto">
<li>SWAR fallbacks are provided for machines which lack proper SIMD instructions.
<ul dir="auto">
<li>We can check for equality against a character by broadcasting the character and performing an xor operation:</li>
</ul>
<div data-snippet-clipboard-copy-content="  0xaabbccddeeffgghh
^ 0xcccccccccccccccc
--------------------
  0x~~~~00~~~~~~~~~~"><pre><code>  0xaabbccddeeffgghh
^ 0xcccccccccccccccc
--------------------
  0x~~~~00~~~~~~~~~~
</code></pre></div>
<ul dir="auto">
<li>The previous step will result in 0's in the byte array in the positions where we found our target byte (in this case, <code>cc</code>). We can then add a broadcasted <code>0x7F</code>.</li>
</ul>
<div data-snippet-clipboard-copy-content="  0x~~~~00~~~~~~~~~~
+ 0x7F7F7F7F7F7F7F7F
  ----------------
  0x8~8~7F8~8~8~8~8~"><pre><code>  0x~~~~00~~~~~~~~~~
+ 0x7F7F7F7F7F7F7F7F
  ----------------
  0x8~8~7F8~8~8~8~8~
</code></pre></div>
<ul dir="auto">
<li>This will result in a 1 bit in the most significant bit of each byte that didn't start out as a 0 after the previous step. The only problem with the technique as I have presented it thus far is the potential for overflow across bytes. To remedy this, we mask out the highest bit of each byte before starting this algorithm. That way, when we add 7F we know it cannot overflow beyond the most significant bit of each byte, and then we know we can look at the most significant bit of each byte to tell us whether our target byte was <strong>not</strong> there.</li>
<li>Then we can mask out the most significant bit of each byte and emulate a movmask operation, i.e. concentrate the bits together, with a multiplication:</li>
</ul>
<div data-snippet-clipboard-copy-content="Example with 32 bit integers:
We want to concentrate the upper bits of each byte into a single nibble.
Doing the gradeschool multiplication algorithm, we can see that each 1 bit
in the bottom multiplicand shifts the upper multiplicand, and then we add all these
shifted bitstrings together. (Note `.` represents a 0)
  a.......b.......c.......d.......
* ..........1......1......1......1
-------------------------------------------------------------------------
  a.......b.......c.......d.......
  .b.......c.......d..............
  ..c.......d.....................
+ ...d............................
-------------------------------------------------------------------------
  abcd....bcd.....cd......d.......

Then we simply shift to the right by `32 - 4` (bitstring size minus the number of relevant
bits) to isolate the desired `abcd` bits in the least significant byte!"><pre><code>Example with 32 bit integers:
We want to concentrate the upper bits of each byte into a single nibble.
Doing the gradeschool multiplication algorithm, we can see that each 1 bit
in the bottom multiplicand shifts the upper multiplicand, and then we add all these
shifted bitstrings together. (Note `.` represents a 0)
  a.......b.......c.......d.......
* ..........1......1......1......1
-------------------------------------------------------------------------
  a.......b.......c.......d.......
  .b.......c.......d..............
  ..c.......d.....................
+ ...d............................
-------------------------------------------------------------------------
  abcd....bcd.....cd......d.......

Then we simply shift to the right by `32 - 4` (bitstring size minus the number of relevant
bits) to isolate the desired `abcd` bits in the least significant byte!
</code></pre></div>
</li>
<li>Even on machines with vectors and powerful instructions, SWAR techniques may still be employed for operator matching.</li>
</ul>
</li>
<li>
<p dir="auto">Reducing unpredictable branches through:</p>
<ul dir="auto">
<li>
<p dir="auto">Using SIMD/SWAR. Using a conventional while loop to capture a completely unpredictable number of characters in the aforementioned categories all but guarantees a branch mispredict every time we exit the loop, and possibly multiple throughout the loop if the branch predictor is having a bad day. Using SIMD/SWAR, we can instead produce a bitstring with 0's marked in the place corresponding to target characters like the matching <code>"</code>, shift the bitstring according to our cursor's position, and count the trailing ones (the reason the bits are the inverse of what you might expect is because when we shift the bitstring it will be filled with 0's). In most cases, a single "count trailing one's" operation is all we need to find the position we are supposed to go to next. No need for a totally unpredictable while loop that goes character-by-character!</p>
</li>
<li>
<p dir="auto">Using perfect hash functions. Specifically, keywords like <code>var</code> and <code>const</code> are mapped into a 7 bit address space by a perfect hash function. Identifiers can be checked against the list of keywords by applying the perfect hash function to each identifier and doing a table lookup to find what keyword it may match, then doing a single 16-byte vs 16-byte comparison to see if the identifier matches that keyword. The keywords are padded in memory to be 16 bytes and have a <code>len</code> stored in the final byte so we can check that the incoming identifier has the same length as the prospective keyword. We also use Phil Bagwell's array-mapped trie compression technique, meaning we have a 128-bit bitmap and find which position to check using the bitmap, thereby enabling us to have a packed buffer that need not have 128 slots. We do a similar trick for operators.</p>
<ul dir="auto">
<li>One cool thing I can do because of Zig's comptime execution feature is tell Zig that a dummy operator/keyword is needed when we do not have an operator or keyword which hashes to the maximum 7 bit value, i.e. 127 (because I am hashing these to 7 bits of address space). If an operator or keyword is added or removed which hashed to 127, the comptime logic will automatically remove or add the dummy operator/keyword. Very nifty! At the moment, one of the perfect hash schemes needs a dummy element and the other does not. It's nice knowing that if we make a change like changing the hash function or adding/removing an operator or keyword, it will automatically figure out the right thing to do. These kinds of tricks are not good in conventional programming languages. We either have to do this work at start-up time or, even worse, someone bakes all the assumptions into the code and then changing it becomes a game of Jenga, except harder because the pieces are not all in one place. In Zig, we write it once and compile-time execution takes care of the rest.</li>
</ul>
</li>
<li>
<p dir="auto">I use a trick where I just allocate the upper-bound amount of memory for tokens per-file, and use the <code>resize</code> facility of the allocator to reclaim the space I did not fill. The nice thing about this trick is I can always assume there is sufficient space, which eliminates the need to check that such a thing is safe.</p>
</li>
<li>
<p dir="auto">I place sentinels at the end of files (and I place a newline at the front) to make the rest of the code simpler. This allows us to safely go back a character at any point if the perfect hash function wants us to grab the last two characters from an identifier with only one character, and allows us to safely go past the end of the source file as well. By placing <code>"</code> and <code>'</code> characters at the end of our buffer, we can eliminate bounds-checking in the code that searches for those characters, and simply check whether we hit the sentinel node after the hot loop finishes. We currently don't break out of these for newlines though, which we should probably do. All other validation for these should occur when actually trying to allocate the string or character they are supposed to represent.</p>
</li>
<li>
<p dir="auto">Some things we do unconditionally that could be hidden behind a branch, but are very inexpensive so there is no point. Other things we hide behind a branch when it's expensive and generally predictable. E.g. utf8 validation is typically just making sure all bytes are less than 128, i.e. 0x80. Once we see some non-ascii sequences, then we have to do the more computationally expensive work of making sure the byte sequence is valid.</p>
</li>
<li>
<p dir="auto">Table lookups. I consolidate the SIMD/SWAR code into one so that we go down the exact same codepaths to find how many non_newline/identifier/non_unescaped_quote/space characters to jump over. This is probably much more efficient than having 4 separate copies of the same hot loop.</p>
</li>
<li>
<p dir="auto">Inlining the SIMD/SWAR loop, even on machines that need to unroll 8 times. This turns out to be worth it in my tests, probably because it is an extremely hot loop!</p>
</li>
</ul>
</li>
<li>
<p dir="auto">We reduce memory consumption by not storing start indices explicitly, which typically need to match the address space of the source length. In the case of Zig, where source files are constrained to be at most ~4GiB, only 32 bits of address space is needed for any given file. Thus the goal becomes reducing 32-bit start indices to something smaller. Quasi-succinct schemes for reducing the space consumption of monotonically increasing integer sequences immediately spring to mind, such as <a href="https://www.antoniomallia.it/sorted-integers-compression-with-elias-fano-encoding.html" rel="nofollow">Elias-Fano encoding</a>. However, we can achieve good space compression by simply storing the length of each token rather than the start index. Because tokens almost always have a length that can fit in a byte, we try to store all lengths in a byte. In the event that the length is too large to be stored in a byte, we store a <code>0</code> instead and make the next 4 bytes the true length. This works because tokens cannot have a length of 0, else they would not exist, therefore we can use lengths of <code>0</code> to trigger special behavior. We also know that this idea does not affect the upper bound on the number of Token elements we need to allocate because in order for a token to take up 3 times as much space as a typical token, it needs to have a length of at least 256, which the astute reader may note is significantly larger than 3.</p>
</li>
<li>
<p dir="auto">Use fewer variables where possible. While machines nowadays have <em>a lot</em> more registers than they used to, you still only have access to 16 or 32 general purpose registers! If you have more variables than that, you have to spill to the stack (it's actually worse than this, because intermediate values in expressions temporarily need their own registers too). While machines do have extra registers they can use under the hood, you do not! Therefore, we can get better performance by</p>
<ul dir="auto">
<li>Using pointers rather than pointers + index</li>
<li>Being clever about how we write out our <code>non_newlines</code> bitstrings. Instead of storing all of the bitstrings I get from the SIMD/SWAR code on the stack in a <code>[4]u64</code> (on 64 bit machines), and then writing separately to a <code>non_newlines</code> pointer, I write <em>all</em> the bitstrings into the memory allocated for the <code>non_newlines</code> bitstrings. Each time, I increment the place we are writing in the allocation by the width of a single bitstring, i.e. 8 bytes on 64 bit machines. Since I always write the <code>non_newlines</code> into the current position in the allocated memory and the other bitstrings are written after it, we will be left at the end with only <code>non_newlines</code> bitstrings. The only downside is we need to overallocate an extra 3 u64's than we otherwise would, but that's hardly any trouble. Here is a diagram of how this strategy looks in memory:</li>
</ul>
<div data-snippet-clipboard-copy-content="|0|1|2|3|4|5|6|7|8|9| <- slots
|a|b|c|d|   <- We write our bitstrings to 4 slots. (`a` is `non_newlines`)
  |a|b|c|d| <- Each time, we move one slot forward
    |a|b|c|d|
      |a|b|c|d|
        |a|b|c|d|
          |a|b|c|d|
            |a|b|c|d|
|a|a|a|a|a|a|a|b|c|d| <- In the end, we are left with this"><pre><code>|0|1|2|3|4|5|6|7|8|9| &lt;- slots
|a|b|c|d|   &lt;- We write our bitstrings to 4 slots. (`a` is `non_newlines`)
  |a|b|c|d| &lt;- Each time, we move one slot forward
    |a|b|c|d|
      |a|b|c|d|
        |a|b|c|d|
          |a|b|c|d|
            |a|b|c|d|
|a|a|a|a|a|a|a|b|c|d| &lt;- In the end, we are left with this
</code></pre></div>
</li>
</ol>
<p dir="auto"><h2 tabindex="-1" dir="auto">Still to-do</h2><a id="user-content-still-to-do" aria-label="Permalink: Still to-do" href="#still-to-do"></a></p>
<p dir="auto">Aside from the to-do's listed in the <code>main.zig</code> file, the plan with this is to rewrite the Zig parser which produces the Abstract Syntax Tree as well. I have a number of ideas on how to dramatically improve efficiency there as well. Stay tuned!</p>
<p dir="auto">My ultimate goal is that this repository will be integrated with the Zig compiler.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use</h2><a id="user-content-how-to-use" aria-label="Permalink: How to use" href="#how-to-use"></a></p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/Validark/Accelerated-Zig-Parser.git"><pre><code>git clone https://github.com/Validark/Accelerated-Zig-Parser.git
</code></pre></div>
<p dir="auto">Next, install one or more Zig projects under the <code>src/files_to_parse</code> folder.</p>
<div data-snippet-clipboard-copy-content="cd Zig-Parser-Experiment/src/files_to_parse
git clone https://github.com/ziglang/zig.git
git clone https://github.com/zigtools/zls.git"><pre><code>cd Zig-Parser-Experiment/src/files_to_parse
git clone https://github.com/ziglang/zig.git
git clone https://github.com/zigtools/zls.git
</code></pre></div>
<p dir="auto">Then run it!</p>
<div data-snippet-clipboard-copy-content="cd ../..
zig build -Doptimize=ReleaseFast run"><pre><code>cd ../..
zig build -Doptimize=ReleaseFast run
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Latest work</h2><a id="user-content-latest-work" aria-label="Permalink: Latest work" href="#latest-work"></a></p>
<p dir="auto">In the last few days, I have:</p>
<ul dir="auto">
<li>
<p dir="auto">Disabled loop unrolling for quote parsing loop on SWAR-enabled machines. Only a 1% uplift on my Sifive U74, but considering that's about 9 milliseconds at the moment, I'll take it.</p>
</li>
<li>
<p dir="auto">Updated the keyword lookup algorithm for non-vector architectures to use aligned loads where possible. There still could be room for improvement but today I saw a <strong>~5% performance uplift</strong>.</p>
</li>
<li>
<p dir="auto">Updated to a <a href="https://github.com/simdjson/simdjson/pull/2042" data-hovercard-type="pull_request" data-hovercard-url="/simdjson/simdjson/pull/2042/hovercard">slightly better optimized version</a> of the escape-detection algorithm.</p>
</li>
<li>
<p dir="auto">Made toggles so that <code>"</code> and <code>'</code> can be moved between the SIMD/SWAR section and a naïve scalar version very easily. It appears that for machines which have to use SWAR, it is faster to do the naïve scalar version (almost <strong>~8% uplift on my RISC-V SiFive U74</strong>). On the other hand, it's still more efficient on my desktop to do quote classification in SIMD, but for other less-powerful devices, it may not be worth it.</p>
<ul dir="auto">
<li>There is also a trade-off to be made on big-endian hardware. The SIMD <code>'</code>/<code>"</code> escape detection algorithm currently has to be done in little-endian, so there necessarily has to be a reversal somewhere (or byte-reversal on the vectors) if we want to not use the naïve scalar version.
<ul dir="auto">
<li>
<p dir="auto">With SIMD, we need to do a vector reversal, unless we have fast machine-word bit-reverse instructions. At the moment I am not aware of any ISA's supported by the Zig compiler with a fast bit-reverse instruction besides arm/aarch64.</p>
<ul dir="auto">
<li>We take advantage of arm's bit-reverse instruction (<code>rbit</code>) so that we can use <code>clz</code> directly in our bitstring queries, rather than <code>rbit</code>+<code>clz</code>. On little-endian machines, we do the flip after the escape-detection algorithm. On big-endian, we can do it before, but then we can just bitreverse the backslashes before and after the escape detection algorithm. arm is typically little-endian these days, but who knows, maybe a future ISA can take advantage of the flexibility.</li>
</ul>
</li>
<li>
<p dir="auto">mips64 and powerpc64 have built-in <code>clz</code> instructions, and emulate <code>ctz</code> via <code>@bitSizeOf(usize) - clz(~x &amp; (x -% 1))</code>. Therefore, if we wanted to do quotes in SIMD <em>and</em> use <code>clz</code>, we would have to flip our bitstrings twice! Ouch! Hopefully I or someone else figures out how to make a big-endian equivalent of the escape character bitstring generation algorithm.</p>
</li>
<li>
<p dir="auto">some sparc64 machines have <code>popc</code> (e.g. niagara 2 and up), which can emulate <code>ctz</code> via <code>popc(~x &amp; (x -% 1))</code>. To do <code>clz</code> we have to do <code>x |= x &gt;&gt; 1; x |= x &gt;&gt; 2; x |= x &gt;&gt; 4; x |= x &gt;&gt; 8; x |= x &gt;&gt; 16; x |= x &gt;&gt; 32;</code> to spread the most-significant bit all the way right-wards, then we can invert the bitstring to get a mask of the leading zeroes, and popcount that. So on big-endian sparc64 machines, we WANT to do a bitreverse. Also, LLVM's Vectorization currently does not work on sparc64 (or powerpc) machines, so we probably have to use the SWAR algorithm for the time being.</p>
</li>
<li>
<p dir="auto">machines which do not have <code>clz</code> builtin can probably emulate a <code>ctz</code> faster than a <code>clz</code>.</p>
</li>
<li>
<p dir="auto">With SWAR, we can do either a <code>@byteSwap</code> on the register being treated as a vector or we can reverse the bits with a bitreversing movmask algorithm. The problem with the latter is that we have to do an extra shift right on the bitstring before multiplying because the most significant bit of the most significant byte has to be moved to the lowest bit position of its byte. We <em>can</em> avoid this extra shift by instead using a multiply-high operation and concentrating the bits in the upper half of a double machine-word, and maintaining a 3 instruction movmask. However, the problem with this idea is that multiply-high might be a function call or have terrible throughput / port constraints, whereas multiplies typically have a throughput of 1 per cycle. Is the throughput actually a problem in practice though? Unsure. We <em>do</em> have quite a lot of other work to do in between multiplies.</p>
<ul dir="auto">
<li>To generate 3 bitstrings for a chunk, we need 3 extra instructions for the bitreversed movmask (assuming we don't do <code>'</code>/<code>"</code> in SWAR). Therefore, if we can do a machine-word byte-reverse faster than 3 shifts and/or in fewer than 3 instructions, it would be smarter to do the byte-reverse. Alternatively, if we have fast multiply-high's somehow, we could use that to eliminate the 3 extra shifts (per native subchunk).</li>
</ul>
</li>
<li>
<p dir="auto">For now, I think the bitstring escape sequence algorithm is best left disabled on big-endian hardware without a fast bit-reverse (so just arm atm).</p>
</li>
<li>
<p dir="auto">Since sparc64 and powerpc have to use SWAR until LLVM improves, they should do quote/escape logic in scalar code, not vector code. sparc64 machines lack bit-reverse and byte-reverse, so we can use the movemask-reversed function on sparc64.</p>
</li>
<li>
<p dir="auto">powerpc can stay in big-endian land and use <code>clz</code>.</p>
</li>
<li>
<p dir="auto">mips64 has an extension to the ISA which adds vector instructions, although I'm not sure if it has gone into real hardware yet or whether those vectors are actually useful for the kind of SIMD we are doing here.</p>
<ul dir="auto">
<li>therefore mips64 can stay in big-endian land and use <code>clz</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p dir="auto">Partially added some control character bans but there is still more to be done. Still, as of yet, incomplete.</p>
</li>
<li>
<p dir="auto">Replaced the SWAR movmask algorithm with one significantly better on typical hardware. Before, we were using <a href="http://0x80.pl/articles/scalar-sse-movmask.html" rel="nofollow">an algorithm from Wojciech Muła</a> which for 64 bit operand <code>x</code> would basically do: <code>(@as(u128, x) * constant) &gt;&gt; 64</code>. Now, we can stay within the lower 64 bits by concentrating the target bits in the most significant byte, so no widening is necessary. This is really good news for basically every machine I could find info on for the difference between <code>mulhi</code> vs <code>mul</code>. Typically <code>mulhi</code> instructions have much higher latency and signicantly worse throughput, and some machines do not even have a <code>mulhi</code> instruction at all. My algorithm modifies <a href="http://0x80.pl/articles/scalar-sse-movmask.html" rel="nofollow">Wojciech Muła's algorithm</a> to use only the lower 64 bits of the product of the multiplication:</p>
<div data-snippet-clipboard-copy-content="Example with 32 bit integers:
We want to concentrate the upper bits of each byte into a single nibble.
Doing the gradeschool multiplication algorithm, we can see that each 1 bit
in the bottom multiplicand shifts the upper multiplicand, and then we add all these
shifted bitstrings together. (Note `.` represents a 0)
  a.......b.......c.......d.......
* ..........1......1......1......1
-------------------------------------------------------------------------
  a.......b.......c.......d.......
  .b.......c.......d..............
  ..c.......d.....................
+ ...d............................
-------------------------------------------------------------------------
  abcd....bcd.....cd......d.......

Then we simply shift to the right by `32 - 4` (bitstring size minus the number of relevant
bits) to isolate the desired `abcd` bits in the least significant byte!"><pre><code>Example with 32 bit integers:
We want to concentrate the upper bits of each byte into a single nibble.
Doing the gradeschool multiplication algorithm, we can see that each 1 bit
in the bottom multiplicand shifts the upper multiplicand, and then we add all these
shifted bitstrings together. (Note `.` represents a 0)
  a.......b.......c.......d.......
* ..........1......1......1......1
-------------------------------------------------------------------------
  a.......b.......c.......d.......
  .b.......c.......d..............
  ..c.......d.....................
+ ...d............................
-------------------------------------------------------------------------
  abcd....bcd.....cd......d.......

Then we simply shift to the right by `32 - 4` (bitstring size minus the number of relevant
bits) to isolate the desired `abcd` bits in the least significant byte!
</code></pre></div>
</li>
<li>
<p dir="auto">Laid groundwork for exporting non_newline bitmaps, that way we can use it later on in the compiler to figure out what line we are on <a href="https://github.com/ziglang/zig/blob/91e117697ad90430d9266203415712b6cc59f669/src/AstGen.zig#L12498C10-L12515">without needing to go byte-by-byte later on in the pipeline</a>.</p>
<ul dir="auto">
<li>Use a clever trick where we write out the SIMD/SWAR movmasked bitstrings into the allocated area, but we shift where we are writing by the width of one bitstring each time. That way, in the end we have filled our buffer with the first bitstring we write out in each step, with the overhead of basically one instruction (the pointer increment) per chunk (64 bytes on 64 bit machines).</li>
</ul>
<div data-snippet-clipboard-copy-content="|0|1|2|3|4|5|6|7|8|9| <- slots
|a|b|c|d|   <- We write our bitstrings to 4 slots. (`a` is `non_newlines`)
  |a|b|c|d| <- Each time, we move one slot forward
    |a|b|c|d|
      |a|b|c|d|
        |a|b|c|d|
          |a|b|c|d|
            |a|b|c|d|
|a|a|a|a|a|a|a|b|c|d| <- In the end, we are left with this"><pre><code>|0|1|2|3|4|5|6|7|8|9| &lt;- slots
|a|b|c|d|   &lt;- We write our bitstrings to 4 slots. (`a` is `non_newlines`)
  |a|b|c|d| &lt;- Each time, we move one slot forward
    |a|b|c|d|
      |a|b|c|d|
        |a|b|c|d|
          |a|b|c|d|
            |a|b|c|d|
|a|a|a|a|a|a|a|b|c|d| &lt;- In the end, we are left with this
</code></pre></div>
</li>
<li>
<p dir="auto">Fixed random performance issues, like the compiler not realizing that our SIMD/SWAR chunks are always aligned loads. (It matters a lot on less-mainstream machines!)</p>
</li>
<li>
<p dir="auto">Made the SIMD/SWAR code go chunk by chunk in lockstep rather than have each individual component load its 64 (on 64-bit machines) bytes separately. I am assuming that LLVM was able to reuse loaded vectors on some occasions, but in practice I saw a massive speedup in the last week. Granted, the utf8 validator was turned off temporarily while it is being reworked. However, on my Zen 3 machine I typically saw basically no performance difference between running the utf8 validator versus not. The reason for this is because we can almost always exit early (when the entire chunk is ascii). Due to alignment/cache/happenstance, I typically saw my tokenization times go <em>down</em> with the utf8 validator turned <em>on</em>, so I don't think I am unfairly advantaging my most recent measurements.</p>
</li>
<li>
<p dir="auto">Turned off the utf8 validator. I need to fix the types for it so it can be re-enabled. We also need to port a SWAR version. simdjson or Golang might have some tricks we can use.</p>
</li>
<li>
<p dir="auto">Added an option to enable or disable the folding of comments into adjacent nodes (<code>FOLD_COMMENTS_INTO_ADJACENT_NODES</code>). This should make it a little easier to change my mind on the particulars of the AST implementation.</p>
</li>
<li>
<p dir="auto">Added more tests and compile-time assertions. We're getting there!</p>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Science, the Endless Frontier (1945) [pdf] (101 pts)]]></title>
            <link>https://nsf-gov-resources.nsf.gov/2023-04/EndlessFrontier75th_w.pdf</link>
            <guid>43705796</guid>
            <pubDate>Wed, 16 Apr 2025 14:09:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nsf-gov-resources.nsf.gov/2023-04/EndlessFrontier75th_w.pdf">https://nsf-gov-resources.nsf.gov/2023-04/EndlessFrontier75th_w.pdf</a>, See on <a href="https://news.ycombinator.com/item?id=43705796">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Dirty tricks 6502 programmers use (2019) (156 pts)]]></title>
            <link>https://nurpax.github.io/posts/2019-08-18-dirty-tricks-6502-programmers-use.html</link>
            <guid>43705649</guid>
            <pubDate>Wed, 16 Apr 2025 13:58:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nurpax.github.io/posts/2019-08-18-dirty-tricks-6502-programmers-use.html">https://nurpax.github.io/posts/2019-08-18-dirty-tricks-6502-programmers-use.html</a>, See on <a href="https://news.ycombinator.com/item?id=43705649">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<article>





<p>This post recaps some of the C64 coding tricks used in my little <a href="https://twitter.com/nurpax/status/1159192477598965766">Commodore 64 coding competition</a>. The competition rules were simple: make a C64 executable (PRG) that draws two lines to form the below image. The objective was to do this in as few bytes as possible.</p>
<p><img width="75%" src="https://nurpax.github.io/images/c64/lines/lines-2x.png">
</p>
<p>Entries were posted as Twitter replies and DMs, containing only the PRG byte-length and an MD5 hash of the PRG file.</p>
<p>Here’s a list of participants with source code links to their submissions:</p>
<ul>
<li><a href="https://twitter.com/fsphil">Philip Heron</a> (<a href="https://github.com/fsphil/tinyx">code</a> - 34 bytes - compo winner)</li>
<li><a href="https://twitter.com/GeirSigmund">Geir Straume</a> (<a href="https://c64prg.appspot.com/downloads/lines34b.zip">code</a> - 34 bytes)</li>
<li><a href="https://twitter.com/petrih3">Petri Häkkinen</a> (<a href="https://github.com/petrihakkinen/c64-lines">code</a> - 37 bytes)</li>
<li><a href="https://twitter.com/laubzega">Mathlev Raxenblatz</a> (<a href="https://gist.github.com/laubzega/fb59ee6a3d482feb509dae7b77e925cf">code</a> - 38 bytes)</li>
<li><a href="https://twitter.com/achrenico">Jan Achrenius</a> (<a href="https://twitter.com/achrenico/status/1161383381835362305">code</a> - 48 bytes)</li>
<li><a href="https://twitter.com/jamie30dbs">Jamie Fuller</a> (<a href="https://github.com/30dbs/c64x">code</a> - 50 bytes)</li>
<li><a href="https://twitter.com/dagershman">David A. Gershman</a> (<a href="http://c64.dagertech.net/cgi-bin/cgiwrap/c64/index.cgi?p=xchallenge/.git;a=tree">code</a> - 53 bytes)</li>
<li><a href="https://twitter.com/nurpax">Janne Hellsten</a> (<a href="https://gist.github.com/nurpax/d429be441c7a9f4a6ceffbddc35a0003">code</a> - 56 bytes)</li>
</ul>
<p>(If I missed someone, please let me know and I’ll update the post.)</p>
<p>The rest of this post focuses on some of the assembly coding tricks used in the compo submissions.</p>
<h3 id="basics">Basics</h3>
<p>The C64 default graphics mode is the 40x25 charset mode. The framebuffer is split into two arrays in RAM:</p>
<ul>
<li><code>$0400</code> (Screen RAM, 40x25 bytes)</li>
<li><code>$d800</code> (Color RAM, 40x25 bytes)</li>
</ul>
<p>To set a character, you store a byte into screen RAM at <code>$0400</code> (e.g., <code>$0400+y*40+x</code>). Color RAM is by default initialized to light blue (color 14) which happens to be the same color we use for the lines – meaning we can leave color RAM untouched.</p>
<p>You can control the border and background colors with memory mapped I/O registers at <code>$d020</code> (border) and <code>$d021</code> (background).</p>
<p>Drawing the two lines is pretty easy as we can hardcode for the fixed line slope. Here’s a C implementation that draws the lines and dumps screen contents on stdout (register writes stubbed out and screen RAM is <code>malloc()</code>’d to make it run on PC):</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>#include </span><span>&lt;stdint.h&gt;</span></span>
<span id="cb1-2"><span>#include </span><span>&lt;stdio.h&gt;</span></span>
<span id="cb1-3"><span>#include </span><span>&lt;stdlib.h&gt;</span></span>
<span id="cb1-4"></span>
<span id="cb1-5"><span>void</span> dump<span>(</span><span>const</span> <span>uint8_t</span><span>*</span> screen<span>)</span> <span>{</span></span>
<span id="cb1-6">    <span>const</span> <span>uint8_t</span><span>*</span> s <span>=</span> screen<span>;</span></span>
<span id="cb1-7">    <span>for</span> <span>(</span><span>int</span> y <span>=</span> <span>0</span><span>;</span> y <span>&lt;</span> <span>25</span><span>;</span> y<span>++)</span> <span>{</span></span>
<span id="cb1-8">        <span>for</span> <span>(</span><span>int</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> <span>40</span><span>;</span> x<span>++,</span> s<span>++)</span> <span>{</span></span>
<span id="cb1-9">            printf<span>(</span><span>"</span><span>%c</span><span>"</span><span>,</span> <span>*</span>s <span>==</span> <span>0xa0</span> <span>?</span> <span>'#'</span> <span>:</span> <span>'.'</span><span>);</span></span>
<span id="cb1-10">        <span>}</span></span>
<span id="cb1-11">        printf<span>(</span><span>"</span><span>\n</span><span>"</span><span>);</span></span>
<span id="cb1-12">    <span>}</span></span>
<span id="cb1-13"><span>}</span></span>
<span id="cb1-14"></span>
<span id="cb1-15"><span>void</span> setreg<span>(</span><span>uintptr_t</span> dst<span>,</span> <span>uint8_t</span> v<span>)</span> <span>{</span></span>
<span id="cb1-16"><span>//  *((uint8_t *)dst) = v;</span></span>
<span id="cb1-17"><span>}</span></span>
<span id="cb1-18"></span>
<span id="cb1-19"><span>int</span> main<span>()</span> <span>{</span></span>
<span id="cb1-20"><span>//  uint8_t* screenRAM = (uint_8*)0x0400;</span></span>
<span id="cb1-21">    <span>uint8_t</span><span>*</span> screenRAM <span>=</span> <span>(</span><span>uint8_t</span> <span>*)</span>calloc<span>(</span><span>40</span><span>*</span><span>25</span><span>,</span> <span>0x20</span><span>);</span></span>
<span id="cb1-22"></span>
<span id="cb1-23">    setreg<span>(</span><span>0xd020</span><span>,</span> <span>0</span><span>);</span> <span>// Set border color</span></span>
<span id="cb1-24">    setreg<span>(</span><span>0xd021</span><span>,</span> <span>0</span><span>);</span> <span>// Set background color</span></span>
<span id="cb1-25"></span>
<span id="cb1-26">    <span>int</span> yslope <span>=</span> <span>(</span><span>25</span><span>&lt;&lt;</span><span>8</span><span>)/</span><span>40</span><span>;</span></span>
<span id="cb1-27">    <span>int</span> yf <span>=</span> yslope<span>/</span><span>2</span><span>;</span></span>
<span id="cb1-28">    <span>for</span> <span>(</span><span>int</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> <span>40</span><span>;</span> x<span>++)</span> <span>{</span></span>
<span id="cb1-29">        <span>int</span> yi <span>=</span> yf <span>&gt;&gt;</span> <span>8</span><span>;</span></span>
<span id="cb1-30">        <span>// First line</span></span>
<span id="cb1-31">        screenRAM<span>[</span>x <span>+</span> yi<span>*</span><span>40</span><span>]</span> <span>=</span> <span>0xa0</span><span>;</span></span>
<span id="cb1-32">        <span>// Second line (X-mirrored)</span></span>
<span id="cb1-33">        screenRAM<span>[(</span><span>39</span><span>-</span>x<span>)</span> <span>+</span> yi<span>*</span><span>40</span><span>]</span> <span>=</span> <span>0xa0</span><span>;</span></span>
<span id="cb1-34">        yf <span>+=</span> yslope<span>;</span></span>
<span id="cb1-35">    <span>}</span></span>
<span id="cb1-36"></span>
<span id="cb1-37">    dump<span>(</span>screenRAM<span>);</span></span>
<span id="cb1-38"><span>}</span></span></code></pre></div>
<p>The screen codes used above are: <code>$20</code> (blank) and <code>$a0</code> (8x8 filled block). If you run it, you should see ASCII art for the two lines:</p>
<pre><code>##....................................##
..#..................................#..
...##..............................##...
.....#............................#.....
......##........................##......
........##....................##........
..........#..................#..........
...........##..............##...........
.............#............#.............
..............##........##..............
................##....##................
..................#..#..................
...................##...................
..................#..#..................
................##....##................
..............##........##..............
.............#............#.............
...........##..............##...........
..........#..................#..........
........##....................##........
......##........................##......
.....#............................#.....
...##..............................##...
..#..................................#..
##....................................##</code></pre>
<p>Using 6502 assembly and assembly pseudos, we can trivially implement the same in assembly:</p>
<div id="cb3"><pre><code><span id="cb3-1">!<span>include</span> <span>"c64.asm"</span></span>
<span id="cb3-2"></span>
<span id="cb3-3">+c64<span>::</span>basic_start<span>(</span>entry<span>)</span></span>
<span id="cb3-4"></span>
<span id="cb3-5"><span>entry:</span> <span>{</span></span>
<span id="cb3-6">    lda <span>#</span><span>0</span>      <span>; black color</span></span>
<span id="cb3-7">    sta <span>$</span>d020   <span>; set border to 0</span></span>
<span id="cb3-8">    sta <span>$</span>d021   <span>; set background to 0</span></span>
<span id="cb3-9"></span>
<span id="cb3-10">    <span>; clear the screen</span></span>
<span id="cb3-11">    ldx <span>#</span><span>0</span></span>
<span id="cb3-12">    lda <span>#$</span><span>20</span></span>
<span id="cb3-13"><span>clrscr:</span></span>
<span id="cb3-14">!for i in <span>[</span><span>0</span><span>,</span> <span>$</span><span>100</span><span>,</span> <span>$</span><span>200</span><span>,</span> <span>$</span><span>300</span><span>]</span> <span>{</span></span>
<span id="cb3-15">    sta <span>$</span><span>0400</span> <span>+</span> i<span>,</span> x</span>
<span id="cb3-16"><span>}</span></span>
<span id="cb3-17">    inx</span>
<span id="cb3-18">    bne clrscr</span>
<span id="cb3-19"></span>
<span id="cb3-20">    <span>; line drawing, completely unrolled</span></span>
<span id="cb3-21">    <span>; with assembly pseudos</span></span>
<span id="cb3-22">    lda <span>#$</span>a0</span>
<span id="cb3-23"></span>
<span id="cb3-24">    !for i in range<span>(</span><span>40</span><span>)</span> <span>{</span></span>
<span id="cb3-25">        !let y0 <span>=</span> Math<span>.</span>floor<span>(</span><span>25</span><span>/</span><span>40</span><span>*(</span>i<span>+</span><span>0.5</span><span>))</span></span>
<span id="cb3-26">        sta <span>$</span><span>0400</span> <span>+</span> y0<span>*</span><span>40</span> <span>+</span> i</span>
<span id="cb3-27">        sta <span>$</span><span>0400</span> <span>+</span> <span>(</span><span>24</span><span>-</span>y0<span>)*</span><span>40</span> <span>+</span> i</span>
<span id="cb3-28">    <span>}</span></span>
<span id="cb3-29"><span>inf:</span> <span>jmp</span> inf  <span>; halt</span></span>
<span id="cb3-30"><span>}</span></span></code></pre></div>
<p>This completely unrolls the line drawing part resulting in a fairly large 286 byte PRG.</p>
<p>Before diving into optimized variants, let’s make a couple of observations:</p>
<p>First, we’re running on the C64 with the ROM routines banked in. There’s a bunch of subroutines in ROM that may be useful for our little program. For example, you can clear the screen with <code>JSR $E544</code>.</p>
<p>Second, address calculations on an 8-bit CPU like the 6502 can be cumbersome and cost a lot of bytes. This CPU also doesn’t have a multiplier, so computing something like <code>y*40+i</code> usually involves either a bunch of logical shifts or a lookup table, again costing bytes. To avoid multiplying by 40, we can instead advance the screen pointer incrementally:</p>
<div id="cb4"><pre><code><span id="cb4-1">    <span>int</span> yslope <span>=</span> <span>(</span><span>25</span><span>&lt;&lt;</span><span>8</span><span>)/</span><span>40</span><span>;</span></span>
<span id="cb4-2">    <span>int</span> yf <span>=</span> yslope<span>/</span><span>2</span><span>;</span></span>
<span id="cb4-3">    <span>uint8_t</span><span>*</span> dst <span>=</span> screenRAM<span>;</span></span>
<span id="cb4-4">    <span>for</span> <span>(</span><span>int</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> <span>40</span><span>;</span> x<span>++)</span> <span>{</span></span>
<span id="cb4-5">        dst<span>[</span>x<span>]</span> <span>=</span> <span>0xa0</span><span>;</span></span>
<span id="cb4-6">        dst<span>[(</span><span>39</span><span>-</span>x<span>)]</span> <span>=</span> <span>0xa0</span><span>;</span></span>
<span id="cb4-7">        yf <span>+=</span> yslope<span>;</span></span>
<span id="cb4-8">        <span>if</span> <span>(</span>yf <span>&amp;</span> <span>256</span><span>)</span> <span>{</span> <span>// Carry set?</span></span>
<span id="cb4-9">            dst <span>+=</span> <span>40</span><span>;</span></span>
<span id="cb4-10">            yf <span>&amp;=</span> <span>255</span><span>;</span></span>
<span id="cb4-11">        <span>}</span></span>
<span id="cb4-12">    <span>}</span></span></code></pre></div>
<p>We keep adding the line slope to a fixed point counter <code>yf</code> and when the 8-bit addition sets the carry flag, add 40.</p>
<p>Here’s the incremental approach implemented in assembly:</p>
<div id="cb5"><pre><code><span id="cb5-1">!<span>include</span> <span>"c64.asm"</span></span>
<span id="cb5-2"></span>
<span id="cb5-3">+c64<span>::</span>basic_start<span>(</span>entry<span>)</span></span>
<span id="cb5-4"></span>
<span id="cb5-5">!let screenptr <span>=</span> <span>$</span><span>20</span></span>
<span id="cb5-6">!let x0 <span>=</span> <span>$</span><span>40</span></span>
<span id="cb5-7">!let x1 <span>=</span> <span>$</span><span>41</span></span>
<span id="cb5-8">!let yf <span>=</span> <span>$</span><span>60</span></span>
<span id="cb5-9"></span>
<span id="cb5-10"><span>entry:</span> <span>{</span></span>
<span id="cb5-11">        lda <span>#</span><span>0</span></span>
<span id="cb5-12">        sta x0</span>
<span id="cb5-13">        sta <span>$</span>d020</span>
<span id="cb5-14">        sta <span>$</span>d021</span>
<span id="cb5-15"></span>
<span id="cb5-16">        <span>; kernal clear screen</span></span>
<span id="cb5-17">        jsr <span>$</span>e544</span>
<span id="cb5-18"></span>
<span id="cb5-19">        <span>; set screenptr = $0400</span></span>
<span id="cb5-20">        lda <span>#&lt;$</span><span>0400</span></span>
<span id="cb5-21">        sta screenptr<span>+</span><span>0</span></span>
<span id="cb5-22">        lda <span>#&gt;$</span><span>0400</span></span>
<span id="cb5-23">        sta screenptr<span>+</span><span>1</span></span>
<span id="cb5-24"></span>
<span id="cb5-25">        lda <span>#</span><span>80</span></span>
<span id="cb5-26">        sta yf</span>
<span id="cb5-27"></span>
<span id="cb5-28">        lda <span>#</span><span>39</span></span>
<span id="cb5-29">        sta x1</span>
<span id="cb5-30"><span>xloop:</span></span>
<span id="cb5-31">        lda <span>#$</span>a0</span>
<span id="cb5-32">        ldy x0</span>
<span id="cb5-33">        <span>; screenRAM[x] = 0xA0</span></span>
<span id="cb5-34">        sta <span>(</span>screenptr<span>),</span> y</span>
<span id="cb5-35">        ldy x1</span>
<span id="cb5-36">        <span>; screenRAM[39-x] = 0xA0</span></span>
<span id="cb5-37">        sta <span>(</span>screenptr<span>),</span> y</span>
<span id="cb5-38"></span>
<span id="cb5-39">        <span>clc</span></span>
<span id="cb5-40">        lda <span>#</span><span>160</span>  <span>; line slope</span></span>
<span id="cb5-41">        <span>adc</span> yf</span>
<span id="cb5-42">        sta yf</span>
<span id="cb5-43">        bcc no_add</span>
<span id="cb5-44"></span>
<span id="cb5-45">        <span>; advance screen ptr by 40</span></span>
<span id="cb5-46">        <span>clc</span></span>
<span id="cb5-47">        lda screenptr</span>
<span id="cb5-48">        <span>adc</span> <span>#</span><span>40</span></span>
<span id="cb5-49">        sta screenptr</span>
<span id="cb5-50">        lda screenptr<span>+</span><span>1</span></span>
<span id="cb5-51">        <span>adc</span> <span>#</span><span>0</span></span>
<span id="cb5-52">        sta screenptr<span>+</span><span>1</span></span>
<span id="cb5-53"></span>
<span id="cb5-54"><span>no_add:</span></span>
<span id="cb5-55">        <span>inc</span> x0</span>
<span id="cb5-56">        <span>dec</span> x1</span>
<span id="cb5-57">        bpl xloop</span>
<span id="cb5-58"></span>
<span id="cb5-59"><span>inf:</span>    <span>jmp</span> inf</span>
<span id="cb5-60"><span>}</span></span></code></pre></div>
<p>At 82 bytes, this is still pretty hefty. A couple of obvious size problems arise from 16-bit address computations:</p>
<p>Setting up the <code>screenptr</code> value for indirect-indexed addressing:</p>
<div id="cb6"><pre><code><span id="cb6-1">        <span>; set screenptr = $0400</span></span>
<span id="cb6-2">        lda <span>#&lt;$</span><span>0400</span></span>
<span id="cb6-3">        sta screenptr<span>+</span><span>0</span></span>
<span id="cb6-4">        lda <span>#&gt;$</span><span>0400</span></span>
<span id="cb6-5">        sta screenptr<span>+</span><span>1</span></span></code></pre></div>
<p>Advancing <code>screenptr</code> to the next row by adding 40:</p>
<div id="cb7"><pre><code><span id="cb7-1">        <span>; advance screen ptr by 40</span></span>
<span id="cb7-2">        <span>clc</span></span>
<span id="cb7-3">        lda screenptr</span>
<span id="cb7-4">        <span>adc</span> <span>#</span><span>40</span></span>
<span id="cb7-5">        sta screenptr</span>
<span id="cb7-6">        lda screenptr<span>+</span><span>1</span></span>
<span id="cb7-7">        <span>adc</span> <span>#</span><span>0</span></span>
<span id="cb7-8">        sta screenptr<span>+</span><span>1</span></span></code></pre></div>
<p>Sure this code could probably be made smaller but what if we didn’t need manipulate 16-bit addresses in the first place? Let’s see this can be avoided.</p>
<h3 id="trick-1-scrolling">Trick 1: Scrolling!</h3>
<p>Instead of plotting the line across the screen RAM, we draw only on the last Y=24 screen row, and scroll the whole screen up by calling a “scroll up” ROM function with <code>JSR $E8EA</code>!</p>
<p>The x-loop becomes:</p>
<div id="cb8"><pre><code><span id="cb8-1">        lda <span>#</span><span>0</span></span>
<span id="cb8-2">        sta x0</span>
<span id="cb8-3">        lda <span>#</span><span>39</span></span>
<span id="cb8-4">        sta x1</span>
<span id="cb8-5"><span>xloop:</span></span>
<span id="cb8-6">        lda <span>#$</span>a0</span>
<span id="cb8-7">        ldx x0</span>
<span id="cb8-8">        <span>; hardcoded absolute address to last screen line</span></span>
<span id="cb8-9">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb8-10">        ldx x1</span>
<span id="cb8-11">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb8-12"></span>
<span id="cb8-13">        <span>adc</span> yf</span>
<span id="cb8-14">        sta yf</span>
<span id="cb8-15">        bcc no_scroll</span>
<span id="cb8-16">        <span>; scroll screen up!</span></span>
<span id="cb8-17">        jsr <span>$</span>e8ea</span>
<span id="cb8-18"><span>no_scroll:</span></span>
<span id="cb8-19">        <span>inc</span> x0</span>
<span id="cb8-20">        <span>dec</span> x1</span>
<span id="cb8-21">        bpl xloop</span></code></pre></div>
<p>Here’s how the line renderer progresses with this trick:</p>
<p><img width="75%" src="https://nurpax.github.io/images/c64/lines/lines-scroll.gif">
</p>
<p>This trick was one of my favorites in this compo. It was also independently discovered by pretty much every participant.</p>
<h3 id="trick-2-self-modifying-code">Trick 2: Self-modifying code</h3>
<p>The code to store the pixel values ends up being roughly:</p>
<div id="cb9"><pre><code><span id="cb9-1">        ldx x1</span>
<span id="cb9-2">        <span>; hardcoded absolute address to last screen line</span></span>
<span id="cb9-3">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb9-4">        ldx x0</span>
<span id="cb9-5">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb9-6">        <span>inc</span> x0</span>
<span id="cb9-7">        <span>dec</span> x1</span></code></pre></div>
<p>This encodes into the following 14 byte sequence:</p>
<pre><code>0803: A6 22               LDX $22
0805: 9D C0 07            STA $07C0,X
0808: A6 20               LDX $20
080A: 9D C0 07            STA $07C0,X
080D: E6 22               INC $22
080F: C6 20               DEC $20</code></pre>
<p>There’s a more compact way to write this using self-modifying code (SMC)..</p>
<div id="cb11"><pre><code><span id="cb11-1">        ldx x1</span>
<span id="cb11-2">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb11-3"><span>addr0:</span>  sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span></span>
<span id="cb11-4">        <span>; advance the second x-coord with SMC</span></span>
<span id="cb11-5">        <span>inc</span> addr0<span>+</span><span>1</span></span>
<span id="cb11-6">        <span>dec</span> x1</span></code></pre></div>
<p>..which encodes to 13 bytes:</p>
<pre><code>0803: A6 22               LDX $22
0805: 9D C0 07            STA $07C0,X
0808: 8D C0 07            STA $07C0
080B: EE 09 08            INC $0809
080E: C6 22               DEC $22</code></pre>
<h3 id="trick-3-exploiting-the-power-on-state">Trick 3: Exploiting the power on state</h3>
<p>Making wild assumptions about the running environment was considered OK in this compo: the line drawing PRG is the first thing that’s run after C64 power on, and there was no requirement to exit cleanly back to the BASIC prompt. So anything you find from the initial environment upon entry to your PRG, you can and should use to your advantage. Here are some of the things that were considered “constant” upon entry to the PRG:</p>
<ul>
<li>A, X, Y registers were assumed to be all zeros</li>
<li>All CPU flags cleared</li>
<li>Zeropage (addresses <code>$00</code>-<code>$ff</code>) contents</li>
</ul>
<p>Similarly, if you called any KERNAL ROM routines, you could totally take advantage of any side-effects they might have: returned CPU flags, temporary values set into zeropage, etc.</p>
<p>After the first few size-optimization passes, everyone turned their eyes on this machine monitor view to look for any interesting values:</p>
<p><img src="https://nurpax.github.io/images/c64/lines/monitor-screenshot.png">
</p>
<p>The zeropage indeed contains some useful values for our purposes:</p>
<ul>
<li><code>$d5</code>: 39/$27 == line length - 1</li>
<li><code>$22</code>: 64/$40 == initial value for line slope counter</li>
</ul>
<p>You can use these to shave off a few bytes at init time. For example:</p>
<div id="cb13"><pre><code><span id="cb13-1">!let x0 <span>=</span> <span>$</span><span>20</span></span>
<span id="cb13-2">        lda <span>#</span><span>39</span>      <span>; 0801: A9 27    LDA #$27</span></span>
<span id="cb13-3">        sta x0       <span>; 0803: 85 20    STA $20</span></span>
<span id="cb13-4"><span>xloop:</span></span>
<span id="cb13-5">        <span>dec</span> x0       <span>; 0805: C6 20    DEC $20</span></span>
<span id="cb13-6">        bpl xloop    <span>; 0807: 10 FC    BPL $0805</span></span></code></pre></div>
<p>As <code>$d5</code> contains a value 39, you can map your <code>x0</code> counter to point to <code>$d5</code> and skip the LDA/STA pair:</p>
<div id="cb14"><pre><code><span id="cb14-1">!let x0 <span>=</span> <span>$</span>d5</span>
<span id="cb14-2">        <span>; nothing here!</span></span>
<span id="cb14-3"><span>xloop:</span></span>
<span id="cb14-4">        <span>dec</span> x0       <span>; 0801: C6 D5    DEC $D5</span></span>
<span id="cb14-5">        bpl xloop    <span>; 0803: 10 FC    BPL $0801</span></span></code></pre></div>
<p>Philip’s <a href="https://github.com/fsphil/tinyx/blob/master/x34/x34.s">winning entry</a> takes this to the extreme. Recall the address of the last char row <code>$07C0</code> (==<code>$0400+24*40</code>). This value does not exist in the zeropage on init. However, as a side-effect of how the ROM “scroll up” subroutine uses zeropage temporaries, addresses <code>$D1-$D2</code> will contain <code>$07C0</code> on return from this function. So instead of <code>STA $07C0,x</code> to store a pixel, you can use the one byte shorter indirect-indexed addressing mode store <code>STA ($D1),y</code>.</p>
<h3 id="trick-4-smaller-startup">Trick 4: Smaller startup</h3>
<p>A typical C64 PRG binary file contains the following:</p>
<ul>
<li>First 2 bytes: loading address (usually <code>$0801</code>)</li>
<li>12 bytes of BASIC startup sequence</li>
</ul>
<p>The BASIC startup sequence looks like this (addresses <code>$801-$80C</code>):</p>
<pre><code>0801: 0B 08 0A 00 9E 32 30 36 31 00 00 00
080D: 8D 20 D0     STA $D020</code></pre>
<p>Without going into details about <a href="https://www.c64-wiki.com/wiki/BASIC_token">tokenized BASIC memory layout</a>, this sequence more or less amounts to “10 SYS 2061”. Address <code>2061</code> (<code>$080D</code>) is where our actual machine code program starts when the BASIC interpreter executes the SYS command.</p>
<p>14 bytes just to get going feels excessive. Philip, Mathlev and Geir had used some clever tricks to get rid of the BASIC sequence altogether. This requires that the PRG is loaded with <code>LOAD "*",8,1</code> as <code>LOAD "*",8</code> ignores the PRG loading address (the first two bytes) and always loads to <code>$0801</code>.</p>
<p><img width="75%" src="https://nurpax.github.io/images/c64/lines/vice-screen-sys.png">
</p>
<p>Two methods were used:</p>
<ul>
<li>The stack trick</li>
<li>The BASIC warm reset vector trick</li>
</ul>
<h4 id="the-stack-trick">The stack trick</h4>
<p>The trick is to stomp the CPU stack at <code>$01F8</code> with a value that points to our desired entry point. This is done by crafting a PRG that starts with a 16-bit pointer pointing to our code and loading the PRG into <code>$01F8</code>:</p>
<div id="cb16"><pre><code><span id="cb16-1">    * = $01F8</span>
<span id="cb16-2">    !<span>word</span> scroll <span>-</span> <span>1</span>  <span>; overwrite stack</span></span>
<span id="cb16-3"></span>
<span id="cb16-4"><span>scroll:</span>	jsr <span>$</span>E8EA</span></code></pre></div>
<p>Once the BASIC loader (see <a href="https://www.pagetable.com/c64disasm/#F4A5">disassembly</a>) has finished loading and returns to its caller with <code>RTS</code>, instead of returning to whoever called LOAD, it returns right into our PRG.</p>
<h4 id="the-basic-warm-reset-vector-trick">The BASIC warm reset vector trick</h4>
<p>This is a little easier to explain by just looking at the PRG disassembly.</p>
<pre><code>02E6: 20 EA E8    JSR $E8EA
02E9: A4 D5       LDY $D5
02EB: A9 A0       LDA #$A0
02ED: 99 20 D0    STA $D020,Y
02F0: 91 D1       STA ($D1),Y
02F2: 9D B5 07    STA $07B5,X
02F5: E6 D6       INC $D6
02F7: 65 90       ADC $90
02F9: 85 90       STA $90
02FB: C6 D5       DEC $D5
02FD: 30 FE       BMI $02FD
02FF: 90 E7       BCC $02E8
0301: 4C E6 02    JMP $02E6</code></pre>
<p>Notice the last line (<code>JMP $02E6</code>). The JMP instruction starts at address <code>$0301</code> with the branch target stored in addresses <code>$0302-$0303</code>.</p>
<p>When this code is loaded into memory starting at address <code>$02E6</code>, a value of <code>$02E6</code> is written to addresses <code>$0302-$0303</code>. Well, location <code>$0302-$0303</code> has a special meaning: it contains a pointer to the “BASIC idle loop” (see <a href="http://sta.c64.org/cbm64mem.html">C64 memory map</a> for details). Loading the PRG overwrote this location with <code>$02E6</code> and so when the BASIC interpreter tries to jump to the idle loop after warm reset, it never enters the idle loop but instead ends up in the line renderer!</p>

<p>Petri had discovered <a href="https://github.com/petrihakkinen/c64-lines/blob/master/main37.asm">another BASIC start trick</a> which allows injecting your own constants into the zeropage. In this method, you hand-craft your own tokenized BASIC start sequence and encode your constants into the BASIC program line number. The BASIC line number, ahem, your constants, will be stored in addresses <code>$39-$3A</code> upon entry. Very clever!</p>
<h3 id="trick-5-unconventional-control-flow">Trick 5: Unconventional control flow</h3>
<p>Here’s a somewhat simplified version of the x-loop that draws only a single line and then halts execution once the line is done:</p>
<div id="cb18"><pre><code><span id="cb18-1">        lda <span>#</span><span>39</span></span>
<span id="cb18-2">        sta x1</span>
<span id="cb18-3"><span>xloop:</span></span>
<span id="cb18-4">        lda <span>#$</span>a0</span>
<span id="cb18-5">        ldx x1</span>
<span id="cb18-6">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb18-7"></span>
<span id="cb18-8">        <span>adc</span> yf</span>
<span id="cb18-9">        sta yf</span>
<span id="cb18-10">        bcc no_scroll</span>
<span id="cb18-11">        <span>; scroll screen up!</span></span>
<span id="cb18-12">        jsr <span>$</span>e8ea</span>
<span id="cb18-13"><span>no_scroll:</span></span>
<span id="cb18-14">        <span>dec</span> x1</span>
<span id="cb18-15">        bpl xloop</span>
<span id="cb18-16"></span>
<span id="cb18-17">        <span>; intentionally halt at the end</span></span>
<span id="cb18-18"><span>inf:</span>    <span>jmp</span> inf</span></code></pre></div>
<p>This has a bug in it, though. When we’ve drawn the last pixel of a line, we should NOT scroll the screen up anymore. Thus we need more branching to skip scrolling on the last pixel write:</p>
<div id="cb19"><pre><code><span id="cb19-1">        lda <span>#</span><span>39</span></span>
<span id="cb19-2">        sta x1</span>
<span id="cb19-3"><span>xloop:</span></span>
<span id="cb19-4">        lda <span>#$</span>a0</span>
<span id="cb19-5">        ldx x1</span>
<span id="cb19-6">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb19-7"></span>
<span id="cb19-8">        <span>dec</span> x1</span>
<span id="cb19-9">        <span>; skip scrolling if last pixel</span></span>
<span id="cb19-10">        bmi done</span>
<span id="cb19-11"></span>
<span id="cb19-12">        <span>adc</span> yf</span>
<span id="cb19-13">        sta yf</span>
<span id="cb19-14">        bcc no_scroll</span>
<span id="cb19-15">        <span>; scroll screen up!</span></span>
<span id="cb19-16">        jsr <span>$</span>e8ea</span>
<span id="cb19-17"><span>no_scroll:</span></span>
<span id="cb19-18">        <span>jmp</span> xloop</span>
<span id="cb19-19"><span>done:</span></span>
<span id="cb19-20"></span>
<span id="cb19-21">        <span>; intentionally halt at the end</span></span>
<span id="cb19-22"><span>inf:</span>    <span>jmp</span> inf</span></code></pre></div>
<p>The control flow looks a lot like what a C compiler would output from a structured program. The code to skip the last scroll introduced a new <code>JMP abs</code> instruction that takes up 3 bytes. Conditional branches are only two bytes as they encode the branch target using a relative 8-bit immediate.</p>
<p>The “skip last scroll” JMP can be avoided by moving the scroll up call to the top of the loop, and restructuring the control flow a bit. This is the pattern Philip had come up with:</p>
<div id="cb20"><pre><code><span id="cb20-1">        lda <span>#</span><span>39</span></span>
<span id="cb20-2">        sta x1</span>
<span id="cb20-3"><span>scroll:</span> jsr <span>$</span>e8ea</span>
<span id="cb20-4"><span>xloop:</span></span>
<span id="cb20-5">        lda <span>#$</span>a0</span>
<span id="cb20-6">        ldx x1</span>
<span id="cb20-7">        sta <span>$</span><span>0400</span> <span>+</span> <span>24</span><span>*</span><span>40</span><span>,</span> x</span>
<span id="cb20-8"></span>
<span id="cb20-9">        <span>adc</span> yf</span>
<span id="cb20-10">        sta yf</span>
<span id="cb20-11">        <span>dec</span> x1     <span>; doesn't set carry!</span></span>
<span id="cb20-12"><span>inf:</span>    bmi inf    <span>; hang here if last pixel!</span></span>
<span id="cb20-13">        bcc xloop  <span>; next pixel if no scroll</span></span>
<span id="cb20-14">        bcs scroll <span>; scroll up and continue</span></span></code></pre></div>
<p>This completely eliminates one 3 byte JMP and converts another JMP to a 2 byte conditional branch, saving 4 bytes in total.</p>
<h3 id="trick-6-bitpacked-line-drawing">Trick 6: Bitpacked line drawing</h3>
<p>Some of the entries didn’t use a line slope counter but rather they had bit-packed the line pattern into an 8-bit constant. This packing comes out of a realisation that the pixel position along the line follows a repeating 8 pixel pattern:</p>
<div id="cb21"><pre><code><span id="cb21-1"><span>int</span> mask <span>=</span> <span>0xB6</span><span>;</span> <span>// 10110110</span></span>
<span id="cb21-2"><span>uint8_t</span><span>*</span> dst <span>=</span> screenRAM<span>;</span></span>
<span id="cb21-3"><span>for</span> <span>(</span><span>int</span> x <span>=</span> <span>0</span><span>;</span> x <span>&lt;</span> <span>40</span><span>;</span> x<span>++)</span> <span>{</span></span>
<span id="cb21-4">    dst<span>[</span>x<span>]</span> <span>=</span> <span>0xA0</span><span>;</span></span>
<span id="cb21-5">    <span>if</span> <span>(</span>mask <span>&amp;</span> <span>(</span><span>1</span> <span>&lt;&lt;</span> <span>(</span>x<span>&amp;</span><span>7</span><span>)))</span> <span>{</span></span>
<span id="cb21-6">        dst <span>+=</span> <span>40</span><span>;</span> <span>// go down a row</span></span>
<span id="cb21-7">    <span>}</span></span>
<span id="cb21-8"><span>}</span></span></code></pre></div>
<p>This translates to pretty compact assembly. The slope counter variants tended to be even smaller, though.</p>
<h3 id="winner-entry">Winner entry</h3>
<p>This is the <a href="https://github.com/fsphil/tinyx/blob/master/x34/x34.s">winning 34 byte entry</a> from Philip. Most of the above really comes together nicely in his code:</p>
<div id="cb22"><pre><code><span id="cb22-1">ov <span>=</span> <span>$</span><span>22</span> <span>; == $40, initial value for the overflow counter</span></span>
<span id="cb22-2">ct <span>=</span> <span>$</span>D5 <span>; == $27 / 39, number of passes. Decrementing, finished at -1</span></span>
<span id="cb22-3">lp <span>=</span> <span>$</span>D1 <span>; == $07C0, pointer to bottom line. Set by the kernal scroller</span></span>
<span id="cb22-4"></span>
<span id="cb22-5">        <span>; Overwrite the return address of the kernal loader on the stack</span></span>
<span id="cb22-6">        <span>; with a pointer to our own code</span></span>
<span id="cb22-7"></span>
<span id="cb22-8">        * = $01F8</span>
<span id="cb22-9">        .<span>word</span> scroll <span>-</span> <span>1</span></span>
<span id="cb22-10"></span>
<span id="cb22-11"><span>scroll:</span> jsr <span>$</span>E8EA    <span>; Kernal scroll up, also sets lp pointer to $07C0</span></span>
<span id="cb22-12"><span>loop:</span>   ldy ct	     <span>; Load the decrementing counter into Y (39 &gt; -1)</span></span>
<span id="cb22-13">        lda <span>#$</span>A0     <span>; Load the PETSCII block / black col / ov step value</span></span>
<span id="cb22-14">        sta <span>$</span>D020<span>,</span> y <span>; On the last two passes, sets the background black</span></span>
<span id="cb22-15"><span>p1:</span>     sta <span>$</span><span>07C0</span>    <span>; Draw first block (left &gt; right line)</span></span>
<span id="cb22-16">        sta <span>(</span>lp<span>),</span> y  <span>; Draw second block (right &gt; left line)</span></span>
<span id="cb22-17">        <span>inc</span> p1 <span>+</span> <span>1</span>   <span>; Increment pointer for the left &gt; right line</span></span>
<span id="cb22-18">        <span>adc</span> ov	     <span>; Add step value $A0 to ov</span></span>
<span id="cb22-19">        sta ov</span>
<span id="cb22-20">        <span>dec</span> ct	     <span>; Decrement the Y counter</span></span>
<span id="cb22-21">        bmi <span>*</span>	     <span>; If it goes negative, we're finished</span></span>
<span id="cb22-22">        bcc loop     <span>; Repeat. If ov didn't overflow, don't scroll</span></span>
<span id="cb22-23">        bcs scroll   <span>; Repeat. If ov overflowed, scroll</span></span></code></pre></div>
<h3 id="why-stop-at-34-bytes-though">Why stop at 34 bytes, though?</h3>
<p>Once the competition was over, everyone shared code and notes, and a number of lively conversations took place on how to do even better. Several smaller variants were posted after the deadline:</p>
<ul>
<li><a href="https://gist.github.com/fsphil/05deaa06804b9b2054260b616cafed4b">Philip - 33 bytes</a></li>
<li><a href="https://gist.github.com/fsphil/01bda1a9dd58c219002ddd6e18b36c3f">Philip - 32 bytes</a></li>
<li><a href="https://github.com/petrihakkinen/c64-lines/blob/master/main31.asm">Petri - 31 bytes</a></li>
<li><a href="https://gist.github.com/fsphil/7655a394ec5f953c910e9d9369dced56">Philip - 29 bytes</a></li>
</ul>
<p>You should check them out – there are some real gems to be found.</p>
<p>…</p>
<p>Thanks for reading. And most of all, thanks Mathlev, Phil, Geir, Petri, Jamie, Jan and David for your participation. (I hope I didn’t miss anyone – it was really difficult to keep track of these in Twitter mentions!)</p>
<p>PS. Petri had named my compo “<span data-cites="nurpax">@nurpax</span>’s annual C64 size optimization compo”, so uhm, see you next year, I guess.</p>


</article>


        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Reproducing Hacker News writing style fingerprinting (308 pts)]]></title>
            <link>https://antirez.com/news/150</link>
            <guid>43705632</guid>
            <pubDate>Wed, 16 Apr 2025 13:57:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://antirez.com/news/150">https://antirez.com/news/150</a>, See on <a href="https://news.ycombinator.com/item?id=43705632">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article data-comment-id="150-" id="150-"><span><span><a href="https://antirez.com/user/antirez">antirez</a></span> 20 hours ago. 44684 views.  </span><pre>About three years ago I saw a quite curious and interesting post on Hacker News. A student, Christopher Tarry, was able to use cosine similarity against a vector of top words frequencies in comments, in order to detect similar HN accounts — and, sometimes, even accounts actually controlled by the same user, that is, fake accounts used to uncover the identity of the writer.

This is the original post: <a rel="nofollow" href="https://news.ycombinator.com/item?id=33755016">https://news.ycombinator.com/item?id=33755016</a>

I was not aware, back then, of Burrows-Delta method for style detection: it seemed kinda magical that you just needed to normalize a frequency vector of top words to reach such quite remarkable results. I read a few wikipedia pages and took mental note of it. Then, as I was working with Vectors for Redis I remembered about this post, searched the web only to discover that the original page was gone and that the author, in the original post and website, didn’t really explained very well how the data was processed, the top words extracted (and, especially, how many were used) and so forth. I thought I could reproduce the work with Vector Sets, once I was done with the main work. Now the new data type is in the release candidate, and I found some time to work on the problem. This is a report of what I did, but before to continue, the mandatory demo site: you can play with it at the following link:

<a rel="nofollow" href="https://antirez.com/hnstyle?username=pg&amp;threshold=20&amp;action=search">https://antirez.com/hnstyle?username=pg&amp;threshold=20&amp;action=search</a>

NOTE: since the dataset takes 700MB of RAM, in my tiny server, in the next months I may take this down. However, later in this post you will find the link and the Github repository with the code to reproduce everything from scratch.

NOTE2: I hope the web site will survive, it's a very crude Python script. I benchmarked the VSIM command in such a small server and yet it can deliver 80k VSIM per second! The wonders of int8 quantization, together with a few more optimizations. But the Python script is terrible, creates a new Redis connection each time and so forth. Fingers crossed.

# Raw data download and processing

Well, the first problem I had, in order to do something like that, was to find an archive with Hacker News comments. Luckily there was one with apparently everything posted on HN from the start to 2023, for a huge 10GB of total data. You can find it here: <a rel="nofollow" href="https://huggingface.co/datasets/OpenPipe/hacker-news">https://huggingface.co/datasets/OpenPipe/hacker-news</a> and, honestly, I’m not really sure how this was obtained, if using scarping or if HN makes this data public in some way.

Since I’m not a big fan of binary files, in the specific case of public datasets at least, I used two Python scripts in order to convert the Parquet files into something smaller and simpler to handle. The first script, gen-top-words.py, takes the binary files and generates a txt file with the list of the top N words used in the dataset. It generates 10k words by default, but for the statistical analysis a lot less are needed (or, actually: if you use too many words you no longer capture the style, but the kind of content a user is talking about!). Then, another Python script, accumulates all the comments for each single user and generates a very big JSONL file where there are just two keys: the user name and the frequency table of all the words used by a given user in all the history from HN starts to 2023. Each entry is like that:

{"by": "rtghrhtr", "freqtab": {"everyone": 1, "hates": 1, "nvidia": 1, "but": 1, "treats": 1, "ati": 1, "as": 1, "an": 1, "afterthought": 1, "another": 1, "completely": 1, "useless": 1, "tool": 1, "to": 1, "throw": 1, "on": 1, "the": 1, "pile": 1}}

At this point, the final script, insert.py, could do all the real work: to apply the Borrows method for each user, create the user style vector, and insert it into Redis. The advantage of pre-processing the files (a slow operation) is that the insertion script could be called more easily with different parameters (especially the number of top words to use) in order to see the different results more promptly, without the need to re-process the Parquet files each time.

# How the Burrow method works?

In the original post, Christopher wrote that you just need to normalize the frequency of the words usage and apply cosine similarity. Actually the process is a bit more involved. First, let’s ask ourselves, how this method actually works, in its essence? Well, it wants to capture words that each specific user over-uses or under-uses compared to the expected “average” language. To do so, we actually use the following steps (from the Python code).

That’s what we do for each of the top words:

# Convert to relative frequency
rel_freq = frequency / total_words

# Standardize using z-score: z = (freq - mean) / stddev
mean = word_means.get(word, 0.0)
stddev = word_stddevs.get(word, 1.0)  # Default to 1.0 to avoid division
by zero

z_score = (rel_freq - mean) / stddev

# Set the z-score directly in the vector at the word's index
vector[word_to_index[word]] = z_score

So we start by “centering” the frequency the user used a given word, by subtracting the *global* usage frequency for that word. This way, we have a number that describes how much the user under (negative) or over (positive) used such word. But, if you think at it, words that have a much higher variance among usage of different writers are less important, when they change. We want to amplify the signal of words that are under of over used by this user in a much greater way compared to the normal variance of the word. This is why we divide the centered frequency by the global standard deviation of the word. Now we have what is called the “z score”, an adjusted measure of how much a given word is an outlier in one or the other direction.

Now, we are ready to insert the word into a Redis vector set, with just:

VADD key FP32 [blob with 350 floats] username

(I’ll not cover the details of vector sets here since you can find the doc here -&gt; <a rel="nofollow" href="https://github.com/redis/redis/blob/unstable/modules/vector-sets/README.md">https://github.com/redis/redis/blob/unstable/modules/vector-sets/README.md</a>)

Note that Redis performs L2 normalization of the inserted vectors, but remembers the L2 value in order to return back the values when VEMB is used to retrieve the associated vector, so the z_score was set as it is.

Finally, with VSIM, we can get similar users:

127.0.0.1:6379&gt; vsim hn_fingerprint ele pg
 1) "pg"
 2) "karaterobot"
 3) "Natsu"
 4) "mattmaroon"
 5) "chc"
 6) "montrose"
 7) "jfengel"
 8) "emodendroket"
 9) "vintermann"
10) "c3534l"

All the code (but the webapp itself) can be found here: <a rel="nofollow" href="https://github.com/antirez/hnstyle">https://github.com/antirez/hnstyle</a>

The README file explains how to reproduce every part.

# Why 350 words?

One of the things missing in the original post that stimulated this blog post, is how many top words one should use. If you use too many words, you’ll see many comments of mine about Redis, since Redis is one of the top 10k words used. Guess what? I did exactly this error, initially, and VSIM continued to report users that talked about similar topics than myself, not with similar *style*. But fortunately the Internet Archive cached the Christopher results for the “pg” account, here:

<a rel="nofollow" href="https://web.archive.org/web/20221126235433/https">https://web.archive.org/web/20221126235433/https</a>://stylometry.net/user?username=pg

So now I could tune my top-k words to get similar results. Also, reading the original papers, I discovered that, with my surprise, for the analysis to work well you need even as little as 150 words. And in general the range from 150 to 500 is considered to be optimal.

Warning: don’t believe that when you search for a user you’ll find mostly fake accounts. For many fake accounts there is too little data, as often people create throw away accounts, write a few comments, and that’s it. So most of the accounts associated with a given user style will be just other people that have a similar writing style. This method I believe is quite powerful in distinguishing who is a native speaker and who is not. This is especially clear from the vectors visualization below.

# Validate and visualize…

Another thing that I reproduced (also an idea from OP) was to try inserting the same users in two variants, like antirez_A and antirez_B, using two different set of comments. Then check if asking for similar users to antirez_A would report B. Indeed, for *most* of the users I tested this against, it worked very well, and often times it was the top result. So we know that actually our method works.

But since from the vectors it is so easy to “see” a style, what about our naked eyes? Recently I switched to Ghostty as my terminal, and it supports the Kitty graphics protocol, so you can display bitmaps directly in the terminal window. It is quite some time I want to play with it. Finally I had a good reason to test this feature.

<img src="http://antirez.com/misc/hnstyle_1.jpg">

What’s happening above is that we call the VEMB command, that returns just a list of floats (the vector).
Then the vshow utility, also part of the repository, will care to find the smallest square that can contain the vector and show positive values in red, negative in green.

As you can see, as a non native speaker I over-use very simple words and under-use more sophisticated words. Other authors stress certain specific words, others are much more “plain”, showing less artifacts. At some point I was curious about what was really happening there: what words I would use too much and too little? So in the demo website you can also press the button to analyze a given user, and see the top 10 words over-used and under-used. Well, a few of mine are definitely due to my issues with English grammar :D

Ok, enough with this investigation! Vector sets are now in Redis 8 RC1 and I have more work to do, but this was fun, and I believe it shows that vectors were definitely cool even before AI. Thanks for reading such a long post.

EDIT: I forgot to say that the insert.py script also inserts the JSON metadata with the total words written by the user. So you can use FILTER in order to only show matches with a given number of words. This can be useful to detect duplicated accounts since often they are used only seldom, when the identity must be covered:

127.0.0.1:6379&gt; vsim hn_fingerprint ele pg FILTER ".wordcount &lt; 10000"
 1) "montrose"
 2) "kar5pt"
 3) "ryusage"
 4) "corwinstephen"
 5) "ElfinTrousers"
 6) "beaned"
 7) "MichaelDickens"
 8) "bananaface"
 9) "area51org"
10) "william42"

EDIT2: In case the matches look suspicious to you (meaningless), like tptacek noted in a comment in the HN submission of this blog post, here is a "visual" match that shows how, for instance, montrose and pg are really similar in the words usage patterns:

<img src="http://antirez.com/misc/hnstyle_2.jpg"></pre></article></div></div>]]></description>
        </item>
    </channel>
</rss>