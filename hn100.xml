<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 28 Nov 2024 01:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Malware can turn off webcam LED and record video, demonstrated on ThinkPad X230 (336 pts)]]></title>
            <link>https://github.com/xairy/lights-out</link>
            <guid>42259278</guid>
            <pubDate>Wed, 27 Nov 2024 20:10:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/xairy/lights-out">https://github.com/xairy/lights-out</a>, See on <a href="https://news.ycombinator.com/item?id=42259278">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Lights Out</h2><a id="user-content-lights-out" aria-label="Permalink: Lights Out" href="#lights-out"></a></p>
<p dir="auto">This repository contains tools that allow getting software control of the webcam LED on ThinkPad X230 <strong>without physical access to the laptop</strong>.
These were created as a practical demonstration that malware can record video through the webcam without the LED indication.</p>
<p dir="auto">This works via reflashing the webcam firmware over USB (the X230 webcam is connected over USB internally) to add a capability of arbitrarily controlling the LED.
This approach likely affects many other laptops, as connecting the webcam over USB and allowing to reflash its firmware is a common design pattern across laptop manufacturers.</p>
<p dir="auto">See the <a href="https://docs.google.com/presentation/d/1NSS2frdiyRVr-5vIjAU-2wf_agzpdiMR1DvVhz2eDwc/edit?usp=sharing" rel="nofollow">"Lights Out: Covertly turning off the ThinkPad webcam LED indicator"</a> talk (<a href="https://powerofcommunity.net/poc2024/Andrey%20Konovalov,%20Lights%20Out%20-%20Covertly%20turning%20off%20the%20ThinkPad%20webcam%20LED%20indicator.pdf" rel="nofollow">pdf</a>) I gave at <a href="https://powerofcommunity.net/" rel="nofollow">POC 2024</a> for the details: discovering a way to reflash the X230 webcam firmware, reverse engineering the firmware, adding an implant for LED control, and notes about the applicability of the approach to other laptops.</p>
<p dir="auto"><strong>Note: Reflashing the webcam firmware might brick the webcam, use these tools with caution</strong>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto">The webcam used on ThinkPad X230 (and a few other laptops from the same era) is based on the Ricoh R5U8710 USB camera controller.
This controller stores a part of its firmware, the SROM part, on the SPI flash chip located on the webcam board.
The controller also allows reflashing the contents of the SPI chip over USB.</p>
<p dir="auto">The LED on the X230 webcam board is connected to the GPIO B1 pin of the R5U8710 controller.
The GPIO B port is mapped to address <code>0x80</code> in the <code>XDATA</code> memory space of the 8051-based CPU inside R5U8710.
Thus, changing the value at that address changes the state of the LED.
This works regardless of whether the webcam is streaming video at the moment or not.</p>
<p dir="auto">The tools provided in this repository allow flashing custom firmware with a USB-controlled so-called "universal implant" onto the SPI chip on the webcam board.
This implant allows writing controlled data to arbitrary addesses (within the <code>XDATA</code> memory space) and calling arbitrary addresses (within the <code>CODE</code> memory space; aliased with <code>XDATA</code> starting from offset <code>0xb000</code>).</p>
<p dir="auto">The universal implant can be used for:</p>
<ul dir="auto">
<li>
<p dir="auto">Dynamically uploading a second-stage implant within the camera contoller memory and executing it (originally used for reverse engineering purposes);</p>
</li>
<li>
<p dir="auto">Directly controlling the webcam LED.</p>
</li>
</ul>
<p dir="auto">See the talk slides for more details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tools</h2><a id="user-content-tools" aria-label="Permalink: Tools" href="#tools"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom.py">srom.py</a> — reads and writes the SROM part of the firmware of a Ricoh R5U8710–based webcam over USB.</p>
<p dir="auto">Note: The webcam only loads the SROM firmware during its boot.
Thus, you will need to power cycle the laptop (full shutdown, not just reboot) for the updated firmware to get loaded;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/patch_srom.py">patch_srom.py</a> — patches the SROM image from the FRU <code>63Y0248</code> webcam (not from the original X230 webcam) to add the universal implant.</p>
<p dir="auto">Note: This tool requires modification to work with the original X230 webcam SROM image.
However, the FRU <code>63Y0248</code> SROM image (optionally, with the implant added) can be flashed onto the original X230 webcam as well;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/fetch.py">fetch.py</a> — fetches the contents of the <code>IRAM</code>, <code>XDATA</code>, or <code>CODE</code> memory space over USB via a second-stage implant that gets dynamically uploaded via the universal implant;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/led.py">led.py</a> — turns the webcam LED on or off by overwriting the value at address <code>0x80</code> in <code>XDATA</code> via the universal implant.</p>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Memory dumps</h2><a id="user-content-memory-dumps" aria-label="Permalink: Memory dumps" href="#memory-dumps"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom/x230.bin">srom/x230.bin</a> — SROM contents of the original X230 webcam module (FRU unknown; <code>19N1L1NVRA0H</code> marking on the board);</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/srom/63Y0248.bin">srom/63Y0248.bin</a> — SROM contents of the FRU <code>63Y0248</code> webcam module;</p>
</li>
<li>
<p dir="auto"><a href="https://github.com/xairy/lights-out/blob/main/code/63Y0248.bin">code/63Y0248.bin</a> — Contents of the <code>CODE</code> memory space leaked from the FRU <code>63Y0248</code> webcam module.</p>
<p dir="auto">Note: Boot ROM is below the offset <code>0xb000</code>, and it is identical to the Boot ROM on the original X230 webcam module.</p>
</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The US copyright office has struck down a major effort for game preservation (126 pts)]]></title>
            <link>https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/</link>
            <guid>42259133</guid>
            <pubDate>Wed, 27 Nov 2024 19:54:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/">https://www.gamesradar.com/games/publishers-are-absolutely-terrified-preserved-video-games-would-be-used-for-recreational-purposes-so-the-us-copyright-office-has-struck-down-a-major-effort-for-game-preservation/</a>, See on <a href="https://news.ycombinator.com/item?id=42259133">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">
<p>A three-year fight to help support game preservation has come to a sad end today. The US copyright office has denied a request for a DMCA exemption that would allow libraries to remotely share digital access to preserved video games.</p><p>"For the past three years, the Video Game History Foundation has been supporting with the Software Preservation Network (SPN) on a petition to allow libraries and archives to <a data-analytics-id="inline-link" href="https://www.copyright.gov/1201/2024/comments/Class%206(b)%20-%20Initial%20Comments%20-%20%20Software%20Preservation%20Network%20and%20Library%20Copyright%20Alliance.pdf" target="_blank" data-url="https://www.copyright.gov/1201/2024/comments/Class%206(b)%20-%20Initial%20Comments%20-%20%20Software%20Preservation%20Network%20and%20Library%20Copyright%20Alliance.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">remotely share digital access to out-of-print video games in their collections</a>," VGHF explains in its <a data-analytics-id="inline-link" href="https://gamehistory.org/dmca-2024-statement/" target="_blank" data-url="https://gamehistory.org/dmca-2024-statement/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">statement</a>. "Under the current anti-circumvention rules in Section 1201 of the DMCA, libraries and archives are unable to break copy protection on games in order to make them remotely accessible to researchers."</p><p>Essentially, this exemption would open up the possibility of a digital library where historians and researchers could 'check out' digital games that run through emulators. The VGHF argues that <a data-analytics-id="inline-link" href="https://gamehistory.org/87percent/" target="_blank" data-url="https://gamehistory.org/87percent/" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">around 87% of all video games released in the US before 2010 are now out of print</a>, and the only legal way to access those games now is through the occasionally exorbitant prices and often failing hardware that defines the retro gaming market.</p><p>Still, the US copyright office has said no. "The Register concludes that proponents did not show that removing the single-user limitation for preserved computer programs or permitting off-premises access to video games are likely to be noninfringing," according to the <a data-analytics-id="inline-link" href="https://public-inspection.federalregister.gov/2024-24563.pdf" target="_blank" data-url="https://public-inspection.federalregister.gov/2024-24563.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">final ruling</a>. "She also notes the greater risk of market harm with removing the video game exemption’s premises limitation, given the market for legacy video games."</p><p>That ruling cites the belief of the Entertainment Software Association and other industry lobby groups that "there would be a significant risk that preserved video games would be used for recreational purposes." We cannot, of course, entertain the notion that researchers enjoy their subjects for even a moment. More importantly, this also ignores the fact that libraries <em>already</em> lend out digital versions of more traditional media like books and movies to everyday people for what can only be described as recreational purposes.</p><p>Members of the VGHF are naturally unhappy with the decision. "Unfortunately, lobbying efforts by rightsholder groups continue to hold back progress," the group says in its statement, noting the ESA's absolutist position that it would <a data-analytics-id="inline-link" href="https://www.gamesradar.com/games/the-esa-says-its-members-wont-support-the-one-form-of-game-preservation-that-might-actually-work/" data-before-rewrite-localise="https://www.gamesradar.com/games/the-esa-says-its-members-wont-support-the-one-form-of-game-preservation-that-might-actually-work/">not support a similar sort of copyright reform under any circumstances</a>.</p><p>"I'm proud of the work we and the orgs we partnered with did to try and change copyright law," VGHF founder and director Frank Cifaldi says on <a data-analytics-id="inline-link" href="https://x.com/frankcifaldi/status/1849869475782459704" target="_blank" data-url="https://x.com/frankcifaldi/status/1849869475782459704" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">Twitter</a>. "We really gave it our all, I can't see what else we could have done. This fails the needs of citizens in favor of a weak sauce argument from the industry, and it's really disappointing."</p><div data-hydrate="true" id="slice-container-newsletterForm-articleInbodyContent-fdSYVfdKPF5N2AbJW46cMW"><section><p>Weekly digests, tales from the communities you love, and more</p></section></div><p><em>Your legal access to the </em><a data-analytics-id="inline-link" href="https://www.gamesradar.com/best-games-of-all-time/" data-before-rewrite-localise="https://www.gamesradar.com/best-games-of-all-time/"><em>best games of all time</em></a><em> is not a guarantee.</em>&nbsp;</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Feels Like Paper (132 pts)]]></title>
            <link>https://www.lukasmoro.com/paper</link>
            <guid>42258540</guid>
            <pubDate>Wed, 27 Nov 2024 18:43:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.lukasmoro.com/paper">https://www.lukasmoro.com/paper</a>, See on <a href="https://news.ycombinator.com/item?id=42258540">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[You can use C-Reduce for any language (255 pts)]]></title>
            <link>https://bernsteinbear.com/blog/creduce/</link>
            <guid>42258103</guid>
            <pubDate>Wed, 27 Nov 2024 17:56:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://bernsteinbear.com/blog/creduce/">https://bernsteinbear.com/blog/creduce/</a>, See on <a href="https://news.ycombinator.com/item?id=42258103">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        

        
        
        <p><i>November 15, 2024</i></p>
        
        
        <div>
            <p><a href="https://github.com/csmith-project/creduce">C-Reduce</a> is a tool by Regehr and
friends for minimizing C compiler bug reproducers. Imagine if you had a 10,000
line long C file that triggered a Clang bug. You don’t want to send a massive
blob to the compiler developers because that’s unhelpful, but you also don’t
want to cut it down to size by hand. The good news is that C-Reduce can do that
for you. The bad news is that everyone thinks it only works for C.</p>

<p>It’s pretty widely applicable. You only need:</p>

<ul>
  <li>A deterministic condition<sup id="fnref:loop" role="doc-noteref"><a href="#fn:loop" rel="footnote">1</a></sup></li>
  <li>A reasonably quick reproducer (it helps with the speed of the reduction)</li>
  <li>One or more mutable source files for C-Reduce to cut down</li>
</ul>

<p>I ran into a bug with <a href="https://github.com/RustPython/RustPython">RustPython</a>
running <a href="https://github.com/tekknolagi/scrapscript">scrapscript</a> and wanted to
report it. So I ran wrote a script <code>interesting.sh</code> to reproduce the bug:</p>

<div><pre><code><span>#!/bin/bash</span>
<span># No -o pipefail; we don't want rustpython failures to cause the script to fail</span>
<span>set</span> <span>-eu</span>

<span># Note the absolute path to the binary, which is not in $PATH</span>
/path/to/RustPython/target/release/rustpython scrapscript.py 2&gt;&amp;1 | <span>grep</span> <span>\</span>
    <span>"tried to push value onto stack but overflowed max_stackdepth"</span>
</code></pre></div>

<p>And then I ran C-Reduce. This all happened within a couple of seconds:</p>

<div><pre><code><span>$</span><span> </span>creduce <span>--not-c</span> interesting.sh scrapscript.py
<span>===&lt; 2263604 &gt;</span><span>===</span>
<span>running 4 interestingness tests in parallel
</span><span>===&lt; pass_blank :: 0 &gt;</span><span>===</span>
<span>(0.5 %, 200799 bytes)
(0.6 %, 200607 bytes)
</span><span>===&lt; pass_lines :: 0 &gt;</span><span>===</span>
<span>(9.2 %, 183225 bytes)
(18.1 %, 165228 bytes)
(26.5 %, 148382 bytes)
(29.3 %, 142674 bytes)
(34.6 %, 131961 bytes)
(38.1 %, 124960 bytes)
(40.6 %, 119872 bytes)
(42.3 %, 116504 bytes)
(44.4 %, 112161 bytes)
(46.4 %, 108180 bytes)
(47.5 %, 105950 bytes)
</span><span>...
</span></code></pre></div>

<p>What you see is C-Reduce cutting down the file by 50% nearly instantly… and I
don’t even have a very fast computer.</p>

<p>We use <code>--not-c</code> because otherwise C-Reduce uses a bunch of C-specific passes.
If we’re working on Python, it will likely just slow things down (but not
materially change the outcome).</p>

<p>There you have it. Fast and easy. As I finish typing these next couple of
sentences, we’re already at 96.9% reduced.</p>


        </div>
            
    <!-- Workaround for FB MITM -->
    <!-- Google tag (gtag.js) -->







    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comparing AWS S3 with Cloudflare R2: Price, Performance and User Experience (177 pts)]]></title>
            <link>https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience</link>
            <guid>42256771</guid>
            <pubDate>Wed, 27 Nov 2024 15:26:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience">https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience</a>, See on <a href="https://news.ycombinator.com/item?id=42256771">Hacker News</a></p>
Couldn't get https://kerkour.com/aws-s3-vs-cloudflare-r2-price-performance-user-experience: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Redis Inc seeks control over future of Rust redis-rs client library (105 pts)]]></title>
            <link>https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/</link>
            <guid>42256594</guid>
            <pubDate>Wed, 27 Nov 2024 14:58:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/">https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/</a>, See on <a href="https://news.ycombinator.com/item?id=42256594">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
                            <article>
        <div>
            <ul>
                                        <li><a href="https://devclass.com/category/databases/">Databases</a></li>
                                </ul>

            <header>
                <!-- title -->
                <h3>
                    <a href="https://devclass.com/2024/11/27/redis-inc-seeks-control-over-future-of-rust-redis-rs-client-library-amid-talk-of-trademark-threat/" rel="bookmark" title="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns">
                        Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns                    </a>
                </h3>

                
            </header>

            <div>
                <!-- image -->
                                        <p><img src="https://devclass.com/wp-content/uploads/2019/04/shutterstock_491993500-768x427.jpg" alt="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns" title="Redis Inc seeks control over future of Rust redis-rs client library, amid talk of trademark concerns">
                                                    </p>
                				
                
<p>Redis inc, whose core product is the formerly open source Redis in-memory database, has prompted further unease in the community by approaching the maintainers of the most popular Rust client library for Redis with the intent either to control or to fork it.</p>



<p>Armin Ronacher, who controls the redis-rs entry on crates.io, the Rust package registry, <a href="https://github.com/redis-rs/redis-rs/issues/1419">posted</a> about an email from Redis product manager Mirko Ortensi, followed by a call, in which the company expressed its desire for a Rust client with official support. The proposal was to take over redis-rs in order to add “enterprise-grade features” but continuing with community contributions and compatibility with the official community edition of Redis.</p>



<p>Ronacher said he understood from the call that “the name of the library constitutes a trademark violation in their mind” and that the options were either to transfer the code to Redis, or to rename the crate. He said he did not wish to be in any kind of trademark dispute. He also expressed concern for those who use the library with Valkey, an open source alternative to Redis.</p>



<p>In March 2024 Redis <a href="https://www.theregister.com/2024/03/22/redis_changes_license/">changed the licensing</a> for its core code from the open source BSD-3 to the Redis Source Available License v2 or the Server Side Public License v1, restricting the use of that code. One of the consequences was the <a href="https://www.linuxfoundation.org/press/linux-foundation-launches-open-source-valkey-community">formation of Valkey</a>, based on Redis 7.2.4 and continuing with the BSD-3 license.</p>



<p>Ortensi posted to the thread, clarifying that while he had not called the name redis-rs a trademark violation, “companies do consider protecting their trademarks where their reputation is challenged.” He also said that the Redis crate should be for Redis and that Valkey could not guarantee compatibility with Redis long-term and should have its own crate.</p><!-- FALCON via Article Inline Ad -->
            



<p>Valkey maintainer Madelyn Olson said that her hope was “to support both Valkey and Redis [in rust-rs] because of the overlap between the products.”</p>



<p>Another rust-rs committer commented, asking why Redis could not simply contribute pull requests to the existing project for the required new features, as well as support for the forthcoming Redis 8, adding that “I would feel much better about yielding governance if I saw that Redis Inc was actively contributing.”</p>



<p>Apache Software Foundation member Xuanwo pitched in, stating that there are other Redis-compatible services which use the Redis protocol including Apache Kvrocks, as well as others such as DragonflyDB. “If this repository is transferred to Redis, Inc., I would be concerned that Redis, Inc. might introduce breaking changes to the protocol or client itself, preventing users from using this client to access other Redis-compatible services,” he said.</p>



<p>Redis creator Salvatore Sanfilippo, also known as antirez, offered to talk to the Redis company about authorization “so that open source client libraries can use the name ‘Redis’ without issues.”&nbsp;&nbsp;</p>



<p>It was Sanfilippo who made Redis open source in 2009, early in the life of the project, though he stepped down as maintainer in 2020. At the time, Redis <a href="https://redis.io/blog/thank-you-salvatore-sanfilippo/">said</a> that “the core of the open source Redis project will remain under the 3-Clause BSD license,” a promise that was kept only for a few more years.</p>



<div><p>Even if Sanfilippo mitigates the trademark issue, there remains the question of whether Redis Inc will still wish to acquire or fork redis-rs for its own purposes, further alienating the open source community.</p></div>
				
							<!-- QUIZ HERE -->
							
				<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->
            </div>
        </div>
    </article>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Emacs arbitrary code execution and how to avoid it (126 pts)]]></title>
            <link>https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html</link>
            <guid>42256409</guid>
            <pubDate>Wed, 27 Nov 2024 14:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html">https://eshelyaron.com/posts/2024-11-27-emacs-aritrary-code-execution-and-how-to-avoid-it.html</a>, See on <a href="https://news.ycombinator.com/item?id=42256409">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
<header>

<p role="doc-subtitle">Details and advice about a long standing arbitrary code execution vulnerability in Emacs</p>
</header><p>Created on <span><span>[2024-11-27]</span></span>, last updated <span><span>[2024-11-27]</span></span></p>


<p>
This is a security advisory about CVE-2024-53920, an Emacs
vulnerability that I (re-)discovered a few months ago.
</p>
<div id="outline-container-org049caf1">
<h2 id="org049caf1">TL;DR</h2>
<div id="text-org049caf1">
<p>
Viewing or editing Emacs Lisp code in Emacs can run arbitrary code.
The vulnerability stems from unsafe Lisp <i>macro-expansion</i>, which runs
unrestricted Emacs Lisp code.  Most common configurations are
vulnerable (see details below).  The best security measures are:
</p>

<ul>
<li>Avoid visiting untrusted <code>.el</code> files in Emacs</li>
<li>Disable automatic error checking (with Flymake or Flycheck) in
untrusted <code>.el</code> files</li>
<li>Disable auto-completion features in untrusted <code>.el</code> files</li>
</ul>

<p>
This is a long-standing vulnerability which has been known for several
years, but has not been addressed thus far.  Emacs maintainers are
working on countermeasures that will hopefully make their way into
future Emacs versions.  This advisory is intended to help users of
existing Emacs versions protect themselves.
</p>
</div>
</div>
<div id="outline-container-org33b9590">
<h2 id="org33b9590">Background</h2>
<div id="text-org33b9590">
<p>
<i>Macros</i> are a staple feature across Lisp dialects.  They are often
cited as one of the superpowers of Lisp.  They are essentially a
meta-programming facility: a macro is just a Lisp function that
outputs Lisp code.  Since Lisp is homoiconic (code and data are
represented using the same data structures), manipulating Lisp code in
Lisp is as simple as processing any other program input.  This makes
such meta-programming fun and easy, especially in comparison to the
experience of writing elaborate C preprocessor macros, for example,
which often feels a bit hackish.
</p>

<p>
However, as is often the case with great powers, Lisp macros are
double-edged swords—wielding them safely requires special care.
</p>

<p>
Normally, macros are executed, or “expanded”, during so-called
macro-expansion time: after parsing (“reading”) text into a Lisp form,
macro calls that occur in the form are expanded by executing the
macro, which produces new (sub-)forms.  The macro-free form obtained
by expanding all macro calls can then be compiled and executed.  Thus
macro-expansion time comes after “read time” and before compile time
and runtime.
</p>

<p>
<i>Emacs Lisp</i> is the programming language used implement most of
Emacs’s core features and extensions, as well to configure it.  It is
not the most powerful Lisp dialect out there, but it does boast a
full-blown meta-programming facility in the form of macros.  The
problem is that macros in Emacs Lisp come with no safety
measures—they can execute arbitrary, unrestricted, Emacs Lisp code.
The basic macro-expansion primitive in Emacs is the Lisp function
<code>macroexpand</code>, defined in C code in <code>src/eval.c</code> in the Emacs sources.
It repeatedly replaces macro names with their definitions as
functions, and applies those functions to the provided code:
</p>

<div>
<pre><span>while</span> <span>(</span>1<span>)</span>
  <span>{</span>
    

...
    <span>{</span>
      <span>Lisp_Object</span> <span>newform</span> = apply1 <span>(</span>expander, XCDR <span>(</span>form<span>)</span><span>)</span>;
      <span>if</span> <span>(</span>EQ <span>(</span>form, newform<span>)</span><span>)</span>
        <span>break</span>;
      <span>else</span>
        form = newform;
    <span>}</span>
  <span>}</span>
<span>return</span> form;
</pre>
</div>

<p>
That <code>apply1</code> call up there can do, well, literally anything,
depending on the <code>expander</code> function (the definition of the macro) and
the given input <code>form</code>.
</p>

<p>
The Emacs Lisp library <code>macroexp.el</code> provides higher-level routines on
top of this <code>macroexpand</code> primitive, such as <code>macroexpand-all</code> which
the Lisp byte-compiler in <code>bytecomp.el</code> uses to preprocess Lisp forms.
</p>

<p>
In addition, Emacs ships with several built-in macros that actually do
execute arbitrary code by <i>evaluating</i> some of their arguments, no
questions asked.  These macros are <code>static-if</code>, <code>rx</code>, <code>cl-eval-when</code>,
<code>eval-when-compile</code>, <code>eval-and-compile</code>, and perhaps others.
</p>

<p>
Therefore, if we can nudge Emacs to expand one of these macros, we get
arbitrary code execution.  That’s the crux of this vulnerability.
<i>Expanding macros in Emacs Lisp is unsafe by design</i>.
</p>
</div>
</div>
<div id="outline-container-org435223b">
<h2 id="org435223b">Exploitation</h2>
<div id="text-org435223b">
<p>
But could an attacker really coerce Emacs to expand macros without an
explicit user request?  When you open (or “visit”, in Emacs parlance)
an Emacs Lisp file, Emacs enables “ELisp mode”, a dedicated editor
mode defined in <code>elisp-mode.el</code>, which provides various useful
features for exploring and editing Emacs Lisp code.
</p>

<p>
One of the features that ELisp mode provides is code completion.
Completion is implemented in the function <code>elisp-completion-at-point</code>,
which tries to examine the code around your cursor and come up with
relevant completions.  Among other things, it invokes a subroutine
<code>elisp--local-variables</code> that looks for local variable names in the
current scope.  Since macros can completely change the meaning of the
code they apply to, <code>elisp--local-variables</code> expands macros in the
surrounding code to uncover local variables that may be created or
obscured by such macros.  Hence <i>invoking code completion runs
arbitrary code</i>.  In vanilla Emacs, by default, code completion is
only triggered when you issue a completion command.  However, since
macros run arbitrary code in a Turing complete language (Emacs Lisp),
there’s no way to know for sure whether invoking completion will get
you pwned.  More importantly, almost no one uses the default Emacs
configuration.  Emacs users tweak various knobs, and in many common
configurations folks enable auto-completion features which then
trigger code completion without an explicit completion command.  Such
auto-completion is performed by the popular Emacs packages Corfu and
Company, as well as the newly built-in <a href="https://eshelyaron.com/posts/2023-11-17-completion-preview-in-emacs.html">Completion Preview mode</a>.
</p>

<p>
But the most common flow that involves automatic macro-expansion is
probably <i>on-the-fly code diagnosis</i>.  There are two widespread Emacs
packages that check your code and warn about potential errors
automatically.  One is Flymake, which is built into Emacs, and the
other is a popular extension package called <a href="https://www.flycheck.org/en/latest/">Flycheck</a>.  Both of them,
when enabled in an ELisp mode buffer, check for code issues by
<i>byte-compiling</i> the code.  As mentioned earlier, this involves
macro-expansion, and thus arbitrary code execution.  For Flymake, this
byte-compilation happens in the function <code>elisp-flymake-byte-compile</code>.
Like auto-completion, on-the-fly diagnosis is not enabled by default
in vanilla Emacs, but it is extremely common for users to enable it.
In some Emacs “distributions”, such as the popular <a href="https://github.com/doomemacs/doomemacs">Doom Emacs</a> and
<a href="https://prelude.emacsredux.com/en/latest/">Prelude</a>, either Flymake or Flycheck are enabled by default in ELisp
mode.
</p>

<p>
So the idea is simple: to exploit this vulnerability, an attacker
crafts an Emacs Lisp file that includes a malicious macro invocation,
and sends that file to an unsuspecting Emacs user.  When that user
opens the file in Emacs, code diagnosis is triggered automatically,
which expands macros and executes arbitrary code.
</p>

<p>
Here’s the content of the POC “malicious” file that I shared with the
Emacs maintainers when reporting this vulnerability:
</p>

<div>
<pre><span>(</span><span>rx</span> <span>(</span>eval <span>(</span><span>call-process</span> <span>"touch"</span> nil nil nil <span>"/tmp/owned"</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
If you have Flymake or Flycheck hooked to ELisp mode (again, such a
setting is often the default in Emacs starter kits, and generally very
common among Emacs users), then just putting the above line of code
anywhere in a <code>.el</code> file and opening that file in Emacs will create a
new file <code>/tmp/owned</code> on your system.  Such a setup usually looks
something like the following in the Emacs initialization file,
<code>~/.emacs.d/init.el</code>:
</p>

<div>
<pre>
<span>(</span><span>add-hook</span> 'emacs-lisp-mode-hook #'<span>flymake-mode</span><span>)</span>
</pre>
</div>

<p>
This is reproducible at least since Emacs version from 26.1 and all
the way up to the development version of the upcoming Emacs 30.
</p>

<p>
So this is a long-standing vulnerability, and the gist of it is very
simple: macros are unsafe, and in common setups Emacs expands them
automatically.  I’ve come to discover this issue while working on an
enhancement for ELisp mode, which employed macro-expansion to provide
semantic code highlighting.  I quickly realized that doing so naively
is a security risk, and soon afterwards it hit me that Emacs suffered
from such a vulnerability already without my custom hacks.
</p>

<p>
The very same day, 17/08/2024, I reported my findings to the Emacs
maintainers via private email.  The maintainers informed me that
variants of this issue have been surfaced in the past, but the issue,
sadly, still stands.  AFAICT the earliest public discussion about the
security implications of Emacs Lisp macros started in August 2018,
when <a href="https://yhetil.org/emacs/CAFXAjY5f4YfHAtZur1RAqH34UbYU56_t6t2Er0YEh1Sb7-W=hg@mail.gmail.com/">Wilfred Hughes noted</a> that code completion can lead to arbitrary
code execution via macro-expansion.  In October 2019, <a href="https://yhetil.org/emacs/CAJw81da4=R1jMJ0enx6SbO7G1rzaL61K2kqbY+jxhe=AM-3vtQ@mail.gmail.com/">Adam Plaice
reported</a> that Flymake specifically can be used in a similar exploit.
Some solutions have been floated in the discussions following these
reports, but unfortunately, Emacs remains vulnerable to this very day.
</p>

<p>
Following my report, the maintainers requested 90 days to work on a
fix before public disclosure.  That non-disclosure period have since
expired, hence this advisory.  They continue to work on a fix, which I
hope will be available soon, and now we at least have a CVE to track
this vulnerability.  Until new guardrails are put in place to mitigate
this risk, it is important to realize that macro-expansion of
untrusted Emacs Lisp code is unsafe, and to be vigilant about <code>.el</code>
files that you open in Emacs.  Crucially, <b>do not enable
Flymake/Flycheck in ELisp mode automatically</b>.  Only allow automatic
macro-expansion in <code>.el</code> files that trust and you control, and protect
those files from tampering.
</p>
</div>
</div>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Recommendation for a SWE looking to get up to speed with latest on AI (198 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=42256093</link>
            <guid>42256093</guid>
            <pubDate>Wed, 27 Nov 2024 13:55:20 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=42256093">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="42256405"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256405" href="https://news.ycombinator.com/vote?id=42256405&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>The poster's looking for articles, so this recommendation's a bit off the mark. I learned more from participating in a few Kaggle competitions (<a href="https://www.kaggle.com/competitions" rel="nofollow">https://www.kaggle.com/competitions</a>) than I did from reading about AI. Many folks in the community shared their homework, and by learning how to follow their explanations I developed a much more intuitive understanding of the technology. The first competition had a steep learning curve. I felt it was worth it. The application of having a specific goal and the provided datasets made the problem space more tractable.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256720"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256720" href="https://news.ycombinator.com/vote?id=42256720&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Out of sheer curiosity, how much time did you spend on it on average? How much of this knowledge are you using now?</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256785"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42256785" href="https://news.ycombinator.com/vote?id=42256785&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Not the poster you responded to but I learned quite a bit from kaggle too.</p><p>I started from scratch, spent 2-4 hrs per day for 6 months &amp; won a silver in a kaggle NLP competition.  Now I use some of it now but not all of it. More than that, I'm quite comfortable with models, understand the costs/benefits/implications etc. I started with Andrew Ng's intro courses, did a bit of fastai, did Karpathy's Zero to Hero fully, all of Kaggle's courses &amp; a few other such things. Kagglers share excellent notebooks and I found them v helpful. Overall I highly recommend this route of learning.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257032"><td></td></tr>
            <tr id="42256925"><td></td></tr>
                              <tr id="42256144"><td></td></tr>
                <tr id="42256502"><td></td></tr>
                  <tr id="42256403"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256403" href="https://news.ycombinator.com/vote?id=42256403&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>I don't think it's a good idea to kepp up to date at a daily/weekly cadence, unless you somehow directly get paid for it. It's like checking stocks daily, it doesn't lead to good investment decisions.</p><p>It's better to do it more batchy, like once every 6-12 months or so.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256452"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256452" href="https://news.ycombinator.com/vote?id=42256452&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>How do you do that? Once you're out of the loop for half a year, it becomes harder to know what's important and what's not, I think.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257829"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257829" href="https://news.ycombinator.com/vote?id=42257829&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Some ideas:</p><p>1. Buy O'reilly (and other tech) books as they come out. This will have a lag, but essentially somebody did this research &amp; summarization work, and wrote it up for you in chapters. Note that you don't have to read everything in a book. Also, $50 is a great investment if it saves you 10s of hours of time.</p><p>2. Talks on Youtube at conferences by industry leaders, like Yann LeCun, or maintainers of popular libraries, etc. Also, YT videos on the topic that are upvoted/linked.</p><p>3. If you're interested in hardcore research, look for review articles on arxiv.</p><p>4. Look at tutorials/examples in the documentation/repo of popular ML/AI libraries, like Pytorch.</p><p>5. Try to cover your blindspots. One way or another, you'll know how new AI is applied to SWE and related fields. But how is AI applied to perpendicular fields, like designing buildings, composing music, or balancing a budget? Trying to cover these areas will be tougher, because it will be more noisy, as most commenters will be non-experts compared to you. To get a feel for this, do something that feels unnatural, like watch TED talks that seem bullshity, read HBR articles intended for MBAs, and check out what Palantir is doing.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256624"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42256624" href="https://news.ycombinator.com/vote?id=42256624&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Every release is novel. Once something has been around for a while and is still being referenced, you know it’s worth learning.</p><p>Waiting 3-6 months to take a deep dive is a good pattern to prevent investing your time in dead-end routes.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257570"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_42257570" href="https://news.ycombinator.com/vote?id=42257570&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Yes this is why I never buy the latest CPUs and try to never run the latest release of any software. Stay a (supported) release or two behind the bleeding edge, and you'll find stuff is more stable. Common bugs and other issues have been shaken out by the early adopters.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                              <tr id="42257627"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257627" href="https://news.ycombinator.com/vote?id=42257627&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>For news-like content I follow accounts on X: @kimmonismus @apples_jimmy and the accounts of Antropic, Mistal, Gemini / DeepMind and OpenAI.
I think everyone who is really interested in the hot AI developments must also follow what comes from China. I follow <a href="https://chinai.substack.com/" rel="nofollow">https://chinai.substack.com/</a> but I am open to hear about other Chinese resources.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257607"><td></td></tr>
            <tr id="42257387"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257387" href="https://news.ycombinator.com/vote?id=42257387&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>I read about 30 LLM papers a couple months ago dated from 2018-2024. Mostly folks are publishing on the “how do we prompt better” problem, and you can kind of get the gist in about a day by reading a few blogs (RAG, fine tuning, tool use, etc). There is also more progress being made for model capabilities, like multi modality, and each company seems to be pushing in only slightly different directions, but essentially they are still black boxes.</p><p>It depends what you are looking for honestly “the latest things happening” is pretty vague. I’d say the place to look is probably just the blogs of OpenAI/Anthropic/Genini, since they are the only teams with inside information and novel findings to report. Everyone else is just using the tools we are given.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257629"><td></td></tr>
            <tr id="42256529"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256529" href="https://news.ycombinator.com/vote?id=42256529&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>The best place for the latest information isn't tech blogs in my opinion. It's the stable diffusion and local llama subreddits. If you are looking to learn about everything on a fundamental level you need to check out Andrej Karpathy on YouTube. There other some other notable mentions in other people's comments.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257251"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257251" href="https://news.ycombinator.com/vote?id=42257251&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>New short course on FreeCodeCamp YouTube channel looks good -</p><p>Ollama Course – Build AI Apps Locally
<a href="https://youtu.be/GWB9ApTPTv4?feature=shared" rel="nofollow">https://youtu.be/GWB9ApTPTv4?feature=shared</a></p><p>As an aside, does anyone have any ideas about this: there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs, in addition to ingesting docs, text and content in the normal RAG way. Then you could build AI chat-enabled knowledge resources around specific subjects. Autogenerated summaries and dashboards would provide useful overviews.</p><p>Perhaps this already exists?</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257429"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257429" href="https://news.ycombinator.com/vote?id=42257429&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>&lt;&lt; there should be an app like an 'auto-RAG' that scrapes RSS feeds and URLs,</p><p>I am not aware if that exists yet, but the challenge I see with it is rather simple: you get overwhelmed with information really quickly. In other words, you would still need human somewhere in that process to review those scrapes and the quality of that varies widely. For example, even on HN it is not a given a link will be pure gold ( you still want to check if it fits your use case ).</p><p>That said, as ideas goes, it sounds like a fun weekend project.</p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42257174"><td></td></tr>
                <tr id="42257385"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257385" href="https://news.ycombinator.com/vote?id=42257385&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>My issue with YouTube channels that focus on AI news is that they’re heavily incentivized to give you a frequent stream of attention-grabbing news. Week-by-week updates aren’t that helpful. It’s easy to miss the bigger picture and there’s too much content to feel like a good use of time.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257668"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257668" href="https://news.ycombinator.com/vote?id=42257668&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>I agree with this statement, most YouTube channels are incentivized to keep repeating the same trivial information like how to compose prompts etc</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42257363"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257363" href="https://news.ycombinator.com/vote?id=42257363&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>First thing you need to do is change your LinkedIn to “AI evangelist” then go to your boss and say I want triple the pay. Then let the chips fall where they may. Oh also rename all your GitHub or personal projects to have AI in the name. You don’t actually have to do much else.</p>
              </div></td></tr>
        </tbody></table></td></tr>
            <tr id="42257076"><td></td></tr>
            <tr id="42257364"><td></td></tr>
            <tr id="42256542"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256542" href="https://news.ycombinator.com/vote?id=42256542&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Simon's blog is fragmented because it's, well, a blog. It would be hard to find a better source to "keep updated on things AI" though. He does do longer summary articles sometimes, but mostly he's keeping up with things in real time. The search and tagging systems on his blog work well, too. I suggest you stick his RSS feed in your feed reader, and follow along that way.</p><p>Swyx also has a lot of stuff keeping up to date at <a href="https://www.latent.space/" rel="nofollow">https://www.latent.space/</a>, including the Latent Space podcast, although tbh I haven't listened to more than one or two episodes.</p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257239"><td></td></tr>
                  <tr id="42256966"><td></td></tr>
            <tr id="42256621"><td></td></tr>
                <tr id="42257255"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257255" href="https://news.ycombinator.com/vote?id=42257255&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>daveshap quit ai right? got agi pilled/"oneshotted by ayahuasca" as the kids say</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42257285"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_42257285" href="https://news.ycombinator.com/vote?id=42257285&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>He was only gone for a few days, IIRC. At any rate, he's back publishing AI related content again, and it looks like all (?) of his old content is back on his YT channel.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                        <tr id="42257131"><td></td></tr>
            <tr id="42256497"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256497" href="https://news.ycombinator.com/vote?id=42256497&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>As I was building up my understanding/intuition for the internals of transformers + attention, I found 3Blue1Brown's series of videos (specifically on attention) to be super helpful.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256557"><td></td></tr>
                  <tr id="42256670"><td></td></tr>
                <tr id="42257544"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42257544" href="https://news.ycombinator.com/vote?id=42257544&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Sadly, you'll have to include 4chan /g/'s local models general, which, unfortunately, seems to have top AI researchers posting there (anonymously)</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42256540"><td></td></tr>
            <tr id="42256469"><td></td></tr>
            <tr id="42256628"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256628" href="https://news.ycombinator.com/vote?id=42256628&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Reproduce nanogpt.</p><p>Then find a small dataset and see if you can start getting close to some of the reported benchmark numbers with similar architectures.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256666"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42256666" href="https://news.ycombinator.com/vote?id=42256666&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Build a tool on top of the LLM layer for a specific use case. That'll get you up to speed. You haven't missed much.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                <tr id="42256810"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_42256810" href="https://news.ycombinator.com/vote?id=42256810&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div>
                  <p>Exactly. Avoid intentionally throw-away effort and instead attempt to build something specific and practical. Learn by doing.</p>
              </div></td></tr>
        </tbody></table></td></tr>
                  <tr id="42257393"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257393" href="https://news.ycombinator.com/vote?id=42257393&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Lots of good suggestions here already. I'd start by adding one quick note though. "AI" is more than just LLM's. Sure, the "current, trendy, fashionable" thing is all LLM's, but the field as a whole is still much larger. I'd encourage you to not myopically focus on LLM's to exclusion. Depending on your existing background knowledge, there's a lot to be said for going out and getting a copy of <i>Artificial Intelligence: A Modern Approach</i> and reading through it. Likewise for something like <i>Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow</i>.</p><p>Beyond that: there are some decent sub-reddits for keeping up with AI happenings, a lot of good Youtube channels (although a lot of the ones that talk about the "current, trendy" AI stuff tend to be a bit tabloid'ish), and even a couple of Facebook groups. You can also find good signal by choosing the right people to follow on Twitter/LinkedIn/Mastodon/Bluesky/etc.</p><p><a href="https://www.reddit.com/r/artificial/" rel="nofollow">https://www.reddit.com/r/artificial/</a></p><p><a href="https://reddit.com/r/machineLearning/" rel="nofollow">https://reddit.com/r/machineLearning/</a></p><p><a href="https://www.reddit.com/r/LLM/" rel="nofollow">https://www.reddit.com/r/LLM/</a></p><p><a href="https://www.reddit.com/r/agi" rel="nofollow">https://www.reddit.com/r/agi</a></p><p><a href="https://www.reddit.com/r/ollama/" rel="nofollow">https://www.reddit.com/r/ollama/</a></p><p><a href="https://www.youtube.com/@matthew_berman" rel="nofollow">https://www.youtube.com/@matthew_berman</a></p><p><a href="https://www.youtube.com/@TheAiGrid" rel="nofollow">https://www.youtube.com/@TheAiGrid</a></p><p><a href="https://www.youtube.com/@WesRoth" rel="nofollow">https://www.youtube.com/@WesRoth</a></p><p><a href="https://www.youtube.com/@DaveShap" rel="nofollow">https://www.youtube.com/@DaveShap</a></p><p><a href="https://www.youtube.com/c/MachineLearningStreetTalk" rel="nofollow">https://www.youtube.com/c/MachineLearningStreetTalk</a></p><p><a href="https://www.youtube.com/@twimlai" rel="nofollow">https://www.youtube.com/@twimlai</a></p><p><a href="https://www.youtube.com/@YannicKilcher" rel="nofollow">https://www.youtube.com/@YannicKilcher</a></p><p>And you can always go straight to "the source" and follow pre-prints showing up in arXiv.</p><p><a href="https://arxiv.org/corr" rel="nofollow">https://arxiv.org/corr</a></p><p>For tools to make it easier to track new releases, arXiv supports subscriptions to daily digest emails, and also has RSS feeds.</p><p><a href="https://info.arxiv.org/help/subscribe.html" rel="nofollow">https://info.arxiv.org/help/subscribe.html</a></p><p><a href="https://info.arxiv.org/help/rss.html" rel="nofollow">https://info.arxiv.org/help/rss.html</a></p><p>There are also some bots in the Fediverse that push out links to new arXiv papers.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256846"><td></td></tr>
            <tr id="42256354"><td></td></tr>
                <tr id="42256806"><td></td></tr>
                  <tr id="42256482"><td></td></tr>
            <tr id="42256774"><td></td></tr>
            <tr id="42256565"><td></td></tr>
            <tr id="42257064"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_42257064" href="https://news.ycombinator.com/vote?id=42257064&amp;how=up&amp;goto=item%3Fid%3D42256093"></a></center>    </td><td><br><div><p>Are you wanting to get into LLMs in particular or something else? I am a software engineer also trying to make headways into so-called "AI", but I have little interest in LLMs. For one, it's suffering from a major hype bubble right now. The second reason is that because of reason one, it has a huge amount of attention from people who study and work on this every day. It's not something I have the time commitment for to compete with that. Lastly, as mentioned, I have no interest in it and my understanding of them leads me to believe they have few interesting applications besides generating a huge amount of noise in society and dumping heat. The Internet, like blogs, articles, and even YouTube, are already being overrun by LLM-generated material that is effectively worthless. I'm not sure of the net positive for LLMs.</p><p>For me personally, I prefer to work backwards and then forwards. What I mean by that is that I want to understand the basics and fundamentals first. So, I'm, slowly, trying to bone up on my statistics, probability, and information theory and have targeted machine learning books that also take a fundamental approach. There's no end to books in this realm for neural networks, machine learning, etc., so it's hard to recommend beyond what I've just picked, and I'm just getting started anyway.</p><p>If you can get your employer to pay for it, MIT xPRO has courses on machine learning (<a href="https://xpro.mit.edu/programs/program-v1:xPRO+MLx/" rel="nofollow">https://xpro.mit.edu/programs/program-v1:xPRO+MLx/</a> and <a href="https://xpro.mit.edu/courses/course-v1:xPRO+GenAI/" rel="nofollow">https://xpro.mit.edu/courses/course-v1:xPRO+GenAI/</a>). These will likely give a pretty up to date overview of the technologies.</p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="42256640"><td></td></tr>
            <tr id="42256722"><td></td></tr>
            </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ancient Sumerians created the first writing system (126 pts)]]></title>
            <link>https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/</link>
            <guid>42255829</guid>
            <pubDate>Wed, 27 Nov 2024 13:15:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/">https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/</a>, See on <a href="https://news.ycombinator.com/item?id=42255829">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								        
										<p>“In Uruk he built walls, a great rampart, and the temple of blessed Eanna for the god of the firmament Anu, and for Ishtar the goddess of love. Look at it still today: the outer wall where the cornice runs, it shines with the brilliance of copper; and the inner wall, it has no equal. Touch the threshold, it is ancient.”<br>
–<em>The Epic of Gilgamesh</em>, ca. 1750 BC<br>
*</p><p><span>Article continues after advertisement</span></p>
<p>In the middle of the fourth millennium before Christ, men and women could feed themselves and their families, much of the time, but almost nobody else. They did not yet have the wheel. They could fight, but they did not have the capacity to make war. They could not read or write, for there was no writing. Without writing, there was no history. There were stories but no literature. Art was something that people might produce on their pottery, but never for a living. There were customs but no laws. There were chiefs but no kings, tribes but no nations. The city was unknown.</p>
<p>And then, around that time, civilization was born: urban life, based on nutritional surplus and social organization, characterized by complexity and material culture, much of it made possible by writing. This happened in a very particular part of the world: the flood-prone, drought-wracked, frequently pestilential plain of southern Iraq, where the rivers Tigris and Euphrates meet the Persian Gulf. The plain could be fertile, very fertile, but only when people worked together to irrigate it and control the floods with channels and earthworks; this necessity, most likely, accounts for much of the early surge in social complexity that distinguished the area. Later civilizations would arise independently in two great river valleys not so far away, the Indus and the Nile, but the original organized, literate, urban culture was produced by a far crueler and more challenging environment than either of those.</p>
<p><span>The need for a single script to serve a geography using two such dissimilar languages almost interchangeably was a great spur to the development of early Mesopotamian writing.</span></p><p>This first civilization came to be known as Sumer. By about the year 3000 BC, a city called Uruk near the mouth of the Euphrates River, just inland of the head of the Persian Gulf, had eighty thousand residents. A thousand years later Iraq, the land along the Euphrates and its sister stream, the Tigris, would be named for this early metropolis of Uruk. Sharing the land of Sumer, about the size of Belgium, with a dozen other city-states, Uruk was not always the foremost among its rivals in the land. But for most of its existence, spanning the two millennia of the Sumerian world, Uruk was the greatest city on earth.</p>
<p>The Sumerians invented kingship, priesthood, diplomacy, law, and war. They gave the West its founding stories: the opposition of darkness and light at the Beginning; the Flood, with its ark and dove and surviving patriarch; the tower of Babel; the distant ancestors of Odysseus and Hercules. The Sumerians established the outlines of our political, legal, and temporal structures too, with the first kings and assemblies, the first written laws, the first legal contracts, and the sexagesimal system of counting that regulates the hours and seconds of our days.</p><div><p><span>Article continues after advertisement</span></p></div>
<p>The Sumerians wrote the first epics and constructed the first monumental buildings. They invented the wheel, the sailing boat, the dome, and the arch. They were the first people to cast, rivet, and solder metals. They were the first to develop mathematics, calculating the hypotenuse of a right triangle two thousand years before Pythagoras and enabling extraordinary achievements in civil engineering. Compiling methodical lists of plants and animals, the Sumerians were the first people to apply rational order to our knowledge of the natural world.</p>
<p>The Sumerians wrote down almost everything they knew, much of it on disposable clay tablets that have survived the millennia. Some thirty-nine centuries after the last of the Sumerians died, another inventive and curious people, the Victorians of the nineteenth century AD, initiated a remarkable period of foreign exploration in Iraq. Thanks to this colorful and dramatic intellectual adventure, which began in the 1840s, today we can follow the course of Sumerian lawsuits, track Sumerian inventories, and study the terms of Sumerian marriages, wills, and loans. We read the overtures of Sumer’s diplomats. We follow in detail the provisioning of Sumer’s armies and the triumphs or disasters of their expeditions. We know intimately the pleadings of Sumerian students for more money from their fathers, and the pleadings of their fathers for more diligence from their sons. We track the transactions of Sumerian merchants in copper or onions. We admire the complex and perfect calculations of Sumerian engineers.</p>
<p>Human life on the alluvial plain of the two rivers at the birth of civilization five thousand years ago was precarious. Again and again, through the ancient stories and archaeological records that illuminate the dawn of history, plagues and pestilence swept the hot, low country. Terrifying floods killed and destroyed everything within reach of the raging waters that came every spring when the snow melted in the mountains five hundred miles and more to the north, in what is now Armenia and southeast Turkey. At Ur in Sumer’s far south, the great archaeologist Sir Leonard Woolley, digging in 1929, discovered a layer of “perfectly clean clay” more than eight feet thick separating the remains—pottery and much more—of two distinct cultures from some time before 3000 BC. A single flood, in other words, had created a temporary lake that deposited this eight-foot-thick layer. The catastrophic scale of such a deluge is almost beyond the powers of imagination. Woolley naturally surmised that it was the great flood of Genesis. Other floods have left similar records in southern Iraq. Most were smaller than Woolley’s Ur deluge. One left eleven feet of new flood soil.</p>
<p>Meanwhile neighbors from the higher, rougher country to the east, north, and west were greedy for the wealth of the settled plain, then as now. The invasions of barbarians from the Persian hill country, the Kurdish and Turkish mountains, and the Arabian steppe sometimes paused, but never ended. Within Sumer, Uruk and its neighboring city-states fought against each other almost constantly during the twenty-odd centuries of Sumerian civilization.</p>
<p>The soil of southern Iraq is a dusty, flinty accumulation of silt from the two shifting rivers that originate far to the north. In the areas where Iraq’s alluvial soil is not dry, it is marshy, especially in the south; it was more so in ancient times, when the Tigris and Euphrates were bigger. The ground is home to no minerals or ores, although bitumen seeps from the earth in places. The land contains no stones for building. Almost no tree, aside from the date palm, grows on it successfully. Trade with the far-off source-lands of raw materials—for tin and copper to alloy into bronze for weapons, for gold and silver to please the rich and the divine, for hardwood timbers for the roof beams of palaces and temples—required the pooling of resources. Organization and leadership were required to conduct commerce at scale with places as far afield as Anatolia for tin, Lebanon for cedar timbers, “Oman for copper, south-west Iran for carved stone bowls, eastern Iran for lapis lazuli, the Indus for carnelian.”</p><div><p><span>Article continues after advertisement</span></p></div>
<p>*</p>
<p>The water of the two great rivers irrigated the rainless plain. It also raged as a violent killer, to be restrained with dykes and channels. This required cooperation on a much larger scale than the individual village or town could offer. Better irrigation led to increasing harvests. As the land of Sumer became crowded with more and more people, food was another reason for increasingly sophisticated social arrangements. Each of these catalysts—trade, water, sustenance—also led to humanity’s first organized conflicts. War was born. Every Sumerian city had its own principal deity, and the many gods also sent men into their earliest battles there on the hot plain.</p>
<p>*</p>
<p>Late in the fourth millennium BC, a couple of thousand years after the advent of agriculture with the Neolithic revolution, Sumer was one of several distinct cultures around the world. In none of these cultures had true urban life and, with it, civilization yet developed. Then the Sumerian genius produced its greatest innovation: writing.</p>
<p>The eighty thousand people living in Uruk by 3000 BC sheltered behind walls that were forty feet high and six miles long. Archaeologists estimate these to have cost over five million man-hours to build. The fourth-millennium city occupied about 1.7 square miles, a little bit less than imperial Rome at its peak (2.1 square miles) and larger than classical Athens.</p><div><p><span>Article continues after advertisement</span></p></div>
<p>At the archaeological site of Uruk, the residential buildings, workshops, and barracks have not yet been excavated. Thus it is still the case that “very little about the actual conditions of life in the city is known.” Yet this is certain: Uruk was the world’s only major city of the fourth millennium BC, marked by public buildings that were “unprecedented and unrivaled at the time.”&nbsp; Most of the labor for such civic projects in Sumer came from free laborers requiring recompense for their work. Trade in livestock and agricultural produce fed them and the residents of nearby towns. The Sumerians needed a way to keep track of it all. This was the setting in which writing was born.</p>
<p>The earliest writing and the earliest direct precursors of writing, all from the second half of the fourth millennium, have been found at Uruk. Initially, clay tokens the size of a thimble would be formed to represent the sorts of things that a person might own and trade, such as sheep. For convenience, these tokens would then be put into a larger, hollow clay ball a little smaller than a grapefruit. These clay spheres, called “bullae,” served as something like sealed wallets or envelopes for the information within. On its exterior, the bulla would then be impressed with authenticating marks from cylindrical seals rolled upon the clay surface.</p>
<p>At Uruk some of these bullae have been found with additional marks impressed onto their surfaces. These marks indicated the number of tokens contained inside. It was an obvious step. The next step then suggested itself. With the contents marked on the exterior, there was no need for the little tokens rattling around inside. By 3300 BC, the information was instead simply scratched onto the surface of the spheres. The Sumerians had invented writing.</p>
<p>It is the only invention that has ever rivaled that of agriculture for its transformational effect upon human existence. Eventually flat clay tablets replaced the bullae.</p>
<p>At this stage writing was almost purely pictographic. Characters signified their objects through more or less recognizable images. Any given pictograph might mean several different things. “Mountain”—a right-side-up pyramid formed by three convex half circles—also meant “foreign lands,” for Sumer was completely flat. Consequently the same character also signified “conquest.” Shown together with the symbol for “woman,” a downward-pointing triangle with a notch at the bottom tip, the two symbols meant a woman captured from far away: “slave-woman.”</p><div><p><span>Article continues after advertisement</span></p></div>
<p>Pictographs were originally drawn on wet clay with a sharp-pointed object. Clay was an ideal medium for the Sumerians. It was cheap and abundant on the floodplain. Clay tablets were easy to make and prepare, although it is still not known how the larger ones were kept wet and impressionable. Sumerian scribes eventually wrote for the most part as we do, from left to right, top to bottom.</p>
<p>A typical tablet might be two to three inches high and half again as wide, with writing often going all the way to the margins. Incisions toward the bottom of archaic Iraq’s writing tablets tend to be visibly less deep and clear than those at the top of tablets, as the drying clay became harder to work. Once the inscribed clay had dried in southern Mesopotamia’s hot sun, it would endure for scores of centuries, and possibly forever, if left somewhere still and dry. Tablets made from such cheap and ubiquitous material were easily discarded once no longer needed. To the delight of archaeologists dozens of centuries later, they were thrown into heaps or used to fill the spaces beneath floors.</p>
<p>The original pictographs were for the most part recognizably indicative of something physical: a plow or a mountain, a head or a hand. But clay as a two-dimensional medium is ill-suited to both detail and curves. Around the year 2900, scribes discovered that impressing a sequence of lines with a straight-edged implement such as a cut reed was easier than tracing with a pointed implement. Reeds are flat, with a spine along one edge. Thus the mark made by each impression of the cut-off reed comprised a straight line with a wedge at its tip. By 2100, Sumerian scribes possessed a fast, well-developed script. Almost four thousand years later, in 1700 AD, cuneiform was named after the Latin word for wedge, <em>cuneus</em>, by the court interpreter of Eastern languages at the court of William III of England.</p>
<p>The rigid straight lines of the new technique pushed the characters away from the representational and toward the symbolic and the stylized. As centuries passed, the pictographs lost their illustrational quality. They were now “ideographs.” “Mountain,” for example, became three semicircles. By 2500 BC the recognizably representational had disappeared.</p>
<p><span>Here was the evolution from the ideographic to the phonetic. The impact was revolutionary. The boundaries of writing were now as infinite as those of speech.</span></p><p>A representational writing system has significant limitations. It is not practical to have a symbol for everything. The symbols must mean the same to all who use the writing. Users must memorize thousands of these symbols and must also be familiar with that which is being expressed. Tenses, cases, and voices are mostly impossible to depict. In the first centuries of writing, an image illustrating a foot meant “walk,” “stand up,” “ground,” “foundation,” and more besides simply “foot.” This made things difficult enough, but how would one say, “She will walk”? Or, worse, “Will she walk?” or “How will she have walked?” The ideographic method also had great limitations, as it connected writing not to words themselves, but rather to whatever it was that the words expressed. Ideographic writing bypassed spoken language, in other words. Restricted to known events and objects, unconnected to the spoken word, such a system can never cover all that language covers.</p>
<p>The next great innovation in the development of writing derived from puns. Early in the third millennium before Christ, Sumerian scribes perceived that homophones allowed them greatly to expand the verbal territory covered by the symbols they had mastered. For example, the Sumerians originally lacked a pictograph for their word sum, “to give.” To signify “give” in writing they used the pictograph for another word (“garlic”) that also was pronounced “sum.” In English such a visual pun is called a rebus. We might remember these from school. The picture of an eye next to that of a reed is one such, challenging us to remember dimly, the Sumerians with the sentence “I read.”</p>
<p>With this development, writing was now attached to sounds, to the “signifier” and not the “signified.” By the time of what is known as the Old Babylonian period, about 1500 BC, the Sumerian discovery of the power of paronomasia had helped the Uruk period’s written lexicon of two thousand characters halve in number, even as it covered more meaning. Writing was more accessible. During the Old Babylonian period even a king might be able to read, where hitherto that skill had been largely the province of scribes.</p>
<p>*</p>
<p>Shortly after the earliest development of writing, an ominous cloud appeared on Sumer’s northern horizon: a people called the Akkadians. In contrast to the native Sumerians, the Akkadians were Semitic pastoralists living in what came to be known as the Arabian Desert, the huge, dry steppe to the south and west of the Mesopotamian floodplain. By about 3000 BC, the Akkadians had moved eastward out of the desert. They settled north of Sumer in the part of Iraq that later came to be known as Babylonia.</p>
<p>The Sumerians and Akkadians lived next to each other for a thousand years. The two peoples mixed and fought constantly. There was a great degree of bilingualism, and all manner of sharing between the two languages over time. But the Sumerian and Akkadian tongues are entirely different. How, in such a setting, might a Sumerian scribe record the name of an Akkadian merchant? The need for a single script to serve a geography using two such dissimilar languages almost interchangeably was a great spur to the development of early Mesopotamian writing. Eventually the increasingly cosmopolitan quality of life on the Mesopotamian floodplain would force the script to make itself usable by people of different tongues.</p>
<p>The demands of the emerging southern Mesopotamian sprachbund required that the script deliver more and more of the nuances of speech. With writing no longer able to ignore spoken language, a crucial change happened. Most of writing’s symbols came to represent not meaning—an object, activity, or idea, for example—but rather sound. Here was the evolution from the ideographic to the phonetic. The impact was revolutionary. The boundaries of writing were now as infinite as those of speech. Once the Sumerian script became phonetic, the civilization that cuneiform defined would spread until it reached from Iran to the Mediterranean and from the Persian Gulf to Anatolia.</p>
<p>__________________________________</p>
<p><img fetchpriority="high" decoding="async" data-attachment-id="245872" data-permalink="https://lithub.com/how-the-ancient-sumerians-created-the-worlds-first-writing-system/land-between-the-rivers/" data-orig-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg" data-orig-size="340,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="land between the rivers" data-image-description="" data-image-caption="" data-medium-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg" data-large-file="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg" src="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg" alt="" width="200" height="300" srcset="https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-200x300.jpg 200w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-40x60.jpg 40w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers-33x50.jpg 33w, https://s26162.pcdn.co/wp-content/uploads/2024/11/land-between-the-rivers.jpg 340w" sizes="(max-width: 200px) 100vw, 200px"></p>
<p><em>Excerpted from </em><a href="https://bookshop.org/a/132/9780802162502" target="_blank">Land Between the Rivers: A 5,000-Year History of Iraq</a> <em>by Bartle Bull. Copyright </em><em>© 2024 by Bartle Bull. Reprinted with the permission of the publisher, Atlantic Monthly Press, an imprint of Grove Atlantic, Inc. All rights reserved.</em></p>
										
																				
																		
										<div id="about_the_author">
												<p><a href="https://lithub.com/author/bartlebull/"><img src="https://s26162.pcdn.co/wp-content/uploads/2024/11/Bartle-Bull-100x100.jpeg" width="100" height="100" srcset="https://s26162.pcdn.co/wp-content/uploads/2024/11/Bartle-Bull.jpeg 2x" alt="Bartle Bull"></a></p>
												
											</div>

										
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi CM5 is a faster, drop-in upgrade (186 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly</link>
            <guid>42254379</guid>
            <pubDate>Wed, 27 Nov 2024 09:15:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly">https://www.jeffgeerling.com/blog/2024/raspberry-pi-cm5-2-3x-faster-drop-upgrade-mostly</a>, See on <a href="https://news.ycombinator.com/item?id=42254379">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-angle.jpeg" alt="Raspberry Pi Compute Module 5"></p>

<p>The Raspberry Pi <a href="http://raspberrypi.com/products/compute-module-5/">Compute Module 5</a> is smaller than a credit card, and I already have it gaming in 4K with an eGPU, running a Kubernetes cluster, and I even upgraded my NEC Commercial display from a CM4 to CM5, just swapping the Compute Modules!</p>

<p>The Compute Module 4 was hard to get for <em>years</em>. It launched right after the COVID supply chain crisis, leading to insane scalper pricing.</p>

<p>It was so <em>useful</em>, though, that Raspberry Pi sold every unit they made, and they're inside <em>everything</em>: from <a href="https://youtu.be/cbm03jtWWL0?t=2851">commercial 3D printers</a>, to <a href="https://www.jeffgeerling.com/blog/2022/tv-thats-not-necs-pi-powered-55-display">TVs</a>, to <a href="https://pipci.jeffgeerling.com/boards_cm/blikvm-pci-express-card.html">IP KVM cards</a>.</p>

<p>After <a href="https://www.youtube.com/watch?v=Lky4FSfbc1E">pre-announcing the CM5</a> earlier this year, the biggest question was, is it a drop-in replacement?</p>

<p>Yes. <em>For the most part.</em></p>

<p>I've been testing it in <em>tons</em> of Compute Module boards, and it's been awesome seeing a 2-3x speedup just dropping in the new module.</p>

<p>It boots up in seconds, it has USB 3 instead of USB 2, and it's compatible with PCIe Gen 3 instead of Gen 2. The CPU is 2-3x faster, RAM is <em>3-4x</em> faster, <em>WiFi</em>'s faster, storage is faster... It's basically a Pi 5, but without the plugs. Most CM4 cases and accessories still work with it, just there's a LOT more bandwidth.</p>

<p>The big advantage to a Compute Module versus a Pi 5 is modularity. And I published a video today going over a ton of use cases enabled by various Compute Module carrier boards. All the ones I've tested were built for the CM4, but the CM5 is an instant drop-in upgrade:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/X4blR5Ua3S0" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>I won't cover the individual use cases in this blog post. Rather, I'll focus on CM5 benchmarking and my notes from using the hardware a few weeks.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/CM5-Pricing-Table.png" alt="CM5 Launch Pricing Table"></p>

<p>The second-most-asked question is how much it will cost. Put simply, the 8GB CM5 is roughly the same price as the 8GB CM4. The 4GB module is $5 more, and the 2GB module is $10 more. So the cheapest CM5 is now $45 instead of $35—they're dropping the 1GB option from the lineup this generation. For any specific pricing information, please consult the <a href="https://datasheets.raspberrypi.com/cm5/cm5-product-brief.pdf">CM5 Product Brief</a>.</p>

<h2>Performance</h2>

<p>Good news: you can expect almost all the same numbers as a Pi 5 with the same amount of RAM.</p>

<p>Raspberry Pi made some quality of life improvements for management, too:</p>

<ul>
<li>You can edit the EEPROM (e.g. to change the <code>BOOT_ORDER</code>) without needing another computer</li>
<li>Raspberry Pi maintains <a href="https://github.com/raspberrypi/pi-gen-micro">pi-gen-micro</a> to build smaller custom Pi OS installations</li>
</ul>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.001.boot_.png" alt="CM5 Benchmark - Boot time"></p>

<p>Right off the bat, the most refreshing difference is it boots up about 4 seconds faster.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.002.hpl_.png" alt="CM5 Benchmark - HPL Linpack FP64"></p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.003.hpl-efficiency.png" alt="CM5 Benchmark - HPL Efficiency"></p>

<p>Once it's running, the CPU is almost 3x faster. And it's also about 1.5x more efficient, according to my High Performance Linpack tests.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.004.linux_.png" alt="CM5 Benchmark - Linux compile"></p>

<p>And of course, I had to test recompiling the Linux kernel. The CM5 obliterates the CM4, it's more than 3x faster.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.005.x264-4k.png" alt="CM5 Benchmark - x264 4K Transcode"></p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.006.x264-1080p.png" alt="CM5 Benchmark - x264 1080p Transcode"></p>

<p>Video encoding is also about 3x faster. I tested x264 transcoding both at 4K and 1080p resolutions, using Phoronix. All these benchmarks are helped by the faster LPDDR4x RAM on the CM5, which I tested using tinymembench:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.007.ram_.png" alt="CM5 Benchmark - RAM speed"></p>

<p>But all these speedups consume more power, at least at full blast: the CM5 uses almost <em>twice</em> the power flat out. But at idle, the CM5 uses a tiny bit <em>less</em>: I measured 2.3 watts at the wall:</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.008.power_.png" alt="CM5 Benchmark - Power consumption"></p>

<p>And if you're deciding on which CM5 to buy, more RAM is better, at least if you're looking for raw performance.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.009.hpl-cm5.png" alt="CM5 Benchmark - HPL on various RAM capacities"></p>

<p>You can save some money with less RAM, but don't expect the performance numbers on a 2 gig model to match the 8 gig model.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/Benchmarks-CM5.010.igpu_.png" alt="CM5 Benchmark - iGPU GLMark2 V3D performance"></p>

<p>The built-in graphics are much faster, too. Just testing with GLMark I saw the score jump from about 750 to 1916. It's not nearly as fast as even an older graphics card, but any improvement is welcome, especially for things like 4K displays.</p>

<p>You might've noticed, there was a third module in most of these graphs, except that last one. That's <em>another</em> CM5, <a href="https://radxa.com/products/cm/cm5/">this one being made by Radxa</a>. It uses a Rockchip RK3588S2, which is a monster in its own right, beating the Pi on <em>almost</em> every benchmark, including efficiency.</p>

<p>The elephant in the room is all the Compute Module clones. Because of the Pi shortages, every SBC maker on the planet built their own Compute Module. Though... some work better than others. A lot are <em>faster</em> than the Pi, but pricing is fairly similar, when you compare RAM and relative performance.</p>

<p>The big difference between the Pi and all the others, though, is support. I've written how other SBCs <em>could</em> become Pi-killers—I mean the hardware is often there—but they lack <em>support</em>.</p>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/compute-module-5-clones.jpg" alt="Compute Module 5 and Clones"></p>

<p>One big part of that is the breadth of options for the Pi, which may or may not work on other Compute Modules. And if you want to try, you can expect to debug hardware and OS issues yourself. Like I couldn't get a valid GLMark score for the Radxa, because I couldn't get an OS image to boot and use the built-in Mali GPU in time for this post! It's often a frustrating experience.</p>

<p>I regularly test other Compute Modules, though, and I post <em>all</em> my test data and experiences in my <a href="https://github.com/geerlingguy/sbc-reviews">sbc-reviews GitHub repo</a>.</p>

<h2>Hardware - CM5 IO Board</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-io-board.jpeg" alt="CM5 IO Board"></p>

<p>Along with the CM5, Raspberry Pi's selling an updated IO board, for $20, with a few helpful changes. First, a power button, with the same behavior as the Pi 5. This would've saved <em>so</em> much time debugging graphics cards on the CM4.</p>

<p>Then, there's a new tiny fan header, the same one on the Raspberry Pi 5. Companies like EDAtec already have active coolers for the CM5, and I'll test some cooling options on my my 2nd channel, Level2Jeff.</p>

<p>On the port side, they got rid of the 12 volt barrel jack for power, and now they just use USB-C. They dropped down to two multipurpose Camera/Display ports. Each one has 4 lanes of MIPI bandwidth, just like the Pi 5.</p>

<p>There are still two full-size HDMI ports, an Ethernet port, and two USB type-A ports, but these are upgraded to USB 3. There's a microSD card that only works on Lite Compute Modules without eMMC, and finally an M.2 slot, with a little LED that blinks when you're using an SSD.</p>

<p>This is nice, because probably 99% of people buying these things would plug in storage. On the CM4, you had to use an awkward adapter card, but that's not required anymore.</p>

<p>Maybe we could see this on the Pi 5 someday? Or if not, maybe we could hack it using the Compute Module! That's foreshadowing...</p>

<h2>Hardware - CM5</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-memory-emmc-silkscreen.jpeg" alt="CM5 Silkscreen - RAM and eMMC options"></p>

<p>The feature that'll make the biggest impact for <em>me</em>, since I use a lotta compute modules, is this new silkscreen up in the top corner. It has resistors for the RAM and storage sizes, so the specs are right up top.</p>

<p>The major changes from the CM4 include:</p>

<ul>
<li>BCM2712 D0 stepping SoC, with 4x Cortex A76 CPU cores at 2.4 GHz</li>
<li>RP1 chip for IO expansion (GPIO, MIPI Camera/Display, 2x USB 3.0 bus, Ethernet)</li>
<li>eMMC storage is moved to the bottom of the Compute Module</li>
<li>The Wireless chip has been raised up onto a short PCB mezzanine (I believe it can be had separately now, for system integrators, maybe?)</li>
<li>The RAM is now an LPDDR4x RAM module, sporting much higher speeds (and on-chip ECC)</li>
<li>The Pi 5 PMIC is included on the CM5 board, for USB-C PD negotation or direct 5V input like on the Pi 5</li>
</ul>

<p>Other things are familiar, like the switchable PCB antenna / u.fl connector, the 2x 200-pin hirose board to board connections, and the Broadcom BCM54210PE (which <a href="https://www.jeffgeerling.com/blog/2022/ptp-and-ieee-1588-hardware-timestamping-on-raspberry-pi-cm4">enables hardware PTP timestamping support</a>).</p>

<p>I've been testing the CM5 on various carrier boards, even with eGPUs and 10 Gbps NICs on the official IO Board, and all that testing can be seen in <a href="https://www.youtube.com/watch?v=l819Nnj5PNc">my YouTube video on the CM5</a>.</p>

<h2>Conclusion</h2>

<p><img width="700" height="auto" src="https://www.jeffgeerling.com/sites/default/files/images/cm5-compute-blade.jpeg" alt="CM5 in Compute Blade"></p>

<p>But tying up the CM5, Raspberry Pi kept the price the same for the 8 gig model; those start at $75 for the Lite version. For 4 gig, they're going up five bucks, and for 2 gig, it's up 10 bucks, from $35 to $45.</p>

<p>They're dropping the 1 gig model from the lineup, and in reality, a lotta applications choke with less than 2 gigs of RAM, so I'm not surprised.</p>

<p>When the Compute Module 4 came out, it changed <em>literally</em> everything about the Compute Module. Including the form factor. That meant everything built for the CM1 and CM3 had to be redesigned, and it made many hardware developers angry.</p>

<p>Luckily, this time they kept the form factor, meaning for <em>most</em> things, it's a drop-in upgrade, where you get 2-3x faster performance, and at least for the larger models, the same price.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: App that asks 'why?' every time you unlock your phone (638 pts)]]></title>
            <link>https://play.google.com/store/apps/details?id=com.actureunlock&amp;hl=en_US</link>
            <guid>42254156</guid>
            <pubDate>Wed, 27 Nov 2024 08:34:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://play.google.com/store/apps/details?id=com.actureunlock&#x26;hl=en_US">https://play.google.com/store/apps/details?id=com.actureunlock&#x26;hl=en_US</a>, See on <a href="https://news.ycombinator.com/item?id=42254156">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-g-id="description"><p>Intenty helps you build a healthier relationship with your phone through gentle awareness prompts that appear right when you need them – at unlock. No blockers, no limits, just mindful choices.</p><p>🎯 Thoughtful nudges<br>Choose from carefully crafted default nudges or create your own:</p><p>* Intention - Set clear purposes for each phone session<br>* Necessity - Question if you really need to use your phone now<br>* Grounding - Return to the present moment<br>* Posture - Remember your physical wellbeing<br>* Minimalism - Stay focused on what truly matters</p><p>✨ Smart customisation</p><p>* Create personal nudges with your own prompts<br>* Control how often nudges appear with intensity settings<br>* Set cooldown periods to prevent prompt fatigue<br>* Export your data for personal insights</p><p>🎨 Minimalist design</p><p>* Clean, distraction-free interface<br>* Full-screen prompts for maximum impact<br>* Thoughtfully crafted user experience</p><p>🛡️ Privacy first</p><p>* Works 100% locally<br>* No ads or tracking<br>* No metrics or analytics collection<br>* Your phone, your data, your control</p><p>💡 Why it works<br>Instead of blocking apps or setting arbitrary limits, Intenty helps you build awareness naturally. Each unlock becomes an opportunity to check in with yourself, making mindful decisions about your phone use throughout the day. Perfect for anyone looking to check their phone less and use their phone more mindfully.</p><p>🌟 Who it's for<br>Perfect for anyone who wants to:</p><p>* Reduce mindless phone-checking<br>* Stay present and focused<br>* Build better digital habits<br>* Maintain productivity without restrictive blocks</p><p>Would you be ready to transform your relationship with your phone? Download Intenty today and make every unlock count.</p><p>🔐 Note on Intenty permissions usage: </p><p>Intenty might use quite permissive Android capabilities such as Display over other apps, Battery optimization disablement, or Accessibility service. All permissions are used exclusively for features to work locally on your device.</p><p>Accessibility service is used exclusively to let you quickly turn off your phone's screen with a Lock button. The service is optional, disabled by default, and does not collect nor share any data.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I Wrote "Janet for Mortals" (218 pts)]]></title>
            <link>https://ianthehenry.com/posts/janet-for-mortals/</link>
            <guid>42253241</guid>
            <pubDate>Wed, 27 Nov 2024 05:34:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ianthehenry.com/posts/janet-for-mortals/">https://ianthehenry.com/posts/janet-for-mortals/</a>, See on <a href="https://news.ycombinator.com/item?id=42253241">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>

<div><p>I wrote a book.</p>
<p>It’s called <a href="https://janet.guide/"><em>Janet for Mortals</em></a>, and it’s free, and it’s on the internet, and you can read it right now.</p>
<p>And you <em>should</em> read it right now, instead of reading this blog post, because this blog post is not very interesting if you haven’t read the book. Heck, this blog post is not very interesting even if you <em>have</em> read the book. This blog post is a thinly-veiled promotion for my book to slip into my newsletter and RSS feed, with just enough additional content to pad it out to the length of a real post.</p>
<p>The book is about <a href="https://janet-lang.org/">Janet</a>, a programming language that <a href="https://ianthehenry.com/posts/janet-game/">I have written about before</a>. I’ve been using Janet a lot lately, and I’ve been having a lot of fun with it, and I think that more people should know about it so that they can have fun with it too. People like you.</p>
<p>I’m not really going to talk much about <em>why</em> you should read the book, or even why you should care about Janet in the first place – that will come in a later post. Instead, this is going to be a short retrospective of what it was like to write my first technical book.</p>
<hr>
<p>We’ll start with some numbers.</p>
<p>It took me twenty weeks to write the book, working in my spare time. I had originally estimated twelve weeks, which turned out to be a really good guess for how long I spent <em>writing</em> the book, but I didn’t account for how much time I would spend working on book-adjacent coding side quests.</p>
<p>The final book is pretty short: 44k words of English prose, if you don’t count any of the code snippets. I tried to find an example of a famous book with a similar word count to put that number in perspective, and the best I can do is <em>The Great Gatsby</em>, which clocks in at 47k words. It’s right on the border between novella- and novel-length, but it’s less than half as long as <a href="https://ianthehenry.com/posts/how-to-learn-nix/">my series of posts about Nix</a>, which is sort of terrifying.</p>
<p>But writing English words was only a fraction of the work. Over the course of those five months, I also spent a lot of time on:</p>
<ul>
<li><a href="https://janet.guide/">the website itself</a></li>
<li><a href="https://github.com/ianthehenry/jimmy"><code>jimmy</code></a>, bindings to a C++ library of persistent data structures</li>
<li><a href="https://toodle.studio/">Toodle.Studio</a>, an interactive turtle graphics playground</li>
<li><a href="https://github.com/ianthehenry/cmd"><code>cmd</code></a>, a command-line argument parsing library</li>
<li><a href="https://github.com/ianthehenry/judge"><code>judge</code></a>, an inline snapshot testing framework</li>
<li><a href="https://github.com/ianthehenry/to-do"><code>to do</code></a>, a command-line todo list manager</li>
</ul>
<p>These things are not very interesting by themselves, but this blog post just exists to promote the book, so I’m going to reflect on them now. You are welcome to stop reading at any point and <a href="https://janet.guide/">go read the actual book instead</a>.</p>
<h2 id="the-website-2-weeks">The Website (2 weeks)</h2>
<p>The most interesting thing about <em>Janet for Mortals</em> is that it has a built-in repl. At any point you can press escape and pull it up, and it’s docked to the bottom of the page, just out of the way of the text. I’m sure that it’s not the first programming book to include a repl like this, but I’ve never actually seen it done before.</p>
<p>The editor portion of the repl is <a href="https://codemirror.net/">CodeMirror</a>, which I had used previously in <a href="https://ianthehenry.com/posts/janet-for-mortals/bauble.studio/">Bauble</a>. CodeMirror doesn’t know anything about Janet out of the box, but I had already implemented some basic <a href="https://ianthehenry.com/posts/janet-for-mortals/github.com/ianthehenry/codemirror-lang-janet">language support</a> when I wrote Bauble.</p>
<p>But I skipped a lot of the Janet language when I was writing the grammar for Bauble, like <code>``multi`backtick`quoted``</code> strings, because they didn’t really matter in Bauble’s constrained DSL. But they mattered for the book, so I had to spend time figuring out how to implement them.</p>
<p>But fleshing out the CodeMirror grammar (or more precisely, the <a href="https://lezer.codemirror.net/docs/guide/">Lezer</a> grammar that CodeMirror uses) had an unexpected side effect: it let me re-use the grammar to do syntax highlighting for the code snippets in the book itself.</p>
<p><em>Janet for Mortals</em> is just a static site, but no static site generators that I know of know how to highlight Janet code. For a long time the book was entirely black-and-white, which I don’t mind, but I knew I needed to add some color before I released it upon an unsuspecting public – I think Janet’s syntax is pretty unfamiliar to most people reading the book, and anything to make it look friendlier helps.</p>
<p>So I knew that I’d have to roll my own syntax highlighter of some kind, and I ended up just writing a simple static site generator in <a href="https://github.com/apenwarr/redo"><code>redo</code></a>, which was not a very good fit, but… well, least bad choice that I know of. The meat of the generator is written in JavaScript, so that I could plug in the Lezer grammar for free, but it’s all tied together by a fragile web of shell.</p>
<p>I used <a href="https://github.com/remarkjs/remark">Remark</a> to implement the parsing of the book’s source, and it was nice how much control I had over the generated output. I even added a simple extension to label code blocks, which was pretty easy.</p>
<p>I also re-used Remark in the client itself, as part of the repl. The docstrings in the Janet standard library are written in Markdown, and I’m actually parsing and rendering them to HTML on the fly as part of the repl autocomplete.</p>
<p>I spent a long time getting the repl autocomplete working well – because this book was written for newcomers to the Janet language, I thought that the help-as-you-type would be really useful for people trying to follow along in the repl.</p>
<p>Autocomplete works by dynamically querying the Janet environment via WebAssembly at repl startup. This means if you define a new symbol with a docstring, it won’t actually appear in the autocomplete output, but I think that’s… fine. I could re-generate the autocompletions after every command is run, but… I don’t think there’s much value in that.</p>
<p>The most interesting part of the repl is probably the <code>(report)</code> function, which takes a string and POSTs it to a simple web server that sticks it into a SQLite database for me to peruse later. It’s not really any different than a comment box, but I feel like there’s something fun about doing it from the repl. I’m really glad that I added it – it’s been fun reading people’s feedback, and I’ve fixed quite a few errors because of it. I’m sad that I didn’t implement any way to respond, though!</p>
<p>The backend for reports is <em>not</em> written in Janet; it’s a tiny Haskell application that just listens for POST requests and sticks them into a SQLite database.</p>
<p>There are people using Janet to make websites, but I am not one of them: the primary thing I want out of a web server is security, and I just don’t think Janet or its HTTP libraries are “battle-tested” enough for me to connect them to the internet.</p>
<p>I also just think the idea of using a dynamically-typed interpreted language to build a web service is crazy, when there are optimizing compilers <em>right there</em>, but that’s a whole other conversation.</p>
<h2 id="jimmy-1-week"><code>jimmy</code> (1 week)</h2>
<p>I spent a little bit of time writing bindings to <a href="https://github.com/arximboldi/immer">immer</a>, a library of persistent data structures. I never finished them, and probably won’t, at least not until I have a use for them. But as a demonstration of how to interop with C++ code from Janet, I think it was successful.</p>
<h2 id="httpstoodlestudio-2-weeks"><a href="https://toodle.studio/">https://toodle.studio</a> (2 weeks)</h2>
<p>Last year I wrote a little art playground called <a href="https://bauble.studio/">Bauble</a>. It was my first time embedding Janet in the browser, and I had a pretty tough time figuring out how to do that.</p>
<p>There weren’t a lot of resources back then about embedding Janet <em>period</em>, and doing it in the browser added an extra layer of difficulty. I’d never used WebAssembly or Emscripten before, or even TypeScript, and it turns out there are no tutorials on how to write TypeScript Emscripten WebAssembly Janet bindings, so I spent a while figuring out how all the pieces worked together.</p>
<p>And I’m glad I did, because I think the final product is really neat: it’s a website that is <em>not written in JavaScript</em>. I mean, a lot of it is. The UI is, still. But the actual application logic is all Janet.</p>
<p>I thought that that was a really useful superpower of Janet, and I wanted to make the technique more accessible. In fact this was a big motivation for writing this book about Janet – I wanted people to know that this was <em>possible</em> in the first place, and I wanted to make it easier to get started with it.</p>
<p>But <em>Janet for Mortals</em> doesn’t talk about Bauble at all. Bauble is actually not very interesting from an interop perspective: Bauble is completely stateless, and basically uses Janet to implement a pure function from strings to strings (they’re… pretty complicated strings; Bauble is a Janet-to-GLSL compiler, but they are strings nonetheless). I didn’t think it was a very good showcase for everything you can do with Janet, so I briefly considered talking about how I implemented the repl in the book, but I decided that that was far too boring. So I wrote <a href="https://toodle.studio/">Toodle.Studio</a> – an obvious fork of Bauble – instead.</p>
<p>Toodle.Studio <em>seems</em> a lot simpler than Bauble, but the interop with JavaScript is much more involved. Toodle.Studio has to execute long-running Janet programs asynchronously over time. It has to think about memory management, as the JavaScript code retains multiple references to the same Janet values. It has to pass complex nested data structures to and from Janet, going through C++ as an intermediary. It does a very simple version of all of these things, but it’s a pretty good showcase for the techniques.</p>
<p>But the most interesting part of Toodle.Studio isn’t the interop or the memory management. The most interesting part of Toodle.Studio is the logo.</p>
<p>I wasn’t really planning on making a logo – this is a demo project for a book, after all – but sadly I had no choice. When I was getting ready to release the website, I showed it to my partner, because it’s rare that I work on something comprehensible to normal human beings. I thought she’d like it, but she was <em>aghast</em>.</p>
<p>“You said you were working on turtle graphics,” she said. “Where are the turtles?”</p>
<p>I tried to explain that the turtles aren’t <em>really</em> turtles, that it’s like a flea circus, and the turtles are metaphors – but she was having none of it. The lack of turtles was a base betrayal, so I had to spend a day or so <a href="https://gist.github.com/ianthehenry/612c980f0db04ea3c2ccab2741475870">modeling a cute animated turtle in Bauble</a> to act as the logo. And making its eyes follow the mouse, of course.</p>
<p>Relationship repaired. The logo wound up being my favorite part of the site, and it was fun to get a chance to use Bauble to make something “real.”</p>
<h2 id="cmd-2-weeks"><code>cmd</code> (2 weeks)</h2>
<p>One of the things that I spent the most time on, oddly enough, was a command-line argument parsing library. The library itself only gets, like, three paragraphs of screen time in the book, but it was very important to me that it exist before the book came out, so that I could unambiguously claim that “Janet is an excellent scripting language.” Before <code>cmd</code>, that was still true, but the phrasing was more “Janet is a great choice for scripting and writing CLI tools, except that the argument parsing is kind of janky, sorry, but hey at least it’s better than Bash.”</p>
<p><code>cmd</code> was heavily inspired by <a href="https://ocaml.org/p/core/latest/doc/Core/Command/Param/index.html"><code>Core.Command</code></a>, which is the best command-line argument parsing library that I have ever used. I’m extremely spoiled by how easy it makes writing CLIs, and I wanted to replicate that experience in Janet. <code>cmd</code> is definitely not as good as <code>Core.Command</code> – types, my goodness, types make everything so much easier – but it has 95% of the features I care about, and the concise notation makes it more pleasant to use in ad-hoc scripts.</p>
<p>One thing that I miss, though, is that <code>Core.Command</code> autogenerates Bash completion functions. I want to add that to <code>cmd</code> one day – the API is designed so that that will be <em>possible</em> to do. But… so many projects, so little time.</p>
<h2 id="judge-1-week"><code>judge</code> (1 week)</h2>
<p><code>judge</code> was <a href="https://ianthehenry.com/posts/janet-game/judging-janet/">one of the first things that I wrote in Janet</a>, all the way back in 2021. I think that it worked pretty well considering that I didn’t know anything about Janet when I wrote it, but now I do, so I rewrote it from scratch. Not only is the API much nicer to use now, but the implementation is way simpler – and easier to make changes to.</p>
<p>The main differences between Judge v1 and Judge v2 are that tests can now appear inside regular source files, not just the <code>test/</code> directory, and I added the <code>test-macro</code> and <code>test-stdout</code> helpers, which are <em>extremely</em> useful. <a href="https://blog.janestreet.com/the-joy-of-expect-tests/">The OCaml equivalent of <code>test-stdout</code></a> is pretty much the only way that I write tests professionally, because OCaml doesn’t really have a way to embed arbitrary data in source code, so we turn everything into a string.</p>
<p>After publishing the book – which <a href="https://janet.guide/testing-and-debugging/">has a whole chapter on testing with Judge</a> – I had a chance to spend a little more time improving Judge, and I finally added an <code>--interactive</code> mode, which I’ve been wanting for a long time. And since I’m not spending all my time working on this book anymore, I’ve actually had a few opportunities to <em>use</em> the new Judge, and I gotta say: it’s nice. It’s really nice. I know I can’t impress upon you just how nice it is in this post – it really needs a demo, and I’m too lazy to record one right now – but I’m very happy with how it feels to use it to write Janet.</p>
<h2 id="to-do-2-hours"><code>to do</code> (2 hours)</h2>
<p>I picked this project to highlight for <a href="https://janet.guide/scripting/">the scripting chapter</a>, because it’s a non-trivial thing that I had done in Bash before, and actually found it pretty painful. Parsing multi-line text with Sed is not fun, and trying to do date manipulation with <code>date</code> in a way that works the same on macOS and Linux is… basically impossible, as far as I can tell. I quickly ran into the limits of my patience, and gave up on the idea some years ago.</p>
<p>It was really fun to return to this with the full power of PEGs and <a href="https://github.com/andrewchambers/janet-sh"><code>sh</code></a> and <a href="https://github.com/ianthehenry/cmd"><code>cmd</code></a> at my disposal. I immediately surpassed all of features of my original Bash todo list, and was able to add quite a few more (like <code>fzf</code> multi-select – good luck constructing null-terminated strings in Bash).</p>
<p>The book covers a very simplified version of the app – it can’t schedule tasks for the future, and there’s no concept of “skipping” tasks. Those features are important for <em>my</em> todo list workflow, but they are probably not important for <em>your</em> todo list workflow, so the book only discusses the core functionality of adding things to a list and crossing them off. I think that it makes a good starting point to run with and make your own – paired with <a href="https://github.com/ianthehenry/zsh-autoquoter"><code>zsh-autoquoter</code></a>, it’s actually a surprisingly useful app!</p>
<hr>
<p>If you put all of these projects together, I was writing code for almost half the time that I spent working on the book. Eight out of twenty weeks, plus some periods where I was doing both at once.</p>
<p>I didn’t really budget for that going into this. I thought that I’d improve Judge, and I thought that I’d write an argument parser. But I thought that writing an argument parser would be <em>way easier</em> than it actually was. And I thought that I’d just talk about Bauble – it never occurred to me that I’d write <em>another</em> art playground just because Bauble was <em>too easy</em>.</p>
<p>So that’s the story of writing the book. Or really, everything <em>but</em> writing the book. All the other things. The writing itself isn’t that interesting. I wrote it in Markdown, in Sublime Text, which is my favorite editor for writing long-form prose. I have nothing interesting to say about that part.</p>
<p>Two new versions of Janet came out while I was writing the book, and I did have to go back and update the chapters on debugging and native modules to keep up with changes to the language. I plan on keeping the book up to date with the latest Janet release – we’ll see how long I can keep that up.</p>
<hr>
<p>I haven’t done much to promote the book yet. I <a href="https://news.ycombinator.com/item?id=35386405">submitted it to Hacker News</a>, and I <a href="https://lobste.rs/s/duwkz7">submitted it to Lobsters</a>, and I wrote <a href="https://twitter.com/ianthehenry/status/1641797578739306499">a very half-hearted tweet about it</a>. The reception was pretty much as good as I could have hoped for: it was on the Hacker News front page all day, and even held the number one spot for a while.</p>
<p>What does that actually mean? Well, according my Nginx access logs, I got:</p>
<ul>
<li>30,025 unique visitors on Friday</li>
<li>9,568 unique visitors on Saturday</li>
<li>3,777 unique visitors on Sunday</li>
</ul>
<p>Those numbers don’t mean very much, though. Those are just people who clicked on a link – the number of people who actually <em>read</em> the book is much, much smaller.</p>
<p>I don’t actually know how much smaller exactly, because I don’t have any client-side behavior-tracking analytics on the site. But I can sort of try to guess, by looking at my access logs. It seems like retention is not great:</p>
<ul>
<li>Chapter One had 22% as many visitors as the home page.</li>
<li>Chapter Two had 20% as many visitors as Chapter One.</li>
<li>Chapter Three had 69% as many visitors as Chapter Two.</li>
<li>Chapters Four and Nine, “<a href="https://janet.guide/pegular-expressions/">Pegular Expressions</a>” and “<a href="https://janet.guide/xenofunctions/">Xenofunctions</a>,” had more visitors than Chapter Three.</li>
</ul>
<p>I’m guessing that last bit is because people clicked on those chapters to see what they were about, which just goes to show that unique visitor count is not a very dependable metric.</p>
<p>My best attempt at answering the question “how many people are actually reading the book” is 387, as of the end of the launch weekend. So far 387 unique IP addresses have loaded five or more distinct chapters, which is probably a decent proxy for the metric I care about.</p>
<p>I really had no expectations for what these numbers would be before I launched the book. It’s a big time commitment to read a weird book about a programming language you’ve barely heard of, and 387 seems simultaneously low (compared to, say, any blog post) and high (I don’t think <em>I’ve</em> ever read a book off a HN link). But it’s more than zero!</p>
<p>Alright, I think that’s enough. I’ll close with some fun facts:</p>
<ul>
<li>
<p>The Janet language is named after an immortal being in <a href="https://en.wikipedia.org/wiki/The_Good_Place"><em>The Good Place</em></a> who helps mortals navigate the afterlife, hence the title.</p>
</li>
<li>
<p>The chapter with the fewest visits is currently “Testing and Debugging,” despite being the third-to-last chapter. This does not surprise me at all, but I think it’s a shame: the last three chapters are by far the most interesting in the book, and the style of testing described in that chapter is one of the biggest productivity upgrades that I have personally experienced in my engineering career.</p>
</li>
<li>
<p>So far I’ve received 494 reports from the built-in repl reporting feature. Most of these were of the “hey nice book” or “testing” variety, but I’ve gotten several dozen typo reports, clarification requests, or otherwise useful comments through it as well.</p>
</li>
<li>
<p>The most interesting report was just “you should listen to this song: <a href="https://www.youtube.com/watch?v=46i3LbIbbhI">https://www.youtube.com/watch?v=46i3LbIbbhI</a>.” No context, no explanation, and I have no way to reply for clarification. But… thanks! It’s a good song. I’m into it.</p>
</li>
<li>
<p>A few people asked me questions without including any kind of contact info, so I have no way to answer them. I hope that they found peace, wherever they are. I’m not ignoring you. I just… I only implemented an extremely primitive one-way feedback function.</p>
</li>
<li>
<p>I’m going to plug the book one last time.</p>
</li>
</ul>
<p>With feeling: <em><a href="https://janet.guide/">Janet for Mortals</a>!</em> Out now! The first infinity visitors get their copy for free!</p></div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The capacitor that Apple soldered incorrectly at the factory (446 pts)]]></title>
            <link>https://www.downtowndougbrown.com/2024/11/the-capacitor-that-apple-soldered-incorrectly-at-the-factory/</link>
            <guid>42253119</guid>
            <pubDate>Wed, 27 Nov 2024 05:10:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.downtowndougbrown.com/2024/11/the-capacitor-that-apple-soldered-incorrectly-at-the-factory/">https://www.downtowndougbrown.com/2024/11/the-capacitor-that-apple-soldered-incorrectly-at-the-factory/</a>, See on <a href="https://news.ycombinator.com/item?id=42253119">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				
<p>There have been <a href="https://68kmla.org/bb/index.php?threads/lciii-recap-apple-design-fault-47uf-reversed.27834/" target="_blank" rel="noreferrer noopener">some past rumblings</a> on the internet <a href="https://tinkerdifferent.com/threads/lciii-c22-polarity.2708/" target="_blank" rel="noreferrer noopener">about a capacitor being installed backwards</a> in Apple’s <a href="https://en.wikipedia.org/wiki/Macintosh_LC_III" target="_blank" rel="noreferrer noopener">Macintosh LC III</a>. The LC III was a “pizza box” Mac model produced from early 1993 to early 1994, mainly targeted at the education market. It also manifested as various consumer Performa models: the 450, 460, 466, and 467. Clearly, Apple never initiated a huge recall of the LC III, so I think there is some skepticism in the community about this whole issue. Let’s look at the situation in more detail and understand the circuit. Did Apple actually make a mistake?</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450.jpg" target="_blank" rel=" noreferrer noopener"><img fetchpriority="high" decoding="async" width="1024" height="425" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450-1024x425.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450-1024x425.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450-300x125.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450-768x319.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/performa450.jpg 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>I participated in the discussion thread at the first link over a decade ago, but I never had a machine to look at with my own eyes until now. I recently bought a Performa 450 complete with its original leaky capacitors, and I have several other machines in the same form factor. Let’s check everything out!</p>



<p>Here’s the affected section of the board before I removed the original capacitors. You can see that all three of these caps (C19, C21, and C22) have their negative side pointing upward, matching the PCB silkscreen that has the + sign at the bottom.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps.jpg" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="1024" height="999" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps-1024x999.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps-1024x999.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps-300x293.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps-768x750.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/originalcaps.jpg 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>If the miscellaneous gunk and ugly appearance of the solder joints in this picture isn’t a warning sign that you should replace the SMD electrolytic capacitors in any classic Mac from the ’90s at this point, I don’t know what is! Let’s take a closer look at the circuit after I removed them and cleaned everything up a bit.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved.jpg" target="_blank" rel=" noreferrer noopener"><img decoding="async" width="1024" height="1022" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved-1024x1022.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved-1024x1022.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved-300x300.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved-150x150.jpg 150w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved-768x767.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/capsremoved.jpg 1536w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Yikes, C21 leaked really badly and damaged the solder mask and the copper underneath. When I removed it, there was a big puddle of goo sitting there. I haven’t installed new capacitors on this board yet, but I’m probably going to need to scrape more of that dark crud from the copper and cover it all up with UV-curable solder mask. Luckily, it’s just the ground plane so it’s not a huge deal.</p>



<p>Anyway, the important thing to note in this picture is that the negative terminal of each capacitor goes to the ground plane. The positive terminals all head over to pins on the power supply connector.</p>



<p>What’s happening here is there is one bulk capacitor for each of the three power rails provided by the power supply. C19 is for +5V, C21 is for +12V, and C22 is for -5V. You can see the trace from C22’s positive terminal going directly to the -5V pin on the power supply connector.</p>



<p>This arrangement makes sense for the two positive power rails, but it’s backwards for the -5V rail. If the image above isn’t proof enough for you, here are a couple of pictures with my multimeter definitively showing that the positive terminal of C22 goes to -5V and the negative terminal goes to ground. That means when the system is powered on, there will be -5V across this capacitor.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1.jpg" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="1024" height="761" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1-1024x761.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1-1024x761.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1-300x223.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1-768x571.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter1.jpg 1536w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></a></figure>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2.jpg" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="1024" height="615" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2-1024x615.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2-1024x615.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2-300x180.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2-768x461.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/multimeter2.jpg 1536w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></a></figure>



<p>I really don’t need to do any additional analysis at this point in order to say that this is just plain wrong. You aren’t supposed to have a negative voltage across this type of capacitor. There’s a reason they have a marking that identifies the negative side. The voltage at the positive end should be greater than or equal to the voltage at the negative end. In other words, this capacitor’s positive end should have been connected to ground and the negative end should have been connected to -5V.</p>



<p>Let’s compare and contrast this circuit with the corresponding circuit on an original Mac LC, which uses the exact same power supply. This is another system with its original leaky caps:</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps.jpg" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="931" height="1024" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps-931x1024.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps-931x1024.jpg 931w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps-273x300.jpg 273w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps-768x845.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps-1397x1536.jpg 1397w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lccaps.jpg 1536w" sizes="auto, (max-width: 931px) 100vw, 931px"></a></figure>



<p>They installed it correctly on the original LC (and the LC II). -5V goes to the negative end of the capacitor, and ground goes to the positive end, resulting in a net voltage of positive 5 volts across it.</p>



<p>What about the LC 475, which is the successor to the LC III? If Apple miraculously discovered a special exception to the laws of physics during development of the LC III, I would expect them to have continued following this new rule with the design of the LC 475.</p>



<figure><a href="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps.jpg" target="_blank" rel=" noreferrer noopener"><img loading="lazy" decoding="async" width="1024" height="686" src="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps-1024x686.jpg" alt="" srcset="https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps-1024x686.jpg 1024w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps-300x201.jpg 300w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps-768x515.jpg 768w, https://www.downtowndougbrown.com/wp-content/uploads/2024/11/lc475caps.jpg 1536w" sizes="auto, (max-width: 1024px) 100vw, 1024px"></a></figure>



<p>Nope! It’s back to the same (correct) orientation that was used on the original LC.</p>



<p>After seeing it myself and comparing the circuit with other Mac models of the era, I’m very confident that Apple made a boo-boo on the LC III. It’s not just a factory component placement issue; the PCB’s silkscreen is also incorrect. It’s basically the hardware equivalent of a copy/paste error when you’re writing code. I’m hoping to raise awareness of this mistake because all of the (very useful) recapping guide collections I’ve found on the Internet strangely fail to mention this reversed capacitor for some reason, even though it’s known to have caused problems for many people.</p>



<p>But, you may ask, why didn’t it matter with the original liquid-filled electrolytic capacitor fitted on the board? Why didn’t this cause a huge uproar back in the day? Why didn’t everyone’s LC III explode in a giant fireball? Well, for one, the original capacitor was obviously tolerant of this mistake. It was rated for 16V but only -5V was being put across it. According to what I’ve read online, that’s more than enough reverse voltage to permanently damage this type of capacitor, but it may not be enough to cause it to violently explode. Plus, it is only involved with the -5V rail, which is really only needed for the RS-422 serial ports. The capacitor might not have been doing its job properly if it was installed backwards, but it didn’t seem to really be hurting anything.</p>



<p>With the way that a lot of people in the hobby these days (including me) are using tantalum capacitors as replacements, I think it’s potentially dangerous that this backwards capacitor isn’t widely documented. Although the computer seems to work okay in this configuration with a normal electrolytic capacitor like what was installed by the factory, tantalum capacitors are not quite as forgiving when installed in reverse. <a href="https://retroviator.com/apple-macintosh-lc-iii/" target="_blank" rel="noreferrer noopener">Multiple people</a> online have observed that when they have a tantalum capacitor installed in the original incorrect orientation, they end up with an incorrect voltage on the -5V rail. The <a href="https://68kmla.org/bb/index.php?threads/lciii-recap-apple-design-fault-47uf-reversed.27834/" target="_blank" rel="noreferrer noopener">original poster about this issue</a>, paul.gaastra, said that with the tantalum capacitor installed backwards it was drawing 1.3 amps (way too much) and the voltage was only -2.3V. At best, this is going to result in serial port problems. At worst, <a href="https://68kmla.org/bb/index.php?threads/lciii-recap-apple-design-fault-47uf-reversed.27834/page-2#post-525187" target="_blank" rel="noreferrer noopener">you’re asking for the capacitor to explode or catch on fire</a>. It’s probably not good for the power supply, either; it’s only rated for 75 mA on the -5V rail.</p>



<p>The bottom line is that Apple’s silkscreen markings and factory placement for C22 on the LC III are flat out wrong. There’s no other correct answer. Please, if you are recapping one of these machines, install C22 backwards from what the silkscreen on the PCB says. If you don’t believe me, or want to double check for yourself, you can easily verify this with a multimeter in continuity test mode with the system powered off. The positive end of the cap needs to be connected to ground, and the negative end needs to be connected to -5V. Using your multimeter’s DC voltage mode, if you power on the system, you should see 5V across the capacitor (negative probe to negative side of cap, positive probe to positive side of cap). That’s how it is on <em>every</em> other Mac with a -5V rail.</p>
			  
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI hits pause on video model Sora after artists leak access in protest (129 pts)]]></title>
            <link>https://www.washingtonpost.com/technology/2024/11/26/openai-sora-ai-video-model-artists-protest/</link>
            <guid>42252806</guid>
            <pubDate>Wed, 27 Nov 2024 03:59:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.washingtonpost.com/technology/2024/11/26/openai-sora-ai-video-model-artists-protest/">https://www.washingtonpost.com/technology/2024/11/26/openai-sora-ai-video-model-artists-protest/</a>, See on <a href="https://news.ycombinator.com/item?id=42252806">Hacker News</a></p>
Couldn't get https://www.washingtonpost.com/technology/2024/11/26/openai-sora-ai-video-model-artists-protest/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[I Didn't Need Kubernetes, and You Probably Don't Either (330 pts)]]></title>
            <link>https://benhouston3d.com/blog/why-i-left-kubernetes-for-google-cloud-run</link>
            <guid>42252336</guid>
            <pubDate>Wed, 27 Nov 2024 02:26:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://benhouston3d.com/blog/why-i-left-kubernetes-for-google-cloud-run">https://benhouston3d.com/blog/why-i-left-kubernetes-for-google-cloud-run</a>, See on <a href="https://news.ycombinator.com/item?id=42252336">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Kubernetes often represents the ultimate solution for container orchestration, but my experience has led me to leave it behind in favor of a simpler, cost-effective solution using <a href="https://cloud.google.com/run">Google Cloud Run</a>. This transition has made my infrastructure projects easier to manage, more scalable, and significantly cheaper. Here’s why I made this choice and how Cloud Run offers a better fit for my needs going forward.</p>
<h2>How I ended up on Kubernetes</h2>
<p>First, let's quickly look at how we ended up on Kubernetes. We has launched <a href="https://clara.io/">Clara.io (now sunset)</a>, an online 3D editor and rendering platform, in 2013. We cost optimized the platform by using bare metal machines from <a href="https://www.ovhcloud.com/">OVH</a> for both its primary servers, DBs and job workers. While it worked, bare metal machines were a source of potential failures and we did have some over the years. Luckily we had a redundant setup so our users never noticed. But it was a massive amount of work to provision, monitor and maintain.</p>
<p>So when we looked to remake the platform for <a href="https://threekit.com/">Threekit.com</a>, an enterprise focused re-imaging of Clara.io, we looked to switch to a managed compute setup. At the time in 2018, Kubernetes was just emerging as the industry solution as Azure, AWS and Docker converged on it in late 2017.</p>
<h2>Why I Left Kubernetes</h2>
<p>At first, Kubernetes seemed like the right approach for managing services at scale. But as we lived with it over the years since 2018, it became apparent that the complexity and costs were significant. Here’s a breakdown of the challenges we encountered:</p>
<ol>
<li>
<p><strong>Cost Overruns</strong>: Kubernetes comes with substantial infrastructure costs that go beyond DevOps and management time. The high cost arises from needing to provision a bare-bones cluster with redundant management nodes. Moreover, Kubernetes’s slow autoscaling meant I had to over-provision services to ensure availability, paying for unused resources rather than scaling based on demand.</p>
</li>
<li>
<p><strong>Difficulty Managing Large Job Volumes</strong>: Handling a high volume of jobs on Kubernetes is tedious. Both the built-in scheduler and Argo introduced limitations and complexity, often failing to scale well under load or just being really complex.</p>
</li>
<li>
<p><strong>Complexity Overload</strong>: Kubernetes is feature-rich, yet these “enterprise” capabilities turned even simple tasks into protracted processes. The result was added complexity without substantial benefits, making it more of an obstacle than a solution. If you have Kubernetes, you probably need at least one dedicated Kubernetes dev-ops engineer, if not a couple.</p>
</li>
</ol>
<p>Overall, Kubernetes proved difficult to provision, expensive to maintain, and time-consuming to manage. For companies or individual projects seeking simplicity and cost-effectiveness, it may not be the right choice. But it did get rid of the need for us to keep track of whether the hardware in our machines was breaking down and our manual provision processing.</p>
<h2>Embracing Cloud Run for a Simpler Setup</h2>
<p>Google Cloud Run offers a streamlined alternative to Kubernetes. Here’s how my new setup works:</p>
<h3>The Setup</h3>
<p>My infrastructure is now centered around <strong>Docker containers</strong>, with some running as auto-scaling services and others as tasks for long-running jobs. Google Cloud Run handles container deployment, scaling, downtime management, and running/retrying jobs eliminating many of the challenges I faced with Kubernetes.</p>
<h3>Why Cloud Run Is Ideal</h3>
<ol>
<li><strong>Cost Efficiency</strong>: Cloud Run charges only for the CPU and memory used during requests, making it highly cost-effective. For example, this personal project of mine, <a href="https://web3dsurvey.com/">Web3D Survey</a> sees 500,000 hits monthly and costs just <strong>$4/month</strong> for hosting, even though it is running all the time. They key is that Cloud Run charges based on the fraction of the CPU you use per second. The ability to scale to zero also means no charges for idle services.</li>
<li><strong>Fast, Reliable Autoscaling</strong>: Cloud Run scales in a few seconds, unlike Kubernetes, where scaling often took minutes. This quick scaling lets me handle surges reliably without over-provisioning.</li>
<li><strong>No Kubernetes Management Overhead</strong>: Cloud Run, built atop Google’s Borg, avoids the need for Kubernetes cluster management, simplifying deployments and cutting costs.</li>
<li><strong>Simple Async Tasks</strong>: Cloud Run Tasks allows me to execute up to 10,000 tasks per job, track their results with auto-retries with no need to manage job-running infrastructure or individual machines — a refreshing alternative to the complexity running this on Kubernetes was.</li>
</ol>
<h2>The Kubernetes Lock-In Trap</h2>
<p>One overlooked downside of Kubernetes is <strong>cluster lock-in</strong>. Once you start using Kubernetes-specific features, it becomes challenging to leverage resources outside the cluster. Integrating services across data centers or using dedicated resources in a colocation setup adds significant complexity. Kubernetes demands you stay within its ecosystem, effectively binding you to the infrastructure that supports it, making even simple expansions or migrations into costly, complex endeavors.</p>
<h2>Addressing Common Concerns</h2>
<p>Several questions arose from others when I shared my experience online, so here’s a deeper look into how this setup works:</p>
<ul>
<li><strong>Orchestration</strong>: I use GitHub Actions CI to handle CI/CD, leveraging workflows with dependencies and matrix strategies for builds across multiple services which only deploy if all tests/builds are successful.</li>
<li><strong>Storage</strong>: Managed databases or Cloud Storage cover shared data needs, eliminating the need to manage my own disks.</li>
<li><strong>Inter-Service Communication</strong>: For async communication, I leverage pub-sub messaging. When direct connections are absolutely necessary, each service has a dedicated domain-name.</li>
<li><strong>Security</strong>: Cloud Run supports internal-only services, and for public services, I secure routes using JWT.</li>
</ul>
<h2>Debunking Misconceptions</h2>
<h3>“Aren’t You Afraid of Being Locked into GCP?”</h3>
<p>Switching cloud providers, such as AWS, wouldn’t be overly complex since my setup is Docker-based, and migration would take about a week. In practice, few companies switch providers unless politics are involved, as the differences between major cloud services are minimal.</p>
<h3>“Cloud Run Is Just Managed Kubernetes, Right?”</h3>
<p>While Cloud Run uses Knative interfaces, it’s not a Kubernetes PaaS. Cloud Run runs on Google’s Borg, avoiding Kubernetes cluster overhead and allowing for simpler, cost-effective deployments. Even if it was based on Kubernetes underneath it hides the completely complexities, and cost of Kubernetes.</p>
<h2>Remaining Workflow Pains</h2>
<p>There are some pains I have with my current Cloud Run development workflow:</p>
<h3>Arbitrary Management of Services Names</h3>
<p>I do find that I need to manage my service names both locally and in the server in a unified way with clear configuration. Basically an abstraction layer. I know Kubernetes has one and I do miss that.</p>
<h3>Lack of Cloud Run Task Emulation</h3>
<p>There is no solution for running Cloud Run Tasks locally that I have found. I would like it to be able to just run an arbitrary command line locally in place of a docker container in a locally emulated Cloud Run Tasks environment that captures log output, trackings runs, etc. This would simplify development of tasks without having to build and deploy docker containers.</p>
<h2>My New Stack and Workflow</h2>
<p>My infrastructure is built around a reliable stack. You can view a simplistic prototype setup and practices in this <a href="https://github.com/bhouston/template-typescript-monorepo">TypeScript monorepo template</a>. Cloud Run enables me to deploy this stack efficiently, without the complexity or cost overheads Kubernetes brought.</p>
<h2>Final Thoughts</h2>
<p>For my projects, Cloud Run offers the perfect blend of <strong>cost savings, speed, scalability, and simplicity</strong>. While Kubernetes may suit some large enterprises, for agile projects where simplicity and efficiency matter, the managed environment of Cloud Run is transformative. If your infrastructure goals include reduced DevOps overhead, predictable costs, and responsive scaling, Cloud Run may be the solution you’ve been looking for.</p>
<p>(PS. Yes, I am sure there was another library/extension I should have added to Kubernetes to enable feature X, Y or Z, but this really is just further increasing the complexity. I don't want to have to exist inside of world of Kubernetes-specific lingo and techniques if they are not giving me benefits.)</p>
<p><em>This post was inspired by <a href="https://news.ycombinator.com/item?id=42041917">this discussion on Hacker News on 04/11/2025</a></em></p></div></div>]]></description>
        </item>
    </channel>
</rss>