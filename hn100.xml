<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 26 Mar 2025 17:30:04 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Hyperlight WASM: Fast, secure, and OS-free (135 pts)]]></title>
            <link>https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/</link>
            <guid>43482556</guid>
            <pubDate>Wed, 26 Mar 2025 14:18:51 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/">https://opensource.microsoft.com/blog/2025/03/26/hyperlight-wasm-fast-secure-and-os-free/</a>, See on <a href="https://news.ycombinator.com/item?id=43482556">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-bi-an="Blog Body">
					

					
<p>Last fall the Azure Core Upstream team&nbsp;<a href="https://aka.ms/hyperlight-announcement" target="_blank" rel="noreferrer noopener">introduced Hyperlight</a>: an open-source Rust library you can use to execute small, embedded functions using hypervisor-based protection. Then, we showed how to run <a href="https://aka.ms/hl-kubecon-demo-post" target="_blank" rel="noreferrer noopener">Rust functions really, really fast</a>, followed by using <a href="https://aka.ms/hyperlight-javascript" target="_blank" rel="noreferrer noopener">C to run Javascript</a>. In February 2025, the Cloud Native Computing Foundation (CNCF) voted to onboard Hyperlight into their Sandbox program.</p>



<p>We’re announcing the release of Hyperlight Wasm: a Hyperlight virtual machine (VM) “micro-guest” that can run wasm component workloads written in many programming languages. If you’d like to dive straight in, you can visit the <a href="https://github.com/hyperlight-dev/hyperlight-wasm" target="_blank" rel="noreferrer noopener">hyperlight-wasm repo</a> on GitHub. In the remainder of this post we’ll cover the basics of how Hyperlight Wasm works and then walk through how to build a Rust example step-by-step.</p>







<h2 id="performance-and-compatibility">Performance and compatibility</h2>



<p>Traditional virtual machines do a lot of work to be able to run programs. Not only do they have to load an entire operating system, they also boot up the virtual devices that the operating system depends on. Hyperlight is fast because it doesn’t do that work; all it exposes to its VM guests is a linear slice of memory and a CPU. No virtual devices. No operating system.</p>



<p>But this speed comes at the cost of&nbsp;<em>compatibility</em>. Chances are that your current production application expects a Linux operating system running on the x86-64 architecture (hardware), not a bare linear slice of memory. And compatibility is not just limited to operating systems; it can be discussed at three distinct levels:</p>



<ul>
<li><strong>Operating system</strong>: Linux, macOS, and Windows provide a portable abstraction across different hardware.</li>



<li><strong>System interface layer</strong>: System&nbsp;interface standards such as Portable Operating System Interface (POSIX) and the <a href="https://github.com/WebAssembly/wasi" target="_blank" rel="noreferrer noopener">WebAssembly System Interface</a> (WASI) provide interoperability across operating systems.</li>



<li><strong>Programming language/library</strong>: Programming languages’ standard libraries and runtimes provide interoperability across system interfaces.</li>
</ul>



<p>Targeting compatibility with an OS at that layer allows one to abstract over the language/runtime that a customer might want to use, because common OS’s are almost universally supported by languages, libraries, and application programs—but that comes at the cost of requiring that a specific relatively-heavyweight execution environment be provided. On the other hand, very lightweight services can and do abstract over the details of their not-a-full-OS execution environment by changing the standard library of a single language to support their platform, which offers vastly improved performance—at the cost of requiring that a specific language be used to implement programs running in that environment.</p>



<p>WASI and the WebAssembly Component Model provide a middle ground between these contrasting abstractions: by implementing these interfaces, one can allow any lightweight execution environment to run programs written in (nearly) any language. Hyperlight Wasm takes advantage of this to allow you to implement a small set of high-level, performant, abstractions in almost any execution environment and provide a very fast, hardware protected, but nevertheless widely-compatible execution environment.</p>



<h2 id="introducing-the-hyperlight-wasm-guest">Introducing the Hyperlight Wasm guest</h2>



<p>How compatible? Well, building Hyperlight with a WebAssembly&nbsp;runtime—<a href="https://wasmtime.dev/" target="_blank" rel="noreferrer noopener">wasmtime</a>—enables any programming language to execute in a protected Hyperlight micro-VM without any prior knowledge of Hyperlight at all. As far as program authors are concerned, they’re just compiling for the&nbsp;<strong>wasm32-wasip2</strong>&nbsp;target. This means they can run their programs locally using runtimes like&nbsp;<a href="https://wasmtime.dev/" target="_blank" rel="noreferrer noopener">wasmtime</a> or <a href="https://github.com/bytecodealliance/jco" target="_blank" rel="noreferrer noopener">Jco</a>. Or run them on a server using for <a href="https://unit.nginx.org/" target="_blank" rel="noreferrer noopener">Nginx Unit</a>, <a href="https://github.com/spinframework/spin" target="_blank" rel="noreferrer noopener">Spin</a>,&nbsp;<a href="https://github.com/wasmCloud/wasmCloud" target="_blank" rel="noreferrer noopener">WasmCloud</a>—or now also <a href="https://aka.ms/hyperlight-wasm" target="_blank" rel="noreferrer noopener">Hyperlight Wasm</a>. If done right, developers don’t need to think about what runtime their code will run on as they’re developing it. That is a degree of developer flexibility that is only possible through standards.</p>



<p>Executing workloads in the Hyperlight Wasm guest isn’t just possible for compiled languages like C, Go, and Rust, but also for interpreted languages like Python, JavaScript, and C#. The trick here, much like with containers, is to also include a language runtime as part of the image. For example, for JavaScript, the&nbsp;<a href="https://github.com/bytecodealliance/StarlingMonkey" target="_blank" rel="noreferrer noopener">StarlingMonkey JS Runtime</a>&nbsp;was designed to natively run in WebAssembly.</p>



<p>Programming languages, runtimes, application platforms, and cloud providers are all starting to offer rich experiences for WebAssembly out of the box. If we do things right, you will never need to think about whether your application is running inside of a Hyperlight Micro-VM in Azure. You may never know your workload is executing in a Hyperlight Micro VM. And that’s a good thing.</p>



<h2 id="more-layers-of-security-fewer-layers-in-total">More layers of security, fewer layers in total</h2>



<p>The big magic trick we’re performing by combining Hyperlight with WebAssembly is that we’re achieving more security and performance than traditional VMs by doing less work overall. When traditional virtual machine managers (VMMs) create a new virtual machine, they first need to create new virtual devices, then load a kernel, then load an operating system, and only then are they able to start the application. The lower end of this will take about 125 milliseconds.</p>


<figure><img decoding="async" src="https://opensource.microsoft.com/blog/wp-content/uploads/2025/03/image-4.webp" alt="Diagram showing that traditional hypervisors have four layers of heavy work for each instance of an application: the VM guest, guest kernel, OS distribution, and the application binaries." srcset="" data-orig-src="https://opensource.microsoft.com/blog/wp-content/uploads/2025/03/image-4.webp"></figure>



<p>With Hyperlight and Hyperlight Wasm we end up doing far less than traditional VMs. When the Hyperlight VMM creates a new VM, all it needs do to is create a new slice of memory and load the VM guest, which in turn loads the wasm workload. This takes about 1-2 milliseconds today, and work is happening to bring that number to be less than 1 millisecond in the future.</p>


<figure><img decoding="async" src="https://opensource.microsoft.com/blog/wp-content/uploads/2025/03/image-5.webp" alt="Diagram showing that hyperlight removes three layers of heavy work for each instance of an application compared to the traditional microservices approach." srcset="" data-orig-src="https://opensource.microsoft.com/blog/wp-content/uploads/2025/03/image-5.webp"></figure>



<p>Not only is this architecture good for start times, fast start times also affect the way you can schedule your applications. If starting a workload takes about a millisecond, you can afford not to have any idling instances. If you do choose to have a warm pool ready, the memory footprint is drastically smaller. It also allows you to do more work on cheaper hardware, located closer to users. That’s the logic behind our upcoming Azure Front DoorEdge Actions service, powered by Hyperlight and soon to be in private preview.<a id="_msocom_1"></a></p>



<p>Combining Hyperlight with wasm is not just good for performance either; it is also good for security. Under the covers, the Hyperlight Wasm guest uses the best-in-class wasmtime runtime, compiled into a Hyperlight guest as a Rust no_std module. Wasmtime provides strong isolation boundaries for wasm workloads via a software-defined runtime sandbox. While potential attackers will have a bad time breaking out of wasm’s sandbox, on the Hyperlight Wasm guest, even if they could manage to, they would be facing the challenge of then also escaping the VM. One layer of sandboxing is good. But having two layers is even better.</p>



<h2 id="udp-echo-example">UDP echo example</h2>



<p>Alright, let’s look at how to use Hyperlight Wasm from Rust. For our example, we’ll run a simple User Datagram Protocol (UDP) echo server that uses a portion of the <a href="https://github.com/WebAssembly/wasi-sockets" target="_blank" rel="noreferrer noopener">wasi:sockets</a> interface. Luckily for us, we don’t have to write that program ourselves: we can download a pre-compiled wasm program (if you want to compile it yourself, <a href="https://github.com/hyperlight-dev/wasm-udp-echo-sample" target="_blank" rel="noreferrer noopener">the source is available here</a>) and run it. Let’s start by doing that first. Assuming you have a working Rust installation, start <a href="https://github.com/bytecodealliance/wasm-pkg-tools#installation" target="_blank" rel="noreferrer noopener">by installing the wkg tool</a> to download wasm binaries from GitHub Artifacts, and then use that to get a copy of the wasm binary:</p>


<div><pre title="">cargo install wkg
wkg oci pull ghcr.io/hyperlight-dev/wasm-udp-echo-sample/udp-echo-server:latest -o echo.wasm
</pre></div>


<div>
<p>Now that we have a Wasm Binary, we can start wiring up the Hyperlight host. Right now that is a little complicated, since we haven’t yet published cargo crates. So let’s start by git cloning our example repo:</p>


<div><pre title="">git clone https://github.com/hyperlight-dev/hyperlight-wasm-sockets-example
mv echo.wasm hyperlight-wasm-sockets-example
cd hyperlight-wasm-sockets-example
</pre></div></div>



<div>
<p>If you look at the code in the repo, you’ll notice it is structured like a regular Rust project. That’s because it is. It includes several files, most of which are there to implement boilerplate interfaces that the echo sample uses. In the root of the project there is a file called <em>hyperlight.wit</em>. This file is a text representation in the WebAssembly Interface Types (WIT) language that specifies the precise interfaces that the host is making available to, and expects to get from, the wasm module. We need to process this file into a binary wasm representation, which will be used when hyperlight-wasm is built:</p>


<div><pre title="">wasm-tools component wit hyperlight.wit -w -o hyperlight-world.wasm 
export HYPERLIGHT_WASM_WORLD=$(readlink -f hyperlight-world.wasm)
</pre></div></div>



<p>Now, let’s take a look at the code that uses hyperlight-wasm to run a component. To get bindings that we can use to easily implement imports/call exports of the wasm module, we can use <code><strong>hyperlight_component_macro::host_bindgen</strong></code>:</p>



<p><code><strong>// bindings.rs<br>extern crate alloc;<br>hyperlight_component_macro::host_bindgen!();</strong></code></p>



<p>This generates a set of traits representing the WebAssembly component model instances imported and exported by the component inside the sandbox. We define a state structure which keeps track of everything we need to implement the imports (but in this sample application, that is not used):&nbsp;</p>


<div><pre title="">// state.rs
pub struct MyState {}
impl MyState {
    pub fn new() -&gt; Self { MyState {} 	}
}
</pre></div>


<p>We then need to specify that this state representation can be used to implement the interfaces that the component uses:</p>


<div><pre title="">// main.rs
use bindings::*;
impl root::component::RootImports for MyState {
    type Udp = MyState;
    fn udp(&amp;mut self) -&gt; &amp;mut Self  { self }
    // ... one for each imported instance
}
</pre></div>


<p>The wasi:sockets udp interface is very simple to implement, since it doesn’t actually have any functions not associated with a resource:</p>


<div><pre title="">// udp.rs 

impl wasi::sockets::Udp&lt; 

    ErrorCode, 

    IpSocketAddress, 

    (), 

    MyPollable&gt; 

for MyState {} 

</pre></div>


<p>But, since it does export a <code><strong>UdpSocket</strong></code> resource, we need to implement that resource, specifying the host type that underlies it and how to implement its methods on the host:</p>


<div><pre title="">impl wasi::sockets::udp::UdpSocket&lt;
    wasi::sockets::network::ErrorCode,
    MyDatagramStream,
    wasi::sockets::network::IpSocketAddress,
    (),
    MyDatagramStream,
    MyPollable
    &gt;
for MyState {
     type T = MySocket;
    fn start_bind(
        &amp;mut self,
        self_: BorrowedResourceGuard&lt;MySocket&gt;,
        _network: BorrowedResourceGuard&lt;()&gt;,
        local_address: wasi::sockets::network::IpSocketAddress
    ) -&gt; Result&lt;(), wasi::sockets::network::ErrorCode&gt; {
        *(*self_).os.lock().unwrap() = Some(Arc::new(
            std::net::UdpSocket::bind(local_address)
                .map_err(|_| wasi::sockets::network::ErrorCode::Unknown)?));
        Ok(())
    }
    fn stream(
        &amp;mut self,
        self_: BorrowedResourceGuard&lt;Self::T&gt;,
        _remote_address: Option&lt;IpSocketAddress&gt;
    ) -&gt; Result&lt;(MyDatagramStream, MyDatagramStream), ErrorCode&gt; {
        let sock = (*self_).os.lock().unwrap();
        let sock = sock.as_ref().unwrap();
        Ok((MyDatagramStream { socket: sock.clone() },
            MyDatagramStream { socket: sock.clone() }))
    }

    fn finish_bind(
        &amp;mut self,
        _self: BorrowedResourceGuard&lt;Self::T&gt;
    ) -&gt; std::result::Result&lt;(), ErrorCode&gt;  {
        Ok(())
    }

    fn r#subscribe(
        &amp;mut self,
        _self: BorrowedResourceGuard&lt;Self::T&gt;
    ) -&gt; MyPollable  {
        MyPollable::AlwaysReady
    }
}

</pre></div>


<p>Now that we have that, we’re ready to run Hyperlight and point it to our Wasm binary. And all that takes is a little bit of boilerplate. In the code below, we’re first creating a new Hyperlight sandbox with enough memory to run a Wasm runtime. Then, we’re registering the bindings we just wrote. And finally, we load our Wasm Component and run it.</p>


<div><pre title="">fn main() {
    let state = State::new();
    // Setup the sandbox with enough resources to run a Wasm runtime
    let mut sb: hyperlight_wasm::ProtoWasmSandbox =
        hyperlight_wasm::SandboxBuilder::new()
            .with_guest_input_buffer_size(5_000_000)
            .with_guest_heap_size(10_000_000)
            .with_guest_panic_context_buffer_size(10_000_000)
            .with_guest_stack_size(10_000_000)
            .with_guest_function_call_max_execution_time_millis(0)
            .build()
            .unwrap();

    // Register the host functions
    let rt = crate::bindings::register_host_functions(&amp;mut sb, state);

    // Load our Wasm Component and run it
    let sb = sb.load_runtime().unwrap();
    let sb = sb.load_module("echo.wasm").unwrap();
    let mut wrapped = bindings::RootSandbox { sb, rt };

    let run_inst = root::component::RootExports::run(&amp;mut wrapped);
    let _ = run_inst.run();
}

</pre></div>


<p>Finally, before we can run the sample Wasm binary, we need to Ahead-Of-Time compile it into a format that wasmtime can load without having to generate code at runtime:&nbsp;</p>


<div><pre title="">cargo install --git https://github.com/hyperlight-dev/hyperlight-wasm --branch hyperlight-component-macro hyperlight-wasm-aot 
hyperlight-wasm-aot compile --component echo.wasm echo.bin 
</pre></div>


<p>And now we’re ready to start the application and run it. You can do that by running cargo run in one terminal, which will start a server listening on port 8080:&nbsp;</p>



<p><code><strong>cargo run</strong></code></p>



<p>And in another terminal, we can now send User Datagram Protocol (UDP) packets. You can do that using the netcat utility as follows (for Windows <a href="https://github.com/hyperlight-dev/hyperlight-wasm-sockets-example" target="_blank" rel="noreferrer noopener">you can find a netcat alternative here</a>):&nbsp;</p>



<p><code><strong>nc -u 127.0.0.1&nbsp; 8080</strong></code></p>



<p>Now you’re free to type! Whatever you send to the server will be echoed back. And that’s the basics of Hyperlight’s Wasm guest.</p>



<h2 id="what-s-next">What’s next?</h2>



<p>So far we’ve mostly talked about using WASI on Hyperlight for portability between operating systems and VMs. But it doesn’t just stop there: because the WebAssembly instruction set and the Component Model abstract binary interface (ABI) are not tied to any one machine architecture, wasm applications are also portable between different instruction sets. You can soon expect Hyperlight Wasm to also work on Arm64 processors. Rebuilding your host will just work, without you ever needing to recompile the wasm applications running inside.</p>



<p>You may also have noticed that, while we can support WASI APIs in the guest, the VMM host doesn’t provide its own default implementation of WASI interfaces, so you have to implement them yourselves. While many applications will appreciate that flexibility, including cloud vendors like Microsoft who are using Hyperlight to create products, it does mean that getting started and trying things out can take some time. For that reason, we’re planning to <a href="https://github.com/hyperlight-dev/hyperlight/issues" target="_blank" rel="noreferrer noopener">extend Hyperlight-Wasm with default bindings</a> for some WASI interfaces soon. That way, if you just want to sandbox an HTTP server or a service that listens on a socket, you don’t need to do much else to get started.</p>



<h2 id="get-involved-with-hyperlight">Get involved with Hyperlight</h2>



<p>Hyperlight has been donated by Microsoft to the CNCF’s Sandbox program. Our goal is to raise the bar for fast, efficient, and secure cloud-native computing. The Hyperlight Wasm guest is our latest addition to the Hyperlight project, making it convenient to write programs that run on Hyperlight.</p>



<p>As an open-source project licensed under the Apache 2.0 license, Hyperlight underscores Microsoft’s commitment to fostering innovation and collaboration within the tech community. We welcome developers, solution architects, and IT professionals to help build and enhance Hyperlight. To get started with Hyperlight, please visit&nbsp;<a href="https://aka.ms/hyperlight-dev" target="_blank" rel="noreferrer noopener">the repo at Hyperlight</a>&nbsp;and let us know what you think.</p>









					
<div data-bi-an="Author Bio">
					<div>
			<div>
						<p><img width="170" height="170" src="https://opensource.microsoft.com/blog/wp-content/uploads/2024/11/yosh-388x388.png" alt="Headshot of Yosh Wuyts.">						</p>
					</div>
			<div>
				

									<p>
						Yosh is a Cloud Native Advocate at Microsoft based in Copenhagen, Denmark. They're a member of the Rust Async WG and a Bytecode Alliance Recognized contributor. They’re also a proud cat dad and enthusiast cook.					</p>
				
				<p><a href="https://opensource.microsoft.com/blog/author/yosh-wuyts/" data-bi-cn="See more articles from this author" data-bi-id="96531" data-bi-ct="author link" rel="author" aria-label="
						See more articles from Yosh Wuyts					">
					See more articles from this author				</a>
			</p></div>
		</div>
					<div>
			<div>
						<p><img alt="" src="https://opensource.microsoft.com/blog/wp-content/themes/cloud-marketing-moray/dist/images/default-avatar.png" height="170" width="170">						</p>
					</div>
			<div>
				<div>
					<p>
						Lucy Menon					</p>

											<p>
							Software engineer and researcher, Microsoft						</p>
					
									</div>

									<p>
						Lucy Menon is a software engineer and researcher at Microsoft working on Hyperlight and formalizing the WebAssembly Component Model.					</p>
				
				<p><a href="https://opensource.microsoft.com/blog/author/lucy-menon/" data-bi-cn="See more articles from this author" data-bi-id="97274" data-bi-ct="author link" rel="author" aria-label="
						See more articles from Lucy Menon					">
					See more articles from this author				</a>
			</p></div>
		</div>
	</div>

					
									</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Here are the Attack Plans That Trump's Advisers Shared on Signal (126 pts)]]></title>
            <link>https://www.theatlantic.com/politics/archive/2025/03/signal-group-chat-attack-plans-hegseth-goldberg/682176/</link>
            <guid>43481521</guid>
            <pubDate>Wed, 26 Mar 2025 12:34:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/politics/archive/2025/03/signal-group-chat-attack-plans-hegseth-goldberg/682176/">https://www.theatlantic.com/politics/archive/2025/03/signal-group-chat-attack-plans-hegseth-goldberg/682176/</a>, See on <a href="https://news.ycombinator.com/item?id=43481521">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>The administration has downplayed the importance of the text messages inadvertently sent to <em>The Atlantic</em>’s editor in chief.</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Pete Hegseth and Michael Waltz" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/qoUTa3LCcy11jONTctaZjyWSZh8=/0x0:4999x2812/750x422/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 750w, https://cdn.theatlantic.com/thumbor/ZMu5yy0JD92TFMDb5XkRbkoxGc8=/0x0:4999x2812/828x466/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 828w, https://cdn.theatlantic.com/thumbor/CpMH8U0OlYWT4LVEIkmyH9dxFx0=/0x0:4999x2812/960x540/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 960w, https://cdn.theatlantic.com/thumbor/z-iMt6enhgz993cTDCDDvCCqw88=/0x0:4999x2812/976x549/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 976w, https://cdn.theatlantic.com/thumbor/uu9yDcyy5CgvAr7LK0YuJ2AnLFw=/0x0:4999x2812/1952x1098/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/CpMH8U0OlYWT4LVEIkmyH9dxFx0=/0x0:4999x2812/960x540/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg" id="article-lead-image" width="960" height="540"></picture></div><figcaption data-flatplan-lead_figure_caption="true">Andrew Harnik / Getty</figcaption></figure></div></div><div><p><time datetime="2025-03-26T12:19:08Z" data-flatplan-timestamp="true">March 26, 2025, 8:19 AM ET</time> </p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><div data-view-action="view - audio player - start" data-view-label="682176" data-event-module="audio player" data-event-content-type="narrated" data-event-module-state="start" data-event-view="true"><div><p><img alt="Pete Hegseth and Michael Waltz" sizes="80px" srcset="https://cdn.theatlantic.com/thumbor/ldUIVBa351Bzphhp2m26Tw_Eq00=/225x262:2306x2343/80x80/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 80w, https://cdn.theatlantic.com/thumbor/JtYeqRVFltMBHGn4Lh7Fr3mC0SM=/225x262:2306x2343/96x96/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 96w, https://cdn.theatlantic.com/thumbor/TUqiKun2lwU1AuLeHulny-hJiuw=/225x262:2306x2343/128x128/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 128w, https://cdn.theatlantic.com/thumbor/7UFOkiUMLS6F4jOC0TCgJ3sTKRo=/225x262:2306x2343/160x160/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 160w, https://cdn.theatlantic.com/thumbor/lwLQBhaYASajfrLwc1nKsVokJgM=/225x262:2306x2343/192x192/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 192w, https://cdn.theatlantic.com/thumbor/fktao3RArDfqkc5c7mI3KAfwchE=/225x262:2306x2343/256x256/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 256w, https://cdn.theatlantic.com/thumbor/DtShUT_1sUjj94EgCbx9bbasemE=/225x262:2306x2343/384x384/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 384w, https://cdn.theatlantic.com/thumbor/DVznxp7eWY25zu-oP6piU5hCkWA=/225x262:2306x2343/512x512/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg 512w" src="https://cdn.theatlantic.com/thumbor/ldUIVBa351Bzphhp2m26Tw_Eq00=/225x262:2306x2343/80x80/media/img/mt/2025/03/2025_03_SignalTextChain-1/original.jpg" width="80" height="80"></p></div><p>Produced by ElevenLabs and<!-- --> <a href="https://newsoveraudio.com/?offerId=atl_reader_exclusive_jks1kjl"> <!-- -->News Over Audio (Noa)</a> <!-- -->using AI narration. Listen to more stories on the Noa app.</p></div><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">So, about that Signal chat.</p><p data-flatplan-paragraph="true">On Monday, shortly after we published a story about a massive Trump-administration security breach, a reporter asked the secretary of defense, <a data-event-element="inline link" href="https://www.theatlantic.com/tag/person/pete-hegseth/">Pete Hegseth</a>, why he had shared plans about a forthcoming attack on Yemen on the Signal messaging app. He answered, “Nobody was texting war plans. And that’s all I have to say about that.”</p><p data-flatplan-paragraph="true">At a Senate hearing yesterday, the director of national intelligence, <a data-event-element="inline link" href="https://www.theatlantic.com/tag/person/tulsi-gabbard/">Tulsi Gabbard</a>, and the director of the Central Intelligence Agency, John Ratcliffe, were both asked about the Signal chat, to which Jeffrey Goldberg, the editor in chief of <em>The Atlantic</em>, was inadvertently invited by National Security Adviser Michael Waltz. “There was no classified material that was shared in that Signal group,” Gabbard told members of the Senate Intelligence Committee.</p><p data-flatplan-paragraph="true">Ratcliffe said much the same: “My communications, to be clear, in the Signal message group were entirely permissible and lawful and did not include classified information.”</p><p data-flatplan-paragraph="true"><a data-event-element="inline link" href="https://www.theatlantic.com/tag/person/donald-trump/">President Donald Trump</a>, asked yesterday afternoon about the same matter, said, “It wasn’t classified information.”</p><p data-flatplan-paragraph="true">These statements presented us with a dilemma. In <em>The Atlantic</em>’s <a data-event-element="inline link" href="https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/">initial story about the Signal chat</a>—the “Houthi PC small group,” as it was named by Waltz—we withheld specific information related to weapons and to the timing of attacks that we found in certain texts. As a general rule, we do not publish information about military operations if that information could possibly jeopardize the lives of U.S. personnel. That is why we chose to characterize the nature of the information being shared, not specific details about the attacks.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/">Read: The Trump administration accidentally texted me its war plans</a></p><p data-flatplan-paragraph="true">The statements by Hegseth, Gabbard, Ratcliffe, and Trump—combined with the assertions made by numerous administration officials that we are lying about the content of the Signal texts—have led us to believe that people should see the texts in order to reach their own conclusions. There is a clear public interest in disclosing the sort of information that Trump advisers included in nonsecure communications channels, especially because senior administration figures are attempting to downplay the significance of the messages that were shared.</p><p data-flatplan-paragraph="true">Experts have repeatedly told us that use of a Signal chat for such sensitive discussions poses a threat to national security. As a case in point, Goldberg received information on the attacks two hours before the scheduled start of the bombing of Houthi positions. If this information—particularly the exact times American aircraft were taking off for Yemen—had fallen into the wrong hands in that crucial two-hour period, American pilots and other American personnel could have been exposed to even greater danger than they ordinarily would face. The Trump administration is arguing that the military information contained in these texts was not classified—as it typically would be—although the president has not explained how he reached this conclusion.</p><p data-flatplan-paragraph="true">Yesterday, we asked officials across the Trump administration if they objected to us publishing the full texts. In emails to the Central Intelligence Agency, the Office of the Director of National Intelligence, the National Security Council, the Department of Defense, and the White House, we wrote, in part: “In light of statements today from multiple administration officials, including before the Senate Intelligence Committee, that the information in the Signal chain about the Houthi strike is not classified, and that it does not contain ‘war plans,’ <em>The Atlantic</em> is considering publishing the entirety of the Signal chain.”</p><p data-flatplan-paragraph="true">We sent our first request for comment and feedback to national-security officials shortly after noon, and followed up in the evening after most failed to answer.</p><p data-flatplan-paragraph="true">Late yesterday, White House Press Secretary Karoline Leavitt emailed a response: “As we have repeatedly stated, there was no classified information transmitted in the group chat. However, as the CIA Director and National Security Advisor have both expressed today, that does not mean we encourage the release of the conversation. This was intended to be a an [<em>sic</em>] internal and private deliberation amongst high-level senior staff and sensitive information was discussed. So for those reason [<em>sic</em>] — yes, we object to the release.” (The Leavitt statement did not address which elements of the texts the White House considered sensitive, or how, more than a week after the initial air strikes, their publication could have bearing on national security.)</p><p data-flatplan-paragraph="true">A CIA spokesperson asked us to withhold the name of John Ratcliffe’s chief of staff, which Ratcliffe had shared in the Signal chain, because CIA intelligence officers are traditionally not publicly identified. Ratcliffe had testified earlier yesterday that the officer is not undercover and said it was “completely appropriate” to share their name in the Signal conversation. We will continue to withhold the name of the officer. Otherwise, the messages are unredacted.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/podcasts/archive/2025/03/jeffrey-goldberg-group-chat-broke-internet/682161/">Listen: Jeffrey Goldberg on the group chat that broke the internet</a></p><p data-flatplan-paragraph="true">As we wrote on Monday, much of the conversation in the “Houthi PC small group” concerned the timing and rationale of attacks on the Houthis, and contained remarks by Trump-administration officials about the alleged shortcomings of America’s European allies. But on the day of the attack—Saturday, March 15—the discussion veered toward the operational.</p><p data-flatplan-paragraph="true">At 11:44 a.m. eastern time, Hegseth posted in the chat, in all caps, “TEAM UPDATE:”</p><p data-flatplan-paragraph="true">The text beneath this began, “TIME NOW (1144et): Weather is FAVORABLE. Just CONFIRMED w/CENTCOM we are a GO for mission launch.” Centcom, or Central Command, is the military’s combatant command for the Middle East. The Hegseth text continues:</p><div><ul><li>“1215et: F-18s LAUNCH (1st strike package)”</li> <li>“1345: ‘Trigger Based’ F-18 1st Strike Window Starts (Target Terrorist is @ his Known Location so SHOULD BE ON TIME – also, Strike Drones Launch (MQ-9s)”</li></ul></div><p data-flatplan-paragraph="true">Let us pause here for a moment to underscore a point. This Signal message shows that the U.S. secretary of defense texted a group that included a phone number unknown to him—Goldberg’s cellphone—at 11:44 a.m. This was 31 minutes before the first U.S. warplanes launched, and two hours and one minute before the beginning of a period in which a primary target, the Houthi “Target Terrorist,” was expected to be killed by these American aircraft. If this text had been received by someone hostile to American interests—or someone merely indiscreet, and with access to social media—the Houthis would have had time to prepare for what was meant to be a surprise attack on their strongholds. The consequences for American pilots could have been catastrophic.</p><p data-flatplan-paragraph="true">The Hegseth text then continued:</p><div><ul><li>“1410: More F-18s LAUNCH (2nd strike package)”</li> <li>“1415: Strike Drones on Target (THIS IS WHEN THE FIRST BOMBS WILL DEFINITELY DROP, pending earlier ‘Trigger Based’ targets)”</li> <li>“1536 F-18 2nd Strike Starts – also, first sea-based Tomahawks launched.”</li> <li>“MORE TO FOLLOW (per timeline)”</li> <li>“We are currently clean on OPSEC”—that is, operational security.</li> <li>“Godspeed to our Warriors.”</li></ul></div><p data-flatplan-paragraph="true">Shortly after, <a data-event-element="inline link" href="https://www.theatlantic.com/tag/person/j-d-vance/">Vice President J. D. Vance</a> texted the group, “I will say a prayer for victory.”</p><section data-event-module="recirc" data-flatplan-ignore="true"><h2>Recommended Reading</h2><ul><li></li><li></li><li><gpt-ad lazy-load="3" format="native" sizes-at-0="native" targeting-pos="native-article-related" targeting-native="native"></gpt-ad></li></ul></section><p data-flatplan-paragraph="true">At 1:48 p.m., Waltz sent the following text, containing real-time intelligence about conditions at an attack site, apparently in Sanaa: “VP. Building collapsed. Had multiple positive ID. Pete, Kurilla, the IC, amazing job.” Waltz was referring here to Hegseth; General Michael E. Kurilla, the commander of Central Command; and the intelligence community, or IC. The reference to “multiple positive ID” suggests that U.S. intelligence had ascertained the identities of the Houthi target, or targets, using either human or technical assets.</p><p data-flatplan-paragraph="true">Six minutes later, the vice president, apparently confused by Waltz’s message, wrote, “What?”</p><p data-flatplan-paragraph="true">At 2 p.m., Waltz responded: “Typing too fast. The first target – their top missile guy – we had positive ID of him walking into his girlfriend’s building and it’s now collapsed.”</p><p data-flatplan-paragraph="true">Vance responded a minute later: “Excellent.” Thirty-five minutes after that, Ratcliffe, the CIA director, wrote, “A good start,” which Waltz followed with a text containing a fist emoji, an American-flag emoji, and a fire emoji. The Houthi-run Yemeni health ministry reported that at least 53 people were killed in the strikes, a number that has not been independently verified.</p><p data-flatplan-paragraph="true">Later that afternoon, Hegseth posted: “CENTCOM was/is on point.” Notably, he then told the group that attacks would be continuing. “Great job all. More strikes ongoing for hours tonight, and will provide full initial report tomorrow. But on time, on target, and good readouts so far.”</p><p data-flatplan-paragraph="true">It is still unclear why a journalist was added to the text exchange. Waltz, who invited Goldberg into the Signal chat, said yesterday that he was investigating “how the heck he got into this room.”</p><hr><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/TcCybzsovOAQXiH4pDwlQupnLFw=/665x1043/media/img/posts/2025/03/01/original.jpg" src="https://cdn.theatlantic.com/thumbor/TcCybzsovOAQXiH4pDwlQupnLFw=/665x1043/media/img/posts/2025/03/01/original.jpg" width="665" height="1043"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/FhihKmaLvlfIcMIVFcgSPrN-oBQ=/665x682/media/img/posts/2025/03/02/original.jpg" src="https://cdn.theatlantic.com/thumbor/FhihKmaLvlfIcMIVFcgSPrN-oBQ=/665x682/media/img/posts/2025/03/02/original.jpg" width="665" height="682"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/kIKTbDhSKlL_iuvGm5pFHTszLhw=/665x693/media/img/posts/2025/03/3/original.jpg" src="https://cdn.theatlantic.com/thumbor/kIKTbDhSKlL_iuvGm5pFHTszLhw=/665x693/media/img/posts/2025/03/3/original.jpg" width="665" height="693"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/vu8kjot67dB-EFFOe3RnCDP-EH0=/665x886/media/img/posts/2025/03/4-1/original.jpg" src="https://cdn.theatlantic.com/thumbor/vu8kjot67dB-EFFOe3RnCDP-EH0=/665x886/media/img/posts/2025/03/4-1/original.jpg" width="665" height="886"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/dNqd2GHAyg_36cCKXc_DI8ld6QA=/665x698/media/img/posts/2025/03/5-1/original.jpg" src="https://cdn.theatlantic.com/thumbor/dNqd2GHAyg_36cCKXc_DI8ld6QA=/665x698/media/img/posts/2025/03/5-1/original.jpg" width="665" height="698"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/M4ZxZ9qUdDgtJgftzmy47PDsDx8=/665x1046/media/img/posts/2025/03/6-1/original.jpg" src="https://cdn.theatlantic.com/thumbor/M4ZxZ9qUdDgtJgftzmy47PDsDx8=/665x1046/media/img/posts/2025/03/6-1/original.jpg" width="665" height="1046"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/vR86C30Jo--TfZ-a4uIyOP_7brA=/665x988/media/img/posts/2025/03/7/original.jpg" src="https://cdn.theatlantic.com/thumbor/vR86C30Jo--TfZ-a4uIyOP_7brA=/665x988/media/img/posts/2025/03/7/original.jpg" width="665" height="988"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" sizes="(min-width: 729px) 655px, (min-width: 576px) calc(100vw - 48px), 100vw" srcset="https://cdn.theatlantic.com/thumbor/3UAlf0rB6GioMvTWeRAW5qId1fo=/0x0:736x974/655x867/media/img/posts/2025/03/8/original.jpg 655w" src="https://cdn.theatlantic.com/thumbor/3UAlf0rB6GioMvTWeRAW5qId1fo=/0x0:736x974/655x867/media/img/posts/2025/03/8/original.jpg" width="655" height="867"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" sizes="(min-width: 729px) 655px, (min-width: 576px) calc(100vw - 48px), 100vw" srcset="https://cdn.theatlantic.com/thumbor/EF4_Bu3HlXK4Eb2GzpbKayT6SAY=/0x0:736x1067/655x950/media/img/posts/2025/03/9/original.jpg 655w" src="https://cdn.theatlantic.com/thumbor/EF4_Bu3HlXK4Eb2GzpbKayT6SAY=/0x0:736x1067/655x950/media/img/posts/2025/03/9/original.jpg" width="655" height="950"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/kfKj-82LLyysTvMDRlUkpyXbPoA=/665x913/media/img/posts/2025/03/10/original.jpg" src="https://cdn.theatlantic.com/thumbor/kfKj-82LLyysTvMDRlUkpyXbPoA=/665x913/media/img/posts/2025/03/10/original.jpg" width="665" height="913"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/yRxNVoRymISzg8Cy0d83vAaL7fo=/665x203/media/img/posts/2025/03/11/original.jpg" src="https://cdn.theatlantic.com/thumbor/yRxNVoRymISzg8Cy0d83vAaL7fo=/665x203/media/img/posts/2025/03/11/original.jpg" width="665" height="203"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/M-BiLuz-e8LZZymSKQGYcWmifQw=/665x961/media/img/posts/2025/03/12-1/original.jpg" src="https://cdn.theatlantic.com/thumbor/M-BiLuz-e8LZZymSKQGYcWmifQw=/665x961/media/img/posts/2025/03/12-1/original.jpg" width="665" height="961"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" sizes="(min-width: 729px) 655px, (min-width: 576px) calc(100vw - 48px), 100vw" srcset="https://cdn.theatlantic.com/thumbor/Y3vbBbWxT9jM3z_rxYCp5YHrkQY=/0x0:1320x358/655x178/media/img/posts/2025/03/13/original.jpg 655w, https://cdn.theatlantic.com/thumbor/sr0Y-DhtQG_yVrZxOtQUMCrGs5Y=/0x0:1320x358/750x204/media/img/posts/2025/03/13/original.jpg 750w, https://cdn.theatlantic.com/thumbor/e4akWXMW9iN2zyNR-A1OC7bf7gc=/0x0:1320x358/850x231/media/img/posts/2025/03/13/original.jpg 850w, https://cdn.theatlantic.com/thumbor/sQEGYy60Uk_th2chsrcXiD_E35s=/0x0:1320x358/928x252/media/img/posts/2025/03/13/original.jpg 928w, https://cdn.theatlantic.com/thumbor/ATxrmrURB46ZpM5PRnfzLfdl5nU=/0x0:1320x358/1310x356/media/img/posts/2025/03/13/original.jpg 1310w" src="https://cdn.theatlantic.com/thumbor/Y3vbBbWxT9jM3z_rxYCp5YHrkQY=/0x0:1320x358/655x178/media/img/posts/2025/03/13/original.jpg" width="655" height="178"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/DrbNnB9vZme8vdZBAWs4TxNEhAI=/665x1024/media/img/posts/2025/03/14/original.jpg" src="https://cdn.theatlantic.com/thumbor/DrbNnB9vZme8vdZBAWs4TxNEhAI=/665x1024/media/img/posts/2025/03/14/original.jpg" width="665" height="1024"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/SHxOZDFginWz5GNxSdh8K5BjgCA=/665x1224/media/img/posts/2025/03/15/original.jpg" src="https://cdn.theatlantic.com/thumbor/SHxOZDFginWz5GNxSdh8K5BjgCA=/665x1224/media/img/posts/2025/03/15/original.jpg" width="665" height="1224"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/zAkXFtSGWoc-2Ecii8upxvq1cjY=/665x676/media/img/posts/2025/03/16-1/original.jpg" src="https://cdn.theatlantic.com/thumbor/zAkXFtSGWoc-2Ecii8upxvq1cjY=/665x676/media/img/posts/2025/03/16-1/original.jpg" width="665" height="676"></picture></figure></div><div data-flatplan-inline_image="true"><figure><picture><img alt="Screenshot" loading="lazy" srcset="https://cdn.theatlantic.com/thumbor/V3Dhsk04aS9k44-PCCHPzSYy-Hg=/665x932/media/img/posts/2025/03/17/original.jpg" src="https://cdn.theatlantic.com/thumbor/V3Dhsk04aS9k44-PCCHPzSYy-Hg=/665x932/media/img/posts/2025/03/17/original.jpg" width="665" height="932"></picture></figure></div></section><div data-event-module="footer"><p><h3>About the Authors</h3></p><div><address id="article-writer-0" data-event-element="author" data-event-position="1" data-flatplan-bio="true"><div><p><a href="https://www.theatlantic.com/author/jeffrey-goldberg/" data-event-element="image"><img alt="" loading="lazy" src="https://cdn.theatlantic.com/thumbor/umxEbDHzu_6lWzJxYOnCZNM4_sg=/0x0:2977x2977/120x120/media/img/authors/2021/06/Jeffrey_Goldberg_Headshot_bw_1/original.png" width="60" height="60"></a></p></div></address></div></div><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You should know this before choosing Next.js (215 pts)]]></title>
            <link>https://eduardoboucas.com/posts/2025-03-25-you-should-know-this-before-choosing-nextjs/</link>
            <guid>43481295</guid>
            <pubDate>Wed, 26 Mar 2025 12:08:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eduardoboucas.com/posts/2025-03-25-you-should-know-this-before-choosing-nextjs/">https://eduardoboucas.com/posts/2025-03-25-you-should-know-this-before-choosing-nextjs/</a>, See on <a href="https://news.ycombinator.com/item?id=43481295">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          <p>Picking the technology stack for a project is an important and consequential decision. In the enterprise space in particular, it often involves a multi-year commitment with long-lasting implications on the roadmap of the project, the pace of its development, the quality of the deliverables, and even the ability to assemble and maintain a happy team.</p>
<p>The open-source software model is a fundamental answer to this. By using software that is developed in the open, anyone is free to extend it or modify it in whatever way fits their use case. More crucially, the portability of open-source software gives developers and organisations the freedom to move their infrastructure between different providers without fear of getting locked in to a specific vendor.</p>
<p>This is the expectation with Next.js, an open-source web development framework created and <a href="https://nextjs.org/governance">governed by Vercel</a>, a cloud provider that offers managed hosting of Next.js as a service.<!--more--></p>
<p>There is nothing wrong with a company profiting from an open-source software it created, especially when that helps fund the development of the project. In fact, there are plenty of examples of that model working successfully in our industry.</p>
<p>But I think that can only work sustainably if the boundaries between the company and the open-source project are abundantly clear, with well-defined expectations between the maintainers, the hosting providers and the users about how and where each feature of the framework can be used.</p>
<p>I want to explain why I don't think this transparency exists today.</p>
<p>My goal is not to stop anyone from using Next.js, but to lay out as much information as possible so developers and businesses can make an informed decision about their technology stack.</p>
<h2 id="declaration-of-interest"><a href="#declaration-of-interest">¶</a> Declaration of interest</h2>
<p>Let me lead with a declaration of interest:</p>
<ul>
<li>I work at <a href="https://www.netlify.com/">Netlify</a> and have done so for over four years</li>
<li>Netlify is a frontend cloud platform that supports Next.js and other web frameworks as part of its product offering</li>
<li>Netlify and Vercel are direct competitors</li>
</ul>
<p>It's important for me to establish this for a few reasons.</p>
<p>My job involves building the infrastructure and tooling needed to support the full feature set of Next.js on Netlify, which has exposed me to the internals of the framework in a way that most people won't see. Over the years, I have seen concerning patterns of tight coupling between the open-source framework and the infrastructure of the company that builds it.</p>
<p>My employment is also the reason why I have always been very wary of voicing these concerns in public. As a Netlify employee, I don't really get to voice an objective concern about Next.js without people dismissing my claims as Netlify unleashing one of its minions to spread <a href="https://en.wikipedia.org/wiki/Fear,_uncertainty,_and_doubt">FUD</a> about a competitor.</p>
<p>I'm not keen on exposing myself and the company to that type of debate, so I have always chosen to work behind the scenes in supporting the developers who decide to deploy their sites on Netlify and shield them from all the complexity that goes into making that possible.</p>
<p>But then something happened.</p>
<p>Last weekend, Vercel disclosed a critical security vulnerability with Next.js. This type of issue is normal, but the way Vercel chose to handle it was so poor, reckless and disrespectful to the community that it has exacerbated my concerns about the governance of the project.</p>
<p>For me, things change once your decisions put other people at risk, so I felt the urge to speak up.</p>
<h2 id="openness-and-governance"><a href="#openness-and-governance">¶</a> Openness and governance</h2>
<p>I'll come back to this incident later, but before that I want to back up a little and give you a peek behind the curtain. My history of reservations about the openness and governance of Next.js stem from a series of decisions made by Vercel over the years that make it incredibly challenging for other providers to support the full feature set of the framework.</p>
<p>I'll cover these by laying out a series of facts about how Next.js is built. I'll then add some of my own considerations about how those facts live up to the expectations of an open, interoperable, enterprise-grade software product.</p>
<h3 id="fact-1-no-adapters"><a href="#fact-1-no-adapters">¶</a> Fact #1: No adapters</h3>
<p>Most modern web development frameworks use the concept of adapters to configure the output of the framework to a specific deployment target: <a href="https://remix.run/docs/en/main/discussion/runtimes">Remix</a>, <a href="https://docs.astro.build/en/reference/adapter-reference/">Astro</a>, <a href="https://nitro.build/deploy/custom-presets">Nuxt</a>, <a href="https://kit.svelte.dev/docs/adapters">SvelteKit</a> and <a href="https://www.gatsbyjs.com/docs/how-to/previews-deploys-hosting/adapters/">Gatsby</a> are just a few examples. This pattern allows developers to keep the core of their applications untouched, and simply swap the adapter if they decide to start deploying to a different provider.</p>
<p>These adapters can be maintained by framework authors, by the hosting providers, by the community, or all of the above. Frameworks are typically structured in such a way that it’s possible for anyone to build their own adapter in case one isn’t available for the provider of their choice.</p>
<p>Next.js does not have the concept of adapters and they have <a href="https://archive.leerob.io/blog/using-nextjs#open-source-and-framework-boundaries">stated in the past</a> that they would not support them. The output of a Next.js build has a proprietary and undocumented format that is used in Vercel deployments to provision the infrastructure needed to power the application.</p>
<p>Vercel's alternative to this was the Build Output API, a documented specification for the output format of frameworks who wish to deploy to Vercel.</p>
<p>This is not an adapter interface for Next.js, and in fact has nothing to do with Next.js. The <a href="https://vercel.com/blog/build-output-api">announcement blog post</a> said that Next.js supports this format, but as of today that isn’t true.</p>
<p>In November 2023, the <a href="https://github.com/vercel/next.js/commit/958dcbc7e35dac5b84dd5a3bd3f4bb7f5ba0bf1a">Next.js documentation has been updated</a> to say that Next.js would adopt the Build Output API in the following major version of the framework (which would be version 15):</p>
<blockquote>
<blockquote>
<p>Next.js produces a standard deployment output used by managed and self-hosted Next.js. This ensures all features are supported across both methods of deployment. In the next major version, we will be transforming this output into our <a href="https://vercel.com/docs/build-output-api/v3?utm_source=next-site&amp;utm_medium=docs&amp;utm_campaign=next-website">Build Output API specification</a>.</p>
</blockquote>
</blockquote>
<p>Next.js 15.0.0 was <a href="https://nextjs.org/blog/next-15">released in October 2024</a> without support for the Build Output API</p>
<p>Vercel have built the Build Output API because they wanted their customers to leverage the rich ecosystem of frameworks in the space, but their own framework doesn't support it to this day.</p>
<p>This means that any hosting providers other than Vercel must build on top of undocumented APIs that can introduce unannounced breaking changes in minor or patch releases. (And they have.)</p>
<p>Late last year, <a href="https://blog.cloudflare.com/builder-day-2024-announcements/#cloudflare-joins-opennext">Cloudflare</a> and <a href="https://www.netlify.com/blog/netlify-joins-opennext/">Netlify</a> have joined <a href="https://opennext.js.org/">OpenNext</a>, a movement of different cloud providers that collaborate on open-source adapters for Next.js. Shortly after, Vercel have engaged with the movement and committed to building support for adapters. They haven't made any timeline commitments, but have <a href="https://x.com/feedthejim/status/1903837444648382758?s=46">recently said they are actively working on it</a>.</p>
<p>It's important to remember that it's been almost three years since the launch of the Build Output API, and to this day the framework still isn't portable. I'm cautiously optimistic about that actually changing this time.</p>
<h3 id="fact-2-no-official-serverless-support"><a href="#fact-2-no-official-serverless-support">¶</a> Fact #2: No official serverless support</h3>
<p>The official methods for <a href="https://nextjs.org/docs/pages/building-your-application/deploying#self-hosting">self-hosting Next.js</a> require running the application in a stateful way, as long-running servers. While technically possible, this is very hard to operate in any real-world production environment where a single instance isn’t sufficient.</p>
<p>The setup needs to be able to dynamically scale up very quickly in order to handle sudden bursts of traffic, while at the same time being able to scale down to zero in order to be cost-effective. This last part is essential when working with <a href="https://nextjs.org/docs/app/building-your-application/rendering/server-components">server components</a>, for example, where the deep tangling between client and server code <a href="https://x.com/youyuxi/status/1804331313421521101">can break older clients</a> unless every version of the server code ever deployed is available indefinitely.</p>
<p>One obvious answer to these requirements is serverless computing, as attested by official Next.js documentation that <a href="https://nextjs.org/blog/next-8#serverless-nextjs">confirms the benefits of this model</a>:</p>
<blockquote>
<blockquote>
<p>Serverless allows for distributed points of failure, infinite scalability, and is incredibly affordable with a "pay for what you use" model.</p>
</blockquote>
</blockquote>
<p>This clearly advantageous computing paradigm is precisely how Vercel has run Next.js sites in their own infrastructure for years. Given that Next.js is an open framework, it is reasonable to expect that you'd be able to use that same model in any serverless provider of your choice. But it's not that simple.</p>
<p>Next.js once had <a href="https://nextjs.org/blog/next-8#serverless-nextjs">a serverless mode</a> that you could enable with a configuration property, but it was <a href="https://github.com/vercel/next.js/pull/41495">removed without further explanation in October 2022</a>. No equivalent mode was ever introduced.</p>
<p>The official React documentation, which is <a href="https://github.com/vercel/next.js/pull/41495">the Next.js team help maintain</a>, says that Next.js can be <a href="https://react.dev/learn/creating-a-react-app#nextjs-app-router">deployed to <em>any serverless hosting</em></a>, but there is no official documentation whatsoever for this.</p>
<p>This means that any providers who want to offer support for Next.js with the same computing model that the framework itself promotes must reverse-engineer their way to a custom implementation.</p>
<h3 id="fact-3-vercel-specific-code-paths"><a href="#fact-3-vercel-specific-code-paths">¶</a> Fact #3: Vercel-specific code paths</h3>
<p>Next.js has <a href="https://github.com/search?q=repo%3Avercel%2Fnext.js+NEXT_MINIMAL+path%3A%2F%5Epackages%5C%2Fnext%5C%2F%2F&amp;type=code">code paths</a> that are only ever executed for sites deployed to Vercel. An example of this is a private flag called <a href="https://github.com/vercel/next.js/discussions/29801"><em>minimal mode</em></a>, which allows Vercel to shift work away from the framework and run it on their edge infrastructure.</p>
<p>Here's an example of why that matters. <a href="https://nextjs.org/blog/next-12#introducing-middleware">Next 12 introduced middleware</a>, a way to address use cases such as feature flags, A/B tests and advanced routing. What's common in all of these use cases is the need to run logic on the hot path, behind the cache, with very low latency.</p>
<p>The announcement included this:</p>
<blockquote>
<blockquote>
<p>This works out of the box using <code>next start</code>, as well as on Edge platforms like Vercel, which use Edge Middleware.</p>
</blockquote>
</blockquote>
<p>In practice, this means that you have two options: use <code>next start</code> and run middleware alongside the rest of your application in your <em>origin</em> server (which is typically running in a single region, after the cache), or use one of the «<em>Edge platforms like Vercel</em>» to run middleware at the edge, before the cache, unlocking all the incredible use cases that <a href="https://vercel.com/resources/edge-middleware-experiments-personalization-performance">Vercel boasted in the resources linked in the announcement</a>.</p>
<p>The phrase «<em>Edge platforms like Vercel</em>» surely means that there are many alternatives out there because other providers were given the option to also implement middleware at the edge, right? No.</p>
<p>This secret minimal mode is what allowed Vercel to break out middleware from the rest of the application so they could run it at the edge, but only Vercel has access to it.</p>
<p>Netlify does support running middleware at the edge, but we've done it at the expense of having a full team of engineers dedicated to reverse-engineering the framework and building our own edge middleware implementation on top of undocumented APIs. This type of commitment is just impossible for smaller companies that simply do not have the resources to fight this battle, which makes most of them <a href="https://www.stormkit.io/blog/why-we-are-dropping-support-for-next-js">stop trying</a>.</p>
<p>As far as I know, Netlify is the only cloud provider to support the full feature set of Next.js outside of Vercel, which doesn't make sense to me. With Next.js having such a sizeable share of the market, I would expect a lot more hosting options, which would foster competition and innovation across the board, ultimately benefitting users and the web.</p>
<p>So why is there a hidden door in Next.js for which only Vercel holds the key? I think it's expected that the framework maintainers regularly experiment with features before they're launched, but minimal mode isn't that. We're talking about entirely different operation mode for the framework, which has been in the code base for many years and which unlocks capabilities that are reserved for the for-profit company that owns the framework.</p>
<p>If WordPress had a privileged code path that was only accessible to sites deployed to Automattic properties, would it be trusted as a truly open project and would it have the dominance it has today?</p>
<h2 id="security-posture"><a href="#security-posture">¶</a> Security posture</h2>
<p>Let's go back to the security incident. On Friday, March 21st at 10:17 AM (UTC), Vercel published <a href="https://github.com/advisories/GHSA-f82v-jwr5-mffw">a CVE for a critical security incident</a>, ranked with a severity of 9.1 out of 10.</p>
<p>In essence, it was possible for anyone to completely bypass Next.js middleware by sending a specific header in the request. This is important because <a href="https://nextjs.org/blog/next-12#introducing-middleware">authorisation was one of the flagship use cases of middleware</a>, and this exploit meant that anyone could bypass the authentication layer and gain access to protected resources.</p>
<p>As the incident unravelled, a few things became apparent. First of all, the vulnerability was <a href="https://nextjs.org/blog/cve-2025-29927#timeline">reported to the Next.js team on February 27th</a>, but it wasn't until March 14th that the team started looking into it. Once they did, they started pushing fixes for <a href="https://github.com/vercel/next.js/commit/5fd3ae8f8542677c6294f32d18022731eab6fe48">Next 14</a> and <a href="https://github.com/vercel/next.js/commit/52a078da3884efe6501613c7834a3d02a91676d2">Next 15</a> within a couple of hours.</p>
<p>So by March 14th (at the latest), Vercel knew they had a serious incident on their hands. The responsible thing to do at that point would be immediately disclosing the vulnerability to other providers, so that they could assess the impact to their own customers and take any necessary actions to protect them as quickly as possible. At times like these, our duty to protect users should rise above any competition between companies.</p>
<p>That is not what happened. It took Vercel 8 (eight) days to reach out to Netlify. In that time, they managed to push patches to Next.js, cut two releases, and even write a blog post that framed the incident as something that Vercel's firewall had <em>«proactively protected»</em> their customers from (even though <a href="https://x.com/cramforce/status/1903648110863343871?s=46">their CTO later said</a> that their firewall had nothing to do with it).</p>
<p>I think it's incredibly disingenuous to spin a critical security vulnerability in your open-source project as a strength of your product, with absolutely no consideration for whether users in other providers were also affected and what they should do to mitigate. In fact, they wouldn't even know this, because they hadn't even reached out to us at this point.</p>
<p>After <a href="https://bsky.app/profile/eduardoboucas.com/post/3lky5uuo5os2o">being called out on social media</a>, Vercel have rewritten the blog post to remove any mention of their firewall and clarify which providers had been affected whether their customers had to take any action.</p>

<p>Vercel has then <a href="https://vercel.com/blog/postmortem-on-next-js-middleware-bypass#2025-03-21">released a postmortem</a> where they said — for the first time — that on March 21st they were able to «<em>verify Netlify and Cloudflare Workers were not impacted</em>». This is directly contradicted by their staff <a href="https://x.com/eduardoboucas/status/1904672921206865935">reaching out to Netlify on March 22nd</a> offering help to «<em>get a patch up</em>». If we were not impacted, what was there to patch?</p>
<p>This lack of consideration for any users outside of Vercel has created unnecessary anxiety and confusion for a lot of people, leaving some providers scrambling to <a href="https://x.com/elithrar/status/1903411980070797691">find a solution</a> and then having to <a href="https://x.com/elithrar/status/1903526240847331362">partially roll it back</a>, others <a href="https://x.com/ClerkDev/status/1903497002828120426">announcing that they were not vulnerable</a> when in reality <a href="https://x.com/n2d4wastaken/status/1903748178874360024?s=46">they were</a>, etc.</p>
<p>As you read this, it's impossible for anyone to know how many sites out there are still vulnerable to this exploit, many of which would've been safe if things were handled differently.</p>
<p>And at the height of all this mess, Vercel's leadership had... <a href="https://x.com/rauchg/status/1903528305002762387">a different focus</a>.</p>
<h2 id="but-vercel-owns-next-js"><a href="#but-vercel-owns-next-js">¶</a> But Vercel owns Next.js</h2>
<p>They do. And they have every right to make a business out of the framework that they've put so much work, talent, time and energy into building and growing. I'm not disputing that.</p>
<p>But that growth holds them to a high bar of standards that, in my opinion, they have repeatedly failed to meet.</p>
<p><em>«If Vercel own Next.js, what incentive do they have to open it up to other providers?»</em> is <a href="https://x.com/jamonholmgren/status/1904174718779072575">a question I sometimes see</a> and which I find intriguing. What incentives does Redis have for opening up their software when they own Redis Cloud? Why make Grafana open when Grafana Cloud is owned by the same company? Or WordPress, ClickHouse and many others?</p>
<p>The incentive is that they <em>have</em> to do those things if they choose to publish their software as open-source and not as a closed, proprietary solution. Their success is intrinsically associated their users having the guarantee that they are free to choose whatever provider offers the service that meets your needs at any given time.</p>
<h2 id="wrapping-up"><a href="#wrapping-up">¶</a> Wrapping up</h2>
<p>It's not my business to say which framework you should use. If you like Next.js and you still think it's the best tool for the problem you need to solve, you should absolutely use it. But I hope that this information helps you feel more confident about your decision, whichever way you're leaning.</p>
<p>As for me, I'll keep doing my job to help support the developers who chose to deploy their sites to Netlify, whatever their framework of choice is. And competition aside, I'm genuinely looking forward to help Vercel make Next.js more open and interoperable through the OpenNext movement. ∎</p>
<h3 id="vercel-s-response"><a href="#vercel-s-response">¶</a> Vercel's response</h3>
<p><em>This is a placeholder where I will share any response I receive from Vercel to this post.</em></p>
<p><em>Update (March 26th):</em> Added <a href="#update-1">a note</a> about Vercel's most recent postmortem and <a href="https://eduardoboucas.com/#vercel-s-response">a section for Vercel's response</a>.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[DOGE staffer,'Big Balls', provided tech support to cybercrime ring, records show (147 pts)]]></title>
            <link>https://www.reuters.com/world/us/doge-staffer-big-balls-provided-tech-support-cybercrime-ring-records-show-2025-03-26/</link>
            <guid>43480880</guid>
            <pubDate>Wed, 26 Mar 2025 11:09:59 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/world/us/doge-staffer-big-balls-provided-tech-support-cybercrime-ring-records-show-2025-03-26/">https://www.reuters.com/world/us/doge-staffer-big-balls-provided-tech-support-cybercrime-ring-records-show-2025-03-26/</a>, See on <a href="https://news.ycombinator.com/item?id=43480880">Hacker News</a></p>
Couldn't get https://www.reuters.com/world/us/doge-staffer-big-balls-provided-tech-support-cybercrime-ring-records-show-2025-03-26/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Europe's Largest Makerspace (128 pts)]]></title>
            <link>https://www.berlin-partner.de/en/news/detail/europas-groesster-makerspace</link>
            <guid>43480396</guid>
            <pubDate>Wed, 26 Mar 2025 09:42:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.berlin-partner.de/en/news/detail/europas-groesster-makerspace">https://www.berlin-partner.de/en/news/detail/europas-groesster-makerspace</a>, See on <a href="https://news.ycombinator.com/item?id=43480396">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-content"><!--
					
						
					
            --><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>20 selected startups presented their business ideas to high-calibre investors in the Rotes Rathaus. </p><p><a title="Startup Pitch 2025" href="https://www.berlin-partner.de/en/news/detail/startup-pitch-2025">
			Read more
		</a></p></div><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>A YouTube documentary offers exciting insights to those interested. </p><p><a title="A virtual visit to the ICC " href="https://www.berlin-partner.de/en/news/detail/ein-virtueller-besuch-im-icc">
			Read more
		</a></p></div><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>A delegation trip and much more: Berlin’s creative scene will be showcased in Austin, Texas, from 7 to 15 March.</p><p><a title="Berlin goes Austin: SXSW 2025" href="https://www.berlin-partner.de/en/news/detail/berlin-goes-austin-sxsw-2025">
			Read more
		</a></p></div><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>On sale from 3 March: 15 euros per scarf go to three organisations that help the homeless. </p><p><a title="Style and solidarity: The exclusive Berlin scarf" href="https://www.berlin-partner.de/en/news/detail/style-and-solidarity-the-exclusive-berlin-scarf">
			Read more
		</a></p></div><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>Berlin Partner’s annual results 2024 show: The capital’s economy continues to develop positively despite the weakening economy nationwide. </p><p><a title="Positive Development in Berlin " href="https://www.berlin-partner.de/en/news/detail/positive-development-in-berlin">
			Read more
		</a></p></div><!--
	=====================
		Partials/List/Item.html
--><div itemscope="itemscope" itemtype="http://schema.org/Article"><p>The Business Angels Club Berlin-Brandenburg has been supporting startup founders in building their own companies for more than 20 years.</p><p><a title="The Investor Network" href="https://www.berlin-partner.de/en/news/detail/das-investierenden-netzwerk">
			Read more
		</a></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Gemini 2.5 Pro reasons about task feasibility (127 pts)]]></title>
            <link>https://everything.intellectronica.net/p/negotiating-with-the-machine</link>
            <guid>43479985</guid>
            <pubDate>Wed, 26 Mar 2025 08:21:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://everything.intellectronica.net/p/negotiating-with-the-machine">https://everything.intellectronica.net/p/negotiating-with-the-machine</a>, See on <a href="https://news.ycombinator.com/item?id=43479985">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>After spending some time this morning generating various pictures of monkeys I got bored and decided to ask Gemini 2.5 Pro to create a virtual synthesizer for me. My initial ambition was to get a recreation of the famous ReBirth RB-338 virtual synth from the late 90s, and I have gathered a pretty good spec and instructed the AI to recreate it in HTML and Javascript.</p><p>What happened next is surprising and significant. Gemini did its “thinking” schtick. During its thinking session it reached the conclusion that this task is not feasible in one shot. It then stopped and explained that to me.</p><p>Thinking Excerpt:</p><blockquote><p><code>…</code></p><p><code>Feasibility Assessment:</code></p><p><code>Creating a complete and fully working reproduction of ReBirth RB-338 is an enormous undertaking, likely requiring months or even years of development by an experienced team. It involves deep knowledge of digital signal processing (DSP), web audio APIs (like Tone.js), UI development, and the specific nuances of the original hardware ReBirth emulated.</code></p><p><code>Limitations:</code></p><p><code>Complexity: The scope is far beyond what can be generated in a single response. It's a full-scale software development project.</code></p><p><code>Accuracy: Achieving authentic emulation, especially for the TB-303 filter, is extremely challenging. Tone.js provides building blocks, but the specific tuning and interaction of components require significant DSP expertise.</code></p><p><code>…</code></p><p><code>Conclusion: It is not feasible to generate a complete, fully working reproduction of ReBirth RB-338 as requested in a single response. The complexity and scope are too large.</code></p><p><code>Alternative Approach:</code></p><p><code>I can provide a basic structural outline and some simplified example code snippets demonstrating key concepts using HTML, JavaScript, and Tone.js to illustrate how one might start building such a project. This would include:</code></p><p><code>Basic HTML structure.</code></p><p><code>Setting up Tone.js.</code></p><p><code>A very simplified representation of one TB-303-style synth with a few controls (e.g., cutoff, resonance).</code></p><p><code>A very simplified 16-step sequencer.</code></p><p><code>Basic UI elements (e.g., simple buttons/sliders).</code></p><p><code>This will not be a ReBirth clone, but rather a conceptual starting point.</code></p><p><code>…</code><span> </span></p></blockquote><p>I have never seen an LLM do this. Typically, if I request something that can’t be achieved, the AI will just try and fail miserably. Gemini 2.5 Pro’s ability to reason about what it can and cannot do is a powerful and important new type of behaviour.</p><p><span>Anyway, not one to take no for an answer, I negotiated, and Gemini did produce a simpler but nevertheless fully working and fun synthesizer. </span><a href="https://codepen.io/intellectronica/full/XJWBxoB" rel="">Give it a try</a><span>.</span></p><div><figure><a target="_blank" href="https://codepen.io/intellectronica/full/XJWBxoB" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png" width="1456" height="1492" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1492,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:136628,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:&quot;https://codepen.io/intellectronica/full/XJWBxoB&quot;,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://everything.intellectronica.net/i/159895404?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5a8a528b-eb71-49f5-ab4f-4c8ae1e0ed60_1526x1564.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coordinating the Superbowl's visual fidelity with Elixir (537 pts)]]></title>
            <link>https://elixir-lang.org/blog/2025/03/25/cyanview-elixir-case/</link>
            <guid>43479094</guid>
            <pubDate>Wed, 26 Mar 2025 05:19:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://elixir-lang.org/blog/2025/03/25/cyanview-elixir-case/">https://elixir-lang.org/blog/2025/03/25/cyanview-elixir-case/</a>, See on <a href="https://news.ycombinator.com/item?id=43479094">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
        <p>How do you coordinate visual fidelity across two hundred cameras for a live event like the Super Bowl?</p>

<p>The answer is: by using the craft of camera shading, which involves adjusting each camera to ensure they match up in color, exposure and various other visual aspects. The goal is to turn the live event broadcast into a cohesive and consistent experience. For every angle used, you want the same green grass and the same skin tones. Everything needs to be very closely tuned across a diverse set of products and brands. From large broadcast cameras, drone cameras, and PTZ cameras to gimbal-held mirrorless cameras and more. This is what Cyanview does. Cyanview is a small Belgian company that sells products for the live video broadcast industry, and its primary focus is shading.</p>

<p>Broadcast is a business where you only get one chance to prove that your tool is up to the task. Reliability is king. There can be no hard failures.</p>

<p>A small team of three built a product so powerful and effective that it spread across the industry purely on the strength of its functionality. Without any marketing, it earned a reputation among seasoned professionals and became a staple at the world’s top live events. Cyanview’s Remote Control Panel (RCP) is now used by specialist video operators on the Olympics, Super Bowl, NFL, NBA, ESPN, Amazon and many more. Even most fashion shows in Paris use Cyanview’s devices.</p>

<p>These devices put Elixir right in the critical path for serious broadcast operations. By choosing Elixir, Cyanview gained best-in-class networking features, state-of-the-art resilience and an ecosystem that allowed fast iteration on product features.</p>

<p><img src="https://elixir-lang.org/images/cases/bg/cyanview-4.jpg" alt="Operating many displays with Cyanview products." title="Operating many displays with Cyanview products."></p>

<h2 id="why-elixir">Why Elixir?</h2>

<p>The founding team of Cyanview primarily had experience with embedded development, and the devices they produce involve a lot of low-level C code and plenty of FPGA. This is due to the low-level details of color science and the really tight timing requirements.</p>

<p>If you’ve ever worked with camera software, you know it can be a mixed bag. Even after going fully digital, much of it remained tied to analog systems or relied on proprietary connectivity solutions. Cyanview has been targeting IP (as in Internet Protocol) from early on. This means Cyanview’s software can operate on commodity networks that work in well-known and well-understood ways. This has aligned well with an increase in remote production, partially due to the pandemic, where production crews operate from a central location with minimal crew on location. Custom radio frequency or serial wire protocols have a hard time scaling to cross-continent distances.</p>

<p>This also paved the way for Elixir, as the Erlang VM was designed to communicate and coordinate millions of devices, reliably, over the network.</p>

<p>Elixir was brought in by the developer Ghislain, who needed to build integrations with cameras and interact with the other bits of required video gear, with many different protocols over the network. The language comes with a lot of practical features for encoding and decoding binary data down to the individual bits. Elixir gave them a strong foundation and the tools to iterate fast.</p>

<p>Ghislain has been building the core intellectual property of Cyanview ever since. While the physical device naturally has to be solid, reliable, and of high quality, a lot of the secret sauce ultimately lies in the massive number of integrations and huge amounts of reverse engineering. Thus, the product is able to work with as many professional camera systems and related equipment as possible. It is designed to be compatible with everything and anything a customer is using. Plus, it offers an API to ensure smooth integration with other devices.</p>

<p>David Bourgeois, the founder of Cyanview, told us a story how these technical decisions alongside Elixir helped them tackle real-world challenges:</p>

<p>“During the Olympics in China, a studio in Beijing relied on a large number of Panasonic PTZ cameras. Most of their team, however, was based in Paris and needed to control the cameras remotely to run various shows throughout the day. The problem? Panasonic’s camera protocols were never designed for internet use — they require precise timing and multiple messages for every adjustment. With network latency, that leads to timeouts, disconnects, and system failures… So they ended up placing our devices next to the cameras in Beijing and controlled them over IP from Paris — just as designed.”</p>

<p><img src="https://elixir-lang.org/images/cases/bg/cyanview-2.jpg" alt="Cyanview RIO device mounted on a camera at a sports field." title="Cyanview RIO device mounted on a camera at a sports field."></p>

<p>The devices in a given location communicate and coordinate on the network over a custom MQTT protocol. Over a hundred cameras without issue on a single Remote Control Panel (RCP), implemented on top of Elixir’s network stack.</p>

<h2 id="technical-composition">Technical composition</h2>

<p>The system as a whole consists of RCP devices running a Yocto Linux system, with most of the logic built in Elixir and C. While Python is still used for scripting and tooling, its role has gradually diminished. The setup also includes multiple microcontrollers and the on-camera device, all communicating over MQTT. Additionally, cloud relays facilitate connectivity, while dashboards and controller UIs provide oversight and control. The two critical devices are the RCP offering control on the production end and the RIO handling low-latency manipulation of the camera. Both run Elixir.</p>

<p>The configuration UI is currently built in Elm, but - depending on priorities - it might be converted to <a href="https://phoenixframework.org/">Phoenix LiveView</a> over time to reduce the number of languages in use. The controller web UI is already in LiveView, and it is performing quite well on a very low-spec embedded Linux machine.</p>

<p>The cloud part of the system is very limited today, which is unusual in a world of SaaS. There are cloud relays for distributing and sharing camera control as well as forwarding network ports between locations and some related features, also built in Elixir, but cloud is not at the core of the business. The devices running Elixir on location form a cluster over IP using a custom MQTT-based protocol suited to the task and are talking to hundreds of cameras and other video devices.</p>

<p>It goes without saying that integration with so much proprietary equipment comes with challenges. Some integrations are more reliable than others. Some devices are more common, and their quirks are well-known through hard-won experience. A few even have good documentation that you can reference while others offer mystery and constant surprises. In this context, David emphasizes the importance of Elixir’s mechanisms for recovering from failures:</p>

<p>“If one camera connection has a blip, a buggy protocol or the physical connection to a device breaks it is incredibly important that everything else keeps working. And this is where Elixir’s supervision trees provide a critical advantage.”</p>

<h2 id="growth--team-composition">Growth &amp; team composition</h2>

<p>The team has grown over the 9 years that the company has been operating, but it did so at a slow and steady pace. On average, the company has added just one person per year. With nine employees at the time of writing, Cyanview supports some of the biggest broadcast events in the world.</p>

<p>There are two Elixir developers on board: Daniil who is focusing on revising some of the UI as well as charting a course into more cloud functionality, and Ghislain, who works on cameras and integration. Both LiveView and Elm are used to power device UIs and dashboards.</p>

<p>What’s interesting is that, overall, the other embedded developers say that they don’t know much about Elixir and they don’t use it in their day-to-day work. Nonetheless, they are very comfortable implementing protocols and encodings in Elixir. The main reason they haven’t fully learned the language is simply time — they have plenty of other work to focus on, and deep Elixir expertise hasn’t been necessary. After all, there’s much more to their work beyond Elixir: designing PCBs, selecting electronic components, reverse engineering protocols, interfacing with displays, implementing FPGAs, managing production tests, real productions and releasing firmware updates.</p>

<h2 id="innovation-and-customer-focus">Innovation and customer focus</h2>

<p><img src="https://elixir-lang.org/images/cases/bg/cyanview-3.jpg" alt="Operator using Cyanview RCP for a massive crowd in an arena." title="Operator using Cyanview RCP for a massive crowd in an arena."></p>

<p>Whether it’s providing onboard cameras in 40+ cars during the 24 hours of Le Mans, covering Ninja Warrior, the Australian Open, and the US Open, operating a studio in the Louvre, being installed in NFL pylons, or connecting over 200 cameras simultaneously – the product speaks for itself. Cyanview built a device for a world that runs on top of IP, using Elixir, a language with networking and protocols deep in its bones. This choice enabled them to do both: implement support for all the equipment and provide features no one else had.</p>

<p>By shifting from conventional local-area radio frequency, serial connections, and inflexible proprietary protocols to IP networking, Cyanview’s devices redefined how camera systems operate. Their feature set is unheard of in the industry: Unlimited multicam. Tally lights. Pan &amp; Tilt control. Integration with color correctors. World-spanning remote production.</p>

<p>The ease and safety of shipping new functionality have allowed the company to support new features very quickly. One example is the increasing use of mirrorless cameras on gimbals to capture crowd shots. Cyanview were able to prototype gimbal control, test it with a customer and validate that it worked in a very short amount of time. This quick prototyping and validation of features is made possible by a flexible architecture that ensures that critical fundamentals don’t break.</p>

<p>Camera companies that don’t produce broadcast shading remotes, such as Canon or RED, recommend Cyanview to their customers. Rather than competing with most broadcast hardware companies, Cyanview considers itself a partner. The power of a small team, a quality product and powerful tools can be surprising. Rather than focusing on marketing, Cyanview works very closely with its customers by supporting the success of their events and providing in-depth customer service.</p>

<h2 id="looking-back-and-forward">Looking back and forward</h2>

<p>When asked if he would choose Elixir again, David responded:</p>

<p>“Yes. We’ve seen what the Erlang VM can do, and it has been very well-suited to our needs. You don’t appreciate all the things Elixir offers out of the box until you have to try to implement them yourself. It was not pure luck that we picked it, but we were still lucky. Elixir turned out to bring a lot that we did not know would be valuable to us. And we see those parts clearly now.”</p>

<p>Cyanview hopes to grow the team more, but plans to do so responsibly over time. Currently there is a lot more to do than the small team can manage.</p>

<p>Development is highly active, with complementary products already in place alongside the main RCP device, and the future holds even more in that regard. Cloud offerings are on the horizon, along with exciting hardware projects that build on the lessons learned so far. As these developments unfold, we’ll see Elixir play an increasingly critical role in some of the world’s largest live broadcasts.</p>

<p><img src="https://elixir-lang.org/images/cases/bg/cyanview-1.jpg" alt="Cyanview Remote Control Panels in a control room." title="Cyanview Remote Control Panels in a control room."></p>

<h2 id="in-summary">In summary</h2>

<p>A high-quality product delivering the right innovation at the right time in an industry that’s been underserved in terms of good integration. Elixir provided serious leverage for developing a lot of integrations with high confidence and consistent reliability. In an era where productivity and lean, efficient teams are everything, Cyanview is a prime example of how Elixir empowers small teams to achieve an outsized impact.</p>


      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[CIA Director Reveals Signal Comes Installed on Agency Computers (113 pts)]]></title>
            <link>https://theintercept.com/2025/03/25/signal-chat-encryption-hegseth-cia/</link>
            <guid>43478091</guid>
            <pubDate>Wed, 26 Mar 2025 02:02:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://theintercept.com/2025/03/25/signal-chat-encryption-hegseth-cia/">https://theintercept.com/2025/03/25/signal-chat-encryption-hegseth-cia/</a>, See on <a href="https://news.ycombinator.com/item?id=43478091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
    
<p><span>For years, U.S.</span> officials villainized end-to-end encrypted messaging apps like Signal as the domain of criminals and terrorists and a threat to national security.</p>



<p>As fallout over a Signal group chat about Yemen war plans ricocheted through Washington, however, CIA Director John Ratcliffe revealed at a Senate Intelligence Committee hearing on Tuesday that the app is approved for official communication and even comes installed on agency computers.</p>



<p>One longtime critic of government attacks on secure messaging said it was a sign that everybody else should follow suit.</p>



<p>“For everyday Americans, this seems like an inadvertent but strong endorsement of the cybersecurity and privacy value that Signal represents — assuming you actually know who you’re adding to the given chats,” said Sean Vitka, executive director of the progressive group Demand Progress.</p>



<h2 id="h-going-dark">“Going Dark”</h2>



<p>The highly sensitive discussion over whether and when to attack Houthis in Yemen included two members of the panel at Tuesday’s hearing, according to a blockbuster <a href="https://www.theatlantic.com/politics/archive/2025/03/trump-administration-accidentally-texted-me-its-war-plans/682151/">report </a>Monday from The Atlantic’s Jeffrey Goldberg.</p>



<p>There was particular irony to an FBI director’s presence on the panel next to members of the thread. For years, successive FBI chiefs Chris Wray and James Comey had <a href="https://theintercept.com/2015/12/09/comey-calls-on-tech-companies-offering-end-to-end-encryption-to-reconsider-their-business-model/">lambasted</a> end-to-end <a href="https://theintercept.com/2015/07/08/fbi-director-comey-proposes-imaginary-solution-encryption/">encryption</a>. The FBI <a href="https://cdt.org/insights/going-dark-versus-a-golden-age-for-surveillance/">popularized</a> the idea that terrorists and drug cartels were “<a href="https://theintercept.com/2015/07/07/fbi-finds-new-bogeyman-anti-encryption-arguments-isis/">going dark</a>” on law enforcement, and that the government needed to step in to do something about it.</p>



<p>The FBI’s <a href="https://www.huffpost.com/entry/james-comey-phone-encryption_n_5996808">favored solution</a> was to create a back door in the apps that would allow the government to snoop on conversations — but only with proper authority, the FBI said.</p>



<p>In a 2014 speech, then-FBI Director Comey <a href="http://fbi.gov/news/speeches/going-dark-are-technology-privacy-and-public-safety-on-a-collision-course">said</a> that the “post-Snowden pendulum has swung too far” in favor of privacy. Without creating a back door, he added, “homicide cases could be stalled, suspects could walk free, and child exploitation victims might not be identified or recovered.”</p>



<p>The FBI never made much progress in Congress toward securing a back door. Across the pond, attacks on end-to-end encryption are ongoing, with the United Kingdom reportedly ordering Apple in secret to create one. France’s National Assembly last week <a href="https://www.eff.org/deeplinks/2025/03/win-encryption-france-rejects-backdoor-mandate">voted down a backdoor mandate</a> sought by the country’s Interior Ministry.</p>



<!-- BLOCK(cta)[0](%7B%22componentName%22%3A%22CTA%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(cta)[0] -->



<h2 id="h-the-cia-seal-of-approval">The CIA Seal of Approval</h2>



<p>The FBI’s official position became increasingly tenuous last year when revelations about “Salt Typhoon” hackers made clear that unencrypted communications were highly vulnerable to foreign adversaries.</p>



  



<p>The hackers, who were allegedly affiliated with the Chinese government, targeted phones used by Donald Trump, JD Vance, and the Kamala Harris campaign, according to reports, and in some cases were able to scoop up the content of text conversations.</p>



<p>By December, the FBI was still promoting back doors under the banner of what it calls “responsibly managed” encryption. At the same time, however, the Cybersecurity and Infrastructure Security Agency was advising end-to-end encrypted messaging apps such as Signal as a defense against Chinese hackers.</p>



<p><a href="https://theintercept.com/2017/05/01/cybersecurity-for-the-people-how-to-keep-your-chats-truly-private-with-signal/">Signal</a>, which is based on an open-source protocol and operated by a nonprofit foundation, is <a href="https://theintercept.com/2024/03/04/signal-app-username-phone-number-privacy/">designed to reduce to a minimum</a> the amount of information that the app can access. Only the users involved in a conversation have decryption keys, making it impossible for the Signal Foundation to view unencrypted conversations. The foundation also cannot see metadata such as a user’s contacts.</p>



<p>On Tuesday, Ratcliffe revealed that the government has adopted Signal at the highest echelons.</p>



<figure><blockquote><p>“One of the first things that happened when I was confirmed as CIA director was Signal was loaded onto my computer at the CIA.”</p></blockquote></figure>



<p>“One of the first things that happened when I was confirmed as CIA director was Signal was loaded onto my computer at the CIA, as it is for most CIA officers,” Ratcliffe said.</p>



<p>The practice began during President Joe Biden’s administration and had the official approval of CIA records management officials, Ratcliffe said, as long as “any decisions that are made are also recorded through formal channels.”</p>



<p>Critics of government secrecy were immediately alarmed that government officials might be trying to evade leaving records subject to the Freedom of Information Act or the <a href="https://theintercept.com/2023/01/20/biden-trump-classified-documents/">Presidential Records Act</a> by using private devices with disappearing messages.</p>



<p>Despite the high level of protection that end-to-end encryption provides in transit, however, the group chat also raised serious security issues. Even secure messaging apps cannot solve the problem of hackers who have compromised the device running them. Nor can they keep information secret in the event of human error — say, <a href="https://www.nytimes.com/2025/03/24/us/politics/hegseth-classified-war-plans-group-chat.html">inadvertently adding a journalist</a> to a sensitive discussion of military strikes.</p>



<p>Under questioning from Sen. Jack Reed, D-R.I., Director of National Intelligence Tulsi Gabbard refused to say whether she used a personal or government-issued phone for her part of the conversation.</p>



<p>Sen. Michael Bennet, D-Colo., also asked Ratcliffe whether he was aware that Trump’s special envoy Steve Witkoff, another member of the group chat, was on a <a href="https://www.cbsnews.com/news/trump-envoy-steve-witkoff-signal-text-group-chat-russia-putin/">trip in Moscow during the conversation,</a> raising more concerns.</p>



<!-- BLOCK(newsletter)[1](%7B%22componentName%22%3A%22NEWSLETTER%22%2C%22entityType%22%3A%22SHORTCODE%22%2C%22optional%22%3Atrue%7D)(%7B%7D) -->

<!-- END-BLOCK(newsletter)[1] -->



<p>Signal offers users the ability to sync messages across multiple devices. Vitka, the advocate with Demand Progress, said that if government officials were syncing messages to vulnerable private devices, that would raise a host of questions.</p>



<p>“That personal device could be the liability. And as soon as any of these devices are compromised, then the entire chat, the entire thread — then all of the information in it is compromised,” he said.</p>



<p>Senate Republicans largely attempted to sidestep questions about the Yemen group chat during the committee hearing, but Democrats were united in their criticism.</p>



<p>“This is an embarrassment. This is utterly unprofessional. There has been no apology. There has been no recognition of the gravity of this error,” <a href="https://x.com/cspan/status/1904568753917943950">said</a> Sen. Jon Ossoff, D-Ga.</p>



<p><strong>Correction: March 2, 2025, 10:55 p.m. ET</strong><br><em>This story has been corrected to remove an errant reference to FBI Director Kash Patel’s presence in the national security officials’ Signal group.</em></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[You might want to stop running atop (290 pts)]]></title>
            <link>https://rachelbythebay.com/w/2025/03/25/atop/</link>
            <guid>43477057</guid>
            <pubDate>Tue, 25 Mar 2025 23:09:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2025/03/25/atop/">https://rachelbythebay.com/w/2025/03/25/atop/</a>, See on <a href="https://news.ycombinator.com/item?id=43477057">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2025/03/25/atop/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Better Shell History Search (183 pts)]]></title>
            <link>https://tratt.net/laurie/blog/2025/better_shell_history_search.html</link>
            <guid>43476793</guid>
            <pubDate>Tue, 25 Mar 2025 22:35:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tratt.net/laurie/blog/2025/better_shell_history_search.html">https://tratt.net/laurie/blog/2025/better_shell_history_search.html</a>, See on <a href="https://news.ycombinator.com/item?id=43476793">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="article-body">





<p>I spend an awful lot of my day in Unix terminals running shell commands. For
some reason, the variance in efficiency between different people when using the shell
is huge: I know people who can run rings around me, and I’ve come across
more than one paid professional who doesn’t use the “up” key to retrieve the
previous command.</p>
<p>I chose that last example very deliberately: most of the commands most of us
run in the shell are highly repetitive. I typically run around 50-100 unique
(i.e. syntactically distinct) shell commands per working day <span>[1]</span> — but
I’ll often run a tiny subset of those commands (e.g. <code>cargo test</code>) hundreds of
time in a single day.</p>
<p>Since many command-line tools have hard-to-remember options, we can save huge
chunks of time – not to mention make fewer errors – if we can search our
shell history to find a previous incantation of a command we want to run. In
this post I’m going to show how, with little effort, searching shell
history can look like this:</p>
<p><video controls=""><source src="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/skim.mp4" type="video/mp4"><a href="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/skim.mp4">[Video]</a></video></p>
<h2><a name="searching_shell_history">Searching shell history</a></h2>
<p>Larger Unix shells such as Bash have long allowed users to search through their
shell history by pressing <code>Ctrl-r</code> and entering a substring. If I (in order)
executed the commands <code>cat /etc/motd</code> then <code>cat /etc/rc.conf</code>, then <code>Ctrl-r</code>
followed by “cat” will first match <code>cat /etc/rc.conf</code>; pressing <code>Ctrl-r</code> again
will cycle backwards for the next match which is <code>cat /etc/motd</code>. I almost
never used this feature, because substring matching is too crude.
For example, I may know the command I want is <code>cat</code>, the leaf
name I’m looking for is <code>motd</code> but I don’t remember the directory: substring
matching can’t help me find what I’m looking for. Instead, I regularly used
<code>grep</code> (with wildcards) to search through my shell’s history file instead.</p>
<p>For me, the game changer was pairing <code>Ctrl-r</code> with
<a href="https://github.com/junegunn/fzf">fzf</a>, which brought two changes. First,
matching is “fuzzy”, so I can type “c mo” and <code>cat /etc/motd</code> will be
matched. Second, multiple matches are shown at once. Typing “cat” will show
me several <code>cat</code> commands, allowing me to quickly select the right
incantation (which may not have been the most recent).</p>
<p>It’s difficult for me to overstate how powerful a feature this is. Few things
in life make me as happy as pressing <code>ctrl-R</code> then typing “<code>l1</code>” and having a 100
character command-line execution that runs a complicated debugging tool, with
multiple environment variables set, whose output gets put in <code>/tmp/l1</code> appear
in my terminal.</p>
<p>Using <code>Ctrl-r</code> and fzf roughly doubled my efficiency in the shell
overnight. Interestingly, it had an even greater long term effect: I became a
more ambitious user of shell commands because I knew I could outsource my
memory to fzf. For example, since it’s now very easy to recall past commands, I
no longer set global environment variables, which had previously caused me
grief when I forgot about them <span>[2]</span>. Now I set environment variables on a
per-command basis, knowing that I can recall them with <code>Ctrl-r</code> and fzf.</p>
<p>For many years my favoured shell was zsh. When I later moved from zsh to fish,
<code>Ctrl-r</code> and fzf was the first thing I configured; and when I moved back to zsh
<span>[3]</span>, and redid my configuration from scratch, <code>Ctrl-r</code> and fzf was again the first
thing I got working (shortly followed by
<a href="https://github.com/zsh-users/zsh-autosuggestions">autosuggestions</a>). If you
take nothing else from this
post than “<code>Ctrl-r</code> and fzf are a significant productivity boon for Unix
users”, then I will have done something useful.</p>
<p>No tool, of course, is perfect. A
couple of months back I somehow stumbled across
<a href="https://github.com/skim-rs/skim">skim</a>, an fzf-alike that out-of-the-box
happens to suit me just a little bit better than fzf. The differences
are mostly minor, and you won’t go far wrong with either tool. That said,
I find that skim’s matching more often finds the commands I want quickly,
I prefer skim’s UI, and I find it easier to install skim on
random boxes — small advantages, perhaps, but enough for switching to be
worth it for me.</p>
<h2><a name="doing_even_better">Doing even better</a></h2>
<p>Finding Skim encouraged me to quickly look around to see what else in this sphere might
improve my productivity. I quickly came across <a href="https://atuin.sh/">Atuin</a>, which is a much
more sophisticated shell history recording mechanism: the video on its front
page showed a much nicer matching UI than I had previously considered possible.</p>
<p>However, I quickly realised Atuin wasn’t for me or, at least, wasn’t easily for
me. These days I regularly <code>ssh</code> into many different servers: over time I’ve
streamlined my shell configuration to a single <code>.zshrc</code> file that I can <code>scp</code>
over to a new machine and which instantly makes me productive. Atuin – and
this isn’t a criticism, because it’s a more powerful tool – is more difficult
to install <span>[4]</span> and setup <span>[5]</span> (I’m also not sure the ‘fuzzy’
aspects of Atuin quite match the heights of fzf/skim). That said, some readers may find
it a useful tool to investigate.</p>
<p>However, what I immediately realised from the Atuin video is that I would like
my fuzzy matcher to show me more useful information about the commands it’s
matching.</p>
<p>In particular, fzf and skim both default to showing me a (to me!) meaningless
integer before my matched command: this had always slightly bothered me, but
I’d never thought to work out what it meant. For example, if I use
zsh + fzf + <code>Ctrl-r</code> I see:</p>
<p><img src="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/fzf.png" alt=""></p>
<p>What does 5408 mean and why is it taking up valuable screen space? Skim
tries to be a bit nicer: it will show <code>5408 today'21:26</code> <span>[6]</span>, but that
takes up even more screen space!</p>
<h2><a name="adapting_zsh_and_fzfskim">Adapting zsh and fzf/skim</a></h2>
<p>Fortunately, it turns out that improving the <code>Ctrl-r</code> and the fzf/skim UI is
easy. Instead of wasting space on a meaningless-to-me integer, what I
now see is the following (where <code>11d</code> means “11 days in the past” and so on):</p>
<p><img src="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/skim.png" alt=""></p>
<p>I’m going to show how I adapted zsh and skim to do this. My guess is that it
will take very little ingenuity to adapt this to other shells (and adapting
this to fzf mostly involves swapping the <code>sk</code> command for <code>fzf</code>).</p>
<p>The first thing I needed to do is make zsh record <em>when</em> commands
were executed. I added this to my <code>~/.zshrc</code>:</p>
<pre><span>setopt</span><span> EXTENDED_HISTORY
</span><span>setopt</span><span> inc_append_history_time
</span></pre>
<p>The <code>EXTENDED_HISTORY</code> changes the format of <code>.zsh_history</code> to record when (in
seconds from the Unix epoch) a command was executed and (with
<code>inc_append_history_time</code>) how long it ran for. The good news is that these
options migrate “traditionally formatted” history files naturally: any
non-extended-history commands will be given the current date so that
all of <code>.zsh_history</code> is in the same format.</p>
<p>I then needed to understand how zsh’s history ended up being interrogated and
displayed when I pressed <code>Ctrl-r</code>. fzf and skim share almost exactly the same
code here: I’ll use skim’s <a href="https://github.com/skim-rs/skim/blob/master/shell/key-bindings.zsh">zsh key
bindings</a>
as my example. In essence, both tools define a function <code>history-widget</code>
which they then bind to <code>Ctrl-r</code>:</p>
<pre><span>history-widget</span><span>() { </span><span>... </span><span>}
</span><span>zle</span><span>     -N</span><span>   history-widget
</span><span>bindkey </span><span>'</span><span>^R</span><span>' history-widget
</span></pre>
<p>One can override the version fzf and skim provide by putting the code above
into your <code>~/.zshrc</code> after the point you import their normal key bindings.</p>
<p>Let’s look at skim’s <code>history-widget</code>:</p>
<pre><span>skim-history-widget</span><span>() {
</span><span>  </span><span>local </span><span>selected num
</span><span>  </span><span>setopt</span><span> localoptions noglobsubst noposixbuiltins pipefail no_aliases </span><span>2</span><span>&gt; /dev/null
</span><span>  </span><span>local </span><span>awk_filter</span><span>='</span><span>{ cmd=$0; sub(/^\s*[0-9]+\**\s+/, "", cmd); if (!seen[cmd]++) print $0 }</span><span>'  </span><span># filter out duplicates
</span><span>  </span><span>local </span><span>n</span><span>=</span><span>2 </span><span>fc_opts</span><span>=''
</span><span>  </span><span>if </span><span>[[ </span><span>-o</span><span> extended_history </span><span>]]</span><span>; </span><span>then
</span><span>    </span><span>local </span><span>today</span><span>=$</span><span>(</span><span>date</span><span> +</span><span>%</span><span>Y</span><span>-</span><span>%</span><span>m</span><span>-</span><span>%</span><span>d</span><span>)
</span><span>    </span><span># For today's commands, replace date ($2) with "today", otherwise remove time ($3).
</span><span>    </span><span># And filter out duplicates.
</span><span>    </span><span>awk_filter</span><span>='</span><span>{
</span><span>      if ($2 == "</span><span>'$</span><span>today</span><span>'</span><span>") sub($2 " ", "today</span><span>'</span><span>\'</span><span>'</span><span>")
</span><span>      else sub($3, "")
</span><span>      line=$0; $1=""; $2=""; $3=""
</span><span>      if (!seen[$0]++) print line
</span><span>    }</span><span>'
</span><span>    </span><span>fc_opts</span><span>='</span><span>-i</span><span>'
</span><span>    </span><span>n</span><span>=</span><span>3
</span><span>  </span><span>fi
</span><span>  </span><span>selected</span><span>=( $(</span><span>fc</span><span> -rl </span><span>$</span><span>fc_opts</span><span> 1 | </span><span>awk </span><span>"$</span><span>awk_filter</span><span>" |
</span><span>    </span><span>SKIM_DEFAULT_OPTIONS</span><span>="</span><span>--height </span><span>$</span><span>{</span><span>SKIM_TMUX_HEIGHT</span><span>:-</span><span>40%} </span><span>$</span><span>SKIM_DEFAULT_OPTIONS</span><span> -n</span><span>$</span><span>n</span><span>..,.. --bind=ctrl-r:toggle-sort </span><span>$</span><span>SKIM_CTRL_R_OPTS</span><span> --query=</span><span>$</span><span>{</span><span>(qqq)LBUFFER</span><span>} --no-multi</span><span>" $(</span><span>__skimcmd</span><span>)) )
</span><span>  </span><span>...
</span></pre>
<p>The first thing to note is that – thanks to <code>EXTENDED_HISTORY</code> – in
my context the <code>-o extended_history</code> check always returns <code>true</code>, so the body of the <code>if</code> is
always executed.</p>
<p>We can then skip ahead: <code>fc -rli 1</code> gets zsh to output its history in a more
easily digestible form than going through <code>.zsh_history</code> directly:</p>
<pre><span>$ fc -rli 1
</span><span>    4  2025-02-07 15:05  pizauth status
</span><span>    3  2025-02-07 15:03  cargo run --release server
</span><span>    2  2025-02-07 15:03  email quick
</span><span>    1  2025-02-07 14:59  rsync_cmd bencher16 ./build.sh cargo test nested_tracing
</span></pre>
<p>We can also now see what the magical integers from earlier are: they’re the row
numbers from <code>fc</code>, where <code>1</code> is the oldest command in my <code>~/.zsh_history</code>! These
are, in some situations, used as identifiers because one can ask zsh to “return
me command 5408”.</p>
<p>The awk code streams over this output, replacing today’s date with the literal
string <code>today</code>, removes the hours/minutes output from previous days, and
removes duplicates.</p>
<p>Although it’s easily missed, in the final line of the code snippet is
<code>-n$n..,..</code> which tells skim which whitespace-separated columns to fuzzy
match and print out.</p>
<p>At this point we now need to decide how to adapt things to our purposes.
The first thing we need to do with <code>fc</code>’s output is convert the time to seconds
since the Unix epoch. We can get <code>fc</code> to do that for us with <code>-t '%s'</code>. Instead
of outputting <code>2025-03-21 22:10</code> we now get <code>1742595052</code>. Notice that two
fields have now become one! Because <code>fc</code> adds leading space to the row
numbers, we’ll strip that off by piping <code>fc</code>’s output through <code>sed -E "s/^ *//"</code> <span>[7]</span>.</p>
<p>I then needed to decide how to format “how far in the past was the command
run”. After a few tries, I decided that a good approach is to give absolute
<code>hour:minute</code> times for commands in the last 20 hours, and <code>1d</code>, <code>2d</code> (etc.)
for commands 1 or more days in the past. Why 20 hours? Well, it turns out that
if I start work at 08:00, press <code>Ctrl-r</code> and see an entry at <code>08:01</code> I won’t
realise that was <em>yesterday’s</em> 08:01 (today’s 08:01 is only 60 seconds in the
future!). 20 hours solves this ambiguity: it means that, at 08:00,
yesterday afternoon’s commands show as <code>16:33</code> but yesterday
morning’s commands as <code>1d</code>.</p>
<p>We now need to switch to awk. I will admit that I initially balked at the use
of awk, a language I have never used before. I quickly explored alternatives
before realising why the code uses awk: every Unix machine has awk installed.
For those unfamiliar with awk, the program that we’re writing iterates over
each line in the input, splits that line up by whitespace, and puts the split
fields into the variables <code>$1</code>, <code>$2</code> (etc.). We’ll keep the duplicate detection
from the awk code above, but change most of the rest.</p>
<p>The first thing we need to do in awk is to convert the Unix epoch time for a
command (in field/variable <code>$2</code>) to an integer, and calculate how many seconds
it is in the past using <code>systime</code> (which returns the current time relative to
the Unix epoch):</p>
<pre><span>ts = int($2)
</span><span>delta = systime() - ts
</span></pre>
<p>We can then convert <code>delta</code> seconds to days by dividing by 86,400 (24h * 60m *
60s == 86,400s). It’s then a simple series of <code>if</code>/<code>else</code> to format this nicely
bearing in mind that:</p>
<ol>
<li>20h == 72,000s</li>
<li>string concatenation and int-to-string conversion in awk is implicit</li>
</ol>
<p>The conversion code looks as follows:</p>
<pre><span>delta_days = int(delta / 86400)
</span><span>if (delta_days &lt; 1 &amp;&amp; delta &lt; 72000) { $2=strftime("%H:%M", ts) }
</span><span>else if (delta_days == 0) { $2="1d" }
</span><span>else { $2=delta_days "d" }
</span></pre>
<p>One could choose to divvy things up further, perhaps showing commands older
than a week with “1w” and so on: I haven’t found that worth worrying about yet.</p>
<p>There is, however, one minor fly in the ointment: clock skew. This could cause
commands to appear to be executing in the future. I’ve not seen seen this
happen in practice yet, but bitter experience with computers and clocks tells
me it will at some point. I’ve defensively catered for the inevitable confusion
that will cause me by using a <code>+</code> prefix for such cases:</p>
<pre><span>delta_days = int(delta / 86400)
</span><span>if (delta &lt; 0) { $2="+" (-delta_days) "d" }
</span><span>else ...
</span></pre>
<p>Notice that I had to put <code>(-delta_days)</code> in brackets as otherwise – for reasons I’m
too lazy to investigate – awk doesn’t concatenate the integer and
string in the way I want.</p>
<p>Since we have one fewer field than before we can slightly simplify our output:</p>
<pre><span>line=$0; $1=""; $2=""
</span><span>if (!seen[$0]++) print line
</span></pre>
<p>That’s the awk code done. We then need to make one change to the <code>selected=...</code>
line changing <code>-n$n..,..</code> to <code>--with-nth $n..</code>. This tells fzf and skim to
suppress the output of the row number and not to make it part
of the fuzzy matching either.</p>
<p>Putting all that together, the updated chunk of the <code>history-widget</code> now
looks as follows (you can find the <a href="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/zsh_history_widget.sh">whole code chunk
here</a>):</p>
<pre><span>    </span><span>local </span><span>n</span><span>=</span><span>1 </span><span>fc_opts</span><span>=''
</span><span>    </span><span>if </span><span>[[ </span><span>-o</span><span> extended_history </span><span>]]</span><span>; </span><span>then
</span><span>      </span><span>awk_filter</span><span>='
</span><span>{
</span><span>  ts = int($2)
</span><span>  delta = systime() - ts
</span><span>  delta_days = int(delta / 86400)
</span><span>  if (delta &lt; 0) { $2="+" (-delta_days) "d" }
</span><span>  else if (delta_days &lt; 1 &amp;&amp; delta &lt; 72000) { $2=strftime("%H:%M", ts) }
</span><span>  else if (delta_days == 0) { $2="1d" }
</span><span>  else { $2=delta_days "d" }
</span><span>  line=$0; $1=""; $2=""
</span><span>  if (!seen[$0]++) print line
</span><span>}</span><span>'
</span><span>      </span><span>fc_opts</span><span>='</span><span>-i</span><span>'
</span><span>      </span><span>n</span><span>=</span><span>2
</span><span>    </span><span>fi
</span><span>    </span><span>selected</span><span>=( $(</span><span>fc</span><span> -rl </span><span>$</span><span>fc_opts -t </span><span>'</span><span>%s</span><span>' 1 | </span><span>sed</span><span> -E </span><span>"</span><span>s/^ *//</span><span>" | </span><span>awk </span><span>"$</span><span>awk_filter</span><span>" |
</span><span>      </span><span>SKIM_DEFAULT_OPTIONS</span><span>="</span><span>--height </span><span>$</span><span>{</span><span>SKIM_TMUX_HEIGHT</span><span>:-</span><span>40%} </span><span>$</span><span>SKIM_DEFAULT_OPTIONS</span><span> --with-nth </span><span>$</span><span>n</span><span>.. --bind=ctrl-r:toggle-sort </span><span>$</span><span>SKIM_CTRL_R_OPTS</span><span> --query=</span><span>$</span><span>{</span><span>(qqq)LBUFFER</span><span>} --no-multi</span><span>" $(</span><span>__skimcmd</span><span>)) )
</span></pre>
<p>That simple change is enough to give me this output when I press <code>Ctrl-r</code> and
start typing:</p>
<p><video controls=""><source src="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/skim.mp4" type="video/mp4"><a href="https://tratt.net/laurie/blog/extra/2025/better_shell_history_search/skim.mp4">[Video]</a></video></p>
<h2><a name="summary">Summary</a></h2>
<p>I’ve been using the changes above for about 6 weeks, and I’ve found it a
meaningful productivity enhancement. It turns out that I often remember enough
about a command I want to recall that seeing if a match is “1d” or “7d” in the
past is enough to immediately rule it in or out without scanning rightwards.
Occasionally I even search on the time delta itself: if I start a match with
“2d” fzf or skim will naturally search commands from 2 days ago.</p>
<p>But, perhaps, there is a larger point to take from this post. If, like me, you
spend a lot of your life in a Unix terminal, it can be easy to fall into
patterns of usage that would be recognisable to shell users from the 1970s.
Not only can we do better, it’s easy to do so, and the productivity
gains can be substantial!</p>
<p><strong>Acknowledgements</strong>: thanks to <a href="http://www.eddbarrett.co.uk/">Edd Barrett</a> for comments.</p>


<p>

2025-03-25 11:50

<a href="https://tratt.net/laurie/blog/2024/can_we_retain_the_benefits_of_transitive_dependencies_without_undermining_security.html">Older</a>

</p>

<div id="article-updates"><p>
If you’d like updates on new blog posts: follow me on
<a href="https://mastodon.social/@ltratt">Mastodon</a>
or <a href="https://twitter.com/laurencetratt">Twitter</a>;
or <a href="https://tratt.net/laurie/blog/blog.rss">subscribe to the RSS feed</a>;
or <a href="https://tratt.net/laurie/newsletter/">subscribe to email updates</a>:

</p>

</div>


<h3>Footnotes</h3>
















<h3>Comments</h3>







</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What's Happening to Students? (157 pts)]]></title>
            <link>https://www.honest-broker.com/p/whats-happening-to-students</link>
            <guid>43476365</guid>
            <pubDate>Tue, 25 Mar 2025 21:47:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.honest-broker.com/p/whats-happening-to-students">https://www.honest-broker.com/p/whats-happening-to-students</a>, See on <a href="https://news.ycombinator.com/item?id=43476365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg" width="1456" height="485" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:485,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:130208,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://www.honest-broker.com/i/159140978?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F751986e4-8b13-47e2-8f4a-4bd35ef8d176_2400x800.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p><span>A frustrated teacher recently took to social media with a </span><a href="https://x.com/j00ny369T/status/1900357484545442119" rel="">desperate warning:</a></p><blockquote><p>You guys don’t know what’s going on in education right now. That’s fine—how could you know unless you were working in it? But I think that you need to know….</p><p>First of all the kids have no ability to be bored whatsoever. They live on their phones. And they’re just fed a constant stream of dopamine from the minute their eyes wake up in the morning until they go to sleep at night.</p><p>Because they are in a constant state of dopamine withdrawal at school, they behave like addicts. They’re super emotional. The smallest things set them off.</p><p>When you are standing in front of them trying to teach, they’re vacant. They have no ability to tune in….</p><p>They’re not there. </p><p>And they have a level of apathy that I’ve never seen before in my whole career. Punishments don’t work because they don’t care about them. They don’t care about grades. They don’t care about college.</p></blockquote><p>They just care about the next fix—because that’s how addicts operate. They have no long term plan, just short term needs.</p><p>They can’t get back to their phones fast enough. </p><p>How bad is it for educators right now? </p><p>Check out this commentary from one experienced teacher, who finds more engaged students in prison than a college classroom.</p><p><span>This comes from Corey McCall, a member of </span><em>The Honest Broker</em><span> community who recently </span><a href="https://www.honest-broker.com/p/the-decline-of-the-novel/comment/71518718" rel="">posted this comment</a><span>:</span></p><blockquote><p>I saw this decline in both reading ability and interest occur firsthand between 2006 and 2021….I had experience teaching undergrads who hadn't comprehended the material before, but hadn't faced the challenge of students who could read it but who simply didn't care….</p><p><span>Since 2021 I've been teaching part-time in prison, and incarcerated students really want to learn. They love to read and think along with authors such as Plato, Descartes, and Simone de Beauvoir. I am teaching </span><em>Intro to Theater</em><span> this semester (the story of how this happened is interesting, but is irrelevant here) and students have been poring over </span><em>Oedipus the King</em><span> and asking why this amazing play isn't performed more regularly alongside plays like </span><em>Hamilton </em><span>and </span><em>The Lion King</em><span>.</span></p><p>I believe that there is hope for the humanities and perhaps for culture more generally, but it will be found in unusual places. </p></blockquote><p><span>I’ve made a similar claim </span><a href="https://www.honest-broker.com/p/the-real-crisis-in-humanities-isnt" rel="">in this article</a><span>—where I look outside of college for a rebirth of the humanities. It would be great if it happened in classrooms, too, but I fear that they are now the epicenter of the zombie wars. </span></p><p>Alas, I fear the number of zombie students is still growing—and at an accelerated pace.</p><p><span>Jonathan Haidt, who has taken the lead in exposing this crisis—and thus gets attacked fiercely by zombie apologists—shares horrifying trendlines from </span><a href="https://monitoringthefuture.org/" rel="">Monitoring the Future</a><span>. </span></p><p>This group at the University of Michigan has studied student behavior since 1975. But what’s happening now is unprecedented.</p><p><span>Students are literally finding it </span><em>too hard to think</em><span>. So they can’t learn new things. </span></p><p><span>Below are more ugly numbers from another in-depth study—which looks at how children spend their day.  It reveals that children </span><em>under the age of two</em><span> are already spending more than an hour per day on screens.</span></p><p>YouTube usage for this group has more than doubled in just four years. </p><p>Poor and marginalized communities are hurt the most. As your income drops, your children’s screen time more than doubles. </p><p>In other words, these children are getting turned into screen addicts long before they enter the school system. </p><p>This is why teachers are speaking out. They see the fallout every day in their classrooms. </p><p>I’m dumbfounded when I hear ‘experts’ claim that phones are not the problem. Like  tobacco companies—whose hired experts long denied the connection between smoking and cancer—they say that “correlation does not prove causation.” </p><p>But that’s just sophistry and spin. </p><p>Parents, for example, have no doubts about the danger—because they see it happening right before their eyes.</p><p>But let’s give tech companies some credit. They have improved one skill among current students—cheating, which has now reached epic proportions. </p><p><span>The situation is so extreme that more than 40% of students were caught cheating recently—</span><em><a href="https://dailynous.com/2023/05/25/am-i-the-unethical-one-a-philosophy-professor-his-cheating-students/" rel="">and it happened in an ethics class!</a></em></p><p>The professor caught them in a simple way. He simply uploaded a copy of his final exam on to the web, but with wrong answers. </p><p>“Most of these answers were not just wrong, but obviously​ wrong to anyone who had paid attention in class,” he adds. But “40 out of 96 students looked at and used the planted final for at least a critical mass of questions.”</p><p><span>Another teacher </span><a href="https://thewalrus.ca/i-used-to-teach-students-now-i-catch-chatgpt-cheats" rel="">shares a similar lament</a><span>: “I used to teach students. Now I catch ChatGPT cheats.” </span></p><blockquote><p>I once believed my students and I were in this together, engaged in a shared intellectual pursuit. That faith has been obliterated over the past few semesters.</p></blockquote><p>Tech companies know exactly what they’re doing. </p><p><span>Microsoft researchers recently published a study showing that excessive use of new tech leads to a </span><a href="https://www.404media.co/microsoft-study-finds-ai-makes-human-cognition-atrophied-and-unprepared-3/" rel="">“deterioration of cognitive faculties that ought to be preserved.”</a></p><p><span>Theses </span><em>innovations</em><span> “deprive the user of the routine opportunities to practice their judgement and strengthen their cognitive musculature, leaving them atrophied and unprepared.” </span></p><p><span>Facebook did similar research, with similarly frightening results—and they </span><a href="https://www.washingtonpost.com/technology/2021/09/16/facebook-files-internal-research-harms/" rel="">worked hard to bury the results</a><span>.  We weren’t supposed to see the charts below. But a brave whistleblower took photos and </span><a href="https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739" rel="">leaked them to the </a><em><a href="https://www.wsj.com/articles/facebook-knows-instagram-is-toxic-for-teen-girls-company-documents-show-11631620739" rel="">Wall Street Journal</a></em><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png" width="1456" height="411" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:411,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1211715,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://www.honest-broker.com/i/159140978?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png&quot;,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd7a50e4e-d280-4674-b551-e2797e32230d_1786x504.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Meanwhile, an </span><a href="https://cdn.openai.com/global-affairs/openai-edu-ai-ready-workforce.pdf" rel="">internal study at OpenAI</a><span> shows that the two most commons uses of AI by students are (1) writing papers and (2) avoiding reading assignments. Other popular uses are answering exam questions and solving math problems. </span></p><p>None of this is a secret—the dysfunctional impact of new tech on students has been documented by study after study. Youngsters are under assault by tech leaders. </p><p>That’s how they meet their profit targets. </p><p>I only have one positive angle on this.</p><p>People are now aware. The blinders have been lifted from the public’s eyes. </p><p>Big tech has destroyed its credibility—and all the billionaires in Silicon Valley can’t restore it. They can buy lobbyists and co-opt “experts” with their cash. But the evil they are doing is now apparent to all unbiased observers.</p><p>Maybe they can stall change in Washington, D.C. by controlling politicians—at least for the time being. But they can’t stop the backlash that’s rising at a grass roots level.</p><p>That’s why the response to zombie culture is happening away from the limelight—in homes, schools, city council meetings, town hall gatherings, and other places where parents, teachers, and concerned individuals gather.</p><p>But it would be wise for our political leaders to take notice, and give their support. Even better, I’d like to see the leading tech companies admit that there’s a huge problem here, and they must fix it—because they caused it in the first place.</p><p>Do you think that’s too much to hope for? Do you doubt that the CEOs of Apple, Meta, Alphabet, X, and other tech empires will help us avert the coming crisis?</p><p>They might not have any other option. Their own management teams and employees are also parents, and just might rebel. </p><p>There must be thousands of people working at these tech behemoths—many in positions of great responsibility—who are horrified by what their own companies are doing. They need to speak up, and lead by example. </p><p> And I’m convinced many of them will.  </p><p>Yes, the palace guards are more powerful than the emperor. So we have legitimate reasons to hope that Silicon Valley itself might someday heal itself—and thus help heal the victims of their overreaching.</p><p>In the meantime, we should continue to push at the local levels. We need to find programs and initiatives that work, and share them. We need to raise awareness. And we need to do what we can to protect those most at risk. </p><p>Others will join us in time. </p><p>And let me make one final plea to those working inside these tech empires. Raise your voices, start a petition, sign an open letter, speak out in private and public. Push back!</p><p>There are others like you who are just waiting from someone brave enough to take the lead. That person could be you. </p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Devs say AI crawlers dominate traffic, forcing blocks on entire countries (341 pts)]]></title>
            <link>https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/</link>
            <guid>43476337</guid>
            <pubDate>Tue, 25 Mar 2025 21:42:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/">https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/</a>, See on <a href="https://news.ycombinator.com/item?id=43476337">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main">
            <article data-id="2084217">
  
  <header>
  <div>
      

      

      <p>
        AI bots hungry for data are taking down FOSS sites by accident, but humans are fighting back.
      </p>

      
    </div>
</header>


  

  
      
    
    <div>
                      
                      
          
<p>Software developer Xe Iaso <a href="https://xeiaso.net/notes/2025/amazon-crawler/">reached a breaking point</a> earlier this year when aggressive AI crawler traffic from Amazon overwhelmed their Git repository service, repeatedly causing instability and downtime. Despite configuring standard defensive measures—adjusting robots.txt, blocking known crawler user-agents, and filtering suspicious traffic—Iaso found that AI crawlers continued evading all attempts to stop them, spoofing user-agents and cycling through residential IP addresses as proxies.</p>
<p>Desperate for a solution, Iaso eventually resorted to moving their server behind a VPN and creating "Anubis," a custom-built proof-of-work challenge system that forces web browsers to solve computational puzzles before accessing the site. "It's futile to block AI crawler bots because they lie, change their user agent, use residential IP addresses as proxies, and more," Iaso wrote in a <a href="https://xeiaso.net/notes/2025/amazon-crawler/">blog post</a> titled "a desperate cry for help." "I don't want to have to close off my Gitea server to the public, but I will if I have to."</p>
<p>Iaso's story highlights a broader crisis rapidly spreading across the open source community, as what appear to be aggressive AI crawlers increasingly overload community-maintained infrastructure, causing what amounts to persistent distributed denial-of-service (DDoS) attacks on vital public resources. According to a <a href="https://thelibre.news/foss-infrastructure-is-under-attack-by-ai-companies/">comprehensive recent report</a> from LibreNews, some open source projects now see as much as 97 percent of their traffic originating from AI companies' bots, dramatically increasing bandwidth costs, service instability, and burdening already stretched-thin maintainers.</p>
<p>Kevin Fenzi, a member of the Fedora Pagure project's sysadmin team, <a href="https://www.scrye.com/blogs/nirik/posts/2025/03/15/mid-march-infra-bits-2025/">reported on his blog</a> that the project had to block all traffic from Brazil after repeated attempts to mitigate bot traffic failed. GNOME GitLab implemented Iaso's "Anubis" system, requiring browsers to solve computational puzzles before accessing content. GNOME sysadmin Bart Piotrowski <a href="https://social.treehouse.systems/@barthalion/114190930216801561">shared</a> on Mastodon that only about 3.2 percent of requests (2,690 out of 84,056) passed their challenge system, suggesting the vast majority of traffic was automated. KDE's GitLab infrastructure was temporarily knocked offline by crawler traffic originating from Alibaba IP ranges, according to LibreNews, citing a KDE Development chat.</p>

          
                      
                  </div>
                    
        
          
    
    <div>
          
          
<p>While Anubis has proven effective at filtering out bot traffic, it comes with drawbacks for legitimate users. When many people access the same link simultaneously—such as when a GitLab link is shared in a chat room—site visitors can face significant delays. Some mobile users have reported waiting up to two minutes for the proof-of-work challenge to complete, according to the news outlet.</p>
<p>The situation isn't exactly new. In December, Dennis Schubert, who maintains infrastructure for the Diaspora social network, <a href="https://pod.geraspora.de/posts/17342163">described</a> the situation as "literally a DDoS on the entire internet" after discovering that AI companies accounted for 70 percent of all web requests to their services.</p>
<p>The costs are both technical and financial. The Read the Docs project reported that blocking AI crawlers immediately decreased their traffic by 75 percent, going from 800GB per day to 200GB per day. This change saved the project approximately $1,500 per month in bandwidth costs, according to their blog post "AI crawlers need to be more respectful."</p>
<h2>A disproportionate burden on open source</h2>
<p>The situation has created a tough challenge for open source projects, which rely on public collaboration and typically operate with limited resources compared to commercial entities. Many maintainers have reported that AI crawlers deliberately circumvent standard blocking measures, ignoring robots.txt directives, spoofing user agents, and rotating IP addresses to avoid detection.</p>
<p>As LibreNews reported, Martin Owens from the Inkscape project <a href="https://floss.social/@doctormo/114191332274003577">noted</a> on Mastodon that their problems weren't just from "the usual Chinese DDoS from last year, but from a pile of companies that started ignoring our spider conf and started spoofing their browser info." Owens added, "I now have a prodigious block list. If you happen to work for a big company doing AI, you may not get our website anymore."</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>On Hacker News, commenters in threads <a href="https://news.ycombinator.com/item?id=43422413">about the LibreNews</a> post last week and a <a href="https://news.ycombinator.com/item?id=42750420">post on Iaso's battles</a> in January expressed deep frustration with what they view as AI companies' predatory behavior toward open source infrastructure. While these comments come from forum posts rather than official statements, they represent a common sentiment among developers.</p>
<p>As one Hacker News user <a href="https://news.ycombinator.com/item?id=43422792">put it</a>, AI firms are operating from a position that "goodwill is irrelevant" with their "$100bn pile of capital." The discussions depict a battle between smaller AI startups that have worked collaboratively with affected projects and larger corporations that have been unresponsive despite allegedly forcing thousands of dollars in bandwidth costs on open source project maintainers.</p>
<p>Beyond consuming bandwidth, the crawlers often hit expensive endpoints, like git blame and log pages, placing additional strain on already limited resources. Drew DeVault, founder of SourceHut, <a href="https://drewdevault.com/2025/03/17/2025-03-17-Stop-externalizing-your-costs-on-me.html">reported on his blog</a> that the crawlers access "every page of every git log, and every commit in your repository," making the attacks particularly burdensome for code repositories.</p>
<p>The problem extends beyond infrastructure strain. As LibreNews points out, some open source projects began receiving AI-generated bug reports as early as December 2023, first <a href="https://daniel.haxx.se/blog/2024/01/02/the-i-in-llm-stands-for-intelligence/">reported</a> by Daniel Stenberg of the Curl project on his blog in a post from January 2024. These reports appear legitimate at first glance but contain fabricated vulnerabilities, wasting valuable developer time.</p>

<h2>Who is responsible, and why are they doing this?</h2>
<p>AI companies have a history of taking without asking. Before the mainstream breakout of AI image generators and ChatGPT attracted attention to the practice in 2022, the machine learning field regularly compiled datasets with little regard to ownership.</p>
<p>While many AI companies engage in web crawling, the sources suggest varying levels of responsibility and impact. Dennis Schubert's <a href="https://pod.geraspora.de/posts/17342163">analysis</a> of Diaspora's traffic logs showed that approximately one-fourth of its web traffic came from bots with an OpenAI user agent, while Amazon accounted for 15 percent and Anthropic for 4.3 percent.</p>

          
                  </div>
                    
        
          
    
    <div>
          
          
<p>The crawlers' behavior suggests different possible motivations. Some may be collecting training data to build or refine large language models, while others could be executing real-time searches when users ask AI assistants for information.</p>
<p>The frequency of these crawls is particularly telling. Schubert observed that AI crawlers "don't just crawl a page once and then move on. Oh, no, they come back every 6 hours because lol why not." This pattern suggests ongoing data collection rather than one-time training exercises, potentially indicating that companies are using these crawls to keep their models' knowledge current.</p>
<p>Some companies appear more aggressive than others. KDE's sysadmin team reported that crawlers from Alibaba IP ranges were responsible for temporarily knocking their GitLab offline. Meanwhile, Iaso's troubles came from Amazon's crawler. A member of KDE's sysadmin team told LibreNews that Western LLM operators like OpenAI and Anthropic were at least setting proper user agent strings (which theoretically allows websites to <a href="https://arstechnica.com/information-technology/2023/08/openai-details-how-to-keep-chatgpt-from-gobbling-up-website-data/">block them</a>), while some Chinese AI companies were reportedly more deceptive in their approaches.</p>
<p>It remains unclear why these companies don't adopt more collaborative approaches and, at a minimum, rate-limit their data harvesting runs so they don't overwhelm source websites. Amazon, OpenAI, Anthropic, and Meta did not immediately respond to requests for comment, but we will update this piece if they reply.</p>
<h2>Tarpits and labyrinths: The growing resistance</h2>
<p>In response to these attacks, new defensive tools have emerged to protect websites from unwanted AI crawlers. As Ars <a href="https://arstechnica.com/tech-policy/2025/01/ai-haters-build-tarpits-to-trap-and-trick-ai-scrapers-that-ignore-robots-txt/">reported in January</a>, an anonymous creator identified only as "Aaron" designed a tool called "Nepenthes" to trap crawlers in endless mazes of fake content. Aaron explicitly describes it as "aggressive malware" intended to waste AI companies' resources and potentially poison their training data.</p>

          
                  </div>
                    
        
          
    
    <div>

        
        <div>
          
          
<p>"Any time one of these crawlers pulls from my tarpit, it's resources they've consumed and will have to pay hard cash for," Aaron explained to Ars. "It effectively raises their costs. And seeing how none of them have turned a profit yet, that's a big problem for them."</p>
<p>On Friday, Cloudflare <a href="https://arstechnica.com/ai/2025/03/cloudflare-turns-ai-against-itself-with-endless-maze-of-irrelevant-facts/">announced</a> "AI Labyrinth," a similar but more commercially polished approach. Unlike Nepenthes, which is designed as an offensive weapon against AI companies, Cloudflare positions its tool as a legitimate security feature to protect website owners from unauthorized scraping, as we reported at the time.</p>
<p>"When we detect unauthorized crawling, rather than blocking the request, we will link to a series of AI-generated pages that are convincing enough to entice a crawler to traverse them," Cloudflare explained in its announcement. The company reported that AI crawlers generate over 50 billion requests to their network daily, accounting for nearly 1 percent of all web traffic they process.</p>
<p>The community is also developing collaborative tools to help protect against these crawlers. The "<a href="https://github.com/ai-robots-txt/ai.robots.txt">ai.robots.txt</a>" project offers an open list of web crawlers associated with AI companies and provides premade robots.txt files that implement the Robots Exclusion Protocol, as well as .htaccess files that return error pages when detecting AI crawler requests.</p>
<p>As it currently stands, both the rapid growth of AI-generated content <a href="https://www.404media.co/ai-slop-is-a-brute-force-attack-on-the-algorithms-that-control-reality/">overwhelming</a> online spaces and aggressive web-crawling practices by AI firms threaten the sustainability of essential online resources. The current approach taken by some large AI companies—<a href="https://www.vintagecomputing.com/index.php/archives/3292/the-pc-is-dead-its-time-to-make-computing-personal-again">extracting</a> vast amounts of data from open-source projects without clear consent or compensation—risks severely damaging the very digital ecosystem on which these AI models depend.</p>
<p>Responsible data collection may be achievable if AI firms collaborate directly with the affected communities. However, prominent industry players have shown little incentive to adopt more cooperative practices. Without meaningful regulation or self-restraint by AI firms, the arms race between data-hungry bots and those attempting to defend open source infrastructure seems likely to escalate further, potentially deepening the crisis for the digital ecosystem that underpins the modern Internet.</p>


          
                  </div>

                  
          






  <div>
  <div>
          <p><a href="https://arstechnica.com/author/benjedwards/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/08/benj_ega.png" alt="Photo of Benj Edwards"></a></p>
  </div>

  <div>
    

    <p>
      Benj Edwards is Ars Technica's Senior AI Reporter and founder of the site's dedicated AI beat in 2022. He's also a tech historian with almost two decades of experience. In his free time, he writes and records music, collects vintage computers, and enjoys nature. He lives in Raleigh, NC.
    </p>
  </div>
</div>


  <p>
    <a href="https://arstechnica.com/ai/2025/03/devs-say-ai-crawlers-dominate-traffic-forcing-blocks-on-entire-countries/#comments" title="50 comments">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 80"><defs><clipPath id="bubble-zero_svg__a"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath><clipPath id="bubble-zero_svg__b"><path fill="none" stroke-width="0" d="M0 0h80v80H0z"></path></clipPath></defs><g clip-path="url(#bubble-zero_svg__a)"><g fill="currentColor" clip-path="url(#bubble-zero_svg__b)"><path d="M80 40c0 22.09-17.91 40-40 40S0 62.09 0 40 17.91 0 40 0s40 17.91 40 40"></path><path d="M40 40 .59 76.58C-.67 77.84.22 80 2.01 80H40z"></path></g></g></svg>
    50 Comments
  </a>
      </p>
              </div>
  </article>


  


  


  <div>
    <header>
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 26"><defs><clipPath id="most-read_svg__a"><path fill="none" d="M0 0h40v26H0z"></path></clipPath><clipPath id="most-read_svg__b"><path fill="none" d="M0 0h40v26H0z"></path></clipPath></defs><g clip-path="url(#most-read_svg__a)"><g fill="none" clip-path="url(#most-read_svg__b)"><path fill="currentColor" d="M20 2h.8q1.5 0 3 .6c.6.2 1.1.4 1.7.6 1.3.5 2.6 1.3 3.9 2.1.6.4 1.2.8 1.8 1.3 2.9 2.3 5.1 4.9 6.3 6.4-1.1 1.5-3.4 4-6.3 6.4-.6.5-1.2.9-1.8 1.3q-1.95 1.35-3.9 2.1c-.6.2-1.1.4-1.7.6q-1.5.45-3 .6h-1.6q-1.5 0-3-.6c-.6-.2-1.1-.4-1.7-.6-1.3-.5-2.6-1.3-3.9-2.1-.6-.4-1.2-.8-1.8-1.3-2.9-2.3-5.1-4.9-6.3-6.4 1.1-1.5 3.4-4 6.3-6.4.6-.5 1.2-.9 1.8-1.3q1.95-1.35 3.9-2.1c.6-.2 1.1-.4 1.7-.6q1.5-.45 3-.6zm0-2h-1c-1.2 0-2.3.3-3.4.6-.6.2-1.3.4-1.9.7-1.5.6-2.9 1.4-4.3 2.3-.7.5-1.3.9-1.9 1.4C2.9 8.7 0 13 0 13s2.9 4.3 7.5 7.9c.6.5 1.3 1 1.9 1.4 1.3.9 2.7 1.7 4.3 2.3.6.3 1.3.5 1.9.7 1.1.3 2.3.6 3.4.6h2c1.2 0 2.3-.3 3.4-.6.6-.2 1.3-.4 1.9-.7 1.5-.6 2.9-1.4 4.3-2.3.7-.5 1.3-.9 1.9-1.4C37.1 17.3 40 13 40 13s-2.9-4.3-7.5-7.9c-.6-.5-1.3-1-1.9-1.4-1.3-.9-2.8-1.7-4.3-2.3-.6-.3-1.3-.5-1.9-.7C23.3.4 22.1.1 21 .1h-1"></path><path fill="#ff4e00" d="M20 5c-4.4 0-8 3.6-8 8s3.6 8 8 8 8-3.6 8-8-3.6-8-8-8m0 11c-1.7 0-3-1.3-3-3s1.3-3 3-3 3 1.3 3 3-1.3 3-3 3"></path></g></g></svg>
      
    </header>
    <ol>
              <li>
                      <a href="https://arstechnica.com/space/2025/03/as-preps-continue-its-looking-more-likely-nasa-will-fly-the-artemis-ii-mission/">
              <img src="https://cdn.arstechnica.net/wp-content/uploads/2025/03/KSC-20250323-PH-FMX01_0159orig-copy-768x432.jpg" alt="Listing image for first story in Most Read: As preps continue, it’s looking more likely that NASA will fly the Artemis II mission" decoding="async" loading="lazy">
            </a>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                    <li>
                    
        </li>
                  </ol>
</div>


  

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sell yourself, sell your work (391 pts)]]></title>
            <link>https://www.solipsys.co.uk/new/SellYourselfSellYourWork.html?yc25hn</link>
            <guid>43476249</guid>
            <pubDate>Tue, 25 Mar 2025 21:35:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.solipsys.co.uk/new/SellYourselfSellYourWork.html?yc25hn">https://www.solipsys.co.uk/new/SellYourselfSellYourWork.html?yc25hn</a>, See on <a href="https://news.ycombinator.com/item?id=43476249">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<h2>Sell yourself, Sell Your Work ...</h2>
<a name="toc_name000"></a>

Doing technically brilliant work may be enough for your
personal
gratification, but you should never think it's enough. If you lock
yourself in a room and do the most marvellous work but don't tell
anyone, then no one will know, no one will benefit, and the work
will be lost. You may have derived
personal satisfaction from it,
but as far as the wider world is concerned, you may as well not have
bothered. For the world to benefit from your work, and therefore for
you to benefit <b>fully</b> from your work, you have to make it known.
<p>
In short, you have to "advertise".
</p><p>
I've dealt with any number of technically brilliant people who produce
outstanding work. The majority of them never bothered to write down
their work and communicate it to others - report writing is too boring,
uninteresting, and hard. And irrelevant. Or so they thought.
</p><p>
But if you've done great work, if you've produced superb
software or
fixed a fault with an aeroplane or investigated a problem ... without
telling anyone, your work is wasted. You have to write, you have to
tell people, and you have to do so in a way that they will take notice.
</p><p>
You don't necessarily need to make it flashy, whizzy, colourful and
animated, but you do have to present it well. Spelling errors may
not obscure the meaning, but you will lose some of your audience.
Poor punctuation may not matter to you, but your intended audience
may be put off by it. Muddied writing with no clear purpose makes it
hard for the reader to understand your point.
</p><p>
Write clearly and concisely, however, and your work may well save
others' time and effort. And gain you reputation.
</p><p>
<div>

Richard W Hamming wrote about one's work:
<p>
...
you can either do it in such a fashion that people
can indeed build on what you've done, or you can do
it in such a fashion that the next person has to
essentially duplicate again what you've done ...
</p><p>
...
it is not sufficient to do a job, you have to sell
it. "Selling" to a scientist is an awkward thing to do.
It's very ugly; you shouldn't have to do it. The world
is supposed to be waiting, and when you do something
great, they should rush out and welcome it. But the
fact is everyone is busy with their own work. You must
present it so well that they will set aside what they
are doing, look at what you've done, read it, and come
back and say, "Yes, that was good."
</p><p>
...  ask why you read some articles and not others.
You had better write your report so when it is published
... as the readers are turning the pages they won't
just turn your pages but they will stop and read yours.
If they don't stop and read it, you won't get credit.
</p><p>
You have to learn to write clearly and well so that
people will read it, you must learn to give reasonably
formal talks, and you also must learn to give informal
talks.
</p><p>
From "You and Your Research".
</p><hr>

For reference, some of Hamming's work includes Hamming codes,
the Hamming matrix, the Hamming window, Hamming numbers,
the Hamming bound, and the Hamming distance.
<p>
<a href="https://en.wikipedia.org/wiki/Richard_Hamming">https://en.wikipedia.org/wiki/Richard_Hamming</a>
</p></div> 
It seems crazy to require that technically talented people should
be forced to spend time doing something - report writing - at which
they're not gifted, but how else can the world benefit from their
brilliance? Without communicating their ideas, their work is lost
and might never have been.
</p><p>
Of course, this is one of the benefits of being an entrepreneur or
the founder of a business. The benefits of your work are there to
be seen - you don't have to play the office politics of constantly
justifying your existence. If you don't have customers, or if you
don't have advertisers, then you won't survive. If you do have
customers, or you do have advertisers, then your existence is
justified by the work you've done.
</p><p>
But you still have to sell! You now have to sell your company's
product or service, you now have to get known so that people will
start to use your product or service, or people will constantly
visit your website, which then attracts advertising. Whatever,
you need to sell! A company lives and dies by what it sells.
</p><p>
Some people say that the sole purpose of a company is to make money.
Others are more idealistic and say that it's to make the world better,
or to make their employees' lives better, or some other goal. But
without making money, everything else is moot.
</p><p>
But the word "sell" doesn't necessarily mean what you think it means.
Richard W. Hamming wrote about this in his talk entitled "You and Your Research",
given as a Bell Communications Research Colloquium Seminar on 1986/03/07.
The side-box is a small excerpt from this talk, transcriptions of which
can easily be found on-line.
</p><p>
So let the world benefit from your work.
</p><hr>

<center>

<hr>

<center></center>
<hr>

<h2>Send us a comment ...</h2>
<a name="toc_name001"></a>


</center></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[In Jail Without a Lawyer: How a Texas Town Fails Poor Defendants (302 pts)]]></title>
            <link>https://www.nytimes.com/2025/03/25/us/maverick-county-texas-court-system.html</link>
            <guid>43474593</guid>
            <pubDate>Tue, 25 Mar 2025 18:59:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2025/03/25/us/maverick-county-texas-court-system.html">https://www.nytimes.com/2025/03/25/us/maverick-county-texas-court-system.html</a>, See on <a href="https://news.ycombinator.com/item?id=43474593">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2025/03/25/us/maverick-county-texas-court-system.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The highest-ranking personal blogs of Hacker News (400 pts)]]></title>
            <link>https://refactoringenglish.com/tools/hn-popularity/</link>
            <guid>43474505</guid>
            <pubDate>Tue, 25 Mar 2025 18:48:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://refactoringenglish.com/tools/hn-popularity/">https://refactoringenglish.com/tools/hn-popularity/</a>, See on <a href="https://news.ycombinator.com/item?id=43474505">Hacker News</a></p>
<div id="readability-page-1" class="page"><section><div><h4>The highest-ranking personal blogs of Hacker News
<a href="https://refactoringenglish.com/tools/hn-popularity/methodology">[<i></i> Methodology]</a></h4><div><p><label for="time-choose">Dates:</label>
</p><p><label for="start-date">Start:</label>
</p><p><label for="end-date">End:</label>
</p></div></div><main><div><table id="resultsTable"><thead><tr><th>Rank</th><th>Domain</th><th>Total Score</th><th>Author</th><th>Bio</th><th>Topics</th><th>Submissions</th></tr></thead><tbody></tbody></table></div><p><label for="result-limit">Limit:</label>
</p></main><div><p><a href="https://github.com/mtlynch/hn-popularity-contest-data"><i></i> Corrections</a></p></div></section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[4o Image Generation (974 pts)]]></title>
            <link>https://openai.com/index/introducing-4o-image-generation/</link>
            <guid>43474112</guid>
            <pubDate>Tue, 25 Mar 2025 18:06:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/introducing-4o-image-generation/">https://openai.com/index/introducing-4o-image-generation/</a>, See on <a href="https://news.ycombinator.com/item?id=43474112">Hacker News</a></p>
Couldn't get https://openai.com/index/introducing-4o-image-generation/: Error: Request failed with status code 403]]></description>
        </item>
    </channel>
</rss>