<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 09 Nov 2024 17:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Scientist treated her own cancer with viruses she grew in the lab (117 pts)]]></title>
            <link>https://www.nature.com/articles/d41586-024-03647-0</link>
            <guid>42094573</guid>
            <pubDate>Sat, 09 Nov 2024 14:23:30 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/d41586-024-03647-0">https://www.nature.com/articles/d41586-024-03647-0</a>, See on <a href="https://news.ycombinator.com/item?id=42094573">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    
                        <figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Coloured transmission electron micrograph of cultured measles virus particles." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713234.jpg"><figcaption><p><span>Viruses such as measles (pictured here) can be used to attack cancerous cells. </span><span>Credit: Eye Of Science/Science Photo Library</span></p></figcaption></picture></figure><p>A scientist who successfully treated her own <a href="https://www.nature.com/subjects/breast-cancer" data-track="click" data-label="https://www.nature.com/subjects/breast-cancer" data-track-category="body text link">breast cancer</a> by injecting the tumour with lab-grown viruses has sparked discussion about the ethics of self-experimentation. </p><p>Beata Halassy discovered in 2020, aged 49, that she had breast cancer at the site of a previous mastectomy. It was the second recurrence there since her left breast had been removed, and she couldn’t face another bout of chemotherapy. </p><p>Halassy, a virologist at the University of Zagreb, studied the literature and decided to take matters into her own hands with an unproven treatment. </p><p>A case report published in <i>Vaccines</i> in August<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup> outlines how Halassy self-administered a treatment called <a href="https://www.nature.com/articles/s41571-022-00719-w" data-track="click" data-label="https://www.nature.com/articles/s41571-022-00719-w" data-track-category="body text link">oncolytic virotherapy</a> (OVT) to help treat her own stage 3 cancer. She has now been cancer-free for four years. </p><p>In choosing to <a href="https://www.nature.com/articles/nm0508-471b" data-track="click" data-label="https://www.nature.com/articles/nm0508-471b" data-track-category="body text link">self-experiment</a>, Halassy joins a long line of scientists who have participated in this under-the-radar, stigmatized and ethically fraught practice. “It took a brave editor to publish the report,” says Halassy.</p><h2>Up-and-coming therapy</h2><p>OVT is an emerging field of <a href="https://www.nature.com/subjects/cancer-therapy" data-track="click" data-label="https://www.nature.com/subjects/cancer-therapy" data-track-category="body text link">cancer treatment</a> that uses viruses to both attack cancerous cells and provoke the immune system into fighting them. Most OVT clinical trials so far have been in late-stage, metastatic cancer, but in the past few years they have been directed towards earlier-stage disease. One OVT, called T-VEC, has been in approved in the United States to treat metastatic melanoma, but there are as yet no OVT agents approved to treat breast cancer of any stage, anywhere in the world. </p><p>Halassy stresses that she isn’t a specialist in OVT, but her expertise in cultivating and purifying viruses in the laboratory gave her the confidence to try the treatment. She chose to target her tumour with two different viruses consecutively — a <a href="https://www.nature.com/subjects/measles-virus" data-track="click" data-label="https://www.nature.com/subjects/measles-virus" data-track-category="body text link">measles virus</a> followed by a vesicular stomatitis virus (VSV). Both pathogens are known to infect the type of cell from which her tumour originated, and have already been used in OVT clinical trials. A measles virus has been trialled against metastatic breast cancer.</p><p>Halassy had previous experience working with both viruses, and both have a good safety record. The strain of measles she chose is used extensively in childhood vaccines, and the strain of VSV induces, at worst, mild influenza-like symptoms. </p><figure><picture><source type="image/webp" srcset="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 767w, https://media.nature.com/lw319/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"><img alt="Portrait of Beata Halassy." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27713236.jpg"><figcaption><p><span>Halassy’s experience with self-treatment has changed the focus of her research. </span><span>Credit: Ivanka Popić </span></p></figcaption></picture></figure><p>Over a two-month period, a colleague administered a regime of treatments with research-grade material freshly prepared by Halassy, injected directly into her tumour. Her oncologists agreed to monitor her during the self-treatment, so that she would be able to switch to conventional chemotherapy if things went wrong.</p><p>The approach seemed to be effective: over the course of the treatment, and with no serious side effects, the tumour shrank substantially and became softer. It also detached from the pectoral muscle and skin that it had been invading, making it easy to remove surgically.</p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-024-02613-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_27470032.jpg"><p>How a trove of cancer genomes could improve kids’ leukaemia treatment</p></a></article><p>Analysis of the tumour after removal showed that it was thoroughly infiltrated with immune cells called lymphocytes, suggesting that the OVT had worked as expected and provoked Halassy’s immune system to attack both the viruses and the tumour cells. “An immune response was, for sure, elicited,” says Halassy. After the surgery, she received a year’s treatment with the anticancer drug trastuzumab. </p><p>Stephen Russell, an OVT specialist who runs virotherapy biotech company Vyriad in Rochester, Minnesota, agrees that Halassy’s case suggests the viral injections worked to shrink her tumour and cause its invasive edges to recede. </p><p>But he doesn’t think her experience really breaks any new ground, because researchers are already trying to use OVT to help treat earlier-stage cancer. He isn’t aware of anyone trying two viruses sequentially, but says it isn’t possible to deduce whether this mattered in an ‘<i>n</i> of 1’ study. “Really, the novelty here is, she did it to herself with a virus that she grew in her own lab,” he says.</p><h2>Ethical dilemma</h2><p>Halassy felt a responsibility to publish her findings. But she received more than a dozen rejections from journals — mainly, she says, because the paper, co-authored with colleagues, involved self-experimentation. “The major concern was always ethical issues,” says Halassy. She was particularly determined to persevere after she came across a review highlighting the value of self-experimentation<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. </p><p>That journals had concerns doesn’t surprise Jacob Sherkow, a law and medicine researcher at the University of Illinois Urbana-Champaign who has examined the ethics of researcher self-experimentation in relation to COVID-19 vaccines. </p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-023-02075-w" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-024-03647-0/d41586-024-03647-0_26019860.jpg"><p>Huge leap in breast cancer survival rate</p></a></article><p>The problem is not that Halassy used self-experimentation as such, but that publishing her results could encourage others to reject conventional treatment and try something similar, says Sherkow. People with cancer can be particularly susceptible to trying unproven treatments. Yet, he notes, it’s also important to ensure that the knowledge that comes from self-experimentation isn’t lost. The paper emphasizes that self-medicating with cancer-fighting viruses “should not be the first approach” in the case of a cancer diagnosis. </p><p>“I think it ultimately does fall within the line of being ethical, but it isn’t a slam-dunk case,” says Sherkow, adding that he would have liked to see a commentary fleshing out the ethics perspective, published alongside the case report.</p><p>Halassy has no regrets about self-treating, or her dogged pursuit of publication. She thinks it is unlikely that someone would try to copy her, because the treatment requires so much scientific knowledge and skill. And the experience has given her own research a new direction: in September she got funding to investigate OVT to treat cancer in domestic animals. “The focus of my laboratory has completely turned because of the positive experience with my self-treatment,” she says.</p>
                    
                </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I Analyzed 650k TikTok Influencers and This Is What I Found (291 pts)]]></title>
            <link>https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</link>
            <guid>42093911</guid>
            <pubDate>Sat, 09 Nov 2024 11:49:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/">https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/</a>, See on <a href="https://news.ycombinator.com/item?id=42093911">Hacker News</a></p>
Couldn't get https://old.reddit.com/r/eCommerceSEO/comments/1gn8egy/ultimate_ecommerce_marketing_tool_influencers/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Mergiraf: a syntax-aware merge driver for Git (223 pts)]]></title>
            <link>https://mergiraf.org/</link>
            <guid>42093756</guid>
            <pubDate>Sat, 09 Nov 2024 11:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mergiraf.org/">https://mergiraf.org/</a>, See on <a href="https://news.ycombinator.com/item?id=42093756">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="page-wrapper">

            <div id="content" class="page">
                    <main>
                        <p><em>Are you held back by conflicts? Then meet</em></p>

<p>Mergiraf can solve <a href="https://mergiraf.org/conflicts.html">a wide range of Git merge conflicts</a>. That's because it's aware of the trees in your files!
Thanks to <a href="https://mergiraf.org/languages.html">its understanding of your language</a>, it can often reconcile the needs of both sides.</p>
<p>You can <a href="https://mergiraf.org/adding-a-language.html">teach Mergiraf a new language</a> in a completely declarative way. It's a nonviolent animal, so it prefers that over imperatives.</p>
<h2 id="demo">Demo</h2>
<p>Configure Git to use Mergiraf instead of its default merge heuristics. This will enhance <code>git merge</code>, <code>revert</code>, <code>rebase</code>, <code>cherry-pick</code> and more.</p>


<p>You can also keep Git's original behaviour and manually invoke Mergiraf after encountering conflicts.</p>


<div>
<p><img src="https://mergiraf.org/img/scene_1.png" alt="A giraffe observes a fighting pair"></p><p><strong>Figure 1:</strong> Two git users making inadequate use of <code>blame</code>, <code>push</code> and <code>pull</code> to resolve a conflict</p>
</div>
<h2 id="ready-to-give-it-a-try"><a href="#ready-to-give-it-a-try">Ready to give it a try?</a></h2>
<p>Head to the <a href="https://mergiraf.org/installation.html">installation</a> page and start merging nonviolently today!</p>
<h2 id="aspirations"><a href="#aspirations">Aspirations</a></h2>
<p>Mergiraf is designed with your needs in mind. Its goals are:</p>
<h3 id="dont-sweep-conflicts-under-the-rug"><a href="#dont-sweep-conflicts-under-the-rug">Don't sweep conflicts under the rug</a></h3>
<p>Syntax-aware merging heuristics can sometimes be a bit too optimistic in considering a conflict resolved. Mergiraf does its best to err on the side of caution and retain conflict markers in the file when encountering suspicious cases.</p>
<p>If it manages to resolve all conflicts on its own, it encourages you to review its mediation work via the <code>mergiraf review</code> command.
If a merge looks faulty, <a href="https://mergiraf.org/usage.html#reporting-a-bad-merge">you can report it easily</a>.</p>
<h3 id="be-fast-enough-for-interactive-use"><a href="#be-fast-enough-for-interactive-use">Be fast enough for interactive use</a></h3>
<div>
<p><img src="https://mergiraf.org/img/scene_2.png" alt="The giraffe surrounds the pair with its neck and they are surprised by its intervention"></p><p><strong>Figure 2:</strong> Mergiraf offers to mediate</p>
</div>
<p>Did you know that giraffes can run as fast as 60 kilometers per hour? Anyways. The operation of merging diverging versions of files happens routinely when working on a code base, often without you noticing as long as there aren't any conflicts. So Mergiraf tries to be quick so as not to interrupt you in your tasks.</p>
<h3 id="be-open-to-other-methods"><a href="#be-open-to-other-methods">Be open to other methods</a></h3>
<p>In many cases, line-based merging works just great and there is no need for tree-munging business. If a line-based merge is conflict-free, then Mergiraf just returns that merge (which is very quick).
One exception to this rule is <a href="https://mergiraf.org/conflicts.html#line-based-merges">when line-based merging creates duplicate keys</a>. In such a case, Mergiraf does a bit more work to resolve the issue or highlight it to you with conflict markers.</p>


                    </main>

                    <nav aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->

                            <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i></i>
                            </a>

                        
                    </nav>
                </div>

            <nav aria-label="Page navigation">

                    <a rel="next prefetch" href="https://mergiraf.org/installation.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i></i>
                    </a>
            </nav>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: HTML-to-Markdown – convert entire websites to Markdown with Golang/CLI (149 pts)]]></title>
            <link>https://github.com/JohannesKaufmann/html-to-markdown</link>
            <guid>42093511</guid>
            <pubDate>Sat, 09 Nov 2024 09:48:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/JohannesKaufmann/html-to-markdown">https://github.com/JohannesKaufmann/html-to-markdown</a>, See on <a href="https://news.ycombinator.com/item?id=42093511">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">html-to-markdown</h2><a id="user-content-html-to-markdown" aria-label="Permalink: html-to-markdown" href="#html-to-markdown"></a></p>
<p dir="auto">A robust html-to-markdown converter that transforms HTML (even entire websites) into clean, readable Markdown. It supports complex formatting, customizable options, and plugins for full control over the conversion process.</p>
<p dir="auto">Use the fully extendable <a href="#golang-library">Golang library</a> or a quick <a href="#cli---using-it-on-the-command-line">CLI command</a>. Alternatively, try the <a href="https://html-to-markdown.com/demo" rel="nofollow">Online Demo</a> or <a href="https://html-to-markdown.com/api" rel="nofollow">REST API</a> to see it in action!</p>
<p dir="auto">Here are some <em>cool features</em>:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Bold &amp; Italic:</strong> Supports bold and italic—even within single words.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_bold_italic.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_bold_italic.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>List:</strong> Handles ordered and unordered lists with full nesting support.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_list.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_list.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Blockquote:</strong> Blockquotes can include other elements, with seamless support for nested quotes.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_blockquote.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_blockquote.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Inline Code &amp; Code Block:</strong> Correctly handles backticks and multi-line code blocks, preserving code structure.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_code.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_code.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Link &amp; Image:</strong> Properly formats multi-line links, adding escapes for blank lines where needed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_link_image.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_link_image.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Smart Escaping:</strong> Escapes special characters only when necessary, to avoid accidental Markdown rendering.
🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_escaping.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_escaping.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Remove/Keep HTML:</strong> Choose to strip or retain specific HTML tags for ultimate control over output.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_wrapper.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_wrapper.png" alt=""></a></p>
</li>
<li>
<p dir="auto"><strong>Plugins:</strong> Easily extend with plugins. Or create custom ones to enhance functionality.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/point_strikethrough.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/point_strikethrough.png" alt=""></a></p>
</li>
</ul>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">Golang Library</h2><a id="user-content-golang-library" aria-label="Permalink: Golang Library" href="#golang-library"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="go get -u github.com/JohannesKaufmann/html-to-markdown/v2"><pre>go get -u github.com/JohannesKaufmann/html-to-markdown/v2</pre></div>
<p dir="auto"><em>Or if you want a specific commit add the suffix <code>/v2@commithash</code></em></p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">This is the documentation for the v2 library. For the old version switch to the <a href="https://github.com/JohannesKaufmann/html-to-markdown/tree/v1">"v1" branch</a>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/JohannesKaufmann/html-to-markdown/v2" rel="nofollow"><img src="https://camo.githubusercontent.com/4de9ed495aaf54b8396c04b85bc3edb47d7736aab876b29756705763dc8d1ec1/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f4a6f68616e6e65734b6175666d616e6e2f68746d6c2d746f2d6d61726b646f776e2f76322e737667" alt="Go V2 Reference" data-canonical-src="https://pkg.go.dev/badge/github.com/JohannesKaufmann/html-to-markdown/v2.svg"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	htmltomarkdown &quot;github.com/JohannesKaufmann/html-to-markdown/v2&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	markdown, err := htmltomarkdown.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: **Bold Text**
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	htmltomarkdown <span>"github.com/JohannesKaufmann/html-to-markdown/v2"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>htmltomarkdown</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: **Bold Text**</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/basics/main.go">Example code, basics</a></li>
</ul>
<p dir="auto">The function <code>htmltomarkdown.ConvertString()</code> is a <em>small wrapper</em> around <code>converter.NewConverter()</code> and the <em>base</em> and <em>commonmark</em> plugins. If you want more control, use the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
	&quot;fmt&quot;
	&quot;log&quot;

	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/converter&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base&quot;
	&quot;github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark&quot;
)

func main() {
	input := `<strong>Bold Text</strong>`

	conv := converter.NewConverter(
		converter.WithPlugins(
			base.NewBasePlugin(),
			commonmark.NewCommonmarkPlugin(
				commonmark.WithStrongDelimiter(&quot;__&quot;),
				// ...additional configurations for the plugin
			),
		),
	)

	markdown, err := conv.ConvertString(input)
	if err != nil {
		log.Fatal(err)
	}
	fmt.Println(markdown)
	// Output: __Bold Text__
}"><pre><span>package</span> main

<span>import</span> (
	<span>"fmt"</span>
	<span>"log"</span>

	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/converter"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/base"</span>
	<span>"github.com/JohannesKaufmann/html-to-markdown/v2/plugin/commonmark"</span>
)

<span>func</span> <span>main</span>() {
	<span>input</span> <span>:=</span> <span>`&lt;strong&gt;Bold Text&lt;/strong&gt;`</span>

	<span>conv</span> <span>:=</span> <span>converter</span>.<span>NewConverter</span>(
		<span>converter</span>.<span>WithPlugins</span>(
			<span>base</span>.<span>NewBasePlugin</span>(),
			<span>commonmark</span>.<span>NewCommonmarkPlugin</span>(
				<span>commonmark</span>.<span>WithStrongDelimiter</span>(<span>"__"</span>),
				<span>// ...additional configurations for the plugin</span>
			),
		),
	)

	<span>markdown</span>, <span>err</span> <span>:=</span> <span>conv</span>.<span>ConvertString</span>(<span>input</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>log</span>.<span>Fatal</span>(<span>err</span>)
	}
	<span>fmt</span>.<span>Println</span>(<span>markdown</span>)
	<span>// Output: __Bold Text__</span>
}</pre></div>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/options/main.go">Example code, options</a></li>
</ul>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">If you use <code>NewConverter</code> directly make sure to also <strong>register the commonmark and base plugin</strong>.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Plugins</h3><a id="user-content-plugins" aria-label="Permalink: Plugins" href="#plugins"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Published Plugins</h4><a id="user-content-published-plugins" aria-label="Permalink: Published Plugins" href="#published-plugins"></a></p>
<p dir="auto">These are the plugins located in the <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/plugin">plugin folder</a>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Base</td>
<td>Implements basic shared functionality (e.g. removing nodes)</td>
</tr>
<tr>
<td>Commonmark</td>
<td>Implements Markdown according to the <a href="https://spec.commonmark.org/" rel="nofollow">Commonmark Spec</a></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>GitHubFlavored</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>TaskListItems</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>Strikethrough</td>
<td>Converts <code>&lt;strike&gt;</code>, <code>&lt;s&gt;</code>, and <code>&lt;del&gt;</code> to the <code>~~</code> syntax.</td>
</tr>
<tr>
<td>Table</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>VimeoEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>YoutubeEmbed</td>
<td><em>planned</em></td>
</tr>
<tr>
<td></td>
<td></td>
</tr>
<tr>
<td>ConfluenceCodeBlock</td>
<td><em>planned</em></td>
</tr>
<tr>
<td>ConfluenceAttachments</td>
<td><em>planned</em></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Not all the plugins from v1 are already ported to v2. These will soon be implemented...</p>
</div>
<p dir="auto">These are the plugins in other repositories:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>[Plugin Name](Your Link)</td>
<td>A short description</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><h4 tabindex="-1" dir="auto">Writing Plugins</h4><a id="user-content-writing-plugins" aria-label="Permalink: Writing Plugins" href="#writing-plugins"></a></p>
<p dir="auto">You want to write custom logic?</p>
<ol dir="auto">
<li>
<p dir="auto">Write your logic and <strong>register</strong> it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/.github/images/autocomplete_register.png"><img src="https://github.com/JohannesKaufmann/html-to-markdown/raw/main/.github/images/autocomplete_register.png" alt=""></a></p>
<ul dir="auto">
<li>🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></li>
</ul>
</li>
<li>
<p dir="auto"><em>Optional:</em> Package your logic into a <strong>plugin</strong> and publish it.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ol>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">CLI - Using it on the command line</h2><a id="user-content-cli---using-it-on-the-command-line" aria-label="Permalink: CLI - Using it on the command line" href="#cli---using-it-on-the-command-line"></a></p>
<p dir="auto">Using the Golang library provides the most customization, while the CLI is the simplest way to get started.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation-1" aria-label="Permalink: Installation" href="#installation-1"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Homebrew Tap</h4><a id="user-content-homebrew-tap" aria-label="Permalink: Homebrew Tap" href="#homebrew-tap"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="brew install JohannesKaufmann/tap/html2markdown"><pre>brew install JohannesKaufmann/tap/html2markdown</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Manually</h4><a id="user-content-manually" aria-label="Permalink: Manually" href="#manually"></a></p>
<p dir="auto">Download the pre-compiled binaries from the <a href="https://github.com/JohannesKaufmann/html-to-markdown/releases">releases page</a> and copy them to the desired location.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Version</h3><a id="user-content-version" aria-label="Permalink: Version" href="#version"></a></p>

<div dir="auto"><p dir="auto">Note</p><p dir="auto">Make sure that <code>--version</code> prints <code>2.X.X</code> as there is a different CLI for V2 of the converter.</p>
</div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Usage</h3><a id="user-content-usage-1" aria-label="Permalink: Usage" href="#usage-1"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="$ echo &quot;<strong>important</strong>&quot; | html2markdown

**important**"><pre>$ <span>echo</span> <span><span>"</span>&lt;strong&gt;important&lt;/strong&gt;<span>"</span></span> <span>|</span> html2markdown

<span>**</span>important<span>**</span></pre></div>
<div data-snippet-clipboard-copy-content="$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)"><pre lang="text"><code>$ curl --no-progress-meter http://example.com | html2markdown

# Example Domain

This domain is for use in illustrative examples in documents. You may use this domain in literature without prior coordination or asking for permission.

[More information...](https://www.iana.org/domains/example)
</code></pre></div>
<p dir="auto"><em>(The cli does not support every option yet. Over time more customization will be added)</em></p>
<hr>
<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Extending with Plugins</h3><a id="user-content-extending-with-plugins" aria-label="Permalink: Extending with Plugins" href="#extending-with-plugins"></a></p>
<ul dir="auto">
<li>
<p dir="auto">Need your own logic? Write your own code and then <strong>register</strong> it.</p>
<ul dir="auto">
<li>
<p dir="auto">Don't like the <strong>defaults</strong> that the library uses? You can use <code>PriorityEarly</code> to run you logic <em>earlier</em> than others.</p>
</li>
<li>
<p dir="auto">🧑‍💻 <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/examples/register/main.go">Example code, register</a></p>
</li>
</ul>
</li>
<li>
<p dir="auto">If you believe that you logic could also benefit others, you can package it up into a <strong>plugin</strong>.</p>
<ul dir="auto">
<li>🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/WRITING_PLUGINS.md">WRITING_PLUGINS.md</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Bugs</h3><a id="user-content-bugs" aria-label="Permalink: Bugs" href="#bugs"></a></p>
<p dir="auto">You found a bug?</p>
<p dir="auto"><a href="https://github.com/JohannesKaufmann/html-to-markdown/issues/new/choose">Open an issue</a> with the HTML snippet that does not produce the expected results. Please, please, plase <em>submit the HTML snippet</em> that caused the problem. Otherwise it is very difficult to reproduce and fix...</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Security</h3><a id="user-content-security" aria-label="Permalink: Security" href="#security"></a></p>
<p dir="auto">This library produces markdown that is readable and can be changed by humans.</p>
<p dir="auto">Once you convert this markdown back to HTML (e.g. using <a href="https://github.com/yuin/goldmark">goldmark</a> or <a href="https://github.com/russross/blackfriday">blackfriday</a>) you need to be careful of malicious content.</p>
<p dir="auto">This library does NOT sanitize untrusted content. Use an HTML sanitizer such as <a href="https://github.com/microcosm-cc/bluemonday">bluemonday</a> before displaying the HTML in the browser.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/SECURITY.md">SECURITY.md</a> if you find a security vulnerability</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Goroutines</h3><a id="user-content-goroutines" aria-label="Permalink: Goroutines" href="#goroutines"></a></p>
<p dir="auto">You can use the <code>Converter</code> from (multiple) goroutines. Internally a mutex is used &amp; there is a test to verify that behaviour.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Escaping &amp; Backslash</h3><a id="user-content-escaping--backslash" aria-label="Permalink: Escaping &amp; Backslash" href="#escaping--backslash"></a></p>
<p dir="auto">Some characters have a special meaning in markdown (e.g. "*" for emphasis). The backslash <code>\</code> character is used to "escape" those characters. That is perfectly safe and won't be displayed in the final render.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/ESCAPING.md">ESCAPING.md</a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributing</h3><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">You want to contribute? Thats great to hear! There are many ways to help:</p>
<p dir="auto">Helping to answer questions, triaging issues, writing documentation, writing code, ...</p>
<p dir="auto">If you want to make a code change: Please first discuss the change you wish to make, by opening an issue. I'm also happy to guide you to where a change is most likely needed. There are also extensive tests (see below) so you can freely experiment 🧑‍🔬</p>
<p dir="auto"><em>Note: The outside API should not change because of backwards compatibility...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Testing</h3><a id="user-content-testing" aria-label="Permalink: Testing" href="#testing"></a></p>
<p dir="auto">You don't have to be afraid of breaking the converter, since there are many "Golden File" tests:</p>
<p dir="auto">Add your problematic HTML snippet to one of the <code>.in.html</code> files in the <code>testdata</code> folders. Then run <code>go test -update</code> and have a look at which <code>.out.md</code> files changed in GIT.</p>
<p dir="auto">You can now change the internal logic and inspect what impact your change has by running <code>go test -update</code> again.</p>
<p dir="auto"><em>Note: Before submitting your change as a PR, make sure that you run those tests and check the files into GIT...</em></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Unless otherwise specified, the project is licensed under the terms of the MIT license.</p>
<p dir="auto">🗒️ <a href="https://github.com/JohannesKaufmann/html-to-markdown/blob/main/LICENSE">LICENSE</a></p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[SVDQuant: 4-Bit Quantization Powers 12B Flux on a 16GB 4090 GPU with 3x Speedup (116 pts)]]></title>
            <link>https://hanlab.mit.edu/blog/svdquant</link>
            <guid>42093112</guid>
            <pubDate>Sat, 09 Nov 2024 07:46:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hanlab.mit.edu/blog/svdquant">https://hanlab.mit.edu/blog/svdquant</a>, See on <a href="https://news.ycombinator.com/item?id=42093112">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Muyang Li*, Yujun Lin*, Zhekai Zhang*, Tianle Cai, Xiuyu Li, Junxian Guo, Enze Xie, Chenlin Meng, Jun-Yan Zhu, Song Han</p><p>November 7, 2024</p></div><p>A new post-training training quantization paradigm for diffusion models, which quantize both the weights and activations of FLUX.1 to 4 bits, achieving 3.5× memory and 8.7× latency reduction on a 16GB laptop 4090 GPU.</p><div><p>
  <img src="https://github.com/mit-han-lab/nunchaku/blob/main/assets/demo.gif?raw=true" width="70%">
</p><p>Check our interactive demo at <a href="https://svdquant.mit.edu/">https://svdquant.mit.edu</a>! Our quantization library is at <a href="https://github.com/mit-han-lab/deepcompressor">github.com/mit-han-lab/deepcompressor</a> and inference engine is at <a href="https://github.com/mit-han-lab/nunchaku">github.com/mit-han-lab/nunchaku</a>. Our paper is at <a href="http://arxiv.org/abs/2411.05007">this link</a>.</p><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcef3c3ec127e8078fd_672d1b2115081c1e8ac82ea9_teaser.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant is a post-training quantization technique for 4-bit weights and activations that well maintains visual fidelity. On 12B FLUX.1-dev, it achieves 3.6× memory reduction compared to the BF16 model. By eliminating CPU offloading, it offers 8.7× speedup over the 16-bit model when on a 16GB laptop 4090 GPU, 3× faster than the NF4 W4A16 baseline. On PixArt-∑, it demonstrates significantly superior visual quality over other W4A4 or even W4A8 baselines.</p><h2>Background</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a9dcbacb7d59271c5662e_672a9a6c364fccc4e4443187_trend.jpeg" loading="lazy" alt=""></p><figcaption>Computation <em>v.s.</em> parameters for LLMs and diffusion models.</figcaption></figure><p>Diffusion models are revolutionizing AI with their ability to generate high-quality images from text prompts. To improve image quality and improve the alignment between text and image, researchers are scaling up these models. As shown in the right figure, while Stable Diffusion 1.4 has 800 million parameters, newer models like AuraFlow and FLUX.1 reach billions, delivering more refined and detailed outputs. However, scaling brings challenges: these models become computationally heavy, demanding high memory and longer processing times, making them prohibitive for real-time applications.</p><p>As Moore's law slows down, hardware vendors are turning to low-precision inference, such as NVIDIA's new 4-bit floating point (FP4) precision in Blackwell. In large language models (LLMs), quantization has helped reduce model sizes and speed up inference, primarily by addressing latency from loading model weights. Diffusion models, however, are computationally bound, even for single batches, so quantizing weights alone yields limited gains. To achieve measured speedups, both weights and activations must be quantized to the same bit width; otherwise, the lower precision is upcast during computation, negating any performance benefits.</p><p>In this blog, we introduce SVDQuant to quantize both the weights and activations of diffusion models to 4 bits. At such an aggressive level, conventional post-training methods fall short. Unlike smoothing, which redistributes outliers, SVDQuant absorbs them through a high-precision low-rank branch, significantly preserving image quality. Visual examples demonstrate its effectiveness. See the above figure for some visual examples.</p><h2>SVDQuant: Absorbing Outliers via Low-Rank Branch</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a66701e9812afb49e0cfa_672a651614cb88ed4fd9dc29_intuition-animate.gif" loading="lazy" alt=""></p></figure><div>


    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LaTeX Rendering Example</title>
    


    <p>
The key idea behind SVDQuant is to introduce an additional low-rank branch that can absorb quantization difficulties in both weights and activations. As shown in the above animation, originally, both the activation \( \boldsymbol{X} \) and weights \( \boldsymbol{W} \) contain massive outliers, making 4-bit quantization challenging. We can first aggregate the outliers by migrating them from activations to weights via smoothing, resulting in the updated activation \( \hat{\boldsymbol{X}} \) and weights \( \hat{\boldsymbol{W}} \). While \( \hat{\boldsymbol{X}} \) becomes easier to quantize, \( \hat{\boldsymbol{W}} \) now becomes more difficult. At the last stage, SVDQuant further decomposes \( \hat{\boldsymbol{W}} \) into a low-rank component \( \boldsymbol{L}_1 \boldsymbol{L}_2 \) and a residual \( \hat{\boldsymbol{W}} - \boldsymbol{L}_1 \boldsymbol{L}_2 \) with Singular Value Decomposition (SVD). As the singular value distribution of \( \hat{\boldsymbol{W}} \) is highly imbalanced, with only the first several values being significantly larger, removing these dominant values can dramatically reduce \( \hat{\boldsymbol{W}} \)’s magnitude and outliers, as suggested by <a href="https://en.wikipedia.org/wiki/Low-rank_approximation">Eckart-Young-Mirsky theorem</a>. Thus, the quantization difficulty is alleviated by the low-rank branch, which runs at 16-bit precision. The below figure illustrates an example value distribution of the input activations and weights in PixArt-∑.
    </p>

</div><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672abca95c5f67bff08b7664_672abca0fde8974bb6d63e6d_distribution.jpeg" loading="lazy" alt=""></p><figcaption>Example value distribution of inputs and weights in PixArt-∑.</figcaption></figure><h2>Nunchaku: Fusing Low-Rank and Low-Bit Branch Kernels</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1fccad9d41d739c84c2c_672a6ac09cf7fc46071c3fb8_672a6a991adf3346a0ee4dbb_engine.jpeg" loading="lazy" alt=""></p></figure><p>Although the low-rank branch adds only minor computational costs on paper, running it separately can lead to significant latency overhead—about 50% of the 4-bit branch's latency, as shown in figure (a). This is because, despite reduced computation costs with a small rank, the data size of input and output activations remains the same, shifting the bottleneck to memory access instead of computation.</p><p>To address this, we co-designed our inference engine, Nunchaku, with the SVDQuant algorithm. Specifically, we noted that the down projection in the low-rank branch uses the same input as the quantization kernel in the low-bit branch, and the up projection shares the same output as the 4-bit computation kernel, as shown in figure (b). By fusing the down projection with the quantization kernel and the up projection with the 4-bit computation kernel, the low-rank branch can now share activations with the low-bit branch. This eliminates extra memory access and cuts the number of kernel calls in half. As a result, the low-rank branch now adds only 5–10% additional latency, making its cost almost negligible.</p><h2>Performance</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672d1bcdf3c3ec127e8078f3_672d1b5772f1247fa24e231d_efficiency.jpeg" loading="lazy" alt=""></p></figure><p>SVDQuant reduces the model size of the 12B FLUX.1 by 3.6×. Additionally, Nunchaku further cuts memory usage of the 16-bit model by 3.5× and delivers 3.0× speedups over the NF4 W4A16 baseline on both the desktop and laptop NVIDIA RTX 4090 GPUs. Remarkably, on laptop 4090, it achieves in total 10.1× speedup by eliminating CPU offloading. </p><h2>Quality</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672ac9098069a7c6f2baedbd_672ac78c0b59dc8da3c15987_visual.jpeg" loading="lazy" alt=""></p></figure><p>On FLUX.1 models, our 4-bit models outperform the NF4 W4A16 baselines, demonstrating superior text alignment and closer similarity to the 16-bit models. For instance, NF4 misinterprets "dinosaur style," generating a real dinosaur. On PixArt-∑ and SDXL-Turbo, our 4-bit results demonstrate noticeably better visual quality than ViDiT-Q's and MixDQ's W4A8 results.</p><p>‍</p><h2>Integrate with LoRA</h2><figure><p><img src="https://cdn.prod.website-files.com/64f4e81394e25710d22d042e/672a6c74c47e63fff4b5b216_672a6c25ef1acf8704ef65af_lora.jpeg" loading="lazy" alt=""></p></figure><p>Traditional quantization methods require fusing LoRA branches and then requantizing the model when integrating LoRAs. Our SVDQuant, however, avoids redundant memory access, making it possible to add a separate LoRA branch directly. The figure above shows visual examples of our INT4 FLUX.1-dev model with LoRAs applied in five distinct styles—<a href="https://huggingface.co/XLabs-AI/flux-RealismLora">Realism</a>, <a href="https://huggingface.co/aleksa-codes/flux-ghibsky-illustration">Ghibsky Illustration</a>, <a href="https://huggingface.co/alvdansen/sonny-anime-fixed">Anime</a>, <a href="https://huggingface.co/Shakker-Labs/FLUX.1-dev-LoRA-Children-Simple-Sketch">Children Sketch</a>, and <a href="https://huggingface.co/linoyts/yarn_art_Flux_LoRA">Yarn Art</a>. Our INT4 model adapts seamlessly to each style, maintaining the image quality of the original 16-bit version.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Texture-Less Text Rendering (117 pts)]]></title>
            <link>https://poniesandlight.co.uk/reflect/debug_print_text/</link>
            <guid>42093037</guid>
            <pubDate>Sat, 09 Nov 2024 07:27:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://poniesandlight.co.uk/reflect/debug_print_text/">https://poniesandlight.co.uk/reflect/debug_print_text/</a>, See on <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    
  	
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/look_ma.png" loading="lazy">
</figure>
<div>
<p>Sometimes, all you want is to quickly print some text into a Renderpass. But <a href="https://stackoverflow.com/questions/22080881/how-to-render-text-in-modern-opengl-with-glsl">traditionally, drawing text</a> requires you first to render all possible glyphs of a font into an atlas, to bind this atlas as a texture, and then to render glyphs one by one by drawing triangles on screen, with every triangle picking the correct glyph from the font atlas texture.</p>
<p>This is how <a href="https://github.com/ocornut/imgui">imgui</a> does it, how anyone using <a href="https://github.com/nothings/stb/blob/master/stb_truetype.h">stb_truetype</a> does it, and it’s delightfully close to how <a href="https://en.wikipedia.org/wiki/Typesetting">type setting</a> used to be done ages bygone on physical letterpresses.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/upper_case_and_lower_case.jpg" alt="Composing cases of an early letterpress" title="Composing cases of an early letterpress">
<figcaption>
    Case in point: Some ancient Letterpress Type Cases (public domain) – <a href="https://babel.hathitrust.org/846c4e7f-3fa3-4275-b53c-3183150e9481">source</a><p>In case you wonder – <a href="https://www.mcgill.ca/oss/article/did-you-know-history/why-it-called-upper-and-lower-case">yes</a></p><p>That’s enough (ed).
</p></figcaption>
</figure>
<p>Quaint, correct, but also quite cumbersome.</p>
<p>What if – for quick and dirty debug messaging – there was a simpler way to do this?</p>
<p>Here, I’ll describe a technique for <em>texture-less</em> rendering of debug text. On top of it all, it draws all the text in a single draw call.</p>
<h2 id="the-font-pixels-sans-texture">The Font: Pixels Sans Texture&nbsp;<a href="#the-font-pixels-sans-texture"></a></h2>
<p>How can we get rid of the font atlas texture? We’d need to store a font atlas or something similar <em>directly inside</em> the fragment shader. Obviously, we can’t store <em>bitmaps</em> inside our shaders, but we can store integer constants, which, if you squint hard enough, are nothing but maps of bits. Can we pretend that an integer is a bitmap?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/0x42_as_bitmap.svg" alt="The integer 0x42 as a bitmap" title="The integer 0x42 as a bitmap">
<figcaption>
    An 8 bit integer as a bitmap. The value 66, or <code>0x42</code> in hex notation, translates to <code>0b01000010</code> in binary notation. If we assume that every bit is a pixel  on/off value, we get something like this.
</figcaption>
</figure>
<p>We can draw this to the screen using a GLSL fragment shader by mapping a fragment’s <code>xy</code> position to the bit that is covered by it in the “bitmap”. If the bit is set, we draw in the foreground colour. If the bit is not set, we draw in the background colour.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>bitmap</span> <span>=</span> <span>0x42</span><span>;</span>
</span></span><span><span><span>vec4</span> <span>col_fg</span> <span>=</span> <span>vec4</span><span>(</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span><span>vec4</span> <span>col_bg</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>
</span></span><span><span><span>// vec2 uv is the normalized texture coordinate for the fragment</span>
</span></span><span><span><span>// with the origin top-left</span>
</span></span><span><span><span>uint</span> <span>which_bit</span> <span>=</span> <span>7</span> <span>-</span> <span>min</span><span>(</span><span>7</span><span>,</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>x</span> <span>*</span> <span>8</span><span>));</span> 
</span></span><span><span>
</span></span><span><span><span>out_color</span> <span>=</span> <span>mix</span><span>(</span><span>col_bg</span><span>,</span> <span>col_fg</span><span>,</span> <span>(</span><span>bitmap</span> <span>&gt;&gt;</span> <span>which_bit</span><span>)</span> <span>&amp;</span> <span>1</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Now, one byte will only draw one line of pixels for us. If we want to draw nicer glyphs, we will need more bytes. If we allowed <span>16 bytes</span><span> (that’s 16 lines)</span> per glyph, this would give us an 8x16 pixel canvas to work with. A single <code>uvec4</code>, which is a built-in type in GLSL, covers exactly the correct amount of bytes that we need.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/character_A.svg" alt="The Glyph A encoded as an uvec4" title="The Glyph A encoded as an uvec4">
<figcaption>
    The character <code>A</code> encoded in 16 bytes, stored as an <code>uvec4</code>, that’s 4 uints with each 4 bytes.
</figcaption>
</figure>
<p>16 bytes per glyph seems small enough; It should allow us to encode the complete <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> subset of 96 printable glyphs in all of 1536 bytes of shader <span>memory</span><span>. (We could probably compress this further, but we would lose simplicity and/or readability)</span>.</p>
<h2 id="where-do-we-get-the-bitmaps-from">Where do we get the bitmaps from?&nbsp;<a href="#where-do-we-get-the-bitmaps-from"></a></h2>
<p>Conveniently, the encoding of a font into bitmaps such as described above is very much the definition of the venerable <a href="https://en.wikipedia.org/wiki/PC_Screen_Font">PSF1 format</a>, give or take a few header bytes. We can therefore harvest the glyph pixels from any PSF1 terminal font by opening it in a hex editor such as <a href="https://imhex.werwolv.net/">ImHex</a>, travelling past the header (4 bytes) and the first section of non-printable glyphs (512 bytes), and then exporting the raw data for the next 96 glyphs (1536 bytes) by using “Copy as → C Array”.</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/imhex_screenshot.png" alt="A Screenshot of ImHex" title="A Screenshot of ImHex">
<figcaption>
    The ImHex hex editor has a really useful feature: you can copy binary data as a c-array.
</figcaption>
</figure>
<p>This will give us a nicely formatted array of chars, which we can easily edit into an array of <code>uint</code>s, which we then group into <code>uvec4</code>s. We need to remember that just concatenating the raw chars into <code>uint</code>s flips the endianness of our <code>uint</code>s, but we can always flip this back when we sample the font data…</p>
<p>Once we’re done, this is how our font bitmap data table looks like in the fragment shader:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uvec4</span> <span>font_data</span><span>[</span><span>96</span><span>]</span> <span>=</span> <span>{</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x1e: SPACE</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080800</span><span>,</span> <span>0x08080000</span> <span>},</span> <span>// 0x21: '!'</span>
</span></span><span><span>  <span>{</span> <span>0x00002222</span><span>,</span> <span>0x22220000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x22: '\'</span>
</span></span><span><span>  <span>{</span> <span>0x00000000</span><span>,</span> <span>0x1212127E</span><span>,</span> <span>0x24247E48</span><span>,</span> <span>0x48480000</span> <span>},</span> <span>// 0x23: '#'</span>
</span></span><span><span>  <span>// ... etc ... </span>
</span></span><span><span>
</span></span><span><span>  <span>{</span> <span>0x00000808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span><span>,</span> <span>0x08080808</span> <span>},</span> <span>// 0x7C: '|'</span>
</span></span><span><span>  <span>{</span> <span>0x00000030</span><span>,</span> <span>0x08081010</span><span>,</span> <span>0x08040810</span><span>,</span> <span>0x10080830</span> <span>},</span> <span>// 0x7D: '}'</span>
</span></span><span><span>  <span>{</span> <span>0x00000031</span><span>,</span> <span>0x49460000</span><span>,</span> <span>0x00000000</span><span>,</span> <span>0x00000000</span> <span>},</span> <span>// 0x7E: '~'</span>
</span></span><span><span>  <span>{</span> <span>0xFC1B26EF</span><span>,</span> <span>0xC8E04320</span><span>,</span> <span>0x8958625E</span><span>,</span> <span>0x79BAEE7E</span> <span>},</span> <span>// 0x7F: BACKSPACE</span>
</span></span><span><span><span>};</span>                                              </span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>I say table, because the <code>font_data</code> array now stores the bitmaps for 96 character glyphs, indexed by their ASCII value (minus 0x20). This table therefore covers the full printable ASCII range from <code>0x20</code> <kbd>SPACE</kbd> to <code>0x7F</code> <kbd>BACKSPACE</kbd> (inclusive), but in the snippet above I’m showing only 8 of them, to save space.</p>
<p>So far, all this is just so that we don’t have to bind a texture when drawing our text. But how to draw the text itself?</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small.png" alt="Text output" title="Text output">
<figcaption>
    This is what we want to print at the end of this process
</figcaption>
</figure>
<h2 id="one-draw-call-thats-all">One Draw Call, That’s All.&nbsp;<a href="#one-draw-call-thats-all"></a></h2>
<p>We’re going to use a single <strong>instanced</strong> draw call.</p>

</div>
<div>
    
<p>With instanced drawing, we don’t have to repeatedly issue draw <em>instructions</em>, since we encode the logic into per-instance data. One draw call contains everything we need, provided it uses two attribute streams. The fist stream, per-draw, has just the necessary information to draw a generic quad. And the second stream, per-instance, packs the two pieces of information that change with every instance of such a quad: First, a position offset, so that we know <em>where in screen space</em> to draw the quad. And second, of course, the text that we want to print.</p>
<p>For the position offset we can use one float each for x and y, which leaves two floats for this particular attribute binding <span>unused</span><span> (attribute bindings in GLSL/Vulkan are at minimum the equivalent of 4 floats wide)</span>. We have more than enough space to use one extra float to pack in a font scale parameter, if we like.</p>

</div>
<div>
  
<p>For the text that we want to print, we have a similarly wasteful situation – the smallest basic vertex attribute data type <a href="https://docs.vulkan.org/spec/latest/chapters/fxvertex.html#fxvertex-attrib-location">is usually 32bit wide</a>, and so it makes sense to make best use of this and pack at least 4 characters at a time. If we do this, we must make sure that the message that we want to print has a length divisible by 4. If it was shorter, we need to fill up the difference with zero byte (<code>\0</code>) characters. Conveniently, the zero byte is also used to signal the end of a c-string.</p>
<p>Our per-instance data looks like this:</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>struct</span> <span>word_data</span> <span>{</span>
</span></span><span><span>  <span>float</span>          <span>pos_and_scale</span><span>[</span> <span>3</span> <span>];</span> <span>// xy position + scale 
</span></span></span><span><span><span></span>  <span>uint32_t</span>       <span>word</span><span>;</span>               <span>// four characters that we want to print
</span></span></span><span><span><span></span><span>};</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>It’s the application’s responsibility to split up the message into chunks of 4 characters, to convert these four characters into an <code>unit32_t</code>, and to store it into a <code>word_data</code> struct together with the position offset for where on screen to render these four characters. Once a <code>word_data</code> is filled, we append it into an array where we accumulate all the data for our text draw calls. Once we are ready to draw, we can then bind this array as a per-instance binding to our debug text drawing pipeline, and draw all text with a single <span>instanced draw call</span><span>, with the number of instances being the number of quads that we want to draw</span>.</p>
<p>More interesting things happen in the vertex and fragment shader of the debug text drawing pipeline.</p>
<h2 id="vertex-shader">Vertex Shader&nbsp;<a href="#vertex-shader"></a></h2>
<p>Our vertex shader produces three outputs.</p>
<p>First, it writes to <code>gl_Position</code> to place the vertices for our triangles on the screen. This operates in <span> NDC </span><span> = Normalised Device </span> “screen space” Coordinates. We calculate an offset for each vertex using the per-instance <code>pos_and_scale</code> attribute data.</p>
<p>The second output of the vertex shader is the word that we want to render: We just pass though the attribute <code>uint</code> as an output to the fragment shader – but we make sure to use the <code>flat</code> qualifier so that it does not get interpolated.</p>
<p>And then, the vertex shader synthesizes texture coordinates (via <code>gl_VertexIndex</code>). It does so pretty cleverly:</p>
<ul>
<li><code>12 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>0, 0, 1, 1</code>,</li>
<li><code> 9 &gt;&gt; gl_VertexIndex &amp; 1</code> will give a sequence <code>1, 0, 0, 1</code>,</li>
</ul>
<p>This creates a sequence of uv coordinates <code>(0,1), (0,0), (1,0), (1,1)</code> in a branchless way.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span><span>34
</span><span>35
</span><span>36
</span><span>37
</span><span>38
</span><span>39
</span><span>40
</span><span>41
</span><span>42
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>#version 450 core</span>
</span></span><span><span>
</span></span><span><span><span>#extension GL_ARB_separate_shader_objects : enable</span>
</span></span><span><span><span>#extension GL_ARB_shading_language_420pack : enable</span>
</span></span><span><span>
</span></span><span><span><span>// Inputs </span>
</span></span><span><span><span>// Uniforms - Push Constants</span>
</span></span><span><span><span>layout</span> <span>(</span><span>push_constant</span><span>)</span> <span>uniform</span> <span>Params</span>
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>vec2</span> <span>u_resolution</span><span>;</span> <span>// screen canvas resolution in physical pixels</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>// Input Attributes</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>in</span> <span>vec3</span> <span>pos</span><span>;</span>      <span>// "vanilla" vertex position attribute - given in pixels</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>in</span> <span>uint</span> <span>word</span><span>;</span>     <span>// per-instance: four chars</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>2</span><span>)</span> <span>in</span> <span>vec3</span> <span>word_pos</span><span>;</span> <span>// per-instance: where to place the word in screen space</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>3</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_fg</span><span>;</span>   <span>// per-instance: foreground colour</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>4</span><span>)</span> <span>in</span> <span>vec4</span> <span>col_bg</span><span>;</span>   <span>// per-instance: background colour</span>
</span></span><span><span>
</span></span><span><span><span>// Vertex Outputs </span>
</span></span><span><span><span>struct</span> <span>per_word_data</span> <span>{</span>
</span></span><span><span>	<span>uint</span> <span>msg</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>fg_colour</span><span>;</span>
</span></span><span><span>	<span>vec4</span> <span>bg_colour</span><span>;</span>
</span></span><span><span><span>};</span>
</span></span><span><span>
</span></span><span><span><span>out</span> <span>gl_PerVertex</span> <span>{</span> <span>vec4</span> <span>gl_Position</span><span>;</span> <span>};</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>0</span><span>)</span> <span>out</span> <span>vec2</span> <span>outTexCoord</span><span>;</span>
</span></span><span><span><span>layout</span> <span>(</span><span>location</span> <span>=</span> <span>1</span><span>)</span> <span>flat</span> <span>out</span> <span>per_word_data</span> <span>outMsg</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>void</span> <span>main</span><span>()</span> 
</span></span><span><span><span>{</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>msg</span> <span>=</span> <span>word</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>fg_colour</span> <span>=</span> <span>col_fg</span><span>;</span>
</span></span><span><span>	<span>outMsg</span><span>.</span><span>bg_colour</span> <span>=</span> <span>col_bg</span><span>;</span>
</span></span><span><span>
</span></span><span><span>	<span>vec2</span> <span>scale_factor</span> <span>=</span> <span>vec2</span><span>(</span><span>1.</span><span>,</span><span>2.</span><span>)</span><span>/</span><span>(</span><span>u_resolution</span><span>);</span>
</span></span><span><span>	<span>outTexCoord</span> <span>=</span> <span>vec2</span><span>((</span><span>12</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span><span>)</span> <span>&amp;</span><span>1</span><span>,</span> <span>(</span><span>9</span> <span>&gt;&gt;</span> <span>gl_VertexIndex</span> <span>)</span> <span>&amp;</span><span>1</span><span>);</span>
</span></span><span><span>	<span>vec4</span> <span>position</span> <span>=</span> <span>vec4</span><span>(</span><span>0</span><span>,</span><span>0</span><span>,</span><span>0</span><span>,</span><span>1</span><span>);</span>
</span></span><span><span>	<span>position</span><span>.</span><span>xy</span> <span>=</span> <span>vec2</span><span>(</span><span>-</span><span>1</span><span>,</span> <span>-</span><span>1</span><span>)</span> <span>+</span> <span>(</span><span>pos</span><span>.</span><span>xy</span> <span>*</span> <span>word_pos</span><span>.</span><span>z</span> <span>+</span> <span>word_pos</span><span>.</span><span>xy</span><span>)</span> <span>*</span> <span>scale_factor</span><span>;</span>
</span></span><span><span>	<span>gl_Position</span> <span>=</span> <span>position</span><span>;</span>
</span></span><span><span><span>}</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>If we at this point visualise just the output of the vertex shader, we will get something like this:</p>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv_continuous.png" alt="Quad visualisation with uv coords" title="Quad visualisation with uv coords">
<figcaption>
    Visualisation of per-quad <code>outTexCoord</code> uv coords. Note that these are continuous (smooth).
</figcaption>
</figure>
<h2 id="fragment-shader">Fragment Shader&nbsp;<a href="#fragment-shader"></a></h2>

</div>
<div>
  
<p>Our fragment shader needs three pieces of information to render text, two of which it receives from the vertex shader stage:</p>
<ol>
<li>The fragment’s interpolated uv coordinate, <code>uv</code></li>
<li>The character that we want to draw, <code>in_word</code></li>
<li>The font data array, <code>font_data</code></li>
</ol>
<p>To render a glyph, each fragment must map its uv-coordinate to the correct bit of the glyph bitmap. If the bit at the lookup position is set, then render the fragment in the foreground colour, otherwise render it in background colour.</p>
<p>This mapping works like this:</p>
<p>First, we must map the uv coordinates to <span>word </span><span>– <strong>word</strong> not, <em>world</em>! –</span> pixel coordinates. The nice thing about these two coordinate systems is that they both have their origin at the <span>top left</span><span>, so we only need to bother with scaling, and not origin transformation</span>.</p>
<p>We know that our uv coordinates are normalised floats going from <code>vec2(0.f,0.f)</code> to <code>vec2(1.f,1.f)</code>, while our font pixel coordinates are integers, going from <code>uvec2(0,0)</code> to <code>uvec2(7,15)</code>.</p>
<p>We also must find out which one of the four characters in the word to draw.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>const</span> <span>uint</span> <span>WORD_LEN</span> <span>=</span> <span>4</span><span>;</span> <span>// 4 characters in a word</span>
</span></span><span><span>
</span></span><span><span><span>// quantize uv coordinate to discrete steps</span>
</span></span><span><span><span>uvec2</span> <span>word_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>floor</span><span>(</span><span>uv</span><span>.</span><span>xy</span> <span>*</span> <span>vec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span><span>,</span> <span>16</span><span>)));</span> 
</span></span><span><span><span>// limit pixel coord range to uvec2(0..31, 0..15)</span>
</span></span><span><span><span>word_pixel_coord</span> <span>=</span> <span>min</span><span>(</span><span>uvec2</span><span>(</span> <span>8</span> <span>*</span> <span>WORD_LEN</span> <span>-</span><span>1</span><span>,</span> <span>16</span> <span>-</span><span>1</span><span>),</span> <span>word_pixel_coord</span><span>);</span>
</span></span><span><span><span>// Find which of the four characters in the word this fragment falls onto</span>
</span></span><span><span><span>uint</span> <span>printable_character</span> <span>=</span> <span>in_word</span> <span>&gt;&gt;</span> <span>(</span><span>WORD_LEN</span> <span>-</span> <span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>/</span> <span>8</span><span>));</span>
</span></span><span><span><span>// Map fragment coordinate to pixel coordinate inside character bitmap</span>
</span></span><span><span><span>uvec2</span> <span>glyph_pixel_coord</span> <span>=</span> <span>uvec2</span><span>(</span><span>word_pixel_coord</span><span>.</span><span>x</span> <span>%</span> <span>8</span><span>,</span> <span>word_pixel_coord</span><span>.</span><span>y</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_small_uv.png" alt="Quad visualisation of word_pixel_coord" title="Quad visualisation of word_pixel_coord">
<figcaption>
    A visualisation of <code>word_pixel_coord</code> (normalised)
</figcaption>
</figure>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv.png" alt="Quad visualisation of glyph_pixel_coord" title="Quad visualisation of glyph_pixel_coord">
<figcaption>
    A visualisation of <code>glyph_pixel_coord</code> (normalised)
</figcaption>
</figure>
<p>Remember, to draw a character, we must look up the character in the font bitmap table, where we must find the correct bit to check based on the uv coordinate of the fragment. You will notice that in the first GLSL example above, we were only worried about the <code>.x</code> coordinate. Now, let’s focus on <code>.y</code>, so that we can draw more lines of pixels by looking up the correct line to sample from.</p>
<p>Let’s do this step by step. First, we fetch the character bitmap from our <code>font_data</code> as an <code>uvec4</code>. Then we use the <code>glyph_pixel_coord.y</code> to pick the correct one of 4 <code>uints</code> that make up the glyph. This will give us four lines of pixels.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>// First, map character ASCII code to an index offset into font_data table. </span>
</span></span><span><span><span>// The first character in the font_data table is 0x20, SPACE.</span>
</span></span><span><span><span>offset</span> <span>=</span> <span>printable_character</span> <span>-</span> <span>0x20</span><span>;</span> 
</span></span><span><span><span>// Then get the bitmap for this glyph</span>
</span></span><span><span><span>uvec4</span> <span>character_bitmap</span> <span>=</span> <span>font_data</span><span>[</span><span>offset</span><span>];</span> 
</span></span><span><span><span>// Find the uint that contains one of the four lines that </span>
</span></span><span><span><span>// are touched by our pixel coordinate</span>
</span></span><span><span><span>uint</span> <span>four_lines</span> <span>=</span> <span>character_bitmap</span><span>[</span><span>glyph_pixel_coord</span><span>.</span><span>y</span> <span>/</span> <span>4</span><span>];</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>Once we have the <code>uint</code> covering four lines, we must pick the correct line from it.</p>
<p>Note that lines are stored in reverse order because after we used ImHex to lift the bitmap bytes out of the font file, we just concatenated the <code>chars</code> into <code>uint</code>. This means that our bitmap <code>uint</code>s have the wrong endianness; We want to keep it like this though, because it is much less work to just concatenate chars copied form ImHex than to manually convert endianness in a text editor.</p>

</div>
<div>
    
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_line</span>  <span>=</span> <span>(</span><span>four_lines</span> <span>&gt;&gt;</span> <span>(</span><span>8</span><span>*</span><span>(</span><span>3</span><span>-</span><span>(</span><span>glyph_pixel_coord</span><span>.</span><span>y</span><span>)</span><span>%</span><span>4</span><span>)))</span> <span>&amp;</span> <span>0xff</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>And, lastly, we must pick the correct bit in the bitmap. Note the <code>7-</code> – this is because bytes are stored with the most significant bit at the highest index. To map this to a left-to-right coordinate system, we must index backwards, again.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>uint</span> <span>current_pixel</span> <span>=</span> <span>(</span><span>current_line</span> <span>&gt;&gt;</span> <span>(</span><span>7</span><span>-</span><span>glyph_pixel_coord</span><span>.</span><span>x</span><span>))</span> <span>&amp;</span> <span>0x01</span><span>;</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><p>We now can use the current pixel to shade our fragment, so that if the pixel is set in the bitmap, we shade our fragment in the foreground colour, and if it is not set, shade our fragment in the background colour:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="glsl"><span><span><span>vec3</span> <span>color</span> <span>=</span> <span>mix</span><span>(</span><span>background_colour</span><span>,</span> <span>foreground_colour</span><span>,</span> <span>current_pixel</span><span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>glsl</span>
</p></div><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/screenshot_per_char_uv_overlay.png" alt="Quad visualisation" title="Quad visualisation">
<figcaption>
    Text printed with uv coordinates overlaid
</figcaption>
</figure>
<p>What about the fill chars that get inserted if our printable text is too short to be completely divisible by 4? We detect these in the fragment shader: In case were are about to render such a fill character, we should do absolutely nothing, not even draw the background. We can do this by testing <code>printable_character</code>, and issuing a <code>discard</code> in case the printable character is <code>\0</code>.</p>
<h2 id="a-visual-summary">A Visual Summary&nbsp;<a href="#a-visual-summary"></a></h2>
<p>It is said that an image is worth a thousand words. Why not have both? Here is a diagram which summarises the mapping from quad-uv space to glyph bitmap space:</p>
</div>
<figure>
<img src="https://poniesandlight.co.uk/img/reflect/debug_print_text/summary.svg" loading="lazy">
<figcaption>
	    <div><p>Note: Our Fragment position is marked by the blue speck.</p><p>① pick the correct character from our per-quad word. ② calculate the offset into <code>font_data</code> using the character ASCII code. ③ fetch the <code>uvec4</code> that holds the bitmap for our glyph from <code>font_data</code> ④ pick the <code>uint</code> representing the four lines of the glyph that our fragment falls in (via its y-coord) ⑤ pick the correct line using the fragment’s .y coord ⑥ pick the correct bit using the per-glyph <code>x</code> coordinate.
	    </p></div>
</figcaption>
</figure>
<div>
<h2 id="full-implementation--more-source-code">Full Implementation &amp; More Source Code&nbsp;<a href="#full-implementation--more-source-code"></a></h2>
<figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/island_preview.png" alt="Island preview image" title="Island preview image">
<figcaption>
    You can find an implementation of the technique described above in the source code for <a href="https://github.com/tgfrerer/island/tree/wip/modules/le_debug_print_text">le_print_debug_print_text</a>, which is a new <a href="https://poniesandlight.co.uk/tags/island/">Island</a> module that allows you to easily print debug messages to screen. It has some extra nice bits around text processing and caching which, however, would be too wordy to describe here.
</figcaption>
</figure>
<p>Using this technique, it is now possible, from nearly anywhere in an Island project, to call:</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="cpp"><span><span><span>char</span> <span>const</span> <span>msg_2</span><span>[]</span> <span>=</span> <span>{</span> <span>70</span><span>,</span> <span>111</span><span>,</span> <span>108</span><span>,</span> <span>107</span><span>,</span> <span>115</span><span>,</span> <span>'!'</span><span>,</span> <span>0</span> <span>};</span>
</span></span><span><span><span>le</span><span>::</span><span>DebugPrint</span><span>(</span> <span>"That's all, %s"</span><span>,</span> <span>msg_2</span> <span>);</span></span></span></code></pre></td></tr></tbody></table>
</div><p><span>cpp</span>
</p></div><p>And see the following result on screen:

</p><figure>
<img loading="lazy" src="https://poniesandlight.co.uk/img/reflect/debug_print_text/that_s_all_folks.png" alt="Image That&amp;rsquo;s all Folks">
</figure>
<h2 id="acknowledgements">Acknowledgements&nbsp;<a href="#acknowledgements"></a></h2>
<ul>
<li>Diagrams drawn with <a href="https://excalidraw.com/">Excalidraw</a></li>
<li>Original source data for the pixel font came from <a href="http://www.fial.com/~scott/tamsyn-font/">Tamsyn</a>, a free pixel font by Scott Fial</li>
</ul>
<h2 id="backlinks">Backlinks&nbsp;<a href="#backlinks"></a></h2>
<p>This article was featured on <a href="https://www.jendrikillner.com/post/graphics-programming-weekly-issue-363/">Graphics Programming Weekly</a>, and discussed on <a href="https://lobste.rs/s/5iiqji/texture_less_text_rendering">Lobste.rs</a>, and <a href="https://news.ycombinator.com/item?id=42093037">Hacker News</a>.</p>
<p>If you like more of this, subscribe to the rss feed, and if you want the very latest, and hear about occasional sortees into generative art and design, follow me on <a href="https://bsky.app/profile/tgfrerer.bsky.social">bluesky</a> or <a href="https://mastodon.social/@tgfrerer">mastodon</a>, or maybe even <a href="https://www.instagram.com/tgfrerer/">Instagram</a>. Shameless plug: my services are also available for contract work.</p>


	</div>
	
	
	
		<div>
			<h3>RSS:</h3>
			<p>Find out first about new posts by subscribing to the <a href="https://poniesandlight.co.uk//reflect/feed.xml">RSS Feed</a> <a href="https://poniesandlight.co.uk//reflect/feed.xml" type="application/rss+xml"><svg style="width: 1em; position:relative; bottom:-0.25em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm64 120c0 17.7-14.3 32-32 32s-32-14.3-32-32s14.3-32 32-32s32 14.3 32 32z"></path></svg></a></p>
		</div>
	
		<p>
			<h3>Further Posts:</h3>
		</p>
		
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's legal for police to use deception in interrogations. Some want that to end (256 pts)]]></title>
            <link>https://text.npr.org/nx-s1-4974964</link>
            <guid>42091423</guid>
            <pubDate>Fri, 08 Nov 2024 23:57:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://text.npr.org/nx-s1-4974964">https://text.npr.org/nx-s1-4974964</a>, See on <a href="https://news.ycombinator.com/item?id=42091423">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>Ted Bradford says the worst day of his life was when detectives took him into a tiny room to question him about a rape.</p><p>“The whole day it was like accusation after accusation,” he says. “I kept telling them over and over, ‘I didn't do this.’”</p><p>Bradford says the officers in Yakima, Wash., <a href="https://wainnocenceproject.org/stories/ted-bradford/"><u>claimed they had biological evidence</u></a> that would prove he did it, and they weren't going to let him leave until he admitted it.</p><p>“I knew I didn’t do it,” he said. “So I'm thinking, ‘In order to get out of this situation, I could just give them a statement. They’ll test that evidence. It’ll show that I didn’t do it, and then this will all be done with.’”</p><p>After<em> </em>hours of questioning, Bradford confessed to the crime. But the evidence police had – a mask left at the scene – could not be DNA-tested. This was the late nineties and the technology wasn’t there yet.</p><p>Bradford recanted his confession, but was convicted anyway. He was 22 with two small children when he went to prison.</p><p>“Every day I woke up and knew that I shouldn't be there,” he says.</p><p>Advancements in DNA testing helped lead to his exoneration in 2010.</p><p>What happened to Bradford might seem extreme, but nearly 30 years later, the tactic used on him is not. In every state, police officers are allowed to lie to adults during an interrogation. The hope, in many cases, is that they’ll get a person to confess to committing a crime.</p><p>When it comes to children and teenagers, a growing number of states are stopping that practice: Ten have passed laws in recent years effectively banning police from lying to juveniles during interrogations, starting with Illinois in 2021. But some legal advocates are pushing for a deception ban that would apply to everyone, not just kids.</p><h2>‘A quick and relatively straightforward way to close a case’</h2><p>Deception is a powerful law enforcement tool in eliciting confessions, says wrongful convictions attorney Laura Nirider.</p><p>“Police are trained around the country in all 50 states to use deception during interrogation, to lie both about the evidence against a suspect and to lie about the consequences of confessing in order to make it seem not so bad if you just say that you did these things,” she says.</p><p>Police can go into an interrogation room with a suspect, Nirider says, and emerge with “one of the most believable pieces of evidence imaginable, a confession.”</p><p>“It's a quick and relatively straightforward way to close a case,” she says.</p><p>But Nirider says using deception can also draw false confessions.</p><p>According to the Innocence Project, a national organization that works to overturn wrongful convictions, nearly a third of DNA exonerations from 1989 to 2020 <a href="https://innocenceproject.org/dna-exonerations-in-the-united-states/"><u>involved a false confession</u></a>.</p><p>Legal experts say the deception bans passed in recent years fail to protect other vulnerable groups: young adults, people with intellectual disabilities, even just people who are naturally compliant.</p><p>“Children are one category that makes you more vulnerable, but it's certainly not the only category,” says Lara Zarowsky, executive and policy director at the Washington Innocence Project. “It's something that all of us are vulnerable to.”</p><h2>‘Law enforcement is the biggest impediment’</h2><p>In Washington state, where Bradford was convicted, Democratic lawmakers want to set a higher bar: A bill that would make incriminating statements made in police custody – by adults or children – largely inadmissible in court if obtained using deception.</p><p>State Rep. Strom Peterson has introduced the bill twice, but it hasn’t gone anywhere.</p><p>“Law enforcement is the biggest impediment to the bill. They believe that the system in which they work is effective,” he says.</p><p>The Washington Association of Sheriffs and Police Chiefs declined NPR’s request for an interview, but said in a statement that it opposes such a measure, because banning deception would take away a tactic that yields “many more true confessions” than false ones.</p><p>“We fear that it will negatively impact our ability to solve crimes and would result in less accountability for those who victimize others,” the association’s policy director, James McMahan, <a href="https://tvw.org/video/house-appropriations-2024021057/?eventID=2024021057"><u>said at a hearing</u></a> for the bill in February.</p><p>“Criminals often conduct elaborate stories to conceal their crimes,” McMahan said at the hearing. “Sometimes the use of deception is required to locate the truth both to convict and to exonerate people. Such deceptions include telling a person that abuse was discovered during a routine medical exam rather than reported by a family member.”</p><p>In its statement, the association added that judges assess whether confessions are given voluntarily before they can be introduced as evidence, and convictions based solely on confessions are rare.</p><p>Even with other evidence, however, confessions carry a lot of weight. Research indicates that people who confess <a href="https://core.ac.uk/reader/81748492?utm_source=linkout"><u>are treated differently</u></a> afterwards: They’re more likely to be charged, face more charges, and receive a harsher punishment when convicted.</p><p>“A confession will trump everything,” says Jim Trainum, a retired homicide detective in Washington, D.C.</p><p>In his experience, there is pressure to move on after a suspect confesses because a detective’s measure of success is often tied to closure rates.</p><p>“Let's say that I get a confession and I get all the stuff that I want to go out and corroborate. I want to make sure that this is an accurate confession,” Trainum says. “I'm sitting there at my desk working very, very hard on it. And my sergeant comes up and says, ‘What are you doing? That's a confession. That's closed. Move on. You got other ones to take care of.’”</p><h2>‘Trying to give the police new tools’</h2><p>Those against deception bans see them as an attack on police, says Mark Fallon, a consultant on interrogation practices and former federal agent. In fact, he says, it’s the opposite.</p><p>“It is actually trying to give the police new tools, better tools,” he says.</p><p>There’s another way for police to question people, Fallon says, that relies on building rapport and asking open-ended questions, and where the primary goal is information, rather than a confession.</p><p>That technique is used in other countries, including much of Europe. In England, France, Germany, Australia, Japan and elsewhere, for instance, the police are generally <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3669413"><u>not allowed to deceive suspects</u></a>.</p><p>Trainum says interrogation methods that don’t rely on deception ultimately make the police more trustworthy to communities.</p><p>“Today’s suspect is tomorrow's witness,” he says.</p><p>When a suspect or witness has been lied to, he says, “that radiates out. And no wonder people don't trust us. Why should they trust us?”</p><p>That is why Peterson, the lawmaker, plans to introduce the bill in Washington again. He says the public is<em> </em>better off when police use the best tools available to convict the right people.</p>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Delta: A syntax-highlighting pager for Git, diff, grep, and blame output (515 pts)]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>42091365</guid>
            <pubDate>Fri, 08 Nov 2024 23:46:46 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/dandavison/delta">https://github.com/dandavison/delta</a>, See on <a href="https://news.ycombinator.com/item?id=42091365">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto">
  <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png" alt="image"></a>
</p>
<p dir="auto">
  <a href="https://github.com/dandavison/delta/actions">
    <img src="https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg" alt="CI">
  </a>
  <a href="https://coveralls.io/github/dandavison/delta?branch=main" rel="nofollow">
    <img src="https://camo.githubusercontent.com/e8785ac8ede00f6ec8ad672e5031d27eb6eb5a599d56b232a469b9824f76753c/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f64616e64617669736f6e2f64656c74612f62616467652e7376673f6272616e63683d6d61696e" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main">
  </a>
  <a href="https://gitter.im/dandavison-delta/community?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge" rel="nofollow">
    <img src="https://camo.githubusercontent.com/6c92914f6e39c859372cd85d6c7676c73d524f994663f1ae0e2b0b566a0e1361/68747470733a2f2f6261646765732e6769747465722e696d2f64616e64617669736f6e2d64656c74612f636f6d6d756e6974792e737667" alt="Gitter" data-canonical-src="https://badges.gitter.im/dandavison-delta/community.svg">
  </a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Get Started</h2><a id="user-content-get-started" aria-label="Permalink: Get Started" href="#get-started"></a></p>
<p dir="auto"><a href="https://dandavison.github.io/delta/installation.html" rel="nofollow">Install it</a> (the package is called "git-delta" in most package managers, but the executable is just <code>delta</code>) and add this to your <code>~/.gitconfig</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true    # use n and N to move between diff sections

    # delta detects terminal colors automatically; set one of these to disable auto-detection
    # dark = true
    # light = true

[merge]
    conflictstyle = zdiff3"><pre>[<span>core</span>]
    <span>pager</span> <span>=</span> <span>delta</span>

[<span>interactive</span>]
    <span>diffFilter</span> <span>=</span> <span>delta</span> <span>--color-only</span>

[<span>delta</span>]
    <span>navigate</span> <span>=</span> <span>true</span>    <span><span>#</span> use n and N to move between diff sections</span>

    <span><span>#</span> delta detects terminal colors automatically; set one of these to disable auto-detection</span>
    <span><span>#</span> dark = true</span>
    <span><span>#</span> light = true</span>

[<span>merge</span>]
    <span>conflictstyle</span> <span>=</span> <span>zdiff3</span></pre></div>
<p dir="auto">Delta has many features and is very customizable; please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Language syntax highlighting with the same syntax-highlighting themes as <a href="https://github.com/sharkdp/bat#readme">bat</a></li>
<li>Word-level diff highlighting using a Levenshtein edit inference algorithm</li>
<li>Side-by-side view with line-wrapping</li>
<li>Line numbering</li>
<li><code>n</code> and <code>N</code> keybindings to move between files in large diffs, and between diffs in <code>log -p</code> views (<code>--navigate</code>)</li>
<li>Improved merge conflict display</li>
<li>Improved <code>git blame</code> display (syntax highlighting; <code>--hyperlinks</code> formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)</li>
<li>Syntax-highlights grep output from <code>rg</code>, <code>git grep</code>, <code>grep</code>, etc</li>
<li>Support for Git's <code>--color-moved</code> feature.</li>
<li>Code can be copied directly from the diff (<code>-/+</code> markers are removed by default).</li>
<li><code>diff-highlight</code> and <code>diff-so-fancy</code> emulation modes</li>
<li>Commit hashes can be formatted as terminal <a href="https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda">hyperlinks</a> to the hosting provider page (<code>--hyperlinks</code>).
File paths can also be formatted as hyperlinks for opening in your OS.</li>
<li>Stylable box/line decorations to draw attention to commit, file and hunk header sections.</li>
<li>Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git</li>
<li>Handles traditional unified diff output in addition to git output</li>
<li>Automatic detection of light/dark terminal background</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">A syntax-highlighting pager for git, diff, and grep output</h2><a id="user-content-a-syntax-highlighting-pager-for-git-diff-and-grep-output" aria-label="Permalink: A syntax-highlighting pager for git, diff, and grep output" href="#a-syntax-highlighting-pager-for-git-diff-and-grep-output"></a></p>
<p dir="auto">Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.</p>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a>
      <br>
      <sub>delta with <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<markdown-accessiblity-table><p>
      <a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a>
      <br>
      <sub>delta with <code>side-by-side</code> and <code>line-numbers</code> activated</sub>
    </p></markdown-accessiblity-table>
<p dir="auto">Here's what <code>git show</code> can look like with git configured to use delta:</p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Syntax-highlighting themes</h3><a id="user-content-syntax-highlighting-themes" aria-label="Permalink: Syntax-highlighting themes" href="#syntax-highlighting-themes"></a></p>
<p dir="auto"><strong>All the syntax-highlighting color themes that are available with <a href="https://github.com/sharkdp/bat/">bat</a> are available with delta:</strong></p>
<br>
<markdown-accessiblity-table></markdown-accessiblity-table>

<p dir="auto"><h3 tabindex="-1" dir="auto">Side-by-side view</h3><a id="user-content-side-by-side-view" aria-label="Permalink: Side-by-side view" href="#side-by-side-view"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/side-by-side-view.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    side-by-side = true"><pre>[<span>delta</span>]
    <span>side-by-side</span> <span>=</span> <span>true</span></pre></div>
<p dir="auto">By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [<a href="#side-by-side-view-1">config</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png"><img width="800px" src="https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto">Side-by-side view wraps long lines automatically:</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Line numbers</h3><a id="user-content-line-numbers" aria-label="Permalink: Line numbers" href="#line-numbers"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/line-numbers.html" rel="nofollow">User manual</a>]</p>
<div dir="auto" data-snippet-clipboard-copy-content="[delta]
    line-numbers = true"><pre>[<span>delta</span>]
    <span>line-numbers</span> <span>=</span> <span>true</span></pre></div>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png"><img width="400px" src="https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Merge conflicts</h3><a id="user-content-merge-conflicts" aria-label="Permalink: Merge conflicts" href="#merge-conflicts"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/merge-conflicts.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png"><img width="500px" src="https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Git blame</h3><a id="user-content-git-blame" aria-label="Permalink: Git blame" href="#git-blame"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/git-blame.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p><a target="_blank" rel="noopener noreferrer nofollow" href="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png"><img width="600px" src="https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png" alt="image"></a></p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Ripgrep, git grep</h3><a id="user-content-ripgrep-git-grep" aria-label="Permalink: Ripgrep, git grep" href="#ripgrep-git-grep"></a></p>
<p dir="auto">[<a href="https://dandavison.github.io/delta/grep.html" rel="nofollow">User manual</a>]</p>
<markdown-accessiblity-table><p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"><img width="600px" alt="image" src="https://private-user-images.githubusercontent.com/52205/242993705-d203d380-5acb-4296-aeb9-e38c73d6c27f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzExMTk3MDMsIm5iZiI6MTczMTExOTQwMywicGF0aCI6Ii81MjIwNS8yNDI5OTM3MDUtZDIwM2QzODAtNWFjYi00Mjk2LWFlYjktZTM4YzczZDZjMjdmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDExMDklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMTA5VDAyMzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTM0YTI4NDcxNzJhNjgwZjYyZmU0YzAzMzU0NDRlNWVlOWYwN2ZhMzYwYzUyMzg0MzgxZmIwYTcwYzFmNGY5OTAmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.KIvs6cUnqPH2O6y8UH16_sX9nhVwj9vdzsY6x6HmdJY"></a>
</p></markdown-accessiblity-table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation and usage</h3><a id="user-content-installation-and-usage" aria-label="Permalink: Installation and usage" href="#installation-and-usage"></a></p>
<p dir="auto">Please see the <a href="https://dandavison.github.io/delta/" rel="nofollow">user manual</a> and <code>delta --help</code>.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Maintainers</h3><a id="user-content-maintainers" aria-label="Permalink: Maintainers" href="#maintainers"></a></p>
<ul dir="auto">
<li><a href="https://github.com/dandavison">@dandavison</a></li>
<li><a href="https://github.com/th1000s">@th1000s</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Claude AI to process secret government data through new Palantir deal (220 pts)]]></title>
            <link>https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</link>
            <guid>42091043</guid>
            <pubDate>Fri, 08 Nov 2024 22:42:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/">https://arstechnica.com/ai/2024/11/safe-ai-champ-anthropic-teams-up-with-defense-giant-palantir-in-new-deal/</a>, See on <a href="https://news.ycombinator.com/item?id=42091043">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          
<h2>An ethical minefield</h2>
<p>Since its founders started Anthropic in 2021, the company has <a href="https://www.youtube.com/watch?v=UMF1nf3Iy3Q">marketed itself</a> as one that takes an ethics- and safety-focused approach to AI development. The company differentiates itself from competitors like OpenAI by adopting what it calls responsible development practices and self-imposed ethical constraints on its models, such as its "<a href="https://arstechnica.com/information-technology/2023/05/ai-with-a-moral-compass-anthropic-outlines-constitutional-ai-in-its-claude-chatbot/">Constitutional AI</a>" system.</p>
<p>As Futurism <a href="https://futurism.com/the-byte/ethical-ai-anthropic-palantir">points out</a>, this new defense partnership appears to conflict with Anthropic's public "good guy" persona, and pro-AI pundits on social media are noticing. <span>Frequent AI commentator Nabeel S. Qureshi <a href="https://x.com/nabeelqu/status/1854574146283618521">wrote</a> on X, </span><span>"Imagine telling the safety-concerned, effective altruist founders of Anthropic in 2021 that a mere three years after founding the company, they'd be signing partnerships to deploy their ~AGI model straight to the military frontlines.</span>"</p>
<figure>
    <div>
              <p><a data-pswp-width="1200" data-pswp-height="675" data-pswp-srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w" data-cropped="true" href="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" target="_blank">
                <img decoding="async" width="1200" height="675" src="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg" alt="Anthropic's &quot;Constitutional AI&quot; logo." srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red.jpg 1200w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-300x169.jpg 300w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-640x360.jpg 640w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-768x432.jpg 768w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-384x216.jpg 384w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-1152x648.jpg 1152w, https://cdn.arstechnica.net/wp-content/uploads/2024/11/anthropic_constitution_red-980x551.jpg 980w" sizes="(max-width: 1200px) 100vw, 1200px">
              </a></p><div id="caption-2061278"><p>
                Anthropic's "Constitutional AI" logo.
                                  </p><p>
                    Credit:
                                          Anthropic / Benj Edwards
                                      </p>
                              </div>
            </div>
                  <figcaption>
          <div>
    
    <p>
      Anthropic's "Constitutional AI" logo.

              <span>
          Credit:

          
          Anthropic / Benj Edwards

                  </span>
          </p>
  </div>
        </figcaption>
            </figure>

<p>Aside from the implications of working with defense and intelligence agencies, the deal connects Anthropic with Palantir, a <a href="https://amp.theguardian.com/commentisfree/2020/sep/04/palantir-ipo-ice-immigration-trump-administration">controversial company</a> which <a href="https://defensescoop.com/2024/05/29/palantir-480-million-army-contract-maven-smart-system-artificial-intelligence/">recently won</a> a $480 million contract to develop an AI-powered target identification system called Maven Smart System for the US Army. Project Maven has <a href="https://www.reuters.com/article/business/media-telecom/google-to-scrub-us-military-deal-protested-by-employees-source-idUSL2N1T320P/">sparked criticism</a> within the tech sector over military applications of AI technology.</p>
<p>It's worth noting that Anthropic's terms of service <a href="https://www.anthropic.com/news/expanding-access-to-claude-for-government">do outline</a> specific rules and limitations for government use. These terms permit activities like foreign intelligence analysis and identifying covert influence campaigns, while prohibiting uses such as disinformation, weapons development, censorship, and domestic surveillance. Government agencies that maintain regular communication with Anthropic about their use of Claude may receive broader permissions to use the AI models.</p>
<p>Even if Claude is never used to target a human or as part of a weapons system, other issues remain. While its Claude models are highly regarded in the AI community, they (like all LLMs) have the tendency to <a href="https://arstechnica.com/information-technology/2023/04/why-ai-chatbots-are-the-ultimate-bs-machines-and-how-people-hope-to-fix-them/">confabulate</a>, potentially generating incorrect information in a way that is difficult to detect.</p>
<p>That's a huge potential problem that could impact Claude's effectiveness with secret government data, and that fact, along with the other associations, has Futurism's Victor Tangermann worried. As he puts it, "It's a disconcerting partnership that sets up the AI industry's growing ties with the US military-industrial complex, a worrying trend that should raise all kinds of alarm bells given the tech's many inherent flaws—and even more so when lives could be at stake."</p>


          
                  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Staff Engineer? (129 pts)]]></title>
            <link>https://nishtahir.com/what-is-a-staff-engineer/</link>
            <guid>42090771</guid>
            <pubDate>Fri, 08 Nov 2024 21:55:40 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nishtahir.com/what-is-a-staff-engineer/">https://nishtahir.com/what-is-a-staff-engineer/</a>, See on <a href="https://news.ycombinator.com/item?id=42090771">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <!--kg-card-begin: markdown--><blockquote>
<p><em>"I've worked with a couple of Staff Engineers on different teams in the past and I've seen them do different things, but I've not been able to pin down exactly what they do."</em></p>
</blockquote>
<p>I get this question quite frequently. Sometimes from engineers looking to elevate their roles. At other times, team members reach out looking to learn how they could get the most value from Staff Engineers on the teams. It is a complicated question because a lot of ambiguity exists in the role. Different engineers have distinct interpretations, so you may get a significantly different answer depending on who you ask. With that in mind, I wanted to capture my thoughts on the subject. It's deep, complex, and nuanced. As a result, I'm likely to be as successful as someone attempting to unravel the mysteries of Engineering Management <sup><a href="#fn1" id="fnref1">[1]</a></sup> in a single blog post.</p>
<p>To lay some foundation, I'll be describing a class of engineers as <em>Staff Plus</em> (Staff+). These engineers operate above the Senior level. However, they do not assume the role of an Engineering Manager. These engineers often aim to stay within the technical track of an organization's career ladder. While there is currently no universally accepted title for this role <sup><a href="#fn2" id="fnref2">[2]</a></sup>, successful individuals I've seen in this role tend to share notable common traits</p>
<ul>
<li>They are proven experts in their area of expertise</li>
<li>They have a lot of experience leading teams toward shipping products</li>
</ul>
<h2 id="characterizing-a-staff-engineer">Characterizing a Staff+ Engineer</h2>
<p>One of my favorite ways to characterize the Staff+ role is by using the "4 key skills <sup><a href="#fn3" id="fnref3">[3]</a></sup> every job needs". It provides a solid framework that we can use to determine the distribution of skills one would need to be successful in the role.</p>
<p><img src="https://nishtahir.com/content/images/2023/01/four_skills_every_job_needs.png" alt="four_skills_every_job_needs" loading="lazy"></p>
<h2 id="core-technical-skill">Core Technical Skill</h2>
<p>This is the foundational skill needed to execute the role effectively and one that the Staff+ Engineer should be highly proficient in. In my experience, this level requires deep technical knowledge in some specialty<sup><a href="#fn4" id="fnref4">[4]</a></sup>, and it is often accompanied by a wide breadth of knowledge and experience working with multiple different systems within multiple different environments<sup><a href="#fn5" id="fnref5">[5]</a></sup>. This is the wealth of experience that the Staff+ Engineer reaches into to solve complex technical problems that contribute toward furthering their team's objectives. While I cannot overstate the importance of this skill as a foundational element of the role, it's not enough to be successful on its own. It must be fluidly combined with other skills to empower the Staff+ Engineer to fluidly adapt to different roles on the team, some of which I will cover below.</p>
<h2 id="product-management">Product Management</h2>
<p>A Staff+ Engineer relies on this skill to determine what should be built as well as why. At this level, the Staff+ Engineer should be capable of looking at a team, project, and/or organization's objectives, gaining some understanding of its history, and developing a technical vision<sup><a href="#fn6" id="fnref6">[6]</a></sup> to meet those objectives<sup><a href="#fn7" id="fnref7">[7]</a></sup>. A skilled Staff+ Engineer should be able to communicate this vision to their stakeholders, as well as other parties that may have a stake in the outcome, and get buy-in from all parties, especially the engineering team that will be responsible for building the solution. This role may sometimes manifest as a Technical Architect<sup><a href="#fn8" id="fnref8">[8]</a></sup>.</p>
<h2 id="project-management">Project Management</h2>
<p>This skill helps the Staff+ engineer break down large work items into smaller more manageable tasks for more junior members of the team, create a plan/timeline for completion that can be tracked, as well as manage uncertainties/risks that may deter completion of the work. Proficiency in this skill requires a mastery of basic project management fundamentals <sup><a href="#fn9" id="fnref9">[9]</a></sup>. This does not mean that Staff+ Engineers should be expected to replace project managers; rather these roles should be seen as complementary.</p>
<h2 id="people-management">People Management</h2>
<p>This includes the ability to rally and lead a team toward completing a set of objectives. I've heard this fondly described as "herding cats"<sup><a href="#fn10" id="fnref10">[10]</a></sup>. While I don't think a Staff+ engineer in this role is required to assume full people management responsibilities (that's what Managers are for), there is notably a lot of overlap. For example, I would expect an engineer operating at this level to be an effective mentor, able to provide technical and a reasonable extent of career guidance. This skill also requires having a solid awareness of the team's composition. This includes the skills makeup, strengths as well as growth areas. At this level, the Staff+ engineer should be able to use this awareness to elevate the effectiveness of the team through coaching and mentoring.</p>
<h2 id="youre-rubber-im-glue">You're rubber, I'm glue</h2>
<blockquote>
<p><em>"I feel like they do a little bit of everything. They seem to be the go-to on the team when there's an issue. They are like a rock with all the answers!"</em></p>
</blockquote>
<p>I've found that a key aspect of my day-to-day is autonomously combining these skills to fill roles that may find difficult to fill. It's often the less glamorous but high-value work that is required to build or maintain team momentum. This is sometimes described as "glue" work.</p>
<blockquote>
<p><em>"Every senior person in an organisation should be aware of the less glamorous - and often less-promotable - work that needs to happen to make a team successful. Managed deliberately, glue work demonstrates and builds strong technical leadership skills. Left unconscious, it can be career limiting."</em><sup><a href="#fn11" id="fnref11">[11]</a></sup></p>
</blockquote>
<p>Doing glue work often requires a cross-functional grasp of how the team operates as well as deep insight into areas of the team that may require optimization. Here are a couple of scenarios that exemplify glue work,</p>
<ol>
<li>You notice that a couple of email threads between your engineers and a 3rd party vendor have been running long. They seem to be talking past each other without making any headway. You decide to help improve the situation by scheduling a couple of meetings to help foster alignment and develop a culture of partnership between the teams.</li>
<li>You notice an up tick in the number of bug tickets being written about a feature in the product. After a brief investigation, you find that area of the code lacks automated tests because of a dependency on a third-party framework and will require some rework to make it testable. The development team needs some coaching on how to handle these sorts of problems in the future and a plan needs to be drafted and communicated to the leadership team. There's some upfront cost but will pay for itself in fewer bug tickets down the road.</li>
<li>A team member has been struggling with a new aspect of their assignment. They are unsure of what specific skills they need to learn to be most effective. So you help by offering some light coaching by offering some resources that help them get up to speed quickly as well as setting up 1:1s where they can ask questions and get feedback.</li>
<li>Your team was asked to build a tool that aggregates data for marketing and Business Intelligence (BI). The requirements were vague but enough for the engineering team to work on. Noticing the potential for improvement, you schedule meetings with representatives from the marketing and BI team to better understand how the aggregated data will be used to provide a better product.</li>
</ol>
<p>While one could argue that this work has a high-value impact on the team, it may be tough to justify having the Staff+ Engineer function doing any one of those things in the long term. As a result, a crucial part of the role is leveling up the team such that they may take over such responsibilities such that the Staff+ Engineer may shift their focus towards tackling other priorities. It may be by coaching an existing team member to own one of those tasks or working with the leadership team to staff a new permanent owner.</p>
<h2 id="conclusion">Conclusion</h2>
<blockquote>
<p><em>"I forget what was said exactly, but [Staff+ Engineer] spoke up and said something with clarity and confidence that changed the conversation to be much more productive. They were thoughtful with their comments and have a keen ability to drive toward clarity in a room of swirling indecision."</em></p>
</blockquote>
<p>I've only scratched the surface here, but hope I've captured some specific nuances in the role. Ultimately I think a Staff+ Engineer should be able to use their autonomy and influence within an organization and turn that into meaningful impact and value in service of a team or organization's objectives.</p>
<p>Here are a couple of great resources that I recommend if you are interested in learning more.</p>
<ol>
<li><a href="https://learning.oreilly.com/library/view/the-staff-engineers/9781098118723/?ref=nishtahir.com">The Staff Engineers Path</a> by Tanya Rielly</li>
<li><a href="https://staffeng.com/book?ref=nishtahir.com">Staff Engineer: Leadership beyond the management track</a> by Will Larson</li>
</ol>
<p>To wrap things up, I'm adding an assorted collection of questions I've gotten recently. This is either because I couldn't figure out a way to answer it directly within the context of this blog post or because I thought it may add additional perspective to address the question directly.</p>
<h2 id="faq">FAQ</h2>
<ol>
<li>
<blockquote>
<p>Does Staff+ Engineering require mentoring responsibilities?</p>
</blockquote>
</li>
</ol>
<p>Yes. I think this is a non-negotiable part of the role. The ability to elevate a team's capability is predicated on being a good mentor. In essence, the ability to identify strengths and growth areas on the team. Additionally, creating opportunities for team members to learn and grow.</p>
<ol start="2">
<li>
<blockquote>
<p>What kinds of teams need a Staff+ Engineer?</p>
</blockquote>
</li>
</ol>
<p>A Staff+ Engineer can exist on any team in theory. However, their role will depend on the specific team composition. The Staff+ Engineer may be the main Individual Contributor (IC) on a small team working on a proof of concept for some experimental technology, while a Staff+ Engineer may act as a technical lead on a larger team trying to build long-term momentum. The opportunity cost is the Staff+ Engineer's time and must be considered when making staffing decisions. Could a Senior Engineer be sourced to fill the IC role? This would free up the Staff+ Engineer to work on more complex or higher value problems for the project.</p>
<ol start="3">
<li>
<blockquote>
<p>What differentiates senior levels of Staff Engineers?</p>
</blockquote>
</li>
</ol>
<p>The main differentiator is their scope of impact. More senior Staff+ Engineers should be able to have and manage an impact on an organization or company, in some cases an industry at large. Being able to build and leverage their influence to guide a technical direction is a skill in and of itself</p>
<ol start="4">
<li>
<blockquote>
<p>Hmm... It looks like you went over a lot of general points but didn't address a lot of specific expectations of the role</p>
</blockquote>
</li>
</ol>
<p>This is because the nature of the role changes with each individual and circumstance. This means that being able to adapt to each circumstance is important. That being said, I think the most important thing is that the Staff+ Engineer can turn autonomy into meaningful impact at a scale proportional to their role/level.</p>
<ol start="5">
<li>
<blockquote>
<p>I stayed on the technical track with I got promoted because I wanted to continue to write code. How do I balance leadership responsibilities but still retain coding in my day-to-day?</p>
</blockquote>
</li>
</ol>
<p>I would argue that at this level, your leadership skills are likely your most valuable asset. Trying to keep hands-on-keyboard writing code a major part of your role may not be using your talents to their full potential. However, your day-to-day should be determined by the team/project needs while considering that time dedicated towards work that an IC would typically do comes at the cost of glue work and other higher-level work that may require your attention. This is not to say that you should be completely removed from the code avenues such as working on future work such as PoCs or lower priority features as you have availability might be great ways to keep you engaged in writing code.</p>
<hr>
<section>
<ol>
<li id="fn1"><p><a href="https://dzone.com/articles/the-art-of-engineering-management?ref=nishtahir.com">Chegini, A. (2022) The art of engineering management, dzone.com. DZone. Available at: https://dzone.com/articles/the-art-of-engineering-management (Accessed: January 24, 2023)</a> <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>Some alternate titles I've encountered include Lead Engineer/Developer, Principal/Distinguished Engineer, Technical Fellow, etc... <a href="#fnref2">↩︎</a></p>
</li>
<li id="fn3"><p><a href="https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff?ref=nishtahir.com">Zunger, Y. (no date) Role and Influence: The IC trajectory beyond Staff, Leaddev.com. Available at: https://leaddev.com/leaddev-live/role-and-influence-ic-trajectory-beyond-staff (Accessed: January 24, 2023).</a> <a href="#fnref3">↩︎</a></p>
</li>
<li id="fn4"><p><a href="https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/?ref=nishtahir.com">Woodhams, B. (2018) Balance between breadth and depth of learning software development, candidates. Available at: https://hired.com/blog/candidates/balance-breadth-depth-learning-software-development/ (Accessed: January 24, 2023).</a> <a href="#fnref4">↩︎</a></p>
</li>
<li id="fn5"><p>This may be different in your organization and your specific personality <a href="#fnref5">↩︎</a></p>
</li>
<li id="fn6"><p><a href="https://lethain.com/what-do-staff-engineers-actually-do/?ref=nishtahir.com">What do Staff engineers actually do? (2020) Lethain.com. Available at: https://lethain.com/what-do-staff-engineers-actually-do/ (Accessed: January 24, 2023).</a> <a href="#fnref6">↩︎</a></p>
</li>
<li id="fn7"><p><a href="https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/?ref=nishtahir.com">Micol, D. (2021) Writing our 3-year technical vision, Engineering Blog. Available at: https://www.eventbrite.com/engineering/writing-our-3-year-technical-vision/ (Accessed: January 24, 2023).</a> <a href="#fnref7">↩︎</a></p>
</li>
<li id="fn8"><p><a href="https://www.lucidchart.com/blog/defining-technical-architects?ref=nishtahir.com">Rethinking the role of the technical architect (2021) Lucidchart. Available at: https://www.lucidchart.com/blog/defining-technical-architects (Accessed: January 24, 2023).</a> <a href="#fnref8">↩︎</a></p>
</li>
<li id="fn9"><p><a href="https://www.northeastern.edu/graduate/blog/essential-project-management-skills/?ref=nishtahir.com">Joubert, S. (2019) Project management skills, Northeastern University Graduate Programs. Available at: https://www.northeastern.edu/graduate/blog/essential-project-management-skills/ (Accessed: January 24, 2023).</a> <a href="#fnref9">↩︎</a></p>
</li>
<li id="fn10"><p><a href="https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/?ref=nishtahir.com">Tech lead engineer - herding cats &amp; drinks - Front End Happy Hour (no date) Frontendhappyhour.com. Available at: https://www.frontendhappyhour.com/episodes/tech-lead-engineer-herding-cats-&amp;-drinks/ (Accessed: January 25, 2023).</a> <a href="#fnref10">↩︎</a></p>
</li>
<li id="fn11"><p><a href="https://noidea.dog/glue?ref=nishtahir.com">Being Glue — (no date) No Idea Blog. Available at: https://noidea.dog/glue (Accessed: January 25, 2023).</a> <a href="#fnref11">↩︎</a></p>
</li>
</ol>
</section>
<!--kg-card-end: markdown-->
        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[My Notes on Apple Math Notes (141 pts)]]></title>
            <link>https://mlajtos.mu/posts/new-kind-of-paper-5</link>
            <guid>42090633</guid>
            <pubDate>Fri, 08 Nov 2024 21:31:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mlajtos.mu/posts/new-kind-of-paper-5">https://mlajtos.mu/posts/new-kind-of-paper-5</a>, See on <a href="https://news.ycombinator.com/item?id=42090633">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<div><div><p>September 24, 2024</p><!-- --><p> · </p><!-- --><p>Milan Lajtoš</p></div><p><span>new kind of paper</span><span>, </span><span>thinking</span><span>, </span><span>computation</span><span>, </span><span>paper &amp; pencil</span><span>, </span><span>human-computer interaction</span><span>, </span><span>Apple</span></p></div>
<p>In the previous parts (<a href="https://mlajtos.mu/posts/new-kind-of-paper">1</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">2</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-3">3</a>, <a href="https://mlajtos.mu/posts/new-kind-of-paper-4">4</a>) written in 2021, I described <strong>New Kind of Paper</strong> – an app that enhances <strong>paper &amp; pencil</strong>, the best medium for thinking, with the capabilities of a crazy <strong>advanced calculator</strong>.</p>
<p>In 2024, Apple introduced their spin on this topic under the name <strong>Math Notes</strong>. In this article, I will provide my <strong>deep praise (and even deeper hate)</strong> for their attempt to bring a bit of <strong>innovation into the UX of math</strong>.</p>
<hr>
<p>Let's start with a <strong>simple example</strong> of how Math Notes works...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/0-8601d68a71218ed6ce2ff0869d1845c8.mov" poster="https://mlajtos.mu/_next/static/media/0.7b1a32c5.png" preload="none"></video><figcaption>Writing a math expression in Apple Math Notes</figcaption></figure>
<p>It <span>*fucking*</span> works! 🥹</p>
<p>At first glance, it may not seem like much, but in this brief example, a lot has happened. First, the handwriting recognition worked flawlessly, despite my awful handwriting. It perfectly recognized what I meant by those scratch marks. Second, after I wrote the trigger symbol, <code>=</code> (the equal sign), the expression was evaluated, and the result was inserted inline, mimicking my handwriting style. The inline insertion could be improved to better match the handwriting style, but overall, this is basically magic. With my writing magic wand, I have conjured up a little computational spell. 🪄</p>
<p>The fact that millions of people have this technology at their fingertips and pencil tips (works both on iPads &amp; iPhones too), is a major miracle. The democratization of this technology is the hardest part, and it is in the hands of the people who know how to get shit done. Maybe not on the first try, but the third iteration... <span><em>*chef's kiss*</em></span></p>
<h2>Too Magical &amp; Not Alive Enough</h2>
<p><strong>How do you know that the result is correct?</strong> The calculation is definitely correct, but how can you trust your calculator to recognize your badly handwritten "1" as "1" and not as "7"? You simply don't. This is essentially Apple claiming that their handwriting recognition is infallible. It's a rather bold claim, don't you think? I appreciate the confidence, but I don't believe we have reached that level of accuracy yet. Even basic calculators indicate which button you (mis-)pressed.</p>
<p><strong>Why does it appear lifeless most of the time?</strong> If you only saw the first 90% of that demonstration, you wouldn't even know if this thing works. Honestly, it seemed dead most of the time. And when the result finally appeared, it was accompanied by flashy animation. 🫣 I love the animation, and I understand why it adds a nice touch to the initial version, but it's really just a distraction. This calculator should feel MORE alive!</p>
<p>Of course, talk is cheap, so let me demonstrate what I mean:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-a218e67f18e4f4486a486defaa970615.mp4" poster="https://mlajtos.mu/_next/static/media/1.7046d6ac.png" preload="none"></video><figcaption>Writing a math expression with live feedback (<a href="https://mlajtos.mu/posts/new-kind-of-paper-2">source</a>, 2021)</figcaption></figure>
<p><strong>Not as polished, but it is alive!</strong> And snappy. And colorful. The feedback is immediate, and you can see the result as you write. This kind of feedback instills trust in the system and gives you a sense of control. Of course, Apple will fix these issues differently...</p>
<p>The first problem – whether the system recognized your handwriting correctly – can be solved with another iPadOS feature called Smart Script. It lets you beautify your handwriting – simply write an ugly "1" and it will progressively transform the scribble into neatly handwritten "1" or "7". The point is to inform the user, give them feedback on how the system recognized the symbol. This helps tremendously with the trust issue.</p>
<p>The second problem, the missing liveness, is even easier to solve – just ditch the "=" and evaluate the expression when the user pauses. Not too eager, not too lazy. This "interactive" mode can be simulated in Math Notes with this technique:</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/7-b425cecd44d2f48d757ebb2aea627c14.mov" poster="https://mlajtos.mu/_next/static/media/7.b98d48de.png" preload="none"></video><figcaption>"Interactive" mode in Math Notes<br><span>&amp; number of WTF moments</span></figcaption></figure>
<h2>Scratch to Delete</h2>
<p>*no comment*</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/1-1dfb304ebcd57e666ca89e09b4b70b33.mov" poster="https://mlajtos.mu/_next/static/media/1.7fd6e9b0.png" preload="none"></video><figcaption>Unnecessary switching between writing and erasing<br><span>&amp; 2-second long inconsistent state</span></figcaption></figure>
<h2>The Math You Know™</h2>
<h3>2D notation</h3>
<p>Math Notes supports 2D notation – you can write exponents as superscript, use fractions, etc. You know, the usual scary math stuff:</p>
<figure><div><p><img alt="log_2(2^10 / 2) = 9" loading="lazy" width="358.5" height="200.5" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=384&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F3.df76e21a.jpeg&amp;w=750&amp;q=75"></p></div><figcaption>Example of 2D notation: Relation between exponentiation, divison, and logarithm.<br><span>Every operation has different 2D representation.</span></figcaption></figure>
<p>I know how crazy difficult this must have been to pull off. <span>*Bravo!*</span></p>
<h3>PEMDAS</h3>
<p>PEMDAS – the order of operations: <strong>P</strong>arentheses, <strong>E</strong>xponents, <strong>M</strong>ultiplication/<strong>D</strong>ivision, <strong>A</strong>ddition/<strong>S</strong>ubtraction. It's everywhere. It's in our textbooks, our calculators, programming languages and now even in Apple's Math Notes. <span>*sigh*</span></p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/2-d47b8c3b0a560012784715d75efa08ee.mov" poster="https://mlajtos.mu/_next/static/media/2.6ce2b48c.png" preload="none"></video><figcaption>Illustration of operator precedence</figcaption></figure>
<h3>The Future of Math Notation</h3>
<p>Supporting the traditional handwritten math notation is no easy task. It is extremely messy, inconsistent and sometimes ambiguous. However, a calculator that wants to be useful must support ideas that have been forged for centuries. It is hard to change math.</p>
<p>When math started to become executable in form of software &amp; hardware, we developed consistent notation that was shaped by keyboards, not by pencils. We migrated from 2D into 1D, misused some glyphs, and introduced constructs that made sense for computing. Math definitely adapted to this new medium.</p>
<p>Math Notes embodies even newer medium on which math can grow and change. While supporting existing traditional notation is a must, adding ability to define custom notation is an aspiration. We can't evolve math if the medium does not allow it. Today, the notation in Math Notes is fixed and it doesn't even cover a lot of useful math (e.g. calculus). This is fine in the short term, but if we are serious, we should start to think about user-definable 2D notation. Heck, even user-definable operators (e.g. <code>≈</code> or <code>⊙</code>) would be a good first step.</p>
<p>While Math Notes isn't doing anything on this front yet, Apple leaned heavily into different direction...</p>
<h2>Dynamic Scribbles</h2>
<p>Since we are not stuck with static scribbles on the paper, Math Notes supports some dynamic behaviors, e.g. changing a numeric value just by dragging a slider.</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/4-67b47bb57bbaee5b32156324a02cd185.mov" poster="https://mlajtos.mu/_next/static/media/4.3af29c54.png" preload="none"></video><figcaption>Simple means of "solving".<br><span>Circular knob with different speeds might be better in the long-term,<br> but the slider is a great choice for first iteration.</span></figcaption></figure>
<p>Or graphing a function...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/5-35e4fbbd8d953708a710ff81dc9844f7.mov" poster="https://mlajtos.mu/_next/static/media/5.50a8d043.png" preload="none"></video><figcaption>Term "graphing calculator" has a new meaning now.</figcaption></figure>
<p>These are fantastic features that millions of people will love. With just a scribble and touch of a finger, I can solve non-trivial computational problems. Can you imagine the effort, if you wanted to achieve the same thing in e.g. Python? <span><em>*Bleh..*</em></span></p>
<p>However, graphs are dead – they do not respond to changing coefficients...</p>
<figure><video controls="" src="https://mlajtos.mu/_next/static/videos/8-cc08b6635b462f3697d8c2027d7e0e76.mov" poster="https://mlajtos.mu/_next/static/media/8.43e7c2c7.png" preload="none"></video><figcaption>Graphs in Math Notes are useful, but dead.</figcaption></figure>
<h3>λλλ</h3>
<p>One obvious omission in this part of Math Notes, is proper function definition. Define a function, see its graph, and be able to evaluate it with a specific input value. You know, something like this...</p>
<figure><div><p><img alt="fn(x)=10*x; a=1; b=fn(a); b=10" loading="lazy" width="592" height="313" decoding="async" data-nimg="1" srcset="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=640&amp;q=75 1x, https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75 2x" src="https://mlajtos.mu/_next/image?url=%2F_next%2Fstatic%2Fmedia%2F6.8dd4f17d.png&amp;w=1200&amp;q=75"></p></div><figcaption>Mockup of a better function definition.<br><span>Showing a point at [1, 10] would be neat...</span></figcaption></figure>
<p>This notation for function definition (or lambdas/λ in comp-sci jargon) is pretty understandable and supports multiple arguments. Also, it opens up a route to primitive custom (infix) operators.</p>
<hr>
<h2>Solving Way Harder Stuff</h2>
<p>All these features are hinting at a calculator that is a good companion for a mind that wants to solve problems that can be turned into a computation. So far, the capabilities of Math Notes are pretty limited – e.g. <a href="https://mlajtos.mu/posts/new-kind-of-paper-2">how would you sum up numbers from 1 to 100?</a> That is a pretty easy computational problem, but you can't solve it easily with this type of calculator – yet.</p>
<p>However, "solving" is much broader topic than a straight-to-an-answer computation. What about problems that involves optimizing a function with thousand of parameters in an iterated manner? This problem-solving technique is currently limited to small set of smart people. Math Notes could unlock it for much broader, and younger audience. Like Excel did open up sophisticated computation for mere mortals. But this time in a much more humane way.</p>
<h2>∞ Amount of Constructive Criticism...</h2>
<p>I have been thinking about this type of calculator for many many years, and I am extremely happy to see this <strong>new kind of calculator</strong> in the wild. I want to see it used by everybody – from curious 5 year olds to PhD-level proffesionals in the science &amp; engineering. Solving our personal problems and civilization-level ones too.</p>
<blockquote>
<p>We can only see a short distance ahead, but we can see plenty there that needs to be done.</p>
<p>– Alan Turing</p>
</blockquote>
<hr>
<p>Do you have ideas about this kind of stuff? Please share them online!</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I quit Google to work for myself (2018) (302 pts)]]></title>
            <link>https://mtlynch.io/why-i-quit-google/</link>
            <guid>42090430</guid>
            <pubDate>Fri, 08 Nov 2024 20:59:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mtlynch.io/why-i-quit-google/">https://mtlynch.io/why-i-quit-google/</a>, See on <a href="https://news.ycombinator.com/item?id=42090430">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>For the past four years, I’ve worked as a software developer at Google. On February 1st, I quit. It was because they refused to buy me a Christmas present.</p><p>Well, I guess it’s a little more complicated than that.</p><h2 id="the-first-two-years">The first two years<a href="#the-first-two-years" arialabel="Anchor"> 🔗︎</a></h2><p>Two years in, I loved Google.</p><p>When the annual employee survey asked me whether I expected to be at Google in five years, it was a no-brainer.</p><p>Of <em>course</em> I’d still be at Google in five years. I was surrounded by the best engineers in the world, using the most advanced development tools in the world, and eating the free-est food in the world.</p><p><a href="https://mtlynch.io/why-i-quit-google/spoiled-coder.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/spoiled-coder_hu4f194abb4e8e6858d1fbc287ed8a6d8e_188016_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/spoiled-coder.png 1024w" src="https://mtlynch.io/why-i-quit-google/spoiled-coder.png" alt="My typical day at Google" loading="lazy"></a></p><p>My most recent performance rating was “Strongly Exceeds Expectations.” If I just kept going, I’d soon be promoted to the next level, Senior Software Engineer. What a great title! Forever after in my career, I’d be able to say, “Yes, I was a <em>Senior</em> Software Engineer. At <em>Google</em>.” People would be so impressed.</p><p>My manager assured me that my promotion was close. He felt that I was already capable of senior-level work. I just needed the right project to prove it to the promotion committee.</p><p>No, managers at Google can’t promote their direct reports. They don’t even get a vote.</p><p>Instead, promotion decisions come from small committees of upper-level software engineers and managers who have never heard of you until the day they decide on your promotion.</p><p>You apply for promotion by assembling a “promo packet”: a collection of written recommendations from your teammates, design documents you’ve created, and mini-essays you write to explain why your work merits a promotion.</p><p>A promotion committee then reviews your packet with a handful of others, and they spend the day deciding who gets promoted and who doesn’t.</p><p>During my two-year honeymoon phase, this system sounded great to me. Of <em>course</em> my fate should be in the hands of a mysterious committee who’s never met me. They wouldn’t be tainted by any sort of favoritism or politics. They’d see past all that and recognize me for my high-quality code and shrewd engineering decisions.</p><h2 id="thats-not-really-how-it-works">That’s not really how it works<a href="#thats-not-really-how-it-works" arialabel="Anchor"> 🔗︎</a></h2><p>Before I put together my first promo packet, I never thought about the logistics of how it all worked.</p><p>In my head, the promotion committee was this omniscient and fair entity. If I spent each day choosing the right problems to solve, making the codebase better, and helping my team execute efficiently, the promotion committee would magically know this and reward me for it.</p><p>Unsurprisingly, it doesn’t work like that. It took me two years to figure that out.</p><h2 id="working-naïvely">Working naïvely<a href="#working-naïvely" arialabel="Anchor"> 🔗︎</a></h2><p>My main responsibility until that point was a legacy data pipeline. It had been in maintenance mode for years, but load had increased, and the pipeline was buckling under the pressure. It frequently died silently or produced incorrect output. Its failures took days to diagnose because nobody had written documentation for it since its original design spec.</p><p>I proudly and lovingly nursed the pipeline back to health. I fixed dozens of bugs and wrote automated tests to make sure they wouldn’t reappear. I deleted thousands of lines of code that were either dead or could be replaced by modern libraries. I documented the pipeline as I learned it so that the institutional knowledge was available to my teammates instead of siloed in my head.</p><p>The problem, as I discovered at promotion time, was that none of this was quantifiable. I couldn’t prove that anything I did had a positive impact on Google.</p><h2 id="metrics-or-it-didnt-happen">Metrics or it didn’t happen<a href="#metrics-or-it-didnt-happen" arialabel="Anchor"> 🔗︎</a></h2><p>The pipeline didn’t record many metrics. The ones it did have made it look like things had gotten worse. My bug discoveries caused the overall bug count to increase. The pipeline’s failures increased because I made it fail fast on anomalies instead of silently passing along bad data. I drastically reduced the time developers spent repairing those failures, but there were no metrics that tracked developer time.</p><p>My other work didn’t look so good on paper either. On several occasions, I put my projects on hold for weeks or even months at a time to help a teammate whose launch was at risk. It was the right decision for the team, but it looked unimpressive in a promo packet. To the promotion committee, my teammate’s project was the big, important work that demanded coordination from multiple developers. If they hornswoggled me into helping them, it’s evidence of their strong leadership qualities. I was just the mindless peon whose work was so irrelevant that it could be pre-empted at a moment’s notice.</p><p>I submitted my first promo packet, and the results were what I feared: the promotion committee said that I hadn’t proven I could handle technical complexity, and they couldn’t see the impact I had on Google.</p><p><a href="https://mtlynch.io/why-i-quit-google/promo-committee.png"><img sizes="(min-width: 768px) 800px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/promo-committee_hu7b22fcc95e2f40d7ada24e83ce6de553_523971_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/promo-committee.png 1024w" src="https://mtlynch.io/why-i-quit-google/promo-committee.png" alt="Arguing my case to the promotion committee" loading="lazy"></a></p><h2 id="learning-from-rejection">Learning from rejection<a href="#learning-from-rejection" arialabel="Anchor"> 🔗︎</a></h2><p>The rejection was a difficult blow, but I wasn’t discouraged. I felt I was performing above my level, but the promotion committee couldn’t see it. That was solvable.</p><p>I decided that I had been too naïve in my first couple years. I didn’t do enough planning up front to make sure the work I was doing left a paper trail. Now that I understood how the process worked, I could keep doing the same good work, just with better record-keeping.</p><p>For example, my team was receiving tons of distracting email alerts due to false alarms. Old me would have just fixed these alerts. But now I knew that for this work to appear in my promo packet, I should first set up metrics so that we’d have historical records of alert frequency. At promotion time, I’d have an impressive-looking graph of the alerts trending downward.</p><p>Shortly after, I was assigned a project that seemed destined for promotion. It depended heavily on machine-learning, which was and still is the hot thing at Google. It would automate a task that hundreds of human operators were doing manually, so it had a clear, objective impact on Google. It also required me to lead a junior developer throughout the project, which generally won points with promotion committees.</p><h2 id="the-holiday-gift-wake-up-call">The holiday gift wake up call<a href="#the-holiday-gift-wake-up-call" arialabel="Anchor"> 🔗︎</a></h2><p>A few months later, Google <a href="http://fortune.com/2016/12/09/alphabet-donated-its-employees-holiday-gifts-to-charity/">made headlines</a> when they ended their long-standing tradition of giving lavish holiday gifts to all of their employees. Instead, they used the gift budget to buy <del>advertising disguised as charity</del> Chromebooks for underprivileged schoolchildren.</p><p>Shortly after this, I witnessed the following conversation between two employees:</p><blockquote><p><strong>Employee A</strong>: You effectively <strong>are</strong> still getting the gift. Cuts like these increase the value of Google’s stock. You can sell your stock grants and buy any present you choose.</p><p><strong>Employee B</strong>: What if I told my wife that I wasn’t buying her a Christmas gift, but she could use the money in our bank account to buy any present she wants?</p><p><strong>Employee A</strong>: You’re in a <strong>business</strong> relationship with Google. If you’re disappointed that Google isn’t “romancing” you with gifts like you do for your wife, you have a misguided notion of the relationship.</p></blockquote><p>Wait a second. <em>I</em> was in a business relationship with Google.</p><p>It may sound strange that it took me two and a half years to realize it, but Google does a good job of building a sense of community within the organization. To make us feel that we’re not just employees, but that we <em>are</em> Google.</p><p>That conversation made me realize that I’m <em>not</em> Google. I provide a service to Google in exchange for money.</p><p>So if Google and I have a business relationship that exists to serve each side’s interests, why was I spending time on all these tasks that served Google’s interests instead of my own? If the promotion committee doesn’t reward bugfixing or team support work, why was I doing that?</p><p>My first denied promotion taught me the wrong lesson. I thought I could keep doing the same work but package it to look good for the promotion committee. I should have done the opposite: figure out what the promotion committee wants, and do that work exclusively.</p><p>I adopted a new strategy. Before starting any task, I asked myself whether it would help my case for promotion. If the answer was no, I didn’t do it.</p><p>My quality bar for code dropped from, “Will we be able to maintain this for the next 5 years?” to, “Can this last until I’m promoted?” I didn’t file or fix any bugs unless they risked my project’s launch. I wriggled out of all responsibilities for maintenance work. I stopped volunteering for campus recruiting events. I went from conducting one or two interviews per week to zero.</p><h2 id="then-my-project-was-canceled">Then my project was canceled<a href="#then-my-project-was-canceled" arialabel="Anchor"> 🔗︎</a></h2><p>Priorities shifted. Management traded my project away to our sister team in India. In exchange, that team gave us one of their projects. It was an undocumented system, built on deprecated infrastructure, but it was nevertheless a critical component in production. I was assigned to untangle it from our sister team’s code and migrate it to a new framework, all while keeping it running in production and hitting its performance metrics.</p><p>As far as my promotion was concerned, this was a setback of several months. Because I hadn’t released anything for my canceled project, the two months I spent on it were worthless. It would take me weeks just to get up to speed on the system I was inheriting, and I was liable to lose several more in the gruntwork of keeping it operational.</p><h2 id="what-am-i-even-doing">What am I even doing?<a href="#what-am-i-even-doing" arialabel="Anchor"> 🔗︎</a></h2><p>It was the third time in six months that my manager had reassigned me midway through a project. Each time, he assured me that it had nothing to do with the quality of my work, but rather some shift in upper management strategy or team headcount.</p><p>At this point, I took a step back to assess what was happening from a high level. Forget my manager, forget his managers, forget the promotion committee. What if I boiled it down to just me and just Google? What was happening in our “business relationship?”</p><p>Well, Google kept telling me that it couldn’t judge my work until it saw me complete a project. Meanwhile, I couldn’t complete any projects because Google kept interrupting them midway through and assigning me new ones.</p><p>The dynamic felt absurd.</p><p><a href="https://mtlynch.io/why-i-quit-google/book-publisher.png"><img sizes="(min-width: 768px) 750px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/book-publisher_hu67c1fce3e1f8685743944e5c14f41bdf_378594_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/book-publisher.png 1024w" src="https://mtlynch.io/why-i-quit-google/book-publisher.png" alt="The Google promotion committee approach to book publishing" loading="lazy"></a></p><p>My career was being dictated by a shifting, anonymous committee who thought about me for an hour of their lives. Management decisions that I had no input into were erasing months of my career progress.</p><p>Worst of all, I wasn’t proud of my work. Instead of asking myself, “How can I solve this challenging problem?” I was asking, “How can I make this problem <em>look</em> challenging for promotion?” I hated that.</p><p>Even if I got the promotion, what then? Popular wisdom said that each promotion was exponentially harder than the last. To continue advancing my career, I’d need projects that were even larger in scope and involved collaboration with more partner teams. But that just meant the project could fail due to even more factors outside my control, wasting months or years of my life.</p><h2 id="whats-the-alternative">What’s the alternative?<a href="#whats-the-alternative" arialabel="Anchor"> 🔗︎</a></h2><p>Around this time, I discovered Indie Hackers.</p><p><a href="https://mtlynch.io/why-i-quit-google/indie-hackers.png"><img sizes="(min-width: 768px) 550px, 98vw" srcset="https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_300x0_resize_lanczos_3.png 300w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_600x0_resize_lanczos_3.png 600w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_800x0_resize_lanczos_3.png 800w,
https://mtlynch.io/why-i-quit-google/indie-hackers_hu41c2d18a1506b17864c6f0bbd92fea7f_91019_1200x0_resize_lanczos_3.png 1200w,
https://mtlynch.io/why-i-quit-google/indie-hackers.png 1545w" src="https://mtlynch.io/why-i-quit-google/indie-hackers.png" alt="Screenshot of Indie Hackers website" loading="lazy"></a></p><p>It’s an online community for founders of small software businesses. Emphasis on small. These weren’t Zuckerberg hopefuls, but rather people who wanted to build modest, profitable businesses that pay their bills.</p><p>I had always been interested in starting my own software company, but I only knew of the Silicon Valley startup path. I thought being a software founder meant spending most of my time fundraising and the rest of it worrying about how to attract my next million users.</p><p>Indie Hackers presented an attractive alternative. Most members built their businesses with their own savings or as side projects to their full-time jobs. They didn’t answer to investors, and they certainly didn’t have to prove themselves to anonymous committees.</p><p>There were downsides, of course. Their income was less steady, and they faced more numerous catastrophic risks. If I ever made a mistake at Google that cost the company $10 million, I would suffer no consequences. I’d be asked to write a post-mortem, and everyone would celebrate the learning opportunity. For most of these founders, a $10 million mistake would mean the end of their business and several lifetimes of debt.</p><p>Founders on Indie Hackers captivated me because they were in control. Whether their business became a runaway success or stagnated for years, they were calling the shots. At Google, I didn’t feel in control of my own projects, much less my career growth or my team’s direction.</p><p>I thought about it for months and finally decided. I wanted to be an Indie Hacker.</p><h2 id="one-last-thing-before-i-leave">One last thing before I leave<a href="#one-last-thing-before-i-leave" arialabel="Anchor"> 🔗︎</a></h2><p>I still had unfinished business at Google. After investing three years into my promotion, I hated the idea of leaving with nothing to show for it. There were only a few months left until I could reapply for promotion, so I decided to give it one last shot.</p><p>Six weeks before the performance period ended, my project was canceled. Again.</p><p>Actually, my whole team was canceled. This was a common enough occurrence at Google that there was a euphemism for it: a defrag. Management transferred my team’s projects to our sister team in India. My teammates and I all had to start over in different areas of the company.</p><p>I applied for the promotion anyway. Weeks later, my manager read me the results. My performance rating was “Superb,” the highest possible score, given to around 5% of employees each cycle. The promotion committee noted that in the past six months, I clearly demonstrated senior-level work. These were, uncoincidentally, the months when I was optimizing for promotion.</p><p><em>But</em> they felt that six months wasn’t a long enough track record, so… better luck next time.</p><p>My manager told me I had a strong chance at promotion if I did the same quality work for another six months. I can’t say I wasn’t tempted, but by that point, I’d been hearing, “great shot at promotion in six months,” for the past two years.</p><p>It was time to go.</p><h2 id="whats-next">What’s next?<a href="#whats-next" arialabel="Anchor"> 🔗︎</a></h2><p>When I tell people I left Google, they assume I must have some brilliant startup idea. Only an <em>idiot</em> would leave a job as cushy as Google Software Engineer.</p><p>But I am indeed an idiot with no idea.</p><p>My plan is to try different projects for a few months each to see if any of them catch on, for example:</p><ul><li>Continue working on <a href="https://mtlynch.io/tags/ketohub">KetoHub</a> to see if I can make it profitable</li><li>Build a business on top of Sia, a distributed storage technology I’ve <a href="https://mtlynch.io/tags/sia">written about frequently</a></li><li>Spend more time writing, and look for ways to earn money from it</li></ul><p>Google was a great place to work, and I learned valuable skills during my time there. Leaving was difficult because I had more to learn, but there will always be employers like Google. I won’t always have the freedom to start my own company, so I look forward to seeing where this takes me.</p><h2 id="updates">Updates<a href="#updates" arialabel="Anchor"> 🔗︎</a></h2><ul><li><strong>Update (Feb. 1, 2019)</strong>: <a href="https://mtlynch.io/solo-developer-year-1/">My First Year as a Solo Developer</a></li><li><strong>Update (Jan. 31, 2020)</strong>: <a href="https://mtlynch.io/solo-developer-year-2/">My Second Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2021)</strong>: <a href="https://mtlynch.io/solo-developer-year-3/">My Third Year as a Solo Developer</a></li><li><strong>Update (Feb. 1, 2022)</strong>: <a href="https://mtlynch.io/solo-developer-year-4/">My Fourth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2023)</strong>: <a href="https://mtlynch.io/solo-developer-year-5/">My Fifth Year as a Bootstrapped Founder</a></li><li><strong>Update (Feb. 10, 2024)</strong>: <a href="https://mtlynch.io/solo-developer-year-6/">My Sixth Year as a Bootstrapped Founder</a></li></ul><hr><p><em>Illustrations by <a href="https://www.loraineyow.com/">Loraine Yow</a>.</em></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The case of a program that crashed on its first instruction (103 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20241108-00/?p=110490</link>
            <guid>42088789</guid>
            <pubDate>Fri, 08 Nov 2024 17:43:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20241108-00/?p=110490">https://devblogs.microsoft.com/oldnewthing/20241108-00/?p=110490</a>, See on <a href="https://news.ycombinator.com/item?id=42088789">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="single-wrapper">
    
    <article data-clarity-region="article" id="post-110490">
        <div data-bi-area="body_article" data-bi-id="post_page_body_article">
            <p>A customer was baffled by crash reports that indicated that their program was failing on its very first instruction.</p>
<p>I opened one of the crash dumps, and it was so weird, the debugger couldn’t even say what went wrong.</p>
<pre>ERROR: Unable to find system thread FFFFFFFF
ERROR: The thread being debugged has either exited or cannot be accessed
ERROR: Many commands will not work properly
This dump file has an exception of interest stored in it.
The stored exception information can be accessed via .ecxr.
ERROR: Exception C0000005 occurred on unknown thread FFFFFFFF
(61c.ffffffff): Access violation - code c0000005 (first/second chance not available)
0:???&gt; r
WARNING: The debugger does not have a current process or thread
WARNING: Many commands will not work
       ^ Illegal thread error in 'r'
0:???&gt; .ecxr
WARNING: The debugger does not have a current process or thread
WARNING: Many commands will not work
0:???&gt;
</pre>
<p>Let’s see what threads we have.</p>
<pre>0:???&gt; ~
WARNING: The debugger does not have a current process or thread
WARNING: Many commands will not work
   0  Id: 61c.12b4 Suspend: 1 Teb: 000000c7`9604d000 Unfrozen
   1  Id: 61c.22d4 Suspend: 1 Teb: 000000c7`9604f000 Unfrozen
   2  Id: 61c.1ab0 Suspend: 1 Teb: 000000c7`96051000 Unfrozen
   3  Id: 61c.3308 Suspend: 1 Teb: 000000c7`96053000 Unfrozen
   4  Id: 61c.2af0 Suspend: 1 Teb: 000000c7`96055000 Unfrozen
   5  Id: 61c.2054 Suspend: 1 Teb: 000000c7`96059000 Unfrozen
0:???&gt;
</pre>
<p>I wonder what they are doing.</p>
<p>We’ll switch to each thread just to see what instruction they are at</p>
<pre>0:???&gt; ~0s
WARNING: The debugger does not have a current process or thread
WARNING: Many commands will not work
ntdll!RtlUserThreadStart:
00007ffa`bb16df50 4883ec78        sub     rsp,78h
0:000&gt; ~*s
         ^ Illegal thread error in '~*s'
0:000&gt; ~1s
00000293`42074058 66894340        mov     word ptr [rbx+40h],ax ds:00007ff6`e4600040=1f0e
0:001&gt; ~2s
ntdll!ZwWaitForWorkViaWorkerFactory+0x14:
00007ffa`bb1b29c4 c3              ret
0:002&gt; ~3s
ntdll!ZwWaitForWorkViaWorkerFactory+0x14:
00007ffa`bb1b29c4 c3              ret
0:003&gt; ~4s
ntdll!ZwWaitForWorkViaWorkerFactory+0x14:
00007ffa`bb1b29c4 c3              ret
0:004&gt; ~5s
ntdll!ZwDelayExecution+0x14:
00007ffa`bb1af3f4 c3              ret
</pre>
<p>The ostensible reason for the crash was an invalid write instruction, and only thread&nbsp;1 is doing a write. Let’s take a closer look at what it’s trying to write to.</p>
<pre>0:001&gt; !address @rbx

Usage:                  Image
Base Address:           00007ff6`e4600000
End Address:            00007ff6`e4601000
Region Size:            00000000`00001000 (   4.000 kB)
State:                  00001000          MEM_COMMIT
Protect:                00000002          PAGE_READONLY
Type:                   01000000          MEM_IMAGE
Allocation Base:        00007ff6`e4600000
Allocation Protect:     00000080          PAGE_EXECUTE_WRITECOPY
Image Path:             C:\Program Files\Contoso\ContosoDeluxe.exe
Module Name:            ContosoDeluxe
Loaded Image Name:      ContosoDeluxe.exe
Mapped Image Name:      C:\Program Files\Contoso\ContosoDeluxe.exe
More info:              lmv m ContosoDeluxe
More info:              !lmi ContosoDeluxe
More info:              ln 0x7ff6e4600000
More info:              !dh 0x7ff6e4600000

Content source: 2 (mapped), length: 400
0:001&gt; ln @rbx
(00000000`00000000)   ContosoDeluxe!__ImageBase
</pre>
<p>Okay, so we are writing to the mapped image header for ContosoDeluxe itself. This is a read-only page (<code>PAGE_<wbr>READ­ONLY</code>), which is why we take a write access violation.</p>
<p>In fact, we’re writing into the image header, which is not something anybody normally does. This looks quite suspicious.</p>
<p>If we ask for stacks, we get this:</p>
<pre>0:001&gt; ~*k

   0  Id: 61c.12b4 Suspend: 1 Teb: 000000c7`9604d000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`962ffd48 00000000`00000000     ntdll!RtlUserThreadStart

   1  Id: 61c.22d4 Suspend: 1 Teb: 000000c7`9604f000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`963ff900 00007ff6`e4600000     0x00000293`42074058

   2  Id: 61c.1ab0 Suspend: 1 Teb: 000000c7`96051000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`964ff718 00007ffa`bb145a0e     ntdll!ZwWaitForWorkViaWorkerFactory+0x14
000000c7`964ff720 00007ffa`ba25244d     ntdll!TppWorkerThread+0x2ee
000000c7`964ffa00 00007ffa`bb16df78     kernel32!BaseThreadInitThunk+0x1d
000000c7`964ffa30 00000000`00000000     ntdll!RtlUserThreadStart+0x28

   3  Id: 61c.3308 Suspend: 1 Teb: 000000c7`96053000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`965ff6a8 00007ffa`bb145a0e     ntdll!ZwWaitForWorkViaWorkerFactory+0x14
000000c7`965ff6b0 00007ffa`ba25244d     ntdll!TppWorkerThread+0x2ee
000000c7`965ff990 00007ffa`bb16df78     kernel32!BaseThreadInitThunk+0x1d
000000c7`965ff9c0 00000000`00000000     ntdll!RtlUserThreadStart+0x28

   4  Id: 61c.2af0 Suspend: 1 Teb: 000000c7`96055000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`966ffad8 00007ffa`bb145a0e     ntdll!ZwWaitForWorkViaWorkerFactory+0x14
000000c7`966ffae0 00007ffa`ba25244d     ntdll!TppWorkerThread+0x2ee
000000c7`966ffdc0 00007ffa`bb16df78     kernel32!BaseThreadInitThunk+0x1d
000000c7`966ffdf0 00000000`00000000     ntdll!RtlUserThreadStart+0x28

   5  Id: 61c.2054 Suspend: 1 Teb: 000000c7`96059000 Unfrozen
Child-SP          RetAddr               Call Site
000000c7`968ffcb8 00007ffa`bb165833     ntdll!ZwDelayExecution+0x14
000000c7`968ffcc0 00007ffa`b88f9fcd     ntdll!RtlDelayExecution+0x43
000000c7`968ffcf0 00000293`420a1efd     KERNELBASE!SleepEx+0x7d
000000c7`968ffd70 00000000`00000000     0x00000293`420a1efd
</pre>
<p>Thread&nbsp;1 is the suspicious thread that committed the access violation.</p>
<p>There’s another suspicious thread, thread&nbsp;5, which is in a <code>SleepEx</code> call called from the same suspicious source <code>0x00000293`420xxxxx</code>. This other thread is probably waiting for something to happen, so let’s take a look at it.</p>
<p>First, let’s see what kind of memory we are executing from.</p>
<pre>0:001&gt; !address 00000293`420a1ee0

Usage:                  &lt;unknown&gt;
Base Address:           00000293`420a0000
End Address:            00000293`420ca000
Region Size:            00000000`0002a000 ( 168.000 kB)
State:                  00001000          MEM_COMMIT
Protect:                00000040          PAGE_EXECUTE_READWRITE
Type:                   00020000          MEM_PRIVATE
Allocation Base:        00000293`420a0000
Allocation Protect:     00000040          PAGE_EXECUTE_READWRITE
</pre>
<p>Yikes, <code>PAGE_<wbr>EXECUTE_<wbr>READ­WRITE</code>. That’s not a good sign. That smells like malicious code injection, because it is highly unusual for normal code to be read-write. But let’s hold out hope that maybe there’s a legitimate explanation for all of this, and it’s just a matter of finding it.</p>
<p>Let’s see what code we are executing.</p>
<pre>00000293`420a1ed9 add     rsp,30h
00000293`420a1edd pop     rdi
00000293`420a1ede ret
00000293`420a1edf int     3
00000293`420a1ee0 push    rbx
00000293`420a1ee2 sub     rsp,20h
00000293`420a1ee6 call    00000293`420a13e0
00000293`420a1eeb mov     qword ptr [00000293`420c0c78],rax
00000293`420a1ef2 mov     ecx,3E8h
00000293`420a1ef7 call    qword ptr [00000293`420b4028]
                  ^^^^^^^^ YOU ARE HERE
00000293`420a1efd call    00000293`420a13e0 // do it again
00000293`420a1f02 mov     rdx,rax
00000293`420a1f05 mov     rbx,rax
00000293`420a1f08 call    00000293`420a19d0
00000293`420a1f0d test    eax,eax
00000293`420a1f0f jne     00000293`420a1f22
00000293`420a1f11 mov     rax,qword ptr [00000293`420c0c78]
00000293`420a1f18 mov     qword ptr [00000293`420c0c78],rbx
00000293`420a1f1f mov     rbx,rax
00000293`420a1f22 mov     rcx,rbx
00000293`420a1f25 call    00000293`420a17f0
00000293`420a1f2a jmp     00000293`420a1ef2
</pre>
<p>The first few instructions, up to the <code>int 3</code> appear to be the end of the previous function, so we can start our analysis at the <code>push rbx</code>.</p>
<pre>    push rbx                        ; preserve register
    sub rsp, 20h                    ; stack frame
    call 00000293`420a13e0          ; mystery function 1
    mov  [00000293`420c0c78],rax    ; save answer in global

00000293`420a1ef2:
    mov  ecx, 3E8h                  ; decimal 1000
    call [00000293`420b4028]        ; mystery function 2
    ^^^^^^^^ YOU ARE HERE

    call 00000293`420a13e0          ; mystery function 1
    mov  rdx, rax                   ; return value becomes param1
    mov  rbx, rax                   ; save return value in rbx
    call 00000293`420a19d0          ; mystery function 3
    test eax,eax                    ; Q: did it succeed?
    jne  00000293`420a1f22          ; N: Skip
    mov  rax, [00000293`420c0c78]   ; get previous value
    mov  [00000293`420c0c78], rbx   ; replace with new value
    mov  rbx, rax                   ; save previous value in rbx

00000293`420a1f22:
    mov   rcx, rbx                  ; rcx = updated value in rbx
    call    00000293`420a17f0       ; mystery function 3
    jmp     00000293`420a1ef2       ; loop back forever
</pre>
<p>One thing that’s apparent here is that this thread never exits. It’s an infinite loop.</p>
<p>First, let’s see if we can identify the mystery functions.</p>
<p>The easiest is probably mystery function&nbsp;2, since it looks like a call to an imported function.</p>
<pre>0:001&gt; dps 00000293`420b4028 L1
00000293`420b4028  00007ffa`ba258370 kernel32!SleepStub
</pre>
<p>Aha, mystery function&nbsp;2 is <code>Sleep</code>, and the call is a <code>Sleep(1000)</code>. Which we sort of knew from the stack trace but it’s nice to see confirmation.</p>
<p>But let’s look around near that address, since that may be <a title="Any sufficiently advanced uninstaller is indistinguishable from malware" href="https://devblogs.microsoft.com/oldnewthing/20230911-00/?p=108749"> part of a larger table of function pointers</a>.</p>
<pre>00000293`420b4000  00007ffa`baa59810 advapi32!RegCloseKeyStub
00000293`420b4008  00007ffa`baa596e0 advapi32!RegQueryInfoKeyWStub
00000293`420b4010  00007ffa`baa595a0 advapi32!RegOpenKeyExWStub 
00000293`420b4018  00007ffa`baa5ab30 advapi32!RegEnumValueWStub
00000293`420b4020  00000000`00000000
00000293`420b4028  00007ffa`ba258370 kernel32!SleepStub
00000293`420b4030  00007ffa`ba250cc0 kernel32!GetLastErrorStub
00000293`420b4038  00007ffa`ba266b60 kernel32!lstrcatW
00000293`420b4040  00007ffa`ba25ff00 kernel32!CloseHandle
00000293`420b4048  00007ffa`ba254380 kernel32!CreateThreadStub
</pre>
<p>Bingo, this appears to be a table of imported function pointers.</p>
<p>Mystery function 1 seems to be called to start things off, and then again in a loop, so it seems kind of important. Let’s see what it is.</p>
<pre>00000293`420a13e0 mov     qword ptr [rsp+8],rbx
00000293`420a13e5 mov     qword ptr [rsp+10h],rsi
00000293`420a13ea mov     qword ptr [rsp+18h],rdi
00000293`420a13ef push    rbp
00000293`420a13f0 mov     rbp,rsp
00000293`420a13f3 sub     rsp,80h
00000293`420a13fa mov     rax,qword ptr [00000293`420bf010]
00000293`420a1401 xor     rax,rsp
00000293`420a1404 mov     qword ptr [rbp-8],rax
00000293`420a1408 mov     ecx,40h
00000293`420a140d call    00000293`420a8478 // mystery function 3
</pre>
<p>This looks like a typical C function, not hand-coded assembly. After saving non-volatile registers, it builds a stack frame, and the <code>mov rax, [global]</code> followed by a <code>xor rax, rsp</code> looks a lot like a <tt>/GS</tt> stack canary.</p>
<p>So at least it’s nice that this rogue code was compiled with stack buffer overflow protection. Can’t be too careful.</p>
<p>Let’s look at mystery function&nbsp;3.</p>
<pre>00000293`420a8478
    push rbx
    sub  rsp, 20h
    mov  rbx, rcx
    jmp  00000293`420a8492

00000293`420a8483
    mov  rcx, rbx
    call 00000293`420aad50
    test eax, eax
    je   00000293`420a84a2
    mov  rcx, rbx

00000293`420a8492
    call 00000293`420aadb4
    test rax, rax
    je   00000293`420a8483
    add  rsp, 20h
    pop  rbx
    ret

00000293`420a84a2
    cmp  rbx, 0FFFFFFFFFFFFFFFFh
    je   00000293`420a84ae

    call 00000293`420a8c80
    int  3

00000293`420a84ae
    call 00000293`420a8ca0
    int  3

00000293`420a84b4
    jmp  00000293`420a8478
</pre>
<p>This reverse-compiles to</p>
<pre>uint64_t something(uint64_t value)
{
    uint64_t p;
    while (uint64_t p = func00000293420aadb4(value); !p) {
        if (!func00000293420aad50(value)) {
            if (value == ~0ULL) {
                func00000293420a8c80();
            } else {
                func00000293420a8c80();
            }
            // NOTREACHED
        }
    }
    return p;
}
</pre>
<p>This seems to call a function at <code>func00000293420aadb4</code> repeatedly.</p>
<pre>00000293`420aadb4 jmp     00000293`420acf8c
</pre>
<p>This appears to be an incremental linking thunk. So whatever this is, it looks like it was compiled in debug mode.</p>
<pre>00000293`420acf8c
    push rbx
    sub  rsp, 20h
    mov  rbx,rcx
    cmp  rcx, 0FFFFFFFFFFFFFFE0h
    ja   00000293`420acfd7
    test rcx, rcx
    mov  eax, 1
    cmove rbx, rax
    jmp  00000293`420acfbe

00000293`420acfa9
    call 00000293`420b02c0
    test eax, eax
    je   00000293`420acfd7
    mov  rcx, rbx
    call 00000293`420aad50
    test eax, eax
    je   00000293`420acfd7

00000293`420acfbe 
    mov  rcx, [00000293`420c07f8]
    mov  r8, rbx
    xor  edx, edx
    call [00000293`420b4298]
    test rax, rax
    je   00000293`420acfa9
    jmp  00000293`420acfe4

00000293`420acfd7
    call  00000293`420ac71c
    mov   [rax], 0Ch
    xor   eax, eax
    add   rsp, 20h
    pop   rbx
    ret
</pre>
<p>The initial comparison against <code>0xFFFFFFFF`FFFFFFFE</code> makes me suspect that this is <code>malloc()</code> or <code>operator new</code> because those functions begin with a check for an excessive allocation size, to avoid integer overflow.</p>
<p>And indeed, that’s basically what this function is, as revealed by the indirect function call:</p>
<pre>0:005&gt; dps 00000293`420b4298 L1
00000293`420b4298  00007ffa`bb14cca0 ntdll!RtlAllocateHeap
</pre>
<p>Okay, so we found <code>malloc()</code> or <code>operator new</code>.</p>
<p>This will help us understand mystery function 1 a lot better.</p>
<pre>00000293`420a13e0
    mov     [rsp+8], rbx
    mov     [rsp+10h], rsi
    mov     [rsp+18h], rdi
    push    rbp
    mov     rbp, rsp
    sub     rsp, 80h
    mov     rax, [00000293`420bf010]
    xor     rax, rsp
    mov     [rbp-8], rax      ; /GS canary
    mov     ecx, 40h
    call    00000293`420a8478 ; allocate 64 bytes
    xorps   xmm0, xmm0
    mov     ecx, 18h
    mov     rdi,rax           ; save first allocation
    movups  [rax],xmm0        ; zero out first allocation
    movups  [rax+10h],xmm0
    movups  [rax+20h],xmm0
    movups  [rax+30h],xmm0
    call    00000293`420a8478 ; allocate 24 bytes
    xor     esi,esi
    mov     ecx, 80h
    mov     rbx,rax           ; save second allocation
    mov     [rax+0Ch], rsi    ; zero out second allocation
    mov     [rax+14h], esi
    mov     [rax], esi
    mov     [rax+4], 10h
    mov     [rax+8], 1
    call    00000293`420a84b4 ; mystery function 4
    mov     [rbx+10h], rax    ; save result
    lea     ecx, [rsi+10h]    ; ecx = 0x10
    mov     [rdi], rbx
    call    00000293`420a8478 ; third allocation
    lea     ecx, [rsi+40h]    ; ecx = 0x40
    mov     rbx, rax
    mov     [rax+8], rsi      ; initialize third allocation
    mov     [rax], esi
    mov     [rax+4], 10h
    call    00000293`420a84b4 ; mystery function 4
    mov     [rbx+8], rax
    lea     ecx, [rsi+18h]    ; ecx = 0x18
</pre>
<p>Okay, so this function starts by allocating many memory blocks and initializing them.</p>
<p>Let’s skip ahead to where it finally does something interesting.</p>
<pre>    lea     rdx, [00000293`420bba90] ; LR"(SOFTWARE\systemconfig)"
    lea     rax, [rbp-50h]
    mov     [rdi+38h], rbx
    mov     r9d, 20119h       ; KEY_READ
    mov     [rsp+20h], rax
    xor     r8d, r8d
    mov     rcx,0FFFFFFFF80000002h ; HKEY_LOCAL_MACHINE
    call    qword ptr [00000293`420b4010] ; RegOpenKeyExW
    test    eax, eax
</pre>
<p>A <code>dps 00000293`420b4010</code> reveals that the function pointer is <code>Reg­Open­Key­ExW</code>, so the entire function call must have been</p>
<pre>RegOpenKeyExW(HKEY_LOCAL_MACHINE,
    L"SOFTWARE\\systemconfig", 0, KEY_READ, &amp;key);
</pre>
<p>Further disassembly shows that if the code successfully opens the key, it tries to read some values from it. My guess is that <code>system­config</code> is where the code stores its state.</p>
<p>Okay, so maybe I can speed things up by dumping strings and seeing if there’s anything that will give me a clue about the identity of this code. Recall that the <code>!address</code> command told us that the memory block was</p>
<pre>0:001&gt; !address 00000293`420a1ee0
Base Address:           00000293`420a0000
End Address:            00000293`420ca000
</pre>
<p>We’ll ask <a title="MEX Debugging Extension for WinDbg" href="https://www.microsoft.com/en-us/download/details.aspx?id=53304"> the <tt>!mex</tt> debugger extension</a> to find any strings in the memory block.</p>
<pre>0:005&gt; !mex.strings 00000293`420a0000 00000293`420ca000
...
00000293420bbd10 system
00000293420bc1d4 H:\rootkit\r77-rootkit-master\vs\x64\Release\r77-x64.pdb
</pre>
<p>Okay, so I guess it’s malware, or at least self-identifies as a rootkit. And, hey, an Internet search for this rootkit name shows that its source code is public.</p>
<p>The good news for the developer is that the problem is not their fault. The bad news is that since the crash dumps are submitted anonymously, they have no way of contacting the users to tell them that they have been infected with malware.</p>
        </div><!-- .entry-content -->

        <!-- AI Disclaimer -->
            </article>
    
</div><div><!-- Author section -->
            <h2>Author</h2>
            <div><div><p><img src="https://devblogs.microsoft.com/oldnewthing/wp-content/uploads/sites/38/2019/02/RaymondChen_5in-150x150.jpg" alt="Raymond Chen"></p></div><p>Raymond has been involved in the evolution of Windows for more than 30 years. In 2003, he began a Web site known as The Old New Thing which has grown in popularity far beyond his wildest imagination, a development which still gives him the heebie-jeebies. The Web site spawned a book, coincidentally also titled The Old New Thing (Addison Wesley 2007). He occasionally appears on the Windows Dev Docs Twitter account to tell stories which convey no useful information.</p></div>        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Mitochondria Are Alive (572 pts)]]></title>
            <link>https://www.asimov.press/p/mitochondria</link>
            <guid>42088758</guid>
            <pubDate>Fri, 08 Nov 2024 17:39:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.asimov.press/p/mitochondria">https://www.asimov.press/p/mitochondria</a>, See on <a href="https://news.ycombinator.com/item?id=42088758">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><strong><span>An opinion essay by </span><a href="https://www.hertzfoundation.org/person/liyam-chitayat/" rel="">Liyam Chitayat</a></strong></p><p>The cells within our body are the remnants of an ancient alliance.&nbsp;</p><p><span>In a 1967 paper called “</span><a href="https://doi.org/10.1016/0022-5193(67)90079-3" rel="">On the Origin of Mitosing Cells</a><span>,” American evolutionary biologist Lynn Margulis proposed an idea that, upon first hearing, seems ludicrous. Her paper, in fact, was rejected by 12 different journals before it was published.</span></p><p>Margulis argued that one-and-a-half billion years ago, a primitive eukaryotic cell engulfed an oxygen-utilizing bacterium. But rather than digesting this bacterium — or conversely, the bacterium destroying its newfound host — the two cells gradually entered into an endosymbiotic relationship; the host provided nutrients and protection to the bacterium, and the bacterium supplied energy to the host. Margulis argued that this endosymbiosis event was a seminal “innovation engine” for biological systems, ultimately leading to the modern mitochondrion and chloroplast.</p><p>Margulis’ theory was attacked and ridiculed, igniting academic hostilities that lasted for decades. Over time, though, biologists began to accept her ideas because the membrane structure and molecular machinery within mitochondria closely resemble that of extant bacteria. Most biologists today, however, also believe that mitochondria have “devolved” into little more than membrane-bound organelles, similar to inanimate components like the endoplasmic reticulum or Golgi apparatus.</p><p><span>But a swelling tide of scientific evidence about mitochondrial functions and dynamics suggests otherwise — </span><em>mitochondria are not just organelles, but their own life forms.</em><strong>&nbsp;&nbsp;&nbsp;</strong></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:309045,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F58d79ce7-9f19-4a32-8ad2-13c18f831ad8_1200x800.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>An image from L. Margulis’ 1967 paper, depicting the origins of modern mitochondria.</figcaption></figure></div><p>This distinction between “life” on the one hand and “mere membranous structure” on the other may seem trivial, but it’s a symptom of a deeper problem. Defining mitochondria as “nonliving” isn’t just a classification mistake, nor a question of word choice. Rather, it is a fundamental misunderstanding of the nature and role of mitochondria. It inherently undermines our understanding of biological systems and deeply influences the tools we build to study them. </p><p>If we think of mitochondria as non-living organelles, how will we ever harness their full potential?</p><p>The precise definition of “life” has been debated since the inception of biology as a scientific field. Even today, researchers offer overlapping, but distinct, criteria. Molecular biologists tend to focus on characteristics like metabolism, growth and development, response to stimuli, reproduction, and the ability to process information or evolve. This definition uses “checklists” to determine whether or not an organism is alive.</p><p>Biophysicists often take a more rigorous approach, defining life by means of energetic terms. Physicists Erwin Schrödinger and Ilya Prigogine said that living organisms maintain order despite the universe's tendency towards increasing entropy, a measure of how dispersed or disordered the energy within a system is. Living systems maintain far-from-equilibrium states, constantly exchanging matter and energy with their environment to sustain highly organized structures. Cells take in low-entropy inputs, such as food or sunlight, and expel high-entropy outputs, including waste.</p><p>Regardless of which definition one chooses, mitochondria are clearly alive.</p><p>Mitochondria carry their own genomes and express their own genes within their lumens, an internal pocket of watery space, using biomolecules distinct from the cell’s nucleus. Mitochondria also replicate and divide through binary fission, much like bacteria. If one considers bacteria as living entities — and all biologists seem to — then it is impossible to explain why mitochondria are not.</p><p>From a thermodynamic perspective, mitochondria take in low-entropy inputs from their host cell, such as glucose or fatty acids, and expel high-entropy outputs, including carbon dioxide and water. Mitochondria also pump out protons through their inner membrane to maintain an out-of-equilibrium thermodynamic balance, using the resulting gradient to produce the ATP molecules that fuel cellular functions, from DNA replication to protein synthesis.</p><p><span>From the molecular biologist’s perspective, a mitochondrion’s role is not limited to simple energy generation, either. Mitochondria also process</span><em> </em><span>information and interact with their environment, much like a human cell. They monitor steroid hormones, oxidative stress, heat, ATP levels, secondary metabolites, and </span><a href="https://journals.physiology.org/doi/full/10.1152/physrev.00058.2021#" rel="">many more molecules</a><span> floating through their environment, the cell’s cytoplasm. Mitochondria then use this information to precisely control cellular functions. For example, when a virus invades a cell, the mitochondria are critical in sensing the intrusion and signaling a host cell to undergo programmed cell death to halt its spread.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/abab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:327767,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fabab6c4f-4f66-44a9-8234-cc8eaddc975e_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Mitochondria are intimately involved in many cellular processes; not just energy production. Image by the author.</figcaption></figure></div><p>And finally, mitochondria grow and reproduce in a manner distinct from the host’s replication process. Mitochondria independently copy their circular genomes, known as mitochondrial DNA, and divide through binary fission. Notably, mitochondrial replication has several distinct properties from those observed during human cellular replication. Mitochondrial DNA mutates 100-1,000 times faster than the human genome and these mutations can significantly alter a mitochondrion’s fitness, thereby changing the fitness of its host cell. Mitochondria are thus agents of — and subject to — the forces of evolution.</p><p><span>Despite all this evidence, the main case made against mitochondria being alive is that they do not perform all of these functions </span><em>independently</em><span>, as they must be embedded within the cytoplasm of a host cell to function. However, such an argument is logically inconsistent because, by this same logic, most organisms on Earth would not be considered “living.” After all, nothing in biology lives in isolation from its environment.&nbsp;</span></p><p><span>Human life begins inside of another human, with a zygote requiring many months in the uterus to develop into an infant. Many other organisms — not just mitochondria — also live inside other cells. For example, the bacteria </span><em><a href="https://www.ncbi.nlm.nih.gov/books/NBK7624/" rel="">rickettsiae</a><span> </span></em><span>occupy the cytoplasm of cells of ticks, lice, fleas, and mites. Other bacteria, such as </span><em><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC5911502/" rel="">Holospora spp.</a></em><span>, also live within the nucleus of various protists. All living creatures have evolved and live embedded within an environment or biological system, with different organisms embedded in different layers.</span></p><p>It seems like scientists have decided what is living based on whether or not an organism exists in certain, arbitrarily chosen layers of our biosphere. But this is a logical fallacy. Every living organism grows and adapts to occupy a specific context in the universe. We refer to this as the “effective niche” of the lifeform, which could be both inside and outside of another living system. Just because an organism has evolved to live in one niche does not mean that the organism cannot survive in another. Therefore, the so-called “potential niche” of a lifeform is often much larger than its effective niche.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png" width="1200" height="800" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/fa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:800,&quot;width&quot;:1200,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:404460,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffa6de7af-2472-42ef-8e1d-cfad5738af17_1200x800.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The “potential” niche of an organism is typically much larger than its “effective” niche. Image by the author.</figcaption></figure></div><p><span>Consider, for example, that free-living bacteria have been artificially implanted into the cytoplasms of different fungi. Researchers at ETH Zurich </span><a href="https://www.nature.com/articles/s41586-024-08010-x" rel="">recently implanted</a><span> “bacteria into the filamentous fungus </span><em>Rhizopus microsporus</em><span> to follow the fate of artificially induced endosymbioses.” It is clear that the insertion of bacteria into other cells does not suddenly make those bacteria non-living.</span></p><p><span>Similarly, a mitochondrion’s effective niche is a host cell’s cytoplasm, but its potential niche is likely far greater. Mitochondria are not bound to their host cell; they can </span><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/tra.12951" rel="">travel between different cells</a><span>. Although different species carry distinct mitochondria, experiments show that mitochondria from one species can be transferred to another.&nbsp;</span></p><p><span>In 1997, scientists isolated mitochondria from chimpanzees and gorillas and showed that they are naturally internalized and integrated </span><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC23071/" rel="">into human cells</a><span>. Notably, the addition of external mitochondria even showed therapeutic benefits in </span><a href="https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2022.800883/full" rel="">heart failure and spinal cord injury</a><span>. Thus, the potential niche that mitochondria can live in is greater than their effective niche.&nbsp;</span></p><p>When Margulis fought to overturn widely-held ideas in evolutionary biology, it allowed biologists to understand how complexity emerges in biological systems with the creation of eukaryotes and the rise of multicellularity. By revisiting our understanding of mitochondria, we will similarly break down long-held scientific dogmas.</p><p><span>In the early 20th century, Albert Einstein and Claude Shannon laid out the three pillars of the physical world: matter, information, and energy. When Francis Crick and James Watson published their model of the DNA double helix, they created a paradigm shift in our ability to understand and control the first two: matter and information. In the 70 years since then, we’ve developed powerful tools to study genes, decode how information moves through cells, and manipulate DNA using tools such as CRISPR-based gene editing. However, we have not yet reached an equal level of understanding of, or tools to manipulate, biological </span><em>energy</em><span>. Just as CRISPR enabled scientists to rewrite the code of life, we need similar tools to engineer mitochondria and control bioenergetics across the eukaryotic tree of life.</span></p><p>Despite more than a billion years of evolution, mitochondria still play critical roles within cells; they have not been displaced or rendered obsolete. This means that, as humans evolved, so too did the role of mitochondria in shaping our health and longevity. Mitochondrial dysfunction has long been linked to cardiovascular disorders, diabetes, Alzheimers, Parkinsons, amyotrophic lateral sclerosis, and other age-related diseases. In patients with these conditions, the mitochondria adopt abnormal and fragmented morphologies, failing to make enough energy for cells or sending improper communication signals. The diseased mitochondria gradually make toxic compounds that accelerate cell death.&nbsp;</p><p>Perhaps one of the paths to solving energy-related diseases, extending lifespan, or even engineering processes like photosynthesis lies in the complex interaction between our cells and the other lifeforms so actively inhabiting them. To find out, let’s embrace these eons-old alliances.</p><p><em>Thanks to Kate Adamala, Zeno Fox, Michael Retchin, Niko McCarty, and Ed Boyden for helpful feedback on this essay.</em></p><p><strong>Liyam Chitayat </strong><span>is a Hertz Fellow and PhD student at MIT working on synthetic endosymbiosis and building an initiative to integrate and accelerate the field. Liyam is also a Fellow of The Council on Strategic Risk.</span></p><p><strong>Cite: </strong><span>Liyam Chitayat. “Mitochondria Are Alive” </span><em>Asimov Press </em><span>(2024). DOI: https://doi.org/10.62211/38pe-75hu</span></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Pirating "The Pirate Bay" TV Series Is Ironically Difficult (104 pts)]]></title>
            <link>https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/</link>
            <guid>42088731</guid>
            <pubDate>Fri, 08 Nov 2024 17:37:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/">https://torrentfreak.com/pirating-the-pirate-bay-tv-series-is-ironically-difficult-241108/</a>, See on <a href="https://news.ycombinator.com/item?id=42088731">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

          <p>    
                 <!-- Breadcrumb NavXT 7.3.1 -->
<span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to TorrentFreak." href="https://torrentfreak.com/"><span property="name">Home</span></a><meta property="position" content="1"></span> &gt; <span property="itemListElement" typeof="ListItem"><a property="item" typeof="WebPage" title="Go to the Piracy category archives." href="https://torrentfreak.com/category/piracy/"><span property="name">Piracy</span></a><meta property="position" content="2"></span> &gt; <span></span>
	</p>

        <p>
                      <span> </span>
                    The Pirate Bay made its debut as a TV series on the Swedish streaming platform SVT Play earlier today. International viewers are left waiting until other services pick it up. In the meantime, some may be tempted to explore unofficial channels for pirated copies of the show. But finding a pirated copy is proving surprisingly difficult.
        </p>
      </div><div>
        <p><img loading="lazy" decoding="async" src="https://torrentfreak.com/images/tpbseries-300x193.jpg" alt="tpb series" width="300" height="193" srcset="https://torrentfreak.com/images/tpbseries-300x193.jpg 300w, https://torrentfreak.com/images/tpbseries.jpg 1033w" sizes="(max-width: 300px) 100vw, 300px">The inception and early years of The Pirate Bay are <a href="https://torrentfreak.com/the-pirate-bay-celebrates-its-20th-anniversary-230919/">an intriguing chapter</a> of the Internet’s history. </p>
<p>Founded by the Piratbyrån group, The Pirate Bay and its founders embraced the power of the new BitTorrent technology: to copy culture <em>en masse</em>. </p>
<p>By doing so, they altered the public discourse, <a href="https://torrentfreak.com/the-pirate-bays-rebellious-history-in-doodles-180429/">openly taunting</a> the entertainment industries in the process. </p>
<p>This chapter didn’t end as planned for the lead characters; Fredrik Neij (TiAMO), Peter Sunde (Brokep), and Gotffrid Svartholm (Anakata), who were eventually <a href="https://torrentfreak.com/the-pirate-bay-lives-on-a-decade-after-operators-were-found-guilty-190420/">sentenced to prison</a>. By then, however, they had sparked a digital and political revolution, the impact of which is still felt today.</p>
<h2>TV Series</h2>
<p>The Pirate Bay didn’t just trigger a file-sharing bonanza, it was exemplary for the rapid rise of the web. New technology empowered people whose lives were traditionally dictated by mainstream entertainment and publishing companies. </p>
<p>The web created new forms to share news, opinions, knowledge, and media. And few Swedes with keyboards had the power to upset billion-dollar companies.</p>
<p>It doesn’t take a genius to realize that this is a good story, perhaps even a movie script? This includes the people at the Swedish production company B-Reel Films, who got the green light to turn it into a TV series a few years ago. </p>
<p>The series <a href="https://www.svtplay.se/the-pirate-bay">premiered</a> at the on-demand platform of the Swedish national broadcaster SVT a few hours ago. International deals haven’t been announced, but pirates can generally get access anyway.</p>
<h2>Pirating ‘The Pirate Bay’ Series</h2>
<p>Soon after the first two episodes of The Pirate Bay series came out, scene release copies started <a href="https://predb.org/">circulating online</a>. As one would expect. </p>
<p>The Scene group OLLONBORRE, which specializes in Swedish content, was the first to pick the show up. Within minutes, the first 1080p WEB-rips were posted on private scene servers and 720p copies followed a few hours later. </p>
<center><picture loading="lazy" decoding="async">
<source type="image/webp" srcset="https://torrentfreak.com/images/piratebayleak2.jpg.webp 714w, https://torrentfreak.com/images/piratebayleak2-300x103.jpg.webp 300w" sizes="(max-width: 600px) 100vw, 600px">
<img loading="lazy" decoding="async" src="https://torrentfreak.com/images/piratebayleak2.jpg" alt="tpb-leak" width="600" height="207" srcset="https://torrentfreak.com/images/piratebayleak2.jpg 714w, https://torrentfreak.com/images/piratebayleak2-300x103.jpg 300w, https://torrentfreak.com/images/piratebayleak2-600x207.jpg 600w, https://torrentfreak.com/images/piratebayleak2-150x52.jpg 150w" sizes="(max-width: 600px) 100vw, 600px">
</picture>
</center>
<p>Interestingly, pirate releases have yet to make their way to The Pirate Bay. We haven’t seen any other copies on other public pirate sites either, which is surprising given the topic of the series. </p>
<p>It’s common knowledge that <a href="https://en.wikipedia.org/wiki/Warez_scene">The Scene</a> – a secretive network of release groups – prefers to keep its releases private. Therefore, it wasn’t happy with The Pirate Bay’s public nature and rise to prominence in the early 2003s, which is highlighted in the first episodes of the TV series. </p>
<p>However, we expected non-scene release groups would be eager to pick up the show. Apparently that’s not the case, yet.  </p>
<h2>Fact-Based Fiction</h2>
<p>While the broader international audience must wait for the officially sanctioned release, we can add a disclaimer for future viewers. While entertaining and engaging, the series should not be taken as fact.</p>
<p>The script is loosely based on The Pirate Bay story and many of the scenes are fiction. New elements were added, timelines have been changed, and the characters are constructed by the show’s writers, which is not necessarily how they came across in real life.</p>
<center>


</center>
<p>The Pirate Bay’s founders <a href="https://torrentfreak.com/tpb-founders-are-not-involved-in-the-the-pirate-bay-tv-series-230407/">didn’t participate in the production</a>, which means that the creators had no other option than to fill in some blanks. </p>
<p>In an interview with <a href="https://dramaquarterly.com/">Drama Quarterly</a>, director Jens Sjögren previously acknowledged that they had to mix facts and fiction to tell the story. He understands that some people won’t like that.</p>
<p>“People are going to say a lot of shit about it. ‘It was not exactly like this, blah, blah, blah.’ No, but we really broke our fucking backs to try to just embrace the feeling of really struggling with something you believe in so hard – so much so you would almost be ready to go to prison for it,” Sjögren said.</p>
<p>It wasn’t the creators’ main goal to create a literal replay of what happened. Instead, Sjögren said that he tried to capture the spirit of The Pirate Bay founders’ ambitions and goals. </p>
<p>Whether this succeeded is up to the viewer, but the series definitely shows the contrasting personalities of Fredrik, Gottfrid, and Peter. They were all in it for different reasons, which may be part of their initial success. </p>
<p><em>—</em></p><p><em>This weekend we will publish a follow-up article, sharing some thoughts on the series with input from Pirate Bay co-founder Peter Sunde and Piratbyrån co-founder Rasmus Fleischer.</em></p>

      </div></div>]]></description>
        </item>
    </channel>
</rss>