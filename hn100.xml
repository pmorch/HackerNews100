<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Mon, 30 Oct 2023 22:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Gmail, Yahoo announce new 2024 authentication requirements for bulk senders (149 pts)]]></title>
            <link>https://blog.google/products/gmail/gmail-security-authentication-spam-protection/</link>
            <guid>38074992</guid>
            <pubDate>Mon, 30 Oct 2023 20:07:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.google/products/gmail/gmail-security-authentication-spam-protection/">https://blog.google/products/gmail/gmail-security-authentication-spam-protection/</a>, See on <a href="https://news.ycombinator.com/item?id=38074992">Hacker News</a></p>
<div id="readability-page-1" class="page"><article ng-init="drawerToggle = {'open': true}">

    
    





    

    
      

<div data-analytics-module="{
    &quot;module_name&quot;: &quot;Hero Menu&quot;,
    &quot;section_header&quot;: &quot;New Gmail protections for a safer, less spammy inbox&quot;
  }">
      
      
        <p>
          Starting in 2024, we’ll require bulk senders to authenticate their emails, allow for easy unsubscription and stay under a reported spam threshold.
        </p>
      
    </div>

    

    
      







<div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-600.format-webp.webp 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1600.format-webp.webp 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gmail_security_policies_hero_2.width-1200.format-webp.webp" fetchpriority="high" alt="An abstract graphic showing the Gmail logo surrounded by security-related icons, like padlocks and shields.">
  </p>
</div>

      
    </figure>
  </div>


    

    
    <div data-component="uni-drop-cap|uni-tombstone" data-analytics-module="{
           &quot;module_name&quot;: &quot;Paragraph&quot;,
           &quot;section_header&quot;: &quot;New Gmail protections for a safer, less spammy inbox&quot;
         }" data-reading-time="true"><p data-block-key="z5p66">It’s clear that email has become an essential part of daily communication. And whether you’re submitting a job application or staying in touch with a loved one, your emails should be safe and secure.</p><p data-block-key="deihi">Gmail’s AI-powered defenses <a href="https://safety.google/gmail/">stop more than 99.9% of spam, phishing and malware</a> from reaching inboxes and <a href="https://blog.google/products/gmail/holiday-season-scams/">block nearly 15 billion unwanted emails</a> every day. But now, nearly 20 years after Gmail launched, the threats we face are more complex and pressing than ever.</p><p data-block-key="46ole">So today, we’re introducing new requirements for bulk senders — those who send more than 5,000 messages to Gmail addresses in one day — to keep your inbox even safer and more spam-free.</p><h2 data-block-key="fh3ee">Focus on email validation</h2><p data-block-key="cs1bi">Many bulk senders don’t appropriately secure and configure their systems, allowing attackers to easily hide in their midst. To help fix that, we’ve focused on a crucial aspect of email security: the validation that a sender is who they claim to be. As basic as it sounds, it’s still sometimes impossible to verify who an email is from given the web of antiquated and inconsistent systems on the internet.</p><p data-block-key="f1d8c">Last year we started requiring that emails sent to a Gmail address must have some form of authentication. And we’ve seen the number of unauthenticated messages Gmail users receive plummet by 75%, which has helped declutter inboxes while blocking billions of malicious messages with higher precision.</p><p data-block-key="3vage">That’s great progress, but there’s much more we need to do — starting with new requirements for large senders.</p><h2 data-block-key="53u78">New requirements for bulk senders</h2><p data-block-key="uma9">By February 2024, Gmail will start to require that bulk senders:</p><ol><li data-block-key="838h2"><b>Authenticate their email:</b> You shouldn’t need to worry about the intricacies of email security standards, but you should be able to confidently rely on an email’s source. So we're requiring those who send significant volumes to strongly authenticate their emails following well-established <a href="https://support.google.com/a/answer/174124">best practices</a>. Ultimately, this will close loopholes exploited by attackers that threaten everyone who uses email.<br></li><li data-block-key="9nsf4"><b>Enable easy unsubscription:</b> You shouldn’t have to jump through hoops to stop receiving unwanted messages from a particular email sender. It should take one click. So we’re requiring that large senders give Gmail recipients the ability to unsubscribe from commercial email in one click, and that they process unsubscription requests within two days. We’ve built these requirements on open standards so that once senders implement them, everyone who uses email benefits.<br></li><li data-block-key="ar3h6"><b>Ensure they’re sending wanted email:</b> Nobody likes spam, and Gmail already includes <a href="https://safety.google/gmail/">many tools</a> that keep unwanted messages out of your inbox. To add yet another protection, moving forward, we’ll enforce a clear spam rate threshold that senders must stay under to ensure Gmail recipients aren’t bombarded with unwanted messages. This is an industry first, and as a result, you should see even less spam in your inbox.</li></ol><p data-block-key="770m9">We aren’t the only ones pushing for these changes. Our industry partners also see the pressing need to institute them: "No matter who their email provider is, all users deserve the safest, most secure experience possible,” says Marcel Becker, Sr. Dir. Product at Yahoo. “In the interconnected world of email, that takes all of us working together. Yahoo looks forward to working with Google and the rest of the email community to make these common sense, high-impact changes the new industry standard."</p><p data-block-key="1thnm">These practices should be considered basic email hygiene, and many senders already meet most of these requirements. For those who need help to improve their systems, we’re sharing <a href="https://support.google.com/mail/answer/81126">clear guidance</a> before enforcement begins in February 2024.<br></p><p data-block-key="250nh">These changes are like a tune-up for the email world, and by fixing a few things under the hood, we can keep email running smoothly. But just like a tune-up, this is not a one-time exercise. Keeping email more secure, user friendly and spam-free requires constant collaboration and vigilance from the entire email community. And we'll keep working together to make sure your inbox stays safe.</p></div>
  </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[HNInternal: Ask HN: Cloudflare Workers Are Down? (133 pts)]]></title>
            <link>https://news.ycombinator.com/item?id=38074906</link>
            <guid>38074906</guid>
            <pubDate>Mon, 30 Oct 2023 20:01:36 GMT</pubDate>
            <description><![CDATA[<p>See on <a href="https://news.ycombinator.com/item?id=38074906">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            <tbody><tr id="38075713"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075713" href="https://news.ycombinator.com/vote?id=38075713&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It is funny that just last a few days ago the company whose core competency is availability laughed at Okta for a breach, and they are now experiencing an outage.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38074954"><td></td></tr>
                <tr id="38075005"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075005" href="https://news.ycombinator.com/vote?id=38075005&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Just noted on HN and already incident upgrade. Much faster "response" than most other companies:-)<p>All the best to the people fixing!
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075623"><td></td></tr>
                  <tr id="38075117"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075117" href="https://news.ycombinator.com/vote?id=38075117&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>And just 30 minutes ago we were about to flip the switch on a months long migration to Cloudflare Pages for our new website, I guess some things weren't meant to be :')</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075192"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075192" href="https://news.ycombinator.com/vote?id=38075192&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Omg. What timing. I feel your pain. We recently migrated to Cloudflare Pages and I was happy at the speed and everything and now this :(. Never had a downtime when I self hosted on my DigitalOcean droplet. damn. Re-considering going back to old school nginx static site hosting.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075709"><td></td></tr>
            <tr id="38075230"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075230" href="https://news.ycombinator.com/vote?id=38075230&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Yep our current marketing site is NextJS hosted on Hetzner fronted by Cloudflare, fortunately that's still up and never has any problems.<p>We've moved to next-on-pages for our new marketing site and I've spent the whole day on finishing touches ready for switch over at 20:00 UTC, and now this :((
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075289"><td></td></tr>
                        <tr id="38074919"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38074919" href="https://news.ycombinator.com/vote?id=38074919&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>3:55 PM Eastern: Our entire website hosted on cloudflare pages is returning 500. I also cannot login to the dashboard either (it just spins)<p>EDIT 4:10 PM Eastern: Now I can login to the dashboard but "Workers and Pages" menu is returning errors and no access. Website still down :(</p><p>EDIT at 4:23 PM Eastern: RESOLVED. Website (cloudflare pages) is back up now for me.</p><p>Looks like they took about 25 mins to resolve.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075058"><td></td></tr>
                <tr id="38075099"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075099" href="https://news.ycombinator.com/vote?id=38075099&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Our main Marketing website that brings revenue is down. No Sympathy from me. It has been 20 mins now. Losing money as I type this.<p>EDIT: I panicked a little. As a dev, I should have been more sympathetic.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075197"><td><table>  <tbody><tr>    <td indent="3"><img src="https://news.ycombinator.com/s.gif" height="1" width="120"></td><td>
      <center><a id="up_38075197" href="https://news.ycombinator.com/vote?id=38075197&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It’s only reasonable to be angry but do try to remember that the people fixing this are people like you who showed up at work to build something and are instead dealing with a fire. Ask their bosses about how they got in that situation but be nice to them, they’re having an even worse day than you are.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075277"><td><table>  <tbody><tr>    <td indent="4"><img src="https://news.ycombinator.com/s.gif" height="1" width="160"></td><td>
      <center><a id="up_38075277" href="https://news.ycombinator.com/vote?id=38075277&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Fair enough. They resolved it now and I was in a bit of panic considering our revenue depends on the website. As a developer though, I should have been more sympathetic.</span></p></div></td></tr>
        </tbody></table></td></tr>
                              <tr id="38075097"><td></td></tr>
                  <tr id="38075094"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075094" href="https://news.ycombinator.com/vote?id=38075094&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>For any terraform users that may be using code like this:<p>data "cloudflare_ip_ranges" "cloudflare_ipv4_list" {}</p><p>This is coming back with an empty list on some fields and causing havoc in terraform.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075248"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075248" href="https://news.ycombinator.com/vote?id=38075248&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It is shocking to me how bad to non-existent error handling is in most terraform providers.  It leads to some remarkably arcane and esoteric error messages</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075639"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075639" href="https://news.ycombinator.com/vote?id=38075639&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>Terraform error handling <i>as a whole</i> is nuts anyway. Like, I recently tried to delete an ACM cert that still was in use in a Cloudfront distribution - didn't work, but it took <i>20 minutes</i> for Terraform to recognize that, yes, there's an API error. It shouldn't have come so far given that the API call immediately errors out when trying over the CLI or Web Console, but instead of erroring out, Terraform retried for 20 minutes until it hit some sort of timeout.<p>To make it worse, you can't even <i>kill</i> Terraform safely because while it does register your Ctrl+C, it won't interrupt an ongoing process, and if you force kill it you run the very serious risk of corrupting your state file.</p><p>Seriously, I'm looking for OpenTofu to light some fire under the ass of Hashicorp. I don't know where all the VC money went, but for what's supposed to be the golden standard of IaC solutions, it's sometimes bloody ridiculous.</p><p>(Not to mention it's written in Go of all things which means there's virtually zero tooling and documentation to debug it or to develop anything for... especially when compared to the state of the art in Java, NodeJS or PHP)
              </p></span></p></td></tr>
        </tbody></table></td></tr>
            <tr id="38075256"><td></td></tr>
                  <tr id="38075250"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075250" href="https://news.ycombinator.com/vote?id=38075250&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>In the time I made this post and now it's come back. Really wish that would've returned an error and not an empty list, that almost caused a disaster in my automation.</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38075107"><td></td></tr>
                <tr id="38075609"><td></td></tr>
                  <tr id="38075159"><td></td></tr>
            <tr id="38075439"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075439" href="https://news.ycombinator.com/vote?id=38075439&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>I won't be the first or last to say these three things:<p>The internet was meant to stop reliance on single sources (in case of nuclear war)</p><p>The size of a house of cards increases the number of failure points</p><p>Marketers lie
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                <tr id="38075604"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075604" href="https://news.ycombinator.com/vote?id=38075604&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><p><span>&gt; The internet was meant to stop reliance on single sources<p>You have all the technical means. Your home server possibly won't be reachable, yes.</p><p>The global connectivity as-is is really, really, really fault tolerant.
              </p></span></p></td></tr>
        </tbody></table></td></tr>
                  <tr id="38075079"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075079" href="https://news.ycombinator.com/vote?id=38075079&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Complete Pages outage for me. I have several sites hosted on Cloudflare Pages and I can't access any of them, they're all returning 500's.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075171"><td></td></tr>
                  <tr id="38075229"><td></td></tr>
            <tr id="38075040"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075040" href="https://news.ycombinator.com/vote?id=38075040&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>I can't login to my domain dashboard either. Maybe that is a downstream effect of workers being offline?</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38075504"><td></td></tr>
                <tr id="38075528"><td><table>  <tbody><tr>    <td indent="1"><img src="https://news.ycombinator.com/s.gif" height="1" width="40"></td><td>
      <center><a id="up_38075528" href="https://news.ycombinator.com/vote?id=38075528&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>No way to confirm, but I think so, just because NPM threw this error at me:<pre><code>     KV GET failed: 401 Unauthorized
</code></pre>
where KV could refer to the CF KV in workers</span></p></div></td></tr>
        </tbody></table></td></tr>
                  <tr id="38074961"><td></td></tr>
                <tr id="38075010"><td></td></tr>
                <tr id="38075187"><td></td></tr>
                        <tr id="38075444"><td></td></tr>
            <tr id="38075170"><td><table>  <tbody><tr>    <td indent="0"><img src="https://news.ycombinator.com/s.gif" height="1" width="0"></td><td>
      <center><a id="up_38075170" href="https://news.ycombinator.com/vote?id=38075170&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>It's probably bad that I noticed this just due to a large percentage of my regular online-habits suddenly breaking. I liked the old internet where websites just broke one at a time.</span></p></div></td></tr>
        </tbody></table></td></tr>
            <tr id="38074924"><td></td></tr>
            <tr id="38074985"><td></td></tr>
                <tr id="38075035"><td></td></tr>
                  <tr id="38075301"><td></td></tr>
            <tr id="38075068"><td></td></tr>
                <tr id="38075106"><td></td></tr>
                <tr id="38075148"><td><table>  <tbody><tr>    <td indent="2"><img src="https://news.ycombinator.com/s.gif" height="1" width="80"></td><td>
      <center><a id="up_38075148" href="https://news.ycombinator.com/vote?id=38075148&amp;how=up&amp;goto=item%3Fid%3D38074906"></a></center>    </td><td><br><div>
                  <p><span>Ah, I don't know about Cloudflare Pages. I think they use Workers underneath. So unfortunately, there's no fix yet. Sorry.</span></p></div></td></tr>
        </tbody></table></td></tr>
                <tr id="38075158"><td></td></tr>
                              <tr id="38075265"><td></td></tr>
            <tr id="38075232"><td></td></tr>
            <tr id="38074970"><td></td></tr>
                      <tr id="38075441"><td></td></tr>
            <tr id="38074964"><td></td></tr>
            <tr id="38074931"><td></td></tr>
                <tr id="38075071"><td></td></tr>
            <tr id="38074944"><td></td></tr>
                  <tr id="38074958"><td></td></tr>
                <tr id="38075006"><td></td></tr>
                  </tbody></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Use YouTube to improve your English pronunciation (176 pts)]]></title>
            <link>https://youglish.com/</link>
            <guid>38074701</guid>
            <pubDate>Mon, 30 Oct 2023 19:47:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://youglish.com/">https://youglish.com/</a>, See on <a href="https://news.ycombinator.com/item?id=38074701">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p><label title="All accents">
&nbsp;&nbsp;
All
</label>
<label title="American accent">
&nbsp;&nbsp;
United States
</label>
<label title="British accent">
&nbsp;&nbsp;
United Kingdom
</label>
<label title="Australian accent">
&nbsp;&nbsp;
Australia
</label>
<label title="Canadian accent">
&nbsp;&nbsp;
Canada
</label>
<label title="Irish accent">
&nbsp;&nbsp;
Ireland
</label>
<label title="Scottish accent">
&nbsp;&nbsp;
Scotland
</label>
<label title="New Zealand accent">
&nbsp;&nbsp;
New Zealand
</label>
</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Threads Software Limited gives Meta 30 days to stop using the name Threads (213 pts)]]></title>
            <link>https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads</link>
            <guid>38072495</guid>
            <pubDate>Mon, 30 Oct 2023 17:20:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads">https://www.businesswire.com/news/home/20231030082004/en/Threads-Software-Limited-Gives-Meta%E2%80%99s-Instagram-30-Days-to-Desist-from-Using-the-Service-Name-Threads</a>, See on <a href="https://news.ycombinator.com/item?id=38072495">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>LONDON--(<span itemprop="provider publisher copyrightHolder" itemscope="itemscope" itemtype="https://schema.org/Organization" itemid="https://www.businesswire.com"><span itemprop="name"><a referrerpolicy="unsafe-url" rel="nofollow" itemprop="url" href="https://www.businesswire.com/">BUSINESS WIRE</a></span></span>)--UK software company Threads Software Limited and its lawyers have today (30 October) written to Meta’s Instagram giving it 30 days to stop using the name Threads for their service in the UK. If it does not, Threads Software Limited will seek an injunction from the English Courts.

</p>
<blockquote></blockquote>
<p>
Threads - an intelligent message hub provided by Threads Software Limited - was conceived and trademarked in 2012 by JPY Ltd. The service has been actively promoted worldwide since 2014.

</p><p>
In 2018, the first commercial sale was made in the USA, and as a result JPY Ltd spun off a new company, Threads Software Ltd. It has since licenced nearly 1,000 organisations worldwide with sales currently growing at 200% a year.

</p><p>
From April 2023, Meta’s lawyers made four offers to purchase the domain ‘threads.app’ from Threads Software Ltd. Every offer was declined. It was made clear to Meta’s Instagram that the domain was not for sale.

</p><p>
In July 2023, Meta’s Instagram announced its ‘threads’ social media platform and removed Threads Software Limited from its Facebook platform.

</p><p>
Dr John Yardley, Managing Director of Threads Software Ltd said: “Taking on a US$150 billion company is not an easy decision for us to make. We have invested 10 years in our platform, establishing a recognised brand in the name, Threads. Our business now faces a serious threat from one of the largest technology companies in the world.

</p><p>
“We recognise that this is a classic ‘David and Goliath’ battle with Meta. And whilst they may think they can use whatever name they want, that does not give them the right to use the Threads brand name.

</p><p>
“We want them to stop using the Threads name with immediate effect. If they do not, we will seek an injunction from the UK courts.”

</p><p>
<b>About Threads Software</b>

</p><p>
Threads is a Cloud-based service that captures, transcribes, and organises all of a company’s digital messages (emails and phone calls) into one easily searchable database.

</p><p>
Message meta-data is extracted to automatically and intelligently create a subscriber-specific address book, eliminating the need to manually maintain directories of contacts and companies.

</p><p>
Threads is able to provide high-quality transcriptions by extracting VoIP call and routing data at much greater resolution than most call recording systems. Additionally, by intelligently processing email data, Threads can apply vital <i>contex</i>t to phone calls and further improve its understanding of speech.

</p>
        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Global CO2 Levels (256 pts)]]></title>
            <link>https://www.co2levels.org/</link>
            <guid>38072267</guid>
            <pubDate>Mon, 30 Oct 2023 17:06:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.co2levels.org/">https://www.co2levels.org/</a>, See on <a href="https://news.ycombinator.com/item?id=38072267">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Real-time and Historical data</h4>
            <p>CO2 levels are updated daily with data directly from NOAA's science lab on the slopes of Moana Loa volcano on the Big Island of Hawaii.  Atmospheric carbon dioxide measurements have been collected here daily since 1959. Pre-1959 data comes from ice core data taken from Antarctica.  Historical and current atmospheric temperature can be overlayed on the graph. <a href="#sources">Learn more about the data sources</a>.</p>
          </div>
        
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Free CO<sub>2</sub> Levels Graph</h4>
            <p>This interactive graph is free to use on your website.  Simply choose your color theme and then copy and paste 2 lines of code.  Data and source code is hosted on our servers so you do not have to worry about using up your server's bandwidth. New CO2 measurement data is updated automatically  every day and temperature data is updated monthly.
          </p></div>
        
        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Zoomable and Printable</h4>
            <p>View atmospheric CO<sub>2</sub> levels and/or temperature over a span of thousands of years or zoom to specific time periods.  Use your fingers to pinch and zoom on a handheld device or use a mouse with a computer. Export the chart to PNG, JPG, PDF or SVG format with the click of a button or print the chart directly from the web page.
          </p></div>

        <div data-wow-delay=".3s" data-wow-duration=".3s">
            <h4>Customizable and Responsive</h4>
            <p> Choose from  4 color themes to match your website's look and feel.  Customize the width and height of your graph or have it <a href="https://www.co2levels.org/atmospheric_co2_graph.php" target="_blank">fill your entire screen</a>.  The carbon dioxide levels graph is responsive and can automatically resize to fit whatever device or screen size it is being viewed on.</p>
          </div>
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google Brain cofounder says Big Tech lying about risks of AI wiping out humanity (190 pts)]]></title>
            <link>https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10</link>
            <guid>38072218</guid>
            <pubDate>Mon, 30 Oct 2023 17:03:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10">https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10</a>, See on <a href="https://news.ycombinator.com/item?id=38072218">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="piano-inline-content-wrapper" data-piano-inline-content-wrapper=""> 
                    
                    
                    
                          
                          
                          <section data-offer-key="pre-churn-offer" data-component-type="inline-offer" data-place-after-element-selector=".post-content .content-lock-content > p">
                            <article>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/top-left.svg" alt="">
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/bottom-right.svg" alt="">
                          
                                        </article>
                          </section>
                    
                    <div data-component-type="content-lock" data-load-strategy="exclude">
                                  <ul><li>Big Tech is lying about some AI risks to shut down competition, a Google Brain cofounder has said.</li><li>Andrew Ng told The Australian Financial Review that tech leaders hoped to trigger strict regulation.</li><li>Some large tech companies didn't want to compete with open source, he added.</li></ul><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="techinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you're on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="https://www.businessinsider.com/public/assets/rebrand/newsletter-bull.png" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1 1'%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png">
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p>A leading AI expert and Google Brain cofounder said Big Tech companies were stoking fears about the technology's risks to shut down competition.</p><p>Google Brain was a deep-learning AI research team that merged with the DeepMind division earlier this year.</p><p><a target="_blank" href="https://www.businessinsider.com/ai-godfather-top-names-possibilities-dangers-openai-chatgpt-list-2023-8?r=US&amp;IR=T#british-american-computer-scientist-andrew-ng-founded-a-massive-deep-learning-project-called-google-brain-in-2011-9" data-analytics-product-module="body_link" rel="">Andrew Ng</a>, an adjunct professor at Stanford University who taught OpenAI CEO Sam Altman, told The Australian Financial Review that <a target="_blank" href="https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz" data-analytics-product-module="body_link" rel=" nofollow">the biggest tech companies </a>hoped to trigger strict regulation with the "bad idea that AI could make us go extinct."</p><p>"There are definitely large tech companies that would rather not have to try to compete with open source, so they're creating fear of AI leading to human extinction," he told the news outlet. "It's been a weapon for lobbyists to argue for legislation that would be very damaging to the open-source community."</p><p>In May, <a target="_blank" href="https://www.businessinsider.com/ai-extinction-risk-openai-deepmind-anthropic-ceos-sam-altman-2023-5?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">AI experts and CEOs signed</a> a statement from the Center for AI Safety that compared the risks posed by AI with nuclear war and pandemics. OpenAI CEO <a target="_blank" rel="" href="https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1" data-analytics-product-module="body_link"><u>Sam Altman</u></a>, DeepMind CEO Demis Hassabis, and Anthropic CEO Dario Amodei all put their names to the public statement.</p><p>Other AI heavyweights have issued several warnings about the <a target="_blank" href="https://www.businessinsider.com/elon-musk-ai-pause-openai-gpt4-powerful-development-2023-3?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">accelerated development of advanced</a> generative AI models, with many urging regulators to act quickly.</p><p>Governments around the world are <a target="_blank" href="https://www.businessinsider.com/ai-regulation-2023-us-eu-china-100-10?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">looking to regulate AI</a>, citing concerns over safety, potential job losses, and even the risk of human extinction. The European Union will likely be the first region to enforce oversight or <a target="_blank" rel="" href="https://www.businessinsider.com/us-copyright-office-new-rules-generative-ai-2023-8" data-analytics-product-module="body_link"><u>regulation</u></a> around generative AI.</p><p>Ng said the idea that AI could wipe out humanity could lead to policy proposals that require licensing of AI, which risked crushing innovation. Any necessary AI regulation should be created thoughtfully, he added. </p><p>Ng did not immediately respond to Insider's request for comment, made outside normal working hours.</p>
                      </div>
                    
                    
                        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta to charge for ad-free versions of Facebook and Instagram in Europe (128 pts)]]></title>
            <link>https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html</link>
            <guid>38071472</guid>
            <pubDate>Mon, 30 Oct 2023 16:12:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html">https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html</a>, See on <a href="https://news.ycombinator.com/item?id=38071472">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/10/30/technology/facebook-meta-subscription-europe.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Razor 1911 (181 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Razor_1911</link>
            <guid>38071341</guid>
            <pubDate>Mon, 30 Oct 2023 16:05:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Razor_1911">https://en.wikipedia.org/wiki/Razor_1911</a>, See on <a href="https://news.ycombinator.com/item?id=38071341">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr">

<table><caption>Razor 1911</caption><tbody><tr><td colspan="2"><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Razor1911_JEDACID_HQ.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/180px-Razor1911_JEDACID_HQ.jpg" decoding="async" width="180" height="66" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/270px-Razor1911_JEDACID_HQ.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Razor1911_JEDACID_HQ.jpg/360px-Razor1911_JEDACID_HQ.jpg 2x" data-file-width="3440" data-file-height="1264"></a></span><p>Razor 1911</p></td></tr><tr><th scope="row">Formation</th><td>October 1985</td></tr><tr><th scope="row">Purpose</th><td><a href="https://en.wikipedia.org/wiki/Warez" title="Warez">Warez</a> / <a href="https://en.wikipedia.org/wiki/Demoscene" title="Demoscene">Demo</a></td></tr><tr><th scope="row">Location</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a></li></ul></div></td></tr><tr><th scope="row"><p>Origin</p></th><td><a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a></td></tr><tr><th scope="row"><p>Founders</p></th><td>Doctor No<br>Insane TTM<br>Sector9</td></tr><tr><th scope="row">Website</th><td><s><a rel="nofollow" href="http://www.razor1911.com/">razor1911.com</a></s> Currently down, latest archived snapshot available <a rel="nofollow" href="https://web.archive.org/web/20210629173434/https://razor1911.com/">here</a></td></tr></tbody></table>
<p><b>Razor 1911</b> (<b>RZR</b>) is a <a href="https://en.wikipedia.org/wiki/Warez" title="Warez">warez</a> and <a href="https://en.wikipedia.org/wiki/Demogroup" title="Demogroup">demogroup</a> founded in Norway, 1986. It was the first ever such group to be initially founded exclusively as a demogroup, before moving into warez in 1987.<sup id="cite_ref-:0_1-0"><a href="#cite_note-:0-1">[1]</a></sup> According to the US Justice Department, Razor 1911 is the oldest software cracking group that is still active on the internet.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup><sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> Razor 1911 ran the <a href="https://en.wikipedia.org/wiki/Diskmag" title="Diskmag">diskmag</a> 'Propaganda' until 1995.<sup id="cite_ref-:0_1-1"><a href="#cite_note-:0-1">[1]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="History">History</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=1" title="Edit section: History"><span>edit</span></a><span>]</span></span></h2>
<p>The group was founded as <i>Razor 2992</i> by Doctor No, Insane TTM and Sector9 in <a href="https://en.wikipedia.org/wiki/Norway" title="Norway">Norway</a> in October 1985 as a <a href="https://en.wikipedia.org/wiki/Commodore_64" title="Commodore 64">Commodore 64</a> <a href="https://en.wikipedia.org/wiki/Software_cracking" title="Software cracking">software cracking</a> group. Shortly after, they changed from 2992 to 1911 which translates to <a href="https://en.wikipedia.org/wiki/777_(number)#Computing" title="777 (number)">777</a> in
<a href="https://en.wikipedia.org/wiki/Hexadecimal" title="Hexadecimal">hexadecimal</a>.
</p><p>Between 1987 and 1988 the group began to move away from the Commodore 64 and migrated to a new hardware platform, coding demos and cracking games for the <a href="https://en.wikipedia.org/wiki/Amiga" title="Amiga">Amiga</a>. In the very early 1990s Razor 1911 made another transition, this time to the <a href="https://en.wikipedia.org/wiki/IBM_PC" title="IBM PC">IBM PC</a>, foremost as a cracking group, but still continuing to release <a href="https://en.wikipedia.org/wiki/Crack_intro" title="Crack intro">cracktro loaders</a>, demos and music.
</p><p>Razor was a supply group on <a href="https://en.wikipedia.org/wiki/Floppy_disk" title="Floppy disk">diskette</a> from 1992 until diskettes were abandoned for <a href="https://en.wikipedia.org/wiki/CD-ROM" title="CD-ROM">CD-ROMs</a>. Throughout the 1990s Razor faced competition from many different groups, ranging from groups such as <a href="https://en.wikipedia.org/wiki/Tristar_and_Red_Sector_Incorporated" title="Tristar and Red Sector Incorporated">Tristar &amp; Red Sector inc.</a> (TRSi), <a href="https://en.wikipedia.org/wiki/International_Network_of_Crackers" title="International Network of Crackers">International Network of Crackers</a> (INC) and <a href="https://en.wikipedia.org/wiki/Fairlight_(group)" title="Fairlight (group)">Fairlight</a> (FLT) in 1994 to Prestige, <a href="https://en.wikipedia.org/w/index.php?title=Hybrid_(warez)&amp;action=edit&amp;redlink=1" title="Hybrid (warez) (page does not exist)">Hybrid</a> (HBD), and others in 1995. Razor was revitalised by new members gained from another group, Nexus, who brought with them some UK suppliers and the leaders The Speed Racer (TSR), Hot Tuna and The Gecko. Razor had a handful of others throughout the 1990s, such as Zodact, ROMKernel, The Renegade Chemist (TRC), The WiTcH KiNG, Butcher, SwiTch, Marauder, and Randall Flagg.
</p><p>Razor 1911 took a break from the demoscene in 1992. In 1993 a new demogroup calling itself Razor 1911 formed, in which Colorbird was the only original member of Razor 1911. Razor 1911 was still active as a software cracking group.<sup id="cite_ref-:0_1-2"><a href="#cite_note-:0-1">[1]</a></sup>
</p><p>In 1995 diskette releases were rapidly being supplanted by CD-ROMs, and Razor 1911 moved into the CD-ripping scene. The crew that led Razor into this new chapter included members such as TSR, Pharaoh, Fatal Error, GRIZZLY, Suspicious Image, Third Son, Hot Tuna, Beowulf, Pitbull, Bunter, Manhunter, Niteman, Vitas, Mausioso and The Punisher.
</p><p>Razor once again took on a new challenge when the <a href="https://en.wikipedia.org/wiki/ISO_9660" title="ISO 9660">ISO</a> scene was formed. Razor 1911 began to release ISOs when they became the standard of the day, led most significantly by The Punisher. He was instrumental in Razor's recovery and its solid performance in the ISO scene. Following The Punisher's retirement, Razor was led by various different people and underwent some internal problems in the form of leadership challenges. This was solved when Pitbull, an old Razor member from the 1990s, took over the leadership role. The FBI claimed him to still be the leader of Razor at the time when "<a href="https://en.wikipedia.org/wiki/Operation_Buccaneer" title="Operation Buccaneer">Operation Buccaneer</a>", an international anti-piracy operation which led to raids at the homes of over 60 piracy suspects worldwide in 2001, was carried out even though NFOs and scene activity at the time points out The Renegade Chemist as actual leader of the group.
</p><p>Sean Michael Breen was convicted in 2004 to "50 months in prison and three years of supervised release, for violating the criminal copyright laws as a member of the first computer game piracy ring on the Internet, and for defrauding Cisco Systems".<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> The press release alleges them to be the leader of the group, although their nickname is not mentioned.
</p>
<h2><span id="Return">Return</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=2" title="Edit section: Return"><span>edit</span></a><span>]</span></span></h2>
<p>On June 22, 2006, Razor 1911 started releasing games again. They have been releasing games fairly consistently ever since, and as of 2010 are among the most prolific groups at cracking new releases.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup>
</p><p>On April 1, 2011, Razor 1911 "cracked" the TV show 101% on the French TV channel <a href="https://en.wikipedia.org/wiki/Nolife_(TV_channel)" title="Nolife (TV channel)">Nolife</a>, inducing many unwanted "bugs" and behaviors in the show. While this was a joke, the intro contained a real code giving unlimited access to the paid replay service for one day.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup>
</p><p>On April 22, 2011, Razor 1911's demo division won the public choice award<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> during the <a rel="nofollow" href="http://awards.scene.org/">Scene.org Awards</a> ceremony at <a href="https://en.wikipedia.org/wiki/The_Gathering_(computer_party)" title="The Gathering (computer party)">The Gathering</a> for their <a href="https://en.wikipedia.org/wiki/64k_intro" title="64k intro">64k intro</a> "Insert No Coins" coded by Rez with music from Dubmood.<sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p>
<h2><span id="Members">Members</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=3" title="Edit section: Members"><span>edit</span></a><span>]</span></span></h2>
<p>Dycus, a member of Razor 1911, died of <a href="https://en.wikipedia.org/wiki/Throat_cancer" title="Throat cancer">throat cancer</a> in 2012.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=4" title="Edit section: See also"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a href="https://en.wikipedia.org/wiki/List_of_warez_groups" title="List of warez groups">List of warez groups</a></li>
<li><a href="https://en.wikipedia.org/wiki/Warez_group" title="Warez group">Warez group</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=5" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-:0-1"><span>^ <a href="#cite_ref-:0_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_1-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:0_1-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFPolgár2000">Polgár, Tamás 'Tomcat' (2000). <i>Freax Volume 1</i>. CSW-Verlag. pp.&nbsp;100, 148, 171. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/3981049403" title="Special:BookSources/3981049403"><bdi>3981049403</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Freax+Volume+1&amp;rft.pages=100%2C+148%2C+171&amp;rft.pub=CSW-Verlag&amp;rft.date=2000&amp;rft.isbn=3981049403&amp;rft.aulast=Polg%C3%A1r&amp;rft.aufirst=Tam%C3%A1s+%27Tomcat%27&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20130415114316/http://www.justice.gov/criminal/cybercrime/press-releases/2003/pitmanSent.htm">"Former Leader of Razor 1911, the Oldest Game Software Piracy Ring on the Internet, Sentenced (June 6, 2003)"</a>. Archived from <a rel="nofollow" href="https://www.justice.gov/criminal/cybercrime/press-releases/2003/pitmanSent.htm">the original</a> on 2013-04-15<span>. Retrieved <span>2021-11-22</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Former+Leader+of+Razor+1911%2C+the+Oldest+Game+Software+Piracy+Ring+on+the+Internet%2C+Sentenced+%28June+6%2C+2003%29&amp;rft_id=http%3A%2F%2Fwww.justice.gov%2Fcriminal%2Fcybercrime%2Fpress-releases%2F2003%2FpitmanSent.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFFisk2009">Fisk, Nathan (2009). <i>Warez Groups</i>. pp.&nbsp;193–194. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-313-33974-5" title="Special:BookSources/978-0-313-33974-5"><bdi>978-0-313-33974-5</bdi></a>. <q>Razor 1911 is widely considered to be the oldest surviving warez group, having been established in 1985.</q></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Warez+Groups&amp;rft.pages=193-194&amp;rft.date=2009&amp;rft.isbn=978-0-313-33974-5&amp;rft.aulast=Fisk&amp;rft.aufirst=Nathan&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span> </span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.justice.gov/archive/criminal/cybercrime/press-releases/2004/breenSent.htm">"Leader of Oldest Game Piracy Group Get 50-Month Prison Sentence"</a><span>. Retrieved <span>2023-06-30</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Leader+of+Oldest+Game+Piracy+Group+Get+50-Month+Prison+Sentence&amp;rft_id=https%3A%2F%2Fwww.justice.gov%2Farchive%2Fcriminal%2Fcybercrime%2Fpress-releases%2F2004%2FbreenSent.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="http://scenenotice.org/details.php?id=1708">"The Game Scene Charts Issue 38 December 2009 Edition"</a>. <i>SceneNotice.org</i>. 2010-01-20.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=SceneNotice.org&amp;rft.atitle=The+Game+Scene+Charts+Issue+38+December+2009+Edition&amp;rft.date=2010-01-20&amp;rft_id=http%3A%2F%2Fscenenotice.org%2Fdetails.php%3Fid%3D1708&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span> Razor 1911 is on position 10 for the year 2009.</span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><a rel="nofollow" href="https://www.youtube.com/watch?v=Cve7PNySRZ4"><span>"Nolife - 101% cracked by RAZOR 1911"</span></a> on <a href="https://en.wikipedia.org/wiki/YouTube_video_(identifier)" title="YouTube video (identifier)">YouTube</a></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="http://awards.scene.org/awards.php?year=2010&amp;cat=11">"Scene.org Awards"</a>. 2011-04-22.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Scene.org+Awards&amp;rft.date=2011-04-22&amp;rft_id=http%3A%2F%2Fawards.scene.org%2Fawards.php%3Fyear%3D2010%26cat%3D11&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.pouet.net/prod.php?which=55991">"pouet.net"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=pouet.net&amp;rft_id=http%3A%2F%2Fwww.pouet.net%2Fprod.php%3Fwhich%3D55991&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.pouet.net/topic.php?which=8696">"Rez, sorry to hear about Dycus"</a>. <i>pouët.net</i><span>. Retrieved <span>2021-03-01</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=pou%C3%ABt.net&amp;rft.atitle=Rez%2C+sorry+to+hear+about+Dycus&amp;rft_id=http%3A%2F%2Fwww.pouet.net%2Ftopic.php%3Fwhich%3D8696&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ARazor+1911"></span></span>
</li>
</ol></div>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Razor_1911&amp;action=edit&amp;section=6" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<ul><li><a rel="nofollow" href="http://www.razor1911.com/">Razor 1911 Demo Division website</a> <a rel="nofollow" href="https://web.archive.org/web/20080330071459/http://www.razor1911.com/">Archived</a> 2008-03-30 at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a></li></ul>

<!-- 
NewPP limit report
Parsed by mw1414
Cached time: 20231025211149
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.348 seconds
Real time usage: 0.472 seconds
Preprocessor visited node count: 2071/1000000
Post‐expand include size: 67362/2097152 bytes
Template argument size: 12603/2097152 bytes
Highest expansion depth: 19/100
Expensive parser function count: 5/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 35461/5000000 bytes
Lua time usage: 0.234/10.000 seconds
Lua memory usage: 7162613/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  429.828      1 -total
 34.39%  147.825      4 Template:Ambox
 29.36%  126.182      1 Template:Reflist
 21.22%   91.203      1 Template:Multiple_issues
 19.39%   83.330      1 Template:Authority_control
 17.95%   77.140      2 Template:Cite_book
 14.34%   61.656      1 Template:Infobox_organization
 13.05%   56.111      1 Template:More_citations_needed
 12.83%   55.158      1 Template:Infobox
 12.62%   54.254      1 Template:Short_description
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:36161666-0!canonical and timestamp 20231025211148 and revision id 1181844709. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[New York Times Tech Workers to Strike This Afternoon (212 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays</link>
            <guid>38070098</guid>
            <pubDate>Mon, 30 Oct 2023 14:48:15 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays">https://www.bloomberg.com/news/articles/2023-10-30/new-york-times-tech-union-to-strike-over-office-return-contract-delays</a>, See on <a href="https://news.ycombinator.com/item?id=38070098">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Replacing WebRTC: real-time latency with WebTransport and WebCodecs (163 pts)]]></title>
            <link>https://quic.video/blog/replacing-webrtc/</link>
            <guid>38069974</guid>
            <pubDate>Mon, 30 Oct 2023 14:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://quic.video/blog/replacing-webrtc/">https://quic.video/blog/replacing-webrtc/</a>, See on <a href="https://news.ycombinator.com/item?id=38069974">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<p>The long path to use <em>something else</em> for real-time media.</p>
<h2 id="tldr">tl;dr</h2>
<p>If you primarily use WebRTC for…</p>
<ul>
<li><strong>real-time media</strong>: it will take a while to replace WebRTC; we’re working on it.</li>
<li><strong>data channels</strong>: WebTransport is amazing and <em>actually</em> works.</li>
<li><strong>peer-to-peer</strong>: you’re stuck with WebRTC for the forseeable future.</li>
</ul>
<h2 id="disclaimer">Disclaimer</h2>
<p>I spent almost two years building/optimizing a partial WebRTC stack @ Twitch using <a href="https://github.com/pion/webrtc">pion</a>.
Our use-case was quite custom and we ultimately scrapped it, but your millage may vary.</p>
<h2 id="why-webrtc">Why WebRTC?</h2>
<p>Google released WebRTC in 2011 as a way of fixing a very specific problem:</p>
<blockquote>
<p>How do we build Google Meet?</p>
</blockquote>
<p>Back then, the web was a very different place.
Flash was the only way to do live media and it was a <em>mess</em>.
HTML5 video was primarily for pre-recorded content.
It personally took me until 2015 to write a <a href="https://reddit.com/r/Twitch/comments/3hqfkw/the_csgo_client_embeds_the_twitch_html5_player/">HTML5 player for Twitch</a> using <a href="https://developer.mozilla.org/en-US/docs/Web/API/Media_Source_Extensions_API">MSE</a>, and we’re still talking 5+ seconds of latency on a good day.</p>
<p>Transmitting video over the internet <em>in real-time</em> is hard.</p>
<p>You need a tight coupling between the video encoding and the network to avoid any form of queuing, which adds latency.
This effectively rules out TCP and forces you to use UDP.
But now you also need a video encoder/decoder that can deal with packet loss without spewing artifacts everywhere.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/artifact.png" alt="Video artifacts"></p><figcaption><p><a href="https://flashphoner.com/10-important-webrtc-streaming-metrics-and-configuring-prometheus-grafana-monitoring/">Source</a>.
Example of Artifacts caused by packet loss.</p></figcaption></figure>
<p>Google (correctly) determined that it would be impossible to solve these problems piecewise with new web standards.
The approach instead was to create <a href="https://webrtc.googlesource.com/src/">libwebrtc</a>, the defacto WebRTC implementation that still ships with all browsers.
It does everything, from networking to video encoding/decoding to data transfer, and it does it remarkably well.
It’s actually quite a feat of software engineering, <em>especially</em> the part where Google managed to convince Apple/Mozilla to embed a full media/networking stack into their browsers.</p>
<p>My favorite part about WebRTC is that it manages to leverage existing standards.
WebRTC is not really a protocol, but rather a collection of protocols: <a href="https://datatracker.ietf.org/doc/html/rfc8445">ICE</a>, <a href="https://datatracker.ietf.org/doc/html/rfc5389">STUN</a>, <a href="https://datatracker.ietf.org/doc/html/rfc5766">TURN</a>, <a href="https://datatracker.ietf.org/doc/html/rfc6347">DTLS</a>, <a href="https://datatracker.ietf.org/doc/html/rfc3550">RTP/RTCP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc3711">SRTP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc4960">SCTP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc4566">SDP</a>, <a href="https://datatracker.ietf.org/doc/html/rfc6762">mDNS</a>, etc.
Throw a <a href="https://www.w3.org/TR/webrtc/">Javascript API</a> on top of these and you have WebRTC.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/layers.png" alt="WebRTC protocols and layers">
</p><figcaption><a href="https://hpbn.co/webrtc/">Source</a>. That’s a lot of protocols layered on top of each other.</figcaption></figure>
<h2 id="why-not-webrtc">Why not WebRTC?</h2>
<p>I wouldn’t be writing this blog post if WebRTC was perfect.
The core issue is that WebRTC is not a protocol; it’s a monolith.</p>
<p>WebRTC does a lot of things, let’s break down it down piece by piece:</p>
<ul>
<li><a href="#media">Media</a>: a full capture/encoding/networking/rendering pipeline.</li>
<li><a href="#data">Data</a>: reliable/unreliable messages.</li>
<li><a href="#p2p">P2P</a>: peer-to-peer connectability.</li>
<li><a href="#sfu">SFU</a>: a relay that selectively forwards media.</li>
</ul>
<h3 id="media">Media</h3>
<p>The WebRTC media stack is designed for conferencing and does an amazing job at it.
The problems start when you try to use it for anything else.</p>
<p>My final project at Twitch was to reduce latency by replacing HLS with WebRTC for delivery.
This seems like a no-brainer at first, but it quickly turned into <a href="https://docs.google.com/document/d/1OTnJunbpSJchdj8XI3GU9Fo-RUUFBqLO1AhlaKk5Alo/edit?usp=sharing">death by a thousand cuts</a>.
The biggest issue was that the user experience was just terrible.
Twitch doesn’t need the same aggressive latency as Google Meet, but WebRTC is hard-coded to compromise on quality.</p>
<p>In general, it’s quite difficult to customize WebRTC outside of a few configurable modes.
It’s a black box that you turn on, and if it works it works.
And if it doesn’t work, then you have to deal with the pain that is <a href="https://github.com/webrtc-sdk/libwebrtc">forking libwebrtc</a>… or just hope Google fixes it for you.</p>
<p>The protocol has some wiggle room and I really enjoyed my time tinkering with <a href="https://github.com/pion/webrtc">pion</a>.
But you’re ultimately bound by the browser implementation, unless you don’t need web support, in which case you don’t need WebRTC.</p>
<h3 id="data">Data</h3>
<p>WebRTC also has a data channel API, which is particularly useful because <a href="#webtransport">until recently</a>, it’s been the only way to send/receive “unreliable” messages from a browser.
In fact, many companies use WebRTC data channels to avoid the WebRTC media stack (ex. Zoom).</p>
<p>I went down this path too, attempting to send each video frame as an unreliable message, but it didn’t work due to fundamental flaws with <a href="https://www.rfc-editor.org/rfc/rfc9260.html">SCTP</a>.
I won’t go into the detail in this post, but I eventually hacked “datagram” support into SCTP by breaking frames into unreliable messages below the MTU size.</p>
<p>Finally! UDP* in the browser, but at what cost:</p>
<ul>
<li>a convoluted handshake that takes at least 10 (!) round trips.</li>
<li>2x the packets, because libsctp immediately ACKs every “datagram”.</li>
<li>a custom SCTP implementation, which means the browser can’t send “datagrams”.</li>
</ul>
<p>Oof.</p>
<h3 id="p2p">P2P</h3>
<p>The best and worst part about WebRTC is that it supports peer-to-peer.</p>
<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Connectivity">ICE handshake</a> is extremely complicated, even from the <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API/Signaling_and_video_calling">application’s point of view</a>.
Without going into detail, there’s an explosion of permutations that you need to handle based on the network topology.
Some networks block P2P (ex. symmetric NATs) while others outright block UDP, forcing you to use a TURN server a <a href="https://twitter.com/HCornflower/status/894600051506515968">non-insignificant amount of time</a>.</p>
<p>Most conferencing solutions are client-server anyway, relying on their own private network instead of public transit (aka a CDN).
However the server is still forced to perform the complicated ICE handshake which has major architecture ramifications, but I’ll save that for another blog post.</p>
<p>Note that there are rumblings of <a href="https://w3c.github.io/p2p-webtransport/">P2P WebTransport</a> and <a href="https://datatracker.ietf.org/doc/draft-seemann-quic-nat-traversal/">P2P QUIC</a>, but I wouldn’t hold my breath.</p>
<h3 id="sfu">SFU</h3>
<p>Last but not least, WebRTC scales using SFUs (Selective Forwarding Units).</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/sfu.png" alt="SFU example"></p><figcaption><p><a href="https://blog.livekit.io/scaling-webrtc-with-distributed-mesh/">Source</a>. Participants send to a central server,
rather than directly to each other.</p></figcaption></figure>
<p>The problem with SFUs is subtle: they’re custom.</p>
<p>It requires a lot of business logic to determine <em>where</em> to forward packets.
A single server like that diagram won’t scale, nor will all of the participants be located in the same geo.
Each SFU needs to be made aware of the network topology and the location of each participant <em>somehow</em>.</p>
<p>Additionally, a good SFU will avoid dropping packets based on dependencies, otherwise you waste bandwidth on undecodable packets.
Unfortunately, determining this requires parsing each RTP packet on a <em>per-codec</em> basis.
For example, here’s a <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/modules/rtp_rtcp/source/video_rtp_depacketizer_h264.cc">h.264 depacketizer</a> for libwebrtc.</p>
<p>But the biggest issue at Twitch was that SFUs share very little in common with CDNs.
One team is optimizing WebRTC, another team is optimizing HTTP, and they’re not talking to each other.</p>
<p>This is why HLS/DASH uses HTTP instead: <strong>economies of scale</strong></p>
<h2 id="replacing-webrtc-1">Replacing WebRTC</h2>
<p>Okay enough ranting about what’s wrong, let’s fix it.</p>
<p>First off, <strong>WebRTC is not going anywhere</strong>. It does a fantastic job at what it was designed for: conferencing.
It will take a long time before anything will reach feature/latency parity with WebRTC.</p>
<p>Before you can replace <strong>Web</strong>RTC, you need <strong>Web</strong>Support.
Fortunately, we now have <strong>Web</strong>Codecs and <strong>Web</strong>Transport.</p>
<h2 id="webcodecs">WebCodecs</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API">WebCodecs</a> is a new API for encoding/decoding media in the browser.
It’s remarkably simple:</p>
<ol>
<li>Capture input via <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">canvas</a> or a <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia">media device</a>.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/VideoEncoder">VideoEncoder</a>: Input raw frames, output encoded frames.</li>
<li>Transfer those frames somehow. (ex. <a href="#webtransport">WebTransport</a>)</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/VideoDecoder">VideoDecoder</a>: Input encoded frames, output raw frames.</li>
<li>Render output via <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">canvas</a> or just marvel at the pixel data.</li>
</ol>
<p>The catch is that the application is responsible for all timing.
That means you need to choose when to render each frame via <a href="https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame">requestAnimationFrame</a>.
In fact, you need to choose when to render each audio <em>sample</em> via <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioWorklet">AudioWorklet</a>.</p>
<p>The upside is that now your web application gets full control of how to render media.
It’s now possible to implement WebRTC-like behavior, like temporarily freezing video and desyncing A/V.</p>
<p>Check <a href="https://caniuse.com/webcodecs">caniuse</a> for current browser support.</p>
<h2 id="webtransport">WebTransport</h2>
<p><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebCodecs_API">WebTransport</a> is a new API for transmitting data over the network.
Think of it like WebSockets, but with a few key differences:</p>
<ul>
<li><a href="https://www.rfc-editor.org/rfc/rfc9000.html">QUIC</a> not TCP.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebTransport_API#reliable_transmission_via_streams">Reliable streams</a> that are delivered in order.</li>
<li><strong>Semi-reliable streams</strong> by closing a stream (with an error code) to drop the tail.</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebTransport/datagrams">Unreliable datagrams</a> that may be dropped during congestion.</li>
</ul>
<p>QUIC has too many benefits to enumerate, but some highlights:</p>
<ul>
<li>Fully encrypted</li>
<li>Congestion controlled (even datagrams)</li>
<li>Independent streams (no head-of-line blocking)</li>
<li>1-RTT handshake</li>
<li>Multiplexed over a single UDP port</li>
<li>Transparent network migration (ex. switching from Wifi to LTE)</li>
<li>Used for HTTP/3</li>
</ul>
<p>That last one is surprisingly important: WebTransport will share all of the optimizations that HTTP/3 receives.
A HTTP/3 server can simultaneously serve multiple WebTransport sessions and HTTP requests over the same connection.</p>
<p>Check <a href="https://caniuse.com/webtransport">caniuse</a> for current browser support.
Use my <a href="https://docs.rs/webtransport-quinn/latest/webtransport_quinn/">Rust library</a> for servers and native clients!</p>
<h2 id="but-how">But how?</h2>
<p>Okay, so we have WebCodecs and WebTransport, but are they actually useful?</p>
<p>I alluded to the secret behind latency earlier: avoiding queues.
Queuing can occur at any point in the media pipeline.</p>















<table><thead><tr><th>Capture/Encode</th><th>Send/Receive</th><th>Decode/Render</th></tr></thead><tbody><tr><td>—&gt;</td><td>—&gt;</td><td>—&gt;</td></tr></tbody></table>
<p>Let’s start with the easy one.
<a href="#webcodecs">WebCodecs</a> allows you to avoid queuing almost entirely.</p>















<table><thead><tr><th>Capture/Encode</th><th>Send/Receive</th><th>Decode/Render</th></tr></thead><tbody><tr><td><strong>WebCodecs</strong></td><td>?</td><td><strong>WebCodecs</strong></td></tr></tbody></table>
<p>The tricky part is the bit in the middle, the network.
It’s not as simple as throwing your hands into the air and proclaiming “UDP has no queues!”</p>
<h3 id="the-internet-of-queues">The Internet of Queues</h3>
<p>The internet is a <a href="https://en.wikipedia.org/wiki/Series_of_tubes">series of tubes</a>.
You put packets in one end and they eventually come out of the other end, kinda.
This section will get an entire blog post in the future, but until then, let’s over-simplify things.</p>
<p>Every packet you send will fight with other packets on the internet.</p>
<ul>
<li>If routers have sufficient throughput, <strong>packets arrive on time</strong>.</li>
<li>If routers have limited throughput, <strong>packets will be queued</strong>.</li>
<li>If those queues are full, <strong>packets will be dropped</strong>.</li>
</ul>
<p>There can be random packet loss, but 99% of the time we care about loss due to queuing.
Note that even datagrams may be queued by the network; a firehose of packets is never the answer.</p>
<h3 id="detecting-queuing">Detecting Queuing</h3>
<p>The goal of congestion control is to detect queuing and back off.</p>
<p>Different congestion control algorithms use different signals to detect queuing.
This is a gross oversimplification of a topic with an immense amount of research, but here’s a rough breakdown:</p>



































<table><thead><tr><th>Signal</th><th>Description</th><th>Latency</th><th>Examples</th></tr></thead><tbody><tr><td>Packet Loss</td><td>Wait until the queue is full and packets are dropped.</td><td><a href="https://en.wikipedia.org/wiki/Bufferbloat">High</a></td><td><a href="https://en.wikipedia.org/wiki/TCP_congestion_control">Reno</a>, <a href="https://en.wikipedia.org/wiki/CUBIC_TCP">CUBIC</a></td></tr><tr><td>ACK Delay</td><td>Indirectly measure the queue size via ACK RTT.</td><td>Medium</td><td><a href="https://research.google/pubs/pub45646/">BBR</a>, <a href="https://web.mit.edu/copa/">COPA</a></td></tr><tr><td>Packet Delay</td><td>Indirectly measure the queue size via packet RTT.</td><td>Low</td><td><a href="https://datatracker.ietf.org/doc/html/draft-ietf-rmcat-gcc-02">GCC</a>, <a href="https://github.com/EricssonResearch/scream">SCReAM</a></td></tr><tr><td>ECN</td><td>Get told by the router to back off.</td><td>None*</td><td><a href="https://datatracker.ietf.org/doc/rfc9330/">L4S</a></td></tr></tbody></table>
<p>There’s no single “best” congestion control algorithm; it depends on your use-case, network, and target latency.
But this is one area where WebRTC has an advantage thanks to <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/docs/native-code/rtp-hdrext/transport-wide-cc-02/README.md">transport-wide-cc</a>.</p>
<h3 id="reducing-bitrate">Reducing Bitrate</h3>
<p>Once you detect queuing, the application needs to send fewer bytes.</p>
<p>In some situations we can just reduce the encoder bitrate, however:</p>
<ul>
<li>This only applies to future frames.</li>
<li>We don’t want one viewer to degrade the experience for all.</li>
<li>It’s too expensive to encode on a per-viewer basis.</li>
</ul>
<p>So basically, we have to drop encoded media in response to congestion.</p>
<p>This is the fundamental problem with TCP.
Once you queue data on a TCP socket, it can’t be undone without closing the connection.
You can’t put the toothpaste back in the tube.</p>
<figure><p><img src="https://quic.video/blog/replacing-webrtc/toothpaste.jpg" alt="TCP toothpaste"></p><figcaption><p><a href="https://knowyourmeme.com/memes/shitting-toothpaste-pooping-toothpaste">Source</a>. You earned a meme for making it
this far.</p></figcaption></figure>
<p>However, there are actually quite a few ways of dropping media with <a href="#webtransport">WebTransport</a>:</p>
<ol>
<li>Use datagrams and choose which packets to transmit. (like WebRTC)</li>
<li>Use QUIC streams and close them to stop transmissions. (like <a href="https://www.ietf.org/archive/id/draft-kpugin-rush-00.html">RUSH</a>)</li>
<li>Use QUIC streams and prioritize them. (like <a href="https://www.youtube.com/watch?v=PncdrMPVaNc">Warp</a>)</li>
</ol>
<p>I’m biased because I made the 3rd one.
WebTransport’s <a href="https://www.w3.org/TR/webtransport/#dom-webtransportsendstreamoptions-sendorder">sendOrder</a> can be used to instruct the QUIC stack what should be sent during congestion.
But that deserves an entire blog post on its own.</p>
<h2 id="replacing-webrtc-2">Replacing WebRTC</h2>
<p>But to actually replace WebRTC, we need a standard. Anybody can make their own UDP-based protocol (<em>and they do</em>), using this new web tech (<em>and they will</em>).</p>
<p>What sets <a href="https://datatracker.ietf.org/wg/moq/about/">Media over QUIC</a> apart is that we’re doing it through the IETF, the same organization that standardized WebRTC… and virtually every internet protocol.</p>
<p>It’s going to take years.<br>
It’s going to take a lot of idiots like myself who want to replace WebRTC. <br>
It’s going to take a lot of companies who are willing to bet on a new standard.<br></p>
<p>And there are major flaws with both <strong>WebCodecs</strong> and <strong>WebTransport</strong> that still need to be addressed before we’ll ever reach WebRTC parity.
To name a few:</p>
<ul>
<li>We need better <a href="https://www.w3.org/TR/webtransport/#dom-webtransportoptions-congestioncontrol">congestion control</a> in browsers.</li>
<li>We need something like <a href="https://webrtc.googlesource.com/src/+/refs/heads/main/docs/native-code/rtp-hdrext/transport-wide-cc-02/README.md">transport-wide-cc</a> in QUIC: <a href="https://www.ietf.org/archive/id/draft-smith-quic-receive-ts-00.html">like this proposal</a></li>
<li>We need echo cancellation in <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">WebAudio</a>, which might be possible?</li>
<li>We may need <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction">FEC</a> in QUIC: <a href="https://datatracker.ietf.org/doc/draft-michel-quic-fec/">like this proposal</a></li>
<li>We may need more encoding options, like non-reference frames or SVC.</li>
<li>Oh yeah and full browser support: <a href="https://caniuse.com/webcodecs">WebCodecs</a> - <a href="https://caniuse.com/webtransport">WebTransport</a></li>
</ul>
<h2 id="so-yeah">So yeah…</h2>
<p>Written by <a href="https://github.com/kixelated">@kixelated</a>.
Hit me up on <a href="https://discord.gg/FCYF3p99mr">Discord</a> if you want to help!</p>
<p>Tune in for next week’s episode: <strong>Replacing HLS/DASH</strong> and then <strong>Replacing RTMP</strong>.</p>
<img src="https://quic.video/blog/kixelCat.png"></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The costs of microservices (2020) (256 pts)]]></title>
            <link>https://robertovitillo.com/costs-of-microservices/</link>
            <guid>38069915</guid>
            <pubDate>Mon, 30 Oct 2023 14:33:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://robertovitillo.com/costs-of-microservices/">https://robertovitillo.com/costs-of-microservices/</a>, See on <a href="https://news.ycombinator.com/item?id=38069915">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header><p>November 22, 2020</p></header><p>An application typically starts its life as a monolith. Take a modern backend of a single-page Javascript application, for example - it starts out as a single stateless web service that exposes a RESTful HTTP API and uses a relational database as a backing store. The service is composed of a number of components, or libraries, that implement different business capabilities:</p><p><span>
      <a href="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/024d6/monolith.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Monolith" title="Monolith" src="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/fcda8/monolith.png" srcset="https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/12f09/monolith.png 148w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/e4a3f/monolith.png 295w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/fcda8/monolith.png 590w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/efc66/monolith.png 885w,https://robertovitillo.com/static/20b3d909b15d98f33bee31e8357203ce/024d6/monolith.png 961w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>As the number of feature teams contributing to the same codebase increases, its components become increasingly coupled over time. This leads the teams to step on each other’s toes more and more frequently, decreasing their productivity. </p><p>The codebase becomes complex enough that nobody fully understands every part of it, and implementing new features or fixing bugs becomes time-consuming. Even if the backend is componentized into different libraries owned by different teams, a change to a library requires the service to be redeployed. And if a change introduces a bug - like a memory leak - the entire service can potentially be affected by it. Additionally, rolling back a faulty build affects the velocity of all teams, not just the one that introduced the bug.</p><p>One way to mitigate the growing pains of a <em>monolithic</em> backend is to split it into a set of independently deployable services that communicate via APIs. The APIs decouple the services from each other by creating boundaries that are hard to violate, unlike the ones between components running in the same process: </p><p><span>
      <a href="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/dc61a/api_gw.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Microservices" title="Microservices" src="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/fcda8/api_gw.png" srcset="https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/12f09/api_gw.png 148w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/e4a3f/api_gw.png 295w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/fcda8/api_gw.png 590w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/efc66/api_gw.png 885w,https://robertovitillo.com/static/54b0da5dd791ad53ea771e66c73f5d67/dc61a/api_gw.png 1147w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>This architectural style is also referred to as the microservice architecture. The term <em>micro</em> can be misleading, though - there doesn’t have to be anything micro about the services. In fact, I would argue that if a service doesn’t do much, it just creates more operational toll than benefits. A more appropriate name for this architecture is <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">service-oriented architecture</a>, but unfortunately, that name comes with some old baggage as well. Perhaps in 10 years, we will call the same concept with yet another name, but for now we will have to stick to microservices. </p><p>Breaking down the backend by business capabilities into a set of services with well-defined boundaries allows each service to be developed and operated by a single small team. The reduced team size increases the application’s development speed for a variety of reasons:</p><ul><li>Smaller teams are more effective as the communication overhead grows <a href="https://en.wikipedia.org/wiki/The_Mythical_Man-Month">quadratically</a> with the team’s size.</li><li>As each team dictates its own release schedule and has complete control over its codebase, less cross-team communication is required, and therefore decisions can be taken in less time.</li><li>The codebase of a service is smaller and easier to digest by its developers, reducing the time it takes to ramp up new hires. Also, a smaller codebase doesn’t slow down IDEs, which makes the developers more productive. </li><li>The boundaries between services are much stronger than the boundaries between components in the same process. Because of that, when a developer needs to change a part of the backend, they only need to understand a small part of the whole. </li><li>Each service can be scaled independently and adopt a different technology stack based on its own needs. The consumers of the APIs don’t care how the functionality is implemented after all. This makes it easy to experiment and evaluate new technologies without affecting other parts of the system.</li><li>Each microservice can have its own independent data model and data store(s) that best fit its use-cases, allowing developers to change its schema without affecting other services. </li></ul><h2 id="costs"><a href="#costs" aria-label="costs permalink"></a>Costs</h2><p>The microservices architecture adds more moving parts to the overall system, and this doesn’t come for free. The cost of fully embracing microservices is only worth paying if it can be amortized across dozens of development teams. </p><p><strong>Development Experience</strong></p><p>Nothing forbids the use of different languages, libraries, and datastores for each microservice - but doing so transforms the application into an unmaintainable mess. For example, it makes it more challenging for a developer to move from one team to another if the software stack is completely different. And think of the sheer number of libraries - one for each language adopted - that need to be supported to provide common functionality that all services need, like logging.</p><p>It’s only reasonable then that a certain degree of standardization is needed. One way to do that - while still allowing some degree of freedom - is to loosely encourage specific technologies by providing a great development experience for the teams that stick with the recommended portfolio of languages and technologies.</p><p><strong>Resource Provisioning</strong></p><p>To support a large number of independent services, it should be simple to spin up new servers, data stores, and other commodity resources - you don’t want every team to come up with their own way of doing it. And once these resources have been provisioned, they have to be configured. To be able to pull this off, you will need a fair amount of automation.</p><p><strong>Communication</strong></p><p>Remote calls are expensive and introduce <a href="https://robertovitillo.com/default-timeouts/">new and fun ways</a> your systems can crumble. You will need defense mechanisms to protect against failures, like timeouts, retries and circuit breakers. You will also have to leverage asynchrony and batching to mitigate the performance hit of communicating across the network. All of which increases the system’s complexity. A lot of what I describe in my <a href="https://understandingdistributed.systems/">book about distributed systems</a> is about dealing with this complexity. </p><p>That being said, even a monolith doesn’t live in isolation as it’s being accessed by remote clients, and it’s likely to use third-party APIs as well. So eventually, these issues need to be solved there as well, albeit on a smaller scale.</p><p><strong>Continuous Integration, Delivery, and Deployment</strong></p><p>Continuous integration ensures that code changes are merged into the main branch after an automated build and test processes have run. Once a code change has been merged, it should be automatically published and deployed to a production-like environment, where a battery of integration and end-to-end tests run to ensure that the microservice doesn’t break any service that depends on it.</p><p>While testing individual microservices is not more challenging than testing a monolith, testing the integration of all the microservices is an order of magnitude harder. Very subtle and unexpected behavior can emerge when individual services interact with each other. </p><p><strong>Operations</strong></p><p>Unlike with a monolith, it’s much more expensive to staff each team responsible for a service with its own operations team. As a result, the team that develops a service is typically also on-call for it. This creates friction between development work and operational toll as the team needs to decide what to prioritize during each sprint. </p><p>Debugging systems failures becomes more challenging as well - you can’t just load the whole application on your local machine and step through it with a debugger. The system has more ways to fail, as there are more moving parts. This is why good logging and monitoring becomes crucial at all levels.</p><p><strong>Eventual Consistency</strong></p><p>A side effect of splitting an application into separate services is that the data model no longer resides in a single data store. Atomically updating records stored in different data stores, and guaranteeing strong consistency, is slow, expensive, and hard to get right. Hence, this type of architecture usually requires embracing eventual consistency.</p><h2 id="practical-considerations"><a href="#practical-considerations" aria-label="practical considerations permalink"></a>Practical Considerations</h2><p>Splitting an application into services adds a lot of complexity to the overall system. Because of that, it’s generally best to start with a monolith and split it up only when there is a good reason to do so. </p><p>Getting the boundaries right between the services is challenging - it’s much easier to move them around within a monolith until you find a sweet spot. Once the monolith is well matured and growing pains start to rise, then you can start to peel off one microservice at a time from it. </p><p>You should only start with a microservice first approach if you already have experience with it, and you either have built out a platform for it or have accounted for the time it will take you to build one. </p><hr></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I accidentally saved my company half a million dollars (609 pts)]]></title>
            <link>https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/</link>
            <guid>38069710</guid>
            <pubDate>Mon, 30 Oct 2023 14:15:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/">https://ludic.mataroa.blog/blog/i-accidentally-saved-half-a-million-dollars/</a>, See on <a href="https://news.ycombinator.com/item?id=38069710">Hacker News</a></p>
<div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        

        

        <div itemprop="articleBody">
            <p>I saved my company half a million dollars in about five minutes. This is more money than I've made for my employers over the course of my entire career because this industry is a sham. I clicked about five buttons.</p>
<p>Let's talk about why happened and why it's a disgrace that it was even possible.</p>
<h2 id="i-background">I. Background</h2>
<p>Let's start with some background, because it is fucking <em>wild</em> that an inefficiency that took me five minutes to solve in a GUI configuration panel was allowed to persist. We <em>cancelled someone's contract</em> the week before I did this. <em>Someone lost their job</em> because no one could get their act together long enough to click the button I told them to click.</p>
<p>A few years ago, this company decided that it wanted to create an analytics platform, following the decision to become more "data driven". They hired some incredibly talented people to make this happen, and then like five times as many idiots.</p>
<p>At the time this was happening, I had just graduated and joined the organization as a data scientist. We, of course, did not do any data science, because the organization did not require any data science to be done - what they actually needed to do was fire most of the staff in every team, leaving behind the two people who actually had good domain knowledge, then allow them to collaborate with good engineering teams to build sensible processes and systems. Instead, they hired a bunch of Big Firm Consultants. You can see where this is going already.</p>
<p>Nonetheless, at the time I was young and took the organization at its word. Executives would tell us constantly how excited they were for us to roll out new A.I initiatives (then tell us there was no time, so could we please get that report to them in a spreadsheet), and I'd ask for some sort of compute to <em>perform</em> some machine learning, or even set up data pipelines.</p>
<p>It never worked. Instead, we were told that we just had to wait for the Advanced Analytics Platform (AAP) to be deployed. You see, it's December, and it's launching in January.</p>
<p>Then in January I was told to be patient, it was coming in March.</p>
<p>In June, I was told it had been put on hold due to Covid - this was a very convenient excuse because they had absolutely fucked the whole project up already, but it bought some valuable time. By the next December, I had left the organization and the AAP was still nowhere to be seen.</p>
<p>We skip ahead three years. The AAP is finally ready to launch. It turns out none of the features I needed were ever planned, so I guess they were just lying to me before I left.</p>
<p>Four engineers leave the company in the same week, and I speak with the directors because I know they need a <em>real</em> engineer in and they can't find them. I'm a substantially less experienced engineer than many of the readers here, but suffice it to say that I can read documentation without panicking, which is considered S-tier in this country. My conditions - a big pile of money and they had to put me on the AAP team because they're the only team that gets actual toys to play with.</p>
<h2 id="ii-it-fucking-sucks">II. It Fucking Sucks</h2>
<p>It's an insane dumpster fire spiderweb of technical debt and it's only like one week old. Here are some fun details.</p>
<p>I get a friend of mine hired (big fan of nepotism), and he finds, <em>on day one</em>, a file in the project's repository that deletes prod using our CI/CD pipelines if it is ever moved into the wrong folder. It comes complete with the key and password required for an admin account. It was produced by the former lead engineer, who has moved on to a new role before his sins catch up with him.</p>
<p>The entire thing is stitched together by spreadsheets that are parsed by Python, dropped into S3, parsed by Lambdas into more S3, the S3 files are picked up by MongoDB, then MongoDB records are passed by another Lambda into S3, the S3 files are pulled into Snowflake via Snowpipe, the new Snowflake data is pivoted by a Javascript stored procedure into a relational format... and that's how you edit someone's database access. That whole process is to upload like a 2KB CSV to a database that has people's database roles in it.</p>
<p>This is considered <em>more auditable</em>.</p>
<p>Everything is transformed into a CSV because the security team demanded something that could undergo easy scanning for malicious content, then they never deployed the scanning tool, so we have all the downsides of the CSVs and none of the upsides.</p>
<p>Every Lambda function, the backbone of all the ETL pipelines, starts with <code>counter = 1</code> because one of the early iterations <em>used to use a counter</em> and people have just been copying that line over and over. <em>Senior data engineers</em> have been copying that line over and over.</p>
<p>The test suites in the CI/CD pipelines have been failing for months, because someone during debugging chose to use the Linux <code>tee</code> command to log any errors to both <code>stdout</code> and a file at the same time, but <code>tee</code> successfully executing was overwriting the error code from the failing tests.</p>
<p>To get access to the password for any API we need to hit, you search for something like <code>service-password</code> in an AWS service, which returns the value... <code>service-password</code> (as in, literally all the values are the same as the keys), then you use <em>that</em> to look up the actual password in a completely different service. No one knows why we do this.</p>
<p>The script that generates configuration files for our pipelines starts with 600 lines of comments, because senior engineers have been commenting the lines out in case they're needed later. The lines are just setting the same variables to different values, and they're all on GitHub anyway.</p>
<p>This is at an organization that some percentage of readers will recognize on sheer brand strength if they're in my country.</p>
<p>I'm not even getting started, but we have to stop for now because I am going to catch fire. These details are important because now you understand the kind of operational incompetence that allows you to waste so much money on processing &lt;1TB of data per day that it dwarfs your team's salary.</p>
<h2 id="iii-the-budget">III.  The Budget</h2>
<p>The next thing to realize is that this platform never really had a chance of making any money for the organization. They do a little accounting trick (read: lying) which I'll talk about in another post that makes it seem like they've had huge wins, but really this is just many times more expensive than our previous operational model.</p>
<p>The deal is that we pretend the whole team is doing something or other, and we stay within budget because the organization can't afford to spend infinite money on this social fiction. However, the budget for our database costs was being drastically overrun. I'm not sure what the original estimate was, but I think it was intended to cost something like 200K for a year of operations, but we were now close to a million dollars.</p>
<p>Some quick facts:</p>
<ol>
<li>We use Snowflake as our database, which charges you based on the size of the computer you use to run your queries.</li>
<li>You only pay for computers while they're on.</li>
<li>We probably run a few thousand queries per week, mostly developers experimenting with little tweaks for PowerBI reports that no one reads, and on average they take about 2 seconds to run.</li>
<li><strong>The computers are set to idle for 10 minutes after every query</strong>.</li>
</ol>
<p>I noticed this about a month into joining the team, and suggested we uh... don't have the computers run for like two orders of magnitude longer than they need to for every query. I literally can't remember what was said, there was some Agile bullshit about doing a discovery piece, then it just never happened.</p>
<h2 id="iv-just-doing-the-fucking-thing">IV. Just Doing The Fucking Thing</h2>
<p>Anyway, <em>months</em> later, they finally give me a card that says "Discovery: Optimise Costs". Now I <em>have</em> to optimize costs so that I have something to say at the next standup, and fortunately I know just the thing! I'll test my hypothesis that this is all a sick joke, and I'm going to push the button that I secretly think should obviously have been pushed.</p>
<p>We've got a new guy on another team who seems excellent, so I ask management if I can give him admin credentials since we need competent people. They say no. I flick him some lower-level database credentials that I <em>technically</em> wasn't told not to do since they aren't admin credentials, and he sanity-checks that it would save money. At 4PM on the last day of the week, I ping a chat full of good engineers and no managers to make sure I'm not about to nuke everything, then just do it.</p>
<h2 id="v-chaos-reigns">V.  Chaos Reigns</h2>
<p>I return to work the following Monday. I <em>suspected</em> that this would save a bunch of money, and guess what, our projected bill dropped from a million to half a million dollars, and everyone is losing their fucking minds.</p>
<p>My team has spun this as a huge cost saving, when <em>really</em> we just applied a fire extinguisher to the pile of money that we had set alight.</p>
<p>Other teams are attacking my team, insisting that it can't be a coincidence that the one new guy joined exactly as we did this, and how was it possible we didn't know how to generate that kind of saving without his help? They are saying this because it makes them seem higher status and their teams only produce money in the land where you lie all day, but it <em>is</em> a fair question.</p>
<p>While my managers are very happy, they quietly suggest it may be unwise to roll out the changes to all the computers (I only did a few to be safe) because it would oversaturate the department to hear about us all day. And invite unwelcome questions. The subtext is that if we do this all slowly enough, it might seem like it took a lot of effort instead of just clicking buttons that I said had to be clicked almost a year ago.</p>
<p>I am asked to write some PowerPoints, which include phrases like "a careful statistical analysis of user usage patterns indicated an opportunity to more effectively allocate resources", implying that nothing was <em>wrong</em>, we just needed to collect more data before deciding not to let the expensive machines idle all day.</p>
<p>Every day, I dread someone asking me to explain what the change was, because I will have to fucking <em>yeet</em> some managers I like under a bus, but they can't resist talking about the change non-stop because it is the closest some of them will ever get to impacting the bottom line. And <em>many of them are actually decent managers</em>, it's just that this whole department, like many departments, is some sort of weird political PsyOp to get executives promoted. It's <em>cosplaying as a real business</em> and the board thinks the costume is convincing. </p>
<h2 id="vi-the-aftermaths-and-takeaways">VI. The Aftermaths and Takeaways</h2>
<p>By identifying a handful of good engineers and going totally rogue, we outperformed the entire department pretty effortlessly. The competent people are there, just made totally impotent by the organization, and I'm still convinced that this place is probably better than the median organization.</p>
<p>I ask management for a 30K raise after saving 500K and my message is still unread. I suspect I will eventually receive either nothing or 5K.</p>
<p>I have even more meetings now because everyone wants to talk about how we saved the money. I had to make a PowerPoint. Kill me.</p>
<p>I would have been better off <em>not doing anything</em>. Let that be a lesson to you. Do you hear me? I applied myself for <em>five minutes</em> against my own better judgement, had the greatest success of my career, and have immediately been punished for it. <em>Learn from my mistakes, I beg of you.</em></p>
        </div>
    </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[eBPF-based auto-instrumentation outperforms manual instrumentation (145 pts)]]></title>
            <link>https://odigos.io/blog/ebpf-instrumentation-faster-than-manual</link>
            <guid>38069659</guid>
            <pubDate>Mon, 30 Oct 2023 14:10:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://odigos.io/blog/ebpf-instrumentation-faster-than-manual">https://odigos.io/blog/ebpf-instrumentation-faster-than-manual</a>, See on <a href="https://news.ycombinator.com/item?id=38069659">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>We're developing Odigos, an open-source project for effortless distributed tracing. See more at <a href="https://github.com/keyval-dev/odigos">https://github.com/keyval-dev/odigos</a>.</p>
<p>Distributed tracing tracks the journey of requests as they move through a distributed system, offering insights for debugging, performance optimization, and end-to-end visibility. It is crucial for gaining in-depth insights into request flows within complex distributed systems.</p>
<p>However, there are two ways in which it can suck: extensive code changes (requires manual instrumentation), and a significant performance impact.</p>
<p>Odigos addresses the code change challenge by using eBPF for automating tracing without any manual effort or code changes. We generate traces in OpenTelemetry format, ensuring compatibility and avoiding vendor lock-in. You can read more <a href="https://news.ycombinator.com/item?id=34442603">here</a></p>
<p>That leaves the performance issues, which we’ve been working on. Our performance tests, which we’ll go into below, show that eBPF-based automatic instrumentation is over 20x faster than manually instrumenting code. This is achieved by separating data recording and data processing, eliminating extra workload, object allocation, and network calls during application runtime.</p>
<p>As a result, you can have the best of both worlds: automated distributed tracing with minimal performance overhead.</p>
<h2>How we tested</h2>
<p>Benchmarking latency is not a trivial task. Latency can be measured in many different ways, each with its own advantages and disadvantages. Our testing is inspired by this excellent talk by Gil Tene called <a href="https://www.youtube.com/watch?v=lJ8ydIuPFeU">How NOT to Measure Latency</a>. We are using a <a href="http://hdrhistogram.org/">High Dynamic Range Histogram</a> to visualize the results and <a href="https://github.com/giltene/wrk2">wrk2</a> to generate load.</p>
<p>In order to reduce noise as much as possible, we are running each test on a dedicated AWS bare metal instance (c5n.metal) with Intel Xeon Platinum 8000 series (Skylake-SP) processor.</p>
<p>For the target application, we are using a simple Go HTTP server written in Go 1.21 that returns a simple JSON response.</p>
<h2>Test results</h2>
<p>Each test is run for 5 minutes and generates 10,000 requests per second.
First, we ran the test without any instrumentation. Then we ran the test with manual instrumentation using <a href="https://github.com/open-telemetry/opentelemetry-go">OpenTelemetry Go SDK</a> and finally, we ran the test with <a href="https://github.com/open-telemetry/opentelemetry-go-instrumentation">eBPF-based automatic instrumentation</a>.</p>
<p><img src="https://odigos.io/images/blog/ebpf-vs-manual/results.png" alt="Test Results"></p>
<p>At the lower percentiles (up to the 99.9th percentile), the overhead of not having instrumentation, manual instrumentation, and eBPF-based automatic instrumentation is similar</p>
<p>However, at the higher percentiles (99.9th percentile and above), manual instrumentation has a significantly higher overhead than eBPF-based automatic instrumentation, which is over 20x faster.</p>
<p>If you're wondering whether the top of the spectrum matters, the answer is yes, especially in distributed environments. The following table shows how many clients will experience the 99th percentile latency according to the number of different services involved in the request (taken from Gil's talk)</p>
<p><img src="https://odigos.io/images/blog/ebpf-vs-manual/p99_is_a_lie.png" alt="p99 is a lie"></p>
<p>For maximum precision and isolation, we are generating traces containing a single span. In a production environment, we anticipate the performance difference to be even greater.</p>
<h2><strong>The performance impact of generating distributed traces</strong></h2>
<p>Let's see what happens inside our application when we generate distributed traces, either manually via SDKs or automatically via something like a Java agent or monkey patching:</p>
<ol>
<li><strong>Recording data</strong> - Spans objects that contain the relevant data are being created</li>
<li><strong>Maintaining a queue of data</strong> - Spans are being batched in a queue before being sent to the external system</li>
<li><strong>Delivering data to the external system</strong> - The application sends the data in the queue to the external system by making network calls, serializing the data, and sending it over the network.</li>
</ol>
<p>Another consideration to keep in mind is that the application runtime must now manage more objects, which can negatively impact heap size and GC performance, especially in languages with stop-the-world GC like Java. All this can lead to longer GC pauses and decreased performance. We'll dive deeper and explore this topic in a separate blog post. Stay tuned.</p>
<p>Unlike metrics and logs, distributed tracing is a stateful signal. Logs are typically written to a file, and metrics are typically pulled from an HTTP endpoint by the monitoring system (for example <code>/metrics</code> endpoint when exposing Prometheus metrics). Distributed tracing is different. It requires the application to actively send batched data to an external system.</p>
<h2>Separation between recording and processing</h2>
<p>When using eBPF to generate distributed traces, we are separating the recording of the data from the processing of the data. The recording of the data is done by the eBPF program and the processing and delivery of the data is done by a different process. This means that the application runtime does no additional work, creates no additional objects, and makes no additional network calls. The only additional overhead (compared to not having any instrumentation) is the overhead of invoking eBPF programs (context switching from user space to kernel space).</p>
<h2>Conclusion</h2>
<p>Traditionally, there has been a tradeoff between automated distributed tracing and performance.</p>
<p>Odigos solves this problem by providing a way to automate distributed tracing that actually improves performance. This is because we use eBPF-based automatic instrumentation to  reduce the overhead of generating distributed tracing data.</p>
<p><strong>As a result, you can now have the best of both worlds: automated distributed tracing without any performance overhead</strong>.</p>
<h2>More updates coming soon</h2>
<p>eBPF-based automatic instrumentation is a game-changer, enabling us to generate distributed traces <strong>without code changes</strong> or <strong>performance impact</strong>. We're just getting started and will bring this to more programming languages soon. Stay tuned!</p>
<h2>Try it out</h2>
<p>The easiest way to try eBPF-based distributed tracing today is to use our <a href="https://github.com/keyval-dev/odigos">open-source project, Odigos</a>. Please support us by starring ⭐ the project on <a href="https://github.com/keyval-dev/odigos">GitHub</a>.</p>
</div><p>If you want to learn more about how you can generate distributed traces instantly check out our GitHub repository. We'd really appreciate it if you could throw us a ⭐👇<br><a target="_blank" href="https://github.com/keyval-dev/odigos">https://github.com/keyval-dev/odigos</a></p></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Private equity is devouring the U.S. economy (197 pts)]]></title>
            <link>https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/</link>
            <guid>38069197</guid>
            <pubDate>Mon, 30 Oct 2023 13:25:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/">https://www.theatlantic.com/ideas/archive/2023/10/private-equity-publicly-traded-companies/675788/</a>, See on <a href="https://news.ycombinator.com/item?id=38069197">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Private equity has made one-fifth of the market effectively invisible to investors, the media, and regulators.</p></div><div><figure><div><picture><source media="(prefers-reduced-motion)" srcset="https://cdn.theatlantic.com/thumbor/KqAoGR-ALX6d3-jBGpkilpaU03I=/1x0:965x542/750x422/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 750w, https://cdn.theatlantic.com/thumbor/Q5D6I_yQHCbAUkh-3rYKLBMBRZE=/1x0:965x542/828x466/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 828w, https://cdn.theatlantic.com/thumbor/XEuPcHpzWO4gGxZIDfEDeJhbvmI=/1x0:965x542/960x540/filters:still()/media/img/mt/2023/10/StockMarketPoof/original.gif 960w" sizes="(min-width: 976px) 976px, 100vw"><img alt="A photo illustration of the Wall Street bull disappearing in a white cloud" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/ceBGZTUB0XWRyhFxoU7FR-BVOgU=/1x0:965x542/750x422/media/img/mt/2023/10/StockMarketPoof/original.gif 750w, https://cdn.theatlantic.com/thumbor/u5YnhlXBkjIweWXPNFR2mvu0dOM=/1x0:965x542/828x466/media/img/mt/2023/10/StockMarketPoof/original.gif 828w, https://cdn.theatlantic.com/thumbor/j46ndE6sj1BBs3_vsXowNBwva5A=/1x0:965x542/960x540/media/img/mt/2023/10/StockMarketPoof/original.gif 960w" src="https://cdn.theatlantic.com/thumbor/j46ndE6sj1BBs3_vsXowNBwva5A=/1x0:965x542/960x540/media/img/mt/2023/10/StockMarketPoof/original.gif" width="960" height="540"></picture></div><figcaption>Illustration by The Atlantic. Sources: Shutterstock; Getty.</figcaption></figure></div></div><div><p><time datetime="2023-10-30T11:30:00Z">October 30, 2023, 7:30 AM ET</time></p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body"><p><em><small>Updated at 9:30 a.m. ET on October 30, 2023</small></em></p><p>T<span>he publicly traded company </span>is disappearing. In 1996, about 8,000 firms were listed in the U.S. stock market. Since then, the national economy has grown by nearly $20 trillion. The population has increased by 70 million people. And yet, today, the number of American public companies stands at <a data-event-element="inline link" href="https://www.cnn.com/2023/06/09/investing/premarket-stocks-trading/index.html">fewer than 4,000</a>. How can that be?</p><p>One answer is that the private-equity industry is devouring them. When a private-equity fund buys a publicly traded company, it takes the company private—hence the name. (If the company has not yet gone public, the acquisition keeps that from happening.) This gives the fund total control, which in theory allows it to find ways to boost profits so that it can sell the company for a big payday a few years later. In practice, going private can have more troubling consequences. The thing about public companies is that they’re, well, public. By law, they have to disclose information about their finances, operations, business risks, and legal liabilities. Taking a company private exempts it from those requirements.</p><p>That may not have been such a big deal when private equity was a niche industry. Today, however, it’s anything but. In 2000, private-equity firms managed about 4 percent of total U.S. corporate equity. By 2021, that number was closer to 20 percent. In other words, private equity has been growing nearly five times faster than the U.S. economy as a whole.</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/ideas/archive/2022/12/stock-market-inflation-interest-rates-recession/672612/">James Surowiecki: The method in the market’s madness</a></p><p>Elisabeth de Fontenay, a law professor at Duke University who studies corporate finance, told me that if current trends continue, “we could end up with a completely opaque economy.”</p><p>This should alarm you even if you’ve never bought a stock in your life. One-fifth of the market has been made effectively invisible to investors, the media, and regulators. Information as basic as who actually owns a company, how it makes its money, or whether it is profitable is “disappearing indefinitely into private equity darkness,” as the Harvard Law professor John Coates writes in his book <a data-event-element="inline link" href="https://tertulia.com/book/the-problem-of-twelve-when-a-few-financial-institutions-control-everything-john-coates/9798987053546?affiliate_id=atl-347"><em>The Problem of Twelve</em></a>. This is not a recipe for corporate responsibility or economic stability. A private economy is one in which companies can more easily get away with wrongdoing and an economic crisis can take everyone by surprise. And to a startling degree, a private economy is what we already have.</p><p>A<span>merica learned </span>the hard way what happens when corporations operate in the dark. Before the Great Depression, the whole U.S. economy functioned sort of like the crypto market in 2021. Companies could raise however much money they wanted from whomever they wanted. They could claim almost anything about their finances or business model. Investors often had no good way of knowing whether they were being defrauded, let alone whether to expect a good return.</p><p>Then came the worst economic crisis in U.S. history. From October to December of 1929, the stock market lost 50 percent of its value, with more losses to come. Thousands of banks collapsed, wiping out the savings of millions of Americans. Unemployment spiked to 25 percent. The Great Depression generated a crisis of confidence for American capitalism. Public hearings revealed just how rampant corporate fraud had become before the crash. In response, Congress passed the Securities Act of 1933 and the Securities Exchange Act of 1934. These laws launched a regime of “full and fair disclosure” and created a new government agency, the Securities and Exchange Commission, to enforce it. Now if companies wanted to raise money from the public, they would have to disclose a wide array of information to the public. This would include basic details about the company’s operations and finances, plus a comprehensive list of major risks facing the company, plans for complying with current and future regulations, and documentation of outstanding legal liabilities. All of these disclosures would be reviewed for accuracy by the SEC.</p><p>This regime created a new social contract for American capitalism: scale in exchange for transparency. Private companies were limited to 100 investors, putting a hard limit on how quickly they could grow. Any business that wanted to raise serious capital from the public had to submit itself to the new reporting laws. Over the next half century, this disclosure regime would underwrite the longest period of economic growth and prosperity in U.S. history. But it didn’t last. Beginning in the “Greed Is Good” 1980s, a wave of deregulatory reforms made it easier for private companies to raise capital. Most important was the National Securities Markets Improvement Act of 1996, which allowed private funds to raise an unlimited amount of money from an unlimited number of institutional investors. The law created a loophole that effectively broke the scale-for-transparency bargain. Tellingly, 1997 was the year the <a data-event-element="inline link" href="https://www.federalreserve.gov/econres/notes/feds-notes/the-post-covid-stock-listing-boom-20220617.html">number</a> of public companies in America peaked.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/magazine/archive/2018/11/private-inequity/570808/">From the November 2018 issue: The death of the IPO</a></p><p>“Suddenly, private companies could raise all the money they want without even thinking about an IPO,” De Fontenay said. “That completely undermined the incentives companies had to go public.” Indeed, from 1980 to 2000, an average of 310 companies went public every year; from 2001 to 2022, only 118 did. The number briefly shot up during the coronavirus pandemic but has since fallen. (Over the same time period, the rate of mergers and acquisitions <a data-event-element="inline link" href="https://www.theatlantic.com/business/archive/2016/01/2015-mergers-acquisitions/423096/">soared</a>, which also helps explain the decline in public companies.)</p><p>Meanwhile, private equity has matured into a multitrillion-dollar industry, devoted to making short-term profits from highly leveraged transactions, operating with almost no regulatory or public scrutiny. Not all private-equity deals end in calamity, of course, and not all public companies are paragons of civic virtue. But the secrecy in which private-equity firms operate emboldens them to act more recklessly—and makes it much harder to hold them accountable when they do. Private-equity investment in nursing homes, to take just one example, <a data-event-element="inline link" href="https://www.ineteconomics.org/uploads/papers/WP_118-Appelbaum-and-Batt-2-rb-Clean.pdf">has grown</a> from about $5 billion at the turn of the century to more than $100 billion today. The results have not been pretty. The industry seems to have recognized that it could improve profit margins by cutting back on staffing while relying more on psychoactive medication. Stories abound of patients being <a data-event-element="inline link" href="https://www.washingtonpost.com/business/economy/opioid-overdoses-bedsores-and-broken-bones-what-happened-when-a-private-equity-firm-sought-profits-in-caring-for-societys-most-vulnerable/2018/11/25/09089a4a-ed14-11e8-baac-2a674e91502b_story.html">rushed</a> to the hospital after being overprescribed opioids, of bedside call buttons so <a data-event-element="inline link" href="https://www.newyorker.com/news/dispatch/when-private-equity-takes-over-a-nursing-home">poorly attended</a> that residents suffer in silence while waiting for help, of nurses being <a data-event-element="inline link" href="https://time.com/5843893/nursing-homes-workers-coronavirus/">pressured</a> to work while sick with COVID. A 2021 study <a data-event-element="inline link" href="https://www.nber.org/digest/202104/how-patients-fare-when-private-equity-funds-acquire-nursing-homes">concluded</a> that private-equity ownership was associated with about 22,500 premature nursing-home deaths from 2005 to 2017—<em>before</em> the wave of death and misery wrought by the pandemic.</p><p>Eventually, the public got wind of what was happening. The pandemic death count focused attention on the industry. Journalists and watchdog groups exposed the worst of the behaviors. Policy makers and regulators, at long last, began to take action. But by then, much of the damage had been done. “If we had some form of disclosure, we probably would have seen regulatory action a decade earlier,” Coates told me. “But instead, we’ve had 10-plus years of experimentation and abuse without anyone knowing.”</p><p>Something similar could be said about any number of industries, including <a data-event-element="inline link" href="https://www.nber.org/papers/w24976">higher education</a>, <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2021/11/alden-global-capital-killing-americas-newspapers/620171/">newspapers</a>, <a data-event-element="inline link" href="https://www.theatlantic.com/magazine/archive/2018/07/toys-r-us-bankruptcy-private-equity/561758/">retail</a>, and <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2020/02/how-private-equity-ruined-fairway/606625/">grocery stores</a>. Across the economy, private-equity firms are known for laying off workers, evading regulations, reducing the quality of services, and <a data-event-element="inline link" href="https://www.theatlantic.com/ideas/archive/2023/05/private-equity-firms-bankruptcies-plunder-book/673896/">bankrupting companies</a> while ensuring that their own partners are paid handsomely. The veil of secrecy makes all of this easier to execute and harder to stop.</p><p>Private-equity funds dispute many of the criticisms of the industry. They argue that the horror stories are exaggerated and that a handful of problematic firms shouldn’t tarnish the rest of the industry, which is doing great work. Freed from onerous disclosure requirements, they claim, private companies can build more dynamic, flexible businesses that generate greater returns for shareholders. But the lack of public information makes verifying these claims difficult. <a data-event-element="inline link" href="https://www.hbs.edu/ris/Publication%20Files/ReplicatingPE_201512_3859877f-bd53-4d3e-99aa-6daec2a3a2d3.pdf">Most</a> <a data-event-element="inline link" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=473341">careful</a> <a data-event-element="inline link" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2597259">academic</a> <a data-event-element="inline link" href="https://www.jstor.org/stable/30225708">studies</a> find that although private-equity funds slightly outperformed the stock market on average prior to the early 2000s, they no longer do so. When you take into account their high fees, they appear to be a worse investment than a simple index fund.</p><p>“These companies basically get to write their own stories,” says Alyssa Giachino, the research director at the Private Equity Stakeholder Project. “They produce their own reports. They come up with their own numbers. And there’s no one making sure they are telling the truth.”</p><p>I<span>n the Roaring ’20s,</span> the lack of corporate disclosure allowed a massive financial crisis to build up without anyone noticing. A century later, the growth of a new shadow economy could pose similar risks.</p><p>The hallmark of a private-equity deal is the so-called leveraged buyout. Funds take on massive amounts of debt to buy companies, with the goal of reselling in a few years at a profit. If all of that debt becomes hard to pay back—because of, say, an economic downturn or rising interest rates—a wave of defaults could ripple through the financial system. In fact, this has happened before: The original leveraged buyout mania of the 1980s <a data-event-element="inline link" href="https://www.latimes.com/archives/la-xpm-1989-10-29-op-140-story.html">helped spark</a> the 1989 stock-market crash. Since then, private equity has grown into a $12 trillion industry and has begun raising much of its money from unregulated, nonbank lenders, many of which are owned by the same private-equity funds taking out loans in the first place.</p><p>Meanwhile, interest rates have reached a 20-year high, posing <a data-event-element="inline link" href="https://www.wsj.com/articles/private-equity-exits-sink-to-one-of-lowest-points-in-over-a-decade-86b684b6">a direct threat</a> to private equity’s debt-heavy business model. In response, many private-equity funds have migrated toward even <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2023-09-26/private-equity-is-piling-debt-on-itself-like-never-before?sref=BGQFqz7X">riskier forms</a> of backroom financing. Many of these involve taking on even more debt on <a data-event-element="inline link" href="https://www.ft.com/content/afc90e17-253d-49a7-bc39-dc5fbe31e648">the assumption</a> that market conditions will soon improve enough to restore profitability. If that doesn’t happen—and many of these big deals fail—the implications could be massive.</p><p id="injected-recirculation-link-2" data-view-action="view link - injected link - item 3" data-event-element="injected link" data-event-position="3"><a href="https://www.theatlantic.com/ideas/archive/2023/10/private-equity-hospitals-health-care/675779">Joe Nocera and Bethany McLean: What financial engineering does to hospitals</a></p><p>The industry counters that private markets are a better place for risky deals precisely because they have fewer ties to the real economy. A traditional bank has a bunch of ordinary depositors, whereas if a private-equity firm goes bust, the losers are institutional investors: pension funds, university endowments, wealthy fund managers. Bad, but not catastrophic. The problem, once again, is that no one knows how true that story is. Banks have to disclose information to regulators about how much they’re lending, how much capital they’re holding, and how their loans are performing. Private lenders sidestep all of that, meaning that regulators can’t know what risks exist in the system or <a data-event-element="inline link" href="https://www.reuters.com/business/finance/blackstones-first-quarter-earnings-plunge-real-estate-slowdown-2023-04-20/">how tied they are</a> to the real economy.</p><p>“Everything could be just fine,” says Ana Arsov, a managing director at Moody’s Investors Service who leads research on private lending. “But the point is that we don’t have the information we need to assess risk. Who is making these loans? How big are they? What are the terms? We just don’t know. So the worry is that the leverage in the system might grow and grow and grow without anyone noticing. And we really don’t know what the effects could be if something goes wrong.”</p><p>The government appears to be at least somewhat <a data-event-element="inline link" href="https://www.fdic.gov/news/speeches/2023/spsept2023.html#:~:text=According%20to%20the%20findings%20of,to%20their%20reliance%20on%20leverage">aware</a> of this problem. In August, the SEC <a data-event-element="inline link" href="https://www.sec.gov/news/statement/crenshaw-statement-private-fund-advisers-082323">proposed</a> a new rule requiring private-equity fund advisers to give more information to their investors. That’s better than nothing, but it hardly addresses the bad behavior or systemic risk. Nearly a century ago, Congress concluded that the nation’s economic system could not survive as long as its most powerful companies were left to operate in the shadows. It took the worst economic cataclysm in American history to learn that lesson. The question now is what it will take to learn it again.</p><hr><p><em><small>This article originally stated that Ana Arsov works for Moody's Analytics. In fact, she works for Moody's Investors Service. </small></em></p></section><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Raspberry Pi 5 has no hardware video encoding and only HEVC decoding (288 pts)]]></title>
            <link>https://www.raspberrypi.com/news/introducing-raspberry-pi-5/#comment-1594055</link>
            <guid>38068801</guid>
            <pubDate>Mon, 30 Oct 2023 12:47:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.raspberrypi.com/news/introducing-raspberry-pi-5/#comment-1594055">https://www.raspberrypi.com/news/introducing-raspberry-pi-5/#comment-1594055</a>, See on <a href="https://news.ycombinator.com/item?id=38068801">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        
<p>Today, we’re delighted to announce the launch of Raspberry Pi 5, coming at the end of October. Priced at $60 for the 4GB variant, and $80 for its 8GB sibling (plus your local taxes), virtually every aspect of the platform has been upgraded, delivering a no-compromises user experience. Raspberry Pi 5 comes with new features, it’s over twice as fast as its predecessor, and it’s the first Raspberry Pi computer to feature silicon designed in‑house here in Cambridge, UK.</p>



<figure><img decoding="async" loading="lazy" width="1024" height="683" src="https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-1024x683.jpg" alt="A Raspberry Pi 5, photographed corner-on, against a plain grey background." srcset="https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-1024x683.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-768x512.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-1536x1024.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-2048x1365.jpg 2048w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-800x533.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/aa7841cb-421a-4000-8ab9-c77478a4f83b-900x600.jpg 900w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>







<p>Key features include:</p>



<ul>
<li>2.4GHz quad-core 64-bit Arm Cortex-A76 CPU</li>



<li>VideoCore VII GPU, supporting OpenGL ES 3.1, Vulkan 1.2</li>



<li>Dual 4Kp60 HDMI® display output</li>



<li>4Kp60 HEVC decoder</li>



<li>Dual-band 802.11ac Wi-Fi®</li>



<li>Bluetooth 5.0 / Bluetooth Low Energy (BLE)</li>



<li>High-speed microSD card interface with SDR104 mode support</li>



<li>2 × USB 3.0 ports, supporting simultaneous 5Gbps operation</li>



<li>2 × USB 2.0 ports</li>



<li>Gigabit Ethernet, with PoE+ support (requires separate PoE+ HAT, coming soon)</li>



<li>2 × 4-lane MIPI camera/display transceivers</li>



<li>PCIe 2.0 x1 interface for fast peripherals</li>



<li>Raspberry Pi standard 40-pin GPIO header</li>



<li>Real-time clock</li>



<li>Power button</li>
</ul>



<p>In a break from recent tradition, we are announcing Raspberry Pi 5 before the product arrives on shelves. Units are available to pre-order today from many of our Approved Reseller partners, and we expect the first units to ship by the end of October.</p>







<figure><p>
<iframe loading="lazy" title="Eben Upton introduces Raspberry Pi 5" width="500" height="281" src="https://www.youtube.com/embed/oo5wb4LDWW4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p><figcaption>Watch Eben do some talking about Raspberry Pi 5</figcaption></figure>







<p>We’re incredibly grateful to the community of makers and hackers who make Raspberry Pi what it is; you’ve been extraordinarily patient throughout the supply chain issues that have made our work so challenging over the last couple of years. We’d like to thank you: we’re going to ringfence all of the Raspberry Pi 5s we sell until at least the end of the year for single-unit sales to individuals, so you get the first bite of the cherry.</p>



<p>We’re also giving every print subscriber to <a href="http://magpi.cc/priorityboarding">The MagPi</a> and <a href="http://hsmag.cc/priorityboarding">HackSpace</a> magazines a single-use code, giving them priority access to Raspberry Pi 5 hardware. Click those links to learn more about our Priority Boarding programme — and if you subscribe today, you can get your hands on a Priority Boarding pass too.</p>







<figure>
<figure><img decoding="async" loading="lazy" width="1024" height="1024" data-id="101712" src="https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-1024x1024.jpg" alt="Cover of The MagPi magazine issue 143 (October 2023), with &quot;Introducing... Raspberry Pi 5&quot; cover feature " srcset="https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-1024x1024.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-300x300.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-150x150.jpg 150w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-768x768.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-1536x1536.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-2048x2048.jpg 2048w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-800x800.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-100x100.jpg 100w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-450x450.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/4e0dbb6b-f3e5-4bef-b14d-89c014e8196e-900x900.jpg 900w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<figure><img decoding="async" loading="lazy" width="1024" height="1024" data-id="101713" src="https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-1024x1024.jpg" alt="Cover of HackSpace magazine issue 71 (October 2023), with &quot;Eben Upton presents Raspberry Pi 5&quot; cover feature " srcset="https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-1024x1024.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-300x300.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-150x150.jpg 150w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-768x768.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-1536x1536.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-2048x2048.jpg 2048w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-800x800.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-100x100.jpg 100w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-450x450.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/190e2010-c309-4259-b4b4-2f7b8dc9cc9d-900x900.jpg 900w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</figure>











<p>Between now and the end of October, we’ll be running a series of regular articles and videos, focusing on different aspects of the platform. Keep checking in <a href="https://www.raspberrypi.com/5">here</a>.</p>



<h2>A little history</h2>



<p>Way back in June 2019, we launched Raspberry Pi 4, the first true PC-class Raspberry Pi computer. With a quad-core Arm Cortex-A72 processor clocked at 1.5GHz, it was roughly forty times faster than the original Raspberry Pi model from 2012. In many ways the timing was perfect: in March the following year, schools closed, and millions of schoolchildren around the world were sent to study from home. Tens of thousands of them were able to rely on a Raspberry Pi 4 as their primary PC.</p>







<figure><p>
<iframe loading="lazy" title="Introducing Raspberry Pi 5" width="500" height="281" src="https://www.youtube.com/embed/yul4gq_LrOI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>
</p><figcaption>Watch Raspberry Pi 5 show you all of its bits without talking</figcaption></figure>







<p>In the four years since then, Raspberry Pi 4, and its derivatives Raspberry Pi 400 and Compute Module 4, have become firm favourites of enthusiasts, educators, and professional design engineers worldwide. Modern Raspberry Pi 4 computers run 20% faster than the launch variant, with a core clock speed of 1.8GHz. And, despite the well publicised challenges that have affected the electronics supply chain over the last two years, we’ve made and sold over 14 million units of Raspberry Pi 4 in that time.</p>



<p>But time doesn’t stand still, and neither does our community’s appetite for performance. And since 2016 — the era of Raspberry Pi 3 — we’ve been quietly working on a much more radical overhaul of the Raspberry Pi platform. Today, that effort bears fruit, with the launch of Raspberry Pi 5: compared to Raspberry Pi 4, we have between two and three times the CPU and GPU performance; roughly twice the memory and I/O bandwidth; and for the first time we have Raspberry Pi silicon on a flagship Raspberry Pi device.</p>



<h2>New platform, new chipset</h2>



<p>Three new chips, each designed specifically for the Raspberry Pi 5 program, come together to deliver a step change in performance.</p>



<h3>BCM2712</h3>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="687" src="https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-1024x687.png" alt="Close-up photo of part of the Raspberry Pi 5 board, centring the metal shield over the BCM2712 chip, with laser etching identifying the chip." srcset="https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-1024x687.png 1024w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-300x201.png 300w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-768x515.png 768w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-1536x1031.png 1536w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-2048x1374.png 2048w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-800x537.png 800w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-450x302.png 450w, https://www.raspberrypi.com/app/uploads/2023/09/76f84f73-4b69-4eea-8bd3-6ab0dc0cd835-900x604.png 900w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>BCM2712 is a new 16-nanometer application processor (AP) from Broadcom, derived from the 28-nanometer BCM2711 AP which powers Raspberry Pi 4, with numerous architectural enhancements. At its heart is a quad-core 64-bit Arm Cortex-A76 processor, clocked at 2.4GHz, with 512KB per-core L2 caches, and a 2MB shared L3 cache. Cortex-A76 is three microarchitectural generations beyond Cortex-A72, and offers both more instructions per clock (IPC) and lower energy per instruction. The combination of a newer core, a higher clock speed, and a smaller process geometry yields a much faster Raspberry Pi, and one that consumes much less power for a given workload.</p>



<p>Our newer, faster CPU is complemented by a newer, faster GPU: Broadcom’s VideoCore VII, developed here in Cambridge, with fully open source Mesa drivers from our friends at Igalia. An updated VideoCore hardware video scaler (HVS) is capable of driving two simultaneous 4Kp60 HDMI displays, up from single 4Kp60 or dual 4Kp30 on Raspberry Pi 4. A 4Kp60 HEVC decoder and a new Image Sensor Pipeline (ISP), both developed at Raspberry Pi, round out the multimedia subsystem. To keep the system supplied with memory bandwidth, we have a 32-bit LPDDR4X SDRAM subsystem, running at 4267MT/s, up from an effective 2000MT/s on Raspberry Pi 4.</p>



<h3>RP1</h3>



<p>Previous Raspberry Pi generations were built on a <em>monolithic</em> AP architecture: while some peripheral functions were provided by an external device (the Via Labs VL805 USB controller and hub on Raspberry Pi 4, and the Microchip LAN951x and LAN7515 USB hub and Ethernet controller chips on earlier products), substantially all of the I/O functions were integrated into the AP itself. Fairly early in the history of Raspberry Pi, we realised that as we migrated the AP to progressively newer process nodes, this approach would eventually become both technically and economically unsustainable.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="682" src="https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-1024x682.png" alt="Close-up photo of part of the Raspberry Pi 5 board, centring the RP1 chip, on which the Raspberry Pi logo and text identifying the chip are printed" srcset="https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-1024x682.png 1024w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-768x512.png 768w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-800x533.png 800w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956-900x600.png 900w, https://www.raspberrypi.com/app/uploads/2023/09/45e129f7-036b-42e3-bb8c-7c7d87195956.png 1319w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Raspberry Pi 5, in contrast, is built on a disaggregated <em>chiplet</em> architecture. Here, only the major fast digital functions, the SD card interface (for board layout reasons), and the very fastest interfaces (SDRAM, HDMI, and PCI Express) are provided by the AP. All other I/O functions are offloaded to a separate I/O controller, implemented on an older, cheaper process node, and connected to the AP via PCI Express.</p>



<p>RP1 is our I/O controller for Raspberry Pi 5, designed by the same team at Raspberry Pi that delivered the RP2040 microcontroller, and implemented, like RP2040, on TSMC’s mature 40LP process. It provides two USB 3.0 and two USB 2.0 interfaces; a Gigabit Ethernet controller; two four-lane MIPI transceivers for camera and display; analogue video output; 3.3V general-purpose I/O (GPIO); and the usual collection of GPIO-multiplexed low-speed interfaces (UART, SPI, I2C, I2S, and PWM). A four-lane PCI Express 2.0 interface provides a 16Gb/s link back to BCM2712.</p>



<p>Under development since 2016, RP1 is by a good margin the longest-running, most complex, and (at $15 million) most expensive program we’ve ever undertaken here at Raspberry Pi. It has undergone substantial evolution over the years, as our projected requirements have changed: the C0 step used on Raspberry Pi 5 is the third major revision of the silicon. And while its interfaces differ in fine detail from those of BCM2711, they have been designed to be very similar from a functional perspective, ensuring a high degree of compatibility with earlier Raspberry Pi devices.</p>



<h3>DA9091</h3>



<p>BCM2712 and RP1 are supported by the third new component of the chipset, the Renesas DA9091 “Gilmour” power-management IC (PMIC). This integrates eight separate switch-mode power supplies to generate the various voltages required by the board, including a quad-phase core supply, capable of providing 20 amps of current to power the Cortex-A76 cores and other digital logic in BCM2712.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="683" src="https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-1024x683.png" alt="Close-up photo of part of the Raspberry Pi 5 board, centring the DA9091 power-management IC, on which its name is printed" srcset="https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-1024x683.png 1024w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-300x200.png 300w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-768x512.png 768w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-800x534.png 800w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-450x300.png 450w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81-900x600.png 900w, https://www.raspberrypi.com/app/uploads/2023/09/e1260879-084f-4273-8fdb-2cf577c13c81.png 1450w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Like BCM2712, DA9091 is the product of a multi-year co-development effort. Working closely with the Renesas team in Edinburgh allowed us to produce a PMIC which is precisely tuned for our needs. And we were able to squeeze in two frequently requested features: a real-time clock (RTC), which can be powered by an external supercapacitor or a rechargeable lithium-manganese cell; and a PC-style power button, supporting hard and soft power-off and power-on events.</p>



<p>Two other elements of the chipset have been retained from Raspberry Pi 4. The Infineon CYW43455 combo chip provides dual-band 802.11ac Wi-Fi and Bluetooth 5.0 with Bluetooth Low-Energy (BLE); while the chip itself is unchanged, it is provided with a dedicated switched power supply rail for lower power consumption, and is connected to BCM2712 by an upgraded SDIO interface which supports DDR50 mode for higher potential throughput. As before, Ethernet connectivity is provided by a Broadcom BCM54213 Gigabit Ethernet PHY; this now sits at a jaunty 45-degree angle, a first for Raspberry Pi, and a source of enduring disappointment for orthogonal-layout enthusiast and CTO (Software) Gordon Hollingworth.</p>



<h2>Form-factor evolution</h2>



<p>On the outside, Raspberry Pi 5 closely resembles its predecessors. But, while retaining the overall credit-card-sized footprint, we’ve taken the opportunity to update some elements of the design, to align with the capabilities of the new chipset.</p>



<p>We’ve removed the four-pole composite video and analogue audio jack from the board. Composite video, now generated by RP1, is still available from a pair of 0.1”-spaced pads on the bottom edge of the board.</p>



<p>We now sport a pair of FPC connectors, in the space formerly occupied by the four-pole jack and camera connector. These are four-lane MIPI interfaces, using the same higher-density pinout found on various generations of Compute Module I/O board; and they are bi-directional (transceiver) interfaces, meaning that each one can connect either to a CSI-2 camera or to a DSI display. The space on the left of the board formerly occupied by the display connector now contains a smaller FPC connector which provides a single lane of PCI Express 2.0 connectivity for high-speed peripherals.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="685" src="https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-1024x685.png" alt="Close-up photo of part of the Raspberry Pi 5 board, centring the two FPC connectors, labelled CAM/DISP 0 and CAM/DISP 1" srcset="https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-1024x685.png 1024w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-300x201.png 300w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-768x513.png 768w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-800x535.png 800w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-450x301.png 450w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80-900x602.png 900w, https://www.raspberrypi.com/app/uploads/2023/09/58f150c0-bd72-4e42-a77f-6be0890c8a80.png 1484w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>The Gigabit Ethernet jack has returned to its classic position in the bottom right corner of the board, after a brief sojourn in the top right on Raspberry Pi 4. And it’s brought with it the four-pin PoE connector, simplifying the board layout at the cost of a compatibility break with our existing PoE and PoE+ HATs.</p>



<p>Finally, we’ve grown a pair of mounting holes for a heatsink, as well as JST connectors for the RTC battery (two pins), Arm debug and UART (three pins), and fan with PWM control and tacho feedback (four pins).</p>



<h2>Designed in Cambridge, manufactured in Wales</h2>



<p>Like all flagship Raspberry Pi products, Raspberry Pi 5 is built at the Sony UK Technology Centre in Pencoed, South Wales. We have been working with Sony since the launch of the first Raspberry Pi computer in 2012, and we’re firm believers in the benefits of manufacturing our products within a few hours’ drive of our engineering design centre in Cambridge: a decade of frequent interaction with the Sony team has helped us understand how to design products that can be built reliably, cheaply, and at massive scale.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="682" src="https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-1024x682.jpg" alt="Close-up photo of a corner of the Raspberry Pi 5 box, centred on a Welsh flag icon (red dragon rampant on a grey field against a white sky) beside the words &quot;Made in the UK&quot;." srcset="https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-1024x682.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-768x512.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-1536x1024.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-800x533.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc-900x600.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/dc698c34-e35c-4195-96ec-a2b3ece66cdc.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Raspberry Pi 5 marks the introduction of a number of manufacturing innovations. One of these is intrusive reflow for connectors, which improves the mechanical quality of the product, increases throughput, and eliminates the costly and energy-intensive selective- or wave-solder process from the production flow. Others include fully routed panel singulation for cleaner board edges, and a new approach to production test inspired by our experiences testing our RP2040 microcontroller at scale.</p>



<h2>Accessories, accessories, accessories</h2>



<p>Every new flagship Raspberry Pi product is accompanied by new accessories, and Raspberry Pi 5 is no exception. Layout changes, new interfaces, and much higher peak performance (and a smaller increase in peak power consumption) have led us to redesign some existing accessories, and to develop some entirely new ones.</p>



<h3>Case</h3>



<p>The updated case for Raspberry Pi 5, priced at $10, builds on the aesthetic of its Raspberry Pi 4 predecessor, but adds a host of new usability and thermal-management features.</p>



<p>An integrated 2.79 (max) CFM fan, with fluid dynamic bearings selected for low noise and an extended operating lifetime, connects to the four-pin JST connector on Raspberry Pi 5 to provide temperature‑controlled cooling. Air is drawn in through a 360‑degree slot under the lid, blown over a heatsink attached to the BCM2712 AP, and exhausted through connector apertures and vents in the base.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="693" src="https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-1024x693.jpg" alt="The Raspberry Pi Case for Raspberry Pi 5, showing its red base, the fan assembly with a white frame floating above it, and the white lid floating above that" srcset="https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-1024x693.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-300x203.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-768x519.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-1536x1039.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-800x541.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-450x304.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025-900x609.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/630d0701-9c8b-4b7d-a1f8-9adfcb38b025.jpg 1761w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>We’ve lengthened the case, and tweaked the retention features, to make it possible to insert the Raspberry Pi 5 board without removing the SD card. And by removing the top of the case, it is now possible to stack multiple cases, as well as to mount HATs on top of the fan, using spacers and GPIO header extensions.</p>



<p>Like all our plastic products, the new case is manufactured by our friends at <a href="https://www.t-zero.co.uk/">T-Zero</a>, in the West Midlands, UK.</p>



<h3>Active Cooler</h3>



<p>Raspberry Pi 5 has been designed to handle typical client workloads, uncased, with no active cooling. Users who wish to use the board uncased under continuous heavy load, without throttling, have the option of adding a $5 Active Cooler. This attaches to the board via two new mounting holes, and connects to the same four-pin JST connector as the case&nbsp;fan.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="683" src="https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-1024x683.jpg" alt="The Raspberry Pi Active Cooler mounted on a Raspberry Pi 5. The blower, heatsink, and wires connecting to the Raspberry Pi's four-pin JST connector are visible." srcset="https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-1024x683.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-768x512.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-1536x1024.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-800x534.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b-900x600.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/91e84eee-f588-4953-ae72-693acb1fe97b.jpg 1600w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>A radial blower, again selected for low noise and extended operating lifetime, pushes air through an extruded and milled aluminium heatsink. Both the case and the Active Cooler are able to keep Raspberry Pi 5 well below the thermal throttle point for typical ambient temperatures and worst-case loads. The cooling performance of the Active Cooler is somewhat superior, making it particularly suitable for overclockers.</p>



<h3>27W USB-C Power Supply</h3>



<p>Raspberry Pi 5 consumes significantly less power, and runs significantly cooler, than Raspberry Pi 4 when running an identical workload. However, the much higher performance ceiling means that for the most intensive workloads, and in particular for pathological “power virus” workloads, peak power consumption increases to around 12W, versus 8W for Raspberry Pi 4.</p>



<p>When using a standard 5V, 3A (15W) USB-C power adapter with Raspberry Pi 5, by default we must limit downstream USB current to 600mA to ensure that we have sufficient margin to support these workloads. This is lower than the 1.2A limit on Raspberry Pi 4, though generally still sufficient to drive mice, keyboards, and other low‑power peripherals.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="678" src="https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-1024x678.jpg" alt="The white 3-pin UK variant of the new Raspberry Pi 27W USB-C Power Supply, pictured with the cable tightly wrapped with a cable tie and the pins facing towards the viewer" srcset="https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-1024x678.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-300x199.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-768x509.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-1536x1017.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-800x530.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-450x298.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503-900x596.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/b95428ec-1431-4d39-90a3-f01746a4d503.jpg 1573w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>For users who wish to drive high-power peripherals like hard drives and SSDs while retaining margin for peak workloads, we are offering a $12 USB-C power adapter which supports a 5V, 5A (25W) operating mode. If the Raspberry Pi 5 firmware detects this supply, it increases the USB current limit to 1.6A, providing 5W of extra power for downstream USB devices and 5W of extra on-board power budget: a boon for those of you who want to experiment with overclocking your Raspberry Pi 5.</p>



<p>It should be noted that users have the option to override the current limit, specifying the higher value even when using a 3A adapter. In our testing, we have found that in this mode Raspberry Pi 5 functions perfectly well with typical configurations of higher-power USB devices, and all but the most pathological workloads.</p>



<h3>Camera and display cables</h3>



<p>The new, higher-density pinout of the MIPI connectors means that an adapter is required to connect our own cameras and displays, and third-party products, to Raspberry Pi 5.</p>



<p>To support existing camera and display owners, we are offering FPC camera and display cables, which convert from the higher-density format (now referred to as “mini”) to the older lower-density format (now referred to as “standard”). These cables are available in 200mm, 300mm, and 500mm lengths, priced at $1, $2, and $3 respectively.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="679" src="https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--1024x679.jpg" alt="Two orange cables crossed at one far end lying flat on a plain grey background. White writing on the each cable says &quot;Raspberry Pi Display Cable Standard Mini 200mm&quot; with a Raspberry Pi logo in white and other legal safety logos in white" srcset="https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--1024x679.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--300x199.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--768x509.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--800x531.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--450x299.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f--900x597.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/390e0db7-b71c-4a06-b79b-a78bd4c4962f-.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Camera Module 3, the High-Quality Camera, the Global Shutter Camera, and the Touchscreen Display will all ship with both a standard-to-standard and a 200mm mini-to-standard cable.</p>



<h3>PoE+ HAT</h3>



<p>From early 2024, we will be offering a new PoE+ HAT. This supports the new location for the four-pin PoE header, and has an L-shaped form factor which allows it to sit inside the Raspberry Pi 5 case without interfering mechanically or disrupting airflow.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="683" src="https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-1024x683.jpg" alt="A visibly hand-soldered prototype of the L-shaped Raspberry Pi PoE+ HAT for Raspberry Pi 5" srcset="https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-1024x683.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-768x513.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-1536x1025.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-800x534.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54-900x601.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/eb82802e-e57f-4b8e-b967-360ff088ad54.jpg 1804w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Prototype PoE+ HAT. We don’t know yet what the production version will look like, but we do know that it won’t look like this.</figcaption></figure></div>






<p>The new PoE+ HAT integrates a planar transformer into the PCB layout, and utilises an optimised flyback converter architecture to sustain high efficiency across the whole zero to 25W range of output powers.</p>



<h3>M.2 HATs </h3>



<p>One of the most exciting additions to the Raspberry Pi 5 feature set is the single-lane PCI Express 2.0 interface. Intended to support fast peripherals, it is exposed on a 16-pin, 0.5mm pitch&nbsp;FPC connector on the left-hand side of the board.</p>



<p>From early 2024, we will be offering a pair of mechanical adapter boards which convert between this connector and a subset of the M.2 standard, allowing users to attach NVMe SSDs and other M.2-format accessories. The first, which conforms to the standard HAT form factor, is intended for mounting larger devices. The second, which shares the L-shaped form factor of the new PoE+ HAT, supports mounting 2230- and 2242-format devices inside the Raspberry Pi 5 case.</p>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="682" src="https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-1024x682.jpg" alt="Prototype of the larger (standard HAT form factor) M.2 HAT, mounted on a Raspberry Pi 5" srcset="https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-1024x682.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-768x512.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-1536x1024.jpg 1536w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-800x533.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3-900x600.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/40e82000-af31-4f9a-9fa4-3dc1ebfed2c3.jpg 2000w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Prototype M.2 HAT. Final hardware will not look like this.</figcaption></figure></div>






<h3>Raspberry Pi Beginner’s Guide, 5<sup>th</sup> Edition</h3>



<p>Sporting a brand-new look and feel, and priced at RRP £19.99 ($24.99), this new edition of our bestselling Raspberry Pi Beginner’s Guide is the definitive manual for Raspberry Pi computers and accessories. It has been comprehensively updated to cover Raspberry Pi 5, and the upcoming release of Raspberry Pi OS based on Debian Bookworm.</p>



<h3>RTC battery</h3>


<div>
<figure><img decoding="async" loading="lazy" width="1024" height="683" src="https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-1024x683.jpg" alt="RTC coin cell connected by red and black jumper wires to a two-pin JST plug" srcset="https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-1024x683.jpg 1024w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-300x200.jpg 300w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-768x512.jpg 768w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-800x533.jpg 800w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-450x300.jpg 450w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52-900x600.jpg 900w, https://www.raspberrypi.com/app/uploads/2023/09/3fccfd79-16f8-4fe7-8400-188439d19b52.jpg 1467w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></div>






<p>Last, but very much not least, we have sourced a Panasonic lithium manganese rechargeable coin cell, with a pre-fitted two-pin JST plug and an adhesive mounting pad. This is priced at $5, and is suitable for powering the Raspberry Pi 5 real-time clock (RTC) when the main power supply is disconnected.</p>



<h2>A newer, better Raspberry Pi OS</h2>



<p>In parallel with the final stages of the Raspberry Pi 5 programme, our software team has been busy developing a new version of Raspberry Pi OS, the official first-party operating system for Raspberry Pi devices. This is based on the most recent release of Debian (and its derivative Raspbian), codenamed “Bookworm”, and incorporates numerous enhancements, notably the transition from X11 to the Wayfire Wayland compositor on Raspberry Pi 4 and 5.</p>



<p>Raspberry Pi OS will launch in mid-October, and will be the sole supported first-party operating system for Raspberry Pi 5. Keep checking back here: we’ll be telling you some more about the new OS, and you’ll be able to download it shortly before Raspberry Pi 5 arrives on the shelves in late October.</p>



<h2 id="credits">Credits</h2>



<p>Bringing Raspberry Pi 5 to life has been a seven-year, $25 million endeavour, involving tens of organisations and hundreds of individuals. A non-exhaustive list of those who have contributed to Raspberry Pi 5, and its constituent silicon programs, can be found below — just click to expand it.</p>



<details><summary>A credits list for Raspberry Pi 5</summary>
<p>We’d like to thank everybody who has contributed to Raspberry Pi 5. It’s been an enormous, lengthy project, and you’ve been a wonderful team to work with. Inevitably, when building a list this long, we accidentally omit people: if you’ve been missed off the list, please email us. You know where to find us!</p>



<p>James Adams, Cyrus Afghahi, Snehil Agrawal, Sam Alder, Alasdair Allan, Kevin Allen, Kiarash Amiri, James Anderson, Andrew Anderson, Neil Bailey, Tarek Bairakdar, Scott Baker, Isuvetha Balendra, Giles Ballard, Kris Baxter, Jeff Beach, David Bell, Jonathan Bell, Oguz Benderli, Benjamin Benson, Paul Bentley, Rick Berard, Doug Berger, Suneel Bharadwaj, Sandeep Bhatia, Shawn Bhatiani, Geoff Blackman, Ed Bleich, Alina Borlan, Chris Boross, Wayne Bortman, Richard Boult, James Boyce, Jamie Brogan-Shaw, Robert Brownhill, Mike Buffham, Efim Bukovsky, Andre Burani, Andrew Burge, Simon Burgess, Kevin Campbell, Thierry Canaud, Amy Carter, Jose María Casanova, Jen-Ming Chai, Swetha Challawar, Louis Chan, Shu Chan, Keyu Chang, Nick Chase, Melvin Cheah, Sherman Chen, Wei Chen, Bonnie Chen, Kuanghui Cheng, Chun Fai Cheung, Toon Tun Chiam, Mark Childs, Jae Cho, Chye Yaw Chong, Kevin Choung, Anne-Marie Christie, David Christie, Scott Clark, Dominic Cobley, Nate Contino, Ben Cook, Stephen Cook, Sheena Coote, John Cowan-Hughes, John Cox, Richard Croad, Darryl Cross, Tom Davies, Shijun Deng, Todd DeRego, Nicola Early, Philip Elwell, Dave Emett, Dan English, Mark Evens, Benjamin Everard, Andras Ferencz, Nick Francis, Liam Fraser, Alexander Fuessel, Nachiket Galgali, Eric Gastelum, Jan Gatermann, Monica Gemeneanu, Valeria Germini, Deven Ghelani, Sharna Ghosh, Ben Giese, Doug Giles, Tracey Glover, Andrew Goros, Timothy Gover, Ron Green, Peter Green, Simon Greening, Andrew Gregory, Glen Grover, Charlotte Hallworth, Paul Hammond, Lauren Hancock, Peter Harper, Lisa Harris, Lucy Hattersley, Xiaocheng He, Amanda Henderson, David Henly, Jason Herrick, Leon Hesch, Darren Hill, Nicholas Hollinghurst, Gordon Hollingworth, Andrew Holme, Michael Howells, Andrew Hsu, Wanchen Hsu, Chi-Yuan Hsu, Mingyuan Huang, Tim Hughes, James Hughes, Andy Hulbert, Rami Husni, James Hutchinson, Lee Huynh, Lee Huynh, Steven Hwang, Leane Ickes, Paul Ittoopunny, Bruno Izern, Chris Jacobs, Olivier Jacquemart, Anurag Jain, Geraint James, Sri Jandhyala, Chris Jaszczur, Dinesh Jayabharathi, Brian Jepson, Dave John, Antonia Johnson, Richard Jones, Lily Jones, Lijo Jose, Tammy Julyan, Nejat Kamaci, Jarkko Karjalainen, Gary Keall, Kevin Kelly, Bruce Kent, Ian Kersley, Gerard Khoo, Megan Kiddy, Chris Kim, Chhavi Kishore, Keith Klingler, Srivarada Kota, Vijay Anantha Krishnan, Y Ravi Chandra Kumar, Eldhose Kurian, Wayne Kusumo, Ramki Lakshman, Koen Lampaert, Anthony Le, Hungchi Lee, Seong Ho Lee, William Lee, Joon Lee, David Lee, Graeme Leese, David Lewsey, Danyu Li, Jay Li, Sherman Li, Dan Li, Tatiane Dias de Lima, Sam Liu, Xiaogang Liu, Simon Long, Patrick Loo, Vasco Lopes, Melissa Lovato, Joshua Low, Jeremy Low, Chris Lowder, Yoana Lozano, Janice Lu, Mihai Lupu, Jeff Lussier, Helen Lynn, Jun Ma, Ian Macaulay, Terry Mackown, Christopher Mairs, Oren Mamet, Tim Mamtora, Sorin-Alexandru Mare, Christopher Martin, Simon Martin, Wasim Master, Jonathan Matthews, Andrea Mauri, Glen McDonnell, Nellie McKesson, Craig McNaughton, Steven Mcninch, Ingrid Megarademy, James Mills, Vassil Mitov, Danny Miyabe, Ali Syed Mohammed, Shawn Molavi, Mircea Moldovan, Marta Momotko, Daniel Moran, Alan Morgan, Anthony Morton, Paul Mucur, Aram Nahidipour, Eng Yee Ng, Thomas Nguyen, Ut Nguyen, Mirela Nicolescu, Keri Norris, Rhian Norris, Rose Nott, Brian O Halloran, Yong Oh, Kenneth Okolo, Eng Choon Ooi, Emma Ormond, Shujuan Pan, Yuan Pang, Ravi Papineni, Simon Parish, Sara Parodi, Chris Pasqualino, Naushirwan Patuck, Davin Phenix, Rui Pimenta, Alejandro Piñeiro, David Plowman, Dominic Plunkett, Lloyd Porter, Neil Price, Jim Quinlan, Nutan Raj, Siva Rajagopalan, Karthik Rajendran, Ashwin Rao, Chaitanya Ray, Haifa Redissi, Justin Rees, Ravi Revanakara, Matt Richardson, Dan Riiff, Maxime Ripard, Peter de Rivaz, Steven Roberts, Toby Roberts, Landis Rogers, Paul Rolfe, Marcelo Romero, Sarah Roth, Matt Rowley, Andy Ruan, Benjamin Ryu, Dave Saarinen, Ali Salem, Akshaye Sama, Suzie Sanders, Graham Sanderson, Aniruddha Sane, Subramaniam Sankaralingam, Muthia Muthiah Sarandoss, Santosh Savekar, Andrew Scheller, Serge Schneider, Graham Scott, Gareth Scourfield, Saran Kumar Seethapathi, Vinaya Lakshmi Puthur Sekar, Saumeet Shah, Sharkus, Ammar Sheikh, Shashank Shekhar, Joe Sheppard, Bhaskar Sherigar, Paul Sherry, Guang-Ting Shin, Jawaid Siddiqi, Amit Paul Singh, Hannah Slater, Ross Smith, Paul Smith, Graham Smith, Kieran Snow, Samantha Snyder, Thomas Spurden, Hosahalli Srinivas, Ajay Srivastava, Tim Stenning, Ben Stephens, David Stevenson, Michael Stimson, Chee Siong Su, Austin Su, Juan Suárez, Bhushan Subbarao, Chris Szczuka, Raymond Szkornik, Jeffrey Tang, Salene Tarling, Raju Tatte, Thian Fatt Tay, Fred Taylor, Robert Thomas, Matthew Thomas, Dan Thompsett, Roger Thornton, Darren Tilley, Chris Tomlinson, Anand Tongle, Iago Toral, Duke Tran, Jim Tseng, Steven Tseng, Richard Tuck, Utku Turker, David Turner, Natalie Turner, Agalgave Umesh, Rachit Upreti, Liz Upton, Manoj Vajhallya, Sandeep Venkatadas, Sushil Verghese, William Vinnicombe, Marco Vrouwe, John Wadsworth, Paul Wallace, Yongbing Wan, Irene Wang, Benjamin Waters, Longyin Wei, Melissa Wen, Simon West, Thomas Westcott, Joe Whaley, Ray Whitley, Ashley Whittaker, Oli Wilkin, Charlotte Williams, Jack Willis, Anthony Wong, Luke Wren, David Wright, David Wu, Romona Wu, Sheldon Wu, Xin Xie, Huajun Xiong, Zheng Xu, Jian Xu, Jason Young, Johnny Yang, Adrian Yu, Chi-Li Yu, Sylvia Yu, Yingdong Yu, Vladimir Zabezhinsky, Angelina Zamora, Kaibin Zhang, Wei Zhang, Jean Zhou, Rob Zwetsloot</p>
</details>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Biden to issue first regulations on artificial intelligence systems (122 pts)]]></title>
            <link>https://www.nytimes.com/2023/10/30/us/politics/biden-artificial-intelligence.html</link>
            <guid>38067477</guid>
            <pubDate>Mon, 30 Oct 2023 10:02:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2023/10/30/us/politics/biden-artificial-intelligence.html">https://www.nytimes.com/2023/10/30/us/politics/biden-artificial-intelligence.html</a>, See on <a href="https://news.ycombinator.com/item?id=38067477">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2023/10/30/us/politics/biden-artificial-intelligence.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence (108 pts)]]></title>
            <link>https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/</link>
            <guid>38067314</guid>
            <pubDate>Mon, 30 Oct 2023 09:35:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/">https://www.whitehouse.gov/briefing-room/statements-releases/2023/10/30/fact-sheet-president-biden-issues-executive-order-on-safe-secure-and-trustworthy-artificial-intelligence/</a>, See on <a href="https://news.ycombinator.com/item?id=38067314">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
	


	<div>
								


<div><p>Today, President Biden is issuing a landmark Executive Order to ensure that America leads the way in seizing the promise and managing the risks of artificial intelligence (AI). The Executive Order establishes new standards for AI safety and security, protects Americans’ privacy, advances equity and civil rights, stands up for consumers and workers, promotes innovation and competition, advances American leadership around the world, and more.</p><p>As part of the Biden-Harris Administration’s comprehensive strategy for responsible innovation, the Executive Order builds on previous actions the President has taken, including work that led to voluntary commitments from 15 leading companies to drive safe, secure, and trustworthy development of AI.</p><p>The Executive Order directs the following actions:</p><p><strong>New Standards for AI Safety and Security</strong></p></div>



<p>As AI’s capabilities grow, so do its implications for Americans’ safety and security.&nbsp;<strong>With this Executive Order, the</strong><strong>&nbsp;President directs the&nbsp;</strong><strong>most sweeping&nbsp;</strong><strong>actions&nbsp;</strong><strong>ever taken&nbsp;</strong><strong>to protect Americans from&nbsp;</strong><strong>the potential&nbsp;</strong><strong>risks&nbsp;</strong><strong>of&nbsp;</strong><strong>AI</strong><strong>&nbsp;systems</strong><strong>:</strong></p>



<ul>
<li><strong>Require that developers of the most powerful AI systems share their safety test results and other critical information with the U.S. government.&nbsp;</strong>In accordance with the Defense Production Act, the Order will require that companies developing any foundation model that poses a serious risk to national security, national economic security, or national public health and safety must notify the federal government when training the model, and must share the results of all red-team safety tests. These measures will ensure AI systems are safe, secure, and trustworthy before companies make them public.&nbsp;</li>



<li><strong>Develop standards, tools, and tests to help ensure that AI systems are safe, secure, and trustworthy.</strong>&nbsp;The National Institute of Standards and Technology will set the rigorous standards for extensive red-team testing to ensure safety before public release. The Department of Homeland Security will apply those standards to critical infrastructure sectors and establish the AI Safety and Security Board. The Departments of Energy and Homeland Security will also address AI systems’ threats to critical infrastructure, as well as chemical, biological, radiological, nuclear, and cybersecurity risks. Together, these are the most significant actions ever taken by any government to advance the field of AI safety.</li>



<li><strong>Protect against the risks of using AI to engineer dangerous biological materials&nbsp;</strong>by developing strong new standards for biological synthesis screening. Agencies that fund life-science projects will establish these standards as a condition of federal funding, creating powerful incentives to ensure appropriate screening and manage risks potentially made worse by AI.</li>



<li><strong>Protect Americans from AI-enabled fraud and deception by establishing standards and best practices for detecting AI-generated content and authenticating official content</strong>. The Department of Commerce will develop guidance for content authentication and watermarking to clearly label AI-generated content. Federal agencies will use these tools to make it easy for Americans to know that the communications they receive from their government are authentic—and set an example for the private sector and governments around the world.</li>



<li><strong>Establish an advanced cybersecurity program to develop AI tools to find and fix vulnerabilities in critical software,&nbsp;</strong>building on the Biden-Harris Administration’s ongoing AI Cyber Challenge. Together, these efforts will harness AI’s potentially game-changing cyber capabilities to make software and networks more secure.</li>



<li><strong>Order the development of a National Security Memorandum that directs further actions on AI and security,&nbsp;</strong>to be developed by the National Security Council and White House Chief of Staff. This document will ensure that the United States military and intelligence community use AI safely, ethically, and effectively in their missions, and will direct actions to counter adversaries’ military use of AI.</li>
</ul>



<p><strong>Protecting Americans’ Privacy</strong></p>



<p>Without safeguards, AI can put Americans’ privacy further at risk. AI not only makes it easier to extract, identify, and exploit personal data, but it also heightens incentives to do so because companies use data to train AI systems.&nbsp;<strong>To better protect Americans’ privacy, including from the risks posed by AI, the President calls on Congress to pass bipartisan data privacy legislation to protect all Americans, especially kids, and directs the following actions:</strong></p>



<ul>
<li><strong>Protect Americans’ privacy by prioritizing federal support for accelerating the development and use of privacy-preserving techniques—</strong>including ones that use cutting-edge AI and that let AI systems be trained while preserving the privacy of the training data. &nbsp;</li>



<li><strong>Strengthen privacy-preserving research</strong>&nbsp;<strong>and technologies,</strong>&nbsp;such as cryptographic tools that preserve individuals’ privacy, by funding a Research Coordination Network to advance rapid breakthroughs and development. The National Science Foundation will also work with this network to promote the adoption of leading-edge privacy-preserving technologies by federal agencies.</li>



<li><strong>Evaluate how agencies collect and use commercially available information</strong>—including information they procure from data brokers—and<strong>&nbsp;strengthen privacy guidance for federal agencies</strong>&nbsp;to account for AI risks. This work will focus in particular on commercially available information containing personally identifiable data.</li>



<li><strong>Develop guidelines for federal agencies to evaluate the effectiveness of privacy-preserving techniques,&nbsp;</strong>including those used in AI systems. These guidelines will advance agency efforts to protect Americans’ data.</li>
</ul>



<p><strong>Advancing Equity and Civil Rights</strong></p>



<p>Irresponsible uses of AI can lead to and deepen discrimination, bias, and other abuses in justice, healthcare, and housing. The Biden-Harris Administration has already taken action by publishing the&nbsp;<a href="https://www.whitehouse.gov/ostp/ai-bill-of-rights/">Blueprint for an AI Bill of Rights</a>&nbsp;and issuing an&nbsp;<a href="https://www.whitehouse.gov/briefing-room/statements-releases/2023/02/16/fact-sheet-president-biden-signs-executive-order-to-strengthen-racial-equity-and-support-for-underserved-communities-across-the-federal-government/">Executive Order directing agencies to combat algorithmic discrimination</a>, while enforcing existing authorities to protect people’s rights and safety.&nbsp;<strong>To ensure that AI advances equity and civil rights, the President directs the following additional actions:</strong></p>



<ul>
<li><strong>Provide clear guidance to landlords, Federal benefits programs, and federal contractors&nbsp;</strong>to keep AI algorithms from being used to exacerbate discrimination.</li>



<li><strong>Address algorithmic discrimination&nbsp;</strong>through training, technical assistance, and coordination between the Department of Justice and Federal civil rights offices on best practices for investigating and prosecuting civil rights violations related to AI.</li>



<li><strong>Ensure fairness throughout the criminal justice system&nbsp;</strong>by developing best practices on the use of AI in sentencing, parole and probation, pretrial release and detention, risk assessments, surveillance, crime forecasting and predictive policing, and forensic analysis.</li>
</ul>



<p><strong>Standing Up for Consumers, Patients, and Students</strong></p>



<p>AI can bring real benefits to consumers—for example, by making products better, cheaper, and more widely available. But AI also raises the risk of injuring, misleading, or otherwise harming Americans.&nbsp;<strong>To protect consumers while ensuring that AI can make Americans better off, the President directs the following actions:</strong></p>



<ul>
<li><strong>Advance the responsible use of AI&nbsp;</strong>in healthcare and the development of affordable and life-saving drugs. The Department of Health and Human Services will also establish a safety program to receive reports of—and act to remedy – harms or unsafe healthcare practices involving AI.&nbsp;</li>



<li><strong>Shape AI’s potential to transform education&nbsp;</strong>by creating resources to support educators deploying AI-enabled educational tools, such as personalized tutoring in schools.</li>
</ul>



<p><strong>Supporting Workers</strong></p>



<p>AI is changing America’s jobs and workplaces, offering both the promise of improved productivity but also the dangers of increased workplace surveillance, bias, and job displacement.&nbsp;<strong>To mitigate these risks, support workers’ ability to bargain collectively, and invest in workforce training and development that is accessible to all, the President directs the following actions:</strong></p>



<ul>
<li><strong>Develop principles and best practices to mitigate the harms and maximize the benefits of AI for workers&nbsp;</strong>by addressing job displacement; labor standards; workplace equity, health, and safety; and data collection. These principles and best practices will benefit workers by providing guidance to prevent employers from undercompensating workers, evaluating job applications unfairly, or impinging on workers’ ability to organize.</li>



<li><strong>Produce a report on AI’s potential labor-market impacts</strong>, and&nbsp;<strong>study and identify options for strengthening federal support for workers facing labor disruptions</strong>, including from AI.</li>
</ul>



<p><strong>Promoting Innovation and Competition</strong></p>



<p>America already leads in AI innovation—more AI startups raised first-time capital in the United States last year than in the next seven countries combined.&nbsp;<strong>The Executive Order ensures that we continue to lead the way in innovation and competition through the following actions:</strong></p>



<ul>
<li><strong>Catalyze AI research across the United States&nbsp;</strong>through a pilot of the National AI Research Resource—a tool that will provide AI researchers and students access to key AI resources and data—and expanded grants for AI research in vital areas like healthcare and climate change.</li>



<li><strong>Promote a fair, open, and competitive AI ecosystem&nbsp;</strong>by providing small developers and entrepreneurs access to technical assistance and resources, helping small businesses commercialize AI breakthroughs, and encouraging the Federal Trade Commission to exercise its authorities.</li>



<li><strong>Use existing authorities to expand the ability of highly skilled immigrants and nonimmigrants with expertise in critical areas to study, stay, and work in the United States</strong>&nbsp;by modernizing and streamlining visa criteria, interviews, and reviews.</li>
</ul>



<p><strong>Advancing American Leadership Abroad</strong></p>



<p>AI’s challenges and opportunities are global.&nbsp;<strong>The Biden-Harris Administration will continue working with other nations to support safe, secure, and trustworthy deployment and use of AI worldwide. To that end, the President directs the following actions:</strong></p>



<ul>
<li><strong>Expand bilateral, multilateral, and multistakeholder engagements to collaborate on AI</strong>. The State Department, in collaboration, with the Commerce Department will lead an effort to establish robust international frameworks for harnessing AI’s benefits and managing its risks and ensuring safety. In addition, this week, Vice President Harris will speak at the UK Summit on AI Safety, hosted by Prime Minister Rishi Sunak.</li>



<li><strong>Accelerate development and implementation of vital AI standards</strong>&nbsp;with international partners and in standards organizations, ensuring that the technology is safe, secure, trustworthy, and interoperable.</li>



<li><strong>Promote the safe, responsible, and rights-affirming development and deployment of AI abroad to solve global challenges,&nbsp;</strong>such as advancing sustainable development and mitigating dangers to critical infrastructure.</li>
</ul>



<p><strong>Ensuring Responsible and Effective Government Use of AI</strong></p>



<p>AI can help government deliver better results for the American people. It can expand agencies’ capacity to regulate, govern, and disburse benefits, and it can cut costs and enhance the security of government systems. However, use of AI can pose risks, such as discrimination and unsafe decisions.&nbsp;<strong>To ensure the responsible government deployment of AI and modernize federal AI infrastructure, the President directs the following actions:</strong></p>



<ul>
<li><strong>Issue guidance for agencies’ use of AI,&nbsp;</strong>including clear standards to protect rights and safety, improve AI procurement, and strengthen AI deployment. &nbsp;</li>



<li><strong>Help agencies acquire specified AI products and services</strong>&nbsp;faster, more cheaply, and more effectively through more rapid and efficient contracting.</li>



<li><strong>Accelerate the rapid hiring of AI professionals</strong>&nbsp;as part of a government-wide AI talent surge led by the Office of Personnel Management, U.S. Digital Service, U.S. Digital Corps, and Presidential Innovation Fellowship. Agencies will provide AI training for employees at all levels in relevant fields.</li>
</ul>



<div><p>As we advance this agenda at home, the Administration will work with allies and partners abroad on a strong international framework to govern the development and use of AI. The Administration has already consulted widely on AI governance frameworks over the past several months—engaging with Australia, Brazil, Canada, Chile, the European Union, France, Germany, India, Israel, Italy, Japan, Kenya, Mexico, the Netherlands, New Zealand, Nigeria, the Philippines, Singapore, South Korea, the UAE, and the UK. The actions taken today support and complement Japan’s leadership of the G-7 Hiroshima Process, the UK Summit on AI Safety, India’s leadership as Chair of the Global Partnership on AI, and ongoing discussions at the United Nations.</p><p>The actions that President Biden directed today are vital steps forward in the U.S.’s approach on safe, secure, and trustworthy AI. More action will be required, and the Administration will continue to work with Congress to pursue bipartisan legislation to help America lead the way in responsible innovation.</p><p>For more on the Biden-Harris Administration’s work to advance AI, and for opportunities to join the Federal AI workforce, visit <a href="https://ai.gov/">AI.gov</a>.</p></div>



<p>###</p>
			</div>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI.gov (288 pts)]]></title>
            <link>https://ai.gov/</link>
            <guid>38067206</guid>
            <pubDate>Mon, 30 Oct 2023 09:21:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.gov/">https://ai.gov/</a>, See on <a href="https://news.ycombinator.com/item?id=38067206">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main-content" aria-label="Main Content">



<div>
			<p data-animation="lines" data-animation-delay="0">Introduction</p>
			<p data-animation="lines" data-animation-delay="0">AI is one of the most powerful technologies of our time. President Biden has been clear that we must take bold action to harness the benefits and mitigate the risks of AI. The Biden-Harris Administration has acted decisively to protect safety and rights in the age of AI, so that everyone can benefit from the promise of AI.</p>
			<p data-animation="lines" data-animation-delay="1000">
				<a href="https://ai.gov/actions/">Learn More about the Biden-Harris Administration’s Actions</a>			</p>
		</div>

<div>
		<div data-animation="block" data-animation-delay="600" data-animation-duration="600">
				<h2>Administration Actions on AI</h2>
				<p>President Biden has signed an Executive Order to advance agencies’ efforts on AI across the federal government, building on previous actions to harness the benefits and mitigate the risks of AI.</p>
				
			</div>
		<div data-animation="block" data-animation-delay="400" data-animation-duration="600">
				<h2>Join the AI Talent Surge</h2>
				<p>The federal government is rapidly hiring talent to build and govern AI to fulfill the priorities set forth by the Biden-Harris Administration.</p>
				
			</div>
	</div>

<div>
	<div>
		<picture>
			<source srcset="https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/workforce-cover-bg-360.webp 360w, https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/workforce-cover-bg.webp 1440w" type="image/webp">
			<img src="https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/workforce-cover-bg-360.jpg" srcset="https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/workforce-cover-bg-360.jpg 360w, https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/workforce-cover-bg.jpg 1440w" width="1440" height="1258" loading="lazy" alt="">
		</picture>
	</div>
	
	<div>
			<h2 data-animation="lines" data-animation-delay="800">Build Your AI Skills</h2>
			<p data-animation="lines" data-animation-delay="1000">American students, workers, and educators are foundational to ensuring our nation’s leadership in AI.</p>
			
		</div>
</div>

<div>
					<h2 data-animation="block" data-animation-delay="800">Bring your AI Skills to the U.S.</h2>
					<p data-animation="block" data-animation-delay="1000">Building the most talented AI workforce in the world includes welcoming the world’s AI talent to our country.</p>
					
				</div>

<div>
		<div data-animation="block" data-animation-duration="600">
				<p><img src="https://ai.gov/wp-content/themes/static/ai46/assets/img/ai/gov-seal-white.svg" width="108" height="90" loading="lazy" alt=""></p><h2>Government<br>Use of AI</h2>
				<p>The federal government is harnessing the opportunities of AI to improve its services for the public.</p>
				
			</div>
		<div data-animation="block" data-animation-duration="600" data-animation-delay="400">
				<h2>National AI Advisory Committee</h2>
				<p>The National AI Advisory Committee (NAIAC) advises the White House on a range of issues related to AI.</p>
				
			</div>
	</div>

	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The History of Microsoft Encarta (126 pts)]]></title>
            <link>https://www.abortretry.fail/p/the-history-of-microsoft-encarta</link>
            <guid>38066779</guid>
            <pubDate>Mon, 30 Oct 2023 08:06:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abortretry.fail/p/the-history-of-microsoft-encarta">https://www.abortretry.fail/p/the-history-of-microsoft-encarta</a>, See on <a href="https://news.ycombinator.com/item?id=38066779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div dir="auto"><p><span>In 1985, shortly after the release of </span><a href="https://www.abortretry.fail/p/the-history-of-windows-10" rel="">Windows 1.0</a><span>, Bill Gates set Min Lee on a mission to find a partner for a digital encyclopedia product that would serve as a reference companion to Microsoft’s productivity applications. Lee then approached Britannica, the undisputed leader in the encyclopedia market, who’d recently released a new version of the fifteenth edition of their encyclopedia. Microsoft proposed a partnership to produce a multimedia CD-ROM version of the Encyclopædia Britannica. In exchange for non-exclusive rights to Britannica’s text, Microsoft would pay Britannica a royalty on each copy of the CD-ROM product sold. Britannica immediately declined Lee’s proposal. Britannica’s director of public relations at the time, Larry Grinnell, said: </span></p><blockquote><p><em>The Encyclopædia Britannica has no plans to be on a home computer. And since the market is so small, only 4 or 5 percent of households have computers, we would not want to hurt our traditional way of selling.</em></p></blockquote><p><span>While this might seem insane now, this was not at all insane in 1985. Home computers weren’t yet common, and computers capable of any sort of multimedia were even less common. Microsoft was a much smaller company than it would be in a few short years, and it was a company known primarily for </span><a href="https://www.abortretry.fail/p/history-of-basic-part-1" rel="">BASIC</a><span> and </span><a href="https://www.abortretry.fail/p/disk-operating-systems" rel="">MS-DOS</a><span>. Britannica had no readily apparent reason to fear competition from Microsoft and little reason to desire a partnership with a young company. Britannica was </span><em>the </em><span>encyclopedia. They controlled the market, charged extremely high prices, and had strong and stable profits. Britannica was also a company that was led by its sales organization. Traditionally, encyclopedias were something sold not bought. A person didn’t walk into a bookstore and buy the set; a door-to-door salesman showed up.</span></p><div id="youtube2--lSLzYKVd2s" data-attrs="{&quot;videoId&quot;:&quot;-lSLzYKVd2s&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/-lSLzYKVd2s?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p>For Britannica, losing its sales people was a real fear. Would they defect if they learned that a cheaper product with the same information was being sold? Would they wish to be associated with a CD-ROM product instead of the stately and serious books they were selling?</p><p><span>Also in 1985, Grolier’s released two electronic forms of its own encyclopedia. They released </span><em>Knowledge Disc: The World’s First Laser Videodisc Encyclopedia</em><span> as well as </span><em>New Grolier Electronic Encyclopedia.</em><span> These were both text-only. The Knowledge Disc was a laser disc as the name implied, and it was intended for use in schools. The Electronic Encyclopedia was on a CD and intended for use with IBM PC compatible computers running MS-DOS.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png" width="711" height="698.3786982248521" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:498,&quot;width&quot;:507,&quot;resizeWidth&quot;:711,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F53cb484f-dd8b-4c69-bbb4-5b29a7bbd48f_507x498.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>Having been refused by Britannica, Microsoft turned to World Book who likewise rejected them. This search went on for four years until Microsoft was able to strike a deal with Funk &amp; Wagnall’s which was nearly bankrupt at the time. With the deal in place, Microsoft began project Gandalf. Whether in hope of remaining competitive with Grolier’s or something they’d intended but chose to keep secret, Britannica did release their own multimedia CD-ROM encyclopedia in 1989 under the Compton brand name. The Compton product was a free add-on to print encyclopedias from Britannica, but a standalone CD-ROM version retailed for $895 (around $2221 in 2023).</p><p>The Funk &amp; Wagnall’s name wasn’t well regarded so the Gandalf team knew that it wouldn’t be part of their own product’s name. Lee, Gates, and the team also knew that simply putting the text on a disc wasn’t enough. This would be a new kind of encyclopedia with search, hyperlinks, graphics, sound, video, and interactivity; an encyclopedia designed with images, illustrations, and maps in mind from the start. Despite having both passion and ambition, this was a relatively high risk project and the team was small. When the project had first started, printed encyclopedia sets generally sold at a price above $1000 (nearly $3000 in 2023). With Grolier’s and Compton’s both having been on the market, the common price had steadily fallen to just under $400 (around $941 in 2023). The profit that might have been was clearly reduced, and a race to the bottom had begun. Until October of 1991, project Gandalf’s team had consisted of fewer than 4 full-time employees at any one time. This started to increase as the project took more form, and the editorial team at Microsoft became the largest editorial team of any encyclopedia publisher over the product’s lifetime.</p><p>To make this encyclopedia work, several DLLs were created in C that extended Multimedia Viewer. These were then used with SGML text files and an Access database. The resulting product was Microsoft Encarta which  included fourteen thousand media elements, five thousand photos, one hundred animations, and seven hours of sound. Getting all of this together was a difficult process for the team. For each image, animation, or audio clip included, something had to be removed. CD-ROM storage is very much a zero sum game.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png" width="735" height="692" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:692,&quot;width&quot;:735,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:583672,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7769ee51-e1fe-40b5-af3c-adbe0467ece5_735x692.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>PC Magazine, 22nd of December 1992</figcaption></figure></div><p><span>At launch in March of 1993, Encarta was $395 (around $841 in 2023). Over the first six months following release, it gained just three percent market share. Compton’s had reacted to Microsoft’s entrance by dropping their price to $129 (around $274 in 2023) for anyone who claimed to own a competitor’s product. Retail outlets didn’t exert much effort to have customers prove the claim, and Compton’s started to sell very well. The Encarta sales team was eager to drop the price to compete, and Encarta was then sold at $99 (around $210 in 2023) for the holiday season. By the year’s end, Encarta was the best selling CD encyclopedia on the market with more than three hundred fifty thousand copies sold. Encarta quickly became a product bundled with multimedia PCs, and revenue was brought in as people bought newer editions. This first edition was followed by the “1994” edition later in 1993, and a release was made yearly thereafter. For many people, Encarta was the first practical reason to purchase a CD-ROM drive for a computer. While audio CDs had been introduced in Japan in 1982 with Europe and North America following in 1983, they didn’t overtake vinyl in the USA until 1988. CDs surpassed audio cassettes in 1992. With Encarta and then </span><a href="https://www.abortretry.fail/p/the-history-of-windows-95" rel="">Windows 95</a><span>, CD-ROM became normal in the world of PCs.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:305788,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F619e3692-5d7a-40da-bb11-86b6ae55ac6b_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Encarta setup loading screen</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:12906,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6c093677-0ed1-49f5-b6ca-f202cc4aaaa5_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Pick your install path</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:8899,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18ace379-5dc1-4b64-a6ec-d31b84c47cb5_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Checking system requirements</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:13783,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31e188c3-bfd5-420c-9a4b-3541104f711d_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>All requirements passed!</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:15570,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbdbfe32a-70a1-4f57-8bcb-c4caac2d76d0_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Installation type selection</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:25054,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc76a971b-c54a-4e85-85f1-7e5a9312e3be_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Installation underway</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/114d3b77-46fd-422b-822f-4899e71e357d_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:12242,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F114d3b77-46fd-422b-822f-4899e71e357d_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Time to restart</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:6577,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff1b96b56-4a97-4edf-b10e-eeb588254930_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The new folder in Program Manager</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:267104,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F12380ff8-5f2b-407e-b19f-8bceb4a3b08e_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The Encarta start screen</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png" width="722" height="541.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:722,&quot;bytes&quot;:113173,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F41731dbd-3408-4b55-80f3-2e2840b58b6f_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>First article, the letter A</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png" width="718" height="538.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:718,&quot;bytes&quot;:89643,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F45a2e88c-29c7-47ff-8930-b976b1a102a5_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Find stuff in the text</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:113135,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F19c0a874-2fa4-45e0-b714-341eb1b2fb9c_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The topics found</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/efee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:24850,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fefee19e9-9849-427f-9d56-6cda0bd72ae5_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Results in the article</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png" width="718" height="538.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:718,&quot;bytes&quot;:12250,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F90b8a8d1-56c9-42c4-854b-9e9dac15cbec_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Old style encyclopedic topic selection made digital</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:34214,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8e04a7d8-6d5e-475c-821d-9291debf841a_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>The atlas</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/eae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:132135,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feae2d641-fbbb-4fc0-9bbc-85bf20be86b6_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Image integration</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:36416,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F56be8425-9110-4bfc-8295-4b954e8f991c_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Timeline and event finder</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png" width="726" height="544.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:726,&quot;bytes&quot;:56823,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F780ac54b-6af2-432f-8ae7-791a80427c68_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>MindMaze</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png" width="724" height="543" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f678d99e-d97a-49a2-88ef-78debce60e99_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:724,&quot;bytes&quot;:53765,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff678d99e-d97a-49a2-88ef-78debce60e99_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>First question correctly answered!</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png" width="724" height="543" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:724,&quot;bytes&quot;:25583,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F6586adcc-fb53-49f3-8729-4badc8cd5bf5_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Clicking to article from MindMaze</figcaption></figure></div><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png" width="722" height="541.5" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:480,&quot;width&quot;:640,&quot;resizeWidth&quot;:722,&quot;bytes&quot;:55077,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F18e9c749-18bb-4386-a9f7-13589417bca9_640x480.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Back to the game interface</figcaption></figure></div><p>This was a devastating blow to print encyclopedias. In 1990, Britannica’s annual revenues were $650 million (about $1.5 billion in 2023). This figure dropped to $345 million for 1996 (around $677 million in 2023). Britannica sold the Compton’s digital product line to the Chicago Tribune for $57 million in 1993 (around $112 million in 2023) as they had finally relented and released CD-ROM version with their primary brand for $1200 (around $2492 in 2023). This failed and the price was dropped to $995 in 1995 (around $2009 in 2023). The sales force was furious, the product didn’t sell despite the price reduction, and in August, Britannica closed two-thirds of its sales offices. It launched a web version of its product in October.  By December, things were bleak and a sale of Britannica to Jacob E. Safra was announced the 19th of December in 1995.</p><p><span>While Britannica was imploding, Microsoft’s efforts were going strong. Encarta was ported to the Macintosh in 1994. Encarta Atlas was introduced in 1995 and the product was made fully 32 bit using C++ and MFC. In 1996, Encarta expanded to two CDs. This again posed a difficult challenge. Stub articles had to be added to the first CD, and then upon clicking to expand an article the user was prompted to switch discs. How does navigating backward happen? Does the user get prompted to switch discs again? Does the user get a stub? Should the prior article be cached? When is any one of these options appropriate? All difficult choices. Figuring out when and where to make this happen wasn’t easy. Disc swapping was later ameliorated as hard disks grew in size and full installation became possible, but this wasn’t yet so. A virtual globe was added in 1997. Through the late 1990s, content was added to Encarta from both Collier’s and New Merit Scholar’s encyclopedias as Microsoft gained the rights to their respective texts. In 2000, Encarta became available on the web. Full access to the web was restricted to paid subscribers with a smaller subset of the encyclopedia made available to all. This also provided article updates to locally installed versions if users wanted it and had a subscription. 3D Virtual Tours were added to Encarta in 2001. Interestingly, Encarta was also available in Windows Live Messenger via </span><code>encarta@conversagent.com </code><span>or </span><code>encarta@botmetro.net</code><span>. Over the lifetime of Encarta, the encyclopedia expanded to 5 CDs or a DVD. The product was also available in three versions: Standard, Deluxe, Reference Library. The technical side of the program also changed to web technologies (Trident, HTML, CSS, Flash) and C# over time despite being available entirely locally on DVD. The team approached programming technologies very pragmatically attempting to choose the right tool for any given task as opposed to dogmatically choosing a single tool.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png" width="800" height="600" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:600,&quot;width&quot;:800,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F26c25a32-7c0d-49b4-a67b-5a60bf1bbe45_800x600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Encarta 98, Virtual Globe, Grand Canyon</figcaption></figure></div><p><span>Unlike many products, Encarta’s ship dates were fixed. The product always had to be ready for “</span><em>back to school.</em><span>” Yet, this was also a product shipped on read-only media before cheap internet access existed, and therefore showstopping bugs couldn’t be present. When bugs did ship, they were often known to the team. So, if you walked through a wall in the Parthenon, the team knew this could happen. The key was that a bug couldn’t be so bad that it ruined the experience. The product was extremely rich in visuals, audio, and interactivity and therefore it could be (and by many on the design team certainly was) considered a work of art. People on the team lost hours over single pixel imperfections, over sluggishness or glitching in palette swapping, and over bugs in navigation history. People on the team would sometimes work for twenty four hours straight and sleep at their desks in attempts to get things ready to ship, and often enough entire articles or even features had to be pushed to a later edition.</span></p><p>Despite the Encarta team having grown and become international with localization teams around the globe, Encarta wasn’t a massive source of revenue for Microsoft. It had a large amount of overhead and the educational market was rather thin. Many of the people on the team could have received pay raises or promotions rather quickly if they’d transferred to other teams, but the Encarta team had rather low turnover. The sense that I get is that this was quite a dedicated team who enjoyed the work that they were doing and the product that they made. Several members mentioned that a rather serious occupational hazard was getting lost in content while working. They’d be editing something or testing something and find themselves having lost an hour just reading the encyclopedia they were working on, an eerily modern and relatable issue.</p><p>On the 9th of March in 2000, Jimmy Wales and Larry Sanger launched Nupedia. This was an online encyclopedia where articles were written by volunteers who had subject matter expertise (with preference for PhDs). Those articles were then reviewed by editors, and approved articles were subsequently published online and licensed as free content. Apparently, encyclopedias are difficult to make. In it’s first year of operation, Nupedia had only 21 articles. On the 10th of January in 2001, Sanger proposed a wiki that would server as an upstream content source for Nupedia. Wikipedia was launched on the 15th of January in 2001. Wikipedia’s growth was explosive. In its first month, it gained 200 articles. By January of 2002, Wikipedia included more than 20000 articles. Nupedia was dissolved in September of 2003 following a server crash.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png" width="1456" height="899" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:899,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:258987,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F916f8b32-2f25-45f2-bd06-8e04f526d287_1678x1036.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption>Wikipedia in January of 2002</figcaption></figure></div><p>Microsoft had completely revolutionized and democratized the encyclopedia market, made CDs common, and made human knowledge searchable. Unfortunately, Wikipedia continued to grow, and Encarta sales declined. Encarta was discontinued on the 31st of October in 2009. </p><p>Many reasons are given for Encarta’s demise. Wikipedia’s effect on the market cannot be discounted, but it also wasn’t the only cause. Google offered Wikipedia results and many more sites besides. People paying for an internet connection could simply search a topic or a question and be presented with millions of potential information sources. Personally, I find this disappointing. Encarta’s information was more engaging and more fun to explore. There were many rainy days in my youth where I could be found exploring Encarta 94 or 97. Encarta also had a better user experience than the web. There weren’t banner ads, pop ups, cookie notices, donation requests, or any other annoyance. A person could simply use a searchable, linked, multimedia encyclopedia.</p><p>I now have readers from many of the companies whose history I cover, many of you were present for time periods I cover, and a few of you are mentioned by name in my articles. All corrections to the record are welcome; feel free to leave a comment.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Internal slides on the work of the Google "Ads Quality" team (115 pts)]]></title>
            <link>https://twitter.com/jason_kint/status/1718830641016414657</link>
            <guid>38066135</guid>
            <pubDate>Mon, 30 Oct 2023 05:52:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/jason_kint/status/1718830641016414657">https://twitter.com/jason_kint/status/1718830641016414657</a>, See on <a href="https://news.ycombinator.com/item?id=38066135">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="ScriptLoadFailure"><form action="" method="GET"><div><p><span>Something went wrong, but don’t fret — let’s give it another shot.</span></p><br></div></form></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finding services companies via their TXT records (109 pts)]]></title>
            <link>https://www.abenezerbelachew.com/blog/services-companies-use-txt-records</link>
            <guid>38066034</guid>
            <pubDate>Mon, 30 Oct 2023 05:33:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.abenezerbelachew.com/blog/services-companies-use-txt-records">https://www.abenezerbelachew.com/blog/services-companies-use-txt-records</a>, See on <a href="https://news.ycombinator.com/item?id=38066034">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>I was watching <a target="_blank" rel="noopener noreferrer" href="https://jvns.ca/">Julia Evan</a>'s <a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=tsxjNsFu_2g">talk</a> on DNS at RubyConf during
an early dinner when I came across something interesting. I thought I would share it here.</p>
<p>Before watching the talk, I knew what TXT records were and had even used them to verify domains for
some services. However, I never knew they were public and visible for everyone. I genuinely thought they were solely
used for verification purposes by the companies that employed them and were kept private. I was wrong.</p>
<p>🌞 For those unfamiliar, TXT records are used to store text data associated with a domain name. They have various applications,
including verification and authentication. While there may be more uses, these are the two I have encountered in the past.</p>
<ul>
<li>
<p>For example, when a product asks you to verify your domain, they might request you to add a TXT record to your domain. Once added, they check for the presence of this record to verify your domain.</p>
</li>
<li>
<p>Reflecting on that definition and example, I'm not sure why I didn't realize they were public before. 🤦</p>
</li>
<li>
<p>Anyways, here's how you can discover the products and services companies use through their TXT records.</p>
</li>
</ul>
<h2 id="1-find-a-companys-domain"><a href="#1-find-a-companys-domain"><span></span></a>1. Find a company's domain</h2>
<p>First, you need to find a company's domain. For example, let's use <a target="_blank" rel="noopener noreferrer" href="https://stripe.com/">Stripe</a>. Their domain
is stripe.com.</p>
<p><span><span></span><img alt="Mind Blown Meme" srcset="https://www.abenezerbelachew.com/_next/image?url=%2Fstatic%2Fimages%2Fproducts-txt-records%2Fmind-blow-galaxy.gif&amp;w=384&amp;q=75 1x, https://www.abenezerbelachew.com/_next/image?url=%2Fstatic%2Fimages%2Fproducts-txt-records%2Fmind-blow-galaxy.gif&amp;w=750&amp;q=75 2x" src="https://www.abenezerbelachew.com/_next/image?url=%2Fstatic%2Fimages%2Fproducts-txt-records%2Fmind-blow-galaxy.gif&amp;w=750&amp;q=75" decoding="async" data-nimg="intrinsic" loading="lazy" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p><h2 id="2-find-the-txt-records-for-the-domain"><a href="#2-find-the-txt-records-for-the-domain"><span></span></a>2. Find the TXT records for the domain</h2>
<p>Finding the TXT records for a domain is straightforward. You can use <a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Dig_(command)">dig</a> or
<a target="_blank" rel="noopener noreferrer" href="https://en.wikipedia.org/wiki/Nslookup">nslookup</a>. I will be using dig.</p>
<pre><code><span><span>dig</span> stripe.com TXT
</span></code></pre>
<ul>
<li>For instance, here's the answer section for stripe.com on the day I wrote this post: Oct 29, 2023.</li>
</ul>
<pre><code><span><span>;</span><span>;</span> ANSWER SECTION:
</span><span>www.stripe.com.         <span>0</span>       IN      CNAME   stripe.com.
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"google-site-verification=hPfjsDwiisKJ4RP1ExOst9gAOD_0P8Q7-kxdcKUvEcc"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"liveramp-site-verification=7gyFkTwGYsvgd7IUQwyAOfImETwR06wgKjKiXq90KEY"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"h1-domain-verification=KhpNX9YNAc7bX95agGvFsPPKbYTVe1KC6xj7P1zKZrRzxcuS"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"atlassian-domain-verification=upLp21qQgja1aHG2gnAb1AmXRqb/zG0UK1a0n3zTSXZg5DgOSttR3i5uzA3T9Cdk"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"v=spf1 ip4:198.2.180.60/32 ip4:13.111.2.227/32 include:spf1.stripe.com include:greenhouse-outbound-mail.stripe.com ~all"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"MS=ms80697640"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"3l1wm9pqffwmrbvq2f5tbwjwtb8gjbr7"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"jhf40tgyx4pkkxllg33nthrwj3ty3dd8"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"kjch4f71j4hsrkjgvfbtcqlj0b5r7bjx"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"z4mthhzk10l6qc0rg4211mnnppkh2y5b"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"asv=8de0c1a866b958297e22a36216e594a6"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"edcbf4c7-b604-457b-870e-1b05f655e769"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"apple-domain-verification=8kIS0gmJTvILWQuI"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"docusign=4a93db58-af07-4632-a881-b569d41a6c57"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"docusign=4c9f5602-1c19-4e4c-bde7-77dc4b9ea8a0"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"whimsical=253112f9add9790f3a27b9d9893626451fc4cda1"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"docker-verification=ccde1a0d-8d2c-44b5-9d20-6c4e19113fc9"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"facebook-domain-verification=m7id9rt8ehlgcg9tt2yggbsi6gro7i"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"google-site-verification=PrlpJHdk11CIkPsiXoHEAJevWHAk39JRFAqVSe9l7n0"</span>
</span><span>stripe.com.             <span>0</span>       IN      TXT     <span>"google-site-verification=ZgGi2-xDdfnaWxdfjn5AqtUS11jKWqSXAV_EHODFzdE"</span>
</span></code></pre>
<ul>
<li>So Stripe seems to have verified their site with Google, Liveramp (I didn't know what this was until minutes ago, for example), Atlassian, Docker, Docusign
and a couple others.</li>
</ul>
<h3 id="using-nslookup"><a href="#using-nslookup"><span></span></a>Using nslookup</h3>
<p>The following is the nslookup equivalent of the dig command above.</p>
<pre><code><span><span>nslookup</span> -type<span>=</span>TXT stripe.com
</span></code></pre>
<h4 id="note"><a href="#note"><span></span></a>Note:</h4>
<ul>
<li>
<p>You can obtain different results based on the inclusion of subdomains. For instance, when you run the commands dig stripe.com TXT and dig
<a target="_blank" rel="noopener noreferrer" href="http://www.stripe.com/">www.stripe.com</a> TXT, you might get different results. Not only can the specific records differ based on the site you're 'digging',
but also the order in which the records are returned might vary.</p>
</li>
<li>
<p>Most of the companies I checked have verification records for Atlassian. I knew it was a big company, but I didn't realize it was so
deeply integrated into the tech ecosystem.</p>
</li>
<li>
<p>As someone who frequently reads various tech blogs from different companies and regularly checks sites like <a target="_blank" rel="noopener noreferrer" href="https://stackshare.io/">stackshare.io</a> to
discover the technology used behind the scenes by companies, this was a great find.</p>
</li>
<li>
<p>I'm sure there are other ways to discover the
products and services companies use, but this is a great one to add to your arsenal.</p>
</li>
</ul>
<p>🐒</p>
<br>

<ul>
<li>🇪🇬 Egypt achieved independence in 1922. I don't know why this surprised me, but it did. I thought it was much earlier.</li>
</ul></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The death of a public intellectual (131 pts)]]></title>
            <link>https://thmsmlr.com/public-intellectuals</link>
            <guid>38065779</guid>
            <pubDate>Mon, 30 Oct 2023 04:44:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://thmsmlr.com/public-intellectuals">https://thmsmlr.com/public-intellectuals</a>, See on <a href="https://news.ycombinator.com/item?id=38065779">Hacker News</a></p>
<div id="readability-page-1" class="page"><div phx-hook="ScrollTracker" id="post">
  <p>
  <img src="https://thmsmlr.com/im/thinkingman.jpg" alt="The Death of a Public Intellectual">
</p>
<p>
Is it that time of the year again? A new intellectual minted. The loss of next
few evenings watching YouTube, reading substacks? All for that sweet nectar of a
novel “hot take”.</p>
<p>
It seems every 6 months I find someone new to obsess over. This started a few
years ago. First it was Jordan Peterson, then it i was Eric Weinstein, then
Chamath, the list goes on. Most recently, it’s been Peter Zeihan.</p>
<p>
The story goes something like this, I get recommended a clip on YouTube, there’s
a man who is calm, articulate, and says something that completely violates the
narrative. How fascinating. Is my understanding of the world completely wrong?!
I need to read everything this man written.</p>
<p>
The next few weeks are spent digging up every single video I can find, hearing
the same points repeated, each video adding a little extra context which helps
fill in the gaps. By the end of it I feel like I can articulate the points as well as
him. I can’t, but it sure feels like I can.</p>
<p>
And so the man gets a seat on the roster. From here on out, anytime a new
piece of content comes out, i’ll be the first to listen.</p>
<p>
Without fail, each one of comes to dissapoint. They’re either a one trick
pony, and every development in the world is analyzed through the same tired lens
whether its applicable or not. Or, they are so desparate for keeping momentum
so they have a “hot take” everything. Problem is their first take is
often born out of decades of experience in a field, whereas each subsequent is born
out of decreasing rigor. And so, their credibility withers.</p>
<p>
It’s a shame because they are clearly very smart men who have much to contribute
to the public conversation, but they make the tactical error of getting out over
their skis.</p>
<p>
I don’t blame them either. Imagine toiling away in the obscurity of some dark
university office building. Thrown into the limelight because you have the next
interesting thing to say at the right moment when the world is paying attention.
Milk it for all it’s worth. Get that bag. </p>
<p>
But dear reader see this pattern for what it is.</p>
<p>
You’re basis for truth often relies on authority of your source.
Epistemologically speaking it’s a weak standard, but this is a busy world, and
you need some heuristic to sift through it quickly. Know this pattern so you can
cast off these men at their peak instead of riding it all the way down.</p>
<p>
And take note when one doesn’t fall, study them the hardest.</p>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to Move Your Google Photos (131 pts)]]></title>
            <link>https://www.auckland.ac.nz/en/students/my-tools/googlechanges/Move-your-google-photos.html</link>
            <guid>38065002</guid>
            <pubDate>Mon, 30 Oct 2023 02:16:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.auckland.ac.nz/en/students/my-tools/googlechanges/Move-your-google-photos.html">https://www.auckland.ac.nz/en/students/my-tools/googlechanges/Move-your-google-photos.html</a>, See on <a href="https://news.ycombinator.com/item?id=38065002">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                    <p>How to move your Google Photos from your University Google Drive</p>
                </div><div><div>
        <h3>IMPORTANT</h3>

<p><b>It is&nbsp;critical&nbsp;that you delete your photos once you've moved them as Google doesn't provide administrators with any ability to delete photos, so if you don't remove them then we'll be forced to delete your entire account, including your email contents. We don't want to do this, so make sure you delete your photos.</b></p>



    </div>
<p>





    <h2>1. Choose your new photos location</h2>
</p>
<div>
        <p>Select the service you will use. All the cloud services listed have a free service with the ability to pay for additional storage if required.</p>

<p>This is just a small selection of other services - there's plenty of others you can use.</p>

<p>None of them are affiliated or supported by the University - this is your choice to make.</p>

<ul>
<li><b>Personal Google account. This is the easiest - just follow these <a href="https://www.auckland.ac.nz/en/students/my-tools/googlechanges/Move-google-photos.html">instructions</a></b></li>
</ul>

<ul>
<li>University OneDrive - not recommended as your photos will be automatically deleted when your affiliation with the University ends</li>
<li><a href="https://onedrive.live.com/">Personal OneDrive</a> - free 15GB storage</li>
<li><a href="https://www.dropbox.com/">DropBox</a> - free 2GB storage</li>
<li><a href="https://degoo.com/">Degoo</a> -&nbsp; free 100GB storage</li>
<li>Local computer</li>
</ul>



    </div>
<p>





    <h2>2. Decide if you want to reduce the size of your photos beforehand</h2>
</p>
<p>While all photos you upload to Google photos are stored in the original quality that you created them in, Google also has a storage saver mode that can dramatically reduce the size of the photos and video files with a minimal degradation in quality. This <a href="https://www.auckland.ac.nz/en/students/my-tools/googlechanges/google-photos-storage-saver.html">Google Storage Saver page</a> covers information about this option that you should read before moving on to using Google Takeout.</p>
<p>





    <h2>3. Delete any videos you don't need</h2>
</p>
<div>




    
    
        <p>Videos will always take more space than a photo. Deleting old unused videos is the easiest way to free up space in Google Photos.&nbsp;&nbsp;<b>Note that Google uses the terms Bin and Trash to mean the same thing - on your device it may show Trash rather than Bin.</b></p>

<ol>
<li>Go to&nbsp;<a href="https://photos.google.com/">https://photos.google.com</a> and login with your @aucklanduni.ac.nz details</li>
<li>Click&nbsp;<b>Explore</b>&nbsp;on the left hand side</li>
<li>Down the bottom of the screen select&nbsp;<b>Categories &gt; Videos</b></li>
<li>Select the videos you don’t want and click the&nbsp;<b>rubbish bin</b>&nbsp;icon in<br>
the top right</li>
<li>Select&nbsp;<b>Move to bin</b></li>
<li>Go to the <b>Bin</b> and click&nbsp;<b>Empty bin</b></li>
<li>Click&nbsp;<b>Empty bin</b>&nbsp;again<br>
</li>
</ol>



    
    

</div>
<p>





    <h2>Watch the instruction video</h2>
</p>
<div>


    <p>
        <iframe allowfullscreen="" frameborder="0" scrolling="no" src="https://www.youtube.com/embed/IZXUs7s39wU?rel=0&amp;vq=hd720&amp;autohide=1&amp;modestbranding=1&amp;showinfo=1&amp;&amp;iv_load_policy=3"></iframe>
    </p>
</div>
<p>





    <h2>4. Use Google TakeOut to download your photos</h2>
</p>
<div>




    
    
        <p>Google TakeOut can be used to export individual photo libraries or your entire photo collection in Google Photos.</p>

<ol>
<li>&nbsp;Go to <a href="https://takeout.google.com/">https://takeout.google.com</a></li>
<li>&nbsp;Sign in using your @aucklanduni.ac.nz address and usual password</li>
<li>&nbsp;Under <b>1.&nbsp;Select data to include</b>, click the blue <b>Deselect all</b> link</li>
<li>&nbsp;Put a tick in <b>Google Photos</b>. If you want to only choose specific libraries then click on <b>All photo albums included</b> and tick the libraries you want to copy</li>
<li>&nbsp;Scroll to the bottom of the screen and click <b>Next step</b></li>
<li><b>&nbsp;</b>Choose the Delivery method (normally this is send download link via email). Note that Add to OneDrive will not add to OneDrive for Business (the University's OneDrive)</li>
<li>Change the file type and size to either:</li>
</ol>

<ul>
<li><b>10 GB </b>- if you have less than 100GB of photos</li>
<li><b>20 GB -&nbsp;</b>if you have more than 100GB of photos</li>
</ul>

<ol>
<li>Click <b>Create Export</b></li>
</ol>



    
    

</div>
<div>
    
        

            <figure>
                
    
    <picture>
        
        
            
            
            <source media="(min-width: 768px)" srcset="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/jcr:content/leftpar/imagecomponent/image.img.1024.medium.jpg/1627359132488.png">
            <source media="(min-width: 480px)" srcset="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/jcr:content/leftpar/imagecomponent/image.img.768.medium.jpg/1627359132488.png">
        
        
        
        <img src="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/_jcr_content/leftpar/imagecomponent/image.img.480.low.jpg/1627359132488.png">
    </picture>

                    
                
            </figure>
        
    
</div>
<div>




    
    
        <p>A zip file will now be created that you can open on your computer.This may take up to 24 hours. Once it's been created you will be emailed at your @aucklanduni.ac.nz email address.</p>

<p>Note that for each photo there is a JSON file. The JSON files are only useful if you've added comments, descriptions etc. in Google Photos.&nbsp;</p>

<p>Click on the <b>download link</b>.</p>



    
    

</div>
<div>
    
        

            <figure>
                
    
    <picture>
        
        
            
            
            <source media="(min-width: 768px)" srcset="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/jcr:content/leftpar/imagecomponent_743173574/image.img.1024.medium.jpg/1627359246827.png">
            <source media="(min-width: 480px)" srcset="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/jcr:content/leftpar/imagecomponent_743173574/image.img.768.medium.jpg/1627359246827.png">
        
        
        
        <img src="https://cdn.auckland.ac.nz/aem/content/auckland/en/students/my-tools/googlechanges/Move-your-google-photos/_jcr_content/leftpar/imagecomponent_743173574/image.img.480.low.jpg/1627359246827.png">
    </picture>

                    
                
            </figure>
        
    
</div>
<p>





    <h2>5. Delete the JSON files</h2>
</p>
<div>




    
    
        <p>For each file there is a JSON file. This file is only useful if you have added any information like captions or descriptions to the photo within Google Photos.&nbsp;The information about where and when a photo was taken and any camera settings are stored in the photo file - they don't need the JSON file.</p>

<ol>
<li>Open the zip file(s) and extract them to folders on your computer</li>
<li>Search for JSON</li>
<li>Select all the files that are found (in Windows this is CTRL-A)</li>
<li>Delete all the JSON files</li>
</ol>



    
    

</div>
<p>





    <h2>6. Copy the files to your new service</h2>
</p>
<div>




    
    
        <p>Once you have removed the JSON files you can now copy the files to your new service. Instructions will be different for each. Your University OneDrive is only available to you while you are affiliated with the University so is not a good location for your personal photos. Here's some guides for common services, but you're not limited to using the list here - choose a service that works best for you.</p>

<ul>
<li><a href="https://help.dropbox.com/files-folders/share/add-files">Upload files to DropBox</a></li>
<li><a href="https://support.microsoft.com/en-us/office/upload-photos-and-files-to-onedrive-b00ad3fe-6643-4b16-9212-de00ef02b586">Upload files to your personal OneDrive</a></li>
<li><a href="https://degoo.com/download">Upload files to Degoo</a></li>
</ul>



    
    

</div>
<p>





    <h2>7. Delete the old files</h2>
</p>
<div>




    
    
        <p>Google Transfer copies your files - it doesn't move them. Once you have checked and are happy that you have all the files you need please remove the originals from both your local computer, mobile device and University Google Drive.</p>

<h3>Step 1: Delete the photos from your computer and mobile and turn off syncing</h3>

<p>It is critical that you also make sure that you turn off any Google Photo's syncing on any computer or mobile device otherwise any newly taken photos will upload to your University Google Drive.</p>

<p>Use these <a href="https://support.google.com/photos/answer/6193313?hl=en&amp;co=GENIE.Platform%3DAndroid">instructions to Turn backup and sync off</a>. You will need to do this for each device you have configured before moving to Step 2.</p>

<p>Note that the Google Photo app on a mobile device shows a combination of local photos and those on Google Drive.</p>

<h3>Step 2: Remove photos from your University Google Drive</h3>

<p><b>Note that Google uses the terms Bin and Trash to mean the same thing - on your device it may show Trash rather than Bin.</b>The University has no ability to delete your photos for you. Remember you must do this step otherwise we will have to remove your entire account, mail, drive and photos.</p>

<p><b>To remove photos in Google:</b></p>

<ol>
<li>Go to Photos on the web on a computer (https://photos.google.com)</li>
<li>Note where the Delete bin is in the top right of the screen</li>
<li>Ctrl+Shift+minus to zoom out on your browser until you can only just see the check mark in the corner of an image</li>
<li>Hold shift as you click the first photo</li>
<li>Release shift</li>
<li>PgDn 20-30 times then find another image, hold shift and click the check mark.&nbsp; They all turn blue down to that point</li>
<li>Click the tiny top right bin&nbsp;Click&nbsp;<b>Move to bin</b></li>
</ol>

<p>The photos will be automatically removed in 30 days. Your storage allocation will change after the 30 days, or you can remove all files from the bin beforehand.</p>



    
    

</div>
<p>





    <h2>I’ve accidentally deleted folders from Google Drive, how do I get them back?</h2>
</p>
<div>




    
    
        <ol>
<li>Go to <b>Bin</b> on the left-hand side</li>
<li>Highlight the folder or file to restore, Right-click<br>
and select <b>Restore</b></li>
</ol>



    
    

</div>
<p>





    <h2>I have a large amount of photos and Google Takeout is inefficient</h2>
</p>
<div>




    
    
        
<p>If you have large amounts of photos and Google Takeout is splitting the zip files into many files, another solution for Windows users is to use a 30 day trial of <b>SyncBack Pro</b> to copy the photos to a local drive or to use <a href="https://www.msp360.com/download.aspx?prod=cbbackup&amp;p=backup">CloudBerry Backup Free</a>.</p>

<h3>SyncBack Pro instructions:</h3>

<ol>
<li>&nbsp;Download the 30 day trial from here:&nbsp;<a href="https://www.2brightsparks.com/assets/software/SyncBackPro64_Setup.exe">https://www.2brightsparks.com/assets/software/SyncBackPro64_Setup.exe</a></li>
<li>&nbsp;Run the downloaded file and follow the installation steps</li>
<li>&nbsp;At SyncBackPro Welcome and Serial Number Input, click <b>Evaluate</b></li>
<li><b>&nbsp;</b>Click <b>New</b> to create a new profile, entering a name. Choose <b>Backup</b></li>
<li><b>&nbsp;</b>Change the Source to <b>Google Photos</b> (it's towards the bottom of the list of sources)</li>
<li>&nbsp;You need to check you have have sufficient local disk space if you haven't already.</li>
<li>&nbsp;At the Google Photos screen, just click <b>Connect to Google Photos -&nbsp;</b>don't try and fill in any details in the Account field</li>
<li><b>&nbsp;</b>A browser window will open and ask you to sign in to Google. Click your @aucklanduni.ac.nz account if it gives you an option of multiple accounts</li>
<li>Make sure that there are ticks next to everything SyncBackPro needs to access and click <b>Continue</b></li>
<li><b>&nbsp;</b>A long string of text and numbers will appear. Copy this by clicking the <b>Copy</b> button to the right of it</li>
<li>&nbsp;Go back to SyncBackPro's authorisation code window and press <b>CTRL-V</b> to paste the code. Click <b>OK</b></li>
<li>&nbsp;Your @aucklanduni.ac.nz account will now appear in the Account field. Click <b>Done</b></li>
<li><b>&nbsp;</b>At the Profile Setup page use the folder icon next to the Destination field to choose a folder to put your photos. This must have sufficient space to fit all your photos.</li>
<li>&nbsp;Some more information will appear under Description of this profile. Click <b>OK</b></li>
<li><b>&nbsp;</b>Click <b>Yes</b> to Would you like to perform a simulated run for this profile?</li>
<li>&nbsp;The simulation window will show you files that would be copied and their new location - it doesn't actually copy any photos. Check that the photos would be copied to the correct location</li>
<li>&nbsp;Go back to the Profiles windows, highlight the backup profile you created above and click <b>Run</b>. SyncBackPro will now backup your Google Photos to your local computer. <b>You need to keep your computer on, and SyncBackPro running during this</b>.</li>
</ol>



    
    

</div>
<p>





    <h2>I am struggling to do this</h2>
</p>
<div>




    
    
        <p>If you have already attempted to migrate your photos but are having issues, please use one of these forms to contact us for assistance:</p>

<ul>
<li><a href="https://auckland.ac.nz/google-changes-staff-request-form">Request form for current staff members</a></li>
<li><a href="https://forms.office.com/Pages/ResponsePage.aspx?id=lW6z0VAN6UKVj7Y_qQa-qhEp57JodRdNodS5aE9KqQhUQ0NTNk5HWTk2VUNOUU01VFhGSEpUSDI0WC4u">Request form for students, alumni and previous members of staff</a></li>
</ul>



    
    

</div>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web FM synthesizer made with HTML5 (233 pts)]]></title>
            <link>https://www.taktech.org/takm/WebFMSynth/</link>
            <guid>38064856</guid>
            <pubDate>Mon, 30 Oct 2023 01:53:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.taktech.org/takm/WebFMSynth/">https://www.taktech.org/takm/WebFMSynth/</a>, See on <a href="https://news.ycombinator.com/item?id=38064856">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
  	<a href="http://www.taktech.org/takm/DXie/DXi_for_iPhone.html">
    	<p>DXi FM synthesizer for iPhone/iPad</p>
    	<p>2010-2014 Takashi Mizuhiki &amp; creative studio CUE</p>
		<p><img src="https://www.taktech.org/takm/WebFMSynth/Available_on_the_App_Store_Badge_US-UK_135x40_0801.svg" width="135px" height="40px">
		</p>
	</a>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How deep is the brain? The shallow brain hypothesis (182 pts)]]></title>
            <link>https://www.nature.com/articles/s41583-023-00756-z</link>
            <guid>38064287</guid>
            <pubDate>Mon, 30 Oct 2023 00:28:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nature.com/articles/s41583-023-00756-z">https://www.nature.com/articles/s41583-023-00756-z</a>, See on <a href="https://news.ycombinator.com/item?id=38064287">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Hegde, J. &amp; Felleman, D. J. Reappraising the functional implications of the primate visual anatomical hierarchy. <i>Neuroscientist</i> <b>13</b>, 416–421 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1177/1073858407305201" data-track-action="article reference" href="https://doi.org/10.1177%2F1073858407305201" aria-label="Article reference 1" data-doi="10.1177/1073858407305201">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17901251" aria-label="PubMed reference 1">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Reappraising%20the%20functional%20implications%20of%20the%20primate%20visual%20anatomical%20hierarchy&amp;journal=Neuroscientist&amp;doi=10.1177%2F1073858407305201&amp;volume=13&amp;pages=416-421&amp;publication_year=2007&amp;author=Hegde%2CJ&amp;author=Felleman%2CDJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="2."><p id="ref-CR2">LeCun, Y., Bengio, Y. &amp; Hinton, G. Deep learning. <i>Nature</i> <b>521</b>, 436–444 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature14539" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature14539" aria-label="Article reference 2" data-doi="10.1038/nature14539">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXht1WlurzP" aria-label="CAS reference 2">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26017442" aria-label="PubMed reference 2">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 2" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20learning&amp;journal=Nature&amp;doi=10.1038%2Fnature14539&amp;volume=521&amp;pages=436-444&amp;publication_year=2015&amp;author=LeCun%2CY&amp;author=Bengio%2CY&amp;author=Hinton%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="3."><p id="ref-CR3">Stokel-Walker, C. &amp; Van Noorden, R. What ChatGPT and generative AI mean for science. <i>Nature</i> <b>614</b>, 214–216 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/d41586-023-00340-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fd41586-023-00340-6" aria-label="Article reference 3" data-doi="10.1038/d41586-023-00340-6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXivVKisLY%3D" aria-label="CAS reference 3">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36747115" aria-label="PubMed reference 3">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20ChatGPT%20and%20generative%20AI%20mean%20for%20science&amp;journal=Nature&amp;doi=10.1038%2Fd41586-023-00340-6&amp;volume=614&amp;pages=214-216&amp;publication_year=2023&amp;author=Stokel-Walker%2CC&amp;author=Noorden%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="4."><p id="ref-CR4">He, K., Zhang, X., Ren, S. &amp; Sun, J. Deep residual learning for image recognition. In <i>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i> 770–778 (2016).</p></li><li data-counter="5."><p id="ref-CR5">Russakovsky, O. et al. ImageNet large scale visual recognition challenge. <i>Int. J. Comput. Vis.</i> <b>115</b>, 211–252 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s11263-015-0816-y" data-track-action="article reference" href="https://doi.org/10.1007%2Fs11263-015-0816-y" aria-label="Article reference 5" data-doi="10.1007/s11263-015-0816-y">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=ImageNet%20large%20scale%20visual%20recognition%20challenge&amp;journal=Int.%20J.%20Comput.%20Vis.&amp;doi=10.1007%2Fs11263-015-0816-y&amp;volume=115&amp;pages=211-252&amp;publication_year=2015&amp;author=Russakovsky%2CO">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="6."><p id="ref-CR6">Xu, K. et al. Show, attend and tell: neural image caption generation with visual attention. In <i>32nd Int. Conf. on Machine Learning</i> (eds F. Bach. &amp; D. Blei) 2048–2057 (2015).</p></li><li data-counter="7."><p id="ref-CR7">Fukushima, K. Neocognitron—a self-organizing neural network model for a mechanism of pattern-recognition unaffected by shift in position. <i>Biol. Cybern.</i> <b>36</b>, 193–202 (1980).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF00344251" data-track-action="article reference" href="https://doi.org/10.1007%2FBF00344251" aria-label="Article reference 7" data-doi="10.1007/BF00344251">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL3c7nsFKntw%3D%3D" aria-label="CAS reference 7">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7370364" aria-label="PubMed reference 7">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Neocognitron%E2%80%94a%20self-organizing%20neural%20network%20model%20for%20a%20mechanism%20of%20pattern-recognition%20unaffected%20by%20shift%20in%20position&amp;journal=Biol.%20Cybern.&amp;doi=10.1007%2FBF00344251&amp;volume=36&amp;pages=193-202&amp;publication_year=1980&amp;author=Fukushima%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="8."><p id="ref-CR8">Hubel, D. H. &amp; Wiesel, T. N. Receptive fields, binocular interaction and functional architecture in the cat’s visual cortex. <i>J. Physiol.</i> <b>160</b>, 106–154 (1962).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1113/jphysiol.1962.sp006837" data-track-action="article reference" href="https://doi.org/10.1113%2Fjphysiol.1962.sp006837" aria-label="Article reference 8" data-doi="10.1113/jphysiol.1962.sp006837">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaF38%2FltFSisA%3D%3D" aria-label="CAS reference 8">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=14449617" aria-label="PubMed reference 8">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1359523" aria-label="PubMed Central reference 8">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Receptive%20fields%2C%20binocular%20interaction%20and%20functional%20architecture%20in%20the%20cat%E2%80%99s%20visual%20cortex&amp;journal=J.%20Physiol.&amp;doi=10.1113%2Fjphysiol.1962.sp006837&amp;volume=160&amp;pages=106-154&amp;publication_year=1962&amp;author=Hubel%2CDH&amp;author=Wiesel%2CTN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="9."><p id="ref-CR9">Chang, L. &amp; Tsao, D. Y. The code for facial identity in the primate brain. <i>Cell</i> <b>169</b>, 1013–1028.e14 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2017.05.011" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2017.05.011" aria-label="Article reference 9" data-doi="10.1016/j.cell.2017.05.011">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXpt1ags7Y%3D" aria-label="CAS reference 9">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28575666" aria-label="PubMed reference 9">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8088389" aria-label="PubMed Central reference 9">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20code%20for%20facial%20identity%20in%20the%20primate%20brain&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2017.05.011&amp;volume=169&amp;pages=1013-1028.e14&amp;publication_year=2017&amp;author=Chang%2CL&amp;author=Tsao%2CDY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="10."><p id="ref-CR10">Yamins, D. L. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, 8619–8624 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1403112111" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1403112111" aria-label="Article reference 10" data-doi="10.1073/pnas.1403112111">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXnslWnsb4%3D" aria-label="CAS reference 10">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24812127" aria-label="PubMed reference 10">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4060707" aria-label="PubMed Central reference 10">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance-optimized%20hierarchical%20models%20predict%20neural%20responses%20in%20higher%20visual%20cortex&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1403112111&amp;volume=111&amp;pages=8619-8624&amp;publication_year=2014&amp;author=Yamins%2CDL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="11."><p id="ref-CR11">Guclu, U. &amp; van Gerven, M. A. Deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream. <i>J. Neurosci.</i> <b>35</b>, 10005–10014 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.5023-14.2015" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.5023-14.2015" aria-label="Article reference 11" data-doi="10.1523/JNEUROSCI.5023-14.2015">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26157000" aria-label="PubMed reference 11">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6605414" aria-label="PubMed Central reference 11">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20networks%20reveal%20a%20gradient%20in%20the%20complexity%20of%20neural%20representations%20across%20the%20ventral%20stream&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.5023-14.2015&amp;volume=35&amp;pages=10005-10014&amp;publication_year=2015&amp;author=Guclu%2CU&amp;author=Gerven%2CMA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="12."><p id="ref-CR12">Cichy, R. M., Khosla, A., Pantazis, D., Torralba, A. &amp; Oliva, A. Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence. <i>Sci. Rep.</i> <b>6</b>, 27755 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/srep27755" data-track-action="article reference" href="https://doi.org/10.1038%2Fsrep27755" aria-label="Article reference 12" data-doi="10.1038/srep27755">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xpslymtbc%3D" aria-label="CAS reference 12">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27282108" aria-label="PubMed reference 12">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4901271" aria-label="PubMed Central reference 12">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20deep%20neural%20networks%20to%20spatio-temporal%20cortical%20dynamics%20of%20human%20visual%20object%20recognition%20reveals%20hierarchical%20correspondence&amp;journal=Sci.%20Rep.&amp;doi=10.1038%2Fsrep27755&amp;volume=6&amp;publication_year=2016&amp;author=Cichy%2CRM&amp;author=Khosla%2CA&amp;author=Pantazis%2CD&amp;author=Torralba%2CA&amp;author=Oliva%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="13."><p id="ref-CR13">Schrimpf, M. et al. The neural architecture of language: integrative modeling converges on predictive processing. <i>Proc. Natl Acad. Sci. USA</i> <b>118</b>, e2015646118 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.2105646118" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.2105646118" aria-label="Article reference 13" data-doi="10.1073/pnas.2105646118">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neural%20architecture%20of%20language%3A%20integrative%20modeling%20converges%20on%20predictive%20processing&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.2105646118&amp;volume=118&amp;publication_year=2021&amp;author=Schrimpf%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="14."><p id="ref-CR14">Kriegeskorte, N. Deep neural networks: a new framework for modeling biological vision and brain information processing. <i>Annu. Rev. Vis. Sci.</i> <b>1</b>, 417–446 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-vision-082114-035447" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-vision-082114-035447" aria-label="Article reference 14" data-doi="10.1146/annurev-vision-082114-035447">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28532370" aria-label="PubMed reference 14">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20neural%20networks%3A%20a%20new%20framework%20for%20modeling%20biological%20vision%20and%20brain%20information%20processing&amp;journal=Annu.%20Rev.%20Vis.%20Sci.&amp;doi=10.1146%2Fannurev-vision-082114-035447&amp;volume=1&amp;pages=417-446&amp;publication_year=2015&amp;author=Kriegeskorte%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="15."><p id="ref-CR15">Yamins, D. L. &amp; DiCarlo, J. J. Using goal-driven deep learning models to understand sensory cortex. <i>Nat. Neurosci.</i> <b>19</b>, 356–365 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4244" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4244" aria-label="Article reference 15" data-doi="10.1038/nn.4244">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XjtVOjt7k%3D" aria-label="CAS reference 15">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26906502" aria-label="PubMed reference 15">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20goal-driven%20deep%20learning%20models%20to%20understand%20sensory%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4244&amp;volume=19&amp;pages=356-365&amp;publication_year=2016&amp;author=Yamins%2CDL&amp;author=DiCarlo%2CJJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="16."><p id="ref-CR16">Friston, K. A theory of cortical responses. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>360</b>, 815–836 (2005).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2005.1622" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2005.1622" aria-label="Article reference 16" data-doi="10.1098/rstb.2005.1622">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15937014" aria-label="PubMed reference 16">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1569488" aria-label="PubMed Central reference 16">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20theory%20of%20cortical%20responses&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2005.1622&amp;volume=360&amp;pages=815-836&amp;publication_year=2005&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="17."><p id="ref-CR17">Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. <i>Nat. Neurosci.</i> <b>2</b>, 79–87 (1999).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/4580" data-track-action="article reference" href="https://doi.org/10.1038%2F4580" aria-label="Article reference 17" data-doi="10.1038/4580">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK1MXhsl2ns7k%3D" aria-label="CAS reference 17">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10195184" aria-label="PubMed reference 17">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20in%20the%20visual%20cortex%3A%20a%20functional%20interpretation%20of%20some%20extra-classical%20receptive-field%20effects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F4580&amp;volume=2&amp;pages=79-87&amp;publication_year=1999&amp;author=Rao%2CRP&amp;author=Ballard%2CDH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="18."><p id="ref-CR18">Lee, T. S. &amp; Mumford, D. Hierarchical Bayesian inference in the visual cortex. <i>J. Opt. Soc. Am. A Opt. Image Sci. Vis.</i> <b>20</b>, 1434–1448 (2003).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1364/JOSAA.20.001434" data-track-action="article reference" href="https://doi.org/10.1364%2FJOSAA.20.001434" aria-label="Article reference 18" data-doi="10.1364/JOSAA.20.001434">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12868647" aria-label="PubMed reference 18">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchical%20Bayesian%20inference%20in%20the%20visual%20cortex&amp;journal=J.%20Opt.%20Soc.%20Am.%20A%20Opt.%20Image%20Sci.%20Vis.&amp;doi=10.1364%2FJOSAA.20.001434&amp;volume=20&amp;pages=1434-1448&amp;publication_year=2003&amp;author=Lee%2CTS&amp;author=Mumford%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="19."><p id="ref-CR19">Srinivasan, M. V., Laughlin, S. B. &amp; Dubs, A. Predictive coding: a fresh view of inhibition in the retina. <i>Proc. R. Soc. Lond. B Biol. Sci.</i> <b>216</b>, 427–459 (1982).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rspb.1982.0085" data-track-action="article reference" href="https://doi.org/10.1098%2Frspb.1982.0085" aria-label="Article reference 19" data-doi="10.1098/rspb.1982.0085">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL3s%2FptFWhsQ%3D%3D" aria-label="CAS reference 19">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6129637" aria-label="PubMed reference 19">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%3A%20a%20fresh%20view%20of%20inhibition%20in%20the%20retina&amp;journal=Proc.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frspb.1982.0085&amp;volume=216&amp;pages=427-459&amp;publication_year=1982&amp;author=Srinivasan%2CMV&amp;author=Laughlin%2CSB&amp;author=Dubs%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="20."><p id="ref-CR20">Dayan, P., Hinton, G. E., Neal, R. M. &amp; Zemel, R. S. The Helmholtz machine. <i>Neural Comput.</i> <b>7</b>, 889–904 (1995).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/neco.1995.7.5.889" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.1995.7.5.889" aria-label="Article reference 20" data-doi="10.1162/neco.1995.7.5.889">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK28%2FitVKrtA%3D%3D" aria-label="CAS reference 20">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7584891" aria-label="PubMed reference 20">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20Helmholtz%20machine&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1995.7.5.889&amp;volume=7&amp;pages=889-904&amp;publication_year=1995&amp;author=Dayan%2CP&amp;author=Hinton%2CGE&amp;author=Neal%2CRM&amp;author=Zemel%2CRS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="21."><p id="ref-CR21">Dora, S., Bohte, S. M. &amp; Pennartz, C. M. A. Deep gated Hebbian predictive coding accounts for emergence of complex neural response properties along the visual cortical hierarchy. <i>Front. Comput. Neurosci.</i> <b>15</b>, 666131 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fncom.2021.666131" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncom.2021.666131" aria-label="Article reference 21" data-doi="10.3389/fncom.2021.666131">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34393744" aria-label="PubMed reference 21">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8355371" aria-label="PubMed Central reference 21">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20gated%20Hebbian%20predictive%20coding%20accounts%20for%20emergence%20of%20complex%20neural%20response%20properties%20along%20the%20visual%20cortical%20hierarchy&amp;journal=Front.%20Comput.%20Neurosci.&amp;doi=10.3389%2Ffncom.2021.666131&amp;volume=15&amp;publication_year=2021&amp;author=Dora%2CS&amp;author=Bohte%2CSM&amp;author=Pennartz%2CCMA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="22."><p id="ref-CR22">McDermott, J. H., Wrobleski, D. &amp; Oxenham, A. J. Recovering sound sources from embedded repetition. <i>Proc. Natl Acad. Sci. USA</i> <b>108</b>, 1188–1193 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1004765108" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1004765108" aria-label="Article reference 22" data-doi="10.1073/pnas.1004765108">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXhtlWqtbs%3D" aria-label="CAS reference 22">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21199948" aria-label="PubMed reference 22">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3024660" aria-label="PubMed Central reference 22">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Recovering%20sound%20sources%20from%20embedded%20repetition&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1004765108&amp;volume=108&amp;pages=1188-1193&amp;publication_year=2011&amp;author=McDermott%2CJH&amp;author=Wrobleski%2CD&amp;author=Oxenham%2CAJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="23."><p id="ref-CR23">Mill, R. W., Bohm, T. M., Bendixen, A., Winkler, I. &amp; Denham, S. L. Modelling the emergence and dynamics of perceptual organisation in auditory streaming. <i>PLoS Comput. Biol.</i> <b>9</b>, e1002925 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1002925" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1002925" aria-label="Article reference 23" data-doi="10.1371/journal.pcbi.1002925">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXlvVamurY%3D" aria-label="CAS reference 23">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23516340" aria-label="PubMed reference 23">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3597549" aria-label="PubMed Central reference 23">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Modelling%20the%20emergence%20and%20dynamics%20of%20perceptual%20organisation%20in%20auditory%20streaming&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1002925&amp;volume=9&amp;publication_year=2013&amp;author=Mill%2CRW&amp;author=Bohm%2CTM&amp;author=Bendixen%2CA&amp;author=Winkler%2CI&amp;author=Denham%2CSL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="24."><p id="ref-CR24">Kanai, R., Komura, Y., Shipp, S. &amp; Friston, K. Cerebral hierarchies: predictive processing, precision and the pulvinar. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>370</b>, 20140169 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2014.0169" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2014.0169" aria-label="Article reference 24" data-doi="10.1098/rstb.2014.0169">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25823866" aria-label="PubMed reference 24">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4387510" aria-label="PubMed Central reference 24">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Cerebral%20hierarchies%3A%20predictive%20processing%2C%20precision%20and%20the%20pulvinar&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2014.0169&amp;volume=370&amp;publication_year=2015&amp;author=Kanai%2CR&amp;author=Komura%2CY&amp;author=Shipp%2CS&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="25."><p id="ref-CR25">Schwartenbeck, P., FitzGerald, T. H., Mathys, C., Dolan, R. &amp; Friston, K. The dopaminergic midbrain encodes the expected certainty about desired outcomes. <i>Cereb. Cortex</i> <b>25</b>, 3434–3445 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhu159" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhu159" aria-label="Article reference 25" data-doi="10.1093/cercor/bhu159">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25056572" aria-label="PubMed reference 25">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20dopaminergic%20midbrain%20encodes%20the%20expected%20certainty%20about%20desired%20outcomes&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhu159&amp;volume=25&amp;pages=3434-3445&amp;publication_year=2015&amp;author=Schwartenbeck%2CP&amp;author=FitzGerald%2CTH&amp;author=Mathys%2CC&amp;author=Dolan%2CR&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="26."><p id="ref-CR26">Rikhye, R. V., Wimmer, R. D. &amp; Halassa, M. M. Toward an integrative theory of thalamic function. <i>Annu. Rev. Neurosci.</i> <b>41</b>, 163–183 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-neuro-080317-062144" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-neuro-080317-062144" aria-label="Article reference 26" data-doi="10.1146/annurev-neuro-080317-062144">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXntVGiu7s%3D" aria-label="CAS reference 26">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29618284" aria-label="PubMed reference 26">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Toward%20an%20integrative%20theory%20of%20thalamic%20function&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev-neuro-080317-062144&amp;volume=41&amp;pages=163-183&amp;publication_year=2018&amp;author=Rikhye%2CRV&amp;author=Wimmer%2CRD&amp;author=Halassa%2CMM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="27."><p id="ref-CR27">Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/1.1.1" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F1.1.1" aria-label="Article reference 27" data-doi="10.1093/cercor/1.1.1">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK38zltlGmsg%3D%3D" aria-label="CAS reference 27">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1822724" aria-label="PubMed reference 27">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F1.1.1&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Essen%2CDC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="28."><p id="ref-CR28">Minsky, M. &amp; Papert, S. <i>Perceptrons; An Introduction to Computational Geometry</i> (MIT Press, 1969).</p></li><li data-counter="29."><p id="ref-CR29">Gross, C. G., Rocha-Miranda, C. E. &amp; Bender, D. B. Visual properties of neurons in inferotemporal cortex of the macaque. <i>J. Neurophysiol.</i> <b>35</b>, 96–111 (1972).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.1972.35.1.96" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.1972.35.1.96" aria-label="Article reference 29" data-doi="10.1152/jn.1972.35.1.96">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaE38%2FptV2rsQ%3D%3D" aria-label="CAS reference 29">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4621506" aria-label="PubMed reference 29">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Visual%20properties%20of%20neurons%20in%20inferotemporal%20cortex%20of%20the%20macaque&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.1972.35.1.96&amp;volume=35&amp;pages=96-111&amp;publication_year=1972&amp;author=Gross%2CCG&amp;author=Rocha-Miranda%2CCE&amp;author=Bender%2CDB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="30."><p id="ref-CR30">Tsao, D. Y., Schweers, N., Moeller, S. &amp; Freiwald, W. A. Patches of face-selective cortex in the macaque frontal lobe. <i>Nat. Neurosci.</i> <b>11</b>, 877–879 (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2158" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2158" aria-label="Article reference 30" data-doi="10.1038/nn.2158">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXptVWmu7o%3D" aria-label="CAS reference 30">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18622399" aria-label="PubMed reference 30">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8123225" aria-label="PubMed Central reference 30">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Patches%20of%20face-selective%20cortex%20in%20the%20macaque%20frontal%20lobe&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2158&amp;volume=11&amp;pages=877-879&amp;publication_year=2008&amp;author=Tsao%2CDY&amp;author=Schweers%2CN&amp;author=Moeller%2CS&amp;author=Freiwald%2CWA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="31."><p id="ref-CR31">Hegde, J. &amp; Van Essen, D. C. A comparative study of shape representation in macaque visual areas V2 and V4. <i>Cereb. Cortex</i> <b>17</b>, 1100–1116 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhl020" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhl020" aria-label="Article reference 31" data-doi="10.1093/cercor/bhl020">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16785255" aria-label="PubMed reference 31">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20comparative%20study%20of%20shape%20representation%20in%20macaque%20visual%20areas%20V2%20and%20V4&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhl020&amp;volume=17&amp;pages=1100-1116&amp;publication_year=2007&amp;author=Hegde%2CJ&amp;author=Essen%2CDC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="32."><p id="ref-CR32">Rockland, K. S. &amp; Pandya, D. N. Laminar origins and terminations of cortical connections of the occipital lobe in the rhesus monkey. <i>Brain Res.</i> <b>179</b>, 3–20 (1979).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(79)90485-2" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2879%2990485-2" aria-label="Article reference 32" data-doi="10.1016/0006-8993(79)90485-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL3c%2Fms1Cqsw%3D%3D" aria-label="CAS reference 32">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=116716" aria-label="PubMed reference 32">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Laminar%20origins%20and%20terminations%20of%20cortical%20connections%20of%20the%20occipital%20lobe%20in%20the%20rhesus%20monkey&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2879%2990485-2&amp;volume=179&amp;pages=3-20&amp;publication_year=1979&amp;author=Rockland%2CKS&amp;author=Pandya%2CDN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="33."><p id="ref-CR33">Markov, N. T. et al. Cortical high-density counterstream architectures. <i>Science</i> <b>342</b>, 1238406 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1238406" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1238406" aria-label="Article reference 33" data-doi="10.1126/science.1238406">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24179228" aria-label="PubMed reference 33">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3905047" aria-label="PubMed Central reference 33">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20high-density%20counterstream%20architectures&amp;journal=Science&amp;doi=10.1126%2Fscience.1238406&amp;volume=342&amp;publication_year=2013&amp;author=Markov%2CNT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="34."><p id="ref-CR34">Markov, N. T. &amp; Kennedy, H. The importance of being hierarchical. <i>Curr. Opin. Neurobiol.</i> <b>23</b>, 187–194 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2012.12.008" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2012.12.008" aria-label="Article reference 34" data-doi="10.1016/j.conb.2012.12.008">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXht1yis7g%3D" aria-label="CAS reference 34">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23339864" aria-label="PubMed reference 34">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20importance%20of%20being%20hierarchical&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2012.12.008&amp;volume=23&amp;pages=187-194&amp;publication_year=2013&amp;author=Markov%2CNT&amp;author=Kennedy%2CH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="35."><p id="ref-CR35">D’Souza, R. D. et al. Hierarchical and nonhierarchical features of the mouse visual cortical network. <i>Nat. Commun.</i> <b>13</b>, 503 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-022-28035-y" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-022-28035-y" aria-label="Article reference 35" data-doi="10.1038/s41467-022-28035-y">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35082302" aria-label="PubMed reference 35">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8791996" aria-label="PubMed Central reference 35">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 35" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchical%20and%20nonhierarchical%20features%20of%20the%20mouse%20visual%20cortical%20network&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-022-28035-y&amp;volume=13&amp;publication_year=2022&amp;author=D%E2%80%99Souza%2CRD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="36."><p id="ref-CR36">Siegle, J. H. et al. Survey of spiking in the mouse visual system reveals functional hierarchy. <i>Nature</i> <b>592</b>, 86–92 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-020-03171-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-020-03171-x" aria-label="Article reference 36" data-doi="10.1038/s41586-020-03171-x">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhs12jur4%3D" aria-label="CAS reference 36">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33473216" aria-label="PubMed reference 36">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC10399640" aria-label="PubMed Central reference 36">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Survey%20of%20spiking%20in%20the%20mouse%20visual%20system%20reveals%20functional%20hierarchy&amp;journal=Nature&amp;doi=10.1038%2Fs41586-020-03171-x&amp;volume=592&amp;pages=86-92&amp;publication_year=2021&amp;author=Siegle%2CJH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="37."><p id="ref-CR37">Nakamura, H., Gattass, R., Desimone, R. &amp; Ungerleider, L. G. The modular organization of projections from areas V1 and V2 to areas V4 and TEO in macaques. <i>J. Neurosci.</i> <b>13</b>, 3681–3691 (1993).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.13-09-03681.1993" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.13-09-03681.1993" aria-label="Article reference 37" data-doi="10.1523/JNEUROSCI.13-09-03681.1993">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3sznsFejtw%3D%3D" aria-label="CAS reference 37">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7690064" aria-label="PubMed reference 37">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6576450" aria-label="PubMed Central reference 37">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 37" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20modular%20organization%20of%20projections%20from%20areas%20V1%20and%20V2%20to%20areas%20V4%20and%20TEO%20in%20macaques&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.13-09-03681.1993&amp;volume=13&amp;pages=3681-3691&amp;publication_year=1993&amp;author=Nakamura%2CH&amp;author=Gattass%2CR&amp;author=Desimone%2CR&amp;author=Ungerleider%2CLG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="38."><p id="ref-CR38">Burkhalter, A., D’Souza, R. D., Ji, W. &amp; Meier, A. M. Integration of feedforward and feedback information streams in the modular architecture of mouse visual cortex. <i>Annu. Rev. Neurosci.</i> <b>46</b>, 259–280 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-neuro-083122-021241" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-neuro-083122-021241" aria-label="Article reference 38" data-doi="10.1146/annurev-neuro-083122-021241">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36972612" aria-label="PubMed reference 38">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Integration%20of%20feedforward%20and%20feedback%20information%20streams%20in%20the%20modular%20architecture%20of%20mouse%20visual%20cortex&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev-neuro-083122-021241&amp;volume=46&amp;pages=259-280&amp;publication_year=2023&amp;author=Burkhalter%2CA&amp;author=D%E2%80%99Souza%2CRD&amp;author=Ji%2CW&amp;author=Meier%2CAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="39."><p id="ref-CR39">Coogan, T. A. &amp; Burkhalter, A. Hierarchical organization of areas in rat visual cortex. <i>J. Neurosci.</i> <b>13</b>, 3749–3772 (1993).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.13-09-03749.1993" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.13-09-03749.1993" aria-label="Article reference 39" data-doi="10.1523/JNEUROSCI.13-09-03749.1993">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3sznsFeisw%3D%3D" aria-label="CAS reference 39">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7690066" aria-label="PubMed reference 39">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6576464" aria-label="PubMed Central reference 39">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchical%20organization%20of%20areas%20in%20rat%20visual%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.13-09-03749.1993&amp;volume=13&amp;pages=3749-3772&amp;publication_year=1993&amp;author=Coogan%2CTA&amp;author=Burkhalter%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="40."><p id="ref-CR40">Friston, K. The free-energy principle: a unified brain theory? <i>Nat. Rev. Neurosci.</i> <b>11</b>, 127–138 (2010).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2787" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2787" aria-label="Article reference 40" data-doi="10.1038/nrn2787">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXksFGktw%3D%3D" aria-label="CAS reference 40">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20068583" aria-label="PubMed reference 40">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20free-energy%20principle%3A%20a%20unified%20brain%20theory%3F&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2787&amp;volume=11&amp;pages=127-138&amp;publication_year=2010&amp;author=Friston%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="41."><p id="ref-CR41">Bastos, A. M. et al. Canonical microcircuits for predictive coding. <i>Neuron</i> <b>76</b>, 695–711 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2012.10.038" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2012.10.038" aria-label="Article reference 41" data-doi="10.1016/j.neuron.2012.10.038">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhslejsbzJ" aria-label="CAS reference 41">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23177956" aria-label="PubMed reference 41">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3777738" aria-label="PubMed Central reference 41">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=Canonical%20microcircuits%20for%20predictive%20coding&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2012.10.038&amp;volume=76&amp;pages=695-711&amp;publication_year=2012&amp;author=Bastos%2CAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="42."><p id="ref-CR42">Pennartz, C. M. A., Dora, S., Muckli, L. &amp; Lorteije, J. A. M. Towards a unified view on pathways and functions of neural recurrent processing. <i>Trends Neurosci.</i> <b>42</b>, 589–603 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2019.07.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2019.07.005" aria-label="Article reference 42" data-doi="10.1016/j.tins.2019.07.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXhsVygurbJ" aria-label="CAS reference 42">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31399289" aria-label="PubMed reference 42">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20a%20unified%20view%20on%20pathways%20and%20functions%20of%20neural%20recurrent%20processing&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2019.07.005&amp;volume=42&amp;pages=589-603&amp;publication_year=2019&amp;author=Pennartz%2CCMA&amp;author=Dora%2CS&amp;author=Muckli%2CL&amp;author=Lorteije%2CJAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="43."><p id="ref-CR43">Findling, C. et al. Brain-wide representations of prior information in mouse decision-making. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2023.07.04.547684" data-track="click" data-track-action="external reference" data-track-label="10.1101/2023.07.04.547684">https://doi.org/10.1101/2023.07.04.547684</a> (2023).</p></li><li data-counter="44."><p id="ref-CR44">Keller, G. B. &amp; Mrsic-Flogel, T. D. Predictive processing: a canonical cortical computation. <i>Neuron</i> <b>100</b>, 424–435 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.10.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.10.003" aria-label="Article reference 44" data-doi="10.1016/j.neuron.2018.10.003">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXitVSisrnF" aria-label="CAS reference 44">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30359606" aria-label="PubMed reference 44">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6400266" aria-label="PubMed Central reference 44">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20processing%3A%20a%20canonical%20cortical%20computation&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.10.003&amp;volume=100&amp;pages=424-435&amp;publication_year=2018&amp;author=Keller%2CGB&amp;author=Mrsic-Flogel%2CTD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="45."><p id="ref-CR45">Keller, G. B., Bonhoeffer, T. &amp; Hubener, M. Sensorimotor mismatch signals in primary visual cortex of the behaving mouse. <i>Neuron</i> <b>74</b>, 809–815 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2012.03.040" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2012.03.040" aria-label="Article reference 45" data-doi="10.1016/j.neuron.2012.03.040">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38Xot12hs70%3D" aria-label="CAS reference 45">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22681686" aria-label="PubMed reference 45">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensorimotor%20mismatch%20signals%20in%20primary%20visual%20cortex%20of%20the%20behaving%20mouse&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2012.03.040&amp;volume=74&amp;pages=809-815&amp;publication_year=2012&amp;author=Keller%2CGB&amp;author=Bonhoeffer%2CT&amp;author=Hubener%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="46."><p id="ref-CR46">Jordan, R. &amp; Keller, G. B. Opposing influence of top-down and bottom-up input on excitatory layer 2/3 neurons in mouse primary visual cortex. <i>Neuron</i> <b>108</b>, 1194–1206.e5 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2020.09.024" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2020.09.024" aria-label="Article reference 46" data-doi="10.1016/j.neuron.2020.09.024">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXitFGrsbjI" aria-label="CAS reference 46">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33091338" aria-label="PubMed reference 46">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7772056" aria-label="PubMed Central reference 46">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Opposing%20influence%20of%20top-down%20and%20bottom-up%20input%20on%20excitatory%20layer%202%2F3%20neurons%20in%20mouse%20primary%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2020.09.024&amp;volume=108&amp;pages=1194-1206.e5&amp;publication_year=2020&amp;author=Jordan%2CR&amp;author=Keller%2CGB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="47."><p id="ref-CR47">Padamsey, Z. &amp; Rochefort, N. L. Defying expectations: how neurons compute prediction errors in visual cortex. <i>Neuron</i> <b>108</b>, 1016–1019 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2020.12.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2020.12.005" aria-label="Article reference 47" data-doi="10.1016/j.neuron.2020.12.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXis12ht7jF" aria-label="CAS reference 47">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33357416" aria-label="PubMed reference 47">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Defying%20expectations%3A%20how%20neurons%20compute%20prediction%20errors%20in%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2020.12.005&amp;volume=108&amp;pages=1016-1019&amp;publication_year=2020&amp;author=Padamsey%2CZ&amp;author=Rochefort%2CNL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="48."><p id="ref-CR48">Muzzu, T. &amp; Saleem, A. B. Feature selectivity can explain mismatch signals in mouse visual cortex. <i>Cell Rep.</i> <b>37</b>, 109772 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.celrep.2021.109772" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.celrep.2021.109772" aria-label="Article reference 48" data-doi="10.1016/j.celrep.2021.109772">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXitFOlur7P" aria-label="CAS reference 48">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34610298" aria-label="PubMed reference 48">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8655498" aria-label="PubMed Central reference 48">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Feature%20selectivity%20can%20explain%20mismatch%20signals%20in%20mouse%20visual%20cortex&amp;journal=Cell%20Rep.&amp;doi=10.1016%2Fj.celrep.2021.109772&amp;volume=37&amp;publication_year=2021&amp;author=Muzzu%2CT&amp;author=Saleem%2CAB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="49."><p id="ref-CR49">Walsh, K. S., McGovern, D. P., Clark, A. &amp; O’Connell, R. G. Evaluating the neurophysiological evidence for predictive processing as a model of perception. <i>Ann. N. Y. Acad. Sci.</i> <b>1464</b>, 242–268 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1111/nyas.14321" data-track-action="article reference" href="https://doi.org/10.1111%2Fnyas.14321" aria-label="Article reference 49" data-doi="10.1111/nyas.14321">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32147856" aria-label="PubMed reference 49">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7187369" aria-label="PubMed Central reference 49">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluating%20the%20neurophysiological%20evidence%20for%20predictive%20processing%20as%20a%20model%20of%20perception&amp;journal=Ann.%20N.%20Y.%20Acad.%20Sci.&amp;doi=10.1111%2Fnyas.14321&amp;volume=1464&amp;pages=242-268&amp;publication_year=2020&amp;author=Walsh%2CKS&amp;author=McGovern%2CDP&amp;author=Clark%2CA&amp;author=O%E2%80%99Connell%2CRG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="50."><p id="ref-CR50">Schwiedrzik, C. M. &amp; Freiwald, W. A. High-level prediction signals in a low-level area of the macaque face-processing hierarchy. <i>Neuron</i> <b>96</b>, 89–97.e4 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2017.09.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2017.09.007" aria-label="Article reference 50" data-doi="10.1016/j.neuron.2017.09.007">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXhsFOrsLfK" aria-label="CAS reference 50">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28957679" aria-label="PubMed reference 50">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5757317" aria-label="PubMed Central reference 50">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=High-level%20prediction%20signals%20in%20a%20low-level%20area%20of%20the%20macaque%20face-processing%20hierarchy&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2017.09.007&amp;volume=96&amp;pages=89-97.e4&amp;publication_year=2017&amp;author=Schwiedrzik%2CCM&amp;author=Freiwald%2CWA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="51."><p id="ref-CR51">Issa, E. B., Cadieu, C. F. &amp; DiCarlo, J. J. Neural dynamics at successive stages of the ventral visual stream are consistent with hierarchical error signals. <i>eLife</i> <b>7</b>, e42870 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.42870" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.42870" aria-label="Article reference 51" data-doi="10.7554/eLife.42870">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30484773" aria-label="PubMed reference 51">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6296785" aria-label="PubMed Central reference 51">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20dynamics%20at%20successive%20stages%20of%20the%20ventral%20visual%20stream%20are%20consistent%20with%20hierarchical%20error%20signals&amp;journal=eLife&amp;doi=10.7554%2FeLife.42870&amp;volume=7&amp;publication_year=2018&amp;author=Issa%2CEB&amp;author=Cadieu%2CCF&amp;author=DiCarlo%2CJJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="52."><p id="ref-CR52">Chao, Z. C., Takaura, K., Wang, L., Fujii, N. &amp; Dehaene, S. Large-scale cortical networks for hierarchical prediction and prediction error in the primate brain. <i>Neuron</i> <b>100</b>, 1252–1266.e3 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.10.004" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.10.004" aria-label="Article reference 52" data-doi="10.1016/j.neuron.2018.10.004">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXitVWju7bN" aria-label="CAS reference 52">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30482692" aria-label="PubMed reference 52">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Large-scale%20cortical%20networks%20for%20hierarchical%20prediction%20and%20prediction%20error%20in%20the%20primate%20brain&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.10.004&amp;volume=100&amp;pages=1252-1266.e3&amp;publication_year=2018&amp;author=Chao%2CZC&amp;author=Takaura%2CK&amp;author=Wang%2CL&amp;author=Fujii%2CN&amp;author=Dehaene%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="53."><p id="ref-CR53">Spratling, M. W. A review of predictive coding algorithms. <i>Brain Cogn.</i> <b>112</b>, 92–97 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.bandc.2015.11.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.bandc.2015.11.003" aria-label="Article reference 53" data-doi="10.1016/j.bandc.2015.11.003">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC28nktFOqsw%3D%3D" aria-label="CAS reference 53">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26809759" aria-label="PubMed reference 53">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20review%20of%20predictive%20coding%20algorithms&amp;journal=Brain%20Cogn.&amp;doi=10.1016%2Fj.bandc.2015.11.003&amp;volume=112&amp;pages=92-97&amp;publication_year=2017&amp;author=Spratling%2CMW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="54."><p id="ref-CR54">Spratling, M. W. Fitting predictive coding to the neurophysiological data. <i>Brain Res.</i> <b>1720</b>, 146313 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.brainres.2019.146313" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.brainres.2019.146313" aria-label="Article reference 54" data-doi="10.1016/j.brainres.2019.146313">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXhtlSlsrvP" aria-label="CAS reference 54">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31265817" aria-label="PubMed reference 54">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 54" href="http://scholar.google.com/scholar_lookup?&amp;title=Fitting%20predictive%20coding%20to%20the%20neurophysiological%20data&amp;journal=Brain%20Res.&amp;doi=10.1016%2Fj.brainres.2019.146313&amp;volume=1720&amp;publication_year=2019&amp;author=Spratling%2CMW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="55."><p id="ref-CR55">Bianchini, M. &amp; Scarselli, F. On the complexity of neural network classifiers: a comparison between shallow and deep architectures. <i>IEEE Trans. Neural Netw. Learn. Syst.</i> <b>25</b>, 1553–1565 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/TNNLS.2013.2293637" data-track-action="article reference" href="https://doi.org/10.1109%2FTNNLS.2013.2293637" aria-label="Article reference 55" data-doi="10.1109/TNNLS.2013.2293637">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25050951" aria-label="PubMed reference 55">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 55" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20complexity%20of%20neural%20network%20classifiers%3A%20a%20comparison%20between%20shallow%20and%20deep%20architectures&amp;journal=IEEE%20Trans.%20Neural%20Netw.%20Learn.%20Syst.&amp;doi=10.1109%2FTNNLS.2013.2293637&amp;volume=25&amp;pages=1553-1565&amp;publication_year=2014&amp;author=Bianchini%2CM&amp;author=Scarselli%2CF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="56."><p id="ref-CR56">Cohen, N., Sharir, O. &amp; Shashua, A. On the expressive power of deep learning: a tensor analysis. In <i>29th Annual Conference on Learning Theory</i> (eds. Feldman, V., Rakhlin, A. &amp; Shamir, O.) 698–728 (2016).</p></li><li data-counter="57."><p id="ref-CR57">Hinton, G. E. Training products of experts by minimizing contrastive divergence. <i>Neural Comput.</i> <b>14</b>, 1771–1800 (2002).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/089976602760128018" data-track-action="article reference" href="https://doi.org/10.1162%2F089976602760128018" aria-label="Article reference 57" data-doi="10.1162/089976602760128018">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12180402" aria-label="PubMed reference 57">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=Training%20products%20of%20experts%20by%20minimizing%20contrastive%20divergence&amp;journal=Neural%20Comput.&amp;doi=10.1162%2F089976602760128018&amp;volume=14&amp;pages=1771-1800&amp;publication_year=2002&amp;author=Hinton%2CGE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="58."><p id="ref-CR58">Dabelow, L. &amp; Ueda, M. Three learning stages and accuracy-efficiency tradeoff of restricted Boltzmann machines. <i>Nat. Commun.</i> <b>13</b>, 5474 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-022-33126-x" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-022-33126-x" aria-label="Article reference 58" data-doi="10.1038/s41467-022-33126-x">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XisVWntLnF" aria-label="CAS reference 58">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36115845" aria-label="PubMed reference 58">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9482660" aria-label="PubMed Central reference 58">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Three%20learning%20stages%20and%20accuracy-efficiency%20tradeoff%20of%20restricted%20Boltzmann%20machines&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-022-33126-x&amp;volume=13&amp;publication_year=2022&amp;author=Dabelow%2CL&amp;author=Ueda%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="59."><p id="ref-CR59">Liao, R., Kornblith, S., Ren, M., Fleet, D. J. &amp; Hinton, G. Gaussian–Bernoulli RBMs without tears. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/ARXIV.2210.10318" data-track="click" data-track-action="external reference" data-track-label="10.48550/ARXIV.2210.10318">https://doi.org/10.48550/ARXIV.2210.10318</a> (2022).</p></li><li data-counter="60."><p id="ref-CR60">Hilgetag, C. C. &amp; Goulas, A. ‘Hierarchy’ in the organization of brain networks. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>375</b>, 20190319 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2019.0319" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2019.0319" aria-label="Article reference 60" data-doi="10.1098/rstb.2019.0319">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32089116" aria-label="PubMed reference 60">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7061955" aria-label="PubMed Central reference 60">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=%E2%80%98Hierarchy%E2%80%99%20in%20the%20organization%20of%20brain%20networks&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2019.0319&amp;volume=375&amp;publication_year=2020&amp;author=Hilgetag%2CCC&amp;author=Goulas%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="61."><p id="ref-CR61">Sherman, S. M. &amp; Guillery, R. W. Functional organization of thalamocortical relays. <i>J. Neurophysiol.</i> <b>76</b>, 1367–1395 (1996).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.1996.76.3.1367" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.1996.76.3.1367" aria-label="Article reference 61" data-doi="10.1152/jn.1996.76.3.1367">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK28XmsFCksb4%3D" aria-label="CAS reference 61">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8890259" aria-label="PubMed reference 61">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 61" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20organization%20of%20thalamocortical%20relays&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.1996.76.3.1367&amp;volume=76&amp;pages=1367-1395&amp;publication_year=1996&amp;author=Sherman%2CSM&amp;author=Guillery%2CRW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="62."><p id="ref-CR62">Jones, E. G. The thalamic matrix and thalamocortical synchrony. <i>Trends Neurosci.</i> <b>24</b>, 595–601 (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0166-2236(00)01922-6" data-track-action="article reference" href="https://doi.org/10.1016%2FS0166-2236%2800%2901922-6" aria-label="Article reference 62" data-doi="10.1016/S0166-2236(00)01922-6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3MXntVyltrc%3D" aria-label="CAS reference 62">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11576674" aria-label="PubMed reference 62">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20thalamic%20matrix%20and%20thalamocortical%20synchrony&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2FS0166-2236%2800%2901922-6&amp;volume=24&amp;pages=595-601&amp;publication_year=2001&amp;author=Jones%2CEG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="63."><p id="ref-CR63">Sherman, S. M. &amp; Guillery, R. W. <i>Exploring the Thalamus and Its Role in Cortical Function</i> 2nd edn (MIT Press, 2009).</p></li><li data-counter="64."><p id="ref-CR64">Halassa, M. <i>Thalamus</i> 1st edn (Cambridge Univ. Press, 2023).</p></li><li data-counter="65."><p id="ref-CR65">Kemp, J. M. &amp; Powell, T. P. The cortico-striate projection in the monkey. <i>Brain</i> <b>93</b>, 525–546 (1970).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/brain/93.3.525" data-track-action="article reference" href="https://doi.org/10.1093%2Fbrain%2F93.3.525" aria-label="Article reference 65" data-doi="10.1093/brain/93.3.525">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaE3M%2FgtlWlsA%3D%3D" aria-label="CAS reference 65">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4990231" aria-label="PubMed reference 65">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cortico-striate%20projection%20in%20the%20monkey&amp;journal=Brain&amp;doi=10.1093%2Fbrain%2F93.3.525&amp;volume=93&amp;pages=525-546&amp;publication_year=1970&amp;author=Kemp%2CJM&amp;author=Powell%2CTP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="66."><p id="ref-CR66">Oka, H. Organization of the cortico-caudate projections. A horseradish peroxidase study in the cat. <i>Exp. Brain Res.</i> <b>40</b>, 203–208 (1980).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF00237538" data-track-action="article reference" href="https://doi.org/10.1007%2FBF00237538" aria-label="Article reference 66" data-doi="10.1007/BF00237538">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL3M%2FksVejtw%3D%3D" aria-label="CAS reference 66">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6159222" aria-label="PubMed reference 66">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 66" href="http://scholar.google.com/scholar_lookup?&amp;title=Organization%20of%20the%20cortico-caudate%20projections.%20A%20horseradish%20peroxidase%20study%20in%20the%20cat&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2FBF00237538&amp;volume=40&amp;pages=203-208&amp;publication_year=1980&amp;author=Oka%2CH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="67."><p id="ref-CR67">Ito, S. &amp; Feldheim, D. A. The mouse superior colliculus: an emerging model for studying circuit formation and function. <i>Front. Neural Circuits</i> <b>12</b>, 10 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fncir.2018.00010" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncir.2018.00010" aria-label="Article reference 67" data-doi="10.3389/fncir.2018.00010">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29487505" aria-label="PubMed reference 67">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5816945" aria-label="PubMed Central reference 67">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20mouse%20superior%20colliculus%3A%20an%20emerging%20model%20for%20studying%20circuit%20formation%20and%20function&amp;journal=Front.%20Neural%20Circuits&amp;doi=10.3389%2Ffncir.2018.00010&amp;volume=12&amp;publication_year=2018&amp;author=Ito%2CS&amp;author=Feldheim%2CDA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="68."><p id="ref-CR68">Basso, M. A. &amp; May, P. J. Circuits for action and cognition: a view from the superior colliculus. <i>Annu. Rev. Vis. Sci.</i> <b>3</b>, 197–226 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-vision-102016-061234" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-vision-102016-061234" aria-label="Article reference 68" data-doi="10.1146/annurev-vision-102016-061234">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28617660" aria-label="PubMed reference 68">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752317" aria-label="PubMed Central reference 68">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Circuits%20for%20action%20and%20cognition%3A%20a%20view%20from%20the%20superior%20colliculus&amp;journal=Annu.%20Rev.%20Vis.%20Sci.&amp;doi=10.1146%2Fannurev-vision-102016-061234&amp;volume=3&amp;pages=197-226&amp;publication_year=2017&amp;author=Basso%2CMA&amp;author=May%2CPJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="69."><p id="ref-CR69">May, P. J. The mammalian superior colliculus: laminar structure and connections. <i>Prog. Brain Res.</i> <b>151</b>, 321–378 (2006).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0079-6123(05)51011-2" data-track-action="article reference" href="https://doi.org/10.1016%2FS0079-6123%2805%2951011-2" aria-label="Article reference 69" data-doi="10.1016/S0079-6123(05)51011-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16221594" aria-label="PubMed reference 69">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 69" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20mammalian%20superior%20colliculus%3A%20laminar%20structure%20and%20connections&amp;journal=Prog.%20Brain%20Res.&amp;doi=10.1016%2FS0079-6123%2805%2951011-2&amp;volume=151&amp;pages=321-378&amp;publication_year=2006&amp;author=May%2CPJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="70."><p id="ref-CR70">McBride, E. G. et al. Influence of claustrum on cortex varies by area, layer, and cell type. <i>Neuron</i> <b>111</b>, 275–290.e5 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2022.10.026" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2022.10.026" aria-label="Article reference 70" data-doi="10.1016/j.neuron.2022.10.026">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36368317" aria-label="PubMed reference 70">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 70" href="http://scholar.google.com/scholar_lookup?&amp;title=Influence%20of%20claustrum%20on%20cortex%20varies%20by%20area%2C%20layer%2C%20and%20cell%20type&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2022.10.026&amp;volume=111&amp;pages=275-290.e5&amp;publication_year=2022&amp;author=McBride%2CEG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="71."><p id="ref-CR71">Narikiyo, K. et al. The claustrum coordinates cortical slow-wave activity. <i>Nat. Neurosci.</i> <b>23</b>, 741–753 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-020-0625-7" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-020-0625-7" aria-label="Article reference 71" data-doi="10.1038/s41593-020-0625-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXptVKitbs%3D" aria-label="CAS reference 71">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32393895" aria-label="PubMed reference 71">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 71" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20claustrum%20coordinates%20cortical%20slow-wave%20activity&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-020-0625-7&amp;volume=23&amp;pages=741-753&amp;publication_year=2020&amp;author=Narikiyo%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="72."><p id="ref-CR72">Jackson, J., Karnani, M. M., Zemelman, B. V., Burdakov, D. &amp; Lee, A. K. Inhibitory control of prefrontal cortex by the claustrum. <i>Neuron</i> <b>99</b>, 1029–1039.e4 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.07.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.07.031" aria-label="Article reference 72" data-doi="10.1016/j.neuron.2018.07.031">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhsFeqt7fM" aria-label="CAS reference 72">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30122374" aria-label="PubMed reference 72">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6168643" aria-label="PubMed Central reference 72">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=Inhibitory%20control%20of%20prefrontal%20cortex%20by%20the%20claustrum&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.07.031&amp;volume=99&amp;pages=1029-1039.e4&amp;publication_year=2018&amp;author=Jackson%2CJ&amp;author=Karnani%2CMM&amp;author=Zemelman%2CBV&amp;author=Burdakov%2CD&amp;author=Lee%2CAK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="73."><p id="ref-CR73">Legg, C. R., Mercier, B. &amp; Glickstein, M. Corticopontine projection in the rat: the distribution of labelled cortical cells after large injections of horseradish peroxidase in the pontine nuclei. <i>J. Comp. Neurol.</i> <b>286</b>, 427–441 (1989).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902860403" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902860403" aria-label="Article reference 73" data-doi="10.1002/cne.902860403">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL1MzotV2jtA%3D%3D" aria-label="CAS reference 73">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2778100" aria-label="PubMed reference 73">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 73" href="http://scholar.google.com/scholar_lookup?&amp;title=Corticopontine%20projection%20in%20the%20rat%3A%20the%20distribution%20of%20labelled%20cortical%20cells%20after%20large%20injections%20of%20horseradish%20peroxidase%20in%20the%20pontine%20nuclei&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902860403&amp;volume=286&amp;pages=427-441&amp;publication_year=1989&amp;author=Legg%2CCR&amp;author=Mercier%2CB&amp;author=Glickstein%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="74."><p id="ref-CR74">Habas, C. &amp; Cabanis, E. A. Cortical projections to the human red nucleus: a diffusion tensor tractography study with a 1.5-T MRI machine. <i>Neuroradiology</i> <b>48</b>, 755–762 (2006).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s00234-006-0117-9" data-track-action="article reference" href="https://doi.org/10.1007%2Fs00234-006-0117-9" aria-label="Article reference 74" data-doi="10.1007/s00234-006-0117-9">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16937147" aria-label="PubMed reference 74">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 74" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20projections%20to%20the%20human%20red%20nucleus%3A%20a%20diffusion%20tensor%20tractography%20study%20with%20a%201.5-T%20MRI%20machine&amp;journal=Neuroradiology&amp;doi=10.1007%2Fs00234-006-0117-9&amp;volume=48&amp;pages=755-762&amp;publication_year=2006&amp;author=Habas%2CC&amp;author=Cabanis%2CEA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="75."><p id="ref-CR75">Tervo, D. G. et al. A designer AAV variant permits efficient retrograde access to projection neurons. <i>Neuron</i> <b>92</b>, 372–382 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2016.09.021" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2016.09.021" aria-label="Article reference 75" data-doi="10.1016/j.neuron.2016.09.021">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs1Cls7fN" aria-label="CAS reference 75">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27720486" aria-label="PubMed reference 75">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5872824" aria-label="PubMed Central reference 75">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20designer%20AAV%20variant%20permits%20efficient%20retrograde%20access%20to%20projection%20neurons&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2016.09.021&amp;volume=92&amp;pages=372-382&amp;publication_year=2016&amp;author=Tervo%2CDG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="76."><p id="ref-CR76">Murakami, T., Matsui, T., Uemura, M. &amp; Ohki, K. Modular strategy for development of the hierarchical visual network in mice. <i>Nature</i> <b>608</b>, 578–585 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-022-05045-w" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-022-05045-w" aria-label="Article reference 76" data-doi="10.1038/s41586-022-05045-w">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XitVGgtbjI" aria-label="CAS reference 76">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35922512" aria-label="PubMed reference 76">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 76" href="http://scholar.google.com/scholar_lookup?&amp;title=Modular%20strategy%20for%20development%20of%20the%20hierarchical%20visual%20network%20in%20mice&amp;journal=Nature&amp;doi=10.1038%2Fs41586-022-05045-w&amp;volume=608&amp;pages=578-585&amp;publication_year=2022&amp;author=Murakami%2CT&amp;author=Matsui%2CT&amp;author=Uemura%2CM&amp;author=Ohki%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="77."><p id="ref-CR77">Tang, L. &amp; Higley, M. J. Layer 5 circuits in V1 differentially control visuomotor behavior. <i>Neuron</i> <b>105</b>, 346–354.e5 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2019.10.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2019.10.014" aria-label="Article reference 77" data-doi="10.1016/j.neuron.2019.10.014">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXit1SmsLbE" aria-label="CAS reference 77">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31757603" aria-label="PubMed reference 77">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 77" href="http://scholar.google.com/scholar_lookup?&amp;title=Layer%205%20circuits%20in%20V1%20differentially%20control%20visuomotor%20behavior&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2019.10.014&amp;volume=105&amp;pages=346-354.e5&amp;publication_year=2020&amp;author=Tang%2CL&amp;author=Higley%2CMJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="78."><p id="ref-CR78">Takahashi, N. et al. Active dendritic currents gate descending cortical outputs in perception. <i>Nat. Neurosci.</i> <b>23</b>, 1277–1285 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-020-0677-8" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-020-0677-8" aria-label="Article reference 78" data-doi="10.1038/s41593-020-0677-8">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhsFait7zK" aria-label="CAS reference 78">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32747790" aria-label="PubMed reference 78">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 78" href="http://scholar.google.com/scholar_lookup?&amp;title=Active%20dendritic%20currents%20gate%20descending%20cortical%20outputs%20in%20perception&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-020-0677-8&amp;volume=23&amp;pages=1277-1285&amp;publication_year=2020&amp;author=Takahashi%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="79."><p id="ref-CR79">Fuster, J. M. <i>The Prefrontal Cortex: Anatomy, Physiology, and Neuropsychology of the Frontal Lobe</i> (Raven, 1980).</p></li><li data-counter="80."><p id="ref-CR80">Miller, E. K. &amp; Cohen, J. D. An integrative theory of prefrontal cortex function. <i>Annu. Rev. Neurosci.</i> <b>24</b>, 167–202 (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.neuro.24.1.167" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.neuro.24.1.167" aria-label="Article reference 80" data-doi="10.1146/annurev.neuro.24.1.167">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3MXls1Shsro%3D" aria-label="CAS reference 80">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11283309" aria-label="PubMed reference 80">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 80" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20integrative%20theory%20of%20prefrontal%20cortex%20function&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.neuro.24.1.167&amp;volume=24&amp;pages=167-202&amp;publication_year=2001&amp;author=Miller%2CEK&amp;author=Cohen%2CJD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="81."><p id="ref-CR81">Oswald, M. J., Tantirigama, M. L., Sonntag, I., Hughes, S. M. &amp; Empson, R. M. Diversity of layer 5 projection neurons in the mouse motor cortex. <i>Front. Cell Neurosci.</i> <b>7</b>, 174 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fncel.2013.00174" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncel.2013.00174" aria-label="Article reference 81" data-doi="10.3389/fncel.2013.00174">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24137110" aria-label="PubMed reference 81">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3797544" aria-label="PubMed Central reference 81">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 81" href="http://scholar.google.com/scholar_lookup?&amp;title=Diversity%20of%20layer%205%20projection%20neurons%20in%20the%20mouse%20motor%20cortex&amp;journal=Front.%20Cell%20Neurosci.&amp;doi=10.3389%2Ffncel.2013.00174&amp;volume=7&amp;publication_year=2013&amp;author=Oswald%2CMJ&amp;author=Tantirigama%2CML&amp;author=Sonntag%2CI&amp;author=Hughes%2CSM&amp;author=Empson%2CRM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="82."><p id="ref-CR82">Akintunde, A. &amp; Buxton, D. F. Origins and collateralization of corticospinal, corticopontine, corticorubral and corticostriatal tracts: a multiple retrograde fluorescent tracing study. <i>Brain Res.</i> <b>586</b>, 208–218 (1992).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(92)91629-S" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2892%2991629-S" aria-label="Article reference 82" data-doi="10.1016/0006-8993(92)91629-S">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK38zptlGktA%3D%3D" aria-label="CAS reference 82">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1381650" aria-label="PubMed reference 82">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=Origins%20and%20collateralization%20of%20corticospinal%2C%20corticopontine%2C%20corticorubral%20and%20corticostriatal%20tracts%3A%20a%20multiple%20retrograde%20fluorescent%20tracing%20study&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2892%2991629-S&amp;volume=586&amp;pages=208-218&amp;publication_year=1992&amp;author=Akintunde%2CA&amp;author=Buxton%2CDF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="83."><p id="ref-CR83">Harris, K. D. &amp; Shepherd, G. M. The neocortical circuit: themes and variations. <i>Nat. Neurosci.</i> <b>18</b>, 170–181 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3917" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3917" aria-label="Article reference 83" data-doi="10.1038/nn.3917">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhsFSntL4%3D" aria-label="CAS reference 83">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25622573" aria-label="PubMed reference 83">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4889215" aria-label="PubMed Central reference 83">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 83" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20neocortical%20circuit%3A%20themes%20and%20variations&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3917&amp;volume=18&amp;pages=170-181&amp;publication_year=2015&amp;author=Harris%2CKD&amp;author=Shepherd%2CGM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="84."><p id="ref-CR84">Musall, S. et al. Pyramidal cell types drive functionally distinct cortical activity patterns during decision-making. <i>Nat. Neurosci.</i> <b>26</b>, 495–505 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXhslKnsLw%3D" aria-label="CAS reference 84">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36690900" aria-label="PubMed reference 84">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9991922" aria-label="PubMed Central reference 84">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 84" href="http://scholar.google.com/scholar_lookup?&amp;title=Pyramidal%20cell%20types%20drive%20functionally%20distinct%20cortical%20activity%20patterns%20during%20decision-making&amp;journal=Nat.%20Neurosci.&amp;volume=26&amp;pages=495-505&amp;publication_year=2023&amp;author=Musall%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="85."><p id="ref-CR85">Mohan, H. et al. Cortical glutamatergic projection neuron types contribute to distinct functional subnetworks. <i>Nat. Neurosci.</i> <b>26</b>, 481–494 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXhslKnsLo%3D" aria-label="CAS reference 85">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36690901" aria-label="PubMed reference 85">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC10571488" aria-label="PubMed Central reference 85">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 85" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20glutamatergic%20projection%20neuron%20types%20contribute%20to%20distinct%20functional%20subnetworks&amp;journal=Nat.%20Neurosci.&amp;volume=26&amp;pages=481-494&amp;publication_year=2023&amp;author=Mohan%2CH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="86."><p id="ref-CR86">Kuramoto, E. et al. Ventral medial nucleus neurons send thalamocortical afferents more widely and more preferentially to layer 1 than neurons of the ventral anterior–ventral lateral nuclear complex in the rat. <i>Cereb. Cortex</i> <b>25</b>, 221–235 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bht216" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbht216" aria-label="Article reference 86" data-doi="10.1093/cercor/bht216">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23968832" aria-label="PubMed reference 86">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 86" href="http://scholar.google.com/scholar_lookup?&amp;title=Ventral%20medial%20nucleus%20neurons%20send%20thalamocortical%20afferents%20more%20widely%20and%20more%20preferentially%20to%20layer%201%20than%20neurons%20of%20the%20ventral%20anterior%E2%80%93ventral%20lateral%20nuclear%20complex%20in%20the%20rat&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbht216&amp;volume=25&amp;pages=221-235&amp;publication_year=2015&amp;author=Kuramoto%2CE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="87."><p id="ref-CR87">Cruikshank, S. J. et al. Thalamic control of layer 1 circuits in prefrontal cortex. <i>J. Neurosci.</i> <b>32</b>, 17813–17823 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3231-12.2012" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3231-12.2012" aria-label="Article reference 87" data-doi="10.1523/JNEUROSCI.3231-12.2012">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhvVCmu7%2FN" aria-label="CAS reference 87">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23223300" aria-label="PubMed reference 87">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3535493" aria-label="PubMed Central reference 87">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 87" href="http://scholar.google.com/scholar_lookup?&amp;title=Thalamic%20control%20of%20layer%201%20circuits%20in%20prefrontal%20cortex&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3231-12.2012&amp;volume=32&amp;pages=17813-17823&amp;publication_year=2012&amp;author=Cruikshank%2CSJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="88."><p id="ref-CR88">Schroeder, A. et al. Inhibitory top-down projections from zona incerta mediate neocortical memory. <i>Neuron</i> <b>111</b>, 727–738.e8 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2022.12.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2022.12.010" aria-label="Article reference 88" data-doi="10.1016/j.neuron.2022.12.010">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXlvFCjsg%3D%3D" aria-label="CAS reference 88">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36610397" aria-label="PubMed reference 88">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 88" href="http://scholar.google.com/scholar_lookup?&amp;title=Inhibitory%20top-down%20projections%20from%20zona%20incerta%20mediate%20neocortical%20memory&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2022.12.010&amp;volume=111&amp;pages=727-738.e8&amp;publication_year=2023&amp;author=Schroeder%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="89."><p id="ref-CR89">Ahmadlou, M. et al. A cell type-specific cortico-subcortical brain circuit for investigatory and novelty-seeking behavior. <i>Science</i> <b>372</b>, eabe9681 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.abe9681" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.abe9681" aria-label="Article reference 89" data-doi="10.1126/science.abe9681">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhtFSlur3K" aria-label="CAS reference 89">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33986154" aria-label="PubMed reference 89">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 89" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20cell%20type-specific%20cortico-subcortical%20brain%20circuit%20for%20investigatory%20and%20novelty-seeking%20behavior&amp;journal=Science&amp;doi=10.1126%2Fscience.abe9681&amp;volume=372&amp;publication_year=2021&amp;author=Ahmadlou%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="90."><p id="ref-CR90">Brenner, J. M., Beltramo, R., Gerfen, C. R., Ruediger, S. &amp; Scanziani, M. A genetically defined tecto-thalamic pathway drives a system of superior-colliculus-dependent visual cortices. <i>Neuron</i> <b>111</b>, 2247–2257.e7 (2023).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2023.04.022" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2023.04.022" aria-label="Article reference 90" data-doi="10.1016/j.neuron.2023.04.022">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3sXpvFWhtb4%3D" aria-label="CAS reference 90">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37172584" aria-label="PubMed reference 90">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 90" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20genetically%20defined%20tecto-thalamic%20pathway%20drives%20a%20system%20of%20superior-colliculus-dependent%20visual%20cortices&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2023.04.022&amp;volume=111&amp;pages=2247-2257.e7&amp;publication_year=2023&amp;author=Brenner%2CJM&amp;author=Beltramo%2CR&amp;author=Gerfen%2CCR&amp;author=Ruediger%2CS&amp;author=Scanziani%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="91."><p id="ref-CR91">Guo, Z. V. et al. Maintenance of persistent activity in a frontal thalamocortical loop. <i>Nature</i> <b>545</b>, 181–186 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature22324" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature22324" aria-label="Article reference 91" data-doi="10.1038/nature22324">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXntVKms7c%3D" aria-label="CAS reference 91">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28467817" aria-label="PubMed reference 91">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6431254" aria-label="PubMed Central reference 91">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 91" href="http://scholar.google.com/scholar_lookup?&amp;title=Maintenance%20of%20persistent%20activity%20in%20a%20frontal%20thalamocortical%20loop&amp;journal=Nature&amp;doi=10.1038%2Fnature22324&amp;volume=545&amp;pages=181-186&amp;publication_year=2017&amp;author=Guo%2CZV">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="92."><p id="ref-CR92">Hsiao, K. et al. A thalamic orphan receptor drives variability in short-term memory. <i>Cell</i> <b>183</b>, 522–536.e19 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2020.09.011" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2020.09.011" aria-label="Article reference 92" data-doi="10.1016/j.cell.2020.09.011">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhvFKjurvO" aria-label="CAS reference 92">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32997977" aria-label="PubMed reference 92">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7572771" aria-label="PubMed Central reference 92">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 92" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20thalamic%20orphan%20receptor%20drives%20variability%20in%20short-term%20memory&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2020.09.011&amp;volume=183&amp;pages=522-536.e19&amp;publication_year=2020&amp;author=Hsiao%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="93."><p id="ref-CR93">Redinbaugh, M. J. et al. Thalamus modulates consciousness via layer-specific control of cortex. <i>Neuron</i> <b>106</b>, 66–75.e12 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2020.01.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2020.01.005" aria-label="Article reference 93" data-doi="10.1016/j.neuron.2020.01.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXjtFWitLg%3D" aria-label="CAS reference 93">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32053769" aria-label="PubMed reference 93">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7243351" aria-label="PubMed Central reference 93">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 93" href="http://scholar.google.com/scholar_lookup?&amp;title=Thalamus%20modulates%20consciousness%20via%20layer-specific%20control%20of%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2020.01.005&amp;volume=106&amp;pages=66-75.e12&amp;publication_year=2020&amp;author=Redinbaugh%2CMJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="94."><p id="ref-CR94">Aru, J., Suzuki, M. &amp; Larkum, M. E. Cellular mechanisms of conscious processing. <i>Trends Cogn. Sci.</i> <b>24</b>, 814–825 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2020.07.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2020.07.006" aria-label="Article reference 94" data-doi="10.1016/j.tics.2020.07.006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32855048" aria-label="PubMed reference 94">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 94" href="http://scholar.google.com/scholar_lookup?&amp;title=Cellular%20mechanisms%20of%20conscious%20processing&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2020.07.006&amp;volume=24&amp;pages=814-825&amp;publication_year=2020&amp;author=Aru%2CJ&amp;author=Suzuki%2CM&amp;author=Larkum%2CME">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="95."><p id="ref-CR95">Aru, J., Suzuki, M., Rutiku, R., Larkum, M. E. &amp; Bachmann, T. Coupling the state and contents of consciousness. <i>Front. Syst. Neurosci.</i> <b>13</b>, 43 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnsys.2019.00043" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnsys.2019.00043" aria-label="Article reference 95" data-doi="10.3389/fnsys.2019.00043">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31543762" aria-label="PubMed reference 95">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6729974" aria-label="PubMed Central reference 95">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 95" href="http://scholar.google.com/scholar_lookup?&amp;title=Coupling%20the%20state%20and%20contents%20of%20consciousness&amp;journal=Front.%20Syst.%20Neurosci.&amp;doi=10.3389%2Ffnsys.2019.00043&amp;volume=13&amp;publication_year=2019&amp;author=Aru%2CJ&amp;author=Suzuki%2CM&amp;author=Rutiku%2CR&amp;author=Larkum%2CME&amp;author=Bachmann%2CT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="96."><p id="ref-CR96">Suzuki, M. &amp; Larkum, M. E. General anesthesia decouples cortical pyramidal neurons. <i>Cell</i> <b>180</b>, 666–676.e13 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2020.01.024" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2020.01.024" aria-label="Article reference 96" data-doi="10.1016/j.cell.2020.01.024">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXnvFeltbc%3D" aria-label="CAS reference 96">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32084339" aria-label="PubMed reference 96">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 96" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20anesthesia%20decouples%20cortical%20pyramidal%20neurons&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2020.01.024&amp;volume=180&amp;pages=666-676.e13&amp;publication_year=2020&amp;author=Suzuki%2CM&amp;author=Larkum%2CME">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="97."><p id="ref-CR97">Schiff, N. D. et al. Behavioural improvements with thalamic stimulation after severe traumatic brain injury. <i>Nature</i> <b>448</b>, 600–603 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature06041" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature06041" aria-label="Article reference 97" data-doi="10.1038/nature06041">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXosVSrt7g%3D" aria-label="CAS reference 97">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17671503" aria-label="PubMed reference 97">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 97" href="http://scholar.google.com/scholar_lookup?&amp;title=Behavioural%20improvements%20with%20thalamic%20stimulation%20after%20severe%20traumatic%20brain%20injury&amp;journal=Nature&amp;doi=10.1038%2Fnature06041&amp;volume=448&amp;pages=600-603&amp;publication_year=2007&amp;author=Schiff%2CND">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="98."><p id="ref-CR98">Bastos, A. M. et al. Neural effects of propofol-induced unconsciousness and its reversal using thalamic stimulation. <i>eLife</i> <b>10</b>, e60824 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.60824" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.60824" aria-label="Article reference 98" data-doi="10.7554/eLife.60824">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXitlOgsr3J" aria-label="CAS reference 98">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33904411" aria-label="PubMed reference 98">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8079153" aria-label="PubMed Central reference 98">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 98" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20effects%20of%20propofol-induced%20unconsciousness%20and%20its%20reversal%20using%20thalamic%20stimulation&amp;journal=eLife&amp;doi=10.7554%2FeLife.60824&amp;volume=10&amp;publication_year=2021&amp;author=Bastos%2CAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="99."><p id="ref-CR99">Crick, F. C. &amp; Koch, C. What is the function of the claustrum. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>360</b>, 1271–1279 (2005).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2005.1661" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2005.1661" aria-label="Article reference 99" data-doi="10.1098/rstb.2005.1661">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16147522" aria-label="PubMed reference 99">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1569501" aria-label="PubMed Central reference 99">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 99" href="http://scholar.google.com/scholar_lookup?&amp;title=What%20is%20the%20function%20of%20the%20claustrum&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2005.1661&amp;volume=360&amp;pages=1271-1279&amp;publication_year=2005&amp;author=Crick%2CFC&amp;author=Koch%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="100."><p id="ref-CR100">Chevee, M., Finkel, E. A., Kim, S. J., O’Connor, D. H. &amp; Brown, S. P. Neural activity in the mouse claustrum in a cross-modal sensory selection task. <i>Neuron</i> <b>110</b>, 486–501.e7 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2021.11.013" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2021.11.013" aria-label="Article reference 100" data-doi="10.1016/j.neuron.2021.11.013">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXis1Klsb3M" aria-label="CAS reference 100">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34863367" aria-label="PubMed reference 100">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 100" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20activity%20in%20the%20mouse%20claustrum%20in%20a%20cross-modal%20sensory%20selection%20task&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2021.11.013&amp;volume=110&amp;pages=486-501.e7&amp;publication_year=2022&amp;author=Chevee%2CM&amp;author=Finkel%2CEA&amp;author=Kim%2CSJ&amp;author=O%E2%80%99Connor%2CDH&amp;author=Brown%2CSP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="101."><p id="ref-CR101">Huang, W., Qin, J., Zhang, C., Qin, H. &amp; Xie, P. Footshock-induced activation of the claustrum–entorhinal cortical pathway in freely moving mice. <i>Physiol. Res.</i> <b>71</b>, 695–701 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.33549/physiolres.934899" data-track-action="article reference" href="https://doi.org/10.33549%2Fphysiolres.934899" aria-label="Article reference 101" data-doi="10.33549/physiolres.934899">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XjtFWhur7L" aria-label="CAS reference 101">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36047724" aria-label="PubMed reference 101">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9841810" aria-label="PubMed Central reference 101">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 101" href="http://scholar.google.com/scholar_lookup?&amp;title=Footshock-induced%20activation%20of%20the%20claustrum%E2%80%93entorhinal%20cortical%20pathway%20in%20freely%20moving%20mice&amp;journal=Physiol.%20Res.&amp;doi=10.33549%2Fphysiolres.934899&amp;volume=71&amp;pages=695-701&amp;publication_year=2022&amp;author=Huang%2CW&amp;author=Qin%2CJ&amp;author=Zhang%2CC&amp;author=Qin%2CH&amp;author=Xie%2CP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="102."><p id="ref-CR102">Smythies, J. On the function of object cells in the claustrum—key components in information processing in the visual system? <i>Front. Cell Neurosci.</i> <b>9</b>, 443 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fncel.2015.00443" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncel.2015.00443" aria-label="Article reference 102" data-doi="10.3389/fncel.2015.00443">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26594152" aria-label="PubMed reference 102">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4633478" aria-label="PubMed Central reference 102">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 102" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20function%20of%20object%20cells%20in%20the%20claustrum%E2%80%94key%20components%20in%20information%20processing%20in%20the%20visual%20system%3F&amp;journal=Front.%20Cell%20Neurosci.&amp;doi=10.3389%2Ffncel.2015.00443&amp;volume=9&amp;publication_year=2015&amp;author=Smythies%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="103."><p id="ref-CR103">Tsumoto, T. &amp; Suda, K. Effects of stimulation of the dorsocaudal claustrum on activities of striate cortex neurons in the cat. <i>Brain Res.</i> <b>240</b>, 345–349 (1982).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(82)90233-5" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2882%2990233-5" aria-label="Article reference 103" data-doi="10.1016/0006-8993(82)90233-5">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL383lvVejtg%3D%3D" aria-label="CAS reference 103">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7104694" aria-label="PubMed reference 103">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 103" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20of%20stimulation%20of%20the%20dorsocaudal%20claustrum%20on%20activities%20of%20striate%20cortex%20neurons%20in%20the%20cat&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2882%2990233-5&amp;volume=240&amp;pages=345-349&amp;publication_year=1982&amp;author=Tsumoto%2CT&amp;author=Suda%2CK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="104."><p id="ref-CR104">Remedios, R., Logothetis, N. K. &amp; Kayser, C. A role of the claustrum in auditory scene analysis by reflecting sensory change. <i>Front. Syst. Neurosci.</i> <b>8</b>, 44 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnsys.2014.00044" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnsys.2014.00044" aria-label="Article reference 104" data-doi="10.3389/fnsys.2014.00044">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24772069" aria-label="PubMed reference 104">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3983479" aria-label="PubMed Central reference 104">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 104" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20role%20of%20the%20claustrum%20in%20auditory%20scene%20analysis%20by%20reflecting%20sensory%20change&amp;journal=Front.%20Syst.%20Neurosci.&amp;doi=10.3389%2Ffnsys.2014.00044&amp;volume=8&amp;publication_year=2014&amp;author=Remedios%2CR&amp;author=Logothetis%2CNK&amp;author=Kayser%2CC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="105."><p id="ref-CR105">Qadir, H. et al. The mouse claustrum synaptically connects cortical network motifs. <i>Cell Rep.</i> <b>41</b>, 111860 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.celrep.2022.111860" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.celrep.2022.111860" aria-label="Article reference 105" data-doi="10.1016/j.celrep.2022.111860">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XjtFGitL3I" aria-label="CAS reference 105">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36543121" aria-label="PubMed reference 105">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9838879" aria-label="PubMed Central reference 105">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 105" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20mouse%20claustrum%20synaptically%20connects%20cortical%20network%20motifs&amp;journal=Cell%20Rep.&amp;doi=10.1016%2Fj.celrep.2022.111860&amp;volume=41&amp;publication_year=2022&amp;author=Qadir%2CH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="106."><p id="ref-CR106">Taylor, N. L. et al. Structural connections between the noradrenergic and cholinergic system shape the dynamics of functional brain networks. <i>Neuroimage</i> <b>260</b>, 119455 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2022.119455" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2022.119455" aria-label="Article reference 106" data-doi="10.1016/j.neuroimage.2022.119455">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38Xit1yjtL3I" aria-label="CAS reference 106">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35809888" aria-label="PubMed reference 106">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 106" href="http://scholar.google.com/scholar_lookup?&amp;title=Structural%20connections%20between%20the%20noradrenergic%20and%20cholinergic%20system%20shape%20the%20dynamics%20of%20functional%20brain%20networks&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2022.119455&amp;volume=260&amp;publication_year=2022&amp;author=Taylor%2CNL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="107."><p id="ref-CR107">Deutch, A. Y. &amp; Roth, R. H. in <i>Fundamental Neuroscience</i> (eds M. J. Zigmond et al.) 193–234 (Academic, 1999).</p></li><li data-counter="108."><p id="ref-CR108">Chevalier, G. &amp; Deniau, J. M. Disinhibition as a basic process in the expression of striatal functions. <i>Trends Neurosci.</i> <b>13</b>, 277–280 (1990).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0166-2236(90)90109-N" data-track-action="article reference" href="https://doi.org/10.1016%2F0166-2236%2890%2990109-N" aria-label="Article reference 108" data-doi="10.1016/0166-2236(90)90109-N">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3czitVSlsQ%3D%3D" aria-label="CAS reference 108">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1695403" aria-label="PubMed reference 108">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 108" href="http://scholar.google.com/scholar_lookup?&amp;title=Disinhibition%20as%20a%20basic%20process%20in%20the%20expression%20of%20striatal%20functions&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2F0166-2236%2890%2990109-N&amp;volume=13&amp;pages=277-280&amp;publication_year=1990&amp;author=Chevalier%2CG&amp;author=Deniau%2CJM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="109."><p id="ref-CR109">Voorn, P., Vanderschuren, L. J., Groenewegen, H. J., Robbins, T. W. &amp; Pennartz, C. M. Putting a spin on the dorsal–ventral divide of the striatum. <i>Trends Neurosci.</i> <b>27</b>, 468–474 (2004).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2004.06.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2004.06.006" aria-label="Article reference 109" data-doi="10.1016/j.tins.2004.06.006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2cXmtVahtrs%3D" aria-label="CAS reference 109">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15271494" aria-label="PubMed reference 109">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 109" href="http://scholar.google.com/scholar_lookup?&amp;title=Putting%20a%20spin%20on%20the%20dorsal%E2%80%93ventral%20divide%20of%20the%20striatum&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2004.06.006&amp;volume=27&amp;pages=468-474&amp;publication_year=2004&amp;author=Voorn%2CP&amp;author=Vanderschuren%2CLJ&amp;author=Groenewegen%2CHJ&amp;author=Robbins%2CTW&amp;author=Pennartz%2CCM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="110."><p id="ref-CR110">Budinger, E., Heil, P., Hess, A. &amp; Scheich, H. Multisensory processing via early cortical stages: connections of the primary auditory cortical field with other sensory systems. <i>Neuroscience</i> <b>143</b>, 1065–1083 (2006).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroscience.2006.08.035" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroscience.2006.08.035" aria-label="Article reference 110" data-doi="10.1016/j.neuroscience.2006.08.035">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD28Xht1KgurbN" aria-label="CAS reference 110">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17027173" aria-label="PubMed reference 110">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 110" href="http://scholar.google.com/scholar_lookup?&amp;title=Multisensory%20processing%20via%20early%20cortical%20stages%3A%20connections%20of%20the%20primary%20auditory%20cortical%20field%20with%20other%20sensory%20systems&amp;journal=Neuroscience&amp;doi=10.1016%2Fj.neuroscience.2006.08.035&amp;volume=143&amp;pages=1065-1083&amp;publication_year=2006&amp;author=Budinger%2CE&amp;author=Heil%2CP&amp;author=Hess%2CA&amp;author=Scheich%2CH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="111."><p id="ref-CR111">Benavidez, N. L. et al. Organization of the inputs and outputs of the mouse superior colliculus. <i>Nat. Commun.</i> <b>12</b>, 4004 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-021-24241-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-021-24241-2" aria-label="Article reference 111" data-doi="10.1038/s41467-021-24241-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhsFOgtb%2FF" aria-label="CAS reference 111">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34183678" aria-label="PubMed reference 111">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8239028" aria-label="PubMed Central reference 111">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 111" href="http://scholar.google.com/scholar_lookup?&amp;title=Organization%20of%20the%20inputs%20and%20outputs%20of%20the%20mouse%20superior%20colliculus&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-021-24241-2&amp;volume=12&amp;publication_year=2021&amp;author=Benavidez%2CNL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="112."><p id="ref-CR112">Beltramo, R. &amp; Scanziani, M. A collicular visual cortex: neocortical space for an ancient midbrain visual structure. <i>Science</i> <b>363</b>, 64–69 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.aau7052" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.aau7052" aria-label="Article reference 112" data-doi="10.1126/science.aau7052">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXkvVKr" aria-label="CAS reference 112">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30606842" aria-label="PubMed reference 112">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 112" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20collicular%20visual%20cortex%3A%20neocortical%20space%20for%20an%20ancient%20midbrain%20visual%20structure&amp;journal=Science&amp;doi=10.1126%2Fscience.aau7052&amp;volume=363&amp;pages=64-69&amp;publication_year=2019&amp;author=Beltramo%2CR&amp;author=Scanziani%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="113."><p id="ref-CR113">Constantinople, C. M. &amp; Bruno, R. M. Effects and mechanisms of wakefulness on local cortical networks. <i>Neuron</i> <b>69</b>, 1061–1068 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2011.02.040" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2011.02.040" aria-label="Article reference 113" data-doi="10.1016/j.neuron.2011.02.040">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXjvFejs7Y%3D" aria-label="CAS reference 113">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21435553" aria-label="PubMed reference 113">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3069934" aria-label="PubMed Central reference 113">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 113" href="http://scholar.google.com/scholar_lookup?&amp;title=Effects%20and%20mechanisms%20of%20wakefulness%20on%20local%20cortical%20networks&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2011.02.040&amp;volume=69&amp;pages=1061-1068&amp;publication_year=2011&amp;author=Constantinople%2CCM&amp;author=Bruno%2CRM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="114."><p id="ref-CR114">Aru, J., Siclari, F., Phillips, W. A. &amp; Storm, J. F. Apical drive—a cellular mechanism of dreaming? <i>Neurosci. Biobehav. Rev.</i> <b>119</b>, 440–455 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neubiorev.2020.09.018" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neubiorev.2020.09.018" aria-label="Article reference 114" data-doi="10.1016/j.neubiorev.2020.09.018">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33002561" aria-label="PubMed reference 114">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 114" href="http://scholar.google.com/scholar_lookup?&amp;title=Apical%20drive%E2%80%94a%20cellular%20mechanism%20of%20dreaming%3F&amp;journal=Neurosci.%20Biobehav.%20Rev.&amp;doi=10.1016%2Fj.neubiorev.2020.09.018&amp;volume=119&amp;pages=440-455&amp;publication_year=2020&amp;author=Aru%2CJ&amp;author=Siclari%2CF&amp;author=Phillips%2CWA&amp;author=Storm%2CJF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="115."><p id="ref-CR115">Wainstein, G., Muller, E. J., Taylor, N., Munn, B. &amp; Shine, J. M. The role of the locus coeruleus in shaping adaptive cortical melodies. <i>Trends Cogn. Sci.</i> <b>26</b>, 527–538 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2022.03.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2022.03.006" aria-label="Article reference 115" data-doi="10.1016/j.tics.2022.03.006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35469726" aria-label="PubMed reference 115">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 115" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20the%20locus%20coeruleus%20in%20shaping%20adaptive%20cortical%20melodies&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2022.03.006&amp;volume=26&amp;pages=527-538&amp;publication_year=2022&amp;author=Wainstein%2CG&amp;author=Muller%2CEJ&amp;author=Taylor%2CN&amp;author=Munn%2CB&amp;author=Shine%2CJM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="116."><p id="ref-CR116">Polack, P. O., Friedman, J. &amp; Golshani, P. Cellular mechanisms of brain state-dependent gain modulation in visual cortex. <i>Nat. Neurosci.</i> <b>16</b>, 1331–1339 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3464" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3464" aria-label="Article reference 116" data-doi="10.1038/nn.3464">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtFCit7nK" aria-label="CAS reference 116">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23872595" aria-label="PubMed reference 116">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3786578" aria-label="PubMed Central reference 116">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 116" href="http://scholar.google.com/scholar_lookup?&amp;title=Cellular%20mechanisms%20of%20brain%20state-dependent%20gain%20modulation%20in%20visual%20cortex&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3464&amp;volume=16&amp;pages=1331-1339&amp;publication_year=2013&amp;author=Polack%2CPO&amp;author=Friedman%2CJ&amp;author=Golshani%2CP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="117."><p id="ref-CR117">Harris, K. D. &amp; Thiele, A. Cortical state and attention. <i>Nat. Rev. Neurosci.</i> <b>12</b>, 509–523 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn3084" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn3084" aria-label="Article reference 117" data-doi="10.1038/nrn3084">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXpvFait70%3D" aria-label="CAS reference 117">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21829219" aria-label="PubMed reference 117">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3324821" aria-label="PubMed Central reference 117">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 117" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20state%20and%20attention&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn3084&amp;volume=12&amp;pages=509-523&amp;publication_year=2011&amp;author=Harris%2CKD&amp;author=Thiele%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="118."><p id="ref-CR118">Parikh, V., Kozak, R., Martinez, V. &amp; Sarter, M. Prefrontal acetylcholine release controls cue detection on multiple timescales. <i>Neuron</i> <b>56</b>, 141–154 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2007.08.025" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2007.08.025" aria-label="Article reference 118" data-doi="10.1016/j.neuron.2007.08.025">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXht1WksrzJ" aria-label="CAS reference 118">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17920021" aria-label="PubMed reference 118">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2084212" aria-label="PubMed Central reference 118">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 118" href="http://scholar.google.com/scholar_lookup?&amp;title=Prefrontal%20acetylcholine%20release%20controls%20cue%20detection%20on%20multiple%20timescales&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2007.08.025&amp;volume=56&amp;pages=141-154&amp;publication_year=2007&amp;author=Parikh%2CV&amp;author=Kozak%2CR&amp;author=Martinez%2CV&amp;author=Sarter%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="119."><p id="ref-CR119">Puig, M. V. &amp; Gulledge, A. T. Serotonin and prefrontal cortex function: neurons, networks, and circuits. <i>Mol. Neurobiol.</i> <b>44</b>, 449–464 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s12035-011-8214-0" data-track-action="article reference" href="https://doi.org/10.1007%2Fs12035-011-8214-0" aria-label="Article reference 119" data-doi="10.1007/s12035-011-8214-0">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXhsFOjt7bE" aria-label="CAS reference 119">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22076606" aria-label="PubMed reference 119">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3282112" aria-label="PubMed Central reference 119">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 119" href="http://scholar.google.com/scholar_lookup?&amp;title=Serotonin%20and%20prefrontal%20cortex%20function%3A%20neurons%2C%20networks%2C%20and%20circuits&amp;journal=Mol.%20Neurobiol.&amp;doi=10.1007%2Fs12035-011-8214-0&amp;volume=44&amp;pages=449-464&amp;publication_year=2011&amp;author=Puig%2CMV&amp;author=Gulledge%2CAT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="120."><p id="ref-CR120">Buhot, M. C., Martin, S. &amp; Segu, L. Role of serotonin in memory impairment. <i>Ann. Med.</i> <b>32</b>, 210–221 (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3109/07853890008998828" data-track-action="article reference" href="https://doi.org/10.3109%2F07853890008998828" aria-label="Article reference 120" data-doi="10.3109/07853890008998828">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3cXms1Ohu7w%3D" aria-label="CAS reference 120">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10821328" aria-label="PubMed reference 120">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 120" href="http://scholar.google.com/scholar_lookup?&amp;title=Role%20of%20serotonin%20in%20memory%20impairment&amp;journal=Ann.%20Med.&amp;doi=10.3109%2F07853890008998828&amp;volume=32&amp;pages=210-221&amp;publication_year=2000&amp;author=Buhot%2CMC&amp;author=Martin%2CS&amp;author=Segu%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="121."><p id="ref-CR121">Petroni, F., Panzeri, S., Hilgetag, C. C., Kotter, R. &amp; Young, M. P. Simultaneity of responses in a hierarchical visual network. <i>Neuroreport</i> <b>12</b>, 2753–2759 (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1097/00001756-200108280-00032" data-track-action="article reference" href="https://doi.org/10.1097%2F00001756-200108280-00032" aria-label="Article reference 121" data-doi="10.1097/00001756-200108280-00032">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD3MvpsFSksg%3D%3D" aria-label="CAS reference 121">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11522961" aria-label="PubMed reference 121">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 121" href="http://scholar.google.com/scholar_lookup?&amp;title=Simultaneity%20of%20responses%20in%20a%20hierarchical%20visual%20network&amp;journal=Neuroreport&amp;doi=10.1097%2F00001756-200108280-00032&amp;volume=12&amp;pages=2753-2759&amp;publication_year=2001&amp;author=Petroni%2CF&amp;author=Panzeri%2CS&amp;author=Hilgetag%2CCC&amp;author=Kotter%2CR&amp;author=Young%2CMP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="122."><p id="ref-CR122">Zeki, S. The rough seas of cortical cartography. <i>Trends Neurosci.</i> <b>41</b>, 242–244 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2018.03.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2018.03.005" aria-label="Article reference 122" data-doi="10.1016/j.tins.2018.03.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXotlGnu7o%3D" aria-label="CAS reference 122">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29703374" aria-label="PubMed reference 122">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 122" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20rough%20seas%20of%20cortical%20cartography&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2018.03.005&amp;volume=41&amp;pages=242-244&amp;publication_year=2018&amp;author=Zeki%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="123."><p id="ref-CR123">Silvanto, J. Why is “blindsight” blind? A new perspective on primary visual cortex, recurrent activity and visual awareness. <i>Conscious. Cogn.</i> <b>32</b>, 15–32 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.concog.2014.08.001" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.concog.2014.08.001" aria-label="Article reference 123" data-doi="10.1016/j.concog.2014.08.001">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25263935" aria-label="PubMed reference 123">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 123" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20is%20%E2%80%9Cblindsight%E2%80%9D%20blind%3F%20A%20new%20perspective%20on%20primary%20visual%20cortex%2C%20recurrent%20activity%20and%20visual%20awareness&amp;journal=Conscious.%20Cogn.&amp;doi=10.1016%2Fj.concog.2014.08.001&amp;volume=32&amp;pages=15-32&amp;publication_year=2015&amp;author=Silvanto%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="124."><p id="ref-CR124">Schmolesky, M. T. et al. Signal timing across the macaque visual system. <i>J. Neurophysiol.</i> <b>79</b>, 3272–3278 (1998).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.1998.79.6.3272" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.1998.79.6.3272" aria-label="Article reference 124" data-doi="10.1152/jn.1998.79.6.3272">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK1czgtFGhtQ%3D%3D" aria-label="CAS reference 124">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9636126" aria-label="PubMed reference 124">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 124" href="http://scholar.google.com/scholar_lookup?&amp;title=Signal%20timing%20across%20the%20macaque%20visual%20system&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.1998.79.6.3272&amp;volume=79&amp;pages=3272-3278&amp;publication_year=1998&amp;author=Schmolesky%2CMT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="125."><p id="ref-CR125">Bullier, J. &amp; Nowak, L. G. Parallel versus serial processing: new vistas on the distributed organization of the visual system. <i>Curr. Opin. Neurobiol.</i> <b>5</b>, 497–503 (1995).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0959-4388(95)80011-5" data-track-action="article reference" href="https://doi.org/10.1016%2F0959-4388%2895%2980011-5" aria-label="Article reference 125" data-doi="10.1016/0959-4388(95)80011-5">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK2MXnslOhtLo%3D" aria-label="CAS reference 125">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7488852" aria-label="PubMed reference 125">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 125" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20versus%20serial%20processing%3A%20new%20vistas%20on%20the%20distributed%20organization%20of%20the%20visual%20system&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2F0959-4388%2895%2980011-5&amp;volume=5&amp;pages=497-503&amp;publication_year=1995&amp;author=Bullier%2CJ&amp;author=Nowak%2CLG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="126."><p id="ref-CR126">Douglas, R. J. &amp; Martin, K. A. Mapping the matrix: the ways of neocortex. <i>Neuron</i> <b>56</b>, 226–238 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2007.10.017" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2007.10.017" aria-label="Article reference 126" data-doi="10.1016/j.neuron.2007.10.017">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXht12jsrrP" aria-label="CAS reference 126">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17964242" aria-label="PubMed reference 126">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 126" href="http://scholar.google.com/scholar_lookup?&amp;title=Mapping%20the%20matrix%3A%20the%20ways%20of%20neocortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2007.10.017&amp;volume=56&amp;pages=226-238&amp;publication_year=2007&amp;author=Douglas%2CRJ&amp;author=Martin%2CKA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="127."><p id="ref-CR127">Rockland, K. S. &amp; Ichinohe, N. Some thoughts on cortical minicolumns. <i>Exp. Brain Res.</i> <b>158</b>, 265–277 (2004).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/s00221-004-2024-9" data-track-action="article reference" href="https://doi.org/10.1007%2Fs00221-004-2024-9" aria-label="Article reference 127" data-doi="10.1007/s00221-004-2024-9">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15365664" aria-label="PubMed reference 127">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 127" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20thoughts%20on%20cortical%20minicolumns&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2Fs00221-004-2024-9&amp;volume=158&amp;pages=265-277&amp;publication_year=2004&amp;author=Rockland%2CKS&amp;author=Ichinohe%2CN">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="128."><p id="ref-CR128">Molnár, Z. &amp; Rockland, K. S. in <i>Neural Circuit and Cognitive Development</i> Ch. 5 (eds J. Rubenstein, P. Rakic, B. Chen &amp; K. Y. Kwan) 103–126 (Academic, 2020).</p></li><li data-counter="129."><p id="ref-CR129">Trojanowski, J. Q. &amp; Jacobson, S. Medial pulvinar afferents to frontal eye fields in rhesus monkey demonstrated by horseradish peroxidase. <i>Brain Res.</i> <b>80</b>, 395–411 (1974).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(74)91025-7" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2874%2991025-7" aria-label="Article reference 129" data-doi="10.1016/0006-8993(74)91025-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaE2M%2FhvFSlsQ%3D%3D" aria-label="CAS reference 129">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=4138113" aria-label="PubMed reference 129">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 129" href="http://scholar.google.com/scholar_lookup?&amp;title=Medial%20pulvinar%20afferents%20to%20frontal%20eye%20fields%20in%20rhesus%20monkey%20demonstrated%20by%20horseradish%20peroxidase&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2874%2991025-7&amp;volume=80&amp;pages=395-411&amp;publication_year=1974&amp;author=Trojanowski%2CJQ&amp;author=Jacobson%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="130."><p id="ref-CR130">Baizer, J. S., Desimone, R. &amp; Ungerleider, L. G. Comparison of subcortical connections of inferior temporal and posterior parietal cortex in monkeys. <i>Vis. Neurosci.</i> <b>10</b>, 59–72 (1993).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S0952523800003229" data-track-action="article reference" href="https://doi.org/10.1017%2FS0952523800003229" aria-label="Article reference 130" data-doi="10.1017/S0952523800003229">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3s7ksVagtg%3D%3D" aria-label="CAS reference 130">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8424928" aria-label="PubMed reference 130">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 130" href="http://scholar.google.com/scholar_lookup?&amp;title=Comparison%20of%20subcortical%20connections%20of%20inferior%20temporal%20and%20posterior%20parietal%20cortex%20in%20monkeys&amp;journal=Vis.%20Neurosci.&amp;doi=10.1017%2FS0952523800003229&amp;volume=10&amp;pages=59-72&amp;publication_year=1993&amp;author=Baizer%2CJS&amp;author=Desimone%2CR&amp;author=Ungerleider%2CLG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="131."><p id="ref-CR131">Stanton, G. B., Goldberg, M. E. &amp; Bruce, C. J. Frontal eye field efferents in the macaque monkey: I. Subcortical pathways and topography of striatal and thalamic terminal fields. <i>J. Comp. Neurol.</i> <b>271</b>, 473–492 (1988).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902710402" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902710402" aria-label="Article reference 131" data-doi="10.1002/cne.902710402">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL1c3lslKjtQ%3D%3D" aria-label="CAS reference 131">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2454970" aria-label="PubMed reference 131">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 131" href="http://scholar.google.com/scholar_lookup?&amp;title=Frontal%20eye%20field%20efferents%20in%20the%20macaque%20monkey%3A%20I.%20Subcortical%20pathways%20and%20topography%20of%20striatal%20and%20thalamic%20terminal%20fields&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902710402&amp;volume=271&amp;pages=473-492&amp;publication_year=1988&amp;author=Stanton%2CGB&amp;author=Goldberg%2CME&amp;author=Bruce%2CCJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="132."><p id="ref-CR132">Lynch, J. C., Hoover, J. E. &amp; Strick, P. L. Input to the primate frontal eye field from the substantia nigra, superior colliculus, and dentate nucleus demonstrated by transneuronal transport. <i>Exp. Brain Res.</i> <b>100</b>, 181–186 (1994).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1007/BF00227293" data-track-action="article reference" href="https://doi.org/10.1007%2FBF00227293" aria-label="Article reference 132" data-doi="10.1007/BF00227293">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2M7htlSguw%3D%3D" aria-label="CAS reference 132">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7813649" aria-label="PubMed reference 132">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 132" href="http://scholar.google.com/scholar_lookup?&amp;title=Input%20to%20the%20primate%20frontal%20eye%20field%20from%20the%20substantia%20nigra%2C%20superior%20colliculus%2C%20and%20dentate%20nucleus%20demonstrated%20by%20transneuronal%20transport&amp;journal=Exp.%20Brain%20Res.&amp;doi=10.1007%2FBF00227293&amp;volume=100&amp;pages=181-186&amp;publication_year=1994&amp;author=Lynch%2CJC&amp;author=Hoover%2CJE&amp;author=Strick%2CPL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="133."><p id="ref-CR133">Berman, R. A. &amp; Wurtz, R. H. Exploring the pulvinar path to visual cortex. <i>Prog. Brain Res.</i> <b>171</b>, 467–473 (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0079-6123(08)00668-7" data-track-action="article reference" href="https://doi.org/10.1016%2FS0079-6123%2808%2900668-7" aria-label="Article reference 133" data-doi="10.1016/S0079-6123(08)00668-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18718342" aria-label="PubMed reference 133">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2802535" aria-label="PubMed Central reference 133">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 133" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20the%20pulvinar%20path%20to%20visual%20cortex&amp;journal=Prog.%20Brain%20Res.&amp;doi=10.1016%2FS0079-6123%2808%2900668-7&amp;volume=171&amp;pages=467-473&amp;publication_year=2008&amp;author=Berman%2CRA&amp;author=Wurtz%2CRH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="134."><p id="ref-CR134">Huerta, M. F., Krubitzer, L. A. &amp; Kaas, J. H. Frontal eye field as defined by intracortical microstimulation in squirrel monkeys, owl monkeys, and macaque monkeys: I. Subcortical connections. <i>J. Comp. Neurol.</i> <b>253</b>, 415–439 (1986).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902530402" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902530402" aria-label="Article reference 134" data-doi="10.1002/cne.902530402">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL2s%2FosVWgug%3D%3D" aria-label="CAS reference 134">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3793998" aria-label="PubMed reference 134">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 134" href="http://scholar.google.com/scholar_lookup?&amp;title=Frontal%20eye%20field%20as%20defined%20by%20intracortical%20microstimulation%20in%20squirrel%20monkeys%2C%20owl%20monkeys%2C%20and%20macaque%20monkeys%3A%20I.%20Subcortical%20connections&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902530402&amp;volume=253&amp;pages=415-439&amp;publication_year=1986&amp;author=Huerta%2CMF&amp;author=Krubitzer%2CLA&amp;author=Kaas%2CJH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="135."><p id="ref-CR135">Leichnetz, G. R., Smith, D. J. &amp; Spencer, R. F. Cortical projections to the paramedian tegmental and basilar pons in the monkey. <i>J. Comp. Neurol.</i> <b>228</b>, 388–408 (1984).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902280307" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902280307" aria-label="Article reference 135" data-doi="10.1002/cne.902280307">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL2M%2FgslKisw%3D%3D" aria-label="CAS reference 135">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6480918" aria-label="PubMed reference 135">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 135" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20projections%20to%20the%20paramedian%20tegmental%20and%20basilar%20pons%20in%20the%20monkey&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902280307&amp;volume=228&amp;pages=388-408&amp;publication_year=1984&amp;author=Leichnetz%2CGR&amp;author=Smith%2CDJ&amp;author=Spencer%2CRF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="136."><p id="ref-CR136">Andersen, R. A., Asanuma, C., Essick, G. &amp; Siegel, R. M. Corticocortical connections of anatomically and physiologically defined subdivisions within the inferior parietal lobule. <i>J. Comp. Neurol.</i> <b>296</b>, 65–113 (1990).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902960106" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902960106" aria-label="Article reference 136" data-doi="10.1002/cne.902960106">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK3c3ptlajtw%3D%3D" aria-label="CAS reference 136">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2358530" aria-label="PubMed reference 136">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 136" href="http://scholar.google.com/scholar_lookup?&amp;title=Corticocortical%20connections%20of%20anatomically%20and%20physiologically%20defined%20subdivisions%20within%20the%20inferior%20parietal%20lobule&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902960106&amp;volume=296&amp;pages=65-113&amp;publication_year=1990&amp;author=Andersen%2CRA&amp;author=Asanuma%2CC&amp;author=Essick%2CG&amp;author=Siegel%2CRM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="137."><p id="ref-CR137">Lynch, J. C., Graybiel, A. M. &amp; Lobeck, L. J. The differential projection of two cytoarchitectonic subregions of the inferior parietal lobule of macaque upon the deep layers of the superior colliculus. <i>J. Comp. Neurol.</i> <b>235</b>, 241–254 (1985).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.902350207" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.902350207" aria-label="Article reference 137" data-doi="10.1002/cne.902350207">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL2M3gvVGiug%3D%3D" aria-label="CAS reference 137">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3998211" aria-label="PubMed reference 137">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 137" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20differential%20projection%20of%20two%20cytoarchitectonic%20subregions%20of%20the%20inferior%20parietal%20lobule%20of%20macaque%20upon%20the%20deep%20layers%20of%20the%20superior%20colliculus&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.902350207&amp;volume=235&amp;pages=241-254&amp;publication_year=1985&amp;author=Lynch%2CJC&amp;author=Graybiel%2CAM&amp;author=Lobeck%2CLJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="138."><p id="ref-CR138">Schall, J. D., Morel, A., King, D. J. &amp; Bullier, J. Topography of visual cortex connections with frontal eye field in macaque: convergence and segregation of processing streams. <i>J. Neurosci.</i> <b>15</b>, 4464–4487 (1995).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.15-06-04464.1995" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.15-06-04464.1995" aria-label="Article reference 138" data-doi="10.1523/JNEUROSCI.15-06-04464.1995">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK2MXmt1aqtbs%3D" aria-label="CAS reference 138">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7540675" aria-label="PubMed reference 138">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6577698" aria-label="PubMed Central reference 138">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 138" href="http://scholar.google.com/scholar_lookup?&amp;title=Topography%20of%20visual%20cortex%20connections%20with%20frontal%20eye%20field%20in%20macaque%3A%20convergence%20and%20segregation%20of%20processing%20streams&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.15-06-04464.1995&amp;volume=15&amp;pages=4464-4487&amp;publication_year=1995&amp;author=Schall%2CJD&amp;author=Morel%2CA&amp;author=King%2CDJ&amp;author=Bullier%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="139."><p id="ref-CR139">Vernet, M., Quentin, R., Chanes, L., Mitsumasu, A. &amp; Valero-Cabre, A. Frontal eye field, where art thou? Anatomy, function, and non-invasive manipulation of frontal regions involved in eye movements and associated cognitive operations. <i>Front. Integr. Neurosci.</i> <b>8</b>, 66 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25202241" aria-label="PubMed reference 139">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4141567" aria-label="PubMed Central reference 139">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 139" href="http://scholar.google.com/scholar_lookup?&amp;title=Frontal%20eye%20field%2C%20where%20art%20thou%3F%20Anatomy%2C%20function%2C%20and%20non-invasive%20manipulation%20of%20frontal%20regions%20involved%20in%20eye%20movements%20and%20associated%20cognitive%20operations&amp;journal=Front.%20Integr.%20Neurosci.&amp;volume=8&amp;publication_year=2014&amp;author=Vernet%2CM&amp;author=Quentin%2CR&amp;author=Chanes%2CL&amp;author=Mitsumasu%2CA&amp;author=Valero-Cabre%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="140."><p id="ref-CR140">Liu, Y., Yttri, E. A. &amp; Snyder, L. H. Intention and attention: different functional roles for LIPd and LIPv. <i>Nat. Neurosci.</i> <b>13</b>, 495–500 (2010).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2496" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2496" aria-label="Article reference 140" data-doi="10.1038/nn.2496">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXisFeksr4%3D" aria-label="CAS reference 140">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20190746" aria-label="PubMed reference 140">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2846989" aria-label="PubMed Central reference 140">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 140" href="http://scholar.google.com/scholar_lookup?&amp;title=Intention%20and%20attention%3A%20different%20functional%20roles%20for%20LIPd%20and%20LIPv&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2496&amp;volume=13&amp;pages=495-500&amp;publication_year=2010&amp;author=Liu%2CY&amp;author=Yttri%2CEA&amp;author=Snyder%2CLH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="141."><p id="ref-CR141">Coe, B. C. &amp; Munoz, D. P. Mechanisms of saccade suppression revealed in the anti-saccade task. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>372</b>, 20160192 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2016.0192" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2016.0192" aria-label="Article reference 141" data-doi="10.1098/rstb.2016.0192">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28242726" aria-label="PubMed reference 141">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5332851" aria-label="PubMed Central reference 141">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 141" href="http://scholar.google.com/scholar_lookup?&amp;title=Mechanisms%20of%20saccade%20suppression%20revealed%20in%20the%20anti-saccade%20task&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2016.0192&amp;volume=372&amp;publication_year=2017&amp;author=Coe%2CBC&amp;author=Munoz%2CDP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="142."><p id="ref-CR142">Milardi, D. et al. Red nucleus connectivity as revealed by constrained spherical deconvolution tractography. <i>Neurosci. Lett.</i> <b>626</b>, 68–73 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neulet.2016.05.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neulet.2016.05.009" aria-label="Article reference 142" data-doi="10.1016/j.neulet.2016.05.009">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xpslyqs7w%3D" aria-label="CAS reference 142">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27181514" aria-label="PubMed reference 142">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 142" href="http://scholar.google.com/scholar_lookup?&amp;title=Red%20nucleus%20connectivity%20as%20revealed%20by%20constrained%20spherical%20deconvolution%20tractography&amp;journal=Neurosci.%20Lett.&amp;doi=10.1016%2Fj.neulet.2016.05.009&amp;volume=626&amp;pages=68-73&amp;publication_year=2016&amp;author=Milardi%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="143."><p id="ref-CR143">Na, J., Kakei, S. &amp; Shinoda, Y. Cerebellar input to corticothalamic neurons in layers V and VI in the motor cortex. <i>Neurosci. Res.</i> <b>28</b>, 77–91 (1997).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0168-0102(97)00031-X" data-track-action="article reference" href="https://doi.org/10.1016%2FS0168-0102%2897%2900031-X" aria-label="Article reference 143" data-doi="10.1016/S0168-0102(97)00031-X">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2szitlCgtw%3D%3D" aria-label="CAS reference 143">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=9179883" aria-label="PubMed reference 143">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 143" href="http://scholar.google.com/scholar_lookup?&amp;title=Cerebellar%20input%20to%20corticothalamic%20neurons%20in%20layers%20V%20and%20VI%20in%20the%20motor%20cortex&amp;journal=Neurosci.%20Res.&amp;doi=10.1016%2FS0168-0102%2897%2900031-X&amp;volume=28&amp;pages=77-91&amp;publication_year=1997&amp;author=Na%2CJ&amp;author=Kakei%2CS&amp;author=Shinoda%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="144."><p id="ref-CR144">Martinez-Gonzalez, C., Bolam, J. P. &amp; Mena-Segovia, J. Topographical organization of the pedunculopontine nucleus. <i>Front. Neuroanat.</i> <b>5</b>, 22 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnana.2011.00022" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnana.2011.00022" aria-label="Article reference 144" data-doi="10.3389/fnana.2011.00022">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21503154" aria-label="PubMed reference 144">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074429" aria-label="PubMed Central reference 144">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 144" href="http://scholar.google.com/scholar_lookup?&amp;title=Topographical%20organization%20of%20the%20pedunculopontine%20nucleus&amp;journal=Front.%20Neuroanat.&amp;doi=10.3389%2Ffnana.2011.00022&amp;volume=5&amp;publication_year=2011&amp;author=Martinez-Gonzalez%2CC&amp;author=Bolam%2CJP&amp;author=Mena-Segovia%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="145."><p id="ref-CR145">Sherman, S. M. &amp; Guillery, R. W. Distinct functions for direct and transthalamic corticocortical connections. <i>J. Neurophysiol.</i> <b>106</b>, 1068–1077 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1152/jn.00429.2011" data-track-action="article reference" href="https://doi.org/10.1152%2Fjn.00429.2011" aria-label="Article reference 145" data-doi="10.1152/jn.00429.2011">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21676936" aria-label="PubMed reference 145">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 145" href="http://scholar.google.com/scholar_lookup?&amp;title=Distinct%20functions%20for%20direct%20and%20transthalamic%20corticocortical%20connections&amp;journal=J.%20Neurophysiol.&amp;doi=10.1152%2Fjn.00429.2011&amp;volume=106&amp;pages=1068-1077&amp;publication_year=2011&amp;author=Sherman%2CSM&amp;author=Guillery%2CRW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="146."><p id="ref-CR146">de Kock, C. P., Bruno, R. M., Spors, H. &amp; Sakmann, B. Layer- and cell-type-specific suprathreshold stimulus representation in rat primary somatosensory cortex. <i>J. Physiol.</i> <b>581</b>, 139–154 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1113/jphysiol.2006.124321" data-track-action="article reference" href="https://doi.org/10.1113%2Fjphysiol.2006.124321" aria-label="Article reference 146" data-doi="10.1113/jphysiol.2006.124321">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17317752" aria-label="PubMed reference 146">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2075227" aria-label="PubMed Central reference 146">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 146" href="http://scholar.google.com/scholar_lookup?&amp;title=Layer-%20and%20cell-type-specific%20suprathreshold%20stimulus%20representation%20in%20rat%20primary%20somatosensory%20cortex&amp;journal=J.%20Physiol.&amp;doi=10.1113%2Fjphysiol.2006.124321&amp;volume=581&amp;pages=139-154&amp;publication_year=2007&amp;author=Kock%2CCP&amp;author=Bruno%2CRM&amp;author=Spors%2CH&amp;author=Sakmann%2CB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="147."><p id="ref-CR147">Masamizu, Y. et al. Two distinct layer-specific dynamics of cortical ensembles during learning of a motor task. <i>Nat. Neurosci.</i> <b>17</b>, 987–994 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.3739" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.3739" aria-label="Article reference 147" data-doi="10.1038/nn.3739">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXovFCgt7Y%3D" aria-label="CAS reference 147">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24880217" aria-label="PubMed reference 147">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 147" href="http://scholar.google.com/scholar_lookup?&amp;title=Two%20distinct%20layer-specific%20dynamics%20of%20cortical%20ensembles%20during%20learning%20of%20a%20motor%20task&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.3739&amp;volume=17&amp;pages=987-994&amp;publication_year=2014&amp;author=Masamizu%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="148."><p id="ref-CR148">Guo, K., Yamawaki, N., Svoboda, K. &amp; Shepherd, G. M. G. Anterolateral motor cortex connects with a medial subdivision of ventromedial thalamus through cell type-specific circuits, forming an excitatory thalamo-cortico-thalamic loop via layer 1 apical tuft dendrites of layer 5b pyramidal tract type neurons. <i>J. Neurosci.</i> <b>38</b>, 8787–8797 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1333-18.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1333-18.2018" aria-label="Article reference 148" data-doi="10.1523/JNEUROSCI.1333-18.2018">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXit1ynur3K" aria-label="CAS reference 148">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30143573" aria-label="PubMed reference 148">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6181310" aria-label="PubMed Central reference 148">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 148" href="http://scholar.google.com/scholar_lookup?&amp;title=Anterolateral%20motor%20cortex%20connects%20with%20a%20medial%20subdivision%20of%20ventromedial%20thalamus%20through%20cell%20type-specific%20circuits%2C%20forming%20an%20excitatory%20thalamo-cortico-thalamic%20loop%20via%20layer%201%20apical%20tuft%20dendrites%20of%20layer%205b%20pyramidal%20tract%20type%20neurons&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1333-18.2018&amp;volume=38&amp;pages=8787-8797&amp;publication_year=2018&amp;author=Guo%2CK&amp;author=Yamawaki%2CN&amp;author=Svoboda%2CK&amp;author=Shepherd%2CGMG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="149."><p id="ref-CR149">Bharioke, A. et al. General anesthesia globally synchronizes activity selectively in layer 5 cortical pyramidal neurons. <i>Neuron</i> <b>110</b>, 2024–2040.e10 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2022.03.032" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2022.03.032" aria-label="Article reference 149" data-doi="10.1016/j.neuron.2022.03.032">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XhtVKntLjN" aria-label="CAS reference 149">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35452606" aria-label="PubMed reference 149">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9235854" aria-label="PubMed Central reference 149">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 149" href="http://scholar.google.com/scholar_lookup?&amp;title=General%20anesthesia%20globally%20synchronizes%20activity%20selectively%20in%20layer%205%20cortical%20pyramidal%20neurons&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2022.03.032&amp;volume=110&amp;pages=2024-2040.e10&amp;publication_year=2022&amp;author=Bharioke%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="150."><p id="ref-CR150">Larkum, M. A cellular mechanism for cortical associations: an organizing principle for the cerebral cortex. <i>Trends Neurosci.</i> <b>36</b>, 141–151 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2012.11.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2012.11.006" aria-label="Article reference 150" data-doi="10.1016/j.tins.2012.11.006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhvV2ku7%2FL" aria-label="CAS reference 150">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23273272" aria-label="PubMed reference 150">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 150" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20cellular%20mechanism%20for%20cortical%20associations%3A%20an%20organizing%20principle%20for%20the%20cerebral%20cortex&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2012.11.006&amp;volume=36&amp;pages=141-151&amp;publication_year=2013&amp;author=Larkum%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="151."><p id="ref-CR151">Brea, J., Gaal, A. T., Urbanczik, R. &amp; Senn, W. Prospective coding by spiking neurons. <i>PLoS Comput. Biol.</i> <b>12</b>, e1005003 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1005003" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1005003" aria-label="Article reference 151" data-doi="10.1371/journal.pcbi.1005003">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27341100" aria-label="PubMed reference 151">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4920376" aria-label="PubMed Central reference 151">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 151" href="http://scholar.google.com/scholar_lookup?&amp;title=Prospective%20coding%20by%20spiking%20neurons&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1005003&amp;volume=12&amp;publication_year=2016&amp;author=Brea%2CJ&amp;author=Gaal%2CAT&amp;author=Urbanczik%2CR&amp;author=Senn%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="152."><p id="ref-CR152">Roelfsema, P. R. &amp; Holtmaat, A. Control of synaptic plasticity in deep cortical networks. <i>Nat. Rev. Neurosci.</i> <b>19</b>, 166–180 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn.2018.6" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn.2018.6" aria-label="Article reference 152" data-doi="10.1038/nrn.2018.6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXivVSiuro%3D" aria-label="CAS reference 152">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29449713" aria-label="PubMed reference 152">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 152" href="http://scholar.google.com/scholar_lookup?&amp;title=Control%20of%20synaptic%20plasticity%20in%20deep%20cortical%20networks&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn.2018.6&amp;volume=19&amp;pages=166-180&amp;publication_year=2018&amp;author=Roelfsema%2CPR&amp;author=Holtmaat%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="153."><p id="ref-CR153">Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. <i>Nat. Rev. Neurosci.</i> <b>21</b>, 335–346 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41583-020-0277-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-020-0277-3" aria-label="Article reference 153" data-doi="10.1038/s41583-020-0277-3">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXnsVCksrk%3D" aria-label="CAS reference 153">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32303713" aria-label="PubMed reference 153">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 153" href="http://scholar.google.com/scholar_lookup?&amp;title=Backpropagation%20and%20the%20brain&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-020-0277-3&amp;volume=21&amp;pages=335-346&amp;publication_year=2020&amp;author=Lillicrap%2CTP&amp;author=Santoro%2CA&amp;author=Marris%2CL&amp;author=Akerman%2CCJ&amp;author=Hinton%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="154."><p id="ref-CR154">Whittington, J. C. R. &amp; Bogacz, R. Theories of error back-propagation in the brain. <i>Trends Cogn. Sci.</i> <b>23</b>, 235–250 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2018.12.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2018.12.005" aria-label="Article reference 154" data-doi="10.1016/j.tics.2018.12.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30704969" aria-label="PubMed reference 154">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6382460" aria-label="PubMed Central reference 154">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 154" href="http://scholar.google.com/scholar_lookup?&amp;title=Theories%20of%20error%20back-propagation%20in%20the%20brain&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2018.12.005&amp;volume=23&amp;pages=235-250&amp;publication_year=2019&amp;author=Whittington%2CJCR&amp;author=Bogacz%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="155."><p id="ref-CR155">Xiong, Q., Znamenskiy, P. &amp; Zador, A. M. Selective corticostriatal plasticity during acquisition of an auditory discrimination task. <i>Nature</i> <b>521</b>, 348–351 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature14225" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature14225" aria-label="Article reference 155" data-doi="10.1038/nature14225">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXktVCns7c%3D" aria-label="CAS reference 155">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25731173" aria-label="PubMed reference 155">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4454418" aria-label="PubMed Central reference 155">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 155" href="http://scholar.google.com/scholar_lookup?&amp;title=Selective%20corticostriatal%20plasticity%20during%20acquisition%20of%20an%20auditory%20discrimination%20task&amp;journal=Nature&amp;doi=10.1038%2Fnature14225&amp;volume=521&amp;pages=348-351&amp;publication_year=2015&amp;author=Xiong%2CQ&amp;author=Znamenskiy%2CP&amp;author=Zador%2CAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="156."><p id="ref-CR156">Cox, J. &amp; Witten, I. B. Striatal circuits for reward learning and decision-making. <i>Nat. Rev. Neurosci.</i> <b>20</b>, 482–494 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41583-019-0189-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-019-0189-2" aria-label="Article reference 156" data-doi="10.1038/s41583-019-0189-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXhsVWjsb3L" aria-label="CAS reference 156">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31171839" aria-label="PubMed reference 156">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7231228" aria-label="PubMed Central reference 156">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 156" href="http://scholar.google.com/scholar_lookup?&amp;title=Striatal%20circuits%20for%20reward%20learning%20and%20decision-making&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-019-0189-2&amp;volume=20&amp;pages=482-494&amp;publication_year=2019&amp;author=Cox%2CJ&amp;author=Witten%2CIB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="157."><p id="ref-CR157">Park, J. M. et al. Deep and superficial layers of the primary somatosensory cortex are critical for whisker-based texture discrimination in mice. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2020.08.12.245381" data-track="click" data-track-action="external reference" data-track-label="10.1101/2020.08.12.245381">https://doi.org/10.1101/2020.08.12.245381</a> (2022).</p></li><li data-counter="158."><p id="ref-CR158">Hong, Y. K., Lacefield, C. O., Rodgers, C. C. &amp; Bruno, R. M. Sensation, movement and learning in the absence of barrel cortex. <i>Nature</i> <b>561</b>, 542–546 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-018-0527-y" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-018-0527-y" aria-label="Article reference 158" data-doi="10.1038/s41586-018-0527-y">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhslCjt77N" aria-label="CAS reference 158">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30224746" aria-label="PubMed reference 158">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6173956" aria-label="PubMed Central reference 158">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 158" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensation%2C%20movement%20and%20learning%20in%20the%20absence%20of%20barrel%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fs41586-018-0527-y&amp;volume=561&amp;pages=542-546&amp;publication_year=2018&amp;author=Hong%2CYK&amp;author=Lacefield%2CCO&amp;author=Rodgers%2CCC&amp;author=Bruno%2CRM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="159."><p id="ref-CR159">Von Neumann, J. <i>The Computer and the Brain</i> (Yale Univ. Press, 1958).</p></li><li data-counter="160."><p id="ref-CR160">Mo, C. &amp; Sherman, S. M. A sensorimotor pathway via higher-order thalamus. <i>J. Neurosci.</i> <b>39</b>, 692–704 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1467-18.2018" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1467-18.2018" aria-label="Article reference 160" data-doi="10.1523/JNEUROSCI.1467-18.2018">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXltVagsLc%3D" aria-label="CAS reference 160">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30504278" aria-label="PubMed reference 160">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6343647" aria-label="PubMed Central reference 160">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 160" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20sensorimotor%20pathway%20via%20higher-order%20thalamus&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1467-18.2018&amp;volume=39&amp;pages=692-704&amp;publication_year=2019&amp;author=Mo%2CC&amp;author=Sherman%2CSM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="161."><p id="ref-CR161">Lake, B. M., Ullman, T. D., Tenenbaum, J. B. &amp; Gershman, S. J. Building machines that learn and think like people. <i>Behav. Brain Sci.</i> <b>40</b>, e253 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1017/S0140525X16001837" data-track-action="article reference" href="https://doi.org/10.1017%2FS0140525X16001837" aria-label="Article reference 161" data-doi="10.1017/S0140525X16001837">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27881212" aria-label="PubMed reference 161">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 161" href="http://scholar.google.com/scholar_lookup?&amp;title=Building%20machines%20that%20learn%20and%20think%20like%20people&amp;journal=Behav.%20Brain%20Sci.&amp;doi=10.1017%2FS0140525X16001837&amp;volume=40&amp;publication_year=2017&amp;author=Lake%2CBM&amp;author=Ullman%2CTD&amp;author=Tenenbaum%2CJB&amp;author=Gershman%2CSJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="162."><p id="ref-CR162">Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>375</b>, 20190307 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2019.0307" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2019.0307" aria-label="Article reference 162" data-doi="10.1098/rstb.2019.0307">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31840578" aria-label="PubMed reference 162">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 162" href="http://scholar.google.com/scholar_lookup?&amp;title=Linguistic%20generalization%20and%20compositionality%20in%20modern%20artificial%20neural%20networks&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2019.0307&amp;volume=375&amp;publication_year=2020&amp;author=Baroni%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="163."><p id="ref-CR163">Ruediger, S. &amp; Scanziani, M. Learning speed and detection sensitivity controlled by distinct cortico-fugal neurons in visual cortex. <i>eLife</i> <b>9</b>, e59247 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.59247" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.59247" aria-label="Article reference 163" data-doi="10.7554/eLife.59247">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXovVeltbs%3D" aria-label="CAS reference 163">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33284107" aria-label="PubMed reference 163">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7748414" aria-label="PubMed Central reference 163">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 163" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20speed%20and%20detection%20sensitivity%20controlled%20by%20distinct%20cortico-fugal%20neurons%20in%20visual%20cortex&amp;journal=eLife&amp;doi=10.7554%2FeLife.59247&amp;volume=9&amp;publication_year=2020&amp;author=Ruediger%2CS&amp;author=Scanziani%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="164."><p id="ref-CR164">Brooks, R. A. A robust layered control-system for a mobile robot. <i>IEEE T Robotic Autom.</i> <b>2</b>, 14–23 (1986).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1109/JRA.1986.1087032" data-track-action="article reference" href="https://doi.org/10.1109%2FJRA.1986.1087032" aria-label="Article reference 164" data-doi="10.1109/JRA.1986.1087032">Article</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 164" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20robust%20layered%20control-system%20for%20a%20mobile%20robot&amp;journal=IEEE%20T%20Robotic%20Autom.&amp;doi=10.1109%2FJRA.1986.1087032&amp;volume=2&amp;pages=14-23&amp;publication_year=1986&amp;author=Brooks%2CRA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="165."><p id="ref-CR165">Brooks, R. A. New approaches to robotics. <i>Science</i> <b>253</b>, 1227–1232 (1991).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.253.5025.1227" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.253.5025.1227" aria-label="Article reference 165" data-doi="10.1126/science.253.5025.1227">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC3cvlsVehsQ%3D%3D" aria-label="CAS reference 165">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17831441" aria-label="PubMed reference 165">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 165" href="http://scholar.google.com/scholar_lookup?&amp;title=New%20approaches%20to%20robotics&amp;journal=Science&amp;doi=10.1126%2Fscience.253.5025.1227&amp;volume=253&amp;pages=1227-1232&amp;publication_year=1991&amp;author=Brooks%2CRA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="166."><p id="ref-CR166">Haider, P., Ellenberger, B., Kriener, L., Jordan, J., Senn, W. &amp; Petrovici, M. A. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. <i>Adv. Neural Inf. Process. Syst.</i> <b>34</b>, 17839–17851 (2021).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 166" href="http://scholar.google.com/scholar_lookup?&amp;title=Latent%20equilibrium%3A%20a%20unified%20learning%20theory%20for%20arbitrarily%20fast%20computation%20with%20arbitrarily%20slow%20neurons&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=34&amp;pages=17839-17851&amp;publication_year=2021&amp;author=Haider%2CP&amp;author=Ellenberger%2CB&amp;author=Kriener%2CL&amp;author=Jordan%2CJ&amp;author=Senn%2CW&amp;author=Petrovici%2CMA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="167."><p id="ref-CR167">Narayanan, R. T. et al. Beyond columnar organization: cell type- and target layer-specific principles of horizontal axon projection patterns in rat vibrissal cortex. <i>Cereb. Cortex</i> <b>25</b>, 4450–4468 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhv053" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhv053" aria-label="Article reference 167" data-doi="10.1093/cercor/bhv053">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25838038" aria-label="PubMed reference 167">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4816792" aria-label="PubMed Central reference 167">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 167" href="http://scholar.google.com/scholar_lookup?&amp;title=Beyond%20columnar%20organization%3A%20cell%20type-%20and%20target%20layer-specific%20principles%20of%20horizontal%20axon%20projection%20patterns%20in%20rat%20vibrissal%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhv053&amp;volume=25&amp;pages=4450-4468&amp;publication_year=2015&amp;author=Narayanan%2CRT">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="168."><p id="ref-CR168">Chen, G., Scherr, F. &amp; Maass, W. A data-based large-scale model for primary visual cortex enables brain-like robust and versatile visual processing. <i>Sci. Adv.</i> <b>8</b>, eabq7592 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/sciadv.abq7592" data-track-action="article reference" href="https://doi.org/10.1126%2Fsciadv.abq7592" aria-label="Article reference 168" data-doi="10.1126/sciadv.abq7592">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36322646" aria-label="PubMed reference 168">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9629744" aria-label="PubMed Central reference 168">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 168" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20data-based%20large-scale%20model%20for%20primary%20visual%20cortex%20enables%20brain-like%20robust%20and%20versatile%20visual%20processing&amp;journal=Sci.%20Adv.&amp;doi=10.1126%2Fsciadv.abq7592&amp;volume=8&amp;publication_year=2022&amp;author=Chen%2CG&amp;author=Scherr%2CF&amp;author=Maass%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="169."><p id="ref-CR169">Guest, J. M., Bast, A., Narayanan, R. T. &amp; Oberlaender, M. Thalamus gates active dendritic computations in cortex during sensory processing. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2021.10.21.465325" data-track="click" data-track-action="external reference" data-track-label="10.1101/2021.10.21.465325">https://doi.org/10.1101/2021.10.21.465325</a> (2021).</p></li><li data-counter="170."><p id="ref-CR170">Constantinople, C. M. &amp; Bruno, R. M. Deep cortical layers are activated directly by thalamus. <i>Science</i> <b>340</b>, 1591–1594 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1236425" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1236425" aria-label="Article reference 170" data-doi="10.1126/science.1236425">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXpvFektLo%3D" aria-label="CAS reference 170">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23812718" aria-label="PubMed reference 170">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4203320" aria-label="PubMed Central reference 170">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 170" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20cortical%20layers%20are%20activated%20directly%20by%20thalamus&amp;journal=Science&amp;doi=10.1126%2Fscience.1236425&amp;volume=340&amp;pages=1591-1594&amp;publication_year=2013&amp;author=Constantinople%2CCM&amp;author=Bruno%2CRM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="171."><p id="ref-CR171">Pluta, S. et al. A direct translaminar inhibitory circuit tunes cortical output. <i>Nat. Neurosci.</i> <b>18</b>, 1631–1640 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4123" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4123" aria-label="Article reference 171" data-doi="10.1038/nn.4123">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhsFKqu7vP" aria-label="CAS reference 171">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26414615" aria-label="PubMed reference 171">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4624464" aria-label="PubMed Central reference 171">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 171" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20direct%20translaminar%20inhibitory%20circuit%20tunes%20cortical%20output&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4123&amp;volume=18&amp;pages=1631-1640&amp;publication_year=2015&amp;author=Pluta%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="172."><p id="ref-CR172">Stuart, G., Spruston, N. &amp; Häusser, M. <i>Dendrites</i> 3rd edn (Oxford Univ. Press, 2016).</p></li><li data-counter="173."><p id="ref-CR173">Major, G., Larkum, M. E. &amp; Schiller, J. Active properties of neocortical pyramidal neuron dendrites. <i>Annu. Rev. Neurosci.</i> <b>36</b>, 1–24 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-neuro-062111-150343" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-neuro-062111-150343" aria-label="Article reference 173" data-doi="10.1146/annurev-neuro-062111-150343">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXhtlCku7%2FL" aria-label="CAS reference 173">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23841837" aria-label="PubMed reference 173">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 173" href="http://scholar.google.com/scholar_lookup?&amp;title=Active%20properties%20of%20neocortical%20pyramidal%20neuron%20dendrites&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev-neuro-062111-150343&amp;volume=36&amp;pages=1-24&amp;publication_year=2013&amp;author=Major%2CG&amp;author=Larkum%2CME&amp;author=Schiller%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="174."><p id="ref-CR174">Mikulasch, F. A., Rudelt, L., Wibral, M. &amp; Priesemann, V. Where is the error? Hierarchical predictive coding through dendritic error computation. <i>Trends Neurosci.</i> <b>46</b>, 45–59 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2022.09.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2022.09.007" aria-label="Article reference 174" data-doi="10.1016/j.tins.2022.09.007">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36577388" aria-label="PubMed reference 174">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 174" href="http://scholar.google.com/scholar_lookup?&amp;title=Where%20is%20the%20error%3F%20Hierarchical%20predictive%20coding%20through%20dendritic%20error%20computation&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2022.09.007&amp;volume=46&amp;pages=45-59&amp;publication_year=2022&amp;author=Mikulasch%2CFA&amp;author=Rudelt%2CL&amp;author=Wibral%2CM&amp;author=Priesemann%2CV">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="175."><p id="ref-CR175">Richards, B. A. &amp; Lillicrap, T. P. Dendritic solutions to the credit assignment problem. <i>Curr. Opin. Neurobiol.</i> <b>54</b>, 28–36 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.conb.2018.08.003" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2018.08.003" aria-label="Article reference 175" data-doi="10.1016/j.conb.2018.08.003">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhsFGlsLfO" aria-label="CAS reference 175">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30205266" aria-label="PubMed reference 175">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 175" href="http://scholar.google.com/scholar_lookup?&amp;title=Dendritic%20solutions%20to%20the%20credit%20assignment%20problem&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2018.08.003&amp;volume=54&amp;pages=28-36&amp;publication_year=2019&amp;author=Richards%2CBA&amp;author=Lillicrap%2CTP">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="176."><p id="ref-CR176">Guerguiev, J., Lillicrap, T. P. &amp; Richards, B. A. Towards deep learning with segregated dendrites. <i>eLife</i> <b>6</b>, e22901 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.22901" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.22901" aria-label="Article reference 176" data-doi="10.7554/eLife.22901">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29205151" aria-label="PubMed reference 176">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5716677" aria-label="PubMed Central reference 176">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 176" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20deep%20learning%20with%20segregated%20dendrites&amp;journal=eLife&amp;doi=10.7554%2FeLife.22901&amp;volume=6&amp;publication_year=2017&amp;author=Guerguiev%2CJ&amp;author=Lillicrap%2CTP&amp;author=Richards%2CBA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="177."><p id="ref-CR177">Hawkins, J. &amp; Ahmad, S. Why neurons have thousands of synapses, a theory of sequence memory in neocortex. <i>Front. Neural Circuits</i> <b>10</b>, 23 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fncir.2016.00023" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncir.2016.00023" aria-label="Article reference 177" data-doi="10.3389/fncir.2016.00023">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27065813" aria-label="PubMed reference 177">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4811948" aria-label="PubMed Central reference 177">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 177" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20neurons%20have%20thousands%20of%20synapses%2C%20a%20theory%20of%20sequence%20memory%20in%20neocortex&amp;journal=Front.%20Neural%20Circuits&amp;doi=10.3389%2Ffncir.2016.00023&amp;volume=10&amp;publication_year=2016&amp;author=Hawkins%2CJ&amp;author=Ahmad%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="178."><p id="ref-CR178">Schiess, M., Urbanczik, R. &amp; Senn, W. Somato-dendritic synaptic plasticity and error-backpropagation in active dendrites. <i>PLoS Comput. Biol.</i> <b>12</b>, e1004638 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1004638" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1004638" aria-label="Article reference 178" data-doi="10.1371/journal.pcbi.1004638">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26841235" aria-label="PubMed reference 178">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4739747" aria-label="PubMed Central reference 178">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 178" href="http://scholar.google.com/scholar_lookup?&amp;title=Somato-dendritic%20synaptic%20plasticity%20and%20error-backpropagation%20in%20active%20dendrites&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1004638&amp;volume=12&amp;publication_year=2016&amp;author=Schiess%2CM&amp;author=Urbanczik%2CR&amp;author=Senn%2CW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="179."><p id="ref-CR179">Poirazi, P. &amp; Papoutsi, A. Illuminating dendritic function with computational models. <i>Nat. Rev. Neurosci.</i> <b>21</b>, 303–321 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41583-020-0301-7" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-020-0301-7" aria-label="Article reference 179" data-doi="10.1038/s41583-020-0301-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXptVKhsbs%3D" aria-label="CAS reference 179">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32393820" aria-label="PubMed reference 179">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 179" href="http://scholar.google.com/scholar_lookup?&amp;title=Illuminating%20dendritic%20function%20with%20computational%20models&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-020-0301-7&amp;volume=21&amp;pages=303-321&amp;publication_year=2020&amp;author=Poirazi%2CP&amp;author=Papoutsi%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="180."><p id="ref-CR180">Beniaguev, D., Segev, I. &amp; London, M. Single cortical neurons as deep artificial neural networks. <i>Neuron</i> <b>109</b>, 2727–2739.e3 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2021.07.002" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2021.07.002" aria-label="Article reference 180" data-doi="10.1016/j.neuron.2021.07.002">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXhslGms7fI" aria-label="CAS reference 180">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34380016" aria-label="PubMed reference 180">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 180" href="http://scholar.google.com/scholar_lookup?&amp;title=Single%20cortical%20neurons%20as%20deep%20artificial%20neural%20networks&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2021.07.002&amp;volume=109&amp;pages=2727-2739.e3&amp;publication_year=2021&amp;author=Beniaguev%2CD&amp;author=Segev%2CI&amp;author=London%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="181."><p id="ref-CR181">Cossell, L. et al. Functional organization of excitatory synaptic strength in primary visual cortex. <i>Nature</i> <b>518</b>, 399–403 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature14182" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature14182" aria-label="Article reference 181" data-doi="10.1038/nature14182">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXitVGisbc%3D" aria-label="CAS reference 181">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25652823" aria-label="PubMed reference 181">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4843963" aria-label="PubMed Central reference 181">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 181" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20organization%20of%20excitatory%20synaptic%20strength%20in%20primary%20visual%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fnature14182&amp;volume=518&amp;pages=399-403&amp;publication_year=2015&amp;author=Cossell%2CL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="182."><p id="ref-CR182">Seeman, S. C. et al. Sparse recurrent excitatory connectivity in the microcircuit of the adult mouse and human cortex. <i>eLife</i> <b>7</b>, e37349 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.37349" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.37349" aria-label="Article reference 182" data-doi="10.7554/eLife.37349">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30256194" aria-label="PubMed reference 182">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6158007" aria-label="PubMed Central reference 182">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 182" href="http://scholar.google.com/scholar_lookup?&amp;title=Sparse%20recurrent%20excitatory%20connectivity%20in%20the%20microcircuit%20of%20the%20adult%20mouse%20and%20human%20cortex&amp;journal=eLife&amp;doi=10.7554%2FeLife.37349&amp;volume=7&amp;publication_year=2018&amp;author=Seeman%2CSC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="183."><p id="ref-CR183">Garner, A. R. &amp; Keller, G. B. A cortical circuit for audio-visual predictions. <i>Nat. Neurosci.</i> <b>25</b>, 98–105 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-021-00974-7" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-021-00974-7" aria-label="Article reference 183" data-doi="10.1038/s41593-021-00974-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXis1Khs7fI" aria-label="CAS reference 183">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34857950" aria-label="PubMed reference 183">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 183" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20cortical%20circuit%20for%20audio-visual%20predictions&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-021-00974-7&amp;volume=25&amp;pages=98-105&amp;publication_year=2022&amp;author=Garner%2CAR&amp;author=Keller%2CGB">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="184."><p id="ref-CR184">Ghazanfar, A. A. &amp; Schroeder, C. E. Is neocortex essentially multisensory? <i>Trends Cogn. Sci.</i> <b>10</b>, 278–285 (2006).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tics.2006.04.008" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2006.04.008" aria-label="Article reference 184" data-doi="10.1016/j.tics.2006.04.008">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16713325" aria-label="PubMed reference 184">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 184" href="http://scholar.google.com/scholar_lookup?&amp;title=Is%20neocortex%20essentially%20multisensory%3F&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2006.04.008&amp;volume=10&amp;pages=278-285&amp;publication_year=2006&amp;author=Ghazanfar%2CAA&amp;author=Schroeder%2CCE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="185."><p id="ref-CR185">Fetsch, C. R., DeAngelis, G. C. &amp; Angelaki, D. E. Bridging the gap between theories of sensory cue integration and the physiology of multisensory neurons. <i>Nat. Rev. Neurosci.</i> <b>14</b>, 429–442 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn3503" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn3503" aria-label="Article reference 185" data-doi="10.1038/nrn3503">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3sXnvVSit7o%3D" aria-label="CAS reference 185">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=23686172" aria-label="PubMed reference 185">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 185" href="http://scholar.google.com/scholar_lookup?&amp;title=Bridging%20the%20gap%20between%20theories%20of%20sensory%20cue%20integration%20and%20the%20physiology%20of%20multisensory%20neurons&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn3503&amp;volume=14&amp;pages=429-442&amp;publication_year=2013&amp;author=Fetsch%2CCR&amp;author=DeAngelis%2CGC&amp;author=Angelaki%2CDE">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="186."><p id="ref-CR186">Graybiel, A. M. The basal ganglia. <i>Curr. Biol.</i> <b>10</b>, R509–R511 (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0960-9822(00)00593-5" data-track-action="article reference" href="https://doi.org/10.1016%2FS0960-9822%2800%2900593-5" aria-label="Article reference 186" data-doi="10.1016/S0960-9822(00)00593-5">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3cXkvFSlsbY%3D" aria-label="CAS reference 186">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10899013" aria-label="PubMed reference 186">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 186" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20basal%20ganglia&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2FS0960-9822%2800%2900593-5&amp;volume=10&amp;pages=R509-R511&amp;publication_year=2000&amp;author=Graybiel%2CAM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="187."><p id="ref-CR187">Alexander, G. E., DeLong, M. R. &amp; Strick, P. L. Parallel organization of functionally segregated circuits linking basal ganglia and cortex. <i>Annu. Rev. Neurosci.</i> <b>9</b>, 357–381 (1986).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev.ne.09.030186.002041" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev.ne.09.030186.002041" aria-label="Article reference 187" data-doi="10.1146/annurev.ne.09.030186.002041">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL283htlKksw%3D%3D" aria-label="CAS reference 187">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=3085570" aria-label="PubMed reference 187">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 187" href="http://scholar.google.com/scholar_lookup?&amp;title=Parallel%20organization%20of%20functionally%20segregated%20circuits%20linking%20basal%20ganglia%20and%20cortex&amp;journal=Annu.%20Rev.%20Neurosci.&amp;doi=10.1146%2Fannurev.ne.09.030186.002041&amp;volume=9&amp;pages=357-381&amp;publication_year=1986&amp;author=Alexander%2CGE&amp;author=DeLong%2CMR&amp;author=Strick%2CPL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="188."><p id="ref-CR188">Parent, A. et al. Organization of the basal ganglia: the importance of axonal collateralization. <i>Trends Neurosci.</i> <b>23</b>, S20–S27 (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S1471-1931(00)00022-7" data-track-action="article reference" href="https://doi.org/10.1016%2FS1471-1931%2800%2900022-7" aria-label="Article reference 188" data-doi="10.1016/S1471-1931(00)00022-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3cXotVGrt7c%3D" aria-label="CAS reference 188">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11052216" aria-label="PubMed reference 188">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 188" href="http://scholar.google.com/scholar_lookup?&amp;title=Organization%20of%20the%20basal%20ganglia%3A%20the%20importance%20of%20axonal%20collateralization&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2FS1471-1931%2800%2900022-7&amp;volume=23&amp;pages=S20-S27&amp;publication_year=2000&amp;author=Parent%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="189."><p id="ref-CR189">Takakusaki, K., Saitoh, K., Harada, H. &amp; Kashiwayanagi, M. Role of basal ganglia–brainstem pathways in the control of motor behaviors. <i>Neurosci. Res.</i> <b>50</b>, 137–151 (2004).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neures.2004.06.015" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neures.2004.06.015" aria-label="Article reference 189" data-doi="10.1016/j.neures.2004.06.015">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD2cvntFSqtw%3D%3D" aria-label="CAS reference 189">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15380321" aria-label="PubMed reference 189">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 189" href="http://scholar.google.com/scholar_lookup?&amp;title=Role%20of%20basal%20ganglia%E2%80%93brainstem%20pathways%20in%20the%20control%20of%20motor%20behaviors&amp;journal=Neurosci.%20Res.&amp;doi=10.1016%2Fj.neures.2004.06.015&amp;volume=50&amp;pages=137-151&amp;publication_year=2004&amp;author=Takakusaki%2CK&amp;author=Saitoh%2CK&amp;author=Harada%2CH&amp;author=Kashiwayanagi%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="190."><p id="ref-CR190">Graybiel, A. M., Aosaki, T., Flaherty, A. W. &amp; Kimura, M. The basal ganglia and adaptive motor control. <i>Science</i> <b>265</b>, 1826–1831 (1994).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.8091209" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.8091209" aria-label="Article reference 190" data-doi="10.1126/science.8091209">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2cznsl2ktA%3D%3D" aria-label="CAS reference 190">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8091209" aria-label="PubMed reference 190">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 190" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20basal%20ganglia%20and%20adaptive%20motor%20control&amp;journal=Science&amp;doi=10.1126%2Fscience.8091209&amp;volume=265&amp;pages=1826-1831&amp;publication_year=1994&amp;author=Graybiel%2CAM&amp;author=Aosaki%2CT&amp;author=Flaherty%2CAW&amp;author=Kimura%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="191."><p id="ref-CR191">Roseberry, T. K. et al. Cell-type-specific control of brainstem locomotor circuits by basal ganglia. <i>Cell</i> <b>164</b>, 526–537 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2015.12.037" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2015.12.037" aria-label="Article reference 191" data-doi="10.1016/j.cell.2015.12.037">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12lsrc%3D" aria-label="CAS reference 191">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26824660" aria-label="PubMed reference 191">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4733247" aria-label="PubMed Central reference 191">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 191" href="http://scholar.google.com/scholar_lookup?&amp;title=Cell-type-specific%20control%20of%20brainstem%20locomotor%20circuits%20by%20basal%20ganglia&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2015.12.037&amp;volume=164&amp;pages=526-537&amp;publication_year=2016&amp;author=Roseberry%2CTK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="192."><p id="ref-CR192">Parent, M., Levesque, M. &amp; Parent, A. Two types of projection neurons in the internal pallidum of primates: single-axon tracing and three-dimensional reconstruction. <i>J. Comp. Neurol.</i> <b>439</b>, 162–175 (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1002/cne.1340" data-track-action="article reference" href="https://doi.org/10.1002%2Fcne.1340" aria-label="Article reference 192" data-doi="10.1002/cne.1340">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BD3MrkvV2qtg%3D%3D" aria-label="CAS reference 192">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11596046" aria-label="PubMed reference 192">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 192" href="http://scholar.google.com/scholar_lookup?&amp;title=Two%20types%20of%20projection%20neurons%20in%20the%20internal%20pallidum%20of%20primates%3A%20single-axon%20tracing%20and%20three-dimensional%20reconstruction&amp;journal=J.%20Comp.%20Neurol.&amp;doi=10.1002%2Fcne.1340&amp;volume=439&amp;pages=162-175&amp;publication_year=2001&amp;author=Parent%2CM&amp;author=Levesque%2CM&amp;author=Parent%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="193."><p id="ref-CR193">Parent, M. &amp; Parent, A. The pallidofugal motor fiber system in primates. <i>Parkinsonism Relat. Disord.</i> <b>10</b>, 203–211 (2004).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.parkreldis.2004.02.007" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.parkreldis.2004.02.007" aria-label="Article reference 193" data-doi="10.1016/j.parkreldis.2004.02.007">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15120094" aria-label="PubMed reference 193">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 193" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20pallidofugal%20motor%20fiber%20system%20in%20primates&amp;journal=Parkinsonism%20Relat.%20Disord.&amp;doi=10.1016%2Fj.parkreldis.2004.02.007&amp;volume=10&amp;pages=203-211&amp;publication_year=2004&amp;author=Parent%2CM&amp;author=Parent%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="194."><p id="ref-CR194">Pennartz, C. M., Groenewegen, H. J. &amp; Lopes da Silva, F. H. The nucleus accumbens as a complex of functionally distinct neuronal ensembles: an integration of behavioural, electrophysiological and anatomical data. <i>Prog. Neurobiol.</i> <b>42</b>, 719–761 (1994).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0301-0082(94)90025-6" data-track-action="article reference" href="https://doi.org/10.1016%2F0301-0082%2894%2990025-6" aria-label="Article reference 194" data-doi="10.1016/0301-0082(94)90025-6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2M%2FisVOgsQ%3D%3D" aria-label="CAS reference 194">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7938546" aria-label="PubMed reference 194">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 194" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20nucleus%20accumbens%20as%20a%20complex%20of%20functionally%20distinct%20neuronal%20ensembles%3A%20an%20integration%20of%20behavioural%2C%20electrophysiological%20and%20anatomical%20data&amp;journal=Prog.%20Neurobiol.&amp;doi=10.1016%2F0301-0082%2894%2990025-6&amp;volume=42&amp;pages=719-761&amp;publication_year=1994&amp;author=Pennartz%2CCM&amp;author=Groenewegen%2CHJ&amp;author=Lopes%20da%20Silva%2CFH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="195."><p id="ref-CR195">Di Chiara, G., Porceddu, M. L., Morelli, M., Mulas, M. L. &amp; Gessa, G. L. Evidence for a GABAergic projection from the substantia nigra to the ventromedial thalamus and to the superior colliculus of the rat. <i>Brain Res.</i> <b>176</b>, 273–284 (1979).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0006-8993(79)90983-1" data-track-action="article reference" href="https://doi.org/10.1016%2F0006-8993%2879%2990983-1" aria-label="Article reference 195" data-doi="10.1016/0006-8993(79)90983-1">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=40667" aria-label="PubMed reference 195">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 195" href="http://scholar.google.com/scholar_lookup?&amp;title=Evidence%20for%20a%20GABAergic%20projection%20from%20the%20substantia%20nigra%20to%20the%20ventromedial%20thalamus%20and%20to%20the%20superior%20colliculus%20of%20the%20rat&amp;journal=Brain%20Res.&amp;doi=10.1016%2F0006-8993%2879%2990983-1&amp;volume=176&amp;pages=273-284&amp;publication_year=1979&amp;author=Chiara%2CG&amp;author=Porceddu%2CML&amp;author=Morelli%2CM&amp;author=Mulas%2CML&amp;author=Gessa%2CGL">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="196."><p id="ref-CR196">Williams, L. E. &amp; Holtmaat, A. Higher-order thalamocortical inputs gate synaptic long-term potentiation via disinhibition. <i>Neuron</i> <b>101</b>, 91–102.e4 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.10.049" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.10.049" aria-label="Article reference 196" data-doi="10.1016/j.neuron.2018.10.049">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXit12lsbbK" aria-label="CAS reference 196">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30472077" aria-label="PubMed reference 196">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 196" href="http://scholar.google.com/scholar_lookup?&amp;title=Higher-order%20thalamocortical%20inputs%20gate%20synaptic%20long-term%20potentiation%20via%20disinhibition&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.10.049&amp;volume=101&amp;pages=91-102.e4&amp;publication_year=2019&amp;author=Williams%2CLE&amp;author=Holtmaat%2CA">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="197."><p id="ref-CR197">Gambino, F. et al. Sensory-evoked LTP driven by dendritic plateau potentials in vivo. <i>Nature</i> <b>515</b>, 116–119 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature13664" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature13664" aria-label="Article reference 197" data-doi="10.1038/nature13664">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXhvVemtrvM" aria-label="CAS reference 197">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25174710" aria-label="PubMed reference 197">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 197" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensory-evoked%20LTP%20driven%20by%20dendritic%20plateau%20potentials%20in%20vivo&amp;journal=Nature&amp;doi=10.1038%2Fnature13664&amp;volume=515&amp;pages=116-119&amp;publication_year=2014&amp;author=Gambino%2CF">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="198."><p id="ref-CR198">Anastasiades, P. G., Collins, D. P. &amp; Carter, A. G. Mediodorsal and ventromedial thalamus engage distinct L1 circuits in the prefrontal cortex. <i>Neuron</i> <b>109</b>, 314–330.e4 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2020.10.031" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2020.10.031" aria-label="Article reference 198" data-doi="10.1016/j.neuron.2020.10.031">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXitlCktLvN" aria-label="CAS reference 198">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33188733" aria-label="PubMed reference 198">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 198" href="http://scholar.google.com/scholar_lookup?&amp;title=Mediodorsal%20and%20ventromedial%20thalamus%20engage%20distinct%20L1%20circuits%20in%20the%20prefrontal%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2020.10.031&amp;volume=109&amp;pages=314-330.e4&amp;publication_year=2021&amp;author=Anastasiades%2CPG&amp;author=Collins%2CDP&amp;author=Carter%2CAG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="199."><p id="ref-CR199">Schmitt, L. I. et al. Thalamic amplification of cortical connectivity sustains attentional control. <i>Nature</i> <b>545</b>, 219–223 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature22073" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature22073" aria-label="Article reference 199" data-doi="10.1038/nature22073">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXntVKms74%3D" aria-label="CAS reference 199">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28467827" aria-label="PubMed reference 199">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5570520" aria-label="PubMed Central reference 199">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 199" href="http://scholar.google.com/scholar_lookup?&amp;title=Thalamic%20amplification%20of%20cortical%20connectivity%20sustains%20attentional%20control&amp;journal=Nature&amp;doi=10.1038%2Fnature22073&amp;volume=545&amp;pages=219-223&amp;publication_year=2017&amp;author=Schmitt%2CLI">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="200."><p id="ref-CR200">Inagaki, H. K. et al. A midbrain–thalamus–cortex circuit reorganizes cortical dynamics to initiate movement. <i>Cell</i> <b>185</b>, 1065–1081.e23 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2022.02.006" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2022.02.006" aria-label="Article reference 200" data-doi="10.1016/j.cell.2022.02.006">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XlvVekt78%3D" aria-label="CAS reference 200">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35245431" aria-label="PubMed reference 200">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8990337" aria-label="PubMed Central reference 200">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 200" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20midbrain%E2%80%93thalamus%E2%80%93cortex%20circuit%20reorganizes%20cortical%20dynamics%20to%20initiate%20movement&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2022.02.006&amp;volume=185&amp;pages=1065-1081.e23&amp;publication_year=2022&amp;author=Inagaki%2CHK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="201."><p id="ref-CR201">Wang, M. B. &amp; Halassa, M. M. Thalamocortical contribution to flexible learning in neural systems. <i>Netw. Neurosci.</i> <b>6</b>, 980–997 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1162/netn_a_00235" data-track-action="article reference" href="https://doi.org/10.1162%2Fnetn_a_00235" aria-label="Article reference 201" data-doi="10.1162/netn_a_00235">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36875011" aria-label="PubMed reference 201">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9976647" aria-label="PubMed Central reference 201">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 201" href="http://scholar.google.com/scholar_lookup?&amp;title=Thalamocortical%20contribution%20to%20flexible%20learning%20in%20neural%20systems&amp;journal=Netw.%20Neurosci.&amp;doi=10.1162%2Fnetn_a_00235&amp;volume=6&amp;pages=980-997&amp;publication_year=2022&amp;author=Wang%2CMB&amp;author=Halassa%2CMM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="202."><p id="ref-CR202">La Terra, D. et al. The role of higher-order thalamus during learning and correct performance in goal-directed behavior. <i>eLife</i> <b>11</b>, e77177 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.77177" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.77177" aria-label="Article reference 202" data-doi="10.7554/eLife.77177">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35259091" aria-label="PubMed reference 202">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8937217" aria-label="PubMed Central reference 202">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 202" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20higher-order%20thalamus%20during%20learning%20and%20correct%20performance%20in%20goal-directed%20behavior&amp;journal=eLife&amp;doi=10.7554%2FeLife.77177&amp;volume=11&amp;publication_year=2022&amp;author=Terra%2CD">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="203."><p id="ref-CR203">Ruis, L., Andreas, J., Baroni, M., Bouchacourt, D. &amp; Lake, B. M. A benchmark for systematic generalization in grounded language understanding. In <i>Proc. 34th Int. Conf. Neural Information Processing Systems</i> (eds. Larochelle, H. et al.) 19861–19872 (Curran, 2020).</p></li><li data-counter="204."><p id="ref-CR204">Lake, B. M. &amp; Baroni, M. Generalization without systematicity: on the compositional skills of sequence-to-sequence recurrent networks. In <i>Int. Conf. Machine Learning</i> (eds. Dy, J. &amp; Krause, A.) 2879–2888 (2018).</p></li><li data-counter="205."><p id="ref-CR205">Pfeiffer, J., Ruder, S., Vulić, I. &amp; Ponti, E. M. Modular deep learning. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.2302.11529" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.2302.11529">https://doi.org/10.48550/arXiv.2302.11529</a> (2023).</p></li><li data-counter="206."><p id="ref-CR206">Goyal, A. et al. Recurrent independent mechanisms. Preprint at <i>arXiv</i>&nbsp;<a href="https://doi.org/10.48550/arXiv.1909.10893" data-track="click" data-track-action="external reference" data-track-label="10.48550/arXiv.1909.10893">https://doi.org/10.48550/arXiv.1909.10893</a> (2020).</p></li><li data-counter="207."><p id="ref-CR207">Albright, T. D., Jessell, T. M., Kandel, E. R. &amp; Posner, M. I. Neural science: a century of progress and the mysteries that remain. <i>Neuron</i> <b>25</b>, S1–S55 (2000).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(00)80912-5" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2800%2980912-5" aria-label="Article reference 207" data-doi="10.1016/S0896-6273(00)80912-5">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10718192" aria-label="PubMed reference 207">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 207" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20science%3A%20a%20century%20of%20progress%20and%20the%20mysteries%20that%20remain&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2800%2980912-5&amp;volume=25&amp;pages=S1-S55&amp;publication_year=2000&amp;author=Albright%2CTD&amp;author=Jessell%2CTM&amp;author=Kandel%2CER&amp;author=Posner%2CMI">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="208."><p id="ref-CR208">Wallis, J. D., Anderson, K. C. &amp; Miller, E. K. Single neurons in prefrontal cortex encode abstract rules. <i>Nature</i> <b>411</b>, 953–956 (2001).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/35082081" data-track-action="article reference" href="https://doi.org/10.1038%2F35082081" aria-label="Article reference 208" data-doi="10.1038/35082081">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3MXkvVWgsrY%3D" aria-label="CAS reference 208">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=11418860" aria-label="PubMed reference 208">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 208" href="http://scholar.google.com/scholar_lookup?&amp;title=Single%20neurons%20in%20prefrontal%20cortex%20encode%20abstract%20rules&amp;journal=Nature&amp;doi=10.1038%2F35082081&amp;volume=411&amp;pages=953-956&amp;publication_year=2001&amp;author=Wallis%2CJD&amp;author=Anderson%2CKC&amp;author=Miller%2CEK">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="209."><p id="ref-CR209">Verschure, P. F., Pennartz, C. M. &amp; Pezzulo, G. The why, what, where, when and how of goal-directed choice: neuronal and computational principles. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>369</b>, 20130483 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2013.0483" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2013.0483" aria-label="Article reference 209" data-doi="10.1098/rstb.2013.0483">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25267825" aria-label="PubMed reference 209">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4186236" aria-label="PubMed Central reference 209">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 209" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20why%2C%20what%2C%20where%2C%20when%20and%20how%20of%20goal-directed%20choice%3A%20neuronal%20and%20computational%20principles&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2013.0483&amp;volume=369&amp;publication_year=2014&amp;author=Verschure%2CPF&amp;author=Pennartz%2CCM&amp;author=Pezzulo%2CG">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="210."><p id="ref-CR210">Dias, R., Robbins, T. W. &amp; Roberts, A. C. Dissociation in prefrontal cortex of affective and attentional shifts. <i>Nature</i> <b>380</b>, 69–72 (1996).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/380069a0" data-track-action="article reference" href="https://doi.org/10.1038%2F380069a0" aria-label="Article reference 210" data-doi="10.1038/380069a0">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK28XhsFeisb4%3D" aria-label="CAS reference 210">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=8598908" aria-label="PubMed reference 210">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 210" href="http://scholar.google.com/scholar_lookup?&amp;title=Dissociation%20in%20prefrontal%20cortex%20of%20affective%20and%20attentional%20shifts&amp;journal=Nature&amp;doi=10.1038%2F380069a0&amp;volume=380&amp;pages=69-72&amp;publication_year=1996&amp;author=Dias%2CR&amp;author=Robbins%2CTW&amp;author=Roberts%2CAC">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="211."><p id="ref-CR211">Wilson, R. C., Takahashi, Y. K., Schoenbaum, G. &amp; Niv, Y. Orbitofrontal cortex as a cognitive map of task space. <i>Neuron</i> <b>81</b>, 267–279 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2013.11.005" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2013.11.005" aria-label="Article reference 211" data-doi="10.1016/j.neuron.2013.11.005">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXht1Glsb4%3D" aria-label="CAS reference 211">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24462094" aria-label="PubMed reference 211">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4001869" aria-label="PubMed Central reference 211">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 211" href="http://scholar.google.com/scholar_lookup?&amp;title=Orbitofrontal%20cortex%20as%20a%20cognitive%20map%20of%20task%20space&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2013.11.005&amp;volume=81&amp;pages=267-279&amp;publication_year=2014&amp;author=Wilson%2CRC&amp;author=Takahashi%2CYK&amp;author=Schoenbaum%2CG&amp;author=Niv%2CY">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="212."><p id="ref-CR212">Fan, J., McCandliss, B. D., Fossella, J., Flombaum, J. I. &amp; Posner, M. I. The activation of attentional networks. <i>Neuroimage</i> <b>26</b>, 471–479 (2005).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2005.02.004" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2005.02.004" aria-label="Article reference 212" data-doi="10.1016/j.neuroimage.2005.02.004">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15907304" aria-label="PubMed reference 212">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 212" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20activation%20of%20attentional%20networks&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2005.02.004&amp;volume=26&amp;pages=471-479&amp;publication_year=2005&amp;author=Fan%2CJ&amp;author=McCandliss%2CBD&amp;author=Fossella%2CJ&amp;author=Flombaum%2CJI&amp;author=Posner%2CMI">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="213."><p id="ref-CR213">Womelsdorf, T. &amp; Everling, S. Long-range attention networks: circuit motifs underlying endogenously controlled stimulus selection. <i>Trends Neurosci.</i> <b>38</b>, 682–700 (2015).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.tins.2015.08.009" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tins.2015.08.009" aria-label="Article reference 213" data-doi="10.1016/j.tins.2015.08.009">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhslyrur3L" aria-label="CAS reference 213">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26549883" aria-label="PubMed reference 213">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 213" href="http://scholar.google.com/scholar_lookup?&amp;title=Long-range%20attention%20networks%3A%20circuit%20motifs%20underlying%20endogenously%20controlled%20stimulus%20selection&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2Fj.tins.2015.08.009&amp;volume=38&amp;pages=682-700&amp;publication_year=2015&amp;author=Womelsdorf%2CT&amp;author=Everling%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="214."><p id="ref-CR214">Cohen, M. R. &amp; Maunsell, J. H. Attention improves performance primarily by reducing interneuronal correlations. <i>Nat. Neurosci.</i> <b>12</b>, 1594–1600 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.2439" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.2439" aria-label="Article reference 214" data-doi="10.1038/nn.2439">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1MXhsVWlsbrJ" aria-label="CAS reference 214">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19915566" aria-label="PubMed reference 214">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2820564" aria-label="PubMed Central reference 214">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 214" href="http://scholar.google.com/scholar_lookup?&amp;title=Attention%20improves%20performance%20primarily%20by%20reducing%20interneuronal%20correlations&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.2439&amp;volume=12&amp;pages=1594-1600&amp;publication_year=2009&amp;author=Cohen%2CMR&amp;author=Maunsell%2CJH">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="215."><p id="ref-CR215">Reynolds, J. H. &amp; Desimone, R. Interacting roles of attention and visual salience in V4. <i>Neuron</i> <b>37</b>, 853–863 (2003).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0896-6273(03)00097-7" data-track-action="article reference" href="https://doi.org/10.1016%2FS0896-6273%2803%2900097-7" aria-label="Article reference 215" data-doi="10.1016/S0896-6273(03)00097-7">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD3sXitlSrsb8%3D" aria-label="CAS reference 215">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12628175" aria-label="PubMed reference 215">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 215" href="http://scholar.google.com/scholar_lookup?&amp;title=Interacting%20roles%20of%20attention%20and%20visual%20salience%20in%20V4&amp;journal=Neuron&amp;doi=10.1016%2FS0896-6273%2803%2900097-7&amp;volume=37&amp;pages=853-863&amp;publication_year=2003&amp;author=Reynolds%2CJH&amp;author=Desimone%2CR">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="216."><p id="ref-CR216">Poort, J. et al. The role of attention in figure-ground segregation in areas V1 and V4 of the visual cortex. <i>Neuron</i> <b>75</b>, 143–156 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2012.04.032" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2012.04.032" aria-label="Article reference 216" data-doi="10.1016/j.neuron.2012.04.032">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhtVekt7fM" aria-label="CAS reference 216">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22794268" aria-label="PubMed reference 216">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 216" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20attention%20in%20figure-ground%20segregation%20in%20areas%20V1%20and%20V4%20of%20the%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2012.04.032&amp;volume=75&amp;pages=143-156&amp;publication_year=2012&amp;author=Poort%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="217."><p id="ref-CR217">Reep, R. L. &amp; Corwin, J. V. Posterior parietal cortex as part of a neural network for directed attention in rats. <i>Neurobiol. Learn. Mem.</i> <b>91</b>, 104–113 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.nlm.2008.08.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.nlm.2008.08.010" aria-label="Article reference 217" data-doi="10.1016/j.nlm.2008.08.010">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18824116" aria-label="PubMed reference 217">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 217" href="http://scholar.google.com/scholar_lookup?&amp;title=Posterior%20parietal%20cortex%20as%20part%20of%20a%20neural%20network%20for%20directed%20attention%20in%20rats&amp;journal=Neurobiol.%20Learn.%20Mem.&amp;doi=10.1016%2Fj.nlm.2008.08.010&amp;volume=91&amp;pages=104-113&amp;publication_year=2009&amp;author=Reep%2CRL&amp;author=Corwin%2CJV">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="218."><p id="ref-CR218">Saalmann, Y. B., Pinsk, M. A., Wang, L., Li, X. &amp; Kastner, S. The pulvinar regulates information transmission between cortical areas based on attention demands. <i>Science</i> <b>337</b>, 753–756 (2012).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1223082" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1223082" aria-label="Article reference 218" data-doi="10.1126/science.1223082">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38XhtFCktb7L" aria-label="CAS reference 218">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22879517" aria-label="PubMed reference 218">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3714098" aria-label="PubMed Central reference 218">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 218" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20pulvinar%20regulates%20information%20transmission%20between%20cortical%20areas%20based%20on%20attention%20demands&amp;journal=Science&amp;doi=10.1126%2Fscience.1223082&amp;volume=337&amp;pages=753-756&amp;publication_year=2012&amp;author=Saalmann%2CYB&amp;author=Pinsk%2CMA&amp;author=Wang%2CL&amp;author=Li%2CX&amp;author=Kastner%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="219."><p id="ref-CR219">Rikhye, R. V., Gilra, A. &amp; Halassa, M. M. Thalamic regulation of switching between cortical representations enables cognitive flexibility. <i>Nat. Neurosci.</i> <b>21</b>, 1753–1763 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-018-0269-z" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-018-0269-z" aria-label="Article reference 219" data-doi="10.1038/s41593-018-0269-z">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXit1Crsb3K" aria-label="CAS reference 219">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30455456" aria-label="PubMed reference 219">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7225728" aria-label="PubMed Central reference 219">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 219" href="http://scholar.google.com/scholar_lookup?&amp;title=Thalamic%20regulation%20of%20switching%20between%20cortical%20representations%20enables%20cognitive%20flexibility&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-018-0269-z&amp;volume=21&amp;pages=1753-1763&amp;publication_year=2018&amp;author=Rikhye%2CRV&amp;author=Gilra%2CA&amp;author=Halassa%2CMM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="220."><p id="ref-CR220">Van der Werf, Y. D., Witter, M. P. &amp; Groenewegen, H. J. The intralaminar and midline nuclei of the thalamus. Anatomical and functional evidence for participation in processes of arousal and awareness. <i>Brain Res. Brain Res. Rev.</i> <b>39</b>, 107–140 (2002).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0165-0173(02)00181-9" data-track-action="article reference" href="https://doi.org/10.1016%2FS0165-0173%2802%2900181-9" aria-label="Article reference 220" data-doi="10.1016/S0165-0173(02)00181-9">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=12423763" aria-label="PubMed reference 220">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 220" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20intralaminar%20and%20midline%20nuclei%20of%20the%20thalamus.%20Anatomical%20and%20functional%20evidence%20for%20participation%20in%20processes%20of%20arousal%20and%20awareness&amp;journal=Brain%20Res.%20Brain%20Res.%20Rev.&amp;doi=10.1016%2FS0165-0173%2802%2900181-9&amp;volume=39&amp;pages=107-140&amp;publication_year=2002&amp;author=Werf%2CYD&amp;author=Witter%2CMP&amp;author=Groenewegen%2CHJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="221."><p id="ref-CR221">Groenewegen, H. J. &amp; Berendse, H. W. The specificity of the ‘nonspecific’ midline and intralaminar thalamic nuclei. <i>Trends Neurosci.</i> <b>17</b>, 52–57 (1994).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/0166-2236(94)90074-4" data-track-action="article reference" href="https://doi.org/10.1016%2F0166-2236%2894%2990074-4" aria-label="Article reference 221" data-doi="10.1016/0166-2236(94)90074-4">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK2c3ht1CmtQ%3D%3D" aria-label="CAS reference 221">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7512768" aria-label="PubMed reference 221">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 221" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20specificity%20of%20the%20%E2%80%98nonspecific%E2%80%99%20midline%20and%20intralaminar%20thalamic%20nuclei&amp;journal=Trends%20Neurosci.&amp;doi=10.1016%2F0166-2236%2894%2990074-4&amp;volume=17&amp;pages=52-57&amp;publication_year=1994&amp;author=Groenewegen%2CHJ&amp;author=Berendse%2CHW">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="222."><p id="ref-CR222">Breton-Provencher, V., Drummond, G. T., Feng, J., Li, Y. &amp; Sur, M. Spatiotemporal dynamics of noradrenaline during learned behaviour. <i>Nature</i> <b>606</b>, 732–738 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41586-022-04782-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-022-04782-2" aria-label="Article reference 222" data-doi="10.1038/s41586-022-04782-2">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XhsVant7vI" aria-label="CAS reference 222">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35650441" aria-label="PubMed reference 222">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9837982" aria-label="PubMed Central reference 222">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 222" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatiotemporal%20dynamics%20of%20noradrenaline%20during%20learned%20behaviour&amp;journal=Nature&amp;doi=10.1038%2Fs41586-022-04782-2&amp;volume=606&amp;pages=732-738&amp;publication_year=2022&amp;author=Breton-Provencher%2CV&amp;author=Drummond%2CGT&amp;author=Feng%2CJ&amp;author=Li%2CY&amp;author=Sur%2CM">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="223."><p id="ref-CR223">Ren, J. et al. Anatomically defined and functionally distinct dorsal raphe serotonin sub-systems. <i>Cell</i> <b>175</b>, 472–487.e20 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cell.2018.07.043" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cell.2018.07.043" aria-label="Article reference 223" data-doi="10.1016/j.cell.2018.07.043">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXhsFyktbjN" aria-label="CAS reference 223">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30146164" aria-label="PubMed reference 223">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6173627" aria-label="PubMed Central reference 223">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 223" href="http://scholar.google.com/scholar_lookup?&amp;title=Anatomically%20defined%20and%20functionally%20distinct%20dorsal%20raphe%20serotonin%20sub-systems&amp;journal=Cell&amp;doi=10.1016%2Fj.cell.2018.07.043&amp;volume=175&amp;pages=472-487.e20&amp;publication_year=2018&amp;author=Ren%2CJ">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="224."><p id="ref-CR224">Lohani, S. et al. Spatiotemporally heterogeneous coordination of cholinergic and neocortical activity. <i>Nat. Neurosci.</i> <b>25</b>, 1706–1713 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-022-01202-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-022-01202-6" aria-label="Article reference 224" data-doi="10.1038/s41593-022-01202-6">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XivFOlsbvF" aria-label="CAS reference 224">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36443609" aria-label="PubMed reference 224">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 224" href="http://scholar.google.com/scholar_lookup?&amp;title=Spatiotemporally%20heterogeneous%20coordination%20of%20cholinergic%20and%20neocortical%20activity&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-022-01202-6&amp;volume=25&amp;pages=1706-1713&amp;publication_year=2022&amp;author=Lohani%2CS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="225."><p id="ref-CR225">Morris, L. S. et al. Fronto-striatal organization: defining functional and microstructural substrates of behavioural flexibility. <i>Cortex</i> <b>74</b>, 118–133 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cortex.2015.11.004" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cortex.2015.11.004" aria-label="Article reference 225" data-doi="10.1016/j.cortex.2015.11.004">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26673945" aria-label="PubMed reference 225">PubMed</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4729321" aria-label="PubMed Central reference 225">PubMed Central</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 225" href="http://scholar.google.com/scholar_lookup?&amp;title=Fronto-striatal%20organization%3A%20defining%20functional%20and%20microstructural%20substrates%20of%20behavioural%20flexibility&amp;journal=Cortex&amp;doi=10.1016%2Fj.cortex.2015.11.004&amp;volume=74&amp;pages=118-133&amp;publication_year=2016&amp;author=Morris%2CLS">
                    Google Scholar</a>&nbsp;
                </p></li><li data-counter="226."><p id="ref-CR226">Apicella, P., Legallet, E., Nieoullon, A. &amp; Trouche, E. Neglect of contralateral visual stimuli in monkeys with unilateral striatal dopamine depletion. <i>Behav. Brain Res.</i> <b>46</b>, 187–195 (1991).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/S0166-4328(05)80112-3" data-track-action="article reference" href="https://doi.org/10.1016%2FS0166-4328%2805%2980112-3" aria-label="Article reference 226" data-doi="10.1016/S0166-4328(05)80112-3">Article</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK387ltlegsA%3D%3D" aria-label="CAS reference 226">CAS</a>&nbsp;
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1786125" aria-label="PubMed reference 226">PubMed</a>&nbsp;
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 226" href="http://scholar.google.com/scholar_lookup?&amp;title=Neglect%20of%20contralateral%20visual%20stimuli%20in%20monkeys%20with%20unilateral%20striatal%20dopamine%20depletion&amp;journal=Behav.%20Brain%20Res.&amp;doi=10.1016%2FS0166-4328%2805%2980112-3&amp;volume=46&amp;pages=187-195&amp;publication_year=1991&amp;author=Apicella%2CP&amp;author=Legallet%2CE&amp;author=Nieoullon%2CA&amp;author=Trouche%2CE">
                    Google Scholar</a>&nbsp;
                </p></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[π in Other Universes (305 pts)]]></title>
            <link>https://azeemba.com/posts/pi-in-other-universes.html</link>
            <guid>38063536</guid>
            <pubDate>Sun, 29 Oct 2023 22:35:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://azeemba.com/posts/pi-in-other-universes.html">https://azeemba.com/posts/pi-in-other-universes.html</a>, See on <a href="https://news.ycombinator.com/item?id=38063536">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p>Everyone loves $\pi$. It’s usually the first irrational number someone encounters. $\pi$ is conceptually simple enough that it can be explained with basic geometry.</p><figure><figcaption><p>A circle with diameter 1 has a circumference of $\pi$. The circumference can be measured by slicing the circle and unwrapping it. The more slices that are added by moving the slider, the more accurate the measurement becomes. (Adapted from <a href="https://jsxgraph.uni-bayreuth.de/wiki/index.php?title=Approximation_of_the_circle_area">here</a>)</p></figcaption></figure><p>$\pi$ is the ratio between the circumference and the diameter. Usually, written as:</p><p>$$ C = 2\pi r $$</p><p>where $C$ is the circumference, $r$ is the radius (half of the diameter) and $\pi$ is famously $3.14159..$.</p><p>But why does $\pi$ have to have that value? Could it have some other value? The answer is yes! But to figure that out, we first have to talk about circles which are closely tied to the definition of $\pi$.</p><h2 id="circle">Circle</h2><p>Since the definition of $\pi$ depends on two properties of a circle (circumference, radius), it’s good to figure out what a circle even is. Mathematically, a circle is the collection of all points that are an equal distance from the center. So if the radius of a circle is 1, then the circle is the collection of all the points that are 1 unit distance away from the center.</p><p>In practical terms, a circle tells you all the points that have an equal “cost”. For example:</p><ul><li>If you start running from the center, then the circle represents all the farthest points you can reach in a given amount of time. Here the distance is measured in units of time.</li><li>If you start driving from the center, then the circle represents all the farthest points you can reach in a given amount of fuel. Here the distance is measured in units of fuel.</li></ul><p>But not all constant-cost functions will create the same shape. For example, suppose you are sailing on a windy day. Traveling in the direction of the wind will be easy but traveling orthogonal to the wind will require more effort and traveling against the wind will require significant effort. So for fixed effort, the farthest points you can travel will create an ellipse shifted against the direction of the wind.</p><figure><picture><source srcset="https://azeemba.com/posts/pi-in-other-universes/windy-sailing-effort_huec29f904673ee74b3c369a7ced6e6e03_94902_720x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/windy-sailing-effort_huec29f904673ee74b3c369a7ced6e6e03_94902_1080x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 500px)" type="image/webp"><source srcset="https://azeemba.com/posts/pi-in-other-universes/windy-sailing-effort_huec29f904673ee74b3c369a7ced6e6e03_94902_450x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/windy-sailing-effort_huec29f904673ee74b3c369a7ced6e6e03_94902_675x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 300px)" type="image/webp"><img src="https://azeemba.com/posts/pi-in-other-universes/windy-sailing-effort_huec29f904673ee74b3c369a7ced6e6e03_94902_1080x0_resize_box_3.png" width="100%"></picture><figcaption><p>If there is strong wind to the right, you can sail much farther to the right than to the left with the same effort. The red ellipse shows the points you can reach with equal effort. The black circle represents the farthest you can travel with equal effort when traveling on a day without any wind or current.<span>
<a href="https://www.desmos.com/calculator/gohgpumb54">[graph]</a></span></p></figcaption></figure><p>But does this cost-function (effort needed to sail) define a proper distance? Can we use it to measure radius and measure circumference? Seems kinda arbitrary to say yes or no. If time and fuel can all be “distances” in some situations then why couldn’t effort be a distance in this situation? Fortunately, we don’t have to make an arbitrary decision here since we can rely on a preexisting concept that defines what kinds of cost functions are valid distances.</p><h2 id="metrics">Metrics</h2><p>Mathematics can be seen as a logic game. You start with a set of assumptions and you come up with all the logical conclusions you can from that. Then, if someone else finds a situation that fits those assumptions, they can benefit from the pre-discovered logical conclusions. This means that if some conclusions require fewer assumptions, then those conclusions are more generally applicable.</p><p>As a result, mathematics goes through continuous cycles where mathematicians go back and trim down the assumptions needed for any mathematical system. For example, a lot of geometry from the times of the Greeks used only the single definition of distance: the Euclidean distance ($d = \sqrt{x^2 + y^2}$). We even named it after the Greek mathematician. Even Newton relied solely on Euclidean distance when he invented Calculus. Then, in the early 20th century, mathematicians realized that any function can be used as a distance function, as long as it followed some basic requirements. As long as the distance function followed those requirements, a lot of the established math would still work. So you could still do geometry and calculus and topology with just minor tweaks. Functions that fit these requirements are called <a href="https://en.wikipedia.org/wiki/Metric_space"><em>metrics</em></a>.</p><p>A function is a metric if it follows the following rules:</p><ol><li>The distance between a point and itself is always 0. If you don’t go anywhere, the distance traveled is 0.</li><li>The distance between any two different points is always positive</li><li>The distance from $a$ to $b$ is the same as the distance from $b$ to $a$</li><li>Going directly from $a$ to $c$ is at least as fast as going from $a$ to $b$ and then from $b$ to $c$</li></ol><p>Now, with these requirements, does “effort to sail” define a metric? The answer is no. We can probably debate 1 and 2 but 3 is very clearly not true. If $b$ is downwind of $a$, then the effort in one direction is smaller than the effort in the opposite direction.</p><p>Okay, so what functions are a metric? There are two classic examples: Manhattan distance and maximum distance.</p><h2 id="manhattan-distance">Manhattan Distance</h2><p>When you are driving in a city grid, you can’t drive diagonally. You have to drive in one grid direction and then the other. When you drive like this, the distance between two points is just $d = x + y$. This is popularly called the <a href="https://en.wikipedia.org/wiki/Manhattan_distance">Manhattan distance</a> or the taxicab distance.</p><p>One application of this metric is measuring accuracy. Suppose you are asked to predict the total population change of two cities. If you guess within 1,000 people, then you win a prize. You can visualize this by charting the population change of one city on the x-axis and the population change of the other city on the y-axis. Then a “circle” around your guess with a radius of 1,000 tells you the range where you can still win the prize.</p><figure><picture><source srcset="https://azeemba.com/posts/pi-in-other-universes/manhattan_hu6795c5e0f4a35a67254c451fae67197c_99743_720x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/manhattan_hu6795c5e0f4a35a67254c451fae67197c_99743_1080x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 500px)" type="image/webp"><source srcset="https://azeemba.com/posts/pi-in-other-universes/manhattan_hu6795c5e0f4a35a67254c451fae67197c_99743_450x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/manhattan_hu6795c5e0f4a35a67254c451fae67197c_99743_675x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 300px)" type="image/webp"><img src="https://azeemba.com/posts/pi-in-other-universes/manhattan_hu6795c5e0f4a35a67254c451fae67197c_99743_1080x0_resize_box_3.png" width="100%"></picture><figcaption><p>A circle using the Manhattan distance. The circle captures all the points that add up to 1,000. These are all the points that have a total inaccuracy of 1,000.<span>
<a href="https://www.desmos.com/calculator/a4okw60u43">[graph]</a></span></p></figcaption></figure><p>The circle looks like a rotated square!</p><p>The circle has radius of 1,000 but what is its circumference? If we use the Manhattan distance to measure the circumference then each line has a distance of 2,000 ($x + y = 1000 + 1000$) and since there are 4 lines, the circumference is 8,000. This means:</p><p>$$ C = 2 \pi r $$
$$ 8,000 = 2 \pi (1,000)$$
$$ 4 = \pi $$</p><p>In the universe where you measure distance using the Manhattan distance, the value of $\pi$ is 4!</p><h2 id="maximal-distance">Maximal Distance</h2><p>Another distance function that is a valid metric is the <a href="https://en.wikipedia.org/wiki/Chebyshev_distance">maximal distance</a>: $d = max(x,y)$. So instead of combining x and y, we use the larger of the two as the distance.</p><p>A lot of times when you are doing multiple things at the same time, it only matters how long the longest item takes. For example, suppose you need to prepare two ingredients for a dish, and you can prepare the ingredients in parallel. The amount of time you need to finish your dish is as long as the slowest ingredient.</p><p>Suppose for a cooking competition, you are required to finish cooking in exactly 60 minutes plus/minus 5 minutes. Then how much time can each ingredient take? If we use the x-axis to represent the time ingredient 1 takes and the y-axis to represent the time ingredient 2 takes, then we can draw a 5 minutes-wide circle that tells us how long each ingredient can take.</p><figure><picture><source srcset="https://azeemba.com/posts/pi-in-other-universes/p-infinity_hu6795c5e0f4a35a67254c451fae67197c_52805_720x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/p-infinity_hu6795c5e0f4a35a67254c451fae67197c_52805_1080x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 500px)" type="image/webp"><source srcset="https://azeemba.com/posts/pi-in-other-universes/p-infinity_hu6795c5e0f4a35a67254c451fae67197c_52805_450x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/p-infinity_hu6795c5e0f4a35a67254c451fae67197c_52805_675x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 300px)" type="image/webp"><img src="https://azeemba.com/posts/pi-in-other-universes/p-infinity_hu6795c5e0f4a35a67254c451fae67197c_52805_1080x0_resize_box_3.png" width="100%"></picture><figcaption><p>As long as both ingredients are finished between 55 and 65 minutes, we can win the cooking competition. The red ‘circle’ demarcates the area where we can still win.<span>
<a href="https://www.desmos.com/calculator/sixscn6qqc">[graph]</a></span></p></figcaption></figure><p>This circle looks like a regular square! The circle has radius 5 but what is its circumference? Each line has a distance of 10 and there are 4 lines so the circumference is 40.</p><p>$$ C = 2 \pi r $$
$$ 40 = 2 \pi 5 $$
$$ 4 = \pi $$</p><p>And again, in the universe where distance is measured using the maximal distance, the value of $\pi$ is 4!</p><h2 id="p-norm">p-norm</h2><p>Till now we have covered three distances: Euclidean, Manhattan, and Maximal. What other examples can we look at? Well, we have the <a href="https://en.wikipedia.org/wiki/Lp_space#The_p-norm_in_finite_dimensions">p-norm metric</a> which is a collection of infinite metrics defined as:</p><p>$$ d = \left(x^p + y^p\right)^{1/p}$$</p><p>where $p$ can be any number greater than or equal to 1.</p><p>The cool thing about p-norms are that they are a generalization of the metrics we covered before.
Euclidean, Manhattan, and maximal distances are specific examples of p-norms.
When $p$ is 1, we have the Manhattan distance. When $p$ is 2, we have the Euclidean distance. When $p$ is $\infty$, we have the maximal distance. So Manhattan distance and maximal distance are the extremes of the p-norms.</p><p>Here are what circles look like in different p-norms:</p><figure><figcaption><p>P-norms define a different metric for different values of $p$. Here we graph the “circles” of the respective p-norm metrics.</p></figcaption></figure><p>Just as we did before, the circumference and the value of $\pi$ can be calculated for the different p-norms. In previous examples, we were able to calculate the circumference just by looking at it, since they were straight lines but that strategy doesn’t work in general. So, for the rest of the shapes we need to caculate the circumferences computationally. We can write a program to tell a computer to walk around the circle and track the distance traveled. Fortunately, someone else has already done this <a href="http://www.jstor.org/stable/2687579">work</a> so we can refer to their results<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><table><thead><tr><th>p</th><th>$\pi$</th></tr></thead><tbody><tr><td>1</td><td>4</td></tr><tr><td>1.1</td><td>3.757…</td></tr><tr><td>2</td><td>3.141…</td></tr><tr><td>2.25</td><td>3.155…</td></tr><tr><td>3</td><td>3.259…</td></tr><tr><td>11</td><td>3.757…</td></tr><tr><td>$\infty$</td><td>4</td></tr></tbody></table><p>In addition to calculating these values, the paper linked above also proves that 3.14159 is the smallest value of $\pi$ possible for all the p-norms. Our regular $\pi$ is the smallest possible $\pi$ in the family of p-norms!</p><h2 id="all-metrics">All Metrics</h2><p>While there are infinitely many p-norm metrics, there are infinitely more metrics that are not p-norms. What are the values of $\pi$ in all the other metrics?</p><p>This <a href="https://arxiv.org/abs/2107.07715v2">article</a> by Sahoo proves that $\pi$ is between 3 and 4 for <em>all</em> metrics. We have seen the metrics that give us $\pi = 4$. What’s the metric that gives us $\pi = 3$?</p><p>The <a href="https://math.stackexchange.com/a/3549811/194741">answer</a> is a little gnarly<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p><p>$$ d = \frac{1}{2\sqrt{3}}\sum_{n=1}^6\left|x\sin\left(\frac{\pi n}{3}\right)+y\cos\left(\frac{\pi n}{3}\right)\right| $$</p><p>But drawing out the circle for this metric gives us a hexagon.</p><figure><picture><source srcset="https://azeemba.com/posts/pi-in-other-universes/hex-medium2_hufa459388e9cdd2daf1aebd501157aa11_64882_720x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/hex-medium2_hufa459388e9cdd2daf1aebd501157aa11_64882_1080x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 500px)" type="image/webp"><source srcset="https://azeemba.com/posts/pi-in-other-universes/hex-medium2_hufa459388e9cdd2daf1aebd501157aa11_64882_450x0_resize_q75_h2_box_3.webp, https://azeemba.com/posts/pi-in-other-universes/hex-medium2_hufa459388e9cdd2daf1aebd501157aa11_64882_675x0_resize_q75_h2_box_3.webp 1.5x" media="(min-width: 300px)" type="image/webp"><img src="https://azeemba.com/posts/pi-in-other-universes/hex-medium2_hufa459388e9cdd2daf1aebd501157aa11_64882_1080x0_resize_box_3.png" width="100%"></picture><figcaption><p>Circle with the ‘hexagon’ metric. Note that changes in the y-direction are weighed more (because of the cosine term) so no point on the ‘circle’ ever reaches to y=1.<span>
<a href="https://www.desmos.com/calculator/9xuveriguq">[graph]</a></span></p></figcaption></figure><p>By using the distance equation defined above, we can calculate the length of each line of the hexagon<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. This gives us a length of 1 for each line of the hexagon which means that the circumference is 6.</p><p>$$ 6 = C = 2 \pi r = 2 \pi (1) $$
$$ 3 = \pi $$</p><p>So next March, instead of just celebrating $\pi$-day on March 14th (3/14), feel free to celebrate $\pi$-month all through March. You just have to do the work of finding the appropriate metric for each day of the month.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Casio fx-CG50 calculator comes with Python built-in (114 pts)]]></title>
            <link>https://www.casio.com/intl/scientific-calculators/product.FX-CG50/</link>
            <guid>38063482</guid>
            <pubDate>Sun, 29 Oct 2023 22:28:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.casio.com/intl/scientific-calculators/product.FX-CG50/">https://www.casio.com/intl/scientific-calculators/product.FX-CG50/</a>, See on <a href="https://news.ycombinator.com/item?id=38063482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="productfeaturexf-4d752b8e0c">
    
    <div id="container-a1d0a75793">
<p id="text-40c1c69174">
    <h2><u><span>Features</span></u></h2>

</p>

    

</div>
<div id="container-c8b6a091e9">
    
    <div>
<p id="text-13d95b76ee">
    <h2>3D Graph</h2>

</p>

    

</div>
<div>
<p id="text-863af93265">
    <h3><b>3D graph types</b></h3>

</p>

    

</div>
<div id="container-b49ebe1771">
<p>Four types of 3D graphs (Sphere,Cylinder,Plane and Line) are available. It is easy to draw 3D graphs using templates.(An industry-first feature)</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy/container_2145155079_674725436/image.casiocoreimg.100{.width}.jpeg/1617330605992/img01.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img01.jpg" id="container-784c1db421" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy/container_2145155079_674725436/image.casiocoreimg.jpeg/1617330605992/img01.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy/container_2145155079_674725436/image.casiocoreimg.jpeg/1617330605992/img01.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>


<div id="container-672f687809">
    
    <div>
<p id="text-e67e7ba6ba">
    <h3><b>Draw and display up to three 3D graphs</b></h3>

</p>

    

</div>
<div>
<p>Recognize combinations of graphs and interactive relationships between two or three graphs mathematically.</p>

    

</div>
<div id="container-581206f6c0">
    
    <div id="container-2919c0eaec">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333049004/img06.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img06.jpg" id="image-bfac7b1ac5" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy/image_1315325768.casiocoreimg.jpeg/1617333049004/img06.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy/image_1315325768.casiocoreimg.jpeg/1617333049004/img06.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-dcc38b5c98">
    <h5>Three expressions available</h5>

</p>

    

</div>

    
</div>
<div id="container-45d2f476cc">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333054858/img07.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img07.jpg" id="image-2fa19ae628" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617333054858/img07.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617333054858/img07.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-f8e16fd597">
    <h5>Cylinder and plane expressions</h5>

</p>

    

</div>

    
</div>
<div id="container-2c89c50362">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333057546/img08.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img08.jpg" id="image-869626946e" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617333057546/img08.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1890217319/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617333057546/img08.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-6ed9218753">
    <h5>Cylinder and plane graphs</h5>

</p>

    

</div>

    
</div>

    
</div>

    
</div>
<div id="container-aedb88e658">
    
    <div>
<p id="text-95ed6d8579">
    <h3><b>Investigate the relationship between expressions and 3D graphs</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333844596/img09.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img09.jpg" id="container-9d771164bf" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617333844596/img09.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617333844596/img09.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1097391792/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333847234/img10.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img10.jpg" id="container-2f157923a7" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1097391792/image_1315325768.casiocoreimg.jpeg/1617333847234/img10.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1097391792/image_1315325768.casiocoreimg.jpeg/1617333847234/img10.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p>Select EXPRESS, VECTOR or POINTS format when in putting expression of 3D graphs.</p>

    

</div>
<div id="container-0731944c9b">
    
    <div id="container-723fb9fa88">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333977453/img11.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img11.jpg" id="image-d1128c3e6a" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy/image_1315325768.casiocoreimg.jpeg/1617333977453/img11.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy/image_1315325768.casiocoreimg.jpeg/1617333977453/img11.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-e06f5616e4">
    <h5>EXPRESS</h5>

</p>

    

</div>

    
</div>
<div id="container-d4674f1037">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_1562418896/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333979838/img12.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img12.jpg" id="image-7842207ac3" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617333979838/img12.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617333979838/img12.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-a7cd1c2d63">
    <h5>VECTOR FORMAT</h5>

</p>

    

</div>

    
</div>
<div id="container-6384744722">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_573108504/image_1315325768.casiocoreimg.100{.width}.jpeg/1617333984439/img13.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img13.jpg" id="image-bcd3e6703b" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617333984439/img13.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__922905936/container_copy_copy__1194870425/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617333984439/img13.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-f134877eb3">
    <h5>POINTS FORMAT</h5>

</p>

    

</div>

    
</div>

    
</div>

    
</div>
<div id="container-aad0850ecc">
    
    <div>
<p id="text-0a9352af07">
    <h3><b>Explore 3D graphs mathematically</b></h3>

</p>

    

</div>
<div>
<p id="text-c059e0d7b2">
    <h3><b>① Zoom in and zoom out</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334103536/img14.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img14.jpg" id="container-18c7cf07a4" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334103536/img14.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334103536/img14.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy__2055408557/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334107454/img15.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img15.jpg" id="container-6265673ea6" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334107454/img15.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1492396314/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334107454/img15.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-be24aac40f">
    
    <div>
<p id="text-6033aebc2e">
    <h3><b>② Vertical and horizontal rotation</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334788957/img16.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img16.jpg" id="container-d5ff7b21b9" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334788957/img16.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334788957/img16.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy__2055408557/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334792262/img17.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img17.jpg" id="container-5f93fac8df" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334792262/img17.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__15593410/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334792262/img17.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-bb7b941385">
    
    <div>
<p id="text-738b885102">
    <h3><b>③ Cross section</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__327943096/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334851000/img18.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img18.jpg" id="container-654a59ad6c" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__327943096/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334851000/img18.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__327943096/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334851000/img18.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-a1120a060e">
    
    <div>
<p id="text-5575a94906">
    <h3><b>④ X-axis,Y-axis, Z-axis view</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334888805/img19.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img19.jpg" id="container-d1e1fe3dee" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334888805/img19.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617334888805/img19.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy__2055408557/image_1315325768.casiocoreimg.100{.width}.jpeg/1617334891460/img20.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img20.jpg" id="container-1b392ddc49" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334891460/img20.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__2017809908/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617334891460/img20.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-d242c357f4">
    
    <div>
<p id="text-8a3ead1209">
    <h2>E-CON4 Application</h2>

</p>

    

</div>
<div>
<p>This feature, with a simple user interface, is effective for collecting data for use in classroom science and technology lessons.</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335022545/img21.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img21.jpg" id="container-60cfabbcf0" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617335022545/img21.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617335022545/img21.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy__2055408557/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335025023/img22.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img22.jpg" id="container-64223dff9b" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617335025023/img22.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1397521539/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617335025023/img22.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p>This feature has Auto-ID recognition, which enables drawing of graphs of collected data automatically with no complicated settings.</p>

    

</div>

    
</div>
<div id="container-0845ea947f">
    
    <div>
<p id="text-0e7a4c5acb">
    <h2>Catalog Function</h2>

</p>

    

</div>
<div>
<p>Select the desired command easily and quickly use the catalog function.</p>

    

</div>
<div id="container-78fecad208">
    
    <div id="container-f707cce758">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_/image_1315325768_cop.casiocoreimg.100{.width}.jpeg/1617335233317/img23.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img23.jpg" id="image-172a318140" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_/image_1315325768_cop.casiocoreimg.jpeg/1617335233317/img23.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_/image_1315325768_cop.casiocoreimg.jpeg/1617335233317/img23.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-61bf763aa9">
    <h5>History search</h5>

</p>

    

</div>

    
</div>
<div id="container-0ae23d5de3">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335239800/img24.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img24.jpg" id="image-0be72ad85e" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617335239800/img24.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_1562418896/image_1315325768.casiocoreimg.jpeg/1617335239800/img24.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-8e8359a6e4">
    <h5>History search</h5>

</p>

    

</div>

    
</div>
<div id="container-89055b425e">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335244309/img25.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img25.jpg" id="image-d196b8641a" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617335244309/img25.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy_714330041/container_copy_copy_/container_copy_copy_573108504/image_1315325768.casiocoreimg.jpeg/1617335244309/img25.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-58f3c9caf0">
    <h5>Category search</h5>

</p>

    

</div>

    
</div>

    
</div>

    
</div>
<div id="container-1462f174e7">
    
    <div>
<p id="text-98e047c410">
    <h2>Examination Mode</h2>

</p>

    

</div>
<div>
<p>This mode allows you to quickly prepare your calculator for exams. This mode restricts access to memory, programs, functions and applications, so that these features would not be available during exams.</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy_/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335352682/img26.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img26.jpg" id="container-ca6d9804a3" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617335352682/img26.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy_/image_1315325768.casiocoreimg.jpeg/1617335352682/img26.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy__2055408557/image_1315325768.casiocoreimg.100{.width}.jpeg/1617335355380/img27.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img27.jpg" id="container-ab988cb051" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617335355380/img27.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1602485120/container_copy_copy__2055408557/image_1315325768.casiocoreimg.jpeg/1617335355380/img27.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>


    
</div>
<div id="container-8bfb0bbbe7">
    
    <div>
<p id="text-e4f99a58d0">
    <h2>Enhance your lesson plans by linking the calculator to various devices.</h2>

</p>

    

</div>
<div>
<p id="text-d1e9f03e76">
    <h3><b>Peripherals</b></h3>

</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1051657777/container/image.casiocoreimg.100{.width}.jpeg/1617335501505/img28.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img28.jpg" id="container-a5118fdcc8" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1051657777/container/image.casiocoreimg.jpeg/1617335501505/img28.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1051657777/container/image.casiocoreimg.jpeg/1617335501505/img28.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-ee698f28e1">
    
    <div>
<p id="text-2086704b8c">
    <h2>Software (Manager)</h2>

</p>

    

</div>
<div id="container-f6c24e7c5e">
<p>Manager is a software program that emulates the operation of Graphing calculator fx-CG50. This enables teachers to prepare teaching materials (Activities) and present them in the classroom using a projector (Workshops).</p>

    

</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__911246953/container_2145155079_674725436/image.casiocoreimg.100{.width}.jpeg/1617335578192/img29.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img29.jpg" id="container-3272303dbb" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__911246953/container_2145155079_674725436/image.casiocoreimg.jpeg/1617335578192/img29.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__911246953/container_2145155079_674725436/image.casiocoreimg.jpeg/1617335578192/img29.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>

    
</div>
<div id="container-ca89d2d326">
    
    <div>
<p id="text-7147d229a6">
    <h3><b>Subscription Methods</b></h3>

</p>

    

</div>
<div id="container-2fe4fc6e1f">
    
    <div>
<p>There are two ways to subscribe: online or card.</p>

    

</div>
<div>
<p id="text-69e8aa02e7">
    <h3><b>fx-CG Manager PLUS Subscription</b><br>
</h3>

</p>

    

</div>
<div id="text-7c62b8f981"><p>for fx-CG Series</p><p>

• fx-CG50 Calculator Emulation<br>
for Windows<br>
for Mac</p></div>

    
</div>
<div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__833095439/container_2145155079_674725436/image.casiocoreimg.100{.width}.jpeg/1617335739323/img30.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img30.jpg" id="container-3d03b0d883" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__833095439/container_2145155079_674725436/image.casiocoreimg.jpeg/1617335739323/img30.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__833095439/container_2145155079_674725436/image.casiocoreimg.jpeg/1617335739323/img30.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p>fx-CG Manager PLUS Subscription for fx-CG20 Series license can utilize<br>
fx-CG Manager Subscription for fx-CG50 Series with the same lisence</p>

    

</div>

    
</div>
<div id="container-fb9843574c">
    
    <div>
<p id="text-bee998b42e">
    <h3><b>Licensing Opions</b></h3>

</p>

    

</div>
<div id="container-cd2e533ad3">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079/image.casiocoreimg.100{.width}.jpeg/1617336033207/img32.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img32.jpg" id="image-236056d3cc" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079/image.casiocoreimg.jpeg/1617336033207/img32.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079/image.casiocoreimg.jpeg/1617336033207/img32.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-f56ae5e28b">
    <h3><b>Card</b></h3>

</p>

    

</div>
<div id="text-d69de51f78">
    
<p>License expiration period 1 year</p>


</div>
<div>
<p>• FA-CG1SA(Single License)<br>
• FA-CG1SB(10 Licenses)<br>
• FA-CG1SC(30 Licenses)<br>
• FA-CG1SD(100 Licenses)</p>

    

</div>

    
</div>
<div id="container-5684d9d2aa">
    
    <div data-cmp-is="image" data-cmp-lazy="" data-cmp-lazythreshold="0" data-cmp-src="/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079_844620001/image.casiocoreimg.100{.width}.jpeg/1617336036091/img31.jpeg" data-asset="/content/dam/casio/global/calculator/scientific-calculators/graphic-model/fx-cg50/img31.jpg" id="image-0066172a6e" itemscope="" itemtype="http://schema.org/ImageObject">
	
		
		
			<picture>
				<!-- SP -->
				
				<!-- PC -->
				<source srcset="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079_844620001/image.casiocoreimg.jpeg/1617336036091/img31.jpeg" media="(min-width: 768px)" width="0" height="0">
				<!-- As for the src value, add PC image path as a default -->
				<img src="https://www.casio.com/content/experience-fragments/casio/en/product-info/calculator/product/f/fx/fxc/fx_cg50/fx-cg50/master/_jcr_content/root/container_copy_copy__1926382241/container_2145155079_844620001/image.casiocoreimg.jpeg/1617336036091/img31.jpeg" loading="lazy" alt="" width="0" height="0">
			</picture>
		
	
	
	
</div>
<div>
<p id="text-04a68b31d9">
    <h3><b>Online</b></h3>

</p>

    

</div>
<div id="text-b4550e680b">
    
<p>License expiration period 1 year</p>


</div>
<div>
<p>• FA-CG-1-W1A(Single License)<br>
• FA-CG1-W1B(10 Licenses)<br>
• FA-CG1-W1C(30 Licenses)<br>
• FA-CG1-W1D(100 Licenses)</p>

    

</div>
<div id="text-a18fc60695">
    
<p>License expiration period 3 years</p>


</div>
<div>
<p>• FA-CG1-W3A(Single License)<br>
• FA-CG1-W3B(10 Licenses)<br>
• FA-CG1-W3C(30 Licenses)<br>
• FA-CG1-W3D(100 Licenses)</p>

    

</div>

    
</div>


    
</div>
<div id="container-e5161ec672">
    
    <div>
<p id="text-d69c1d11f6">
    <h2>Basic Functions</h2>

</p>

    

</div>
<div>
<p>• Angle unit, Angle unit conversion (Deg, Rad, Gra)<br>
• Trigonometric functions, Inverse trigonometric functions<br>
• Hyperbolic functions, Inverse hyperbolic functions<br>
• Exponent functions, Logarithmic functions<br>
• Power functions (square root, cubic root, square, power, radical root)<br>
• Coordinate conversion (Pol, Rec)<br>
• Combination/Permutation (nCr, nPr)<br>
• Factorial, Inverse, Random numbers, Random sampling of an existing list, Fractions<br>
• Logical operations<br>
• Sexagesimal ↔ Decimal conversion<br>
• Matrix calculations<br>
• Vector calculations<br>
• Complex number calculations<br>
• Base-n calculations/conversions<br>
• List data calculations<br>
• Rounding<br>
• Display format<br>
• Conversion (pre-installed software)<br>
• Engineering symbol calculation<br>
• Engineering notation</p>

    

</div>

    
</div>
<div id="container-bc25c6acf2">
    
    <div>
<p id="text-af585f2143">
    <h2>Graphing</h2>

</p>

    

</div>
<div>
<p>• 3D Graph (pre-installed software)<br>
• Rectangular coordinate graphing,Polar coordinate graphing<br>
• Integration graph<br>
• Parametric function graphing, Inequality graphing<br>
• Trace, Zoom (box zoom, zoom in, zoom out, auto zoom)<br>
• Table and Graph<br>
• Dual Graph (table and graph, graph and graph)<br>
• Sketch (tangent line, normal line, inverse function)<br>
• Solve (root, minimum, maximum, intersection, integration: integral calculation improvement (real-time integral calculation), new integral calculation function (mixed integrals))<br>
• Dynamic graph<br>
• Conic section graph<br>
• Recursion graph<br>
• Picture Plot (pre-installed software)</p>

    

</div>

    
</div>
<div id="container-a6cf4e6f1c">
    
    <div>
<p id="text-76aef713aa">
    <h2>Statistics</h2>

</p>

    

</div>
<div>
<p>• List-based one-variable and two-variable statistical analysis<br>
• Statistical regression calculations<br>
• Statistical plot (scatter plot, xyLine, normal probability plot, histogram, box plot)<br>
• Statistical regression graphs (linear, med-med, quadratic, cubic, quartic, logarithmic, exponential, power, sinusoidal, logistic regression)<br>
• Advanced statistical calculations: tests (Z-test, t-test, χ²-test, F-test, ANOVA), intervals (Z-interval, t-interval), distributions<br>
• Pie chart<br>
• Bar graph</p>

    

</div>

    
</div>
<div id="container-a9b71c509b">
    
    <div>
<p id="text-23eecc55ae">
    <h2>Hardware</h2>

</p>

    

</div>
<div>
<p>• Power supply : Four AAA-size alkaline batteries or four nickel-metal hydride batteries<br>
• Approximate battery life (hours) : 140 (AAA-size alkaline batteries), 85 (nickel-metal hydride batteries) Assuming 5 minutes calculation and 55 minutes display per hour<br>
• Dot matrix display : 216 x 384 dots<br>
• Display capacity (characters) : 21 x 8<br>
• Internal operation digits : 15<br>
• Nested parentheses levels : 26<br>
• Data communication : 3-pin cable, USB cable<br>
• 3-pin serial port<br>
• USB port</p>

    

</div>


    
</div>

    
</div></div>]]></description>
        </item>
    </channel>
</rss>