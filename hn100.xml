<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sun, 22 Sep 2024 12:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Nextcloud: Open-Source Cloud Apps (150 pts)]]></title>
            <link>https://nextcloud.com/</link>
            <guid>41615102</guid>
            <pubDate>Sun, 22 Sep 2024 06:50:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nextcloud.com/">https://nextcloud.com/</a>, See on <a href="https://news.ycombinator.com/item?id=41615102">Hacker News</a></p>
Couldn't get https://nextcloud.com/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[It is hard to recommend Google Cloud (182 pts)]]></title>
            <link>https://ashishb.net/programming/google-cloud/</link>
            <guid>41614795</guid>
            <pubDate>Sun, 22 Sep 2024 05:21:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ashishb.net/programming/google-cloud/">https://ashishb.net/programming/google-cloud/</a>, See on <a href="https://news.ycombinator.com/item?id=41614795">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><h2 id="google-domains">Google Domains</h2><p>A year back, I had to migrate my domain after Google decided to shut down Google Domains decided to <a href="https://blog.pragmaticengineer.com/google-domains-to-shut-down/">shut down</a>.
I had to, not only, painfully setup multiple side-projects sub-domain mappings again on a new domain registrar but also re-verify my domain and re-create those mappings on <a href="https://ashishb.net/tech/how-to-deploy-side-projects-as-web-services-for-free/">Google Cloud Run</a>.</p><h2 id="google-container-registry">Google Container Registry</h2><p>Google Container Registry is <a href="https://cloud.google.com/artifact-registry/docs/transition/prepare-gcr-shutdown">shutting down</a> in 2025.
It has been replaced with a new project called Artifact Registry.
So, why is Container Registry being shut down?
Probably because it 10X cheaper than Artifact Registry.</p><p>I just spent multiple hours migrating side-projects from GCR to GAR.
It wasn’t easy.
Some <a href="https://decksaver.ashishb.net/">projects</a> were deployed multiple years back and are working perfectly fine.
Some other are <a href="https://musicsync.ashishb.net/">single-page homepages</a>.</p><p>The two migrations have been laborious.
While Google Cloud has made me jump hoops, there has been little upside in doing these migrations.</p><h2 id="google-cloud---great-engineering-good-product-terrible-strategy">Google Cloud - great engineering, good product, terrible strategy</h2><p>I strongly believe Google Cloud is a superior product to both AWS and <a href="https://ashishb.net/programming/how-to-deploy-docker-images-on-microsoft-azure/">Microsoft Azure</a>.</p><p>The UX is much simpler.
The primitives are much nicer and evolved compared to AWS.
The reliability while not as high as AWS is pretty close.</p><p>However, the continuous churn that I have experienced has made it hard to recommend it.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[They stole my voice with AI (391 pts)]]></title>
            <link>https://www.jeffgeerling.com/blog/2024/they-stole-my-voice-ai</link>
            <guid>41614490</guid>
            <pubDate>Sun, 22 Sep 2024 03:49:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.jeffgeerling.com/blog/2024/they-stole-my-voice-ai">https://www.jeffgeerling.com/blog/2024/they-stole-my-voice-ai</a>, See on <a href="https://news.ycombinator.com/item?id=41614490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Listen to <a href="https://www.youtube.com/watch?v=WHfPH-Kr9XU">this clip</a>:</p>

<p>
<video controls="" playsinline="">
  <source src="https://www.jeffgeerling.com/sites/default/files/elecrow-clip-geerling-voice-ezgif.com-video-to-mp4-converter.mp4" type="video/mp4">
  Your browser does not support the video tag.
</video>
</p>

<p>I don't know about you, but that sounds <a href="https://www.youtube.com/watch?v=UMofZIT9FcQ">pretty familiar</a>. I mean I <em>would</em> like you to subscribe to my YouTube channel. But that's the <a href="https://www.youtube.com/c/JeffGeerling">Jeff Geerling channel</a>, not <a href="https://www.youtube.com/watch?v=WHfPH-Kr9XU">Elecrow</a>, where the clip above is from. I never said the words that are in that video.</p>

<p>Someone emailed me a link to Elecrow's video and said it sounded <em>off</em>. I'm guessing at least some of the thousands of people who watched the video thought I agreed to voice some Elecrow videos, since I talk about some of the same topics on my channel.</p>

<p>I even reviewed one of their products a few years ago, <a href="https://www.youtube.com/watch?v=mvDQWST8aFM">the CrowPi 2</a>. I didn't have a bad relationship with them in the past. They make electronics and even Raspberry Pi accessories.</p>

<blockquote>
  <p>There's also a <a href="https://www.youtube.com/watch?v=UMofZIT9FcQ">video version of this blog post</a>, if you don't enjoy reading, and wish to hear the clip embedded above in context, for a direct comparison with my natural voice.</p>
</blockquote>

<p>And I don't know if I can prove it, I mean how can you? But I'm <em>pretty</em> sure they fed my YouTube videos into some AI voice clone tool, then used my voice to narrate multiple series of promotional tutorials, like <a href="https://www.youtube.com/playlist?list=PLwh4PlcPx2Ge-h-Pfsa7juFeWMgXmv8lc">this one on ESP32</a>, and <a href="https://www.youtube.com/playlist?list=PLwh4PlcPx2GcEcWVavHI4dwXw_ETM-H8i">this one on RP2040</a>.</p>

<p>That's... not cool.</p>

<p>I remember when <a href="https://www.nbcnews.com/tech/tech-news/scarlett-johansson-shocked-angered-openai-voice-rcna153180">OpenAI practically cloned Scarlett Johanssen's voice</a>, but I thought the fallout from that would lead to companies being careful about the AI voices they use for things like product demos and tutorials...</p>

<p>Apparently not.</p>

<p>I haven't decided what to do. I mean, like I said, I haven't had a problem with Elecrow in the past. I'm hoping beyond all hope it was an honest mistake and they didn't even realize it was my voice.</p>

<p>But beyond that, the worse thing is there isn't any legal precedent for unauthorized AI voice cloning, at least not that I'm aware of. There <em>is</em> precedent for not using someone's voice in commercial works without their consent. Look up <a href="https://grr.com/publications/hey-thats-my-voice-can-i-sue-them/">Midler vs. Ford</a>.</p>

<p>I don't know if I want to do anything with lawyers, because that costs money and right now I'm just trying to keep my old Camry running through the end of the year. And I'm not even sure non-consensual voice cloning is against YouTube's Terms of Service.</p>

<p>But the main thing is, I want to make a point—that's why I'm writing this post:</p>

<p><em>You can't just steal someone's voice or likeness, and slap it on your products or videos.</em></p>

<p>You should hire a voiceover artist, or pay a content creator to work with you. A lot of brands actually do that! Just... don't steal my voice and use it to promote your product.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[WP Engine is not WordPress (189 pts)]]></title>
            <link>https://wordpress.org/news/2024/09/wp-engine/</link>
            <guid>41613628</guid>
            <pubDate>Sun, 22 Sep 2024 00:16:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://wordpress.org/news/2024/09/wp-engine/">https://wordpress.org/news/2024/09/wp-engine/</a>, See on <a href="https://news.ycombinator.com/item?id=41613628">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<article>
	
	
	

	
	<hr>
	

	
	<div>
<p>It has to be said and repeated: <em>WP Engine is not WordPress</em>. My own mother was confused and thought <a href="https://wpengine.com/">WP Engine</a> was an official thing. Their branding, marketing, advertising, and entire promise to customers is that they’re giving you WordPress, but they’re not. And they’re profiting off of the confusion.</p>



<p><a href="https://www.youtube.com/watch?v=fnI-QcVSwMU">I spoke yesterday at WordCamp</a> about how <a href="https://www.silverlake.com/people/lee-wittlinger/">Lee Wittlinger</a> at <a href="https://www.silverlake.com/">Silver Lake</a>, a private equity firm with $102B assets under management, can hollow out an open source community. Today, I would like to offer a specific, technical example of how they break the trust and sanctity of our software’s promise to users to save themselves money so they can extract more profits from you.</p>



<p>WordPress is a content management system, and the content is <em>sacred</em>. Every change you make to every page, every post, is tracked in a revision system, just like the Wikipedia. This means if you make a mistake, you can <em>always</em> undo it. It also means if you’re trying to figure out why something is on a page, you can see precisely the history and edits that led to it. These revisions are stored in our database.</p>



<p>This is very important, it’s at the core of the user promise of protecting your data, and it’s why WordPress is architected and designed to never lose anything.</p>



<p><strong>WP Engine turns this off.</strong> They disable revisions because it costs them more money to store the history of the changes in the database, and they don’t want to spend that to protect your content. It strikes to the very heart of what WordPress does, and they shatter it, the integrity of your content. If you make a mistake, you have no way to get your content back, breaking the core promise of what WordPress does, which is manage and protect your content.</p>



<p>Here is a screenshot of <a href="https://wpengine.com/support/platform-settings/#Post_Revisions">their support page</a> saying they disable this across their 1.5 million WordPress installs.</p>



<figure><img fetchpriority="high" decoding="async" width="1024" height="864" src="https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03%E2%80%AFPM.png?resize=1024%2C864&amp;ssl=1" alt="" srcset="https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=1024%2C864&amp;ssl=1 1024w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=300%2C253&amp;ssl=1 300w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?resize=768%2C648&amp;ssl=1 768w, https://i0.wp.com/wordpress.org/news/files/2024/09/Screenshot-2024-09-21-at-4.05.03 https://wordpress.org/news/2024/09/wp-engine/PM.png?w=1472&amp;ssl=1 1472w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"></figure>



<p>They say it’s slowing down your site, but what they mean is they want to avoid paying to store that data. We tested revisions on <em>all</em> of the recommended hosts on WordPress.org, and <em>none</em> disabled revisions by default. <strong>Why is WP Engine the only one that does?</strong> They are strip-mining the WordPress ecosystem, giving our users a crappier experience so they can make more money.</p>



<p><strong>What WP Engine gives you is not WordPress</strong>, it’s something that they’ve chopped up, hacked, butchered to look like WordPress, but actually they’re giving you a cheap knock-off and charging you more for it.</p>



<p>This is one of the many reasons they are a cancer to WordPress, and it’s important to remember that unchecked, cancer will spread. WP Engine is setting a poor standard that others may look at and think is ok to replicate. We must set a higher standard to ensure WordPress is here for the next 100 years.</p>



<p>If you are a customer of “WordPress Engine,” you should <a href="https://wpengine.com/contact/">contact their support</a> immediately to at least get the 3 revisions they allow turned on so you don’t accidentally lose something important. Ideally, they should go to unlimited. <strong>Remember that you, the customer, hold the power; they are nothing without the money you give them.</strong> And as you vote with your dollars, consider literally any other WordPress host as WP Engine is the only one we’ve found that completely disables revisions by default.</p>
</div>
	
</article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What happened to the Japanese PC platforms? (204 pts)]]></title>
            <link>https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/</link>
            <guid>41612984</guid>
            <pubDate>Sat, 21 Sep 2024 22:06:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/">https://www.mistys-internet.website/blog/blog/2024/09/21/what-happened-to-the-japanese-pc-platforms/</a>, See on <a href="https://news.ycombinator.com/item?id=41612984">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p><em>(This was originally posted on a social media site; I’ve revised and updated it for my blog.)</em></p>

<p>The other day <a href="https://nex-3.com/">a friend</a> asked me a pretty interesting question: what <em>happened</em> to all those companies who made those Japanese computer platforms that were never released outside Japan? I thought it’d be worth expanding that answer into a full-size post.</p>

<h3>A quick introduction: the players</h3>

<p>It’s hard to remember these days, but there there used to be an incredible amount of variety in the computer space. There were a <em>lot</em> of different computer platforms, pretty much all of them totally incompatible with each other. North America settled on the IBM PC/Mac duopoly pretty early<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, but Europe still had plenty of other computers popular well into the 90s, and Japan had its own computers that essentially didn’t exist anywhere else.</p>

<p>So who were they? By the 16-bit computer era, there’s three I’m going to talk about today<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup>: NEC’s PC-98, Fujitsu’s FM Towns, and Sharp’s X68000. The PC-98 was far and away the biggest of those platforms, with the other two having a more niche market.</p>

<h3>The PC-98 in a time of transition</h3>

<p>First, a quick digression: what is this DOS thing?</p>

<p>The thing about DOS is that it’s a much thinner OS than what we think of in 2024. When you’re writing DOS software of any kind of complexity, you’re talking straight to the hardware, or to drivers that are specific to particular classes of hardware. When we talk about “DOS” in the west, we specifically mean “DOS on IBM compatible PCs”. PC-98 and FM Towns both had DOS-based operating systems, but their hardware was nothing at all like IBM compatible PCs and there was no level of software compatibility between them. The PC-98 was originally a DOS-based computer without a GUI of any kind - just like DOS-based IBM PCs. When we talk about “PC-98” games and software, what we really mean is DOS-based PC-98 software that only runs on that platform.</p>

<p>Windows software is very different from DOS in one important way: Windows incorporates a hardware abstraction layer. Software written for Windows APIs doesn’t need to be specific to particular hardware, and that set the stage for the major transition that was going to come.</p>

<p>NEC and Microsoft teamed up on porting Windows to the PC-98 platform. Both the PC-98 and the IBM PC use the same CPU, even though the rest of their hardware is very different, which made the port technically feasible. The first Windows release for PC-98 came out in 1992, but Windows didn’t really take off in a big way until Windows 95 in the mid-90s. And so, suddenly, for the first time software could run on both IBM PCs running Japanese language Windows <em>and</em> PC-98 running Windows.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup> Software developers didn’t have to do anything special to get that compatibility: it happened by default, so long as they were using the standard Windows software features and didn’t talk directly to the hardware.</p>

<p>Around the same time, NEC started making IBM-compatible PCs. As far as I can tell, they made both PC-98s and IBM PCs alongside each other for quite a few years. With Windows software not caring what the underlying hardware was, the distinction between “PC-98” and “PC” got a lot fuzzier. If you were buying a PC, you had no reason to buy a PC-98 unless you wanted to run DOS-based PC-98 software. If you just wanted that shiny new Windows software, why not buy the cheaper IBM PC that NEC would also sell you?</p>

<p>So, for the PC-98, the answer isn’t really that it <em>died</em> - it sort of faded away and merged into what every other system was becoming.</p>

<h3>The FM Towns</h3>

<p>The FM Towns had a similar transition. While it had a homegrown GUI-based OS called Towns OS, it was relatively primitive compared to Windows 3 and especially Windows 95. The FM Towns also used the same CPU as IBM PCs and the PC-98, which means Microsoft could work with Fujitsu to port their software to the platform. And, just like what happened with the PC-98, the platform became far less relevant and less distinctive when it was just another platform to run Windows software on. If you didn’t care about running the older FM Towns-specific software, why would you care about buying an FM Towns instead of any other IBM PC?</p>

<p>Fujitsu, just like NEC, made the transition to making standard Windows PCs and discontinued the FM Towns a few years later.</p>

<h3>The X68000 loses out in the CPU wars</h3>

<p>Unlike the other two platforms, the X68000 had a different CPU and a distinct homegrown OS. It used the 68000 series of processors from Motorola, which were incredibly popular in the 80s and 90s. The same CPU was used by the Mac until the mid 90s, the Amiga, and a huge number of home consoles and arcade boards. It was a powerful CPU, but when every other platform was looking for a way to merge with the Windows platform, they had a big problem: you simply couldn’t port Windows to the platform and get it to run regular Windows software because they didn’t use the same CPUs. Sharp were locked out. While they also switched to making Windows PCs in the 90s, they had no way to bring their existing users with them by giving them a transition path.</p>

<h3>The lure of multitasking</h3>

<p>Why did Windows win out, though? In the west we often credit Microsoft Office as the killer app, but it wasn’t a major player in Japan where Japanese language-specific word processors were huge in the market for years. I’d argue instead that multitasking was the killer feature.</p>

<p>In the DOS era, you ran one program at a time. You might have a lot of software you used, but you’d pick one program to use at a time. If you wanted to switch to something else, you’d have to save whatever you’re doing, quit, and open a completely different full-screen app. While competing platforms like the Mac<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup> had multitasking via their GUIs for years, Windows and especially Windows 3 is what brought it to the wider market.</p>

<p>If you’re going to be using more than one program at the same time, having a wider amount of software <em>that’s inter-compatible</em> becomes more important. I’d argue that multitasking is what nudged market consolidation onto a smaller number of computers. Windows, and especially Windows 95, became <em>very</em> hard for other platforms to compete with because its base of software was just so large. It made far more sense for NEC and Fujitsu to bring Windows to their users even if it meant losing the lock-in that their unique OSs and platform-specific software had gotten them.</p>

<h3>Shifts in the gaming market</h3>

<p>In the 16-bit era, the FM Towns and X68000 were doing great in the computer gaming niche. They had powerful 2D gaming hardware and a lot of very sophisticated action games. Their original games and ports of arcade games compared extremely well against what 16-bit consoles could do, giving them a reputation of being the real gamers' platforms. By 1994 though, they had a problem: the 32-bit consoles were out, which could do 2D games just as well as the FM Towns and X68000, and the consoles could also do 3D that blew away anything those computers could handle. Fujitsu and Sharp, meanwhile, just weren’t releasing new hardware that could keep up. The PC gaming niche had already been shrinking and moving towards consoles for a few years, and this killed off a lot of what was left.</p>

<p>I also suspect that Sony’s marketing for the PlayStation changed things significantly. Home computers had older players than the 16-bit consoles did, but Sony was marketing the PS1 towards those same older audiences. It probably made it easy for computer players to look at the new consoles and decide to move on.</p>

<h3>What about the 8-bit platforms?</h3>

<p>Japan had a variety of 8-bit computer platforms, some of which (like the MSX) were also well-known in western countries. While in Europe the 8-bit micros held on right into the 90s, and many users upgraded straight from 8-bit micros to Windows PCs, in Japan the 8-bit computers had already been supplanted by native 16-bit computing platforms before the Windows era. In some cases, these were 16-bit computers by the same manufacturers - both Sharp and NEC had been major players in the 8-bit computing era too. The MSX, meanwhile, had failed to produce either a 16-bit evolution of the platform or a 16-bit successor and so many of its users had already moved on by the time Windows 95 came out.</p>

<h3>So, in conclusion</h3>

<p>None of the 16-bit Japanese computer makers acutally died off - they just switched to making standard Windows PCs that were interchangeable with anything else out there. Microsoft took over that market just like they did everywhere else in the world, but at least the companies themselves survived better than the Commodores and Ataris of the world.</p>


</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flow Computing aims to boost CPUs with ‘parallel processing units’ (113 pts)]]></title>
            <link>https://spectrum.ieee.org/parallel-processing-unit</link>
            <guid>41612665</guid>
            <pubDate>Sat, 21 Sep 2024 21:04:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://spectrum.ieee.org/parallel-processing-unit">https://spectrum.ieee.org/parallel-processing-unit</a>, See on <a href="https://news.ycombinator.com/item?id=41612665">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-headline="Startup Says It Can Make a 100x Faster CPU"><p>In an era of fast-evolving <a href="https://spectrum.ieee.org/new-inference-chips" target="_blank">AI accelerators</a>, general purpose CPUs don’t get a lot of love. “If you look at the CPU generation by generation, you see incremental improvements,” says <a href="https://www.linkedin.com/in/timovaltonen/?originalSubdomain=fi" target="_blank">Timo Valtonen</a>, CEO and co-founder of Finland-based <a href="https://flow-computing.com/" target="_blank">Flow Computing</a>.<br></p><p>Valtonen’s goal is to put CPUs back in their rightful, ‘central’ role. In order to do that, he and his team are proposing a new paradigm. Instead of trying to speed up computation by putting 16 identical CPU cores into, say, a laptop, a manufacturer could put 4 standard CPU cores and 64 of Flow Computing’s so-called parallel processing unit (PPU) cores into the same footprint, and achieve up to 100 times better performance. Valtonen and his collaborators <a href="https://hc2024.hotchips.org/sponsors_courtyard/flow%20computing/" target="_blank">laid out their case</a> at the <a href="https://hc2024.hotchips.org/attendees/" rel="noopener noreferrer" target="_blank">Hot Chips</a> conference in August.</p><p>The PPU provides a speed-up in cases where the computing task is parallelizable, but a traditional CPU isn’t well equipped to take advantage of that parallelism, yet offloading to something like a GPU would be too costly.</p><p>“Typically, we say, ‘okay, parallelization is only worthwhile if we have a large workload,’ because otherwise the overhead kills lot of our gains,” says <a href="https://www.fernuni-hagen.de/pv/en/team/joerg.keller.shtml" target="_blank">Jörg Keller</a>, professor and chair of parallelism and VLSI at FernUniversität in Hagen, Germany, who is not affiliated with Flow Computing. “And this now changes towards smaller workloads, which means that there are more places in the code where you can apply this parallelization.”</p><p>Computing tasks can roughly be broken up into two categories: sequential tasks, where each step depends on the outcome of a previous step, and parallel tasks, which can be done independently. Flow Computing CTO and co-founder <a href="https://scholar.google.com/citations?user=LHgDIjUAAAAJ&amp;hl=fi" target="_blank">Martti Forsell</a> says a single architecture cannot be optimized for both types of tasks. So, the idea is to have separate units that are optimized for each type of task.</p><p>“When we have a sequential workload as part of the code, then the CPU part will execute it. And when it comes to parallel parts, then the CPU will assign that part to PPU. Then we have the best of both words,” Forsell says.</p><p>According to Forsell, there are four main requirements for a computer architecture that’s optimized for parallelism: tolerating memory latency, which means finding ways to not just sit idle while the next piece of data is being loaded from memory; sufficient bandwidth for communication between so-called threads, chains of processor instructions that are running in parallel; efficient synchronization, which means making sure the parallel parts of the code execute in the correct order; and low-level parallelism, or the ability to use the multiple functional units that actually perform mathematical and logical operations simultaneously. For Flow Computing new approach, “we have redesigned, or started designing an architecture from scratch, from the beginning, for parallel computation,” Forsell says.</p><p>Any CPU can be potentially upgraded</p><p>To hide the latency of memory access, the PPU implements multi-threading: when each thread calls to memory, another thread can start running while the first thread waits for a response. To optimize bandwidth, the PPU is equipped with a flexible communication network, such that any functional unit can talk to any other one as needed, also allowing for low-level parallelism. To deal with synchronization delays, it utilizes a proprietary algorithm called wave synchronization that is claimed to be up to 10,000 times more efficient than traditional synchronization protocols.<strong></strong></p><p>To demonstrate the power of the PPU, Forsell and his collaborators built a proof-of-concept FPGA implementation of their design. The team says that the FPGA performed identically to their simulator, demonstrating that the PPU is functioning as expected. The team performed <a href="https://link.springer.com/article/10.1007/s11227-021-03985-0" target="_blank">several</a>&nbsp;<a href="https://ieeexplore.ieee.org/document/10305463" rel="noopener noreferrer" target="_blank">comparison</a> studies between their PPU design and existing CPUS. “Up to 100x [improvement] was reached in our preliminary performance comparisons assuming that there would be a silicon implementation of a Flow PPU running at the same speed as one of the compared commercial processors and using our microarchitecture,” Forsell says.</p><p>Now, the team is working on a compiler for their PPU, as well as looking for partners in the CPU production space. They are hoping that a large CPU manufacturer will be interested in their product, so that they could work on a co-design. Their PPU can be implemented with any instruction set architecture, so any CPU can be potentially upgraded.</p><p>“Now is really the time for this technology to go to market,” says Keller. “Because now we have the necessity of energy efficient computing in mobile devices, and at the same time, we have the need for high computational performance.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Tetris shows promise in reducing PTSD symptoms (105 pts)]]></title>
            <link>https://www.legalreader.com/tetris-game-shows-promise-in-reducing-ptsd-symptoms/</link>
            <guid>41612367</guid>
            <pubDate>Sat, 21 Sep 2024 20:09:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.legalreader.com/tetris-game-shows-promise-in-reducing-ptsd-symptoms/">https://www.legalreader.com/tetris-game-shows-promise-in-reducing-ptsd-symptoms/</a>, See on <a href="https://news.ycombinator.com/item?id=41612367">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<h2><p>The 1980s video game proves to make a notable difference with intrusive memories.</p>
</h2>
				<hr>
								<p>A recent study led by researchers at Uppsala University has uncovered promising results for a simple yet effective intervention in alleviating symptoms of post-traumatic stress disorder (PTSD). The research, published in <em>BMC Medicine</em>, focuses on the use of video games, particularly the well-known Tetris game that has been around for decades, to help reduce intrusive memories, a core and sometimes debilitating symptom of the condition.</p>
<p>PTSD is often marked by intrusive, distressing memories or flashbacks, where individuals vividly recall traumatic events as if reliving them. These flashbacks can be debilitating, affecting a person’s overall mental health, sleep, concentration, and ability to engage in daily activities. Traditionally, treatments for PTSD involve therapy sessions, including cognitive behavioral therapy (CBT) or exposure therapy, often requiring multiple appointments with a trained clinician. However, this new research introduces a simpler, much less pricey intervention that individuals can easily access at home.</p>
<p>The study involved healthcare workers who had been exposed to traumatic stress while working on the frontlines during the COVID pandemic. The researchers were particularly interested in how a single session of guided treatment, including the game Tetris, could substantially reduce the frequency and severity of flashbacks.</p>
<p>Emily Holmes, a professor at Uppsala University and leader of the study, expressed optimism about the findings, stating, “It is possible to reduce the frequency of unpleasant and intrusive memories of trauma, and thereby also alleviate other PTSD symptoms. With just one guided treatment session, we saw positive effects that persisted after five weeks and even six months after treatment.”</p>
<figure id="attachment_13558351" aria-describedby="caption-attachment-13558351"><a href="https://www.legalreader.com/wp-content/uploads/2024/09/pexels-ron-lach-10487206.jpg"><img src="https://www.legalreader.com/wp-content/uploads/2024/09/pexels-ron-lach-10487206.jpg" alt="Tetris Game Shows Promise in Reducing PTSD Symptoms" width="481" height="320"></a><figcaption id="caption-attachment-13558351">Photo by Ron Lach from Pexels</figcaption></figure>
<p>The Tetris-based treatment leverages a concept known as “mental rotation,” a cognitive task central to the gameplay of <a href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-024-03569-8" target="_blank" rel="noopener noreferrer">Tetris</a>. In the game, players must mentally rotate and manipulate different-shaped blocks to fit them into a grid. The visual engagement and mental task of manipulating these shapes require significant cognitive resources, which, according to Holmes and her colleagues, “can disrupt the brain’s ability to replay intrusive memories. This distraction prevents the trauma-related flashbacks from becoming deeply ingrained.”</p>
<p>To test their theory, the researchers recruited 164 participants. All of them were healthcare professionals who had been exposed to traumatic experiences during the pandemic. The participants were divided into two groups. Both groups were asked to monitor their intrusive memories for one week, noting the frequency of flashbacks. Afterward, one group was asked to engage in a visual task—playing Tetris—while the control group participated in a non-visual task, such as listening to the radio.</p>
<p>The results were striking. At the beginning of the study, participants experienced an average of 15 flashbacks per week. Five weeks after the intervention, those in the control group, who had not engaged in the visual task, still experienced about five flashbacks per week. In contrast, the group that played <a href="https://www.news-medical.net/news/20240920/Study-shows-video-games-can-alleviate-PTSD-flashbacks.aspx" target="_blank" rel="noopener noreferrer">Tetris</a> game reported an average of just one flashback per week. Even more surprising, the benefits of the treatment persisted for months. Six months later, the group that played Tetris continued to show a significant reduction in the overall severity of PTSD symptoms. In contrast, the control group saw less improvement.</p>
<p>The effectiveness of the Tetris intervention was measured using the PTSD Checklist for DSM-5 (PCL-5), a widely recognized tool for assessing PTSD symptoms. The Tetris group showed almost half the PTSD symptoms compared to the control group. This result points to the potential of such a brief intervention as a valuable tool for early treatment.</p>
<p>The study also introduced the concept of a “cognitive vaccine,” a tool that could be used in the aftermath of trauma to prevent the onset of more severe PTSD symptoms. Much like how vaccines are used to prevent physical diseases, Holmes envisions a future where mental health tools, like the Tetris-based intervention, could be administered after traumatic events to prevent the development of PTSD.</p>
<p>This easy, innovative approach offers new hope for individuals struggling with PTSD, suggesting that even brief, targeted interventions can offer meaningful and lasting improvements.</p>
<h2>Sources:</h2>
<p><a href="https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-024-03569-8">A guided single session intervention to reduce intrusive memories of work-related trauma: a randomised controlled trial with healthcare workers in the COVID-19 pandemic</a></p>
<p><a href="https://www.news-medical.net/news/20240920/Study-shows-video-games-can-alleviate-PTSD-flashbacks.aspx">Study shows video games can alleviate PTSD flashbacks</a></p>
			</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sanding UI (695 pts)]]></title>
            <link>https://blog.jim-nielsen.com/2024/sanding-ui/</link>
            <guid>41612154</guid>
            <pubDate>Sat, 21 Sep 2024 19:36:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.jim-nielsen.com/2024/sanding-ui/">https://blog.jim-nielsen.com/2024/sanding-ui/</a>, See on <a href="https://news.ycombinator.com/item?id=41612154">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
          
          <p>One of the ways I like to do development is to build something, click around <em>a ton</em>, make tweaks, click around more, more tweaks, more clicks, etc., until I finally consider it done.</p>
<p>The <em>clicking around a ton</em> is the important part. If it’s a page transition, that means going back and forth a ton. Click, back button. Click, right-click context menu, “Back”. Click, in-app navigation to go back (if there is one). Click, keyboard shortcut to go back. Over and over and over. You get the idea.</p>
<p>It’s kind of a QA tactic in a sense, just click around and try to break stuff. But I like to think of it as being more akin to woodworking. You have a plank of wood and you run it through the belt sander to get all the big, coarse stuff smoothed down. Then you pull out the hand sander, sand a spot, run your hand over it, feel for splinters, sand it some more, over and over until you’re satisfied with the result.</p>
<p>With software, the fact is that sometimes there are just <a href="https://daverupert.com/2024/02/ui-states/">too many variables</a> to know and test and smooth out. So I click around, <a href="https://notes.jim-nielsen.com/#2023-03-08T1210">using the UI over and over</a>, until I finally cannot give myself any more splinters.</p>
<p>Just the other day, I was working on a list of radio options, pretty standard-fare stuff:</p>
<ul>
<li>Create a <code>&lt;label&gt;</code> with an associated <code>&lt;input type="radio"&gt;</code>.</li>
<li>Put them on the same row, center align them with a gap between the control and the label.</li>
<li>Etc.</li>
</ul>
<p>As an oldie who used to leverage floats in CSS, I’m still amazed when I can use flexbox to do this stuff — it’s so easy!</p>
<pre><code><span>&lt;<span>div</span> <span>class</span>=<span>"container"</span>&gt;</span>
  <span>&lt;<span>label</span> <span>for</span>=<span>"control"</span>&gt;</span>Foo<span>&lt;/<span>label</span>&gt;</span>
  <span>&lt;<span>input</span> <span>id</span>=<span>"control"</span> <span>type</span>=<span>"radio"</span>&gt;</span>
<span>&lt;/<span>div</span>&gt;</span>

<span>&lt;<span>style</span>&gt;</span><span>
    <span>.container</span> {
      <span>display</span>: flex;
      <span>flex-direction</span>: row;
      <span>align-items</span>: center;
      <span>gap</span>: .<span>5rem</span>;
    }
</span><span>&lt;/<span>style</span>&gt;</span>
</code></pre>
<p>As I was doin’ my thang — clicking around a bunch, trying to get some splinters — I realized there was a dead spot in the UI, a place between the radio and the label where clicking didn’t toggle the control like I expected.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-flexbox-animated.gif" width="172" height="135" alt="Animated gif of some radio inputs where the space between the control and the label doesn’t select the radio grouping.">

</p><p>“What the?” I thought. “I’ve got my <code>&lt;label&gt;</code> and <code>&lt;input&gt;</code> and associated <code>for</code> attribute, why isn’t this working?” Then I thought, “<code>gap</code> in my flex display must be the culprit!”</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-flexbox.png" width="312" height="159" alt="Screenshot of Chrome developer tools where an item has a flex layout with a CSS gap in between a label and an input.">

</p><p>Sure enough, it was. While flexbox had made it super easy to add some visual spacing between the control and its label, that spacing had become a dead zone of interaction even though it wasn’t my intention!</p>
<p>There’s probably a million different ways to solve this problem — because <a href="https://blog.jim-nielsen.com/2021/css-is-in-fact-awesome/">CSS is awesome</a> — but I just removed the <code>gap</code> and added some padding to my label, then voilà!</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox-padding.png" width="95" height="29" alt="Screenshot Chrome developer tools with a label that has a left padding.">

</p><p>Putting padding on the label, instead of the containing flexbox, made the whole thing clickable without a deadzone.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox.png" width="269" height="81" alt="Screenshot of the Chrome developer tools where an element has a flex layout but no gap.">

</p><p>A bunch more clicking around and things were working as expected.</p>
<p><img src="https://cdn.jim-nielsen.com/blog/2024/radios-non-flexbox-animated.gif" width="135" height="106" alt="Animated gif of some radio inputs where the space between the control and the label can be clicked and it selects the entire radio grouping.">

</p><p>It’s a small thing, but lots of small splinters lead to an agonizing experience.</p>
<p>So my recipe is: sand it, feel the grain, get a splinter, sand again, and repeat until smooth.</p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[What Is a Particle? (2020) (135 pts)]]></title>
            <link>https://www.quantamagazine.org/what-is-a-particle-20201112/</link>
            <guid>41612049</guid>
            <pubDate>Sat, 21 Sep 2024 19:20:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/what-is-a-particle-20201112/">https://www.quantamagazine.org/what-is-a-particle-20201112/</a>, See on <a href="https://news.ycombinator.com/item?id=41612049">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-role="selectable">
    <p>Given that everything in the universe reduces to particles, a question presents itself: What are particles?</p>
<p>The easy answer quickly shows itself to be unsatisfying. Namely, electrons, photons, quarks and other “fundamental” particles supposedly lack substructure or physical extent. “We basically think of a particle as a pointlike object,” said <a href="https://physics.berkeley.edu/people/faculty/mary-k-gaillard">Mary Gaillard</a>, a particle theorist at the University of California, Berkeley who predicted the masses of two types of quarks in the 1970s. And yet particles have distinct traits, such as charge and mass. How can a dimensionless point bear weight?</p>
<p>“We say they are ‘fundamental,’” said <a href="https://web.mit.edu/physics/people/faculty/wen_xiao-gang.html">Xiao-Gang Wen</a>, a theoretical physicist at the Massachusetts Institute of Technology. “But that’s just a [way to say] to students, ‘Don’t ask! I don’t know the answer. It’s fundamental; don’t ask anymore.’”</p>
<p>With any other object, the object’s properties depend on its physical makeup — ultimately, its constituent particles. But those particles’ properties derive not from constituents of their own but from mathematical patterns. As points of contact between mathematics and reality, particles straddle both worlds with an uncertain footing.</p>
<p>When I recently asked a dozen particle physicists what a particle is, they gave remarkably diverse descriptions. They emphasized that their answers don’t conflict so much as capture different facets of the truth. They also described two major research thrusts in fundamental physics today that are pursuing a more satisfying, all-encompassing picture of particles.</p>
<p>“‘What is a particle?’ indeed is a very interesting question,” said Wen. “Nowadays there is progress in this direction. I should not say there’s a unified point of view, but there’s several different points of view,<a id="back1"></a> and all look interesting.”</p>
<h2><a href="#Nanopoulos">A Particle Is a ‘Collapsed Wave Function’<sup>1</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot1-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The quest to understand nature’s fundamental building blocks began with the ancient Greek philosopher Democritus’s assertion that such things exist. Two millennia later, Isaac Newton and Christiaan Huygens debated whether light is made of particles or waves. The discovery of quantum mechanics some 250 years after that proved both luminaries right: Light comes in individual packets of energy known as photons, which behave as both particles and waves.</p>
<p>Wave-particle duality turned out to be a symptom of a deep strangeness. Quantum mechanics revealed to its discoverers in the 1920s that photons and other quantum objects are best described not as particles or waves but by abstract “wave functions” — evolving mathematical functions that indicate a particle’s probability of having various properties. The wave function representing an electron, say, is spatially spread out, so that the electron has possible locations rather than a definite one. But somehow, strangely, when you stick a detector in the scene and measure the electron’s location, its wave function suddenly “collapses” to a point, and the particle clicks at that position in the detector.</p>
<figure>
    <p><img width="1120" height="784" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle-WAVE.gif" alt="" decoding="async" loading="lazy"><img width="1120" height="784" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle-WAVE-MOBILE.gif" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>A particle is thus a collapsed wave function. But what in the world does that mean? Why does observation cause a distended<a id="back2"></a> mathematical function to collapse and a concrete particle to appear? And what decides the measurement’s outcome? Nearly a century later, physicists have no idea.</p>
<h2><a href="#Quinn">A Particle Is a ‘Quantum Excitation of a Field’<sup>2</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot2-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The picture soon got even stranger. In the 1930s, physicists realized that the wave functions of many individual photons collectively behave like a single wave propagating through conjoined electric and magnetic fields — exactly the classical picture of light discovered in the 19th century by James Clerk Maxwell. These researchers found that they could “quantize” classical field theory, restricting fields so that they could only oscillate in discrete amounts known as the “quanta” of the fields. In addition to &nbsp;photons — the quanta of light — Paul Dirac and others discovered that the idea could be extrapolated to electrons and everything else: According to quantum field theory, particles are excitations of quantum fields that fill all of space.</p>
<p>In positing the existence of these more fundamental fields, quantum field theory stripped particles of status, characterizing them as mere bits of energy that set fields sloshing. Yet despite the ontological baggage of omnipresent fields, quantum field theory became the lingua franca of particle physics because it allows researchers to calculate with extreme precision what happens when particles interact — particle interactions being, at base level, the way the world is put together.</p>

<p>As physicists discovered more of nature’s particles and their associated fields, a parallel perspective developed. The properties of these particles and fields appeared to follow numerical patterns. By extending these patterns, physicists were able to predict the existence of more particles. “Once you encode the patterns you observe into the mathematics, the mathematics is predictive; it tells you more things you might observe,” explained <a href="https://www.quantamagazine.org/roberto-peccei-and-helen-quinn-driving-around-stanford-in-a-clunky-jeep-20170615/">Helen Quinn</a>, an emeritus particle physicist at Stanford University.<br>
<a id="back3"></a><br>
The patterns also suggested a more abstract and potentially deeper perspective on what particles actually are.</p>
<h2><a href="#GlashowNeemanSternberg">A Particle Is an ‘Irreducible<br>
Representation of a Group’<sup>3</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot3-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Mark Van Raamsdonk remembers the beginning of the first class he took on quantum field theory as a Princeton University graduate student. The professor came in, looked out at the students, and asked, “What is a particle?”</p>
<p>“An irreducible representation of the Poincaré group,” a precocious classmate answered.</p>
<p>Taking the apparently correct definition to be general knowledge, the professor skipped any explanation and launched into an inscrutable series of lectures. “That entire semester I didn’t learn a single thing from the course,” said <a href="https://phas.ubc.ca/~mav/vanraamsdonk.html">Van Raamsdonk</a>, who’s now a respected theoretical physicist at the University of British Columbia.</p>
<p>It’s the standard deep answer of people in the know: Particles are “representations” of “symmetry groups,” which are sets of transformations that can be done to objects.</p>
<p>Take, for example, an equilateral triangle. Rotating it by 120 or 240 degrees, or reflecting it across the line from each corner to the midpoint of the opposite side, or doing nothing, all leave the triangle looking the same as before. These six symmetries form a group. The group can be expressed as a set of mathematical matrices — arrays of numbers that, when multiplied by coordinates of an equilateral triangle, return the same coordinates. Such a set of matrices is a “representation” of the symmetry group.</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_SYMMETRY.V3.svg" alt="" decoding="async" loading="lazy"><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_SYMMETRY-MOBILE.V2.svg" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Similarly, electrons, photons and other fundamental particles are objects that essentially stay the same when acted on by a certain group. Namely, particles are representations of the Poincaré group: the group of 10 ways of moving around in the space-time continuum. Objects can shift in three spatial directions or shift in time; they can also rotate in three directions or receive a boost in any of those directions. In 1939, the mathematical physicist Eugene Wigner <a href="https://www.jstor.org/stable/1968551?seq=1">identified particles</a> as the simplest possible objects that can be shifted, rotated and boosted.</p>
<p>For an object to transform nicely under these 10 Poincaré transformations, he realized, it must have a certain minimal set of properties, and particles have these properties. One is energy. Deep down, energy is simply the property that stays the same when the object shifts in time. Momentum is the property that stays the same as the object moves through space.</p>
<p>A third property is needed to specify how particles change under combinations of spatial rotations and boosts (which, together, are rotations in space-time). This key property is “spin.” At the time of Wigner’s work, physicists already knew particles have spin, a kind of intrinsic angular momentum that determines many aspects of particle behavior, including whether they act like matter (as electrons do) or as a force (like photons). Wigner showed that, deep down, “spin is just a label that particles have because the world has rotations,” said <a href="https://www.quantamagazine.org/nima-arkani-hamed-and-the-future-of-physics-20150922/">Nima Arkani-Hamed</a>, a particle physicist at the Institute for Advanced Study in Princeton, New Jersey.</p>
<p>Different representations of the Poincaré group are particles with different numbers of spin labels, or degrees of freedom that are affected by rotations. There are, for example, particles with three spin degrees of freedom. These particles rotate in the same way as familiar 3D objects. All matter particles, meanwhile, have two spin degrees of freedom, nicknamed “spin-up” and “spin-down,” which rotate differently. If you rotate an electron by 360 degrees, its state will be inverted, just as an arrow, when moved around a 2D Möbius strip, comes back around pointing the opposite way.</p>
<figure>
    <p><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_MOBIUS.V2.svg" alt="" decoding="async" loading="lazy"><img src="https://www.quantamagazine.org/wp-content/uploads/2020/11/what-is-a-particle_MOBIUS-MOBILE.svg" alt="" decoding="async" loading="lazy">    </p>
            <figcaption>
            <p>Samuel Velasco/Quanta Magazine</p>
        </figcaption>
    </figure>

<p>Elementary particles with one and five spin labels also appear in nature. Only a representation of the Poincaré group with four spin labels seems to be missing.</p>
<p>The correspondence between elementary particles and representations is so neat that some physicists — like Van Raamsdonk’s professor — equate them. Others see this as a conflation. “The representation is not the particle; the representation is a way of describing certain properties of the particle,” said <a href="http://physics.bu.edu/people/show/slg">Sheldon Glashow</a>, a Nobel Prize-winning particle <a id="back4"></a>theorist and professor emeritus at Harvard University and Boston University. “Let us not confuse the two.”</p>
<h2><a href="#Wen1">‘Particles Have So Many Layers’<sup>4</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot4-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Whether there’s a distinction or not, the relationship between particle physics and group theory grew both richer and more complicated over the course of the 20th century. The discoveries showed that elementary particles don’t just have the minimum set of labels needed to navigate space-time; they have extra, somewhat superfluous labels as well.</p>
<p>Particles with the same energy, momentum and spin behave identically under the 10 Poincaré transformations, but they can differ in other ways. For instance, they can carry different amounts of electric charge. As “the whole particle zoo” (as Quinn put it) was discovered in the mid-20th century, additional distinctions between particles were revealed, necessitating new labels dubbed “color” and “flavor.”</p>

<p>Just as particles are representations of the Poincaré group, theorists came to understand that their extra properties reflect additional ways they can be transformed. But instead of shifting objects in space-time, these new transformations are more abstract; they change particles’ “internal” states, for lack of a better word.</p>
<p>Take the property known as color: In the 1960s, physicists ascertained that quarks, the elementary constituents of atomic nuclei, exist in a probabilistic combination of three possible states, which they nicknamed “red,” “green” and “blue.” These states have nothing to do with actual color or any other perceivable property. It’s the number of labels that matters: Quarks, with their three labels, are representations of a group of transformations called SU(3) consisting of the infinitely many ways of mathematically mixing the three labels.</p>
<p>While particles with color are representations of the symmetry group SU(3), particles with the internal properties of flavor and electric charge are representations of the symmetry groups SU(2) and U(1), respectively. Thus, the <a href="https://www.quantamagazine.org/a-new-map-of-the-standard-model-of-particle-physics-20201022/">Standard Model of particle physics</a> — the quantum field theory of all known elementary particles and their interactions — is often said to represent the symmetry group SU(3) × SU(2) × U(1), consisting of all combinations of the symmetry operations in the three subgroups. (That particles also transform under the Poincaré group is apparently too obvious to even mention.)</p>

<p>The Standard Model reigns half a century after its development. Yet it’s an incomplete description of the universe. Crucially, it’s missing the force of gravity, which quantum field theory can’t fully handle. Albert Einstein’s general theory of relativity separately describes gravity as curves in the space-time fabric. Moreover, the Standard Model’s three-part SU(3) × SU(2) × U(1) structure raises questions. To wit: “Where the hell did all this come from?” as <a href="https://physics.tamu.edu/directory/dimitri-nanopoulos/">Dimitri Nanopoulos</a> put it. “OK, suppose it works,” continued Nanopoulos, a particle physicist at Texas A&amp;M University who was active during the Standard Model’s early days. “But what is this thing? It cannot <a id="back5"></a>be three groups there; I mean, ‘God’ is better than this — God in quotation marks.”</p>
<h2><a href="#Gaillard">Particles ‘Might Be Vibrating Strings’<sup>5</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot5_b-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>In the 1970s, Glashow, Nanopoulos and others tried fitting the SU(3), SU(2) and U(1) symmetries inside a single, larger group of transformations, the idea being that particles were representations of a single symmetry group at the beginning of the universe. (As symmetries broke, complications set in.) The most natural candidate for such a “grand unified theory” was a symmetry group called SU(5), but experiments soon ruled out that option. Other, less appealing possibilities <a href="https://www.quantamagazine.org/no-proton-decay-means-grand-unification-must-wait-20161215/">remain in play</a>.</p>
<p>Researchers placed even higher hopes in string theory: the idea that if you zoomed in enough on particles, you would see not points but one-dimensional vibrating strings. You would also see six extra spatial dimensions, which string theory says are curled up at every point in our familiar 4D space-time fabric. The geometry of the small dimensions determines the properties of strings and thus the macroscopic world. “Internal” symmetries of particles, like the SU(3) operations that transform quarks’ color, obtain physical meaning: These operations map, in the string picture, onto rotations in the small spatial dimensions, just as spin reflects rotations in the large dimensions. “Geometry gives you symmetry gives you particles, and all of this goes together,” Nanopoulos said.</p>
<p>However, if any strings or extra dimensions exist, they’re too small to be detected experimentally. In their absence, other ideas have blossomed. Over the past decade, two approaches in particular have attracted the brightest minds in contemporary fundamental physics.<a id="back6"></a> Both approaches refresh the picture of particles yet again.</p>
<h2><a href="#Wen2">A Particle Is a ‘Deformation of the Qubit Ocean’<sup>6</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot6-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>The first of these research efforts goes by the slogan “it-from-qubit,” which expresses the hypothesis that everything in the universe — all particles, as well as the space-time fabric those particles stud like blueberries in a muffin — arises out of quantum bits of information, or qubits. Qubits are probabilistic combinations of two states, labeled 0 and 1. (Qubits can be stored in physical systems just as bits can be stored in transistors, but you can think of them more abstractly, as information itself.) When there are multiple qubits, their possible states can get tangled up, so that each one’s state depends on the states of all the others. Through these contingencies, a small number of entangled qubits can encode a huge amount of information.</p>
<p>In the it-from-qubit conception of the universe, if you want to understand what particles are, you first have to understand space-time. In 2010, Van Raamsdonk, a member of the it-from-qubit camp, wrote <a href="https://arxiv.org/abs/1005.3035">an influential essay</a> boldly declaring what various calculations suggested. He argued that entangled qubits might stitch together the space-time fabric.</p>
<p>Calculations, thought experiments and toy examples going back decades suggest that space-time has “holographic” properties: It’s possible to encode all information about a region of space-time in degrees of freedom in one fewer dimension — often on the region’s surface. “In the last 10 years, we’ve learned a lot more about how this encoding works,” Van Raamsdonk said.</p>
<p>What’s most surprising and fascinating to physicists about this holographic relationship is that space-time is bendy because it includes gravity. But the lower-dimensional system that encodes information about that bendy space-time is a purely quantum system that lacks any sense of curvature, gravity or even geometry. It can be thought of as a system of entangled qubits.</p>
<p>Under the it-from-qubit hypothesis, the properties of space-time — its robustness, its symmetries — essentially come from the way 0s and 1s are braided together. The long-standing quest for a quantum description of gravity becomes a matter of identifying the qubit entanglement pattern that encodes the particular kind of space-time fabric found in the actual universe.</p>

<p>So far, researchers know much more about how this all works in toy universes that have negatively curved, saddle-shaped space-time — mostly because they’re relatively easy to work with. Our universe, by contrast, is positively curved. But researchers have found, to their surprise, that anytime negatively curved space-time pops up like a hologram, particles come along for the ride. That is, whenever a system of qubits holographically encodes a region of space-time, there are always qubit entanglement patterns that correspond to localized bits of energy floating in the higher-dimensional world.</p>
<p>Importantly, algebraic operations on the qubits, when translated in terms of space-time, “behave just like rotations acting on the particles,” Van Raamsdonk said. “You realize there’s this picture being encoded by this nongravitational quantum system. And somehow in that code, if you can decode it, it’s telling you that there are particles in some other space.”</p>
<p>The fact that holographic space-time always has these particle states is “actually one of the most important things that&nbsp;distinguishes these holographic systems from other quantum systems,” he said. “I think nobody really understands the reason why holographic models have&nbsp;this property.”</p>
<p>It’s tempting to picture qubits having some sort of spatial arrangement that creates the holographic universe, just as familiar holograms project from spatial patterns. But in fact, the qubits’ relationships and interdependencies might be far more abstract, with no real physical arrangement at all. “You don’t need to talk about these 0s and 1s living in a particular space,” said <a href="https://web.mit.edu/physics/people/faculty/engelhardt_netta.html">Netta Engelhardt</a>, a physicist at MIT who recently <a href="https://breakthroughprize.org/News/60">won a New Horizons in Physics Prize</a> for <a href="https://www.quantamagazine.org/the-most-famous-paradox-in-physics-nears-its-end-20201029/">calculating the quantum information content of black holes</a>. “You can talk about the abstract existence of 0s and 1s, and how an operator might act on 0s and 1s, and these are all much more abstract mathematical relations.”</p>
<p>There’s clearly more to understand. But if the it-from-qubit picture is right, then particles are holograms, just like space-time. Their truest definition <a id="back7"></a>is in terms of qubits.</p>
<h2><a href="#ArkaniHamed">‘Particles Are What We Measure in Detectors’<sup>7</sup></a></h2>
<figure>
    <p><img width="1120" height="250" src="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b.png" alt="" decoding="async" loading="lazy" srcset="https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b.png 1120w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b-520x116.png 520w, https://www.quantamagazine.org/wp-content/uploads/2020/11/spot7_b-768x171.png 768w" sizes="(max-width: 1120px) 100vw, 1120px">    </p>
    </figure>

<p>Another camp of researchers who call themselves “amplitudeologists” seeks to return the spotlight to the particles themselves.</p>
<p>These researchers argue that quantum field theory, the current lingua franca of particle physics, tells far too convoluted a story. Physicists use quantum field theory to calculate essential formulas called scattering amplitudes, some of the most basic calculable features of reality. When particles collide, amplitudes indicate how the particles might morph or scatter. Particle interactions make the world, so the way physicists test their description of the world is to compare their scattering amplitude formulas to the outcomes of particle collisions in experiments such as Europe’s Large Hadron Collider.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Infineon's CO2 Sensor Monitors Indoor Air Quality (132 pts)]]></title>
            <link>https://www.allaboutcircuits.com/news/infineons-co2-sensor-precisely-monitors-indoor-air-quality/</link>
            <guid>41611965</guid>
            <pubDate>Sat, 21 Sep 2024 19:08:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.allaboutcircuits.com/news/infineons-co2-sensor-precisely-monitors-indoor-air-quality/">https://www.allaboutcircuits.com/news/infineons-co2-sensor-precisely-monitors-indoor-air-quality/</a>, See on <a href="https://news.ycombinator.com/item?id=41611965">Hacker News</a></p>
Couldn't get https://www.allaboutcircuits.com/news/infineons-co2-sensor-precisely-monitors-indoor-air-quality/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[LHC experiments at CERN observe quantum entanglement at the highest energy yet (124 pts)]]></title>
            <link>https://home.cern/news/press-release/physics/lhc-experiments-cern-observe-quantum-entanglement-highest-energy-yet</link>
            <guid>41611613</guid>
            <pubDate>Sat, 21 Sep 2024 18:09:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://home.cern/news/press-release/physics/lhc-experiments-cern-observe-quantum-entanglement-highest-energy-yet">https://home.cern/news/press-release/physics/lhc-experiments-cern-observe-quantum-entanglement-highest-energy-yet</a>, See on <a href="https://news.ycombinator.com/item?id=41611613">Hacker News</a></p>
<div id="readability-page-1" class="page"><p>
          
            Artist’s impression of a quantum-entangled pair of top quarks. (Image: CERN)
          
        </p><div>
        <p>Quantum entanglement is a fascinating feature of quantum physics – the theory of the very small. If two particles are quantum-entangled, the state of one particle is tied to that of the other, no matter how far apart the particles are. This mind-bending phenomenon, which has no analogue in classical physics, has been observed in a wide variety of systems and has found several important applications, such as quantum cryptography and quantum computing. In 2022, the <a href="https://www.nobelprize.org/prizes/physics/2022/summary/">Nobel Prize in Physics</a> was awarded to Alain Aspect, John F. Clauser and Anton Zeilinger for groundbreaking experiments with entangled photons. These experiments confirmed the predictions for the manifestation of entanglement <a href="https://home.cern/news/news/physics/fifty-years-bells-theorem">made by the late CERN theorist John Bell</a> and pioneered quantum information science.</p>

<p>Entanglement has remained largely unexplored at the high energies accessible at particle colliders such as the <a href="https://www.home.cern/science/accelerators/large-hadron-collider">Large Hadron Collider</a> (LHC). In an <a href="https://www.nature.com/articles/s41586-024-07824-z">article</a> published today in <em>Nature</em>, the <a href="https://home.cern/science/experiments/atlas">ATLAS</a> collaboration reports how it succeeded in observing quantum entanglement at the LHC for the first time, between fundamental particles called top quarks and at the highest energies yet. First reported by ATLAS in <a href="https://atlas.web.cern.ch/Atlas/GROUPS/PHYSICS/CONFNOTES/ATLAS-CONF-2023-069/">September 2023</a> and since confirmed by a <a href="https://arxiv.org/abs/2406.03976">first</a> and a <a href="https://arxiv.org/abs/2409.11067">second</a> observation made by the <a href="https://home.cern/science/experiments/cms">CMS</a> collaboration, this result has opened up a new perspective on the complex world of quantum physics.</p>

<p>"While particle physics is deeply rooted in quantum mechanics, the observation of quantum entanglement in a new particle system and at much higher energy than previously possible is remarkable,” says ATLAS spokesperson Andreas Hoecker. “It paves the way for new investigations into this fascinating phenomenon, opening up a rich menu of exploration as our data samples continue to grow."</p>

<p>The ATLAS and CMS teams observed quantum entanglement between a top quark and its <a href="https://home.cern/science/physics/antimatter">antimatter</a> counterpart. The observations are based on a <a href="https://link.springer.com/article/10.1140/epjp/s13360-021-01902-1">recently proposed method</a> to use pairs of top quarks produced at the LHC as a new system to study entanglement.</p>

<p>The top quark is the heaviest known fundamental particle. It normally decays into other particles before it has time to combine with other quarks, transferring its spin and other quantum traits to its decay particles. Physicists observe and use these decay products to infer the top quark’s spin orientation.</p>

<p>To observe entanglement between top quarks, the ATLAS and CMS collaborations selected pairs of top quarks from data from proton–proton collisions that took place at an energy of 13 teraelectronvolts during the second run of the LHC, between 2015 and 2018. In particular, they looked for pairs in which the two quarks are simultaneously produced with low particle momentum relative to each other. This is where the spins of the two quarks are expected to be strongly entangled.</p>

<p>The existence and degree of spin entanglement can be inferred from the angle between the directions in which the electrically charged decay products of the two quarks are emitted. By measuring these angular separations and correcting for experimental effects that could alter the measured values, the ATLAS and CMS teams each observed spin entanglement between top quarks with a statistical significance larger than <a href="https://home.cern/resources/faqs/five-sigma">five standard deviations</a>.</p>

<p>In its <a href="https://arxiv.org/abs/2409.11067">second study</a>, the CMS collaboration also looked for pairs of top quarks in which the two quarks are simultaneously produced with high momentum relative to each other. In this domain, for a large fraction of top quark pairs, the relative positions and times of the two top quark decays&nbsp;are predicted to be such that classical exchange of information by particles traveling at no more than the speed of light is excluded, and CMS observed spin entanglement between top quarks also in this case.</p>

<p>“With measurements of entanglement and other quantum concepts in a new particle system and at an energy range beyond what was previously accessible, we can test the <a href="https://home.cern/science/physics/standard-model">Standard Model</a> of particle physics in new ways and look for signs of new physics that may lie beyond it.” says CMS spokesperson Patricia McBride.</p>

<p>Read more:</p>

<ul>
	<li><a href="https://www.nature.com/articles/s41586-024-07824-z">ATLAS <em>Nature</em> paper</a></li>
	<li><a href="https://arxiv.org/abs/2406.03976">CMS first study</a></li>
	<li><a href="https://arxiv.org/abs/2409.11067">CMS second study</a></li>
</ul>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Applied Mathematical Programming (176 pts)]]></title>
            <link>https://web.mit.edu/15.053/www/AMP.htm</link>
            <guid>41611571</guid>
            <pubDate>Sat, 21 Sep 2024 18:00:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://web.mit.edu/15.053/www/AMP.htm">https://web.mit.edu/15.053/www/AMP.htm</a>, See on <a href="https://news.ycombinator.com/item?id=41611571">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[What 10k Hours of Coding Taught Me: Don't Ship Fast (114 pts)]]></title>
            <link>https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast</link>
            <guid>41610832</guid>
            <pubDate>Sat, 21 Sep 2024 16:13:53 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast">https://sotergreco.com/what-10000-hours-of-coding-taught-me-dont-ship-fast</a>, See on <a href="https://news.ycombinator.com/item?id=41610832">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="post-content-wrapper"><p>I’ve been an engineer for over 7 years now. I have worked on countless projects in backend, frontend, and DevOps. I don’t consider myself a great engineer; there are people out there who are not only smarter but also more experienced. Over the years, I have learned some tricks to help me climb the programming ladder, allowing me to build software that is reliable and easy to work with.</p>
<p>Being slow has made me code faster, ship more, and be more productive in general. This didn’t come only from years of coding but also from life lessons and my religion. As an Orthodox Christian, you have to always be slow and not rush your moves.</p>
<h2 id="heading-the-1-problem-with-software">The #1 Problem with Software</h2>
<p>Most people, when they start to code, think that great engineers are magicians who build applications in a unique way that no one can understand. That is very far from the truth. If you actually take a look at great engineers' code, you will find it very simple and easy to navigate and understand.</p>
<p>Your application doesn’t need to be fast, fancy, or use cutting-edge technology for you to be considered a good programmer. Managers also make that mistake. They hire people based on things that are far from the truth.</p>
<p>Giving coding tests where you have to build an application from scratch is a terrible way to judge someone's skills. Whiteboard interviews are actually better than coding challenges that give you 3 days to complete because at least they take a look at your IQ and your way of thinking.</p>
<p>Now, let's talk about the #1 problem that everyone should focus on but often overlooks:</p>
<p><strong>Developer Experience</strong></p>
<p>This is the most important thing in the entire project 99% of the time. Because everybody wants to ship fast to make money, but they end-up building 90% of the application in 1 month and the last 10% takes them 3 months to finish.</p>
<p>Developers are also hyped up for new projects so they try to take the quick dopamine to just have something to showcase as fast as possible and make there managers happy as well.</p>
<p>They end-up making there managers happy, yet in the long-run everybody is panicking and they are considering refactoring or even building the application from scratch after 4-5 years.</p>
<p>That’s why actually creating features becomes really hard and even harder to push them to production. This creates a snowball effect.  </p>
<p>Let’s take a look at 2 code examples. We have 2 controllers that get the trending users from our database and attach emojis to them. This is from one of my open-source projects <a target="_blank" href="http://eporanger.xyz/">reporanger.xyz</a>.</p>
<p>This is the controller that is being called from the routes. In there we have all the functionality as well as a try-catch block to check for any errors as well.</p>
<pre><code><span>// users.controller.ts</span>
<span>const</span> getTrendingUsers = <span>async</span> (_req: Request, res: Response, _next: NextFunction) =&gt; {
  <span>try</span> {
    <span>const</span> events = <span>await</span> GithubEvent.find({
      where: { event_date: MoreThan(<span>new</span> <span>Date</span>(<span>Date</span>.now() - <span>24</span> * <span>60</span> * <span>60</span> * <span>1000</span>)) },
      order: { event_size: <span>'DESC'</span> },
      take: <span>3</span>,
    });
    <span>const</span> users = <span>await</span> Username.find({ where: { id: In(events.map(<span>(<span>event</span>) =&gt;</span> event.username_id)) } });
    <span>const</span> topUsers = <span>await</span> getTopUsers(<span>3</span>);
    <span>const</span> trendingUsers = <span>await</span> <span>Promise</span>.all(
      users.map(<span>async</span> (user) =&gt; ({
        ...user,
        emoji: <span>await</span> emojiService.getEmoji(user.score, topUsers),
      })),
    );
    res.status(<span>200</span>).json({
      status: <span>200</span>,
      message: <span>'Trending users fetched successfully'</span>,
      data: trendingUsers,
      error: <span>''</span>,
      success: <span>true</span>,
    });
  } <span>catch</span> (error) {
    res.status(<span>500</span>).json({
      status: <span>500</span>,
      message: <span>'Error fetching trending users'</span>,
      data: <span>null</span>,
      error: error.message,
      success: <span>false</span>,
    });
  }
};
</code></pre>
<p>Here is the same controller but we’ve used one simple principle: <strong>Unique Responsibility</strong></p>
<p>We spitted our code in 4 smaller re-usable files:<br><code>user.controller.ts</code><br><code>user.service.ts</code><br><code>async.util.ts</code><br><code>response.util.ts</code></p>
<p>This help’s us in many more ways than we can understand.</p>
<ol>
<li><p>We can re-use the <code>user.service.ts</code> everywhere in our application we want. For example on a cron-job we can do <code>usernameService.getTrendingUsers();</code></p>
</li>
<li><p>We removed every try-catch block to make the code cleaner. We also log every error (<code>logger('error', error);</code>). This way, we can easily create an error service later that stores all errors in the database for future use-cases.</p>
</li>
<li><p>We have unified responses for all of our controller with the <code>resFn</code> <strong>,</strong> this is really important because we make sure that all of the request will return that same response by just using a simple generic as you can see below.</p>
</li>
<li><p>Developing a new controller is now 10X easier, because our coding architecture is seamless across our entire application. Even if another developer wrote code it wouldn’t make a difference on the coding style.</p>
</li>
</ol>
<pre><code><span>// user.controller.ts</span>
<span>const</span> getTrendingUsers = asyncFn(<span>async</span> (_req: Request, res: Response, _next: NextFunction) =&gt; {
  <span>const</span> trendingUsers = <span>await</span> usernameService.getTrendingUsers();
  resFn(res, {
    status: <span>200</span>,
    message: <span>'Trending users fetched successfully'</span>,
    data: trendingUsers,
    error: <span>''</span>,
    success: <span>true</span>,
  });
});

<span>// user.service.ts</span>
<span>const</span> getTrendingUsers = <span>async</span> () =&gt; {
  <span>const</span> events = <span>await</span> GithubEvent.find({
    where: { event_date: MoreThan(<span>new</span> <span>Date</span>(<span>Date</span>.now() - <span>24</span> * <span>60</span> * <span>60</span> * <span>1000</span>)) },
    order: { event_size: <span>'DESC'</span> },
    take: <span>3</span>,
  });
  <span>const</span> users = <span>await</span> Username.find({ where: { id: In(events.map(<span>(<span>event</span>) =&gt;</span> event.username_id)) } });
  <span>const</span> topUsers = <span>await</span> getTopUsers(<span>3</span>);
  <span>const</span> usersWithEmoji = <span>await</span> <span>Promise</span>.all(
    users.map(<span>async</span> (user) =&gt; ({
      ...user,
      emoji: <span>await</span> emojiService.getEmoji(user.score, topUsers),
    })),
  );
  <span>return</span> usersWithEmoji;
};

<span>// async.util.ts</span>
<span>export</span> <span>const</span> asyncFn = <span>(<span>fn: asyncPropsFunction</span>) =&gt;</span> <span>async</span> (req: Request, res: Response, next: NextFunction) =&gt; {
  <span>try</span> {
    <span>await</span> fn(req, res, next);
  } <span>catch</span> (error) {
    logger(<span>'error'</span>, error);
    next(error);
  }
};

<span>// response.util.ts</span>
<span>export</span> <span>const</span> resFn = <span>(<span>res: Response, { status, error, data, message, success }: IResponse&lt;<span>any</span>&gt;</span>) =&gt;</span> {
  <span>const</span> suc = success !== <span>undefined</span> ? success : <span>true</span>;

  res.status(status).json({
    error,
    data,
    message,
    success: suc,
    status,
  });
};

<span>// response.interface.ts</span>
<span>export</span> <span>interface</span> IResponse&lt;T&gt; {
  status: <span>number</span>;
  message: <span>string</span>;
  data: T | <span>any</span>;
  error: <span>string</span>;
  success: <span>boolean</span>;
}
</code></pre>
<p>Now imagine if we didn’t implement a good architecture from the beginning and wanted to change something small across the application in the future. Even if we just wanted to log our errors, we would have to go to all of our controllers and add <code>logger('error', error);</code>. Or if we wanted to add a sixth field to our response, for example, <code>metadata</code>. It would be a nightmare.</p>
<h2 id="heading-do-the-refactoring-first">Do the Refactoring First</h2>
<p>Refactoring should be done before you write your code. What I mean by this is that eventually, every application needs refactoring. Refactoring a relatively big software, for example, with over 70,000 lines of code, can take 30-40 hours and also create a lot of errors and bugs in the process.</p>
<p>You might end up breaking the application or spending 20 more hours testing it. Also, when you reach a size this large, the refactoring won’t be as good as if you did it in the beginning.</p>
<p>What I propose is to spend your first 40-50 hours planning and refactoring. Just create a few controllers, brainstorm how that would scale in the future, refactor, and then continue.</p>
<p>Yes, your manager might scream in the beginning because you spent 50 hours coding and have almost nothing to showcase except a good architecture that will scale that no-one understand. But if you have the option to do it, then do it. It will save a ton of headaches for not only you but future developers as well.</p>
<p>Unit testing is also really important. Don’t be crazy with it just have at least 60% coverage and you are good to go. It will save you tones of bugs in the future.</p>
<h2 id="heading-pre-commit-checks">Pre-commit Checks</h2>
<p>This is very important. For JavaScript/TypeScript projects, we have Husky, but there are many alternatives for every language or framework out there. Husky is a tool that runs some commands before you commit your code. If got throw an error, the commit won't pass. Here is an example <code>.husky</code> configuration from <a target="_blank" href="http://reporanger.xyz/">reporanger.xyz</a>.</p>
<ol>
<li><p>Lint Check</p>
</li>
<li><p>Run Tests</p>
</li>
<li><p>Prettify</p>
</li>
</ol>
<p>This 3 simple steps will make your codebase. 10X better.</p>
<pre><code><span>#!/bin/sh</span>
npx eslint --max-warnings=0 src api/src || {
  <span>echo</span> <span>"ESLint check failed. Commit aborted."</span>
  <span>exit</span> 1
}

<span>cd</span> ./api &amp;&amp; npx jest || {
  <span>echo</span> <span>"Tests failed. Commit aborted."</span>
  <span>exit</span> 1
}

<span>cd</span> .. &amp;&amp; npx prettier --write .
git update-index --again
</code></pre>
<h2 id="heading-in-a-nutshell">In a nutshell</h2>
<p>There are many things you could do to improve your code. But the things that I mentioned are not even hard to implement. Especially now with LLM’s the problem is that you are bored to do them not that you can’t.</p>
<p>Throw boredom out of the window and you will get many blessings. Start coding with love and not for money. If you do that, you will make more money, make your co-workers happy and your managers will thank you.</p>
<h3 id="heading-because-coding-is-not-writing-it-is-architecture"><em>Because Coding is not writing, it is Αrchitecture.</em></h3>
<p>Thanks for reading, and I hope you found this article helpful. If you have any questions, feel free to email me at <a target="_blank" href="mailto:x@sotergreco.com"><strong>x@sotergreco.com</strong></a><strong>, and I will respond.</strong></p>
<p>You can also keep up with my latest updates by checking out my X here: <a target="_blank" href="http://x.com/sotergreco"><strong>x.com/sotergreco</strong></a></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Omega-3 intake counteracts symptoms of anxiety and depression in mice (251 pts)]]></title>
            <link>https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</link>
            <guid>41610619</guid>
            <pubDate>Sat, 21 Sep 2024 15:31:33 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/">https://www.psypost.org/omega-3-fatty-acid-intake-counteracts-symptoms-of-stress-induced-anxiety-and-depression-in-mice/</a>, See on <a href="https://news.ycombinator.com/item?id=41610619">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="psypo-463511331"><p><a href="https://news.google.com/publications/CAAqBwgKMLz2gwsw-5CAAw" aria-label="Follow PsyPost on Google News"><img decoding="async" src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" data-src="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_250,h_85/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png" alt="Follow PsyPost on Google News" data-srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w" data-sizes="(max-width: 510px) 100vw, 510px" width="250" height="85" srcset="https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_510/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1.png 510w, https://sp-ao.shortpixel.ai/client/to_webp,q_glossy,ret_img,w_300/https://www.psypost.org/wp-content/uploads/2024/02/follow-on-google-news-1-300x100.png 300w"></a></p></div><p>A study on mice found that adding omega-3 polyunsaturated fatty acids to their diets effectively counteracts depressive and anxiety-like behaviors induced by stress. Not only did the supplementation reduce these stress-induced symptoms, but it also lowered anxiety levels in mice that were not exposed to stress. These findings, published in <a href="https://www.sciencedirect.com/science/article/pii/S2352289524000420"><em>Neurobiology of Stress</em></a>, suggest that omega-3 fatty acids may have protective mental health benefits.</p><p>Omega-3 polyunsaturated fatty acids are essential fats that the body cannot produce, meaning they must be obtained through food. There are three main types of omega-3s: alpha-linolenic acid (ALA), found in plant oils, and eicosapentaenoic acid (EPA) and docosahexaenoic acid (DHA), primarily found in fish and seafood. These fats play a key role in maintaining brain function, preserving the integrity of cell membranes, and reducing inflammation throughout the body.</p><p>Omega-3s are widely recognized for their cardiovascular benefits, such as lowering blood pressure and reducing the risk of heart disease. They are equally important for mental health. Research indicates that omega-3s may alleviate symptoms of depression and anxiety, likely due to their anti-inflammatory properties and their role in maintaining brain health.</p><p>Several recent rodent studies have shown that incorporating these fatty acids into the diet can help counteract some of the negative effects of chronic stress, particularly during critical developmental periods. Omega-3s are most abundant in fatty fish like salmon and tuna, as well as in plant sources such as flaxseeds, walnuts, and chia seeds.</p><p>Study author Tatyana Strekalova and her colleagues wanted to explore whether exposing young mice to prolonged stress would induce behaviors similar to anxiety and depression in humans, and if supplementing the diet with omega-3 fatty acids would help prevent the development of these symptoms. Chronic stress was induced through exposure to ultrasound frequencies, simulating emotional stress that could lead to depressive-like symptoms. This method is an established way to model stress-induced depression in animals, which is used to better understand how these conditions develop in humans.</p><p>The experiments were conducted using 40 C57BL/6 male mice, each one month old. This strain of mice is commonly used in research because of their genetic uniformity and their susceptibility to diet-related conditions, such as obesity and diabetes. They are frequently used in studies on neurobiology, immunology, and cancer, making them ideal for this experiment. The mice were housed individually, with unlimited access to food and water.</p><p>The researchers divided the mice into four groups of ten. One group served as a control and received a regular diet without exposure to stress. The second group was subjected to chronic stress in the form of unpredictable ultrasound frequencies for 21 days, without any dietary supplementation. The third group received omega-3 fatty acids in their diet but was not exposed to stress. The fourth group was both exposed to stress and given the omega-3 supplement. The supplement included 0.55 mg/kg/day each of EPA and DHA, matching the recommended dosage of omega-3s for humans, scaled appropriately for mice.</p><p>After the 21-day period of stress exposure, the mice underwent several behavioral tests designed to measure symptoms analogous to human depression and anxiety. These tests included the sucrose preference test, which assesses anhedonia (the loss of interest in pleasurable activities), the novel cage test, the dark-light box test, and the open field test, which measure anxiety and exploratory behaviors. Once the behavioral tests were completed, the mice were killed, and their blood and tissues were analyzed to assess the biological effects of stress and omega-3 supplementation.</p><p>Mice that were exposed to ultrasound stress but received no dietary supplements showed significant anxiety- and depression-like behaviors. They displayed reduced sucrose consumption, indicating anhedonia, and exhibited less exploratory behavior in the tests. Furthermore, their blood samples revealed elevated levels of corticosterone, a hormone linked to stress responses.</p><p>The researchers also detected increased expression of TNF and interleukin-1 beta (IL-1β) genes in the brain, both of which are markers of inflammation. Inflammation in the brain is associated with various neurological disorders and can exacerbate conditions like depression and anxiety. The enhanced gene expression suggests that chronic stress had triggered an inflammatory response in these mice, leading to changes in their brain function and behavior.</p><p>In contrast, the mice that were exposed to stress but received omega-3 supplementation did not show the same degree of behavioral and physiological changes. They continued to drink sucrose, indicating they were less affected by stress-induced anhedonia, and they explored their environment more freely during the tests. Their levels of corticosterone and inflammatory markers, including TNF and IL-1β, were also lower than those in the stressed mice without supplementation.</p><p>These findings suggest that omega-3 fatty acids may protect against the harmful effects of chronic stress by reducing inflammation in the brain. Interestingly, even the mice that were not exposed to stress but received omega-3 supplements showed fewer anxiety-like behaviors compared to the control group, highlighting the broad mental health benefits of these fatty acids.</p><p>“Chronic omega-3 intake counteracted depressive- and anxiety-like behaviors in a US model of juvenile depression in mice [mice exposed to chronic stress as juveniles using ultrasound]. These effects likely stem from the anti-inflammatory properties of the supplement, suggesting potential therapeutic applications in juvenile depression,” the study authors concluded.</p><p>The study demonstrates the protective effects of omega-3 fatty acid supplements in mice exposed to chronic stress. However, it should be emphasized that this study was done on mice, not on humans. While mice and humans share many physiological similarities, there are significant differences between the two species. The effects observed in this study may not necessarily translate directly to human patients, and further research is needed to confirm whether omega-3 supplements would have the same benefits in people.</p><p>The paper, “<a href="https://doi.org/10.1016/j.ynstr.2024.100646">Omega-3 alleviates behavioral and molecular changes in a mouse model of stress-induced juvenile depression,</a>” was authored by Tatyana Strekalova, Daniel Radford-Smith, Isobel K. Dunstan, Anna Gorlova, Evgeniy Svirin, Elisaveta Sheveleva, Alisa Burova, Sergey Morozov, Aleksey Lyundup, Gregor Berger, Daniel C. Anthony, and Susanne Walitza.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Scaling up linear programming with PDLP (185 pts)]]></title>
            <link>https://research.google/blog/scaling-up-linear-programming-with-pdlp/</link>
            <guid>41609670</guid>
            <pubDate>Sat, 21 Sep 2024 12:57:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://research.google/blog/scaling-up-linear-programming-with-pdlp/">https://research.google/blog/scaling-up-linear-programming-with-pdlp/</a>, See on <a href="https://news.ycombinator.com/item?id=41609670">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-gt-publish-date="20240920">
                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="vflng">Classic <a href="https://en.wikipedia.org/wiki/Linear_programming" target="_blank" rel="noopener noreferrer">linear programming</a> (LP) problems are one of the most foundational problems in computer science and operations research. With extensive applications across numerous sectors of the global economy, such as manufacturing, networking, and other fields, LP has been the cornerstone of mathematical programming and has significantly influenced the development of today’s sophisticated modeling and algorithmic frameworks for data-driven decision making. If there's something to optimize, there's a good chance LP is involved.</p><p data-block-key="c5c0o">Since the late 1940s, LP solving has evolved significantly, with the <a href="https://en.wikipedia.org/wiki/Simplex_algorithm" target="_blank" rel="noopener noreferrer">simplex method</a> by Dantzig and various <a href="https://en.wikipedia.org/wiki/Interior-point_method" target="_blank" rel="noopener noreferrer">interior-point methods</a> being the most prevalent techniques. Today's advanced commercial LP solvers utilize these methods but face challenges in scaling to very large instances due to computational demands. In response to this limitation, <a href="https://en.wikipedia.org/wiki/Category:First_order_methods" target="_blank" rel="noopener noreferrer">first-order methods</a> (FOMs) have gained traction for large-scale LP problems.</p><p data-block-key="3ip58">With the above in mind, we introduce our solver PDLP (<a href="https://link.springer.com/article/10.1007/s10851-010-0251-1" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> enhanced for LP), a new FOM–based LP solver that significantly scales up our LP solving capabilities. Utilizing <a href="https://en.wikipedia.org/wiki/Matrix_multiplication#Definitions" target="_blank" rel="noopener noreferrer">matrix-vector multiplication</a> rather than <a href="https://en.wikipedia.org/wiki/Matrix_decomposition" target="_blank" rel="noopener noreferrer">matrix factorization</a>, PDLP requires less memory and is more compatible with modern computational technologies like GPUs and distributed systems, offering a scalable alternative that mitigates the memory and computational inefficiencies of traditional LP methods. PDLP is open-sourced in Google’s <a href="https://github.com/google/or-tools" target="_blank" rel="noopener noreferrer">OR-Tools</a>. This project has been in development since 2018 [<a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">1</a>, <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">2</a>, <a href="https://epubs.siam.org/doi/full/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">3</a>], and we are proud to announce that it was co-awarded the prestigious <a href="https://www.mathopt.org/?nav=boh" target="_blank" rel="noopener noreferrer">Beale — Orchard-Hays Prize</a> at the <a href="https://ismp2024.gerad.ca/" target="_blank" rel="noopener noreferrer">International Symposium of Mathematical Programming</a> in July 2024. This accolade is one of the highest honors in the field of computational optimization, awarded every three years by the <a href="https://www.mathopt.org/" target="_blank" rel="noopener noreferrer">Mathematical Optimization Society</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">LP and first-order methods for LP</h2><p data-block-key="covcv">Scaling the methods used in today’s state of the art LP solvers presents significant challenges. The primary computational limitations for both methods relate to matrix factorization required for solving linear equations, introducing two key challenges as problem sizes grow:</p><ol><li data-block-key="ekud4"><i>Memory overflows:</i> LP solvers that use the simplex method (such as Google's <a href="https://en.wikipedia.org/wiki/GLOP" target="_blank" rel="noopener noreferrer">GLOP</a>) employ <a href="https://en.wikipedia.org/wiki/LU_decomposition" target="_blank" rel="noopener noreferrer">LU factorization</a>, and solvers that use the interior point method use <a href="https://en.wikipedia.org/wiki/Cholesky_decomposition" target="_blank" rel="noopener noreferrer">Cholesky factorization</a>. For both these methods the resulting factorization uses considerably more memory than the LP instance itself.</li><li data-block-key="3dv18"><i>Hardware-related challenges:</i> Both methods face difficulties leveraging modern computing architectures, such as GPUs or distributed systems, because the sparse matrix factorization step usually requires highly sequential operations.</li></ol><p data-block-key="3ac05">Given the above limitations associated with traditional LP methods, FOMs have emerged as a promising alternative for tackling large-scale LP problems. Unlike methods that rely on matrix factorization, FOMs utilize gradient information to iteratively update their solutions, with the primary computational requirement being matrix-vector multiplication. This distinction means that FOMs require only the storage of the LP instance itself, without needing additional memory to store factorized forms. Additionally, advances in FOMs for machine learning and deep learning have enhanced their scalability, <a href="https://arxiv.org/abs/1606.04838" target="_blank" rel="noopener noreferrer">making them highly efficient</a> on modern computing platforms such as GPUs and distributed computing. This scalability and reduced memory dependency make FOMs particularly suitable for large and complex LP tasks where traditional methods may falter.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="vflng">Restarted primal-dual hybrid gradient for LP</h2><p data-block-key="a2f41"><a href="https://optimization-online.org/2010/06/2646/" target="_blank" rel="noopener noreferrer">Primal-dual hybrid gradient</a> (PDHG) is widely recognized for its application in image processing. When applied to LP, PDHG's primary computational demand involves matrix-vector multiplication, eliminating the need for matrix factorizations. This makes PDHG particularly efficient for large-scale computational tasks, but it is not reliable in solving LP. For example, in a benchmark of 383 instances, PDHG can only solve <a href="https://proceedings.neurips.cc/paper/2021/file/a8fbbd3b11424ce032ba813493d95ad7-Paper.pdf" target="_blank" rel="noopener noreferrer">113 instances to moderate accuracy</a>.</p><p data-block-key="4m87g">To enhance PDHG’s reliability in solving LP problems, we have developed a modified approach called <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">restarted PDHG</a>. This version uses a two-loop structure where PDHG is run until a restarting condition is triggered, after which the average of the PDHG iterations is computed. The algorithm then restarts from this average point. This approach is visualized below where the trajectory of the standard PDHG is depicted with a blue line, the average iteration with a red line, and the restarted PDHG with a green line. Notably, the restarted PDHG shows a quicker convergence to the optimal solution, marked by a star on the plot.</p>
</div>

                    
                    
    




                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <p data-block-key="qp0k3">The intuition behind this faster convergence is that by restarting from the computed average at the end of each spiral phase, the restarted PDHG effectively shortens the path to convergence. This strategy leverages the cyclical nature of the PDHG spirals to expedite the solution process.</p><p data-block-key="e8fdh">We show in <a href="https://arxiv.org/abs/2105.12715" target="_blank" rel="noopener noreferrer">our research</a> that this restarting technique can significantly speed up the convergence behaviors of PDHG for LP both in theory and in practice. This establishes restarted PDHG as a highly efficient and theoretically sound method for tackling LP challenges, reinforcing its utility and effectiveness in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">PDLP</h2><p data-block-key="6ptml">We designed <a href="https://developers.google.com/optimization/lp/pdlp_math" target="_blank" rel="noopener noreferrer">PDLP</a> as a software package that can solve linear programming problems efficiently. The core algorithm of PDLP is based on the restarted PDHG, which we have enhanced significantly through five improvements:</p><ul><li data-block-key="336v2"><i>Presolving</i>: This process simplifies the LP problem before solving. It involves detecting inconsistent bounds, detecting duplicate rows, tightening bounds, etc. These steps reduce complexity and improve the efficiency of the solver.</li><li data-block-key="60lg4"><i>Preconditioning</i>: A preconditioner in PDLP rescales variables and constraints within the LP instance. This adjustment helps speed up the algorithm by optimizing the numerical condition of the problem, thereby enhancing convergence rates.</li><li data-block-key="fo387"><i>Infeasibility detection</i>: In real-world scenarios, LP problems may often be infeasible or unbounded. Our approach utilizes the iterates of PDHG, which encodes information about the problem's feasibility and boundedness, allowing for detection without extra computational effort. The theory of this method is detailed in <a href="https://epubs.siam.org/doi/abs/10.1137/22M1510467" target="_blank" rel="noopener noreferrer">our SIAM Journal paper</a>.</li><li data-block-key="6ubbl"><i>Adaptive restarts</i>: This technique involves strategically deciding when to optimally restart the PDHG algorithm to enhance its efficiency, particularly speeding up the convergence to a high-accuracy solution.</li><li data-block-key="6u9l9"><i>Adaptive step-size</i>: We introduced an adaptive method for selecting the step-size in the PDHG, which significantly reduces the need for manual tuning. This approach adjusts the step-size dynamically based on the problem's characteristics and the algorithm's performance, promoting faster convergence.</li></ul><p data-block-key="8lct3">PDLP is open-sourced as part of Google’s <a href="https://developers.google.com/optimization" target="_blank" rel="noopener noreferrer">OR-Tools</a>, an open-source software suite for optimization. The solver is easy to use and it has interfaces in <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" target="_blank" rel="noopener noreferrer">Python</a>, <a href="https://en.wikipedia.org/wiki/C%2B%2B" target="_blank" rel="noopener noreferrer">C++</a>, <a href="https://en.wikipedia.org/wiki/Java_(programming_language)" target="_blank" rel="noopener noreferrer">Java</a> and <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" target="_blank" rel="noopener noreferrer">C#</a>. More details and examples on how to use PDLP can be found in the <a href="https://developers.google.com/optimization/lp/lp_example" target="_blank" rel="noopener noreferrer">OR-Tools documentation</a>.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Applications</h2><p data-block-key="56kp2">Scaling up and speeding up LP enables new applications — here, we briefly mention three:</p><ol><li data-block-key="6f59p"><i>Data center network traffic engineering (</i><a href="https://cloud.google.com/blog/topics/systems/the-evolution-of-googles-jupiter-data-center-network" target="_blank" rel="noopener noreferrer"><i>blog post</i></a><i>,</i> <a href="https://research.google/pubs/jupiter-evolving-transforming-googles-datacenter-network-via-optical-circuit-switches-and-software-defined-networking/"><i>paper</i></a><i>):</i> Google's data centers rely on dynamically optimized traffic engineering for high-performance efficiency. The challenge of optimizing network traffic routing is periodically addressed as a large-scale LP problem. Previously, solving this large problem fast enough was not possible, leading to the development of partition heuristics. These heuristics decomposed the problem into many smaller-scale LPs that could be solved concurrently, albeit at the cost of optimality. With the introduction of PDLP, we can now efficiently optimize traffic routing across an entire data center network, effectively saving a significant amount of machine resources across the network. This solution has been deployed in Google's production environment since May 2023.</li><li data-block-key="a199v"><i>Container shipping optimization (</i><a href="https://research.google/blog/heuristics-on-the-high-seas-mathematical-optimization-for-cargo-ships/"><i>blog post</i></a><i>):</i> The world's shipping supply chain relies on optimizing the order in which vessels visit ports and the placement of containers on those vessels. Due to the extreme scale of real-world instances, a direct solution often is intractable. Consequently, various heuristic approaches have been proposed to enhance efficiency and practicality in solving this complex optimization problem. The problem can be formulated as a type of optimization problem called a massive integer two-layer <a href="https://en.wikipedia.org/wiki/Multi-commodity_flow_problem" target="_blank" rel="noopener noreferrer">multi-commodity flow problem</a>. PDLP enables solving the linear relaxation of this formulation, quantifying the quality of the heuristics.</li><li data-block-key="bii5j"><i>Traveling salesman problem:</i> The <a href="https://en.wikipedia.org/wiki/Travelling_salesman_problem" target="_blank" rel="noopener noreferrer">traveling salesman problem</a> (TSP) poses a classic question: given a list of cities and their distances, what's the shortest route that visits every city once and returns to the starting point? This problem is notoriously challenging, holding significant importance in theoretical computer science and operations research. PDLP has <a href="https://research.google/blog/google-research-2022-beyond-algorithmic-advances/">demonstrated its power</a> by solving real-world TSP lower bound LP instances of immense scale, encompassing up to 12 billion non-zero entries in the constraint matrix. This capability far surpasses the capacity of even the most advanced commercial solvers available today, showcasing PDLP's potential for tackling large-scale LP challenges.</li></ol>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Broader impacts</h2><p data-block-key="947n">Since its initial release, PDLP has attracted significant interest, leading to further enhancements. Here are some notable developments: <a href="https://github.com/jinwen-yang/cuPDLP.jl" target="_blank" rel="noopener noreferrer">cuPDLP.jl</a> is an open-sourced GPU implementation of PDLP, written in <a href="https://julialang.org/" target="_blank" rel="noopener noreferrer">Julia</a>. The commercial solver company, <a href="https://www.copt.de/" target="_blank" rel="noopener noreferrer">Cardinal Optimizer</a>, has incorporated PDLP into their software in <a href="https://github.com/COPT-Public/COPT-Release" target="_blank" rel="noopener noreferrer">Version 7.1</a> in January 2024. The open-source solver, <a href="https://highs.dev/" target="_blank" rel="noopener noreferrer">HiGHS</a>, has incorporated a version of PDLP in their software in <a href="https://conan.io/center/recipes/highs" target="_blank" rel="noopener noreferrer">V1.7.0</a> in March 2024. In addition, the academic community has continued to explore and expand upon the theoretical foundations of PDLP. Recent studies have focused on areas such as <a href="https://arxiv.org/pdf/2206.12061" target="_blank" rel="noopener noreferrer">new analysis on PDHG</a>, <a href="https://arxiv.org/pdf/2312.14774" target="_blank" rel="noopener noreferrer">condition number theory</a>, <a href="https://arxiv.org/pdf/2307.03664v2" target="_blank" rel="noopener noreferrer">trajectory-based analysis</a>, extensions to <a href="https://arxiv.org/pdf/2311.07710" target="_blank" rel="noopener noreferrer">quadratic programming</a> and <a href="https://arxiv.org/pdf/2402.00311" target="_blank" rel="noopener noreferrer">semi-definite programming</a>, etc. These efforts not only deepen the understanding of PDLP's underlying mechanics but also explore its potential applications to more complex problems. These developments reflect PDLP's significant impact on the field of optimization, bridging the gap between theoretical research and practical application. As PDLP continues to evolve, its influence is expected to grow, pushing the boundaries of what can be achieved in computational optimization.</p>
</div>

                    
                    
    


<div data-gt-id="rich_text" data-gt-component-name="">
    <h2 data-block-key="qp0k3">Acknowledgments</h2><p data-block-key="e8dq7"><i>We are grateful to our co-authors Mateo Diaz, Oliver Hinder, Miles Lubin, and Warren Schudy for their exceptional support and contributions. We would also like to thank our managers, Vahab Mirrokni, Jon Orwant and Aaron Archer, and our collaborators in the Data Center Networking team, the Algorithm team and the Operations Research team.</i></p>
</div>

                    
                </div></div>]]></description>
        </item>
    </channel>
</rss>