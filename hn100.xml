<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Wed, 03 Jul 2024 12:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[I Received an AI Email (576 pts)]]></title>
            <link>https://timharek.no/blog/i-received-an-ai-email</link>
            <guid>40862865</guid>
            <pubDate>Wed, 03 Jul 2024 05:05:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://timharek.no/blog/i-received-an-ai-email">https://timharek.no/blog/i-received-an-ai-email</a>, See on <a href="https://news.ycombinator.com/item?id=40862865">Hacker News</a></p>
&lt;Not HTML&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Why AI Infrastructure Startups Are Insanely Hard to Build (129 pts)]]></title>
            <link>https://nextword.substack.com/p/why-ai-infrastructure-startups-are</link>
            <guid>40862436</guid>
            <pubDate>Wed, 03 Jul 2024 03:15:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://nextword.substack.com/p/why-ai-infrastructure-startups-are">https://nextword.substack.com/p/why-ai-infrastructure-startups-are</a>, See on <a href="https://news.ycombinator.com/item?id=40862436">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Recently, </span><a href="http://adept.ai/" rel="">Adept AI</a><span> announced </span><a href="https://techcrunch.com/2024/06/28/amazon-hires-founders-away-from-ai-startup-adept/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAM7kyimVR-Nntc7w3SCp466ss9rI61B5U68ESaJExyUE65kA2h6sdH5pHKpdJ0oi6Y0SvXy7wg2OgsX1JTB-hZw9n0esnLkFCY_6JckUVqoIbgGFEy2gSjzMw4YJBYwbCFKJqPR19xgviwpcnO8cCVPa99I_tMkjrjBWHoQqPtTI" rel="">they are being acquired by Amazon</a><span>, and this solidified a somewhat controversial opinion I’ve held for a while - </span><strong>that AI infra startups are a tarpit idea</strong><span>, </span><strong><span>especially as a “venture-scale” business.</span></strong></p><p><span>The term “tarpit idea” refers to startup ideas that sound reasonable on the surface, but when put to test against reality or rigorous thought, fail to hold up.</span><br></p><div><p><span>I believe most AI infra startups will also fall into this category, where AI infra refers to the “building blocks” companies </span><strong>between the cloud layer and the application layer</strong><span> - RAG services, finetuning infrastructure, text processing services, TTS APIs, vector databases, etc. I won’t name specific names, but just think of any AI infra startup that raised sizable seed rounds off of open source or social media momentum.</span></p></div><p><span>I also believe </span><strong>many founders agree with this viewpoint</strong><span>, which explains the sale of Adept (to Amazon), </span><a href="https://openai.com/index/openai-acquires-rockset/" rel="">Rockset (to OpenAI)</a><span>, InflectionAI (to Microsoft), as well as the soon to be acquisitions of Stability (if it happens), </span><a href="http://character.ai/" rel="">Character</a><span>AI, etc. Every incumbent is looking at M&amp;A to paint an “end-to-end AI platform” story. Only a lucky few will get bought.</span><br></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png" width="1456" height="819" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;June 28 updated AI Infra market map&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="June 28 updated AI Infra market map" title="June 28 updated AI Infra market map" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddeab17f-4637-437e-baeb-cd2ffb0e846a_1600x900.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption>Source: Bessemer Venture Partners</figcaption></figure></div><div><p><span>So why is selling AI infrastructure </span><em>as a startup</em><span> a tarpit idea? On paper, it’s perfectly reasonable to sell picks and shovels amidst proliferation of AI startups and enterprises building Gen AI features. After all, there’s over 30K “.ai” domains registered every month.</span></p></div><div><p><strong>In a nutshell, the new AI infra startups will struggle to succeed because they lack significant differentiation and capital to crack the enterprise segment.</strong><span> It’s not the startups’ fault, the real problem is competitive dynamics. There’s simply too many entities offering the same table stakes features within 1-3 months apart from each other, which creates a collective tarpit dynamic, where only the incumbents can keep swimming.</span></p></div><p>The argument goes:</p><ul><li><p>For AI infra startups to be “venture scale”, they will eventually need to win over enterprise customers. No question. That requires the startups to have some sustainable edge that separates their products from the incumbents’ (GCP, AWS, as well as the likes of Vercel, Databricks, Datadog, etc).</p></li><li><p>Unfortunately, most cutting edge innovation either comes from the incumbents or the research / OSS community - and incumbents are in a better position to commercialize the innovations because they have more usage data than startups, as well as the relationships.</p></li><li><p>To add salt to the injury, any good ideas that originate from startups get benchmarked and copied quickly. For example, I was quite surprised how quickly Databricks and Datadog caught up to the leading LLMOps products from the startup world (e.g. Arize AI). </p></li><li><p>Furthermore, OSS community can’t help but create OSS versions of other AI infra startups’ products - perhaps a testament to how easy it has become to write software.</p></li><li><p>Thus, startups struggle to maintain a sustainable lead over the incumbents to buy them time to win enterprise contracts.</p></li><li><p>And enterprise customers are incentivized to “hold off” on onboarding new vendors, because vendor products diminish in value so quickly because AI landscape changes every few months.</p></li><li><p>This ultimately lengthens sales cycles, and increases churn, which hurts startups more than the incumbents.</p></li></ul><div><p><span>There are also some other dynamics at play (to be discussed in the next section) - but essentially the AI infrastructure space becomes a grind that favors players with the longest runways.</span></p></div><div><p><span>My intention here is not to doom-post, but to highlight some real challenges, which I’m happy to be wrong on (DM me if you disagree). Also, I will end by offering some advice to AI infra startups.</span></p></div><p><em><span>To clarify, by “AI infra startup”, I’m referring to “venture scale” AI infrastructure startups. I’m sure founders can create essentially system integration agencies targeting SMB or mid market, and call themselves an AI infra company. But that’s a completely different business with a much smaller upside.</span><br></em></p><p>There’s three other major forces that’s worsening the competitive environment:</p><ol><li><p>Builders are now conditioned to “demand” composability, a.k.a making it easy to switch out your product for others’. This is great for application layer companies, but not infrastructure companies. Developers can rip out Langchain with Llamaindex, OpenAI models with Claude 3.5 through AWS Bedrock, etc. Every layer of the LLM training and inference stack has at least 10+ viable solutions, that it becomes difficult to create any type of lock-in.</p></li><li><p>The ongoing plummeting of inference costs also plays a role. The COGS are dropping fast, so AI infra players need to constantly price-match the incumbents who have the biggest economies of scale. Models or code have little perceived differentiation, so the consumption goes to the lowest cost providers (incumbents).</p></li><li><p>Incumbents seem to all have the same business strategy of creating an “end-to-end AI platform”. Databricks is getting into AI model training and business intelligence, competing with AWS Sagemaker and Tableau. Github Workspaces is getting into AI-powered security reviews, etc.</p><ol><li><p>Everyone’s default product strategy is to own all upstream and downstream workloads from their core product, which unintentionally makes startups’ lives more difficult, since it becomes hard to compete with a point solution.</p></li></ol></li></ol><p><br><span>With all these challenges, some AI infra startups have chosen to go vertical or move to the application layer. For example, I have been tracking a “Business Intelligence with Natural Language” startup since late 2022 that has pivoted three times already from:</span></p><ul><li><p>a general purpose “chat with data” platform, to</p></li><li><p>“chat with business intelligence data” platform, to</p></li><li><p>“chat with financial data” platform.</p></li></ul><div><p><span>The AI infra darlings LlamaIndex and Langchain also took this path of focus when it comes to their enterprise-oriented products. LlamaIndex is focusing on managed document parsing / OCR, whereas Langchain is focusing on LLMOps and agent building solutions. My guess is that both are working on narrowing their focus even further, since even selling a managed document parsing service is a huge scope for a seed-stage startup, given that Google and AWS already have existing vertical text extraction services. It’s not easy.</span></p></div><div><p><span>Narrowing the scope and going vertical is a typical response for AI infra startups - but I argue that these pivots rarely work out and cause new set of problems. Most importantly, these vertical pivots underestimate the importance of deep domain expertise once you go vertical, which many AI infra founders lack. Accumulating domain knowledge is time consuming. Also, your product may need to be heavily customized for the unique needs of the vertical, which means lower margins.</span></p></div><p><span>Not to mention, these application layer ecosystems have even worse competition (e.g. VCs’ LegalTech ecosystem maps ran out of space to put new logos long time ago). There’s not just the other AI startup competition, but competition from the legacy software companies. Pivoting to a vertical does not suddenly get rid of your competitors - you will just have new ones in that vertical who have been there before you. For example, legal tech industry has existed for ages, and many Legal AI companies are now competing with </span><strong>the legacy legal tech providers plus system integrators.</strong></p><div><p><span>So what’s the solution for AI infra startups? Should we all hope to be acquihired, or is it possible for startups to also stay independent for longer and find product market fit?</span></p><p><span>Here’s a somewhat anti-climatic answer, but the solution for startups goes back to the fundamentals: </span><strong>think deeply about how to be different from the incumbents.</strong><span> Here are four ways to iterate from here:</span></p></div><ul><li><p><strong>Narrow down the scope even further:</strong><span> focus on a very tiny segment of enterprise customers, as opposed to serving all customers. Don’t build all the integrations. Be a managed RAG service for customers using Salesforce with on-prem VMWare, as opposed to a general purpose RAG service. Startups don’t have the resources to solve for every environment, at least initially.</span></p></li><li><p><strong>Focus on just one workload:</strong><span> startups shouldn’t try to solve for too many workloads. Do one thing really well. Don’t try to be a platform for finetuning any LLM - there’s already too many of those. Instead, try to be the best platform for finetuning Tagalog models. The catch: the TAM might be too small.</span></p></li><li><p><strong>Raise more VC money than you think you need:</strong><span> long runways are non-negotiable. It can take a while for enterprises to be receptive to buying startup AI infra solutions, if ever. Be prepared for the worst case scenario.</span></p></li><li><p><strong>Or, don’t raise any VC money at all:</strong><span> raising VC money kind of forces you to orient business strategy around selling to the enterprise - which might be not something you can or want to do. You want the flexibility to work on more interesting and promising problems when they arise, given there’s constantly new changes in AI landscape.</span></p></li></ul><p><span>Lastly, AI startups should be open to being acquired by a larger player, even if it’s not a prestigious destination like OpenAI or Google. </span><strong>My view is that M&amp;A landscape for AI infrastructure sector will become worse, not better, over time.</strong></p><p><span>The acquisition market will become more “efficient” as the winners/losers emerge, and the workloads and enterprise needs become more clearly defined. Thus, in order to sell your startup at an “attractive” valuation, it needs to be marketed prior to the dust settles when the market is less efficient. Don’t wait for another 18 months to shop your startup, when all AI infra startups start running out of runway at the same time.</span></p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The Illustrated Transformer (2018) (115 pts)]]></title>
            <link>https://jalammar.github.io/illustrated-transformer/</link>
            <guid>40861148</guid>
            <pubDate>Tue, 02 Jul 2024 22:42:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://jalammar.github.io/illustrated-transformer/">https://jalammar.github.io/illustrated-transformer/</a>, See on <a href="https://news.ycombinator.com/item?id=40861148">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p><span>Discussions:
<a href="https://news.ycombinator.com/item?id=18351674">Hacker News (65 points, 4 comments)</a>, <a href="https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/">Reddit r/MachineLearning (29 points, 3 comments)</a>
</span>
<br>
<span>Translations: <a href="https://www.mundhor.site/post/post14">Arabic</a>, <a href="https://blog.csdn.net/yujianmin1990/article/details/85221271">Chinese (Simplified) 1</a>, <a href="https://blog.csdn.net/qq_36667170/article/details/124359818">Chinese (Simplified) 2</a>, <a href="https://a-coles.github.io/2020/11/15/transformer-illustre.html">French 1</a>, <a href="https://lbourdois.github.io/blog/nlp/Transformer/">French 2</a>, <a href="https://medium.com/@val.mannucci/il-transformer-illustrato-it-37a78e3e2348">Italian</a>, <a href="https://tips-memo.com/translation-jayalmmar-transformer">Japanese</a>, <a href="https://nlpinkorean.github.io/illustrated-transformer/">Korean</a>, <a href="http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/">Persian</a>, <a href="https://habr.com/ru/post/486358/">Russian</a>, <a href="https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/">Spanish 1</a>, <a href="https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp">Spanish 2</a>, <a href="https://trituenhantao.io/tin-tuc/minh-hoa-transformer/">Vietnamese</a></span>
<br>
<span>Watch: MIT’s <a href="https://youtu.be/53YvP6gdD7U?t=432">Deep Learning State of the Art</a> lecture referencing this post</span>
<br>
<span>Featured in courses at <a href="https://web.stanford.edu/class/cs224n/">Stanford</a>, <a href="https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/transformers">Harvard</a>, <a href="https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf">MIT</a>, <a href="https://www.cs.princeton.edu/courses/archive/fall22/cos597G/">Princeton</a>, <a href="https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf">CMU</a> and others</span></p>

<p>In the <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">previous post, we looked at Attention</a> – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at <strong>The Transformer</strong> – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their <a href="https://cloud.google.com/tpu/">Cloud TPU</a> offering. So let’s try to break the model apart and look at how it functions.</p>

<p>The Transformer was proposed in the paper <a href="https://arxiv.org/abs/1706.03762">Attention is All You Need</a>. A TensorFlow implementation of it is available as a part of the <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor</a> package. Harvard’s NLP group created a <a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">guide annotating the paper with PyTorch implementation</a>. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.</p>

<p><strong>2020 Update</strong>: I’ve created a “Narrated Transformer” video which is a gentler approach to the topic:</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/-QH8fRhqFHM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="a-high-level-look">A High-Level Look</h2>
<p>Let’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.</p>

<p><img src="https://jalammar.github.io/images/t/the_transformer_3.png">
</p>

<!--more-->

<p>Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png">
</p>

<p>The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number.</p>

<p><img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png">
</p>

<p>The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers:</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_encoder.png">
</p>

<p>The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.</p>

<p>The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position.</p>

<p>The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in <a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">seq2seq models</a>).</p>

<p><img src="https://jalammar.github.io/images/t/Transformer_decoder.png">
</p>

<h2 id="bringing-the-tensors-into-the-picture">Bringing The Tensors Into The Picture</h2>

<p>Now that we’ve seen the major components of the model, let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output.</p>

<p>As is the case in NLP applications in general, we begin by turning each input word into a vector using an <a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca">embedding algorithm</a>.</p>



<p><img src="https://jalammar.github.io/images/t/embeddings.png">
  <br>
  Each word is embedded into a vector of size 512. We'll represent those vectors with these simple boxes.
</p>

<p>The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below. The size of this list is hyperparameter we can set – basically it would be the length of the longest sentence in our training dataset.</p>

<p>After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors.png">
  <br>

</p>

<p>Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.</p>

<p>Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder.</p>

<h2 id="now-were-encoding">Now We’re Encoding!</h2>

<p>As we’ve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.</p>

<p><img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png">
  <br>
  The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately.
</p>

<h2 id="self-attention-at-a-high-level">Self-Attention at a High Level</h2>
<p>Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.</p>

<p>Say the following sentence is an input sentence we want to translate:</p>

<p>”<code>The animal didn't cross the street because it was too tired</code>”</p>

<p>What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.</p>

<p>When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.</p>

<p>As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.</p>

<p>If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png">
  <br>
  As we are encoding the word "it" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on "The Animal", and baked a part of its representation into the encoding of "it".
</p>

<p>Be sure to check out the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb">Tensor2Tensor notebook</a> where you can load a Transformer model, and examine it using this interactive visualization.</p>

<h2 id="self-attention-in-detail">Self-Attention in Detail</h2>
<p>Let’s first look at how to calculate self-attention using vectors, then proceed to look at how it’s actually implemented – using matrices.</p>

<p>The <strong>first step</strong> in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.</p>

<p>Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_vectors.png">
  <br>
  Multiplying <span>x1</span> by the <span>WQ</span> weight matrix produces <span>q1</span>, the "query" vector associated with that word. We end up creating a "query", a "key", and a "value" projection of each word in the input sentence.
</p>



<div><p>What are the “query”, “key”, and “value” vectors?
</p><p>

They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.</p></div>

<p>The <strong>second step</strong> in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.</p>

<p>The score is calculated by taking the dot product of the <span>query vector</span> with the <span>key vector</span> of the respective word we’re scoring. So if we’re processing the self-attention for the word in position <span>#1</span>, the first score would be the dot product of <span>q1</span> and <span>k1</span>. The second score would be the dot product of <span>q1</span> and <span>k2</span>.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png">
  <br>

</p>



<p>The <strong>third and fourth steps</strong> are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.</p>



<p><img src="https://jalammar.github.io/images/t/self-attention_softmax.png">
  <br>

</p>

<p>This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.</p>



<p>The <strong>fifth step</strong> is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).</p>

<p>The <strong>sixth step</strong> is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).</p>



<p><img src="https://jalammar.github.io/images/t/self-attention-output.png">
  <br>
</p>

<p>That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level.</p>

<h2 id="matrix-calculation-of-self-attention">Matrix Calculation of Self-Attention</h2>
<p><strong>The first step</strong> is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix <span>X</span>, and multiplying it by the weight matrices we’ve trained (<span>WQ</span>, <span>WK</span>, <span>WV</span>).</p>

<p><img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png">
  <br>
  Every row in the <span>X</span> matrix corresponds to a word in the input sentence. We again see the difference in size of the embedding vector (512, or 4 boxes in the figure), and the q/k/v vectors (64, or 3 boxes in the figure)
</p>



<p><strong>Finally</strong>, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.</p>

<p><img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png">
  <br>
  The self-attention calculation in matrix form
</p>





<h2 id="the-beast-with-many-heads">The Beast With Many Heads</h2>

<p>The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:</p>

<ol>
  <li>
    <p>It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to.</p>
  </li>
  <li>
    <p>It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace.</p>
  </li>
</ol>

<p><img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png">
   <br>
   With multi-headed attention, we maintain separate Q/K/V weight matrices for each head resulting in different Q/K/V matrices. As we did before, we multiply X by the WQ/WK/WV matrices to produce Q/K/V matrices.
 </p>

<p><br>
If we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices</p>

<p><img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png">
  <br>

</p>



<p>This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.</p>

<p>How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png">
  <br>

</p>

<p>That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place</p>



<p><img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png">
  <br>

</p>



<p>Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png">
  <br>
  As we encode the word "it", one attention head is focusing most on "the animal", while another is focusing on "tired" -- in a sense, the model's representation of the word "it" bakes in some of the representation of both "animal" and "tired".
</p>



<p>If we add all the attention heads to the picture, however, things can be harder to interpret:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png">
  <br>
</p>

<h2 id="representing-the-order-of-the-sequence-using-positional-encoding">Representing The Order of The Sequence Using Positional Encoding</h2>
<p>One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.</p>

<p>To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png">
  <br>
  To give the model a sense of the order of the words, we add positional encoding vectors -- the values of which follow a specific pattern.
</p>


<p>If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png">
  <br>
  A real example of positional encoding with a toy embedding size of 4
</p>



<p>What might this pattern look like?</p>

<p>In the following figure, each row corresponds to a positional encoding of a vector. So the first row would be the vector we’d add to the embedding of the first word in an input sequence. Each row contains 512 values – each with a value between 1 and -1. We’ve color-coded them so the pattern is visible.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png">
  <br>
  A real example of positional encoding for 20 words (rows) with an embedding size of 512 (columns). You can see that it appears split in half down the center. That's because the values of the left half are generated by one function (which uses sine), and the right half is generated by another function (which uses cosine). They're then concatenated to form each of the positional encoding vectors.
</p>

<p>The formula for positional encoding is described in the paper (section 3.5). You can see the code for generating positional encodings in <a href="https://github.com/tensorflow/tensor2tensor/blob/23bd23b9830059fbc349381b70d9429b5c40a139/tensor2tensor/layers/common_attention.py"><code>get_timing_signal_1d()</code></a>. This is not the only possible method for positional encoding. It, however, gives the advantage of being able to scale to unseen lengths of sequences (e.g. if our trained model is asked to translate a sentence longer than any of those in our training set).</p>

<p><strong>July 2020 Update:</strong> 
The positional encoding shown above is from the Tensor2Tensor implementation of the Transformer. The method shown in the paper is slightly different in that it doesn’t directly concatenate, but interweaves the two signals. The following figure shows what that looks like. <a href="https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb">Here’s the code to generate it</a>:</p>

<p><img src="https://jalammar.github.io/images/t/attention-is-all-you-need-positional-encoding.png">
  <br>
</p>

<h2 id="the-residuals">The Residuals</h2>
<p>One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a <a href="https://arxiv.org/abs/1607.06450">layer-normalization</a> step.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png">
  <br>
</p>

<p>If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png">
  <br>
</p>

<p>This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png">
  <br>
</p>

<h2 id="the-decoder-side">The Decoder Side</h2>
<p>Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.</p>

<p>The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence:</p>

<p><img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif">
  <br>
  After finishing the encoding phase, we begin the decoding phase. Each step in the decoding phase outputs an element from the output sequence (the English translation sentence in this case).
</p>

<p>The following steps repeat the process until a special <end of="" sentence=""> symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.</end></p>

<p><img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif">
  <br>

</p>

<p>The self attention layers in the decoder operate in a slightly different way than the one in the encoder:</p>

<p>In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to <code>-inf</code>) before the softmax step in the self-attention calculation.</p>

<p>The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack.</p>

<h2 id="the-final-linear-and-softmax-layer">The Final Linear and Softmax Layer</h2>

<p>The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.</p>

<p>The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.</p>

<p>Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.</p>

<p>The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step.</p>



<p><img src="https://jalammar.github.io/images/t/transformer_decoder_output_softmax.png">
  <br>
  This figure starts from the bottom with the vector produced as the output of the decoder stack. It is then turned into an output word.
</p>



<h2 id="recap-of-training">Recap Of Training</h2>
<p>Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.</p>

<p>During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.</p>

<p>To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&lt;eos&gt;” (short for ‘end of sentence’)).</p>

<p><img src="https://jalammar.github.io/images/t/vocabulary.png">
   <br>
   The output vocabulary of our model is created in the preprocessing phase before we even begin training.
 </p>

<p>Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector:</p>

<p><img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png">
  <br>
  Example: one-hot encoding of our output vocabulary
</p>

<p>Following this recap, let’s discuss the model’s loss function – the metric we are optimizing during the training phase to lead up to a trained and hopefully amazingly accurate model.</p>

<h2 id="the-loss-function">The Loss Function</h2>
<p>Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.</p>

<p>What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.</p>

<p><img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png">
  <br>
  Since the model's parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model's weights using backpropagation to make the output closer to the desired output.
</p>



<p>How do you compare two probability distributions? We simply subtract one from the other. For more details, look at  <a href="https://colah.github.io/posts/2015-09-Visual-Information/">cross-entropy</a> and <a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained">Kullback–Leibler divergence</a>.</p>

<p>But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:</p>

<ul>
  <li>Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)</li>
  <li>The first probability distribution has the highest probability at the cell associated with the word “i”</li>
  <li>The second probability distribution has the highest probability at the cell associated with the word “am”</li>
  <li>And so on, until the fifth output distribution indicates ‘<code>&lt;end of sentence&gt;</code>’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.</li>
</ul>

<p><img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png">
   <br>
   The targeted probability distributions we'll train our model against in the training example for one sample sentence.
 </p>



<p>After training the model for enough time on a large enough dataset, we would hope the produced probability distributions would look like this:</p>

<p><img src="https://jalammar.github.io/images/t/output_trained_model_probability_distributions.png">
    <br>
    Hopefully upon training, the model would output the right translation we expect. Of course it's no real indication if this phrase was part of the training dataset (see: <a href="https://www.youtube.com/watch?v=TIgfjmp-4BA">cross validation</a>). Notice that every position gets a little bit of probability even if it's unlikely to be the output of that time step -- that's a very useful property of softmax which helps the training process.
</p>

<p>Now, because the model produces the outputs one at a time, we can assume that the model is selecting the word with the highest probability from that probability distribution and throwing away the rest. That’s one way to do it (called greedy decoding). Another way to do it would be to hold on to, say, the top two words (say, ‘I’ and ‘a’ for example), then in the next step, run the model twice: once assuming the first output position was the word ‘I’, and another time assuming the first output position was the word ‘a’, and whichever version produced less error considering both positions #1 and #2 is kept. We repeat this for positions #2 and #3…etc. This method is called “beam search”, where in our example, beam_size was two (meaning that at all times, two partial hypotheses (unfinished translations) are kept in memory), and top_beams is also two (meaning we’ll return two translations). These are both hyperparameters that you can experiment with.</p>

<h2 id="go-forth-and-transform">Go Forth And Transform</h2>

<p>I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:</p>

<ul>
  <li>Read the <a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> paper, the Transformer blog post (<a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">Transformer: A Novel Neural Network Architecture for Language Understanding</a>), and the <a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html">Tensor2Tensor announcement</a>.</li>
  <li>Watch <a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">Łukasz Kaiser’s talk</a> walking through the model and its details</li>
  <li>Play with the <a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb">Jupyter Notebook provided as part of the Tensor2Tensor repo</a></li>
  <li>Explore the <a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor repo</a>.</li>
</ul>

<p>Follow-up works:</p>

<ul>
  <li><a href="https://arxiv.org/abs/1706.03059">Depthwise Separable Convolutions for Neural Machine Translation</a></li>
  <li><a href="https://arxiv.org/abs/1706.05137">One Model To Learn Them All</a></li>
  <li><a href="https://arxiv.org/abs/1801.09797">Discrete Autoencoders for Sequence Models</a></li>
  <li><a href="https://arxiv.org/abs/1801.10198">Generating Wikipedia by Summarizing Long Sequences</a></li>
  <li><a href="https://arxiv.org/abs/1802.05751">Image Transformer</a></li>
  <li><a href="https://arxiv.org/abs/1804.00247">Training Tips for the Transformer Model</a></li>
  <li><a href="https://arxiv.org/abs/1803.02155">Self-Attention with Relative Position Representations</a></li>
  <li><a href="https://arxiv.org/abs/1803.03382">Fast Decoding in Sequence Models using Discrete Latent Variables</a></li>
  <li><a href="https://arxiv.org/abs/1804.04235">Adafactor: Adaptive Learning Rates with Sublinear Memory Cost</a></li>
</ul>

<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thanks to <a href="https://twitter.com/ilblackdragon">Illia Polosukhin</a>, <a href="http://jakob.uszkoreit.net/">Jakob Uszkoreit</a>, <a href="https://www.linkedin.com/in/llion-jones-9ab3064b">Llion Jones </a>, <a href="https://ai.google/research/people/LukaszKaiser">Lukasz Kaiser</a>, <a href="https://twitter.com/nikiparmar09">Niki Parmar</a>, and <a href="https://dblp.org/pers/hd/s/Shazeer:Noam">Noam Shazeer</a> for providing feedback on earlier versions of this post.</p>

<p>Please hit me up on <a href="https://twitter.com/JayAlammar">Twitter</a> for any corrections or feedback.</p>

  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Brazil data regulator bans Meta from mining data to train AI models (135 pts)]]></title>
            <link>https://apnews.com/article/brazil-tech-meta-privacy-data-93e00b2e0e26f7cc98795dd052aea8e1</link>
            <guid>40861057</guid>
            <pubDate>Tue, 02 Jul 2024 22:29:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://apnews.com/article/brazil-tech-meta-privacy-data-93e00b2e0e26f7cc98795dd052aea8e1">https://apnews.com/article/brazil-tech-meta-privacy-data-93e00b2e0e26f7cc98795dd052aea8e1</a>, See on <a href="https://news.ycombinator.com/item?id=40861057">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                                        <p>RIO DE JANEIRO (AP) — Brazil’s national data protection authority determined on Tuesday that Meta, the parent company of Instagram and Facebook, cannot use data originating in the country to train its artificial intelligence. </p><p>Meta’s updated privacy policy enables the company to feed people’s public posts into its AI systems. That practice will not be permitted in Brazil, however.</p><p>The decision stems from “the imminent risk of serious and irreparable or difficult-to-repair damage to the fundamental rights of the affected data subjects,” the agency said in the nation’s official gazette. </p><p>Brazil is one of Meta’s biggest markets. Facebook alone has around 102 million active users in the country, the agency said in a statement. The nation has a population of 203 million, according to the country’s 2022 census.</p><p>A spokesperson for Meta said in a statement the company is “disappointed” and insists its method “complies with privacy laws and regulations in Brazil.”</p>
    

<p>“This is a step backwards for innovation, competition in AI development and further delays bringing the benefits of AI to people in Brazil,” the spokesperson added.</p>



<p>The social media company has also encountered resistance to its privacy policy update in Europe, where it recently put on hold its plans to start feeding people’s public posts into training AI systems — which was supposed to start last week.</p><p>In the U.S., where there’s no national law protecting online privacy, such training is already happening.</p>
    
<p>Meta said on its Brazilian blog in May that it could “use information that people have shared publicly about Meta’s products and services for some of our generative AI features,” which could include “public posts or photos and their captions.”</p><p>Refusing to partake is possible, Meta said in that statement. Despite that option, there are “excessive and unjustified obstacles to accessing the information and exercising” the right to opt out, the agency said in a statement. </p>
    

<p>Meta did not provide sufficient information to allow people to be aware of the possible consequences of using their personal data for the development of generative AI, it added.</p><p>Meta isn’t the only company that has sought to train its AI systems on data from Brazilians.</p><p>Human Rights Watch released a report last month that found that personal photos of identifiable Brazilian children sourced from a large database of online images — pulled from parent blogs, the websites of professional event photographers and video-sharing sites such as YouTube — were being used to create AI image-generator tools without families’ knowledge. In some cases, those tools have been used create AI-generated nude imagery.</p><p>Hye Jung Han, a Brazil-based researcher for the rights group, said in an email Tuesday that the regulator’s action “helps to protect children from worrying that their personal data, shared with friends and family on Meta’s platforms, might be used to inflict harm back on them in ways that are impossible to anticipate or guard against.”</p><p>But the decision regarding Meta will “very likely” encourage other companies to refrain from being transparent in the use of data in the future, said Ronaldo Lemos, of the Institute of Technology and Society of Rio de Janeiro, a think-tank. </p>
    

<p>“Meta was severely punished for being the only one among the Big Tech companies to clearly and in advance notify in its privacy policy that it would use data from its platforms to train artificial intelligence,” he said. </p><p>Compliance must be demonstrated by the company within five working days from the notification of the decision, and the agency established a daily fine of 50,000 reais ($8,820) for failure to do so.</p>
                                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All I want for Christmas is a negative leap second (105 pts)]]></title>
            <link>https://qntm.org/leap</link>
            <guid>40860831</guid>
            <pubDate>Tue, 02 Jul 2024 22:01:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://qntm.org/leap">https://qntm.org/leap</a>, See on <a href="https://news.ycombinator.com/item?id=40860831">Hacker News</a></p>
Couldn't get https://qntm.org/leap: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Apple poised to get OpenAI board observer role as part of AI pact (127 pts)]]></title>
            <link>https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement</link>
            <guid>40860363</guid>
            <pubDate>Tue, 02 Jul 2024 21:01:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement">https://www.bloomberg.com/news/articles/2024-07-02/apple-to-get-openai-board-observer-role-as-part-of-ai-agreement</a>, See on <a href="https://news.ycombinator.com/item?id=40860363">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
    <section>
        <h3>Why did this happen?</h3>
        <p>Please make sure your browser supports JavaScript and cookies and that you are not
            blocking them from loading.
            For more information you can review our <a href="https://www.bloomberg.com/notices/tos">Terms of
                Service</a> and <a href="https://www.bloomberg.com/notices/tos">Cookie Policy</a>.</p>
    </section>
    <section>
        <h3>Need Help?</h3>
        <p>For inquiries related to this message please <a href="https://www.bloomberg.com/feedback">contact
            our support team</a> and provide the reference ID below.</p>
        <p>Block reference ID:</p>
    </section>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: I made a search engine for Hacker News (148 pts)]]></title>
            <link>https://hackernews.demo.vectara.com/</link>
            <guid>40860022</guid>
            <pubDate>Tue, 02 Jul 2024 20:11:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://hackernews.demo.vectara.com/">https://hackernews.demo.vectara.com/</a>, See on <a href="https://news.ycombinator.com/item?id=40860022">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Google's carbon emissions surge nearly 50% due to AI energy demand (145 pts)]]></title>
            <link>https://www.cnbc.com/2024/07/02/googles-carbon-emissions-surge-nearly-50percent-due-to-ai-energy-demand.html</link>
            <guid>40859993</guid>
            <pubDate>Tue, 02 Jul 2024 20:07:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/07/02/googles-carbon-emissions-surge-nearly-50percent-due-to-ai-energy-demand.html">https://www.cnbc.com/2024/07/02/googles-carbon-emissions-surge-nearly-50percent-due-to-ai-energy-demand.html</a>, See on <a href="https://news.ycombinator.com/item?id=40859993">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107402399" data-test="InlineImage"><p>A view of the Google headquarters in Mountain View, California, on April 16, 2024.</p><p>Tayfun Coskun | Anadolu | Getty Images</p></div><div><p><span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-1"><a href="https://www.cnbc.com/quotes/GOOGL/">Google</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span>'s emissions surged nearly 50% compared to 2019, the company said Tuesday in its <a href="https://www.gstatic.com/gumdrop/sustainability/google-2024-environmental-report.pdf" target="_blank">2024 environmental report</a>, marking a notable setback in its goal to achieve net-zero emissions by 2030.&nbsp;</p><p>Google's emissions also increased 13% year over year in 2023, per the report.</p><p>The company attributed the emissions spike to an increase in data center energy consumption and supply chain emissions driven by rapid advancements in and demand for <a href="https://www.cnbc.com/ai-artificial-intelligence/">artificial intelligence</a>. The report noted that the company's total data center electricity consumption grew 17% in 2023.&nbsp;</p><p>The impact of AI on electricity demand is well documented. Electricity demand is <a href="https://www.cnbc.com/2024/05/05/ai-could-drive-natural-gas-boom-as-utilities-face-surging-electric-demand.html">forecast to grow</a> as much as 20% by 2030, with AI data centers alone expected to add about 323 terawatt hours of electricity demand in the U.S., CNBC previously reported.</p><p>While renewables will likely play an important role in meeting AI energy demands, analysts say that immediate implementation is challenging. This is due to factors such as the time required to build the power lines that transport resources to the data centers, Wells Fargo analyst Roger Read<a href="https://www.cnbc.com/2024/05/05/ai-could-drive-natural-gas-boom-as-utilities-face-surging-electric-demand.html"> previously told</a> CNBC.</p><p>Google said in the report that its data centers are 1.8 times as energy efficient as a typical data center. The company added that it remains committed to mitigating the environmental impact of AI through model optimization, efficient infrastructure and emissions reductions.&nbsp;</p><p>Google is not the only major tech company to face increased emissions due to AI demand. <span data-test="QuoteInBody" id="RegularArticle-QuoteInBody-6"><a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a><span><span id="-WatchlistDropdown" data-analytics-id="-WatchlistDropdown"></span></span></span> reported in May that its <a href="https://docs.google.com/document/u/0/d/1Oreyv8tjRotBp3Gl0yGcuBmJjfqTcRu2kGv3Xxet8IM/edit" target="_blank">total carbon emissions</a> rose nearly 30% since 2020 primarily due to the construction of data centers.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Sonar is destroying my job and it's driving me to despair (118 pts)]]></title>
            <link>https://community.sonarsource.com/t/sonar-is-destroying-my-job-and-its-driving-me-to-despair/92438</link>
            <guid>40859937</guid>
            <pubDate>Tue, 02 Jul 2024 20:00:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://community.sonarsource.com/t/sonar-is-destroying-my-job-and-its-driving-me-to-despair/92438">https://community.sonarsource.com/t/sonar-is-destroying-my-job-and-its-driving-me-to-despair/92438</a>, See on <a href="https://news.ycombinator.com/item?id=40859937">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemscope="" itemtype="http://schema.org/DiscussionForumPosting" id="main-outlet" role="main">
      <meta itemprop="headline" content="Sonar is destroying my job and it's driving me to despair">
      
      <meta itemprop="datePublished" content="2023-06-13T12:17:38Z">
        <meta itemprop="articleSection" content="SonarQube">
      <meta itemprop="keywords" content="kotlin, sonarqube">
      


          <div itemprop="text" id="post_1">
              <p>First of all, I understand that Sonar is a well intentioned product.</p>
<p>It’s right <em>most</em> of the time.  Unfortunately coding is, of course, complex and it’s challenging for a product like Sonar to keep pace with the fast changing syntax of newer languages.</p>
<p>I’m an experienced Developer and Team Lead, currently coding in Kotlin with Coroutines. I’ve also worked with Java, C++, C, Objective-C and Swift.  We can all learn more, but I’ve been around the block and know a few things about what code quality looks like and how to make pragmatic decisions around it.</p>
<p>Our ‘default’ Sonar setup is currently making me ‘butcher’ my Kotlin code to comply with it’s rules and, as you may tell, it’s really upsetting.</p>
<p>You may say <em>“The rules can be customised”</em>, or <em>“Allow an exception”</em>.  You need to understand <strong>that is not a simple option for many of your users</strong>.  In my case, I have a superior who administers Sonar and is, let’s say, completely committed to it.  For any ‘exception granted’ we would have to book time with them days in advance then white-board the reason why Sonar is wrong, or produce a sample program - who has got time for that with tight deadlines?</p>
<p>Please rethink your UX with the realisation that there are probably many professional and experienced software engineers out there who - far from appreciating your product, actually feel genuinely oppressed by it: like victims of a cold unfeeling system with no ‘right to reply’.  Unable to merge deadline code until every point is addressed, for better or worse.  It’s a terrible helpless feeling.</p>
<p>A couple of Kotlin examples:</p>
<ul>
<li>
<p>Inability to define a single suspending function interface. Sonar tells me to make it a fun interface, then tells me fun interfaces can’t have suspending functions.  I should make this a functional type instead?  Completely <em>inconsistent</em> with the rest of the code and removes the opportunity to provide information though labelling the function.</p>
</li>
<li>
<p>Sonar doesn’t respect import aliasing.  Let’s say I have Domain and Service models for some entities.  I have ‘Person’ defined in domain and service packages. In one of those packages, I want to write a mapper extension.  I use import aliasing to disambiguate each ‘Person’ as DomainPerson and ServicePerson.  This is an informative convention, but Sonar doesn’t allow it: <code>import service.Person as ServicePerson</code> is considered redundant.  I could then use a private typealias ServicePerson = Person` but this isn’t the same.</p>
</li>
</ul>
<p>These are just two examples, I could find more.</p>
<p><strong>Can you do something with your product</strong> to give users more of a ‘right to reply’ and re-empower them?<br>
There will be creative ways to achieve this without undermining Sonar’s purpose.  Just some ideas:</p>
<ul>
<li>Allow a user role where rules can be overridden but the admin gets informed and can remove the override at a later time.</li>
<li>A mode where an override can be granted by 3-4 other users all agreeing, who aren’t admins.</li>
<li>Button to fast-access (lazily create) a community thread regarding a certain rule, to report a problem with it, so you know your difficulty is being heard at least by Sonar, if not within your organisation.</li>
</ul>
<p>Thank you for listening to my part rant, part suggestions.  This is sincere.</p>
            </div>
          <div id="post_2" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.sonarsource.com/u/Colin"><span itemprop="name">Colin</span></a>
                (Colin)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2023-06-14T08:51:41Z">
                    June 14, 2023,  8:51am
                  </time>
                  <meta itemprop="dateModified" content="2023-06-14T09:29:39Z">
              <span itemprop="position">2</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Hey there.</p>
<p>Thanks for the feedback. It’s essential in our quest to ensure developers not only find value in our products but also enjoy and feel empowered by the experience.</p>
<p>If you disagree with a rule implementation, I encourage you to post the details in the category titled <a href="https://community.sonarsource.com/c/clean-code/fp/7">Report a False-Positive/False-Negative</a>, for which we <a href="https://community.sonarsource.com/t/how-to-report-a-false-positive-false-negative/37022">have a post detailing what is required to report</a> (code sample, product versions, rule IDs…). Our teams are very reactive and enjoy engaging in these discussions.</p>

<p>There is an <a href="https://docs.sonarqube.org/latest/instance-administration/security/#:~:text=permission%C2%A0below.-,Project%20permissions,-Project%20permissions%20are"><strong>Administer Issue</strong></a> permission that in most organizations would be granted to Team leaders or experienced developers (like yourself) to be able to mark issues as False-Positive/Won’t Fix.</p>
<p>Somebody else (like your superior) has at least two options (maybe more) to discover these exceptions:</p>
<ul>
<li>Using the <strong>Issues</strong> tab of a project (or the SonarQube instance overall) to filter for issues that are marked as False-Positive / Won’t Fix if they want to do some kind of global review.</li>
<li>Configure a project-level <a href="https://docs.sonarqube.org/latest/instance-administration/notifications/">e-mail notification</a> for <strong>Issues resolved as false positive or won’t fix</strong></li>
</ul>
<p>And, to be honest, Chris, if you have a superior that trusts in Sonar 100% and trusts you and your fellow developers very little (unwilling to delegate permissions, decision making)… I think that’s the root of your problem and not one that can be fixed with product changes. We create a new user role? Enable some kind of consensus-driven issue status? Your superior could just decide not to grant it.</p>
<p>Happy to continue discussing this.</p>
            </div>

            

            

          </div>
          <div id="post_4" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.sonarsource.com/u/john.clifton"><span itemprop="name">john.clifton</span></a>
                (John Clifton)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2023-06-14T09:51:59Z">
                    June 14, 2023,  9:51am
                  </time>
                  <meta itemprop="dateModified" content="2023-06-14T09:51:59Z">
              <span itemprop="position">4</span>
              </span>
            </p>
            <div itemprop="text">
              
<p>Hi <a href="https://community.sonarsource.com/u/chris_hatton">@Chris_Hatton</a>, we are looking into something similar to this at the moment. If you would be willing, I’d love to have a short call to talk to you about your suggestion.</p>
            </div>

            

            

          </div>
          <div id="post_7" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.sonarsource.com/u/Jeremy_Cox"><span itemprop="name">Jeremy_Cox</span></a>
                (Jeremy Cox)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2023-06-28T13:24:02Z">
                    June 28, 2023,  1:24pm
                  </time>
                  <meta itemprop="dateModified" content="2023-06-28T13:30:14Z">
              <span itemprop="position">7</span>
              </span>
            </p>
            <div itemprop="text">
              <blockquote>
<p>if you have a superior that trusts in Sonar 100% and trusts you and your fellow developers very little (unwilling to delegate permissions, decision making)… I think that’s the root of your problem</p>
</blockquote>
<p>You make a fair point that anyone who uses a tool and does not understand is part of the problem.  However, if the tool could be easier to understand, that could go a long way to addressing that issue.</p>
<p>Respectfully, the root of the problem is that SonarQube is not clear to everyone who uses it.  Specifically, it offers little towards gauging what is important and and what is not.  Programmers have been engaged with a tug of war with management since the dawn of the digital era.  Managers, who don’t understand coding well enough to police it, are now offered Sonarqube as a policing tool.  They are given a bat to hit programmers over the head.  This has an easy metric for determining perfections – 0 issues found.  It’s a managers dream – a computer that sums up everything you need to know in one number.  If you give someone a bat, they’re going to use it to hit things.  It’s pretty simple.</p>
<p>The number of issues found in your project is similar to likes on social media – it’s a badge of honor to show off to all your manager friends. I have a coding library that’s tens of thousands of lines.  Military Standard data types are defined by two numbers, so my (Java) class names end with something like “_1234_567”  Like a good programmer, my fields and getters follow the same naming pattern.<br>
This violates S101, S116, S100, S101 for a total of 4.7k hits. This has caused everyone to freak out.</p>
<p>The OP point is well taken, that if I had an opportunity to add some structured comments to that report before a manager read it, the sky would not be falling.  Now I am having trouble explaining in meeting after meeting, “we violated 4 <em>MINOR</em> rules on purpose.  So if we ignore those rules like we’re supposed to, the 4,700 hits go away.”  To which they respond, “You want us to cover up 4,700 hits?”</p>
<p>Clearly, it’s a major problem that they don’t understand a minor sonarqube finding “<a href="https://docs.sonarqube.org/latest/user-guide/issues/#:~:text=MINOR%3A%20A%20quality%20flaw%20that,quality%20flaw%2C%20just%20a%20finding." rel="noopener nofollow ugc">may slightly impact developer productivity</a>” and it <strong>may also not</strong> affect quality.</p>
<p>So thanks to Sonarqube, I am going to have to make my code unreadable to a human in order to please management, which means INTENTIONALLY creating a mountain of technical debt.  But that’s okay, because Sonarqube doesn’t count it.</p>
<p>Sonarqube exacerbates the problem of communication with management; it does not help it. The problem is how the information is presented.  As OP pointed out, Programmers don’t have an opportunity to respond proactively to the issues.  It’s fair to blame managers, it also fair to blame the bad information they are given to make decisions. For example, your issue count could be broken down into “must address” and “not urgent” or the like.  It could further have something like, “4,712 issues have open discussions, here is a link.”  The idea that a single number could sum up technical debt is simply dangerous.  It encourages people to NOT investigate and learn more.  It encourages people to not listen.</p>
<p>“Dude, look, it’s really simple, your project has 4,700 sonarqube findings, everyone else has less than 100.  This is a job performance problem.”  – Overheard in a meeting</p>
<p>Finally, I have a question.  Are there articles posted by Sonarsource telling managers how to interpret sonarqube results properly?  I’ve been scouring the web for “how to handle minor sonarqube issues best practice” and found nothing useful to my case.  I’d welcome knowledge if anyone has any.</p>
            </div>

            

            

          </div>
          <div id="post_11" itemprop="comment" itemscope="" itemtype="http://schema.org/Comment">
            <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
                <a itemprop="url" href="https://community.sonarsource.com/u/Colin"><span itemprop="name">Colin</span></a>
                (Colin)
              </span>



              <span>
                  <time itemprop="datePublished" datetime="2023-07-07T11:10:25Z">
                    July 7, 2023, 11:10am
                  </time>
                  <meta itemprop="dateModified" content="2023-07-07T11:10:25Z">
              <span itemprop="position">11</span>
              </span>
            </p>
            <div itemprop="text">
              <p>Hey there <a href="https://community.sonarsource.com/u/jeremy_cox">@Jeremy_Cox</a>.</p>
<p>Thanks for the super valuable feedback (that we’ve been discussing a lot internally). I want to provide a few preliminary notes.</p>
<ul>
<li>
<p>We’re conscious of the fact that Sonar can be misused, and we’ve made some efforts to minimize how easy that is. We once had a feature (meant to “gamify” fixing issues and not introducing new ones) which… you guessed it, resulted in some managers using it to measure individual performance. Some organizations loved this feature! We removed it because it absolutely didn’t align with our values.</p>
</li>
<li>
<p>A big shift is going to come to our products soon (this year) that will shift focus on raising <em>findings</em> about <em>facts</em> about the code (<em>this is not a coding practice that aligns with our organization’s practices</em>), rather than <em>issues</em> with a hypothesized impact (“this may slightly impact developer productivity”). This repositioning might also make it easier to explain why you want to ignore a rule. T</p>
</li>
<li>
<p>As part of this shift we are also looking at how to make sure Clean Code (and Clean as You Code) is easy to understand by governance stakeholders and de-emphasize issue count. Yes, there will be product changes that have to happen as well as education/positioning that has to change (no silver bullets, only lots of reuglar ones)</p>
</li>
</ul>

<p>I don’t think we have anything regarding this. It’s a valid point I’ll pass on.</p>
<p>Please don’t hesitate to keep giving us honest feedback as things progress, or if you’ve thought of any other points you want to share. Feedback is a gift. <img src="https://emoji.discourse-cdn.com/twitter/gift.png?v=12" title=":gift:" alt=":gift:" loading="lazy" width="20" height="20"></p>
            </div>

            

            

          </div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bruce Bastian, WordPerfect co-creator, has died (251 pts)]]></title>
            <link>https://www.heraldextra.com/news/local/2024/jun/17/bruce-bastian-byu-alum-turned-tech-pioneer-and-equality-advocate-dies-at-76/</link>
            <guid>40858583</guid>
            <pubDate>Tue, 02 Jul 2024 17:11:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.heraldextra.com/news/local/2024/jun/17/bruce-bastian-byu-alum-turned-tech-pioneer-and-equality-advocate-dies-at-76/">https://www.heraldextra.com/news/local/2024/jun/17/bruce-bastian-byu-alum-turned-tech-pioneer-and-equality-advocate-dies-at-76/</a>, See on <a href="https://news.ycombinator.com/item?id=40858583">Hacker News</a></p>
<div id="readability-page-1" class="page"><section id="article_content">
															
								    <p><img width="350" height="500" src="https://ogden_images.s3.amazonaws.com/www.heraldextra.com/images/2024/06/17151419/50372586-8111-47C2-A83E-7E1AC692B4E5-350x500.jpeg" alt="">								    </p>
																<div id="caption"><p><span>Courtesy Human Rights Campaign</span></p><p>Bruce Bastian, a former tech entrepreneur, philanthropist and advocate for LGBTQ+ communities, died Sunday, June 16, 2024, at age 76.</p></div>														<!-- <input type=radio id="show" name="group"><label for="show">SHOW ARTICLE</label> 
							<div class="hide_article"> -->
								<p>Bruce Bastian, an alumnus of Brigham Young University who pioneered a successful word-processing application and later would become an advocate for the LGBTQ+ community, died Sunday.</p>
<p>Bastian, 76, passed away surrounded by his four sons, husband Clint Ford, friends and other family members, the <a href="https://www.hrc.org/press-releases/human-rights-campaign-mourns-the-loss-of-bruce-bastian-champion-for-lgbtq-equality-hrc-board-member-for-22-years" target="_blank" rel="noopener">Human Rights Campaign</a> reported.</p>
<p>His death was marked family and members of the LGBTQ+ community he championed, as well as other organizations he was involved with.</p>
<p>“I think people will remember him for a number of reasons, from his work with technology, his philanthropy, and within the LGBTQ community. As for others, we’ll remember him as a loving husband and father,” Bastian’s oldest son, Rick, told the Daily Herald.</p>
<p>Bastian was a member of the Human Rights Campaign, Encircle, Equality Utah and the Utah Pride Center. He traveled to the nation’s capital and fought for equal marriage rights while advocating for inclusion of people with differing sexual orientations.</p>
<p>“Bruce was in this fight, working at every level of politics and advocacy, for over three decades,” Kelley Robinson, president of the Human Rights Campaign, said in a press release. “He traveled all across this country on HRC’s behalf and worked tirelessly to help build an inclusive organization where more people could be a part of this work.”</p>
<p>Bastian also was a major supporter of organizations like Equality Utah, Utah Pride Center, and Encircle.</p>
<p><a href="https://encircletogether.org/" target="_blank" rel="noopener">Encircle</a> has a series of homes throughout Utah that provide mental health services, resources and tools for LGBTQ+ youth and families. Encircle opened its first location seven years ago <a href="https://encircletogether.org/visit-a-home" target="_blank" rel="noopener">in Provo</a>, and it was named after Bastian and Ford.</p>
<p>“Bruce was an invaluable member of our community and worked tirelessly to make our country a safer place for LGBTQ+ individuals,” Encircle’s CEO, Jordan Sgro, said in an emailed statement sent to the Daily Herald. “He was instrumental in building Encircle and we would not be where we are today without support from Bruce and his husband, Clint. Most importantly, Bruce was a friend and an incredible mentor, and served for years on our Board of Directors. He will be greatly missed.”</p>
<p>Prior to his social impact and philanthropic work, or even entrepreneurship, Bastian moved to Utah from southern Idaho to attend Brigham Young University. During the mid 1970s, he served as director of the <a href="https://byucougars.com/the-power-of-the-wasatch" target="_blank" rel="noopener">Cougar Marching Band</a>.</p>
<p>In 1979, while still attending the university as a graduate student in computer science, he co-founded what would eventually become WordPerfect Corp. along with faculty member Alan Ashton. It initially was developed as a word-processing software for a minicomputer owned by the City of Orem. Bastian and Ashton were able to maintain ownership of the software.</p>
<p>The company served as a dominant force in the technology space throughout the 1980s and 1990s. At one point, Bastian was worth $840 million, the <a href="https://www.deseret.com/2003/6/22/19730449/bastian-s-profile-low-151-in-utah-at-least/" target="_blank" rel="noopener">Deseret News</a> reported in 2003.</p>
<p>Bastian stepped down from his role as chairman of WordPerfect in 1994 and the company was sold to Novell a short time later.</p>
<p>Bastian would go on to focus his time on charitable causes and philanthropy. In 1997, he started the <a href="https://bastianfoundation.org/about_us" target="_blank" rel="noopener">B.W. Bastian Foundation</a>, whose commitment is to only support organizations that fully embrace equality.</p>
<p>“The impact he had on so many lives was immeasurable,” Michael Marriott, the foundation’s executive director, said in a press release. “His spirit and memory will live on through Clint, his husband of six years, through Bruce’s four sons and their families, and through the many lives he touched through his generosity, time, energy and commitment to making the world a better place. And Bruce’s legacy will continue in the work of the B.W. Bastian Foundation and its mission.”</p>
<p>Bastian also maintained his love for music and the arts. In 2010, then-President Barack Obama <a href="https://obamawhitehouse.archives.gov/realitycheck/the-press-office/president-obama-announces-more-key-administration-posts-22610" target="_blank" rel="noopener">appointed him to the Presidential Advisory Committee on the Arts</a>.</p>
<p>Bastian continued to use his resources and fortune to support organizations providing services to Utah’s LGBTQ+ community and other pro-equality causes, including the Utah Democratic Party.</p>
<p>“Bruce Bastian was a light to the people of our state,” Utah Democratic Party Chair Diane Lewis said in a statement. “His example calls on us to do more, especially when it comes to supporting our LGBTQ+ community.”</p>
<p>Bastian was born March 23, 1948, in Twin Falls, Idaho. He grew up on his family’s farm before moving south to Provo to attend BYU, where he earned a bachelor’s in music education and his master’s in computer science.</p>
<p>His adult life was spent in Orem and Palm Springs, California, where he lived with Ford.</p>
<p>In addition to his partner and four sons, Bastian also leaves behind 14 grandchildren, two sisters and a brother.</p>
<p>Rick Bastian says he wants his father to be remembered as being courageous, someone who stood up for social justice and advocated for others. “We’ll miss him dearly,” he said.</p>

														                        


<h3>Newsletter</h3>
<section id="newsletter">
    <p>Join thousands already receiving our daily newsletter.</p>
    
</section>



					</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta 3D Gen (419 pts)]]></title>
            <link>https://ai.meta.com/research/publications/meta-3d-gen/</link>
            <guid>40857517</guid>
            <pubDate>Tue, 02 Jul 2024 15:19:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/research/publications/meta-3d-gen/">https://ai.meta.com/research/publications/meta-3d-gen/</a>, See on <a href="https://news.ycombinator.com/item?id=40857517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2>Zusammenfassung</h2><p>We introduce Meta 3D Gen (3DGen), a new state-of-the-art, fast pipeline for text-to-3D asset generation. 3DGen offers 3D asset creation with high prompt fidelity and high-quality 3D shapes
and textures in under a minute. It supports physically-based rendering (PBR), necessary for 3D asset relighting in real-world applications. Additionally, 3DGen supports generative retexturing of previously generated (or artist-created) 3D shapes using additional textual inputs provided by the user. 3DGen integrates key technical components, Meta 3D AssetGen and Meta 3D TextureGen, that we developed for text-to-3D and text-to-texture generation, respectively. By combining their strengths, 3DGen represents 3D objects simultaneously in three ways: in view space, in volumetric space, and in UV (or texture) space. The integration of these two techniques achieves a win rate of
68% with respect to the single-stage model. We compare 3DGen to numerous industry baselines, and show that it outperforms them in terms of prompt fidelity and visual quality for complex textual prompts, while being significantly faster.</p><a role="button" href="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.2365-6/449707112_509645168082163_2193712134508658234_n.pdf?_nc_cat=111&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=5bSbn3KaluAQ7kNvgHdZ399&amp;_nc_ht=scontent.fzrh3-1.fna&amp;gid=AXBASXz1KO8tg3z1y-Ars0j&amp;oh=00_AYCt-8K376OTlrWw8mqkXdaNoo4nF8ugEL3fZyLp9Kc7oQ&amp;oe=668A1851" data-ms="{&quot;creative&quot;:&quot;button&quot;,&quot;creative_detail&quot;:&quot;button&quot;,&quot;create_type&quot;:&quot;button&quot;,&quot;create_type_detail&quot;:&quot;button&quot;}" target="_blank" data-lnfb-mode="ie"><p>Download the Paper</p></a></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[GraphRAG is now on GitHub (238 pts)]]></title>
            <link>https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/</link>
            <guid>40857174</guid>
            <pubDate>Tue, 02 Jul 2024 14:41:19 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/">https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/</a>, See on <a href="https://news.ycombinator.com/item?id=40857174">Hacker News</a></p>
<div id="readability-page-1" class="page"><div itemprop="articleBody" data-bi-an="post-body">

						
<figure><img fetchpriority="high" decoding="async" width="1400" height="788" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1.png" alt="GraphRAG blog hero" srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-300x169.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1024x576.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-768x432.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1066x600.png 1066w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-655x368.png 655w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-240x135.png 240w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-640x360.png 640w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-960x540.png 960w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRag2024-BlogHeroFeature-1400x788-1-1280x720.png 1280w" sizes="(max-width: 1400px) 100vw, 1400px"></figure>



<div data-bi-an="margin-callout">
	<ul>
		<li>
						<span>Download</span>
			<a href="https://github.com/microsoft/graphrag" target="_blank" data-bi-type="annotated-link" aria-label="GraphRAG" data-bi-an="margin-callout" data-bi-cn="GraphRAG">
				GraphRAG&nbsp;
			</a>
					</li>
	</ul>
</div>







<p>Earlier this year, we introduced <a href="https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/">GraphRAG<span> (opens in new tab)</span></a>, a graph-based approach to retrieval-augmented generation (RAG) that enables question-answering over private or previously unseen datasets. Today, we’re pleased to announce that GraphRAG is now available on <a href="https://github.com/microsoft/graphrag" target="_blank" rel="noreferrer noopener">GitHub<span> (opens in new tab)</span></a>, offering more structured information retrieval and comprehensive response generation than naive RAG approaches.&nbsp;The GraphRAG code repository is complemented by a <a href="https://github.com/Azure-Samples/graphrag-accelerator/" target="_blank" rel="noreferrer noopener">solution accelerator<span> (opens in new tab)</span></a>, providing an easy-to-use API experience hosted on Azure that can be deployed code-free in a few clicks. </p>



<p>GraphRAG uses a large language model (LLM) to automate the extraction of a rich knowledge graph from any collection of text documents. One of the most exciting features of this graph-based data index is its ability to report on the semantic structure of the data prior to any user queries. It does this by detecting “communities” of densely connected nodes in a hierarchical fashion, partitioning the graph at multiple levels from high-level themes to low-level topics, as illustrated in Figure 1. Using an LLM to summarize each of these communities creates a hierarchical summary of the data, providing an overview of a dataset without needing to know which questions to ask in advance. Each community serves as the basis of a <em>community summary</em> that describes its entities and their relationships.</p>



<figure><img decoding="async" width="1400" height="721" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1.png" alt="Figure 1: Two network diagrams shown side-by-side with the same layout but different node colors. The diagram on the left has fewer larger clusters of color, while the diagram on the right has a greater number of smaller color clusters." srcset="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1.png 1400w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-300x155.png 300w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-1024x527.png 1024w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-768x396.png 768w, https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/GraphRAG-knowledge-graph_Fig1-240x124.png 240w" sizes="(max-width: 1400px) 100vw, 1400px"><figcaption>Figure 1. Knowledge graph of entity nodes and relationship edges derived from a <a href="https://github.com/yixuantt/MultiHop-RAG/" target="_blank" rel="noreferrer noopener">news dataset<span> (opens in new tab)</span></a>, with different colors representing various communities. Level 0 communities (left) represent the highest-level themes of the dataset, while level 1 communities (right) show the emergence of more granular topics within these themes.</figcaption></figure>







<p>In a recent <a href="https://www.microsoft.com/en-us/research/publication/from-local-to-global-a-graph-rag-approach-to-query-focused-summarization/">preprint</a>, we explore how these community summaries can also help answer <em>global questions</em>—which address the entire dataset rather than focusing on specific chunks of text—where naive RAG approaches based on vector search fall short. For example, consider the question “What are the main themes in the dataset?” This is a reasonable starting point but one where naive RAG will always give misleading answers. This is because it generates answers from chunks of text semantically similar to the question, not necessarily from the subset of input texts needed to answer it.</p>



<p>However, if a question addresses the entire dataset, <em>all</em> input texts should be considered. Since naive RAG only considers the top-<em>k </em>most similar chunks of input text, it fails. Even worse, it will match the question against chunks of text that are superficially similar to that question, resulting in misleading answers. Community summaries help answer such global questions because the graph index of entity and relationship descriptions has already considered all input texts in its construction. Therefore, we can use a map-reduce approach for question answering that retains all relevant content from the global data context:</p>



<ol start="1">
<li>Group community reports up to the LLM context window size.&nbsp;</li>



<li>Map the question across each group to create community answers.&nbsp;</li>



<li>Reduce all relevant community answers into a final global answer.&nbsp;&nbsp;</li>
</ol>



<h2 id="evaluation-and-results">Evaluation and results&nbsp;</h2>



<p>To evaluate this approach against naive RAG and hierarchical source-text summarization, we used the LLM GPT-4 to generate a diverse set of activity-centered sense-making questions from short descriptions of two datasets: podcast transcripts and news articles. We then selected three metrics for head-to-head comparison of generated answers, as evaluated by an LLM judge: comprehensiveness (covers all aspects in detail), diversity (provides different perspectives), and empowerment (supports informed decision making).</p>



<p>The results show that GraphRAG, when using community summaries at any level of the community hierarchy, outperforms naive RAG on comprehensiveness and diversity (~70–80% win rate). GraphRAG using intermediate- and low-level community summaries also performed better than source text summarization on these metrics at lower token costs (~20–70% token use per query). Performance was competitive with hierarchical source text summarization for the highest-level communities at substantially lower token costs (~2–3% token use per query). This is shown in Figure 2.</p>



<figure><img decoding="async" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/Responses_GraphRAG.png" alt="Question: Which public figures are repeatedly mentioned across various entertainment articles? Naive RAG response: Public figures who are repeatedly mentioned across various entertainment articles include <Public figures 1, 2, 3, and 4>. These individuals have been highlighted for various reasons, ranging from their professional achievements to their personal lives. <Public figure 1> [...] <Public figure 2> [...] <Public figure 3> [...] <Public figure 4> [...] These figures are frequently covered due to their high-profile status and the public’s interest in their careers and personal lives. Their activities, whether in music, sports, or personal relationships, have significant cultural and economic impacts, as evidenced by the media coverage and public reactions. GraphRAG response: The entertainment industry is vast and diverse, encompassing film, television, music, sports, and digital media. Certain public figures stand out due to their significant contributions and influence across these sectors. The following summary highlights key individuals who are repeatedly mentioned in various entertainment articles, reflecting their impact and presence within the industry. Actors and Directors [...20 figures...] Public Figures in Controversy [...3 figures...] Musicians and Executives [...5 figures...] Athletes and Coaches [...7 figures...] Influencers and Entrepreneurs [...3 figures...] The repeated mention of these figures in entertainment articles signifies their ongoing relevance and the public’s interest in their work. Their influence spans across various aspects of entertainment, from shaping cultural narratives in film and television to driving trends in music and digital media. These individuals not only contribute to their respective fields but also influence the broader cultural landscape, often becoming central figures in social discussions and public discourse. LLM evaluation: Comprehensiveness: Winner = GraphRAG; Diversity: Winner = GraphRAG; Empowerment: Winner = GraphRAG. "><figcaption>Figure 2. Comparison of naive RAG and GraphRAG responses to a global question about a <a href="https://github.com/yixuantt/MultiHop-RAG/" target="_blank" rel="noreferrer noopener">news dataset<span> (opens in new tab)</span></a> indicates that GraphRAG outperformed naïve RAG in terms of comprehensiveness, diversity, and empowerment.</figcaption></figure>



	<div data-bi-an="promo" data-bi-id="1044939">
		

		<p>
		<span>on-demand event</span>
	</p>
	
	<div>
						<p><a href="https://www.microsoft.com/en-us/research/quarterly-brief/jun-2024-brief/" aria-label="Microsoft Research Forum Episode 3" data-bi-cn="Microsoft Research Forum Episode 3" target="_blank">
					<img decoding="async" src="https://www.microsoft.com/en-us/research/uploads/prodnew/2024/06/RF-Ep3-Recap-BlogHeroFeature-1400x788-1.jpg" alt="Microsoft Research Forum | Episode 3 | panel discussion">
				</a>
			</p>
			
			<div>

									<h2>Microsoft Research Forum Episode 3</h2>
				
								<p>Dive into the importance of globally inclusive and equitable AI, updates on AutoGen and MatterGen, explore novel new use cases for AI, and more.</p>
				
								
							</div><!--/.msr-promo__content-->
	</div><!--/.msr-promo__inner-wrap-->
</div><!--/.msr-promo-->
	


<h2 id="research-insights-and-future-directions">Research insights and future directions&nbsp;</h2>



<p>Through the initial research cycle, we demonstrated that LLMs can successfully derive rich knowledge graphs from unstructured text inputs, and these graphs can support a new class of global queries for which (a) naive RAG cannot generate appropriate responses, and (b) hierarchical source text summarization is prohibitively expensive per query. The overall suitability of GraphRAG for any given use case, however, depends on whether the benefits of structured knowledge representations, readymade community summaries, and support for global queries outweigh the upfront costs of graph index construction.</p>



<p>We’re currently exploring various approaches to reduce these costs while maintaining response quality. Our latest work on automatically tuning LLM extraction prompts to the problem domain is an example of how we are reducing the upfront effort required to customize these prompts, enumerate entity types, create few-shot examples, and so on. To enable evaluation of GraphRAG with minimal upfront indexing costs, we’re also investigating NLP-based approaches to approximating the knowledge graph and community summaries that would be generated by a full indexing process. Our goal is to ensure that, whatever the constraints of the deployment context, there is a GraphRAG configuration that can accommodate these constraints while still delivering exceptional response quality.</p>







<p>By making GraphRAG and a&nbsp;<a href="https://github.com/Azure-Samples/graphrag-accelerator/">solution accelerator<span> (opens in new tab)</span></a> publicly available, we aim to make graph-based RAG approaches more accessible for users and use cases where it’s critical to understand data at a global level. We encourage community feedback and suggestions on both the code repository and solution accelerator as we work together to enable the next generation of RAG experiences.</p>



<h2 id="acknowledgements">Acknowledgements</h2>



<p><a href="https://www.microsoft.com/en-us/research/people/joshbradley/">Joshua Bradley</a>, Christine Caggiano, Mónica Carvajal,&nbsp;<a href="https://www.microsoft.com/en-us/research/people/achao/">Alex Chao</a>, Newman Cheng, Ed Clark, <a href="https://www.microsoft.com/en-us/research/people/bcutler/">Ben Cutler</a>, <a href="https://www.microsoft.com/en-us/research/people/andresmor/">Andres Morales Esquivel</a>, <a href="https://www.microsoft.com/en-us/research/people/amhoak/">Nathan Evans</a>, <a href="https://www.microsoft.com/en-us/research/people/alonsog/">Alonso Guevara Fernández</a>, <a href="https://www.microsoft.com/en-us/research/people/amhoak/" target="_blank" rel="noreferrer noopener">Amber Hoak</a>, <a href="https://www.microsoft.com/en-us/research/people/kalytv/">Kate Lytvynets</a>, <a href="https://www.microsoft.com/en-us/research/people/gaudyb/">Gaudy Blanco Meneses</a>, <a href="https://www.microsoft.com/en-us/research/people/moapurva/">Apurva Mody</a>, <a href="https://www.microsoft.com/en-us/research/people/chtrevin/">Robert Ness</a>, Gabriel Nieves-Ponce, Douglas Orbaker, Richard Ortega, Rodrigo Racanicci, Billie Rinaldi, Katy Smith, <a href="https://www.microsoft.com/en-us/research/people/smithsarah/">Sarah Smith</a>, Shane Solomon, <a href="https://www.microsoft.com/en-us/research/people/ddesouza/">Dayenne Souza</a>, <a href="https://www.microsoft.com/en-us/research/people/datittsw/">David Tittsworth</a>, <a href="https://www.microsoft.com/en-us/research/people/chtrevin/" target="_blank" rel="noreferrer noopener">Chris Trevino</a>, Derek Worthen</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[8cc.vim: Pure Vim script C Compiler (131 pts)]]></title>
            <link>https://github.com/rhysd/8cc.vim</link>
            <guid>40857120</guid>
            <pubDate>Tue, 02 Jul 2024 14:36:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/rhysd/8cc.vim">https://github.com/rhysd/8cc.vim</a>, See on <a href="https://news.ycombinator.com/item?id=40857120">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">8cc.vim: Pure Vim script C Compiler</h2><a id="user-content-8ccvim-pure-vim-script-c-compiler" aria-label="Permalink: 8cc.vim: Pure Vim script C Compiler" href="#8ccvim-pure-vim-script-c-compiler"></a></p>
<p dir="auto"><a href="https://travis-ci.org/rhysd/8cc.vim" rel="nofollow"><img src="https://camo.githubusercontent.com/d7cbcca5308106b2c7a3b0653eb93263da6e72984b223718ec60448530ba2bc5/68747470733a2f2f7472617669732d63692e6f72672f72687973642f3863632e76696d2e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.org/rhysd/8cc.vim.svg?branch=master"></a></p>
<p dir="auto">This is a Vim script port of <a href="https://github.com/rui314/8cc">8cc</a> built on <a href="https://github.com/shinh/elvm">ELVM</a>.
In other words, this is a complete C compiler written in Vim script.</p>
<p dir="auto"><a href="https://github.com/rui314/8cc">8cc</a> is a nicely-written small C compiler for x86_64 Linux. It's C11-aware and self-hosted.</p>
<p dir="auto"><a href="https://github.com/shinh/elvm">ELVM</a> is a <strong>E</strong>so <strong>L</strong>ang <strong>V</strong>irtual <strong>M</strong>achine.
ELVM retargets 8cc to emit its own intermediate representation, EIR.
ELVM compiles C code into EIR with the retargeted 8cc as frontend. And then translates EIR into various targets (Python, Ruby, C,
BrainFxxk, Piet, Befunge, Emacs Lisp, ...) in backend. The architecture resembles LLVM.
<a href="http://shinh.skr.jp/slide/elvm/000.html" rel="nofollow">This presentation</a> is a good stuff to know ELVM architecture further (though in Japanese).</p>
<p dir="auto">ELVM can compile itself into various targets.
So I added a new 'Vim script' backend and use it to translate C code of 8cc into Vim script.</p>
<p dir="auto">Now 8cc.vim is written in pure Vim script. 8cc.vim consists of frontend (customized 8cc) and backend (ELC).
It can compile C code into Vim script. And of course Vim can evaluate the generated Vim script code.</p>
<p dir="auto">Note that this is a toy project. 8cc.vim is much much slower.
It takes 824 (frontend: 430 + backend: 396) seconds to compile the simplest <code>putchar()</code> program
on MacBook Pro Early 2015 (2.7 GHz Intel Core i5). But actually it works!</p>
<p dir="auto">As VM runs on Vim script, 8cc.vim works on Linux, OS X and (hopefully) Windows.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">Please clone this repository and <code>:packadd</code> (please see <code>:help pack-add</code>).</p>
<p dir="auto">Or please use your favorite plugin manager (<a href="https://github.com/junegunn/vim-plug">vim-plug</a>,
<a href="https://github.com/Shougo/dein.vim">dein.vim</a> and so on).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<ul dir="auto">
<li>Commands
<ul dir="auto">
<li><code>:EccCompile</code></li>
<li><code>:EccRun</code></li>
</ul>
</li>
<li>Functions
<ul dir="auto">
<li><code>eightcc#compile()</code></li>
<li><code>eightcc#run()</code></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compile C Code</h2><a id="user-content-compile-c-code" aria-label="Permalink: Compile C Code" href="#compile-c-code"></a></p>
<p dir="auto">Prepare your C code in the current buffer. Following is a 'Hello world' example.</p>
<div dir="auto" data-snippet-clipboard-copy-content="int putchar(int x);

int main() {
  const char* p = &quot;Hello, world!\n&quot;;
  for (; *p; p++)
    putchar(*p);
  return 0;
}"><pre><span>int</span> <span>putchar</span>(<span>int</span> <span>x</span>);

<span>int</span> <span>main</span>() {
  <span>const</span> <span>char</span><span>*</span> <span>p</span> <span>=</span> <span>"Hello, world!\n"</span>;
  <span>for</span> (; <span>*</span><span>p</span>; <span>p</span><span>++</span>)
    <span>putchar</span>(<span>*</span><span>p</span>);
  <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto">Then execute <code>:EccCompile</code> command. Note that you can use several options such as <code>--verbose</code> for this.
Please see <code>:EccCompile --help</code> for more detail.</p>
<p dir="auto">It takes a long time 20 minutes or more.  Let's take a rest and get some ☕.</p>
<p dir="auto">As the result, new buffer is opened with Vim script code which was compiled from C code. Load it by
<code>:w putchar.vim</code> and <code>:source putchar.vim</code>.</p>
<p dir="auto">Finally, execute below Vim script code by your hand.  The compiled code is run on VM on Vim script.
The <code>SetupVM()</code> function creates a VM instance.</p>
<div data-snippet-clipboard-copy-content=":let vm = SetupVM()
:call vm.run()"><pre><code>:let vm = SetupVM()
:call vm.run()
</code></pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/rhysd/ss/master/8cc.vim/hello.png"><img src="https://raw.githubusercontent.com/rhysd/ss/master/8cc.vim/hello.png" alt="result screen shot"></a></p>
<p dir="auto">If you want to see only the result of running Vim script, you can use <code>:EccRun</code> to skip above process.</p>
<p dir="auto">Corresponding to <code>:EccCompile</code> and <code>:EccRun</code>, you can use <code>eightcc#compile()</code> and <code>eightcc#run()</code> functions.
They can take one dictionary for execution options.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">MIT License</p>
<p dir="auto">Copyright (c) 2016 rhysd</p>
<p dir="auto">Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:</p>
<p dir="auto">The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.</p>
<p dir="auto">THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The history of Alt+number sequences (115 pts)]]></title>
            <link>https://devblogs.microsoft.com/oldnewthing/20240702-00/?p=109951</link>
            <guid>40857092</guid>
            <pubDate>Tue, 02 Jul 2024 14:33:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devblogs.microsoft.com/oldnewthing/20240702-00/?p=109951">https://devblogs.microsoft.com/oldnewthing/20240702-00/?p=109951</a>, See on <a href="https://news.ycombinator.com/item?id=40857092">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="featured">
                         <p>
            July 2nd, 2024</p><!-- .entry-meta -->
        <p>Once upon a time, the IBM PC was released.</p>
<p>In the IBM PC BIOS, you could enter characters that weren’t present on the keyboard by holding the <kbd>Alt</kbd> key and typing the decimal value on the numeric keypad. For example, you could enter ñ by holding <kbd>Alt</kbd> and typing <kbd>Numpad1</kbd> <kbd>Numpad6</kbd> <kbd>Numpad4</kbd>, then releasing the <kbd>Alt</kbd> key.</p>
<p>For expository simplicity, I will henceforth use the notation <kbd>Alt</kbd>+<kbd>164</kbd> to indicate that you press the <kbd>Alt</kbd> key, then type the specified digits in sequence on the numeric keypad, then release the <kbd>Alt</kbd> key.</p>
<p>Okay, so in the IBM PC BIOS, when you typed <kbd>Alt</kbd>+<kbd>…</kbd>, the code numbers were treated as decimal byte values, and the result on the screen came from your video card’s character generator. In the United States, the character generator’s ROM showed what we today call <a href="https://en.wikipedia.org/wiki/Code_page_437"> Code Page 437</a>.</p>
<p>When it was introduced, Windows in the United States used <a href="https://en.wikipedia.org/wiki/Windows-1252"> Code Page 1252</a> as its 8-bit character set, which it called the “ANSI character set”; the old BIOS character set was retroactively named the OEM character set. To preserve compatibility with MS-DOS, if you used the <kbd>Alt</kbd> key in conjunction with the numeric keypad, the number you typed was still looked up in OEM character set, so that your muscle-memory code numbers still worked. You could still type <kbd>Alt</kbd>+<kbd>164</kbd> to get your ñ, even though the code number for ñ in Code Page 1252 is 241, not 164.</p>
<p>If you wanted to type a character that had no OEM equivalent, you could prefix a numeric keypad <kbd>0</kbd> to indicate that you wanted the value looked up in the ANSI code page. Therefore, you could type <kbd>Alt</kbd>+<kbd>0169</kbd> to get a ©, which did not exist in the OEM code page. You could also type <kbd>Alt</kbd>+<kbd>0241</kbd> to get your precious ñ, using the ANSI code point number rather than the OEM code point number.</p>
<p>If you entered a number larger than 255, both Windows and the IBM PC BIOS took your value mod 256, so typing <kbd>Alt</kbd>+<kbd>259</kbd> was the same as typing <kbd>Alt</kbd>+<kbd>3</kbd>. Both gave you OEM code point 3, which for Code Page 437 is a heart ♥.</p>
<p>If you ask the Internet how to type some of these non-ASCII characters on Windows, you may see people (and large language models) that tell you to type, say, <kbd>Alt</kbd>+<kbd>9731</kbd> to get a Unicode snowman ☃. Unfortunately, from what we’ve learned above, this doesn’t work. You instead get the OEM character whose value is 9731 mod 256 = 3, or the aforementioned heart ♥.</p>
<p>A customer reported that a recent Windows update broke their ability to type a snowman by using <kbd>Alt</kbd>+<kbd>9731</kbd>. We explained that the update was not at fault; rather, <kbd>Alt</kbd>+<kbd>9731</kbd> was never supposed to produce a snowman at all! But the customer insisted that it used to work.</p>
<p>A closer investigation of the issue revealed the reason.</p>
<p>You see, while it’s true that the <kbd>Alt</kbd>+<kbd>…</kbd> decimal value is taken mod 256, that is just the default behavior of the Windows input system. But some controls (most notably the RichEdit control) override the default handling of the <kbd>Alt</kbd>+<kbd>…</kbd> sequence and parse out the decimal value <i>mod 65536</i> rather than <i>mod 256</i>.</p>
<p>This means that whether the <kbd>Alt</kbd>+<kbd>…</kbd> value is taken mod 256 depends on what kind of control you are typing into.</p>
<p>By default, the value is taken mod 256, and <kbd>Alt</kbd>+<kbd>9731</kbd> gives you a heart.</p>
<p>But if you happen to be using a RichEdit control, then the <kbd>Alt</kbd>+<kbd>…</kbd> value is taken mod 65536, and <kbd>Alt</kbd>+<kbd>9731</kbd> gives you a snowman.</p>
<p>(I don’t know of anybody who takes the value mod 2097151, to support direct entry of code points outside the Basic Multilingual Plane.)</p>

        

        
		
        
	</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[With fifth busy beaver, researchers approach computation's limits (436 pts)]]></title>
            <link>https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/</link>
            <guid>40857041</guid>
            <pubDate>Tue, 02 Jul 2024 14:27:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/">https://www.quantamagazine.org/amateur-mathematicians-find-fifth-busy-beaver-turing-machine-20240702/</a>, See on <a href="https://news.ycombinator.com/item?id=40857041">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>One memorable encounter occurred while Ligocki was visiting Germany the summer after his sophomore year, when he took a side trip to Berlin to meet up with Marxen. “We got through the language barrier through the medium of busy beavers,” he said. The medium of beer also helped. Ligocki ended up having too many and missed his train back to Hamburg.</p>
<p>The busy beaver bug stuck with Ligocki throughout college, but when he graduated and found a job, life got in the way. He returned to the hunt from time to time, but never for long. In early 2022, he set up an <a href="https://groups.google.com/g/busy-beaver-discuss">online discussion group</a> to help researchers stay in touch. Then in May, Stérin discovered the mailing list and sent an invitation to join the Busy Beaver Challenge. Ligocki needed no convincing.</p>

<p>One of his first contributions to the project was reviving a technique invented by Marxen, which they’d discussed in that Berlin pub 16 years earlier. Called the “closed tape language method,” it was a new way to identify patterns on a Turing machine’s tape that indicate it will never halt. This is the basic strategy behind programs that identify loopers and many other species of non-halting machines, but the closed tape language method had the potential to identify a much broader class of patterns using a unified mathematical framework.</p>
<p>Ligocki wrote a <a href="https://www.sligocki.com/2022/06/10/ctl.html">blog post</a> introducing his new collaborators to the technique, but even though the theoretical idea was very general, he didn’t know how to write a program that would cover all the cases. Blanchard figured out how to do that shortly after joining the project in the fall, but his program was relatively slow. Then two other contributors found ways to make it run much faster. Within the span of a few months, the closed tape language technique had gone from a promising idea to one of their <a href="https://discuss.bbchallenge.org/t/decider-finite-automata-reduction/123">most powerful tools</a>. It could even handle 10 of Georgiev’s 43 holdouts, nicknamed <a href="https://bbchallenge.org/skelet">Skelet machines</a> in his honor.</p>
<p>“This thing would never have existed with any one person contributing,” Ligocki said.</p>
<h2><strong>A Monster Approaches</strong></h2>
<p>As the months passed, new contributors discovered the Busy Beaver Challenge and began chipping away at different parts of the problem. But many machines remained unsolved, and two developed especially fearsome reputations.</p>
<p>The first was <a href="https://bbchallenge.org/1LC1LE_---1LD_1RD0LD_1LA1RE_0LB0RC">Skelet #1</a>, which kept alternating between phases of predictable and chaotic behavior. Then in March 2023, Ligocki and Pavel Kropitz — a Slovakian contributor who doesn’t speak English and communicates with the rest of the team using Google Translate — developed a series of ideas that finally <a href="https://www.sligocki.com/2023/03/13/skelet-1-infinite.html">cracked it open</a>. Using a souped-up version of Marxen and Buntrock’s 30-year-old accelerated simulation technique, they discovered that the tug-of-war between order and chaos did end, but only after more than a trillion trillion steps. Then it finally settled into a repeating cycle that was itself unusually long. Practically all infinite loops begin repeating within 1,000 steps; Skelet #1’s was more than 8 billion steps long.</p>
<p>“Who ordered that?” Blanchard said. “Where did that come from? Why is it here?”</p>

<p>The machine’s behavior was so strange, and the proof combined so many different ideas, that for nearly five months Ligocki wasn’t sure of the result. That period of uncertainty was dispelled by a new contributor — a 21-year-old self-taught programmer named <a href="https://github.com/meithecatte">Maja Kądziołka</a>, who mostly goes by the single name mei.</p>
<p>Kądziołka grew up in Poland and attended the University of Warsaw for one semester in fall 2021 before dropping out — the rigidity of the curriculum and the move to remote instruction after a surge of Covid-19 cases didn’t fit well with their learning style. They worked at a software company for a little over a year but increasingly found the work draining, and began looking for something more intellectually stimulating. They found it in Coq, the software designed to encode and certify the validity of mathematical proofs.</p>

<p>The Busy Beaver Challenge contributors were already using computer programs in their proofs, but like paper-and-pencil proofs, computer programs are vulnerable to errors. In Coq proofs, the code won’t run unless every line logically follows from the preceding ones, making errors effectively impossible. To Kądziołka, figuring out how to craft these proofs began to feel like a game. “It’s almost addictive,” they said. “I started at a normal hour, and then it was night. Then it was morning.”</p>
<p>After learning Coq, Kądziołka began looking for an open problem to test it out. That’s when they found the Busy Beaver Challenge. A few weeks later, they’d <a href="https://github.com/meithecatte/busycoq">translated</a> several of the team’s proofs into Coq, including Ligocki and Kropitz’s proof that Skelet #1 never halts — Ligocki could finally be sure about it. Suddenly, an even higher standard of rigor than Stérin’s emphasis on reproducibility seemed possible. And it had all started with someone who had no formal training at all — an amateur mathematician.</p>
<p>“Let’s remember that means a lover of mathematics,” Moore said. “It is not a pejorative term.”</p>
<h2><strong>The Dam Breaks</strong></h2>
<p>Around the same time, a graduate student named <a href="http://chrisxudoesmath.com/">Chris Xu</a> made a breakthrough on the second monstrous machine — <a href="https://bbchallenge.org/1LB---_0RC1LE_0RD1RC_1LA1RB_0LB0LA">Skelet #17</a>. It was usually easy to summarize the behavior of even the most fiendish five-rule Turing machines once you figured out how they worked. “Then you encounter some bullshit like Skelet 17, and you go, ‘Nah, the universe is trolling us,’” Kądziołka said. Understanding Skelet #17 by studying the patterns on its tape was like deciphering a secret message wrapped in four layers of encryption: Cracking one code just revealed another totally unrelated code, and two more below that. Xu had to decipher all of them before he could finally prove that the machine never halted.</p>
<p><a href="http://chrisxudoesmath.com/papers/skelet17.pdf">Xu’s proof</a> was brilliant, but it involved some mathematical intuition that nobody knew how to formalize in the precise terms demanded by Coq. What’s more, the Busy Beaver Challenge’s work wasn’t done: While Skelet #1 and #17 were the two machines that had seemed most formidable, some others remained to be solved, and still more had only been solved using inefficient programs. That was no way to convince the world.</p>

<p>“We wanted to make sure that it was something reasonably reproducible,” Blanchard said, “and also not write a proof where we would say, ‘Step 63: Let this program run for six months.’”</p>
<p>Over the following months, the community slowly cobbled together proofs for the remaining machines, but most had yet to be translated into Coq. Then in April a <a href="https://discuss.bbchallenge.org/t/proving-bb-5-in-coq/225">mysterious new contributor</a> known only by the pseudonym mxdys came in to finish the job. Nobody on the team knows where mxdys is located or any other personal details about them. In a Discord direct message exchange, they mentioned a long-standing interest in mathematical games, but they declined to provide more information about their background.</p>
<p>On May 10, mxdys posted a characteristically succinct message to the Discord server: “The Coq proof of BB(5) is finished.” Stérin replied a minute later with a series of seven exclamation points. In a matter of weeks, mxdys had refined the community’s techniques and synthesized their results into a single <a href="https://github.com/ccz181078/Coq-BB5">40,000-line Coq proof</a>.</p>
<p>“This is not a thing that’s easy to formalize,” said <a href="https://yforster.de/">Yannick Forster</a>, a Coq expert at the French national research institute Inria who reviewed the proof. “I’m still positively shocked.”</p>
<p>The machine that Marxen and Buntrock had discovered over 30 years earlier, which halted after 47 million steps, really was the fifth busy beaver.</p>
<p>“These news are very exciting for me,” Georgiev wrote in an email. “I never expected that this problem would be solved in my time.”</p>
<p>But for another Busy Beaver pioneer, the news came too late. Allen Brady <a href="https://www.rgj.com/obituaries/pnvs0805561">died on April 21</a>, less than a month before the proof was finished. He was 90 years old.</p>
<h2><strong>Where Beavers Roam</strong></h2>
<p>The Busy Beaver Challenge contributors have begun to draft a formal academic paper describing their results, supplementing mxdys’ Coq proof with a human-readable one. That’ll take a while: Most machines were proved non-halting in multiple ways, and the team will need to decide how best to combine the results into a single proof.</p>

<p>Meanwhile, part of the team has moved on to the next beaver. But just four days ago, mxdys and another contributor known as Racheline discovered a barrier for BB(6) that seems insurmountable: a six-rule machine whose halting problem resembles a famously intractable math problem called the <a href="https://www.quantamagazine.org/computer-scientists-attempt-to-corner-the-collatz-conjecture-20200826/">Collatz conjecture</a>. Connections between Turing machines and the Collatz conjecture date back to a <a href="https://link.springer.com/article/10.1007/BF01409968">1993 paper</a> by the mathematician <a href="https://bbchallenge.org/~pascal.michel/index.html">Pascal Michel</a>, but the newly discovered machine, dubbed “<a href="https://bbchallenge.org/1RB1RA_0LC1LE_1LD1LC_1LA0LB_1LF1RE_---0RA&amp;status=undecided">Antihydra</a>,” is the smallest one that appears unsolvable without a conceptual breakthrough in mathematics. That adds an extra layer of significance to the BB(5) result.</p>
<p>“It’s conceivable that this is the last busy beaver number that we will ever know,” Aaronson said.</p>
<p>There are many variants of the original busy beaver problem, and some Busy Beaver Challenge contributors plan to keep working on these. But not everyone intends to continue this work. They each came to the project on their own, for their own reasons, and their journeys are beginning to diverge.</p>
<p>Stérin wants to develop software tools to facilitate collaborative online projects in other areas of mathematics. “The thing that BB challenge brought me is the deep, deep, deep conviction that it’s an extremely effective way of performing research,” he said. “It deserves to have a bigger stage.”</p>

<p>Kądziołka too is pulling back, after developing a fascination with the European international rail network. “I will probably come back to busy beaver things again at some point, but currently it’s not the thing on my mind,” they said. “I’m currently pursuing becoming a train driver.”</p>
<p>Ligocki thinks he’ll keep up his busy beaver hunting, but after 20 years of switching between bursts of intense activity and not thinking about beavers at all, he’s learned not to put too much stock in his predictions.</p>
<p>“It’s kind of like the halting problem,” he said. “You just never can quite tell what’s going to happen.”</p>
<p><em>Editor’s note: Scott Aaronson is a member of&nbsp;</em>Quanta Magazine<em>’s&nbsp;</em><a href="https://www.quantamagazine.org/about/"><em>advisory board</em></a><em>.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Adding Mistral Codestral and GPT-4o to Jupyter Notebooks (230 pts)]]></title>
            <link>https://github.com/pretzelai/pretzelai/blob/main/README.md</link>
            <guid>40857009</guid>
            <pubDate>Tue, 02 Jul 2024 14:23:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/pretzelai/pretzelai/blob/main/README.md">https://github.com/pretzelai/pretzelai/blob/main/README.md</a>, See on <a href="https://news.ycombinator.com/item?id=40857009">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true" aria-labelledby="file-name-id-wide file-name-id-mobile"><article itemprop="text"><p dir="auto"><h3 tabindex="-1" dir="auto">Pretzel 🥨</h3><a id="user-content-pretzel-" aria-label="Permalink: Pretzel 🥨" href="#pretzel-"></a></p>
  

<p dir="auto">
   <a href="https://github.com/pretzelai/pretzelai/stargazers"><img src="https://camo.githubusercontent.com/0d6d5fa196151643c6eb985ccf4cd6800e261162166a005fa1bbab46813366a4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f707265747a656c61692f707265747a656c6169" alt="Github Stars" data-canonical-src="https://img.shields.io/github/stars/pretzelai/pretzelai"></a>
   <a href="https://pypi.org/project/pretzelai/" rel="nofollow"><img src="https://camo.githubusercontent.com/12c4cc1800522ce874d09736f3959cb380e3213fec8f67482e79afcf5a5d6a46/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f707265747a656c61692e7376673f7374796c653d666c61742d737175617265266c6162656c3d507950492b507265747a656c4149" alt="Issues" data-canonical-src="https://img.shields.io/pypi/v/pretzelai.svg?style=flat-square&amp;label=PyPI+PretzelAI"></a>
   <a href="https://discord.gg/xxDcWste" rel="nofollow"><img src="https://camo.githubusercontent.com/83c7aebf0e1903c12c7daf985de39d952e9ae3d7a3752c6141a0ff27236d68d0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d507265747a656c41492d626c75653f6c6f676f3d646973636f7264" alt="Join Pretzel on Discord" data-canonical-src="https://img.shields.io/badge/Discord-PretzelAI-blue?logo=discord"></a>
   <a href="https://github.com/pretzelai/pretzelai/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/f923e9df9b8a64e9dcab58ce636406f0f56268c664622fcf0e40bedbaf045cd2/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4147504c76332d707572706c65" alt="License" data-canonical-src="https://img.shields.io/badge/license-AGPLv3-purple"></a>
   <a href="https://github.com/pretzelai/pretzelai/pulse"><img src="https://camo.githubusercontent.com/d149bba025be4e9c66c25432c092fcc532029109603cc953d975579915e1dd51/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f707265747a656c61692f707265747a656c6169" alt="Commits-per-month" data-canonical-src="https://img.shields.io/github/commit-activity/m/pretzelai/pretzelai"></a>
</p>
<details open="">
  <summary>
    
    <span aria-label="Video description Pretzel.AI.Overview.with.Subtitles.mp4">Pretzel.AI.Overview.with.Subtitles.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/121360087/344195954-ff4643b1-c931-410e-aa0b-9233e0766223.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5NDUzMDMsIm5iZiI6MTcxOTk0NTAwMywicGF0aCI6Ii8xMjEzNjAwODcvMzQ0MTk1OTU0LWZmNDY0M2IxLWM5MzEtNDEwZS1hYTBiLTkyMzNlMDc2NjIyMy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzAyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwMlQxODMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04ZWRiM2U3YWU3ZjVlZTczMDc1MmE1YTJhYTI4NWIyZTEyMWFkNTk4MTA3MmVmYjBiM2JmNWZkMzU1MWFiMjQ5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.mnyZUNSuU9gUj5cm97tYtptuBx1J2hKunvxDTXkVcjU" data-canonical-src="https://private-user-images.githubusercontent.com/121360087/344195954-ff4643b1-c931-410e-aa0b-9233e0766223.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5NDUzMDMsIm5iZiI6MTcxOTk0NTAwMywicGF0aCI6Ii8xMjEzNjAwODcvMzQ0MTk1OTU0LWZmNDY0M2IxLWM5MzEtNDEwZS1hYTBiLTkyMzNlMDc2NjIyMy5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNzAyJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDcwMlQxODMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT04ZWRiM2U3YWU3ZjVlZTczMDc1MmE1YTJhYTI4NWIyZTEyMWFkNTk4MTA3MmVmYjBiM2JmNWZkMzU1MWFiMjQ5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.mnyZUNSuU9gUj5cm97tYtptuBx1J2hKunvxDTXkVcjU" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Pretzel is a fork of Jupyter with the goal to improve Jupyter's capabilities. For our first few features, we've added AI code generation and editing, inline tab completion, sidebar chat and error fixing to Jupyter.</p>
<p dir="auto">Switching to Pretzel from Jupyter is extremely easy <strong>since it's simply an improved version of Jupyter</strong>. All of your Jupyter config, settings, keybindings, and extensions will work out of the box.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick Start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick Start" href="#quick-start"></a></p>
<ul dir="auto">
<li>Installation: <code>pip install pretzelai</code> then run <code>pretzel lab</code> to open the web interface. OR, use our <strong>free hosted version</strong>: <a href="https://pretzelai.app/" rel="nofollow">pretzelai.app</a></li>
<li>Simply start typing in a cell to get inline tab completions</li>
<li>In any Jupyter cell, click “<strong>Ask AI</strong>” or press Cmd+K (Mac) / Ctrl+K (Linux/Windows) to prompt AI</li>
<li>Use the <strong>AI Sidebar</strong> with Ctrl+Cmd+B (Mac) or Ctrl+Alt+B (Linux/Windows) to chat with AI, generate code, and ask questions</li>
<li>To switch to your own OpenAI API key, see the <a href="#configuration">Configuration</a> section</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/pretzelai/pretzelai/blob/main/assets/main.png"><img src="https://github.com/pretzelai/pretzelai/raw/main/assets/main.png" alt=""></a></p>
<hr>
<p dir="auto">Our roadmap includes building features such as:</p>
<ul dir="auto">
<li>Native AI code generation and understanding features similar to <a href="https://cursor.sh/" rel="nofollow">Cursor</a></li>
<li>Frictionless realtime collaboration: pair-programming, comments, version history, etc.</li>
<li>SQL support (both in code cells and as a standalone SQL IDE)</li>
<li>Visual analysis builder (see more <a href="https://github.com/pretzelai/pretzelai/tree/main/pretzelai_visual#readme">here</a>)</li>
<li>VSCode like code-writing experience using <a href="https://github.com/microsoft/monaco-editor">Monaco</a></li>
<li>1-click dashboard creation and sharing from Jupyter notebooks</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">You can install Pretzel by using pip:</p>

<p dir="auto">If using conda, first install pip with <code>conda install pip</code> followed by <code>pip install pretzelai</code>.</p>
<p dir="auto">Then, start Pretzel with:</p>

<p dir="auto">Just as with Jupyter, you should see a URL to access the Pretzel interface.</p>
<p dir="auto">To use your own OpenAI API key, see the <a href="#configuration">Configuration</a> section.</p>
<p dir="auto"><strong>Bleeding Edge Version</strong></p>
<p dir="auto">Bugs possible. To use the latest version of Pretzel:</p>
<ul dir="auto">
<li>Make sure Node.js is installed and is version 20</li>
<li>Clone and install the package</li>
</ul>
<div data-snippet-clipboard-copy-content="git clone https://github.com/pretzelai/pretzelai.git
cd pretzelai
pip install ."><pre><code>git clone https://github.com/pretzelai/pretzelai.git
cd pretzelai
pip install .
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Inline Tab Completion</h4><a id="user-content-inline-tab-completion" aria-label="Permalink: Inline Tab Completion" href="#inline-tab-completion"></a></p>
<ul dir="auto">
<li>Start typing in a cell to get inline tab completions with <a href="https://mistral.ai/news/codestral/" rel="nofollow">Mistral's Codestral</a></li>
<li>Wait for 1 second to trigger completions</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Generating and editing code in notebook cells</h4><a id="user-content-generating-and-editing-code-in-notebook-cells" aria-label="Permalink: Generating and editing code in notebook cells" href="#generating-and-editing-code-in-notebook-cells"></a></p>
<ul dir="auto">
<li>In a cell, press <strong><code>Cmd+K</code> (Mac) / <code>Ctrl+K</code> (Windows/Linux)</strong> or <strong>click "Ask AI"</strong> to open AI prompt textbox and write your code generation/editing instruction
<ul dir="auto">
<li>Mention <code>@variable</code> to refer to variables and dataframes in memory</li>
<li>We automatically send relevant code in the current notebook as context to the AI</li>
</ul>
</li>
<li>If there's existing code in a cell, the prompt will edit the existing code
<ul dir="auto">
<li>If you select/highlight some code in the cell, only the selected code will be edited</li>
</ul>
</li>
<li>You can accept/reject the response or edit your prompt if you want to re-submit with modifications</li>
<li>Use ↑ / ↓ to cycle through prompt history</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using the AI Sidebar</h4><a id="user-content-using-the-ai-sidebar" aria-label="Permalink: Using the AI Sidebar" href="#using-the-ai-sidebar"></a></p>
<ul dir="auto">
<li>Use <strong><code>Ctrl+Cmd+B</code> (Mac) / <code>Ctrl+Alt+B</code> (Linux/Windows)</strong> or the <a href="https://github.com/pretzelai/pretzelai/blob/main/assets/pretzel-icon-finder.png">Pretzel Icon on the right sidebar</a> to activate the AI Sidebar</li>
<li>You can ask questions, generate code, or search for existing code</li>
<li>The AI always <strong>uses the code in the active cell as context</strong>. If you highlight some code in the active cell, only the highlighted code will be used as context</li>
<li>Mention <code>@notebook</code> to send additional relevant code in the current notebook as context to the AI</li>
</ul>
<p dir="auto"><em>Example uses of AI Sidebar</em>:</p>
<ul dir="auto">
<li>"Modify the function <code>my_function</code> in @notebook to be more efficient" ← <em>this will search for the function <code>my_function</code> in the whole notebook and modify it</em></li>
<li>"Where is the code in @notebook that removes outliers"? ← <em>this will search for code that removes outliers in the whole notebook</em></li>
<li>"Can you explain what this code does?" ← <em>this will explain the code <strong>in the current cell</strong></em></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Adding code in the middle of existing code</h4><a id="user-content-adding-code-in-the-middle-of-existing-code" aria-label="Permalink: Adding code in the middle of existing code" href="#adding-code-in-the-middle-of-existing-code"></a></p>
<ul dir="auto">
<li>Put your cursor either on an empty line or an existing line of code. Bring up the AI prompting text box with Cmd+K</li>
<li>Start your prompt with the word <code>inject</code> or <code>ij</code> (case-insensitive) - this tells the AI to only add new code and not edit the existing code in the cell</li>
<li><strong>Code will be added one line below</strong> where your cursor was placed</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Fix errors with AI</h4><a id="user-content-fix-errors-with-ai" aria-label="Permalink: Fix errors with AI" href="#fix-errors-with-ai"></a></p>
<ul dir="auto">
<li>When there's an error, you'll see a button on top-right "<strong>Fix Error with AI</strong>". Click it try fixing the error</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Configuration</h2><a id="user-content-configuration" aria-label="Permalink: Configuration" href="#configuration"></a></p>
<p dir="auto"><strong>Pretzel works out-of-the-box, no configuration needed.</strong></p>
<p dir="auto">Pretzel uses our free AI server by default. You can <strong>configure it to use your own OpenAI/Azure API key</strong> instead.</p>
<p dir="auto"><strong>OpenAI Support</strong></p>
<ul dir="auto">
<li>Open the <code>Settings</code> menu in the top menubar, then click <code>Settings Editor</code></li>
<li>Search for <code>Pretzel</code> and select <code>Pretzel AI Settings</code> on the left bar</li>
<li>From the <code>AI Service</code> dropdown, select <code>OpenAI API Key</code> and fill out your API key under <code>OpenAI Settings &gt; API Key</code>.</li>
<li>If your company uses OpenAI Enterprise, then you can also enter the base URL for OpenAI call under <code>OpenAI Settings</code></li>
<li>We use <code>GPT-4o</code> as the default model. You can change this with the <code>OpenAI Model</code> dropdown.</li>
</ul>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/pretzelai/pretzelai/blob/main/assets/settings-openai-key.png"><img src="https://github.com/pretzelai/pretzelai/raw/main/assets/settings-openai-key.png" alt="help image here"></a></p>
<p dir="auto"><strong>Azure Support</strong>
Just as with OpenAI settings, you can also use Azure hosted models if you select <code>Use Azure API</code> in the <code>AI Service</code> dropdown. <em>We haven't tested this yet so there may be bugs.</em></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Feedback, bugs and docs</h2><a id="user-content-feedback-bugs-and-docs" aria-label="Permalink: Feedback, bugs and docs" href="#feedback-bugs-and-docs"></a></p>
<ul dir="auto">
<li>Please report bugs here: <a href="https://github.com/pretzelai/pretzelai/issues">https://github.com/pretzelai/pretzelai/issues</a></li>
<li>Have any feedback? Any complains? We'd love feedback: <a href="mailto:founders@withpretzel.com">founders@withpretzel.com</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Jupyter specific information</h2><a id="user-content-jupyter-specific-information" aria-label="Permalink: Jupyter specific information" href="#jupyter-specific-information"></a></p>
<p dir="auto">The original Jupyter documentation is available <a href="https://jupyter.org/" rel="nofollow">here</a> and
the Jupyterlab README is available <a href="https://github.com/jupyterlab/jupyterlab">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Privacy Policy, Data Collection and Retention</h2><a id="user-content-privacy-policy-data-collection-and-retention" aria-label="Permalink: Privacy Policy, Data Collection and Retention" href="#privacy-policy-data-collection-and-retention"></a></p>
<p dir="auto">We collect no personal information. We use basic telemetry for only the AI features we've built - for example, when you click on "Ask AI", we receive an event that <em>someone</em> clicked on "Ask AI". We only associate an anonymous ID to your user. If you allow cookies, that helps us tell that it's the same user across multiple browser sessions (which is very helpful!). If you don't allow cookies, every time you open a browser, you're a new anonymous user to us.</p>
<p dir="auto">We also collect prompts (<strong>but not the responses</strong>) for the AI features we've built. This can be turned off in the settings (Settings &gt; Pretzel AI &gt; Uncheck Prompt Telemetry) but we'd really appreciate if you didn't - this is very helpful in improving our prompts.</p>
<p dir="auto">We do not collect any code whatsoever. Even when you use Pretzel's cloud AI server for completions, we don't store any of this code.</p>
<p dir="auto">If you use the hosted version of Pretzel (<a href="https://pretzelai.app/" rel="nofollow">https://pretzelai.app</a>), we create a user for you based on your email address. You can always simply log-in and delete any data you may have stored on our hosted server. We make no backups or copies of your data.</p>
<p dir="auto">Our hosted server is free to use. However, we will delete your data and your account 30 days after your last login. If you'd like to delete your account sooner, please email us at <a href="mailto:founders@withpretzel.com">founders@withpretzel.com</a> with the subject line "Account Deletion" and we'll delete your account immediately.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto"><strong>Q.</strong> <em>What happened to the old version of Pretzel AI - the visual, in-browser data manipulation tool?</em></p>
<p dir="auto"><strong>A.</strong> It's available in the <a href="https://github.com/pretzelai/pretzelai/tree/main/pretzelai_visual"><code>pretzelai_visual</code> folder here</a>. Please see <a href="https://github.com/pretzelai/pretzelai/pull/76" data-hovercard-type="pull_request" data-hovercard-url="/pretzelai/pretzelai/pull/76/hovercard">this PR</a> for more info.</p>
<p dir="auto"><strong>Q.</strong> <em>What AI model does Pretzel use?</em></p>
<p dir="auto"><strong>A.</strong> Pretzel uses different AI models for various tasks:</p>
<ol dir="auto">
<li>
<p dir="auto">Default model: GPT-4o</p>
<ul dir="auto">
<li>Offers a good balance between speed and quality</li>
<li>Can be changed in Pretzel Settings if you're using your own API key</li>
</ul>
</li>
<li>
<p dir="auto">Inline completions: <a href="https://mistral.ai/news/codestral/" rel="nofollow">Mistral's Codestral model</a></p>
<ul dir="auto">
<li>Excellent for code completion</li>
<li>Very fast performance (22B parameter model)</li>
</ul>
</li>
<li>
<p dir="auto">Fallback option:</p>
<ul dir="auto">
<li>If you're using your own API key without providing a Mistral API Key, Pretzel will use GPT-4o for inline completions as well</li>
</ul>
</li>
</ol>
<p dir="auto">We're continuing to experiment with models and supporting local models and Anthropic's Claude is at the top of our list.</p>
<p dir="auto"><strong>Q.</strong> <em>What about feature X?</em></p>
<p dir="auto"><strong>A.</strong> There's a ton we want to build. Please <a href="https://github.com/pretzelai/pretzelai/issues">open an issue</a> and tell us what you want us to build!</p>
<p dir="auto"><strong>Q.</strong> <em>Where's the roadmap?</em></p>
<p dir="auto"><strong>A.</strong> We have a rough roadmap at the top of this README. There are many features we'd like to build, but there's just two of us. So, we're collecting feedback about what would be most helpful. Please open an issue or just email us with your feedback! Based on what we find, we'll prioritize our roadmap.</p>
<p dir="auto"><strong>Q.</strong> <em>Why are you using the AGPL license? Or, why not use MIT/BSD3 licenses?</em></p>
<p dir="auto"><strong>A.</strong> Our goal with building Pretzel is to make an amazing data tool that is free for both individuals and companies to use. That said, we are a two-person startup - and we don't want some third party to just take our code and sell a hosted version of it without giving back to the community. Jupyter code is licensed as BSD-3 and if we keep our new code BSD-3 licensed, there would be no way to stop a third party from doing this. As a result, we went with the AGPLv3 license for all the new code. This ensures that if someone else does want to take our code and sell it (SaaS or otherwise), they have to open-source all of their modifications under AGPLv3 as well.</p>
<p dir="auto"><strong>Q.</strong> <em>Why a fork of Jupyter? Why not contribute into Jupyter directly?</em></p>
<p dir="auto"><strong>A.</strong> This deserves a longer answer but here's the short answer: We've set out to make the <strong>new</strong> de-facto, modern, open-source data tool. Initially, we wanted to start from scratch. However, after talking to several data professionals, we realized it will be very hard to get people to switch to a new tool, no matter how good. The best way to get people to switch is to not have them switch at all. That's why we decided to fork Jupyter - for the near zero switching costs. Also, Jupyter is a mature product, and we're shipping feature really fast - frankly, at the pace we're shipping features, the code we write won't be accepted into the Jupyter codebase 😅. There are also many downsides to this decision - we've had to spend considerable time understanding the whole Jupyter ecosystem and multiple codebases, the complex release processes, the various APIs etc. However, we think this is the right decision for us.</p>
<p dir="auto"><strong>Q.</strong> <em>My company is worried about using an AGPLv3 licensed tool. What can I do?</em></p>
<p dir="auto"><strong>A.</strong> The AGPL is a barrier ONLY IF you're modifying Pretzel AND redistributing it to the public. If you're simply using it as a tool in your company (even with modifications), the AGPL DOES NOT ask you to share your code. Still, if AGPL is an issue for you, please contact us, and we can figure out something that works.</p>
<p dir="auto"><strong>Q.</strong> <em>How are you planning on making money? OR, how are you free? I'm worried that you'll make this tool paid in the future.</em></p>
<p dir="auto"><strong>A.</strong> We're planning on selling a hosted version of the tool to companies to make money. This hosted version will probably have some company specific features that individuals don't want or need such as data access controls, connectors for data sources, integration with GitHub, hosted and shareable dashboard, scalable and on-demand compute for large data jobs etc. We will not retroactively make Pretzel's individual version paid.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ladybird Web Browser becomes a non-profit with $1M from GitHub Founder (895 pts)]]></title>
            <link>https://lunduke.locals.com/post/5812560/ladybird-web-browser-becomes-a-non-profit-with-1-million-from-github-founder</link>
            <guid>40856791</guid>
            <pubDate>Tue, 02 Jul 2024 14:01:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lunduke.locals.com/post/5812560/ladybird-web-browser-becomes-a-non-profit-with-1-million-from-github-founder">https://lunduke.locals.com/post/5812560/ladybird-web-browser-becomes-a-non-profit-with-1-million-from-github-founder</a>, See on <a href="https://news.ycombinator.com/item?id=40856791">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <p>The original founder of GitHub (Chris Wanstrath) has partnered up with the founder of SerenityOS and the Ladybird web browser (Andreas Kling) to create "<a href="https://ladybird.org/" target="_blank" rel="noreferrer noopener">The Ladybird Browser Initiative</a>" -- a USA-based non-profit dedicated exclusively to building a brand new web browser.&nbsp; From scratch.</p><p>While many have claimed that developing a new web browser "from scratch" is an impossible goal, the founders of The Ladybird Browser Initiative believe they can do it.&nbsp; What's more, they are confident it can be done without taking <em>any</em> funding from corporate deals or advertising revenue.</p><p>Their goal?&nbsp; To have a fully functional "Alpha" version of the Ladybird browser ready sometime in 2026.</p><h3>Ladybird Funding</h3><p>Roughly one year ago, the Ladybird Browser received their first major sponsorship (<a href="https://awesomekling.substack.com/p/welcoming-shopify-as-a-ladybird-sponsor" target="_blank" rel="noreferrer noopener">$100,000 from Shopify</a>).&nbsp; Now, with the creation of a 501(c)(3) non-profit (accompanied by a $1 Million dollar pledge from the GitHub founder), Ladybird is preparing to become the only major web browser which does not treat the user like the product being sold.</p><blockquote><p>"Today, every major browser engine is open source, which is wonderful, but there's still one issue: <strong>they're all funded by Google's advertising empire</strong>. Chrome, Edge, Brave, Arc, and Opera all use Google's Chromium. Apple receives billions to make Google the default search engine in Safari, and Firefox has a similar deal where they receive hundreds of millions each year.</p><p>The world needs a browser that puts people first, contributes to open standards using a brand new engine, and is <strong>free from advertising's influence</strong>."</p></blockquote><p>The fact that every major web browser engine is funded by advertising (specifically, via Google) is, indeed, a concern -- which makes the idea of a web browser free from that influence incredibly interesting.</p><p>But how, exactly, is Ladybird going to pull this off?</p><blockquote><p>"Unlike traditional business models that rely on monetizing the user, <strong>Ladybird is funded entirely by sponsorships and donations</strong> from companies and individuals who care about the open web. <strong>Our non-profit will not pursue corporate deals or revenue outside of unrestricted donations</strong>. The software and its source code will be available for free, forever."</p></blockquote><p>While it's easy to dismiss the notion of "funding a web browser via donations" as an unachievable, whimsical goal... Ladybird has already had some significant success in that area (not least of which, the $1 Million dollars from the GitHub founder), resulting in Ladybird already having 4 paid, full time developers (with 3 more programmers "starting soon").</p><p>So, maybe this approach is not as "unachievable" and "whimsical" as it first seems.</p><h3>No Corporate Control</h3><p>Also fascinating is this statement:</p><blockquote><p>"Our non-profit will not pursue corporate deals or revenue outside of unrestricted donations."</p></blockquote><p>What does that mean, in practice?</p><p>It means Ladybird won't be doing corporate deals for default search engines.&nbsp; Or marketing campaigns for other companies.&nbsp; This means that, if they can stick to their guns, Ladybird stands a real chance of a truly independent web browser... one which no company can control.</p><p>In fact the Ladybird Browser Initiative even has a policy specifically not allowing corporate donors to buy board seats:</p><blockquote><p>"All sponsorships are in the form of unrestricted donations. <strong>Board seats and other forms of influence are not for sale</strong>."</p></blockquote><p>This is a huge deal.&nbsp; Massive.</p><p>A problem many non-profit foundations face is corruption of their core mission via corporate control of their boards.&nbsp; There are many examples throughout the Open Source world of exactly this sort of problem (<a href="https://lunduke.locals.com/post/5116049/70-of-companies-on-the-linux-foundation-board-are-gpl-violators" target="_blank" rel="noreferrer noopener">looking at you, Linux Foundation</a>), and to see Ladybird recognize this problem -- and take action to prevent it -- right from the start?</p><p>Color me impressed.</p><p><img src="https://media3.locals.com/images/posts/2024-06-30/102127/102127_n7xyyap4c92jiob_custom.jpeg" alt=""></p><h3>The Current Status</h3><p>The first public "Alpha" release of Ladybird may be a ways out (slated for 2026), but the current development versions are already quite far along.</p><blockquote><p>"<strong>We can already do some of our daily browsing with Ladybird</strong>, like managing GitHub issues and pull requests, and commenting on Hacker News. The browser is improving every day, as our community of contributors are actively fixing bugs and adding features."</p></blockquote><p>Testing of a recent build of Ladybird confirmed that statement.&nbsp; Many websites function perfectly -- including some quite complex sites.&nbsp; While many other websites were... less than functional.&nbsp; Lots of work has clearly been done, with lots more left to do.</p><p>Can the development team improve Ladybird to a point where it will be usable, as a primary web browser, some time in next few years?&nbsp; Considering the progress to date... it seems entirely possible.</p><h3>"We won't be chasing buzzwords"</h3><p>The Lunduke Journal reached out to <a href="https://ladybird.org/" target="_blank" rel="noreferrer noopener">The Ladybird Browser Initiative's</a> co-Founder, Andreas Kling, with a burning question...</p><p>Now that the Ladybird web browser has an official nonprofit, with multiple full time developers working on it, you are clearly moving towards direct competition with the likes of Google and Mozilla. &nbsp;The eye of Sauron is upon you. &nbsp;How does that feel?</p><p>Kling's response:</p><blockquote><p>"Feels great! The web is one of humanity's greatest inventions, and it deserves diverse, competing implementations to truly thrive. The industry has been heading in a troubling direction for years, with companies like Microsoft and Opera abandoning their own browser engines in favor of Chromium.</p><p>We obviously don't have the resources of companies like Google, Apple, and Mozilla, so <strong>things will take some time</strong>. However, I'm extremely optimistic about the road ahead. We have a fantastic community of developers working on Ladybird, and we're making solid, consistent progress.</p><p>One thing we have going for us is focus. <strong>Unlike the major players, we're *completely* focused on one thing only: the web browser</strong>.</p><p><strong>We won't be chasing buzzwords or looking for alternative revenue streams</strong>. Our goal is to build a good browser and give it away for free, while soliciting nothing but unrestricted donations from anyone who likes what we're doing."</p></blockquote><p>There's a lot here to be excited about.</p><ul><li>No chasing buzzwords.</li><li>No alternative revenue streams.</li><li>Total focus on the web browser.</li><li>A brand new, from scratch browser engine.</li><li>No advertising or Big Tech influence.</li><li>A rag-tag team of rebels going, toe to toe, with the Big Tech web browser makers.</li></ul><p>While, according to the Ladybird team, they are a ways off from a major public release... it's hard not to feel a bit optimistic about what this could mean for the future of web browsing.&nbsp; This may be early days still, but the possibilities are tantalizing.</p><p>The Lunduke Journal is rooting for you, Ladybird.</p><div>
    <p><img src="https://media3.locals.com/images/avatars/102127/102127_pavt7hft2xvhhod_thumb.png" alt="community logo">
    </p>
    <p>
        Join the Lunduke Community
    </p>
    <p>
        To read more articles like this, sign up and join my community today
    </p>
    
</div>
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The case against morning yoga, daily routines, and endless meetings (102 pts)]]></title>
            <link>https://andrewchen.substack.com/p/10x-work-versus-1x-work</link>
            <guid>40856316</guid>
            <pubDate>Tue, 02 Jul 2024 13:13:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://andrewchen.substack.com/p/10x-work-versus-1x-work">https://andrewchen.substack.com/p/10x-work-versus-1x-work</a>, See on <a href="https://news.ycombinator.com/item?id=40856316">Hacker News</a></p>
Couldn't get https://andrewchen.substack.com/p/10x-work-versus-1x-work: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Why Is Chile So Long? (1302 pts)]]></title>
            <link>https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long</link>
            <guid>40856030</guid>
            <pubDate>Tue, 02 Jul 2024 12:36:58 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long">https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long</a>, See on <a href="https://news.ycombinator.com/item?id=40856030">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p><span>Chile is so long, it's </span><strong>curved.</strong></p><p><span>How long is it?</span><br><span>Why </span><em>not longer</em><span>?</span><br><span>Why is no other country as thin?</span><br><span>How does that make Chileans incomprehensible?</span></p><p>All your answers in today’s article!</p><p><span>Chile is as long as the US and Canada </span><strong><span>combined.</span><br></strong><span>Chile is as long as all of Europe!</span><br><span>It can stretch from Norway to Morocco.</span><br><span>From London to Baghdad!</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png" width="1200" height="675" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:false,&quot;imageSize&quot;:&quot;large&quot;,&quot;height&quot;:819,&quot;width&quot;:1456,&quot;resizeWidth&quot;:1200,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F48ce9054-ec5f-4f2b-a84c-4e8f51789aa0_1600x900.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a></figure></div><p>You can stack over a dozen European countries in Chile north to south.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png" width="472" height="819.0260047281324" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1468,&quot;width&quot;:846,&quot;resizeWidth&quot;:472,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F11c9c5cb-2209-4f36-b0a5-9e5049891956_846x1468.png 1456w" sizes="100vw"></picture></div></a></figure></div><p>Of course, that means Chile has every possible climate.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png" width="1041" height="1438" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1438,&quot;width&quot;:1041,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2dfdbeb9-6fbf-4909-85d1-2a772f4406c6_1041x1438.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Chile is so long because of the Andes. Here's a map of elevation in South America.</p><p>You can't easily pass these mountains, and the tiny sliver of land to their west is Chile.</p><p>The mountains exist because of the Nazca tectonic plate hitting the South American one:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png" width="1456" height="739" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:739,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84cea210-2aed-4ad0-be75-5a32373cbb56_1600x812.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Here's a superb (composite) image of a Chilean volcano :</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png" width="544" height="768" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:544,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc23f327a-5da9-4ee6-8d6b-af4f05a3832d_544x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>But why is Chile so long? Why not longer? You can get a sense by looking at a satellite map of the region. From it, can you guess where most Chileans live?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png" width="458" height="591.9224555735057" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1600,&quot;width&quot;:1238,&quot;resizeWidth&quot;:458,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc9d57fd9-4267-44b6-9562-d4c8a2659847_1238x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You can see by comparing the satellite map and the map of night lights:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif" width="436" height="553.3254994124559" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:851,&quot;resizeWidth&quot;:436,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_lossy/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7211c09d-cc31-4f96-a6ca-be372e5dbec2_851x1080.gif 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Chileans live in the middle of the country, in the northern part of the green stripe.</p><p>What's happening?</p><p>Winds blow westward close to the Equator and eastward farther south.</p><p>The Andes stop all the moisture from the Atlantic near the Equator, and from the Pacific farther south.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png" width="1456" height="1484" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1484,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd296eee1-1f5b-4e45-97bf-345e6ad03d78_1570x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>That's why both Brazil </span><strong>and Chile</strong><span> have rainforests.&nbsp;</span></p><p><span>The Chilean one is a </span><strong>temperate</strong><span> rainforest—like in the Pacific Northwest in North America.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png" width="402" height="497.88990825688074" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:872,&quot;resizeWidth&quot;:402,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc162029c-93b1-4c0d-8581-9da8a1b2e1ed_872x1080.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You can see that reflected in the map of South America’s forests:</p><p>So all of southern Chile is green, but only the northern half of that is warm enough for comfortable living (and close to other countries' centers of population). That's where most Chileans live.</p><p>What about the northern part then, the desert?</p><p>That area is so dry, it can't support a large population.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png" width="398" height="458.7118644067797" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:680,&quot;width&quot;:590,&quot;resizeWidth&quot;:398,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F09e15f53-97e0-4ca3-a42f-78e0baabcc25_590x680.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>These flowers in the Atacama Desert only bloom every few years, when rainfall is unusually high.</em></figcaption></figure></div><p>And since it's close to the center of South America, it has neighbors...</p><p>Few locals and lots of neighbors means this area was contested for a long time after the Spanish Empire collapsed.</p><p>This is a map of contested areas in South America, 1879:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png" width="465" height="768" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:768,&quot;width&quot;:465,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F0934055e-3f89-494a-a9e3-39cfe2947ccf_465x768.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Peru &amp; Bolivia went to war with Chile for that region, but they lost in the War of the Pacific.</p><p>Why fight? Natural resources: guano and saltpeter.</p><p>Back then, guano was the world’s main fertilizer (and this area had most of the world's guano, thanks to the climate).</p><p>Saltpeter was useful for gunpowder.</p><p>So why is Chile so long, but not longer?</p><ul><li><p>A sliver between coast &amp; Andes</p></li><li><p>Far south: too cold for another country</p></li><li><p>Far north: competing neighbors</p></li><li><p>Natural border there: desert. Chile won the war to get the tip.</p></li></ul><p>That's also why most Chileans live in the middle of the country: too cold in the south, too hot and dry in the north.</p><p>You can see that effect in a map of South American roads:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png" width="460" height="738.2146439317954" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1600,&quot;width&quot;:997,&quot;resizeWidth&quot;:460,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3bd6b3a4-68eb-406a-9a24-10371a0538e1_997x1600.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>Cold, heat, sea and mountains make Chile a country—an extremely isolated one:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png" width="1456" height="1299" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1299,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F29423f18-43e9-46f6-9889-f3bc60669a67_1600x1427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>And that's also the main reason why Chileans are incomprehensible: So isolated from all other Spanish speakers!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png" width="562" height="562" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1080,&quot;width&quot;:1080,&quot;resizeWidth&quot;:562,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa5294bdd-5e66-48a7-8264-17cf12ec34a5_1080x1080.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p><span>Here’s some more detail, from </span><em><a href="https://unchartedterritories.tomaspueyo.com/p/why-do-900-million-people-speak-spanish" rel="">Why Do 900 Million People Speak Spanish and Portuguese the Way They Do?</a><span>:</span></em></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg" width="1456" height="1009" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1009,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F856b5618-ae2c-4e01-a24a-085144fd9ab5_1456x1009.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>This graph shows how much the Spanish from different countries resemble each other. The greener, the closer. The redder, the farther apart.</p><p>You can see some countries are very red:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg" width="1456" height="989" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:989,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1a017346-a01c-4c3f-ad35-cdc667ea6216_1456x989.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>You see how red Chilean Spanish is? It means it’s quite different. In the beginning of Grad School, I could understand all my Hispanic classmates, but I had a hard time understanding the Chileans!</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg" width="598" height="246" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/c979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:246,&quot;width&quot;:598,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc979140e-f443-4fc2-a8d1-e6450b45cfa1_598x246.jpeg 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>I couldn’t find any great analysis on this, so if you find it, please let me know. The best hypotheses I could find were:</p><ul><li><p>It’s the farthest region from Spain, so the least communicated to the rest of the empire, and hence the one that drifted the most from the homeland.</p></li><li><p>It’s extremely isolated by the Andes, the ocean in the west, the ice in the south, and the desert in the north, making its connection even to Argentina, Bolivia or Peru really hard.</p></li><li><p>It didn’t have silver mines, or a climate for sugar or tobacco farming, so it wasn’t a particularly valuable place to exploit, and remained secondary in the empire, getting fewer visitors from other parts of the empire, and drifting further apart.</p></li><li><p>It has strong influences from other regions, such as German, Italian, or even Basque.&nbsp;</p></li></ul><p>But why is no other country as long?</p><p>You need:</p><ul><li><p>A sandwich between sea and continent</p></li><li><p>Oriented north-south, so that it changes climates quickly&nbsp;</p></li><li><p>Far enough from the equator so that the north-south climate does change fast, and so that it’s not too densely populated.</p></li></ul><p>The sandwich requires an oceanic plate subducting under a continental plate, which only happens here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png" width="1456" height="993" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:993,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5273cf8-08e3-4d4d-be55-88abb23d2975_1600x1091.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>From there, take out the areas that are equatorial or too cold:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png" width="1456" height="1007" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/a37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1007,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa37dca14-fb50-4f38-95ed-37e85ecbf2e6_1600x1107.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the western Pacific, that leaves islands, mainly Japan, New Zealand, and maybe the Philippines. But in this part of the world, the mountain chains start from deep under the sea, which generates archipelagos rather than a continental sliver.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png" width="1456" height="907" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:907,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F5186b3b6-6b3a-4d11-b2cc-b8445985b7e6_1600x997.png 1456w" sizes="100vw" loading="lazy"></picture></div></a></figure></div><p>In the eastern Pacific, it leaves Chile and the US – Mexico – Canada west coast. An elevation map shows how a country could have been viable here:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png" width="1456" height="1413" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1413,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F23a598f8-867c-426d-bf30-96af55aa012c_1470x1427.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>West of the mountain chain that runs through all of the American continent, you can see the green sliver that could have been a country.</em></figcaption></figure></div><p>So why don’t we have a Chile of the north?</p><p>Mexico was close to Spain, had silver mines interesting to Spain, smaller mountains than the Andes, and is much narrower from sea to sea. All of this made the country much better communicated east-west, so the western coast couldn’t evolve as a separate entity.</p><p>In the US and Canadian coast, the US conquered that area from the east extremely fast, making the independence of the West Coast impossible. We can imagine that, if these regions had been left to continue developing for a few thousand years, a distinct country (or set of countries) would have emerged in the west.</p><p>So that's why Chile is one of the longest—and the thinnest—countries in the world!</p><div data-attrs="{&quot;url&quot;:&quot;https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="CaptionedButtonToDOM"><p><em>If you know somebody who’d enjoy this article, show you think about them and share it!</em></p><p data-attrs="{&quot;url&quot;:&quot;https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&quot;,&quot;text&quot;:&quot;Share&quot;}" data-component-name="ButtonCreateButton"><a href="https://unchartedterritories.tomaspueyo.com/p/why-is-chile-so-long?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></article></div></div>]]></description>
        </item>
    </channel>
</rss>