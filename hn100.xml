(ignoring known css parsing error)
<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 30 Sep 2025 21:30:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Inflammation now predicts heart disease more strongly than cholesterol (187 pts)]]></title>
            <link>https://www.empirical.health/blog/inflammation-and-heart-health/</link>
            <guid>45430498</guid>
            <pubDate>Tue, 30 Sep 2025 20:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.empirical.health/blog/inflammation-and-heart-health/">https://www.empirical.health/blog/inflammation-and-heart-health/</a>, See on <a href="https://news.ycombinator.com/item?id=45430498">Hacker News</a></p>
<div id="readability-page-1" class="page"><article> <div>   <p>Chronic inflammation has long been known to double your risk of heart disease, but prior to now,
inflammation has never been a SMuRF: <strong>s</strong>tandard <strong>m</strong>odifiable <strong>r</strong>isk <strong>f</strong>actor for heart disease.</p>
<p>The American College of Cardiology just released recommendations that change that. The ACC is now recommending that everyone
measure inflammation (specifically, hs-CRP) via a blood test:</p>
<blockquote>
<p>Because clinicians will not treat what they do not measure, universal screening of hsCRP in both primary and secondary prevention patients, in combination with cholesterol, represents a major clinical opportunity and is therefore recommended. <a href="https://www.jacc.org/doi/10.1016/j.jacc.2025.08.047">American College of Cardiology</a></p>
</blockquote>
<p>There were a many interesting bits of evidence that led to this recommendation. The whole <a href="https://www.jacc.org/doi/10.1016/j.jacc.2025.08.047">article, published in JACC</a>, is worth a read, but this blog post extracts a few of the most interesting parts — or at
least, the parts I thought were most interesting.</p>
<p>
Want to skip ahead and measure your inflammation? Empirical Health's <a href="https://www.empirical.health/product/comprehensive-health-panel?utm_source=blog">advanced heart health panel</a> includes hs-CRP, ApoB, Lp(a), and other critical heart health biomarkers.
</p>
<hr>
<h2 id="inflammation-hs-crp-is-a-stronger-predictor-of-heart-disease-than-cholesterol"><a href="#inflammation-hs-crp-is-a-stronger-predictor-of-heart-disease-than-cholesterol">Inflammation (hs-CRP) is a stronger predictor of heart disease than cholesterol</a></h2>
<p>For decades, LDL cholesterol (or <a href="https://www.empirical.health/blog/apob-blood-test/">ApoB</a>) has been the main focus of cardiovascular risk assessment. But
this chart shows hs-CRP is actually a <em>stronger</em> predictor of heart disease than LDL.</p>
<p><img alt="Inflammation vs LDL cholesterol" loading="lazy" decoding="async" fetchpriority="auto" width="407" height="620" src="https://www.empirical.health/_astro/ldl_vs_inflammation.B5MkNi52_Z2655L8.webp"></p>
<p>Why? In some ways, <strong>cholesterol has become a victim of its own success.</strong> We now screen the whole population
for high cholesterol, give statins to those with high LDL (or ApoB), and so then the majority of people who
end up having heart attacks have lower cholesterol than they would naturally have. This means most of
the majority of residual risk for heart attacks will be found in biomarkers that aren’t SMuRFs.</p>
<p>Inflammation (hs-CRP) is one such non-SMuRF, one perhaps one of the strongest. This is especially true
in people already on statins or those without traditional risk factors (sometimes called “SMuRF-less” patients).
In these groups, cholesterol may be well controlled, but inflammation remains a key driver of events.</p>
<p>Of course, other traditional risk factors matter <em>in addition</em> to inflammation: blood pressure, HbA1c or
insulin resistance, eGFR (kidney function), and so on.</p>
<h2 id="what-can-you-actually-do-to-lower-inflammation"><a href="#what-can-you-actually-do-to-lower-inflammation">What can you actually do to lower inflammation?</a></h2>
<p>The ACC consensus reviews a range of clinical trials testing both drugs and lifestyle interventions for lowering inflammation and reducing cardiovascular risk. Here’s a summary of the clinical trials and their results:</p>



































































































































<table><thead><tr><th>Trial Name</th><th>Drug (Class)</th><th>Sample Size (n)</th><th>Population/NYHA Functional Class</th><th>Follow-Up</th><th>Primary Endpoint</th><th>Treatment Outcome</th></tr></thead><tbody><tr><td>ATTACH</td><td>Infliximab (TNF inhibitor)</td><td>150</td><td>NYHA III/IV HF</td><td>7 mo</td><td>Clinical status (composite score)</td><td>No improvement or worsening; deaths highest in high-dose infliximab</td></tr><tr><td>ACCLAIM</td><td>IVIG</td><td>2314</td><td>NYHA II-IV HF</td><td>10.2 mo</td><td>Composite all-cause mortality and CV hospitalization</td><td>No reduction in events; trend toward benefit in NYHA III and IV</td></tr><tr><td>CANTOS</td><td>Canakinumab (anti–IL-1β)</td><td>10,061</td><td>Prior MI; hsCRP ≥2 mg/L</td><td>3.7 y (median)</td><td>Nonfatal MI, nonfatal stroke, or CV death (MACE); HF-related mortality</td><td>Reduced MACE and HF events; no effect on all-cause mortality; primary endpoint events: 3.86% vs 4.50%</td></tr><tr><td>CIRT</td><td>Methotrexate</td><td>4,786</td><td>Stable MI plus CAD</td><td>2.3 y (median)</td><td>CV event rates</td><td>No effect on CV events, inflammation, or lipids</td></tr><tr><td>CLEAR SYNERGY</td><td>Colchicine</td><td>3,056</td><td>Acute MI plus PCI</td><td>22.6 mo</td><td>Death from CV causes, recurrent MI, ischemic stroke</td><td>No significant difference in primary endpoint</td></tr><tr><td>COLCOT</td><td>Colchicine</td><td>4,745</td><td>Acute MI patients</td><td>22.6 mo</td><td>CV event rates</td><td>CV events lower than placebo</td></tr><tr><td>LoDoCo2</td><td>Colchicine</td><td>5,522</td><td>Stable CAD</td><td>28.6 mo</td><td>Composite of CV death, nonfatal MI, ischemic stroke, or ischemia-driven revasc.</td><td>CV events lower than placebo</td></tr><tr><td>GISSI-HF</td><td>Rosuvastatin (statin)</td><td>4,574</td><td>NYHA II-IV HF</td><td>3.9 y</td><td>All-cause mortality and CV hospitalization</td><td>No effect on primary endpoints</td></tr><tr><td>JUPITER</td><td>Rosuvastatin (statin)</td><td>17,802</td><td>No CVD / LDL &lt;130 mg/dL; hsCRP ≥2 mg/L</td><td>1.9 y (median)</td><td>MI, stroke, arterial revascularization, hospitalization for unstable angina, or CV death</td><td>Reduced events (HR 0.56–0.69)</td></tr><tr><td>CORONA</td><td>Rosuvastatin (statin)</td><td>5,011</td><td>NYHA II-IV HF; ischemic etiology</td><td>32.8 mo</td><td>CV death, nonfatal MI, nonfatal stroke</td><td>No effect on primary endpoint</td></tr><tr><td>OPT-CHF</td><td>Etanercept (TNF inhibitor)</td><td>1,500</td><td>NYHA II-IV HF</td><td>6 mo</td><td>Death, hospitalization, or worsening HF</td><td>No effect on primary endpoint</td></tr><tr><td>DCMP</td><td>Prednisone (corticosteroid)</td><td>84</td><td>NYHA II-IV HF; biopsy-proven myocarditis</td><td>5.7 and 12.3 mo</td><td>Improvement in LVEF, survival, or combined outcome of death or transplantation</td><td>No significant benefit</td></tr><tr><td>RENEWAL</td><td>Etanercept (TNF inhibitor)</td><td>2,048</td><td>NYHA II-IV HF</td><td>6 mo</td><td>Composite outcome of death or hospitalization</td><td>No effect on primary endpoint</td></tr></tbody></table>
<p><strong>What works</strong> to lower inflammation?</p>
<ul>
<li><strong>Statins</strong> (especially in people with high hs-CRP): Substantial reduction in events, even when LDL is normal (JUPITER trial).</li>
<li><strong>Colchicine</strong>: Reduces recurrent events in people with established heart disease (COLCOT, LoDoCo2).</li>
<li><strong>Canakinumab</strong>: Reduces events but is expensive and increases infection risk (CANTOS).</li>
<li><strong>Lifestyle</strong>: Anti-inflammatory diets (Mediterranean, DASH), regular exercise, smoking cessation, and maintaining a healthy weight all lower hs-CRP and reduce risk.</li>
</ul>
<p><strong>What doesn’t work?</strong></p>
<ul>
<li>Some anti-inflammatory drugs (methotrexate, TNF inhibitors, corticosteroids) have not shown benefit in major trials.</li>
</ul>
<hr>
<h2 id="whats-a-normal-good-or-bad-hs-crp"><a href="#whats-a-normal-good-or-bad-hs-crp">What’s a normal, good, or bad hs-CRP?</a></h2>
<p>If you’ve already measured your hs-CRP (great!), then it’s ideally below &lt;1 mg/L. hs-CRP above 3 mg/L is
high risk:</p>
<p><img alt="Inflammation vs LDL cholesterol" loading="lazy" decoding="async" fetchpriority="auto" width="638" height="456" src="https://www.empirical.health/_astro/normal-inflammation-levels.BflUT68q_2dks4G.webp"></p>
<p>(If you’re in moderate or high ranges, see the section above for what to do.)</p>
<h2 id="are-other-biomarkers-of-inflammation-relevant"><a href="#are-other-biomarkers-of-inflammation-relevant">Are other biomarkers of inflammation relevant?</a></h2>
<p>The ACC evaluated other markers: IL-6, fibrinogen, neutrophil-to-lymphocyte ratio, EPA/AA ratio, and serum amyloid A.
These have also been shown to predict cardiovascular risk, but once hs-CRP is known, don’t add more signal.</p>
<p>In other words, you’re best off simply measuring hs-CRP, and then spending money elsewhere on heart health.</p>
<h2 id="other-interesting-bits"><a href="#other-interesting-bits">Other interesting bits</a></h2>
<p>The JACC article is packed with other interesting insights. These ones were interesting:</p>
<ul>
<li><strong>Imaging biomarkers</strong> (like CT, PET, MRI, and perivascular “fat attenuation index”) can detect vascular inflammation and may help predict coronary events, but are not yet ready for routine clinical use.</li>
<li><strong>Bempedoic acid</strong> is a newer cholesterol-lowering drug that also lowers hs-CRP, but its long-term outcomes are still being studied.</li>
<li><strong>Residual inflammatory risk</strong>: Even with well-controlled LDL on statins, many people still have elevated hs-CRP and ongoing risk—so inflammation should be addressed separately from cholesterol.</li>
<li><strong>Universal hs-CRP screening</strong> is now recommended by the ACC for both people with and without established heart disease.</li>
<li><strong>Colchicine (0.5 mg/d)</strong> is now FDA-approved as an adjunct for secondary prevention in stable ASCVD, but should be avoided in people with significant kidney or liver disease.</li>
<li><strong>Novel IL-6 inhibitors</strong> are being studied as future anti-inflammatory therapies for heart disease.</li>
</ul>
<h2 id="how-to-measure-your-inflammation"><a href="#how-to-measure-your-inflammation">How to measure your inflammation</a></h2>
<p>A simple blood test for hs-CRP is widely available and inexpensive. The ACC now recommends routine hs-CRP testing for both people at risk (primary prevention) and those with established heart disease (secondary prevention).</p>
  </div> </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Boeing has started working on a 737 MAX replacement (130 pts)]]></title>
            <link>https://www.wsj.com/business/airlines/boeing-has-started-working-on-a-737-max-replacement-40a110df</link>
            <guid>45428482</guid>
            <pubDate>Tue, 30 Sep 2025 17:31:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wsj.com/business/airlines/boeing-has-started-working-on-a-737-max-replacement-40a110df">https://www.wsj.com/business/airlines/boeing-has-started-working-on-a-737-max-replacement-40a110df</a>, See on <a href="https://news.ycombinator.com/item?id=45428482">Hacker News</a></p>
Couldn't get https://www.wsj.com/business/airlines/boeing-has-started-working-on-a-737-max-replacement-40a110df: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[Sora 2 (269 pts)]]></title>
            <link>https://openai.com/index/sora-2/</link>
            <guid>45428122</guid>
            <pubDate>Tue, 30 Sep 2025 17:04:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/sora-2/">https://openai.com/index/sora-2/</a>, See on <a href="https://news.ycombinator.com/item?id=45428122">Hacker News</a></p>
Couldn't get https://openai.com/index/sora-2/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Sora 2 (315 pts)]]></title>
            <link>https://openai.com/index/sora-2/</link>
            <guid>45427982</guid>
            <pubDate>Tue, 30 Sep 2025 16:55:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://openai.com/index/sora-2/">https://openai.com/index/sora-2/</a>, See on <a href="https://news.ycombinator.com/item?id=45427982">Hacker News</a></p>
Couldn't get https://openai.com/index/sora-2/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[A $196 fine-tuned 7B model outperforms OpenAI o3 on document extraction (179 pts)]]></title>
            <link>https://arxiv.org/abs/2509.22906</link>
            <guid>45427634</guid>
            <pubDate>Tue, 30 Sep 2025 16:31:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2509.22906">https://arxiv.org/abs/2509.22906</a>, See on <a href="https://news.ycombinator.com/item?id=45427634">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
                
    <p><a href="https://arxiv.org/pdf/2509.22906">View PDF</a>
    <a href="https://arxiv.org/html/2509.22906v1">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>This paper presents Extract-0, a 7-billion parameter language model specifically optimized for document information extraction that achieves performance exceeding models with parameter counts several orders of magnitude larger. Through a novel combination of synthetic data generation, supervised fine-tuning with Low-Rank Adaptation (LoRA), and reinforcement learning via Group Relative Policy Optimization (GRPO), Extract-0 achieves a mean reward of 0.573 on a benchmark of 1,000 diverse document extraction tasks, outperforming GPT-4.1 (0.457), o3 (0.464), and GPT-4.1-2025 (0.459). The training methodology employs a memory-preserving synthetic data generation pipeline that produces 280,128 training examples from diverse document sources, followed by parameterefficient fine-tuning that modifies only 0.53% of model weights (40.4M out of 7.66B parameters). The reinforcement learning phase introduces a novel semantic similarity-based reward function that handles the inherent ambiguity in information extraction tasks. This research demonstrates that task-specific optimization can yield models that surpass general-purpose systems while requiring substantially fewer computational resource.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Henrique Godoy [<a href="https://arxiv.org/show-email/90d16046/2509.22906" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Fri, 26 Sep 2025 20:34:43 UTC (1,102 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Launch HN: Airweave (YC X25) – Let agents search any app (121 pts)]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>45427482</guid>
            <pubDate>Tue, 30 Sep 2025 16:21:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/airweave-ai/airweave">https://github.com/airweave-ai/airweave</a>, See on <a href="https://news.ycombinator.com/item?id=45427482">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><themed-picture data-catalyst-inline="true"><picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://github.com/airweave-ai/airweave/raw/main/frontend/public/logo-airweave-darkbg.svg">
  <source media="(prefers-color-scheme: light)" srcset="https://github.com/airweave-ai/airweave/raw/main/frontend/public/logo-airweave-lightbg.svg">
  <img width="1673" alt="airweave-lettermark" src="https://github.com/airweave-ai/airweave/raw/main/frontend/public/logo-airweave-darkbg.svg">
</picture></themed-picture>

<p dir="auto"><h2 tabindex="-1" dir="auto">Overview</h2><a id="user-content-overview" aria-label="Permalink: Overview" href="#overview"></a></p>
<p dir="auto"><strong>Airweave is a tool that lets agents search any app.</strong> It connects to apps, productivity tools, databases, or document stores and transforms their contents into searchable knowledge bases, accessible through a standardized interface for agents.</p>
<p dir="auto">The search interface is exposed via REST API or MCP. When using MCP, Airweave essentially builds a semantically searchable MCP server. The platform handles everything from auth and extraction to embedding and serving.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Table of Contents</h2><a id="user-content-table-of-contents" aria-label="Permalink: Table of Contents" href="#table-of-contents"></a></p>
<ul dir="auto">
<li><a href="#airweave">Airweave</a>
<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#table-of-contents">Table of Contents</a></li>
<li><a href="#-quick-start">🚀 Quick Start</a></li>
<li><a href="#-supported-integrations">🔌 Supported Integrations</a></li>
<li><a href="#-usage">💻 Usage</a>
<ul dir="auto">
<li><a href="#frontend">Frontend</a></li>
<li><a href="#api">API</a></li>
</ul>
</li>
<li><a href="#-sdks">📦 SDKs</a>
<ul dir="auto">
<li><a href="#python">Python</a></li>
<li><a href="#typescriptjavascript">TypeScript/JavaScript</a></li>
</ul>
</li>
<li><a href="#-key-features">🔑 Key Features</a></li>
<li><a href="#-technology-stack">🔧 Technology Stack</a></li>
<li><a href="#-contributing">👥 Contributing</a></li>
<li><a href="#-license">📄 License</a></li>
<li><a href="#-connect">🔗 Connect</a></li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🚀 Quick Start</h2><a id="user-content--quick-start" aria-label="Permalink: 🚀 Quick Start" href="#-quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Managed Service: <a href="https://app.airweave.ai/" rel="nofollow">Airweave Cloud</a></h3><a id="user-content-managed-service-airweave-cloud" aria-label="Permalink: Managed Service: Airweave Cloud" href="#managed-service-airweave-cloud"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Self-hosted:</h3><a id="user-content-self-hosted" aria-label="Permalink: Self-hosted:" href="#self-hosted"></a></p>
<p dir="auto">Make sure docker and docker-compose are installed, then...</p>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh"><pre><span><span>#</span> 1. Clone the repository</span>
git clone https://github.com/airweave-ai/airweave.git
<span>cd</span> airweave

<span><span>#</span> 2. Build and run</span>
chmod +x start.sh
./start.sh</pre></div>
<p dir="auto">That's it! Access the dashboard at <a href="http://localhost:8080/" rel="nofollow">http://localhost:8080</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔌 Supported Integrations</h2><a id="user-content--supported-integrations" aria-label="Permalink: 🔌 Supported Integrations" href="#-supported-integrations"></a></p>

<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/asana.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/asana.svg" alt="Asana" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/bitbucket.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/bitbucket.svg" alt="Bitbucket" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/confluence.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/confluence.svg" alt="Confluence" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/dropbox.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/dropbox.svg" alt="Dropbox" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/github.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/github.svg" alt="Github" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/gmail.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/gmail.svg" alt="Gmail" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/google_calendar.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/google_calendar.svg" alt="Google Calendar" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/google_drive.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/google_drive.svg" alt="Google Drive" width="40" height="40"></a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/hubspot.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/hubspot.svg" alt="Hubspot" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/jira.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/jira.svg" alt="Jira" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/linear.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/linear.svg" alt="Linear" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/monday.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/monday.svg" alt="Monday" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/notion.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/notion.svg" alt="Notion" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/onedrive.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/onedrive.svg" alt="Onedrive" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/outlook_calendar.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/outlook_calendar.svg" alt="Outlook Calendar" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/outlook_mail.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/outlook_mail.svg" alt="Outlook Mail" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/postgresql.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/postgresql.svg" alt="Postgresql" width="40" height="40"></a>
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/slack.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/slack.svg" alt="Slack" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/stripe.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/stripe.svg" alt="Stripe" width="40" height="40"></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/airweave-ai/airweave/blob/main/frontend/src/components/icons/apps/todoist.svg"><img src="https://github.com/airweave-ai/airweave/raw/main/frontend/src/components/icons/apps/todoist.svg" alt="Todoist" width="40" height="40"></a>
  </p>


<p dir="auto"><h2 tabindex="-1" dir="auto">💻 Usage</h2><a id="user-content--usage" aria-label="Permalink: 💻 Usage" href="#-usage"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Frontend</h3><a id="user-content-frontend" aria-label="Permalink: Frontend" href="#frontend"></a></p>
<ul dir="auto">
<li>Access the UI at <code>http://localhost:8080</code></li>
<li>Connect sources, configure syncs, and query data</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">API</h3><a id="user-content-api" aria-label="Permalink: API" href="#api"></a></p>
<ul dir="auto">
<li>Swagger docs: <code>http://localhost:8001/docs</code></li>
<li>Create connections, trigger syncs, and search data</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">📦 SDKs</h2><a id="user-content--sdks" aria-label="Permalink: 📦 SDKs" href="#-sdks"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Python</h3><a id="user-content-python" aria-label="Permalink: Python" href="#python"></a></p>

<div dir="auto" data-snippet-clipboard-copy-content="from airweave import AirweaveSDK

client = AirweaveSDK(
    api_key=&quot;YOUR_API_KEY&quot;,
    base_url=&quot;http://localhost:8001&quot;
)
client.collections.create(
    name=&quot;name&quot;,
)"><pre><span>from</span> <span>airweave</span> <span>import</span> <span>AirweaveSDK</span>

<span>client</span> <span>=</span> <span>AirweaveSDK</span>(
    <span>api_key</span><span>=</span><span>"YOUR_API_KEY"</span>,
    <span>base_url</span><span>=</span><span>"http://localhost:8001"</span>
)
<span>client</span>.<span>collections</span>.<span>create</span>(
    <span>name</span><span>=</span><span>"name"</span>,
)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">TypeScript/JavaScript</h3><a id="user-content-typescriptjavascript" aria-label="Permalink: TypeScript/JavaScript" href="#typescriptjavascript"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install @airweave/sdk
# or
yarn add @airweave/sdk"><pre>npm install @airweave/sdk
<span><span>#</span> or</span>
yarn add @airweave/sdk</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="import { AirweaveSDKClient, AirweaveSDKEnvironment } from &quot;@airweave/sdk&quot;;

const client = new AirweaveSDKClient({
    apiKey: &quot;YOUR_API_KEY&quot;,
    environment: AirweaveSDKEnvironment.Local
});
await client.collections.create({
    name: &quot;name&quot;,
});"><pre><span>import</span> <span>{</span> <span>AirweaveSDKClient</span><span>,</span> <span>AirweaveSDKEnvironment</span> <span>}</span> <span>from</span> <span>"@airweave/sdk"</span><span>;</span>

<span>const</span> <span>client</span> <span>=</span> <span>new</span> <span>AirweaveSDKClient</span><span>(</span><span>{</span>
    <span>apiKey</span>: <span>"YOUR_API_KEY"</span><span>,</span>
    <span>environment</span>: <span>AirweaveSDKEnvironment</span><span>.</span><span>Local</span>
<span>}</span><span>)</span><span>;</span>
<span>await</span> <span>client</span><span>.</span><span>collections</span><span>.</span><span>create</span><span>(</span><span>{</span>
    <span>name</span>: <span>"name"</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔑 Key Features</h2><a id="user-content--key-features" aria-label="Permalink: 🔑 Key Features" href="#-key-features"></a></p>
<ul dir="auto">
<li><strong>Data synchronization</strong> from 25+ sources with minimal config</li>
<li><strong>Entity extraction</strong> and transformation pipeline</li>
<li><strong>Multi-tenant</strong> architecture with OAuth2</li>
<li><strong>Incremental updates</strong> using content hashing</li>
<li><strong>Semantic search</strong> for agent queries</li>
<li><strong>Versioning</strong> for data changes</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔧 Tech Stack</h2><a id="user-content--tech-stack" aria-label="Permalink: 🔧 Tech Stack" href="#-tech-stack"></a></p>
<ul dir="auto">
<li><strong>Frontend</strong>: React/TypeScript with ShadCN</li>
<li><strong>Backend</strong>: FastAPI (Python)</li>
<li><strong>Databases</strong>: PostgreSQL (metadata), Qdrant (vectors)</li>
<li><strong>Deployment</strong>: Docker Compose (dev), Kubernetes (prod)</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">👥 Contributing</h2><a id="user-content--contributing" aria-label="Permalink: 👥 Contributing" href="#-contributing"></a></p>
<p dir="auto">We welcome contributions! Please check <a href="https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">📄 License</h2><a id="user-content--license" aria-label="Permalink: 📄 License" href="#-license"></a></p>
<p dir="auto">Airweave is released under the <a href="https://github.com/airweave-ai/airweave/blob/main/LICENSE">MIT</a> license.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔗 Connect</h2><a id="user-content--connect" aria-label="Permalink: 🔗 Connect" href="#-connect"></a></p>
<ul dir="auto">
<li><strong><a href="https://discord.com/invite/484HY9Ehxt" rel="nofollow">Discord</a></strong> - Get help and discuss features</li>
<li><strong><a href="https://github.com/airweave-ai/airweave/issues">GitHub Issues</a></strong> - Report bugs or request features</li>
<li><strong><a href="https://x.com/airweave_ai" rel="nofollow">Twitter</a></strong> - Follow for updates</li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Leaked Apple M5 9 core Geekbench scores (135 pts)]]></title>
            <link>https://browser.geekbench.com/v6/cpu/14173685</link>
            <guid>45427197</guid>
            <pubDate>Tue, 30 Sep 2025 16:00:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://browser.geekbench.com/v6/cpu/14173685">https://browser.geekbench.com/v6/cpu/14173685</a>, See on <a href="https://news.ycombinator.com/item?id=45427197">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div>
<p>4133</p>
<p>Single-Core Score</p>
</div>
<div>
<p>15437</p>
<p>Multi-Core Score</p>
</div>
<p>
Geekbench 6.5.0 for iOS AArch64
</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kagi News (667 pts)]]></title>
            <link>https://blog.kagi.com/kagi-news</link>
            <guid>45426490</guid>
            <pubDate>Tue, 30 Sep 2025 15:09:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.kagi.com/kagi-news">https://blog.kagi.com/kagi-news</a>, See on <a href="https://news.ycombinator.com/item?id=45426490">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
            <p><img src="https://kagifeedback.org/assets/files/2025-09-29/1759164655-533625-news.png" alt="Cartoon illustration showing multiple smartphone screens showing the Kagi News app with news in different languages."></p>

<p><strong>A comprehensive daily press review with global news. Fully private, with sources openly curated by our community.</strong></p>

<p>News is broken. We all know it, but we’ve somehow accepted it as inevitable. The endless notifications. The clickbait headlines designed to trigger rather than inform, driven by relentless ad monetization. The exhausting cycle of checking multiple apps throughout the day, only to feel more anxious and less informed than when we started. This isn’t what news was supposed to be.
We can do better, and create what news should have been all along: pure, essential information that respects your intelligence and time.</p>

<h2>Our approach: Signal over noise</h2>

<p><a href="https://kite.kagi.com/">Kagi News</a> operates on a simple principle: understanding the world requires hearing from the world. Every day, our system reads thousands of community curated RSS feeds from publications across different viewpoints and perspectives. We then distill this massive information into one comprehensive daily briefing, while clearly citing sources.</p>

<p>We strive for diversity and transparency of resources and welcome your contributions to widen perspectives. This multi-source approach helps reveal the full picture beyond any single viewpoint.</p>

<h2>Design principles that put readers first</h2>

<p><img src="https://kagifeedback.org/assets/files/2025-09-30/1759238916-838501-kaginews.gif" alt="Gif showing a demo of using the Kagi News app, scrolling through the daily press review for world news, clicking on a headline and showing the detailed summary that Kagi News creates. On the left is the Kagi News logo and download icons for Google Play and App Store."></p>

<p><strong>One daily update:</strong> We publish once per day around noon UTC, creating a natural endpoint to news consumption. This is a deliberate design choice that turns news from an endless habit into a contained ritual.</p>

<p><strong>Five-minute complete understanding:</strong> Our briefings cover everything important in just five minutes. No endless scrolling. No attention hijacking. You read, understand, and move on with your day.</p>

<p><strong>Diversity over echo chambers:</strong> Rather than personalizing feeds to match existing preferences, we expose readers to the full spectrum of global perspectives. This approach breaks down information silos instead of reinforcing them.</p>

<p><strong>Privacy by design:</strong> Your reading habits belong to you. We don’t track, profile, or monetize your attention. You remain the customer and not the product.</p>

<p><strong>Community-driven sources:</strong> Our news sources are open source and community-curated through our public GitHub repository. Anyone can propose additions, flag problems, or suggest improvements.</p>

<p><strong>Customizable:</strong> In your settings, you can select and reorder categories to match your interests and priorities. You can also adjust the number of stories shown, as well as dragging to re-order various sections, so that your briefing is focused on the depth and topics that matter most to you.</p>

<p><strong>News in your language:</strong> You can choose your preferred interface and content language. News stories are generated in their original source language, and then translated using Kagi Translate. The default mode shows regional stories in their original language without translation, and all other ones in your browser’s language.</p>

<h2>Technical implementation that respects publishers</h2>

<p>We don’t scrape content from websites. Instead, we use publicly available RSS feeds that publishers choose to provide. Publishers decide what content appears in their feeds; some include full articles, others only titles or summaries. We respect those choices completely. We’re working within the ecosystem publishers have created rather than circumventing their intentions.</p>

<p><img src="https://kagifeedback.org/assets/files/2025-09-29/1759171753-315733-review.png" alt="Review from apple store that says “I’ve avoided news feeds all of my adult life. The onslaught of information and opinions always felt like a waste of my precious time. This app is on a great track to cut through the noise.”"></p>

<h2>Ready to experience news differently?</h2>

<p>If you’re tired of news that makes you feel worse about the world while teaching you less about it, we invite you to try a different approach with Kagi News, so download it today:</p>

<ul>
<li><a href="https://kite.kagi.com/">Web</a></li>
<li><a href="https://apps.apple.com/us/app/kagi-news/id6748314243">iOS</a></li>
<li><a href="https://play.google.com/store/apps/details?id=com.kagi.news">Android</a></li>
</ul>

<p><img src="https://kagifeedback.org/assets/files/2025-09-29/1759164726-927335-kagi-news.jpg" alt="Photo showing hands holding an iPad, with Kagi News open on the Sports news section."></p>

        </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How the AI bubble ate Y Combinator (182 pts)]]></title>
            <link>https://www.inc.com/sam-blum/how-the-ai-bubble-ate-y-combinator/91240632</link>
            <guid>45426205</guid>
            <pubDate>Tue, 30 Sep 2025 14:52:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.inc.com/sam-blum/how-the-ai-bubble-ate-y-combinator/91240632">https://www.inc.com/sam-blum/how-the-ai-bubble-ate-y-combinator/91240632</a>, See on <a href="https://news.ycombinator.com/item?id=45426205">Hacker News</a></p>
Couldn't get https://www.inc.com/sam-blum/how-the-ai-bubble-ate-y-combinator/91240632: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Frank Chimero: I think we're in the lemon stage of the internet (172 pts)]]></title>
            <link>https://frankchimero.com/blog/2025/selling-lemons/</link>
            <guid>45425746</guid>
            <pubDate>Tue, 30 Sep 2025 14:14:28 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://frankchimero.com/blog/2025/selling-lemons/">https://frankchimero.com/blog/2025/selling-lemons/</a>, See on <a href="https://news.ycombinator.com/item?id=45425746">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
			<div>
				<!-- <figure class="full" style="margin-top: calc(-1 * var(--unit-xxl))">
					<img src="/images/borderlands.png" style="object-fit: cover; max-height: 50dvh">
				</figure> -->
				<header>
					<div>
						
						<h2>The hidden costs of the meta game</h2>
						<p><time>September 30, 2025</time>
					</p></div>
				</header>
				<p>I’ve been researching a new talk the last few weeks and along the way stumbled across a concept that’s been rattling around in my head. I am writing to share, because I find it a satisfying description for the tech flop era.</p>

<p>The idea is called “a market for lemons.” The phrase comes from a <a href="https://en.wikipedia.org/wiki/The_Market_for_Lemons">1970 paper by George Akerlof</a> that explains how information asymmetry between buyers and sellers can undermine a marketplace. Akerlof asks us to imagine ourselves buying a used car. Some cars on the lot are reliable, well-maintained gems. Others cars are lemons, the kinds of cars that can make it off the lot but are disasters waiting to happen. The sellers know which cars are which, but you, as a buyer, can’t tell the difference. That information asymmetry affects the average price in the market and eventually impacts the overall market dynamics.</p>

<p>The thinking goes like this: if a buyer can’t distinguish between good and bad, everything gets priced somewhere in the middle. If you’re selling junk, this is fantastic news—you’ll probably get paid more than your lemon is worth. If you’re selling a quality used car, this price is insultingly low. As a result, people with good cars leave the market to sell their stuff elsewhere, which pushes the overall quality and price down even further, until eventually all that’s left on the market are lemons.</p>

<p>I think we’re in the lemon stage of the internet.</p>

<hr>

<p>I thought about this last week while shopping online for a sleep mask. Brands like MZOO, YFONG, WAOAW popped up, and these seemed less like companies and more like vowel smoke ejected from a factory flue hole, then slotted into a distribution platform. The long tail of generic brands on e-commerce platforms is a textbook lemons market: good products get drowned out by these alphabet soup products, who use their higher margins to buy sponsored placement in search results. Both buyers and sellers eventually lose (and perhaps the platforms win, as long as they don’t wear out their reputation).</p>

<p>For shoppers, buying online now feels like rolling the dice on the quality of the product. For sellers, the gamble is that their survival relies more on gaming the system than actually improving the product.</p>

<p>I think the post-pandemic experience has been a collective realization that the value that drew us to certain digital products and marketplaces is gone. Much of this reduction in value gets pinned to ZIRP, but there’s another critical factor—the natural flight of value creators. As platforms matured, the users and sellers who generated real value were squeezed out by players focused on capturing value rather than creating it.</p>

<p>Once you identify a lemon market, you start to see it all over the place.</p>

<p><em>Online dating.</em> A lemon market where participants have no familiarity with one another participate in strategic self-presentation. High-quality partners (emotionally available, looking for genuine connection) can’t effectively distinguish themselves from those just seeking validation and eventually leave.</p>

<p><em>Search results.</em> A lemon market where platforms profit from sponsored placement, misaligning incentives with user needs. The first page is a minefield: sponsored listings posing as organic results, SEO content farms, affiliate aggregators. You add “reddit” to work around this, but even that has less success these days.</p>

<p><em>Social media.</em> Your feed is now professional content creators, low-effort podcast video clips, algorithmic filler reaction videos, stand-up chaff, and animals. Good ideas don’t happen frequently enough to satisfy the pace of the algorithm, so many have pivoted to newsletters or stopped posting.</p>

<p>What makes the Market for Lemons concept so appealing (and what differentiates it in my mind from <a href="https://en.wikipedia.org/wiki/Enshittification">enshittification</a> is that everyone can be acting reasonably, pursuing their own interests, and things still get worse for everyone. No one has to be evil or stupid: the platform does what’s profitable, sellers do what works, buyers try to make smart decisions, and yet the whole system degrades into something nobody actually wants.</p>

<hr>

<p>I was first introduced to the Market of Lemons by Dan Luu in an essay titled, <a href="https://danluu.com/nothing-works/">Why is it so hard to buy things that work well?</a>. Luu applies the market of lemons as a metaphor, and specifically identifies hiring as a market of lemons, because of the <a href="https://danluu.com/hiring-lemons/">information asymmetry for both companies and individuals</a>.</p>

<p>Companies have always struggled to tell the difference between great individual contributors and mediocre ones. Lacking a clear way to separate the two, they lump everyone together and rely on proxy games to evaluate skill. Candidates, for their part, walk into interviews without crucial information: whether the company is quietly dysfunctional, whether the manager they liked during interviews is about to quit, or whether the open role itself is little more than a vestige of an abandoned strategy that’s likely to be cut once the other foot drops. The usual signals of strength or weakness don’t signify much at all when it comes to hiring. Layer on the automated scale of the application process—candidates firing off applications by the hundreds, companies screening by the thousands—and the result is a highly inefficient market that wastes everyone’s time. Meaningful signals get drowned out, everyone gets lumped together, rational players opt out to the extent they are able, and the market slides steadily downward.</p>

<p>There have been countless attempts to make hiring more rational and efficient—the stuff of startup pitch deck lore. But I’m not sure hiring can ever be much more efficient, because neither side has reason to show themselves as they really are, warts and all. Idealistically, both would come straight; pragmatically, it is a game of chicken. Candidates polish résumés and present curated versions of their abilities, listing outcomes and impact statistics with dubious accuracy and provenance. Companies do the same, putting culture and mission front and center while hiding systematic dysfunctions and looming existential risks. When neither side is forthcoming, you’re left with proxies: a famous logo on a resume, a polished culture deck. Gaming the meta of the system supersedes the actual development or evaluation of skill. And, much to my disappointment, gaming the meta may, in fact, be an essential aspect of most jobs.</p>

<hr>

<p>At this point, it should be obvious how the market for lemons applies to ill-considered AI-generated content. I’ll let you sketch out that argument yourself since it’s fairly straightforward, and this thing is already long enough.</p>

<p>Instead, let’s zag and revisit my point earlier about system-gaming becoming the most viable playbook instead of focusing on the product. As a consumer and as a designer, I hope this is a temporary state before a massive recalibration. The primacy of meta-activities—optimizing for algorithms, visibility theater, consumer entrapment, externalization of costs, performative internal alignment, horse-trading amongst a set of DOA ideas—is poison. It is a road to nowhere worth going.</p>

<p>This reflects a business culture obsessed with outcomes while treating outputs as speed bumps. But outputs (code, design, the products themselves) are the load-bearing work—the actual prerequisites for the outcomes desired. Focusing on outcomes while ignoring outputs means hiding in abstractions and absolving oneself of accountability. If any output is acceptable to hit your targets, what awful things emerge at scale? What horrors happen when success detaches completely from the necessity of being good—having both skill and ethics?</p>

<p>The safest, smartest path is also the most mundane: keep the main thing the main thing. Outcomes matter, but output literally comes first. Outputs are the business to everyone outside it—what customers see, buy, and use. You can’t stay safe in abstractions forever. Eventually, you must attend to the reality of what’s in front of you, because that’s where work gets done and where assumptions get validated or falsified (because <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail">reality has a surprising amount of detail</a>).</p>

<p>In other words, the meta ruins things for everyone. To hide in abstractions is to dodge the reality of your choices. These tactics may get you profit, but you sacrifice benefit. The climb may feel like progress, but at the end you’ll find yourself at the top of a mountain of lemons, perhaps not of your own making, but almost certainly of your own doing.</p>

			</div>
		</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[dgsh – Directed Graph Shell (107 pts)]]></title>
            <link>https://www2.dmst.aueb.gr/dds/sw/dgsh/</link>
            <guid>45425298</guid>
            <pubDate>Tue, 30 Sep 2025 13:39:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/">https://www2.dmst.aueb.gr/dds/sw/dgsh/</a>, See on <a href="https://news.ycombinator.com/item?id=45425298">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

<!-- About {{{1
================================================== -->
<section id="intro">
  
<p>
The directed graph shell, <em>dgsh</em>
(<a href="https://en.wiktionary.org/wiki/Appendix:English_pronunciation">pronounced</a> /dæɡʃ/ — <em>dagsh</em>),
provides an expressive way to construct
sophisticated and efficient big data set and stream processing pipelines
using existing Unix tools as well as custom-built components.
It is a Unix-style shell (based on <em>bash</em>)
allowing the specification of pipelines
with non-linear non-uniform operations.
These form a directed acyclic process graph,
which is typically executed by multiple processor cores,
thus increasing the operation's processing throughput.
</p>
<p>
If you want to get a feeling on how <em>dgsh</em> works in practice,
skip right down to the <a href="#examples">examples</a> section.
</p>
<p>
For a more formal introduction to <em>dgsh</em> or to cite it in your work,
see:<br>
Diomidis Spinellis and Marios Fragkoulis.
<a href="http://dx.doi.org/10.1109%2FTC.2017.2695447">Extending Unix Pipelines to DAGs</a>.
<em>IEEE Transactions on Computers</em>, 2017.
doi: 10.1109/TC.2017.2695447
</p>
</section> <!-- Introduction -->

<section id="ipc"> <!-- {{{2 -->
<h2>Inter-process communication</h2>
<p>
<em>Dgsh</em> provides two new ways
for expressing inter-process communication.

</p>
<dl>
<dt>Multipipes</dt><dd> are expressed as usual Unix pipelines,
but can connect commands with more than one output or input channel.
As an example, the <code>comm</code> command supplied with <em>dgsh</em>
expects two input channels and produces on its output three
output channels: the lines appearing only in first (sorted) channel,
the lines appearing only in the second channel,
and the lines appearing in both.
Connecting the output of the <code>comm</code> command to the
<code>cat</code> command supplied with <em>dgsh</em>
will make the three outputs appear in sequence,
while connecting it to the
<code>paste</code> command supplied with <em>dgsh</em>
will make the output appear in its customary format.
</dd>

<dt>Multipipe blocks {{ ... }}</dt><dd>
a) send (multiple) input streams
received on their input side to the asynchronously-running
processes that reside within the block, and,
b) pass the output produced by the processes within the block as
(multiple) streams on their output side.
Multipipe blocks typically receive input from more than one channel
and produce more than one output channel.
For example, a multipipe block that runs <code>md5sum</code> and <code>wc -c</code>
receives two inputs and produces two outputs:
the MD5 hash of its input and the input's size.
Data to multipipe blocks are typically provided with a
<em>dgsh</em>-aware version of <code>tee</code> and collected by
<em>dgsh</em>-aware versions of programs such as
<code>cat</code> and <code>paste</code>.
</dd>

<dt>Stored values</dt> <dd>offer a convenient way for communicating
computed values between arbitrary processes on the graph.
They allow the storage of a data stream's
last record into a named buffer.
This record can be later retrieved asynchronously by one or more readers.
Data in a stored value can be piped into a process or out of it, or it can be read
using the shell's command output substitution syntax.
Stored values are implemented internally through Unix-domain sockets,
a background-running store program, <code>dgsh-writeval</code>, and
a reader program, <code>dgsh-readval</code>.
The behavior of a stored value's IO can be modified by adding flags to
<code>dgsh-writeval</code> and <code>dgsh-readval</code>.
</dd>
</dl>
</section>

<section id="syntax"> <!-- {{{2 -->
<h2>Syntax</h2>
<p>
A <em>dgsh</em> script follows the syntax of a <em>bash</em>(1) shell
script with the addition of <em>multipipe</em> blocks.
A multipipe block contains one or more <em>dgsh</em> simple commands,
other multipipe blocks, or pipelines of the previous two types of commands.
The commands in a multipipe block
are executed asynchronously (in parallel, in the background).
Data may be redirected or piped into and out of a multipipe block.
With multipipe blocks <em>dgsh</em> scripts form directed acyclic process graphs.
It follows from the above description that
multipipe blocks can be recursively composed.
</p>

<p>
As a simple example consider running the following command
directly within <em>dgsh</em>
</p>
<pre>{{ echo hello &amp; echo world &amp; }} | paste
</pre>
<p>
or by invoking <code>dgsh</code> with the command as an argument.
</p>
<pre>dgsh -c '{{ echo hello &amp; echo world &amp; }} | paste'
</pre>
<p>
The command will run <em>paste</em> with input from the two
<em>echo</em> processes to output <code>hello world</code>.
This is equivalent to running the following <em>bash</em> command,
but with the flow of data appearing in the natural left-to-right order.
</p>
<pre>paste &lt;(echo hello) &lt;(echo world)
</pre>

<p>
In the following larger example, which compares the performance of
different compression utilities, the script's standard input
is distributed to
three compression utilities (<em>xz</em>, <em>bzip2</em>, and <em>gzip</em>),
to assess their performance, and also to
<em>file</em> and <em>wc</em> to report the input data's type and size.
The <em>printf</em> commands label the data of each processing type.
All eight commands pass their output
to the <code>cat</code> command, which gathers their outputs
in order.
</p>

<pre>tee |
{{
	printf 'File type:\t'
	file -

	printf 'Original size:\t'
	wc -c

	printf 'xz:\t\t'
	xz -c | wc -c

	printf 'bzip2:\t\t'
	bzip2 -c | wc -c

	printf 'gzip:\t\t'
	gzip -c | wc -c
}} |
cat
</pre>

<p>
Formally, <em>dgsh</em> extends the syntax of the (modified) Unix Bourne-shell
when <code>bash</code> provided with the <code>--dgsh</code> argument
as follows.
</p>

<pre>&lt;dgsh_block&gt;     ::= '{{' &lt;dgsh_list&gt; '}}'

&lt;dgsh_list&gt;      ::= &lt;dgsh_list_item&gt; '&amp;'
                 &lt;dgsh_list_item&gt; &lt;dgsh_list&gt;

&lt;dgsh_list_item&gt; ::= &lt;simple_command&gt;
                 &lt;dgsh_block&gt;
                 &lt;dgsh_list_item&gt; '|' &lt;dgsh_list_item&gt;
</pre>
</section> <!-- syntax -->

<section id="tools"> <!-- {{{2 -->
<h2>Adapted tools</h2>
<p>
A number of Unix tools have been adapted to support multiple inputs
and outputs to match their natural capabilities.
This echoes a similar adaptation that was performed in the early
1970s when Unix and the shell got pipes and the pipeline syntax.
Many programs that worked with files were adjusted to work as filters.
The number of input and output channels of <em>dgsh</em>-compatible commands are
as follows, based on the supplied command-line arguments.
</p>
<table>
	<tbody><tr>
		<th>Tool</th>
		<th>Inputs</th>
		<th>Outputs</th>
		<th>Notes</th>
	</tr>
	<tr>
		<td>cat (<em>dgsh-tee</em>)</td>
		<td>0—N</td>
		<td>0—M</td>
		<td>No options are supported</td>
	</tr>
	<tr>
		<td>cmp</td>
		<td>0—2</td>
		<td>0—1</td>
		<td></td>
	</tr>
	<tr>
		<td>comm</td>
		<td>0—2</td>
		<td>0—3</td>
		<td>Output streams in order: lines only in first file, lines only in second one, and lines in both files</td>
	</tr>
	<tr>
		<td>cut</td>
		<td>0—1</td>
		<td>1—N</td>
		<td>With <code>--multistream</code> output each range into a different stream</td>
	</tr>
	<tr>
		<td>diff</td>
		<td>0—N</td>
		<td>1</td>
		<td>Typically two inputs. Compare an arbitrary number of input streams with the <code>--from-file</code> or <code>--to-file</code> options</td>
	</tr>
	<tr>
		<td>diff3</td>
		<td>0—3</td>
		<td>1</td>
		<td></td>
	</tr>
	<tr>
		<td>grep</td>
		<td>0—2</td>
		<td>0—4</td>
		<td>Available output streams (via arguments): matching files, non-matching files, matching lines, and non-matching lines</td>
	</tr>
	<tr>
		<td>join</td>
		<td>0—2</td>
		<td>1</td>
		<td></td>
	</tr>
	<tr>
		<td>paste</td>
		<td>0—N</td>
		<td>1</td>
		<td>Paste N input streams</td>
	</tr>
	<tr>
		<td>perm</td>
		<td>1—N</td>
		<td>1—N</td>
		<td>Rearrange the order of N input streams</td>
	</tr>
	<tr>
		<td>sort</td>
		<td>0—N</td>
		<td>0—1</td>
		<td>With the <code>-m</code> option, merge sort N input streams</td>
	</tr>
	<tr>
		<td>tee (<em>dgsh-tee</em>)</td>
		<td>0—N</td>
		<td>0—M</td>
		<td>Only the <code>-a</code> option is supported</td>
	</tr>
	<tr>
		<td>dgsh-readval</td>
		<td>0</td>
		<td>1</td>
		<td>Read a value from a socket</td>
	</tr>
	<tr>
		<td>dgsh-wrap</td>
		<td>0—N</td>
		<td>0—1</td>
		<td>Wrap non-dgsh commands and negotiate on their behalf</td>
	</tr>
	<tr>
		<td>dgsh-writeval</td>
		<td>1</td>
		<td>0</td>
		<td>Write a value to a socket</td>
	</tr>
</tbody></table>

<p>
In addition, POSIX user commands that receive no input
or only generate no output, when executed in a <em>dgsh</em> context
are wrapped to specify the corresponding input or output capability.
For example, an <code>echo</code> command in a multipipe block
will appear to receive no input, but will provide one output stream.
By default <code>dgsh</code> automatically wraps all other
commands as filters.
</p><dl>
<dt> Input-only </dt><dd>
read,
write.
</dd>
<dt> Output-only </dt><dd> </dd>
alias,
ar,
basename,
c99,
cal,
cflow,
command,
date,
df,
dirname,
du,
echo,
expr,
find,
getopts,
ipcrm,
jobs,
ls,
make,
man,
printf,
ps,
pwd,
tty,
type,
ulimit,
umask,
uname,
what,
who.
</dl>
<dt> No input and output </dt><dd> </dd>
dbg,
dcd,
dchgrp,
dchmod,
dchown,
dcp,
denv,
dfalse,
dfg,
dkill,
dlink,
dln,
dmesg,
dmkdir,
dmkfifo,
dmv,
dnewgrp,
dnice,
dnohup,
drenice,
drm,
drmdir,
dsleep,
dstrip,
dtest,
dtouch,
dtrue,
dunalias,
dunlink,
dwait,
dyacc.


<p>
Finally, note that any <em>dgsh</em> script will accept and generate
the number of inputs and outputs associated with the commands or
multipipe blocks at its two endpoints.
</p>
</section> <!-- Adapted tools -->


<!-- Downloading and installation {{{1
================================================== -->
<section id="download">
  

<p>
The <em>dgsh</em> suite has been tested under
Debian and Ubuntu Linux, FreeBSD, and Mac OS X.
A Cygwin port is underway.
</p>

<p>
An installation of <a href="http://www.graphviz.org/">GraphViz</a>
will allow you to visualize the <em>dgsh</em> graphs that you specify
in your programs.
</p>

    <section id="debian"> <!-- {{{2 -->
    <h2>Debian and Ubuntu GNU/Linux</h2>
    <section>
    <h3>Prerequisites</h3>
<p>
To compile and run <em>dgsh</em> you will need to have the following commands
installed on your system:
</p><pre>make automake gcc libtool pkg-config texinfo help2man autopoint bison check gperf 
git xz-utils gettext
</pre>

To test <em>dgsh</em> you will need to have the following commands
installed in your system:
<pre>wbritish wamerican libfftw3-dev csh
curl bzip2
</pre>

    <h3>Installation steps</h3>
<p>
Go through the following steps.
</p><ol>
<li>
Recursively clone the project's source code through its
<a href="https://github.com/dspinellis/dgsh">GitHub page</a>.
<pre>git clone --recursive https://github.com/dspinellis/dgsh.git
</pre>
</li>
<li>
Configure <em>bash</em> and the Unix tools adapted for <em>dgsh</em>.
<pre>make config
</pre>
</li>
<li>
Compile all programs.
<pre>make
</pre>
</li>
<li>
Install.
<pre>sudo make install
</pre>
</li>
</ol>

<p>
By default, the program and its documentation are installed under
<code>/usr/local</code>.
You can modify this by setting the <code>PREFIX</code> variable
in the `config` step, for example:
</p><pre>make PREFIX=$HOME config
make
make install
</pre>


    <h3>Testing</h3>
<p>

Issue the following command.
</p><pre>make test
</pre>


    </section>
    <section id="freebsd"> <!-- {{{2 -->
    <h2>FreeBSD</h2>
    <section>
    <h3>Prerequisites</h3>
<p>
To compile and run <em>dgsh</em> you will need to have the following packages
installed in your system:
</p><pre>devel/automake
devel/bison
devel/check
devel/git
devel/gmake
devel/gperf
misc/help2man
print/texinfo
shells/bash
</pre>

To test <em>dgsh</em> you will need to have the following ports
installed on your system:
<pre>archivers/bzip2
ftp/curl
</pre>

    <h3>Installation steps</h3>
<p>
Go through the following steps.
</p><ol>
<li>
Recursively clone the project's source code through its
<a href="https://github.com/dspinellis/dgsh">GitHub page</a>.
<pre>git clone --recursive https://github.com/dspinellis/dgsh.git
</pre>
</li>
<li>
Configure <em>bash</em> and the Unix tools adapted for <em>dgsh</em>.
<pre>gmake config
</pre>
</li>
<li>
Compile all programs.
<pre>gmake
</pre>
</li>
<li>
Install.
<pre>sudo gmake install
</pre>
</li>
</ol>

<p>
By default, the program and its documentation are installed under
<code>/usr/local</code>.
You can modify this by setting the <code>PREFIX</code> variable
in the `config` step, for example:
</p><pre>gmake PREFIX=$HOME config
gmake
gmake install
</pre>


    <h3>Testing</h3>
<p>

Issue the following command.
</p><pre>gmake test
</pre>


    </section>
</section>
</section>

<!-- Reference {{{1
================================================== -->
<section id="reference">
  
<p>
These are the manual pages for <em>dgsh</em>, the associated helper programs
and the API
in formats suitable for browsing and printing.
The commands are listed in the order of usefulness in everyday scenarios.
</p>
<dl>
<dt> dgsh </dt><dd> directed graph shell <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh.pdf">PDF</a></dd>
<dt> dgsh-tee </dt><dd> buffer and copy or scatter standard input to one or more sinks <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-tee.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-tee.pdf">PDF</a></dd>
<dt> dgsh-wrap </dt><dd> allow any filter program to participate in an dgsh pipeline <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-wrap.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-wrap.pdf">PDF</a></dd>
<dt> dgsh-writeval </dt><dd> write values to a data store <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-writeval.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-writeval.pdf">PDF</a></dd>
<dt> dgsh-readval </dt><dd> data store client <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-readval.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-readval.pdf">PDF</a></dd>
<dt> dgsh-monitor </dt><dd> monitor data on a pipe <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-monitor.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-monitor.pdf">PDF</a></dd>
<dt> dgsh-parallel </dt><dd> create a semi-homongeneous dgsh parallel processing block <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-parallel.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-parallel.pdf">PDF</a></dd>
<dt> perm </dt><dd> permute inputs to outputs <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/perm.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/perm.pdf">PDF</a></dd>
<dt> dgsh-httpval </dt><dd> provide data store values through HTTP <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-httpval.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-httpval.pdf">PDF</a></dd>
<dt> dgsh-merge-sum </dt><dd> merge key value pairs, summing the values <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-merge-sum.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-merge-sum.pdf">PDF</a></dd>
<dt> dgsh-conc </dt><dd> input or output pipe concentrator for <em>dgsh</em> negotiation (used internally) <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-conc.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-conc.pdf">PDF</a></dd>
<dt> dgsh-enumerate </dt><dd> enumerate an arbitrary number of output channels (demonstration and <a href="http://istlab.dmst.aueb.gr/~dds/dgsh-egg.sh">debugging</a> tool) <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-enumerate.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh-enumerate.pdf">PDF</a></dd>
<dt> dgsh_negotiate </dt><dd> API for <em>dgsh</em>-compatible
programs to specify and obtain dgsh I/O file descriptors
<a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh_negotiate.html">HTML</a>, <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/dgsh_negotiate.pdf">PDF</a></dd>
</dl>
</section>


<!--</th>
<th>Examples</th>
<th>{{{1
==================================================</th>
<th>-->
<section id="examples">
  

<section id="compress-compare"> <!-- {{{2 -->
<h2>Compression benchmark</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/compress-compare-pretty.png" alt="Compression benchmark">
<!-- Extracted description -->
<p>
Report file type, length, and compression performance for
data received from the standard input.  The data never touches the
disk.
Demonstrates the use of an output multipipe to source many commands
from one followed by an input multipipe to sink to one command
the output of many and the use of dgsh-tee that is used both to
propagate the same input to many commands and collect output from
many commands orderly in a way that is transparent to users.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

tee |
{{
	printf 'File type:\t'
	file -

	printf 'Original size:\t'
	wc -c

	printf 'xz:\t\t'
	xz -c | wc -c

	printf 'bzip2:\t\t'
	bzip2 -c | wc -c

	printf 'gzip:\t\t'
	gzip -c | wc -c
}} |
cat
</pre>
<section id="commit-stats"> <!-- {{{2 -->
<h2>Git commit statistics</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/commit-stats-pretty.png" alt="Git commit statistics">
<!-- Extracted description -->
<p>
Process the Git history, and list the authors and days of the week
ordered by the number of their commits.
Demonstrates streams and piping through a function.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

forder()
{
	sort |
	uniq -c |
	sort -rn
}

git log --format="%an:%ad" --date=default "$@" |
tee |
{{
	echo "Authors ordered by number of commits"
	# Order by frequency
	awk -F: '{print $1}' |
	forder

	echo "Days ordered by number of commits"
	# Order by frequency
	awk -F: '{print substr($2, 1, 3)}' |
	forder
}} |
cat
</pre>
<section id="code-metrics"> <!-- {{{2 -->
<h2>C code metrics</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/code-metrics-pretty.png" alt="C code metrics">
<!-- Extracted description -->
<p>
Process a directory containing C source code, and produce a summary
of various metrics.
Demonstrates nesting, commands without input.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

{{
	# C and header code
	find "$@" \( -name \*.c -or -name \*.h \) -type f -print0 |
	tee |
	{{

		# Average file name length
		# Convert to newline separation for counting
		echo -n 'FNAMELEN: '
		tr \\0 \\n |
		# Remove path
		sed 's|^.*/||' |
		# Maintain average
		awk '{s += length($1); n++} END {
			if (n&gt;0)
				print s / n;
			else
				print 0; }'

		xargs -0 /bin/cat |
		tee |
		{{
			# Remove strings and comments
			sed 's/#/@/g;s/\\[\\"'\'']/@/g;s/"[^"]*"/""/g;'"s/'[^']*'/''/g" |
			cpp -P |
			tee |
			{{
				# Structure definitions
				echo -n 'NSTRUCT: '
				egrep -c 'struct[   ]*{|struct[   ]*[a-zA-Z_][a-zA-Z0-9_]*[       ]*{'
				#}} (match preceding openings)

				# Type definitions
				echo -n 'NTYPEDEF: '
				grep -cw typedef

				# Use of void
				echo -n 'NVOID: '
				grep -cw void

				# Use of gets
	  			echo -n 'NGETS: '
	  			grep -cw gets

				# Average identifier length
				echo -n 'IDLEN: '
				tr -cs 'A-Za-z0-9_' '\n' |
				sort -u |
				awk '/^[A-Za-z]/ { len += length($1); n++ } END {
					if (n&gt;0)
						print len / n;
					else
						print 0; }'
			}}

			# Lines and characters
			echo -n 'CHLINESCHAR: '
			wc -lc |
			awk '{OFS=":"; print $1, $2}'

			# Non-comment characters (rounded thousands)
			# -traditional avoids expansion of tabs
			# We round it to avoid failing due to minor
			# differences between preprocessors in regression
			# testing
			echo -n 'NCCHAR: '
			sed 's/#/@/g' |
			cpp -traditional -P |
			wc -c |
			awk '{OFMT = "%.0f"; print $1/1000}'

			# Number of comments
			echo -n 'NCOMMENT: '
			egrep -c '/\*|//'

			# Occurences of the word Copyright
			echo -n 'NCOPYRIGHT: '
			grep -ci copyright
		}}
	}}

	# C files
	find "$@" -name \*.c -type f -print0 |
	tee |
	{{
		# Convert to newline separation for counting
		tr \\0 \\n |
		tee |
		{{
			# Number of C files
			echo -n 'NCFILE: '
			wc -l

			# Number of directories containing C files
			echo -n 'NCDIR: '
			sed 's,/[^/]*$,,;s,^.*/,,' |
			sort -u |
			wc -l
		}}

		# C code
		xargs -0 /bin/cat |
		tee |
		{{
			# Lines and characters
			echo -n 'CLINESCHAR: '
			wc -lc |
			awk '{OFS=":"; print $1, $2}'

			# C code without comments and strings
			sed 's/#/@/g;s/\\[\\"'\'']/@/g;s/"[^"]*"/""/g;'"s/'[^']*'/''/g" |
			cpp -P |
			tee |
			{{
				# Number of functions
				echo -n 'NFUNCTION: '
				grep -c '^{'

				# Number of gotos
				echo -n 'NGOTO: '
				grep -cw goto

				# Occurrences of the register keyword
				echo -n 'NREGISTER: '
				grep -cw register

				# Number of macro definitions
				echo -n 'NMACRO: '
				grep -c '@[   ]*define[   ][   ]*[a-zA-Z_][a-zA-Z0-9_]*('
				# Number of include directives
				echo -n 'NINCLUDE: '
				grep -c '@[   ]*include'

				# Number of constants
				echo -n 'NCONST: '
				grep -ohw '[0-9][x0-9][0-9a-f]*' | wc -l

			}}
		}}
	}}

	# Header files
	echo -n 'NHFILE: '
	find "$@" -name \*.h -type f |
	wc -l

}} |
# Gather and print the results
cat
</pre>
<section id="duplicate-files"> <!-- {{{2 -->
<h2>Find duplicate files</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/duplicate-files-pretty.png" alt="Find duplicate files">
<!-- Extracted description -->
<p>
List the names of duplicate files in the specified directory.
Demonstrates the combination of streams with a relational join.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Create list of files
find "$@" -type f |

# Produce lines of the form
# MD5(filename)= 811bfd4b5974f39e986ddc037e1899e7
xargs openssl md5 |

# Convert each line into a "filename md5sum" pair
sed 's/^MD5(//;s/)= / /' |

# Sort by MD5 sum
sort -k2 |

tee |
{{

	# Print an MD5 sum for each file that appears more than once
	awk '{print $2}' | uniq -d

	# Promote the stream to gather it
	cat
}} |
# Join the repeated MD5 sums with the corresponding file names
# Join expects two inputs, second will come from scatter
# XXX make streaming input identifiers transparent to users
join -2 2 |

# Output same files on a single line
awk '
BEGIN {ORS=""}
$1 != prev &amp;&amp; prev {print "\n"}
END {if (prev) print "\n"}
{if (prev) print " "; prev = $1; print $2}'
</pre>
<section id="spell-highlight"> <!-- {{{2 -->
<h2>Highlight misspelled words</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/spell-highlight-pretty.png" alt="Highlight misspelled words">
<!-- Extracted description -->
<p>
Highlight the words that are misspelled in the command's first
argument.
Demonstrates stream processing with multipipes and
the avoidance of pass-through constructs to avoid deadlocks.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

export LC_ALL=C

tee |
{{
	# Find errors
	{{
		# Obtain list of words in text
		tr -cs A-Za-z \\n |
		tr A-Z a-z |
		sort -u

		# Ensure dictionary is compatibly sorted
		sort /usr/share/dict/words
	}} |
	# List errors as a set difference
	comm -23

	# Pass through text
	cat
}} |
grep --fixed-strings --file=- --ignore-case --color --word-regex --context=2
</pre>
<section id="word-properties"> <!-- {{{2 -->
<h2>Word properties</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/word-properties-pretty.png" alt="Word properties">
<!-- Extracted description -->
<p>
Read text from the standard input and list words
containing a two-letter palindrome, words containing
four consonants, and words longer than 12 characters.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Consistent sorting across machines
export LC_ALL=C

# Stream input from file
cat $1 |

# Split input one word per line
tr -cs a-zA-Z \\n |
# Create list of unique words
sort -u |
tee |
{{
	# Pass through the original words
	cat

	# List two-letter palindromes
	sed 's/.*\(.\)\(.\)\2\1.*/p: \1\2-\2\1/;t
		g'

	# List four consecutive consonants
	sed -E 's/.*([^aeiouyAEIOUY]{4}).*/c: \1/;t
		g'

	# List length of words longer than 12 characters
	awk '{if (length($1) &gt; 12) print "l:", length($1);
		else print ""}'
}} |
# Paste the four streams side-by-side
paste |
# List only words satisfying one or more properties
fgrep :
</pre>
<section id="web-log-report"> <!-- {{{2 -->
<h2>Web log reporting</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/web-log-report-pretty.png" alt="Web log reporting">
<!-- Extracted description -->
<p>
Creates a report for a fixed-size web log file read from the standard input.
Demonstrates the combined use of multipipe blocks, writeval and readval
to store and retrieve values, and functions in the scatter block.
Used to measure throughput increase achieved through parallelism.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Output the top X elements of the input by the number of their occurrences
# X is the first argument
toplist()
{
	uniq -c | sort -rn | head -$1
	echo
}

# Output the argument as a section header
header()
{
	echo
	echo "$1"
	echo "$1" | sed 's/./-/g'
}

# Consistent sorting
export LC_ALL=C

export -f toplist
export -f header


if [ -z "${DGSH_DRAW_EXIT}" ]
then
cat &lt;&lt;EOF
			WWW server statistics
			=====================

Summary
-------
EOF
fi

tee |
{{
	# Number of accesses
	echo -n 'Number of accesses: '
	dgsh-readval -l -s nAccess

	# Number of transferred bytes
	awk '{s += $NF} END {print s}' |
	tee |
	{{
		echo -n 'Number of Gbytes transferred: '
		awk '{print $1 / 1024 / 1024 / 1024}'

		dgsh-writeval -s nXBytes
	}}

	echo -n 'Number of hosts: '
	dgsh-readval -l -q -s nHosts

	echo -n 'Number of domains: '
	dgsh-readval -l -q -s nDomains

	echo -n 'Number of top level domains: '
	dgsh-readval -l -q -s nTLDs

	echo -n 'Number of different pages: '
	dgsh-readval -l -q -s nUniqPages

	echo -n 'Accesses per day: '
	dgsh-readval -l -q -s nDayAccess

	echo -n 'MBytes per day: '
	dgsh-readval -l -q -s nDayMB

	# Number of log file bytes
	echo -n 'MBytes log file size: '
	wc -c |
	awk '{print $1 / 1024 / 1024}'

	# Host names
	awk '{print $1}' |
	tee |
	{{
		# Number of accesses
		wc -l | dgsh-writeval -s nAccess

		# Sorted hosts
		sort |
		tee |
		{{

			# Unique hosts
			uniq |
			tee |
			{{
				# Number of hosts
				wc -l | dgsh-writeval -s nHosts

				# Number of TLDs
				awk -F. '$NF !~ /[0-9]/ {print $NF}' |
				sort -u |
				wc -l |
				dgsh-writeval -s nTLDs
			}}

			# Top 10 hosts
			{{
				 call 'header "Top 10 Hosts"'
				 call 'toplist 10'
			}}
		}}

		# Top 20 TLDs
		{{
			call 'header "Top 20 Level Domain Accesses"'
			awk -F. '$NF !~ /^[0-9]/ {print $NF}' |
			sort |
			call 'toplist 20'
		}}

		# Domains
		awk -F. 'BEGIN {OFS = "."}
		            $NF !~ /^[0-9]/ {$1 = ""; print}' |
		sort |
		tee |
		{{
			# Number of domains
			uniq |
			wc -l |
			dgsh-writeval -s nDomains

			# Top 10 domains
			{{
				 call 'header "Top 10 Domains"'
				 call 'toplist 10'
			}}
		}}
	}}

	# Hosts by volume
	{{
		call 'header "Top 10 Hosts by Transfer"'
		awk '    {bytes[$1] += $NF}
		END {for (h in bytes) print bytes[h], h}' |
		sort -rn |
		head -10
	}}

	# Sorted page name requests
	awk '{print $7}' |
	sort |
	tee |
	{{

		# Top 20 area requests (input is already sorted)
		{{
			 call 'header "Top 20 Area Requests"'
			 awk -F/ '{print $2}' |
			 call 'toplist 20'
		}}

		# Number of different pages
		uniq |
		wc -l |
		dgsh-writeval -s nUniqPages

		# Top 20 requests
		{{
			 call 'header "Top 20 Requests"'
			 call 'toplist 20'
		}}
	}}

	# Access time: dd/mmm/yyyy:hh:mm:ss
	awk '{print substr($4, 2)}' |
	tee |
	{{

		# Just dates
		awk -F: '{print $1}' |
		tee |
		{{

			# Number of days
			uniq |
			wc -l |
			tee |
			{{
				awk '
					BEGIN {
					"dgsh-readval -l -x -s nAccess" | getline NACCESS;}
					{print NACCESS / $1}' |
				dgsh-writeval -s nDayAccess

				awk '
					BEGIN {
					"dgsh-readval -l -x -q -s nXBytes" | getline NXBYTES;}
					{print NXBYTES / $1 / 1024 / 1024}' |
				dgsh-writeval -s nDayMB
			}}

			{{
				 call 'header "Accesses by Date"'
				 uniq -c
			}}

			# Accesses by day of week
			{{
				 call 'header "Accesses by Day of Week"'
				 sed 's|/|-|g' |
				 call '(date -f - +%a 2&gt;/dev/null || gdate -f - +%a)' |
				 sort |
				 uniq -c |
				 sort -rn
			}}
		}}

		# Hour
		{{
			call 'header "Accesses by Local Hour"'
			awk -F: '{print $2}' |
			sort |
			uniq -c
		}}
	}}
	dgsh-readval -q -s nAccess
}} |
cat
</pre>
<section id="text-properties"> <!-- {{{2 -->
<h2>Text properties</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/text-properties-pretty.png" alt="Text properties">
<!-- Extracted description -->
<p>
Read text from the standard input and create files
containing word, character, digram, and trigram frequencies.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Consistent sorting across machines
export LC_ALL=C


# Convert input into a ranked frequency list
ranked_frequency()
{
	awk '{count[$1]++} END {for (i in count) print count[i], i}' |
	# We want the standard sort here
	sort -rn
}

# Convert standard input to a ranked frequency list of specified n-grams
ngram()
{
	local N=$1

	perl -ne 'for ($i = 0; $i &lt; length($_) - '$N'; $i++) {
		print substr($_, $i, '$N'), "\n";
	}' |
	ranked_frequency
}

export -f ranked_frequency
export -f ngram

tee |
{{
	# Split input one word per line
	tr -cs a-zA-Z \\n |
	tee |
	{{
		# Digram frequency
		call 'ngram 2 &gt;digram.txt'
		# Trigram frequency
		call 'ngram 3 &gt;trigram.txt'
		# Word frequency
		call 'ranked_frequency &gt;words.txt'
	}}

	# Store number of characters to use in awk below
	wc -c |
	dgsh-writeval -s nchars

	# Character frequency
	sed 's/./&amp;\
/g' |
	# Print absolute
	call 'ranked_frequency' |
	awk 'BEGIN {
		"dgsh-readval -l -x -q -s nchars" | getline NCHARS
		OFMT = "%.2g%%"}
		{print $1, $2, $1 / NCHARS * 100}' &gt; character.txt
}}
</pre>
<section id="static-functions"> <!-- {{{2 -->
<h2>C/C++ symbols that should be static</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/static-functions-pretty.png" alt="C/C++ symbols that should be static">
<!-- Extracted description -->
<p>
Given as an argument a directory containing object files, show which
symbols are declared with global visibility, but should have been
declared with file-local (static) visibility instead.
Demonstrates the use of dgsh-capable comm (1) to combine data from
two sources.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Find object files
find "$1" -name \*.o |

# Print defined symbols
xargs nm |

tee |
{{

  # List all defined (exported) symbols
  awk 'NF == 3 &amp;&amp; $2 ~ /[A-Z]/ {print $3}' | sort

  # List all undefined (imported) symbols
  awk '$1 == "U" {print $2}' | sort

}} |
# Print exports that are not imported
comm -23
</pre>
<section id="map-hierarchy"> <!-- {{{2 -->
<h2>Hierarchy map</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/map-hierarchy-pretty.png" alt="Hierarchy map">
<!-- Extracted description -->
<p>
Given two directory hierarchies A and B passed as input arguments
(where these represent a project at different parts of its lifetime)
copy the files of hierarchy A to a new directory, passed as a third
argument, corresponding to the structure of directories in B.
Demonstrates the use of <em>join</em> to process results from two
inputs and the use of <em>gather</em> to order asynchronously
produced results.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

if [ -z "${DGSH_DRAW_EXIT}" -a \( ! -d "$1" -o ! -d "$2" -o -z "$3" \) ]
then
  echo "Usage: $0 dir-1 dir-2 new-dir-name" 1&gt;&amp;2
  exit 1
fi

NEWDIR="$3"

export LC_ALL=C

line_signatures()
{
  find $1 -type f -name '*.[chly]' -print |
  # Split path name into directory and file
  sed 's|\(.*\)/\([^/]*\)|\1 \2|' |
  while read dir file
  do
    # Print "directory filename content" of lines with
    # at least one alphabetic character
    # The fields are separated by  and 
    sed -n "/[a-z]/s|^|$dir$file|p" "$dir/$file"
  done |
  # Error: multi-character tab '\001\001'
  sort -T `pwd` -t -k 2
}


export -f line_signatures


{{
  # Generate the signatures for the two hierarchies
  call 'line_signatures "$1"' -- "$1"
  call 'line_signatures "$1"' -- "$2"
}} |

# Join signatures on file name and content
join -t -1 2 -2 2 |

# Print filename dir1 dir2
sed 's///g' |
awk -F 'BEGIN{OFS=" "}{print $1, $3, $4}' |

# Unique occurrences
sort -u |
tee |
{{
  # Commands to copy
  awk '{print "mkdir -p '$NEWDIR'/" $3 ""}' |
  sort -u

  awk '{print "cp " $2 "/" $1 " '$NEWDIR'/" $3 "/" $1 ""}'
}} |
# Order: first make directories, then copy files
# TODO: dgsh-tee does not pass along first incoming stream
cat |
sh
</pre>
<section id="committer-plot"> <!-- {{{2 -->
<h2>Plot Git committer activity over time</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/committer-plot-pretty.png" alt="Plot Git committer activity over time">
<!-- Extracted description -->
<p>
Process the Git history, and create two PNG diagrams depicting
committer activity over time. The most active committers appear
at the center vertical of the diagram.
Demonstrates image processing, mixining of synchronous and
asynchronous processing in a scatter block, and the use of an
dgsh-compliant join command.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Commit history in the form of ascending Unix timestamps, emails
git log --pretty=tformat:'%at %ae' |
# Filter records according to timestamp: keep (100000, now) seconds
awk 'NF == 2&amp; $1 &gt; 100000&amp; $1 &lt; '`date +%s` |
sort -n |
tee |
{{
	{{
		# Calculate number of committers
		awk '{print $2}' |
		sort -u |
		wc -l |
		tee |
		{{
			dgsh-writeval -s committers1

			dgsh-writeval -s committers2
			dgsh-writeval -s committers3
		}}

		# Calculate last commit timestamp in seconds
		tail -1 |
		awk '{print $1}'

		# Calculate first commit timestamp in seconds
		head -1 |
		awk '{print $1}'
	}} |
	# Gather last and first commit timestamp
	cat |
	# Make one space-delimeted record
	tr '\n' ' ' |
	# Compute the difference in days
	awk '{print int(($1 - $2) / 60 / 60 / 24)}' |
	# Store number of days
	dgsh-writeval -s days

	sort -k2	# &lt;timestamp, email&gt;

	# Place committers left/right of the median
	# according to the number of their commits
	awk '{print $2}' |
	sort |
	uniq -c |
	sort -n |
	awk '
		BEGIN {
			"dgsh-readval -l -x -q -s committers1" | getline NCOMMITTERS
			l = 0; r = NCOMMITTERS;}
		{print NR % 2 ? l++ : --r, $2}' |
	sort -k2	# &lt;left/right, email&gt;

}} |
# Join committer positions with commit time stamps
# based on committer email
join -j 2 |		# &lt;email, timestamp, left/right&gt;
# Order by timestamp
sort -k 2n |
tee |
{{
	# Create portable bitmap
	echo 'P1'

	{{
		dgsh-readval -l -q -s committers2
		dgsh-readval -l -q -s days
	}} |
	cat |
	tr '\n' ' ' |
	awk '{print $1, $2}'

	perl -na -e '
	  BEGIN {
	    open(my $ncf, "-|", "dgsh-readval -l -x -q -s committers3");
	    $ncommitters = &lt;$ncf&gt;;
	    @empty[$ncommitters - 1] = 0; @committers = @empty;
	  }
	  sub out {
		  print join("", map($_ ? "1" : "0", @committers)), "\n";
	  }

	  $day = int($F[1] / 60 / 60 / 24);
	  $pday = $day if (!defined($pday));

	  while ($day != $pday) {
		  out();
		  @committers = @empty;
		  $pday++;
	  }

	  $committers[$F[2]] = 1;

	  END { out(); }
	'
}} |
cat |
# Enlarge points into discs through morphological convolution
pgmmorphconv -erode &lt;(
cat &lt;&lt;EOF
P1
7 7
1 1 1 0 1 1 1
1 1 0 0 0 1 1
1 0 0 0 0 0 1
0 0 0 0 0 0 0
1 0 0 0 0 0 1
1 1 0 0 0 1 1
1 1 1 0 1 1 1
EOF
) |
tee |
{{
	# Full-scale image
	pnmtopng &gt;large.png
	# A smaller image
	pamscale -width 640 |
	pnmtopng &gt;small.png
}}
</pre>
<section id="parallel-word-count"> <!-- {{{2 -->
<h2>Parallel word count</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/parallel-word-count-pretty.png" alt="Parallel word count">
<!-- Extracted description -->
<p>
Count number of times each word appears in the specified input file(s)
Demonstrates parallel execution mirroring the Hadoop WordCount example
via the dgsh-parallel command.
In contrast to GNU parallel, the block generated by dgsh-parallel
has N input and output streams, which can be combined by any
dgsh-compatible tool, such as dgsh-merge-sum or sort -m.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Number of processes
N=8

# Collation order for sorting
export LC_ALL=C

# Scatter input
dgsh-tee -s |
# Emulate Java's default StringTokenizer, sort, count
dgsh-parallel -n $N "tr -s ' \t\n\r\f' '\n' | sort -S 512M | uniq -c" |
# Merge sorted counts by providing N input channels
dgsh-merge-sum $(for i in $(seq $N) ; do printf '&lt;| ' ; done)
</pre>

<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/author-compare-pretty.png" alt="Venue author compare">
<!-- Extracted description -->
<p>
Given the specification of two publication venues, read a compressed
DBLP computer science bibliography from the standard input (e.g. piped
from curl -s http://dblp.uni-trier.de/xml/dblp.xml.gz or from a locally
cached copy) and output the number of papers published in each of the
two venues as well as the number of authors who have published only in
the first venue, the number who have published only in the second one,
and authors who have published in both.  The venues are specified through
the script's first two command-line arguments as a DBLP key prefix, e.g.
journals/acta/, conf/icse/, journals/software/, conf/iwpc/, or conf/msr/.
Demonstrates the use of dgsh-wrap -e to have sed(1) create two output
streams and the use of tee to copy a pair of streams into four ones.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Extract and sort author names
sorted_authors()
{
  sed -n 's/&lt;author&gt;\([^&lt;]*\)&lt;\/author&gt;/\1/p' |
  sort
}

# Escape a string to make it a valid sed(1) pattern
escape()
{
  echo "$1" | sed 's/\([/\\]\)/\\\1/g'
}

export -f sorted_authors

if [ ! "$2" -a ! "$DGSH_DOT_DRAW"] ; then
  echo "Usage: $0 key1 key2" 1&gt;&amp;2
  echo "Example: $0 conf/icse/ journals/software/" 1&gt;&amp;2
  exit 1
fi

gzip -dc |
# Output the two venue authors as two output streams
dgsh-wrap -e sed -n "
/^&lt;.*key=\"$(escape $1)/,/&lt;title&gt;/ w &gt;|
/^&lt;.*key=\"$(escape $2)/,/&lt;title&gt;/ w &gt;|" |
# 2 streams in 4 streams out: venue1, venue2, venue1, venue2
tee |
{{
  {{
    echo -n "$1 papers: "
    grep -c '^&lt;.* mdate=.* key='
    echo -n "$2 papers: "
    grep -c '^&lt;.* mdate=.* key='
  }}

  {{
    call sorted_authors
    call sorted_authors
  }} |
  comm |
  {{
    echo -n "Authors only in $1: "
    wc -l
    echo -n "Authors only in $2: "
    wc -l
    echo -n 'Authors common in both venues: '
    wc -l
  }}
}} |
cat
</pre>
<section id="ft2d"> <!-- {{{2 -->
<h2>Waves: 2D Fourier transforms</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/ft2d-pretty.png" alt="Waves: 2D Fourier transforms">
<!-- Extracted description -->
<p>
Create two graphs:
1) a broadened pulse and the real part of its 2D Fourier transform, and
2) a simulated air wave and the amplitude of its 2D Fourier transform.
Demonstrates using the tools of the Madagascar shared research environment
for computational data analysis in geophysics and related fields.
Also demonstrates the use of two scatter blocks in the same script,
and the used of named streams.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

mkdir -p Fig

# The SConstruct SideBySideIso "Result" method
side_by_side_iso()
{
	vppen size=r vpstyle=n gridnum=2,1 /dev/stdin $*
}

export -f side_by_side_iso

# A broadened pulse and the real part of its 2D Fourier transform
sfspike n1=64 n2=64 d1=1 d2=1 nsp=2 k1=16,17 k2=5,5 mag=16,16 \
	label1='time' label2='space' unit1= unit2= |
sfsmooth rect2=2 |
sfsmooth rect2=2 |
tee |
{{
	sfgrey pclip=100 wanttitle=n

	sffft1 |
	sffft3 axis=2 pad=1 |
	sfreal |
	tee |
	{{
		sfwindow f1=1 | sfreverse which=3
		cat
	}} |
	sfcat axis=1 "&lt;|" |
	sfgrey pclip=100 wanttitle=n label1="1/time" label2="1/space"
}} |
call_with_stdin side_by_side_iso '&lt;|' yscale=1.25 &gt;Fig/ft2dofpulse.vpl

# A simulated air wave and the amplitude of its 2D Fourier transform
sfspike n1=64 d1=1 o1=32 nsp=4 k1=1,2,3,4 mag=1,3,3,1 \
	label1='time' unit1= |
sfspray n=32 d=1 o=0 |
sfput label2=space |
sflmostretch delay=0 v0=-1 |
tee |
{{
	sfwindow f2=1 | sfreverse which=2
	cat
}} |
sfcat axis=2 "&lt;|" |
tee |
{{
	sfgrey pclip=100 wanttitle=n

	sffft1 |
	sffft3 sign=1 |
	tee |
	{{
		sfreal
		sfimag
	}} |
	dgsh-wrap -e sfmath nostdin=y re="&lt;|" im="&lt;|" \
	  output="sqrt(re*re+im*im)" |
	tee |
	{{
		sfwindow f1=1 | sfreverse which=3
		cat
	}} |
	sfcat axis=1 "&lt;|" |
	sfgrey pclip=100 wanttitle=n label1="1/time" label2="1/space"
}} |
call_with_stdin side_by_side_iso '&lt;|' yscale=1.25 &gt;Fig/airwave.vpl

wait
</pre>
<section id="NMRPipe"> <!-- {{{2 -->
<h2>Nuclear magnetic resonance processing</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/NMRPipe-pretty.png" alt="Nuclear magnetic resonance processing">
<!-- Extracted description -->
<p>
Nuclear magnetic resonance in-phase/anti-phase channel conversion and
processing in heteronuclear single quantum coherence spectroscopy.
Demonstrate processing of NMR data using the NMRPipe family of programs.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# The conversion is configured for the following file:
# http://www.bmrb.wisc.edu/ftp/pub/bmrb/timedomain/bmr6443/timedomain_data/c13-hsqc/june11-se-6426-CA.fid/fid
var2pipe -in $1            \
 -xN            1280            -yN     256    \
 -xT            640             -yT     128    \
 -xMODE         Complex -yMODE  Complex      \
 -xSW           8000    -ySW    6000      \
 -xOBS          599.4489584     -yOBS   60.7485301      \
 -xCAR          4.73    -yCAR   118.000      \
 -xLAB          1H      -yLAB   15N      \
 -ndim          2       -aq2D   States      \
-verb  |
tee |
{{
  # IP/AP channel conversion
  # See http://tech.groups.yahoo.com/group/nmrpipe/message/389
  nmrPipe |
  nmrPipe -fn SOL |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 2 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 177 -p1 0.0 -di |
  nmrPipe -fn EXT -left -sw -verb |
  nmrPipe -fn TP |
  nmrPipe -fn COADD -cList 1 0 -time |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 1 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 0 -p1 0 -di |
  nmrPipe -fn TP |
  nmrPipe -fn POLY -auto -verb &gt;A

  nmrPipe |
  nmrPipe -fn SOL |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 2 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 177 -p1 0.0 -di |
  nmrPipe -fn EXT -left -sw -verb |
  nmrPipe -fn TP |
  nmrPipe -fn COADD -cList 0 1 -time |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 1 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 -90 -p1 0 -di |
  nmrPipe -fn TP |
  nmrPipe -fn POLY -auto -verb &gt;B

}}

# We use temporary files rather than streams, because
# addNMR mmaps its input files. The diagram displayed in the
# example shows the notional data flow.
if [ -z "${DGSH_DRAW_EXIT}" ]
then
	addNMR -in1 A -in2 B -out A+B.dgsh.ft2 -c1 1.0 -c2 1.25 -add
	addNMR -in1 A -in2 B -out A-B.dgsh.ft2 -c1 1.0 -c2 1.25 -sub
fi
</pre>
<section id="fft-block8"> <!-- {{{2 -->
<h2>FFT calculation</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/fft-block8-pretty.png" alt="FFT calculation">
<!-- Extracted description -->
<p>
Calculate the iterative FFT for n = 8 in parallel.
Demonstrates combined use of permute and multipipe blocks.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

dgsh-fft-input $1 |
perm 1,5,3,7,2,6,4,8 |
{{
	{{
		dgsh-w 1 0
		dgsh-w 1 0
	}} |
	perm 1,3,2,4 |
	{{
		dgsh-w 2 0
		dgsh-w 2 1
	}}

	{{
		dgsh-w 1 0
		dgsh-w 1 0
	}} |
	perm 1,3,2,4 |
	{{
		dgsh-w 2 0
		dgsh-w 2 1
	}}
}} |
perm 1,5,3,7,2,6,4,8 |
{{
	dgsh-w 3 0

	dgsh-w 3 1

	dgsh-w 3 2

	dgsh-w 3 3
}} |
perm 1,5,2,6,3,7,4,8 |
cat
</pre>
<section id="reorder-columns"> <!-- {{{2 -->
<h2>Reorder columns</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/reorder-columns-pretty.png" alt="Reorder columns">
<!-- Extracted description -->
<p>
Reorder columns in a CSV document.
Demonstrates the combined use of tee, cut, and paste.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

tee |
{{
	cut -d , -f 5-6 -

	cut -d , -f 2-4 -
}} |
paste -d ,
</pre>
<section id="dir"> <!-- {{{2 -->
<h2>Directory listing</h2>
</section>
<img src="https://www2.dmst.aueb.gr/dds/sw/dgsh/dir-pretty.png" alt="Directory listing">
<!-- Extracted description -->
<p>
Windows-like DIR command for the current directory.
Nothing that couldn't be done with <code>ls -l | awk</code>.
Demonstrates use of wrapped commands with no input (df, echo).
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

ls -n |
tee |
{{
	# Reorder fields in DIR-like way
	awk '!/^total/ {print $6, $7, $8, $1, sprintf("%8d", $5), $9}'

	# Count number of files
	wc -l | tr -d \\n

	# Print label for number of files
	echo -n ' File(s) '

	# Tally number of bytes
	awk '{s += $5} END {printf("%d bytes\n", s)}'

	# Count number of directories
	grep -c '^d' | tr -d \\n

	# Print label for number of dirs and calculate free bytes
	df -h . | awk '!/Use%/{print " Dir(s) " $4 " bytes free"}'
}} |
cat
</pre>

</section> <!-- Examples -->

</section></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Imgur pulls out of UK as data watchdog threatens fine (219 pts)]]></title>
            <link>https://www.express.co.uk/news/uk/2115228/image-site-imgur-pulls-out</link>
            <guid>45424888</guid>
            <pubDate>Tue, 30 Sep 2025 13:01:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.express.co.uk/news/uk/2115228/image-site-imgur-pulls-out">https://www.express.co.uk/news/uk/2115228/image-site-imgur-pulls-out</a>, See on <a href="https://news.ycombinator.com/item?id=45424888">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="singleArticle" data-story="2115228" role="main"> <article> <header><h2>A popular image hosting website has stopped its services in the UK after regulators threatened a fine.</h2><div><p><time datetime="2025-09-30T11:35:00Z"> <span>12:35, Tue, Sep 30, 2025</span> </time> <time datetime="2025-09-30T11:38:22Z"> Updated: <span>12:38, Tue, Sep 30, 2025</span> </time></p></div> </header><div data-type="article-body"><div><p><picture><source type="image/avif" srcset="https://cdn.images.express.co.uk/img/dynamic/1/1200x712/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.avif?r=1759232302595" media="screen and (min-width:10000px)"><source type="image/webp" srcset="https://cdn.images.express.co.uk/img/dynamic/1/1200x712/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.webp?r=1759232302595" media="screen and (min-width:10000px)"><source type="image/jpeg" srcset="https://cdn.images.express.co.uk/img/dynamic/1/1200x712/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595" media="screen and (min-width:10000px)"><source type="image/avif" srcset="https://cdn.images.express.co.uk/img/dynamic/1/674x400/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.avif?r=1759232302595" media="screen and (min-width:100000px)"><source type="image/webp" srcset="https://cdn.images.express.co.uk/img/dynamic/1/674x400/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.webp?r=1759232302595" media="screen and (min-width:100000px)"><source type="image/jpeg" srcset="https://cdn.images.express.co.uk/img/dynamic/1/674x400/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595" media="screen and (min-width:100000px)"><source type="image/avif" srcset="https://cdn.images.express.co.uk/img/dynamic/1/940x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.avif?r=1759232302595" media="screen and (min-width:1200px)"><source type="image/webp" srcset="https://cdn.images.express.co.uk/img/dynamic/1/940x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.webp?r=1759232302595" media="screen and (min-width:1200px)"><source type="image/jpeg" srcset="https://cdn.images.express.co.uk/img/dynamic/1/940x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595" media="screen and (min-width:1200px)"><source type="image/avif" srcset="https://cdn.images.express.co.uk/img/dynamic/1/590x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.avif?r=1759232302595" media="screen"><source type="image/webp" srcset="https://cdn.images.express.co.uk/img/dynamic/1/590x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.webp?r=1759232302595" media="screen"><img src="https://cdn.images.express.co.uk/img/dynamic/1/590x/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595" data-img="https://cdn.images.express.co.uk/img/dynamic/1/1200x712/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595" alt="Web Summit 2018 - Day 4" title="Web Summit 2018 - Day 4" width="590" height="393"></picture></p><p><span>Imgur founder. <span>(Image: Getty)</span><span data-img="https://cdn.images.express.co.uk/img/dynamic/1/1200x712/secondary/imgur-founder-alan-schaaf-speaks-during-the-web-summit-2018-in-lisbon-portugal-on-november-8-6459211.jpg?r=1759232302595"></span></span></p></div><div><p>An image hosting platform with more than 130 million users has stopped being available in the UK <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/news/uk/339446/More-firms-breaching-data-rules">after regulators signalled their intention to impose penalties over concerns around children’s data.</a></p><p>The Information Commissioner’s Office (ICO) said that it has reached provisional findings in an investigation in the parent company of image hosting site, Imgur. Its probe was launched earlier this year, as part of the regulator's Children’s Code strategy, which is intended to set the standards for how <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/news/politics/2089661/online-safety-law-watchdog">online services handle the personal information of young people</a>.</p><p>In a statement the ICO said: “We are aware of reports that the social media platform <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/life-style/science-technology/2091749/expressvpn-online-safety-act-2025">Imgur is currently not available in the UK</a>. Imgur's decision to restrict access in the UK is a commercial decision taken by the company.”</p></div><div><p>Tim Capel, the ICO’s Interim Executive Director for Regulatory Supervision, said that the regulator had now issued a notice of intent to fine.</p><p>He said: “We reached our provisional findings on this investigation, and we issued a notice of intent to impose a monetary penalty on MediaLab on 10 September 2025.</p><p>“Our findings are provisional and the ICO will carefully consider any representations from MediaLab before taking a final decision whether to issue a monetary penalty.”</p><p>The ICO also confirmed that companies could not avoid accountability by withdrawing their services in the UK.</p><p>Mr Capel said: “We have been clear that exiting the UK does not allow an organisation to avoid responsibility for any prior infringement of data protection law, and our investigation remains ongoing.</p><p>“This update has been provided to give clarity on our investigation, and we will not be providing any further detail at this time.”</p></div><div><p>He added that protecting young people’s information remains a central focus: “Safeguarding children’s personal information is a key priority for the ICO and our Children’s code strategy outlines our key interventions in this area. Keeping children safe online is the responsibility of the companies offering online services to them and we will continue to hold them to account.”</p><p>Regulators did not disclose the potential size of the penalty for specific breaches it has identified.</p><p>Under UK law, the “notice of intent” process gives the company an opportunity to make representations before any final decision is made.</p><p>Imgur, founded in 2009 and acquired by Los Angeles-based MediaLab AI Inc in 2021, is an image hosting and sharing site popular for memes, viral content and online communities. It’s services appeared to become unavailable in the UK last night.</p><p>Imgur was approached for comment.</p></div><div data-lazy-function="readnext"> <header><h3>Read next</h3> </header><ul><li> <var></var> <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/" data-tmdatatrack="read-next" data-tmdatatrack-articleid="" data-tmdatatrack-platform="nationals" data-tmdatatrack-source="" data-tmdatatrack-index="" data-tmdatatrack-visible="">&nbsp;</a></li><li> <var></var> <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/" data-tmdatatrack="read-next" data-tmdatatrack-articleid="" data-tmdatatrack-platform="nationals" data-tmdatatrack-source="" data-tmdatatrack-index="" data-tmdatatrack-visible="">&nbsp;</a></li><li> <var></var> <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/" data-tmdatatrack="read-next" data-tmdatatrack-articleid="" data-tmdatatrack-platform="nationals" data-tmdatatrack-source="" data-tmdatatrack-index="" data-tmdatatrack-visible="">&nbsp;</a></li><li> <var></var> <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/" data-tmdatatrack="read-next" data-tmdatatrack-articleid="" data-tmdatatrack-platform="nationals" data-tmdatatrack-source="" data-tmdatatrack-index="" data-tmdatatrack-visible="">&nbsp;</a></li><li> <var></var> <a data-link-tracking="InArticle|Link" href="https://www.express.co.uk/" data-tmdatatrack="read-next" data-tmdatatrack-articleid="" data-tmdatatrack-platform="nationals" data-tmdatatrack-source="" data-tmdatatrack-index="" data-tmdatatrack-visible="">&nbsp;</a></li></ul></div><div><p>  <span></span> <span>Invalid email</span></p><p>We use your sign-up to provide content in ways you've consented to and to improve our understanding of you. This may include adverts from us and 3rd parties based on our understanding. You can unsubscribe at any time. Read our <a href="https://www.express.co.uk/privacy-notice">Privacy Policy</a></p></div></div> </article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Founder sentenced to seven years in prison for fraudulent sale to JPMorgan (128 pts)]]></title>
            <link>https://www.cnn.com/2025/09/30/business/charlie-javice-frank-sentenced-jpmorgan-intl</link>
            <guid>45424827</guid>
            <pubDate>Tue, 30 Sep 2025 12:53:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnn.com/2025/09/30/business/charlie-javice-frank-sentenced-jpmorgan-intl">https://www.cnn.com/2025/09/30/business/charlie-javice-frank-sentenced-jpmorgan-intl</a>, See on <a href="https://news.ycombinator.com/item?id=45424827">Hacker News</a></p>
Couldn't get https://www.cnn.com/2025/09/30/business/charlie-javice-frank-sentenced-jpmorgan-intl: Error: Request failed with status code 451]]></description>
        </item>
        <item>
            <title><![CDATA[How has mathematics gotten so abstract? (107 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/how-has-mathematics-gotten-so-abstract</link>
            <guid>45424648</guid>
            <pubDate>Tue, 30 Sep 2025 12:33:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/how-has-mathematics-gotten-so-abstract">https://lcamtuf.substack.com/p/how-has-mathematics-gotten-so-abstract</a>, See on <a href="https://news.ycombinator.com/item?id=45424648">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div dir="auto"><p>Today, mathematics is regarded as a purely abstract science. On forums such as Stack Exchange, trained mathematicians may sneer at newcomers who ask for intuitive explanations of mathematical constructs. Indeed, persistently trying to relate the foundations of math to reality has become the calling card of online cranks.</p><p>I find this ironic: for millennia, mathematics was essentially a natural science. We had no philosophical explanation why 2 + 2 should be equal to 4; we just looked at what was happening in the real world and tried to capture the rules. The abstractions were important, of course, but they needed to be rooted in objectivity. The early development of algebra and geometry followed suit. It was never enough for the axioms to be internally consistent; the angles of your hypothetical triangle needed to match the physical world.</p><p>That said, even in antiquity, the reliance on intuition sometimes looked untenable. A particular cause for concern were the outcomes of thought experiments that involved repeating a task without end. The most famous example is Zeno’s paradox of motion. If you slept through that class, imagine the scenario of Achilles racing a tortoise:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!MzH8!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!MzH8!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 424w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 848w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 1272w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!MzH8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png" width="1456" height="353" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:353,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:106249,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/174503112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!MzH8!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 424w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 848w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 1272w, https://substackcdn.com/image/fetch/$s_!MzH8!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F71d2d033-0511-48aa-bb71-b6732d01a9df_1638x397.png 1456w" sizes="100vw" fetchpriority="high"></picture></div></a><figcaption><em><strong>Catch me if you can.</strong></em></figcaption></figure></div><p>We can reason that after a while, Achilles will catch up to the turtle’s original position (red dot); however, by the time he gets there, the animal will have moved some distance forward (yellow dot):</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!XS3G!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!XS3G!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 424w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 848w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 1272w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!XS3G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png" width="1456" height="478" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/d6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:478,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:144247,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/174503112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!XS3G!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 424w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 848w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 1272w, https://substackcdn.com/image/fetch/$s_!XS3G!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd6567e21-8c90-4e32-a4fb-0f548afbf46b_1638x538.png 1456w" sizes="100vw"></picture></div></a><figcaption><em>And they would have gotten away with it too…</em></figcaption></figure></div><p>Next, consider the time needed for Achilles to reach the yellow dot; once again, by the time he gets there, the turtle will have moved forward a tiny bit. This process can be continued indefinitely; the gap keeps getting smaller but never goes to zero, so we must conclude that Achilles can’t possibly win the race.</p><p>Amusingly, the problems caused by infinity lingered on the periphery of mathematics for centuries, fully surfacing only after we attempted to fix them with calculus. Calculus gave us a rigorous solution to the ancient puzzle: an infinite sum of time slices can be a finite number, so Achilles does catch up to the tortoise. Yet, to arrive at that result, the new field relied on the purported existence of infinitely small numbers (infinitesimals). The founders struggled to explain how to construct such entities, where to find them on the real number line (you can’t), and whether they’re safe to mix with real number algebra in the first place.</p><p>Over time, this prompted a number of mathematicians to try and build a more general model of mathematics, starting from the ground up — that is, from the principles of formal logic. In particular, one prominent faction of the movement sought to define numbers and arithmetic operations in a way that was fully independent of the physical realm.</p><p><span>In the late 19th century, Giuseppe Peano successfully answered this call. His system posits the existence of a single initial number — conventionally, zero — and then defines a successor function </span><em>S</em><span>.</span></p><p>This allows us to define numbers — really, just a collection of labels — solely in terms of a succession relationship:</p><div data-component-name="Latex"><p><span>\(\begin{alignat}{1}
1 &amp;= S(0) \\
2 &amp;= S(1) &amp;&amp;= S(S(0)) \\
3 &amp;= S(2) &amp;&amp;= S(S(S(0))) \\
4 &amp;= S(3) &amp;&amp;= S(S(S(S(0))))
\end{alignat}\)</span></p></div><p><span>While this might seem mundane, the scheme reduces many other problems to the process of induction and recursion. For example, to solve 2 + 2, we don’t need any </span><em>a priori </em><span>knowledge of what “2” or “+” means. Instead, we define addition using the following two rules:</span></p><div data-component-name="Latex"><p><span>\(\begin{alignat}{1}
a &amp;+ 0 &amp;&amp;= a &amp;&amp;\qquad (\textrm{rule 1}) \\
a &amp;+ S(b) &amp;&amp;= S(a+b) &amp;&amp;\qquad ( \textrm{rule 2}) 
\end{alignat}
\)</span></p></div><p>This notation may appear abstract, so to tease it out, let’s try to actually calculate 2 + 2. Because the second operand is non-zero, we can’t apply the first rule just yet. That said, from the construction of Peano numbers, we know that 2 = S(1). In light of this, we can rewrite 2 + 2 in a way that lets us use of the second rule:</p><div data-component-name="Latex"><p><span>\(\begin{array}{r l}
2 + 2 = 2 + S(1) &amp; \textrm{(by the construction of number 2)} \\
2 + S(1) = S(2 + 1) &amp; \textrm{(per rule 2)}
\end{array}\)</span></p></div><p>At this point, we’ve shown that 2 + 2 is the same as S(2 + 1). To solve the original equation, we still need to find the value of 2 + 1; this can be done by applying the same substitution technique once more:</p><div data-component-name="Latex"><p><span>\(\begin{array}{rl}
2 +1 = 2 + S(0) &amp; \textrm{(by construction)} \\
2 + S(0) = S(2+0) &amp; \textrm{(per rule 2)}
\end{array}\)</span></p></div><p><span>In effect, we have restated 2 + 2 as S(2 + 1), and then 2 + 1 as S(2 + 0). In that last instance, the second operand is zero, so we can finally apply rule 1. The rule says that </span><em>a + 0 = a</em><span>, so:</span></p><div data-component-name="Latex"><p><span>\(2 + 1 = S(2 + 0) = S(2)\)</span></p></div><p>Further, from the construction of Peano numbers, we know that our chosen label for S(2) is 3; therefore, 2 + 1 = 3.</p><p>With this equality established, we go back to the initial step where we expressed 2 + 2 as S(2 + 1) and get the final answer:</p><div data-component-name="Latex"><p><span>\(2 + 2 = S(2+1) = S(3) = 4\)</span></p></div><p><span>If you work with software, you might appreciate the following C code that implements roughly the same logic (</span><a href="https://godbolt.org/z/zWh5j1KEr" rel="">demo</a><span>):</span></p><blockquote><pre><code>#include &lt;stdio.h&gt;

struct number { char* label; struct number* next; }
  five  = { "5", NULL },   four = { "4", &amp;five }, three = { "3", &amp;four },
  two   = { "2", &amp;three }, one  = { "1", &amp;two },  zero  = { "0", &amp;one };

struct number* succ(struct number* num) { return num-&gt;next; }

struct number* pred(struct number* num) {
  struct number* ret = &amp;zero;
  while (succ(ret) != num) ret = succ(ret);
  return ret;
}

struct number* add_numbers(struct number* num_a, struct number* num_b) {
  if (num_b == &amp;zero) return num_a;
  return succ(add_numbers(num_a, pred(num_b)));
}

int main() {
  printf(”2 + 3 = %s\n”, add_numbers(&amp;two, &amp;three)-&gt;label);
}</code></pre></blockquote><p>In this program, instead of relying on built-in integers, we start with a unidirectional linked list of strings: “0” → “1” → “2” → “3” → “4” → “5”. This data structure encodes the successor relationship between the labels without giving them any further meaning.</p><p><span>Next, we define a trivial helper called </span><em>succ(x), </em><span>which returns the successor of </span><em>x,</em><span> along with a slightly more complicated function called </span><em>pred(x)</em><span>, which finds the element to which </span><em>x </em><span>is the successor. Finally, </span><em>add_numbers(a, b)</em><span> is a straightforward implementation of the recursive rules for Peano addition, as outlined earlier on.</span></p><p>Again, the merit of this approach is that it lets us model arithmetic without any external assumptions about the nature of numbers, the significance of the addition operator, and so forth. We used familiar labels (0, 1, 2, 3, 4, …), but we could’ve used some other ordered collection of abstract symbols (🥔, 🎵, 🐸, 🌀, 🐱, …). If so, we’d have gotten an equivalent model of math in which 🐸 + 🐸= 🐱.</p><p>Of course, Peano arithmetic is too cumbersome for everyday tasks; instead, it serves as a minimalist model for theoretical work. It is used similarly to how computer scientists use Turing machines; no one wants to browse the internet on a Turing-style computer, but if you proved that P = NP for a Turing machine, this would have implications for more practical computing architectures too.</p><p><span>Giuseppe Peano’s axiomatic approach was revolutionary and led to breakthroughs such as the </span><a href="https://lcamtuf.substack.com/p/monkeys-typewriters-and-busy-beavers" rel="">Gödel incompleteness theorem</a><span>; however, it still didn’t offer a particularly good model of infinite quantities. For that, mathematicians needed to turn to an even more exotic framework: set theory.</span></p><p>In set theory, numbers are conventionally defined as labels for specific, ordered sets. To get started with the construction process, we only need an empty set ({}), which we label as zero:</p><p>To define the successor number, we add an element to the set. To avoid inventing arbitrary new elements, we can simply embed the previously-conjured number zero in the successor set:</p><p>If this seems confusing, you can think of set as boxes. We started with an empty box with zero items inside; we then sealed the box and placed it in a larger container, so the larger box now contains a single element. For this tally, the contents of that smaller, sealed box are of no consequence.</p><p><span>After that, we can’t define the next successor as {0, 0}; this is because in set theory, every set element must be unique. That said, as discussed earlier, a “naked” element </span><em>n </em><span>is distinct from a box containing that element (i.e., a new set </span><em>{n}</em><span>), so we can do this:</span></p><p>Note that in our model, 1 = {0}, so the construction method shown above is equivalent to saying that 2 = {0, 1}.</p><p>To get to the third successor, we need to put one more element in the set. At this point, we can’t reuse 0 or 1, but we can embed the recently-created set representing 2:</p><div data-component-name="Latex"><p><span>\(3 = \{ 0, 1, 2 \} = \{ 0, \{ 0 \}, \{ 0, \{ 0 \} \} \}\)</span></p></div><p>This process can continue for as long as we’d like, e.g.:</p><div data-component-name="Latex"><p><span>\(4 = \{ 0, 1, 2, 3 \} = \{ 0, \{0\}, \{0, \{0\}\}, \{0, \{0\}, \{0, \{0\}\}\} \}
\)</span></p></div><p>In set theory, the labels we’re creating are called ordinals. Note that every ordinal is an ordered set of all the preceding ordinals, and that the set never contains itself.</p><p><span>If you’re seeing parallels to the iterative construction of Peano numbers, this is not an accident; the two approaches are conceptually similar, it’s just that in this instance, the underlying mathematical structure of each number is spelled out more explicitly. The general algorithm is that we build number </span><em>n + 1</em><span> by joining the preceding set </span><em>n</em><span> and a copy of </span><em>n </em><span>embedded inside a new set. The set-joining operation is known as union (∪), so we can formalize a Peano-like successor function for ordinals as:</span></p><p><span>Almost all mathematicians accept the existence of infinite sets; a common example would be the set of all natural numbers, ℕ. Every natural number itself is finite, but there is no upper limit on how large these numbers can get; whenever you pick some </span><em>n</em><span>, I can always best you by shouting “</span><em>n </em><span>+ 1”.</span></p><p>The ordered set of all natural numbers looks like the product of our method for constructing cardinals — that is, if we allowed the process to continue without end:</p><div data-component-name="Latex"><p><span>\(\mathbb{N} = \{0, 1, 2, 3, 4, ...\}\)</span></p></div><p>It’s tempting to ask if the set can function as an infinite ordinal — i.e., an infinite number — and if yes, what numerical properties does it have?</p><p><span>Well, we can say right off the bat that the ordinal we’re talking about wouldn’t be a member of ℕ: every element of ℕ is finite. We can also conclude that the ordinal must not be a successor to any natural number: if </span><em>n</em><span> is a member of ℕ, then so is </span><em>n + 1</em><span>, so the presence of a successor relationship would lead to the same contradiction.</span></p><p>Can such an unmoored, infinite ordinal exist? Well, that’s up to us to decide: conjuring it doesn’t lead to any outright paradoxes and opens up some weird but occasionally useful math. </p><p><span>We can name this ordinal </span><em>ω</em><span>; again, its set-theoretic representation is just:</span></p><div data-component-name="Latex"><p><span>\(\omega = \{0, 1, 2, 3, 4, ...\}  = \mathbb{N}\)</span></p></div><p>Of course, inventing a symbol isn’t much of an accomplishment; the big question is whether, under the axioms of set theory, we can derive any useful arithmetic for this mysterious entity.</p><p>In school, you might have been exposed to notation along the lines of:</p><p><span>In an </span><a href="https://lcamtuf.substack.com/p/09999-1" rel="">earlier article</a><span>, I quipped that this notation is just a glorified calculator error message — all it tells us is that the result is too large for reals:</span></p><div data-component-name="Latex"><p><span>\(\texttt{&lt;Error&gt;} + 1 = \texttt{&lt;Error&gt;}\)</span></p></div><p><span>That said, if you’re accustomed to this way of thinking about infinity, it’s tempting to assume that the rule should apply to actual infinite numbers — i.e. that </span><em>ω </em><span>should be the same as</span><em> ω</em><span> + 1</span><em>. </em><span>Let’s test that hypothesis.</span></p><p><span>In line with the Peano rules, we can express </span><em>ω</em><span> + 1 as the application of the ordinal successor operation to the first operand. As a reminder, the successor operation takes the original infinite set of natural numbers (</span><em>ω = </em><span>ℕ) and then embeds that set as a new element to construct the next ordinal. We get:</span></p><div data-component-name="Latex"><p><span>\(\omega + 1 = S(\omega) = \omega \cup \{\omega\} = \{ 0, 1, 2, 3, 4, ..., \omega \}\)</span></p></div><p><span>We have previously established that </span><em>ω </em><span>itself cannot be a member of </span><em> </em><span>ℕ, because that would make it a natural number, and therefore, a finite quantity. Yet, the newly-constructed set corresponding to </span><em>ω</em><span> + 1 evidently </span><em>does</em><span> contain that element; this tells us that the set is categorically different from ℕ. We must conclude that </span><em>ω </em><span>≠ </span><em>ω</em><span> + 1</span><em>. </em><span>More specifically, because </span><em>ω</em><span> + 1 contains </span><em>ω</em><span>, it sits higher in the rank of ordinals, and we can assert that </span><em>ω &lt; ω</em><span> + 1.</span></p><p><span>But lest we get too cozy with this new reality: addition involving infinite ordinals is not necessarily commutative! To illustrate, let’s construct the set representing 1 + </span><em>ω</em><span>. As before, we rewrite addition as a (repeated) application of the successor function to the first operand:</span></p><div data-component-name="Latex"><p><span>\(1 + \omega =  \underbrace{...S(S(S(1)))}_{\textrm{repeats } \omega \textrm{ times}}\)</span></p></div><p>Recall that we defined the ordinal 1 as a single-element set containing zero: {0}. Starting from that set and applying the successor function, we end up constructing ordinal 2 — another name for {0, 1}. The next application of the nets us 3, aka {0, 1, 2}:</p><div data-component-name="Latex"><p><span>\(\begin{align}
1 &amp;= \{0\} \\
S(1) &amp;= \{0, 1\} \\
S(S(1)) &amp;= \{0, 1, 2\} \\
...
\end{align}\)</span></p></div><p><span>If we repeat this operation </span><em>ω </em><span>times, we obtain an infinite set { 0, 1, 2, 3, 4, … }. Note that the element </span><em>ω </em><span>itself can never make it into the set: it’s not a successor of any natural number, so it can’t be reached by repeatedly incrementing one.</span></p><p><span>Upon closer inspection, the resulting 1 + </span><em>ω </em><span>set is indistinguishable from the set of natural numbers, ℕ. We know that </span><em>ω </em><span>is also just another name for</span><em> </em><span>ℕ, so we can write the following equality: 1 + </span><em>ω = ω. </em><span>Few paragraphs earlier, we showed that </span><em>ω &lt; ω + 1. </em><span>This leads to a surprising result: 1 + </span><em>ω &lt; ω + 1.</em></p><p><span>One might ask if non-commutative addition is a violation of one of the axioms of standard arithmetic. It isn’t, on a technicality: the rules apply only to finite numbers, such as the members of ℕ. Luckily for us, </span><em>ω </em><span>isn’t invited to that club.</span></p><p><span>Before we wrap up, let’s have a look at another interesting corner case: </span><em>ω + ω </em><span>(aka </span><em>ω </em><span>· 2). To calculate this ordinal, we start with </span><em>ω = </em><span>{ 0, 1, 2, 3, 4, … } and then iteratively extend the set through the successor operation. We first append </span><em>ω, </em><span>then </span><em>ω </em><span>+ 1, then </span><em>ω + 2, </em><span>and so on:</span></p><div data-component-name="Latex"><p><span>\(\omega \cdot 2 = \{ 0, 1, 2, 3, 4, ..., \omega, \omega + 1, \omega + 2, ... \}\)</span></p></div><p><span>The tail end of this ordered set is an infinite sequence of successors to </span><em>ω; </em><span>as in all the earlier cases, </span><em>ω </em><span>· 2 can’t be a member of itself, so </span><em>ω </em><span>· 2 must not be reachable by incrementing</span><em> ω. </em><span>This is analogous to how </span><em>ω </em><span>couldn’t be reached by incrementing any finite number</span><em>; </em><span>the discontinuity repeats for each multiple of </span><em>ω.</em></p><p>It’s hard not to notice that our set-theoretic numbers seem to be describe the size (element count) of the underlying set:</p><div data-component-name="Latex"><p><span>\(5 = \{0, 1, 2, 3, 4\}\)</span></p></div><p>For finite sets, this notion of size aligns with common sense. But when we look at the non-commutative addition and the discontinuities of infinite ordinals, one might start to wonder if trying to “count” elements is still a meaningful way to characterize sets in that realm.</p><p>There are several other ways to reason about this problem without resorting to counting. The simplest rule we can come up with is that one set is a strict subset of another, the first set could be described as smaller than the second one.</p><p>Another approach is to consider two sets to be of equivalent “magnitude” if you can map their elements one-to-one. It doesn’t matter which element gets mapped to which, as long as there are no orphaned members on either side:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!O98b!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!O98b!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 424w, https://substackcdn.com/image/fetch/$s_!O98b!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 848w, https://substackcdn.com/image/fetch/$s_!O98b!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 1272w, https://substackcdn.com/image/fetch/$s_!O98b!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!O98b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png" width="1456" height="827" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:827,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:178037,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/174503112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!O98b!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 424w, https://substackcdn.com/image/fetch/$s_!O98b!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 848w, https://substackcdn.com/image/fetch/$s_!O98b!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 1272w, https://substackcdn.com/image/fetch/$s_!O98b!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e61248-a7e5-4e13-bcc5-fd3da6abfc12_1740x988.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>One equivalent pair (top) and two non-equivalent ones (bottom).</em></figcaption></figure></div><p><span>This particular measure of equivalency on the basis of a one-to-one mapping is called </span><em>cardinality</em><span>.</span></p><p>The concepts are dead simple for finite sets, but consider a set of natural numbers next to a set of every even number (E). Obviously, E is strict subset of natural numbers, so by our first rule, we could say that E is smaller than ℕ. Yet, if we’re talking about a one-to-one mapping for a pair of infinite sets, the following approach is perfectly fine:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!2Ood!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!2Ood!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 424w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 848w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 1272w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/$s_!2Ood!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png" width="1456" height="874" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/f31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:874,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:189004,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:&quot;https://lcamtuf.substack.com/i/174503112?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png&quot;,&quot;isProcessing&quot;:false,&quot;align&quot;:null,&quot;offset&quot;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!2Ood!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 424w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 848w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 1272w, https://substackcdn.com/image/fetch/$s_!2Ood!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff31ae3ac-6c8b-4137-86c8-18ccfd09d334_2088x1254.png 1456w" sizes="100vw" loading="lazy"></picture></div></a><figcaption><em>This is legal in 47 states.</em></figcaption></figure></div><p><span>After all, the sets are infinite, so we never run out of elements. We say that the set of natural numbers has a specific cardinality — aleph-null, ℵ</span><sub>0</sub><span> — and that the cardinality of the set of even numbers is the same.</span></p><p>Do any other infinite cardinalities exist? The answer, as demonstrated by Georg Cantor, appears to be yes! Imagine some arbitrary one-to-one mapping from every single natural number to reals (ℝ), e.g.:</p><div data-component-name="Latex"><p><span>\(\begin{array}{c}
1 &amp; \rightarrow &amp; 0.\underline{\textbf{1}}23456... \\
2 &amp; \rightarrow &amp; 0.6\underline{\textbf{5}}4321... \\
3 &amp; \rightarrow &amp; 0.99\underline{\textbf{9}}999... \\
4 &amp; \rightarrow &amp; 0.454\underline{\textbf{5}}45... \\
5 &amp; \rightarrow &amp; 0.1111\underline{\textbf{1}}1... \\
6 &amp; \rightarrow &amp; 0.03133\underline{\textbf{7}}... \\
&amp; ... &amp;
\end{array}\)</span></p></div><p>There’s nothing special about these values; the only point is that we have a distinct real number assigned to every member of ℕ. There are obviously at least as many reals as there are natural numbers, so this is something we should be able to do.</p><p><span>The remaining question is whether there are any orphaned reals left once all the natural numbers are used up. To figure this out, let’s try to construct a new real number, </span><em>d</em><span>. We start by looking at the first row above:</span></p><div data-component-name="Latex"><p><span>\(1 \rightarrow 0.\underline{\textbf{1}}23456...
\)</span></p></div><p><span>We take the underlined (first) decimal digit of the real and then choose </span><em>any value other than this one</em><span> for the corresponding digit in </span><em>d</em><span>. In this case, the offending digit is 1, so we can pick 0, 2, 3, 4, 5, 6, 7, 8, or 9. Let’s go with 9:</span></p><div data-component-name="Latex"><p><span>\(d = 0.\textbf{9} \textrm{ (...to be continued)}\)</span></p></div><p><span>We then proceed to the second row, this time looking at at the second decimal digit — essentially, following the diagonal pattern underlined in the assignment diagram. Once again, for the second decimal digit of </span><em>d</em><span>, we choose any value other than the actual digit marked in row 2; since the highlighted value is 5, we can pick 2 instead:</span></p><div data-component-name="Latex"><p><span>\(d = 0.9\textbf{2} \textrm{ (...more to come)}\)</span></p></div><p>In row three, we can replace 9 with 0; in row four, let’s substitute 5 with 4. For row five, we trade 1 for 3; in row six, we use 5 instead of 7. We keep following the diagonal pattern to infinity:</p><p><span>What’s special about this result? Well, by construction, </span><em>d </em><span>differs by at least one digit from every single real number in our mapping! For example, it can never match row 1 because the first decimal digit is 9 instead of 1; it also doesn’t match row 2 because the second decimal digit is 2 instead of 5.</span></p><p><span>That is to say, </span><em>d</em><span> can’t possibly appear anywhere on the list that assigned a real to every integer. Thus, we have found an orphaned member of ℝ; the cardinality of natural numbers (ℵ</span><sub>0</sub><span>) is evidently less than the cardinality of reals (also known as the </span><em>cardinality of the continuum</em><span>).</span></p><p>Are there any cardinalities in between? Mathematicians don’t think so, but this hypothesis is provably undecidable within the traditional axioms of set theory.</p><p>Maybe? If infinity lurks in some dark corners of the physical universe, we probably have no way of ascertaining its numerical properties. In the absence of this, we have a toolkit for creating weird worlds that restate the rules of formal logic in increasingly mind-bending ways — and sometimes help prove a theorem or two.</p><p>Because the behavior of infinite sets is bizarre, there is a school of mathematics that rejects their existence. Heck, there is a small number of mathematicians who reject infinity altogether. The difficulty is that such decisions require discarding vast amounts of useful math — or at the very least, tossing out an explanation of why we’re doing that math in a particular way.</p><p>On some level, this might not be a big deal: calculus is usually still taught without providing a rigorous justification for limits or infinitesimals. On the flip side, as almost any calculus student will attest, it’s an intellectually unsatisfying approach.</p><p>Just as important, without all these wonderfully confusing notions of infinity, how do you keep the riff-raff out of math?</p><p><em><span>👉 Reader exclusive: for an essential Peano arithmetic calculator, </span><a href="https://lcamtuf.coredump.cx/peano/" rel="">click here</a><span>. </span></em></p><p><em><span>If you’re interested in beavers in addition to turtles, you’re probably going to enjoy </span><a href="https://lcamtuf.substack.com/p/monkeys-typewriters-and-busy-beavers" rel="">this article</a><span>. And if you like the content, please subscribe; there’s no better way to stay in touch with the writers you like.</span></em></p></div></article></div><div id="discussion"><h4>Discussion about this post</h4></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Comprehension debt: A ticking time bomb of LLM-generated code (465 pts)]]></title>
            <link>https://codemanship.wordpress.com/2025/09/30/comprehension-debt-the-ticking-time-bomb-of-llm-generated-code/</link>
            <guid>45423917</guid>
            <pubDate>Tue, 30 Sep 2025 10:37:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://codemanship.wordpress.com/2025/09/30/comprehension-debt-the-ticking-time-bomb-of-llm-generated-code/">https://codemanship.wordpress.com/2025/09/30/comprehension-debt-the-ticking-time-bomb-of-llm-generated-code/</a>, See on <a href="https://news.ycombinator.com/item?id=45423917">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content">
	<main id="main">
		
<article id="post-2299">
	<!-- .entry-header -->

	
	
	<div>
		
<p>An effect that’s being more and more widely reported is the increase in time it’s taking developers to modify or fix code that was generated by Large Language Models. </p>



<p>If you’ve worked on legacy systems that were written by other people, perhaps decades ago, you’ll recognise this phenomenon. Before we can safely change code, we first need to understand it – understand what it does, and also oftentimes why it does it the way it does. In that sense, this is nothing new.</p>



<p>What <em>is </em>new is the scale of the problem being created as lightning-speed code generators spew reams of unread code into millions of projects.</p>



<p>Teams that care about quality will take the time to review and understand (and more often than not, rework) LLM-generated code before it makes it into the repo. This slows things down, to the extent that any time saved using the LLM coding assistant is often canceled out by the downstream effort.</p>



<p>But <em>some </em>teams have opted for a different approach. They’re the ones checking in code nobody’s read, and that’s only been cursorily tested – if it’s been tested at all. And, evidently, there’s a <em>lot </em>of them.</p>



<p>When teams produce code faster than they can understand it, it creates what I’ve been calling “comprehension debt”. If the software gets used, then the odds are high that <em>at some point</em> that generated code will need to change. The “A.I.” boosters will say “We can just get the tool to do that”. And that might work maybe 70% of the time. </p>



<p>But those of us who’ve experimented a lot with using LLMs for code generation and modification know that there will be times when the tool just won’t be able to do it. </p>



<p>“Doom loops”, when we go round and round in circles trying to get an LLM, or a bunch of different LLMs, to fix a problem that it just doesn’t seem to be able to, are an everyday experience using this technology. Anyone claiming it doesn’t happen to them has either been extremely lucky, or is fibbing.</p>



<p>It’s pretty much guaranteed that there will be many times when we have to edit the code ourselves. The “comprehension debt” is the extra time it’s going to take us to understand it first.</p>



<p>And we’re sitting on a rapidly growing mountain of it.</p>

<div>
	<p><img referrerpolicy="no-referrer" alt="Unknown's avatar" src="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G" srcset="https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=42&amp;d=identicon&amp;r=G 1x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=63&amp;d=identicon&amp;r=G 1.5x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=84&amp;d=identicon&amp;r=G 2x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=126&amp;d=identicon&amp;r=G 3x, https://1.gravatar.com/avatar/aadcfbd208e65a0829f5d259192a5886454439a708e425500c59c535e28ae081?s=168&amp;d=identicon&amp;r=G 4x" height="42" width="42" loading="lazy" decoding="async">	</p><!-- .author-avatar -->

	<!-- .author-description -->
</div><!-- .author-info -->
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article><!-- #post-2299 -->

<!-- .comments-area -->

	<nav aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
	</main><!-- .site-main -->

	
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Disqus Turned My Blog into an Ad Farm – So I Killed It (530 pts)]]></title>
            <link>https://ryansouthgate.com/goodbye-disqus/</link>
            <guid>45423268</guid>
            <pubDate>Tue, 30 Sep 2025 08:36:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ryansouthgate.com/goodbye-disqus/">https://ryansouthgate.com/goodbye-disqus/</a>, See on <a href="https://news.ycombinator.com/item?id=45423268">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><h4 id="intro">Intro<a href="#intro"></a></h4><p>This will be a short and sweet post. As I’m not big on goodbyes.</p><p>Disqus started showing ads for their “free” tier comments system a few years back. At the time, the communication they sent out via email, seemed quite laid-back and had the tone of “don’t worry about it, it’s not a big thing”. Which in part lead me to almost forget it happened.</p><p>At the time, the disqus comments system looked quite smart and sleek. I remember thinking that the ads system will possibly look smart and sleek too. Which alleviated any worries I had at the time.</p><p>WELL…….I’ve just seen the ads, and they look horrific!!!</p><h4 id="apologies">Apologies<a href="#apologies"></a></h4><p>I have a <a href="https://pi-hole.net/" target="_blank">Pihole</a> set up, so ads are blocked on my home network. When I’m out of the house, my phone is connected to a <a href="https://www.wireguard.com/" target="_blank">Wireguard VPN</a> which routes my data through my home internet, therefore - getting all the ad-blocking, Pihole goodness.</p><p>After years with Pi-hole, which now blocks over a million domains, I’ve become incredibly accustomed to a mostly ad-free web. Without realizing it, I’d forgotten what the typical internet experience feels like.</p><p>I used to get a couple of emails from Disqus, letting me know that there’s a new comment on this blog. I haven’t had many of these emails recently, so I decided to disable my adblocker for a few minutes and check out the comments.</p><p>There were none, instead I was greeted by some horribly formatted and obviously scammy ads:</p><figure><a><img data-src="./disqus_ads.webp" data-action="zoom" alt="Horrible Disqus Ads" src="https://ryansouthgate.com/goodbye-disqus/disqus_ads.webp"></a></figure><p>For the people who read this blog, I’m sorry.</p><p>I became “blind” to what the web is really like for most users. I’ve tried to keep this blog minimalist - a clean place to find answers. Those ads not only ruin that experience; they trample privacy too:</p><figure><a><img data-src="./disqus_traffic.webp" data-action="zoom" alt="Screenshot of Firefox Dev Tools. Showing a worrying amount of tracking requests" src="https://ryansouthgate.com/goodbye-disqus/disqus_traffic.webp"></a></figure><p>With this post, I’ve removed Disqus. It was making my blog worse, and frankly, they were profiting off my work and my visitor’s data.
I want this blog to be a resource for devs and technologists, free not just in money, but in freedom from unwanted tracking and invasive ads.</p><h4 id="any-alternatives">Any Alternatives?<a href="#any-alternatives"></a></h4><p>I’m not entirely sure comments are needed here. There are other ways to reach me, for example; <a href="https://github.com/ryansouthgate" target="_blank">GitHub</a> or <a href="https://twitter.com/ryan_southgate" target="_blank">Twitter/X</a>. But having a place for discussion under each post can be valuable.
If you have any recommendations for alternative commenting systems (especially those that respect privacy or are self-hosted), I’d love to hear them! Please reach out if you’ve found something that works well.</p><p>Thanks as always for reading - your trust matters to me.</p><p><em>Sorry again for the mess!</em></p><hr><hr></div></article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Companies Are Lying About AI Layoffs (173 pts)]]></title>
            <link>https://huijzer.xyz/posts/111/companies-are-lying-about-ai-layoffs</link>
            <guid>45423088</guid>
            <pubDate>Tue, 30 Sep 2025 08:07:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://huijzer.xyz/posts/111/companies-are-lying-about-ai-layoffs">https://huijzer.xyz/posts/111/companies-are-lying-about-ai-layoffs</a>, See on <a href="https://news.ycombinator.com/item?id=45423088">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-post-link="/posts/111/companies-are-lying-about-ai-layoffs">

<p>Companies are saying that the economy and AI are causing the large amount of tech layoffs, but <a href="https://www.youtube.com/watch?v=e-Ecodxn5m4">Vanessa Wingårdh looked at the H-1B visa data</a> and noticed that the companies are lying.</p>
<p>She argues that the American employees are being replaced by cheaper H-1B visa workers.
<a href="https://www.wsj.com/politics/policy/h1b-visa-grassley-durbin-letter-tech-firms-8fe931e9">WSJ also reported on this due to some senators speaking up.</a>
As proof she uses the H-1B <a href="https://www.uscis.gov/tools/reports-and-studies/h-1b-employer-data-hub">data from the U.S. Citizenship and Immigration Services</a>.
When filtering by fiscal years 2023, 2024 and 2025, the number of Beneficiaries Approved for some of the big corporations as of 30 June 2025 are shown in the second column below.
I also searched a bit for news articles about layoffs and put those numbers in the third column.</p>
<table>
<thead>
<tr>
<th>Employer</th>
<th>Beneficiaries Approved</th>
<th>Layoffs</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMAZON COM SERVICES LLC</td>
<td>19,327</td>
<td></td>
</tr>
<tr>
<td>INFOSYS LIMITED</td>
<td>17,489</td>
<td><a href="https://www.peoplematters.in/news/performance-management/infosys-layoff-spree-continues-200-employees-fired-for-the-fourth-time-45355">800</a></td>
</tr>
<tr>
<td>GOOGLE LLC</td>
<td>15,010</td>
<td><a href="https://americanbazaaronline.com/2025/08/29/google-cuts-35-workforce-offers-voluntary-exit-programs-466893/">12,000</a></td>
</tr>
<tr>
<td>MICROSOFT CORPORATION</td>
<td>14,707</td>
<td><a href="https://timesofindia.indiatimes.com/technology/tech-news/microsoft-salesforce-oracle-and-intel-among-tech-giants-that-have-cut-jobs-in-2025/articleshow/124085478.cms">9,000</a> / <a href="https://economictimes.indiatimes.com/news/international/global-trends/us-news-tech-layoffs-2025-surge-in-us-amazon-microsoft-meta-slash-thousands-of-jobs-check-full-list-of-companies-affected/articleshow/123735499.cms">15,000</a></td>
</tr>
<tr>
<td>META PLATFORMS INC</td>
<td>13,338</td>
<td><a href="https://economictimes.indiatimes.com/news/international/global-trends/us-news-tech-layoffs-2025-surge-in-us-amazon-microsoft-meta-slash-thousands-of-jobs-check-full-list-of-companies-affected/articleshow/123735499.cms">3,000</a></td>
</tr>
<tr>
<td>AMAZON.COM SERVICES LLC</td>
<td>12,629</td>
<td></td>
</tr>
<tr>
<td>APPLE INC</td>
<td>11,896</td>
<td><a href="https://apnews.com/article/apple-layoffs-tech-iphone-workers-9f10788b1d3552385ee8c7b20209ce17">600</a></td>
</tr>
<tr>
<td>...</td>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>IBM CORPORATION</td>
<td>6,989</td>
<td><a href="https://www.techzine.eu/news/infrastructure/129800/ibm-lays-off-thousands-of-employees-again-in-new-round-of-layoffs/">thousands</a></td>
</tr>
<tr>
<td>AMAZON WEB SERVICES</td>
<td>6,667</td>
<td><a href="https://www.capacitymedia.com/article-amazons-aws-cuts">hundreds</a></td>
</tr>
<tr>
<td>INTEL CORPORATION</td>
<td>6,322</td>
<td><a href="https://timesofindia.indiatimes.com/technology/tech-news/microsoft-salesforce-oracle-and-intel-among-tech-giants-that-have-cut-jobs-in-2025/articleshow/124085478.cms">5,000</a> / <a href="https://www.pcmag.com/news/intel-confirms-mass-layoffs-over-24000-jobs-to-be-cut-this-year">24,500</a></td>
</tr>
<tr>
<td>ORACLE AMERICA INC</td>
<td>6,292</td>
<td><a href="https://www.cio.com/article/4062711/product-changes-likely-as-oracle-faces-an-estimated-10000-more-layoffs-by-december.html">10,000</a></td>
</tr>
<tr>
<td>ACCENTURE LLP</td>
<td>5,862</td>
<td><a href="https://www.deccanherald.com/business/companies/layoffs-accenture-cuts-over-11000-jobs-in-3-months-amid-ai-push-3744531">11,000</a></td>
</tr>
</tbody>
</table>
<p>A commenter on <a href="https://news.ycombinator.com/item?id=45423088#45424038">Hacker News</a> writes: "You can go on Blind, Fishbowl, any work related subreddit, etc. and hear the same story over and over and over - 'My company replaced half my department with H1Bs or simply moved it to an offshore center in India, and then on the next earnings call announced that they had replaced all those jobs with AI'. There's a reason why 'AI = Actually Indians' is a meme everywhere on the internet, and it isn't racism, it's just people observing the reality around them."</p>
<p>I searched a bit to verify these claims and it seems plausible since I could without much effort find a report from Boeing in the <a href="https://www.reddit.com/r/boeing/comments/1f1qqud/engineers_replaced_by_h1b/">2000s</a>, and that indeed the replacing of US workers by H-1Bs seems commonly agreed upon <a href="https://www.reddit.com/r/recruitinghell/comments/1nmw5c8/has_anyone_inadvertently_trained_their_h1b/">here</a>, <a href="https://www.reddit.com/r/centrist/comments/1hnodib/h1b_visa_exploited_for_decades/">here</a>, and <a href="https://www.reddit.com/r/AskALiberal/comments/1m9h4x6/what_do_you_think_of_microsoft_laying_off_workers/">here</a>.</p>
<p>Another commenter pointed out that Accenture proposed hiring <a href="https://www.reuters.com/business/autos-transportation/accenture-proposes-new-campus-indias-andhra-pradesh-eyes-adding-12000-jobs-2025-09-23/">12,000 employees in a new campus in India</a>.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Bcachefs removed from the mainline kernel (218 pts)]]></title>
            <link>https://lwn.net/Articles/1040120/</link>
            <guid>45423004</guid>
            <pubDate>Tue, 30 Sep 2025 07:52:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lwn.net/Articles/1040120/">https://lwn.net/Articles/1040120/</a>, See on <a href="https://news.ycombinator.com/item?id=45423004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<div><p>[Posted September 30, 2025 by corbet]
               </p></div>
<div><p>
After marking bcachefs "externally maintained" in 6.17, Linus Torvalds has
<a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=f2c61db29f27">removed
it entirely</a> for 6.18.  "<q>It's now a DKMS module, making the in-kernel
code stale, so remove it to avoid any version confusion.</q>"</p><hr>
            </div> <!-- ArticleText -->
<details open="">
      <summary><h3>Risks</h3>
      <p> Posted Sep 30, 2025 10:30 UTC (Tue)
                               by <b>patrakov</b> (subscriber, #97174)
                              [<a href="https://lwn.net/Articles/1040154/">Link</a>] 
      </p>
      </summary>
      

      
          
        
     </details>
<details open="">
      <summary><h3>Decision process</h3>
      <p> Posted Sep 30, 2025 12:44 UTC (Tue)
                               by <b>daeler</b> (subscriber, #130460)
                              [<a href="https://lwn.net/Articles/1040192/">Link</a>] (3 responses)
      </p>
      </summary>
      <p>
Just curious, no judgement: How is this decision made? Can Linus just decide that he removes something from the kernel?<br>
</p>

      
          
        
     <details open="">
      <summary><h3>Decision process</h3>
      <p> Posted Sep 30, 2025 12:56 UTC (Tue)
                               by <b>corbet</b> (editor, #1)
                              [<a href="https://lwn.net/Articles/1040195/">Link</a>] 
      </p>
      </summary>
      Yes, Linus can make that kind of decision.  He doesn't just do it on his own, though; there was a long series of public and private discussions that led up to this one.


      
          
        
     </details>
<a name="CommAnchor1040194"></a>
    <details open="">
      <summary><h3>Decision process</h3>
      <p> Posted Sep 30, 2025 12:57 UTC (Tue)
                               by <b>pizza</b> (subscriber, #46)
                              [<a href="https://lwn.net/Articles/1040194/">Link</a>] (1 responses)
      </p>
      </summary>
      

      
          
        
     <details open="">
      <summary><h3>Decision process</h3>
      <p> Posted Sep 30, 2025 13:37 UTC (Tue)
                               by <b>Lionel_Debroux</b> (subscriber, #30014)
                              [<a href="https://lwn.net/Articles/1040202/">Link</a>] 
      </p>
      </summary>
      <p>
Note that things go the other way round as well: security fixes available in Linus' Linux but missing from other kernels because the backporting process didn't occur for some reason (difficulty, interest, etc.).<br>
The older a third-party kernel version is, the more it is likely to be missing both backports for security fixes, and vulnerabilities in code introduced in newer versions but not backported to the given third-party kernel (some vendors perform large amounts of backports to their franken-kernels).<br>
</p>

      
          
        
     </details>
</details>
</details>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Geolocation and Starlink (138 pts)]]></title>
            <link>https://www.potaroo.net/ispcol/2025-09/starlinkgeo.html</link>
            <guid>45422514</guid>
            <pubDate>Tue, 30 Sep 2025 06:23:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.potaroo.net/ispcol/2025-09/starlinkgeo.html">https://www.potaroo.net/ispcol/2025-09/starlinkgeo.html</a>, See on <a href="https://news.ycombinator.com/item?id=45422514">Hacker News</a></p>
Couldn't get https://www.potaroo.net/ispcol/2025-09/starlinkgeo.html: AggregateError]]></description>
        </item>
        <item>
            <title><![CDATA[European Union Public Licence (EUPL) (214 pts)]]></title>
            <link>https://eupl.eu/</link>
            <guid>45422512</guid>
            <pubDate>Tue, 30 Sep 2025 06:23:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://eupl.eu/">https://eupl.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=45422512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
    <p>License 1.2: [<a href="https://eupl.eu/1.2/bg/">BG</a>] [<a href="https://eupl.eu/1.2/cs/">CS</a>] [<a href="https://eupl.eu/1.2/da/">DA</a>] [<a href="https://eupl.eu/1.2/de/">DE</a>] [<a href="https://eupl.eu/1.2/el/">EL</a>] [<a href="https://eupl.eu/1.2/en/">EN</a>] [<a href="https://eupl.eu/1.2/es/">ES</a>] [<a href="https://eupl.eu/1.2/et/">ET</a>] [<a href="https://eupl.eu/1.2/fi/">FI</a>] [<a href="https://eupl.eu/1.2/fr/">FR</a>] [<a href="https://eupl.eu/1.2/hr/">HR</a>] [<a href="https://eupl.eu/1.2/hu/">HU</a>] [<a href="https://eupl.eu/1.2/it/">IT</a>] [<a href="https://eupl.eu/1.2/lt/">LT</a>] [<a href="https://eupl.eu/1.2/lv/">LV</a>] [<a href="https://eupl.eu/1.2/mt/">MT</a>] [<a href="https://eupl.eu/1.2/nl/">NL</a>] [<a href="https://eupl.eu/1.2/pl/">PL</a>] [<a href="https://eupl.eu/1.2/pt/">PT</a>] [<a href="https://eupl.eu/1.2/ro/">RO</a>] [<a href="https://eupl.eu/1.2/sk/">SK</a>] [<a href="https://eupl.eu/1.2/sl/">SL</a>] [<a href="https://eupl.eu/1.2/sv/">SV</a>].
    </p><h2>What is the EUPL?</h2>
    <p>EUPL is an acronym for "European Union Public Licence".</p>
    <p>The first EUPL draft (v.0.1) went public in June 2005. A public debate was then organised by the European Commission (IDABC). The consultation of the developers and users community was very productive and has lead to many improvements of the draft licence; 10 out of 15 articles were modified. Based on the results of these modifications (a detailed report and the draft EUPL v.0.2), the European Commission  elaborated a final version (v.1.0) that was officially approved on 9 January 2007, in three linguistic versions.</p>
    <p>By a second Decision of 9 January 2008, the European Commission validated the EUPL in all the official languages of the European Union.</p>
    <p>By a third Decision of 9 January 2009, the European Commission clarified specific points of the EUPL, publishing the version 1.1 in all the official languages of the European Union.</p>
    <p>The Commission Implementing Decision (EU) 2017/863 of 18 May 2017 updating the open source software licence EUPL to further facilitate the sharing and reuse of software developed by public administrations (OJ 19/05/2017 L128 p. 59–64 ) published the version 1.2, with extended compatibility.</p>
    <h2>Why the EUPL?</h2>
    <p>The purpose of the European Commission is first of all to distribute its own software under the licence. Some applications developed in the framework of the IDABC programme, such as Circabc, or Eusurvey have already been licensed under the EUPL in 2007. Other European Institutions are also interested in using the new licence.</p>
    <p>But why creating a new legal instrument from scratch when more than 100 other F/OSS licences exist, such as the GPL, the BSD or the OSL? The reason is that in a detailed legal study no existing licence was found to correspond to the requirements of the European Commission:</p>
    <ul>
      <li>The Licence should have equal legal value in all EU languages;</li>
      <li>The terminology regarding intellectual property rights had to be conformant with European law requirements;</li>
      <li>To be valid in all Member States, limitations of liability or warranty had to be precise, and not formulated "to the extend allowed by the law" as in most licences designed with the legal environment of the United States in mind.</li>
    </ul>
    <h2>Objectives</h2>
    <p>The main objective of the European Commission is to distribute widely and promote the use of software owned by itself and other European Institutions under an Free/Open Source Licence conform to European law requirements.</p>
    <p>The EUPL is however written in neutral terms so that a broader use might be envisaged.</p>
    <p>In addition, distribution of software should avoid the exclusive appropriation of the software even after improvement by a third party (therefore, the EUPL is a "copyleft" licence).</p>
    <h2>Who may use the EUPL?</h2>
    <p>Although the potential users of European Institutions' software are mostly other public sector administrations, there is nothing in the EUPL preventing its broader use. The EUPL could be used by anyone who holds the copyright to a piece of software. It could become – in various languages - an adequate legal interoperability instrument across Europe.</p>
    <p>Nevertheless, the EUPL purpose is not to compete with other licences. It might be used primarily by public administrations, either European or national, that would need a common licensing instrument to mutualise or share software and knowledge.</p>
    <h2>Is the EUPL compatible with the GPL and other F/OSS licences?</h2>
    <p>Yes, it is. The EUPL contains a unique compatibility clause and provides for a list of compatible copyleft licences. The GPL is one of them.</p>
    <p>For example, how would the interaction between the EUPL and the GPL play out in the case of CIRCA, an application a already distributed under the EUPL?</p>
    <p>A developer may merge the Circabc software with a GPL component, and then could license the new derivative work (another project, with a new name) under the GPL. It is not permitted to "re-license" CIRCA under the GPL. A developer will be also able to integrate CIRCA in existing GPL work called e.g. "MY-GPL-PROGRAM" and continue to license this improved work under the GPL licence that he had chosen originally.</p>
    <hr>
    <p><i>This website is not sponsored or endorsed by the <a href="https://ec.europa.eu/" target="_blank">European Commission</a> or any other institution, body or agency of the <a href="http://europa.eu/" target="_blank">European Union</a>.</i></p>
    <p><small>Created by <a href="https://www.javiercasares.com/" target="_blank">Javier Casares</a> (<a href="https://robotstxt.es/legal/" target="_blank">legal</a>) under license <a href="https://eupl.eu/">EUPL 1.2</a>.</small></p>
  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[AI tools I wish existed (112 pts)]]></title>
            <link>https://sharif.io/28-ideas-2025</link>
            <guid>45421812</guid>
            <pubDate>Tue, 30 Sep 2025 04:14:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sharif.io/28-ideas-2025">https://sharif.io/28-ideas-2025</a>, See on <a href="https://news.ycombinator.com/item?id=45421812">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>It's September 2025. We have Claude Opus 4.1. GPT-5. Nano banana. There has never been a better time in the history of computing to build software. Here are a few ideas I wish existed.</p><ol><li>A camera app that uses nano banana to make my mediocre iPhone photos look like they were taken on a Leica.</li><li>A single-purpose AI agent that can take any frontend project and automatically add support for light mode, dark mode, and custom theming. It should be able to use vision to see the UI changes, and then iteratively make changes based on the rendered UI.</li><li>Another single-purpose AI agent that can decompile and debug minified code into an interpretable codebase. This also requires a strong code-then-debug loop.</li><li>A hybrid of Strong (the lifting app) and ChatGPT where the model has access to my workouts, can suggest improvements, and coach me. I mainly just want to be able to chat with the model knowing it has detailed context for each of my workouts (down to the time in between each set).</li><li>A recommendation engine that looks at my browsing history, sees what blog posts or articles I spent the most time on, then searches the web every night for things I should be reading that I’m not. In the morning I should get a digest of links. I also want to be able to give feedback on which were good suggestions and which weren’t to improve the next day’s digest.</li><li>A calorie tracking app that’s a chat app grounded by nutrition databases. Just minimize the cognitive effort it takes me to log a meal.</li><li>A minimalist writing app that lets me write long-form content. A model can also highlight passages and leave me comments in the marginalia. I should be able to set different “personas” to review what I wrote.</li><li>An AI agent that can build one-off specialized AI agents. I want to describe a task like “build me an agent that can decompile code” and this agent will go off and build a hyper-specialized code decompilation agent for me.</li><li>A minimalist ebook reader that lets me read ebooks, but I can highlight passages and have the model explain things in more depth off to the side. It should also take on the persona of the author. It should feel like an <em>extension</em> of the book and not a separate chat instance.</li><li>A Deep Research agent that can reason for multiple days. I want to give it <em>very</em> complex queries and let it know it can spawn hundreds of sub-agents and reason for 3 days before it needs to return a response.</li><li>A <em>paint-by-number</em> filmmaking app. I want to be able to brainstorm an idea for a short film in the app, have the model create a detailed storyboard, and then I just need to use my phone to film each of the storyboarded shots. Kind of like training wheels for making movies.</li><li>A local screen recording app but it uses local models to create detailed semantic summaries of what I’m doing each day on my computer. This should then be provided as context for a chat app. I want to ask things like “Who did I forget to respond to yesterday?” I've been using Rewind for a year now, and it's nowhere near as useful as it should be.</li><li>Semantic filters for Twitter/X/YouTube. I want to be able to write open-ended filters like “hide any tweet that will likely make me angry” and never have my feed show me rage-bait again. By shaping our feeds we shape ourselves.</li><li>An agent that can create a detailed curriculum for very niche topics. I should be able to say something like “I want to learn everything we know about the science of progress” and it would search the web for people, blog posts, YouTube videos, essays, and textbooks. Then it should read through all the content, and give me a guided curriculum that will take me from beginner to expert.</li><li>An <em>actually good</em> book recommendation engine that first quizzes you about things you’ve read in the past, what your goals are, and the sort of things you enjoy reading. Then once it knows a lot about you, another agent simulates what you might think of the books the main agent suggests. It only surfaces books that you’re very likely to enjoy.</li><li>A semantic search engine for TikTok and Instagram Reels. There’s so much useful information locked away in short-form videos. I want to be able to query it.</li><li>A sleep fitness app that pulls in data from my Apple Watch (HR, VO₂), Eight Sleep, Oura Ring, workout apps, and combines them to give me practical recommendations for how to improve my sleep and recovery. I want it to proactively message me. Something like <em>“I noticed your HRV has gone down this week, maybe you’re overtraining?”</em></li><li>A massive component library designed to be rendered within the context of a chat interface. Most existing component libraries have primitives that are too low-level. Less customization, more high level widgets.</li><li>A minimal voice assistant for my Apple Watch. I have lots of questions that are too complicated for Siri but not for ChatGPT. The responses should just be a few words long.</li><li>A writing app that searches the web for the topic you’re writing about, then composes a “suggested reading” list based on what it thinks might be helpful for you to read. (Writing apps should never write <em>for</em> you.)</li><li>A running app that creates a personalized plan, tracks your running pace and heart rate, and then iteratively adjusts the training program based on real world data.</li><li>A nano banana photo-editing app where I don’t have to write a prompt. Just give me hundreds of templates from trying out different haircuts to seeing what you and your partner’s kid would look like to making me look like The Rock. A photo editing super-app.</li><li>Same.energy but for finding YouTube videos with similar vibes. Let me put in a URL and have it find similar videos. YouTube's algorithm today is not this. &nbsp;It just tries to maximize the median user’s engagement.</li><li>A Sony Walkman-style device that you can give to children so they can ask questions to an LLM. It should be voice-first, and focused on explaining things. There shouldn’t be a single screen on the device. Offline-first would be a plus.</li><li>A search engine for biographies of people where the query is a questionnaire about the current problem you’re facing, your stage in life, your field, etc. The engine’s results should be chapters from biographies or autobiographies from great people throughout history who have gone through and written about similar circumstances.</li><li>A screen-recording agent that observes how I’m using my computer and phone. Each day it audits the content I’ve been consuming. Screen Time is not specific enough. I want to know the exact nutritional value of the tokens I’m consuming.</li><li>A marketplace for AI agents. I don’t think today’s general agents will be better than an agent designed for a specific use case. I want a hyper-specific agent catalog for niche tasks like finding an apartment to rent in San Francisco. There should be tens of thousands of these agents that I can use via the web or call via API.</li><li>A writing app that lets you “request a critique” from a bunch of famous writers. What would Hemingway say about this blog post? What did he find confusing? What did he like?</li></ol><p>If you're building anything on this list, please let me know. I'd really like to use it.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Hiring only senior engineers is killing companies (186 pts)]]></title>
            <link>https://workweave.dev/blog/hiring-only-senior-engineers-is-killing-companies</link>
            <guid>45421564</guid>
            <pubDate>Tue, 30 Sep 2025 03:17:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://workweave.dev/blog/hiring-only-senior-engineers-is-killing-companies">https://workweave.dev/blog/hiring-only-senior-engineers-is-killing-companies</a>, See on <a href="https://news.ycombinator.com/item?id=45421564">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>In the last 3 months, I've interviewed 134 engineers - students, mid-level, seniors and even CTOs.&nbsp;</p><p>My main takeaway: there is a huge pool of exceptional junior engineers<strong> </strong>that most companies won’t even consider.&nbsp;</p><p>While everyone else is fighting over seniors, smart companies can get a significant advantage by going the other direction. If you won’t, your competitors will.</p><p>I’m not alone here. In the beginning of 2025 Shopify recently hired 25 interns (and <!--$--><a href="https://www.firstround.com/ai/shopify?ref=review.firstround.com" rel="noopener">their head of engineering said he</a><!--/$--> aims for 1000(!) more by the end of the year, saying that: “...interns bring energy, drive and intensity that pushes the whole team forward.”)</p><h2>Why do companies avoid juniors?</h2><p>Every company has a different excuse:</p><ul><li data-preset-tag="p"><p>In small startups - “we are a very small team and we don’t have time to mentor juniors, we need engineers who will be very productive from day 1"</p></li><li data-preset-tag="p"><p>In medium-sized companies - “we are going to grow very fast, we need engineers who can handle scale and have faced such challenges before"</p></li><li data-preset-tag="p"><p>In big companies - “our infrastructure is super complex, it’ll take juniors too long to ramp up".</p></li></ul><p>It's safer to hire someone with 4+ years of experience who can contribute from day one, even if their ceiling isn't as high as a motivated junior engineer.</p><p>So colleges continue churning out graduates who can't get a job, while companies complain about how hard it is to find senior engineers (and pay premium rates for them).</p><p>The thing is that many of these "experienced" hires aren't actually that much more productive than a well-mentored junior engineer.</p><p>Software development is not rocket science. There are diminishing returns, you will get better with time, but the pace will become slower. You can tell the difference between a developer with 1 year of experience and one with 5, but between those with 10 vs 15? Probably not.</p><p>The most critical parts (motivation, ambition, character, and brains)<strong> </strong>have little to do with experience.</p><h2>What companies are missing</h2><p>The main mistakes companies make:</p><ol><li data-preset-tag="p"><div><p><strong>Old assumptions about onboarding time.</strong> Companies assume junior engineers need 6-12 months to become productive, but AI-savvy juniors can get up to speed much faster. They can use it to understand codebases (without interrupting team members), generate boilerplate code, and learn new technologies at an accelerated pace.</p></div></li><li data-preset-tag="p"><div><p><strong>Outdated interviews</strong> - most technical interviews still focus on algorithm memorization and whiteboard coding. These skills are less relevant when AI can handle all those known problems. </p></div></li><li data-preset-tag="p"><p><strong>They don't know where to find amazing juniors - </strong>companies recruit from the same places and miss the hidden gems. A perfect example: engineers who applied to Y Combinator but didn't get in. They are very often impressive people with strong motivation and drive.</p></li></ol><p>Before I share my take on junior interviews, let’s talk about what’s so great about them:</p><h2>Why I love working with juniors</h2><ul><li data-preset-tag="p"><p>Juniors are<strong> not restricted by what they know</strong>.&nbsp; They haven't been trained to think "that's just how we do things." They’ll not try to reuse the same technologies from previous companies, or recreate those ‘amazing’ design patterns that were useful only in a specific context. It’s not just being AI-native, it’s about having less resistance to change.&nbsp;</p></li><li data-preset-tag="p"><p>Great juniors<strong> learn fast and search for feedback</strong>. It’s easier to manage them. They <strong>want</strong> to improve and know what you think about their work.</p></li><li data-preset-tag="p"><p><strong>Loyalty.</strong> engineers who you train from the beginning tend to stay longer. They understand your systems deeply and can mentor the next generation of junior engineers.</p></li><li data-preset-tag="p"><p><strong>Higher ceiling.</strong> A motivated junior engineer often has more upside. You're getting someone at the beginning of their growth curve rather than the middle or end.</p></li><li data-preset-tag="p"><p>Juniors bring<strong> fresh energy </strong>to the team - they want to learn, and they have a drive to prove themselves and succeed. Their motivation can be contagious!<br>The existing seniors in your team <strong>will enjoy</strong> working with smart and motivated developers.</p></li></ul><p>Before we continue, a side note:</p><p>The argument here is not to stop hiring seniors. To be effective, juniors need people to mentor them, do high quality code reviews, and so on. And in addition, for some critical challenges, you would still want people who’ve done those before at other places.</p><p>Ok, so you’ve decided it’s worth giving some juniors a chance. Now comes the hard part. As there are so many juniors looking for a job, it can be difficult to find the right ones. Here’s the process that worked for us:</p><h2>How to hire the right junior engineers</h2><p>Most companies are still hiring like it's 2019. AI has fundamentally changed how we write software. If your hiring process hasn't changed, you're probably hiring the wrong people.&nbsp;</p><p>For some reason, companies still ban AI during technical interviews. They're optimizing for skills that matter less while ignoring the skills that actually determine success on the job.</p><p>Here’s our hiring process in 5 steps:</p><h4>1. Filter for the right mindset</h4><ul><li data-preset-tag="p"><p>Ask about <strong>projects they've built, then drill deeper.</strong> Ask "Why did you build this?" and "How does that work?" <br>Keep drilling down until you hit the bottom of their understanding and whether they can think through complex problems.</p></li><li data-preset-tag="p"><p><strong>Look for passion and curiosity.</strong> You want the ones who light up when talking about their projects. They should show real excitement about the problems they've solved. These conversations should be energizing for both of you!</p></li><li data-preset-tag="p"><p><strong>Watch out for red flags.</strong> The ones who get defensive when you ask follow-up questions or can't explain their work past the surface level are probably just chasing a tech salary.&nbsp;</p></li></ul><h4>2. “Use whatever tools you like" home assignment&nbsp;</h4><p>A small and realistic coding challenge with explicit permission to use any tools they want.&nbsp;</p><p>The key is what happens next - we schedule a 30-minute follow-up where they walk through their solution. We ask them to explain their approach, then drill deeper on their reasoning - asking "Why did you make that choice?" or "how does this part work?". We keep going until you reach the limits of their understanding.</p><p>Do they understand the code they submitted? Can they explain design decisions and trade-offs? How deep is their knowledge of the technologies they chose?</p><h4>3. Problem solving without AI</h4><p>A ~40-minute interview to test their ability to think through complex problems and design solutions. We focus on system design, architectural decisions, and reasoning through trade-offs.&nbsp;</p><p>Yes, they will use AI in their job even in those tasks, but we also want to see if they can think for themselves, and what is their fundamental engineering thinking.</p><h4>4. Live implementation with AI</h4><p>We give them 20 minutes for a small live coding task and see how they work with AI tools. Their prompting strategies, how they iterate on AI output, and whether they can effectively guide the AI toward solutions that make sense.</p><h4>5. Evaluate their AI strategy</h4><p>Then, we ask candidates to walk us through their typical development workflow.&nbsp;</p><p>We ask them to explain when they choose AI assistance versus manual coding, ideally with specific examples from projects they've built.</p><p>The engineers who can’t think without AI hit walls when they encounter new problems.</p><p>The ones who resist AI are outpaced by peers who go all-in with the new tools.&nbsp;</p><p>We look for engineers who excel in both phases - the ones who understand the huge benefit AI provides, but also know where it hurts.&nbsp;&nbsp;</p><h2>Making it work after the hire</h2><p>Congrats! You’ve hired a new junior engineer. What’s next?</p><p>Here’s my take:</p><ul><li data-preset-tag="p"><p><strong>Invest in mentoring infrastructure.</strong><br>Don’t just assume they can use AI to learn everything. Make sure your experienced engineers have the time to pair with them, create clear learning paths, and be available for their needs.&nbsp;</p></li><li data-preset-tag="p"><p><strong>Be patient with short-term productivity.</strong> Don’t expect them to produce magic because they are ‘AI-native’. Yes, they should be fast, but give them the proper time to learn the basics of your company.</p></li><li data-preset-tag="p"><p><strong>Measure the right metrics.</strong> Track how quickly junior engineers become productive, their retention rates, and their main blockers. We (very objectively) suggest using Weave to benchmark them to your current engineers and industry standards :)</p></li><li data-preset-tag="p"><p><strong>Talk to them!</strong> Ask them about their experience, and what they think you could improve for the next juniors. Use the fresh perspective they bring, and come with an open mind to their suggestions. Also - make sure to appreciate their work and tell them when you do. Even if they are superstars - they might not know it, and could use some encouragement.&nbsp;</p></li><li data-preset-tag="p"><p><strong>Start small.</strong> Don't hire 10 juniors and let them run amok on your codebases. Start with 1-2 and learn what works (from the previous steps) before scaling up.</p></li></ul><h2>Why this matters more than ever</h2><p>I believe most companies are making a huge mistake by avoiding juniors entirely. They're missing out on AI-native engineers who can learn quickly, adapt to new tools, and grow into really exceptional senior engineers quite fast.</p><p>This market inefficiency won't last forever. As we’ve seen with the Shopify example,&nbsp; smart companies will figure out how to hire and develop junior engineers effectively. They will build incredible teams while their competitors fight over the same pool of expensive senior talent.</p><p>Investing your time in passionate junior developers will pay off in the long run. The question is whether you'll start now or wait until everyone else figures it out.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Devbox – Containers for better dev environments (103 pts)]]></title>
            <link>https://devbox.ar0.eu/</link>
            <guid>45421302</guid>
            <pubDate>Tue, 30 Sep 2025 02:26:39 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://devbox.ar0.eu/">https://devbox.ar0.eu/</a>, See on <a href="https://news.ycombinator.com/item?id=45421302">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article> <p>  <span>Isolated Environments</span> </p> <p>Each project runs in its own Docker box (container), preventing dependency conflicts and keeping your host system clean. Boxes restart automatically and persist between reboots.</p> </article> <article> <p>  <span>Host File Access</span> </p> <p>Your code stays on the host filesystem for easy editing with your favorite tools while running in isolated environments.</p> </article> <article> <p>  <span>Simple Commands</span> </p> <p>Easy-to-use CLI with intuitive commands for creating, managing, and working with development environments.</p> </article> <article> <p>  <span>Safety Checks</span> </p> <p>Validates Docker installation and prevents accidental overwrites with built-in safety features.</p> </article> <article> <p>  <span>Templates &amp; Configuration</span> </p> <p>Project-specific devbox.json configuration and built-in templates for Python, Node.js, Go, and web development.</p> </article> <article> <p>  <span>Advanced Docker Features</span> </p> <p>Port mapping, volume mounting, environment variables, and resource limits for powerful, customizable environments.</p> </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FAA decides it trusts Boeing enough to certify safety of its own planes again (191 pts)]]></title>
            <link>https://www.theregister.com/2025/09/29/faa_decides_it_trusts_boeing/</link>
            <guid>45420327</guid>
            <pubDate>Mon, 29 Sep 2025 23:56:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theregister.com/2025/09/29/faa_decides_it_trusts_boeing/">https://www.theregister.com/2025/09/29/faa_decides_it_trusts_boeing/</a>, See on <a href="https://news.ycombinator.com/item?id=45420327">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="body">
<p>After years of relying on the FAA to certify its jets as airworthy, Boeing is finally going to be allowed to do so itself – sometimes.&nbsp;</p>
<p>The US Federal Aviation Administration <a href="https://www.faa.gov/newsroom/faa-statement-boeing-airworthiness-certificates" rel="nofollow">said</a> on Friday that it was granting Boeing "limited delegation" to issue its own airworthiness certificates for the 737 Max and 787 aircraft, which it hasn't been able to do since 2019 and 2022, respectively.&nbsp;</p>
<p>Boeing lost its ability to certify the airworthiness of the 737 Max after a <a href="https://www.theregister.com/2024/05/15/boeing_might_be_criminally_prosecuted/">pair of crashes</a> in 2018 and 2019 that killed 346 people. The agency took 787 certification out of Boeing's hands due to what the FAA said was "production quality issues."&nbsp;</p>

    

<p>As we've previously reported, the 787's problems include things like a need to be <a href="https://www.theregister.com/2024/05/15/boeing_might_be_criminally_prosecuted/">power cycled every 51 days</a> due to faulty software, <a href="https://www.theregister.com/2019/08/08/boeing_787_software_bug_hack/">easy hackability</a> of plane systems, <a href="https://www.theregister.com/2014/01/16/us_safety_authorities_on_boeings_case_787_batteries_fail/">melting batteries</a>, and other issues pointed out before the FAA took control of its airworthiness. Not that things have become much better for the 787 since the FAA assumed responsibility for its airworthiness, mind you: Since then Boeing has <a href="https://www.theregister.com/2023/06/07/boeing_787_production_defect/">delayed 787 deliveries</a> due to faulty horizontal stabilizers, and a whistleblower has argued that <a href="https://www.theregister.com/2024/04/17/boeing_whistleblower_fuselage_gaps/">chronic fuselage gaps</a> have left the entire 787 fleet in a position to fly apart at the seams.&nbsp;</p>

        


        

<p>The 737 Max has continued to have problems since the FAA took over inspection of that Boeing model, too. It was a 737 Max 9 which <a href="https://www.theregister.com/2024/01/08/boeing_737_max_9_airplanes/">lost a door plug in flight</a> last year. The FAA grounded 737 Max aircraft following the door plug incident, after which United Airlines and Alaska Airlines, the only carriers with Max 9s in their fleets, discovered a <a href="https://www.theregister.com/2024/01/09/united_alaska_737_loose_bolts/">chronic problem of loose bolts</a> on the questionably-airworthy aircraft. A Congressional look at internal Boeing documents found emails from engineers <a href="https://www.theregister.com/2020/01/11/boeing_737_max_emails/">saying</a> in 2020 that they wouldn't put their own families on the 737 Max over safety concerns.</p>
<p>The FAA gave Boeing <a href="https://www.theregister.com/2024/02/28/faa_gives_boeing_90_days/">90 days</a> to fix a number of safety shortcomings it flagged in a February 2024 report it published following the door plug blowout. It's well past that 90-day deadline, but the FAA now says that they're at least partially content with improvements the company has made since it started scrutinizing the firm, again, last year.&nbsp;</p>
<h3>
<p>
  <strong>Airworthiness certification custody sharing</strong>
</p>
<p>"The FAA will only allow this step forward because we are confident it can be done safely," the agency said in its Friday press release – but being done safely still means Boeing will be subject to FAA scrutiny.&nbsp;</p>

        

<p>Per the Administration, Boeing will only get to issue airworthiness certificates every other week, with the FAA handling things the other half of the time. Far from being simply an acknowledgement that Boeing is doing better, the FAA is going to use its every-other-week model to spend more time keeping a watchful eye on the assembly process.&nbsp;</p>
<p>"By alternating weeks, we are creating more opportunities to directly observe how Boeing is carrying out this responsibility in practice," an FAA spokesperson told <em>The Register.</em>&nbsp;</p>
<ul>

<li><a href="https://www.theregister.com/2025/01/15/boeing_airbus_commercial_deliveries_2024/">Boeing going backwards as production's slowing and woes keep flowing</a></li>

<li><a href="https://www.theregister.com/2025/04/23/boeing_thoma_bravo_software_sale/">Boeing offloads some software businesses to private equiteer Thoma Bravo</a></li>

<li><a href="https://www.theregister.com/2025/03/28/boeing_starliner_fixes/">Boeing's Starliner may fly again, pending fixes to literally everything</a></li>

<li><a href="https://www.theregister.com/2024/12/31/faa_whistleblower_complaints/">Report claims FAA ignores most whistleblower complaints</a></li>
</ul>
<p>"The FAA's role is to provide oversight of Boeing's performance, ensuring that it issues certificates only when airplanes meet all applicable safety requirements," the spokesperson continued. "Alternating weeks strengthens our ability to identify trends, intervene early if concerns arise, and maintain confidence in the overall safety of Boeing's system."</p>
<p>The FAA didn't tell us whether the agreement was temporary, or how long it might take Boeing to earn its complete trust and confidence in its ability to issue reliable airworthiness certificates. Boeing didn't respond to questions for this story. ®&nbsp;</p>                                
                    </h3></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to create an OS from scratch (212 pts)]]></title>
            <link>https://github.com/cfenollosa/os-tutorial</link>
            <guid>45420173</guid>
            <pubDate>Mon, 29 Sep 2025 23:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/cfenollosa/os-tutorial">https://github.com/cfenollosa/os-tutorial</a>, See on <a href="https://news.ycombinator.com/item?id=45420173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">os-tutorial</h2><a id="user-content-os-tutorial" aria-label="Permalink: os-tutorial" href="#os-tutorial"></a></p>
<p dir="auto"><em><g-emoji alias="warning">⚠️</g-emoji> Hey! This is an old, abandoned project, with both technical and design issues <a href="https://github.com/cfenollosa/os-tutorial/issues/269" data-hovercard-type="issue" data-hovercard-url="/cfenollosa/os-tutorial/issues/269/hovercard">listed here</a>. Please have fun with this tutorial but do look for more modern and authoritative sources if you want to learn about OS design. <g-emoji alias="warning">⚠️</g-emoji></em></p>
<p dir="auto">How to create an OS from scratch!</p>
<p dir="auto">I have always wanted to learn how to make an OS from scratch. In college I was taught
how to implement advanced features (pagination, semaphores, memory management, etc)
but:</p>
<ul dir="auto">
<li>I never got to start from my own boot sector</li>
<li>College is hard so I don't remember most of it.</li>
<li>I'm fed up with people who think that reading an already existing kernel, even if small, is
a good idea to learn operating systems.</li>
</ul>
<p dir="auto">Inspired by <a href="http://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf" rel="nofollow">this document</a>
and the <a href="http://wiki.osdev.org/" rel="nofollow">OSDev wiki</a>, I'll try to make short step-by-step READMEs and
code samples for anybody to follow. Honestly, this tutorial is basically the first document but
split into smaller pieces and without the theory.</p>
<p dir="auto">Updated: more sources: <a href="https://littleosbook.github.io/" rel="nofollow">the little book about OS development</a>,
<a href="https://web.archive.org/web/20160412174753/http://www.jamesmolloy.co.uk/tutorial_html/index.html" rel="nofollow">JamesM's kernel development tutorials</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>This course is a code tutorial aimed at people who are comfortable with low level computing. For example,
programmers who have curiosity on how an OS works but don't have the time or willpower to start reading the Linux kernel
top to bottom.</li>
<li>There is little theory. Yes, this is a feature. Google is your theory lecturer. Once you pass college,
excessive theory is worse than no theory because it makes things seem more difficult than they really are.</li>
<li>The lessons are tiny and may take 5-15 minutes to complete. Trust me and trust yourself. You can do it!</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">How to use this tutorial</h2><a id="user-content-how-to-use-this-tutorial" aria-label="Permalink: How to use this tutorial" href="#how-to-use-this-tutorial"></a></p>
<ol dir="auto">
<li>
<p dir="auto">Start with the first folder and go down in order. They build on previous code, so if
you jump right to folder 05 and don't know why there is a <code>mov ah, 0x0e</code>, it's because you missed lecture 02.
Really, just go in order. You can always skip stuff you already know.</p>
</li>
<li>
<p dir="auto">Open the README and read the first line, which details the concepts you should be familiar with
before reading the code. Google concepts you are not familiar with. The second line states the goals for each lesson.
Read them, because they explain why we do what we do. The "why" is as important as the "how".</p>
</li>
<li>
<p dir="auto">Read the rest of the README. It is <strong>very concise</strong>.</p>
</li>
<li>
<p dir="auto">(Optional) Try to write the code files by yourself after reading the README.</p>
</li>
<li>
<p dir="auto">Look at the code examples. They are extremely well commented.</p>
</li>
<li>
<p dir="auto">(Optional) Experiment with them and try to break things. The only way to make sure you understood something is
trying to break it or replicate it with different commands.</p>
</li>
</ol>
<p dir="auto">TL;DR: First read the README on each folder, then the code files. If you're brave, try to code them yourself.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Strategy</h2><a id="user-content-strategy" aria-label="Permalink: Strategy" href="#strategy"></a></p>
<p dir="auto">We will want to do many things with our OS:</p>
<ul dir="auto">
<li>Boot from scratch, without GRUB - DONE!</li>
<li>Enter 32-bit mode - DONE</li>
<li>Jump from Assembly to C - DONE!</li>
<li>Interrupt handling - DONE!</li>
<li>Screen output and keyboard input - DONE!</li>
<li>A tiny, basic <code>libc</code> which grows to suit our needs - DONE!</li>
<li>Memory management</li>
<li>Write a filesystem to store files</li>
<li>Create a very simple shell</li>
<li>User mode</li>
<li>Maybe we will write a simple text editor</li>
<li>Multiple processes and scheduling</li>
</ul>
<p dir="auto">Probably we will go through them in that order, however it's soon to tell.</p>
<p dir="auto">If we feel brave enough:</p>
<ul dir="auto">
<li>A BASIC interpreter, like in the 70s!</li>
<li>A GUI</li>
<li>Networking</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">This is a personal learning project, and even though it hasn't been updated for a long time, I still have hopes to get into it at some point.</p>
<p dir="auto">I'm thankful to all those who have pointed out bugs and submitted pull requests. I will need some time to review everything and I cannot guarantee that at this moment.</p>
<p dir="auto">Please feel free to fork this repo. If many of you are interested in continuing the project, let me know and I'll link the "main fork" from here.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Safe zero-copy operations in C# (205 pts)]]></title>
            <link>https://ssg.dev/safe-zero-copy-operations-in-c/</link>
            <guid>45420001</guid>
            <pubDate>Mon, 29 Sep 2025 23:12:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ssg.dev/safe-zero-copy-operations-in-c/">https://ssg.dev/safe-zero-copy-operations-in-c/</a>, See on <a href="https://news.ycombinator.com/item?id=45420001">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>C# is a versatile language. You can write mobile apps, desktop apps, games, websites, services and APIs with it. You can write it like Java with all the abstractions and <code>AbstractionFactoryClassProvider</code>s. But differently from Java, you can write low-level and unsafe code too. When I say low-level, I mean without the GC, with raw pointers. </p><p>Low-level code is usually required for performance or interoperability with C libraries or the operating system. The reason low-level code helps with performance is that it can be used to eliminate runtime checks on memory accesses.</p><p><strong>Array element accesses are bounds-checked in C# for safety</strong>. But, that means that there's performance impact unless the compiler can eliminate a bounds-checking operation. The bounds-checking elimination logic needs to ensure that the array index was already bounds-checked before, or can be assured to be inside bounds during the compile-time. For example, take this simple function:</p><pre><code>int sum(int[] array)
{
  int sum = 0;
  for (int i = 0; i &lt; array.Length; i++)
  {
    sum += array[i];
  }
  return sum;
}</code></pre><p>That's an ideal situation for bounds-checking elimination because the index variable <code>i</code> is created with known boundaries, and it depends on the array's length. The index variable's lifetime is shorter than the array's lifetime and it's guaranteed to be contained valid values throughout the function. The native code produced for <code>sum</code> has no bounds-checking:</p><pre><code>L0000	xor	    eax, eax
L0002	xor	    edx, edx
L0004	mov     r8d, [rcx+8]          ; read length
L0008	test    r8d, r8d              ; is empty?
L000b	jle	    short L001c           ; skip the loop
L000d	mov	    r10d, edx
L0010	add	    eax, [rcx+r10*4+0x10] ; sum += array[i];
L0015	inc	    edx                   ; i++
L0017	cmp	    r8d, edx              ; compare length with i
L001a	jg	    short L000d           ; loop if still greater
L001c	ret	</code></pre><p>But, what if the function signature was slightly different?</p><pre><code>int sum(int[] array, int startIndex, int endIndex)
{
  int sum = 0;
  for (int i = startIndex; i &lt;= endIndex; i++)
  {
    sum += array[i];
  }
  return sum;
}</code></pre><p>Now, the C# compiler doesn't have a way to know if the passed <code>startIndex</code> and <code>endIndex</code> values are inside the boundaries of <code>array</code> because their lifetimes are distinct. So the native assembly produced becomes way more involved with bounds-checking operations:</p><pre><code>L0000	sub		rsp, 0x28				
L0004	xor		eax, eax			; sum = 0
L0006	cmp		edx, r8d			; startIndex &gt; endIndex?
L0009	jg		short L0045			; then skip the entire function
L000b	test	rcx, rcx			; array is null?
L000e	je		short L0031			; then cause NullReferenceException
L0010	mov		r10d, edx
L0013	or		r10d, r8d
L0016	jl		short L0031
L0018	cmp		[rcx+8], r8d		; array.Length &lt;= endIndex ?
L001c	jle		short L0031			; then do bounds-checking
L001e	xchg	ax, ax				; alignment NOP
L0020	mov		r10d, edx
L0023	add		eax, [rcx+r10*4+0x10]   ; sum += array[i]
L0028	inc		edx					; consider i + 1
L002a	cmp		edx, r8d			; i &gt; endIndex?
L002d	jle		short L0020			; no, go on
L002f	jmp		short L0045			; return
L0031	cmp		edx, [rcx+8]		; i &gt; array.Length?
L0034	jae		short L004a			; bounds-checking failed. go to ----+
L0036	mov		r10d, edx												|
L0039	add		eax, [rcx+r10*4+0x10]	; sum += array[i]				|
L003e	inc		edx					; i++								|
L0040	cmp		edx, r8d			; i &lt;= endIndex ?					|
L0043	jle		short L0031			; continue for loop					|
L0045	add		rsp, 0x28												|
L0049	ret							; return sum						|
L004a	call	0x00007ff857ec6200	; throw IndexOutOfRangeException &lt;--+
</code></pre><p>We could use low-level unsafe functions and pointers in C# (yes, C# supports raw pointers!) to avoid bounds-checking altogether, like this:</p><pre><code>unsafe int sum(int* ptr, int length)
{
  int* end = ptr + length;
  int sum = 0;
  for (; ptr &lt; end; ptr++)
  {
    sum += *ptr;
  }
  return sum;
}</code></pre><p>That also creates a <em>very </em>optimized code that supports passing along a sub-portion of an array:</p><pre><code>L0000	movsxd	rax, edx        
L0003	lea	rax, [rcx+rax*4]    ; end = ptr + length
L0007	xor	edx, edx            ; sum = 0
L0009	cmp	rcx, rax            ; ptr &gt;= end ?
L000c	jae	short L0019         ; then return
L000e	add	edx, [rcx]          ; sum += *ptr
L0010	add	rcx, 4              ; ptr += sizeof(int)
L0014	cmp	rcx, rax            ; ptr &lt; end?
L0017	jb	short L000e         ; then keep looping
L0019	mov	eax, edx
L001b	ret	                    ; return sum</code></pre><p>Unsafe code and pointer-arithmetic can be very performant as you can see. The problem is that it's too dangerous. With incorrect values of length, you don't simply get an <code>IndexOutOfRangeException</code> but instead your app either crashes, or returns incorrect results. If your code happened to modify the memory region instead of just reading it, then you could have a nice entry point for a buffer overflow security vulnerability in your app too. Not to mention that all the callers of that function will have to have unsafe blocks too.</p><p>But it's possible to handle this safe and fast in C# without resorting to esoteric rituals like that. First, how do you solve this problem of indexes to describe a portion of an array and actual boundaries of the array being disconnected from each other? You create a new immutable type that holds these values together. And that type is called a <em>span</em> in C#. Other programming languages may call it a <em>slice</em>. Declaration of <code>Span</code> type resembles something like this. Well, it's not exactly this, but I want you to understand the concept first:</p><pre><code>readonly struct Span&lt;T&gt;
{
  readonly T* _ptr;
  readonly int _len;
}</code></pre><p>It's basically an immutable pointer with length. The great thing about a type like this is that the compiler can assure that once an immutable Span is initialized with correct bounds, it will always be safe to access without any bounds-checking. That means, you can pass around sub-views of arrays or even other spans safely and quickly without the performance overhead.</p><p>But, how can it be safe? What if the GC decides to throw away the structure that <code>ptr</code> points to? Well, that's where "ref types" come into play in C#.</p><p>A ref type is a type that can't leave the stack and escape to the heap, so it's always guaranteed that a <code>T</code> type will outlive a <code>Span&lt;T&gt;</code> instance. That's why the actual <code>Span&lt;T&gt;</code> declaration looks like this:</p><pre><code>readonly ref struct Span&lt;T&gt;  // notice "ref" 
{
  readonly ref T _ptr;        // notice "ref"
  readonly int _len;
}</code></pre><p>Since a ref type can only live in stack, it can't be a member of a class, nor can it be assigned to a non-ref variable, like, it can't be boxed either. A ref type can only be contained inside another ref type. It's ref types all the way.</p><p>Span-based version of our <code>sum</code> function can eliminate bounds-checking despite that it can now have several super powers. The first one is that it can receive a sub-view of an array too with specific indices:</p><pre><code>int sum(Span&lt;int&gt; span)
{
  int sum = 0;
  for (int i = 0; i &lt; span.Length; i++)
  {
    sum += span[i];
  }
  return sum;
}</code></pre><p>For instance you can call this function with <code>sum(array)</code> or you can call it with a sub-view of an array like <code>sum(array[startIndex..endIndex])</code>. That wouldn't incur new bounds-checking operations other than when you're trying to slice the array using the range operator. See how the generated assembly code for <code>sum</code> becomes optimized again:</p><pre><code>L0000	mov	rax, [rcx]
L0003	mov	ecx, [rcx+8]
L0006	xor	edx, edx            ; sum = 0
L0008	xor	r8d, r8d            ; i = 0
L000b	test	ecx, ecx		; span.Length == 0?
L000d	jle	short L001e
L000f	mov	r10d, r8d
L0012	add	edx, [rax+r10*4]    ; sum += span[i]
L0016	inc	r8d                 ; i++
L0019	cmp	r8d, ecx            ; i &lt; Length?
L001c	jl	short L000f         ; then keep looping
L001e	mov	eax, edx            
L0020	ret						; return sum</code></pre><p>Another superpower you get is that the ability to declare the data structure you receive immutable in your function signature, so your function is guaranteed not to touch it, and you can find bugs instantly. All you need to do is to replace <code>Span&lt;T&gt;</code> with <code>ReadOnlySpan&lt;T&gt;</code>. Then your attempts to modify the span contents will immediately cause a compiler error. Something impossible with regular arrays, even if you declare them <code>readonly</code>. The <code>readonly</code> directive only protects the reference from modification not the contents of the data structure.</p><p>Passing along a smaller portion of a larger data structure to relevant APIs used to involve either copying or passing the relevant part's offset and length values along with that data structure. It required the API to support calls with larger structures with offsets. It was impossible to guarantee the safety of such APIs as the relationship between parameters couldn't be established by the compiler or the runtime.</p><p>It's now both easy and expressive to implement zero-copy operations safely using spans. Consider a <a href="https://en.wikipedia.org/wiki/Quicksort?ref=ssg.dev" rel="noreferrer">Quicksort</a> implementation for instance; it usually has a function like this that works with portions of a given array:</p><pre><code>int partition(int[] array, int low, int high)
{
  int midpoint = (high + low) / 2; // I know, we'll get there!
  int mid = array[midpoint];

  // tuple swaps in C#! ("..^1" means "Length - 1")
  (array[midpoint], array[^1]) = (array[^1], array[midpoint]);
  int pivotIndex = 0;
  for (int i = low; i &lt; high - 1; i++)
  {
     if (array[i] &lt; mid)
     {
       swap(array, i, pivotIndex);
       pivotIndex += 1;
     }
  }
  (array[midpoint], array[endpoint]) = (array[endpoint], array[midpoint]);
  return pivotIndex;
}</code></pre><p>This function receives an array and offsets that designate a part of it, and rearranges the items based on a picked value in it. Values smaller than it move to the left, larger than it move to the right.</p><p>The <code>mid = array[midpoint]</code> has to be bounds-checked because the compiler can't know if the index is inside the bounds of this array. The <code>for</code> loop also performs bounds-check for array accesses in the loop, which some of them can be eliminated, but not fully guaranteed. </p><p>There is also an overflow error because we pass array ranges using <code>high</code> and <code>low</code> values: <code>(high+low)</code> can overflow for very large arrays, and the results would be catastrophic, can even cause buffer overflow exceptions.</p><p>The <code>partition</code> function gets recursively called many times by <code>Quicksort</code> function below, so that means bounds-checking can be a performance issue. </p><pre><code>void Quicksort(int[] array, int low, int high)
{
  if (array.Length &lt;= 1)
  {
    return;
  }

  int pivot = partition(array, low, high);
  Quicksort(span, low, pivot - 1);
  Quicksort(span, pivot + 1, high);
}</code></pre><p>With spans, the same Quicksort function looks like this:</p><pre><code>void Quicksort(Span&lt;int&gt; span)
{
  if (span.Length &lt;= 1)
  {
    return;
  }

  int pivot = partition(span);
  Quicksort(span[..pivot]);
  Quicksort(span[(pivot + 1)..]);
}</code></pre><p>See how expressive using spans are especially with the range syntax? It lets you get a new span out of an existing span or an array using double dots (<code>..</code>)? And the partition function even looks much better too:</p><pre><code>int partition(Span&lt;int&gt; span)
{
  int midpoint = span.Length / 2; // look ma, no buffer overflows!
  int mid = span[midpoint];
  (span[midpoint], span[^1]) = (span[^1], span[midpoint]);
  int pivotIndex = 0;
  for (int i = 0; i &lt; span.Length - 1; i++)
  {
     if (span[i] &lt; mid)
     {
       swap(array, i, pivotIndex);
       pivotIndex += 1;
     }
  }
  (span[midpoint], span[^1]) = (span[^1], span[midpoint]);
  return pivotIndex;
}</code></pre><p>Because C# spans are also zero-based, it's harder to have buffer overflow problems caused by formulae like <code>(low + high) / 2</code>. Now, the implementation is as fast as an unsafe implementation with raw pointers, but still extremely safe.</p><h2 id="new-zero-copy-operations-in-net-runtime">New zero-copy operations in .NET runtime</h2><p>I used a recursive example here to show how sub-portions of a larger data structure can be passed to another function, but spans can be used almost everywhere, and now .NET runtime supports zero-copy alternatives of popular functions too.</p><p>Take <code>String.Split</code> for example. You can now split a string without creating new copies of every split portion of the string. You can split a CSV line into its parts like this:</p><pre><code>string csvLine = // .. read CSV line
string[] parts = csvLine.Split(',');

foreach (string part in parts)
{
  Console.WriteLine(part);
}</code></pre><p>The problem with that is, now you're dealing with newly created 5 buffers with varying lengths. .NET allocates new memory for them, GC keeps track of them. It's slow, it hogs memory. It's problematic especially in loops, and can create GC pressure, slowing your app even more.</p><p>You can instead cast your CSV line into a <code>ReadOnlySpan&lt;char&gt;</code> and iterate over its components to write it to the output:</p><figure><pre><code>string csvLine = // .. read CSV line

var span = csvLine.AsSpan();
var parts = span.Split(',');
foreach (var range in parts)
{
  Console.Out.WriteLine(span[range]);
}</code></pre><figcaption><p dir="ltr"><span>Note that we use a small detour to use </span><code spellcheck="false"><span>Console.Out.WriteLine</span></code><span> instead of </span><code spellcheck="false"><span>Console.WriteLine</span></code><span> because </span><code spellcheck="false"><span>Console</span></code><span> class lacks an overload to output a </span><code spellcheck="false"><span>ReadOnlySpan&lt;char&gt;</span></code><span> like a string.</span></p></figcaption></figure><p>The great ROI of that experiment is making zero memory allocations after reading CSV line into memory. A similar logic that improves performance and memory efficiency can be applied everywhere that can receive a <code>Span&lt;T&gt;</code>/<code>ReadOnlySpan&lt;T&gt;</code> instead of an array.</p><h2 id="embrace-the-future">Embrace the future</h2><p>Spans and slice-like structures in are the future of safe memory operations in modern programming languages. Embrace them. The quick takeaways are: </p><ul><li>Use spans over arrays in your function declarations unless you explicitly require a standalone array in your function for some reason. Such a change opens your API into zero-copy optimization scenarios, and calling code will be more expressive.</li><li>Don't bother with unsafe/pointers if you can code the same logic with spans. You can still perform low-level memory operations without wandering into the dangerous parts of the forest. Your code will still be fast, and yet safer.</li></ul><p>Use spans, wherever possible, mostly readonly.</p>
        </section></div>]]></description>
        </item>
    </channel>
</rss>