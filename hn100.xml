<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 29 Jun 2024 15:30:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[A Bunch of Programming Advice I'd Give to Myself 15 Years Ago (200 pts)]]></title>
            <link>https://mbuffett.com/posts/programming-advice-younger-self/</link>
            <guid>40829607</guid>
            <pubDate>Sat, 29 Jun 2024 11:38:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://mbuffett.com/posts/programming-advice-younger-self/">https://mbuffett.com/posts/programming-advice-younger-self/</a>, See on <a href="https://news.ycombinator.com/item?id=40829607">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><div><p>I finally have the feeling that I’m a decent programmer, so I thought it would be fun to write some advice with the idea of “what would have gotten me to this point faster?” I’m not claiming this is great advice for everyone, just that it would have been good advice for me.</p><p>I can’t tell you how many times I’ve been on a team and there’s something about the system that’s very easy to screw up, but no one thinks about ways to make it harder to make that mistake.</p><p>When I was doing iOS development, we were using CoreData, and subscribed to changes in the store in a bunch of views. The subscription callback came on the same thread that the change was triggered from. So sometimes that was the main thread, and sometimes it was a background thread. Importantly in iOS development, you can only make UI updates on the main thread. So a new change handler could be working fine, but then it would break when someone triggered a change from a background thread, or if you add a UI update later on.</p><p>This was just something people transparently accepted, and often came up in reviews for newer people on the team. Then every now and then it would slip through and we’d go add a <code>DispatchQueue.main.async</code> when we saw the crash report.</p><p>I decided to fix it, and it took ten minutes to update our subscription layer to call subscribers on the main thread instead, which eliminated a whole class of crashes and removed mental load.</p><p>I’m not trying to be like “look at these idiots not fixing an obvious issue with the codebase, it was obvious to me”, because it would have been obvious to anyone who thought about it for a few minutes. These things stick around a weird amount, because there’s never a natural time to address them. When you’re first getting onboarded, you’re not trying to change anything big, so you may think it’s weird but you shouldn’t go changing a bunch of things you’re still learning about. Then when you’ve been on the team for a while, it sort of fades into the background.</p><p>It’s a mindset shift. You just need to occasionally remind yourself that you are capable of making you and your team’s life easier, when these sorts of things are hanging around.</p><h2 id="assess-the-trade-off-youre-making-between-quality-and-pace-make-sure-its-appropriate-for-your-context">Assess the trade-off you’re making between quality and pace, make sure it’s appropriate for your context</h2><p>There’s always a trade-off between implementation speed and how confident you are about correctness. So you should ask yourself: how okay is it to ship bugs in my current context? If the answer to this doesn’t affect the way you work, you’re being overly inflexible.</p><p>At my first job, I was working on greenfield projects around data processing, which had good systems in place to retroactively re-process data. The impact of shipping a bug was very minor. The proper response to an environment like that is to rely on the guardrails a bit, move faster because you can. You don’t need 100% test coverage or an extensive QA process, which will slow down the pace of development.</p><p>At my second company, I was working on a product used by tens of millions of people, which involved lots of high-value financial data and personally identifiable information. Even a small bug would entail a post-mortem. I shipped features at a snail’s pace, but I also think I may have shipped 0 bugs that year.</p><p>Usually, you’re not at the second company. I’ve seen a lot of devs err on the side of that sort of programming though. In situations where bugs aren’t mission critical (ex. 99% of web apps), you’re going to get further with shipping fast and fixing bugs fast, than taking the time to make sure you’re shipping pristine features on your first try.</p><h2 id="spending-time-sharpening-the-axe-is-almost-always-worth-it">Spending time sharpening the axe is almost always worth it</h2><p>You’re going to be renaming things, going to type definitions, finding references, etc <em>a lot</em>; you should be fast at this. You should know all the major shortcuts in your editor. You should be a confident and fast typist. You should know your OS well. You should be proficient in the shell. You should know how to use the browser dev tools effectively.</p><p>I can already tell people are gonna be in the comments like “you can’t just spend all day tweaking your neovim config, sometimes you need to chop the tree too”. I don’t think I’ve ever seen someone actually overdo this though; one of the biggest green flags I’ve seen in new engineers is a level of care in choosing and becoming proficient with their tools.</p><h2 id="if-you-cant-easily-explain-why-something-is-difficult-then-its-incidental-complexity-which-is-probably-worth-addressing">If you can’t easily explain why something is difficult, then it’s incidental complexity, which is probably worth addressing</h2><p>My favorite manager in my career had a habit of pressing me when I would claim something was difficult to implement. Often his response was something along the lines of “isn’t this just a matter of sending up X when we Y”, or “isn’t this just like Z that we did a couple months ago”? Very high level objections, is what I’m trying to say, not on the level of the actual functions and classes we were dealing with, which I was trying to explain.</p><p>I think conventional wisdom is that it’s just annoying when managers simplify things like this. But a shockingly high percentage of the time, I’d realize when he was pressing me, that most of the complexity I was explaining was incidental complexity, and very often you can address this sort of incidental complexity. It won’t just trivialize the current problem, it will make future changes easier too.</p><h2 id="try-to-solve-bugs-one-layer-deeper">Try to solve bugs one layer deeper</h2><p>Imagine this. You have a React component in a dashboard, that deals with a <code>User</code> object retrieved from state, of the currently logged in user. You see a bug report in Sentry that the <code>User</code> was <code>null</code> during render. You could add a quick <code>if (!user) return null</code> to it. Or you could investigate a bit more, and find that your logout function makes two distinct state updates, the first to set the user to <code>null</code>, the second to redirect to the homepage. You swap the two, and now no component will ever have this bug again, because the user object is never be <code>null</code> while you’re within the dashboard.</p><p>Keep doing the first sort of bug fix, and you end up with a mess. Keep doing the second type of bug fix, and you’ll have a clean system and a deep understanding of the invariants.</p><h2 id="dont-underestimate-the-value-of-digging-into-history-to-investigate-some-bugs">Don’t underestimate the value of digging into history to investigate some bugs</h2><p>I’ve always been pretty good at debugging weird issues, with the usual toolkit of <code>println</code> and the debugger. So I never really looked at git much to figure out the history of a bug. But for some bugs it’s crucial.</p><p>I recently had an issue with my server where it was leaking memory seemingly constantly, and then getting OOM-killed and restarted. I couldn’t figure out the cause of this for the life of me. Every likely culprit was ruled out, I couldn’t reproduce it locally, it felt like throwing darts blindfolded. I looked at the commit history, and found it started happening after I added support for Play Store payments. Never a place I would have looked in a million years, it’s just a couple http requests. Turns out it was getting stuck in an infinite loop of fetching access tokens, after the first one expired. Maybe every request only added a kB or so to memory, but when they’re retrying every 10ms on multiple threads, that adds up quick. And usually this sort of thing would have resulted in a stack overflow, but I was using async recursion in Rust, which doesn’t stack overflow. This <em>never</em> would have occurred to me, but when I’m forced to look into a specific bit of code that I know <em>must</em> have caused it, suddenly the theory pops up.</p><p>I’m not sure what the rule is here for when to do this and when not to. It’s intuition based, a different sort of “huh” to a bug report that triggers this sort of investigation. You’ll develop the intuition over time, but it’s enough to know that sometimes it’s invaluable, if you’re stuck.</p><p>Along similar lines, try out <code>git bisect</code> if the problem is amenable to it — meaning a git history of small commits, a quick automated way to test for the issue, and you have one commit you know is bad and one that’s good.</p><h2 id="bad-code-gives-you-feedback-perfect-code-doesnt-err-on-the-side-of-writing-bad-code">Bad code gives you feedback, perfect code doesn’t. Err on the side of writing bad code</h2><p>It’s really easy to write terrible code. But it’s also really easy to write code that follows absolutely every best practice, with 100% test coverage, and has been fuzz-tested and mutation-tested for good measure – your startup will just run out of money before you finish. So a lot of programming is figuring out the balance.</p><p>If you err on the side of writing code quickly, you’ll occasionally get bitten by a bad bit of tech debt. You’ll learn stuff like “I should add great testing for data processing, because it’s often hard or impossible to correct later”, or “I should really think through table design, because changing things without downtime can be extremely hard”.</p><p>If you err on the side of writing perfect code, you don’t get any feedback. Things just universally take a long time. You don’t know where you’re spending your time on things that really deserve it, and where you’re wasting time. Feedback mechanisms are essential for learning, and you’re not getting that.</p><p>To be clear I don’t mean bad as in “I couldn’t remember the syntax for creating a hash map, so I did two inner loops instead”, I mean bad as in:</p><blockquote><p>Instead of a re-write of our data ingestion to make this specific state unrepresentable, I added a couple asserts over our invariants, at a couple key checkpoints</p></blockquote><blockquote><p>Our server models are exactly the same as the DTOs we would write, so I just serialized those, instead of writing all the boilerplate, we can write DTOs as needed later if needed</p></blockquote><blockquote><p>I skipped writing tests for these components because they’re trivial and a bug in one of them is no big deal</p></blockquote><h2 id="make-debugging-easier">Make debugging easier</h2><p>There’s so many little tricks I’ve acquired over the years on making software easier to debug. If you don’t make any effort to make debugging easy, you’re going to spend unacceptable amounts of time debugging each issue, as your software gets more and more complex. You’ll be terrified to make changes because even a couple new bugs might take you a week to figure out.</p><p>Here’s some examples of what I mean:</p><ul><li>For the backend of Chessbook<ul><li>I have a command to copy all of a user’s data down to local, so I can reproduce issues easily with only a username</li><li>I trace every local request with OpenTelemetry, making it very easy to see how a request spends its time</li><li>I have a scratch file that acts as a pseudo-REPL, which re-executes on every change. This makes it easy to pull out bits of code and play around with it to get a better idea what’s going on</li><li>In the staging environment, I limit parallelism to 1, so that it’s easier to visually parse logs</li></ul></li><li>For the frontend<ul><li>I have a <code>debugRequests</code> setting which prevents optimistic loading of data, to make it easier to debug requests</li><li>I have a <code>debugState</code> setting that will print out the entire state of the program after every update, along with a pretty diff of what changed</li><li>I have a file full of little functions that get the UI into specific states, so that as I’m trying to fix bugs, I don’t have to keep clicking in the UI to get to that state.</li></ul></li></ul><p>Stay vigilant about how much of your debugging time is spent on setup, reproduction, and cleanup afterwards. If it’s over 50%, you should figure out how to make it easier, even if that will take slightly longer this time. Bugs should get <em>easier</em> to fix over time, all else being equal.</p><h2 id="when-working-on-a-team-you-should-usually-ask-the-question">When working on a team, you should usually ask the question</h2><p>There’s a spectrum of “trying to figure out everything for yourself” to “bugging your coworkers with every little question”, and I think most people starting their careers are too far on the former side. There’s always someone around that has been in the codebase longer, or knows technology X way better than you, or knows the product better, or is just a more experienced engineer in general. There’s so many times in the first 6 months of working somewhere, where you could spend over an hour figuring something out, or you could get an answer in a few minutes.</p><p>Ask the question. The only time this will be annoying to anyone, is if it’s clear you could have found the answer yourself in a few minutes.</p><h2 id="shipping-cadence-matters-a-lot-think-hard-about-what-will-get-you-shipping-quickly-and-often">Shipping cadence matters a lot. Think hard about what will get you shipping quickly and often</h2><p>Startups have limited runway. Projects have deadlines. When you quit your job to strike out on your own, your savings will only last you for so many months.</p><p>Ideally, your speed on a project only compounds over time, until you’re shipping features faster than you could have imagined. To ship fast you need a lot of things:</p><ul><li>A system that isn’t prone to bugs</li><li>Quick turnaround time between teams</li><li>A willingness to cut out the 10% of a new feature that’s going to take 50% of the engineering time, and the foresight to know what those pieces are</li><li>Consistent reusable patterns, that you can compose together for new screens/features/endpoints</li><li>Quick, easy deploys</li><li>Process that doesn’t slow you down; flaky tests, slow CI, fussy linters, slow PR reviews, JIRA, etc.</li></ul><p>Shipping slowly should merit a post-mortem as much as breaking production does. Our industry doesn’t run like that, but that doesn’t mean you can’t personally follow the north star of Shipping Fast.</p></div></article><div><p>Thanks for reading! If you have any questions, comments, or just want to say hi,
please email me at <a href="mailto:me@mbuffett.com">me@mbuffett.com</a>. Online, I'm
most active <a href="https://twitter.com/MarcusBuffett">on twitter</a>.</p><p>If you're into chess, I've made a <a href="https://chessbook.com/">repertoire builder</a>. It uses statistics from
hundreds of millions of games at your level to find the gaps in your
repertoire, and uses spaced repetition to quiz you on them.</p><p>Samar Haroon, my girlfriend, has started a podcast where she talks about the
South Asian community, from the perspective of a psychotherapist.
<a href="https://open.spotify.com/show/7teSzaHt5I3r9s5PPLZFrF?si=J1-h-uFCTLyXGPbZnYSIGQ" target="_blank">Go check it out!</a>.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How I overcame my addiction to sugar (108 pts)]]></title>
            <link>https://josem.co/how-i-overcame-my-addiction-to-sugar/</link>
            <guid>40829312</guid>
            <pubDate>Sat, 29 Jun 2024 10:52:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://josem.co/how-i-overcame-my-addiction-to-sugar/">https://josem.co/how-i-overcame-my-addiction-to-sugar/</a>, See on <a href="https://news.ycombinator.com/item?id=40829312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><div><p><picture><source srcset="https://josem.co/images/2024/sugar-cookies@2x.webp 2x, https://josem.co/images/2024/sugar-cookies.webp" type="image/webp"><img src="https://josem.co/images/2024/sugar-cookies.jpg" alt="Baked Cookies And Glass Of Milk" decoding="async" data-sizes="auto">
</picture><em>Photo by <a href="https://www.pexels.com/@suzyhazelwood/" rel="noopener" target="_blank">Suzy Hazelwood</a></em></p><p>I remember my breakfast as a kid. It was as sugary as it gets, with cereal and milk or a good marmalade toast and a chocolate shake to start my day.</p><p>I remember the highs and lows of my energy levels throughout the day or how I would look in the mirror and wonder why I grew as a chubby kid instead of thinner and stronger like some friends.</p><p>I had no idea what a good diet looked like, and without any good examples to follow in my environment, I was pretty deep into an addiction that has been hard to defeat in my adulthood.</p><p>The problem with sugar, apart from being <a href="https://www.healthline.com/health/food-nutrition/experts-is-sugar-addictive-drug" rel="noopener" target="_blank">very addictive</a>, is that I used it as a gateway.</p><p>Later in my adult life, when I felt stressed or overwhelmed, I drank a glass of milk and cookies and watched a movie at night. Somehow, the immediate pleasure of the taste was enough to make me forget about my problems. I felt better, even if it was just for a few minutes.</p><p>When I didn’t have anything sugary at home to eat, I had to go to the supermarket, sometimes at embarrassingly late hours, to buy some cookies or a sponge cake.</p><p>At some point in my early twenties, overweight and tired, I accepted I had a problem. I also learned that sugar is very addictive. So, I made a decision—no more added sugar in my diet.</p><p>I cannot count how many times I’ve succumbed again to the addiction. These episodes, and how long they lasted, were thankfully less frequent and shorter over time, but it wasn’t a straight line from point A to point B.</p><p>Thankfully, I’m in a much better position after countless drawbacks. I still have some added sugar here and there, like a dessert on a special occasion, but it’s far from my previous daily consumption levels.</p><p>I’d say there are perhaps three aspects that helped me overcome my addiction.</p><h2 id="1-change-of-environment">1. Change of environment</h2><p>In 1971, the public knew that many soldiers in the Vietnam War were addicted to heroin. Authorities run tests to see who was addicted before returning home and then after the first, second, and third years. The results were surprisingly positive.</p><p>Of all the men addicted in Vietnam, only 12% relapsed to addiction in the three years after returning home—almost 90% of the recovery rate.</p><p>The main conclusion from the <a href="https://findings.org.uk/PHP/dl.php?f=Robins_LN_3.cab" rel="noopener" target="_blank">study</a> is that a change of environment as radical as Vietnam’s during a war period compared to the US was critical for their recovery.</p><p>I used this principle by taking some long vacations in the summer to stop eating sugar. I wasn’t at home and had a different schedule, but I’m sure it made things easier.</p><p>When I came back, I moved to the second step.</p><h2 id="2-removing-the-possibility">2. Removing the possibility</h2><p>Not having anything sugary around the house made it easier not to take it. Of course, I could still buy it, but it was easier not to do it.</p><p>When I returned from my trip, my fridge was empty, so I resisted the temptation to buy those products. This was a one-time challenge compared to the ongoing fight I would have endured if I had something at home.</p><h2 id="3-influential-habits">3. Influential habits</h2><p>Like water overflowing a vase and filling other vases around it, some habits have a positive rippling effect on your life.</p><p>For example, after a good strength session at the gym, I didn’t want to have anything sugary, and overall, I was prone to eat healthier because my body needed more protein and good energy. Or if I drank enough water, I felt full and ate less overall.</p><p>So, another thing I implemented was a good schedule for visiting the gym regularly, drinking enough water, and living an active lifestyle.</p><hr><p>I wish this could help someone out there struggling with the same problem. I can see sugar addiction is very common, even though many people don’t even think about it, but it is still bad for you and your freedom.</p><p>Good luck if you’re struggling with something similar; you’ve got this!</p><p>Until next time.</p></div></article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[It's not just you, Next.js is getting harder to use (128 pts)]]></title>
            <link>https://www.propelauth.com/post/nextjs-challenges</link>
            <guid>40828610</guid>
            <pubDate>Sat, 29 Jun 2024 08:00:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.propelauth.com/post/nextjs-challenges">https://www.propelauth.com/post/nextjs-challenges</a>, See on <a href="https://news.ycombinator.com/item?id=40828610">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
        <p>I wrote a blog post the other day about how Next.js Middleware can be useful for working around some of the <a href="https://www.propelauth.com/post/getting-url-in-next-server-components?ref=propelauth.com">restrictions imposed by server components</a>. This led to some fun discussions in the world about whether this was a reasonable approach or if Next.js DX was just... <a href="https://github.com/vercel/next.js/discussions/65385?ref=propelauth.com">bad</a>.</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Screen-Shot-2024-05-14-at-9.02.53-AM.png" alt="" loading="lazy" width="916" height="498"></figure><p>From my perspective, Next.js’ App Router has two major problems that make it difficult to adopt:</p><ul><li>You need to understand a lot about the internals to do seemingly basic tasks.</li><li>There are many ways to shoot yourself in the foot that are opt-out instead of opt-in.</li></ul><p>To understand this better, let’s look at its predecessor, the Pages Router.</p><h2 id="a-quick-look-at-the-pages-router">A quick look at the Pages Router</h2><p>When I first learned about Next.js, the main “competitor” was Create React App (CRA). I was using CRA for all my projects, but I switched to Next.js for two reasons:</p><ul><li>I liked file-based routing because it allowed me to write less boilerplate code.</li><li>Whenever I ran the dev server, CRA would open <a href="http://localhost:3000/?ref=propelauth.com">http://localhost:3000</a> (which gets annoying fast), and Next.js didn’t.</li></ul><p>The second one is maybe a little silly, but to me, Next.js was:</p><p><strong>React with better defaults.</strong></p><p>And that’s all I really wanted. It wasn’t until later that I discovered the other features Next.js had. API routes were exciting as they gave me a serverless function without setting up any extra infra - super handy for things like “Contact Us” forms on a marketing site. <code>getServerSideProps</code> allowed me to run basic functions on the server before the page loaded.</p><p>Those concepts were powerful, but they were also <strong>simple</strong>.</p><p>An API route looked and acted a lot like every other route handler. If you had used Express or Cloudflare Workers, you can squint at a route handler and all the concepts you already knew translated. <code>getServerSideProps</code> was a little different, but once you understood how to get a <code>request</code> and the format of the response, it turned out to be pretty straightforward too.</p><h2 id="the-app-router-release">The App Router release</h2><p>The Next 13 release introduced the <a href="https://nextjs.org/docs/app?ref=propelauth.com">App Router</a>, adding many new features. You had <a href="https://nextjs.org/docs/app/building-your-application/rendering/server-components?ref=propelauth.com">Server Components</a> which allowed you to render your React components on the server and reduce the amount of data you needed to send to your client.</p><p>You had&nbsp;<a href="https://nextjs.org/docs/app/building-your-application/routing/layouts-and-templates?ref=propelauth.com">Layouts</a>, which allowed you to define aspects of your UI shared by multiple routes and didn’t need to be re-rendered on every navigation.</p><p>Caching got… <a href="https://nextjs.org/docs/app/building-your-application/caching?ref=propelauth.com">more sophisticated</a>.</p><p>And while these features were interesting, the biggest loss was <strong>simplicity</strong>.</p><h2 id="when-a-framework-doesn%E2%80%99t-do-what-you-think-it-will-do">When a framework doesn’t do what you think it will do</h2><p>A fairly universal experience as a developer is banging your head against the wall and yelling, “Why does this not work?”</p><p>Everyone’s been there, and it always sucks. For me, it’s even more painful if it feels like it’s not a bug in my code but a misunderstanding of how things are supposed to work.</p><p>You are no longer yelling, “Why does this not work?” but rather, “Why does this work… like <em>that</em>?”</p><p>The App Router, unfortunately, is full of these kinds of subtleties.</p><p>Let’s look back at my original issue: I just want to get the URL in a Server Component. <a href="https://github.com/vercel/next.js/issues/43704?ref=propelauth.com#issuecomment-2090798307">Here’s an answer</a> to a popular Github issue about the topic, and I’ll post part of it here:</p><blockquote>If we take a step back, the question "Why can't I access&nbsp;<code>pathname</code>&nbsp;or current URL?" is part of a bigger question: "Why can't I access the complete&nbsp;<strong>request and response objects</strong>?"<p>Next.js is both a&nbsp;<strong>static</strong>&nbsp;and&nbsp;<strong>dynamic</strong>&nbsp;rendering framework that splits work into route segments. While exposing the request/response is very powerful, these objects are inherently&nbsp;<strong>dynamic</strong>&nbsp;and affect the entire route. This limits the framework's ability to implement current (caching and streaming) and future (Partial Prerendering) optimizations.</p><p>To address this challenge, we considered exposing the request object and tracking where it's being accessed (e.g. using a proxy). But this would make it harder to track how the methods were being used in your code base, and could lead developers to unintentionally opting into dynamic rendering.</p><p>Instead, we exposed specific methods from the Web Request API, unifying and optimizing each for usage in different contexts: Components, Server Actions, Route Handlers, and Middleware. These APIs allow the developer to explicitly opt into framework heuristics like dynamic rendering, and makes it easier for Next.js to track usage, breaking the work, and optimizing as much as possible.</p><p>For example, when using&nbsp;<a href="https://nextjs.org/docs/app/api-reference/functions/headers?ref=propelauth.com"><code>headers</code></a>, the framework knows to opt into dynamic rendering to handle the request. Or, in the case of&nbsp;<a href="https://nextjs.org/docs/app/api-reference/functions/cookies?ref=propelauth.com">cookies</a>, you can read cookies in the React render context, but only set cookies in a mutation context (e.g. Server Actions and Route Handlers) because cookies cannot be set once streaming starts.</p></blockquote><p>For what it’s worth, this response is incredible. It’s well written, it helps me understand a lot of the underlying issues, and it gives me insight into the tradeoffs associated with different approaches that I absolutely didn’t think about.</p><p>That being said, if you are a developer and all you are trying to do is get the URL in a Server Component, you probably read this and left with 5 more things to Google before realizing you probably have to restructure your code.</p><p>This post summarizes my feelings about it:</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Screen-Shot-2024-05-14-at-1.42.51-AM.png" alt="" loading="lazy" width="860" height="124"></figure><p>It’s not that it’s necessarily incorrect - it’s unexpected.</p><p>That original post also mentioned a few other subtleties. One common footgun is in how <a href="https://www.propelauth.com/post/cookies-in-next-js?ref=propelauth.com">cookies are handled</a>. You can call <code>cookies().set("key", "value")</code> anywhere and it will type-check, but in some cases it will fail at runtime.</p><p>Compare these to the “old” way of doing things where you got a big <code>request</code> object and could do anything you wanted on the server, and it’s fair to say that there’s been a jump in complexity.</p><p>I also need to point out that the “on-by-default” aggressive caching is a rough experience. I’d argue that way more people expect to opt-in to caching rather than dig through a lot of documentation to figure out how to opt-out.</p><p>I’m sure other companies had similar issues to us, but at <a href="https://www.propelauth.com/?ref=propelauth.com">PropelAuth</a> we often got bug reports that weren’t bugs but amounted to “You thought you made an API call, but you didn’t, and you are just reading a cached result.”</p><p>And all of this begs the question, who are these features and optimizations for?</p><h2 id="it%E2%80%99s-very-hard-to-build-a-one-size-fits-all-product">It’s very hard to build a one-size-fits-all product</h2><p>All of these features that I’m painting as overly complex do matter for some people. If you are building an e-commerce platform, for example, there are some great features here.</p><p>Your pages load faster because you send less data to the client. Your pages load faster because everything is aggressively cached. Your pages load faster because only parts of the page need to re-render when the user navigates to a new page. And in the e-commerce world, faster page loads means more money, so you would absolutely take the tradeoff of a more complex framework for them.</p><p>But if I’m building a dashboard for my SaaS application… I don’t really care about any of that. I care way more about the speed at which I ship features, and all that complexity becomes a burden on my dev team.</p><p>My personal experience and frustrations with the App Router will be different than another person’s because we have different products, different use cases, and different resources. Speaking specifically as a person who spends a lot of time writing and helping other people write B2B SaaS applications, the App Router DX is a big step down from the Pages Router.</p><h2 id="is-this-inevitable-for-frameworks-as-they-grow">Is this inevitable for frameworks as they grow?</h2><p>As products/frameworks grow, they tend to get more complicated. Customers ask for more things. Bigger customers ask for more specific things. Bigger customers pay more so you prioritize and build those more specific things.</p><p>Customers who previously loved the simplicity of it all get annoyed at how complicated things feel and… oh, look at that, a new framework has popped up that’s way simpler. We should all switch to that!</p><p>It’s challenging to avoid this, but one way to mitigate it is to not make everyone deal with the complexity that only some people need.</p><h2 id="just-because-something-is-recommended-doesn%E2%80%99t-mean-it%E2%80%99s-right-for-you">Just because something is recommended, doesn’t mean it’s right for you</h2><p>One of my biggest issues with the App Router was just this:</p><figure><img src="https://cdn.getmidnight.com/a1241f0fcb8d83a4c0387f234e241914/2024/05/Untitled-design--15---1-.png" alt="" loading="lazy" width="598" height="148"></figure><p>Next.js has officially recommended that you use the App Router since before it was honestly ready for production use. Next.js doesn’t have a recommendation on whether TypeScript, ESLint, or Tailwind are right for your project (despite providing defaults of Yes on TS/ESLint, No to Tailwind - sorry Tailwind fans), but absolutely believes you should be using the App Router.</p><p>The <a href="https://react.dev/learn/start-a-new-react-project?ref=propelauth.com">official React docs</a> don’t share the same sentiment. They currently recommend the Pages Router and describe the App Router as a “Bleeding-edge React Framework.”</p><p>When you look at the App Router through that lens, it makes way more sense. Instead of thinking of it as the recommended default for React, you can think of it more <a href="https://twitter.com/dan_abramov2/status/1752721357614301690?ref=propelauth.com">like a beta release</a>. The experience is more complicated and <a href="https://github.com/vercel/next.js/discussions/41934?ref=propelauth.com">some things that were easy are now hard/impossible</a>, but what else would you expect from something that’s still “Bleeding-edge?”</p><p>So when you are picking a framework for your next project, it’s worth recognizing that there are still many rough edges in the App Router. You might have better luck reaching for a different tool that’s more suited to your use case.</p>
    </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Hex Editor for Reverse Engineers (172 pts)]]></title>
            <link>https://github.com/WerWolv/ImHex</link>
            <guid>40828493</guid>
            <pubDate>Sat, 29 Jun 2024 07:25:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/WerWolv/ImHex">https://github.com/WerWolv/ImHex</a>, See on <a href="https://news.ycombinator.com/item?id=40828493">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><a href="https://imhex.werwolv.net/" rel="nofollow">
  </a><div dir="auto"><a><h2 tabindex="-1" dir="auto">
    <themed-picture data-catalyst-inline="true"><picture>
      <img height="300px" src="https://github.com/WerWolv/ImHex/raw/master/resources/dist/common/logo/ImHexLogoSVGBG.svg">
    </picture></themed-picture>
  </h2></a><a id="user-content-----------------" aria-label="Permalink: " href="#----------------"></a></div>

<p dir="auto">
    A Hex Editor for Reverse Engineers, Programmers and people who value their retinas when working at 3 AM.
    <br>
    <a href="https://itinerarium.github.io/phoneme-synthesis/?w=/%27%CB%88%C9%AAmh%C9%9Bks/" rel="nofollow"><strong>/ˈɪmhɛks/</strong></a>
</p>
<p dir="auto">
  <a title="'Build' workflow Status" href="https://github.com/WerWolv/ImHex/actions?query=workflow%3ABuild"><img alt="'Build' workflow Status" src="https://camo.githubusercontent.com/e9a6ae94be01ad1c78c2c9e019608c852de5139cf76f710dd4e328798899b33e/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f576572576f6c762f496d4865782f6275696c642e796d6c3f6c6f6e6743616368653d74727565267374796c653d666f722d7468652d6261646765266c6162656c3d4275696c64266c6f676f436f6c6f723d666666266c6f676f3d476974487562253230416374696f6e73266272616e63683d6d6173746572" data-canonical-src="https://img.shields.io/github/actions/workflow/status/WerWolv/ImHex/build.yml?longCache=true&amp;style=for-the-badge&amp;label=Build&amp;logoColor=fff&amp;logo=GitHub%20Actions&amp;branch=master"></a>
  <a title="Discord Server" href="https://discord.gg/X63jZ36xBY" rel="nofollow"><img alt="Discord Server" src="https://camo.githubusercontent.com/602a6aa02ff3f01178d6a266a9498e2933ae5852a69569d43d82c08d556ca242/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f3738393833333431383633313637353935343f6c6162656c3d446973636f7264266c6f676f3d446973636f7264266c6f676f436f6c6f723d666666267374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/discord/789833418631675954?label=Discord&amp;logo=Discord&amp;logoColor=fff&amp;style=for-the-badge"></a>
  <a title="Total Downloads" href="https://github.com/WerWolv/ImHex/releases/latest"><img alt="Total Downloads" src="https://camo.githubusercontent.com/80c94ed6d0f0923b4144dc9a917ccf632378e3bf1cc7548d24bd5d09c8805cf8/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f646f776e6c6f6164732f576572576f6c762f496d4865782f746f74616c3f6c6f6e6743616368653d74727565267374796c653d666f722d7468652d6261646765266c6162656c3d446f776e6c6f616473266c6f676f436f6c6f723d666666266c6f676f3d476974487562" data-canonical-src="https://img.shields.io/github/downloads/WerWolv/ImHex/total?longCache=true&amp;style=for-the-badge&amp;label=Downloads&amp;logoColor=fff&amp;logo=GitHub"></a>
  <a title="Code Quality" href="https://www.codefactor.io/repository/github/werwolv/imhex" rel="nofollow"><img alt="Code Quality" src="https://camo.githubusercontent.com/327679fea33c2c0518bd8391cae3c55b44c31276ddc073f8279b3a2061f2a26c/68747470733a2f2f696d672e736869656c64732e696f2f636f6465666163746f722f67726164652f6769746875622f576572576f6c762f496d4865783f6c6f6e6743616368653d74727565267374796c653d666f722d7468652d6261646765266c6162656c3d436f64652532305175616c697479266c6f676f436f6c6f723d666666266c6f676f3d436f6465466163746f72266272616e63683d6d6173746572" data-canonical-src="https://img.shields.io/codefactor/grade/github/WerWolv/ImHex?longCache=true&amp;style=for-the-badge&amp;label=Code%20Quality&amp;logoColor=fff&amp;logo=CodeFactor&amp;branch=master"></a>
  <a title="Translation" href="https://weblate.werwolv.net/projects/imhex/" rel="nofollow"><img alt="Translation" src="https://camo.githubusercontent.com/b74921658b01a105680a08af3adfa7057d27dad1503f3c44a2c0eb2c218eba38/68747470733a2f2f696d672e736869656c64732e696f2f7765626c6174652f70726f67726573732f696d6865783f6c6f676f3d7765626c617465266c6f676f436f6c6f723d253233464646464646267365727665723d68747470732533412532462532467765626c6174652e776572776f6c762e6e6574267374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/weblate/progress/imhex?logo=weblate&amp;logoColor=%23FFFFFF&amp;server=https%3A%2F%2Fweblate.werwolv.net&amp;style=for-the-badge"></a>
  <a title="Plugins" href="https://github.com/WerWolv/ImHex/blob/master/PLUGINS.md"><img alt="Plugins" src="https://camo.githubusercontent.com/478eda45b5ac92b8ca08c15b849fd06deeca9cf9991bac5326a67cc89c518982/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f506c7567696e732d537570706f727465642d627269676874677265656e3f6c6f676f3d737461636b65646974266c6f676f436f6c6f723d253233464646464646267374796c653d666f722d7468652d6261646765" data-canonical-src="https://img.shields.io/badge/Plugins-Supported-brightgreen?logo=stackedit&amp;logoColor=%23FFFFFF&amp;style=for-the-badge"></a>
</p>
<p dir="auto">
  <a title="Download the latest version of ImHex" href="https://imhex.download/" rel="nofollow"><img alt="Download the latest version of ImHex!" src="https://github.com/WerWolv/ImHex/raw/master/resources/dist/common/get_release_banner.png"></a>
  <a title="Download the latest nightly pre-release version of ImHex" href="https://imhex.download/#nightly" rel="nofollow"><img alt="Download the latest nightly pre-release version of ImHex" src="https://github.com/WerWolv/ImHex/raw/master/resources/dist/common/get_nightly_banner.png"></a>
  <a title="Use the Web version of ImHex right in your browser!" href="https://web.imhex.werwolv.net/" rel="nofollow"><img alt="Use the Web version of ImHex right in your browser!" src="https://github.com/WerWolv/ImHex/raw/master/resources/dist/common/try_online_banner.png"></a>
  <a title="Read the documentation of ImHex!" href="https://docs.werwolv.net/" rel="nofollow"><img alt="Read the documentation of ImHex!" src="https://github.com/WerWolv/ImHex/raw/master/resources/dist/common/read_docs_banner.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Supporting</h2><a id="user-content-supporting" aria-label="Permalink: Supporting" href="#supporting"></a></p>
<p dir="auto">If you like my work, please consider supporting me on GitHub Sponsors, Patreon or PayPal. Thanks a lot!</p>
<p dir="auto">
<a href="https://github.com/sponsors/WerWolv"><img src="https://camo.githubusercontent.com/b30a2a0a1b31b9e1912510a528966cfecd9ed9444be7d9429bb801ee03c44676/68747470733a2f2f776572776f6c762e6e65742f6173736574732f6769746875625f62616e6e65722e706e67" alt="GitHub donate button" data-canonical-src="https://werwolv.net/assets/github_banner.png"></a>
<a href="https://www.patreon.com/werwolv" rel="nofollow"><img src="https://camo.githubusercontent.com/f10aba10564cf2b33d2a0f0ffd8950de69999df26003f7bc056027815e03384b/68747470733a2f2f63352e70617472656f6e2e636f6d2f65787465726e616c2f6c6f676f2f6265636f6d655f615f706174726f6e5f627574746f6e2e706e67" alt="Patreon donate button" data-canonical-src="https://c5.patreon.com/external/logo/become_a_patron_button.png"></a>
<a href="https://werwolv.net/donate" rel="nofollow"><img src="https://camo.githubusercontent.com/6e3b6591afb3b885e4ea85b1df5d029086e2b4d40595b985ce5fe6c5d6ca8756/68747470733a2f2f776572776f6c762e6e65742f6173736574732f70617970616c5f62616e6e65722e706e67" alt="PayPal donate button" data-canonical-src="https://werwolv.net/assets/paypal_banner.png"></a>
</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Screenshots</h2><a id="user-content-screenshots" aria-label="Permalink: Screenshots" href="#screenshots"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/10835354/294305049-4f358238-2d27-41aa-9015-a2c6cc3708cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDUwNDktNGYzNTgyMzgtMmQyNy00MWFhLTkwMTUtYTJjNmNjMzcwOGNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVkOTUyODVjMDBmMjI1ZTgzNGU5MWQ0YjA1NzE4Y2ExMzUyOThjY2U2MzhiNjM0NDdjYjdhMzRlNWJiMjJmZDMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.FZFf_fzsI4aWQKLXTAO4Zl5uXWvs7M2Wv583tRR9Ekw"><img src="https://private-user-images.githubusercontent.com/10835354/294305049-4f358238-2d27-41aa-9015-a2c6cc3708cf.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDUwNDktNGYzNTgyMzgtMmQyNy00MWFhLTkwMTUtYTJjNmNjMzcwOGNmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVkOTUyODVjMDBmMjI1ZTgzNGU5MWQ0YjA1NzE4Y2ExMzUyOThjY2U2MzhiNjM0NDdjYjdhMzRlNWJiMjJmZDMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.FZFf_fzsI4aWQKLXTAO4Zl5uXWvs7M2Wv583tRR9Ekw" alt="Hex editor, patterns and data information"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/10835354/294305189-183bc2cc-2439-4ded-b4c5-b140e19fc92f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDUxODktMTgzYmMyY2MtMjQzOS00ZGVkLWI0YzUtYjE0MGUxOWZjOTJmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVlNDdhZjFjYWM4ZDBkYmU5NWE4MmFiZjcxMGI0MTM0ZmEzN2EzNjE3OWJmYTJiOTJmZjAyODg2YzFjZWRiZDMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bQrl-deGkBBZwAbVEVNNZFQCzoWUceRudujUBTBkzT4"><img src="https://private-user-images.githubusercontent.com/10835354/294305189-183bc2cc-2439-4ded-b4c5-b140e19fc92f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDUxODktMTgzYmMyY2MtMjQzOS00ZGVkLWI0YzUtYjE0MGUxOWZjOTJmLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWVlNDdhZjFjYWM4ZDBkYmU5NWE4MmFiZjcxMGI0MTM0ZmEzN2EzNjE3OWJmYTJiOTJmZjAyODg2YzFjZWRiZDMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.bQrl-deGkBBZwAbVEVNNZFQCzoWUceRudujUBTBkzT4" alt="Bookmarks, disassembler and data processor"></a></p>
<details>
<summary><strong>More Screenshots</strong></summary>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/10835354/294305441-d0623081-3094-4840-a8a8-647b38724db8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0NDEtZDA2MjMwODEtMzA5NC00ODQwLWE4YTgtNjQ3YjM4NzI0ZGI4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThhYWExZjIwMmZkOGMzMTQ2YmY0N2JlOGQxOWU3YjI5YWU1YmU1MWQyNzYwM2M2YjE5MjVjMWM1NGMyNDcxNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.v3D3QjIN7Jsl6FNW_Gv4tshA61XDuG0HLyuxSug_9Oo"><img src="https://private-user-images.githubusercontent.com/10835354/294305441-d0623081-3094-4840-a8a8-647b38724db8.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0NDEtZDA2MjMwODEtMzA5NC00ODQwLWE4YTgtNjQ3YjM4NzI0ZGI4LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThhYWExZjIwMmZkOGMzMTQ2YmY0N2JlOGQxOWU3YjI5YWU1YmU1MWQyNzYwM2M2YjE5MjVjMWM1NGMyNDcxNjEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.v3D3QjIN7Jsl6FNW_Gv4tshA61XDuG0HLyuxSug_9Oo" alt="Data Processor decrypting some data and displaying it as an image"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/10835354/294305435-62cbcd18-1c3f-4dd6-a877-2bf2bf4bb2a5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0MzUtNjJjYmNkMTgtMWMzZi00ZGQ2LWE4NzctMmJmMmJmNGJiMmE1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThhMDUyYjgyZjQ5OGI4YTdmZjM5NTZiYTZjNTJmZTNiZjdjN2NmYmFlZmVkZmI0OTAxZDdiMzQxMjUyZGYxNGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.AHMJdxmdSGTSZ7FhHH7rFs6ywmznSzuCm-mcsmqdpKk"><img src="https://private-user-images.githubusercontent.com/10835354/294305435-62cbcd18-1c3f-4dd6-a877-2bf2bf4bb2a5.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0MzUtNjJjYmNkMTgtMWMzZi00ZGQ2LWE4NzctMmJmMmJmNGJiMmE1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPThhMDUyYjgyZjQ5OGI4YTdmZjM5NTZiYTZjNTJmZTNiZjdjN2NmYmFlZmVkZmI0OTAxZDdiMzQxMjUyZGYxNGImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.AHMJdxmdSGTSZ7FhHH7rFs6ywmznSzuCm-mcsmqdpKk" alt="STL Parser written in the Pattern Language visualizing a 3D model"></a>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/10835354/294305442-d4706c01-c258-45c9-80b8-fe7a10d5a1de.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0NDItZDQ3MDZjMDEtYzI1OC00NWM5LTgwYjgtZmU3YTEwZDVhMWRlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE1YzYzMzY1NDczZDMyMWVmN2YyNmVhMjZiZjAwNmFkYzQ2YjY2NjExZWQwYTIwZDVhNTdmMjA2N2Y5NzhjNDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zIb45dEd3_GVvwC0BWvRuQWpjVl3ZRohxMvj2J2mpf4"><img src="https://private-user-images.githubusercontent.com/10835354/294305442-d4706c01-c258-45c9-80b8-fe7a10d5a1de.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk2NzE3MDMsIm5iZiI6MTcxOTY3MTQwMywicGF0aCI6Ii8xMDgzNTM1NC8yOTQzMDU0NDItZDQ3MDZjMDEtYzI1OC00NWM5LTgwYjgtZmU3YTEwZDVhMWRlLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA2MjklMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNjI5VDE0MzAwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE1YzYzMzY1NDczZDMyMWVmN2YyNmVhMjZiZjAwNmFkYzQ2YjY2NjExZWQwYTIwZDVhNTdmMjA2N2Y5NzhjNDYmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.zIb45dEd3_GVvwC0BWvRuQWpjVl3ZRohxMvj2J2mpf4" alt="Data Information view displaying various stats about the file"></a></p>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<details>
  <summary><strong>Featureful hex view</strong></summary>
<ul dir="auto">
<li>Byte patching</li>
<li>Patch management</li>
<li>Infinite Undo/Redo</li>
<li>"Copy bytes as..."
<ul dir="auto">
<li>Bytes</li>
<li>Hex string</li>
<li>C, C++, C#, Rust, Python, Java &amp; JavaScript array</li>
<li>ASCII-Art hex view</li>
<li>HTML self-contained div</li>
</ul>
</li>
<li>Simple string and hex search</li>
<li>Goto from start, end and current cursor position</li>
<li>Colorful highlighting
<ul dir="auto">
<li>Configurable foreground highlighting rules</li>
<li>Background highlighting using patterns, find results and bookmarks</li>
</ul>
</li>
<li>Displaying data as a list of many different types
<ul dir="auto">
<li>Hexadecimal integers (8, 16, 32, 64 bit)</li>
<li>Signed and unsigned decimal integers (8, 16, 32, 64 bit)</li>
<li>Floats (16, 32, 64 bit)</li>
<li>RGBA8 Colors</li>
<li>HexII</li>
<li>Binary</li>
</ul>
</li>
<li>Decoding data as ASCII and custom encodings
<ul dir="auto">
<li>Built-in support for UTF-8, UTF-16, ShiftJIS, most Windows encodings and many more</li>
</ul>
</li>
<li>Paged data view</li>
</ul>
</details>
<details>
  <summary><strong>Custom C++-like pattern language for parsing highlighting a file's content</strong></summary>
<ul dir="auto">
<li>Automatic loading based on MIME types and magic values</li>
<li>Arrays, pointers, structs, unions, enums, bitfields, namespaces, little and big endian support, conditionals and much more!</li>
<li>Useful error messages, syntax highlighting and error marking</li>
<li>Support for visualizing many different types of data
<ul dir="auto">
<li>Images</li>
<li>Audio</li>
<li>3D Models</li>
<li>Coordinates</li>
<li>Time stamps</li>
</ul>
</li>
</ul>
</details>
<details>
  <summary><strong>Theming support</strong></summary>
<ul dir="auto">
<li>Doesn't burn out your retinas when used in late-night sessions
<ul dir="auto">
<li>Dark mode by default, but a light mode is available as well</li>
</ul>
</li>
<li>Customizable colors and styles for all UI elements through shareable theme files</li>
<li>Support for custom fonts</li>
</ul>
</details>
<details>
  <summary><strong>Importing and Exporting data</strong></summary>
<ul dir="auto">
<li>Base64 files</li>
<li>IPS and IPS32 patches</li>
<li>Markdown reports</li>
</ul>
</details>
<details>
  <summary><strong>Data Inspector</strong></summary>
<ul dir="auto">
<li>Interpreting data as many different types with endianness, decimal, hexadecimal and octal support and bit inversion
<ul dir="auto">
<li>Unsigned and signed integers (8, 16, 24, 32, 48, 64 bit)</li>
<li>Floats (16, 32, 64 bit)</li>
<li>Signed and Unsigned LEB128</li>
<li>ASCII, Wide and UTF-8 characters and strings</li>
<li>time32_t, time64_t, DOS date and time</li>
<li>GUIDs</li>
<li>RGBA8 and RGB65 Colors</li>
</ul>
</li>
<li>Copying and modifying bytes through the inspector</li>
<li>Adding new data types through the pattern language</li>
<li>Support for hiding rows that aren't used</li>
</ul>
</details>
<details>
  <summary><strong>Node-based data pre-processor</strong></summary>
<ul dir="auto">
<li>Modify, decrypt and decode data before it's being displayed in the hex editor</li>
<li>Modify data without touching the underlying source</li>
<li>Support for adding custom nodes</li>
</ul>
</details>
<details>
  <summary><strong>Loading data from many different data sources</strong></summary>
<ul dir="auto">
<li>Local Files
<ul dir="auto">
<li>Support for huge files with fast and efficient loading</li>
</ul>
</li>
<li>Raw Disks
<ul dir="auto">
<li>Loading data from raw disks and partitions</li>
</ul>
</li>
<li>GDB Server
<ul dir="auto">
<li>Access the RAM of a running process or embedded devices through GDB</li>
</ul>
</li>
<li>Intel Hex and Motorola SREC data</li>
<li>Process Memory
<ul dir="auto">
<li>Inspect the entire address space of a running process</li>
</ul>
</li>
</ul>
</details>
<details>
  <summary><strong>Data searching</strong></summary>
<ul dir="auto">
<li>Support for searching the entire file or only a selection</li>
<li>String extraction
<ul dir="auto">
<li>Option to specify minimum length and character set (lower case, upper case, digits, symbols)</li>
<li>Option to specify encoding (ASCII, UTF-8, UTF-16 big and little endian)</li>
</ul>
</li>
<li>Sequence search
<ul dir="auto">
<li>Search for a sequence of bytes or characters</li>
<li>Option to ignore character case</li>
</ul>
</li>
<li>Regex search
<ul dir="auto">
<li>Search for strings using regular expressions</li>
</ul>
</li>
<li>Binary Pattern
<ul dir="auto">
<li>Search for sequences of bytes with optional wildcards</li>
</ul>
</li>
<li>Numeric Value search
<ul dir="auto">
<li>Search for signed/unsigned integers and floats</li>
<li>Search for ranges of values</li>
<li>Option to specify size and endianness</li>
<li>Option to ignore unaligned values</li>
</ul>
</li>
</ul>
</details>
<details>
  <summary><strong>Data hashing support</strong></summary>
<ul dir="auto">
<li>Many different algorithms available
<ul dir="auto">
<li>CRC8, CRC16 and CRC32 with custom initial values and polynomials
<ul dir="auto">
<li>Many default polynomials available</li>
</ul>
</li>
<li>MD5</li>
<li>SHA-1, SHA-224, SHA-256, SHA-384, SHA-512</li>
<li>Adler32</li>
<li>AP</li>
<li>BKDR</li>
<li>Bernstein, Bernstein1</li>
<li>DEK, DJB, ELF, FNV1, FNV1a, JS, PJW, RS, SDBM</li>
<li>OneAtTime, Rotating, ShiftAndXor, SuperFast</li>
<li>Murmur2_32, MurmurHash3_x86_32, MurmurHash3_x86_128, MurmurHash3_x64_128</li>
<li>SipHash64, SipHash128</li>
<li>XXHash32, XXHash64</li>
<li>Tiger, Tiger2</li>
<li>Blake2B, Blake2S</li>
</ul>
</li>
<li>Hashing of specific regions of the loaded data</li>
<li>Hashing of arbitrary strings</li>
</ul>
</details>
<details>
  <summary><strong>Diffing support</strong></summary>
<ul dir="auto">
<li>Compare data of different data sources</li>
<li>Difference highlighting</li>
<li>Table view of differences</li>
</ul>
</details>
<details>
  <summary><strong>Integrated disassembler</strong></summary>
<ul dir="auto">
<li>Support for all architectures supported by Capstone
<ul dir="auto">
<li>ARM32 (ARM, Thumb, Cortex-M, AArch32)</li>
<li>ARM64</li>
<li>MIPS (MIPS32, MIPS64, MIPS32R6, Micro)</li>
<li>x86 (16-bit, 32-bit, 64-bit)</li>
<li>PowerPC (32-bit, 64-bit)</li>
<li>SPARC</li>
<li>IBM SystemZ</li>
<li>xCORE</li>
<li>M68K</li>
<li>TMS320C64X</li>
<li>M680X</li>
<li>Ethereum</li>
<li>RISC-V</li>
<li>WebAssembly</li>
<li>MOS65XX</li>
<li>Berkeley Packet Filter</li>
</ul>
</li>
</ul>
</details>
<details>
  <summary><strong>Bookmarks</strong></summary>
<ul dir="auto">
<li>Support for bookmarks with custom names and colors</li>
<li>Highlighting of bookmarked region in the hex editor</li>
<li>Jump to bookmarks</li>
<li>Open content of bookmark in a new tab</li>
<li>Add comments to bookmarks</li>
</ul>
</details>
<details>
  <summary><strong>Featureful data analyzer and visualizer</strong></summary>
<ul dir="auto">
<li>File magic-based file parser and MIME type database</li>
<li>Byte type distribution graph</li>
<li>Entropy graph</li>
<li>Highest and average entropy</li>
<li>Encrypted / Compressed file detection</li>
<li>Digram and Layered distribution graphs</li>
</ul>
</details>
<details>
  <summary><strong>YARA Rule support</strong></summary>
<ul dir="auto">
<li>Scan a file for vulnerabilities with official yara rules</li>
<li>Highlight matches in the hex editor</li>
<li>Jump to matches</li>
<li>Apply multiple rules at once</li>
</ul>
</details>
<details>
  <summary><strong>Helpful tools</strong></summary>
<ul dir="auto">
<li>Itanium, MSVC, Rust and D-Lang demangler based on LLVM</li>
<li>ASCII table</li>
<li>Regex replacer</li>
<li>Mathematical expression evaluator (Calculator)</li>
<li>Graphing calculator</li>
<li>Hexadecimal Color picker with support for many different formats</li>
<li>Base converter</li>
<li>Byte swapper</li>
<li>UNIX Permissions calculator</li>
<li>Wikipedia term definition finder</li>
<li>File utilities
<ul dir="auto">
<li>File splitter</li>
<li>File combiner</li>
<li>File shredder</li>
</ul>
</li>
<li>IEEE754 Float visualizer</li>
<li>Division by invariant multiplication calculator</li>
<li>TCP Client/Server</li>
<li>Euclidean algorithm calculator</li>
</ul>
</details>
<details>
  <summary><strong>Built-in Content updater</strong></summary>
<ul dir="auto">
<li>Download all files found in the database directly from within ImHex
<ul dir="auto">
<li>Pattern files for decoding various file formats</li>
<li>Libraries for the pattern language</li>
<li>Magic files for file type detection</li>
<li>Custom data processor nodes</li>
<li>Custom encodings</li>
<li>Custom themes</li>
<li>Yara rules</li>
</ul>
</li>
</ul>
</details>
<details>
  <summary><strong>Modern Interface</strong></summary>
<ul dir="auto">
<li>Support for multiple workspaces</li>
<li>Support for custom layouts</li>
<li>Detachable windows</li>
</ul>
</details>
<details>
  <summary><strong>Easy to get started</strong></summary>
<ul dir="auto">
<li>Support for many different languages</li>
<li>Simplified mode for beginners</li>
<li>Extensive documentation</li>
<li>Many example files available on <a href="https://github.com/WerWolv/ImHex-Patterns">the Database</a></li>
<li>Achievements guiding you through the features of ImHex</li>
<li>Interactive tutorials</li>
</ul>
</details>
<p dir="auto"><h2 tabindex="-1" dir="auto">Pattern Language</h2><a id="user-content-pattern-language" aria-label="Permalink: Pattern Language" href="#pattern-language"></a></p>
<p dir="auto">The Pattern Language is the completely custom programming language developed for ImHex.
It allows you to define structures and data types in a C-like syntax and then use them to parse and highlight a file's content.</p>
<ul dir="auto">
<li>Source Code: <a href="https://github.com/WerWolv/PatternLanguage/">Link</a></li>
<li>Documentation: <a href="https://docs.werwolv.net/pattern-language/" rel="nofollow">Link</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Database</h2><a id="user-content-database" aria-label="Permalink: Database" href="#database"></a></p>
<p dir="auto">For format patterns, libraries, magic and constant files, check out the <a href="https://github.com/WerWolv/ImHex-Patterns">ImHex-Patterns</a> repository.</p>
<p dir="auto"><strong>Feel free to PR your own files there as well!</strong></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Requirements</h2><a id="user-content-requirements" aria-label="Permalink: Requirements" href="#requirements"></a></p>
<p dir="auto">To use ImHex, the following minimal system requirements need to be met.</p>
<div dir="auto"><p dir="auto">Important</p><p dir="auto">ImHex requires a GPU with OpenGL 3.0 support in general.
There are releases available (with the <code>-NoGPU</code> suffix) that are software rendered and don't require a GPU, however these can be a lot slower than the GPU accelerated versions.</p>
<p dir="auto">If possible at all, make ImHex use the dedicated GPU on your system instead of the integrated one (especially Intel HD GPUs are known to cause issues).</p>
</div>
<ul dir="auto">
<li><strong>OS</strong>:
<ul dir="auto">
<li><strong>Windows</strong>: Windows 7 or higher (Windows 10/11 recommended)</li>
<li><strong>macOS</strong>: macOS 12.1 (Monterey) or higher,
<ul dir="auto">
<li>Lower versions are supported, but you'll need to compile ImHex yourself</li>
</ul>
</li>
<li><strong>Linux</strong>: "Modern" Linux. The following distributions have official releases available. Other distros are supported through the AppImage and Flatpak releases.
<ul dir="auto">
<li>Ubuntu 22.04/23.04</li>
<li>Fedora 36/37</li>
<li>RHEL/AlmaLinux 9</li>
<li>Arch Linux</li>
</ul>
</li>
</ul>
</li>
<li><strong>CPU</strong>: x86_64 (64 Bit)</li>
<li><strong>GPU</strong>: OpenGL 3.0 or higher
<ul dir="auto">
<li>Intel HD drivers are really buggy and often cause graphic artifacts</li>
<li>In case you don't have a GPU available, there are software rendered releases available for Windows and macOS</li>
</ul>
</li>
<li><strong>RAM</strong>: 256MB, more may be required for more complicated analysis</li>
<li><strong>Storage</strong>: 100MB</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installing</h2><a id="user-content-installing" aria-label="Permalink: Installing" href="#installing"></a></p>
<p dir="auto">Information on how to install ImHex can be found in the <a href="https://github.com/WerWolv/ImHex/blob/master/INSTALL.md">Install</a> guide</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Compiling</h2><a id="user-content-compiling" aria-label="Permalink: Compiling" href="#compiling"></a></p>
<p dir="auto">To compile ImHex on any platform, GCC (or Clang) is required with a version that supports C++23 or higher.
On macOS, Clang is also required to compile some ObjC code.
All releases are being built using latest available GCC.</p>
<div dir="auto"><p dir="auto">Note</p><p dir="auto">Many dependencies are bundled into the repository using submodules so make sure to clone it using the <code>--recurse-submodules</code> option.
All dependencies that aren't bundled, can be installed using the dependency installer scripts found in the <code>/dist</code> folder.</p>
</div>
<p dir="auto">For more information, check out the <a href="https://github.com/WerWolv/ImHex/blob/master/dist/compiling">Compiling</a> guide.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">See <a href="https://github.com/WerWolv/ImHex/blob/master/CONTRIBUTING.md">Contributing</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Plugin development</h2><a id="user-content-plugin-development" aria-label="Permalink: Plugin development" href="#plugin-development"></a></p>
<p dir="auto">To develop plugins for ImHex, use the following template project to get started. You then have access to the entirety of libimhex as well as the ImHex API and the Content Registry to interact with ImHex or to add new content.</p>
<ul dir="auto">
<li><a href="https://github.com/WerWolv/ImHex-Plugin-Template">ImHex Plugin Template</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Credits</h2><a id="user-content-credits" aria-label="Permalink: Credits" href="#credits"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Contributors</h3><a id="user-content-contributors" aria-label="Permalink: Contributors" href="#contributors"></a></p>
<ul dir="auto">
<li><a href="https://github.com/iTrooz">iTrooz</a> for getting ImHex onto the Web as well as hundreds of contributions in every part of the project</li>
<li><a href="https://github.com/jumanji144">jumanji144</a> for huge contributions to the Pattern Language and ImHex's infrastructure</li>
<li><a href="https://github.com/marysaka">Mary</a> for her immense help porting ImHex to MacOS and help during development</li>
<li><a href="https://github.com/Roblabla">Roblabla</a> for adding MSI Installer support to ImHex</li>
<li><a href="https://github.com/Mailaender">Mailaender</a> for getting ImHex onto Flathub</li>
<li>Everybody else who has reported issues on Discord or GitHub that I had great conversations with :)</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Dependencies</h3><a id="user-content-dependencies" aria-label="Permalink: Dependencies" href="#dependencies"></a></p>
<ul dir="auto">
<li>Thanks a lot to ocornut for their amazing <a href="https://github.com/ocornut/imgui">Dear ImGui</a> which is used for building the entire interface
<ul dir="auto">
<li>Thanks to epezent for <a href="https://github.com/epezent/implot">ImPlot</a> used to plot data in various places</li>
<li>Thanks to Nelarius for <a href="https://github.com/Nelarius/imnodes">ImNodes</a> used as base for the data processor</li>
<li>Thanks to BalazsJako for <a href="https://github.com/BalazsJako/ImGuiColorTextEdit">ImGuiColorTextEdit</a> used for the pattern language syntax highlighting</li>
</ul>
</li>
<li>Thanks to nlohmann for their <a href="https://github.com/nlohmann/json">json</a> library used for configuration files</li>
<li>Thanks to vitaut for their <a href="https://github.com/fmtlib/fmt">libfmt</a> library which makes formatting and logging so much better</li>
<li>Thanks to btzy for <a href="https://github.com/btzy/nativefiledialog-extended">nativefiledialog-extended</a> and their great support, used for handling file dialogs on all platforms</li>
<li>Thanks to danyspin97 for <a href="https://sr.ht/~danyspin97/xdgpp" rel="nofollow">xdgpp</a> used to handle folder paths on Linux</li>
<li>Thanks to aquynh for <a href="https://github.com/aquynh/capstone">capstone</a> which is the base of the disassembly window</li>
<li>Thanks to rxi for <a href="https://github.com/rxi/microtar">microtar</a> used for extracting downloaded store assets</li>
<li>Thanks to VirusTotal for <a href="https://github.com/VirusTotal/yara">Yara</a> used by the Yara plugin</li>
<li>Thanks to Martinsos for <a href="https://github.com/Martinsos/edlib">edlib</a> used for sequence searching in the diffing view</li>
<li>Thanks to ron4fun for <a href="https://github.com/ron4fun/HashLibPlus">HashLibPlus</a> which implements every hashing algorithm under the sun</li>
<li>Thanks to mackron for <a href="https://github.com/mackron/miniaudio">miniaudio</a> used to play audio files</li>
<li>Thanks to all other groups and organizations whose libraries are used in ImHex</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">License</h3><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">The biggest part of ImHex is under the GPLv2-only license.
Notable exceptions to this are the following parts which are under the LGPLv2.1 license:</p>
<ul dir="auto">
<li><strong>/lib/libimhex</strong>: The library that allows Plugins to interact with ImHex.</li>
<li><strong>/plugins/ui</strong>: The UI plugin library that contains some common UI elements that can be used by other plugins</li>
</ul>
<p dir="auto">The reason for this is to allow for proprietary plugins to be developed for ImHex.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All web "content" is freeware (140 pts)]]></title>
            <link>https://rubenerd.com/all-web-content-is-freeware/</link>
            <guid>40828441</guid>
            <pubDate>Sat, 29 Jun 2024 07:09:45 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rubenerd.com/all-web-content-is-freeware/">https://rubenerd.com/all-web-content-is-freeware/</a>, See on <a href="https://news.ycombinator.com/item?id=40828441">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>Sean Endicott <a href="https://www.windowscentral.com/software-apps/ever-put-content-on-the-web-microsoft-says-that-its-okay-for-them-to-steal-it-because-its-freeware">quoted a CNBC interview</a> with Microsoft’s CEO of AI, and it’s nothing if not entertaining!</p>
<blockquote>
<p>“With respect to content that is already on the open web, the social contract of that content since the 90s has been that it is fair use. Anyone can copy it, recreate with it, reproduce with it. That has been freeware, if you like. That’s been the understanding,” said Suleyman.</p>
</blockquote>
<p>This is the same company behind <a href="https://en.wikipedia.org/wiki/An_Open_Letter_to_Hobbyists">this famous letter in 1976</a>. Perhaps that’s why he bookended his claims with “since the 90s”. But that means torrents of Windows are freeware! Maybe he should have run this by legal first.</p>
<p>Easy gotchas aside, this rambling, incoherent interview was a fascinating and <em>deeply</em> revealing perspective into how managers are thinking. It’s dawning on them that they’ve lost the financial argument, because these models are unsustainable to anyone not <a href="https://quoteinvestigator.com/2021/04/20/gold-shovel/">selling the shovels</a>. Model decay has revealed the emperor has no clothes when it comes to tools “learning” or “being inspired” as artists are. The general public are beginning to equate “AI generated” with low effort and low quality, coining a <a href="https://www.thestar.com.my/tech/tech-news/2024/06/21/slop-is-the-dubious-online-content-churned-out-by-ai" title="‘Slop’ is the dubious online content churned out by AI">new term in the process</a>. There are also indications that <a href="https://omny.fm/shows/better-offline/are-we-at-peak-ai" title="Better Offline: Are We At Peak AI?">peak AI</a> may already soon be upon us, given they’re rapidly exhausting their supply of organic material to train against.</p>
<p>Backed into an ethical, financial, mathematical, and legal corner, generative AI vendors are now resorting to arguing everything is fair game, because it always was. Don’t blame us, the <a href="https://knowyourmeme.com/memes/torment-nexus" title="Know Your Meme: The Torment Nexus">Torment Nexus</a> is established practice!</p>
<p>This gives me the opportunity to address a point a lot of tech pundits are now making: a chatbot is no different from a search engine. The “social contract” here is that search engines could crawl our pages, create indexes, data mine them based on secret algorithms, and present processed results based on a query. A generative AI chatbox is no different, right?</p>
<p>Except, and I know this may come as a shock: <em>search engines link to their sources!</em> Chatbots don’t. That’s what makes their “hallucinations” so dangerous; there’s no audit trail. Search engines deliver traffic, generative AI tools train against data to avoid doing that. The “social contract” here is completely upside down, as though a tool was asked to generate an image of it.</p>
<p>This is the surest sign to me that we’re in a bubble again: the talking heads are beginning to believe their own nonsense. That’s another form of model decay, now that I think about it.</p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[How to waste bandwidth, battery power, and annoy sysadmins (237 pts)]]></title>
            <link>https://rachelbythebay.com/w/2024/06/28/fxios/</link>
            <guid>40828203</guid>
            <pubDate>Sat, 29 Jun 2024 06:07:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2024/06/28/fxios/">https://rachelbythebay.com/w/2024/06/28/fxios/</a>, See on <a href="https://news.ycombinator.com/item?id=40828203">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2024/06/28/fxios/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[The 'pay phone bandit' who baffled the FBI in the '80s (125 pts)]]></title>
            <link>https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi</link>
            <guid>40827650</guid>
            <pubDate>Sat, 29 Jun 2024 03:19:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi">https://www.mentalfloss.com/posts/pay-phone-bandit-baffled-fbi</a>, See on <a href="https://news.ycombinator.com/item?id=40827650">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><figure></figure><p data-mm-id="_k4ztttvkp">Most of the sightings were the same. Standing in front of the motel clerk or convenience store worker was a man, roughly 5 feet, 9 inches tall, <a href="https://www.washingtonpost.com/archive/politics/1988/08/30/fbi-agents-arrest-suspect-in-legendary-500000-pay-phone-theft-case/bca70245-b2d9-4cb6-899f-2304d7057979/" target="_blank">wearing</a> a baseball cap pulled low and almost touching a pair of gold-rimmed eyeglasses. A ponytail stuck out from the back of the hat. A button-down shirt was left untucked. Cowboy boots protruded from under his pant cuffs.</p><p data-mm-id="_mhcj1fl4t">Most importantly, the man liked to pay for his food or his room in quarters—rolls and rolls of quarters.</p><p data-mm-id="_7dp103nc1">In the 1980s, police in Ohio as well as the FBI spent years <a href="https://www.latimes.com/archives/la-xpm-1988-08-28-me-1808-story.html" target="_blank">chasing</a> the man with the ponytail. Unlike a lot of criminals, he didn’t brandish a gun, resort to violence, or put innocent people in his crosshairs. What he did instead was become the most prolific safecracker in modern times, able to breach what was once <a href="https://www.latimes.com/archives/la-xpm-1987-12-08-me-27444-story.html" target="_blank">believed</a> to be the impenetrable, unbreakable strongbox housed in the country’s 1.8 million pay phones. Using means that baffled even security experts, the “pay phone bandit” or “telephone bandit” eluded capture. Quarter by quarter and year after year, he collected an estimated $500,000 to <a href="https://www.newspapers.com/image/641914911/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">$1 million</a> from these tiny safes. The question was how anyone was ever going to find him.</p><p data-mm-id="_9gir4pvh1">“Unless somebody gets lucky, he’ll probably never get caught,” Ohio Bell Telephone security official Robert Cooperider told <em>The Los Angeles Times</em> in 1987. “He’s well-organized, he’s smart, and he’s not greedy. He only hits a few widely spaced spots each day. He’s always looking over his shoulder, to see if there is a police car, or a telephone company vehicle.”</p><p data-mm-id="_mry61xe1z">Though it’s hard to imagine today, there was once a time when making a telephone call meant going home, asking to use someone’s phone, or plunking a quarter into a freestanding pay phone. (Or more than one, depending on where you were calling and for how long.) </p><p data-mm-id="_psu909emr">The first public pay-to-use coin-operated phone <a href="https://time.com/4425102/public-telephone-booth-history/" target="_blank">debuted</a> in Hartford, Connecticut, in 1889. It relied on the honor system, with users depositing coins owed after their call was done. Over the next century, they appeared everywhere, from convenience stores to diners to bus stations. Some were freestanding; others were located inside of a booth to give callers some privacy.</p><p data-mm-id="_4o23p6aao">While the phones varied somewhat in design, virtually all of them took care to make the coin box virtually impregnable. Bell, then the world’s largest phone carrier, <a href="https://www.newspapers.com/image/295427269/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%20bandit%22" target="_blank">reportedly</a> spent years refining a lock on their box that was thought to be unpickable. If a would-be thief wanted to even have a shot at getting into the box, they’d have to try smashing it open with a sledge hammer or knock it out of the ground with a tractor. Given that the boxes only held about $150 when full, few criminals thought it was worth the effort.</p><div data-mm-id="_izkflqdbd"><figure data-id="_izkflqdbd" data-mm-type="image"><canvas></canvas><picture><source><source><source></picture></figure><p><figcaption>A typical pay phone inside of a phone booth. / Marie Hickman/Stone via Getty Images</figcaption></p></div><p data-mm-id="_6eeeowg0c">James Clark wasn’t one of those people. The Akron, Ohio, native was a machinist by trade, but he had a nebulous history. According to the Associated Press, in 1968 he was arrested for <a href="https://www.newspapers.com/image/296810671/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">attempting</a> to arrange a massive counterfeit money deal with contacts in Europe that would have put $50 million phony bills into circulation. He was caught and sentenced to three years in prison.</p><p data-mm-id="_b7xtffq05">Roughly a decade later, in the early 1980s, Clark devised a new scheme. According to authorities, Clark obtained locks like the ones found on pay phones and created a set of specialized locksmith tools that allowed him to pick the lock. Though different operators had somewhat different lock configurations, Clark zeroed in on specific designs to breach. (His exact tool set and technique has never been publicly disclosed, likely due to security concerns.)</p><p data-mm-id="_x3miqn5vk">Clark’s strategy was simple. Upon arriving at a pay phone, he <a href="https://www.oklahoman.com/story/news/1988/02/14/phone-companies-seek-coin-thief/62661920007/" target="_blank">used</a> a custom tool that he could slip into the margins of the coin box to gauge how much money was inside and whether it was worth pursuing. If it was full, he’d pick up the receiver and pretend to be deep in a conversation. While hunched over the phone, he’d grab his lockpicking tools—which he concealed with an untucked shirttail—and get to work on the lock. Picking one took about 15 minutes. When he got it, the faceplate in front of the coin receptacle came off. Clark would take the box full of change and then replace the faceplate.</p><p data-mm-id="_jl1kf3ska">This last step was key: The phone would <a href="https://www.newspapers.com/image/153864107/?terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">continue</a> to operate without the box, giving no physical or mechanical clue it had been tampered with. No one would realize the box was missing until a phone company employee came to retrieve the money—in some cases a week or so later. By that point, Clark would be long gone.</p><p data-mm-id="_g4dz6n2bv">Clark ransacked pay phones in Ohio, but he soon branched out to other states. By one estimate, he hit phones in 30 of them, mostly in the South and West. He preferred to stick to phones near the interstate so he could leave in a hurry if he had to. He also seemed to favor phones near country and Western bars, either because he liked the entertainment or because he knew businesses would have profitable phones nearby. He stopped off for lodging and food using his stolen quarters as payment, though he was also known to exchange the coins for bills at banks. He was also seemingly cocky. He used the name <em>James Bell</em> when registering for rooms, a nod to the phone giant he was ripping off on a regular basis.</p><p data-mm-id="_35rf0dhs9">Bell was wise to Clark’s scheme early on. As his spree grew, there was a question of whether he was acting alone or whether the phone thefts were part of some interstate crime ring.</p><p data-mm-id="_slth57s83">But closer inspection of the locks revealed a clue. In picking them, Clark left behind a telltale series of scratches that authorities considered almost as good as a fingerprint. It was the one piece of evidence officials had to go on, though there was nothing to compare it to—no national database of lockpicking marks.</p><p data-mm-id="_cguhe9w7j">It wasn’t until 1985 that investigators in Ohio and the FBI got their first real break in the case. A person that news media described as an “informer” told them<strong> </strong>to look closely at Clark,<strong> </strong>the Akron native who had once been embroiled in the counterfeit ring of the late 1960s. Clark’s family—his wife and a grown daughter—were still in the Akron area, but Clark himself was nowhere to be found. He had apparently broken off ties with his relatives.</p><p data-mm-id="_lju6vg5jm">Armed with a search warrant, police searched a trailer belonging to Clark and found a smoking gun of sorts: parts of a Bell lock, which they inferred had been used as a practice lock.</p><div data-mm-id="_24byqll5g"><figure data-id="_24byqll5g" data-mm-type="image"><canvas></canvas><picture><source><source><source></picture></figure><p><figcaption>The lock box on a pay phone can be seen on the lower right. / Carlos E. Serrano/Moment via Getty Images</figcaption></p></div><p data-mm-id="_knefnje51">While there was no sign of Clark, at least they could put a face to their suspect’s name. A sketch artist <a href="https://www.newspapers.com/image/919421370/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%20bandit%22" target="_blank">developed</a> a likeness that was used for wanted posters; police approached convenience store workers and motel workers asking if they had seen him. Some had, including one witness who <a href="https://www.newspapers.com/image/289405984/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">believed</a> they had seen Clark working a phone while being obscured from view by a blue van. The phone’s contents were believed to have been stolen around the time of the sighting. One Bell employee even related a story of confronting Clark while he was in the middle of a heist; Clark, in a rare moment of animus, warned the worker off. Though he apparently never brandished it, Clark was known to carry a .38 revolver. He was seemingly prepared for a confrontation.</p><p data-mm-id="_cfnewbet9">A warrant was issued for Clark’s arrest in Ohio as well as nationally: The FBI sought him in conjunction with unlawful flight from the state. Bell and other phone operators offered a $25,000 reward for information leading to his arrest. Tips continued to come in, though Clark, sticking close to the interstate, was always a day or so ahead of the law. Not even two appearances on <em>America’s Most Wanted</em> resulted in any meaningful leads. Some officials doubted he would ever be caught. If he wasn’t, there really wasn’t anything Bell or other operators could practically do. Even if he were costing them $70,000 annually, that was still cheaper than trying to replace locks on 1.8 million phones.</p><p data-mm-id="_je9hbnwwa">But in August 1988, Clark’s run came to an end. Acting on another tip, the FBI arrested him in Buena Park, California. True to Clark’s subversive style, there was no protracted struggle: He surrendered without incident; unique lockpicking tools were found in his apartment. Though law enforcement didn’t divulge who or what led them to Buena Park, they indicated Clark’s decision to stay in one place may have helped them catch up to him.</p><p data-mm-id="_w04u5a26t">Speaking with the press, his attorney, Paul Potter, said Clark had admitted to being the man police had been searching for in 1985 and characterized his client as “an American tinkerer.”</p><p data-mm-id="_z2tct38og">Bell’s national spree was a logistically messy one for the criminal justice system. Any one of dozens of states could bring charges. Initially, he was <a href="https://www.upi.com/Archives/1988/09/02/Coin-box-bandit-agrees-to-extradition/9461589176000/" target="_blank">extradited</a> back to Ohio, where he pled guilty in Summit County to five counts of grand theft and another five counts of tampering with coin machines, crimes with a loss valued at just $500. In consideration for the plea, the judge <a href="https://www.newspapers.com/image/296810671/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">dropped</a> other charges and took a potential 10-year prison sentence off the table. Clark got three years.</p><p data-mm-id="_npkl89t1h">In 1990, Clark got another <a href="https://www.newspapers.com/image/641914911/?match=1&amp;terms=%22James%20Clark%22%20%22pay%20phone%22%20%22Ohio%22" target="_blank">sentence</a> in Ohio, this one in Columbus after pleading to one count of theft and two counts of tampering. He got a three-year sentence. Whether he received additional time in other states is unclear. </p><p data-mm-id="_1q3915wgl">Clark was roughly 50 years old when he was caught. He died in 2012. In a guestbook marking his passing, a commenter <a href="https://www.legacy.com/us/obituaries/ohio/name/james-clark-obituary?id=23748114" target="_blank">observed</a> that Clark was a “thinker and a doer,” which is probably as fitting a eulogy as he could hope for. It’s also unlikely the FBI’s fears of a copycat will ever materialize: As of 2018, there were <a href="https://money.cnn.com/2018/03/19/news/companies/pay-phones/index.html" target="_blank">less </a>than 100,000 pay phones in the country and likely even fewer today.</p><p data-mm-id="_nz7je012e"><strong>Read More About True Crime:</strong></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The XAES-256-GCM extended-nonce AEAD (150 pts)]]></title>
            <link>https://words.filippo.io/dispatches/xaes-256-gcm/</link>
            <guid>40826683</guid>
            <pubDate>Sat, 29 Jun 2024 00:01:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://words.filippo.io/dispatches/xaes-256-gcm/">https://words.filippo.io/dispatches/xaes-256-gcm/</a>, See on <a href="https://news.ycombinator.com/item?id=40826683">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
            <p>About a year ago <a href="https://words.filippo.io/dispatches/xaes-256-gcm-11/">I wrote</a> that “I want to use XAES-256-GCM/11, which has a number of nice properties and only the annoying defect of not existing.” Well, there is now <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io">an XAES-256-GCM specification</a>. (Had to give up on the /11 part, but that was just a performance optimization.)</p>
<p>XAES-256-GCM is an <em>authenticated encryption with additional data</em> (AEAD) algorithm with 256-bit keys and <strong>192-bit nonces</strong>. It was designed with the following goals:</p>
<ol>
<li>supporting a nonce large enough to be safe to generate randomly for a virtually unlimited number of messages (2⁸⁰ messages with collision risk 2⁻³²);</li>
<li>full, straightforward FIPS 140 compliance; and</li>
<li>trivial implementation on top of common cryptographic libraries.</li>
</ol>
<p>The large nonce enables safer and more friendly APIs that automatically read a fresh nonce from the operating system’s CSPRNG for every message, without burdening the user with any <a href="https://en.wikipedia.org/wiki/Birthday_attack?ref=words.filippo.io">birthday bound</a> calculations. Compliance and compatibility make it available anywhere an AEAD might be needed, including in settings where alternative large-nonce AEADs are not an option.</p>
<p>Like XChaCha20Poly1305, XAES-256-GCM is an extended-nonce construction on top of AES-256-GCM. That is, it uses the key and the large nonce to compute a derived key for the underlying AEAD.</p>
<p>It’s simple enough to fit inline in this newsletter. Here we go. <em>K</em> and <em>N</em> are the input key and nonce, <em>Kₓ</em> and <em>Nₓ</em> are the derived AES-256-GCM key and nonce.</p>
<ol>
<li><em>L</em> = AES-256ₖ(0¹²⁸)</li>
<li>If MSB₁(<em>L</em>) = 0, then <em>K1</em> = <em>L</em> &lt;&lt; 1;<br>
Else <em>K1</em> = (<em>L</em> &lt;&lt; 1) ⊕ 0¹²⁰10000111</li>
<li><em>M1</em> = 0x00 || 0x01 || <code>X</code> || 0x00 || <em>N</em>[:12]</li>
<li><em>M2</em> = 0x00 || 0x02 || <code>X</code> || 0x00 || <em>N</em>[:12]</li>
<li><em>Kₓ</em> = AES-256ₖ(<em>M1</em> ⊕ <em>K1</em>) || AES-256ₖ(<em>M2</em> ⊕ <em>K1</em>)</li>
<li><em>Nₓ</em> = <em>N</em>[12:]</li>
</ol>
<p>As you can see, it costs three AES-256ₖ calls per message, although one can be precomputed for a given key, and the other two can reuse its key schedule.</p>
<p>The <a href="https://github.com/C2SP/C2SP/blob/main/XAES-256-GCM/go/XAES-256-GCM.go?ref=words.filippo.io">Go reference implementation</a> fits in less than 100 lines of mostly boilerplate, including the precomputation optimization, and only uses the standard library’s crypto/cipher and crypto/aes.</p>
<p>Importantly, you could also describe XAES-256-GCM entirely in terms of a standard <a href="https://csrc.nist.gov/publications/detail/sp/800-108/rev-1/final?ref=words.filippo.io">NIST SP 800-108r1</a> KDF and the standard NIST AES-256-GCM AEAD (<a href="https://csrc.nist.gov/pubs/sp/800/38/d/final?ref=words.filippo.io">NIST SP 800-38D</a>, <a href="https://csrc.nist.gov/pubs/fips/197/final?ref=words.filippo.io">FIPS 197</a>).</p>
<blockquote>
<p>Instantiate a counter-based KDF (<a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-108r1.pdf?ref=words.filippo.io#%5B%7B%22num%22%3A79%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C70%2C300%2C0%5D">NIST SP 800-108r1, Section 4.1</a>) with CMAC-AES256 (<a href="https://csrc.nist.gov/publications/detail/sp/800-38b/final?ref=words.filippo.io">NIST SP 800-38B</a>) and the input key as <em>Kin</em>, the ASCII letter <code>X</code> (0x58) as <em>Label</em>, the first 96 bits of the input nonce as <em>Context</em> (as recommended by <a href="https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-108r1.pdf?ref=words.filippo.io#%5B%7B%22num%22%3A71%2C%22gen%22%3A0%7D%2C%7B%22name%22%3A%22XYZ%22%7D%2C70%2C720%2C0%5D">NIST SP 800-108r1, Section 4</a>, point 4), a counter (<em>i</em>) size of 16 bits, and omitting the optional <em>L</em> field, and produce a 256-bit derived key. Use that derived key and the last 96 bits of the input nonce with AES-256-GCM.</p>
</blockquote>
<p>Thanks to the choice of parameters, if we peel off the KDF and CMAC abstractions, the result is barely slower and more complex than straightforwardly invoking AES-256 on a counter. In exchange, we get a vetted and compliant solution. The parameters <a href="https://github.com/C2SP/C2SP/blob/main/XAES-256-GCM/openssl/openssl.c?ref=words.filippo.io">are supported by the high-level OpenSSL API</a>, too.</p>
<p>Why no more “/11”? Well, half the point of using AES-GCM is FIPS 140 compliance. (The other half being hardware acceleration.) If we mucked with the rounds number the design wouldn’t be compliant.</p>
<p>Indeed, if compliance is not a goal there are a number of alternatives, from AES-GCM-SIV to modern AEAD constructions based on the AES core. The specification has <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#alternatives">an extensive Alternatives section</a> that compares each of them to XAES-256-GCM.</p>
<p>Also included in the specification are <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#test-vectors">test vectors</a> for the two main code paths (MSB₁(<em>L</em>) = 0 and 1), and <a href="https://c2sp.org/XAES-256-GCM?ref=words.filippo.io#accumulated-randomized-tests">accumulated test vectors</a> that compress 10 000 or 1 000 000 random iterations.</p>
<p>To sum up, XAES-256-GCM is designed to be a safe, boring, compliant, and interoperable AEAD that can fit high-level APIs, the kind we’d like to add to Go. It’s designed to complement XChaCha20Poly1305 and AES-GCM-SIV as implementations of a hypothetical <a href="https://github.com/golang/go/issues/54364?ref=words.filippo.io#issuecomment-1642676993">nonce-less AEAD API</a>. If other cryptography library maintainers like it (or don’t), I would love to hear about it, because we are not big fans of adding Go-specific constructions to the standard library.</p>
<p>By the way, I have an exciting update about my professional open source maintainer effort coming in less than two weeks! Make sure to subscribe to <a href="https://filippo.io/newsletter?ref=words.filippo.io">Maintainer Dispatches</a> or to follow me on Bluesky at <a href="https://bsky.app/profile/filippo.abyssdomain.expert?ref=words.filippo.io">@filippo.abyssdomain.expert</a> or on Mastodon at <a href="https://abyssdomain.expert/@filippo?ref=words.filippo.io">@filippo@abyssdomain.expert</a>. (Or, see you at <a href="https://www.gophercon.com/?ref=words.filippo.io">GopherCon</a> in Chicago!)</p>
<h2 id="the-picture">The picture</h2>
<p>Earlier this year I ran in the <a href="https://www.centopassi.net/?ref=words.filippo.io">Centopassi</a> motorcycle competition. It involves driving more than 1600km on mountain roads, through one hundred GPS coordinates you select in advance from a long list, in three days and a half. It’s been fantastic. It took me to corners of Italy I would have never seen, and I had a lot of fun. This picture is taken at our 100th location, after a couple kilometers of unpaved hairpins on the side of the hill. The finish line was at the lake you can see in the distance. I was ecstatic.</p>
<p>That’s my 2014 KTM Duke 690, a single-cylinder “naked” from before KTM knew how to make larger street bikes. It’s weird and I love it.</p>
<p><img src="https://words.filippo.io/content/images/2024/06/IMG_1921.jpeg" alt="A black motorcycle with saddlebags and a race plate, parked on a dirt road overlooking a vast, scenic valley with green hills, a lake in the distance, and mountains under a bright blue sky with scattered white clouds." loading="lazy"></p>
<p>My awesome clients—<a href="https://www.sigsum.org/?ref=words.filippo.io">Sigsum</a>, <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a>, <a href="https://interchain.io/?ref=words.filippo.io">Interchain</a>, <a href="https://smallstep.com/?ref=words.filippo.io">Smallstep</a>, <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, <a href="https://goteleport.com/?ref=words.filippo.io">Teleport</a>, <a href="https://www.sandboxaq.com/?ref=words.filippo.io">SandboxAQ</a>, <a href="https://charm.sh/?ref=words.filippo.io">Charm</a>, and <a href="https://tailscale.com/?ref=words.filippo.io">Tailscale</a>—are funding all my work for the community and through our retainer contracts they get face time and unlimited access to advice on Go and cryptography.</p>
<p>Here are a few words from some of them!</p>
<p>Latacora — <a href="https://www.latacora.com/?ref=words.filippo.io">Latacora</a> bootstraps security practices for startups. Instead of wasting your time trying to hire a security person who is good at everything from Android security to AWS IAM strategies to SOC2 and apparently has the time to answer all your security questionnaires plus never gets sick or takes a day off, you hire us. We provide a crack team of professionals prepped with processes and power tools, coupling individual security capabilities with strategic program management and tactical project management.</p>
<p>Teleport — For the past five years, attacks and compromises have been shifting from traditional malware and security breaches to identifying and compromising valid user accounts and credentials with social engineering, credential theft, or phishing. <a href="https://goteleport.com/identity-governance-security/?utm=filippo&amp;ref=words.filippo.io">Teleport Identity Governance &amp; Security</a> is designed to eliminate weak access patterns through access monitoring, minimize attack surface with access requests, and purge unused permissions via mandatory access reviews.</p>
<p>Ava Labs — We at <a href="https://www.avalabs.org/?ref=words.filippo.io">Ava Labs</a>, maintainer of <a href="https://github.com/ava-labs/avalanchego?ref=words.filippo.io">AvalancheGo</a> (the most widely used client for interacting with the <a href="https://www.avax.network/?ref=words.filippo.io">Avalanche Network</a>), believe the sustainable maintenance and development of open source cryptographic protocols is critical to the broad adoption of blockchain technology. We are proud to support this necessary and impactful work through our ongoing sponsorship of Filippo and his team.</p>
<p>SandboxAQ — <a href="https://www.sandboxaq.com/?ref=words.filippo.io">SandboxAQ</a>’s <a href="https://www.sandboxaq.com/solutions/aqtive-guard?ref=words.filippo.io">AQtive Guard</a> is a unified cryptographic management software platform that helps protect sensitive data and ensures compliance with authorities and customers. It provides a full range of capabilities to achieve cryptographic agility, acting as an essential cryptography inventory and data aggregation platform that applies current and future standardization organizations mandates. AQtive Guard automatically analyzes and reports on your cryptographic security posture and policy management, enabling your team to deploy and enforce new protocols, including quantum-resistant cryptography, without re-writing code or modifying your IT infrastructure.</p>

        </section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A Eulogy for DevOps (205 pts)]]></title>
            <link>https://matduggan.com/a-eulogy-for-devops/</link>
            <guid>40826236</guid>
            <pubDate>Fri, 28 Jun 2024 22:59:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/a-eulogy-for-devops/">https://matduggan.com/a-eulogy-for-devops/</a>, See on <a href="https://news.ycombinator.com/item?id=40826236">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>We hardly knew ye. </p><p>DevOps, like many trendy technology terms, has gone from the peak of optimism to the depths of exhaustion. While many of the fundamental ideas behind the concept have become second-nature for organizations, proving it did in fact have a measurable outcome, the difference between the initial intent and where we ended up is vast. For most organizations this didn't result in a wave of safer, easier to use software but instead encouraged new patterns of work that centralized risk and introduced delays and irritations that didn't exist before. We can move faster than before, but that didn't magically fix all our problems. </p><p>The cause of its death was a critical misunderstanding over what was causing software to be hard to write. The belief was by removing barriers to deployment, more software would get deployed and things would be easier and better. Effectively that the issue was that developers and operations teams were being held back by ridiculous process and coordination. In reality these "soft problems" of communication and coordination are much more difficult to solve than the technical problems around pushing more code out into the world more often. </p><h3 id="what-is-devops">What is DevOps?</h3><p>DevOps, when it was introduced around 2007, was a pretty radical concept of removing the divisions between people who ran the hardware and people who wrote the software. Organizations still had giant silos between teams, with myself experiencing a lot of that workflow. </p><p>Since all computer nerds also love space, it was basically us cosplaying as NASA. Copying a lot of the procedures and ideas from NASA to try and increase the safety around pushing code out into the world. Different organizations would copy and paste different parts, but the basic premise was every release was as close to bug free as time allowed. You were typically shooting for zero exceptions.</p><p>When I worked for a legacy company around that time, the flow for releasing software looked as follows. </p><ul><li>Development team would cut a release of the server software with a release number in conjunction with the frontend team typically packaged together as a full entity. They would test this locally on their machines, then it would go to dev for QA to test, then finally out to customers once the QA checks were cleared. </li><li>Operations teams would receive a playbook of effectively what the software was changing and what to do if it broke. This would include how it was supposed to be installed, if it did anything to the database, it was a whole living document. The idea was the people managing the servers, networking equipment and SANs had no idea what the software did or how to fix it so they needed what were effectively step by step instructions. Sometimes you would even get this as a paper document. </li><li>Since these happened often inside of your datacenter, you didn't have unlimited elasticity for growth. So, if possible, you would slowly roll out the update and stop to monitor at intervals. But you couldn't do what people see now as a blue/green deployment because rarely did you have enough excess server capacity to run two versions at the same time for all users. Some orgs did do different datacenters at different times and cut between them (which was considered to be sort of the highest tier of safety). </li><li>You'd pick a deployment day, typically middle of the week around 10 AM local time and then would monitor whatever metrics you had to see if the release was successful or not. These were often pretty basic metrics of success, including some real eyebrow raising stuff like "is support getting more tickets" and "are we getting more hits to our uptime website". Effectively "is the load balancer happy" and "are customers actively screaming at us". </li><li>You'd finish the deployment and then the on-call team would monitor the progress as you went. </li></ul><h3 id="why-didnt-this-work">Why Didn't This Work</h3><p>Part of the issue was this design was very labor-intensive. You needed enough developers coordinating together to put together a release. Then you needed a staffed QA team to actually take that software and ensure, on top of automated testing which was jusssttttt starting to become a thing, that the software actually worked. Finally you needed a technical writer working with the development team to walk through what does a release playbook look like and then finally have the Operations team receive, review the book and then implement the plan. </p><p>It was also slow. Features would often be pushed for months even when they were done just because a more important feature had to go out first. Or this update was making major changes to the database and we didn't want to bundle in six things with the one possibly catastrophic change. It's effectively the Agile vs Waterfall design broken out to practical steps. </p><figure><img src="https://kruschecompany.com/wp-content/uploads/2021/09/Waterfall-vs-Agile-in-software-development-infographic.jpg" alt="Waterfall vs Agile in software development infographic" loading="lazy" width="1000" height="2000"></figure><p>A lot of the lip service around this time that was given as to why organizations were changing was, frankly, bullshit. The real reason companies were so desperate to change was the following:</p><ul><li>Having lots of mandatory technical employees they couldn't easily replace was a bummer</li><li>Recruitment was hard and expensive. </li><li>Sales couldn't easily inject whatever last-minute deal requirement they had into the release cycle since that was often set it stone. </li><li>It provided an amazing opportunity for SaaS vendors to inject themselves into the process by offloading complexity into their stack so they pushed it hard.</li><li>The change also emphasized the strengths of cloud platforms at the time when they were starting to gobble market share. You didn't need lots of discipline, just allocate more servers. </li><li>Money was (effectively) free so it was better to increase speed regardless of monthly bills. </li><li>Developers were understandably frustrated that minor changes could take weeks to get out the door while they were being blamed for customer complaints.</li></ul><p>So executives went to a few conferences and someone asked them if they were "doing DevOps" and so we all changed our entire lives so they didn't feel like they weren't part of the cool club. </p><h3 id="what-was-devops">What Was DevOps?</h3><p>Often this image is used to sum it up:</p><figure><img src="https://wac-cdn.atlassian.com/dam/jcr:ef9fe684-c6dc-4ba0-a636-4ef7bcfa11f1/New%20DevOps%20Loop%20image.png?cdnVersion=1833" alt="DevOps Infinity Wheel" loading="lazy" width="2240" height="1090"></figure><p>In a nutshell, the basic premise was that development teams and operations teams were now one team. QA was fired and replaced with this idea that because you could very quickly deploy new releases and get feedback on those releases, you didn't need a lengthy internal test period where every piece of functionality was retested and determined to still be relevant. </p><p>Often this is <em>conflated</em> with the concept of SRE from Google, which I will argue until I die is a giant mistake. SRE is in the same genre but a very different tune, with a much more disciplined and structured approach to this problem. DevOps instead is about the simplification of the stack such that any developer on your team can deploy to production as many times in a day as they wish with only the minimal amounts of control on that deployment to ensure it had a reasonably high chance of working. </p><p>In reality DevOps as a practice looks much more like how Facebook operated, with employees committing to production on their first day and relying extensively on real-world signals to determine success or failure vs QA and tightly controlled releases. </p><p>In practice it looks like this:</p><ul><li>Development makes a branch in git and adds a feature, fix, change, etc. </li><li>They open up a PR and then someone else on that team looks at it, sees it passes their internal tests, approves it and then it gets merged into main. This is effectively the only safety step, relying on the reviewer to have perfect knowledge of all systems. </li><li>This triggers a webhook to the CI/CD system which starts the build (often of an entire container with this code inside) and then once the container is built, it's pushed to a container registry. </li><li>The CD system tells the servers that the new release exists, often through a Kubernetes deployment or pushing a new version of an internal package or using the internal CLI of the cloud providers specific "run a container as a service" platform. It then monitors and tells you about the success or failure of that deployment. </li><li>Finally there are release-aware metrics which allow that same team, who is on-call for their application, to see if something has changed since they released it. Is latency up, error count up, etc. This is often just a line in a graph saying this was old and this is new. </li><li>Depending on the system, this can either be something where every time the container is deployed it is on brand-new VMs or it is using some system like Kubernetes to deploy "the right number" of containers. </li></ul><p>The sales pitch was simple. Everyone can do everything so teams no longer need as many specialized people. Frameworks like Rails made database operations less dangerous, so we don't need a team of DBAs. Hell, use something like Mongo and you never need a DBA! </p><p>DevOps combined with Agile ended up with a very different philosophy of programming which had the following conceits:</p><ul><li>The User is the Tester</li><li>Every System Is Your Specialization </li><li>Speed Of Shipping Above All</li><li>Catch It In Metrics</li><li>Uptime Is Free, SSO Costs Money (free features were premium, expensive availability wasn't charged for)</li><li>Logs Are Business Intelligence</li></ul><h3 id="what-didnt-work">What Didn't Work</h3><p>The first cracks in this model emerged pretty early on. Developers were testing on their local Mac and Windows machines and then deploying code to Linux servers configured from Ansible playbooks and left running for months, sometimes years. Inevitably small differences in the running fleet of production servers emerged, either from package upgrades for security reasons or just from random configuration events. This could be mitigated by frequently rotating the running servers by destroying and rebuilding them as fresh VMs, but in practice this wasn't done as often as it should have been. </p><p>Soon you would see things like "it's running fine on box 1,2, 4, 5, but 3 seems to be having problems". It wasn't clear in the DevOps model <em>who</em> exactly was supposed to go figure out what was happening or how. In the previous design someone who worked with Linux for years and with these specific servers would be monitoring the release, but now those team members often wouldn't even know a deployment was happening. Telling someone who is amazing at writing great Javascript to go "find the problem with a Linux box" turned out to be easier said than done. </p><p>Quickly feedback from developers started to pile up. They didn't want to have to spend all this time figuring out what Debian package they wanted for this or that dependency. It wasn't what they were interested in doing and also they weren't being rewarded for that work, since they were almost exclusively being measured for promotions by the software they shipped. This left the Operations folks in charge of "smoothing out" this process, which in practice often meant really wasteful practices. </p><p>You'd see really strange workflows around this time of doubling the number of production servers you were paying for by the hour during a deployment and then slowly scaling them down, all relying on the same AMI (server image) to ensure some baseline level of consistency. However since any update to the AMI required a full dev-stage-prod check, things like security upgrades took <em>a very long time</em>. </p><p>Soon you had just a pile of issues that became difficult to assign. Who "owned" platform errors that didn't result in problems for users? When a build worked locally but failed inside of Jenkins, what team needed to check that? The idea of we're all working on the same team broke down when it came to assigning ownership of annoying issues because <em>someone</em> had to own them or they'd just sit there forever untouched. </p><h3 id="enter-containers">Enter Containers</h3><p>DevOps got a real shot in the arm with the popularization of containers, which allowed the movement to progress past its awkward teenage years. Not only did this (mostly) solve the "it worked on my machine" thing but it also allowed for a massive simplification of the Linux server component part. Now servers were effectively dumb boxes running containers, either on their own with Docker compose or as part of a fleet with Kubernetes/ECS/App Engine/Nomad/whatever new thing that has been invented in the last two weeks. </p><p>Combined with you could move almost everything that might previous be a networking team problem or a SAN problem to configuration inside of the cloud provider through tools like Terraform and you saw a real flattening of the skill curve. This greatly reduced the expertise required to operate these platforms and allowed for more automation. Soon you started to see what we now recognize as the current standard for development which is "I push out a bajillion changes a day to production". </p><h3 id="what-containers-didnt-fix">What Containers Didn't Fix</h3><p>So there's a lot of other shit in that DevOps model we haven't talked about. </p><figure><img src="https://matduggan.com/content/images/2024/06/New-DevOps-Loop-image.png" alt="" loading="lazy" width="2000" height="973" srcset="https://matduggan.com/content/images/size/w600/2024/06/New-DevOps-Loop-image.png 600w, https://matduggan.com/content/images/size/w1000/2024/06/New-DevOps-Loop-image.png 1000w, https://matduggan.com/content/images/size/w1600/2024/06/New-DevOps-Loop-image.png 1600w, https://matduggan.com/content/images/2024/06/New-DevOps-Loop-image.png 2240w" sizes="(min-width: 720px) 720px"></figure><p>So far teams had improved the "build, test and deploy" parts. However operating the crap was still very hard. Observability was <em>really really</em> hard and expensive. Discoverability was actually harder than ever because stuff was constantly changing beneath your feet and finally the Planning part immediately collapsed into the ocean because now teams could do whatever they wanted all the time. </p><p><strong>Operate</strong></p><p>This meant someone going through and doing all the boring stuff. Upgrading Kubernetes, upgrading the host operating system, making firewall rules, setting up service meshes, enforcing network policies, running the bastion host, configuring the SSH keys, etc. What organizations quickly discovered was that this stuff was very time consuming to do and often required <em>more</em> specialization than the roles they had previously gotten rid of. </p><p>Before you needed a DBA, a sysadmin, a network engineer and some general Operations folks. Now you needed someone who not only understood databases but understood <em>your specific cloud providers</em> version of that database. You still needed someone with the sysadmin skills, but in addition they needed to be experts in your cloud platform in order to ensure you weren't exposing your database to the internet. Networking was still critical but now it all existed at a level outside of your control, meaning weird issues would sometimes have to get explained as "well that sometimes happens". </p><p>Often teams would delay maintenance tasks out of a fear of breaking something like k8s or their hosted database, but that resulted in delaying the pain and making their lives more difficult. This was the era where every startup I interviewed with basically just wanted someone to update all the stuff in their stack "safely". Every system was well past EOL and nobody knew how to Jenga it all together. </p><p><strong>Observe</strong></p><p>As applications shipped more often, knowing they worked became more important so you could roll back if it blew up in your face. However replacing simple uptime checks with detailed traces, metrics and logs was hard. These technologies are specialized and require detailed understanding of what they do and how they work. A syslog centralized box lasts <em>to a point</em> and then it doesn't. Prometheus scales to x amount of metrics and then no longer works on a single box. You needed someone who had a detailed understanding of how metrics, logs and traces worked and how to work with development teams in getting them sending the correct signal to the right places at the right amount of fidelity. </p><p>Or you could pay a SaaS a <em>shocking amount</em> to do it for you. The rise of companies like Datadog and the eye-watering bills that followed was proof that they understood how important what they were providing was. You quickly saw Observability bills exceed CPU and networking costs for organizations as one team would misconfigure their application logs and suddenly you have blown through your monthly quota in a week. </p><p>Developers were being expected to monitor with detailed precision what was happening with their applications without a full understanding of what they were seeing. How many metrics and logs were being dropped on the floor or sampled away, how did the platform work in displaying these logs to them, how do you write an query for terabytes of logs so that you can surface what you need quickly, all of this was being passed around in Confluence pages being written by desperate developers who were learning as they were getting paged at 2AM how all this shit works together. </p><p><strong>Continuous Feedback</strong></p><p>This to me is the same problem as Observe. It's about whether your deployment worked or not and whether you had signal from internal tests if it was likely to work. It's also about feedback from the team on what in this process worked and what didn't, but because nobody ever did anything with that internal feedback we can just throw that one directly in the trash. </p><p>I guess in theory this would be retros where we all complain about the same six things every sprint and then continue with our lives. I'm not an Agile Karate Master so you'll need to talk to the experts. </p><p><strong>Discover</strong></p><p>A big pitch of combining these teams was the idea of more knowledge sharing. Development teams and Operation teams would be able to cross-share more about what things did and how they worked. Again it's an interesting idea and there was some improvement to discoverability, but in practice that isn't how the incentives were aligned. </p><p>Developers weren't rewarded for discovering more about how the platform operated and Operations didn't have any incentive to sit down and figure out how the frontend was built. It's not a lack of intellectual curiosity by either party, just the finite amount of time we all have before we die and what we get rewarded for doing. Being surprised that this didn't work is like being surprised a mouse didn't go down the tunnel with no cheese just for the experience. </p><p>In practice I "discovered" that if NPM was down nothing worked and the frontend team "discovered" that troubleshooting Kubernetes was a bit like Warhammer 40k Adeptus Mechanicus waving incense in front of machines they didn't understand in the hopes that it would make the problem go away. </p><figure><img src="https://warhammeruniverse.com/wp-content/uploads/2023/12/00007-2552221792-1024x569.png" alt="The Adeptus Mechanicus - Warhammer Universe (2024)" loading="lazy" width="1024" height="569"><figcaption><span>Try restarting the Holy Deployment</span></figcaption></figure><p><strong>Plan</strong></p><p>Maybe more than anything else, this lack of centralization impacted planning. Since teams weren't syncing on a regular basis anymore, things could continue in crazy directions unchecked. In theory PMs were syncing with each other to try and ensure there were railroad tracks in front of the train before it plowed into the ground at 100 MPH, but that was a lot to put on a small cadre of people. </p><p>We see this especially in large orgs with microservices where it is easier to write a new microservice to do something rather than figure out which existing microservice does the thing you are trying to do. This model was sustainable when money was free and cloud budgets were unlimited, but once that gravy train crashed into the mountain of "businesses need to be profitable and pay taxes" that stopped making sense. </p><h3 id="the-part-where-we-all-gave-up">The Part Where We All Gave Up</h3><p>A lot of orgs solved the problems above by simply throwing bodies into the mix. More developers meant it was possible for teams to have someone (anyone) learn more about the systems and how to fix them. Adding more levels of PMs and overall planning staff meant even with the frantic pace of change it was...more possible to keep an eye on what was happening. While cloud bills continued to go unbounded, for the most part these services worked and allowed people to do the things they wanted to do. </p><p>Then layoffs started and budget cuts. Suddenly it wasn't acceptable to spend unlimited money with your logging platform and your cloud provider as well as having a full team. Almost instantly I saw the shift as organizations started talking about "going back to basics". Among this was a hard turn in the narrative around Kubernetes where it went from an amazing technology that lets you grow to Google-scale to a weight around an organizations neck nobody understood. </p><p><strong>Platform Engineering</strong></p><p>Since there are no new ideas, just new terms, a successor to the throne has emerged. No longer are development teams expected to understand and troubleshoot the platforms that run their software, instead the idea is that the entire process is completely abstracted away from them. They provide the container and that is the end of the relationship. </p><p>From a certain perspective this makes more sense since it places the ownership for the operation of the platform with the people who should have owned it from the beginning. It also removes some of the ambiguity over what is whose problem. The development teams are still on-call for their specific application errors, but platform teams are allowed to enforce more global rules. </p><p>Well at least in theory. In practice this is another expansion of roles. You went from needing to be a Linux sysadmin to being a cloud-certified Linux sysadmin to being a Kubernetes-certified multicloud Linux sysadmin to finally being an application developer who can create a useful webUI for deploying applications on top of a multicloud stack that runs on Kubernetes in multiple regions with perfect uptime and observability that doesn't blow the budget. I guess at some point between learning the difference between AWS and GCP we were all supposed to go out and learn how to make useful websites. </p><figure><img src="https://cdn.prod.website-files.com/622b2fcc29fc56492b771cb8/637d1841fc5e9a6a942d5a02_1.png" alt="" loading="lazy" width="1600" height="683"></figure><p>This division of labor makes no sense but at least it's something I guess. Feels like somehow Developers got stuck with a lot more work and Operation teams now need to learn 600 technologies a week. Surprisingly tech executives didn't get any additional work with this system. I'm sure the next reorg they'll chip in more. </p><h3 id="conclusion">Conclusion</h3><p>We are now seeing a massive contraction of the Infrastructure space. Teams are increasingly looking for simple, less platform specific tooling. In my own personal circles it feels like a real return to basics, as small and medium organizations abandon technology like Kubernetes and adopt much more simple and easy-to-troubleshoot workflows like "a bash script that pulls a new container". </p><p>In some respects it's a positive change, as organizations stop pretending they needed a "global scale" and can focus on actually servicing the users and developers they have. In reality a lot of this technology was adopted by organizations who weren't ready for it and didn't have a great plan for how to use it. </p><p>However Platform Engineering is not a magical solution to the problem. It is instead another fabrication of an industry desperate to show monthly growth in cloud providers who know teams lack the expertise to create the kinds of tooling described by such practices. In reality organizations need to be more brutally honest about what they <em>actually need</em> vs what bullshit they've been led to believe they need. </p><p>My hope is that we keep the gains from the DevOps approach and focus on simplification and stability over rapid transformation in the Infrastructure space. I think we desperately need a return to basics ideology that encourages teams to stop designing with the expectation that endless growth is the only possible outcome of every product launch. </p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Open source 'Eclipse Theia IDE' exits beta to challenge Visual Studio Code (181 pts)]]></title>
            <link>https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx</link>
            <guid>40825146</guid>
            <pubDate>Fri, 28 Jun 2024 20:49:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx">https://visualstudiomagazine.com/Articles/2024/06/27/eclipse-theia-ide.aspx</a>, See on <a href="https://news.ycombinator.com/item?id=40825146">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="level0"> 
        
        <p id="ph_pcontent2_0_KickerText"><a href="https://visualstudiomagazine.com/Articles/List/News.aspx">News</a></p>
        
        <h3 id="ph_pcontent2_0_MainHeading">Open Source 'Eclipse Theia IDE' Exits Beta to Challenge Visual Studio Code</h3>
        
        
        

        <p>
  Some seven years in the making, the Eclipse Foundation's Theia IDE project is now generally available, emerging from beta to challenge Microsoft's similar Visual Studio Code editor, with which it shares much tech.
  
</p>



<p>
   The <a href="https://theia-ide.org/#theiaide" target="_blank">Eclipse Theia IDE</a>, part of the <a href="https://ecdtools.eclipse.org/" target="_blank">Eclipse Cloud DevTools ecosystem</a>, primarily differs from VS Code in licensing and governance. Open-source champion Eclipse Foundation calls it a "true open-source alternative" to VS Code, which Microsoft has <a href="https://code.visualstudio.com/docs/supporting/faq" target="_blank">described</a> as being "built" on open source but with proprietary elements like default telemetry with which usage data is collected.
 
</p>



<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_desktop.ashx" target="_blank">
<img alt="Eclipse Theia IDE in on Windows" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_desktop_s.ashx" height="160" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Eclipse Theia IDE in on Windows <em>(source: Screenshot).</em></figcaption>
</figure></div>




<p>
  Note that Eclipse Theia IDE is a separate component from the overall Theia project's related <a href="https://projects.eclipse.org/projects/ecd.theia" target="_blank">Eclipse Theia Platform</a>, used to build IDEs and tools based on modern web technologies.
  
</p>






<p>
  As far as the similarities with VS Code, Theia is built on the same <a href="https://microsoft.github.io/monaco-editor/" target="_blank">Monaco editor</a> that powers VS Code, and it supports the same Language Server Protocol (LSP) and Debug Adapter Protocol (DAP) that provide IntelliSense code completions, error checking and other features.
  
</p>



<p>
  Eclipse Theia IDE also supports the same extensions as VS Code (via the <a href="https://open-vsx.org/" target="_blank">Open VSX Registry</a> instead of Microsoft's Visual Studio Code Marketplace), which are typically written in TypeScript and JavaScript. There are many, many more extensions available for VS Code in Microsoft's marketplace, while "Extensions for VS Code Compatible Editors" in the Open VSX Registry number 3,784 at the time of this writing. 
</p>

    

<br>



<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/open_vsx.ashx" target="_blank">
<img alt="Open VSX Registry" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/open_vsx_s.ashx" height="159" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Open VSX Registry <em>(source: Open VSX Registry).</em></figcaption>
</figure></div>




<p>
Eclipse Foundation <a href="https://eclipsesource.com/blogs/2019/12/06/the-eclipse-theia-ide-vs-vs-code/" target="_blank">compared the two tools</a> in 2019, when it said to make a good decision between using VS Code or Eclipse Theia as a platform for a tool, an organization will need to evaluate custom project requirements, noting that as a general direction:
</p>




<ul>
<li>If you want to provide some tooling, which is focussed on code and want as many developers as possible to use it in their existing IDE, providing an extension for VS Code seems like a valid choice.
</li>
<li>If you want to provide a white-labeled product for customers or your own developers, which is tailored to a specific use case and possibly contains more features than code editing, you might be better served with Eclipse Theia.</li>
</ul>




<p>
  A somewhat more recent <a href="https://blogs.eclipse.org/post/mike-milinkovich/eclipse-theia-and-vs-code-differences-explained" target="_blank">post</a> from 2020 exploring the differences between the Eclipse Theia Platform (not IDE) and VS Code noted two primary ways in which the projects' architectures differ:
  
</p>



<ul>
<li>Eclipse Theia allows developers to create desktop and cloud IDEs using a single, open source technology stack. Microsoft now offers VS Online for cloud development environments, but like VS Code, it cannot be used in open source initiatives such as Gitpod.
</li>
<li>Eclipse Theia allows developers to customize every aspect of the IDE without forking or patching the code. This means they can easily use Theia as a base to develop desktop and cloud IDEs that are fully tailored for the needs of internal company projects or for commercial resale as a branded product. VS Code is a developer IDE only. It was never intended to be used as the base for other IDEs, extended, or further distributed.</li>
</ul>




<p>
  For developers just wanting to pick a tool to write apps with, an Eclipse Foundation blog <a href="https://eclipsesource.com/blogs/2024/06/27/introducing-the-theia-ide/" target="_blank">post</a> today said: "For developers in search of an IDE that combines flexibility, openness, and cutting-edge technology, the Theia IDE is a compelling choice. Distinctive features like an adaptable toolbar, detachable views, remote development support, and the forthcoming live collaboration mode set Theia apart from other open-source IDEs. Moreover, its commitment to privacy and its stance against incorporating telemetry by default reflect its respect for user preferences."
</p>






<p>
  Eclipse Foundation today emphasized another difference between its Theia IDE and VS Code: the surrounding ecosystem/community.
</p>




<div><figure> <a href="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_community.ashx" target="_blank">
<img alt="Eclipse Theia Community" src="https://visualstudiomagazine.com/Articles/2024/06/27/~/media/ECG/visualstudiomagazine/Images/2024/06/theia_community_s.ashx" height="220" width="300"> </a>
<figcaption> <b>[Click on image for larger view.]</b> Eclipse Theia Community <em>(source: Eclipse).</em></figcaption>
</figure></div>




<p>
  "At the core of Theia IDE is its vibrant open source community hosted by the Eclipse Foundation," the organization <a href="https://newsroom.eclipse.org/news/announcements/eclipse-foundation-introduces-theia-ide-elevate-modern-developer-experience" target="_blank">said</a> in a news release. "This ensures freedom for commercial use without proprietary constraints and fosters innovation and reliability through contributions from companies like Ericsson, EclipseSource, STMicroelectronics, TypeFox, and more. The community-driven model encourages participation and adaptation according to user needs and feedback."
</p>




<p>
  Indeed, the list of contributors to and adopters of the platform is extensive, also featuring Broadcom, Arm, IBM, Red Hat, SAP, Samsung, Google, Gitpod, Huawei and many others.
</p>




<p>
  "The Theia IDE's open-source foundation, supported by a vibrant community and underpinned by a license that champions commercial use, sets the stage for a development environment that is not only powerful and flexible but also inclusive and forward-looking," Eclipse Foundation concluded in its announcement today. "By choosing the Theia IDE, developers and organizations are not just adopting an IDE; they are joining a movement that values collaboration, freedom, and the collective pursuit of excellence in software development."
</p>
<br>
        
        
        
        
        
        
        
        <!-- pager start -->
        
        <!-- pager end -->
        
        
            
        

        
                <div>
                    <p id="ph_pcontent2_0_AuthorInfo_AboutAuthor">About the Author</p>
                    
                <p>
                    <strong></strong>
                    David Ramel is an editor and writer for Converge360.
                    <br>
                    
                    <a id="ph_pcontent2_0_AuthorInfo_AuthorEmail_0"></a>
                </p>
            
                </div>
            
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[The story, as best I can remember, of the origin of Mosaic and Netscape [video] (285 pts)]]></title>
            <link>https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember</link>
            <guid>40825033</guid>
            <pubDate>Fri, 28 Jun 2024 20:39:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember">https://pmarca.substack.com/p/the-true-story-as-best-i-can-remember</a>, See on <a href="https://news.ycombinator.com/item?id=40825033">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-testid="navbar"><p><a href="https://pmarca.substack.com/" native=""><img src="https://substackcdn.com/image/fetch/w_96,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"></a></p><h2><a href="https://pmarca.substack.com/" native="">Marc Andreessen Substack</a></h2></div><div><div><article><div><div><div><div><div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="m12 14 4-4"></path><path d="M3.34 19a10 10 0 1 1 17.32 0"></path></svg><p>Playback speed</p></div><div><p>×</p></div></div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share post</p></div></div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share post at current time</p></div></div></div><div><div><div><div id="trigger27149" aria-expanded="false" aria-haspopup="dialog" aria-controls="dialog27150" arialabel="View more"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M4 12v8a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2v-8"></path><polyline points="16 6 12 2 8 6"></polyline><line x1="12" x2="12" y1="2" y2="15"></line></svg><p>Share from 0:00</p></div></div></div><div><div><p>0:00</p><p>/</p><p>0:00</p></div></div></div></div><div><div><p>Transcript</p></div></div></div></div><div><div><div><div><p>Enjoy!</p></div><div><div><a href="https://substack.com/profile/22353-marc-andreessen" target="_blank" rel="noopener"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_80,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_80,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="100vw" alt="" width="80"></picture></a></div><div><div><p><a href="https://substack.com/@pmarca">Marc Andreessen</a></p></div><div><p>Jun 28, 2024</p></div></div></div><div><span><p>Share</p></span><a role="button"><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="var(--color-secondary-themed)" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="21" x2="3" y1="6" y2="6"></line><line x1="15" x2="3" y1="12" y2="12"></line><line x1="17" x2="3" y1="18" y2="18"></line></svg><p>Transcript</p></a></div></div></div><div><div><div><div><a href="https://pmarca.substack.com/" native=""><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 48w, https://substackcdn.com/image/fetch/w_96,h_96,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 96w, https://substackcdn.com/image/fetch/w_144,h_144,c_fill,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 144w" sizes="48px"><img src="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="48px" alt="Marc Andreessen Substack" srcset="https://substackcdn.com/image/fetch/w_48,h_48,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 48w, https://substackcdn.com/image/fetch/w_96,h_96,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 96w, https://substackcdn.com/image/fetch/w_144,h_144,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg 144w" width="48" height="48"></picture></a></div><p>Marc Andreessen Substack</p></div><div data-component-name="SubscribeWidget"><form action="/api/v1/free?nojs=true" method="post" novalidate=""></form></div></div><div><div><p>Authors</p><div><div><a href="https://substack.com/profile/22353-marc-andreessen?utm_source=author-byline-face-podcast" target="_blank" rel="noopener"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_64,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg"><img src="https://substackcdn.com/image/fetch/w_64,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa8ef02fe-d089-466f-9b4a-ea19df828473_400x400.jpeg" sizes="100vw" alt="" width="64"></picture></a></div><div><p>Marc Andreessen</p></div></div></div><div><p>Recent Posts</p><div><div><p><img type="image/gif" src="https://pmarca.substack.com/api/v1/video/upload/b33e4bc3-2428-4b56-8367-cd1d85a680cc/preview.gif?height=480"></p><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_150,h_150,c_fill,f_webp,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F143254349%2Fb33e4bc3-2428-4b56-8367-cd1d85a680cc%2Ftranscoded-00001.png"><img src="https://substackcdn.com/image/fetch/w_150,h_150,c_fill,f_auto,q_auto:good,fl_progressive:steep,g_center/https%3A%2F%2Fsubstack-video.s3.amazonaws.com%2Fvideo_upload%2Fpost%2F143254349%2Fb33e4bc3-2428-4b56-8367-cd1d85a680cc%2Ftranscoded-00001.png" sizes="(min-width:768px) 50vw, 100vw" alt="" width="150" height="150"></picture></div><div><div><p><a href="https://pmarca.substack.com/p/on-tech-politicspolicy-2-hour-video" data-testid="post-preview-title">On Tech Politics/Policy -- 2 hour video discussion</a></p></div><div><p><time datetime="2024-04-04T05:37:52.095Z">Apr 4</time>&nbsp;<span>•</span>&nbsp;<span><a href="https://substack.com/@pmarca">Marc Andreessen</a></span></p></div></div></div></div></div></div></div></div></article></div><div><p>Ready for more?</p><div><form action="/api/v1/free?nojs=true" method="post" novalidate=""></form></div></div></div><div><div><p>© 2024 Marc Andreessen</p><div><p><a href="https://substack.com/privacy" target="_blank" rel="noopener noreferrer">Privacy</a><span> ∙ </span><a href="https://substack.com/tos" target="_blank" rel="noopener noreferrer">Terms</a><span> ∙ </span><a href="https://substack.com/ccpa#personal-data-collected" target="_blank" rel="noopener noreferrer">Collection notice</a></p></div></div><div><a native="" href="https://substack.com/signup?utm_source=substack&amp;utm_medium=web&amp;utm_content=footer"><svg role="img" width="1000" height="1000" viewBox="0 0 1000 1000" fill="#FF6719" stroke-width="1.8" stroke="none" xmlns="http://www.w3.org/2000/svg"><g><title></title><path d="M764.166 348.371H236.319V419.402H764.166V348.371Z"></path><path d="M236.319 483.752V813.999L500.231 666.512L764.19 813.999V483.752H236.319Z"></path><path d="M764.166 213H236.319V284.019H764.166V213Z"></path></g></svg> Start Writing</a><p><a native="" href="https://substack.com/app/app-store-redirect?utm_campaign=app-marketing&amp;utm_content=web-footer-button">Get the app</a></p></div><p><a href="https://substack.com/" native="">Substack</a> is the home for great culture</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[US Supreme Court allows cities to ban homeless camps (112 pts)]]></title>
            <link>https://www.bbc.com/news/articles/cj774nxrpy7o</link>
            <guid>40823850</guid>
            <pubDate>Fri, 28 Jun 2024 18:54:20 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.bbc.com/news/articles/cj774nxrpy7o">https://www.bbc.com/news/articles/cj774nxrpy7o</a>, See on <a href="https://news.ycombinator.com/item?id=40823850">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="byline" data-component="byline-block"><p><time>10 hours ago</time></p><div><p><span data-testid="byline-name">By&nbsp;<!-- -->Samantha Granville<!-- -->,&nbsp;<!-- --></span><span>BBC News, Los Angeles</span></p></div></div><div data-component="text-block"><p>The US Supreme Court has ruled in a 6-3 vote along ideological lines that cities can ban homeless people from sleeping rough.<!-- --></p><p>It is the court's most significant decision on homelessness since at least the 1980s, when many experts say the modern US homeless crisis began.<!-- --></p><p>The ruling says that local governments can enforce laws against people sleeping in public places without being in violation of the US constitution's limits on cruel and unusual punishment.<!-- --></p><p>The case started in the small city of Grants Pass, Oregon, where three homeless people sued after receiving citations for sleeping and camping outside.<!-- --></p><p>At a Supreme Court hearing in April, the city argued that criminal penalties were necessary to enforce local laws banning homeless people from public spaces for "reasons of cleanliness and safety".<!-- --></p><p>The homeless residents said those penalties violated the Eighth Amendment of the US Constitution because the city did not have any public shelters.<!-- --></p><p>Writing for the conservative majority in an opinion issued on Friday, Justice Neil Gorsuch wrote that the city's regulations on camping do not inflict “terror, pain or disgrace”.<!-- --></p><p>He added that the law does not criminalise the “mere status” of being homeless, and that the ban focuses more on the actions taken by individuals rather than their status alone.<!-- --></p><p>“Under the city’s laws, it makes no difference whether the charged defendant is homeless, a backpacker on vacation passing through town, or a student who abandons his dorm room to camp out in protest on the lawn of a municipal building,” Justice Gorsuch wrote.<!-- --></p><p>Justice Sonia Sotomayor, writing on behalf of the three dissenting liberal justices, wrote: “Sleep is a biological necessity, not a crime. Homelessness is a reality for so many Americans.”<!-- --></p><p>Several cities issued statements welcoming the ruling. San Francisco said it would help cities "manage our public spaces more effectively and efficiently," and the city of Grants Pass, the centre of the legal dispute, said that city leaders would meet with their lawyers to discuss next steps. <!-- --></p><p>Homelessness is on the rise in the US, fuelled in part by chronic shortages of affordable housing. Around 653,000 people did not have homes in 2023, the largest number since tracking began in 2007, according to US government figures. <!-- --></p><p>There were also an estimated 256,000 people living without shelter on a given night across the country last year, according to the <!-- --><a target="_blank" href="https://www.huduser.gov/portal/sites/default/files/pdf/2023-AHAR-Part-1.pdf">Department of Housing and Urban Development.<!-- --></a></p><p>Reacting to the ruling, the National Alliance to End Homelessness said it "sets a dangerous precedent that will cause undue harm to people experiencing homelessness and give free reign to local officials who prefer pointless and expensive arrests and imprisonment, rather than real solutions".<!-- --></p><p>Grants Pass's population has doubled to 40,000 in the last 20 years, but its supply of affordable or public housing has not.<!-- --></p><p>Soaring housing costs led to a sizeable number of people losing their homes.<!-- --></p><p>Town officials responded by passing laws that fined people for sleeping or camping in public. Over time, those fines stacked up, reaching thousands of dollars for some.<!-- --></p><p>Unable to pay for multiple citations, three homeless people sued the city.<!-- --></p><p>Their lawsuit reached the 9th Circuit Court of Appeals, which decided in 2022 that the restrictions in Grants Pass were so tight that they amounted to an effective ban on being homeless within city limits.<!-- --></p><p>The court had determined four years earlier in a similar case in Idaho that the constitution “bars a city from prosecuting people criminally for sleeping outside on public property when those people have no home or other shelter to go to".<!-- --></p></div><div data-component="text-block"><p>Meanwhile, the homeless crisis has continued to worsen.<!-- --></p><p>Jennifer Friedenbach, of the Coalition on Homelessness in San Francisco, said that money and resources should "go towards getting folks off the streets".<!-- --></p><p>“What we know is that arresting and fining people for being homeless doesn't work," she said. "It doesn't get anybody off the streets. It wastes municipal resources, and it exacerbates homelessness."<!-- --></p><p>The Supreme Court's Grants Pass decision will now allow cities to take more severe measures without the fear of legal recourse.<!-- --></p><p>The first problem with putting homeless people in jail is that it is extremely expensive, and when they get out, the person is still homeless and now even less apt to finding employment with a criminal record, says Elizabeth Funk, founder of DignityMoves, a nonprofit dedicated to ending unsheltered homelessness.<!-- --></p><p>“We need to be thinking about how to get this problem solved," she says. "It's not going to be fining people for doing something they can't avoid. It's helping them.”<!-- --></p><p>Some of the highest concentrations of homeless are on the West Coast. <!-- --></p><p>California, with its moderate temperatures, accounts for nearly half of all homeless people who live outside and has a total of 123,423 homeless, according to data from the US Department of Housing and Urban Development.<!-- --></p><p>Cities across the country have been wrestling with how to combat the growing crisis. <!-- --></p><p>The issue has been at the heart of recent election cycles in West Coast cities, including Los Angeles, where officials have poured record amounts of money into creating shelters and affordable housing while homelessness has still increased.<!-- --></p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Llama-agents: an async-first framework for building production ready agents (106 pts)]]></title>
            <link>https://github.com/run-llama/llama-agents</link>
            <guid>40822512</guid>
            <pubDate>Fri, 28 Jun 2024 16:54:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/run-llama/llama-agents">https://github.com/run-llama/llama-agents</a>, See on <a href="https://news.ycombinator.com/item?id=40822512">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🦙 <code>llama-agents</code> 🤖</h2><a id="user-content--llama-agents-" aria-label="Permalink: 🦙 llama-agents 🤖" href="#-llama-agents-"></a></p>
<p dir="auto"><code>llama-agents</code> is an async-first framework for building, iterating, and productionizing multi-agent systems, including multi-agent communication, distributed tool execution, human-in-the-loop, and more!</p>
<p dir="auto">In <code>llama-agents</code>, each agent is seen as a <code>service</code>, endlessly processing incoming tasks. Each agent pulls and publishes messages from a <code>message queue</code>.</p>
<p dir="auto">At the top of a <code>llama-agents</code> system is the <code>control plane</code>. The control plane keeps track of ongoing tasks, which services are in the network, and also decides which service should handle the next step of a task using an <code>orchestrator</code>.</p>
<p dir="auto">The overall system layout is pictured below.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/run-llama/llama-agents/blob/main/system_diagram.png"><img src="https://github.com/run-llama/llama-agents/raw/main/system_diagram.png" alt="A basic system in llama-agents"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><code>llama-agents</code> can be installed with pip, and relies mainly on <code>llama-index-core</code>:</p>

<p dir="auto">If you don't already have llama-index installed, to follow these examples, you'll also need</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install llama-index-agent-openai"><pre>pip install llama-index-agent-openai</pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">The quickest way to get started is with an existing agent (or agents) and wrapping into launcher.</p>
<p dir="auto">The example below shows a trivial example with two agents from <code>llama-index</code>.</p>
<p dir="auto">First, lets setup some agents and initial components for our <code>llama-agents</code> system:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import (
    AgentService,
    AgentOrchestrator,
    ControlPlaneServer,
    SimpleMessageQueue,
)

from llama_index.core.agent import ReActAgent
from llama_index.core.tools import FunctionTool
from llama_index.llms.openai import OpenAI


# create an agent
def get_the_secret_fact() -> str:
    &quot;&quot;&quot;Returns the secret fact.&quot;&quot;&quot;
    return &quot;The secret fact is: A baby llama is called a 'Cria'.&quot;


tool = FunctionTool.from_defaults(fn=get_the_secret_fact)

agent1 = ReActAgent.from_tools([tool], llm=OpenAI())
agent2 = ReActAgent.from_tools([], llm=OpenAI())

# create our multi-agent framework components
message_queue = SimpleMessageQueue(port=8000)
control_plane = ControlPlaneServer(
    message_queue=message_queue,
    orchestrator=AgentOrchestrator(llm=OpenAI(model=&quot;gpt-4-turbo&quot;)),
    port=8001,
)
agent_server_1 = AgentService(
    agent=agent1,
    message_queue=message_queue,
    description=&quot;Useful for getting the secret fact.&quot;,
    service_name=&quot;secret_fact_agent&quot;,
    port=8002,
)
agent_server_2 = AgentService(
    agent=agent2,
    message_queue=message_queue,
    description=&quot;Useful for getting random dumb facts.&quot;,
    service_name=&quot;dumb_fact_agent&quot;,
    port=8003,
)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> (
    <span>AgentService</span>,
    <span>AgentOrchestrator</span>,
    <span>ControlPlaneServer</span>,
    <span>SimpleMessageQueue</span>,
)

<span>from</span> <span>llama_index</span>.<span>core</span>.<span>agent</span> <span>import</span> <span>ReActAgent</span>
<span>from</span> <span>llama_index</span>.<span>core</span>.<span>tools</span> <span>import</span> <span>FunctionTool</span>
<span>from</span> <span>llama_index</span>.<span>llms</span>.<span>openai</span> <span>import</span> <span>OpenAI</span>


<span># create an agent</span>
<span>def</span> <span>get_the_secret_fact</span>() <span>-&gt;</span> <span>str</span>:
    <span>"""Returns the secret fact."""</span>
    <span>return</span> <span>"The secret fact is: A baby llama is called a 'Cria'."</span>


<span>tool</span> <span>=</span> <span>FunctionTool</span>.<span>from_defaults</span>(<span>fn</span><span>=</span><span>get_the_secret_fact</span>)

<span>agent1</span> <span>=</span> <span>ReActAgent</span>.<span>from_tools</span>([<span>tool</span>], <span>llm</span><span>=</span><span>OpenAI</span>())
<span>agent2</span> <span>=</span> <span>ReActAgent</span>.<span>from_tools</span>([], <span>llm</span><span>=</span><span>OpenAI</span>())

<span># create our multi-agent framework components</span>
<span>message_queue</span> <span>=</span> <span>SimpleMessageQueue</span>(<span>port</span><span>=</span><span>8000</span>)
<span>control_plane</span> <span>=</span> <span>ControlPlaneServer</span>(
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>orchestrator</span><span>=</span><span>AgentOrchestrator</span>(<span>llm</span><span>=</span><span>OpenAI</span>(<span>model</span><span>=</span><span>"gpt-4-turbo"</span>)),
    <span>port</span><span>=</span><span>8001</span>,
)
<span>agent_server_1</span> <span>=</span> <span>AgentService</span>(
    <span>agent</span><span>=</span><span>agent1</span>,
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>description</span><span>=</span><span>"Useful for getting the secret fact."</span>,
    <span>service_name</span><span>=</span><span>"secret_fact_agent"</span>,
    <span>port</span><span>=</span><span>8002</span>,
)
<span>agent_server_2</span> <span>=</span> <span>AgentService</span>(
    <span>agent</span><span>=</span><span>agent2</span>,
    <span>message_queue</span><span>=</span><span>message_queue</span>,
    <span>description</span><span>=</span><span>"Useful for getting random dumb facts."</span>,
    <span>service_name</span><span>=</span><span>"dumb_fact_agent"</span>,
    <span>port</span><span>=</span><span>8003</span>,
)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Local / Notebook Flow</h3><a id="user-content-local--notebook-flow" aria-label="Permalink: Local / Notebook Flow" href="#local--notebook-flow"></a></p>
<p dir="auto">Next, when working in a notebook or for faster iteration, we can launch our <code>llama-agents</code> system in a single-run setting, where one message is propagated through the network and returned.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import LocalLauncher

# launch it
launcher = LocalLauncher(
    [agent_server_1, agent_server_2],
    control_plane,
    message_queue,
)
result = launcher.launch_single(&quot;What is the secret fact?&quot;)

print(f&quot;Result: {result}&quot;)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>LocalLauncher</span>

<span># launch it</span>
<span>launcher</span> <span>=</span> <span>LocalLauncher</span>(
    [<span>agent_server_1</span>, <span>agent_server_2</span>],
    <span>control_plane</span>,
    <span>message_queue</span>,
)
<span>result</span> <span>=</span> <span>launcher</span>.<span>launch_single</span>(<span>"What is the secret fact?"</span>)

<span>print</span>(<span>f"Result: <span><span>{</span><span>result</span><span>}</span></span>"</span>)</pre></div>
<p dir="auto">As with any agentic system, its important to consider how reliable the LLM is that you are using. In general, APIs that support function calling (OpenAI, Anthropic, Mistral, etc.) are the most reliable.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Server Flow</h3><a id="user-content-server-flow" aria-label="Permalink: Server Flow" href="#server-flow"></a></p>
<p dir="auto">Once you are happy with your system, we can launch all our services as independent processes, allowing for higher throughput and scalability.</p>
<p dir="auto">By default, all task results are published to a specific "human" queue, so we also define a consumer to handle this result as it comes in. (In the future, this final queue will be configurable!)</p>
<p dir="auto">To test this, you can use the server launcher in a script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import ServerLauncher, CallableMessageConsumer


# Additional human consumer
def handle_result(message) -> None:
    print(f&quot;Got result:&quot;, message.data)


human_consumer = CallableMessageConsumer(
    handler=handle_result, message_type=&quot;human&quot;
)

# Define Launcher
launcher = ServerLauncher(
    [agent_server_1, agent_server_2],
    control_plane,
    message_queue,
    additional_consumers=[human_consumer],
)

# Launch it!
launcher.launch_servers()"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>ServerLauncher</span>, <span>CallableMessageConsumer</span>


<span># Additional human consumer</span>
<span>def</span> <span>handle_result</span>(<span>message</span>) <span>-&gt;</span> <span>None</span>:
    <span>print</span>(<span>f"Got result:"</span>, <span>message</span>.<span>data</span>)


<span>human_consumer</span> <span>=</span> <span>CallableMessageConsumer</span>(
    <span>handler</span><span>=</span><span>handle_result</span>, <span>message_type</span><span>=</span><span>"human"</span>
)

<span># Define Launcher</span>
<span>launcher</span> <span>=</span> <span>ServerLauncher</span>(
    [<span>agent_server_1</span>, <span>agent_server_2</span>],
    <span>control_plane</span>,
    <span>message_queue</span>,
    <span>additional_consumers</span><span>=</span>[<span>human_consumer</span>],
)

<span># Launch it!</span>
<span>launcher</span>.<span>launch_servers</span>()</pre></div>
<p dir="auto">Now, since everything is a server, you need API requests to interact with it. The easiest way is to use our client and the control plane URL:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import LlamaAgentsClient, AsyncLlamaAgentsClient

client = LlamaAgentsClient(&quot;<control plane URL>&quot;)  # i.e. http://127.0.0.1:8001
task_id = client.create_task(&quot;What is the secret fact?&quot;)
# <Wait a few seconds>
# returns TaskResult or None if not finished
result = client.get_task_result(task_id)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> <span>LlamaAgentsClient</span>, <span>AsyncLlamaAgentsClient</span>

<span>client</span> <span>=</span> <span>LlamaAgentsClient</span>(<span>"&lt;control plane URL&gt;"</span>)  <span># i.e. http://127.0.0.1:8001</span>
<span>task_id</span> <span>=</span> <span>client</span>.<span>create_task</span>(<span>"What is the secret fact?"</span>)
<span># &lt;Wait a few seconds&gt;</span>
<span># returns TaskResult or None if not finished</span>
<span>result</span> <span>=</span> <span>client</span>.<span>get_task_result</span>(<span>task_id</span>)</pre></div>
<p dir="auto">Rather than using a client or raw <code>curl</code> requests, you can also use a built-in CLI tool to monitor and interact with your services.</p>
<p dir="auto">In another terminal, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-agents monitor --control-plane-url http://127.0.0.1:8000"><pre>llama-agents monitor --control-plane-url http://127.0.0.1:8000</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/run-llama/llama-agents/blob/main/llama_agents_monitor.png"><img src="https://github.com/run-llama/llama-agents/raw/main/llama_agents_monitor.png" alt="The llama-agents monitor app"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">You can find a host of examples in our examples folder:</p>
<ul dir="auto">
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_rag_toolservice.ipynb">Agentic RAG + Tool Service</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_local_single.py">Agentic Orchestrator w/ Local Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_server.py">Agentic Orchestrator w/ Server Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_human_local_single.py">Agentic Orchestrator w/ Human in the Loop</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/agentic_toolservice_local_single.py">Agentic Orchestrator w/ Tool Service</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_local_single.py">Pipeline Orchestrator w/ Local Launcher</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_human_local_single.py">Pipeline Orchestrator w/ Human in the Loop</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/pipeline_agent_service_tool_local_single.py">Pipeline Orchestrator w/ Agent Server As Tool</a></li>
<li><a href="https://github.com/run-llama/llama-agents/blob/main/examples/query_rewrite_rag.ipynb">Pipeline Orchestrator w/ Query Rewrite RAG</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Components of a <code>llama-agents</code> System</h2><a id="user-content-components-of-a-llama-agents-system" aria-label="Permalink: Components of a llama-agents System" href="#components-of-a-llama-agents-system"></a></p>
<p dir="auto">In <code>llama-agents</code>, there are several key components that make up the overall system</p>
<ul dir="auto">
<li><code>message queue</code> -- the message queue acts as a queue for all services and the <code>control plane</code>. It has methods for publishing methods to named queues, and delegates messages to consumers.</li>
<li><code>control plane</code> -- the control plane is a the central gateway to the <code>llama-agents</code> system. It keeps track of current tasks, as well as the services that are registered to the system. It also holds the <code>orchestrator</code>.</li>
<li><code>orchestrator</code> -- The module handles incoming tasks and decides what service to send it to, as well as how to handle results from services. An orchestrator can be agentic (with an LLM making decisions), explicit (with a query pipeline defining a flow), a mix of both, or something completely custom.</li>
<li><code>services</code> -- Services are where the actual work happens. A services accepts some incoming task and context, processes it, and publishes a result
<ul dir="auto">
<li>A <code>tool service</code> is a special service used to off-load the compution of agent tools. Agents can instead be equipped with a meta-tool that calls the tool service.</li>
</ul>
</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Low-Level API in <code>llama-agents</code></h2><a id="user-content-low-level-api-in-llama-agents" aria-label="Permalink: Low-Level API in llama-agents" href="#low-level-api-in-llama-agents"></a></p>
<p dir="auto">So far, you've seen how to define components and how to launch them. However in most production use-cases, you will need to launch services manually, as well as define your own consumers!</p>
<p dir="auto">So, here is a quick guide on exactly that!</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Launching</h3><a id="user-content-launching" aria-label="Permalink: Launching" href="#launching"></a></p>
<p dir="auto">First, you will want to launch everything. This can be done in a single script, or you can launch things with multiple scripts per service, or on different machines, or even in docker images.</p>
<p dir="auto">In this example, we will assume launching from a single script.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio

# launch the message queue
queue_task = asyncio.create_task(message_queue.launch_server())

# wait for the message queue to be ready
await asyncio.sleep(1)

# launch the control plane
control_plane_task = asyncio.create_task(self.control_plane.launch_server())

# wait for the control plane to be ready
await asyncio.sleep(1)

# register the control plane as a consumer
await self.message_queue.client.register_consumer(
    self.control_plane.as_consumer(remote=True)
)

# register the services
control_plane_url = (
    f&quot;http://{self.control_plane.host}:{self.control_plane.port}&quot;
)
service_tasks = []
for service in self.services:
    # first launch the service
    service_tasks.append(asyncio.create_task(service.launch_server()))

    # register the service to the message queue
    await service.register_to_message_queue()

    # register the service to the control plane
    await service.register_to_control_plane(control_plane_url)"><pre><span>import</span> <span>asyncio</span>

<span># launch the message queue</span>
<span>queue_task</span> <span>=</span> <span>asyncio</span>.<span>create_task</span>(<span>message_queue</span>.<span>launch_server</span>())

<span># wait for the message queue to be ready</span>
<span>await</span> <span>asyncio</span>.<span>sleep</span>(<span>1</span>)

<span># launch the control plane</span>
<span>control_plane_task</span> <span>=</span> <span>asyncio</span>.<span>create_task</span>(<span>self</span>.<span>control_plane</span>.<span>launch_server</span>())

<span># wait for the control plane to be ready</span>
<span>await</span> <span>asyncio</span>.<span>sleep</span>(<span>1</span>)

<span># register the control plane as a consumer</span>
<span>await</span> <span>self</span>.<span>message_queue</span>.<span>client</span>.<span>register_consumer</span>(
    <span>self</span>.<span>control_plane</span>.<span>as_consumer</span>(<span>remote</span><span>=</span><span>True</span>)
)

<span># register the services</span>
<span>control_plane_url</span> <span>=</span> (
    <span>f"http://<span><span>{</span><span>self</span>.<span>control_plane</span>.<span>host</span><span>}</span></span>:<span><span>{</span><span>self</span>.<span>control_plane</span>.<span>port</span><span>}</span></span>"</span>
)
<span>service_tasks</span> <span>=</span> []
<span>for</span> <span>service</span> <span>in</span> <span>self</span>.<span>services</span>:
    <span># first launch the service</span>
    <span>service_tasks</span>.<span>append</span>(<span>asyncio</span>.<span>create_task</span>(<span>service</span>.<span>launch_server</span>()))

    <span># register the service to the message queue</span>
    <span>await</span> <span>service</span>.<span>register_to_message_queue</span>()

    <span># register the service to the control plane</span>
    <span>await</span> <span>service</span>.<span>register_to_control_plane</span>(<span>control_plane_url</span>)</pre></div>
<p dir="auto">With that done, you may want to define a consumer for the results of tasks.</p>
<p dir="auto">By default, the results of tasks get published to a <code>human</code> message queue.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from llama_agents import (
    CallableMessageConsumer,
    RemoteMessageConsumer,
    QueueMessage,
)


def handle_result(message: QueueMessage) -> None:
    print(message.data)


human_consumer = CallableMessageConsumer(
    handler=handle_result, message_type=&quot;human&quot;
)

message_queue.register_consumer(human_consumer)

# or, you can send the message to any URL
# human_consumer = RemoteMessageConsumer(url=&quot;some destination url&quot;)
# message_queue.register_consumer(human_consumer)"><pre><span>from</span> <span>llama_agents</span> <span>import</span> (
    <span>CallableMessageConsumer</span>,
    <span>RemoteMessageConsumer</span>,
    <span>QueueMessage</span>,
)


<span>def</span> <span>handle_result</span>(<span>message</span>: <span>QueueMessage</span>) <span>-&gt;</span> <span>None</span>:
    <span>print</span>(<span>message</span>.<span>data</span>)


<span>human_consumer</span> <span>=</span> <span>CallableMessageConsumer</span>(
    <span>handler</span><span>=</span><span>handle_result</span>, <span>message_type</span><span>=</span><span>"human"</span>
)

<span>message_queue</span>.<span>register_consumer</span>(<span>human_consumer</span>)

<span># or, you can send the message to any URL</span>
<span># human_consumer = RemoteMessageConsumer(url="some destination url")</span>
<span># message_queue.register_consumer(human_consumer)</span></pre></div>
<p dir="auto">Or, if you don't want to define a consumer, you can just use the <code>monitor</code> to observe your system results</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-agents monitor --control-plane-url http://127.0.0.1:8000"><pre>llama-agents monitor --control-plane-url http://127.0.0.1:8000</pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Discovered June 16th, large asteroid to pass between Earth and moon on Saturday (102 pts)]]></title>
            <link>https://www.cbc.ca/news/science/asteroid-2024mk-1.7247336</link>
            <guid>40822426</guid>
            <pubDate>Fri, 28 Jun 2024 16:45:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cbc.ca/news/science/asteroid-2024mk-1.7247336">https://www.cbc.ca/news/science/asteroid-2024mk-1.7247336</a>, See on <a href="https://news.ycombinator.com/item?id=40822426">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="detailContent"><!--$--><p><span><a href="https://www.cbc.ca/news/science"><span>Science</span></a></span></p><!--/$--><p>On Saturday, an asteroid that is believed to be larger than 120 metres wide will make a close flyby to Earth.</p><h2 lang="en">The asteroid was only discovered earlier this month</h2><!--$--><!--/$--><!--$--><div data-cy="storyWrapper"><!--$--><figure><p><img alt="A large rock is seen in space with Earth in the background." src="https://i.cbc.ca/1.7247700.1719516237!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/illustration-asteroid-earth.jpg" data-cy="leadmedia-story-img" fetchpriority="high"></p><figcaption>An illustration depicts an asteroid near Earth. Asteroid 2024 MK will pass roughly 290,000 km from our planet on Saturday. <!-- --> <!-- -->(buradaki/Shutterstock)</figcaption></figure><!--/$--><div><p dir="ltr">Earth is surrounded by rocky bodies and bits of debris from when the solar system formed roughly 4.5 billion years ago. On Saturday, one of those leftover rocks will whiz&nbsp;past Earth.</p><p>The asteroid is called 2024 MK and, at its closest, it will pass roughly 290,000 km from Earth. While we have plenty of small asteroids that are scattered within Earth's orbit, this one is sizeable, ranging anywhere from 120 metres to 260 metres in diameter.&nbsp;</p><p>But there's another interesting — and somewhat disquieting — fact about this large asteroid.&nbsp;</p><p>"Maybe the big take-home point on this one is it's a pretty big object and it was only found 10 or 12 days before closest approach," said Peter Brown, Canada Research Chair in meteor astronomy and a professor at Western University in London, Ont. "The last time we had an object this big or bigger pass this close to Earth was ... in&nbsp;2001."</p><p>"So unlike most asteroid stories, this actually is noteworthy in the sense of … this is pretty big, pretty close."</p><hr><p>According to Alan Fitzsimmons, a planetary scientist at Queen's University Belfast in Northern Ireland, at its closest, 2024 MK will be visible from the southern hemisphere. The following night it will be in the constellation Scorpius, which is&nbsp;low in the south in Canada.&nbsp;</p><p>However, don't expect to see it. It won't be visible to the unaided eye, and, Fitzsimmons added to those who may have telescopes, "you've got to have to know exactly where to look. It's motoring."</p><p>Fortunately, it won't impact Earth. But it would be a bad day if it did.&nbsp;</p><p>"This is a big object. An&nbsp;object of this size is going to have the equivalent impact energy in the hundreds of megaton&nbsp;approaching a gigaton," Brown said.&nbsp;"That'd be a regional impact.&nbsp;It's the sort of thing that if it hit the east coast of the U.S., you would have catastrophic effects over most of the eastern seaboard. But it's not big enough to affect the whole world."</p><h2>Bigger, closer asteroids</h2><p>The appearance of 2024 MK is timely. It's passing by just nine days after NASA released a report on the results of an asteroid-threat simulation conducted in early April.&nbsp;And it's making an appearance just one day ahead of <a href="https://asteroidday.org/">Asteroid Day</a> which is held annually on June 30.</p><p>Asteroid Day, <a href="https://www.un.org/en/observances/asteroid-day">sanctioned by the United Nations</a>, was started in 2014 by astrophysicist and former Queen musician Brian May along with&nbsp;Apollo 9 astronaut&nbsp;Rusty Schweickart along with a few others. The goal is to inform the public about asteroids and their potential threats as well as calling on governments to work on asteroid detection programs.</p><p>The threat of asteroids or comets impacting Earth is a very real concern, though there are multiple sky surveys looking for potentially hazardous asteroids (PHA). In fact, one of them — the&nbsp;<a href="https://fallingstar.com/home.php">Asteroid Terrestrial-impact Last Alert System</a> (ATLAS) — discovered 2024 MK last week.</p><p>Both Brown and Fitzsimmons say that at any one time there is a 10-metre asteroid somewhere between Earth and the moon. Essentially, Earth is plowing through debris all the time. Meteors burn up in our atmosphere all the time, it's just that most of them are small&nbsp;and go unnoticed. Brown said that even bigger impacts may go unnoticed as they may impact over the ocean.</p><p>But in 1994, the astronomical world was shocked to see the effects of several pieces of a comet slamming into Jupiter, the largest planet in our solar system.</p><div><figure><p><img loading="lazy" alt="Jupiter's cloud bands are seen close-up with black spots." srcset="https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/jupiter-comet-shoemaker-levy-9.jpg 300w,https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/jupiter-comet-shoemaker-levy-9.jpg 460w,https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/jupiter-comet-shoemaker-levy-9.jpg 620w,https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/jupiter-comet-shoemaker-levy-9.jpg 780w,https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/jupiter-comet-shoemaker-levy-9.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.4773358.1719517096!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/jupiter-comet-shoemaker-levy-9.jpg" data-cy="image-img"></p><figcaption>The Hubble space telescope followed unexpected and dramatic changes in Jupiter's atmosphere caused by collisions with comet fragments.  <!-- --> <!-- -->(Hubble Space Telescope comet team, NASA)</figcaption></figure></div><p>Then in 2013, the reminder that we're in a cosmic shooting gallery hit home. On February 15, a 20-metre wide rock impacted over&nbsp;<a href="https://www.planetary.org/articles/what-was-the-chelyabinsk-meteor-event"><u>entered Earth's atmosphere</u></a>&nbsp;over Chelyabinsk, Russia, causing a massive air burst that blew out windows in the area, injuring roughly 1,000 people.</p><p>Fitzsimmons said that Asteroid Day is a reminder that we're not just sitting ducks.</p><p>"It's the only natural disaster that we can stop. You can't stop a tsunami, you can't stop an earthquake, you can't stop a volcano," he said.&nbsp;"You can actually stop or prevent an asteroid impact, in least in theory."</p><p>And NASA put that to the test in 2021 with its&nbsp;Double Asteroid Redirection Test (DART) mission where it used a <a href="https://www.cbc.ca/news/science/asteroid-spacecraft-nasa-dart-1.6596692">spacecraft to redirect an asteroid</a>. It was hailed as a success, and a follow-up mission by the European Space Agency's <a href="https://www.esa.int/Space_Safety/Hera">Hera mission</a> to further quantify the results&nbsp;will launch in October.</p><div><ul><li><a href="https://www.cbc.ca/radio/quirks/citizen-scientists-discover-a-treasure-trove-of-active-asteroids-1.7152096" text="Citizen scientists discover a treasure trove of active asteroids" flag="Analysis: Bob's blog" data-contentid=""><p><span>Analysis: Bob's blog</span></p><span>Citizen scientists discover a treasure trove of active asteroids</span></a></li></ul><ul><li><a href="https://www.cbc.ca/news/canada/windsor/planet-named-tecumseh-1.7202602" text="How an asteroid was named after Shawnee Chief Tecumseh" flag="Audio" data-contentid=""><p><span>Audio</span></p><span>How an asteroid was named after Shawnee Chief Tecumseh</span></a></li></ul></div><p>NASA's OSIRIS-REx mission, which visited the asteroid Bennu&nbsp;and <a href="https://www.cbc.ca/news/science/osiris-rex-sample-return-1.6974159">returned a sample to Earth in 2023</a>, has been given a new mission called OSIRIS-APEX. The spacecraft will visit the infamous <a href="https://science.nasa.gov/solar-system/asteroids/apophis/">asteroid&nbsp;Apophis</a>.</p><p>At one point, it was believed&nbsp;the 320-metre-wide asteroid had a risk of impacting Earth in 2068, however, that has now been ruled out. But it will swing extremely close to Earth in 2029 — so close that it will be within the region of our geostationary satellites, at roughly 30,000 kilometres from Earth.</p><p><em><strong>WATCH |&nbsp;Animation of Asteroid Apophis' 2029 Close Approach with Earth and satellites:&nbsp;</strong></em><span><span><iframe src="https://www.youtube.com/embed/hjJIyZKbHqc" frameborder="no" title="YouTube content" allowfullscreen="" loading="lazy"></iframe></span></span></p><hr><p>"So [2024] MK&nbsp;is sort of the leader in the next four or five years to a couple of really big events," Brown said. "Of course, the one everybody knows about is&nbsp;Apophis in April 2029. That's a once-in-millennia event. Nothing in historic times has been that close, that big to us. But there's also an asteroid called 2001 WN5, and it's actually going to pass closer than 2024 MK. And it's a monster. It's a kilometre in size."</p><p>Thankfully, NASA and other space agencies are working hard to find all the PHAs. To date it's believed that most objects one kilometre and larger have been found.&nbsp;</p><p>As for 2024 MK, Fitzsimmons said that this is an opportunity for astronomers to study it, even if it is only a brief pass. A team at NASA's Jet Propulsion Laboratory&nbsp;has plans to map it using Earth-based radar telescopes.</p></div></div><!--/$--><!--$--><!--/$--><div><h2>ABOUT THE AUTHOR</h2><div><figure><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.6483294.1654800694!/fileImage/httpImage/image.jpeg_gen/derivatives/square_300/nicole-mortillaro.jpeg 300w,https://i.cbc.ca/1.6483294.1654800694!/fileImage/httpImage/image.jpeg_gen/derivatives/square_460/nicole-mortillaro.jpeg 460w,https://i.cbc.ca/1.6483294.1654800694!/fileImage/httpImage/image.jpeg_gen/derivatives/square_620/nicole-mortillaro.jpeg 620w" sizes="(max-width: 258pxpx) 258pxpx" src="https://i.cbc.ca/1.6483294.1654800694!/fileImage/httpImage/image.jpeg_gen/derivatives/square_620/nicole-mortillaro.jpeg" data-cy="author-image-img"></p></figure></div><p>Based in Toronto, Nicole covers all things science for CBC News. As an amateur astronomer, Nicole can be found looking up at the night sky appreciating the marvels of our universe. She is the editor of the Journal of the Royal Astronomical Society of Canada and the author of several books. In 2021, she won the Kavli Science Journalism Award from the American Association for the Advancement of Science for a Quirks and Quarks audio special on the history and future of Black people in science. You can send her story ideas at Nicole.Mortillaro@cbc.ca.</p><ul><li><a href="https://twitter.com/NebulousNikki">Follow Nicole Mortillaro on Twitter</a></li></ul></div><!--$--><!--/$--><!--$--><!--/$--></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft informs customers that Russian hackers spied on emails (107 pts)]]></title>
            <link>https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/</link>
            <guid>40821994</guid>
            <pubDate>Fri, 28 Jun 2024 16:01:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/">https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/</a>, See on <a href="https://news.ycombinator.com/item?id=40821994">Hacker News</a></p>
Couldn't get https://www.reuters.com/technology/cybersecurity/microsoft-tells-clients-russian-hackers-viewed-emails-bloomberg-news-reports-2024-06-27/: Error: Request failed with status code 401]]></description>
        </item>
    </channel>
</rss>