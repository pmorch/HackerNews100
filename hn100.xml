<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Sat, 11 Jan 2025 10:30:03 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Be Aware of the Makefile Effect (109 pts)]]></title>
            <link>https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect</link>
            <guid>42663231</guid>
            <pubDate>Sat, 11 Jan 2025 04:13:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect">https://blog.yossarian.net/2025/01/10/Be-aware-of-the-Makefile-effect</a>, See on <a href="https://news.ycombinator.com/item?id=42663231">Hacker News</a></p>
<div id="readability-page-1" class="page">

<h2>ENOSUCHBLOG</h2>
<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/series">Series</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
    <li><a href="https://yossarian.net/">Main Site</a></li>
    <li><a href="https://yossarian.net/til">TILs</a></li>
    
</ul>

<hr>



<h2>
  <p>
    <span><em>Jan 10, 2025</em></span>

    &nbsp; &nbsp;

    
      <span>
        Tags:
        
        
          <a href="https://blog.yossarian.net/tags#programming">programming</a>
        
      </span>
    

    &nbsp; &nbsp;

    
  </p>
</h2>






<hr>


<p>I’m not aware of a <em>perfect</em><sup id="fnref:perfect" role="doc-noteref"><a href="#fn:perfect" rel="footnote">1</a></sup> term for this, so I’m making one up:
the Makefile effect<sup id="fnref:aware" role="doc-noteref"><a href="#fn:aware" rel="footnote">2</a></sup>.</p>

<p>The Makefile effect boils down to this:</p>

<blockquote>
  <p>Tools of a certain complexity or routine unfamiliarity are not run <em>de novo</em>,
but are instead copy-pasted and tweaked from previous known-good examples.</p>
</blockquote>

<p>You see this effect frequently with engineers of all stripes and skill/experience
levels, with <a href="https://en.wikipedia.org/wiki/Make_(software)">Make</a> being a common example<sup id="fnref:example" role="doc-noteref"><a href="#fn:example" rel="footnote">3</a></sup>:</p>

<ol>
  <li>A task (one of a common shape) needs completing. A very similar (or even
identical) task has been done before.</li>
  <li><a href="https://en.wikipedia.org/wiki/Make_(software)">Make</a> (or another tool susceptible to this effect) is the correct or
“best” (given expedience, path dependencies, whatever) tool for the task.</li>
  <li>Instead of writing a <code>Makefile</code>, the engineer copies a previous (sometimes
very large and complicated<sup id="fnref:large" role="doc-noteref"><a href="#fn:large" rel="footnote">4</a></sup>) <code>Makefile</code> from a previous instance of the task
and tweaks it until it works in the new context.</li>
</ol>

<p>On one level, this is a perfectly good (even ideal) <em>engineering</em> response
at the <em>point of solution</em>: applying a working example is often the parsimonious
thing to do, and runs a lesser (in theory) risk of introducing bugs, since
most of the work is unchanged.</p>

<p>However, at the <em>point of design</em>, this suggests a tool design (or tool <em>application</em><sup id="fnref:application" role="doc-noteref"><a href="#fn:application" rel="footnote">5</a></sup>)
that is <em>flawed</em>: the tool (or system) is too complicated (or annoying) to use from scratch. Instead
of using it to solve a problem from scratch, users repeatedly copy a known-good solution
and accrete changes over time.</p>

<p>Once you notice it, you start to see this pattern all over the place.
Beyond Make:</p>

<ul>
  <li>CI/CD configurations like GitHub Actions and GitLab CI/CD, where users
copy their YAML spaghetti from the <em>last</em> working setup and tweak it
(often with repeated re-runs) until it works again;</li>
  <li>Linter and formatter configurations, where a basic set of rules gets
copied between projects and strengthened/loosened as needed for local
conditions;</li>
  <li>Build systems themselves, where everything non-trivial begins to resemble
the previous build system.</li>
</ul>

<h2 id="does-this-matter">Does this matter?</h2>

<p>In many cases, perhaps not. However, I think it’s worth thinking about, especially
when designing tools and systems:</p>

<ul>
  <li>
    <p>Tools and systems that enable this pattern often have less-than-ideal
diagnostics or debugging support: the user has to run the tool repeatedly,
often with long delays, to get back relatively small amounts of information.
Think about CI/CD setups, where users diagnose their copy-pasted
CI/CD by doing print-style debugging <em>over the network with a layer
of intermediating VM orchestration.</em> Ridiculous!</p>
  </li>
  <li>
    <p>Tools that enable this pattern often <em>discourage broad learning</em>:
a few mavens know the tool well enough to configure it, and others
copy it with <em>just</em> enough knowledge to do targeted tweaks.
This is sometimes inevitable, but often not: dependency graphs
are an inherent complexity of build systems, but remembering the difference
between <code>$&lt;</code> and <code>$^</code> in Make is not.</p>
  </li>
  <li>
    <p>Tools that enable this pattern are <em>harder to use securely</em>: security
actions typically require deep knowledge of the <em>why</em> behind a piece of
behavior. Systems that are subject to the Makefile effect are also often ones
that enable confusion between code and data (or any kind of
<a href="https://en.wikipedia.org/wiki/In-band_signaling">in-band signalling</a> more generally), in large part because functional
solutions are not always secure ones. Consider, for example, about
<a href="https://woodruffw.github.io/zizmor/audits/#template-injection">template injection</a> in GitHub Actions.</p>
  </li>
</ul>

<p>In general, I think well-designed tools (and systems) should aim to minimize
this effect. This can be hard to do in a fully general manner, but some
things I think about when designing a new tool:</p>

<ul>
  <li>Does it <em>need</em> to be configurable?</li>
  <li>Does it <em>need</em> syntax of its own?
    <ul>
      <li>As a corollary: can it <em>reuse</em> familiar syntax or idioms from other tools/CLIs?</li>
    </ul>
  </li>
  <li>Do <em>I</em> end up copy-pasting my use of it around? If so, are <em>others</em> likely to do the same?</li>
</ul>

<hr>




<hr>




  






</div>]]></description>
        </item>
        <item>
            <title><![CDATA[Very Wrong Math (103 pts)]]></title>
            <link>https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html</link>
            <guid>42661432</guid>
            <pubDate>Fri, 10 Jan 2025 23:10:56 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html">https://www.charlespetzold.com/blog/2025/01/Very-Wrong-Math.html</a>, See on <a href="https://news.ycombinator.com/item?id=42661432">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
            <header>
                

                <p>January 10, 2025<br>New York, N.Y.</p>
            </header>

            
            <p>
            The difference between misinformation and disinformation is the difference between ignorance and malice. Trolling is somewhat different, incorporating an element of provocation and narcissism. But what the hell is this?
            </p>
            <p>
                <img src="https://www.charlespetzold.com/blog/2025/01/FaultyFlightTimes.png" alt="Image from Facebook about Flight Times" width="538" height="537">
            </p>
            <p>
            This was posted by a design and construction company that Facebook thinks I should follow. A cursory glance at their other posts reveals nothing quite as egregiously wrong. So I’m confused. Is it supposed to be a joke?
            </p>
            <p>
            Of course, me being me, I was curious exactly how wrong it was.
            </p>
            <p>
            Let me ignore the “flight time” part of the problem and focus on the length of those two arcs. The length of a circular arc is proportional to the subtending angle and the radius of the circle, specifically:
            </p>
            <math display="block">
            <mi>length of arc</mi><mo>=</mo><mn>2</mn><mo>·</mo><mn>π</mn><mo>·</mo><mfrac><mi>angle</mi><mn>360°</mn></mfrac><mo>·</mo><mi>radius</mi>
            </math>
            <p>
            The angle for the two arcs in the illustration is the same, but in calculating the length of those arcs, the radius of the earth has to be taken into account as well as the distance above the surface of the earth. If the radius of the earth is <i>R</i>, then this illustration implies that:
            </p>
            <math display="block">
            <mi>R</mi><mo>+</mo><mn>33,000′</mn><mo>=</mo><mn>4</mn><mo>·</mo><mo>(</mo><mi>R</mi><mo>+</mo><mn>5,000′</mn><mo>)</mo>
            </math>
            <p>
            The radius of the earth would therefore be:
            </p>
            <math display="block">
            <mi>R</mi><mo>=</mo><mn>4,333′</mn>
            </math>
            <p>
            That’s a distance in feet! That would make the circumference of the earth a bit over 5 miles, which is considerably less than the actual circumference.
            </p>
            <p>
            The mean radius of the earth is actually 3,459 miles or over 18 <i>million</i> feet. Setting <i>R</i> to that value, the ratio of the length of the outer arc to the inner arc is therefore:
            </p>
            <math display="block">
                 <mfrac>
                 <mrow><mi>R</mi><mo>+</mo><mn>33,000′</mn></mrow>
                 <mrow><mi>R</mi><mo>+</mo><mn>5,000′</mn></mrow>
                 </mfrac>
                 <mo>=</mo><mn>1.0015</mn>
            </math>
            <p>
            In other words, the outer arc is less than 1% longer than the inner arc, but the flight time at that altitude would likely be less because of the decreased air resistance.
            </p>


        </article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Portals and Quake (138 pts)]]></title>
            <link>https://30fps.net/pages/pvs-portals-and-quake/</link>
            <guid>42661185</guid>
            <pubDate>Fri, 10 Jan 2025 22:48:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://30fps.net/pages/pvs-portals-and-quake/">https://30fps.net/pages/pvs-portals-and-quake/</a>, See on <a href="https://news.ycombinator.com/item?id=42661185">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="text">

<blockquote>
<p>This is the first installment in the “Demystifying the PVS” series.</p>
<ol type="1">
<li><strong>Portals and Quake</strong></li>
<li><a href="https://30fps.net/pages/pvs-coarse-visibility/">Coarse base visibility</a></li>
<li><a href="https://30fps.net/pages/pvs-fine-visibility/">Fine visibility via clipping</a></li>
<li>Portal flow brings it all together (to be published)</li>
</ol>
</blockquote>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/e1m1_pvs.jpg" alt="Precomputed visibility in Quake’s first level. The camera location is shown in red.">

</figure>
<p><em>Ever wanted to know how exactly did Quake’s precomputed visibility work?
I did, so I wrote <a href="https://github.com/pekkavaa/vis.py">vis.py</a>, a reimplementation of their algorithm in Python.
This guide has all the information you need to understand <strong>vis</strong>, the tool used by Quake, Half-Life and Source Engine games.</em></p>
<p>During the development of Quake, <em>overdraw</em> became a concern.
It means the same pixel getting written many times during the rendering of a frame.
Only the last color stays visible and the earlier writes go to waste.
This is bad if your game is software rendered and already pushing the mid 90’s PCs to their limits.</p>
<p>How to reduce overdraw?
Let’s begin with a very high-level overview of the solution landscape.</p>
<h2 id="portal-culling-helps-with-overdraw">Portal culling helps with overdraw</h2>
<p>In 3D games, it’s a good idea to reduce the number of drawn objects.
<!-- The earlier they can get culled, the better. -->
<em>Frustum culling</em> is one fundamental method for this, in which objects confirmed to be outside the virtual camera’s view are skipped during rendering.
This can be done for example with object bounding boxes or bounding spheres.</p>
<p>Frustum culling still leaves some performance on the table.
Many objects may still be within the field of view of the camera even if they don’t contribute any pixels to the final image. This is not a performance catastrophe if everything is rendered from front to back.
GPU’s early-z testing will help here.
Still, in large worlds it would be faster to never submit these objects for rendering in the first place.</p>
<p><em>Occlusion culling</em> is a process where you discard objects that you deem to lie behind other objects in the scene. Its purpose is to discard as many <em>occluded</em> objects as possible. It’s not strictly needed, since you’ll get the correct image thanks to the z-buffer anyway. There are a few ways to do this such as the hierarchical z-buffer, occlusion queries, portal culling, and potentially visible sets (PVS). In this article I talk about the last two: portals and the PVS.</p>
<p>In portal culling, the world is divided into spaces where the virtual camera can move around and the openings between them. The spaces are called <em>cells</em>, <em>viewcells</em>, <em>zones</em>, <em>clusters</em> or <em>sectors</em>, and the openings <em>portals</em>. This is a useful split especially in architectural models with cleanly separated rooms connected by doorways or windows.
It also works for mostly-indoor video game levels :)</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portals_topdown_crop.png" alt="The floorplan of our example level with three hand-placed portals shown. Cells have the color of their entry portal. In this case also the cell where the camera lies is visible.">

</figure>
<p>Portal rendering starts from the camera’s cell.
The game renders everything inside that cell, and then recursively looks into portals leading away from that first cell to find out what else to draw.
It renders all objects in every cell and then examines the cell’s portals.
If a portal doesn’t line up with another one on screen, it won’t be visited.
Each successive portal shrinks the visible screen area smaller and smaller until the whole portal is clipped away.</p>
<p>A straightforward way to test portals for visibility is to intersect their screenspace bounding boxes.
Those are shown in white in the picture below.
If two bounding boxes overlap, we can see through the respective portals.
More accurate tests can be performed with 3D clipping or per-pixel operations.</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portals_sprite.jpg" alt="This is how three portals could look in game. Portal openings are shown as colored polygons and their screenspace bounding boxes are in white. Objects have dashed bounding boxes. The star object is culled because it doesn’t overlap with the red portal.">

</figure>
<p>The Quake engine uses portals but only during map preparation time.
At runtime, the portals are nowhere to be seen.
This technique is a variant of Seth Teller’s PVS method presented <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/1992/CSD-92-708.pdf">in his 1992 dissertation</a> that only worked with axis-aligned walls.</p>
<h2 id="portals-of-a-quake-map-disappear">Portals of a Quake map disappear</h2>
<p>Often portals are placed by hand by a level designer. Quake’s <strong>bsp</strong> map compilation tool places portals automatically, which is nice, but unfortunately it creates a lot of them!</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/e1m1_start_withportals.jpg" alt="Quake’s first map viewed in the TrenchBroom map editor with portals shown in red. As you can see, not just doorways act as portals.">

</figure>
<p>You see, in Quake the cells are very small.
But no portals are tested at runtime.
Instead, each cell gets a precomputed list of other cells that can been seen from it.
This is the <em>Potentially Visible Set</em> (PVS) for that cell.</p>
<p>In Quake, a cell is a small convex volume of space, so a single room will usually get split into multiple cells.
These cells correspond to leaves of a binary space partitioning (BSP) tree.
The BSP tree was used to divide the map into cells and portals.
For us, the exact method is irrelevant though.
But BSP does make it easy to find the cell the camera is in at runtime.</p>
<p>Since we have now entered the Quake territory in our discussion, I’ll start calling a cell a <em>leaf</em>.
Leaf is the term used in all source code, level editors, error messages, and other resources on Quake.
The meaning stays exactly the same though, it’s just a convex cell connected to other cells via portals.
This is how leaves look in our example level:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/colored_leaves.png" alt="The example map divided to convex leaves. Leaf colors are random.">

</figure>
<p>The portals appear in between leaves, as expected:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/example_top_notextures_small.png" alt="Portals placed automatically by the bsp tool. This map is pretty much 2D but everything discussed works just fine in 3D too. Leaf indices are shown in white.">

</figure>
<p>Nothing would’ve stopped them from grouping multiple leaves to form larger cells with fewer portals in between.
In fact, this is exactly what they did for Quake 2 with its “clusters” of leaves.</p>
<p>With larger clusters of leaves, you do get more overdraw.
Also, a cluster made of convex leaves may not be convex itself any more.
But even in that case you can still act as if it still is, and assume the portals inside can be seen from anywhere in the cluster.
It’s less accurate but works.</p>
<!-- More overdraw 
I don't know how they clusters looked for Quake 2.
assume other portals to be visible and just render a bit too much in the worst case.

and may not be convex (I don't know if that was the case for Quake 2).
In general, the cells in a portal system don't have to be convex.
I mean it's neat, since you can be sure that all portals of a cell are visible to each other (unless coplanar). -->
<h2 id="high-level-overview-of-vis">High-level overview of vis</h2>
<p>The Quake map tool <strong>vis</strong> takes in portals generated by another tool, <strong>bsp</strong>, precomputes a leaf-to-leaf visibility matrix, and writes the matrix back to the compiled map file.
This article series describes how <strong>vis</strong> functions.</p>
<p>We know that leaves can see each other only through portals.
So we don’t even need to know how exactly the leaves look like, only how they are connected together.</p>
<p>At its most basic level, <strong>vis</strong> does two recursive depth-first traversals, followed by a quick resolve pass before writing the visibility results back to a compiled map file. Three steps:</p>
<ol type="1">
<li><strong>Base visibility.</strong> Estimate a coarse leaf-to-portal visibility.</li>
<li><strong>Full visibility.</strong> Refine the coarse results via portal clipping.</li>
<li><strong>Resolve.</strong> Combine the refined portal-to-leaf results to the final leaf-to-leaf visibility.</li>
</ol>
<p>For a quick visual overview, I can recommend Matthew Earl’s <a href="https://www.youtube.com/watch?v=IfCRHSIg6zo">great video on Quake’s PVS</a>.</p>
<h3 id="portals-have-a-direction">Portals have a direction</h3>
<p>In a portal system, the cells and portals are structured as a cell-and-portal graph.
Quake’s map tooling follows this pattern and connects leaves with portals, even though this structure isn’t present at runtime.
Leafs are connected by portals:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/undirected_graph.png" alt="Leaves (nodes) connected by portals (edges) in a cell-and-portal graph.">

</figure>
<p>Each portal is a 3D polygon.
They are written by <strong>bsp</strong> to a plain text file with a version code, the number of leaves and portals, followed by one portal per line. Like this:</p>
<pre><code>PRT1
11
12
4 0 1 (880 -224 -8 ) (880 -272 -8 ) (880 -272 72 ) (880 -224 72 ) 
4 1 2 (832 -224 -8 ) (832 -272 -8 ) (832 -272 72 ) (832 -224 72 ) 
4 2 4 (768 -272 -8 ) (768 -320 -8 ) (768 -320 72 ) (768 -272 72 ) 
4 2 3 (768 -112 72 ) (768 -112 -8 ) (768 -160 -8 ) (768 -160 72 ) 
4 3 5 (720 -112 72 ) (720 -112 -8 ) (720 -160 -8 ) (720 -160 72 ) 
4 4 5 (720 -272 -8 ) (720 -320 -8 ) (720 -320 72 ) (720 -272 72 ) 
4 5 6 (640 -224 -8 ) (640 -288 -8 ) (640 -288 72 ) (640 -224 72 ) 
4 6 7 (592 -224 -8 ) (592 -288 -8 ) (592 -288 72 ) (592 -224 72 ) 
4 7 10 (384 -304 -8 ) (384 -368 -8 ) (384 -368 72 ) (384 -304 72 ) 
4 7 8 (384 -112 -8 ) (384 -176 -8 ) (384 -176 72 ) (384 -112 72 ) 
4 8 9 (240 -176 -8 ) (336 -176 -8 ) (336 -176 72 ) (240 -176 72 ) 
4 9 10 (240 -304 -8 ) (336 -304 -8 ) (336 -304 72 ) (240 -304 72 ) </code></pre>
<p>Each portal is a loop of 3D points:</p>
<pre><code>┌ the number of points
│ 
▽      x    y    z   x     y    z    x    y   z     x    y   z
4 0 1 (880 -224 -8 ) (880 -272 -8 ) (880 -272 72 ) (880 -224 72 ) 
  △ △ 
  └─┴─ the two leaves the portal is in between</code></pre>
<p>Since portals are interfaces between convex leaves, the polygons are also convex.
In 3D, a portal looks like this:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portal_onedirection.jpg" alt="Each portal is stored as a convex polygon.">

</figure>
<p>Conceptually, each portal is a two way opening. You can see through it in both directions.
However, it’s convenient to make the portals directed.
This way we can keep track on what’s visible in different directions.
We give each portal a normal vector, the direction the portal can be seen through.</p>
<p>Now a single input portal becomes two directed portals:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/portal_two_directions.jpg" alt="Each input portal is split into a so called forward (red) and backward (yellow) portal before processing. There’s a small gap here for demonstration purposes but actually they overlap. The arrows show the directions the portals can be seen through.">

</figure>
<p>Therefore the graph will now have directed edges instead:</p>
<figure>
<img src="https://30fps.net/pages/pvs-portals-and-quake/directed_graph_with_colors.png" alt="Each portal is represented by two edges in the graph. The earlier forward and backwards portal edges are highlighted with red and gold, respectively.">

</figure>
<h3 id="the-graph-in-code">The graph in code</h3>
<p>Now is the time to present the main data structures of <strong>vis.py</strong>, the <a href="https://github.com/pekkavaa/vis.py/blob/main/portaltypes.py"><strong>Portal</strong> and <strong>Leaf</strong> classes</a>:</p>
<div id="cb3"><pre><code><span id="cb3-1"><span>class</span> Portal:</span>
<span id="cb3-2">  winding: <span>list</span>[np.ndarray]   <span># polygon's 3D points</span></span>
<span id="cb3-3">  leaf: <span>int</span>                   <span># the leaf this portal leads to</span></span>
<span id="cb3-4">  plane: Plane                <span># plane normal points to destination leaf</span></span>
<span id="cb3-5">  ...                         <span># (other class attributes omitted)</span></span>
<span id="cb3-6"></span>
<span id="cb3-7"><span>class</span> Leaf:</span>
<span id="cb3-8">  portals: <span>list</span>[<span>int</span>]    <span># indices of portals leading away from this leaf</span></span></code></pre></div>
<p>Note that a leaf stores only indices of portals <em>leading away</em> from that leaf.
The graph is stored in two global arrays called <strong>portals</strong> and <strong>leaves</strong> with objects of the respective types.
Since the graph is accessed both via indices and direct object references, I came up with the following naming convention:</p>
<ul>
<li><code>pi</code> is the index of a portal, <code>Pi</code> is the actual object <code>Pi = portals[pi]</code>, and</li>
<li><code>li</code> is the index of a leaf, <code>Li</code> is the actual object <code>Li = leaves[li]</code>.</li>
</ul>
<p>Our goal is to compute which nodes can reach each other in this graph while honoring the 3D visibility relations between portals associated with each edge.
But what on earth are those “visibility relations”?</p>
<p><em>In <a href="https://30fps.net/pages/pvs-coarse-visibility/">the next part</a> we’ll use the graph for some quick checks.</em></p>
<hr>
<p><em>I’m also thinking of writing a book. <a href="https://30fps.net/book">Sign up here</a> if you’re interested.</em></p>



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[OpenAI's bot crushed this seven-person company's web site 'like a DDoS attack' (103 pts)]]></title>
            <link>https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/</link>
            <guid>42660377</guid>
            <pubDate>Fri, 10 Jan 2025 21:21:17 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/">https://techcrunch.com/2025/01/10/how-openais-bot-crushed-this-seven-person-companys-web-site-like-a-ddos-attack/</a>, See on <a href="https://news.ycombinator.com/item?id=42660377">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p id="speakable-summary">On Saturday, <a href="https://triplegangers.com/" target="_blank" rel="noreferrer noopener nofollow">Triplegangers</a> CEO Oleksandr Tomchuk was alerted that his company’s e-commerce site was down. It looked to be some kind of distributed denial-of-service attack.&nbsp;</p>

<p>He soon discovered the culprit was a bot from OpenAI that was relentlessly attempting to scrape his entire, enormous site.&nbsp;</p>







<p>“We have over 65,000 products, each product has a page,” Tomchuk told TechCrunch. “Each page has at least three photos.”&nbsp;</p>

<p>OpenAI was sending “tens of thousands” of server requests trying to download all of it, hundreds of thousands of photos, along with their detailed descriptions.&nbsp;</p>

<p>“OpenAI used 600 IPs to scrape data, and we are still analyzing logs from last week, perhaps it’s way more,” he said of the IP addresses the bot used to attempt to consume his site.&nbsp;</p>

<p>“Their crawlers were crushing our site,” he said “It was basically a DDoS attack.”</p>

<p>Triplegangers’ website is its business. The seven-employee company has spent over a decade assembling what it calls the largest database of “human digital doubles” on the web, meaning 3D image files scanned from actual human models.&nbsp;</p>


<p>It sells the 3D object files, as well as photos — everything from hands to hair, skin, and full bodies — to 3D artists, video game makers, anyone who needs to digitally recreate authentic human characteristics.</p>

<p>Tomchuk’s team, based in Ukraine but also licensed in the U.S. out of Tampa, Florida, has a <a href="https://triplegangers.com/terms-of-use" target="_blank" rel="noreferrer noopener nofollow">terms of service page</a> on its site that forbids bots from taking its images without permission. But that alone did nothing. Websites must use a properly configured robot.txt file with tags specifically telling OpenAI’s bot, GPTBot, to leave the site alone. (OpenAI also has a couple of other bots, ChatGPT-User and OAI-SearchBot, that have their own tags, <a href="https://platform.openai.com/docs/bots/overview-of-openai-crawlers" target="_blank" rel="noreferrer noopener nofollow">according to its information page on its crawlers</a>.)</p>

<p>Robot.txt, otherwise known as the Robots Exclusion Protocol, was created to tell search engine sites what not to crawl as they index the web. OpenAI says on its informational page that it honors such files when configured with its own set of do-not-crawl tags, though it also warns that it can take its bots up to 24 hours to recognize an updated robot.txt file.</p>







<p>As Tomchuk experienced, if a site isn’t properly using robot.txt, OpenAI and others take that to mean they can scrape to their hearts’ content. It’s not an opt-in system.</p>

<p>To add insult to injury, not only was Triplegangers knocked offline by OpenAI’s bot during U.S. business hours, but Tomchuk expects a jacked-up AWS bill thanks to all of the CPU and downloading activity from the bot.</p>

<p>Robot.txt also isn’t a failsafe. AI companies voluntarily comply with it. Another AI startup, Perplexity, pretty famously got called out last summer by a Wired investigation <a href="https://techcrunch.com/2024/07/02/news-outlets-are-accusing-perplexity-of-plagiarism-and-unethical-web-scraping/">when some evidence implied Perplexity wasn’t </a>honoring it.</p>

<figure><img loading="lazy" decoding="async" width="2516" height="1732" data-destinationlink="https://triplegangers.com/browse/scans/full-body" data-event="clickable_image" src="https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?w=680" alt="Triplegangers product page" srcset="https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png 2516w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=150,103 150w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=300,207 300w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=768,529 768w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=680,468 680w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1200,826 1200w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1280,881 1280w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=430,296 430w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=720,496 720w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=900,620 900w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=800,551 800w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=1536,1057 1536w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=2048,1410 2048w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=668,460 668w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=545,375 545w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=896,617 896w, https://techcrunch.com/wp-content/uploads/2025/01/Triplegangers-product-page.png?resize=708,487 708w" sizes="auto, (max-width: 2516px) 100vw, 2516px"><figcaption><span>Each of these is a product, with a product page that includes multiple more photos. Used by permission.</span><span><strong>Image Credits:</strong><a rel="nofollow" href="https://triplegangers.com/browse/scans/full-body" target="_blank">Triplegangers <span>(opens in a new window)</span></a></span></figcaption></figure>

<h2 id="h-can-t-know-for-certain-what-was-taken">Can’t know for certain what was taken</h2>

<p>By Wednesday, after days of OpenAI’s bot returning, Triplegangers had a properly configured robot.txt file in place, and also a Cloudflare account set up to block its GPTBot and several other bots he discovered, like Barkrowler (an SEO crawler) and Bytespider (TokTok’s crawler). Tomchuk is also hopeful he’s blocked crawlers from other AI model companies. On Thursday morning, the site didn’t crash, he said.</p>

<p>But Tomchuk still has no reasonable way to find out exactly what OpenAI successfully took or to get that material removed. He’s found no way to contact OpenAI and ask. OpenAI did not respond to TechCrunch’s request for comment. And OpenAI has so far <a href="https://techcrunch.com/2025/01/01/openai-failed-to-deliver-the-opt-out-tool-it-promised-by-2025/">failed to deliver its long-promised opt-out tool</a>, as TechCrunch recently reported.</p>

<p>This is an especially tricky issue for Triplegangers. “We’re in a business where the rights are kind of a serious issue, because we scan actual people,” he said. With laws like Europe’s GDPR, “they cannot just take a photo of anyone on the web and use it.”</p>

<p>Triplegangers’ website was also an especially delicious find for AI crawlers. <a href="https://techcrunch.com/2025/01/09/scale-ai-hit-by-its-second-employee-wage-lawsuit-in-less-than-a-month/">Multibillion-dollar-valued startups, like Scale AI</a>, have been created where humans painstakingly tag images to train AI. Triplegangers’ site contains photos tagged in detail: ethnicity, age, tattoos versus scars, all body types, and so on.</p>

<p>The irony is that the OpenAI bot’s greediness is what alerted Triplegangers to how exposed it was. Had it scraped more gently, Tomchuk never would have known, he said.</p>







<p>“It’s scary because there seems to be a loophole that these companies are using to crawl data by saying “you can opt out if you update your robot.txt with our tags,” says Tomchuk, but that puts the onus on the business owner to understand how to block them.</p>

<figure><img loading="lazy" decoding="async" width="2079" height="1206" src="https://techcrunch.com/wp-content/uploads/2025/01/openai-crawler-log-2-e1736526937976.jpg?w=680" alt="openai crawler log"><figcaption><span>Triplegangers’ server logs showed how ruthelessly an OpenAI bot was accessing the site, from hundreds of IP addresses. Used by permission.</span></figcaption></figure>

<p>He wants other small online businesses to know that the only way to discover if an AI bot is taking a website’s copyrighted belongings is to actively look. He’s certainly not alone in being terrorized by them. Owners of other websites recently told <a href="https://www.businessinsider.com/openai-anthropic-ai-bots-havoc-raise-cloud-costs-websites-2024-9" target="_blank" rel="noreferrer noopener nofollow">Business Insider</a> how OpenAI bots crashed their sites and ran up their AWS bills.</p>

<p>The problem grew magnitudes in 2024. New research from digital advertising company DoubleVerify <a href="https://doubleverify.com/ai-crawlers-and-scrapers-are-contributing-to-an-increase-in-general-invalid-traffic/" target="_blank" rel="noreferrer noopener nofollow">found that AI crawlers</a> and scrapers caused an 86% increase in “general invalid traffic” in 2024 — that is, traffic that doesn’t come from a real user.</p>

<p>Still, “most sites remain clueless that they were scraped by these bots,” warns Tomchuk. “Now we have to daily monitor log activity to spot these bots.”</p>

<p>When you think about it, the whole model operates a bit like a mafia shakedown: The AI bots will take what they want unless you have protection.</p>

<p>“They should be asking permission, not just scraping data,” Tomchuk says.</p>

<p><em>TechCrunch has an AI-focused newsletter!&nbsp;<a href="https://techcrunch.com/newsletters/" target="_blank" rel="noreferrer noopener">Sign up here</a>&nbsp;to get it in your inbox every Wednesday.</em></p>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Phi-4 Bug Fixes (131 pts)]]></title>
            <link>https://unsloth.ai/blog/phi4</link>
            <guid>42660335</guid>
            <pubDate>Fri, 10 Jan 2025 21:17:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unsloth.ai/blog/phi4">https://unsloth.ai/blog/phi4</a>, See on <a href="https://news.ycombinator.com/item?id=42660335">Hacker News</a></p>
Couldn't get https://unsloth.ai/blog/phi4: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Flattening ASTs and other compiler data structures (2023) (113 pts)]]></title>
            <link>https://www.cs.cornell.edu/~asampson/blog/flattening.html</link>
            <guid>42659061</guid>
            <pubDate>Fri, 10 Jan 2025 19:23:50 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cs.cornell.edu/~asampson/blog/flattening.html">https://www.cs.cornell.edu/~asampson/blog/flattening.html</a>, See on <a href="https://news.ycombinator.com/item?id=42659061">Hacker News</a></p>
<div id="readability-page-1" class="page"><article>
<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/normal.png" alt="a normal AST">
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/flat.png" alt="a flat AST">
<figcaption>Normal and flattened ASTs for the expression <code>a * b + c</code>.</figcaption>
</figure>

<p><a href="https://en.wikipedia.org/wiki/Region-based_memory_management">Arenas, a.k.a. regions,</a> are everywhere in modern language implementations.
One form of arenas is both super simple and surprisingly effective for compilers and compiler-like things.
Maybe because of its simplicity, I haven’t seen the basic technique in many compiler courses—or anywhere else in a CS curriculum for that matter.
This post is an introduction to the idea and its many virtues.</p>

<p><em>Arenas</em> or <em>regions</em> mean many different things to different people, so I’m going to call the specific flavor I’m interested in here <em>data structure flattening</em>.
Flattening uses an arena that only holds one type, so it’s actually just a plain array, and you can use array indices where you would otherwise need pointers.
We’ll focus here on flattening abstract syntax trees (ASTs), but the idea applies to any pointer-laden data structure.</p>

<p>To learn about flattening, we’ll build a basic interpreter twice:
first the normal way and then the flat way.
Follow along with the code in <a href="https://github.com/sampsyo/flatcalc">this repository</a>, where you can <a href="https://github.com/sampsyo/flatcalc/compare/main...flat#diff-42cb6807ad74b3e201c5a7ca98b911c5fa08380e942be6e4ac5807f8377f87fc">compare and contrast the two branches</a>.
The key thing to notice is that the changes are pretty small,
but we’ll see that they make a microbenchmark go 2.4× faster.
Besides performance, flattening also brings some ergonomics advantages that I’ll outline.</p>

<h2 id="a-normal-ast">A Normal AST</h2>

<p>Let’s start with the textbook way to represent an AST. Imagine the world’s simplest language of arithmetic expressions, where all you can do is apply the four basic binary arithmetic operators to literal integers. Some “programs” you can write in this language include <code>42</code>, <code>0 + 14 * 3</code>, and <code>(100 - 16) / 2</code>.</p>

<p>Maybe the clearest way to write the AST for this language would be as an ML type declaration:</p>

<div><pre><code><span>type</span> <span>binop</span> <span>=</span> <span>Add</span> <span>|</span> <span>Sub</span> <span>|</span> <span>Mul</span> <span>|</span> <span>Div</span>
<span>type</span> <span>expr</span> <span>=</span> <span>Binary</span> <span>of</span> <span>binop</span> <span>*</span> <span>expr</span> <span>*</span> <span>expr</span>
          <span>|</span> <span>Literal</span> <span>of</span> <span>int</span>
</code></pre></div>

<p>But for this post, we’ll use Rust instead. Here are <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L10-L24">the equivalent types in Rust</a>:</p>

<div><pre><code><span>enum</span> <span>BinOp</span> <span>{</span> <span>Add</span><span>,</span> <span>Sub</span><span>,</span> <span>Mul</span><span>,</span> <span>Div</span> <span>}</span>
<span>enum</span> <span>Expr</span> <span>{</span>
    <span>Binary</span><span>(</span><span>BinOp</span><span>,</span> <span>Box</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>,</span> <span>Box</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>),</span>
    <span>Literal</span><span>(</span><span>i64</span><span>),</span>
<span>}</span>
</code></pre></div>

<p>If you’re not a committed Rustacean, <code>Box&lt;Expr&gt;</code> may look a little weird, but that’s just Rust for “a plain ol’ pointer to an <code>Expr</code>.” In C, we’d write <code>Expr*</code> to mean morally the same thing; in Java or Python or OCaml, it would just be <code>Expr</code> because everything is a reference by default.<sup id="fnref:inline" role="doc-noteref"><a href="#fn:inline" rel="footnote">1</a></sup></p>

<p>With the AST in hand, we can write all the textbook parts of a language implementation, like a <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L28-L50">parser</a>, a <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L139-L155">pretty-printer</a>, and an <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L52-L67">interpreter</a>.
All of them are thoroughly unremarkable.
The whole interpreter is just one method on <code>Expr</code>:</p>

<div><pre><code><span>fn</span> <span>interp</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>-&gt;</span> <span>i64</span> <span>{</span>
    <span>match</span> <span>self</span> <span>{</span>
        <span>Expr</span><span>::</span><span>Binary</span><span>(</span><span>op</span><span>,</span> <span>lhs</span><span>,</span> <span>rhs</span><span>)</span> <span>=&gt;</span> <span>{</span>
            <span>let</span> <span>lhs</span> <span>=</span> <span>lhs</span><span>.interp</span><span>();</span>
            <span>let</span> <span>rhs</span> <span>=</span> <span>rhs</span><span>.interp</span><span>();</span>
            <span>match</span> <span>op</span> <span>{</span>
                <span>BinOp</span><span>::</span><span>Add</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_add</span><span>(</span><span>rhs</span><span>),</span>
                <span>BinOp</span><span>::</span><span>Sub</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_sub</span><span>(</span><span>rhs</span><span>),</span>
                <span>BinOp</span><span>::</span><span>Mul</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_mul</span><span>(</span><span>rhs</span><span>),</span>
                <span>BinOp</span><span>::</span><span>Div</span> <span>=&gt;</span> <span>lhs</span><span>.checked_div</span><span>(</span><span>rhs</span><span>)</span><span>.unwrap_or</span><span>(</span><span>0</span><span>),</span>
            <span>}</span>
        <span>}</span>
        <span>Expr</span><span>::</span><span>Literal</span><span>(</span><span>num</span><span>)</span> <span>=&gt;</span> <span>*</span><span>num</span><span>,</span>
    <span>}</span>
<span>}</span>
</code></pre></div>

<p>My language has keep-on-truckin’ semantics; every expression eventually evaluates to an <code>i64</code>, even if it’s not the number you wanted.<sup id="fnref:arith" role="doc-noteref"><a href="#fn:arith" rel="footnote">2</a></sup></p>

<p>For extra credit, I also wrote a little <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L118-L136">random program generator</a>. It’s also not all that interesting to look at; it just uses a recursively-increasing probability of generating a literal so it eventually terminates. Using fixed PRNG seeds, the random generator enables some easy <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/Makefile#L4">microbenchmarking</a>. By generating and then immediately evaluating an expression, we can measure the performance of AST manipulation without the I/O costs of parsing and pretty-printing.</p>

<p>You can check out <a href="https://github.com/sampsyo/flatcalc">the relevant repo</a> and try it out:</p>

<div><pre><code><span>$ </span><span>echo</span> <span>'(29 * 3) - 9 * 5'</span> | cargo run
<span>$ </span>cargo run gen_interp  <span># Generate and immediately evaluate a random program.</span>
</code></pre></div>

<h2 id="flattening-the-ast">Flattening the AST</h2>

<p>The <em>flattening</em> idea has two pieces:</p>

<ul>
  <li>Instead of allocating <code>Expr</code> objects willy-nilly on the heap, we’ll pack them into a single, contiguous array.</li>
  <li>Instead of referring to children via pointers, <code>Exprs</code> will refer to their children using their indices in that array.</li>
</ul>

<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/flat.png" alt="the same flat AST from earlier">
</figure>

<p>Let’s look back at the doodle from the top of the post.
We want to use a single <code>Expr</code> array to hold all our AST nodes.
These nodes still need to point to each other; they’ll now do that by referring to “earlier” slots in that array.
Plain old integers will take the place of pointers.</p>

<p>If that plan sounds simple, it is—it’s probably even simpler than you’re thinking.
The main thing we need is an array of <code>Expr</code>s.
I’ll use Rust’s <a href="https://doc.rust-lang.org/rust-by-example/generics/new_types.html">newtype idiom</a> to declare our arena type, <a href="https://github.com/sampsyo/flatcalc/blob/25f10b44252a2191ba6d0b5445f929096ad59361/src/main.rs#L37"><code>ExprPool</code></a>, as a shorthand for an <code>Expr</code> vector:</p>

<div><pre><code><span>struct</span> <span>ExprPool</span><span>(</span><span>Vec</span><span>&lt;</span><span>Expr</span><span>&gt;</span><span>);</span>
</code></pre></div>

<p>To keep things fancy, we’ll also give a <a href="https://github.com/sampsyo/flatcalc/blob/25f10b44252a2191ba6d0b5445f929096ad59361/src/main.rs#L32">name</a> to the plain old integers we’ll use to index into an <code>ExprPool</code>:</p>



<p>The idea is that, everywhere we previously used a pointer to an <code>Expr</code> (i.e., <code>Box&lt;Expr&gt;</code> or sometimes <code>&amp;Expr</code>), we’ll use an <code>ExprRef</code> instead.
<code>ExprRef</code>s are just 32-bit unsigned integers, but by giving them this special name, we’ll avoid confusing them with other <code>u32</code>s.
Most importantly, we need to change the definition of <code>Expr</code> itself:</p>

<div><pre><code> enum Expr {
<span>-    Binary(BinOp, Box&lt;Expr&gt;, Box&lt;Expr&gt;),
</span><span>+    Binary(BinOp, ExprRef, ExprRef),
</span>     Literal(i64),
 }
</code></pre></div>

<p>Next, we need to add utilities to <code>ExprPool</code> to create <code>Expr</code>s (allocation) and look them up (dereferencing).
In my implementation, these little functions are called <code>add</code> and <code>get</code>, and <a href="https://github.com/sampsyo/flatcalc/blob/25f10b44252a2191ba6d0b5445f929096ad59361/src/main.rs#L45-L55">their implementations</a> are extremely boring.
To use them, we need to look over our code and find every place where we create new <code>Expr</code>s or follow a pointer to an <code>Expr</code>.
For example, our <code>parse</code> function <a href="https://github.com/sampsyo/flatcalc/blob/c5bbe7bd79f98a3b857f0432d4739a3f4f6241bd/src/main.rs#L28-L50">used to be a method on <code>Expr</code></a>, but we’ll make it <a href="https://github.com/sampsyo/flatcalc/blob/25f10b44252a2191ba6d0b5445f929096ad59361/src/main.rs#L57-L81">a method on <code>ExprPool</code> instead</a>:</p>

<div><pre><code><span>-fn parse(tree: Pair&lt;Rule&gt;) -&gt; Self {
</span><span>+fn parse(&amp;mut self, tree: Pair&lt;Rule&gt;) -&gt; ExprRef {
</span></code></pre></div>

<p>And where we used to return a newly allocated <code>Expr</code> directly, we’ll now wrap that in <code>self.add()</code> to return an <code>ExprRef</code> instead.
Here’s the <code>match</code> case for constructing a literal expression:</p>

<div><pre><code> Rule::number =&gt; {
     let num = tree.as_str().parse().unwrap();
<span>-    Expr::Literal(num)
</span><span>+    self.add(Expr::Literal(num))
</span> }
</code></pre></div>

<p>Our interpreter <a href="https://github.com/sampsyo/flatcalc/blob/25f10b44252a2191ba6d0b5445f929096ad59361/src/main.rs#L83-L98">gets the same treatment</a>.
It also becomes an <code>ExprPool</code> method, and we have to add <code>self.get()</code> to go from an <code>ExprRef</code> to an <code>Expr</code> we can pattern-match on:</p>

<div><pre><code><span>-fn interp(&amp;self) -&gt; i64 {
</span><span>+fn interp(&amp;self, expr: ExprRef) -&gt; i64 {
</span><span>-    match self {
</span><span>+    match self.get(expr) {
</span></code></pre></div>

<p>That’s about it.
I think it’s pretty cool how few changes are required—see for yourself in <a href="https://github.com/sampsyo/flatcalc/compare/main...flat#diff-42cb6807ad74b3e201c5a7ca98b911c5fa08380e942be6e4ac5807f8377f87fc">the complete diff</a>.
You replace <code>Box&lt;Expr&gt;</code> with <code>ExprRef</code>, insert <code>add</code> and <code>get</code> calls in the obvious places, and you’ve got a flattened version of your code.
Neat!</p>

<h2 id="but-why">But Why?</h2>

<p>Flattened ASTs come with a bunch of benefits.
The classic ones most people cite are all about performance:</p>

<ol>
  <li><strong>Locality.</strong>
Allocating normal pointer-based <code>Expr</code>s runs the risk of <a href="https://en.wikipedia.org/wiki/Fragmentation_(computing)">fragmentation</a>.
Flattened <code>Expr</code>s are packed together in a contiguous region of memory, which is good for <a href="https://en.wikipedia.org/wiki/Locality_of_reference#Types_of_locality">spatial locality</a>.
Your data caches will work better because <code>Expr</code>s are more likely to share a cache line,
and even simple <a href="https://en.wikipedia.org/wiki/Prefetching">prefetchers</a> will do a better job of predicting which <code>Expr</code>s to load before you need them.
<a href="https://dl.acm.org/doi/10.1145/582419.582421">A sufficiently smart memory allocator might achieve the same thing</a>, especially if you allocate the whole AST up front and never add to it, but using a dense array removes all uncertainty.</li>
  <li><strong>Smaller references.</strong>
Normal data structures use pointers for references; on modern architectures, those are always 64 bits.
After flattening, you can use smaller integers—if you’re pretty sure you’ll never need more than 4,294,967,295 AST nodes,
you can get by with 32-bit references, like we did in our example.
That’s a 50% space savings for all your references, which could amount to a substantial overall memory reduction in pointer-heavy data structures like ASTs.
Smaller memory footprints mean less bandwidth pressure and even better spatial locality.
And you might save even more if you can get away with 16- or even 8-bit references for especially small data structures.</li>
  <li><strong>Cheap allocation.</strong>
In flatland, there is no need for a call to <code>malloc</code> every time you create a new AST node.
Instead, provided you pre-allocate enough memory to hold everything, allocation can entail just <a href="https://docs.rs/bumpalo/latest/bumpalo/">bumping the tail pointer</a> to make room for one more <code>Expr</code>.
Again, <a href="https://dl.acm.org/doi/10.1145/582419.582421">a really fast <code>malloc</code> might be hard to compete with</a>—but you basically can’t beat bump allocation on sheer simplicity.</li>
  <li><strong>Cheap deallocation.</strong>
Our flattening setup assumes you never need to free individual <code>Expr</code>s.
That’s probably true for many, although not all, language implementations:
you might build up new subtrees all the time, but you don’t need to reclaim space from many old ones.
ASTs tend to “die together,” i.e., it suffices to deallocate the entire AST all at once.
While freeing a normal AST entails traversing all the pointers to free each <code>Expr</code> individually, you can deallocate a flattened AST in one fell swoop by just freeing the whole <code>ExprPool</code>.</li>
</ol>

<p>I think it’s interesting that many introductions to arena allocation tend to focus on cheap deallocation (#4) as the main reason to do it.
<a href="https://en.wikipedia.org/wiki/Region-based_memory_management">The Wikipedia page</a>, for example, doesn’t (yet!) mention locality (#1 or #2) at all.
You can make an argument that #4 might be the <em>least</em> important for a compiler setting—since ASTs tend to persist all the way to the end of compilation, you might not need to free them at all.</p>

<p>Beyond performance, there are also ergonomic advantages:</p>

<ol>
  <li><strong>Easier lifetimes.</strong>
In the same way that it’s easier for your computer to free a flattened AST all at once, it’s also easier for <em>humans</em> to think about memory management at the granularity of an entire AST.
An AST with <em>n</em> nodes has just one lifetime instead of <em>n</em> for the programmer to think about.
This simplification is quadruply true in Rust, where lifetimes are not just in the programmer’s head but in the code itself.
Passing around a <code>u32</code> is way less fiddly than carefully managing lifetimes for all your <code>&amp;Expr</code>s: your code can rely instead on the much simpler lifetime of the <code>ExprPool</code>.
I suspect this is why the technique is so popular in Rust projects.
As a Rust partisan, however, I’ll argue that the same simplicity advantage applies in C++ or any other language with manual memory management—it’s just latent instead of explicit.</li>
  <li><strong>Convenient deduplication.</strong>
A flat array of <code>Expr</code>s can make it fun and easy to implement <a href="https://en.wikipedia.org/wiki/Hash_consing">hash consing</a> or even simpler techniques to avoid duplicating identical expressions.
For example, if we notice that we are using <code>Literal</code> expressions for the first 128 nonnegative integers a lot, we could reserve the first 128 slots in our <code>ExprPool</code> just for those.
Then, when someone needs the integer literal expression <code>42</code>, our <code>ExprPool</code> don’t need to construct a new <code>Expr</code> at all—we can just produce <code>ExprRef(42)</code> instead.
This kind of game is possible with a normal pointer-based representation too, but it probably requires some kind of auxiliary data structure.</li>
</ol>

<h2 id="performance-results">Performance Results</h2>

<p>Since we have two implementations of the same language, let’s measure those performance advantages.
For a microbenchmark, I randomly generated a program with about 100 million AST nodes and fed it directly into the interpreter (the parser and pretty printer are not involved).
This benchmark is not very realistic: <em>all it does</em> is generate and then immediately run one enormous program.
Some caveats include:</p>

<ul>
  <li>I <a href="https://github.com/sampsyo/flatcalc/blob/2703833615dec76cec4e71419e4073e5bc69dcb0/src/main.rs#L42">reserved enough space</a> in the <code>Vec&lt;Expr&gt;</code> to hold the whole program; in the real world, sizing your arena requires more guesswork.</li>
  <li>I expect this microbenchmark to over-emphasize the performance advantages of cheap allocation and deallocation, because it does very little other work.</li>
  <li>I expect it to under-emphasize the impact of locality, because the program is so big that only a tiny fraction of it will fit the CPU cache at a time.</li>
</ul>

<p>Still, maybe we can learn something.</p>

<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/standard.png" alt="bar chart comparing the execution time of our normal and flat (and extra-flat) interpreters">
</figure>

<p>I used <a href="https://github.com/sharkdp/hyperfine">Hyperfine</a> to compare the average running time over 10 executions on my laptop.<sup id="fnref:setup" role="doc-noteref"><a href="#fn:setup" rel="footnote">3</a></sup>
Here’s a graph of the running times (please ignore the “extra-flat” bar; we’ll cover that next).
The plot’s error bars show the standard deviation over the 10 runs.
In this experiment, the normal version took 3.1 seconds and the flattened version took 1.3 seconds—a 2.4× speedup.
Not bad for such a straightforward code change!</p>

<p>Of that 2.4× performance advantage, I was curious to know how much comes from each of the four potential advantages I mentioned above.
Unfortunately, I don’t know how to isolate most of these effects—but #4, cheaper deallocation, is especially enticing to isolate.
Since our interpreter is so simple, it seems silly that we’re spending <em>any</em> time on freeing our <code>Expr</code>s after execution finishes—the program is about to shut down anyway, so leaking that memory is completely harmless.</p>

<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/nofree.png" alt="bar chart comparing versions of our interpreters with and without deallocation">
</figure>

<p>So let’s build versions of both of our interpreters that skip deallocation altogether<sup id="fnref:forget" role="doc-noteref"><a href="#fn:forget" rel="footnote">4</a></sup> and see how much time they save.
Unsurprisingly, the “no-free” version of the flattened interpreter takes about the same amount of time as the standard version, suggesting that it doesn’t spend much time on deallocation anyway.
For the normal interpreter, however, skipping deallocation takes the running time from 3.1 to 1.9 seconds—it was spending around 38% of its time just on freeing memory!</p>

<p>Even comparing the “no-free” versions head-to-head, however, the flattened interpreter is still 1.5× faster than the normal one.
So even if you don’t care about deallocation, the other performance ingredients, like locality and cheap allocation, still have measurable effects.</p>

<h2 id="bonus-exploiting-the-flat-representation">Bonus: Exploiting the Flat Representation</h2>

<p>So far, flattening has happened entirely “under the hood”:
arenas and integer offsets serve as drop-in replacements for normal allocation and pointers.
What could we do if we broke this abstraction layer—if we exploited stuff about the flattened representation that <em>isn’t</em> true about normal AST style?</p>

<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/flat.png" alt="that same flat AST, yet again">
</figure>

<p>The idea is to build a third kind of interpreter that exploits an extra fact about <code>ExprPool</code>s that arises from the way we built it up.
Because <code>Expr</code>s are immutable, we have to construct trees of them “bottom-up”:
we have to create all child <code>Expr</code>s before we can construct their parent.
If we build the expression <code>a * b</code>, <code>a</code> and <code>b</code> must appear earlier in their <code>ExprPool</code> than the <code>*</code> that refers to them.
Let’s bring that doodle back again: visually, you can imagine that reference arrows always go <em>backward</em> in the array, and data always flows <em>forward</em>.</p>

<p>Let’s write <a href="https://github.com/sampsyo/flatcalc/blob/2703833615dec76cec4e71419e4073e5bc69dcb0/src/main.rs#L100-L124">a new interpreter</a> that exploits this invariant.
Instead of starting at the root of the tree and recursively evaluating each child, we can start at the beginning of the <code>ExprPool</code> and scan from left to right.
This iteration is guaranteed to visit parents after children, so we can be sure that the results for subexpressions will be ready when we need them.
Here’s <a href="https://github.com/sampsyo/flatcalc/blob/2703833615dec76cec4e71419e4073e5bc69dcb0/src/main.rs#L100-L124">the whole thing</a>:</p>

<div><pre><code><span>fn</span> <span>flat_interp</span><span>(</span><span>self</span><span>,</span> <span>root</span><span>:</span> <span>ExprRef</span><span>)</span> <span>-&gt;</span> <span>i64</span> <span>{</span>
    <span>let</span> <span>mut</span> <span>state</span><span>:</span> <span>Vec</span><span>&lt;</span><span>i64</span><span>&gt;</span> <span>=</span> <span>vec!</span><span>[</span><span>0</span><span>;</span> <span>self</span><span>.0</span><span>.len</span><span>()];</span>
    <span>for</span> <span>(</span><span>i</span><span>,</span> <span>expr</span><span>)</span> <span>in</span> <span>self</span><span>.0</span><span>.into_iter</span><span>()</span><span>.enumerate</span><span>()</span> <span>{</span>
        <span>let</span> <span>res</span> <span>=</span> <span>match</span> <span>expr</span> <span>{</span>
            <span>Expr</span><span>::</span><span>Binary</span><span>(</span><span>op</span><span>,</span> <span>lhs</span><span>,</span> <span>rhs</span><span>)</span> <span>=&gt;</span> <span>{</span>
                <span>let</span> <span>lhs</span> <span>=</span> <span>state</span><span>[</span><span>lhs</span><span>.0</span> <span>as</span> <span>usize</span><span>];</span>
                <span>let</span> <span>rhs</span> <span>=</span> <span>state</span><span>[</span><span>rhs</span><span>.0</span> <span>as</span> <span>usize</span><span>];</span>
                <span>match</span> <span>op</span> <span>{</span>
                    <span>BinOp</span><span>::</span><span>Add</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_add</span><span>(</span><span>rhs</span><span>),</span>
                    <span>BinOp</span><span>::</span><span>Sub</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_sub</span><span>(</span><span>rhs</span><span>),</span>
                    <span>BinOp</span><span>::</span><span>Mul</span> <span>=&gt;</span> <span>lhs</span><span>.wrapping_mul</span><span>(</span><span>rhs</span><span>),</span>
                    <span>BinOp</span><span>::</span><span>Div</span> <span>=&gt;</span> <span>lhs</span><span>.checked_div</span><span>(</span><span>rhs</span><span>)</span><span>.unwrap_or</span><span>(</span><span>0</span><span>),</span>
                <span>}</span>
            <span>}</span>
            <span>Expr</span><span>::</span><span>Literal</span><span>(</span><span>num</span><span>)</span> <span>=&gt;</span> <span>num</span><span>,</span>
        <span>};</span>
        <span>state</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>res</span><span>;</span>
    <span>}</span>
    <span>state</span><span>[</span><span>root</span><span>.0</span> <span>as</span> <span>usize</span><span>]</span>
<span>}</span>
</code></pre></div>

<p>We use a dense <code>state</code> table to hold one result value per <code>Expr</code>.
The <code>state[i] = res</code> line fills this vector up whenever we finish an expression.
Critically, there’s no recursion—binary expressions can get the value of their subexpressions by looking them up directly in <code>state</code>.
At the end, when <code>state</code> is completely full of results, all we need to do is return the one corresponding to the requested expression, <code>root</code>.</p>

<p>This “extra-flat” interpreter has two potential performance advantages over the recursive interpreter:
there’s no stack bookkeeping for the recursive calls,
and the linear traversal of the <code>ExprPool</code> could be good for locality.
On the other hand, it has to randomly access a really big <code>state</code> vector, which could be bad for locality.</p>

<figure>
<img src="https://www.cs.cornell.edu/~asampson/media/flattening/standard.png" alt="the same bar chart comparing the execution time for normal, flat, and extra-flat interpreters">
</figure>

<p>To see if it wins overall, let’s return to our bar chart from earlier.
The extra-flat interpreter takes 1.2 seconds, compared to 1.3 seconds for the recursive interpreter for the flat AST.
That’s marginal compared to how much better flattening does on its own than the pointer-based version,
but an 8.2% performance improvement ain’t nothing.</p>

<p>My favorite observation about this technique, due to <a href="https://old.reddit.com/r/ProgrammingLanguages/comments/mrifdr/treewalking_interpreters_and_cachelocality/gumsi2v/">a Reddit comment</a> by <a href="https://craftinginterpreters.com/">Bob Nystrom</a>, is that it essentially reinvents the idea of a <a href="https://en.wikipedia.org/wiki/Bytecode">bytecode</a> interpreter.
The <code>Expr</code> structs are bytecode instructions, and they contain variable references encoded as <code>u32</code>s.
You could make this interpreter even better by swapping out our simple <code>state</code> table for some kind of stack, and then it would <em>really</em> be no different from a bytecode interpreter you might design from first principles.
I just think it’s pretty nifty that “merely” changing our AST data structure led us directly from the land of tree walking to the land of bytecode.</p>

<h2 id="further-reading">Further Reading</h2>

<p>I <a href="https://discuss.systems/@adrian/109990979464062464">asked on Mastodon</a> a while back for pointers to other writing about data structure flattening,
and folks really came through (thanks, everybody!).
Here are some other places it came up in a compilers context:</p>

<ul>
  <li>Mike Pall <a href="http://lua-users.org/lists/lua-l/2009-11/msg00089.html">attributes some of LuaJIT’s performance</a> to its “linear, pointer-free IR.” It’s pointer-free because it’s flattened.</li>
  <li>Concordantly, <a href="https://blog.nelhage.com/post/why-sorbet-is-fast/">a blog post explaining the performance of the Sorbet type-checker for Ruby</a> extols the virtues of using packed arrays and replacing 64-bit pointers with 32-bit indices.</li>
  <li>The Oil shell project has a <a href="https://github.com/oilshell/oil/wiki/Compact-AST-Representation">big collection of links</a> all about “compact AST representation,” much of which boils down to flattening.</li>
</ul>

<p>Beyond just language implementation, similar concepts show up in other performance-oriented domains.
I admit that I understand this stuff less, especially the things from the world of video games:</p>

<ul>
  <li><a href="http://iu-parfunc.github.io/gibbon/">A line of work</a> from Purdue and Indiana is about compiling programs to operate directly on serialized data. <a href="https://drops.dagstuhl.de/opus/volltexte/2017/7273/pdf/LIPIcs-ECOOP-2017-26.pdf">Gibbon</a> in particular is pretty much a translator from “normal”-looking code to flattened implementations.</li>
  <li>Flattening-like ideas appear a lot in <em>data-oriented design</em>, a broadly defined concept that I only partially understand. For example, <a href="https://andrewkelley.me/">Andrew Kelley</a> argues in <a href="https://vimeo.com/649009599#t=850s">a talk on the topic</a> for using indices in place of pointers.</li>
  <li>Check out this <a href="https://manishearth.github.io/blog/2021/03/15/arenas-in-rust/">overview of arena libraries in Rust</a> and its discussion of the ergonomics of arena-related lifetimes.</li>
  <li>Here’s <a href="https://floooh.github.io/2018/06/17/handles-vs-pointers.html">a post comparing handles vs. pointers in game development</a> that advocates for packing homogeneously typed objects into arrays and using indices to refer to them.</li>
  <li>Similar ideas show up in <a href="https://en.wikipedia.org/wiki/Entity_component_system"><em>entity-component systems</em> (ECS)</a>, a big idea from game development that I also don’t completely understand. <a href="https://ajmmertens.medium.com/building-an-ecs-2-archetypes-and-vectorization-fe21690805f9">This post</a> covers many of the same locality-related themes as we did above.</li>
</ul>

<p>After I published this post, many people pointed me toward <a href="https://recursion.wtf/posts/rust_schemes/">a post from last year by Inanna Malick</a> that shows the same technique applied to same kind of toy “calculator” language implemented in Rust.
That post also uses <em>recursion schemes</em>, an elegant idea from the Haskell world that helps abstract over different concrete representations.
I highly recommend checking that post out.</p>



</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Cuttle – a MTG like game using a standard 52 card deck (276 pts)]]></title>
            <link>https://www.pagat.com/combat/cuttle.html</link>
            <guid>42658614</guid>
            <pubDate>Fri, 10 Jan 2025 18:43:26 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.pagat.com/combat/cuttle.html">https://www.pagat.com/combat/cuttle.html</a>, See on <a href="https://news.ycombinator.com/item?id=42658614">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><!-- InstanceBeginEditable name="MainContent" -->

<!-- start panel --><div><p><img src="https://www.pagat.com/images/gametitle/cuttle.jpg"></p></div>

<!-- end panel -->
<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#players">Players and Cards</a></li>
  <li><a href="#goal">Goal</a></li>
  <li><a href="#setup">Set-up</a></li>
  <li><a href="#play">Play</a>: <a href="#types">Card types</a> - <a href="#oneoff">One-off Effects</a> - <a href="#permanent">Permanent Effects</a></li>
  <li><a href="#variants">Variants</a></li>
  <li><a href="#other">Other Cuttle Pages</a></li>
  <li><a href="#online">Cuttle Online</a></li>
  <li><a href="#faq">Richard Sipie's FAQ</a></li>
</ul>
<h2 id="introduction">Introduction</h2>
<p>The exact origin of this unusual two-player game is unknown. Dating from the 1970's at the latest, it is the earliest example I have found of a <a href="https://www.pagat.com/combat/">combat card game</a>. The aim is to be the first build a layout worth at least 21 points. Cards can be used for their point value, or to attack your opponent's layout by destroying or capturing cards.</p>
<p>For some years a <a href="#faq">FAQ by Richard Sipie</a>, first published in 2000, was the only generally available documentation of the game. I am grateful to Michael Pearson for his help in preparing the new description on this page and to Greg Pallis, an enthusiastic player and winner of the Cuttle tournament in the 2009 Mind Sports Olympiad, for answering my various detailed questions about the rules.</p>
<h2 id="players">Players and Cards</h2>
<p>Cuttle is played by two players using a standard 52-card  deck without jokers.</p>
<h2 id="goal">Goal</h2>
<p>The goal is to be the first to accumulate 21 or more  points worth of point cards on your side of the table. The first player to achieve this wins  the game.</p>
<h2 id="setup">Set-up</h2>
<p>Each player has a hand of cards, normally held concealed from the opponent. The dealer deals six cards to himself and five to his  opponent. These are the players' initial hands. The remaining deck is placed face-down and becomes the  <strong>draw pile</strong>. The dealer's opponent then takes the first turn.</p>
<p>During the game,  players play cards from their hands, placing them face up on the table in front of them. This way each player forms a layout of cards on their own side of the table. </p>
<p>Various actions cause cards to be discarded. Discarded cards are stacked face-up next to the draw pile so that only the top card is visible. This pile of discards is called the <strong>scrap pile</strong>. </p>
<h2 id="play">Play</h2>
<p>On your turn you must perform exactly <strong>one</strong> of the following  actions:</p>
<ul>
  <li>draw  a card from the draw pile and add it to your hand</li>
  <li>play  a point card from your hand</li>
  <li>play  a one-off effect card from your hand</li>
  <li>play  a permanent effect card from your hand</li>
</ul>
<p>The turn then passes to your opponent.</p>
<p>If the draw pile runs out, then instead of drawing a card, a player is allowed to pass, i.e. do nothing at all on that turn. If there are three consecutive passes the game ends and neither player wins.</p>
<h3 id="types">Card types and how to use them</h3>
<p>In Cuttle there  are  three  categories of card: point  cards, one-off  effect cards and permanent  effect cards.</p>
<dl>
  <dt>1. Point cards<strong> </strong></dt>
  <dd><strong>Ace, 2, 3, 4, 5, 6, 7, 8, 9, 10</strong> can be played as point cards.</dd>
  <dd>Aces are worth 1 point. Number cards are worth their face  value.</dd>
  <dd>There are two ways to play a point card:</dd>
<ol>
  <li type="a">A point card can be played face-up on your side of the table. These cards add up to form your total points. The first player to accumulate 21 total  points wins the game.</li>
  <li type="a">Alternatively, a point card can  be played as a ‘<strong>scuttle</strong>’ allowing  you to remove an opponent’s point card from the table. The point card you play must be higher in value than the card you wish to scuttle, or equal in value with a higher suit. The rank of the suits is clubs (lowest) &lt; diamonds &lt; hearts &lt; spades (highest). So for example the <strong><img src="https://www.pagat.com/images/internat/diamond.gif" alt="diamond">7</strong> can scuttle the <strong><img src="https://www.pagat.com/images/internat/club.gif" alt="club">7</strong> or the <strong><img src="https://www.pagat.com/images/internat/heart.gif" alt="heart">6</strong> but the <strong><img src="https://www.pagat.com/images/internat/diamond.gif" alt="diamond">7</strong> cannot scuttle the <strong><img src="https://www.pagat.com/images/internat/heart.gif" alt="heart">7</strong>. To scuttle an opponent's point card, place your card on top of it and discard both cards to the scrap pile.</li>
</ol>
  <dt>2. One-off effect cards</dt>
  <dd><strong>Ace, 2, 3, 4, 5, 6, 7, 9</strong> can be played as one-off effect cards.</dd>
  <dd>One-off effect cards are never placed on the table but  are discarded into the scrap pile immediately after use.   See the <a href="#oneoff">list below</a> for a description of each effect.</dd>
  <dt>3. Permanent effect cards</dt>
  <dd><strong>8, Jack, Queen, King</strong> can be played as permanent effect cards</dd>
  <dd>Permanent effect cards are played face-up on the table  like point cards, though note that the 8 is turned sideways. A permanent effect  lasts for as long as the card is on the table. See the <a href="#permanent">list below</a> for a  description of each effect.</dd>
</dl>
<h3 id="oneoff">One-off Effects</h3>
<dl>
  <dt>Ace</dt>
  <dd>  Scrap all point cards on the table - both yours and your opponents'.</dd>
  <dt>2</dt>
  <dd>There are two possible ways to use a two as a one-off effect card.</dd>
<ol>
  <li type="a">  Play a two in your turn to scrap any permanent effect card on the  table.</li>
  <li type="a">Play a two<em> </em>to block a one-off effect card played by your opponent. This is the only case in which you can play a card  during your opponent's turn. Your two and your opponent's one-off effect card are both scrapped. Note that a two can be used to block a two: if you play a one-off effect and your opponent tries to block it with a two, you can use your own two to block your opponent's two. Both twos go to the scrap pile and your original one-off effect card takes effect (unless of course your opponent then plays <em>another</em> two to block it again).</li>
</ol>
  <dt>3<u> </u></dt>
  <dd>  Rummage through the scrap pile and add  a card of your choice to your hand. Since the 3 is not scrapped until after its effect has been carried out, you cannot use this effect to take back the 3 you just played.</dd>
  <dt>4<u> </u></dt>
  <dd>  Your opponent must discard two cards  of his choice from his hand, showing them to you before placing them on the scrap pile.</dd>
  <dt>5 </dt>
  <dd>  Draw the top two cards from the draw pile and add them to your hand.</dd>
  <dt>6 </dt>
  <dd>  Scrap all permanent effect cards on  the table - both yours and your opponents'.</dd>
  <dt>7 </dt>
  <dd>  Draw a card and play it immediately  however you wish. <br>
    If you draw a card that cannot be  played immediately it is discarded, but if it can be played you must play it, even if it is to your disadvantage. For example a jack might have to be used to give a point card to your opponent. </dd>
  <dt>9</dt>
  <dd>  Return any one permanent effect card on  the table to its controller’s hand.<br>
    Note that if you use this to return a jack, the point card that it was stacked on changes sides.</dd>
</dl>
<h3 id="permanent">Permanent Effects</h3>
<dl>
  <dt>8 </dt>
  <dd>  While you have an 8 on the table as a permanent effect card, your opponent must play with the cards  in his hand exposed. The 8 is placed sideways on the table,  distinguishing it from point cards and making it look like a pair of glasses.</dd>
  <dt>Jack </dt>
  <dd>  Transfer control of a  point  card. The jack is placed on top of a   point card and both cards are moved across the table, changing the owner. Multiple jacks can be stacked on top of a single point card, and the ownership changes each time a jack is added or removed.<br>
    Naturally you would normally play a jack on a point card controlled by your opponent, moving it to your side of the table so that it becomes yours. However, if you were to draw a jack as a result of the one-off effect of a 7 when your opponent had no point cards, you would be forced to play  it on  one of your own point cards and pass it to your opponent.<br>
    If a point card is scrapped, either  by an effect or by scuttling, any jacks upon it are also scrapped.</dd>
  <dt>Queen </dt>
  <dd>  All your point cards and permanent  effect cards on the table other than queens  are defended from effects that target single cards. Queens protect against 2, 9 and jack effects, but not against an ace or a 6, since these  target multiple cards. Queens do not protect against scuttling (scuttling is not an effect).<br>
    Since queens do not defend themselves or other queens, you can use a 2 to remove an opponent's queen.<br>
    If you play  a 2, your queen on the  table blocks your opponent from countering it with his own 2.</dd>
  <dt>King </dt>
  <dd>  The number of points you require to win the game is  reduced according to the number of kings on your side of the table as follows:</dd>
  
<ul>
  <li>No kings: 21 or more points;</li>
  <li>One king: 14 or more points;</li>
  <li>Two kings: 10 or more points;</li>
  <li>Three kings: 7 or more points;</li>
  <li>All four kings: 5 or more points.</li>
</ul>
</dl>
<h2 id="variants">Variants</h2>
<p>The following improvements to the game have been suggested.</p>
<h3>Fours</h3>
<p>Greg Pallis recommends that when a four is played as a one-off effect, the two cards scrapped from the opponent's hand should be chosen at random. The opponent's hand is shuffled face down, two cards are drawn from it, exposed, and discarded to the scrap pile. </p>
<p>This rule change encourages aggressive play, makes the four stronger, and somewhat weakens the power of twos, since if you keep them in your hand they are vulnerable to a four attack.</p>
<h3>Eights</h3>
<p>Daniel Goers suggests that an 8 can be played as a one-off effect card to scrap a 8 that is on the table as a permanent effect card. Both 8's are discarded to the scrap pile.</p>
<h3>Nines</h3>
<p>In the standard rules, nines are almost useless as one-off effect cards. You might use one to remove a jack from a point card controlled by your opponent if that immediately won the game. In any other case, your opponent can immediately undo the effect of the nine by simply putting the permanent effect card back on the table.</p>
<p>I suggest the following amended rule. When you play a nine as a one-off effect, you return one permanent card of your choice to your opponent's hand, and <strong>your opponent must wait at least one turn before  playing that card again</strong>.</p>
<p>Reddit user <em>gaylordqueen69</em> has suggested a more powerful use for the nine. When you play a nine as a one-off effect you take one permanent card of your choice from the table and place it face down on top of the draw pile. This card will therefore be acquired by the next player who draws a card.</p>
<h3>Tens</h3>
<p>Daniel Goers suggests that a 10 can be used as a one-off effect card to block a scuttle. The 10 and the card played as a scuttle are discarded to the scrap pile and the card that your opponment was trying to scuttle remains in place.</p>
<h3>Queens</h3>
<p>Reddit user <em>beamer159</em> has suggested a variant in which although a queen does not protect itself, it does protect other queens. Therefore if you have two queens they protect each other as well as your other permanent effect cards and can only be removed by a six.</p>
<h3>Joker</h3>
<p>Daniel Goers suggests that one Joker can be added to the deck. It is played as a one-off effect and causes the players to exchange  hands with each other.</p>
<h2 id="other">Other Cuttle Pages</h2>
<p>Jared Miller has published a revised and clarified set of <a href="https://github.com/shmup/card-game-rules/blob/master/cuttle.md">Cuttle rules</a> on github.</p>
<p>The  <a href="https://www.reddit.com/r/boardgames/comments/2xnnx5/2player_card_game_cuttle/">Cuttle page</a> by <em>gaylordqueen69</em> on Reddit includes an amusing rewrite of the FAQ, some suggested rule changes, and carries comments including a completely revised schedule of one-off effects suggested by <em>beamer159</em>.</p>
<h2 id="online">Cuttle Online</h2>
<p>You can play Cuttle online against human opponents at Ryan Emberling's <a href="https://www.cuttle.cards/">Cuttle site</a>.</p>
<h2 id="faq">Richard Sipie's Cuttle FAQ</h2>

<p>For reference, I have reproduced below  copy of Richard Sipie's original Cuttle FAQ, published in 2000, which used to be at geocities.com. <a href="https://web.archive.org/web/20080320105149/http://www.geocities.com/richardsipie/cuttle.htm" rel="nofollow noopener" target="_blank">An archive copy of the original page</a> is also available. I have tried and failed to contact Richard Sipie to ask his permission to publish this. If anyone has any further news of him or his plans for this FAQ, please <a href="mailto:john@pagat.com?subject=cuttle">let me know</a>.</p>
<hr>

<h3>1. What is Cuttle?</h3>

<p>Cuttle is a game for 2 players, played with a simple 52-card pack.</p>

<p>The objective of the game is to have 21 points worth of "Point Cards" on the table. A game takes approximately five minutes, although anything between twenty minutes and twenty seconds is possible!</p>

<h3>2. How do I play it?</h3>

<p>Play begins with the dealer, who deals six cards to himself and five to his opponent. This opponent then takes the first turn.</p>

<p>On a turn, a player may play a card (see #3), or draw one. If a player has 21 or more points worth of "point cards" on the table at the end of his turn, that player is victorious - otherwise the turn passes to his opponent.</p>

<h3b>
<h3>3. What do the cards do?
  
</h3>
<p>Firstly: ANY numbered card (A-10) may be played as a "point card". In this case, the player puts the card face-up on the table in front of him, and it is worth as many points as the are spots on its face (1 for an ace, etc).</p> 

<p>Secondly: ANY numbered card (A-10) may be played, instead, as a "scuttle". In this case, it is played ON TOP of a point card which it exceeds in value*. Both cards are then moved directly to the scrap pile (face up, as is everything there)**.</p>

<p>*: Value is not just numerical, but alphabetical: clubs - diamonds - hearts - spades. The eight of clubs will scuttle the seven of spades, but not the eight of hearts.</p>

<p>**: Cards in the scrap pile have no controller, and do not effect the game in any way.</p>

<p>Finally:</p>

<p>The numbered cards may all be played as a one-off, except for the eights and tens. In this case, they are placed directly into the scrap pile, with the following effects.</p>

<p><b>ACES:</b> Put all point cards on the table into the scrap pile.</p>

<p><b>TWOS:</b> Place any card on the table into the scrap pile, except a point card. (In practice, Kings, Queens, Jacks and the "glasses" eight) <br>
 &nbsp; &nbsp; &nbsp; <b>OR<br></b>Place any one-off just played into the scrap pile. This occurs before the effect of that card is accomplished, and, uniquely, can be played <i>during the opponents turn</i>, as well as your own.</p>

<p><b>THREES:</b> Rummage through the scrap pile, taking a card of your choice into your hand.</p>

<p><b>FOURS:</b> Opponent must discard two cards of his choice from his hand into the scrap pile.</p>

<p><b>FIVES:</b> You may draw two cards.</p>

<p><b>SIXES:</b> All cards on the table except for point cards are moved into the scrap pile.</p>

<p><b>SEVENS:</b> Draw a card. You can, and must, play this card immediately - whether as a point card, a scuttle, a one-off, whatever. If you are unable to play the card, it is discarded. (This may only happen in the event of drawing a jack).</p>

<p><b>NINES:</b> Return any permanent card to its controller's hand.</p>

<p>--</p>

<p><b>ROYALTY </b>can only be played on your turn, and count as no points.</p>

<p><b>JACKS:</b> Are placed on top of a point card already on the table. Kept there, the card is moved across the table and is now owned by the opponent of its original owner (who is generally your opponent!)</p>

<p><b>QUEENS:</b> Are played on the table, like a point card. With a queen in play, none of your other cards may be the target of opposing cards that target a single card, such as jacks and twos. However, this offers no protection against those like aces that target more widely, even if there is only one card the table that will be effected. Nor do Queens offer any protection against scuttle attacks.</p>

<p><b>KINGS:</b> Are played like queens. With a king in play, a player can win with just 14 points worth of point cards on the table. With two kings he needs just ten, with three, seven, and with all four just five points! (Mathematically, a player needs 21/(1.5^k) points to win, where k is the number of kings controlled by that player).</p>

<p>--</p>

<p><b>THE "GLASSES" EIGHT</b></p>
<p>The final card! As well as a point card, an eight too has a secondary use, although it is not a one-off. Instead, the card may be placed rather like a king or queen, but at right angles to the opponent (and his other cards). This differentiates it from point card eights, and simultaneously makes it look like a pair of glasses! The effect is that the opponent must play with his hand exposed until he finds a way to transfer the eight to the scrap pile.</p>

<p>And we're done! </p>

<h3>4. What happens if the pack is exhausted?</h3>

<p>Although I am no authority, I can find no other guide to the question online. The rule I have played for twenty-five years is that it is unfair (and dull!) to end the game while a win may still be forced. Therefore, I play that "taking a card" in this situation becomes an effective pass, and that if three of these occur in a row, it is only then that the game is declared a draw.</p>

<h3>5. Can I play a two to "counter" a point card? How about a scuttle?</h3>

<p>The single most common question I am asked :-). Players who are used to Magic: The Gathering are often surprised to find out that this is not allowed - a two is not a universal counterspell. It may only "counter"
a one-off, nothing else.</p> 

<h3>6. Do Queens protect against "countering" twos?</h3>

<p>The second most common question I am asked :-). The answer is yes: queens prevent the targeting of any single card controlled by that player, however briefly.</p>

<h3>7. May a two be used to cancel an opponent's two?</h3>

<p>Absolutely! A last-in, first-out order seems the only sensible one to employ - i.e. in this situation the last-played card (the second two) moves the first to the scrap pile. From there it cannot effect the game, so the original card is played unscathed.</p>

<h3>8. May I use a three to rummage for the three I just played?</h3>

<p>I don't think so. Since cards in the scrap pile do not affect the game, I believe a card sits in a kind of suspension until its effect has been resolved. This also gives clarity to the protection of one-offs by queens.</p>

<h3>9. Suppose the only point card on the table is mine, and my one-off seven comes up as a Jack. What happens</h3>

<p>To me, the only logical answer is that the card switches sides, with the jack on top of it!</p>

<h3>10. This game is has similarities with Magic: The Gathering!</h3>

<p>It's been remarked on. It does however predate it considerably - I learnt the rules in 1975. A reverse genealogy would be fascinating - I would love to know if Richard Garfield has heard of the game.</p>

<h3>J. Who is the author?</h3>

<p>Richard Sipie has been playing games since 1951. He also enjoys walking, collecting (especially theatre paraphernalia) and flattery :-). He is happily married and lives in Bloomington, IL.</p> 

<p>R.Sipie, 2000 <br>
(do E-mail me!)<br>
  <i>[but the address given - richardsipie@yahoo.com - unfortunately no longer works - JM]</i></p>
  <!-- InstanceEndEditable -->
    <!-- end #mainContent --></h3b></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta's memo to employees rolling back DEI programs (902 pts)]]></title>
            <link>https://www.axios.com/2025/01/10/meta-dei-memo-employees-programs</link>
            <guid>42657901</guid>
            <pubDate>Fri, 10 Jan 2025 17:48:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.axios.com/2025/01/10/meta-dei-memo-employees-programs">https://www.axios.com/2025/01/10/meta-dei-memo-employees-programs</a>, See on <a href="https://news.ycombinator.com/item?id=42657901">Hacker News</a></p>
Couldn't get https://www.axios.com/2025/01/10/meta-dei-memo-employees-programs: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Starlink is now cheaper than leading internet provider in some African countries (231 pts)]]></title>
            <link>https://restofworld.org/2025/starlink-cheaper-internet-africa/</link>
            <guid>42657692</guid>
            <pubDate>Fri, 10 Jan 2025 17:24:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://restofworld.org/2025/starlink-cheaper-internet-africa/">https://restofworld.org/2025/starlink-cheaper-internet-africa/</a>, See on <a href="https://news.ycombinator.com/item?id=42657692">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
				<!-- Article Start -->
				
<p>Starlink, launched in 2019 by Elon Musk’s SpaceX, has become the leading satellite internet provider in the world. Now available in more than 100 countries, Starlink can also be a relatively affordable option for users trying to log on in countries with limited internet service providers. Across Africa, for example, Starlink is sometimes the cheapest way to get online.&nbsp;</p>



<p>A <em>Rest of World</em> analysis indicates that in at least five of the 16 African countries where the service is available, a monthly Starlink subscription is cheaper than the leading fixed internet service provider. That subscription cost does not include the upfront cost of Starlink hardware, which ranges in price and availability from $178 for a Starlink Mini in Kenya to $381 for a Standard Actuated kit in Nigeria.</p>



<p><em>Rest of World</em> determined the leading fixed internet service providers through reports published by each country’s communications authority, and obtained the cheapest prices from each company’s website. Prices have been converted to U.S. dollars to make comparisons.</p>



<p>Starlink does not have fixed rates; instead it intermittently raises and lowers its prices. On its website, it notes, “Starlink may adjust prices over time to reflect market conditions resulting in a decrease or increase of the monthly service plan cost.” SpaceX did not respond to <em>Rest of World</em>’s request for comment.&nbsp;</p>



<p>To conduct this analysis, <em>Rest of World</em> compared the price of Starlink’s residential service to the cheapest unlimited fixed internet plan offered by leading internet service providers on January 9, 2025.</p>



<figure></figure>



<p>Historically, internet connections around the globe have typically been enabled by ground-based internet service providers using fiber-optic cables and mobile base stations. But in many parts of the world, that infrastructure is sparse or nonexistent. “This is where satellite providers come in,” said Nitinder Mohan, a computer science professor at the Delft University of Technology in the Netherlands who has studied Starlink’s performance around the world.</p>



<p>“I can be in the middle of a forest and, if I have a direct view of the sky, I can get my internet connectivity,” he told <em>Rest of World</em>. “Regions which are previously underconnected — where there was no way of getting internet connectivity to them — now with these satellites, you can actually enable that.”&nbsp;</p>



<p>Satellite internet’s reach makes it an important tool for <a href="https://restofworld.org/2024/mobile-internet-users-growth-rate/">getting more people online</a> in areas that are internet-poor.&nbsp;</p>



<p><em>Rest of World </em>identified at least five countries in Africa where Starlink is cheaper than the average price of internet service: Kenya, Ghana, Zimbabwe, Mozambique, and Cape Verde. According to the latest <a href="https://www.itu.int/itu-d/reports/statistics/2024/11/10/ff24-internet-use/">figures</a> by the International Telecommunication Union, a U.N. agency focused on information and communication technologies, 38% of the population in Africa uses the internet, compared to 91% of Europe.&nbsp;</p>



<p>Starlink prices range widely, from $10 in Kenya to $50 in Eswatini. For most countries in Africa, the cheapest available Starlink plan costs between $28 and $34 per month. </p>



<p>Since launching in Kenya in July 2023, Starlink has disrupted the existing internet service provider industry. Starlink offers high connectivity speeds and wide availability in remote areas, along with dramatically lower prices. The company also introduced a rental option.&nbsp;</p>



<p>According to the <a href="https://www.ca.go.ke/sites/default/files/2024-10/Sector%20Statistics%20Report%20Q4%202023-2024.pdf">latest figures</a> published by the Communications Authority of Kenya, as of June 2024, just over 8,000 Kenyans subscribe to Starlink, making it the tenth most popular service provider in the country. While legacy telecom providers like Safaricom and Jamii maintain control of the market — with 546,000 and 360,000 subscribers, respectively — TechCabal, an Africa-focused tech publication, <a href="https://techcabal.com/2024/10/14/starlink-becomes-kenyas-tenth-largest-isp/">noted</a> that Kenya’s adoption of Starlink has been swift and continues to rise rapidly.</p>



<p>Safaricom and other legacy providers have responded by <a href="https://cioafrica.co/safaricom-woos-back-customers-with-cheaper-offer/">lowering prices</a> and <a href="https://techcabal.com/2024/09/23/safaricom-internet-speeds-upgraded/">increasing internet speeds</a>. Tim Hatt, head of research and consulting at GSMA Intelligence, the research wing of the Global Systems for Mobile Communications Association, told <em>Rest of World</em> internet service providers are also developing their own satellite networks. Safaricom’s parent company, Vodacom, for example, recently announced a <a href="https://www.investors.com/news/ast-spacemobile-asts-stock-vodafone-deal-space-satellite-cell-service/">partnership</a> with satellite mobile network AST SpaceMobile to provide satellite internet in Europe and Africa. AST SpaceMobile launched its first satellites with the help of SpaceX.</p>



<figure><blockquote><p>Starlink has become so popular in Kenya that the company&nbsp;paused new subscriptions.</p></blockquote></figure>



<p>In rural Kenya, where Safaricom services are either too expensive or unreliable, Starlink is becoming a choice internet provider for households, Abel Boreto, an investor based in Nairobi, told <em>Rest of World</em>. Boreto became tired of using unreliable internet from Safaricom when he visited his hometown, and switched to Starlink in August. He said installing Starlink has saved him money and time.</p>



<p>“Safaricom was quite on the high side and the internet wasn’t even reliable so I decided to try out Starlink, which is more affordable ($10 per month for 50GB) to subscribe and use in the long term,” Boreto said. “It’s very fast and allows me to also share the internet with my parents and relatives when I’m not there.”</p>



<p>Starlink has become so popular in Kenya that the company <a href="https://www.connectingafrica.com/connectivity/starlink-halts-new-sign-ups-in-kenya">paused new subscriptions</a> in major cities in early November due to network overload. The company plans to deploy more infrastructure in Nairobi and Johannesburg in order to bring more people online, said Mohan, the computer science professor at Delft University.</p>



<p>For Mohan, the global Starlink boom raises monopolization concerns. A single dominant player not only leaves customers vulnerable to price hikes and decreasing quality of service but also gives a single company the power to control internet access for an entire country. Kenyan telecoms have also raised <a href="https://african.business/2024/11/technology-information/starlinks-aggressive-push-in-africa-keeps-telcos-on-high-alert">concerns</a> about Starlink taking market share away from local companies that employ thousands of people on the African continent.</p>
				<!-- Article End -->
							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Getting silly with C, part (void*)2 (153 pts)]]></title>
            <link>https://lcamtuf.substack.com/p/getting-silly-with-c-part-void2</link>
            <guid>42657591</guid>
            <pubDate>Fri, 10 Jan 2025 17:16:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://lcamtuf.substack.com/p/getting-silly-with-c-part-void2">https://lcamtuf.substack.com/p/getting-silly-with-c-part-void2</a>, See on <a href="https://news.ycombinator.com/item?id=42657591">Hacker News</a></p>
Couldn't get https://lcamtuf.substack.com/p/getting-silly-with-c-part-void2: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Freeact – A Lightweight Library for Code-Action Based Agents (120 pts)]]></title>
            <link>https://github.com/gradion-ai/freeact</link>
            <guid>42657253</guid>
            <pubDate>Fri, 10 Jan 2025 16:44:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/gradion-ai/freeact">https://github.com/gradion-ai/freeact</a>, See on <a href="https://news.ycombinator.com/item?id=42657253">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto"><code>freeact</code></h2><a id="user-content-freeact" aria-label="Permalink: freeact" href="#freeact"></a></p>
<p dir="auto">A lightweight library for code-action based agents.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contents</h2><a id="user-content-contents" aria-label="Permalink: Contents" href="#contents"></a></p>
<ul dir="auto">
<li><a href="#introduction">Introduction</a></li>
<li><a href="#key-capabilities">Key Capabilities</a></li>
<li><a href="#quickstart">Quickstart</a></li>
<li><a href="#evaluation">Evaluation</a></li>
</ul>
<p dir="auto">The <code>freeact</code> documentation is available <a href="https://gradion-ai.github.io/freeact/" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Introduction</h2><a id="user-content-introduction" aria-label="Permalink: Introduction" href="#introduction"></a></p>
<p dir="auto"><code>freeact</code> is a minimalistic agent library that empowers language models to act as autonomous agents through executable <strong>code actions</strong>. By enabling agents to express their actions directly in code rather than through constrained formats like JSON, <code>freeact</code> provides a flexible and powerful approach to solving complex, open-ended problems that require dynamic solution paths.</p>
<p dir="auto">The library builds upon <a href="https://arxiv.org/abs/2402.01030" rel="nofollow">recent</a> <a href="https://arxiv.org/abs/2411.01747" rel="nofollow">research</a> demonstrating that code-based actions significantly outperform traditional agent approaches, with studies showing up to 20% higher success rates compared to conventional methods. While existing solutions often restrict agents to predefined tool sets, <code>freeact</code> removes these limitations by allowing agents to leverage the full power of the Python ecosystem, dynamically installing and utilizing any required libraries as needed.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Key Capabilities</h2><a id="user-content-key-capabilities" aria-label="Permalink: Key Capabilities" href="#key-capabilities"></a></p>
<p dir="auto"><code>freeact</code> agents can autonomously improve their actions through learning from environmental feedback, execution results, and human guidance. A prominent feature is their ability to store and reuse successful code actions as custom skills in long-term memory. These skills can be composed and interactively refined to build increasingly sophisticated capabilities, enabling efficient scaling to complex tasks.</p>
<p dir="auto">The library's architecture emphasizes extensibility and transparency, avoiding the accidental complexity often introduced by heavier frameworks that obscure crucial implementation details. This design philosophy makes freeact particularly suitable for developers and researchers who need fine-grained control over their agent implementations while maintaining the flexibility to handle edge cases that fall outside predefined action spaces.</p>
<p dir="auto"><code>freeact</code> executes all code actions within <a href="https://gradion-ai.github.io/ipybox/" rel="nofollow"><code>ipybox</code></a>, a secure execution environment built on IPython and Docker that can also be deployed locally. This ensures safe execution of dynamically generated code while maintaining full access to the Python ecosystem. Combined with its lightweight and extensible architecture, <code>freeact</code> provides a robust foundation for building adaptable AI agents that can tackle real-world challenges requiring dynamic problem-solving approaches.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quickstart</h2><a id="user-content-quickstart" aria-label="Permalink: Quickstart" href="#quickstart"></a></p>
<p dir="auto">Install <code>freeact</code> using pip:</p>

<p dir="auto">Create a <code>.env</code> file with <a href="https://console.anthropic.com/settings/keys" rel="nofollow">Anthropic</a> and <a href="https://aistudio.google.com/app/apikey" rel="nofollow">Gemini</a> API keys:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Required for Claude 3.5 Sonnet
ANTHROPIC_API_KEY=...

# Required for generative Google Search via Gemini 2
GOOGLE_API_KEY=..."><pre><span><span>#</span> Required for Claude 3.5 Sonnet</span>
<span>ANTHROPIC_API_KEY</span><span>=</span><span>...</span>

<span><span>#</span> Required for generative Google Search via Gemini 2</span>
<span>GOOGLE_API_KEY</span><span>=</span><span>...</span></pre></div>
<p dir="auto">Launch a <code>freeact</code> agent with generative Google Search skill using the CLI</p>
<div dir="auto" data-snippet-clipboard-copy-content="python -m freeact.cli \
  --model-name=claude-3-5-sonnet-20241022 \
  --ipybox-tag=ghcr.io/gradion-ai/ipybox:basic \
  --skill-modules=freeact_skills.search.google.stream.api"><pre>python -m freeact.cli \
  --model-name=claude-3-5-sonnet-20241022 \
  --ipybox-tag=ghcr.io/gradion-ai/ipybox:basic \
  --skill-modules=freeact_skills.search.google.stream.api</pre></div>
<p dir="auto">or an equivalent <a href="https://github.com/gradion-ai/freeact/blob/main/freeact/examples/quickstart.py">quickstart.py</a> script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="import asyncio

from dotenv import load_dotenv
from rich.console import Console

from freeact import Claude, CodeActAgent, execution_environment
from freeact.cli.utils import stream_conversation


async def main():
    async with execution_environment(
        ipybox_tag=&quot;ghcr.io/gradion-ai/ipybox:basic&quot;,
    ) as env:
        skill_sources = await env.executor.get_module_sources(
            module_names=[&quot;freeact_skills.search.google.stream.api&quot;],
        )

        model = Claude(model_name=&quot;claude-3-5-sonnet-20241022&quot;, logger=env.logger)
        agent = CodeActAgent(model=model, executor=env.executor)
        await stream_conversation(agent, console=Console(), skill_sources=skill_sources)


if __name__ == &quot;__main__&quot;:
    load_dotenv()
    asyncio.run(main())"><pre><span>import</span> <span>asyncio</span>

<span>from</span> <span>dotenv</span> <span>import</span> <span>load_dotenv</span>
<span>from</span> <span>rich</span>.<span>console</span> <span>import</span> <span>Console</span>

<span>from</span> <span>freeact</span> <span>import</span> <span>Claude</span>, <span>CodeActAgent</span>, <span>execution_environment</span>
<span>from</span> <span>freeact</span>.<span>cli</span>.<span>utils</span> <span>import</span> <span>stream_conversation</span>


<span>async</span> <span>def</span> <span>main</span>():
    <span>async</span> <span>with</span> <span>execution_environment</span>(
        <span>ipybox_tag</span><span>=</span><span>"ghcr.io/gradion-ai/ipybox:basic"</span>,
    ) <span>as</span> <span>env</span>:
        <span>skill_sources</span> <span>=</span> <span>await</span> <span>env</span>.<span>executor</span>.<span>get_module_sources</span>(
            <span>module_names</span><span>=</span>[<span>"freeact_skills.search.google.stream.api"</span>],
        )

        <span>model</span> <span>=</span> <span>Claude</span>(<span>model_name</span><span>=</span><span>"claude-3-5-sonnet-20241022"</span>, <span>logger</span><span>=</span><span>env</span>.<span>logger</span>)
        <span>agent</span> <span>=</span> <span>CodeActAgent</span>(<span>model</span><span>=</span><span>model</span>, <span>executor</span><span>=</span><span>env</span>.<span>executor</span>)
        <span>await</span> <span>stream_conversation</span>(<span>agent</span>, <span>console</span><span>=</span><span>Console</span>(), <span>skill_sources</span><span>=</span><span>skill_sources</span>)


<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span>:
    <span>load_dotenv</span>()
    <span>asyncio</span>.<span>run</span>(<span>main</span>())</pre></div>
<p dir="auto">Once launched, you can start interacting with the agent:</p>
<details open="">
  <summary>
    
    <span aria-label="Video description freeact_iss_coffee_720.mp4">freeact_iss_coffee_720.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/202907/400425805-83cec179-54dc-456c-b647-ea98ec99600b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY1NDEzMDEsIm5iZiI6MTczNjU0MTAwMSwicGF0aCI6Ii8yMDI5MDcvNDAwNDI1ODA1LTgzY2VjMTc5LTU0ZGMtNDU2Yy1iNjQ3LWVhOThlYzk5NjAwYi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExMFQyMDMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yM2U4YzM0OWY2ZDU0YjE4MDJiZmVlM2U2NzlmODJlYTY1YjNmMzAwMWM2ZGE5YzhlMTBhODc2ZjlmN2E1ODVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.dOeVUSIv43ebqTxvTzZizbyGSLfHDB77lcONO-_eiiw" data-canonical-src="https://private-user-images.githubusercontent.com/202907/400425805-83cec179-54dc-456c-b647-ea98ec99600b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY1NDEzMDEsIm5iZiI6MTczNjU0MTAwMSwicGF0aCI6Ii8yMDI5MDcvNDAwNDI1ODA1LTgzY2VjMTc5LTU0ZGMtNDU2Yy1iNjQ3LWVhOThlYzk5NjAwYi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMTEwJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDExMFQyMDMwMDFaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yM2U4YzM0OWY2ZDU0YjE4MDJiZmVlM2U2NzlmODJlYTY1YjNmMzAwMWM2ZGE5YzhlMTBhODc2ZjlmN2E1ODVlJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.dOeVUSIv43ebqTxvTzZizbyGSLfHDB77lcONO-_eiiw" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><h2 tabindex="-1" dir="auto">Evaluation</h2><a id="user-content-evaluation" aria-label="Permalink: Evaluation" href="#evaluation"></a></p>
<p dir="auto">We <a href="https://github.com/gradion-ai/freeact/blob/main/evaluation">evaluated</a> <code>freeact</code> using three state-of-the-art models:</p>
<ul dir="auto">
<li><code>claude-3-5-sonnet-20241022</code></li>
<li><code>claude-3-5-haiku-20241022</code></li>
<li><code>gemini-2.0-flash-exp</code></li>
</ul>
<p dir="auto">The evaluation was performed on the <a href="https://huggingface.co/datasets/m-ric/agents_medium_benchmark_2" rel="nofollow">m-ric/agents_medium_benchmark_2</a> dataset, developed by the <a href="https://github.com/huggingface/smolagents">smolagents</a> team at 🤗 Hugging Face. It comprises selected tasks from GAIA, GSM8K, and SimpleQA:</p>
<p dir="auto"><a href="https://github.com/gradion-ai/freeact/blob/main/docs/eval/eval-plot.png"><img src="https://github.com/gradion-ai/freeact/raw/main/docs/eval/eval-plot.png" alt="Performance"></a></p>
<p dir="auto">When comparing our results with smolagents using <code>claude-3-5-sonnet-20241022</code>, we observed the following outcomes (evaluation conducted on 2025-01-07, reference data <a href="https://github.com/huggingface/smolagents/blob/c22fedaee17b8b966e86dc53251f210788ae5c19/examples/benchmark.ipynb">here</a>):</p>
<p dir="auto"><a href="https://github.com/gradion-ai/freeact/blob/main/docs/eval/eval-plot-comparison.png"><img src="https://github.com/gradion-ai/freeact/raw/main/docs/eval/eval-plot-comparison.png" alt="Performance comparison" width="60%"></a></p>
<p dir="auto">Interestingly, these results were achieved using zero-shot prompting in <code>freeact</code>, while the smolagents implementation utilizes few-shot prompting. To ensure a fair comparison, we employed identical evaluation protocols and tools. You can find all evaluation details <a href="https://github.com/gradion-ai/freeact/blob/main/evaluation">here</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Finland's zero homeless strategy (2021) (211 pts)]]></title>
            <link>https://oecdecoscope.blog/2021/12/13/finlands-zero-homeless-strategy-lessons-from-a-success-story/</link>
            <guid>42656711</guid>
            <pubDate>Fri, 10 Jan 2025 15:53:07 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://oecdecoscope.blog/2021/12/13/finlands-zero-homeless-strategy-lessons-from-a-success-story/">https://oecdecoscope.blog/2021/12/13/finlands-zero-homeless-strategy-lessons-from-a-success-story/</a>, See on <a href="https://news.ycombinator.com/item?id=42656711">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
	
	

	

	
	<main id="content">

	<div>
						<article id="post-7341">
				<div>
<p>By Laurence Boone, Boris&nbsp;Cournède, OECD Economics Department;&nbsp;and Marissa&nbsp;Plouin,&nbsp;OECD Directorate for Employment, Labour and Social Affairs&nbsp;</p>



<p>Following a period when homelessness rose in many countries, the onset of the COVID-19 pandemic prompted governments across the OECD&nbsp;area&nbsp;to provide unprecedented public support – including to the homeless. In the&nbsp;United Kingdom, for instance, people who had been living on the streets or in shelters were housed in individual accommodations in a matter of days. And in cities and towns across the OECD, public authorities worked closely with service providers and other partners to provide support to the homeless that had previously been considered impossible.&nbsp;&nbsp;</p>



<p>How can&nbsp;countries&nbsp;build on this momentum and&nbsp;ensure more durable outcomes? The experience of Finland over the past several decades – during which the country has nearly eradicated homelessness – provides a glimpse of what can be possible with a sustained national strategy and enduring political will.&nbsp;&nbsp;</p>



<p>The number of homeless people in Finland has&nbsp;continuously decreased&nbsp;over the past three decades&nbsp;from over 16 000 in 1989&nbsp;to around 4 000,&nbsp;or 0.08% of the population&nbsp;(Figure 1). This is a very low number, especially considering that Finland uses a&nbsp;relatively&nbsp;broad definition of homelessness, whereby in particular it&nbsp;includes&nbsp;people temporarily living with friends and relatives&nbsp;in its official&nbsp;homelessness count.&nbsp;In 2020, practically no-one&nbsp;was&nbsp;sleeping rough on a given night in Finland.&nbsp;&nbsp;</p>



<p><strong>Figure&nbsp;1. Homelessness has shrunk remarkably in Finland</strong></p>



<figure><img data-recalc-dims="1" fetchpriority="high" decoding="async" width="1024" height="729" data-attachment-id="7344" data-permalink="https://oecdecoscope.blog/2021/12/13/finlands-zero-homeless-strategy-lessons-from-a-success-story/blog-13-dec-f1-finland/" data-orig-file="https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?fit=2334%2C1662&amp;ssl=1" data-orig-size="2334,1662" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="BLOG-13-DEC-F1-Finland" data-image-description="" data-image-caption="" data-medium-file="https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?fit=300%2C214&amp;ssl=1" data-large-file="https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?fit=1024%2C729&amp;ssl=1" src="https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=1024%2C729&amp;ssl=1" alt="" srcset="https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=1024%2C729&amp;ssl=1 1024w, https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=300%2C214&amp;ssl=1 300w, https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=768%2C547&amp;ssl=1 768w, https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=1536%2C1094&amp;ssl=1 1536w, https://i0.wp.com/oecdecoscope.blog/wp-content/uploads/2021/12/BLOG-13-DEC-F1-Finland.png?resize=2048%2C1458&amp;ssl=1 2048w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Source: Report 2021: Homelessness in Finland 2020, The Housing Finance and Development Centre of Finland (ARA).</figcaption></figure>



<p>This is undoubtedly a remarkable success, even if comparing homelessness statistics across countries is fraught with difficulties (OECD, 2020).&nbsp;Many homeless people&nbsp;live precariously,&nbsp;with the implication that statistical tools such as household surveys typically fail to accurately measure&nbsp;their living conditions.&nbsp;Furthermore,&nbsp;countries define&nbsp;homelessness&nbsp;very differently, for instance counting people who temporarily live&nbsp;with&nbsp;friends or relatives&nbsp;as homeless&nbsp;(as Finland does) or excluding them from homelessness statistics.&nbsp;While&nbsp;there is no OECD-wide&nbsp;average against which to&nbsp;compare Finland’s homeless rate&nbsp;of 0.08%,&nbsp;other countries&nbsp;with similarly&nbsp;broad definitions of homelessness provide points of reference, such as neighbouring Sweden&nbsp;(0.33%)&nbsp;or&nbsp;the Netherlands (0.23%).<span id="easy-footnote-1-7341"></span><span><a href="#easy-footnote-bottom-1-7341" title="The data for Finland refers to 2020 and comes from ARA (2021). The data for the Netherlands, New Zealand and Sweden refer to 2018, 2018 and 2017 and come from the OECD Affordable Housing Database, Indicator HC 3.1"><sup>1</sup></a></span></p>



<p>Finland’s success is not&nbsp;a matter&nbsp;of&nbsp;luck&nbsp;or the outcome of “quick fixes.”&nbsp;Rather, it is&nbsp;the result of a sustained, well-resourced&nbsp;national&nbsp;strategy, driven by a “Housing First” approach, which provides people experiencing homelessness with immediate, independent, permanent housing, rather than temporary accommodation&nbsp;(OECD, 2020). A key pillar&nbsp;of this effort&nbsp;has been to combine emergency assistance with the&nbsp;supply of rentals to host previously homeless people, either by&nbsp;converting&nbsp;some existing shelters into residential buildings with independent apartments (Kaakinen, 2019)&nbsp;or by building&nbsp;new flats&nbsp;by a government agency (ARA, 2021).&nbsp;Building&nbsp;flats&nbsp;is key:&nbsp;otherwise, especially if housing supply is particularly rigid, the funding of rentals&nbsp;can&nbsp;risk driving&nbsp;up rents&nbsp;(OECD, 2021a), thus&nbsp;reducing&nbsp;the “bang for the buck” of&nbsp;public spending.&nbsp;&nbsp;</p>



<p>The Finnish experience demonstrates the&nbsp;effectiveness of tackling&nbsp;homelessness through&nbsp;a combination of financial&nbsp;assistance, integrated&nbsp;and targeted&nbsp;support services&nbsp;<em>and</em>&nbsp;more supply: using&nbsp;just one&nbsp;of these levers&nbsp;is&nbsp;unlikely to work.&nbsp;Financial assistance comes from the social benefits systems, which includes a housing allowance for low-income people (mostly jobless persons with no or low unemployment benefits)&nbsp;covering about 80% of housing costs&nbsp;(Kangas and Kalliomaa-Puha, 2019).&nbsp;Emergency social&nbsp;assistance funding&nbsp;can complement&nbsp;the housing allowance&nbsp;if it is insufficient. Social services provide housing before other interventions&nbsp;that&nbsp;are&nbsp;targeted to beneficiaries’ needs&nbsp;(such as,&nbsp;to&nbsp;pick&nbsp;one example,&nbsp;providing health services to help overcome substance abuse).&nbsp;These efforts require&nbsp;dwellings: investment grants by Finland’s Housing Finance and Development Centre financed the construction of 2 200 flats over 2016-19 for long-term homeless people (ARA, 2021).&nbsp;Indeed, investing in housing development should be a priority for OECD governments as they navigate the recovery from the crisis: over the past two decades, public investment in housing development&nbsp;has dropped to just 0.06% of GDP across the OECD on average&nbsp;(OECD, 2021b).&nbsp;</p>



<p>Another important driver of Finland’s success is the integration of efforts to fight homelessness with other parts of the social safety net. When&nbsp;a housing&nbsp;need is identified in any part of the social service system, housing is provided first,&nbsp;to&nbsp;provide a solid basis for&nbsp;employment, long-term health&nbsp;and/or family assistance&nbsp;(OECD, 2020).&nbsp;This integrated approach avoids the pitfalls that can arise,&nbsp;for instance,&nbsp;when benefits are preconditioned on&nbsp;having an address, or when obtaining&nbsp;a flat requires&nbsp;a&nbsp;minimum income. There are indications that, by facilitating&nbsp;the&nbsp;integration of previously homeless people in society, the upfront Finnish investment&nbsp;that provides people with&nbsp;housing&nbsp;<em>first,&nbsp;</em>pays off by reducing subsequent costs incurred by social services.&nbsp;Evaluations point to&nbsp;annual&nbsp;savings&nbsp;in public expenditure in the range of&nbsp;EUR 9 600-15 000&nbsp;per person&nbsp;who&nbsp;had&nbsp;previously&nbsp;experienced&nbsp;homelessness&nbsp;(Y-Foundation, 2017; Ministry of the Environment, 2011).&nbsp;&nbsp;</p>



<p>Overall, Finland’s achievements illustrate the benefits of integration, balance&nbsp;and continuity in policies to&nbsp;tackle&nbsp;homelessness:&nbsp;<em>integration</em>&nbsp;across&nbsp;housing and&nbsp;social assistance programmes,&nbsp;<em>balance</em>&nbsp;between demand and supply, and&nbsp;political&nbsp;<em>continuity</em>&nbsp;over time have helped to maximise the results of the country’s investment to&nbsp;end&nbsp;homelessness.&nbsp;Not only has this approach resulted in a steady decline in homelessness, but it has also made the system more resilient to shocks, including&nbsp;the COVID-19&nbsp;crisis. Indeed, the pandemic was less of a&nbsp;strain&nbsp;to Finland’s homeless support system&nbsp;compared to other countries, given that many vulnerable people were already housed and supported in individual flats (Fondation&nbsp;Abbé Pierre – FEANTSA, 2021).&nbsp;&nbsp;</p>



<p>These&nbsp;lessons&nbsp;can be transposed to other&nbsp;OECD&nbsp;countries&nbsp;as they look to build on the momentum and lessons learned from the COVID crisis.&nbsp;</p>



<p><strong>References</strong>&nbsp;</p>



<p>ARA (2021),&nbsp;<a rel="noreferrer noopener" href="https://www.ara.fi/en-US/Materials/Homelessness_reports/Report_2021_Homelessness_in_Finland_2020(60242)" target="_blank"><em>Report 2021: Homelessness in Finland 2020</em>,</a>&nbsp;The Housing Finance and Development Centre of Finland (ARA).&nbsp;Fondation&nbsp;Abbé Pierre – FEANTSA (2021),&nbsp;<a rel="noreferrer noopener" href="https://www.fondation-abbe-pierre.fr/documents/pdf/rapport_europe_2021_gb.pdf" target="_blank">Sixth Overview of Housing Exclusion in Europe</a>, FEANTSA – Abbé Pierre.&nbsp;&nbsp;</p>



<p>Kaakinen, J. (2019), “<a rel="noreferrer noopener" href="https://www.oecd-forum.org/posts/49557-time-to-act-let-s-end-homelessness-for-good" target="_blank">Time to act:&nbsp;Let’s end homelessness for good</a>,” OECD Forum Network Series on the New Societal Contract.&nbsp;</p>



<p>Kangas, O. and L. Kalliomaa-Puha(2019), “<a href="https://ec.europa.eu/social/BlobServlet?docId=21600&amp;langId=en">ESPN Thematic Report on National Strategies to Fight Homelessness and Housing Exclusion: Finland</a>”, European Social Policy Network (ESPN), European Commission, Brussels.</p>



<p>Ministry of the Environment (2011), <em>Asunnottomuuden vähentämisen taloudelliset [Economic effects of reducing homelessness]</em>, Ympäristöministeriön.</p>



<p>OECD (2020),&nbsp;“Better data and policies to fight homelessness in the OECD”, Policy Brief on Affordable Housing, OECD, Paris,&nbsp;<a href="http://oe.cd/homelessness-2020" target="_blank" rel="noreferrer noopener">http://oe.cd/homelessness-2020</a>.&nbsp;</p>



<p>OECD (2021a),&nbsp;<a href="http://www.oecd.org/housing/policy-toolkit" target="_blank" rel="noreferrer noopener"><em>Brick by Brick: Building Better Housing Policies</em></a><em>,&nbsp;</em>OECD, Paris.&nbsp;</p>



<p>OECD (2021b),&nbsp;<a href="https://www.oecd.org/housing/data/affordable-housing-database/" target="_blank" rel="noreferrer noopener"><em>OECD Affordable Housing Database</em></a>, indicator PH1.1, OECD, Paris.&nbsp;&nbsp;</p>



<p>Pleace, N. et al. (2021),&nbsp;<a rel="noreferrer noopener" href="https://portal.oecd.org/eshare/eco/pc/Deliverables/Housing%20Horizontal/Housing-Horizontal/Affordability%20QuASH%20questionnaire/Presentations/,%20www.feantsaresearch.org/public/user/Observatory/2021/European_Homlessness_and_COVID-19Web_(1).pdf" target="_blank"><em>European Homelessness and COVID 19</em></a>, European Observatory on Homelessness.&nbsp;&nbsp;</p>



<p><span><img data-recalc-dims="1" decoding="async" src="https://i0.wp.com/oecdecoscope.blog/wp-content/plugins/pdf-print/images/pdf.png?w=1200&amp;ssl=1" alt="image_pdf" title="View PDF"></span><a href="https://oecdecoscope.blog/2021/12/13/finlands-zero-homeless-strategy-lessons-from-a-success-story/?print=print" target="_blank"></a></p><ol><li><span id="easy-footnote-bottom-1-7341"></span>The data for Finland refers to 2020 and comes from ARA (2021). The data for the Netherlands, New Zealand and Sweden refer to 2018, 2018 and 2017 and come from the OECD Affordable Housing Database, Indicator HC 3.1<a href="#easy-footnote-1-7341"></a></li></ol></div>

			</article>
			
		</div>

</main><!--/.neve-main-->



</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Web apps built with Ruby on Rails (143 pts)]]></title>
            <link>https://weuserails.com/</link>
            <guid>42656559</guid>
            <pubDate>Fri, 10 Jan 2025 15:39:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://weuserails.com/">https://weuserails.com/</a>, See on <a href="https://news.ycombinator.com/item?id=42656559">Hacker News</a></p>
Couldn't get https://weuserails.com/: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[Formal Methods: Just Good Engineering Practice? (2024) (182 pts)]]></title>
            <link>https://brooker.co.za/blog/2024/04/17/formal</link>
            <guid>42656433</guid>
            <pubDate>Fri, 10 Jan 2025 15:25:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://brooker.co.za/blog/2024/04/17/formal">https://brooker.co.za/blog/2024/04/17/formal</a>, See on <a href="https://news.ycombinator.com/item?id=42656433">Hacker News</a></p>
Couldn't get https://brooker.co.za/blog/2024/04/17/formal: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[I've Acquired a New Superpower (1445 pts)]]></title>
            <link>https://danielwirtz.com/blog/spot-the-difference-superpower</link>
            <guid>42655870</guid>
            <pubDate>Fri, 10 Jan 2025 14:34:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://danielwirtz.com/blog/spot-the-difference-superpower">https://danielwirtz.com/blog/spot-the-difference-superpower</a>, See on <a href="https://news.ycombinator.com/item?id=42655870">Hacker News</a></p>
Couldn't get https://danielwirtz.com/blog/spot-the-difference-superpower: Error: timeout of 10000ms exceeded]]></description>
        </item>
        <item>
            <title><![CDATA[The Tedious Heroism of David Ruggles (132 pts)]]></title>
            <link>https://commonplace.online/article/the-tedious-heroism-of-david-ruggles/</link>
            <guid>42655636</guid>
            <pubDate>Fri, 10 Jan 2025 14:02:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://commonplace.online/article/the-tedious-heroism-of-david-ruggles/">https://commonplace.online/article/the-tedious-heroism-of-david-ruggles/</a>, See on <a href="https://news.ycombinator.com/item?id=42655636">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					<p>History also changes because of strange, flawed, deeply human people doing unremarkable, tedious, and often boring work.</p>
				</div><div>
							
<p><span data-contrast="auto">I want to tell you a rather boring story: the story of the brig </span><i><span data-contrast="auto">Brilliante</span></i><span data-contrast="auto">.</span><span data-contrast="auto">&nbsp;</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559685&quot;:0,&quot;335559731&quot;:720,&quot;335559740&quot;:480}">&nbsp;</span></p>
<p><span data-ccp-parastyle="Body Text">Th</span><span data-ccp-parastyle="Body Text">e </span><span data-ccp-parastyle="Body Text">hero</span><span data-ccp-parastyle="Body Text"> of this tale is David Ruggles, an extraordinary man. In 1835, at the young age of twenty-five, <span lang="EN-US" xml:lang="EN-US" data-contrast="auto"> <span data-ccp-parastyle="Body Text">Ruggles</span> <span data-ccp-parastyle="Body Text">founded</span> <span data-ccp-parastyle="Body Text">the</span> <span data-ccp-parastyle="Body Text">New</span> <span data-ccp-parastyle="Body Text">York</span> <span data-ccp-parastyle="Body Text">Committee</span> <span data-ccp-parastyle="Body Text">of</span> <span data-ccp-parastyle="Body Text">Vigilance, </span><span data-ccp-parastyle="Body Text">an organization that functioned as </span><span data-ccp-parastyle="Body Text">a public-facing </span><span data-ccp-parastyle="Body Text">component</span><span data-ccp-parastyle="Body Text"> of the Underground Railroad in New York City.</span> <span data-ccp-parastyle="Body Text">As far as we know,</span> <span data-ccp-parastyle="Body Text">he</span><span data-ccp-parastyle="Body Text"> was the first black person to edit a magazine and </span><span data-ccp-parastyle="Body Text">own </span><span data-ccp-parastyle="Body Text">a bookstore in the United States. He wrote political commentary and satire;</span> <span data-ccp-parastyle="Body Text">spoke at meetings;</span> <span data-ccp-parastyle="Body Text">suffered abuse, violence, and imprisonment; </span><span data-ccp-parastyle="Body Text">confronted slaveholders in person; and risked his life and his freedom to ferry hundreds of enslaved people to freedom.</span></span><span><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="Body Text">&nbsp;</span></span></span></span></p>
<p><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="Body Text">When Ruggles’</span> <span data-ccp-parastyle="Body Text">life is summarized in this way—as a series of brilliant accomplishments</span><span data-ccp-parastyle="Body Text">, daring exploits,</span><span data-ccp-parastyle="Body Text"> and historical firsts—it is easy to see why he is </span><span data-ccp-parastyle="Body Text">important, historical, and heroic. </span><span data-ccp-parastyle="Body Text">T</span><span data-ccp-parastyle="Body Text">o </span><span data-ccp-parastyle="Body Text">establish</span><span data-ccp-parastyle="Body Text"> that someone </span><span data-ccp-parastyle="Body Text">is worth remembering</span><span data-ccp-parastyle="Body Text">, </span><span data-ccp-parastyle="Body Text">historians</span><span data-ccp-parastyle="Body Text"> often focus on the most dramatic episodes of that person’s long and complicated life. </span><span data-ccp-parastyle="Body Text">P</span><span data-ccp-parastyle="Body Text">opular histories of </span><span data-ccp-parastyle="Body Text">the Underground Railroad</span><span data-ccp-parastyle="Body Text">, like Fergus </span><span data-ccp-parastyle="Body Text">Bordewich’s book</span> </span><em><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="Body Text">Bound for Canaan</span></span></em><span lang="EN-US" xml:lang="EN-US" data-contrast="auto"><span data-ccp-parastyle="Body Text"> or</span><span data-ccp-parastyle="Body Text"> Laine Drewery’s 2012 PBS documentary</span><span data-ccp-parastyle="Body Text"> about William Still</span><span data-ccp-parastyle="Body Text">,</span><span data-ccp-parastyle="Body Text"> tend to give broad summaries of general historical trends</span> <span data-ccp-parastyle="Body Text">punctuated </span><span data-ccp-parastyle="Body Text">by</span><span data-ccp-parastyle="Body Text"> exciting episodes from the lives of </span><span data-ccp-parastyle="Body Text">heroic </span><span data-ccp-parastyle="Body Text">freedom seekers and those who helped them. People appear, their most dramatic and vivid accomplishment or exploit is described, and then, they disappear, perhaps to resurface in another vivid exploit. Even histories published by academic presses, like Eric Foner’s <em>Gateway to Freedom</em>, sometimes rely on these dramatic stories to lend interest to their historical narratives.</span></span></p>
</div><div>
<p>This way of telling history has much to recommend it, and the examples I have named are wonderful pieces of historical storytelling that deserve to be read. They are vivid and entertaining; the stories effectively use narrative to illustrate important historical trends. But when historical figures are seen as important primarily because of the most dramatic moments of their lives, we can sometimes make it more difficult to see the hard, repetitive, boring work of making social change. After all, world-changing heroism is not just a matter of dramatic escapades, grand accomplishments, literary achievements, and firsts. History also changes because of strange, flawed, deeply human people doing unremarkable, tedious, and often boring work.&nbsp;</p>
<p>David Ruggles was an extraordinary man who spent much of his life doing this kind of unglamorous work. Much of Ruggles’ work was like the work of thousands of other activists, men and women, black and white, who created the Underground Railroad through thousands of unrecorded, unremembered, obscure acts of courage, which often resulted in compromised or incomplete victories. At times, this work must have been boring: writing writs of habeus corpus; tracking expenses for Vigilance Committees; typesetting; delivering letters; cooking food to serve to fugitives or cleaning their bedclothes. Of course we should acknowledge Ruggles’ extraordinary feats. But the Underground Railroad could not have existed without the diﬃcult, self-consciously un-historical, often boring, work that served as the movement’s foundation. This is why the (somewhat dull) story of the brig <em>Brilliante </em>is worth your attention.</p>
</div><div><p>It was December 1836. The days were short, cold, and dark. It very well might have been raining. Since moving to New York in 1827, Ruggles had become a trusted member of the antislavery activist community in New York City. The previous November, Ruggles founded the New York Committee of Vigilance with a core group of four others. Since then, they had conducted their work of attempting to free fugitive slaves through legal and illegal means. On December 3, Ruggles heard from one of his contacts that a known Portuguese slave ship, the brig <em>Brilliante</em>, had arrived in port. Ruggles wanted to verify this report, so he headed down to the docks and spoke with a white sailor, who confirmed that five enslaved men were on board and that the ship would be in New York City for a few weeks for repairs.</p></div><div>
<p>The legal status of enslaved people in New York State was complex. By 1827, slavery was illegal in New York. However, because of an 1817 state law that was still on the books, non-residents could still bring enslaved people into New York for up to nine months without having to free them. But Ruggles reasoned that the captain of the&nbsp;<em>Brilliante</em>&nbsp;couldn’t take advantage of this loophole because the&nbsp;<em>Brilliante</em>&nbsp;was a foreign vessel.&nbsp;Congress had outlawed the international slave trade in 1807, clarifying and extending the prohibition on slave-trading in 1818 and 1820. In short, bringing enslaved men from outside of the U.S. into New York Harbor violated these Federal laws. So, on Friday, December 10, Ruggles headed over to the office of the New York District Attorney, a man named William M. Price. After receiving Ruggles’ report, Price did nothing.</p>
<p>Ruggles returned on Monday, December 12, to check in on Price, who said he would “attend to it.” Ruggles left the District Attorney’s office with instructions from an office assistant to find out the name of the captain of the <em>Brilliante</em>. Ruggles came back again the same day and asked to talk to the Deputy Marshall, who said he didn’t have time deal with the matter that day and that he’d deal with it tomorrow. Ruggles responded, “but she”—the <em>Brilliante</em>—“may be gone.” The Deputy Marshall said that he needed more information and told Ruggles to come to his house that afternoon. But when Ruggles arrived at the house, there was, mysteriously, nobody home.&nbsp;</p>
</div><div><p>Already, you may want to stop reading this article and go do something more entertaining. Ruggles probably would have liked to go and do something else, too. In this story, Ruggles probably spent most of his time walking: from his home to the docks to various oﬃces, homes, and institutions, then back again. In December, New York City was rainy, and sometimes snowy. The streets of New York were famously the filthiest in the United States, too, lined with privies piled high, which overflowed into the streets. Loose pigs and dogs snuﬄed in the mire. As a black man, Ruggles would not have been allowed to take one of the brand-new horse-drawn streetcars. He would have had to trudge through puddles and filthy snow.</p></div><div>
<p>To return to our story: on the evening of Monday, December 12, Ruggles wrote a notice that would appear in the <em>New York Sun </em>the next morning. The note narrated Ruggles’ experience to drum up outrage against the District Attorney’s inaction. On Tuesday morning, Ruggles went to the District Attorney’s oﬃce again (another trudge through filthy snow), only to be, as he put it, “rather uncivilly, [shown] the door!” The District Attorney, clenching his fist, bellowed at Ruggles, “go out of MY OFFICE!”</p>
<p>Ruggles published another account of his adventure in the <em>Evening Post</em>. At that point, it was probably embarrassing for the District Attorney’s inactivity to be exposed so publicly. So, by the end of the day Tuesday, the captain of the <em>Brilliante </em>was arrested, and the enslaved men held on his ship were put in a debtor’s prison while the case proceeded. <em>Finally</em>. After all that work, all the stonewalling by oﬃcials, all the early-morning treks through the streets of New York, justice would be done! Right?</p>
</div><div>
<p>Of course not. Now there was a court case, which started on December 16. In summary, the captain of the brig argued for his innocence based on a technicality. (The men on board the <em>Brilliante</em>, he argued, should not be considered slaves because they were part of the ship’s crew and would not be sold in the United States.) The District Attorney accepted this argument without questioning the captain or introducing any other testimony, then discharged the captain. But the enslaved men were kept in the city’s debtor’s prison for four days, even though they hadn’t been charged with any crime, probably to prevent volunteers from liberating them.</p>
<p>Ruggles and three others went to the debtor’s prison on December 20, one of the darkest days of the year, probably walking once again through frozen filth. They asked: by whose authority are these men being held? The jail-keeper blamed the Sheriﬀ and Marshall. So Ruggles went over to the Sheriﬀ ’s oﬃce. (Another walk). The Sheriﬀ said that he had nothing to do with it. Next, Ruggles went to the District Attorney’s oﬃce. (Another walk.) The District Attorney was not in, but his assistant told Ruggles that the men were being held as the captain’s property, which was illegal in the United States, according to Ruggles. Ruggles and his companions went up to see the Deputy Marshall. (Another walk.) He was also not in. They gave up and went home. It must have felt like they had walked all over the city. And their reward was: precisely nothing.</p>
</div><div><p>The next day, an unnamed person, likely a member of the Vigilance Committee, stopped the Deputy Marshall on the street and asked why the men were still being held in prison. The Deputy Marshall said that they shouldn’t be in jail and wrote a note ordering that the men be released. Ruggles and his companions brought the note to the jailhouse, but the jailkeeper refused to release the men. Ruggles told the jailkeeper that he had no legal authority to hold the men. The jailkeeper seemed not to care. “I shall risk it,” he said. &nbsp;Members of the Vigilance Committee filed a writ of habeas corpus. But before they could finish that process, the slaves had already been moved back aboard the ship, where they were now trapped. It was defeat after infuriating defeat.</p></div><div>
<p>Finally, on Christmas Eve, a group of armed black New Yorkers (reportedly not including Ruggles) boarded the brig <em>Brilliante </em>and managed to rescue two of the men. When they returned later to get the rest of the men, they were unfortunately rebuﬀed. After all that work, only two men were freed. After all those days—all those words written, all the walking around the city, contacting oﬃcial after oﬃcial—all Ruggles got was a painfully incomplete victory.&nbsp;</p>
<p>And even that small victory was not without its costs. On December 28, around 1:30 in the morning, Ruggles was awoken by the loud sounds of knocking on his door. Soon, three men had forced open his front door, brandishing pistols and knives, menacing Ruggles’ landlady, and yelling at Ruggles. Luckily, the police soon arrived and arrested two of the men. But when Ruggles went to City Hall the next day to press charges, <em>he </em>was imprisoned for a short time because the constable had an arrest warrant that allowed him to arrest any black person that matched a description of an escaped slave. The men who forced Ruggles’ front door would probably have kidnapped him and sold him into slavery in retaliation for his eﬀorts to free the slaves on the <em>Brilliante.</em></p>
</div><div>
<p>If all this trudging back and forth between various oﬃces, houses, and jails sounds less like heroic activism to you and more like a Kafkaesque bureaucratic nightmare, that is my point. Slogging for miles through slush and snow in the dark and the cold, following the legal processes, trying to force public servants to do their jobs, knowing the law, understanding court procedures—this is what it was often like to actively work against slavery. Infuriating, complicated, annoying, tedious.</p>
<p>This brand of heroism can be hard to talk about, especially in public-facing histories, which must be not only accurate but entertaining. Sometimes, it seems as if historians work to make the work of activism seem as dramatic and colorful as possible. But it is important, too, to understand that much practical abolitionist work probably didn’t feel heroic or historical or impressive at all. Much of it was the frustrating and incomplete result of sheer doggedness. The story of the brig <em>Brilliante </em>reminds us that history is not just made by firsts: It’s made by repetitive eﬀorts, too. Ruggles’ tedious brand of heroism serves to remind us of the thousands of other acts of quotidian courage performed by thousands of forgotten people, who had jobs and small businesses and children, but who were nonetheless willing to spend hours and hours walking through filthy snow.</p>
<p><strong>Further Reading:</strong></p>
<p><em>Primary sources</em>:</p>
<p>David Ruggles, <em>The First Annual Report of the New</em> <em>York Committee of</em> <em>Vigilance,</em> <em>for the</em> <em>Year 1837, </em><em>Together</em> <em>With</em> <em>Important</em> <em>Facts</em> <em>Relative</em> <em>to</em> <em>Their</em> <em>Proceedings</em> (New York: Piercy &amp; Reed, 1837),&nbsp;&nbsp;<a href="https://reader.library.cornell.edu/docviewer/digital?id=may839002#mode/2up">https://reader.library.cornell.edu/docviewer/digital?id=may839002#mode/2up.</a></p>
<p>David Ruggles, <em>The Mirror of Liberty</em>, vol. 1, no. 1 (New York: David Ruggles, 1838).</p>
<p>Edwin Williams and John Disturnell,&nbsp;<em>New York as it is, in 1837</em>&nbsp;(New York: J. Dusturnell, 1837).</p>
<p>Frank M. O’Brien, <em>The Story of the Sun </em>(New York: George H. Doran Company, 1918).</p>
<p><em>Laws Relative to Slaves and Servants, Passed by the Legislature of New-York, March 31st, 1817. Together with Extracts from the Laws of the United States, Respecting Slaves</em>&nbsp;(New York: S. Wood &amp; Sons, 1817).</p>
<p><em>Longworth’s American Almanac,</em>&nbsp;<em>New York Register, and City Directory</em>&nbsp;(New York: Thomas Longworth, 1836).</p>
<p><em>Secondary sources</em>:</p>
<p>Fergus M. Bordewich, <em>Bound</em> <em>for</em> <em>Canaan:</em> <em>The</em> <em>Epic</em> <em>Story</em> <em>of</em> <em>the</em> <em>Underground</em> <em>Railroad,</em> <em>America’s </em><em>First Civil Rights Movement</em> (New York: Amistad, 2006).</p>
<p>Edwin G. Burrows and Mike Wallace, <em>Gotham:</em> <em>A</em> <em>History</em> <em>of</em> <em>New</em> <em>York</em> <em>City</em> <em>to</em> <em>1898</em> (New York: Oxford University Press, 1999).</p>
<p>Eric Foner, <em>Gateway to Freedom: The Hidden History of America’s Fugitive Slaves </em>(Oxford: Oxford University Press, 2015).</p>
<p>Graham Russell Hodges, <em>David</em> <em>Ruggles:</em> <em>A</em> <em>Radical</em> <em>Black</em> <em>Abolitionist</em> <em>and</em> <em>the</em> <em>Underground </em><em>Railroad in New York City</em> (Chapel Hill: University of North Carolina Press, 2010).</p>
<p>Jesse Olsavsky, <em>The</em> <em>Most</em> <em>Absolute</em> <em>Abolition:</em> <em>Runaways,</em> <em>Vigilance</em> <em>Committees,</em> <em>and</em> <em>the</em> <em>Rise</em> <em>of </em><em>Revolutionary Abolitionism,</em> <em>1835-1861</em> (Baton Rouge: Louisiana State University Press, 2022).</p>
<p>This article originally appeared in December 2024.&nbsp;</p>
<hr>
<p>Isaac Kolding is a PhD candidate in English at the State University of New York at Buﬀalo. His research focuses on the intersection between radical abolitionist rhetoric and literature in the nineteenth-century U.S. His writing appears in <em>American Literature</em>, <em>American Literary Realism</em>, and <em>J19: The Journal of Nineteenth-Century Americanists</em>.</p>
						</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I got OpenTelemetry to work. But why was it so complicated? (223 pts)]]></title>
            <link>https://iconsolutions.com/blog/i-got-opentelemetry-to-work-but-why-was-it-so-complicated/</link>
            <guid>42655102</guid>
            <pubDate>Fri, 10 Jan 2025 12:38:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://iconsolutions.com/blog/i-got-opentelemetry-to-work-but-why-was-it-so-complicated/">https://iconsolutions.com/blog/i-got-opentelemetry-to-work-but-why-was-it-so-complicated/</a>, See on <a href="https://news.ycombinator.com/item?id=42655102">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
                      <p>A number of our customers have recently been asking whether we support&nbsp;<a href="https://opentelemetry.io/docs/" rel="nofollow">OpenTelemetry</a>, the observability framework and toolkit. When the first member of the team who’s client-facing asked me – the go-to guy for metrics and logging at IPF – I barely let them finish: “of course! That’s just Prometheus and Jaeger, right? We’ve supported that for years!”</p>
<p>Well, it turns out I was more or less wrong on all counts. Yay! Let’s get into it.</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-OTel?">OTel?</h2>
<p>As I mentioned up there, OpenTelemetry, or OTel, is an observability&nbsp;<em>framework</em>&nbsp;and&nbsp;<em>toolkit</em>. What does this mean? Well, to start, let’s think about the sort of tools that predated OTel in this space. A nice triad you could use to get started could be:</p>
<ul>
<li><strong>Prometheus</strong>&nbsp;for metrics</li>
<li>Things like&nbsp;<strong>Logstash</strong>&nbsp;for exporting logs to a central aggregator like&nbsp;<strong>Elasticsearch</strong>&nbsp;(other log exporters and aggregators are available)</li>
<li><strong>OpenTracing</strong>&nbsp;for distributed tracing</li>
</ul>
<p>These are three different standards from three different organisations. OpenTelemetry tries to round up, and –&nbsp;more importantly – standardise the tooling in this space by codifying it under three so-called signals:&nbsp;<strong>metrics</strong>,&nbsp;<strong>logs</strong>&nbsp;and&nbsp;<strong>traces</strong>. In addition to just providing a specification, they have created:</p>
<ul>
<li>The OpenTelemetry Protocol (OTLP) which allows applications to report data on the aforementioned primitives to what is known as the…</li>
<li>…OpenTelemetry Collector: a&nbsp;&nbsp;“Vendor-agnostic way to receive, process and export telemetry data.”</li>
<li>Language SDKs for 10+ languages which implement OTLP and exporting of telemetry data</li>
</ul>
<p>These are the core components they have created. There are others, but this will do for now. If you’re confused, here’s a diagram from their root docs page (which is in itself a tell!)</p>
<p><span><img decoding="async" draggable="false" src="https://opentelemetry.io/img/otel-diagram.svg" alt="OpenTelemetry Reference Architecture" width="877" height="582" data-image-src="https://opentelemetry.io/img/otel-diagram.svg"></span></p>
<p>As we can see, “microservices” (remember those?) can report signals to the OTel Collector using auto-instrumentation (“zero code”), the API, or one of the language SDKs. But it’s not restricted to your applications: your infrastructure can also send signals to the OTel Collector!</p>
<p>So this sounds well and good, and indeed a noble cause. As a bonus it ticks all the buzzword boxes: open-source, vendor-agnostic, language-agnostic, distributed,&nbsp;<a href="https://opentelemetry.io/docs/zero-code/" rel="nofollow">zero-code</a>&nbsp;(conditions apply; see below).</p>
<p>So what’s wrong?</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-Nostrangerstoobservability">No strangers to observability</h2>
<p>We are not new to this space. We’ve had docs on these topics for a while now, and our customers have used these in production for some time. Want to&nbsp;<a href="https://docs.ipfdev.co.uk/core/IPF_RELEASE_2024.2.0/flo-starter/features/monitoring.html#option-1-elasticsearchlogstashkibana" rel="nofollow">get IPF to report to an ELK Stack</a>? No problem. General docs on&nbsp;<a href="https://docs.ipfdev.co.uk/core/IPF_RELEASE_2024.2.0/flo-starter/features/monitoring.html" rel="nofollow">monitoring and observability</a>? Sure thing!</p>
<p>As a&nbsp;&nbsp;know what environment an app using our libraries is going to be deployed&nbsp;&nbsp;to stay abstract and never make any vendor-specific choices one way or another. I’m starting to sound like the OTel people. This means we have to spend a lot of time building in overrideable sensible defaults, abstractions (ensuring they are not crappy and/or leaky ones), and so on.</p>
<p>Having said that,&nbsp; we&nbsp;<em>can</em>&nbsp;make recommendations: we usually recommend that logs are pushed to some aggregator like Elasticsearch, LogScale, etc, and by default we enable and support&nbsp;Prometheus metrics as&nbsp;&nbsp;become a&nbsp;<em>de facto</em>&nbsp;standard.&nbsp;&nbsp;OTel came along.</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-Easywins:logsandmetrics">Easy wins: logs and metrics</h2>
<p>While logs and metrics are a fairly well-known quantity amongst our customers, tracing is not. There must be something in the water, because we got three almost simultaneous requests asking about tracing with OTel. And while you’re using OTel for tracing, you might as well use it for the other two things as well!</p>
<p>It was fairly easy for our customers to move logs and&nbsp;&nbsp;to OTel, since to enable logs and metrics you just need to add a new appender and some new config respectively. But what do we do for tracing?</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-Tracingmyheadache">Tracing my headache</h2>
<p>When you trace a transaction through a distributed system, you need to pass some information between the systems to correlate a specific invocation with a specific transaction. This is known as&nbsp;<a href="https://opentelemetry.io/docs/concepts/context-propagation/" rel="nofollow">context propagation</a>.</p>
<p>A&nbsp;<em>trace</em>&nbsp;is a parent/wrapper for a set of individual units of work, called&nbsp;<em>spans</em>. A trace can contain multiple spans, and spans can be nested. Imagine an e-commerce website: clicking the “buy now” button initiates a trace involving the frontend talking to the backend in one span, the backend activates a new child span to talk to the payment/shipping/order management services, and each one of those may activate a new child span to talk to some other downstream system further down. All the distributed services report their part of the trace to the OTel collector (if using OTel) and OTel builds a holistic view under a single trace ID. Well, that’s the theory anyway.</p>
<p>In a typical fashion in our industry where we have the opportunity to gather around one standard for context propagation, we decided to make several. Obligatory reference to the XKCD comic:&nbsp;<a href="https://xkcd.com/927/" rel="nofollow">Standards</a>. The context propagation implementations that OTel MUST(!) support are:</p>
<ul>
<li><a href="https://github.com/openzipkin/b3-propagation" rel="nofollow">b3</a></li>
<li><a href="https://www.w3.org/TR/trace-context/" rel="nofollow">W3C Trace Context</a></li>
<li><a href="https://www.w3.org/TR/baggage/" rel="nofollow">W3C Baggage</a></li>
<li><a href="https://www.jaegertracing.io/docs/1.63/client-libraries/#propagation-format" rel="nofollow">Jaeger</a></li>
</ul>
<p>I don’t really understand why there are four, but I think what’s happened is&nbsp;<a href="https://en.wikipedia.org/wiki/Convergent_evolution" rel="nofollow">convergent evolution</a>: different sets of people – unaware of one another – came to a shared conclusion regarding how to solve a specific problem. Honourable mention for W3C creating&nbsp;<em>two</em>&nbsp;standards for the same thing. Actually, if you read the Baggage spec, they claim that it’s independent of Trace Context. So why does OTel let me propagate the Trace Context over Baggage? I have no idea. Let me know in the comments. Does our blog have comments?</p>
<p>Now, we already had support for the now-deprecated OpenTracing within the Akka parts of our app using&nbsp;<a href="https://developer.lightbend.com/docs/telemetry/current//extensions/opentracing/opentracing.html" rel="nofollow">Lightbend Telemetry support for OpenTracing</a>. Then it got better: in version 2.20.0 of that library, they introduced support for OpenTelemetry logs/events and metrics, but – crucially –&nbsp;<strong>not tracing</strong>! Theoretically this doesn’t matter, because OTel tracing is really just a rebranding of OpenTracing, and Lightbend Telemetry’s OpenTracing supports context propagation using the above four methods anyway. So it should just work…right?</p>
<p>Of course not. We have a new fly in the ointment.</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-ClashofAPIs">Clash of APIs</h2>
<p>IPF makes use of both Spring and Akka for different purposes: we use Spring Boot – and Spring IoC in general – to bootstrap the application and its config, build a set of dependencies, and so on. We use Akka for pretty much everything else: event sourcing, scheduling, clustering, sharding, integration, and so on. But of course we can’t stop customers from doing whatever they want, and so some of them tend to use – for example – a Spring REST controller, or perhaps a&nbsp;<code>@KafkaListener</code>-annotated method to initiate payment flows.</p>
<p>Without OTel, up until now,&nbsp;this was&nbsp;<em>fine</em>:</p>
<ul>
<li><strong>Metrics</strong>: Spring and Akka expose different Prometheus endpoints so won’t&nbsp;step on each other’s toes</li>
<li><strong>Logs</strong>: We use SLF4J and Logback which is common to both frameworks</li>
<li><strong>Traces</strong>: Both used OpenTracing</li>
</ul>
<p>When using OTel, metrics and logs were still being sent through fine based on the fact that Spring and Akka were operating independently of one another. However, when it comes to tracing, we need them to be aware of one another so that they can propagate the trace context within the JVM. The problem is now that there are two different APIs being used&nbsp;<strong>inside the app</strong>&nbsp;to reflect the same thing, and guess what: they aren’t talking to one another. Here’s a diagram if you’re struggling (I certainly am):</p>

<p><img decoding="async" src="https://iconsolutions.com/wp-content/uploads/2024/12/tracing-apis-clash.png" alt="tracing APIs clash" width="1281" height="321" srcset="https://iconsolutions.com/wp-content/uploads/2024/12/tracing-apis-clash.png 1281w, https://iconsolutions.com/wp-content/uploads/2024/12/tracing-apis-clash-300x75.png 300w, https://iconsolutions.com/wp-content/uploads/2024/12/tracing-apis-clash-1024x257.png 1024w, https://iconsolutions.com/wp-content/uploads/2024/12/tracing-apis-clash-768x192.png 768w" sizes="(max-width: 1281px) 100vw, 1281px"></p>

<p>&nbsp;The correct behaviour would be for the Akka HTTP client to reuse the same trace ID&nbsp;<code>123</code>&nbsp;from the left hand side, but make a new span ID to indicate that a new unit of work has started&nbsp;&nbsp;is part of the same&nbsp;<code>123</code>&nbsp;trace.&nbsp;&nbsp;completely different traces with no relation to one another.</p>
<p>The silver lining is that It looks like the OTel people were aware of this, and created&nbsp;<a href="https://github.com/open-telemetry/opentelemetry-java/tree/main/opentracing-shim" rel="nofollow"><code>opentracing-shim</code></a>:&nbsp;a way for you to dress up an OTel&nbsp;<a href="https://javadoc.io/doc/io.opentelemetry/opentelemetry-api/latest/io/opentelemetry/api/trace/Tracer.html" rel="nofollow"><code>Tracer</code></a>&nbsp;as an OpenTracing&nbsp;<a href="https://javadoc.io/static/io.opentracing/opentracing-api/0.33.0/io/opentracing/Tracer.html" rel="nofollow"><code>Tracer</code></a>.&nbsp;, because Lightbend Telemetry uses a custom Tracer implementation which makes the shim&nbsp;<strong>and&nbsp;</strong>Jaeger freak out, and, instead of any of these things doing their job and propagating a trivial string-string map, spams the log with:</p>
<div title="Hint: double-click to select code" id="highlighter_134516" data-hasbody="true" data-macro-name="code">
<p><code>Expected to have an OpenTelemetry Span but got cinnamon.opentracing.TraceLocal$ContextOnlySpan</code></p>
</div>
<p>And in Jaeger’s case:</p>
<div title="Hint: double-click to select code" id="highlighter_807539" data-hasbody="true" data-macro-name="code">
<p><code>Expected to have a JaegerSpanContext but got io.opentelemetry.opentracingshim.SpanContextShim</code></p>
</div>
<p>So Jaeger is freaking out because it’s getting OTel, and OTel is freaking out because it’s getting Lightbend. Why is everybody so precious about their own implementations?! All to move around a map with four scalar values?</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-Intotheweeds">Into the weeds</h2>
<p>Both OTel and Lightbend Telemetry instrumentation use a&nbsp;<a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.instrument/java/lang/instrument/package-summary.html" rel="nofollow">Java Agent</a>&nbsp;which hooks into specific method calls of specific classes and reports on their activity to the tracer. The Lightbend Telemetry&nbsp; instrumentation is not open source, so I had to do a bit of digging into decompiled tracer code to figure out what on earth is going on.</p>
<p>I built a cut-down reproducer which replicates the diagram above, in which I attempted to see where exactly between the green and red box the trace context is being dropped, and see if I could help it along manually.</p>
<p>The first thing I did was set up a breakpoint on the Jaeger freak-out point (<a href="https://github.com/jaegertracing/jaeger-client-java/blob/v1.6.0/jaeger-core/src/main/java/io/jaegertracing/internal/JaegerTracer.java#L285" rel="nofollow">here</a>, if you want to play along) where it’s complaining that it’s getting a shim and not real OpenTracing. My thought process was: okay, this is close to what I want to happen (Jaeger to adopt the OTel context), so can I do something shim-free to help it along?</p>
<p>The caller that was causing it to freak out was&nbsp;<code>OpenTracingAkkaPersistenceActorInstrumentation.class</code>, a proprietary Lightbend Telemetry instrumentation class. I traced the Jaeger breakpoint to this point in the stack which looks promising:</p>
<p><span><img decoding="async" draggable="false" src="https://confluence.iconsolutions.com/download/attachments/415702396/image-2024-11-14_20-12-47.png?version=1&amp;modificationDate=1731575567742&amp;api=v2" alt="" data-image-src="/download/attachments/415702396/image-2024-11-14_20-12-47.png?version=1&amp;modificationDate=1731575567742&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="415702752" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-2024-11-14_20-12-47.png" data-base-url="https://confluence.iconsolutions.com" data-linked-resource-content-type="image/png" data-linked-resource-container-id="415702396" data-linked-resource-container-version="16"></span></p>
<p>It was line 153 that calls into Jaeger and upsets it, but the first clue was on line 152: if&nbsp;<code>var5</code>&nbsp;– an OpenTracing&nbsp;<a href="https://www.javadoc.io/static/io.opentracing/opentracing-api/0.33.0/io/opentracing/SpanContext.html" rel="nofollow"><code>SpanContext</code></a>&nbsp;– is not null, we attach our new span as a child of the current active span. If&nbsp;<code>var5</code>&nbsp;is null, the span has no relationship to the existing trace, and if&nbsp;<code>var5</code>&nbsp;is not a Jaeger SpanContext then Jaeger freaks out. So how can we make&nbsp;<code>var5</code>&nbsp;something that is both null and Jaeger-friendly?</p>
<p>On line 147, the&nbsp;<code>SpanContext</code>&nbsp;is being populated from&nbsp;<code>this.traceLocal.currentContext()</code>&nbsp;. So can I access this from outside somehow and just create a new Jaeger SpanContext myself and stop using the shim?</p>
<p>I then breakpointed on the constructor of&nbsp;<code>OpenTracingAkkaPersistenceActorInstrumentation</code>&nbsp;to see how&nbsp;<code>traceLocal</code>&nbsp;is initialised. Behold another decompiled wonder:</p>
<p><span><img decoding="async" draggable="false" src="https://confluence.iconsolutions.com/download/attachments/415702396/image-2024-11-14_20-19-29.png?version=1&amp;modificationDate=1731575969827&amp;api=v2" alt="" data-image-src="/download/attachments/415702396/image-2024-11-14_20-19-29.png?version=1&amp;modificationDate=1731575969827&amp;api=v2" data-unresolved-comment-count="0" data-linked-resource-id="415702771" data-linked-resource-version="1" data-linked-resource-type="attachment" data-linked-resource-default-alias="image-2024-11-14_20-19-29.png" data-base-url="https://confluence.iconsolutions.com" data-linked-resource-content-type="image/png" data-linked-resource-container-id="415702396" data-linked-resource-container-version="16"></span></p>
<p>Okay,&nbsp;<code>var4</code>&nbsp;is an&nbsp;<code>ExtendedTracer</code>, and from my extensive trawling of Lightbend Telemetry docs, I remembered&nbsp;<a href="https://developer.lightbend.com/docs/telemetry/current//extensions/opentracing/api.html#globalextendedtracer-active-context" rel="nofollow">they had written</a>&nbsp;that it’s possible to access this ExtendedTracer programmatically using the following magical incantation:</p>
<div title="Hint: double-click to select code" id="highlighter_631775" data-hasbody="true" data-macro-name="code">
<p><code>GlobalExtendedTracer.get()</code></p>
</div>
<p>Things are so simple once you know what you’re doing!</p>
<p>This returns an&nbsp;<code>ExtendedTracer</code>&nbsp;and indeed calling&nbsp;<code>local()</code>&nbsp;returns the same&nbsp;<code>TraceLocal</code>&nbsp;that is being used by the instrumentation library. I also noticed that this&nbsp;<code>TraceLocal</code>&nbsp;has an&nbsp;<code>activateContext</code>&nbsp;method which takes an OpenTracing&nbsp;<code>SpanContext</code>. So if I ditch the shim and manually convert the OpenTelemetry Context into a Jaeger SpanContext, then:</p>
<ul>
<li>Jaeger will be happy because it gets its own SpanContext implementation</li>
<li>The shim will be happy because…it’s not being used</li>
<li>I will be happy because the trace ID should be propagated (albeit manually) between OTel and OpenTracing</li>
</ul>
<p>We can convert an OTel context into a OpenTracing one manually using the&nbsp;<a href="https://opentelemetry.io/docs/specs/otel/context/api-propagators/#operations" rel="nofollow">inject and extract operations</a>&nbsp;from the propagators API: I tell OTel to populate (“inject”) a generic Java Map with the context, and I then populate (“extract”) the Jaeger SpanContext with the values of the map.</p>
<p>Here’s what it all it looks like if you’re technically oriented (you must be if you’ve read all the way down here):</p>
<div>
<pre>//make an empty map to populate
var otelContext = new HashMap&lt;&gt;();
//inject OTel context into the map
GlobalOpenTelemetry.get().getPropagators().getTextMapPropagator().inject(Context.current(), otelContext, (carrier, key, value) -&gt; carrier.put(key, value));
//populate new JaegerSpanContext from aforementioned map 
var openTracingContext = new TextMapCodec(false).extract(new TextMapAdapter(otelContext));
//activate this new context before going into Akka
GlobalExtendedTracer.get().local().activateContext(openTracingContext);
//do stuff here - either OTel or Akka - because they should both be sharing the same context now</pre>
</div>
<p>Okay, let’s spin it up, and:</p>
<div data-drawio-colors="color: rgb(0, 0, 0); " id="drawio-macro-content-5f7187e0-ae96-4723-a83f-818ccebdd6df" data-macroid="5f7187e0-ae96-4723-a83f-818ccebdd6df" data-buildnum="9012">
<p><img loading="lazy" decoding="async" src="https://iconsolutions.com/wp-content/uploads/2024/12/otel-works.png" alt="oTel works" width="1839" height="889" srcset="https://iconsolutions.com/wp-content/uploads/2024/12/otel-works.png 1839w, https://iconsolutions.com/wp-content/uploads/2024/12/otel-works-300x145.png 300w, https://iconsolutions.com/wp-content/uploads/2024/12/otel-works-1024x495.png 1024w, https://iconsolutions.com/wp-content/uploads/2024/12/otel-works-768x371.png 768w, https://iconsolutions.com/wp-content/uploads/2024/12/otel-works-1536x743.png 1536w" sizes="(max-width: 1839px) 100vw, 1839px"></p>
</div>
<p>Yes! We can see that it’s working correctly and ticking all the boxes:</p>
<ul>
<li>We have a single trace connecting everything from the initial Spring REST call to&nbsp;<code>/submit</code></li>
<li>We can mix usages of stuff instrumented by OTel and OpenTracing APIs</li>
<li>The trace is propagated across an HTTP boundary (bottom two spans)</li>
</ul>
<p>I gave the two different instrumentations two different names above to highlight that they are two kinds of tracing. But in real life we’d recommend to customers that they line up the&nbsp;<code>otel.service.name</code>&nbsp;and the&nbsp;<code>cinnamon.application</code>&nbsp;to appear as one application to the outside world.</p>
<h2 id="IgotOpenTelemetrytowork.Butwhywasitsocomplicated?-Reflections">Reflections</h2>
<p>From looking at the decompiled Lightbend Telemetry library, I can see that rewriting it to use OTel APIs would be a big effort: they would have to port their&nbsp;<a href="https://developer.lightbend.com/docs/telemetry/current/instrumentations/instrumentations.html" rel="nofollow">many instrumentations</a>&nbsp;– which are currently tied to the Jaeger API – to use the OTel API. But the silver bullet for them is that the OTel Collector supports collecting traces in the legacy Zipkin format, so they could release complete OTel support by relying on the legacy support, and they probably don’t have too many customers like us who are having this kind of clash.</p>
<p>To answer the titular question of why it was so complicated, I guess the short answer is that it’s self-inflicted: by trying to combine two different instrumentations which use two different tracing libraries we’re kind of asking for trouble. I think the OTel project has done a good job of attempting to apply some standardisation in this space (see for example semantic conventions). It starts off&nbsp;a little bit complex to wrap your head around, but I believe it’s a great FOSS project full of great&nbsp;people doing good things.</p>
<p>I am a little bit concerned about how or if Akka will correctly pass the trace context between threads inside its actor model. It seems to be working as expected from my small amount of load testing, but I have opened a ticket with them and can update this if there’s enough demand!</p>
<p>I hope that this will be of help to somebody. And if not, thanks for the free therapy session. Until next time!</p>
                    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Learning How to Think with Meta Chain-of-Thought (200 pts)]]></title>
            <link>https://arxiv.org/abs/2501.04682</link>
            <guid>42655098</guid>
            <pubDate>Fri, 10 Jan 2025 12:37:54 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arxiv.org/abs/2501.04682">https://arxiv.org/abs/2501.04682</a>, See on <a href="https://news.ycombinator.com/item?id=42655098">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="content-inner">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xiang,+V" rel="nofollow">Violet Xiang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Snell,+C" rel="nofollow">Charlie Snell</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Gandhi,+K" rel="nofollow">Kanishk Gandhi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Albalak,+A" rel="nofollow">Alon Albalak</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singh,+A" rel="nofollow">Anikait Singh</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Blagden,+C" rel="nofollow">Chase Blagden</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Phung,+D" rel="nofollow">Duy Phung</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Rafailov,+R" rel="nofollow">Rafael Rafailov</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lile,+N" rel="nofollow">Nathan Lile</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahan,+D" rel="nofollow">Dakota Mahan</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Castricato,+L" rel="nofollow">Louis Castricato</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Franken,+J" rel="nofollow">Jan-Philipp Franken</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Haber,+N" rel="nofollow">Nick Haber</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Finn,+C" rel="nofollow">Chelsea Finn</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2501.04682">View PDF</a></p><blockquote>
            <span>Abstract:</span>We propose a novel framework, Meta Chain-of-Thought (Meta-CoT), which extends traditional Chain-of-Thought (CoT) by explicitly modeling the underlying reasoning required to arrive at a particular CoT. We present empirical evidence from state-of-the-art models exhibiting behaviors consistent with in-context search, and explore methods for producing Meta-CoT via process supervision, synthetic data generation, and search algorithms. Finally, we outline a concrete pipeline for training a model to produce Meta-CoTs, incorporating instruction tuning with linearized search traces and reinforcement learning post-training. Finally, we discuss open research questions, including scaling laws, verifier roles, and the potential for discovering novel reasoning algorithms. This work provides a theoretical and practical roadmap to enable Meta-CoT in LLMs, paving the way for more powerful and human-like reasoning in artificial intelligence.
    </blockquote>

    <!--CONTEXT-->
    
  </div><div>
      <h2>Submission history</h2><p> From: Rafael Rafailov [<a href="https://arxiv.org/show-email/39233bf9/2501.04682" rel="nofollow">view email</a>]      <br>    <strong>[v1]</strong>
        Wed, 8 Jan 2025 18:42:48 UTC (24,263 KB)<br>
</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Who Can Understand the Proof? A Window on Formalized Mathematics (179 pts)]]></title>
            <link>https://writings.stephenwolfram.com/2025/01/who-can-understand-the-proof-a-window-on-formalized-mathematics/</link>
            <guid>42654995</guid>
            <pubDate>Fri, 10 Jan 2025 12:21:06 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://writings.stephenwolfram.com/2025/01/who-can-understand-the-proof-a-window-on-formalized-mathematics/">https://writings.stephenwolfram.com/2025/01/who-can-understand-the-proof-a-window-on-formalized-mathematics/</a>, See on <a href="https://news.ycombinator.com/item?id=42654995">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
            
<h2 id="the-simplest-axiom-for-logic">The Simplest Axiom for Logic</h2>



<p><a href="https://www.wolframscience.com/nks/p808--implications-for-mathematics-and-its-foundations/">Theorem <span>(Wolfram with Mathematica, 2000)</span></a>: <br>The single axiom <span>((<em>a</em>•<em>b</em>)•<em>c</em>)•(<em>a</em>•((<em>a</em>•<em>c</em>)•<em>a</em>))<span></span><em>c</em></span> is a complete axiom system for Boolean algebra (and is the simplest possible)</p>
<p>For more than a century <a href="https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#the-history">people had wondered</a> how simple the axioms of logic (Boolean algebra) could be. <a href="https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#a-discovery-about-basic-logic">On January 29, 2000, I found the answer</a>—and made the surprising discovery that they could be about twice as simple as anyone knew. (I also showed that what I found was <a href="https://www.wolframscience.com/nks/notes-12-9--searching-for-logic-axioms/">the simplest possible</a>.) </p>
<p>It was an interesting result—that gave new intuition about just how simple the foundations of things can be, and for example helped inspire my efforts to find a <a href="https://www.wolframphysics.org/" target="_blank" rel="noopener">simple underlying theory of physics</a>. </p>
<p>But how did I get the result? Well, I used automated theorem proving (specifically, what’s now <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> in <a href="https://www.wolfram.com/language/">Wolfram Language</a>). Automated theorem proving is something that’s <a href="https://www.wolframscience.com/nks/notes-12-9--automated-theorem-proving/">been around since at least the 1950s</a>, and its core methods haven’t changed in a long time. But in the rare cases it’s been used in mathematics it’s typically been to confirm things that were already believed to be true. And in fact, to my knowledge, my Boolean algebra axiom is actually the only truly unexpected result that’s ever been found for the first time using automated theorem proving.<span id="more-65170"></span></p>
<p>But, OK, so we know it’s true. And that’s interesting. But what about the proof? Does the proof, for example, show us why the result is true? Well, actually, in a quarter of a century, nobody (including me) has ever made much headway at all in understanding the proof (which, at least in the form we currently know it, is long and complicated). So is that basically inevitable—say as a consequence of <a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence#sect-12-6--computational-irreducibility">computational irreducibility</a>? Or is there some way—perhaps <a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">using modern AI</a>—to “humanize” the proof to a point where one can understand it?</p>
<p>It is, I think, an interesting challenge—that gets at the heart of what one can (and can’t) expect to achieve with formalized mathematics. In what follows, I’ll discuss what I’ve been able to figure out—and how it relates to foundational questions about what mathematics is and how it can be done. And while I think I’ve been able to clarify some of the issues, the core problem is still out there—and I’d like to issue it here as a challenge:</p>
<p><span>Challenge:</span> Understand the proof of the Theorem</p>
<p>What do I mean by “understand”? Inevitably, “understand” has to be defined in human terms. Something like “so a human can follow and reproduce it”—and, with luck, feel like saying “aha!” at some point, the kind of way they might on hearing a proof of the Pythagorean theorem (or, in logic, something like de Morgan’s law <tt><a href="http://reference.wolfram.com/language/ref/Not.html">Not</a></tt>[<tt><a href="http://reference.wolfram.com/language/ref/And.html">And</a></tt>[<em>p</em>, <em>q</em>]]<span></span><tt><a href="http://reference.wolfram.com/language/ref/Or.html">Or</a></tt>[<tt><a href="http://reference.wolfram.com/language/ref/Not.html">Not</a></tt>[<em>p</em>], <tt><a href="http://reference.wolfram.com/language/ref/Not.html">Not</a></tt>[<em>q</em>]]). </p>
<p>It should be said that it’s certainly not clear that such an understanding would ever be possible. After all, as we’ll discuss, it’s a basic metamathematical fact that out of all possible theorems almost none have short proofs, at least in terms of any particular way of stating the proofs. But what about an “interesting theorem” like the one we’re considering here? Maybe that’s different. Or maybe, at least, there’s some way of building out a “higher-level mathematical narrative” for a theorem like this that will take one through the proof in human-accessible steps.</p>
<p>In principle one could always imagine a somewhat bizarre scenario in which people would just rote learn chunks of the proof, perhaps giving each chunk some name (a bit like how people learned bArbArA and cElArEnt syllogisms in the Middle Ages). And in terms of these chunks there’d presumably then be a “human way” to talk about the proof. But learning the chunks—other than as some kind of recreational or devotional activity—doesn’t seem to make much sense unless there’s metamathematical structure that somehow connects the chunks to “general concepts” that are widely useful elsewhere. </p>
<p>But of course it’s still conceivable that there might be a “big theory” that would lead us to the theorem in an “understandable way”. And that could be a traditional mathematical theory, built up with precise, if potentially very abstract, constructs. But what about something more like a theory in natural science? In which we might treat our automatically generated proof as an object for empirical study—exploring its characteristics, trying to get intuition about it, and ultimately trying to deduce the analog of “natural laws” that give us a “human-level” way of understanding it. </p>
<p>Of course, for many purposes it doesn’t really matter why the theorem is true. All that matters is that it is true, and that one can deduce things on the basis of it. But as one thinks about the future of mathematics, and the future of doing mathematics, it’s interesting to explore to what extent it might or might not ultimately be possible to understand in a human-accessible way the kind of seemingly alien result that the theorem represents. </p>
<h2 id="the-proof-as-we-know-it">The Proof as We Know It</h2>
<p>I first presented a version of the proof on <a href="https://www.wolframscience.com/nks/p810--implications-for-mathematics-and-its-foundations/">two pages</a> of my 2002 book <em><a href="https://www.wolframscience.com/nks/">A New Kind of Science</a></em>, printing it in 4-point type to make it fit: </p>
<p><a href="https://files.wolframcdn.com/pub/www.wolframscience.com/nks/nks-ch12-sec9.pdf"><img src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg1.png" alt="Axiom proof" title="Axiom proof" width="619" height="373"></a></p>
<p>Today, generating a very similar proof is a one-liner in Wolfram Language (as we’ll discuss below, the · dot here can be thought of as representing the <tt><a href="http://reference.wolfram.com/language/ref/Nand.html">Nand</a></tt> operation):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg2.png" alt="" title="" width="455" height="100"> </p>
</div>
<p>The proof involves 307 (mostly rather elaborate) steps. And here’s one page of it (out of about 30)—presented in the form of a computable Wolfram Language dataset:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg4.png" alt="Example proof steps page" title="Example proof steps page" width="619" height="385"></p>
</div>
<p>What’s the basic idea of this proof? Essentially it’s to perform a sequence of purely structural symbolic operations that go from our axiom to <a href="https://www.wolframscience.com/nks/p808--implications-for-mathematics-and-its-foundations/">known axioms of Boolean algebra</a>. And the proof does this by proving a series of lemmas which can be combined to eventually give what we want: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg5A.png" alt="" title="" width="689" height="1012"> </p>
</div>
<p>The highlighted “targets” here are the standard Sheffer axioms for Boolean algebra from 1913:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg6.png" alt="" title="" width="278" height="60"> </p>
</div>
<p>And, yes, even though these are quite short, the intermediate lemmas involved in the proof get quite long—the longest involving 60 symbols (i.e. having <tt><a href="http://reference.wolfram.com/language/ref/LeafCount.html">LeafCount</a></tt> 60):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg7.png" alt="" title="" width="488" height="40"> </p>
</div>
<p>It’s as if to get to where it’s going, the proof ends up having to go through the wilds of metamathematical space. And indeed one gets a sense of this if one plots the sizes (i.e. <tt><a href="http://reference.wolfram.com/language/ref/LeafCount.html">LeafCount</a></tt>) of successive lemmas:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg8.png" alt="" title="" width="674" height="142"> </p>
</div>
<p>Here’s the distribution of these sizes, showing that while they’re often small, there’s a long tail (note, by the way, that if dot · appears <em>n</em> times in a lemma, the <tt><a href="http://reference.wolfram.com/language/ref/LeafCount.html">LeafCount</a></tt> will be 2<em>n</em> + 3):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg9.png" alt="" title="" width="259" height="122"> </p>
</div>
<p>So how are these lemmas related? Here’s a graph of their interdependence (with the size of each dot being proportional to the size of the lemma it represents):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg10.png" alt="" title="" width="565" height="710"> </p>
</div>
<p>Zooming in on the top we see more detail:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg11.png" alt="" title="" width="595" height="375"> </p>
</div>
<p>We start from our axiom, then derive a whole sequence of lemmas—as we’ll see later, always <a href="https://www.wolframscience.com/metamathematics/proofs-in-accumulative-systems/">combining two lemmas to create a new one</a>. (And, yes, we could equally well call these things theorems—but we generate so many of them it seems more natural to call them “lemmas”.) </p>
<p>So, OK, we’ve got a complicated proof. But how can we check that it’s correct? Well, from the symbolic representation of the proof in the Wolfram Language we can immediately generate a “proof function” that in effect contains executable versions of all the lemmas—implemented using simple structural operations:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofCLOUDAimg11A.png" alt="" title="" width="551" height="453"> </p>
</div>
<p>And when you run this function, it applies all these lemmas and checks that the result comes out right:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg14.png" alt="" title="" width="259" height="43"> </p>
</div>
<p>And, yes, this is basically what one would do in a proof assistant system (like <a href="https://lean-lang.org/" target="_blank" rel="noopener">Lean</a> or <a href="https://us.metamath.org/index.html" target="_blank" rel="noopener">Metamath</a>)—except that here the steps in the proof were generated purely automatically, without any human guidance (or effort). And, by the way, the fact that we can readily translate our symbolic proof representation into a function that we can run provides an operational manifestation of the equivalence between proofs and programs. </p>
<p>But let’s look back at our lemma-interdependence “proof graph”. One notable feature is that we see several nodes with high out-degree—corresponding to what we can think of as “pivotal lemmas” from which many other lemmas end up directly being proved. So here’s a list of the “most pivotal” lemmas in our proof:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg15.png" alt="" title="" width="329" height="178"> </p>
</div>
<p>Or, more graphically, here are the results for all lemmas that occur:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg16.png" alt="" title="" width="344" height="239"> </p>
</div>
<p>So what are the “pivotal lemmas”? <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em> we readily recognize as commutativity. But the others—despite their comparative simplicity—don’t seem to correspond to things that have specifically shown up before in the mathematical literature (or, as we’ll <a href="https://writings.stephenwolfram.com/2025/01/who-can-understand-the-proof-a-window-on-formalized-mathematics/#llms-to-the-rescue">discuss later</a>, that’s at least what the current generation of LLMs tell us).</p>
<p>But looking at our proof graph something we can conclude is that a large fraction of the “heavy lifting” needed for the whole proof has already happened by the time we can prove <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>. So, for the sake of avoiding at least some of hairy detail in the full proof, in most of what follows, we’ll concentrate on the proof of <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>—which <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> tells us we can accomplish in 104 steps, with a proof graph of the form</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg17.png" alt="" title="" width="666" height="824"> </p>
</div>
<p>with the sizes of successive lemmas (in what is basically a breadth-first traversal of the proof graph) being:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025proofimg18A.png" alt="" title="" width="509" height="117"> </p>
</div>
<h2 id="the-machine-code-of-the-proof">The “Machine Code” of the Proof</h2>
<p>It’s already obvious from the previous section that the proof as we currently know it is long, complicated, and fiddly—and in many ways reminiscent of something at a “machine-code” level. But to get a grounded sense of what’s going on in the proof, it’s useful to dive into the details—even if, yes, they can be seriously hard to wrap one’s head around. </p>
<p>At a fundamental level, the way the proof—say of <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>—works is by starting from our axiom, and then progressively deducing new lemmas from pairs of existing lemmas. In the simplest case, that deduction works by <a href="https://www.wolframscience.com/metamathematics/the-metamodeling-of-axiomatic-mathematics/">straightforward symbolic substitution</a>. So, for example, let’s say we have the lemmas</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg1.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>and </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg2.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>Then it turns out that from these lemmas we can deduce:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg3.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>Or, in other words, knowing that the first two lemmas hold for any <em>a</em> gives us enough information about · that the third lemma must inevitably also hold. So how do we derive this?</p>
<p>Our lemmas in effect <a href="https://www.wolframscience.com/metamathematics/rules-applied-to-rules/">define two-way equivalences</a>: their left-hand sides are defined as equal to their right-hand sides, which means that if we see an expression that (structurally) matches one side of a lemma, we can always replace it by the other side of the lemma. And to implement this, we can write our second lemma explicitly as a rule—where to avoid confusion we’re using <em>x</em> rather than <em>a</em>:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg4.png" alt="" title="" width="141" height="14"> </p>
</div>
<p>But if we now look at our first lemma, we see that there’s part of it (indicated with a frame) that matches the left-hand side of our rule:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg5.png" alt="" title="" width="132" height="25"> </p>
</div>
<p>If we replace this part (which is at position {2,2}) using our rule we then get</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg6.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>which is precisely the lemma we wanted to deduce. </p>
<p>We can summarize what happened here as a fragment of our proof graph—in which a “substitution event” node takes our first two lemmas as input, and “outputs” our final lemma:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg1.png" alt="" title="" width="277" height="99"> </p>
</div>
<p>As always, the symbolic expressions we’re working with here can be represented as trees:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg8.png" alt="" title="" width="391" height="158"> </p>
</div>
<p>The substitution event then corresponds to a tree rewriting:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg2.png" alt="" title="" width="275" height="242"> </p>
</div>
<p>The <a href="https://www.wolframscience.com/metamathematics/relations-to-automated-theorem-proving/">essence of automated theorem proving</a> is to find a particular sequence of substitutions etc. that get us from whatever axioms or lemmas we’re starting with, to whatever lemmas or theorems we want to reach. Or in effect to find a suitable “path” through the multiway graph of all possible substitutions etc. that can be made. </p>
<p>So, for example, in the particular case we’re considering here, this is the graph that represents all possible transformations that can occur through a single substitution event:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg10.png" alt="" title="" width="582" height="285"> </p>
</div>
<p>The particular transformation (or “path”) we’ve used to prove <em>a</em> · <em>a</em> = <em>a</em> · ((<em>a</em> · <em>a</em>) · <em>a</em>) is highlighted. But as we can see, there are many other possible lemmas that can be generated, or in other words that can be proved from the two lemmas we’ve given as input. Put another way, we can think of our input lemmas as implying or entailing all the other lemmas shown here. And, by analogy to the concept of a light cone in physics, we can view the collection of everything entailed by given lemmas or given events as the (future) “<a href="https://www.wolframscience.com/metamathematics/metamathematical-space/#p-28">entailment cone</a>” of those lemmas or events. A proof that reaches a particular lemma is then effectively a path in this entailment cone—analogous in physics to a world line that reaches a particular spacetime point.</p>
<p>If we continue building out the entailment cone from our original lemmas, then after two (substitution) events we get:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg11.png" alt="" title="" width="701" height="454"> </p>
</div>
<p>There are 49 lemmas generated here. But it turns out that beyond the lemma we already discussed there are only three (highlighted here) that appear in the proof we are studying here:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg12.png" alt="" title="" width="281" height="60"> </p>
</div>
<p>And indeed the <a href="https://writings.stephenwolfram.com/2018/11/logic-explainability-and-the-future-of-understanding/#the-mechanics-of-proof">main algorithmic challenge of theorem proving</a> is to figure out which lemmas to generate in order to get a path to the theorem one’s trying to prove. And, yes, as we’ll discuss later, there are typically many paths that will work, and different algorithms will yield different paths and therefore different proofs.</p>
<p>But, OK, seeing how new lemmas can be derived from old by substitution is already quite complicated. But actually there’s something even more complicated we need to discuss: deriving lemmas not only by substitution but also by what we’ve called <a href="https://www.wolframscience.com/metamathematics/beyond-substitution-cosubstitution-and-bisubstitution/">bisubstitution</a>. </p>
<p>We can think of both substitution and bisubstitution as turning one lemma X == Y into a transformation rule (either X <img src="https://content.wolfram.com/uploads/sites/32/2022/10/rightarrow2.png" width="15" height="11"> Y or Y <img src="https://content.wolfram.com/uploads/sites/32/2022/10/rightarrow2.png" width="15" height="11"> X), and then applying this rule to another lemma, to derive a new lemma. In ordinary substitution, the left-hand side of the rule directly matches (in a Wolfram Language pattern-matching sense) a subexpression in the lemma we’re transforming. But the key point is that all the variables that appear in both our lemmas are really “pattern variables” (<tt>x_</tt> etc. in Wolfram Language). So that means there’s another way that one lemma can transform another, in which in effect replacements are made not only in the lemma being transformed, but also in the lemma that’s doing the transforming. </p>
<p>The net effect, though, is still to take two lemmas and derive another, as in:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg3.png" alt="" title="" width="414" height="130"> </p>
</div>
<p>But in tracing through the details of our proof, we need to distinguish “substitution events” (shown yellowish) from “bisubstitution” ones (shown reddish). (In <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> in Wolfram Language, lemmas produced by ordinary substitution are called “substitution lemmas”, while lemmas produced by bisubstitution are called “critical pair lemmas”.)</p>
<p>OK, so how does bisubstitution work? Let’s look at an example. We’re going to be transforming the lemma </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg14.png" alt="" title="" width="235" height="14"> </p>
</div>
<p>using the lemma (which in this case happens to be our original axiom)</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg15.png" alt="" title="" width="183" height="14"> </p>
</div>
<p>to derive the new lemma:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg16.png" alt="" title="" width="235" height="14"> </p>
</div>
<p>We start by creating a rule from the second lemma. In this case, the rule we need happens to be reversed relative to the way we wrote the lemma, and this means that (in the canonical form we’re using) it’s convenient to rename the variables that appear:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg17.png" alt="" title="" width="237" height="14"> </p>
</div>
<p>To do our bisubstitution we’re going to apply this rule to a subterm of our first lemma. We can write that first lemma with explicit pattern variables:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg18.png" alt="" title="" width="311" height="14"> </p>
</div>
<p>As always, the particular names of those variables don’t matter. And to avoid confusion, we’re going to rename them:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg19.png" alt="" title="" width="306" height="14"> </p>
</div>
<p>Now look at this subterm of this lemma (which is part {2,1,1,2} of the expression):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg20.png" alt="" title="" width="102" height="14"> </p>
</div>
<p>It turns out that with appropriate bindings for pattern variables this can be matched (or “unified”) with the left-hand side of our rule. This provides a way to find such bindings:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg21.png" alt="" title="" width="345" height="14"> </p>
</div>
<p>(Note that in these bindings things like c_ stand only for explicit expressions, like c_, not for expressions that the ordinary Wolfram Language pattern <tt>c_</tt> would match.)</p>
<p>Now if we apply the bindings we’ve found to the left-hand side of our rule</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg22.png" alt="" title="" width="277" height="14"> </p>
</div>
<p>and to the subterm we picked out from our lemma</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg23.png" alt="" title="" width="277" height="14"> </p>
</div>
<p>we see that we get the same expression. Which means that with these bindings the subterm matches the left-hand side of our rule, and we can therefore replace this subterm with the right-hand side of the rule. To see all this in operation, we first apply the bindings we’ve found to the lemma we’re going to transform (and, as it happens, the binding for y_ is the only one that matters here):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg24.png" alt="" title="" width="615" height="14"> </p>
</div>
<p>Now we take this form and apply the rule at the position of the subterm we identified:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg25.png" alt="" title="" width="342" height="14"> </p>
</div>
<p>Renaming variables</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg26.png" alt="" title="" width="345" height="14"> </p>
</div>
<p> we now finally get exactly the lemma that we were trying to derive:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg27.png" alt="" title="" width="235" height="14"> </p>
</div>
<p>And, yes, getting here was a pretty complicated process. But with the symbolic character of our lemmas, it’s one that is inevitably possible, and so can be used in our proof. And in the end, out of the 101 lemmas used in the proof, 47 were derived by ordinary substitution, while 54 were derived by bisubstitution.</p>
<p>And indeed the first few steps of the proof turn out to use only bisubstituion. An example is the first step—which effectively applies the original axiom to itself using bisubsitution:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg4.png" alt="" title="" width="243" height="149"> </p>
</div>
<p>And, yes, even this very first step is pretty difficult to follow. </p>
<p>If we start from the original axiom, there are 16 lemmas that can be derived purely by a single ordinary substitution (effectively of the axiom into itself)—resulting in the following entailment cone:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg29.png" alt="" title="" width="693" height="323"> </p>
</div>
<p>As it happens, though, none of the 16 new lemmas here actually get used in our proof. On the other hand, in the bisubstitution entailment cone</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg30.png" alt="" title="" width="693" height="251"> </p>
</div>
<p>there are 27 new lemmas, and 4 of them get used in the proof—as we can see from the first level of the proof graph (here rotated for easier rendering):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg31.png" alt="" title="" width="657" height="101"> </p>
</div>
<p>At the next level of the entailment cone from ordinary substitution, there are 5153 new lemmas—none of which get used in the proof. But of the 23215 new lemmas in the (pure) bisubstitution entailment cone, 5 do get used:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg32.png" alt="" title="" width="663" height="112"> </p>
</div>
<p>At the next level, lemmas generated by ordinary substitution also start to get used:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg33.png" alt="" title="" width="657" height="126"> </p>
</div>
<p>Here’s another rendering of these first few levels of the proof graph:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg34.png" alt="" title="" width="295" height="198"> </p>
</div>
<p>Going to another couple of levels we’re starting to see quite a few independent chains of lemmas developing</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg35.png" alt="" title="" width="454" height="289"> </p>
</div>
<p>which eventually join up when we assemble the whole proof graph:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg36.png" alt="" title="" width="605" height="631"> </p>
</div>
<p>A notable feature of this proof graph is that it has more bisubstitution events at the top, and more ordinary substitution events at the bottom. So why is that? Essentially it seems to be because bisubstitution events tend to produce larger lemmas, and ordinary substitution events tend to produce smaller ones—as we can see if we plot input and output lemma sizes for all events in the proof:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg37.png" alt="" title="" width="451" height="479"> </p>
</div>
<p>So in effect what seems to be happening is that the proof first has to “spread out in <a href="https://www.wolframscience.com/metamathematics/metamathematical-space/">metamathematical space</a>”, using bisubstitution to generate large lemmas “far out in metamathematical space”. Then later the proof has to “corral things back in”, using ordinary substitution to generate smaller lemmas. And for example, at the very end, it’s a substitution event that yields the final theorem we’re trying to prove:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg38.png" alt="" title="" width="277" height="100"> </p>
</div>
<p>And earlier in the graph, there’s a similar “collapse” to a small (and rather pivotal) lemma:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025machineCLOUDimg39.png" alt="" title="" width="406" height="120"> </p>
</div>
<p>As the plot above indicates, ordinary substitution can lead to large lemmas, and indeed bisubstitution can also lead to smaller ones, as in</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025machineCLOUDimg40.png" alt="" title="" width="367" height="87"> </p>
</div>
<p>or slightly more dramatically:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025machineCLOUDimg41.png" alt="" title="" width="630" height="140"> </p>
</div>
<p>But, OK, so this is some of what’s going on at a “machine-code” level inside the proof we have. Of course, given our axiom and the operations of substitution and bisubstitution there are inevitably a huge number of different possible proofs that could be given. The particular proof we’re considering is what the Wolfram Language <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> gives. (In the Appendix, we’ll also look at results from some other automated theorem proving systems. The results will be very comparable, if usually a little lengthier.) </p>
<p>We won’t discuss the detailed (and rather elaborate) algorithms inside <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt>. But fundamentally what they’re doing is to try constructing certain lemmas, then to find sequences of lemmas that eventually form a “path” to what we’re trying to prove. And as some indication of what’s involved in this, here’s a plot of the number of “candidate lemmas” that are being maintained as possible when different lemmas in the proof are generated:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025machineimg42.png" alt="" title="" width="354" height="145"> </p>
</div>
<p>And, yes, for a while there’s roughly exponential growth, leveling off at just over a million when we get to the “pulling everything together” stage of the proof.</p>
<h2 id="unrolling-the-proof">Unrolling the Proof</h2>
<p>In what we’ve done so far, we’ve viewed our proof as working by starting from an axiom, then <a href="https://www.wolframscience.com/nks/notes-12-9--proof-structures/">progressively building up lemmas</a>, until eventually we get to the theorem we want. But there’s an alternative view that’s in some ways useful in getting a more direct, “mechanical” intuition about what’s going on in the proof.</p>
<p>Let’s say we’re trying to prove that our axiom implies that <em>p</em> · <em>q</em> = <em>q</em> · <em>p</em>. Well, then there must be some way to start from the expression <em>p</em> · <em>q</em> and just keep on judiciously applying the axiom until eventually we get to the expression <em>q</em> · <em>p</em>. And, yes, the number of axiom application steps required might be very large. But ultimately, if it’s true that the axiom implies <em>p</em> · <em>q</em> = <em>q</em> · <em>p</em> there must be a path that gets from <em>p</em> · <em>q</em> to <em>q</em> · <em>p</em>.</p>
<p>But before considering the case of our full proof, let’s start with something simpler. Let’s assume that we’ve already established the lemmas:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg1.png" alt="" title="" width="121" height="37"> </p>
</div>
<p>Then we can treat them as axioms, and ask a question like whether they imply the lemma</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg2.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>or, in our current approach, whether they can be used to form a path from <em>a</em> · <em>a</em> to <em>a</em> · (<em>a</em> · (<em>a</em> · <em>a</em>)). </p>
<p>Well, it’s not too hard to see that in fact there is such a path. Apply our second lemma to <em>a</em> · <em>a</em> to get:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg3.png" alt="" title="" width="77" height="14"> </p>
</div>
<p>But now this subterm</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg4.png" alt="" title="" width="88" height="25"> </p>
</div>
<p>matches the left-hand of the first lemma, so that it can be replaced by the right-hand side of that lemma (i.e. by <em>a</em> · (<em>a</em> · <em>a</em>)), giving in the end the desired <em>a</em> · (<em>a</em> · (<em>a</em> · <em>a</em>)).</p>
<p>So now we can summarize this process as:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg5.png" alt="" title="" width="252" height="138"> </p>
</div>
<p>In what follows, it’ll be convenient to label lemmas. We’ll call our original axiom A1, we’ll call our successive lemmas generated by ordinary substitution S<em>n</em> and the ones generated by bisubsitution B<em>n:</em></p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg6.png" alt="" title="" width="399" height="621"> </p>
</div>
<p>In our proof we’ll also use <img src="https://content.wolfram.com/sites/43/2025/01/rightgreenarrow.png" width="18" height="25"> and <img src="https://content.wolfram.com/sites/43/2025/01/leftpinkarrow.png" width="18" height="25"> to indicate whether we’re going to use the lemma (say <nobr>X = Y)</nobr> in the “forward direction” X <img src="https://content.wolfram.com/uploads/sites/32/2022/10/rightarrow2.png" width="15" height="11"> Y or the “reverse direction” X <img src="https://content.wolfram.com/uploads/sites/32/2022/10/leftarrow.png" width="15" height="11"> Y. And with this labeling, the proof we just gave (which is for the lemma S23) becomes:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg7.png" alt="" title="" width="168" height="138"> </p>
</div>
<p>Each step here is a pure substitution, and requires no replacement in the rule (i.e. “axiom”) being used. But proofs like this can also be done with bisubstitution, where replacements are applied to the rule to get it in a form where it can directly be applied to transform an expression:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg8.png" alt="" title="" width="529" height="136"> </p>
</div>
<p>OK, so how about the first lemma in our full proof? Here’s a proof that its left-hand side can be transformed to its right-hand side just by judiciously applying the original axiom:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg9.png" alt="" title="" width="504" height="140"> </p>
</div>
<p>Here’s a corresponding proof for the second lemma:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg10.png" alt="" title="" width="531" height="136"> </p>
</div>
<p>Both these involve bisubstitution. Here’s a proof of the first lemma derived purely by ordinary substitution:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg11.png" alt="" title="" width="611" height="136"> </p>
</div>
<p>This proof is using not only the original axiom but also the lemma B5. Meanwhile, B5 can be proved using the original axiom together with B2:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg12.png" alt="" title="" width="693" height="181"> </p>
</div>
<p>But now, inserting the proof we just gave above for B2, we can give a proof of B5 just in terms of the original axiom:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg13.png" alt="" title="" width="693" height="278"> </p>
</div>
<p>And recursively continuing this unrolling process, we can then prove S1 purely using the original axiom:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg14.png" alt="" title="" width="693" height="329"> </p>
</div>
<p>What about the whole proof? Well, at the very end we have:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg15.png" alt="" title="" width="222" height="137"> </p>
</div>
<p>If we “unroll” one step we have</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg16.png" alt="" title="" width="275" height="349"> </p>
</div>
<p>and after 2 steps:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg17.png" alt="" title="" width="435" height="444"> </p>
</div>
<p>In principle we could go on with this unrolling, in effect recursively replacing each rule by the sequence of transformations that represents its proof. Typically this process will, however, generate exponentially longer proof sequences. But say for lemma S5</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg18.png" alt="" title="" width="334" height="14"> </p>
</div>
<p>the result is still very easily manageable:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg19.png" alt="" title="" width="670" height="274"> </p>
</div>
<p>We can summarize this result by in effect plotting the sizes of the intermediate expressions involved—and indicating what part of each expression is replaced at each step (with <img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/01082025redbox.png" alt="" title="" width="15" height="15"> as above indicating “forward” use of the axiom A1 <img src="https://content.wolfram.com/uploads/sites/32/2022/10/rightarrow2.png" width="15" height="11"> and <img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/greenbox.png" '="" title="" width="15" height="15"> “backward” A1 <img src="https://content.wolfram.com/uploads/sites/32/2022/10/leftarrow.png" width="15" height="11">):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg20.png" alt="" title="" width="357" height="160"> </p>
</div>
<p>For lemma B33</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg21.png" alt="" title="" width="681" height="14"> </p>
</div>
<p>the unrolled proof is now 30 steps long</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg22.png" alt="" title="" width="357" height="160"> </p>
</div>
<p>while for lemma S11</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg23.png" alt="" title="" width="467" height="14"> </p>
</div>
<p>the unrolled proof is 88 steps long:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg24.png" alt="" title="" width="412" height="182"> </p>
</div>
<p>But here there is a new subtlety. Doing a direct substitution of the “proof paths” for the lemmas used to prove S11 in our original proof gives a proof of length 104:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg25.png" alt="" title="" width="466" height="177"> </p>
</div>
<p>But this proof turns out to be repetitive, with the whole gray section going from one copy to another of:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg26.png" alt="" title="" width="237" height="14"> </p>
</div>
<p>As an example of a larger proof, we can consider lemma B47:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg27.png" alt="" title="" width="157" height="14"> </p>
</div>
<p>And despite the simplicity of this lemma, our proof for it is 1008 steps long: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg28.png" alt="" title="" width="609" height="204"> </p>
</div>
<p>If we don’t remove repetitive sections, it’s 6805 steps:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg29.png" alt="" title="" width="460" height="157"> </p>
</div>
<p>Can we unroll the whole proof of <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>? We can get closer by considering lemma S36:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg30.png" alt="" title="" width="121" height="14"> </p>
</div>
<p>Its proof is 27105 steps long:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg31A.png" alt="" title="" width="621" height="204"> </p>
</div>
<p>The distribution of expression sizes follows a roughly exponential distribution, with a maximum of 20107:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg32.png" alt="" title="" width="274" height="122"> </p>
</div>
<p>Plotting the expression sizes on a log scale one gets: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg33.png" alt="" title="" width="409" height="142"> </p>
</div>
<p>And what stands out most here is a kind of recursive structure—which is the result of long sequences that basically represent the analog of “subroutine calls” that go back and repeatedly prove lemmas that are needed.</p>
<p>OK, so what about the whole proof of <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>? Yes, it can be unrolled—in terms of 83,314 applications of the original axiom. The sequence of expression sizes is:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg34.png" alt="" title="" width="571" height="187"> </p>
</div>
<p>Or on a log scale:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg35.png" alt="" title="" width="519" height="175"> </p>
</div>
<p>The distribution of expression sizes now shows clear deviation from being exponential:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025unrollCLOUDimg36A.png" alt="" title="" width="359" height="160"> </p>
</div>
<p>The maximum is 63245, which occurs just 81 steps after the exact midpoint of the proof. In other words, in the middle, the proof has wandered incredibly far out in metamathematical space (there are altogether <tt><a href="http://reference.wolfram.com/language/ref/CatalanNumber.html">CatalanNumber</a></tt>[63245] ≈ 10<sup>38178</sup> possible expressions of the size it reaches). </p>
<p>The proof returns to small expressions just a few times; here are all the cases in which the size is below 10:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092024JGCLOUDimg8.png" alt="" title="" width="399" height="274"> </p>
</div>
<p>So, yes, it is possible to completely unroll the proof into a sequence of applications of the original axiom. But if one does this, it inevitably involves repeating lots of work. Being able to use intermediate lemmas in effect lets one “share common subparts” in the proof. So that one ends up with just 104 “rule applications”, rather than 63245. Not that it’s easy to understand those 104 steps…</p>
<h2 id="is-there-a-better-notation">Is There a Better Notation?</h2>
<p> Looking at our proof—either in its original “lemma” form, or in its “unrolled” form—the most striking aspect of it is how complicated (and incomprehensible) it seems to be. But one might wonder whether much of that complexity is just the result of not “using the right notation”. In the end, we’ve got a huge number of expressions written in terms of · operations that we can interpret as <tt><a href="http://reference.wolfram.com/language/ref/Nand.html">Nand</a></tt> (or <tt><a href="http://reference.wolfram.com/language/ref/Nor.html">Nor</a></tt>). And maybe it’s a little like seeing the operation of a microprocessor down at the level of individual gates implementing <tt>Nand</tt>s or <tt>Nor</tt>s. And might there perhaps be an analog of a higher-level representation—with higher-level operations (even like arithmetic) that are more accessible to us humans?</p>
<p>It perhaps doesn’t help that <tt>Nand</tt> itself is a rather non-human construct. For example, not a single natural human language seems to have a word for <tt>Nand</tt>. But there are combinations of <tt>Nand</tt>s that have more <a href="https://www.wolframscience.com/nks/p807--implications-for-mathematics-and-its-foundations/">familiar interpretations</a>:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025notationimg1.png" alt="" title="" width="228" height="127"> </p>
</div>
<p>But what combinations actually occur in our proof? Here are the most common subexpressions that appear in lemmas in the proof:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092925NLCLOUDimg12.png" alt="" title="" width="290" height="316"> </p>
</div>
<p>And, yes, we could give the most common of these special names. But it wouldn’t really help in “compressing” the proof—or making it easier to understand.</p>
<p>What about “upgrading” our “laws of inference”, i.e. the way that we can derive new lemmas from old? Perhaps instead of substitution and bisubstitution, which both take two lemmas and produce one more, we could set up more elaborate “tactics” that for example take in more input lemmas. We’ve seen that if we completely unroll the proof, it gets much longer. So perhaps there is a “higher-order” setup that for example dramatically shortens the proof. </p>
<p>One way one might identify this is by seeing commonly repeating structures in the subgraphs that lead to lemmas. But in fact these subgraphs are quite diverse:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025notationimg3.png" alt="" title="" width="589" height="130"> </p>
</div>
<h2 id="what-are-the-popular-lemmas">What Are the Popular Lemmas?</h2>
<p>A typical feature of human-written mathematical proofs is that they’re “anchored” by famous theorems or lemmas. They may have fiddly technical pieces. But usually there’s a backbone of “theorems people know”. </p>
<p>We have the impression that the proof we’re discussing here “spends most of its time wandering around the wilds of metamathematical space”. But perhaps it visits waypoints that are somehow recognizable, or at least should be. Or in other words, perhaps out in the metamathematical space of lemmas there are ones that are somehow sufficiently popular that they’re worth giving names to, and learning—and can then be used as “reference points” in terms of which our proof becomes simpler and more human accessible.</p>
<p>It’s a story very much like what happens with human language. There are things out there in the world, but when there’s a certain category of them that are somehow common or important enough, we make a word for them in our language, which we can then use to “compactly” refer to them. (It’s again the same story when it comes to computational language, and in particular the Wolfram Language, except that in that case it’s been my personal responsibility to come up with the appropriate definitions and names for functions to represent “common lumps of computation”.) </p>
<p>But, OK, so what are the “popular lemmas” of <tt><a href="http://reference.wolfram.com/language/ref/Nand.html">Nand</a></tt> proofs? One way to explore this is to enumerate statements that are “true about <tt>Nand</tt>”—then to look at proofs of these statements (say found with <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> from our axiom) and see what lemmas show up frequently in them. </p>
<p><a href="https://www.wolframscience.com/nks/p818--implications-for-mathematics-and-its-foundations/">Enumerating statements “true about </a><tt><a href="https://www.wolframscience.com/nks/p818--implications-for-mathematics-and-its-foundations/">Nand”</a></tt>, starting from the smallest, we get</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg1.png" alt="" title="" width="598" height="222"> </p>
</div>
<p>where we have highlighted statements from this list that appear as lemmas in our proof.</p>
<p>Proving each of these statements from our original axiom, here are the <a href="https://www.wolframscience.com/nks/notes-12-9--proof-lengths-in-logic/">lengths of proofs we find</a> (for all 1341 distinct theorems with up to <tt><a href="http://reference.wolfram.com/language/ref/LeafCount.html">LeafCount</a></tt> 4 on each side):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg2.png" alt="" title="" width="471" height="204"> </p>
</div>
<p>A histogram shows that it’s basically a bimodal distribution</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg3.png" alt="" title="" width="359" height="134"> </p>
</div>
<p>with the smallest “long-proof” theorem being:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg4.png" alt="" title="" width="173" height="14"> </p>
</div>
<p>In aggregate, all these proofs use about 200,000 lemmas. But only about 1200 of these are distinct. And we can plot which lemmas are used in which proofs—and we see that there are indeed many lemmas that are used across wide ranges of proofs, while there are a few others that are “special” to each proof (the diagonal stripe is associated with lemmas close to the statement being proved):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg5.png" alt="" title="" width="428" height="401"> </p>
</div>
<p>If we rank all distinct lemmas from most frequently to least frequently used, we get the following distribution of lemma usage frequencies across all our proofs: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg6.png" alt="" title="" width="355" height="155"> </p>
</div>
<p>It turns out that there is a “common core” of 49 lemmas that are used in every single one of the proofs. So what are these lemmas? Here’s a plot of the usage frequency of lemmas against their size—with the “common ones” populating the top line: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg7.png" alt="" title="" width="438" height="192"> </p>
</div>
<p>And at first this might seem surprising. We might have expected that short lemmas would be the most frequent, but instead we’re seeing long lemmas that always appear, the very longest being:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg8.png" alt="" title="" width="516" height="40"> </p>
</div>
<p>So why is this? Basically it’s that these long lemmas are being used at the beginning of every proof. They’re the result of applying bisubstitution to the original axiom, and in some sense they seem to be laying down a kind of net in metamathematical space that then allows more diverse—and smaller—lemmas to be derived. </p>
<p>But how are these “common core” popular lemmas distributed within proofs? Here are a few examples:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025lemmasCLOUDXimg9.png" alt="" title="" width="566" height="579"> </p>
</div>
<p>And what we see is that while, yes, the common core lemmas are always at the beginning, they don’t seem to have a uniform way of “plugging into” the rest of the proof. And it doesn’t, for example, seem as if there’s just some small set of (perhaps simple) “waypoint” lemmas that one can introduce that will typically shorten these proofs.</p>
<p>If one effectively allows all the common core lemmas to be used as axioms, then inevitably proofs will be shortened; for example, the proof of <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>—which only ends up using 5 of the common core lemmas—is now shortened to 51 lemmas:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025lemmasCLOUDZimg10B.png" alt="" title="" width="282" height="479"> </p>
</div>
<p>It doesn’t seem to become easier to understand, though. And if it’s unrolled, it’s still 5013 steps. </p>
<p>Still, one can ask what happens if one just introduces particular “recognizable” lemmas as additional axioms. For example, if we include “commutativity” <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em> then we find that, yes, we do manage to <a href="https://www.wolframscience.com/nks/notes-12-9--proof-lengths-in-logic/">reduce the lengths of some proofs</a>, but certainly not all:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg11.png" alt="" title="" width="554" height="280"> </p>
</div>
<p>Are there any other “pivotal” lemmas we could add? In particular, what about lemmas that can help with the length-200 or more proofs? It turns out that all of these proofs involve the lemma: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg12.png" alt="" title="" width="130" height="14"> </p>
</div>
<p>So what happens if we add this? Well, it definitely reduces proof lengths:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg13.png" alt="" title="" width="607" height="316"> </p>
</div>
<p>And sometimes it even seems like it brings proofs into “human range”. For example, a proof of</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025lemmasimg14.png" alt="" title="" width="104" height="14"> </p>
</div>
<p>from our original axiom has length 56. Adding in commutativity reduces it to length 18. And adding our third lemma reduces it to just length 9—and makes it not even depend directly on the original axiom:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025lemmasCLOUDZimg15.png" alt="" title="" width="272" height="249"> </p>
</div>
<p>But despite the apparent simplicity here, the steps involved—particularly when bisubstitution is used—are remarkably hard to follow. (Note the use of <em>a </em>= <em>a</em> as a kind of “implicit axiom”—something that has actually also appeared, without comment, in many of our other proofs.)</p>
<h2 id="can-we-get-a-shorter-proof">Can We Get a Shorter Proof?</h2>
<p>The proof that we’ve been studying can be seen in some ways as a rather arbitrary artifact. It’s the output of <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt>, with all its specific detailed internal algorithms and choices. In the Appendix, we’ll see that other automated theorem proving systems give very similar results. But we still might wonder whether actually the complexity of the proof as we’ve been studying it is just a consequence of the details of our automated theorem proving—and that in fact there’s a much shorter (and perhaps easier to understand) proof that exists.</p>
<p>One approach we could take—reminiscent of higher category theory—is to think about just simplifying the proof we have, effectively using proof-to-proof transformations. And, yes, this is technically difficult, though it doesn’t seem impossible. But what if there are <a href="https://www.wolframscience.com/metamathematics/the-topology-of-proof-space/">“holes” in proof space</a>? Then a “continuous deformation” of one proof into another will get stuck, and even if there is a much shorter proof, we’re liable to get “topologically stuck” before we find it.</p>
<p>One way to be sure we’re getting the shortest proof of a particular lemma is to explicitly find the first place that lemma appears in the (future) entailment cone of our original axiom. For example, as we saw above, a single substitution event leads to the entailment cone:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg1.png" alt="" title="" width="645" height="285"> </p>
</div>
<p>Every lemma produced here is, by construction, in principle derivable by a proof involving a single substitution event. But if we actually use <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> to prove these lemmas, the proofs we get most involve 2 events (and in one case 4):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025shorterAimg2.png" alt="" title="" width="645" height="75"> </p>
</div>
<p>If we take another step in the entailment cone, we get a total of 5151 lemmas. From the way we generated them, we know that all these lemmas can in principle be reached by proofs of length 2. But if we run <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> on them, we find a distribution of proof lengths:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg3.png" alt="" title="" width="314" height="141"> </p>
</div>
<p>And, yes, there is one lemma (with <tt><a href="http://reference.wolfram.com/language/ref/LeafCount.html">LeafCount</a></tt> 183) that is found only by a proof of length 14. But most often the proof length is 4—or about double what it could be. </p>
<p>If we generate the entailment cone for lemmas using bisubstitution rather than just ordinary substitution, there are slightly more cases where <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> does worse at getting minimal proofs. </p>
<p>For example, the lemma</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg4.png" alt="" title="" width="671" height="14"> </p>
</div>
<p>and 3 others can be generated by a single bisubstitution from the original axiom, but <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> gives only proofs of length 4 for all of these.</p>
<p>What about unrolled proofs, in which one can generate an entailment cone by starting from a particular expression, and then applying the original axiom in all possible ways? For example, let’s say we start with:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg5.png" alt="" title="" width="77" height="14"> </p>
</div>
<p>Then applying bisubstitution with the original axiom once in all possible ways gives:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg6.png" alt="" title="" width="601" height="186"> </p>
</div>
<p>Applying bisubstitution a second time gives a larger entailment cone: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025shorterCimg7.png" alt="" title="" width="451" height="406"> </p>
</div>
<p>But now it turns out that—as indicated—one of the expressions in this cone is: </p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg8.png" alt="" title="" width="262" height="14"> </p>
</div>
<p>So this shows that the lemma</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg9.png" alt="" title="" width="359" height="14"> </p>
</div>
<p>can in principle be reached with just two steps of “unrolled” proof:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg10.png" alt="" title="" width="441" height="41"> </p>
</div>
<p>And in this particular case, if we use <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> and then unroll the resulting proof we also get a proof of length 3—but it goes through a different intermediate expression:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025shorterimg11.png" alt="" title="" width="542" height="41"> </p>
</div>
<p>As it happens, this intermediate expression is also reached in the entailment cone that we get by starting from our “output” expression and then applying two bisubsitutions:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025shorterEimg12-min.png" alt="" title="" width="528" height="417"> </p>
</div>
<h2 id="what-actually-is-the--models-and-the-proof">What Actually Is the “·”? Models and the Proof</h2>
<p>We can think of logic (or Boolean algebra) as being associated with a certain collection of theorems. And what our axiom does is to provide something from which all theorems of logic (and nothing but theorems of logic) can be derived. At some level, we can think of it as just being about symbolic expressions. But in our effort to understand what’s going on—say with our proof—it’s sometimes useful to ask how we can “concretely” interpret these expressions.</p>
<p>For example, we might ask what the · operator actually is. And what kinds of things can our symbolic variables be? In effect we’re asking for what in model theory are called <a href="https://www.wolframscience.com/metamathematics/the-model-theoretic-perspective/">“models” of our axiom system</a>. And in aligning with logic the most obvious model to discuss is one in which variables can be <tt><a href="http://reference.wolfram.com/language/ref/True.html">True</a></tt> or <tt><a href="http://reference.wolfram.com/language/ref/False.html">False</a></tt>, and the · represents either the logical operator <tt><a href="http://reference.wolfram.com/language/ref/Nand.html">Nand</a></tt> or the logical operator <tt><a href="http://reference.wolfram.com/language/ref/Nor.html">Nor</a></tt>.</p>
<p>The truth table, say for <tt>Nand</tt>, is:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025actuallyimg1.png" alt="" title="" width="156" height="152"> </p>
</div>
<p>And as expected, with this model for ·, we can confirm that our original axiom holds:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025actuallyimg2.png" alt="" title="" width="379" height="274"> </p>
</div>
<p>In general, though, our original axiom allows two size-2 models (that we can interpret as <tt>Nand</tt> and <tt>Nor</tt>):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025actuallyimg4.png" alt="" title="" width="98" height="52"> </p>
</div>
<p>It allows no size-3 models, and in fact in general <a href="https://www.wolframscience.com/nks/notes-12-9--operators-on-sets/">allows only models of size 2<sup><em>n</em></sup></a>; for example, for size 4 its models are:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025actuallyimg6.png" alt="" title="" width="551" height="210"> </p>
</div>
<p>So what about <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>? What models does it allow? For size 2, it’s all 8 possible models with symmetric “multiplication tables”:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01082025actuallyimg7.png" alt="" title="" width="467" height="52"> </p>
</div>
<p>But the crucial point is that the 2 models for our original axiom system are part of these. In other words, at least for size-2 models, satisfying the original axiom system implies satisfying <nobr><em>a</em> · <em>b</em> = <em>b</em> · <em>a</em>.</nobr></p>
<p>And indeed any lemma derived from our axiom system must allow the models associated with our original axiom system. But it may also allow more—and sometimes many more. So here’s a map of our proof, showing how many models (out of 16 possible) each lemma allows:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg5.png" alt="" title="" width="329" height="674"> </p>
</div>
<p>Here are the results for size-3 models:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01092025KDCLOUDimg6.png" alt="" title="" width="478" height="972"> </p>
</div>
<p>And, once again, these look complicated. We can think of models as defining—in some sense—<a href="https://www.wolframscience.com/nks/p804--implications-for-mathematics-and-its-foundations/">what lemmas are “about”</a>. So, for example, our original axiom is “about” <tt>Nand</tt> and <tt>Nor</tt>. The lemma <em>a</em> · <em>b</em> = <em>b</em> · <em>a</em> is “about” symmetric functions. And so on. And we might have hoped that we could gain some understanding of our proof by looking at how different lemmas that occur in it “sculpt” what is being talked about. But in fact we just seem to end up with complicated descriptions of sets that don’t seem to have any obvious relationship with each other.</p>
<h2 id="what-about-a-higher-level-abstraction">What about a Higher-Level Abstraction?</h2>
<p>If there’s one thing that stands out about our proof—and the analysis we’ve given of it here—it’s how fiddly and “in the weeds” it seems to be. But is that because we’re missing some big picture? Is there actually a more abstract way of discussing things, that gets to our result without having to go through all the details? </p>
<p>In the history of mathematics many of the most important themes have been precisely about finding such higher-level abstractions. We could start from the <a href="https://www.wolframscience.com/nks/notes-12-9--groups-and-axioms/">explicit symbolic axioms</a></p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025abstractionimg1.png" alt="" title="" width="120" height="59"> </p>
</div>
<p>or even</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025abstractionimg2.png" alt="" title="" width="165" height="22"> </p>
</div>
<p>and start building up theorems much as we’ve done here. Or we could recognize that these are axioms for group theory, and then start using the abstract ideas of group theory to derive our theorems.</p>
<p>So is there some higher-level version of what we’re discussing here? Remember that the issue is not about the overall structure of Boolean algebra; rather it’s about the more metamathematical question of how one can prove that all of Boolean algebra can be generated from the axiom:</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025abstractionimg3.png" alt="" title="" width="183" height="14"> </p>
</div>
<p>In the last few sections we’ve tried a few semi-empirical approaches to finding higher-level representations. But they haven’t gotten very far. And to get further we’re probably going to need a serious new idea.</p>
<p>And, if history is a guide, we’re going to need to come up with an abstraction that somehow “goes outside of the system” before “coming back”. It’s like trying to figure out the real roots of a cubic equation, and realizing that the best way to do this is to introduce complex numbers, even though the imaginary parts will cancel at the end. </p>
<p>In the direct exploration of our proof, it feels as if the intermediate lemmas we generate “wander off into the wilds of metamathematical space” before coming back to establish our final result. And if we were using a higher-level abstraction, we’d instead be “wandering off” into the space of that abstraction. But what we might hope is that—at least with the concepts we would use in discussing that abstraction—the path that would be involved would be “short enough to be accessible to human understanding”.</p>
<p>Will we be able to find such an abstraction? It’s a subtle question. Because in effect it asks whether we can reduce the computational effort needed for the proof—or, in other words, whether we can find a pocket of computational reducibility in what in general will be a computationally irreducible process. But it’s not a question that can really be answered just for our specific proof on it own. After all, our “abstraction” could in principle just involve introducing a primitive that represents our whole proof or a large part of it. But to make it what we can think of as a real abstraction we need something that spans many different specific examples—and, in our case, likely many axiomatic systems or symbolic proofs.</p>
<p>So is such an abstraction possible? In the history of mathematics the experience has been that after enough time (often measured in centuries) has passed, abstractions tend to be found. But at some level this has been self fulfilling. Because the areas that are considered to have remained “interesting for mathematics” tend to be just those where general abstractions have in fact been found. </p>
<p>In <a href="https://writings.stephenwolfram.com/2021/09/charting-a-course-for-complexity-metamodeling-ruliology-and-more/">ruliology</a>, though, the typical experience has been different. Because there it’s been routine to <a href="https://www.wolframscience.com/nks/">sample the computational universe of possible simple programs</a> and encounter computational irreducibility. In the end it’s still inevitable that among the computational irreducibility there must be pockets of computational reducibility. But the issue is that these pockets of computational reducibility may not involve features of our system that we care about. </p>
<p>So is a proof of the kind we’re discussing here more like ruliology, or more like “typical mathematics”? Insofar as it’s a mathematical-style proof of a mathematical statement it feels more like typical mathematics. But insofar as it’s something found by the computational process of automated theorem proving it perhaps seems more ruliology. </p>
<p>But what might a higher-level abstraction for it look like? Figuring that out is probably tantamount to finding the abstraction. But perhaps one can at least expect that in some ways it will be metamathematical, and more about the structure and character of proofs than about their content. Perhaps it will be something related to the framework of higher category theory, or some form of meta-algebra. But as of now, we really don’t know—and we can’t even say that such an abstraction with any degree of generality is possible.</p>
<h2 id="llms-to-the-rescue">LLMs to the Rescue?</h2>
<p>The unexpected success of LLMs in language generation and related tasks has led to the idea that perhaps eventually <a href="https://writings.stephenwolfram.com/2024/03/can-ai-solve-science/">systems like LLMs will be able to “do everything”</a>—including for example math. We already know—not least thanks to Wolfram Language—that <a href="https://www.wolfram.com/mathematica/">lots of math can be done computationally</a>. But often the computations are hard—and, as in the example of the proof we’re discussing here, incomprehensible to humans. So the question really is: can LLMs “humanize” what has to be done in math, turning everything into a human-accessible narrative? And here our proof seems like an excellent—if challenging—test case. </p>
<p>But what happens if we just ask a current LLM to generate the proof from scratch? It’s not a good picture. Very often the LLM will eagerly generate a proof, but it’ll be completely wrong, often with the same kind of mistakes that a student somewhat out of their depth might make. Here’s a typical response where an LLM simply assumes that the · operator is associative (which it isn’t in Boolean algebra) then produces a proof that on first blush looks at least vaguely plausible, but is in fact completely wrong:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/01/sw01072025rescueimg1.png" alt="Inadequate LLM proof" title="Inadequate LLM proof" width="611" height="489"></p>
<p>Coming up with an explanation for what went wrong is basically an exercise in “LLM psychology”. But in a first approximation one might say the following. LLMs are trained to “fill in what’s typical”, where “typical” is defined by what appears in the training set. But (absent some recent Wolfram Language and <a href="https://www.wolframalpha.com/">Wolfram|Alpha</a> based technology of ours) what’s been available as a training set has been human-generated mathematical texts, where, yes, operators are often associative, and typical proofs are fairly short. And in the “psychology of LLMs” an LLM is much more likely to “do what’s typical” than to “rigorously follow the rules”. </p>
<p>If you press the LLM harder, then it might just “abdicate”, and suggest using the <a href="https://writings.stephenwolfram.com/2023/03/chatgpt-gets-its-wolfram-superpowers/">Wolfram Language as a tool</a> to generate the proof. So what happens if we do that, then feed the finished proof to the LLM and ask it to explain? Well, typically it just does what LLMs do so well, and writes an essay:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/01/sw01072025rescueimg2.png" alt="LLM proof essay" title="LLM proof essay" width="614" height="516"></p>
<p>So, yes, it does fine in “generally framing the problem”. But not on the details. And if you press it for details, it’ll typically eventually just start parroting what it was given as input. </p>
<p>How else might we try to get the LLM to help? One thing I’ve certainly wondered is how the lemmas in the proof relate to known theorems—perhaps in quite different areas of mathematics. It’s something one might imagine one would be able to answer by searching the literature of mathematics. But, for example, textual search won’t be sufficient: it has to be some form of <a href="https://writings.stephenwolfram.com/2024/07/yet-more-new-ideas-and-new-functions-launching-version-14-1-of-wolfram-language-mathematica/#vector-databases-and-semantic-search">semantic search</a> based on the meaning or symbolic structure of lemmas, not their (fairly arbitrary) textual presentation. A vector database might be all one needs, but one can certainly ask an LLM too:</p>
<p><img src="https://content.wolfram.com/sites/43/2025/01/sw01072025rescueimg3.png" alt="LLM semantic search results" title="LLM semantic search results" width="619" height="485"></p>
<p>It’s not extremely helpful, though, charmingly, it correctly identifies the source of our original axiom. I’ve tried similar queries for our whole set of lemmas across a variety of LLMs, with a variety of RAG systems. Often the LLM will talk about an interpretation for some lemma—but the lemma isn’t actual present in our proof. But occasionally the LLM will mention possible connections (“band theory”; “left self-distributive operations in quandles”; “Moufang loops”)—though so far none have seemed to quite hit the mark.</p>
<p>And perhaps this failure is itself actually a result—telling us that the lemmas that show up in our proof really are, in effect, out in the wilds of metamathematical space, probing places that haven’t ever been seriously visited before by human mathematics.</p>
<p>But beyond LLMs, what about more general machine learning and neural net approaches? Could we imagine <a href="https://writings.stephenwolfram.com/2024/03/can-ai-solve-science/#science-as-narrative">using a neural net as a probe to find “exploitable regularities”</a> in our proof? It’s certainly possible, but I suspect that the systematic algorithmic methods we’ve already discussed for finding optimal notations, popular lemmas, etc. will tend to do better. I suppose it would be one thing if our systematic methods had failed to even find a proof. Then we might have wanted something like neural nets to try to guess the right paths to follow, etc. But as it is, our systematic methods rather efficiently do manage to successfully find a proof. </p>
<p>Of course, there’s still the issue that we’re discussing here that the proof is very “non-human”. And perhaps we could imagine that neural nets, etc.—especially when trained on existing human knowledge—could be used to “form concepts” that would help us humans to understand the proof. </p>
<p>We can get at least a rough analogy for how this might work by looking at <a href="https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/">visual images produced by a generative AI system</a> trained from billions of human-selected images. There’s a concept (like “a cube”) that exists somewhere in the feature space of possible images. But “around” that concept are other things—<a href="https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/#the-notion-of-interconcept-space">“out in interconcept space”</a>—that we don’t (at least yet) explicitly have words for:</p>
<div>
<p><img src="https://content.wolfram.com/sites/43/2025/01/sw01072025rescueimg4.png" alt="Interconcept space" title="Interconcept space" width="494" height="494"></p>
</div>
<p>And it’ll presumably be similar for math, though harder to represent in something like a visual way. There’ll be existing math concepts. But these will be embedded in a vast domain of “mathematical interconcept space” that we humans haven’t yet “colonized”. And what we can imagine is that—perhaps with the help of neural nets, etc.—we can identify a limited number of “points in interconcept space” that we can introduce as new concepts that will, for example, provide useful “waypoints” in understanding our proof.</p>
<h2 id="but-why-is-the-theorem-true">But Why Is the Theorem True?</h2>
<p>It’s a common human urge to think that anything that’s true must be true for a reason. But what about our theorem? Why is it true? Well, we’ve seen a proof. But somehow that doesn’t seem satisfactory. We want “an explanation we can understand”. But we know that in general we can’t always expect to get one.</p>
<p>It’s a fundamental implication of computational irreducibility that things can happen where the only way to “see how they happen” is just to “watch them happen”; there’s no way to “compress the explanation”.</p>
<p>Consider the following patterns. They’re all generated by cellular automata. And all <a href="https://writings.stephenwolfram.com/2024/05/why-does-biological-evolution-work-a-minimal-model-for-biological-evolution-and-other-adaptive-processes/">live exactly 100 steps before dying out</a>. But why?</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025theoremimg1-1.png" alt="" title="" width="597" height="509"> </p>
</div>
<p>In a few cases it seems like we can perhaps at least begin to imagine “narratively describing” a mechanism. But most of the time all we can say is basically that they “live 100 steps because they do”. </p>
<p>It’s a quintessential consequence of computational irreducibility. It might not be what we’d expect, or hope for. But it’s reality in the computational universe. And it seems very likely that our theorem—and its proof—is like this too. The theorem in effect “just happens to be true”—and if you run the steps in the proof (or find the appropriate path in the entailment cone) you’ll find that it is. But there’s no “narrative explanation”. No “understanding of why it’s true”. </p>
<h2 id="intuition-and-automated-theorem-proving">Intuition and Automated Theorem Proving</h2>
<p>We’ve been talking a lot about the proof of our theorem. But where did the theorem to prove come from in the first place? Its immediate origin was an <a href="https://www.wolframscience.com/nks/notes-12-9--searching-for-logic-axioms/">exhaustive search I did of simple axiom systems</a>, filtering for ones that could conceivably generate Boolean algebra, followed by testing each of the candidates using automated theorem proving. </p>
<p>But how did I even get the idea of searching for a simple axiom system for Boolean algebra? Based on the axiom systems for Boolean algebra known before—and the historical difficulty of finding them—one might have concluded that it was quite hopeless to find an axiom system for Boolean algebra by exhaustive search. But by 2000 I had nearly two decades of experience in exploring the computational universe—and I was well used to the <a href="https://www.wolframscience.com/nks/chap-2--the-crucial-experiment/">remarkable phenomenon</a> that even very simple computational rules can lead to behavior of great complexity. So the result was that when I came to think about axiom systems and the foundations of mathematics my intuition led me to imagine that perhaps the simplest axiom system for something like Boolean algebra might be simple enough to exhaustively search for.</p>
<p>And indeed discovering the axiom system we’ve discussed here helped further expand and deepen my intuition about the consequences of simple rules. But what about the proof? What intuition might one get from the proof as we now know it, and as we’ve discussed here?</p>
<p>There’s much intuition to be got from observing the world as it is. But for nearly half a century I’ve had another crucial source of intuition: observing the computational universe—and doing computational experiments. I was recently reflecting on how I came to start developing intuition in this way. And what it might mean for intuition I could now develop from things like automated theorem proving and AI.</p>
<p>Back in the mid-1970s <a href="https://www.stephenwolfram.com/publications/academic/particle-physics">my efforts in particle physics</a> led me to start using computers to do not just numerical, but <a href="https://writings.stephenwolfram.com/2013/06/there-was-a-time-before-mathematica/">also algebraic computations</a>. In numerical computations it was usual to just get a few numbers out, that perhaps one could plot to make a curve. But in algebraic computations one instead got out formulas—and <a href="https://content.wolfram.com/sw-publications/2020/07/effective-coupling-qcd.pdf" target="_blank" rel="noopener">often very ornate ones full of structure and detail</a>. And for me it was routine to get not just one formula, but many. And looking at these formulas I started to develop intuition about them. What functions would they involve? What algebraic form would they take? What kind of numbers would they involve? </p>
<p>I don’t think I ever consciously realized that I was developing a new kind of computationally based intuition. But I soon began to take it for granted. And when—at the beginning of the 1980s—<a href="https://www.wolframscience.com/nks/chap-1--the-foundations-for-a-new-kind-of-science#sect-1-4--the-personal-story-of-the-science-in-this-book">I started to explore the consequences of simple abstract systems</a> like cellular automata it was natural to expect that I would get intuition from just “seeing” how they behaved. And here there was also another important element. Because part of the reason I concentrated on cellular automata was precisely because one could readily visualize their behavior on a computer. </p>
<p>I don’t think I would have learned much if I’d just been printing out “numerical summaries” of what cellular automata do. But as it was, I was seeing their behavior in full detail. And—surprising though what I saw was—I was soon able to start getting an intuition for what could happen. It wasn’t a matter of knowing what the value of every cell would be. But I started doing things like identifying four general classes of cellular automata, and then recognizing the phenomenon of computational irreducibility. </p>
<p>By the 1990s I was much more broadly exploring the computational universe—always trying to see what could happen there. And in almost all cases it was a story of defining simple rules, then running them, and making an explicit step-by-step visualization of what they do—and thereby in effect “seeing computation in action”.</p>
<p>In recent years—spurred by our <a href="https://www.wolframphysics.org/" target="_blank" rel="noopener">Physics Project</a>—I’ve increasingly explored not just computational processes, but also <a href="https://writings.stephenwolfram.com/2021/09/multicomputation-a-fourth-paradigm-for-theoretical-science/">multicomputational ones</a>. And although it’s more difficult I’ve made every effort to visualize the behavior of multiway systems—and to get intuition about what they do. </p>
<p>But what about automated theorem proving? In effect, automated theorem proving is about finding a particular path in a multiway system that leads to a theorem we want. We’re not getting to see “complete behavior”; we’re in effect just seeing one particular “solution” for how to prove a theorem. </p>
<p>And after one’s seen many examples, the challenge once again is to develop intuition. And that’s a large part of what I’ve been trying to do here. It’s crucial, I think, to have some way to visualize what’s happening—in effect because visual input is the most efficient way to get information into our brains. And while the visualizations we’ve developed here aren’t as direct and complete as, say, for cellular automaton evolution, I think they begin to give some overall sense of our proof—and other proofs like it.</p>
<p>In studying simple programs like cellular automata, the intuition I developed led me to things like my <a href="https://www.wolframscience.com/nks/chap-6--starting-from-randomness#sect-6-2--four-classes-of-behavior">classification of cellular automaton behavior</a>, as well as to bigger ideas like the <a href="https://www.wolframscience.com/nks/chap-12--the-principle-of-computational-equivalence/">Principle of Computational Equivalence</a> and computational irreducibility. So having now exposed myself to automated theorem proving as I exposed myself to algebraic computation and the running of simple rules in the past, what general principles might I begin to see? And might they, for example, somehow make the fact that our proof works ultimately seem “obvious”?</p>
<p>In some ways yes, but in other ways no. Much as with simple programs, there are axiom systems so simple that, for example, the <a href="https://www.wolframscience.com/metamathematics/axiom-systems-in-the-wild/">multiway systems they generate are highly regular</a>. But beyond a low threshold, it’s common to get very complicated—and in many ways seemingly random—multiway system structures. Typically an infinite number of lemmas are generated, with little or no obvious regularity in their forms.</p>
<p>And one can expect that—following the ideas of universal computation—it’ll typically be possible to encode in any one such multiway system the behavior of any other multiway system. In terms of axioms what one’s saying is that if one sets up the right translation between theorems, one will be able to use any one such axiom system to generate the theorems of any other. But the issue is that the translation will often make major changes to the structure of the theorems, and in effect define not just a “mathematical translation” (like between geometry and algebra) but a <a href="https://www.wolframscience.com/metamathematics/uniformity-and-motion-in-metamathematical-space/#p-146">metamathematical one (as one would need to get from Peano arithmetic to set theory)</a>. </p>
<p>And what this means is that it isn’t surprising that even a very simple axiom system can generate a complicated set of possible lemmas. But knowing this doesn’t immediately tell one whether those lemmas will align with some particular existing theory—like Boolean algebra. And in a sense that’s a much more detailed question.</p>
<p>At some metamathematical level it might not be a natural question. But at a “mathematical level” it is. And it’s what we have to address in connection with the theorem—and proof—we’re discussing here. Many aspects of the overall form and properties of the proof will be quite generic, and won’t depend on the particulars of the axiom system we’re using. But some will. And quite what intuition we may be able to get about these isn’t clear. And perhaps it’ll necessarily be fragmented and specific—in effect responding to the presence of computational irreducibility.</p>
<p>It’s perhaps worth commenting that LLMs—and machine learning in general—represent another potential source of intuition. That intuition may well be more about the general features of us as observers and thinkers. But such intuition is potentially critical in framing just what we can experience, not only in the natural world, but also in the mathematical and metamathematical worlds. And perhaps the apparent impotence of LLMs when faced with the proof we’ve been discussing already tells us something significant about the nature of “mathematical observers” like us.</p>
<h2 id="so-what-does-it-mean-for-the-future-of-mathematics">So What Does It Mean for the Future of Mathematics?</h2>
<p>Let’s say we never manage to “humanize” the proof we’ve been discussing here. Then in effect we’ll end up with a “black-box theorem”—that we can be sure is true—but we’ll never know quite how or why. So what would that mean for mathematics?</p>
<p>Traditionally, mathematics has tended to operate in a “white box” kind of way, trying to build narrative and understanding along with “facts”. And in this respect it’s very different from natural science. Because in natural science much of our knowledge has traditionally been empirical—derived from observing the world or experimenting on it—and without any certainty that we can “understand its origins”. </p>
<p>Automated theorem proving of the kind we’re discussing here—or, for that matter, pretty much any exploratory computational experimentation—aligns mathematics much more with natural science, deriving what’s true without an expectation of having a narrative explanation of why. </p>
<p>Could one imagine practicing mathematics that way? One’s already to some extent following such a path as soon as one introduces axiom systems to base one’s mathematics on. Where do the axiom systems come from? In <a href="https://writings.stephenwolfram.com/2020/09/the-empirical-metamathematics-of-euclid-and-beyond/">the time of Euclid</a> perhaps they were thought of as an idealization of nature. But in more modern times they are realistically much more the result of human choice and human aesthetics.</p>
<p>So let’s say we determine (given a particular axiom system) that some black-box theorem is true. Well, then we can just add it, just as we could another axiom. Maybe one day it’ll be possible to prove <a href="https://www.wolframscience.com/nks/p765--undecidability-and-intractability/">P≠NP</a> or the <a href="https://writings.stephenwolfram.com/2021/03/after-100-years-can-we-finally-crack-posts-problem-of-tag-a-story-of-computational-irreducibility-and-more/#classic-unsolved">Riemann Hypothesis</a> from existing axioms of mathematics (if they don’t in fact turn out to be independent). And—black box or not—we can expect to add them to what we assume in subsequent mathematics we do, much as they’re routinely added right now, even though their status isn’t yet known. </p>
<p>But it’s one thing to add one or two “black-box theorems”. But what happens when black-box theorems—that we can think of as “experimentally determined”—start to dominate the landscape of mathematics? </p>
<p>Well, then mathematics will take on much more of the character of ruliology—or of an experimental science. When it comes to the applications of mathematics, this probably won’t make much difference, except that in effect mathematics will be able to become much more powerful. But the “inner experience” of mathematics will be quite different—and much less “human”.</p>
<p>If one indeed starts from axioms, it’s not at the outset obvious why everything in mathematics should not be mired in the kind of alien-seeming metamathematical complexity that we’ve encountered in the discussion of our proof here. But <a href="https://www.wolframscience.com/metamathematics/mathematics-and-physics-have-the-same-foundations/">what I’ve argued elsewhere</a> is that the fact that in our experience of doing mathematics it’s not is a reflection of how “mathematical observers like us” sample the raw metamathematical structure generated by axioms (or ultimately by the <a href="https://www.wolframscience.com/metamathematics/going-below-axiomatic-mathematics/">subaxiomatic structure of the ruliad</a>). </p>
<p>The physics analogy I’ve used is that we succeed in doing mathematics at a “fluid dynamics level”, far above the detailed “molecular dynamics level” of things like the proof we’ve discussed here. Yes, we can ask questions—like ones about the structure of our proof—that probe the axiomatic “molecular dynamics level”. But it’s an important fact that in doing what we normally think of as mathematics we almost never have to; there’s a coherent way to operate purely at the “fluid dynamics level”.</p>
<p>Is it useful to “dip down” to the molecular dynamics? Definitely yes, because that’s where we can readily do computations—like those in our proof, or in general those going on in the internals of the Wolfram Language. But a key idea in the design of the Wolfram Language is to provide a computational language that can express concepts at a humanized “fluid dynamics” level—in effect bridging between the way humans can think and understand things, and the way raw computation can be done with them.</p>
<p>And it’s notable that while we’ve had great success over the years in defining “human-accessible” high-level representations for what amount to the “inputs” and “outputs” of computations, that’s been much less true of the “ongoing processes” of computation—or, for example, of the innards of proofs. </p>
<p>Is there a good “human-level” way to represent proofs? If the proofs are short, it’s not too difficult (and the <a href="https://www.wolframalpha.com/pro/step-by-step-math-solver">step-by-step solutions technology of Wolfram|Alpha</a> provides a good large-scale example of what can be done). But—as we’ve discussed—computational irreducibility implies that some proofs will inevitably be long. </p>
<p>If they’re not too long, then at least some parts of them might be constructed by human effort, say in a system like a proof assistant. But as soon as there’s much automation (whether with automated theorem proving or with LLMs) it’s basically inevitable that one will end up with things that at least approach what we’ve seen with the proof we’re discussing here. </p>
<p>What can then be done? Well, that’s the challenge. Maybe there is some way to simplify, abstract or otherwise “humanize” the proof we’ve been discussing. But I rather doubt it. I think this is likely one of those cases where we inevitably find ourselves face to face with computational irreducibility. </p>
<p>And, yes, there’s important science (particularly ruliology) to do on the structures we see. But it’s not mathematics as it’s traditionally been practiced. But that’s not to say that the results that come out of things like our proof won’t be useful for mathematics. They will be. But they make mathematics more like an experimental science—where what matters most is in effect the input and output rather than a “publishable” or human-readable derivation in between. And where the key issue in making progress is less in the innards of derivations than in defining clear computational ways to express input and output. Or, in effect, in capturing “human-level mathematics” in the primitives and structure of <a href="https://writings.stephenwolfram.com/2019/05/what-weve-built-is-a-computational-language-and-thats-very-important/">computational language</a>. </p>
<h2 id="appendix-what-about-a-different-theorem-proving-system">Appendix: What about a Different Theorem Proving System?</h2>
<p>The proof we’ve been discussing here was created using <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> in the Wolfram Language. But what if we were to use a different automated theorem proving system? How different would the results be? In the spectrum of things that automated theorem proving systems do, our proof here is on the difficult end. And many existing automated theorem proving systems don’t manage to do it all. But some of the stronger ones do. And in the end—despite their different internal algorithms and heuristics—it’s remarkable how similar the results they give are to those from the Wolfram Language <tt>FindEquationalProof</tt> (differences in the way lemmas vs. inference steps, etc. are identified make detailed quantitative comparisons difficult):</p>
<div>
<p><img loading="lazy" src="https://content.wolfram.com/sites/43/2025/01/sw01072025appendiximg1.png" alt="" title="" width="650" height="433"> </p>
</div>
<h2 id="thanks">Thanks</h2>
<p>Thanks to Nik Murzin of the <a href="https://wolframinstitute.org/" target="_blank" rel="noopener">Wolfram Institute</a> for his extensive help as part of the Wolfram Institute Empirical Metamathematics Project. Also Roger Germundsson, Sergio Sandoval, Adam Strzebonski, Michael Trott, Liubov Tupikina, James Wiles and Carlos Zapata for input. Thanks to Arnim Buch and Thomas Hillenbrand for their work in the 1990s on Waldmeister which is now part of <tt><a href="http://reference.wolfram.com/language/ref/FindEquationalProof.html">FindEquationalProof</a></tt> (also to Jonathan Gorard for his 2017 work on the interface for <tt>FindEquationalProof)</tt>. I was first seriously introduced to automated theorem proving in the late 1980s by Dana Scott, and have interacted with many people about it over the years, including Richard Assar, Bruno Buchberger, David Hillman, Norm Megill, Todd Rowland and Matthew Szudzik. (I’ve also interacted with many people about proof assistant, proof presentation and proof verification systems, both recently and in the past.)</p>
        </div></div>]]></description>
        </item>
    </channel>
</rss>