<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Tue, 11 Jun 2024 23:30:01 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[Elon Musk drops suit against OpenAI and Sam Altman (170 pts)]]></title>
            <link>https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html</link>
            <guid>40651203</guid>
            <pubDate>Tue, 11 Jun 2024 20:38:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html">https://www.cnbc.com/2024/06/11/elon-musk-drops-suit-against-openai-and-sam-altman.html</a>, See on <a href="https://news.ycombinator.com/item?id=40651203">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="RegularArticle-ArticleBody-5" data-module="ArticleBody" data-test="articleBody-2" data-analytics="RegularArticle-articleBody-5-2"><div id="ArticleBody-InlineImage-107399197" data-test="InlineImage"><p>In this photo illustration, the logo of 'OpenAI' is displayed on a mobile phone screen in front of a computer screen displaying the photographs of Elon Musk and Sam Altman in Ankara, Turkiye on March 14, 2024.</p><p>Muhammed Selim Korkutata | Anadolu | Getty Images</p></div><div><p>Elon Musk on Tuesday withdrew his lawsuit against OpenAI and two of the company's co-founders, Sam Altman and Greg Brockman, in California state court. Musk's decision to file to dismiss the suit came just one day after he <a href="https://www.cnbc.com/2024/06/10/elon-musk-to-ban-apple-devices-from-his-companies-over-openai-deal.html">publicly criticized OpenAI</a> and its new partnership with Apple.</p><p>The case was dismissed without prejudice, according to a court filing obtained by CNBC.</p><p>In February, Musk had filed a lawsuit against OpenAI, Altman and Brockman — the current CEO and president of OpenAI, respectively — for breach of contract and fiduciary duty.</p><p>A hearing was scheduled for Wednesday in San Francisco, in which the judge was going to consider whether the case should be dismissed as requested by the defendants.</p><p>Experts <a href="https://www.cnbc.com/2024/03/05/read-the-complaint-in-elon-musk-v-sam-altman-greg-brockman-openai.html">told CNBC in March</a> that the case was built on a questionable legal foundation, because the contract at the heart of the suit was not a formal written agreement that was signed by all parties involved.</p><p>Rather, Musk had alleged that the early OpenAI team had set out to develop&nbsp;<a href="https://www.cnbc.com/2024/03/05/read-the-complaint-in-elon-musk-v-sam-altman-greg-brockman-openai.html">artificial general intelligence</a>, or AGI, "for the benefit of humanity," but that the project has been transformed into a for-profit entity that's largely controlled by principal shareholder&nbsp;<a href="https://www.cnbc.com/quotes/MSFT/">Microsoft</a>.</p><p>Musk had used much of the 35-page complaint (plus attached exhibits) he filed in March to remind the world of his position in the creation of a company that's since become one of the hottest startups on the planet, (OpenAI ranked first on CNBC's&nbsp;<a href="https://www.cnbc.com/2023/05/09/openai-disruptor-50.html">Disruptor 50 list</a>&nbsp;in 2023) thanks largely to the viral spread of ChatGPT.</p><p>"It's certainly a good advertisement for the benefit of Elon Musk," Kevin O'Brien, partner at Ford O'Brien Landy LLP and former assistant U.S. attorney, told CNBC at the time. "I'm not sure about the legal part though."</p><p>Last year, Musk debuted his own AI startup and OpenAI competitor, xAI, which last month <a href="https://x.ai/blog/series-b" target="_blank">announced</a> a $6 billion Series B funding round. Investors included Andreessen Horowitz, Sequoia Capital and Fidelity Management &amp; Research Company. </p><p>X.AI seeks to "understand the true nature of the universe," according to its website. Last year, X.AI released a chatbot called Grok, which the company says is modeled after "The Hitchhiker's Guide to the Galaxy." The chatbot debuted with two months of training and has real-time knowledge of the internet, the company claims.</p><p>Representatives for Musk and Altman did not immediately respond to a request for comment. </p><p>—<em>CNBC's Lora Kolodny contributed to this report.</em></p><p><em>Correction: The lawsuit was filed in February. An earlier version of this story misstated the month.</em></p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Swift Static Linux SDK (144 pts)]]></title>
            <link>https://www.swift.org/documentation/articles/static-linux-getting-started.html</link>
            <guid>40651054</guid>
            <pubDate>Tue, 11 Jun 2024 20:25:18 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.swift.org/documentation/articles/static-linux-getting-started.html">https://www.swift.org/documentation/articles/static-linux-getting-started.html</a>, See on <a href="https://news.ycombinator.com/item?id=40651054">Hacker News</a></p>
<div id="readability-page-1" class="page"><div role="main">
  <article class="page">
  
    
      <header>
        <h2>Getting Started with the Static Linux SDK</h2>
      </header>
    
  

  <p>It’s well known that Swift can be used to build software for Apple
platforms such as macOS or iOS, but Swift is also supported on other
platforms, including Linux and Windows.</p>

<p>Building for Linux is especially interesting because, historically,
Linux programs written in Swift needed to ensure that a copy of the
Swift runtime—and all of its dependencies—was installed on the
target system.  Additionally, a program built for a particular
distribution, or even a particular major version of a particular
distribution, would not necessarily run on any other distribution or
in some cases even on a different major version of the same
distribution.</p>

<p>The Swift Static Linux SDK solves both of these problems by allowing
you to build your program as a <em>fully statically linked</em> executable,
with no external dependencies at all (not even the C library), which
means that it will run on <em>any</em> Linux distribution as the only thing
it depends on is the Linux system call interface.</p>

<p>Additionally, the Static Linux SDK can be used from any platform
supported by the Swift compiler and package manager; this means that
you can develop and test your program on macOS before building and
deploying it to a Linux-based server, whether running locally or
somewhere in the cloud.</p>



<p><em>Linking</em> is the process of taking different pieces of a computer
program and wiring up any references between those pieces.  For
<em>static</em> linking, generally speaking those pieces are <em>object files</em>,
or <em>static libraries</em> (which are really just collections of object
files).</p>

<p>For <em>dynamic</em> linking, the pieces are <em>executables</em> and <em>dynamic
libraries</em> (aka dylibs, shared objects, or DLLs).</p>

<p>There are two key differences between dynamic and static linking:</p>

<ul>
  <li>
    <p>The time at which linking takes place.  Static linking happens when
you build your program; dynamic linking happens at runtime.</p>
  </li>
  <li>
    <p>The fact that a static library (or <em>archive</em>) is really a collection
of individual object files, whereas a dynamic library is monolithic.</p>
  </li>
</ul>

<p>The latter is important because traditionally, the static linker will
include every object explicitly listed on its command line, but it
will <em>only</em> include an object from a static library if doing so lets
it resolve an unresolved symbolic reference.  If you statically link
against a library that you do not actually use, a traditional static
linker will completely discard that library and not include any code
from it in your final binary.</p>

<p>In practice, things can be more complicated—the static linker may
actually work on the basis of individual <em>sections</em> or <em>atoms</em> from
your object files, so it may in fact be able to discard individual
functions or pieces of data rather than just whole objects.</p>

<h3 id="pros-and-cons-of-static-linking">Pros and Cons of Static Linking <a title="Permalink for Pros and Cons of Static Linking section" href="#pros-and-cons-of-static-linking">
            <!--?xml version="1.0" encoding="utf-8"?--> 
          </a></h3>

<p>Pros of static linking:</p>

<ul>
  <li>
    <p>No runtime overhead.</p>
  </li>
  <li>
    <p>Only include code from libraries that is actually needed.</p>
  </li>
  <li>
    <p>No need for separately installed dynamic libraries.</p>
  </li>
  <li>
    <p>No versioning issues at runtime.</p>
  </li>
</ul>

<p>Cons of static linking:</p>

<ul>
  <li>
    <p>Programs cannot share code (higher overall memory usage).</p>
  </li>
  <li>
    <p>No way to update dependencies without rebuilding program.</p>
  </li>
  <li>
    <p>Larger executables (though this can be offset by not having to
install separate dynamic libraries).</p>
  </li>
</ul>

<p>On Linux in particular, it’s also possible to use static linking to
completely eliminate dependencies on system libraries supplied by the
distribution, resulting in executables that work on any distribution
and can be installed by simply copying.</p>



<p>Before you start, it’s important to note:</p>

<ul>
  <li>
    <p>You will need to <a href="https://www.swift.org/install/">install an Open Source toolchain from
swift.org</a>.</p>
  </li>
  <li>
    <p>You cannot use the toolchain provided with Xcode to build programs
using the SDK.</p>
  </li>
  <li>
    <p>If you are using macOS, you will also need to ensure that you use
the Swift compiler from this toolchain by <a href="https://www.swift.org/install/macos/package_installer/">following the
instructions
here</a>.</p>
  </li>
  <li>
    <p>The toolchain must match the version of the Static Linux SDK that
you install.  The Static Linux SDK includes the corresponding Swift
version in its filename to help identify the correct version of the
SDK.</p>
  </li>
</ul>

<p>Once that is out of the way, actually installing the Static Linux SDK
is easy; at a prompt, enter</p>

<div><pre><code><span>$</span><span> </span>swift sdk <span>install</span> &lt;URL-or-filename-here&gt;
</code></pre></div>

<p>giving the URL or filename at which the SDK can be found.</p>

<p>For instance, assuming you have installed the
<code>swift-6.0-DEVELOPMENT-SNAPSHOT-2024-06-06-a</code> toolchain, you would
need to enter</p>

<div><pre><code><span>$</span><span> </span>swift sdk <span>install </span>https://download.swift.org/development/static-sdk/swift-DEVELOPMENT-SNAPSHOT-2024-06-06-a/swift-DEVELOPMENT-SNAPSHOT-2024-06-06-a_static-linux-0.0.1.artifactbundle.tar.gz
</code></pre></div>

<p>to install the corresponding Static Linux SDK.</p>

<p>Swift will download and install the SDK on your system.  You can get a
list of installed SDKs with</p>



<p>and it’s also possible to remove them using</p>

<div><pre><code><span>$</span><span> </span>swift sdk remove &lt;name-of-SDK&gt;
</code></pre></div>



<p>First, create a directory to hold your code:</p>



<p>Next, ask Swift to create a new program package for you:</p>

<div><pre><code><span>$</span><span> </span>swift package init <span>--type</span> executable
</code></pre></div>

<p>You can build and run this locally:</p>

<div><pre><code><span>$</span><span> </span>swift build
<span>Building for debugging...
[8/8] Applying hello
Build complete! (15.29s)
</span><span>$</span><span> </span>.build/debug/hello
<span>Hello, world!
</span></code></pre></div>

<p>But with the Static Linux SDK installed, you can also build Linux
binaries for x86-64 and ARM64 machines:</p>

<div><pre><code><span>$</span><span> </span>swift build <span>--sdk</span> x86_64-swift-linux-musl
<span>Building for debugging...
[8/8] Linking hello
Build complete! (2.04s)
</span><span>$</span><span> </span>file .build/x86_64-swift-linux-musl/debug/hello
<span>.build/x86_64-swift-linux-musl/debug/hello: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), statically linked, with debug_info, not stripped
</span></code></pre></div>

<div><pre><code><span>$</span><span> </span>swift build <span>--sdk</span> aarch64-swift-linux-musl
<span>Building for debugging...
[8/8] Linking hello
Build complete! (2.00s)
</span><span>$</span><span> </span>file .build/aarch64-swift-linux-musl/debug/hello
<span>.build/aarch64-swift-linux-musl/debug/hello: ELF 64-bit LSB executable, ARM aarch64, version 1 (SYSV), statically linked, with debug_info, not stripped
</span></code></pre></div>

<p>These can be copied to an appropriate Linux-based system and executed:</p>

<div><pre><code><span>$</span><span> </span>scp .build/x86_64-swift-linux-musl/debug/hello linux:~/hello
<span>$</span><span> </span>ssh linux ~/hello
<span>Hello, world!
</span></code></pre></div>



<p>Swift packages that make use of Foundation or Swift NIO should just
work.  If you try to use a package that uses the C library, however,
you may have a little work to do.  Such packages often contain files
with code like the following:</p>

<div><pre><code><span>#if os(macOS) || os(iOS)</span>
<span>import</span> <span>Darwin</span>
<span>#elseif os(Linux)</span>
<span>import</span> <span>Glibc</span>
<span>#elseif os(Windows)</span>
<span>import</span> <span>ucrt</span>
<span>#else</span>
<span>#error(Unknown platform)</span>
<span>#endif</span>
</code></pre></div>

<p>The Static Linux SDK does not use Glibc; instead, it is built on top
of an alternative C library for Linux called
<a href="https://musl-libc.org/">Musl</a>.  We chose this approach for two
reasons:</p>

<ol>
  <li>
    <p>Musl has excellent support for static linking.</p>
  </li>
  <li>
    <p>Musl is permissively licensed, which makes it easy to distribute
executables statically linked with it.</p>
  </li>
</ol>

<p>If you are using such a dependency, you will therefore need to adjust
it to import the <code>Musl</code> module instead of the <code>Glibc</code> module:</p>

<div><pre><code><span>#if os(macOS) || os(iOS)</span>
<span>import</span> <span>Darwin</span>
<span>#elseif canImport(Glibc)</span>
<span>import</span> <span>Glibc</span>
<span>#elseif canImport(Musl)</span>
<span>import</span> <span>Musl</span>
<span>#elseif os(Windows)</span>
<span>import</span> <span>ucrt</span>
<span>#else</span>
<span>#error(Unknown platform)</span>
<span>#endif</span>
</code></pre></div>

<p>Occasionally there might be a difference between the way a C library
type gets imported between Musl and Glibc; this sometimes happens if
someone has added nullability annotations, or where a pointer type is
using a forward-declared <code>struct</code> for which no actual definition is
ever provided.  Usually the problem will be obvious—a function
argument or result will be <code>Optional</code> in one case and non-<code>Optional</code>
in another, or a pointer type will be imported as <code>OpaquePointer</code>
rather than <code>UnsafePointer&lt;FOO&gt;</code>.</p>

<p>If you do find yourself needing to make these kinds of adjustments,
you can make your local copy of the package dependency editable by
doing</p>

<div><pre><code><span>$</span><span> </span>swift package edit SomePackage
</code></pre></div>

<p>and then editing the files in the <code>Packages</code> directory that appears in
your program’s source directory.  You may wish to consider raising PRs
upstream with any fixes you may have.</p>


  
    
  
</article>

</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Flameshot – Open-source screenshot software (115 pts)]]></title>
            <link>https://flameshot.org/</link>
            <guid>40650844</guid>
            <pubDate>Tue, 11 Jun 2024 20:03:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://flameshot.org/">https://flameshot.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40650844">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="pills-tabContent" role="tabpanel" aria-labelledby="pills-linux-tab">
            <h4>Get the latest Flameshot</h4>
            <h5><strong>Linux Downloads</strong></h5>
            <p>64-bit only, install via Appimage, your package manager, Snapcraft or Flathub</p>
            
            <p><a href="https://snapcraft.io/flameshot"><img src="https://flameshot.org/img/snapcraft.svg" title="Get it from the Snapcraft store" alt="get it from snapcraft store"></a>
              <a href="https://flathub.org/apps/details/org.flameshot.Flameshot"><img src="https://flameshot.org/img/flathub.svg" title="Get it from Flathub" alt="get it from flathub"></a>
            </p>
            <p><a href="https://github.com/flameshot-org/flameshot/releases">Looking for older releases?</a></p><div>
              <p>
                <h6>Install via Package Manager</h6>
              </p>
              
              <div>
                <p>Ubuntu 18.04+ and Debian 10+</p>
                <p><code>apt install flameshot</code></p>
              </div>
              <div>
                <p>openSUSE</p>
                <p><code>zypper install flameshot</code></p>
              </div>
              <div>
                <p>Void Linux</p>
                <p><code>xbps-install flameshot</code></p>
              </div>
              
              <div>
                <p>Fedora</p>
                <p><code>dnf install flameshot</code></p>
              </div>
              <div>
                <p>NixOs</p>
                <p><code>nix-env -iA nixos.flameshot</code></p>
              </div>
            </div>
          </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[London–Calcutta Bus Service (136 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/London%E2%80%93Calcutta_bus_service</link>
            <guid>40649091</guid>
            <pubDate>Tue, 11 Jun 2024 17:30:09 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/London%E2%80%93Calcutta_bus_service">https://en.wikipedia.org/wiki/London%E2%80%93Calcutta_bus_service</a>, See on <a href="https://news.ycombinator.com/item?id=40649091">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<p>The bus service from <a href="https://en.wikipedia.org/wiki/London" title="London">London</a>, England to Calcutta, India (now <a href="https://en.wikipedia.org/wiki/Kolkata" title="Kolkata">Kolkata</a>) was considered to be the longest bus route in the world.<sup id="cite_ref-curly_1-0"><a href="#cite_note-curly-1">[1]</a></sup><sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup><sup id="cite_ref-bus_3-0"><a href="#cite_note-bus-3">[3]</a></sup> The bus service, which started in 1957, was routed to India via Belgium, Yugoslavia and North Western India.<sup id="cite_ref-4"><a href="#cite_note-4">[4]</a></sup> This route is also known as the <a href="https://en.wikipedia.org/wiki/Hippie_Trail" title="Hippie Trail">Hippie Route</a>. According to reports, it took about 50 days for the bus to reach Calcutta from London. The voyage was over 10,000 miles (16,000&nbsp;km) one way and 20,300 miles (32,700&nbsp;km) for the round trip. It was in service until 1976.<sup id="cite_ref-samayam_5-0"><a href="#cite_note-samayam-5">[5]</a></sup> The cost of the trip one-way was <a href="https://en.wikipedia.org/wiki/British_Pound" title="British Pound">£</a>85 in 1957 (equivalent to £2,589 in 2023) and <a href="https://en.wikipedia.org/wiki/British_Pound" title="British Pound">£</a>145 in 1973 (equivalent to £2,215 in 2023). This amount included food, travel and accommodation.<sup id="cite_ref-bus_3-1"><a href="#cite_note-bus-3">[3]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Route">Route</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=London%E2%80%93Calcutta_bus_service&amp;action=edit&amp;section=1" title="Edit section: Route"><span>edit</span></a><span>]</span></span></h2>
<p>The bus service was operated by Albert Travel.<sup id="cite_ref-6"><a href="#cite_note-6">[6]</a></sup> The maiden journey set out from London on April 15, 1957.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup> The first service arrived in Calcutta on June 5, 50 days later. During its journey the bus traveled from <a href="https://en.wikipedia.org/wiki/England" title="England">England</a> to <a href="https://en.wikipedia.org/wiki/Belgium" title="Belgium">Belgium</a>, and from there to <a href="https://en.wikipedia.org/wiki/India" title="India">India</a> via <a href="https://en.wikipedia.org/wiki/West_Germany" title="West Germany">West Germany</a>, <a href="https://en.wikipedia.org/wiki/Austria" title="Austria">Austria</a>, <a href="https://en.wikipedia.org/wiki/Yugoslavia" title="Yugoslavia">Yugoslavia</a>, <a href="https://en.wikipedia.org/wiki/Bulgaria" title="Bulgaria">Bulgaria</a>, <a href="https://en.wikipedia.org/wiki/Turkey" title="Turkey">Turkey</a>, <a href="https://en.wikipedia.org/wiki/Iran" title="Iran">Iran</a>, <a href="https://en.wikipedia.org/wiki/Afghanistan" title="Afghanistan">Afghanistan</a>, <a href="https://en.wikipedia.org/wiki/Pakistan" title="Pakistan">Pakistan</a> and North Western India. After entering India, it eventually reached Calcutta via <a href="https://en.wikipedia.org/wiki/New_Delhi" title="New Delhi">New Delhi</a>, <a href="https://en.wikipedia.org/wiki/Agra" title="Agra">Agra</a>, <a href="https://en.wikipedia.org/wiki/Allahabad" title="Allahabad">Allahabad</a> and <a href="https://en.wikipedia.org/wiki/Banaras" title="Banaras">Banaras</a>.<sup id="cite_ref-samayam_5-1"><a href="#cite_note-samayam-5">[5]</a></sup>
</p>
<h2><span id="Facilities_on_the_bus">Facilities on the bus</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=London%E2%80%93Calcutta_bus_service&amp;action=edit&amp;section=2" title="Edit section: Facilities on the bus"><span>edit</span></a><span>]</span></span></h2>
<p>The trip was equipped with reading facilities, separate sleeping bunks for all passengers, fan-operated heaters, and a kitchen. There was a forward observation lounge on the upper deck of the bus. The trip was more like a tour than just a trip. The bus provided radio and a <a href="https://en.wikipedia.org/wiki/Car_stereo" title="Car stereo">music system</a> for parties.<sup id="cite_ref-curly_1-1"><a href="#cite_note-curly-1">[1]</a></sup>  It had time to spend at <a href="https://en.wikipedia.org/wiki/Tourist_destinations_in_India" title="Tourist destinations in India">tourist destinations in India</a>, including <a href="https://en.wikipedia.org/wiki/Banaras" title="Banaras">Banaras</a> and the <a href="https://en.wikipedia.org/wiki/Taj_Mahal" title="Taj Mahal">Taj Mahal</a> on the banks of the <a href="https://en.wikipedia.org/wiki/Yamuna" title="Yamuna">Yamuna</a>. Shopping was also allowed in <a href="https://en.wikipedia.org/wiki/Tehran" title="Tehran">Tehran</a>, <a href="https://en.wikipedia.org/wiki/Salzburg" title="Salzburg">Salzburg</a>, <a href="https://en.wikipedia.org/wiki/Kabul" title="Kabul">Kabul</a>, <a href="https://en.wikipedia.org/wiki/Istanbul" title="Istanbul">Istanbul</a> and <a href="https://en.wikipedia.org/wiki/Vienna" title="Vienna">Vienna</a>.<sup id="cite_ref-bus_3-2"><a href="#cite_note-bus-3">[3]</a></sup><sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p>
<h2><span id="Later_history">Later history</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=London%E2%80%93Calcutta_bus_service&amp;action=edit&amp;section=3" title="Edit section: Later history"><span>edit</span></a><span>]</span></span></h2>
<p>After some years the bus met with an accident and became unusable. Later the bus was purchased by Andy Stewart, a British traveler. He rebuilt it to be a <a href="https://en.wikipedia.org/wiki/Mobile_home" title="Mobile home">mobile home</a> with <a href="https://en.wikipedia.org/wiki/Double-decker_bus" title="Double-decker bus">two levels</a>. The double-decker was renamed as <i>Albert</i> and was traveled from <a href="https://en.wikipedia.org/wiki/Sydney" title="Sydney">Sydney</a> to London via India on October 8, 1968. It took about 132 days for the bus to reach London. Albert Tours was a company based in England and <a href="https://en.wikipedia.org/wiki/Australia" title="Australia">Australia</a> and it operated on London–Calcutta–London and London–Calcutta–Sydney routes.<sup id="cite_ref-9"><a href="#cite_note-9">[9]</a></sup>
</p><p>The bus reached India through <a href="https://en.wikipedia.org/wiki/Iran" title="Iran">Iran</a> and then it traveled to <a href="https://en.wikipedia.org/wiki/Singapore" title="Singapore">Singapore</a> through <a href="https://en.wikipedia.org/wiki/Burma" title="Burma">Burma</a>, <a href="https://en.wikipedia.org/wiki/Thailand" title="Thailand">Thailand</a> and <a href="https://en.wikipedia.org/wiki/Malaysia" title="Malaysia">Malaysia</a>. From <a href="https://en.wikipedia.org/wiki/Singapore" title="Singapore">Singapore</a>, the bus was transported to <a href="https://en.wikipedia.org/wiki/Perth" title="Perth">Perth</a> in Australia by ship, and from there it traveled by road to <a href="https://en.wikipedia.org/wiki/Sydney" title="Sydney">Sydney</a>.<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup><sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> The charge for this service from London to Calcutta was £145. The service had all the modern facilities as before. The bus service was discontinued in 1976 due to political conditions leading up to the <a href="https://en.wikipedia.org/wiki/Iranian_Revolution" title="Iranian Revolution">Iranian Revolution</a> and the escalation of <a href="https://en.wikipedia.org/wiki/Indo-Pakistan_Wars" title="Indo-Pakistan Wars">tensions between Pakistan and India</a>.<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> It is reported that the Albert Tours completed about 15 trips between Kolkata to London and again from London to Sydney, before the service ended permanently.<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup>
</p>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=London%E2%80%93Calcutta_bus_service&amp;action=edit&amp;section=4" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div><ol>
<li id="cite_note-curly-1"><span>^ <a href="#cite_ref-curly_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-curly_1-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://curlytales.com/this-was-the-worlds-longest-bus-route-from-kolkata-to-london/">"This Was 'World's Longest Bus Route' From Kolkata To London"</a>. <i>Curly Tales</i>. 2020-07-06<span>. Retrieved <span>2020-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Curly+Tales&amp;rft.atitle=This+Was+%27World%27s+Longest+Bus+Route%27+From+Kolkata+To+London&amp;rft.date=2020-07-06&amp;rft_id=https%3A%2F%2Fcurlytales.com%2Fthis-was-the-worlds-longest-bus-route-from-kolkata-to-london%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.news18.com/news/buzz/a-bus-ride-from-london-to-kolkata-in-1950s-yes-the-viral-photo-is-real-2696673.html">"A Bus Ride From London to Kolkata in 1950s? Yes, The Viral Photo is Real"</a>. <i>News18</i><span>. Retrieved <span>2020-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=News18&amp;rft.atitle=A+Bus+Ride+From+London+to+Kolkata+in+1950s%3F+Yes%2C+The+Viral+Photo+is+Real&amp;rft_id=https%3A%2F%2Fwww.news18.com%2Fnews%2Fbuzz%2Fa-bus-ride-from-london-to-kolkata-in-1950s-yes-the-viral-photo-is-real-2696673.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-bus-3"><span>^ <a href="#cite_ref-bus_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-bus_3-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-bus_3-2"><sup><i><b>c</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://books.google.com/books?id=x_wmAQAAIAAJ&amp;pg=RA4-PA86"><i>Civic Affairs</i></a>. Vol.&nbsp;4. P. C. Kapoor at the Citizen Press. 1957 – via books.google.com.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Civic+Affairs&amp;rft.pub=P.+C.+Kapoor+at+the+Citizen+Press&amp;rft.date=1957&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3Dx_wmAQAAIAAJ%26pg%3DRA4-PA86&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.shutterstock.com/editorial/image-editorial/london-to-calcutta-bus-trip-1957-london-to-india-by-bus-the-coach-full-of-20-british-stop-for-a-picnic-by-the-river-in-yugoslavia-during-their-trip-1460231a">"London Calcutta Bus Trip 1957 london India Editorial Stock Photo - Stock Image | Shutterstock"</a>. <i>Shutterstock Editorial</i><span>. Retrieved <span>2020-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Shutterstock+Editorial&amp;rft.atitle=London+Calcutta+Bus+Trip+1957+london+India+Editorial+Stock+Photo+-+Stock+Image+%7C+Shutterstock&amp;rft_id=https%3A%2F%2Fwww.shutterstock.com%2Feditorial%2Fimage-editorial%2Flondon-to-calcutta-bus-trip-1957-london-to-india-by-bus-the-coach-full-of-20-british-stop-for-a-picnic-by-the-river-in-yugoslavia-during-their-trip-1460231a&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-samayam-5"><span>^ <a href="#cite_ref-samayam_5-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-samayam_5-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://malayalam.samayam.com/viral-news/omg/did-you-know-there-was-london-calcutta-bus-service-till-the-end-of-1970/articleshow/76747839.cms">"Samayam"</a>. <i>malayalam.samayam.com</i>. 2 July 2020<span>. Retrieved <span>13 June</span> 2023</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=malayalam.samayam.com&amp;rft.atitle=Samayam&amp;rft.date=2020-07-02&amp;rft_id=https%3A%2F%2Fmalayalam.samayam.com%2Fviral-news%2Fomg%2Fdid-you-know-there-was-london-calcutta-bus-service-till-the-end-of-1970%2Farticleshow%2F76747839.cms&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-6"><span><b><a href="#cite_ref-6">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.uniquenewsonline.com/london-to-calcutta-by-road-picture-of-1950s-albert-travel-bus-service-is-going-viral-know-details-about-this-fascinating-historic-journey/">"London to Calcutta by Road? Picture of 1950s Albert Travel Bus Service is Going Viral, Know Details About This Fascinating Historic Journey"</a>. <i>Unique News Online</i>. 2020-07-02<span>. Retrieved <span>2021-02-19</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Unique+News+Online&amp;rft.atitle=London+to+Calcutta+by+Road%3F+Picture+of+1950s+Albert+Travel+Bus+Service+is+Going+Viral%2C+Know+Details+About+This+Fascinating+Historic+Journey&amp;rft.date=2020-07-02&amp;rft_id=https%3A%2F%2Fwww.uniquenewsonline.com%2Flondon-to-calcutta-by-road-picture-of-1950s-albert-travel-bus-service-is-going-viral-know-details-about-this-fascinating-historic-journey%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=thMS7VyyqRI"><i>Whispers of Yesterday, Rare Historical Photos, Old Photos</i></a><span>, retrieved <span>2023-11-29</span></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Whispers+of+Yesterday%2C+Rare+Historical+Photos%2C+Old+Photos&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DthMS7VyyqRI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFadmin2020">admin (2020-07-04). <a rel="nofollow" href="http://newskeralaonline.org/london-culcutta-bus-%e0%b4%b2%e0%b4%a3%e0%b5%8d%e0%b4%9f%e0%b5%bb-%e0%b4%95%e0%b5%bd%e0%b4%95%e0%b5%8d%e0%b4%95%e0%b4%9f%e0%b5%8d%e0%b4%9f-%e0%b4%ac%e0%b4%b8%e0%b5%8d-%e0%b4%b1%e0%b5%82%e0%b4%9f/">"ലണ്ടൻ – കൽക്കട്ട ബസ് റൂട്ട്"</a>. <i>News Kerala online</i><span>. Retrieved <span>2020-07-24</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=News+Kerala+online&amp;rft.atitle=%E0%B4%B2%E0%B4%A3%E0%B5%8D%E0%B4%9F%E0%B5%BB+%E2%80%93+%E0%B4%95%E0%B5%BD%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B4%9F%E0%B5%8D%E0%B4%9F+%E0%B4%AC%E0%B4%B8%E0%B5%8D+%E0%B4%B1%E0%B5%82%E0%B4%9F%E0%B5%8D%E0%B4%9F%E0%B5%8D&amp;rft.date=2020-07-04&amp;rft.au=admin&amp;rft_id=http%3A%2F%2Fnewskeralaonline.org%2Flondon-culcutta-bus-%25e0%25b4%25b2%25e0%25b4%25a3%25e0%25b5%258d%25e0%25b4%259f%25e0%25b5%25bb-%25e0%25b4%2595%25e0%25b5%25bd%25e0%25b4%2595%25e0%25b5%258d%25e0%25b4%2595%25e0%25b4%259f%25e0%25b5%258d%25e0%25b4%259f-%25e0%25b4%25ac%25e0%25b4%25b8%25e0%25b5%258d-%25e0%25b4%25b1%25e0%25b5%2582%25e0%25b4%259f%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-9"><span><b><a href="#cite_ref-9">^</a></b></span> <span><cite id="CITEREFEat2020">Eat, Tech Travel (2020-07-03). <a rel="nofollow" href="http://www.techtraveleat.com/story-of-london-culcutta-bus-service/">"ലണ്ടനിൽ നിന്നും ഇന്ത്യയിലെ കൽക്കട്ടയിലേക്ക് ഒരു ബസ് സർവ്വീസ്"</a>. <i>Technology &amp; Travel Blog from India</i><span>. Retrieved <span>2020-07-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Technology+%26+Travel+Blog+from+India&amp;rft.atitle=%E0%B4%B2%E0%B4%A3%E0%B5%8D%E0%B4%9F%E0%B4%A8%E0%B4%BF%E0%B5%BD+%E0%B4%A8%E0%B4%BF%E0%B4%A8%E0%B5%8D%E0%B4%A8%E0%B5%81%E0%B4%82+%E0%B4%87%E0%B4%A8%E0%B5%8D%E0%B4%A4%E0%B5%8D%E0%B4%AF%E0%B4%AF%E0%B4%BF%E0%B4%B2%E0%B5%86+%E0%B4%95%E0%B5%BD%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B4%9F%E0%B5%8D%E0%B4%9F%E0%B4%AF%E0%B4%BF%E0%B4%B2%E0%B5%87%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B5%8D+%E0%B4%92%E0%B4%B0%E0%B5%81+%E0%B4%AC%E0%B4%B8%E0%B5%8D+%E0%B4%B8%E0%B5%BC%E0%B4%B5%E0%B5%8D%E0%B4%B5%E0%B5%80%E0%B4%B8%E0%B5%8D&amp;rft.date=2020-07-03&amp;rft.aulast=Eat&amp;rft.aufirst=Tech+Travel&amp;rft_id=http%3A%2F%2Fwww.techtraveleat.com%2Fstory-of-london-culcutta-bus-service%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.manoramaonline.com/travel/world-escapes/2020/07/04/facts-about-london-calcutta-bus-service.html">"ലണ്ടനിൽ നിന്നു കൽക്കട്ടയിലെത്തിയ ഇന്ത്യാ മാന്‍..."</a> <i>ManoramaOnline</i> (in Malayalam)<span>. Retrieved <span>2020-07-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ManoramaOnline&amp;rft.atitle=%E0%B4%B2%E0%B4%A3%E0%B5%8D%E0%B4%9F%E0%B4%A8%E0%B4%BF%E0%B5%BD+%E0%B4%A8%E0%B4%BF%E0%B4%A8%E0%B5%8D%E0%B4%A8%E0%B5%81+%E0%B4%95%E0%B5%BD%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B4%9F%E0%B5%8D%E0%B4%9F%E0%B4%AF%E0%B4%BF%E0%B4%B2%E0%B5%86%E0%B4%A4%E0%B5%8D%E0%B4%A4%E0%B4%BF%E0%B4%AF+%E0%B4%87%E0%B4%A8%E0%B5%8D%E0%B4%A4%E0%B5%8D%E0%B4%AF%E0%B4%BE+%E0%B4%AE%E0%B4%BE%E0%B4%A8%E0%B5%8D%E2%80%8D...&amp;rft_id=https%3A%2F%2Fwww.manoramaonline.com%2Ftravel%2Fworld-escapes%2F2020%2F07%2F04%2Ffacts-about-london-calcutta-bus-service.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFINGALIS1957">INGALIS, LEONARD (1957-08-08). "London-Calcutta Bus is back in London - Owner drove passengers 20,300 Miles". <i>The New York Times</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=London-Calcutta+Bus+is+back+in+London+-+Owner+drove+passengers+20%2C300+Miles&amp;rft.date=1957-08-08&amp;rft.aulast=INGALIS&amp;rft.aufirst=LEONARD&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFK">K, Noushad K. <a rel="nofollow" href="https://www.visionnews.in/2020/07/blog-post_72.html">"ലണ്ടൻ - കൽക്കട്ട ബസ്"</a><span>. Retrieved <span>2020-07-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%E0%B4%B2%E0%B4%A3%E0%B5%8D%E0%B4%9F%E0%B5%BB+-+%E0%B4%95%E0%B5%BD%E0%B4%95%E0%B5%8D%E0%B4%95%E0%B4%9F%E0%B5%8D%E0%B4%9F+%E0%B4%AC%E0%B4%B8%E0%B5%8D&amp;rft.aulast=K&amp;rft.aufirst=Noushad+K.&amp;rft_id=https%3A%2F%2Fwww.visionnews.in%2F2020%2F07%2Fblog-post_72.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.whatshot.in/kolkata/kolkata-then-calcutta-once-had-the-worlds-longest-bus-route-till-london-c-23281">"Kolkata, Then Calcutta, Once Had The World's Longest Bus Route All The Way Till London!"</a>. <i>Whats Hot</i><span>. Retrieved <span>2020-07-31</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Whats+Hot&amp;rft.atitle=Kolkata%2C+Then+Calcutta%2C+Once+Had+The+World%27s+Longest+Bus+Route+All+The+Way+Till+London%21&amp;rft_id=https%3A%2F%2Fwww.whatshot.in%2Fkolkata%2Fkolkata-then-calcutta-once-had-the-worlds-longest-bus-route-till-london-c-23281&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALondon%E2%80%93Calcutta+bus+service"></span></span>
</li>
</ol></div>
<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐6d76fd97c7‐gcfd5
Cached time: 20240611192427
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.268 seconds
Real time usage: 0.352 seconds
Preprocessor visited node count: 4936/1000000
Post‐expand include size: 26769/2097152 bytes
Template argument size: 670/2097152 bytes
Highest expansion depth: 21/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 50410/5000000 bytes
Lua time usage: 0.152/10.000 seconds
Lua memory usage: 6625849/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  330.480      1 -total
 46.35%  153.189      1 Template:Reflist
 35.92%  118.701     10 Template:Cite_web
 17.66%   58.347      1 Template:Short_description
 12.62%   41.692      2 Template:Inflation
 11.83%   39.098      1 Template:See_also
  8.72%   28.812      2 Template:Pagetype
  8.57%   28.310      2 Template:Convert
  6.30%   20.815      2 Template:Inflation/UK
  5.77%   19.084      4 Template:Inflation/UK/dataset
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:64634965-0!canonical and timestamp 20240611192427 and revision id 1228534140. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[ARC Prize – a $1M+ competition towards open AGI progress (171 pts)]]></title>
            <link>https://arcprize.org/blog/launch</link>
            <guid>40648960</guid>
            <pubDate>Tue, 11 Jun 2024 17:19:41 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://arcprize.org/blog/launch">https://arcprize.org/blog/launch</a>, See on <a href="https://news.ycombinator.com/item?id=40648960">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>


<p><strong>A $1,000,000+ competition towards open AGI progress.</strong></p>

<p>
    <iframe width="560" height="315" src="https://www.youtube.com/embed/2avWAHXUXXs?si=CTewe9L_Mp8XsDSo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media;" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p>

<p>AGI progress has stalled. New ideas are needed.</p>

<h4 id="intelligence-vs-memorization">Intelligence vs Memorization</h4>

<p>Modern AI (LLMs) have shown to be great memorization engines. They are able to memorize high-dimensional patterns in their training data and apply those patterns into adjacent contexts. This is also how their apparent reasoning capability works. LLMs are not actually reasoning. Instead they memorize reasoning patterns and apply those reasoning patterns into adjacent contexts. But they cannot generate new reasoning based on novel situations.</p>

<p>More training data lets you "buy" performance on memorization based benchmarks (MMLU, GSM8K, ImageNet, GLUE, etc.) But memorization alone is not general intelligence. General intelligence is the ability to efficiently acquire new skills.</p>

<p>More scale will not enable LLMs to learn new skills. We need new architectures or algorithms that enable AI systems to learn at test time. This is how humans are able to adapt to novel situations.</p>

<p>Beyond LLMs, for many years, we've had AI systems that can beat humans at poker, chess, go, and other games. However, no AI system trained to succeed at one game can simply be retrained toward another. Instead researchers have had to re-architect and rebuild entirely new systems per game.</p>

<p>This is a failure to generalize.</p>

<p>Without this capability, AI will forever be rate-limited by the human general intelligence in the loop. We want AGI that can discover and invent alongside humans to push humanity forward.</p>

<p>Given the success and proven economic utility of LLMs over the past 4 years, the above may seem like extraodinary claims. Strong claims require strong evidence.</p>

<hr>

<h3 id="arc-agi">ARC-AGI</h3>

<p>Introduced by <a href="https://x.com/fchollet" target="_blank">François Chollet</a> in his influencial paper "<a href="https://arxiv.org/abs/1911.01547" target="_blank">On the Measure of Intelligence</a>", <a href="https://arcprize.org/arc">ARC-AGI</a> is the only AI eval which measures general intelligence: a system that can efficiently acquire new skills and solve novel, open-ended problems.</p>

<p>ARC-AGI was created in 2019 and the state-of-the-art (SOTA) high score was 20%. Today, only 34%.</p>

<p>Yet humans - even children - score 85% to 100%.</p>

<p>ARC-AGI is easy for humans and impossible for modern AI.</p>

<p>Most AI benchmarks rapidly saturate to human performance-level because they test only for memorization, which is something AI is superhuman at.</p>

<p>ARC-AGI is not saturating, in fact current pace is slowing down. It was designed to resist memorization and has proven extremely challenging for both the largest foundational transformer models as well as bespoke AI systems designed to defeat ARC-AGI.</p>

<p><img src="https://arcprize.org/media/images/ai-benchmarks.png" alt="ARC-AGI Benchmark Comparison"></p>

<p>A solution to ARC-AGI, at a minimum, opens up a completely new programming paradigm where programs can perfectly and reliably generalize from an arbitrary set of priors. We also believe a solution is on the critical path towards AGI</p>

<p><img src="https://arcprize.org/media/images/ThreeARCTasks.png" alt="3 ARC-AGI Tasks"></p>

<hr>

<h3 id="open-source-agi-progress">Open Source AGI Progress</h3>

<p>If you accept new ideas are needed, let's consider how to increase the rate of new ideas. Unfortunately, trends in AI are going the wrong way.</p>

<h4 id="closed-vs-open">Closed vs Open</h4>

<p>Starting with the GPT-4 release, frontier AGI progress has gone closed source. The <a href="https://arxiv.org/abs/2303.08774" target="_blank">GPT-4 technical report</a> surprisingly contains no technical details. OpenAI said "competitive" reasons were the first reason why. Google's <a href="https://arxiv.org/abs/2312.11805" target="_blank">Gemini technical report</a> also contains no technical details on the long context window frontier innovation.</p>

<p>LLMs have also shifted the majority of research attention away from new architectures and new algorithms. Over <a href="https://www.sequoiacap.com/article/ai-ascent-2024/" target="_blank">$20B was deployed</a> to non-general AI companies in 2023 and many frontier DeepMind researchers were restaffed to Gemini (in order to compete with OpenAI.)</p>

<p>Leading labs have strong incentives to loudly claim, "scale is all you need," and, "don't try to compete with us on frontier research," even though they all quietly believe new ideas are needed to reach AGI. Their bet is they can discover all the necessary new ideas within their labs.</p>

<h4 id="llm-history">LLM History</h4>

<p>But let's look at the history of LLMs. Specifically the transformer architecture. Transformers emerged many years downstream of machine translation research (e.g., English to Spanish.)</p>

<ul>
  <li><strong>2014</strong>: Sutskever et. al. (Google) published <a href="https://arxiv.org/abs/1409.3215" target="_blank">Seq2Seq Learning</a> using RNNs and CNNs for variable length input vs output (English and Spanish words are not the same length.)</li>
  <li><strong>2016</strong>: Bahdanau et. al. (Jacobs University) popularized <a href="https://arxiv.org/pdf/1409.0473" target="_blank">the concept of "attention"</a> so a system could consider different parts of the input to predict output (English adjectives come before nouns, Spanish after.)</li>
  <li><strong>2017</strong>: Vaswani et. al. (Google) realized <a href="https://arxiv.org/pdf/1706.03762" target="_blank">"attention is all you need"</a>, dropping RNNs and CNNs, optimizing the architecture, enabling new scale</li>
  <li><strong>2018</strong>: Radford et. al. (OpenAI) <a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank">created GPT-2</a> built on top of the transformer architecture at frontier scale, showing emergent capabilities</li>
</ul>

<p>The story of the transformer is the story of science. Researchers in different labs and teams publish and build on top of each other's work.</p>

<p>While it is possible one lab could discover AGI alone, it is highly unlikely. The global chance of AGI discovery has decreased and will keep decreasing if we accepting this as status quo.</p>

<h4 id="progress">Progress</h4>

<p>I have spoken with many young students and would-be researchers over the past year. Many are depressed. There is a sense of dread that everything has been figured out already. But this is not true! The AI ecosystem is intentioanlly telling a partial-truth to boost their relative competitive positions to the detriment of actual progress towards AGI.</p>

<p>Worse, the inaccurate "scale is all you need" belief is now influencing the AI regulatory environment. Regulators are considering roadblocks to frontier AI research under the wrong assumption that AGI is imminent. The truth is no one knows how to build AGI.</p>

<p>We should be trying to incentivize new ideas, not slow them down. The internet and open source are the strongest innovation engines the world has ever seen.</p>

<p>By incentivizing open source we increase the rate of new ideas, increasing the chance we discover AGI, and ensure those new ideas are widely distributed to establish a more even playing field between small and large AI companies.</p>

<p>We hope ARC Prize can help counterbalance these trends.</p>

<hr>

<p><img src="https://arcprize.org/media/images/m-and-f.jpg" alt="François Chollet and Mike Knoop"></p>

<h3 id="arc-prize">ARC Prize</h3>

<p>Announcing ARC Prize, a $1,000,000+ prize pool competition to beat and open-source a solution to the ARC-AGI eval.</p>

<p>Hosted by <a href="https://mikeknoop.com/" target="_blank">Mike Knoop</a> and <a href="https://fchollet.com/" target="_blank">François Chollet</a>. Presented by Infinite Monkey and Lab42.</p>

<h4 id="arc-prize-goals">ARC Prize Goals</h4>

<ol>
  <li>Increase the number of people working on frontier AGI research.</li>
  <li>Popularize an objective measure of AGI progress.</li>
  <li>Solve ARC-AGI and learn something new about the nature of intelligence.</li>
</ol>

<h4 id="get-started">Get Started</h4>

<p>Ready to make the first significant leap towards AGI in years? No matter who you are, where you come from, what you do for a living, you are welcome to join this competition. New ideas might come from anywhere. Possibly you?</p>



<p>Find competition format and prize details on <a href="https://arcprize.org/competition">ARC Prize 2024 here</a>.</p>

<p>For more information on how to get started solving ARC-AGI <a href="https://arcprize.org/guide">visit the guide.</a></p>

<p>To learn more how ARC-AGI measures general intelligence <a href="https://arcprize.org/arc">visit ARC-AGI.</a></p>

<p>Stay updated on ARC Prize progress and SOTA solutions on <a href="https://x.com/arcprize" target="_blank">X/Twitter</a>, <a href="https://www.youtube.com/@arcprize" target="_blank">YouTube</a>, <a href="https://arcprize.ck.page/bc80575d89" target="_blank">Email</a>, and <a href="https://discord.gg/9b77dPAmcA" target="_blank">Discord</a>. You can also contact us at team@arcprize.org.</p>

		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lynn Conway Has Died (1105 pts)]]></title>
            <link>https://en.wikipedia.org/wiki/Lynn_Conway</link>
            <guid>40648470</guid>
            <pubDate>Tue, 11 Jun 2024 16:44:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://en.wikipedia.org/wiki/Lynn_Conway">https://en.wikipedia.org/wiki/Lynn_Conway</a>, See on <a href="https://news.ycombinator.com/item?id=40648470">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div lang="en" dir="ltr" id="mw-content-text">

<table><tbody><tr><th colspan="2"><p>Lynn Conway</p></th></tr><tr><td colspan="2"><span typeof="mw:File/Frameless"><a href="https://en.wikipedia.org/wiki/File:Lynn_Conway_July_2006.jpg"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/220px-Lynn_Conway_July_2006.jpg" decoding="async" width="220" height="293" srcset="https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/330px-Lynn_Conway_July_2006.jpg 1.5x, https://upload.wikimedia.org/wikipedia/commons/thumb/5/50/Lynn_Conway_July_2006.jpg/440px-Lynn_Conway_July_2006.jpg 2x" data-file-width="751" data-file-height="1000"></a></span><p>Conway in 2006</p></td></tr><tr><th scope="row">Born</th><td>January 2, 1938<br><div><p><a href="https://en.wikipedia.org/wiki/Mount_Vernon,_New_York" title="Mount Vernon, New York">Mount Vernon, New York</a>, U.S.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup></p></div></td></tr><tr><th scope="row">Died</th><td>June 9, 2024 (aged&nbsp;86)<p>Jackson, Michigan, U.S.</p></td></tr><tr><th scope="row">Alma&nbsp;mater</th><td><a href="https://en.wikipedia.org/wiki/Columbia_University" title="Columbia University">Columbia University</a></td></tr><tr><th scope="row">Known&nbsp;for</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Mead%E2%80%93Conway_VLSI_chip_design_revolution" title="Mead–Conway VLSI chip design revolution">Mead–Conway VLSI chip design revolution</a></li><li><a href="https://en.wikipedia.org/wiki/Transgender_activism" title="Transgender activism">transgender activism</a></li></ul></div></td></tr><tr><th scope="row">Spouse</th><td>
<div><p>Charles Rogers</p> <p>​</p><p>(<abbr title="married">m.</abbr>&nbsp;)<wbr>​</p></div></td></tr><tr><th scope="row">Awards</th><td><div>
<ul><li><a href="https://en.wikipedia.org/wiki/Harold_Pender_Award" title="Harold Pender Award">Harold Pender Award</a> (1984)</li>
<li><a href="https://en.wikipedia.org/wiki/John_Price_Wetherill_Medal" title="John Price Wetherill Medal">John Price Wetherill Medal</a> (1985)</li>
<li><a href="https://en.wikipedia.org/wiki/Secretary_of_Defense_Meritorious_Civilian_Service_Award" title="Secretary of Defense Meritorious Civilian Service Award">Secretary of Defense Meritorious Civilian Service Award</a> (1985)</li>
<li><a href="https://en.wikipedia.org/wiki/National_Academy_of_Engineering" title="National Academy of Engineering">National Academy of Engineering</a> (1989)</li>
<li><a href="https://en.wikipedia.org/wiki/Computer_Pioneer_Award" title="Computer Pioneer Award">Computer Pioneer Award</a> (2009)</li>
<li><a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a> Fellow (2014)<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/IEEE/RSE_James_Clerk_Maxwell_Medal" title="IEEE/RSE James Clerk Maxwell Medal">IEEE/RSE James Clerk Maxwell Medal</a> (2015)</li>
<li><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a> (2023)</li></ul>
</div></td></tr><tr><td colspan="2"><b>Scientific career</b></td></tr><tr><th scope="row">Fields</th><td><div><ul><li><a href="https://en.wikipedia.org/wiki/Computer_science" title="Computer science">Computer science</a></li><li><a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">Electrical engineering</a></li></ul></div></td></tr><tr><th scope="row">Institutions</th><td><a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> Advanced Computing Systems (1964–68), <a href="https://en.wikipedia.org/wiki/Memorex" title="Memorex">Memorex</a>, <a href="https://en.wikipedia.org/wiki/Xerox_PARC" title="Xerox PARC">Xerox PARC</a> (1970s), <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a>, <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a></td></tr></tbody></table>
<p><b>Lynn Ann Conway</b> (January 2, 1938 - June 9, 2024<sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup>)<sup id="cite_ref-Lee1995_4-0"><a href="#cite_note-Lee1995-4">[4]</a></sup><sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> was an American <a href="https://en.wikipedia.org/wiki/Computer_scientist" title="Computer scientist">computer scientist</a>, <a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">electrical engineer</a> and <a href="https://en.wikipedia.org/wiki/Transgender_activist" title="Transgender activist">transgender activist</a>.<sup id="cite_ref-Time21Culture_6-0"><a href="#cite_note-Time21Culture-6">[6]</a></sup>
</p><p>She worked at <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> in the 1960s and invented generalized dynamic instruction handling, a key advance used in <a href="https://en.wikipedia.org/wiki/Out-of-order_execution" title="Out-of-order execution">out-of-order execution</a>, used by most modern computer processors to improve performance. She initiated the <a href="https://en.wikipedia.org/wiki/Mead%E2%80%93Conway_VLSI_chip_design_revolution" title="Mead–Conway VLSI chip design revolution">Mead–Conway VLSI chip design revolution</a> in very large scale integrated (<a href="https://en.wikipedia.org/wiki/VLSI" title="VLSI">VLSI</a>) microchip design. That revolution spread rapidly through the <a href="https://en.wikipedia.org/wiki/Research_universities" title="Research universities">research universities</a> and computing industries during the 1980s, incubating an emerging <a href="https://en.wikipedia.org/wiki/Electronic_design_automation" title="Electronic design automation">electronic design automation</a> industry, spawning the modern 'foundry' infrastructure for chip design and production, and triggering a rush of impactful high-tech startups in the 1980s and 1990s.<sup id="cite_ref-smoth01_7-0"><a href="#cite_note-smoth01-7">[7]</a></sup><sup id="cite_ref-comsocpioneeraward_8-0"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-comsocpioneersawardvideo_9-0"><a href="#cite_note-comsocpioneersawardvideo-9">[9]</a></sup><sup id="cite_ref-superproj60b_10-0"><a href="#cite_note-superproj60b-10">[10]</a></sup><sup id="cite_ref-IBMsmotherman_11-0"><a href="#cite_note-IBMsmotherman-11">[11]</a></sup>
</p>
<meta property="mw:PageProp/toc">
<h2><span id="Early_life_and_education">Early life and education</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=1" title="Edit section: Early life and education"><span>edit</span></a><span>]</span></span></h2>
<p>Conway grew up in <a href="https://en.wikipedia.org/wiki/White_Plains,_New_York" title="White Plains, New York">White Plains, New York</a>. Conway was shy and experienced <a href="https://en.wikipedia.org/wiki/Gender_dysphoria" title="Gender dysphoria">gender dysphoria</a> as a child. She became fascinated by <a href="https://en.wikipedia.org/wiki/Astronomy" title="Astronomy">astronomy</a> (building a 6-inch (150&nbsp;mm) <a href="https://en.wikipedia.org/wiki/Reflecting_telescope" title="Reflecting telescope">reflector telescope</a> one summer) and did well in math and science in high school. Conway entered <a href="https://en.wikipedia.org/wiki/MIT" title="MIT">MIT</a> in 1955, earning high grades but ultimately leaving in despair after an attempted <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>, from male to female in 1957–58, failed due to the medical climate at the time.<sup>[<i><a href="https://en.wikipedia.org/wiki/Wikipedia:Citation_needed" title="Wikipedia:Citation needed"><span title="This claim needs references to reliable sources. (February 2022)">citation needed</span></a></i>]</sup> After working as an electronics technician for several years, Conway resumed education at <a href="https://en.wikipedia.org/wiki/Columbia_University" title="Columbia University">Columbia University</a>'s <a href="https://en.wikipedia.org/wiki/Fu_Foundation_School_of_Engineering_and_Applied_Science" title="Fu Foundation School of Engineering and Applied Science">School of Engineering and Applied Science</a>, earning B.S. and M.S.E.E. degrees in 1962 and 1963.<sup id="cite_ref-conI_12-0"><a href="#cite_note-conI-12">[12]</a></sup><sup id="cite_ref-kilbane_13-0"><a href="#cite_note-kilbane-13">[13]</a></sup>
</p>
<h2><span id="Early_research_at_IBM">Early research at IBM</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=2" title="Edit section: Early research at IBM"><span>edit</span></a><span>]</span></span></h2>
<p>Conway was recruited by <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> Research in <a href="https://en.wikipedia.org/wiki/Yorktown_Heights,_New_York" title="Yorktown Heights, New York">Yorktown Heights, New York</a> in 1964, and was soon selected to join the <a href="https://en.wikipedia.org/wiki/Computer_architecture" title="Computer architecture">architecture</a> team designing an advanced <a href="https://en.wikipedia.org/wiki/Supercomputer" title="Supercomputer">supercomputer</a>, working alongside <a href="https://en.wikipedia.org/wiki/John_Cocke_(computer_scientist)" title="John Cocke (computer scientist)">John Cocke</a>, <a href="https://en.wikipedia.org/wiki/Brian_Randell" title="Brian Randell">Brian Randell</a>, Herbert Schorr, <a href="https://en.wikipedia.org/wiki/Ed_Sussenguth" title="Ed Sussenguth">Ed Sussenguth</a>, <a href="https://en.wikipedia.org/wiki/Fran_Allen" title="Fran Allen">Fran Allen</a> and other IBM researchers on the <a href="https://en.wikipedia.org/wiki/ACS-1" title="ACS-1">Advanced Computing Systems</a> (ACS) project, inventing multiple-issue out-of-order dynamic instruction scheduling while working there.<sup id="cite_ref-smoth01_7-1"><a href="#cite_note-smoth01-7">[7]</a></sup><sup id="cite_ref-comsocpioneeraward_8-1"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-comsocpioneersawardvideo_9-1"><a href="#cite_note-comsocpioneersawardvideo-9">[9]</a></sup><sup id="cite_ref-sciam00_14-0"><a href="#cite_note-sciam00-14">[14]</a></sup><sup id="cite_ref-ABCnews01_15-0"><a href="#cite_note-ABCnews01-15">[15]</a></sup> The Computer History Museum has stated that "the ACS machines appears to have been the first <a href="https://en.wikipedia.org/wiki/Superscalar" title="Superscalar">superscalar</a> design, a computer architectural paradigm widely exploited in modern high-performance microprocessors."<sup id="cite_ref-superproj60b_10-1"><a href="#cite_note-superproj60b-10">[10]</a></sup><sup id="cite_ref-IBMsmotherman_11-1"><a href="#cite_note-IBMsmotherman-11">[11]</a></sup><sup id="cite_ref-chm_ibm_acs_reunion_16-0"><a href="#cite_note-chm_ibm_acs_reunion-16">[16]</a></sup><sup id="cite_ref-chm_ibm_acs_video_17-0"><a href="#cite_note-chm_ibm_acs_video-17">[17]</a></sup>
</p>
<h2><span id="Gender_transition">Gender transition</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=3" title="Edit section: Gender transition"><span>edit</span></a><span>]</span></span></h2>
<p>After learning of the pioneering research of <a href="https://en.wikipedia.org/wiki/Harry_Benjamin" title="Harry Benjamin">Harry Benjamin</a> in healthcare for <a href="https://en.wikipedia.org/wiki/Transsexual" title="Transsexual">transsexual</a> women<sup id="cite_ref-18"><a href="#cite_note-18">[18]</a></sup> and realising that gender affirmation surgery was now possible, Conway sought his help and became his patient. After suffering from severe <a href="https://en.wikipedia.org/wiki/Clinical_depression" title="Clinical depression">depression</a> from <a href="https://en.wikipedia.org/wiki/Gender_dysphoria" title="Gender dysphoria">gender dysphoria</a>, Conway contacted Benjamin, who agreed to provide counseling and prescribe <a href="https://en.wikipedia.org/wiki/Hormone_replacement_therapy_(male-to-female)" title="Hormone replacement therapy (male-to-female)">hormones</a>. Under Benjamin's care, Conway began her medical <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>.<sup id="cite_ref-hiltzik_19-0"><a href="#cite_note-hiltzik-19">[19]</a></sup>
</p><p>While struggling with life in a male role,<sup id="cite_ref-hiltzik_19-1"><a href="#cite_note-hiltzik-19">[19]</a></sup> Conway had been married to a woman and had two children. Under the legal constraints then in place, she was denied access to their children after transitioning.<sup id="cite_ref-hiltzik_19-2"><a href="#cite_note-hiltzik-19">[19]</a></sup>
</p><p>Although she had hoped to be allowed to transition on the job, IBM fired Conway in 1968 after she revealed her intention to transition.<sup id="cite_ref-Conway2012_20-0"><a href="#cite_note-Conway2012-20">[20]</a></sup> IBM apologized for this in 2020.<sup id="cite_ref-:1_21-0"><a href="#cite_note-:1-21">[21]</a></sup>
</p>
<h2><span id="Career_as_computer_scientist">Career as computer scientist</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=4" title="Edit section: Career as computer scientist"><span>edit</span></a><span>]</span></span></h2>
<p>Upon completing her <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">transition</a> in 1968, Conway took a new name and identity, and restarted her career in what she called "<a href="https://en.wikipedia.org/wiki/Passing_(gender)#Stealth" title="Passing (gender)">stealth-mode</a>" as a contract programmer at <a href="https://en.wikipedia.org/wiki/Computer_Applications,_Inc." title="Computer Applications, Inc.">Computer Applications, Inc.</a> She went on to work at <a href="https://en.wikipedia.org/wiki/Memorex" title="Memorex">Memorex</a> during 1969–1972 as a digital system designer and computer architect.<sup id="cite_ref-hiltzik_19-3"><a href="#cite_note-hiltzik-19">[19]</a></sup><sup id="cite_ref-22"><a href="#cite_note-22">[22]</a></sup>
</p><p>Conway joined <a href="https://en.wikipedia.org/wiki/Xerox_PARC" title="Xerox PARC">Xerox PARC</a> in 1973, where she led the "<a href="https://en.wikipedia.org/wiki/Large_Scale_Integration" title="Large Scale Integration">LSI</a> Systems" group under <a href="https://en.wikipedia.org/wiki/Bert_Sutherland" title="Bert Sutherland">Bert Sutherland</a>.<sup id="cite_ref-23"><a href="#cite_note-23">[23]</a></sup><sup id="cite_ref-24"><a href="#cite_note-24">[24]</a></sup> When in PARC, Conway founded the "multiproject wafers" (MPW). This new technology made it possible to pack multiple circuit designs from various sources into one single silicon wafer. Her new invention increased production and decreased costs.<sup id="cite_ref-25"><a href="#cite_note-25">[25]</a></sup> Collaborating with <a href="https://en.wikipedia.org/wiki/Ivan_Sutherland" title="Ivan Sutherland">Ivan Sutherland</a> and <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a> of <a href="https://en.wikipedia.org/wiki/Caltech" title="Caltech">Caltech</a> on VLSI <a href="https://en.wikipedia.org/wiki/Design_methodology" title="Design methodology">design methodology</a>, she co-authored <i>Introduction to VLSI Systems</i>, a groundbreaking work that would soon become a standard textbook in chip design, used in nearly 120 universities by 1983.<sup id="cite_ref-26"><a href="#cite_note-26">[26]</a></sup><sup id="cite_ref-auto_27-0"><a href="#cite_note-auto-27">[27]</a></sup><sup id="cite_ref-sciam002_28-0"><a href="#cite_note-sciam002-28">[28]</a></sup><sup id="cite_ref-compworld002_29-0"><a href="#cite_note-compworld002-29">[29]</a></sup> With over 70,000 copies sold, and the new integration of her MPC79/MOSIS innovations, the Mead and Conway revolution became part of VLSI design.<sup id="cite_ref-auto_27-1"><a href="#cite_note-auto-27">[27]</a></sup><sup id="cite_ref-30"><a href="#cite_note-30">[30]</a></sup>
</p><p>In 1978, Conway served as visiting associate professor of electrical engineering and computer science at <a href="https://en.wikipedia.org/wiki/MIT" title="MIT">MIT</a>, teaching a now famous VLSI design course based on a draft of the Mead–Conway text.<sup id="cite_ref-hiltzik_19-4"><a href="#cite_note-hiltzik-19">[19]</a></sup> The course validated the new design methods and textbook, and established the syllabus and instructor's guidebook used in later courses worldwide.<sup id="cite_ref-31"><a href="#cite_note-31">[31]</a></sup><sup id="cite_ref-penfield_32-0"><a href="#cite_note-penfield-32">[32]</a></sup>
</p><p>Among Conway's contributions were the invention of dimensionless, scalable <a href="https://en.wikipedia.org/wiki/Design_rule_checking" title="Design rule checking">design rules</a> that greatly simplified chip design and design tools,<sup id="cite_ref-comsocpioneeraward_8-2"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-kilbane_13-1"><a href="#cite_note-kilbane-13">[13]</a></sup><sup id="cite_ref-33"><a href="#cite_note-33">[33]</a></sup> and invention of a new form of internet-based infrastructure for <a href="https://en.wikipedia.org/wiki/Rapid_prototyping" title="Rapid prototyping">rapid prototyping</a> and short-run fabrication of large numbers of chip designs.<sup id="cite_ref-comsocpioneeraward_8-3"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup><sup id="cite_ref-NRC1999_34-0"><a href="#cite_note-NRC1999-34">[34]</a></sup> The problem they were solving was how to cope with the increasing complexity of chip design while the number of transistors per chip doubled every two years as <a href="https://en.wikipedia.org/wiki/Gordon_Moore" title="Gordon Moore">Gordon Moore</a>&nbsp;(chairman of Intel) had predicted in 1965. The design methods in use in the semiconductor industry were rapidly running out of steam.<sup id="cite_ref-35"><a href="#cite_note-35">[35]</a></sup> The new infrastructure was institutionalized as the <a href="https://en.wikipedia.org/wiki/MOSIS" title="MOSIS">Metal Oxide Semiconductor Implementation Service (MOSIS)</a> system in 1981. Two years into its success, Mead and Conway received <i><a href="https://en.wikipedia.org/wiki/Electronics_(magazine)" title="Electronics (magazine)">Electronics</a></i> magazine's annual award of achievement.<sup id="cite_ref-36"><a href="#cite_note-36">[36]</a></sup> Since then, MOSIS has fabricated more than 50,000 circuit designs for commercial firms, government agencies, and research and educational institutions around the world.<sup id="cite_ref-37"><a href="#cite_note-37">[37]</a></sup> VLSI researcher Charles Seitz commented that "MOSIS represented the first period since the pioneering work of Eckert and Mauchley on the <a href="https://en.wikipedia.org/wiki/ENIAC" title="ENIAC">ENIAC</a> in the late 1940s that universities and small companies had access to state-of-the-art digital technology."<sup id="cite_ref-NRC1999_34-1"><a href="#cite_note-NRC1999-34">[34]</a></sup>
</p><p>The research methods used to develop the Mead–Conway <a href="https://en.wikipedia.org/wiki/VLSI" title="VLSI">VLSI</a> design methodology and the <a href="https://en.wikipedia.org/wiki/MOSIS" title="MOSIS">MOSIS</a> prototype are documented in a 1981 Xerox report<sup id="cite_ref-38"><a href="#cite_note-38">[38]</a></sup> and the Euromicro Journal.<sup id="cite_ref-MPCAdv_39-0"><a href="#cite_note-MPCAdv-39">[39]</a></sup> The impact of the Mead–Conway work is described in a number of historical overviews of computing.<sup id="cite_ref-NRC1999_34-2"><a href="#cite_note-NRC1999-34">[34]</a></sup><sup id="cite_ref-sandtfedfund_40-0"><a href="#cite_note-sandtfedfund-40">[40]</a></sup><sup id="cite_ref-sandtfedfundfigureII13_41-0"><a href="#cite_note-sandtfedfundfigureII13-41">[41]</a></sup><sup id="cite_ref-evolvinghpc_42-0"><a href="#cite_note-evolvinghpc-42">[42]</a></sup><sup id="cite_ref-evolvinghpcfig1point2_43-0"><a href="#cite_note-evolvinghpcfig1point2-43">[43]</a></sup><sup id="cite_ref-44"><a href="#cite_note-44">[44]</a></sup> Conway and her colleagues have compiled an online archive of original papers that documents much of that work.<sup id="cite_ref-VLSIArchive_45-0"><a href="#cite_note-VLSIArchive-45">[45]</a></sup><sup id="cite_ref-46"><a href="#cite_note-46">[46]</a></sup> The methods also came under ethnographic study in 1980 by PARC anthropologist <a href="https://en.wikipedia.org/wiki/Lucy_Suchman" title="Lucy Suchman">Lucy Suchman</a>, who published her interviews with Conway in 2021.<sup id="cite_ref-47"><a href="#cite_note-47">[47]</a></sup><sup id="cite_ref-48"><a href="#cite_note-48">[48]</a></sup>
</p><p>In the early 1980s, Conway left Xerox to join <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a>, where she was a key architect of the <a href="https://en.wikipedia.org/wiki/United_States_Department_of_Defense" title="United States Department of Defense">Defense Department</a>'s <a href="https://en.wikipedia.org/wiki/Strategic_Computing_Initiative" title="Strategic Computing Initiative">Strategic Computing Initiative</a>, a research program studying high-performance computing, <a href="https://en.wikipedia.org/wiki/Autonomous_system_(Internet)" title="Autonomous system (Internet)">autonomous systems</a> technology, and intelligent weapons technology.<sup id="cite_ref-kilbane_13-2"><a href="#cite_note-kilbane-13">[13]</a></sup><sup id="cite_ref-davis_49-0"><a href="#cite_note-davis-49">[49]</a></sup>
</p><p>In a <i><a href="https://en.wikipedia.org/wiki/USA_Today" title="USA Today">USA Today</a></i> article about Conway's joining DARPA, Mark Stefik, a Xerox scientist who worked with her, said "Lynn would like to live five lives in the course of one life" and that she's "charismatic and very energetic".<sup id="cite_ref-Osborn_50-0"><a href="#cite_note-Osborn-50">[50]</a></sup> Douglas Fairbairn, a former Xerox associate, said "She figures out a way so that everybody wins."<sup id="cite_ref-Osborn_50-1"><a href="#cite_note-Osborn-50">[50]</a></sup>
</p><p>Conway joined the <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a> in 1985 as professor of <a href="https://en.wikipedia.org/wiki/Electrical_engineering" title="Electrical engineering">electrical engineering</a> and <a href="https://en.wikipedia.org/wiki/Computer_science" title="Computer science">computer science</a>, and associate dean of engineering. There she worked on "visual communications and control probing for basic system and user-interface concepts as applicable to hybridized internet/broadband-cable communications".<sup id="cite_ref-kilbane_13-3"><a href="#cite_note-kilbane-13">[13]</a></sup> She retired from active teaching and research in 1998, as <a href="https://en.wikipedia.org/wiki/Professor_emeritus#Other_designations" title="Professor emeritus">professor emerita</a> at Michigan.<sup id="cite_ref-emerita_51-0"><a href="#cite_note-emerita-51">[51]</a></sup>
</p>
<h2><span id="Legacy">Legacy</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=5" title="Edit section: Legacy"><span>edit</span></a><span>]</span></span></h2>
<p>As sociologist Thomas Streeter discusses in The Net Effect:<sup id="cite_ref-Streeter2013_52-0"><a href="#cite_note-Streeter2013-52">[52]</a></sup><sup id="cite_ref-Neff2013_53-0"><a href="#cite_note-Neff2013-53">[53]</a></sup> "By taking this job, Conway was demonstrating that she was no antiwar liberal. (In response to critics, she has said, 'if you have to fight, and sometimes you must in order to deal with bad people, history tells us that it really helps to have the best weapons available)".<sup id="cite_ref-conI_12-1"><a href="#cite_note-conI-12">[12]</a></sup> But Conway carried a sense of computers as tools for horizontal communications that she had absorbed at PARC right into <a href="https://en.wikipedia.org/wiki/DARPA" title="DARPA">DARPA</a> – at one of the hottest moments of the cold war."
</p><p>In the fall of 2012, the <a href="https://en.wikipedia.org/wiki/IEEE" title="IEEE">IEEE</a> published a special issue of the <i><a href="https://en.wikipedia.org/w/index.php?title=IEEE_Solid-State_Circuits_Magazine&amp;action=edit&amp;redlink=1" title="IEEE Solid-State Circuits Magazine (page does not exist)">IEEE Solid-State Circuits Magazine</a></i> devoted to Lynn Conway's career,<sup id="cite_ref-Lanzerotti2012_54-0"><a href="#cite_note-Lanzerotti2012-54">[54]</a></sup><sup id="cite_ref-eecsnews2013_55-0"><a href="#cite_note-eecsnews2013-55">[55]</a></sup> including a career memoir by Conway<sup id="cite_ref-Conway2012_20-1"><a href="#cite_note-Conway2012-20">[20]</a></sup> and peer commentaries by Chuck House,<sup id="cite_ref-House2012_56-0"><a href="#cite_note-House2012-56">[56]</a></sup> former Director of Engineering at HP, <a href="https://en.wikipedia.org/wiki/S%C3%A9quin" title="Séquin">Carlo Séquin</a>, Professor of EECS at U.C. Berkeley,<sup id="cite_ref-Sequin2012_57-0"><a href="#cite_note-Sequin2012-57">[57]</a></sup> and <a href="https://en.wikipedia.org/wiki/Kenneth_L_Shepard" title="Kenneth L Shepard">Ken Shepard</a>, of Columbia University.<sup id="cite_ref-Shepard2012_58-0"><a href="#cite_note-Shepard2012-58">[58]</a></sup> Subsequently the scope of Conway's contributions gained wider retrospective attention. "Since I didn't <a href="https://en.wikipedia.org/wiki/I_Look_Like_an_Engineer" title="I Look Like an Engineer">#LookLikeanEngineer</a>, few people caught on to what I was really doing back in the 70s and 80s," says Conway.<sup id="cite_ref-:1_21-1"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>"Clearly a new paradigm had emerged ... Importantly, imaginative support in terms of infrastructure and idea dissemination proved as valuable as the concepts, tools, and chips. The "electronic book" and the "foundry" were both prescient and necessary, providing momentum and proof-points."<sup id="cite_ref-House2012_56-1"><a href="#cite_note-House2012-56">[56]</a></sup> <a href="https://en.wikipedia.org/wiki/James_F._Gibbons" title="James F. Gibbons">James F. "Jim" Gibbons</a>, former dean of engineering at Stanford University, further states that Lynn Conway, from his perspective, "...was the singular force behind the entire '<a href="https://en.wikipedia.org/wiki/Foundry_model" title="Foundry model">foundry</a>' development that emerged."<sup id="cite_ref-House2012_56-2"><a href="#cite_note-House2012-56">[56]</a></sup> <a href="https://en.wikipedia.org/wiki/Kenneth_L_Shepard" title="Kenneth L Shepard">Kenneth Shepard</a>, Professor of Biomedical and Electrical Engineering at Columbia University, stated that "Lynn's amazing story of accomplishment and personal triumph in the face of personal adversity and overt discrimination should serve as an inspiration to all young engineers."<sup id="cite_ref-Shepard2012_58-1"><a href="#cite_note-Shepard2012-58">[58]</a></sup><sup id="cite_ref-59"><a href="#cite_note-59">[59]</a></sup>
</p><p>In 2020, NAE President <a href="https://en.wikipedia.org/wiki/John_L._Anderson" title="John L. Anderson">John L. Anderson</a> stated that "Lynn Conway is not only a revolutionary pioneer in the design of VLSI systems ... But just as important, Lynn has been very brave in telling her own story, and her perseverance has been a reminder to society that it should not be blind to the innovations of women, people of color, or others who don't fit long outdated – but unfortunately, persistent – perceptions of what an engineer looks like."<sup id="cite_ref-:1_21-2"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>In 2023, Lynn Conway collaborated with Jim Boulton to create Lines in the Sand,<sup id="cite_ref-60"><a href="#cite_note-60">[60]</a></sup> a short comic book that tells the story of Conway's groundbreaking invention of <a href="https://en.wikipedia.org/wiki/Very-large-scale_integration" title="Very-large-scale integration">Very Large-Scale Integration</a> (VLSI). The launch event<sup id="cite_ref-61"><a href="#cite_note-61">[61]</a></sup> took place at the <a href="https://en.wikipedia.org/wiki/Centre_for_Computing_History" title="Centre for Computing History">Centre for Computing History</a> on November 23, 2023
</p>
<h2><span id="Transgender_activism">Transgender activism</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=6" title="Edit section: Transgender activism"><span>edit</span></a><span>]</span></span></h2>
<p>When nearing retirement, Conway learned that the story of her early work at <a href="https://en.wikipedia.org/wiki/IBM" title="IBM">IBM</a> might soon be revealed through the investigations of Mark Smotherman that were being prepared for a 2001 publication.<sup id="cite_ref-smoth01_7-2"><a href="#cite_note-smoth01-7">[7]</a></sup> She began quietly <a href="https://en.wikipedia.org/wiki/Coming_out" title="Coming out">coming out</a> in 1999 to friends and colleagues about her past <a href="https://en.wikipedia.org/wiki/Transitioning_(transgender)" title="Transitioning (transgender)">gender transition</a>,<sup id="cite_ref-BD06LC_62-0"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-ED03a_63-0"><a href="#cite_note-ED03a-63">[63]</a></sup><sup id="cite_ref-ASEEPrismOct2011_64-0"><a href="#cite_note-ASEEPrismOct2011-64">[64]</a></sup> using her personal website to tell the story in her own words.<sup id="cite_ref-conI_12-2"><a href="#cite_note-conI-12">[12]</a></sup> Her story was then more widely reported in 2000 in profiles in <i><a href="https://en.wikipedia.org/wiki/Scientific_American" title="Scientific American">Scientific American</a></i><sup id="cite_ref-sciam00_14-1"><a href="#cite_note-sciam00-14">[14]</a></sup> and the <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i>.<sup id="cite_ref-hiltzik_19-5"><a href="#cite_note-hiltzik-19">[19]</a></sup> In a later <i><a href="https://en.wikipedia.org/wiki/Forbes" title="Forbes">Forbes</a></i> interview, Conway commented "From the 1970s to 1999 I was recognized as breaking the gender barrier in the computer science field as a woman, but in 2000 it became the transgender barrier I was breaking."<sup id="cite_ref-:1_21-3"><a href="#cite_note-:1-21">[21]</a></sup>
</p><p>After going public with her story, she began work in <a href="https://en.wikipedia.org/wiki/Transgender_activism" title="Transgender activism">transgender activism</a>, intending to "illuminate and normalize the issues of gender identity and the processes of gender transition".<sup id="cite_ref-65"><a href="#cite_note-65">[65]</a></sup> She has worked to protect and expand the <a href="https://en.wikipedia.org/wiki/LGBT_rights_by_country_or_territory" title="LGBT rights by country or territory">rights of transgender people</a>. She has provided direct and indirect assistance to numerous other transgender women going through transition and maintains a website providing medical resources and emotional advice. Parts have been translated into most of the world's major languages.<sup id="cite_ref-translation_66-0"><a href="#cite_note-translation-66">[66]</a></sup> She maintained a listing of many successful post-transition transgender people, to, in her words "provide role models for individuals who are facing gender transition".<sup id="cite_ref-67"><a href="#cite_note-67">[67]</a></sup> Her website also provided news related to transgender issues and information on <a href="https://en.wikipedia.org/wiki/Sex_reassignment_surgery_male-to-female" title="Sex reassignment surgery male-to-female">sex reassignment surgery for transsexual women</a>, <a href="https://en.wikipedia.org/wiki/Facial_feminization_surgery" title="Facial feminization surgery">facial feminization surgery</a>, academic inquiries into the prevalence of <a href="https://en.wikipedia.org/wiki/Transsexualism" title="Transsexualism">transsexualism</a><sup id="cite_ref-prevalence_68-0"><a href="#cite_note-prevalence-68">[68]</a></sup> and transgender and transsexual issues in general.<sup id="cite_ref-HRCProfile_69-0"><a href="#cite_note-HRCProfile-69">[69]</a></sup><sup id="cite_ref-LGBTHistoryMonthProfile_70-0"><a href="#cite_note-LGBTHistoryMonthProfile-70">[70]</a></sup>
</p><p>She has also advocated for <a href="https://en.wikipedia.org/wiki/Equal_opportunity" title="Equal opportunity">equal opportunities</a> and <a href="https://en.wikipedia.org/wiki/Employment_protection_legislation" title="Employment protection legislation">employment protections</a> for <a href="https://en.wikipedia.org/wiki/Transgender_people" title="Transgender people">transgender people</a> in high-technology industry,<sup id="cite_ref-HP01_71-0"><a href="#cite_note-HP01-71">[71]</a></sup><sup id="cite_ref-FCC01_72-0"><a href="#cite_note-FCC01-72">[72]</a></sup><sup id="cite_ref-Adv01_73-0"><a href="#cite_note-Adv01-73">[73]</a></sup><sup id="cite_ref-Intel03_74-0"><a href="#cite_note-Intel03-74">[74]</a></sup><sup id="cite_ref-PT03_75-0"><a href="#cite_note-PT03-75">[75]</a></sup><sup id="cite_ref-76"><a href="#cite_note-76">[76]</a></sup> and for elimination of the <a href="https://en.wikipedia.org/wiki/Gender_identity_disorder" title="Gender identity disorder">pathologization of transgender people</a> by the psychiatric community.<sup id="cite_ref-77"><a href="#cite_note-77">[77]</a></sup><sup id="cite_ref-78"><a href="#cite_note-78">[78]</a></sup>
</p><p>Conway has been a critic of the <a href="https://en.wikipedia.org/wiki/Blanchard,_Bailey,_and_Lawrence_theory" title="Blanchard, Bailey, and Lawrence theory">Blanchard, Bailey, and Lawrence theory</a> of male-to-female transsexualism that all <a href="https://en.wikipedia.org/wiki/Trans_woman" title="Trans woman">trans women</a> are motivated either by <a href="https://en.wikipedia.org/wiki/Homosexual_transsexual" title="Homosexual transsexual">feminine homosexuality</a> or <a href="https://en.wikipedia.org/wiki/Autogynephilia" title="Autogynephilia">autogynephilia</a>.<sup id="cite_ref-carey_79-0"><a href="#cite_note-carey-79">[79]</a></sup> Along with American transgender rights activist <a href="https://en.wikipedia.org/wiki/Andrea_James" title="Andrea James">Andrea James</a> and University of Chicago economics professor <a href="https://en.wikipedia.org/wiki/Deirdre_McCloskey" title="Deirdre McCloskey">Dierdre McCloskey</a>, she was also a key person in the campaign against <a href="https://en.wikipedia.org/wiki/J._Michael_Bailey" title="J. Michael Bailey">J. Michael Bailey</a>'s book about the theory, <i><a href="https://en.wikipedia.org/wiki/The_Man_Who_Would_Be_Queen" title="The Man Who Would Be Queen">The Man Who Would Be Queen</a>.</i><sup id="cite_ref-dreger2008_80-0"><a href="#cite_note-dreger2008-80">[80]</a></sup><sup id="cite_ref-81"><a href="#cite_note-81">[81]</a></sup> Conway and McCloskey wrote letters to Northwestern University, accusing Bailey of "conducting intimate research observations on human subjects without telling them that they were objects of the study."<sup id="cite_ref-carey_79-1"><a href="#cite_note-carey-79">[79]</a></sup> American bioethicist <a href="https://en.wikipedia.org/wiki/Alice_Dreger" title="Alice Dreger">Alice Dreger</a> in her book <i>Galilieo's Middle Finger</i> criticized Conway for filing a lawsuit against Bailey which had "no legal basis", referring to her allegation that Bailey lacked a license as a clinical psychologist when he wrote letters in support of a young trans woman seeking to transition. According to Dreger, as Bailey did not receive compensation for his services, he would not have needed a license in Illinois, and was "completely forthright in his letters supporting the women, both about the fact that he had only had brief conversations with them (as opposed to having provided them with extensive counseling) and about his own qualifications and expertise... [and] even attached copies of his CV." As Dreger argues, "presumably all this was why [Illinois] never bothered to pursue the charge."<sup id="cite_ref-82"><a href="#cite_note-82">[82]</a></sup> In response, Conway argued that Dreger "deflects attention away from Bailey's book and the massive trans community protest, and caricatures the entire controversy as nothing more than a vicious effort by three rather witch-like women to 'ruin the life' of a brilliant scientist.<sup id="cite_ref-83"><a href="#cite_note-83">[83]</a></sup>
</p><p>Conway was a cast member in the first all-transgender performance of <i><a href="https://en.wikipedia.org/wiki/The_Vagina_Monologues" title="The Vagina Monologues">The Vagina Monologues</a></i> in <a href="https://en.wikipedia.org/wiki/Los_Angeles" title="Los Angeles">Los Angeles</a> in 2004,<sup id="cite_ref-VD04_84-0"><a href="#cite_note-VD04-84">[84]</a></sup> and appeared in a LOGO-Channel documentary film about that event entitled <i>Beautiful Daughters.</i><sup id="cite_ref-BD06LC_62-1"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-BD06_85-0"><a href="#cite_note-BD06-85">[85]</a></sup>
</p><p>In 2009, Conway was named one of the "Stonewall 40 trans heroes" on the 40th anniversary of the <a href="https://en.wikipedia.org/wiki/Stonewall_riots" title="Stonewall riots">Stonewall riots</a> by the <a href="https://en.wikipedia.org/wiki/International_Court_System" title="International Court System">International Court System</a>, one of the oldest and largest predominantly gay organizations in the world, and the <a href="https://en.wikipedia.org/wiki/National_Gay_and_Lesbian_Task_Force" title="National Gay and Lesbian Task Force">National Gay and Lesbian Task Force</a>.<sup id="cite_ref-trans40_86-0"><a href="#cite_note-trans40-86">[86]</a></sup><sup id="cite_ref-ngltf_87-0"><a href="#cite_note-ngltf-87">[87]</a></sup>
</p><p>In 2013, with support from many hi-tech thought-leaders, Conway and Leandra Vicci of the <a href="https://en.wikipedia.org/wiki/University_of_North_Carolina_at_Chapel_Hill" title="University of North Carolina at Chapel Hill">University of North Carolina at Chapel Hill</a> lobbied the directors of the <a href="https://en.wikipedia.org/wiki/Institute_of_Electrical_and_Electronics_Engineers" title="Institute of Electrical and Electronics Engineers">Institute of Electrical and Electronics Engineers</a> (IEEE), the world's largest professional engineering society, for transgender inclusion in the IEEE's code of ethics.<sup id="cite_ref-Beyer2014_88-0"><a href="#cite_note-Beyer2014-88">[88]</a></sup> The code, known within the profession as much as a code of honor as one of ethics, became fully <a href="https://en.wikipedia.org/wiki/LGBT" title="LGBT">LGBT</a> inclusive in January 2014.<sup id="cite_ref-ieeeglance_89-0"><a href="#cite_note-ieeeglance-89">[89]</a></sup><sup id="cite_ref-ieeeethics_90-0"><a href="#cite_note-ieeeethics-90">[90]</a></sup><sup id="cite_ref-McCarty2014_91-0"><a href="#cite_note-McCarty2014-91">[91]</a></sup> 
</p><p>In 2014, <i><a href="https://en.wikipedia.org/wiki/Time_Magazine" title="Time Magazine">Time Magazine</a></i> named Conway as one of "21 Transgender People Who Influenced American Culture".<sup id="cite_ref-Time21Culture_6-1"><a href="#cite_note-Time21Culture-6">[6]</a></sup>
</p><p>In 2015, she was selected for inclusion in "The Trans100"<sup id="cite_ref-2015trans100_92-0"><a href="#cite_note-2015trans100-92">[92]</a></sup> and was interviewed in 2020 for inclusion in the Trans Activism Oral History Project.<sup id="cite_ref-93"><a href="#cite_note-93">[93]</a></sup>
</p>
<h2><span id="Personal_life">Personal life</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=7" title="Edit section: Personal life"><span>edit</span></a><span>]</span></span></h2>
<p>In 1987, Conway met her husband Charles "Charlie" Rogers, a professional engineer who shares her interest in the outdoors, including <a href="https://en.wikipedia.org/wiki/Whitewater_canoeing" title="Whitewater canoeing">whitewater canoeing</a> and <a href="https://en.wikipedia.org/wiki/Motocross_racing" title="Motocross racing">motocross racing</a>.<sup id="cite_ref-hiltzik_19-6"><a href="#cite_note-hiltzik-19">[19]</a></sup><sup id="cite_ref-Forman2013_94-0"><a href="#cite_note-Forman2013-94">[94]</a></sup> They soon started living together, and bought a house with 24 acres (9.7&nbsp;ha) of meadow, marsh, and woodland in rural <a href="https://en.wikipedia.org/wiki/Michigan" title="Michigan">Michigan</a> in 1994.<sup id="cite_ref-hiltzik_19-7"><a href="#cite_note-hiltzik-19">[19]</a></sup> On August 13, 2002, they were married.<sup id="cite_ref-ABCnews01_15-1"><a href="#cite_note-ABCnews01-15">[15]</a></sup><sup id="cite_ref-BD06LC_62-2"><a href="#cite_note-BD06LC-62">[62]</a></sup><sup id="cite_ref-95"><a href="#cite_note-95">[95]</a></sup> In 2014, the University of Michigan's <i>The Michigan Engineer</i> alumni magazine documented the connections between Conway's engineering explorations and the adventures in her personal life.<sup id="cite_ref-moore2014_96-0"><a href="#cite_note-moore2014-96">[96]</a></sup><sup id="cite_ref-Szczepanski2014_97-0"><a href="#cite_note-Szczepanski2014-97">[97]</a></sup>
</p>
<h2><span id="Awards_and_honors">Awards and honors</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=8" title="Edit section: Awards and honors"><span>edit</span></a><span>]</span></span></h2>
<p>Conway has received a number of awards and distinctions:
</p>
<ul><li><i><a href="https://en.wikipedia.org/wiki/Electronics_(magazine)" title="Electronics (magazine)">Electronics</a></i> 1981 Award for Achievement, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a><sup id="cite_ref-98"><a href="#cite_note-98">[98]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Harold_Pender_Award" title="Harold Pender Award">Harold Pender Award</a> of the <a href="https://en.wikipedia.org/wiki/Moore_School" title="Moore School">Moore School</a>, <a href="https://en.wikipedia.org/wiki/University_of_Pennsylvania" title="University of Pennsylvania">University of Pennsylvania</a>, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a>, 1984<sup id="cite_ref-99"><a href="#cite_note-99">[99]</a></sup></li>
<li>IEEE EAB Major Educational Innovation Award, 1984<sup id="cite_ref-100"><a href="#cite_note-100">[100]</a></sup></li>
<li>Fellow of the <a href="https://en.wikipedia.org/wiki/IEEE" title="IEEE">IEEE</a>, 1985, "for contributions to VLSI technology"<sup id="cite_ref-101"><a href="#cite_note-101">[101]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/John_Price_Wetherill_Medal" title="John Price Wetherill Medal">John Price Wetherill Medal</a> of the <a href="https://en.wikipedia.org/wiki/Franklin_Institute" title="Franklin Institute">Franklin Institute</a>, with <a href="https://en.wikipedia.org/wiki/Carver_Mead" title="Carver Mead">Carver Mead</a>, 1985<sup id="cite_ref-102"><a href="#cite_note-102">[102]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Secretary_of_Defense_Meritorious_Civilian_Service_Award" title="Secretary of Defense Meritorious Civilian Service Award">Secretary of Defense Meritorious Civilian Service Award</a>, May 1985<sup id="cite_ref-emerita_51-1"><a href="#cite_note-emerita-51">[51]</a></sup><sup id="cite_ref-SecMAA_103-0"><a href="#cite_note-SecMAA-103">[103]</a></sup></li>
<li>Member of the <a href="https://en.wikipedia.org/wiki/National_Academy_of_Engineering" title="National Academy of Engineering">National Academy of Engineering</a>, 1989<sup id="cite_ref-104"><a href="#cite_note-104">[104]</a></sup></li>
<li>National Achievement Award, <a href="https://en.wikipedia.org/wiki/Society_of_Women_Engineers" title="Society of Women Engineers">Society of Women Engineers</a>, 1990<sup id="cite_ref-105"><a href="#cite_note-105">[105]</a></sup></li>
<li>Presidential Appointment to the <a href="https://en.wikipedia.org/wiki/United_States_Air_Force_Academy#Board_of_Visitors" title="United States Air Force Academy">United States Air Force Academy Board of Visitors</a>, 1996<sup id="cite_ref-106"><a href="#cite_note-106">[106]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Trinity_College_(Connecticut)" title="Trinity College (Connecticut)">Trinity College</a>, 1998<sup id="cite_ref-107"><a href="#cite_note-107">[107]</a></sup></li>
<li><i><a href="https://en.wikipedia.org/wiki/Electronic_Design_(magazine)" title="Electronic Design (magazine)">Electronic Design</a></i> Hall of Fame, 2002<sup id="cite_ref-108"><a href="#cite_note-108">[108]</a></sup></li>
<li>Engineer of the Year, <a href="https://en.wikipedia.org/wiki/National_Organization_of_Gay_and_Lesbian_Scientists_and_Technical_Professionals" title="National Organization of Gay and Lesbian Scientists and Technical Professionals">National Organization of Gay and Lesbian Scientists and Technical Professionals</a>, 2005<sup id="cite_ref-109"><a href="#cite_note-109">[109]</a></sup></li>
<li>Named one of the "Stonewall 40 trans heroes" by the <a href="https://en.wikipedia.org/wiki/Imperial_Court_System" title="Imperial Court System">Imperial Court System</a> and the <a href="https://en.wikipedia.org/wiki/National_LGBTQ_Task_Force" title="National LGBTQ Task Force">National LGBTQ Task Force</a>, 2009.<sup id="cite_ref-trans40_86-1"><a href="#cite_note-trans40-86">[86]</a></sup><sup id="cite_ref-ngltf_87-1"><a href="#cite_note-ngltf-87">[87]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Computer_Pioneer_Award" title="Computer Pioneer Award">Computer Pioneer Award</a>, <a href="https://en.wikipedia.org/wiki/IEEE_Computer_Society" title="IEEE Computer Society">IEEE Computer Society</a>, 2009<sup id="cite_ref-comsocpioneeraward_8-4"><a href="#cite_note-comsocpioneeraward-8">[8]</a></sup></li>
<li>Member of the Corporation, Emerita, The Charles Stark <a href="https://en.wikipedia.org/wiki/Draper_Laboratory" title="Draper Laboratory">Draper Laboratory</a>, 1993–2010<sup id="cite_ref-110"><a href="#cite_note-110">[110]</a></sup></li>
<li>Fellow Award, <a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a>, 2014, "For her work in developing and disseminating new methods of integrated circuit design."<sup id="cite_ref-111"><a href="#cite_note-111">[111]</a></sup><sup id="cite_ref-112"><a href="#cite_note-112">[112]</a></sup><sup id="cite_ref-113"><a href="#cite_note-113">[113]</a></sup><sup id="cite_ref-114"><a href="#cite_note-114">[114]</a></sup><sup id="cite_ref-115"><a href="#cite_note-115">[115]</a></sup><sup id="cite_ref-116"><a href="#cite_note-116">[116]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Illinois_Institute_of_Technology" title="Illinois Institute of Technology">Illinois Institute of Technology</a>, 2014<sup id="cite_ref-117"><a href="#cite_note-117">[117]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/Steinmetz_Memorial_Lecture" title="Steinmetz Memorial Lecture">Steinmetz Memorial Lecture</a>, (Invitational), IEEE/<a href="https://en.wikipedia.org/wiki/Union_College" title="Union College">Union College</a>, 2015.<sup id="cite_ref-118"><a href="#cite_note-118">[118]</a></sup><sup id="cite_ref-119"><a href="#cite_note-119">[119]</a></sup><sup id="cite_ref-120"><a href="#cite_note-120">[120]</a></sup><sup id="cite_ref-121"><a href="#cite_note-121">[121]</a></sup><sup id="cite_ref-122"><a href="#cite_note-122">[122]</a></sup></li>
<li><a href="https://en.wikipedia.org/wiki/IEEE_Maxwell_Award" title="IEEE Maxwell Award">IEEE/RSE James Clerk Maxwell Medal</a>, 2015<sup id="cite_ref-123"><a href="#cite_note-123">[123]</a></sup><sup id="cite_ref-124"><a href="#cite_note-124">[124]</a></sup><sup id="cite_ref-125"><a href="#cite_note-125">[125]</a></sup><sup id="cite_ref-126"><a href="#cite_note-126">[126]</a></sup><sup id="cite_ref-127"><a href="#cite_note-127">[127]</a></sup><sup id="cite_ref-128"><a href="#cite_note-128">[128]</a></sup><sup id="cite_ref-129"><a href="#cite_note-129">[129]</a></sup><sup id="cite_ref-130"><a href="#cite_note-130">[130]</a></sup></li>
<li>Magill Lecture in Science, Technology and the Arts (Invited), Columbia University, 2016<sup id="cite_ref-131"><a href="#cite_note-131">[131]</a></sup><sup id="cite_ref-132"><a href="#cite_note-132">[132]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/University_of_Victoria" title="University of Victoria">University of Victoria</a>, 2016<sup id="cite_ref-133"><a href="#cite_note-133">[133]</a></sup><sup id="cite_ref-134"><a href="#cite_note-134">[134]</a></sup><sup id="cite_ref-135"><a href="#cite_note-135">[135]</a></sup><sup id="cite_ref-136"><a href="#cite_note-136">[136]</a></sup><sup id="cite_ref-137"><a href="#cite_note-137">[137]</a></sup></li>
<li>Fellow Award, <a href="https://en.wikipedia.org/wiki/American_Association_for_the_Advancement_of_Science" title="American Association for the Advancement of Science">American Association for the Advancement of Science</a> (AAAS), 2016<sup id="cite_ref-138"><a href="#cite_note-138">[138]</a></sup><sup id="cite_ref-139"><a href="#cite_note-139">[139]</a></sup><sup id="cite_ref-140"><a href="#cite_note-140">[140]</a></sup><sup id="cite_ref-141"><a href="#cite_note-141">[141]</a></sup></li>
<li>Honorary Doctorate and Commencement Address, University of Michigan, Ann Arbor, 2018<sup id="cite_ref-142"><a href="#cite_note-142">[142]</a></sup><sup id="cite_ref-143"><a href="#cite_note-143">[143]</a></sup><sup id="cite_ref-144"><a href="#cite_note-144">[144]</a></sup><sup id="cite_ref-145"><a href="#cite_note-145">[145]</a></sup></li>
<li>Pioneer in Tech Award, National Center for Women in Technology (NCWIT), 2019<sup id="cite_ref-146"><a href="#cite_note-146">[146]</a></sup></li>
<li>Lifetime Achievement Award, IBM Corporation, 2020<sup id="cite_ref-:0_147-0"><a href="#cite_note-:0-147">[147]</a></sup></li>
<li>Induction into the <a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame (NIHF)</a>, 2023<sup id="cite_ref-148"><a href="#cite_note-148">[148]</a></sup><sup id="cite_ref-149"><a href="#cite_note-149">[149]</a></sup><sup id="cite_ref-150"><a href="#cite_note-150">[150]</a></sup><sup id="cite_ref-151"><a href="#cite_note-151">[151]</a></sup><sup id="cite_ref-152"><a href="#cite_note-152">[152]</a></sup></li>
<li>Honorary Doctorate, <a href="https://en.wikipedia.org/wiki/Princeton_University" title="Princeton University">Princeton University</a>, 2023.<sup id="cite_ref-153"><a href="#cite_note-153">[153]</a></sup></li>
<li>Honorary Doctor of Science, <a href="https://en.wikipedia.org/wiki/Syracuse_University" title="Syracuse University">Syracuse University</a>, 2024<sup id="cite_ref-154"><a href="#cite_note-154">[154]</a></sup></li></ul>
<h2><span id="IBM.27s_apology"></span><span id="IBM's_apology">IBM's apology</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=9" title="Edit section: IBM's apology"><span>edit</span></a><span>]</span></span></h2>
<p>In 2020, 52 years after IBM fired her for being transgender, IBM officially and publicly apologized to Conway;<sup id="cite_ref-155"><a href="#cite_note-155">[155]</a></sup><sup id="cite_ref-156"><a href="#cite_note-156">[156]</a></sup><sup id="cite_ref-157"><a href="#cite_note-157">[157]</a></sup><sup id="cite_ref-158"><a href="#cite_note-158">[158]</a></sup><sup id="cite_ref-159"><a href="#cite_note-159">[159]</a></sup><sup id="cite_ref-160"><a href="#cite_note-160">[160]</a></sup> IBM held a public event "Tech Trailblazer and Transgender Pioneer Lynn Conway in conversation with Diane Gherson" (IBM's senior VP of HR); IBM's Director of Research Dario Gil said "Lynn was recently awarded the rare IBM Lifetime Achievement Award, given to individuals who have changed the world through technology inventions. Lynn's extraordinary technical achievements helped define the modern computing industry. She paved the way for how we design and make computing chips today – and forever changed microelectronics, devices, and people's lives."<sup id="cite_ref-:0_147-1"><a href="#cite_note-:0-147">[147]</a></sup>
</p>
<h2><span id="Selected_works">Selected works</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=10" title="Edit section: Selected works"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFMeadConway1980">Mead, Carver; Conway, Lynn (1980). <span title="Free registration required"><a rel="nofollow" href="https://archive.org/details/introductiontovl00mead"><i>Introduction to VLSI Systems</i></a></span>. Addison-Wesley. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0201043580" title="Special:BookSources/0201043580"><bdi>0201043580</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+VLSI+Systems&amp;rft.pub=Addison-Wesley&amp;rft.date=1980&amp;rft.isbn=0201043580&amp;rft.aulast=Mead&amp;rft.aufirst=Carver&amp;rft.au=Conway%2C+Lynn&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fintroductiontovl00mead&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1981">Conway, L. (February 1981). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv.pdf">"THE MPC ADVENTURES: Experiences with the Generation of VLSI Design and Implementation Methodologies"</a> <span>(PDF)</span>. <i>Xerox PARC Technical Report VLSI-81-2</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Xerox+PARC+Technical+Report+VLSI-81-2&amp;rft.atitle=THE+MPC+ADVENTURES%3A+Experiences+with+the+Generation+of+VLSI+Design+and+Implementation+Methodologies&amp;rft.date=1981-02&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FMPCAdv%2FMPCAdv.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1982">Conway, L. (September 23, 1982). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/ESSCIRC82/The%20Design%20of%20VLSI%20Design%20Methods.pdf">"The Design of VLSI Design Methods"</a> <span>(PDF)</span>. <i>Proc. VUB European Solid-State Circuits Conference (Invited Lecture)</i>. Vrije Universiteit Brüssel, Brussels, Belgium: 106–117.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proc.+VUB+European+Solid-State+Circuits+Conference+%28Invited+Lecture%29&amp;rft.atitle=The+Design+of+VLSI+Design+Methods&amp;rft.pages=106-117&amp;rft.date=1982-09-23&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FESSCIRC82%2FThe%2520Design%2520of%2520VLSI%2520Design%2520Methods.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2012">Conway, Lynn (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Lynn_Conway_VLSI_Reminiscences.pdf">"Reminiscences of the VLSI Revolution: How a Series of Failures Triggered a Paradigm Shift in Digital Design"</a> <span>(PDF)</span>. <i>Solid-State Circuits Magazine</i>. Vol.&nbsp;4, no.&nbsp;4. IEEE. pp.&nbsp;8–31. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215752">10.1109/MSSC.2012.2215752</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Solid-State+Circuits+Magazine&amp;rft.atitle=Reminiscences+of+the+VLSI+Revolution%3A+How+a+Series+of+Failures+Triggered+a+Paradigm+Shift+in+Digital+Design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=8-31&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215752&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FLynn_Conway_VLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2018">Conway, L. (October 2018). <a rel="nofollow" href="https://www.computer.org/csdl/magazine/co/2018/10/mco2018100066/17D45WXIkDI">"The Disappeared: Beyond Winning and Losing"</a>. <i>Computer</i>. Vol.&nbsp;51. IEEE Computer Society. pp.&nbsp;66–73.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Computer&amp;rft.atitle=The+Disappeared%3A+Beyond+Winning+and+Losing&amp;rft.volume=51&amp;rft.pages=66-73&amp;rft.date=2018-10&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fwww.computer.org%2Fcsdl%2Fmagazine%2Fco%2F2018%2F10%2Fmco2018100066%2F17D45WXIkDI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway2011">Conway, Lynn (2011). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/ACS/Lynn_Conway_ACS_Reminiscences.pdf">"IBM-ACS: Reminiscences and Lessons Learned from a 1960's Supercomputer Project"</a> <span>(PDF)</span>. In Jones, C. B.; Lloyd, J. L. (eds.). <i>Dependable and Historic Computing: Essays Dedicated to Brian Randell on the Occasion of his 75th Birthday</i>. Springer-Verlag. pp.&nbsp;185–224. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-3-642-24541-1" title="Special:BookSources/978-3-642-24541-1"><bdi>978-3-642-24541-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=IBM-ACS%3A+Reminiscences+and+Lessons+Learned+from+a+1960%27s+Supercomputer+Project&amp;rft.btitle=Dependable+and+Historic+Computing%3A+Essays+Dedicated+to+Brian+Randell+on+the+Occasion+of+his+75th+Birthday&amp;rft.pages=185-224&amp;rft.pub=Springer-Verlag&amp;rft.date=2011&amp;rft.isbn=978-3-642-24541-1&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FACS%2FLynn_Conway_ACS_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway">Conway, Lynn. <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/Archive/ACSarchive.html">"Lynn Conway's IBM-ACS Archive"</a>. University of Michigan<span>. Retrieved <span>June 4,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway%27s+IBM-ACS+Archive&amp;rft.pub=University+of+Michigan&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FArchive%2FACSarchive.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConwayRandellSenzig1966">Conway, L.; <a href="https://en.wikipedia.org/wiki/Brian_Randell" title="Brian Randell">Randell, Brian</a>; Senzig, D. (February 23, 1966). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/DIS/DIS.pdf">"Dynamic Instruction Scheduling"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Dynamic+Instruction+Scheduling&amp;rft.date=1966-02-23&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft.au=Randell%2C+Brian&amp;rft.au=Senzig%2C+D.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FDIS%2FDIS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFRozenbergConwayRiekert1966">Rozenberg, D.; Conway, L.; Riekert, R. (March 15, 1966). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/SimTech/SimTech.pdf">"ACS Simulation Technique"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ACS+Simulation+Technique&amp;rft.date=1966-03-15&amp;rft.aulast=Rozenberg&amp;rft.aufirst=D.&amp;rft.au=Conway%2C+L.&amp;rft.au=Riekert%2C+R.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FSimTech%2FSimTech.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L. (August 25, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/MPMSim/MPMSim.pdf">"MPM Timing Simulation"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=MPM+Timing+Simulation&amp;rft.date=1967-08-25&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FMPMSim%2FMPMSim.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L. (November 29, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/LogDes/LogDes.pdf">"ACS Logic Design Conventions: A Guide for the Novice"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=ACS+Logic+Design+Conventions%3A+A+Guide+for+the+Novice&amp;rft.date=1967-11-29&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FLogDes%2FLogDes.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1967">Conway, L (October 31, 1967). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/LSS/LSS.pdf">"A Proposed ACS Logic Simulation System"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=A+Proposed+ACS+Logic+Simulation+System&amp;rft.date=1967-10-31&amp;rft.aulast=Conway&amp;rft.aufirst=L&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FLSS%2FLSS.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li>
<li><cite id="CITEREFConway1968">Conway, L. (August 6, 1968). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/ACS/DesProc/DesignProcess.pdf">"The Computer Design Process: A Proposed Plan for ACS"</a> <span>(PDF)</span>. IBM-ACS.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=The+Computer+Design+Process%3A+A+Proposed+Plan+for+ACS&amp;rft.date=1968-08-06&amp;rft.aulast=Conway&amp;rft.aufirst=L.&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FACS%2FDesProc%2FDesignProcess.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li></ul>
<h2><span id="Patents">Patents</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=11" title="Edit section: Patents"><span>edit</span></a><span>]</span></span></h2>
<ul><li><span id="CITEREFConwayVolzWalker1991"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5046022">US 5046022</a>, Conway, Lynn; Volz, Richard &amp; Walker, Michael, "Teleautonomous System and Method Employing Time/Position Synchrony/Desynchrony", issued September 3, 1991.</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5046022&amp;rft.cc=US&amp;rft.title=Teleautonomous+System+and+Method+Employing+Time%2FPosition+Synchrony%2FDesynchrony&amp;rft.inventor=Conway&amp;rft.date=September 3, 1991."></span></li>
<li><span id="CITEREFConway1995"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5444476">US 5444476</a>, Conway, Lynn, "System and Method for Teleinteraction", issued August 22, 1995</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5444476&amp;rft.cc=US&amp;rft.title=System+and+Method+for+Teleinteraction&amp;rft.inventor=Conway&amp;rft.date=August 22, 1995"></span></li>
<li><span id="CITEREFConwayCohen1997"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5652849">US 5652849</a>, Conway, Lynn &amp; Cohen, Charles, "Apparatus and Method for Remote Control Using a Visual Information Stream", issued July 20, 1997</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5652849&amp;rft.cc=US&amp;rft.title=Apparatus+and+Method+for+Remote+Control+Using+a+Visual+Information+Stream&amp;rft.inventor=Conway&amp;rft.date=July 20, 1997"></span></li>
<li><span id="CITEREFConway1998"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5719622">US 5719622</a>, Conway, Lynn, "Visual Control Selection of Remote Mechanisms", issued February 17, 1998</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5719622&amp;rft.cc=US&amp;rft.title=Visual+Control+Selection+of+Remote+Mechanisms&amp;rft.inventor=Conway&amp;rft.date=February 17, 1998"></span></li>
<li><span id="CITEREFConway1998"><a rel="nofollow" href="https://worldwide.espacenet.com/textdoc?DB=EPODOC&amp;IDX=US5745782">US 5745782</a>, Conway, Lynn, "Method and System for Organizing and Presenting Audio/Visual Information", issued April 28, 1998</span><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Apatent&amp;rft.number=5745782&amp;rft.cc=US&amp;rft.title=Method+and+System+for+Organizing+and+Presenting+Audio%2FVisual+Information&amp;rft.inventor=Conway&amp;rft.date=April 28, 1998"></span></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=12" title="Edit section: References"><span>edit</span></a><span>]</span></span></h2>
<div>
<ol>
<li id="cite_note-1"><span><b><a href="#cite_ref-1">^</a></b></span> <span><cite><a rel="nofollow" href="https://computerhistory.org/profile/lynn-conway/">"CHM 2014 Fellow "For her work in developing and disseminating new methods of integrated circuit design"<span></span>"</a>. <i>Computer History Museum</i>. <a rel="nofollow" href="https://web.archive.org/web/20160703014527/http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">Archived</a> from the original on July 3, 2016<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+History+Museum&amp;rft.atitle=CHM+2014+Fellow+%22For+her+work+in+developing+and+disseminating+new+methods+of+integrated+circuit+design%22&amp;rft_id=https%3A%2F%2Fcomputerhistory.org%2Fprofile%2Flynn-conway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-2"><span><b><a href="#cite_ref-2">^</a></b></span> <span><cite id="CITEREFSaariAllisonEllavich1996">Saari, Peggy; Allison, Stephen; Ellavich, Marie C. (1996). <a rel="nofollow" href="https://books.google.com/books?id=8VVvtWrIxtAC"><i>Scientists: A-F</i></a>. U-X-L. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/978-0-7876-0960-3" title="Special:BookSources/978-0-7876-0960-3"><bdi>978-0-7876-0960-3</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Scientists%3A+A-F&amp;rft.pub=U-X-L&amp;rft.date=1996&amp;rft.isbn=978-0-7876-0960-3&amp;rft.aulast=Saari&amp;rft.aufirst=Peggy&amp;rft.au=Allison%2C+Stephen&amp;rft.au=Ellavich%2C+Marie+C.&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3D8VVvtWrIxtAC&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-3"><span><b><a href="#cite_ref-3">^</a></b></span> <span><cite id="CITEREFBoyd">Boyd, Helen. <a rel="nofollow" href="http://www.myhusbandbetty.com/wordPressNEW/2024/06/11/lynn-conway-january-2-1938-june-9-2024/">"Lynn Conway: Trans Icon and Pioneer, 1938 – 2024"</a>. <i>(En)gender</i>. <a rel="nofollow" href="https://web.archive.org/web/20240611172823/http://www.myhusbandbetty.com/wordPressNEW/2024/06/11/lynn-conway-january-2-1938-june-9-2024/">Archived</a> from the original on June 11, 2024<span>. Retrieved <span>June 11,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=%28En%29gender&amp;rft.atitle=Lynn+Conway%3A+Trans+Icon+and+Pioneer%2C+1938+%E2%80%93+2024&amp;rft.aulast=Boyd&amp;rft.aufirst=Helen&amp;rft_id=http%3A%2F%2Fwww.myhusbandbetty.com%2FwordPressNEW%2F2024%2F06%2F11%2Flynn-conway-january-2-1938-june-9-2024%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Lee1995-4"><span><b><a href="#cite_ref-Lee1995_4-0">^</a></b></span> <span><cite id="CITEREFLee1995">Lee, John A. N. (1995). <a rel="nofollow" href="https://archive.org/details/internationalbio00john"><i>International Biographical Dictionary of Computer Pioneers</i></a>. Fitzroy Dearborn. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/1-884964-47-8" title="Special:BookSources/1-884964-47-8"><bdi>1-884964-47-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=International+Biographical+Dictionary+of+Computer+Pioneers&amp;rft.pub=Fitzroy+Dearborn&amp;rft.date=1995&amp;rft.isbn=1-884964-47-8&amp;rft.aulast=Lee&amp;rft.aufirst=John+A.+N.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Finternationalbio00john&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20141110182854/http://computer.org/computer-pioneers/conway.html">"Computer Pioneers - Lynn Conway"</a>. <i>IEEE Computer Society</i>. IEEE. Archived from <a rel="nofollow" href="http://computer.org/computer-pioneers/conway.html">the original</a> on November 10, 2014<span>. Retrieved <span>November 10,</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IEEE+Computer+Society&amp;rft.atitle=Computer+Pioneers+-+Lynn+Conway&amp;rft_id=http%3A%2F%2Fcomputer.org%2Fcomputer-pioneers%2Fconway.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Time21Culture-6"><span>^ <a href="#cite_ref-Time21Culture_6-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Time21Culture_6-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="http://time.com/130734/transgender-celebrities-actors-athletes-in-america/">"21 Transgender People Who Influenced American Culture"</a>. <i>Time</i>. May 29, 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Time&amp;rft.atitle=21+Transgender+People+Who+Influenced+American+Culture&amp;rft.date=2014-05-29&amp;rft_id=http%3A%2F%2Ftime.com%2F130734%2Ftransgender-celebrities-actors-athletes-in-america%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-smoth01-7"><span>^ <a href="#cite_ref-smoth01_7-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-smoth01_7-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-smoth01_7-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFSmotherman">Smotherman, Mark. <a rel="nofollow" href="http://www.cs.clemson.edu/~mark/acs.html">"IBM Advanced Computing Systems (ACS) – 1961–1969"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IBM+Advanced+Computing+Systems+%28ACS%29+%E2%80%93+1961%E2%80%931969&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.cs.clemson.edu%2F~mark%2Facs.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-comsocpioneeraward-8"><span>^ <a href="#cite_ref-comsocpioneeraward_8-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-comsocpioneeraward_8-4"><sup><i><b>e</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20150103172210/http://www.computer.org/portal/web/awards/conway">"Lynn Conway: 2009 Computer Pioneer Award Recipient"</a>. <i>IEEE Computer Society</i>. Archived from <a rel="nofollow" href="http://www.computer.org/portal/web/awards/conway">the original</a> on January 3, 2015<span>. Retrieved <span>January 20,</span> 2010</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=IEEE+Computer+Society&amp;rft.atitle=Lynn+Conway%3A+2009+Computer+Pioneer+Award+Recipient&amp;rft_id=http%3A%2F%2Fwww.computer.org%2Fportal%2Fweb%2Fawards%2Fconway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-comsocpioneersawardvideo-9"><span>^ <a href="#cite_ref-comsocpioneersawardvideo_9-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-comsocpioneersawardvideo_9-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=i4Txvjia3p0"><i>Lynn Conway receives 2009 IEEE Computer Society Computer Pioneer Award</i></a>. IEEE Computer Society. July 30, 2010 – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+receives+2009+IEEE+Computer+Society+Computer+Pioneer+Award&amp;rft.pub=IEEE+Computer+Society&amp;rft.date=2010-07-30&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Di4Txvjia3p0&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-superproj60b-10"><span>^ <a href="#cite_ref-superproj60b_10-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-superproj60b_10-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://computerhistory.org/events/ibm-acs-system-pioneering-supercomputer/">"CHM Events: IBM ACS System: A Pioneering Supercomputer Project of the 1960's"</a>. <i>Computer History Museum</i>. February 18, 2010. <a rel="nofollow" href="https://web.archive.org/web/20100420225250/http://www.computerhistory.org/events/index.php?id=1264112339">Archived</a> from the original on April 20, 2010.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+History+Museum&amp;rft.atitle=CHM+Events%3A+IBM+ACS+System%3A+A+Pioneering+Supercomputer+Project+of+the+1960%27s&amp;rft.date=2010-02-18&amp;rft_id=https%3A%2F%2Fcomputerhistory.org%2Fevents%2Fibm-acs-system-pioneering-supercomputer%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-IBMsmotherman-11"><span>^ <a href="#cite_ref-IBMsmotherman_11-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-IBMsmotherman_11-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFSmothermanSpicer2010">Smotherman, Mark; Spicer, Dag (December 2010). <a rel="nofollow" href="https://cacm.acm.org/opinion/ibms-single-processor-supercomputer-efforts/">"IBM's single-processor supercomputer efforts"</a>. <i><a href="https://en.wikipedia.org/wiki/Communications_of_the_ACM" title="Communications of the ACM">Communications of the ACM</a></i>. <b>53</b> (12): 28–30. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1145%2F1859204.1859216">10.1145/1859204.1859216</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=IBM%27s+single-processor+supercomputer+efforts&amp;rft.volume=53&amp;rft.issue=12&amp;rft.pages=28-30&amp;rft.date=2010-12&amp;rft_id=info%3Adoi%2F10.1145%2F1859204.1859216&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft.au=Spicer%2C+Dag&amp;rft_id=https%3A%2F%2Fcacm.acm.org%2Fopinion%2Fibms-single-processor-supercomputer-efforts%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-conI-12"><span>^ <a href="#cite_ref-conI_12-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-conI_12-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-conI_12-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFConway2004">Conway, Lynn (March 15, 2004). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Retrospective1.html">"Lynn Conway's Retrospective PART I: CHILDHOOD AND EDUCATION"</a>. <i>lynnconway.com</i><span>. Retrieved <span>July 9,</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lynnconway.com&amp;rft.atitle=Lynn+Conway%27s+Retrospective+PART+I%3A+CHILDHOOD+AND+EDUCATION&amp;rft.date=2004-03-15&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FRetrospective1.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-kilbane-13"><span>^ <a href="#cite_ref-kilbane_13-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-kilbane_13-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-kilbane_13-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-kilbane_13-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFKilbane2003">Kilbane, Doris (October 20, 2003). <a rel="nofollow" href="https://www.electronicdesign.com/news/products/article/21795291/lynn-conway-a-trailblazer-on-professional-personal-levels">"Lynn Conway: A Trailblazer On Professional, Personal Levels"</a>. Products &gt; News. <i><a href="https://en.wikipedia.org/wiki/Electronic_Design_(magazine)" title="Electronic Design (magazine)">Electronic Design</a></i>. <a rel="nofollow" href="https://web.archive.org/web/20080608190427/http://electronicdesign.com/Articles/Index.cfm?AD=1&amp;ArticleID=5833">Archived</a> from the original on 2008-06-08<span>. Retrieved <span>2023-02-17</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Electronic+Design&amp;rft.atitle=Lynn+Conway%3A+A+Trailblazer+On+Professional%2C+Personal+Levels&amp;rft.date=2003-10-20&amp;rft.aulast=Kilbane&amp;rft.aufirst=Doris&amp;rft_id=https%3A%2F%2Fwww.electronicdesign.com%2Fnews%2Fproducts%2Farticle%2F21795291%2Flynn-conway-a-trailblazer-on-professional-personal-levels&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-sciam00-14"><span>^ <a href="#cite_ref-sciam00_14-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-sciam00_14-1"><sup><i><b>b</b></i></sup></a></span> <span>Paul Wallich, "<a rel="nofollow" href="http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">Profile: Lynn Conway—Completing the Circuit</a> <a rel="nofollow" href="https://web.archive.org/web/20131004233454/http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">Archived</a> October 4, 2013, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>," Scientific American, December 2000.</span>
</li>
<li id="cite_note-ABCnews01-15"><span>^ <a href="#cite_ref-ABCnews01_15-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ABCnews01_15-1"><sup><i><b>b</b></i></sup></a></span> <span>Dianne Lynch, "<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/ABC%20NEWS/ABCNEWS_com%20%20Wired%20Women%20Engineer%20Lynn%20Conway%27s%20Secret.htm">The Secret Behind 'Project Y': One Woman's Success Story — 'What Works, Works'</a>", ABCNews.com, November 29, 2001.</span>
</li>
<li id="cite_note-chm_ibm_acs_reunion-16"><span><b><a href="#cite_ref-chm_ibm_acs_reunion_16-0">^</a></b></span> <span><cite id="CITEREFSmotherman">Smotherman, Mark. <a rel="nofollow" href="http://www.cs.clemson.edu/~mark/acs_reunion.html">"IBM ACS Reunion – February 18, 2010, in California"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IBM+ACS+Reunion+%E2%80%93+February+18%2C+2010%2C+in+California&amp;rft.aulast=Smotherman&amp;rft.aufirst=Mark&amp;rft_id=http%3A%2F%2Fwww.cs.clemson.edu%2F~mark%2Facs_reunion.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-chm_ibm_acs_video-17"><span><b><a href="#cite_ref-chm_ibm_acs_video_17-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=pod53_F6urQ">"The IBM ACS System: A Pioneering Supercomputer Project – Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/pod53_F6urQ">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=The+IBM+ACS+System%3A+A+Pioneering+Supercomputer+Project+%E2%80%93+Video&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dpod53_F6urQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-18"><span><b><a href="#cite_ref-18">^</a></b></span> <span>
<cite id="CITEREFBenjamin1966">Benjamin, Harry (1966). <i>The Transsexual Phenomenon</i>. Julian Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780446824262" title="Special:BookSources/9780446824262"><bdi>9780446824262</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+Transsexual+Phenomenon&amp;rft.pub=Julian+Press&amp;rft.date=1966&amp;rft.isbn=9780446824262&amp;rft.aulast=Benjamin&amp;rft.aufirst=Harry&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-hiltzik-19"><span>^ <a href="#cite_ref-hiltzik_19-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-hiltzik_19-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-hiltzik_19-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-hiltzik_19-3"><sup><i><b>d</b></i></sup></a> <a href="#cite_ref-hiltzik_19-4"><sup><i><b>e</b></i></sup></a> <a href="#cite_ref-hiltzik_19-5"><sup><i><b>f</b></i></sup></a> <a href="#cite_ref-hiltzik_19-6"><sup><i><b>g</b></i></sup></a> <a href="#cite_ref-hiltzik_19-7"><sup><i><b>h</b></i></sup></a></span> <span>Hiltzik, Michael A. (November 19, 2000.) <a rel="nofollow" href="https://pqasb.pqarchiver.com/latimes/access/64332921.html?dids=64332921:64332921&amp;FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+19%2C+2000&amp;author=MICHAEL+A.+HILTZIK&amp;pub=Los+Angeles+Times&amp;edition=&amp;startpage=1&amp;desc=COVER+STORY%3B+Through+the+Gender+Labyrinth%3B+How+a+bright+boy+with+a+penchant+for+tinkering+grew+up+to+be+one+of+the+top+women+in+her+high-+tech+field">"Through the Gender Labyrinth."</a> <a rel="nofollow" href="https://web.archive.org/web/20121015144026/http://pqasb.pqarchiver.com/latimes/access/64332921.html?dids=64332921:64332921&amp;FMT=ABS&amp;FMTS=ABS:FT&amp;date=Nov+19,+2000&amp;author=MICHAEL+A.+HILTZIK&amp;pub=Los+Angeles+Times&amp;edition=&amp;startpage=1&amp;desc=COVER+STORY%3B+Through+the+Gender+Labyrinth%3B+How+a+bright+boy+with+a+penchant+for+tinkering+grew+up+to+be+one+of+the+top+women+in+her+high-+tech+field">Archived</a> October 15, 2012, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>. <i>Los Angeles Times</i>, Los Angeles Times Magazine, page 1. (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Through%20the%20Gender%20Labyrinth.pdf">Free reprint</a>. Retrieved on September 19, 2007.)</span>
</li>
<li id="cite_note-Conway2012-20"><span>^ <a href="#cite_ref-Conway2012_20-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Conway2012_20-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFConway2012">Conway, Lynn (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Lynn_Conway_VLSI_Reminiscences.pdf">"Reminiscences of the VLSI revolution: How a series of failures triggered a paradigm shift in digital design"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 8–31. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215752">10.1109/MSSC.2012.2215752</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:9286356">9286356</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Reminiscences+of+the+VLSI+revolution%3A+How+a+series+of+failures+triggered+a+paradigm+shift+in+digital+design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=8-31&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A9286356%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215752&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FLynn_Conway_VLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-:1-21"><span>^ <a href="#cite_ref-:1_21-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:1_21-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-:1_21-2"><sup><i><b>c</b></i></sup></a> <a href="#cite_ref-:1_21-3"><sup><i><b>d</b></i></sup></a></span> <span><cite id="CITEREFAlicandri">Alicandri, Jeremy. <a rel="nofollow" href="https://www.forbes.com/sites/jeremyalicandri/2020/11/18/ibm-apologizes-for-firing-computer-pioneer/">"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later"</a>. <i>Forbes</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Forbes&amp;rft.atitle=IBM+Apologizes+For+Firing+Computer+Pioneer+For+Being+Transgender...52+Years+Later&amp;rft.aulast=Alicandri&amp;rft.aufirst=Jeremy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fjeremyalicandri%2F2020%2F11%2F18%2Fibm-apologizes-for-firing-computer-pioneer%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-22"><span><b><a href="#cite_ref-22">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Retrospective3.html">"Lynn Conway's Retrospective PART III: Starting Over"</a>. Ai.eecs.umich.edu. May 12, 1960<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway%27s+Retrospective+PART+III%3A+Starting+Over&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1960-05-12&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FRetrospective3.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-23"><span><b><a href="#cite_ref-23">^</a></b></span> <span><cite id="CITEREFGoldberg1980">Goldberg, Adele J. (September 1980). <a rel="nofollow" href="https://scholar.google.com/scholar?hl=en&amp;lr=&amp;safe=off&amp;q=conway+lsi-systems-group&amp;btnG=Search">"About This Issue..."</a> <i><a href="https://en.wikipedia.org/wiki/ACM_Computing_Surveys" title="ACM Computing Surveys">ACM Computing Surveys</a></i>. <b>12</b> (3): 257–258. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<span title="Freely accessible"><a rel="nofollow" href="https://doi.org/10.1145%2F356819.356820">10.1145/356819.356820</a></span>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/0360-0300">0360-0300</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:27661653">27661653</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=ACM+Computing+Surveys&amp;rft.atitle=About+This+Issue...&amp;rft.volume=12&amp;rft.issue=3&amp;rft.pages=257-258&amp;rft.date=1980-09&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A27661653%23id-name%3DS2CID&amp;rft.issn=0360-0300&amp;rft_id=info%3Adoi%2F10.1145%2F356819.356820&amp;rft.aulast=Goldberg&amp;rft.aufirst=Adele+J.&amp;rft_id=https%3A%2F%2Fscholar.google.com%2Fscholar%3Fhl%3Den%26lr%3D%26safe%3Doff%26q%3Dconway%2Blsi-systems-group%26btnG%3DSearch&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-24"><span><b><a href="#cite_ref-24">^</a></b></span> <span><cite id="CITEREFWalkerTersini1992">Walker, Rob; Tersini, Nancy (1992). <a rel="nofollow" href="https://books.google.com/books?id=XA9Zx1bMH-oC&amp;q=lynn-conway+parc+sutherland&amp;pg=PT206"><i>Silicon Destiny: The Story of Application Specific Integrated Circuits and LSI Logic Corporation</i></a>. Walker Research Associates. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-9632654-0-7" title="Special:BookSources/0-9632654-0-7"><bdi>0-9632654-0-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Silicon+Destiny%3A+The+Story+of+Application+Specific+Integrated+Circuits+and+LSI+Logic+Corporation&amp;rft.pub=Walker+Research+Associates&amp;rft.date=1992&amp;rft.isbn=0-9632654-0-7&amp;rft.aulast=Walker&amp;rft.aufirst=Rob&amp;rft.au=Tersini%2C+Nancy&amp;rft_id=https%3A%2F%2Fbooks.google.com%2Fbooks%3Fid%3DXA9Zx1bMH-oC%26q%3Dlynn-conway%2Bparc%2Bsutherland%26pg%3DPT206&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-25"><span><b><a href="#cite_ref-25">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/sense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway">"Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway"</a>. <i>American Association for the Advancement of Science</i><span>. Retrieved <span>March 20,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=American+Association+for+the+Advancement+of+Science&amp;rft.atitle=Sense+of+Wonder+Motivates+VLSI+Chip+Revolutionary%2C+Lynn+Conway&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Fsense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-26"><span><b><a href="#cite_ref-26">^</a></b></span> <span><cite id="CITEREFConway2012">Conway, Lynn (December 31, 2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/BackgroundContext/Sutherland_Letter.html">"The 'Sutherland Letter' of 1976"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+%27Sutherland+Letter%27+of+1976&amp;rft.date=2012-12-31&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FBackgroundContext%2FSutherland_Letter.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-auto-27"><span>^ <a href="#cite_ref-auto_27-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-auto_27-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html">"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service"</a>. <i>ai.eecs.umich.edu</i><span>. Retrieved <span>March 13,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.eecs.umich.edu&amp;rft.atitle=Impact+of+the+Mead-Conway+VLSI+Design+Methodology+and+of+the+MOSIS+Service&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-sciam002-28"><span><b><a href="#cite_ref-sciam002_28-0">^</a></b></span> <span><cite id="CITEREFWallich2000">Wallich, Paul (December 2000). <a rel="nofollow" href="https://web.archive.org/web/20061028031127/http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">"Profile: Lynn Conway—Completing the Circuit"</a>. <i>Scientific American</i>. Archived from <a rel="nofollow" href="http://www.sciamdigital.com/index.cfm?fa=Products.ViewIssuePreview&amp;ARTICLEID_CHAR=D1E5F66F-2A45-4BF9-BE9E-001B49F7F67">the original</a> on October 28, 2006<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Scientific+American&amp;rft.atitle=Profile%3A+Lynn+Conway%E2%80%94Completing+the+Circuit&amp;rft.date=2000-12&amp;rft.aulast=Wallich&amp;rft.aufirst=Paul&amp;rft_id=http%3A%2F%2Fwww.sciamdigital.com%2Findex.cfm%3Ffa%3DProducts.ViewIssuePreview%26ARTICLEID_CHAR%3DD1E5F66F-2A45-4BF9-BE9E-001B49F7F67&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-compworld002-29"><span><b><a href="#cite_ref-compworld002_29-0">^</a></b></span> <span><cite id="CITEREFSmith2007">Smith, Gina (December 3, 2007). <a rel="nofollow" href="https://web.archive.org/web/20081226130335/http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9046420">"Unsung innovators: Lynn Conway and Carver Mead: They literally wrote the book on chip design"</a>. <i>Computerworld</i>. Archived from <a rel="nofollow" href="http://www.computerworld.com/action/article.do?command=viewArticleBasic&amp;articleId=9046420">the original</a> on December 26, 2008<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computerworld&amp;rft.atitle=Unsung+innovators%3A+Lynn+Conway+and+Carver+Mead%3A+They+literally+wrote+the+book+on+chip+design&amp;rft.date=2007-12-03&amp;rft.aulast=Smith&amp;rft.aufirst=Gina&amp;rft_id=http%3A%2F%2Fwww.computerworld.com%2Faction%2Farticle.do%3Fcommand%3DviewArticleBasic%26articleId%3D9046420&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-30"><span><b><a href="#cite_ref-30">^</a></b></span> <span><cite id="CITEREFMiller2022">Miller, Chris (2022). <i>Chip War: The Fight for the World's Most Critical Technology</i>. Scribner. pp.&nbsp;136–137, 140, 166, 378.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Chip+War%3A+The+Fight+for+the+World%27s+Most+Critical+Technology&amp;rft.pages=136-137%2C+140%2C+166%2C+378&amp;rft.pub=Scribner&amp;rft.date=2022&amp;rft.aulast=Miller&amp;rft.aufirst=Chris&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-31"><span><b><a href="#cite_ref-31">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/InstGuide/InstGuide.pdf"><i>The MIT'78 VLSI System Design Course: A Guidebook for the Instructor of VLSI System Design</i></a>, Lynn Conway, Xerox Palo Alto Research Center, August 12, 1979.</span>
</li>
<li id="cite_note-penfield-32"><span><b><a href="#cite_ref-penfield_32-0">^</a></b></span> <span>Paul Penfield <a rel="nofollow" href="http://issuu.com/miteecs/docs/connector2014_acc15802878d20">"The VLSI Revolution at MIT" by Paul Penfield</a> <i>2014 MIT EECS Connector</i>, Spring 2014, pp. 11–13.</span>
</li>
<li id="cite_note-33"><span><b><a href="#cite_ref-33">^</a></b></span> <span><cite id="CITEREFCarliss_Y._Baldwin_and_Kim_B._Clark2000">Carliss Y. Baldwin and Kim B. Clark (2000). <i>Design Rules: The Power of Modularity</i>. MIT Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/0-262-02466-7" title="Special:BookSources/0-262-02466-7"><bdi>0-262-02466-7</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Design+Rules%3A+The+Power+of+Modularity&amp;rft.pub=MIT+Press&amp;rft.date=2000&amp;rft.isbn=0-262-02466-7&amp;rft.au=Carliss+Y.+Baldwin+and+Kim+B.+Clark&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-NRC1999-34"><span>^ <a href="#cite_ref-NRC1999_34-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-NRC1999_34-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-NRC1999_34-2"><sup><i><b>c</b></i></sup></a></span> <span>National Research Council (1999), <i>Funding a Revolution: Government Support for Computing Research</i>, National Academy Press (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/FundingaRevolution.html#anchor200964">excerpt</a>)</span>
</li>
<li id="cite_note-35"><span><b><a href="#cite_ref-35">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20240425001048/https://interfaces.che.wisc.edu/lynn-conway/">"Lynn Conway"</a>. <i>Gebbie Lab</i>. January 29, 2024. Archived from <a rel="nofollow" href="https://interfaces.che.wisc.edu/lynn-conway/">the original</a> on April 25, 2024<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Gebbie+Lab&amp;rft.atitle=Lynn+Conway&amp;rft.date=2024-01-29&amp;rft_id=https%3A%2F%2Finterfaces.che.wisc.edu%2Flynn-conway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-36"><span><b><a href="#cite_ref-36">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html">"Impact of the Mead-Conway VLSI Design Methodology and of the MOSIS Service"</a>. <i>ai.eecs.umich.edu</i><span>. Retrieved <span>March 22,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=ai.eecs.umich.edu&amp;rft.atitle=Impact+of+the+Mead-Conway+VLSI+Design+Methodology+and+of+the+MOSIS+Service&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-37"><span><b><a href="#cite_ref-37">^</a></b></span> <span>"The MOSIS Service – More than 50,000 designs in 25 years of operation", <a rel="nofollow" href="http://www.mosis.com/">http://www.mosis.com/</a>, 2008</span>
</li>
<li id="cite_note-38"><span><b><a href="#cite_ref-38">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv.pdf"><i>THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies</i></a>, Lynn Conway, Xerox PARC Technical Report VLSI-81-2, January 19, 1981.</span>
</li>
<li id="cite_note-MPCAdv-39"><span><b><a href="#cite_ref-MPCAdv_39-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/MPCAdv/MPCAdv-MM-TEJ.pdf"><i>THE MPC Adventures: Experiences with the Generation of VLSI Design and Implementation Methodologies</i></a>, by Lynn Conway, Microprocessing and Microprogramming – The Euromicro Journal, Vol. 10, No. 4, November 1982, pp 209–228.</span>
</li>
<li id="cite_note-sandtfedfund-40"><span><b><a href="#cite_ref-sandtfedfund_40-0">^</a></b></span> <span><a rel="nofollow" href="http://books.nap.edu/catalog.php?record_id=5040"><i>Allocating Federal Funds for Science and Technology</i></a>, by Committee on Criteria for Federal Support of Research and Development, National Academy of Sciences, National Academy of Engineering, Institute of Medicine, National Research Council, National Academy Press, Washington DC, 1995, page 75.</span>
</li>
<li id="cite_note-sandtfedfundfigureII13-41"><span><b><a href="#cite_ref-sandtfedfundfigureII13_41-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html#Figure.II.13">"<i>Figure II.13: Technological Developments in Computing", in Allocating Federal Funds for Science and Technology, National Academy Press, Washington, DC 1995, page 75.</i>"</a>. Ai.eecs.umich.edu. May 7, 1999<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Figure+II.13%3A+Technological+Developments+in+Computing%22%2C+in+Allocating+Federal+Funds+for+Science+and+Technology%2C+National+Academy+Press%2C+Washington%2C+DC+1995%2C+page+75.&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1999-05-07&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html%23Figure.II.13&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-evolvinghpc-42"><span><b><a href="#cite_ref-evolvinghpc_42-0">^</a></b></span> <span><a rel="nofollow" href="http://www.nap.edu/catalog/4948.html"><i>Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure</i></a>, by Committee to Study High Performance Computing and Communications: Status of a Major Initiative, National Research Council, National Academy Press, Washington DC, 1995, page 20.</span>
</li>
<li id="cite_note-evolvinghpcfig1point2-43"><span><b><a href="#cite_ref-evolvinghpcfig1point2_43-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Impact/Impact.html#Figure.1.2">"<i>Figure 1.2: Government-sponsored computing research and development stimulates creation of innovative ideas and industries", in Evolving the High Performance Computing and Communications Initiative to Support the Nation's Information Infrastructure, National Academy Press, 1995, page 20.</i>"</a>. Ai.eecs.umich.edu. May 7, 1999<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Figure+1.2%3A+Government-sponsored+computing+research+and+development+stimulates+creation+of+innovative+ideas+and+industries%22%2C+in+Evolving+the+High+Performance+Computing+and+Communications+Initiative+to+Support+the+Nation%27s+Information+Infrastructure%2C+National+Academy+Press%2C+1995%2C+page+20.&amp;rft.pub=Ai.eecs.umich.edu&amp;rft.date=1999-05-07&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FImpact%2FImpact.html%23Figure.1.2&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-44"><span><b><a href="#cite_ref-44">^</a></b></span> <span><cite id="CITEREFFeinstein2023">Feinstein, Jonathan S. (2023). <i>Creativity in Large-Scale Contexts</i>. Stanford University Press. pp.&nbsp;196–199, 266–270, 299–304.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Creativity+in+Large-Scale+Contexts&amp;rft.pages=196-199%2C+266-270%2C+299-304&amp;rft.pub=Stanford+University+Press&amp;rft.date=2023&amp;rft.aulast=Feinstein&amp;rft.aufirst=Jonathan+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-VLSIArchive-45"><span><b><a href="#cite_ref-VLSIArchive_45-0">^</a></b></span> <span><i><a rel="nofollow" href="https://web.archive.org/web/20120509201451/http://www.edn.com/blog/EDA_Graffiti/35566-Guest_blog_Lynn_Conway.php">The VLSI Archive</a></i> <a rel="nofollow" href="https://archive.today/20130208045553/http://www.edn.com/blog/920000692/post/760045076.html">Archived</a> February 8, 2013, at <a href="https://en.wikipedia.org/wiki/Archive.today" title="Archive.today">archive.today</a>, by Lynn Conway, Electronic Design News, June 3, 2009.</span>
</li>
<li id="cite_note-46"><span><b><a href="#cite_ref-46">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/VLSI/VLSIarchive.html">"VLSI Archive: An online archive of documents and artifacts from the Mead-Conway VLSI design revolution"</a>. Ai.eecs.umich.edu. <a rel="nofollow" href="https://web.archive.org/web/20071208161339/http://ai.eecs.umich.edu/people/conway/VLSI/VLSIarchive.html">Archived</a> from the original on December 8, 2007<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=VLSI+Archive%3A+An+online+archive+of+documents+and+artifacts+from+the+Mead-Conway+VLSI+design+revolution&amp;rft.pub=Ai.eecs.umich.edu&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FVLSI%2FVLSIarchive.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-47"><span><b><a href="#cite_ref-47">^</a></b></span> <span><cite id="CITEREFSuchman2021">Suchman, Lucy (March 1, 2021). <a rel="nofollow" href="https://www.4sonline.org/a-sociotechnical-exchange-redux/">"A Sociotechnical Exchange, Redux"</a>. <i>Backchannels | Reflections</i>. <a rel="nofollow" href="https://web.archive.org/web/20210304182920/https://www.4sonline.org/a-sociotechnical-exchange-redux/">Archived</a> from the original on March 4, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Backchannels+%7C+Reflections&amp;rft.atitle=A+Sociotechnical+Exchange%2C+Redux&amp;rft.date=2021-03-01&amp;rft.aulast=Suchman&amp;rft.aufirst=Lucy&amp;rft_id=https%3A%2F%2Fwww.4sonline.org%2Fa-sociotechnical-exchange-redux%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-48"><span><b><a href="#cite_ref-48">^</a></b></span> <span><cite id="CITEREFConwaySuchman2021">Conway, Lynn; Suchman, Lucy (February 28, 2021). <a rel="nofollow" href="https://conwaysuchman-conv.pubpub.org/pub/93808pq4/release/4">"Conway-Suchman conversation"</a>. <i>Conway Suchman Conversation</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Conway+Suchman+Conversation&amp;rft.atitle=Conway-Suchman+conversation&amp;rft.date=2021-02-28&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft.au=Suchman%2C+Lucy&amp;rft_id=https%3A%2F%2Fconwaysuchman-conv.pubpub.org%2Fpub%2F93808pq4%2Frelease%2F4&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-davis-49"><span><b><a href="#cite_ref-davis_49-0">^</a></b></span> <span>Dwight B. Davis <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/CSE/SCI/HighTechnology4-85.pdf">"Assessing the Stragetic Computing Initiative," by Dwight B. Davis</a> <i>High Technology</i>, Vol. 5, No. 4, April 1985.</span>
</li>
<li id="cite_note-Osborn-50"><span>^ <a href="#cite_ref-Osborn_50-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Osborn_50-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFOsborn1983">Osborn, Michelle (June 7, 1983). <a rel="nofollow" href="https://web.archive.org/web/20140420032946/https://ai.eecs.umich.edu/people/conway/Memoirs/DARPA/USA_Today_6-07-83.pdf">"Hi-tech researcher chips in to develop smart computer"</a> <span>(PDF)</span>. USA Today. Archived from <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/DARPA/USA_Today_6-07-83.pdf">the original</a> <span>(PDF)</span> on April 20, 2014<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Hi-tech+researcher+chips+in+to+develop+smart+computer&amp;rft.pub=USA+Today&amp;rft.date=1983-06-07&amp;rft.aulast=Osborn&amp;rft.aufirst=Michelle&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FDARPA%2FUSA_Today_6-07-83.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-emerita-51"><span>^ <a href="#cite_ref-emerita_51-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-emerita_51-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20031205144225/https://ai.eecs.umich.edu/people/conway/Awards/Emerita.html">"Lynn Conway awarded Emerita status at the University of Michigan"</a>. University of Michigan. December 31, 1998. Archived from <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Emerita.html">the original</a> on December 5, 2003<span>. Retrieved <span>April 24,</span> 2024</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+awarded+Emerita+status+at+the+University+of+Michigan&amp;rft.pub=University+of+Michigan&amp;rft.date=1998-12-31&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FAwards%2FEmerita.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Streeter2013-52"><span><b><a href="#cite_ref-Streeter2013_52-0">^</a></b></span> <span><a rel="nofollow" href="http://www.uvm.edu/~tstreete/Net_Effect/">"The Net Effect, Romanticism, Capitalism, and the Internet"</a>, Thomas Steeter, New York University Press, 2011, p, 101.</span>
</li>
<li id="cite_note-Neff2013-53"><span><b><a href="#cite_ref-Neff2013_53-0">^</a></b></span> <span><a rel="nofollow" href="http://culturedigitally.org/2013/04/the-net-effect-a-culture-digitally-dialogue/">"On Streeter's The Net Effect: A Culture Digitally Dialogue"</a>, Gina Neff, Mary Gray, and Thomas Streeter, April 25, 2013.</span>
</li>
<li id="cite_note-Lanzerotti2012-54"><span><b><a href="#cite_ref-Lanzerotti2012_54-0">^</a></b></span> <span><cite id="CITEREFLanzerotti2012">Lanzerotti, Mary, ed. (2012). <a rel="nofollow" href="http://www.eecs.umich.edu/eecs/about/articles/2013/VLSI_Reminiscences.pdf">"Editor's Note"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b>. IEEE: 1. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2214274">10.1109/MSSC.2012.2214274</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Editor%27s+Note&amp;rft.volume=4&amp;rft.pages=1&amp;rft.date=2012&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2214274&amp;rft_id=http%3A%2F%2Fwww.eecs.umich.edu%2Feecs%2Fabout%2Farticles%2F2013%2FVLSI_Reminiscences.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-eecsnews2013-55"><span><b><a href="#cite_ref-eecsnews2013_55-0">^</a></b></span> <span><a rel="nofollow" href="http://www.eecs.umich.edu/eecs/about/articles/2013/Conway_VLSI_memoir.html">"Solid-State Circuits Publishes Special Issue with Lynn Conway's Memoir of the VLSI Revolution"</a>, Michigan EECS News, January 31, 2013.</span>
</li>
<li id="cite_note-House2012-56"><span>^ <a href="#cite_ref-House2012_56-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-House2012_56-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-House2012_56-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFHouse2012">House, Chuck (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Commentaries/A_Paradigm_Shift_Was_Happening_by_Chuck_House.pdf">"A Paradigm Shift Was Happening All Around Us"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 32–35. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215759">10.1109/MSSC.2012.2215759</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:8738682">8738682</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=A+Paradigm+Shift+Was+Happening+All+Around+Us&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=32-35&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8738682%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215759&amp;rft.aulast=House&amp;rft.aufirst=Chuck&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FCommentaries%2FA_Paradigm_Shift_Was_Happening_by_Chuck_House.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Sequin2012-57"><span><b><a href="#cite_ref-Sequin2012_57-0">^</a></b></span> <span><cite id="CITEREFSequin2012">Sequin, Carlo (2012). <a rel="nofollow" href="http://www.cs.berkeley.edu/~sequin/PAPERS/2012_SSCM_VLSI.pdf">"Witnessing the Birth of VLSI Design"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 36–39. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215758">10.1109/MSSC.2012.2215758</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:20280958">20280958</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=Witnessing+the+Birth+of+VLSI+Design&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=36-39&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A20280958%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215758&amp;rft.aulast=Sequin&amp;rft.aufirst=Carlo&amp;rft_id=http%3A%2F%2Fwww.cs.berkeley.edu%2F~sequin%2FPAPERS%2F2012_SSCM_VLSI.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Shepard2012-58"><span>^ <a href="#cite_ref-Shepard2012_58-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Shepard2012_58-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFShepard2012">Shepard, Ken (2012). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/VLSI/Commentaries/Covering_by_Ken_Shepard.pdf">"<span></span>"Covering": How We Missed the Inside-Story of the VLSI Revolution"</a> <span>(PDF)</span>. <i>IEEE Solid-State Circuits Magazine</i>. <b>4</b> (4). IEEE: 40–42. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1109%2FMSSC.2012.2215757">10.1109/MSSC.2012.2215757</a>. <a href="https://en.wikipedia.org/wiki/ISSN_(identifier)" title="ISSN (identifier)">ISSN</a>&nbsp;<a rel="nofollow" href="https://www.worldcat.org/issn/1943-0582">1943-0582</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a>&nbsp;<a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:25240158">25240158</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IEEE+Solid-State+Circuits+Magazine&amp;rft.atitle=%22Covering%22%3A+How+We+Missed+the+Inside-Story+of+the+VLSI+Revolution&amp;rft.volume=4&amp;rft.issue=4&amp;rft.pages=40-42&amp;rft.date=2012&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A25240158%23id-name%3DS2CID&amp;rft.issn=1943-0582&amp;rft_id=info%3Adoi%2F10.1109%2FMSSC.2012.2215757&amp;rft.aulast=Shepard&amp;rft.aufirst=Ken&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FVLSI%2FCommentaries%2FCovering_by_Ken_Shepard.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-59"><span><b><a href="#cite_ref-59">^</a></b></span> <span><cite id="CITEREFACM_News2018">ACM News (October 12, 2018). <a rel="nofollow" href="https://cacm.acm.org/news/231829-lynn-conway-and-the-vlsi-revolution-in-microchip-design/fulltext">"Lynn Conway and the VLSI Revolution in Microchip Design"</a>. <i>Communications of the ACM</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Lynn+Conway+and+the+VLSI+Revolution+in+Microchip+Design&amp;rft.date=2018-10-12&amp;rft.au=ACM+News&amp;rft_id=https%3A%2F%2Fcacm.acm.org%2Fnews%2F231829-lynn-conway-and-the-vlsi-revolution-in-microchip-design%2Ffulltext&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-60"><span><b><a href="#cite_ref-60">^</a></b></span> <span><cite id="CITEREFBoulton2024">Boulton, Jim (2024). <i>Lines in the Sand, The Lynn Conway Story (Unsung Heroes of the Information Age)</i>. Unsung Heroes (published February 21, 2024). <a href="https://en.wikipedia.org/wiki/ASIN_(identifier)" title="ASIN (identifier)">ASIN</a>&nbsp;<a rel="nofollow" href="https://www.amazon.com/dp/B0CW1LNGFD">B0CW1LNGFD</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Lines+in+the+Sand%2C+The+Lynn+Conway+Story+%28Unsung+Heroes+of+the+Information+Age%29&amp;rft.pub=Unsung+Heroes&amp;rft.date=2024&amp;rft_id=https%3A%2F%2Fwww.amazon.com%2Fdp%2FB0CW1LNGFD%23id-name%3DASIN&amp;rft.aulast=Boulton&amp;rft.aufirst=Jim&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-61"><span><b><a href="#cite_ref-61">^</a></b></span> <span><cite id="CITEREFThe_Centre_for_Computing_History2024">The Centre for Computing History (April 26, 2024). <a rel="nofollow" href="https://www.youtube.com/watch?v=mw2jAZmnIqU"><i>Lynn Conway - If you want to change the future, start living as if you're already there</i></a><span>. Retrieved <span>June 6,</span> 2024</span> – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+-+If+you+want+to+change+the+future%2C+start+living+as+if+you%27re+already+there&amp;rft.date=2024-04-26&amp;rft.au=The+Centre+for+Computing+History&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dmw2jAZmnIqU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-BD06LC-62"><span>^ <a href="#cite_ref-BD06LC_62-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-BD06LC_62-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-BD06LC_62-2"><sup><i><b>c</b></i></sup></a></span> <span><a rel="nofollow" href="http://www.logoonline.com/shows/dyn/beautiful_daughters/personality.jhtml?personalityId=6829">"Beautiful Daughters Cast: Lynn Conway"</a>, LOGO Channel, 2006</span>
</li>
<li id="cite_note-ED03a-63"><span><b><a href="#cite_ref-ED03a_63-0">^</a></b></span> <span><a rel="nofollow" href="http://electronicdesign.com/Articles/Index.cfm?ArticleID=5836&amp;pg=3">"Class Notes: 2002 Inductees: Here's how many of our 2002 Hall Of Famers enjoy their leisure time and how they still give back to society"</a> <a rel="nofollow" href="https://web.archive.org/web/20081003000938/http://electronicdesign.com/Articles/Index.cfm?ArticleID=5836&amp;pg=3">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Doris Kilbane, Electronic Design, October 20, 2003.</span>
</li>
<li id="cite_note-ASEEPrismOct2011-64"><span><b><a href="#cite_ref-ASEEPrismOct2011_64-0">^</a></b></span> <span><a rel="nofollow" href="http://www.prism-magazine.org/oct11/feature_03.cfm">"Secrets Are Out: Lesbian, gay, bisexual, and transgender engineers are no longer willing to hide their true selves"</a> Jaimie Schock, Prism Magazine, American Society of Engineering Education, October 2011, pp. 44–47.</span>
</li>
<li id="cite_note-65"><span><b><a href="#cite_ref-65">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/conway.html">"Lynn Conway's homepage"</a>. <i>Ai.eecs.umich.edu</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Lynn+Conway%27s+homepage&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2Fconway.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-translation-66"><span><b><a href="#cite_ref-translation_66-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/conway-Translation%20status.htm">"Status of translations of Lynn's webpages, 12-10-13"</a>. December 10, 2013<span>. Retrieved <span>December 23,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Status+of+translations+of+Lynn%27s+webpages%2C+12-10-13&amp;rft.date=2013-12-10&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2Fconway-Translation%2520status.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-67"><span><b><a href="#cite_ref-67">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TSsuccesses/TSsuccesses.html">"Transsexual Women's Successes"</a>. <i>Ai.eecs.umich.edu</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Transsexual+Women%27s+Successes&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTSsuccesses%2FTSsuccesses.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-prevalence-68"><span><b><a href="#cite_ref-prevalence_68-0">^</a></b></span> <span>Olyslager F, Conway L (2008). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Prevalence/TvG_Paper/Transsexualism_is_more_common_than_you_think.pdf">Transseksualiteit komt vaker voor dan u denkt [Transsexualism is more common than you think].</a> <i>Tijdschrift voor Genderstudies</i>, Vol. 11, no. 2, pp. 39–51, 2008. (<a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Prevalence/TvG_Paper/Summaries-English.pdf">abstract in English</a>)</span>
</li>
<li id="cite_note-HRCProfile-69"><span><b><a href="#cite_ref-HRCProfile_69-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20131103234020/http://www.hrc.org/issues/3469.htm">"<span></span>"Profile: Lynn Conway," Human Rights Campaign (HRC) website"</a>. HRC. Archived from <a rel="nofollow" href="http://www.hrc.org/issues/3469.htm">the original</a> on November 3, 2013<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=%22Profile%3A+Lynn+Conway%2C%22+Human+Rights+Campaign+%28HRC%29+website&amp;rft.pub=HRC&amp;rft_id=http%3A%2F%2Fwww.hrc.org%2Fissues%2F3469.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-LGBTHistoryMonthProfile-70"><span><b><a href="#cite_ref-LGBTHistoryMonthProfile_70-0">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20140406095129/http://www.lgbthistorymonth.org.uk/history/lynnconway.htm">"Biographies of famous LGBT people: Science: Professor Lynn Conway, Lesbian Gay Bisexual Trans History Month website"</a>. Lgbthistorymonth.org.uk. Archived from <a rel="nofollow" href="http://www.lgbthistorymonth.org.uk/history/lynnconway.htm">the original</a> on April 6, 2014<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Biographies+of+famous+LGBT+people%3A+Science%3A+Professor+Lynn+Conway%2C+Lesbian+Gay+Bisexual+Trans+History+Month+website&amp;rft.pub=Lgbthistorymonth.org.uk&amp;rft_id=http%3A%2F%2Fwww.lgbthistorymonth.org.uk%2Fhistory%2Flynnconway.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-HP01-71"><span><b><a href="#cite_ref-HP01_71-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/HP/HP.html">"Embracing Diversity – HP employees in Fort Collins, Colorado, welcome Dr. Lynn Conway"</a>, hpNOW, February 8, 2001.</span>
</li>
<li id="cite_note-FCC01-72"><span><b><a href="#cite_ref-FCC01_72-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/ColoradoanArticle/HP-CSU-lynncon.html">"Computer pioneer speaks from the heart about diversity: Transsexual talks at HP, CSU"</a>, by Kate Forgach, Fort Collins Coloradoan, January 26, 2001.</span>
</li>
<li id="cite_note-Adv01-73"><span><b><a href="#cite_ref-Adv01_73-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Advocate/Advocate.html">"Chipping Away at Prejudice"</a>, by Sarah Wildman, The Advocate, March 13, 2001.</span>
</li>
<li id="cite_note-Intel03-74"><span><b><a href="#cite_ref-Intel03_74-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/Intel/iglobe.htm">"What's pride got to do with it?"</a>, by Teri Warner, Employee Communications, Circuit for Employees@Intel, July 1, 2003.</span>
</li>
<li id="cite_note-PT03-75"><span><b><a href="#cite_ref-PT03_75-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Media/PersonnelToday/PersonnelToday_com%20-%20Why%20HR%20should%20wake%20up%20to%20the%20needs%20of%20transsexual%20employees.htm">"Why HR should wake up to the needs of transsexual employees"</a>, by Christine Burns, Personnel Today, November 18, 2003.</span>
</li>
<li id="cite_note-76"><span><b><a href="#cite_ref-76">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/O&amp;E/Raytheon/Raytheon%20Adds%20GI&amp;E.html">"Professor Lynn Conway, Guest at Out &amp; Equal"</a>. <i>Ai.eecs.umich.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=Professor+Lynn+Conway%2C+Guest+at+Out+%26+Equal&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FO%26E%2FRaytheon%2FRaytheon%2520Adds%2520GI%26E.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-77"><span><b><a href="#cite_ref-77">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.queerty.com/dr-kenneth-zuckers-war-on-transgenders-20090206/">"Dr. Kenneth Zucker's War on Transgenders"</a>. Queerty. February 6, 2009.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Dr.+Kenneth+Zucker%27s+War+on+Transgenders&amp;rft.date=2009-02-06&amp;rft_id=http%3A%2F%2Fwww.queerty.com%2Fdr-kenneth-zuckers-war-on-transgenders-20090206%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-78"><span><b><a href="#cite_ref-78">^</a></b></span> <span><cite id="CITEREFAntoine2009"><a href="https://en.wikipedia.org/wiki/Chagmion_Antoine" title="Chagmion Antoine">Antoine, Chagmion</a> (March 6, 2009). <a rel="nofollow" href="https://www.youtube.com/watch?v=JBRCo1KDX_o">"Transgender Crusader – A professor at the University of Michigan is taking on the psychiatric community's ideas about transgendered people and mental illness"</a>. CBS News / YouTube. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/JBRCo1KDX_o">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Transgender+Crusader+%E2%80%93+A+professor+at+the+University+of+Michigan+is+taking+on+the+psychiatric+community%27s+ideas+about+transgendered+people+and+mental+illness&amp;rft.date=2009-03-06&amp;rft.aulast=Antoine&amp;rft.aufirst=Chagmion&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DJBRCo1KDX_o&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-carey-79"><span>^ <a href="#cite_ref-carey_79-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-carey_79-1"><sup><i><b>b</b></i></sup></a></span> <span>
<cite id="CITEREFCarey2007">Carey, Benedict (August 21, 2007). <a rel="nofollow" href="https://www.nytimes.com/2007/08/21/health/psychology/21gender.html?ei=5124&amp;en=0c11623b4c191f82&amp;ex=1345348800&amp;partner=permalink&amp;exprod=permalink&amp;pagewanted=all">"Criticism of a Gender Theory, and a Scientist Under Siege"</a>. <i>New York Times</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+York+Times&amp;rft.atitle=Criticism+of+a+Gender+Theory%2C+and+a+Scientist+Under+Siege&amp;rft.date=2007-08-21&amp;rft.aulast=Carey&amp;rft.aufirst=Benedict&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2007%2F08%2F21%2Fhealth%2Fpsychology%2F21gender.html%3Fei%3D5124%26en%3D0c11623b4c191f82%26ex%3D1345348800%26partner%3Dpermalink%26exprod%3Dpermalink%26pagewanted%3Dall&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-dreger2008-80"><span><b><a href="#cite_ref-dreger2008_80-0">^</a></b></span> <span><cite id="CITEREFDreger2008">Dreger, A. D. (2008). <a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3170124">"The controversy surrounding <i>The man who would be queen:</i> A case history of the politics of science, identity, and sex in the Internet age"</a>. <i>Archives of Sexual Behavior</i>. <b>37</b> (3): 366–421. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1007%2Fs10508-007-9301-1">10.1007/s10508-007-9301-1</a>. <a href="https://en.wikipedia.org/wiki/PMC_(identifier)" title="PMC (identifier)">PMC</a>&nbsp;<span title="Freely accessible"><a rel="nofollow" href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3170124">3170124</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a>&nbsp;<a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/18431641">18431641</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Archives+of+Sexual+Behavior&amp;rft.atitle=The+controversy+surrounding+The+man+who+would+be+queen%3A+A+case+history+of+the+politics+of+science%2C+identity%2C+and+sex+in+the+Internet+age&amp;rft.volume=37&amp;rft.issue=3&amp;rft.pages=366-421&amp;rft.date=2008&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3170124%23id-name%3DPMC&amp;rft_id=info%3Apmid%2F18431641&amp;rft_id=info%3Adoi%2F10.1007%2Fs10508-007-9301-1&amp;rft.aulast=Dreger&amp;rft.aufirst=A.+D.&amp;rft_id=https%3A%2F%2Fwww.ncbi.nlm.nih.gov%2Fpmc%2Farticles%2FPMC3170124&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-81"><span><b><a href="#cite_ref-81">^</a></b></span> <span><cite id="CITEREFConway2003">Conway, Lynn (July 16, 2003). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/ShockingPublicity.html">"Shockingly defamatory official publicity by the US National Academies for Bailey's book"</a>. <i>lynnconway.com</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=lynnconway.com&amp;rft.atitle=Shockingly+defamatory+official+publicity+by+the+US+National+Academies+for+Bailey%27s+book&amp;rft.date=2003-07-16&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FShockingPublicity.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-82"><span><b><a href="#cite_ref-82">^</a></b></span> <span><cite id="CITEREFDreger2015">Dreger, Alice (March 10, 2015). <a rel="nofollow" href="https://www.penguinrandomhouse.com/books/316214/galileos-middle-finger-by-alice-dreger/">"Galileo's Middle Finger: Heretics, Activists, and One Scholar's Search for Justice"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Galileo%27s+Middle+Finger%3A+Heretics%2C+Activists%2C+and+One+Scholar%27s+Search+for+Justice&amp;rft.date=2015-03-10&amp;rft.aulast=Dreger&amp;rft.aufirst=Alice&amp;rft_id=https%3A%2F%2Fwww.penguinrandomhouse.com%2Fbooks%2F316214%2Fgalileos-middle-finger-by-alice-dreger%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-83"><span><b><a href="#cite_ref-83">^</a></b></span> <span><cite id="CITEREFConway2008">Conway, Lynn (June 18, 2008). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/TS/Dreger/ASB%20paper/PeerCommentaries/Peer_Papers_Critical_of_Dreger.html">"Dreger's Defense of J. Michael Bailey: The Peer Commentary Papers Tear It Apart"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Dreger%27s+Defense+of+J.+Michael+Bailey%3A+The+Peer+Commentary+Papers+Tear+It+Apart&amp;rft.date=2008-06-18&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FTS%2FDreger%2FASB%2520paper%2FPeerCommentaries%2FPeer_Papers_Critical_of_Dreger.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-VD04-84"><span><b><a href="#cite_ref-VD04_84-0">^</a></b></span> <span><a rel="nofollow" href="http://www.deepstealth.com/vday/">VDay LA 2004 Commemorative Page</a>, DeepStealth Productions, Los Angeles California, 2004.</span>
</li>
<li id="cite_note-BD06-85"><span><b><a href="#cite_ref-BD06_85-0">^</a></b></span> <span><a rel="nofollow" href="http://www.logoonline.com/shows/dyn/beautiful_daughters/series.jhtml">"Beautiful Daughters"</a>, a documentary by Josh Aronson and Ariel Orr Jordan, LOGO Channel, 2006.</span>
</li>
<li id="cite_note-trans40-86"><span>^ <a href="#cite_ref-trans40_86-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-trans40_86-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20090615170758/http://www.impcourt.org/Trans40/LynnConway.htm">"Trans Hero: Lynn Conway"</a>. <i>Stonewall 40: Trans Heroes</i>. International Court System. 2009. Archived from <a rel="nofollow" href="http://www.impcourt.org/Trans40/LynnConway.htm">the original</a> on June 15, 2009<span>. Retrieved <span>June 14,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Stonewall+40%3A+Trans+Heroes&amp;rft.atitle=Trans+Hero%3A+Lynn+Conway&amp;rft.date=2009&amp;rft_id=http%3A%2F%2Fwww.impcourt.org%2FTrans40%2FLynnConway.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ngltf-87"><span>^ <a href="#cite_ref-ngltf_87-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-ngltf_87-1"><sup><i><b>b</b></i></sup></a></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20090930181348/http://www.commondreams.org/newswire/2009/06/10-17">"Recognizing Outstanding Transgender and Gender-Nonconforming Individuals in the Struggle for LGBT Equality"</a>. National Gay and Lesbian Task Force. June 10, 2009. Archived from <a rel="nofollow" href="http://www.commondreams.org/newswire/2009/06/10-17">the original</a> on September 30, 2009<span>. Retrieved <span>June 14,</span> 2009</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Recognizing+Outstanding+Transgender+and+Gender-Nonconforming+Individuals+in+the+Struggle+for+LGBT+Equality&amp;rft.pub=National+Gay+and+Lesbian+Task+Force&amp;rft.date=2009-06-10&amp;rft_id=http%3A%2F%2Fwww.commondreams.org%2Fnewswire%2F2009%2F06%2F10-17&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Beyer2014-88"><span><b><a href="#cite_ref-Beyer2014_88-0">^</a></b></span> <span><cite id="CITEREFBeyer2014">Beyer, Dana (January 8, 2014). <a rel="nofollow" href="http://www.huffingtonpost.com/dana-beyer/leadership-and-the-value-of-exceptional-allies_b_4543460.html">"Leadership and the Value of Exceptional Allies"</a>. <i>Huffington Post</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Huffington+Post&amp;rft.atitle=Leadership+and+the+Value+of+Exceptional+Allies&amp;rft.date=2014-01-08&amp;rft.aulast=Beyer&amp;rft.aufirst=Dana&amp;rft_id=http%3A%2F%2Fwww.huffingtonpost.com%2Fdana-beyer%2Fleadership-and-the-value-of-exceptional-allies_b_4543460.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ieeeglance-89"><span><b><a href="#cite_ref-ieeeglance_89-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/about/today/at_a_glance.html">"IEEE at a Glace"</a>. IEEE.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+at+a+Glace&amp;rft.pub=IEEE&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fabout%2Ftoday%2Fat_a_glance.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-ieeeethics-90"><span><b><a href="#cite_ref-ieeeethics_90-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/about/corporate/governance/p7-8.html">"IEEE Code of Ethics"</a>. IEEE.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+Code+of+Ethics&amp;rft.pub=IEEE&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fabout%2Fcorporate%2Fgovernance%2Fp7-8.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-McCarty2014-91"><span><b><a href="#cite_ref-McCarty2014_91-0">^</a></b></span> <span><cite id="CITEREFMcCarty2014">McCarty, Maureen (January 13, 2014). <a rel="nofollow" href="https://web.archive.org/web/20140201162715/http://www.hrc.org/blog/entry/the-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive">"The Institute of Electrical and Electronic Engineers Adopts LGBT-Inclusive Code of Ethics"</a>. HRC. Archived from <a rel="nofollow" href="http://www.hrc.org/blog/entry/the-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive">the original</a> on February 1, 2014<span>. Retrieved <span>January 17,</span> 2014</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Institute+of+Electrical+and+Electronic+Engineers+Adopts+LGBT-Inclusive+Code+of+Ethics&amp;rft.pub=HRC&amp;rft.date=2014-01-13&amp;rft.aulast=McCarty&amp;rft.aufirst=Maureen&amp;rft_id=http%3A%2F%2Fwww.hrc.org%2Fblog%2Fentry%2Fthe-institute-of-electrical-and-electronic-engineers-adopts-lgbt-inclusive&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-2015trans100-92"><span><b><a href="#cite_ref-2015trans100_92-0">^</a></b></span> <span><cite><a rel="nofollow" href="http://thetrans100.com/">"The 2015 Trans 100"</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+2015+Trans+100&amp;rft_id=http%3A%2F%2Fthetrans100.com%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-93"><span><b><a href="#cite_ref-93">^</a></b></span> <span><cite id="CITEREFTaylor2020">Taylor, Evan (February 4, 2020). <a rel="nofollow" href="https://vimeo.com/501793564">"Trans Activism Oral History Project - Lynn Conway Full Interview"</a>. <i>The ArQuives</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+ArQuives&amp;rft.atitle=Trans+Activism+Oral+History+Project+-+Lynn+Conway+Full+Interview&amp;rft.date=2020-02-04&amp;rft.aulast=Taylor&amp;rft.aufirst=Evan&amp;rft_id=https%3A%2F%2Fvimeo.com%2F501793564&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-Forman2013-94"><span><b><a href="#cite_ref-Forman2013_94-0">^</a></b></span> <span>Forman, Ross (September 18, 2013) <a rel="nofollow" href="http://www.windycitymediagroup.com/ARTICLE.php?AID=44404">"Transgender pioneer reflects on sports past"</a>. Windy City Times.</span>
</li>
<li id="cite_note-95"><span><b><a href="#cite_ref-95">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/MackinacIsland/MackinacIsland.html">"A Wedding Trip to Mackinac Island"</a>. 2002. <a rel="nofollow" href="https://web.archive.org/web/20020928000028/http://ai.eecs.umich.edu/people/conway/MackinacIsland/MackinacIsland.html">Archived</a> from the original on September 28, 2002.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=A+Wedding+Trip+to+Mackinac+Island&amp;rft.date=2002&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMackinacIsland%2FMackinacIsland.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-moore2014-96"><span><b><a href="#cite_ref-moore2014_96-0">^</a></b></span> <span>Nicole Casal Moore,"<a rel="nofollow" href="http://dme.engin.umich.edu/lynnconway/">Life, Engineered: How Lynn Conway reinvented her world and ours</a> <a rel="nofollow" href="https://web.archive.org/web/20180106181053/http://dme.engin.umich.edu/lynnconway/">Archived</a> January 6, 2018, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>," <i>The Michigan Engineer</i>, College of Engineering, University of Michigan, Fall 2014, pp. 42–49.</span>
</li>
<li id="cite_note-Szczepanski2014-97"><span><b><a href="#cite_ref-Szczepanski2014_97-0">^</a></b></span> <span>Marcin Szczepanski and Evan Dougherty,"<a rel="nofollow" href="https://www.youtube.com/watch?v=7kJ-N54cQu4">A Place to Be Wild</a>," <i>Michigan Engineering</i>, October 8, 2014.</span>
</li>
<li id="cite_note-98"><span><b><a href="#cite_ref-98">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Electronics/ElectAchiev.html">"The 1981 Achievement Award – Lynn Conway, Carver Mead"</a> by Martin Marshall, Larry Waller, and Howard Wolff, <i>Electronics</i>, October 20, 1981</span>
</li>
<li id="cite_note-99"><span><b><a href="#cite_ref-99">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20080705051810/http://www.seas.upenn.edu/pubs/pender-award.html">"Penn Engineering: The Harold Pender Award"</a>. Archived from <a rel="nofollow" href="http://www.seas.upenn.edu/pubs/pender-award.html">the original</a> on July 5, 2008.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Penn+Engineering%3A+The+Harold+Pender+Award&amp;rft_id=http%3A%2F%2Fwww.seas.upenn.edu%2Fpubs%2Fpender-award.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-100"><span><b><a href="#cite_ref-100">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/web/education/awards/past_recipients.html">"IEEE EAB Major Educational Innovation Award, 1984"</a>. Ieee.org<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=IEEE+EAB+Major+Educational+Innovation+Award%2C+1984&amp;rft.pub=Ieee.org&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fweb%2Feducation%2Fawards%2Fpast_recipients.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-101"><span><b><a href="#cite_ref-101">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.ieee.org/web/membership/fellows/Alphabetical/cfellows.html">"Services Update"</a>. <i>Ieee.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ieee.org&amp;rft.atitle=Services+Update&amp;rft_id=http%3A%2F%2Fwww.ieee.org%2Fweb%2Fmembership%2Ffellows%2FAlphabetical%2Fcfellows.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-102"><span><b><a href="#cite_ref-102">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/FranklinInstitute/PhysToday/PhysToday7-85.pdf">"Franklin Institute honors eight physicists"</a>, <i>Physics Today</i>, July 1985.</span>
</li>
<li id="cite_note-SecMAA-103"><span><b><a href="#cite_ref-SecMAA_103-0">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/Mementos_of_Lynn's_awards.html#SecDef">"Secretary of Defense Meritorious Achievement Award, May 1985"</a>, <i>Meritorious Service Award</i>, May 1985.</span>
</li>
<li id="cite_note-104"><span><b><a href="#cite_ref-104">^</a></b></span> <span><a rel="nofollow" href="http://www.nae.edu/nae/naepub.nsf/MembersSec?OpenForm&amp;05,M,1">NAE Member Directory, Section 05.</a> <a rel="nofollow" href="https://web.archive.org/web/20081004111411/http://www.nae.edu/nae/naepub.nsf/MembersSec?OpenForm&amp;05,M,1">Archived</a> October 4, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (year from <a rel="nofollow" href="https://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">The White House Office of the Press Secretary</a> <a rel="nofollow" href="https://web.archive.org/web/20081003143127/http://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>)</span>
</li>
<li id="cite_note-105"><span><b><a href="#cite_ref-105">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20120216084307/http://societyofwomenengineers.swe.org/index.php?option=com_content&amp;task=view&amp;id=657&amp;Itemid=42">"Society of Women Engineers: Achievement Award Winners"</a>. Archived from <a rel="nofollow" href="http://societyofwomenengineers.swe.org/index.php?option=com_content&amp;task=view&amp;id=657&amp;Itemid=42">the original</a> on February 16, 2012.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Society+of+Women+Engineers%3A+Achievement+Award+Winners.&amp;rft_id=http%3A%2F%2Fsocietyofwomenengineers.swe.org%2Findex.php%3Foption%3Dcom_content%26task%3Dview%26id%3D657%26Itemid%3D42&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-106"><span><b><a href="#cite_ref-106">^</a></b></span> <span><a rel="nofollow" href="https://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">President Clinton Names Lynn Conway to the Air Force Academy Board of Visitors"</a> <a rel="nofollow" href="https://web.archive.org/web/20081003143127/http://clinton6.nara.gov/1996/01/1996-01-31-conway-named-to-usaf-academy-board-of-visitors.html">Archived</a> October 3, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, The White House Office of the Press Secretary, January 31, 1996.</span>
</li>
<li id="cite_note-107"><span><b><a href="#cite_ref-107">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20020615003757/http://lor.trincoll.edu/info/pub_college/reporter/winter98/engineer.htm">"100 years of engineering excellence"</a>. Archived from the original on June 15, 2002<span>. Retrieved <span>August 17,</span> 2008</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=100+years+of+engineering+excellence&amp;rft_id=http%3A%2F%2Flor.trincoll.edu%2Finfo%2Fpub_college%2Freporter%2Fwinter98%2Fengineer.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: bot: original URL status unknown (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_bot:_original_URL_status_unknown" title="Category:CS1 maint: bot: original URL status unknown">link</a>)</span>, Trinity Reporter, Trinity College, Hartford, CN, Winter 98.</span>
</li>
<li id="cite_note-108"><span><b><a href="#cite_ref-108">^</a></b></span> <span><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/ElectronicDesign/ED%20Hall%20of%20Fame%202002.pdf">"Electronic Design Hall of Fame – 2002 Inductees"</a>, <i>Electronic Design</i>, October 21, 2002.</span>
</li>
<li id="cite_note-109"><span><b><a href="#cite_ref-109">^</a></b></span> <span><a rel="nofollow" href="http://www.noglstp.org/2005awards.html">"NOGLSTP to Honor Aberson, Conway, and Raytheon at Awards Ceremony in February"</a> <a rel="nofollow" href="https://web.archive.org/web/20081002215806/http://www.noglstp.org/2005awards.html">Archived</a> October 2, 2008, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Press Release, National Organization of Gay and Lesbian Scientists and Technical Professionals, January 25, 2005.</span>
</li>
<li id="cite_note-110"><span><b><a href="#cite_ref-110">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20131210085427/http://www.draper.com/members.html">"The Charles Stark Draper Laboratory, Members of the Corporation"</a>. Draper.com. Archived from <a rel="nofollow" href="http://www.draper.com/members.html">the original</a> on December 10, 2013<span>. Retrieved <span>December 5,</span> 2013</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=The+Charles+Stark+Draper+Laboratory%2C+Members+of+the+Corporation&amp;rft.pub=Draper.com&amp;rft_id=http%3A%2F%2Fwww.draper.com%2Fmembers.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-111"><span><b><a href="#cite_ref-111">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20160703014527/http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">"<span></span>"Lynn Conway: 2014 Fellow", Computer History Museum, 2014 Fellow Awards"</a>. <i>Computerhistory.org</i>. Archived from <a rel="nofollow" href="http://www.computerhistory.org/fellowawards/hall/bios/Lynn,Conway/">the original</a> on July 3, 2016<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computerhistory.org&amp;rft.atitle=%22Lynn+Conway%3A+2014+Fellow%22%2C+Computer+History+Museum%2C+2014+Fellow+Awards&amp;rft_id=http%3A%2F%2Fwww.computerhistory.org%2Ffellowawards%2Fhall%2Fbios%2FLynn%2CConway%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-112"><span><b><a href="#cite_ref-112">^</a></b></span> <span><cite id="CITEREFComputer_History_Museum2014">Computer History Museum (May 29, 2014). <a rel="nofollow" href="https://www.youtube.com/watch?v=m93bvIiCL-c">"Computer History Museum 2014 Fellow Lynn Conway"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/m93bvIiCL-c">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Computer+History+Museum+2014+Fellow+Lynn+Conway&amp;rft.pub=YouTube&amp;rft.date=2014-05-29&amp;rft.au=Computer+History+Museum&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dm93bvIiCL-c&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-113"><span><b><a href="#cite_ref-113">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Awards/CHM/Talk/What_Words_Can_We_Leave_to_Guide_Them.pdf">"<span></span>"Lynn Conway: Fellow Award Acceptance Speech", Computer History Museum, April 26, 2014"</a> <span>(PDF)</span>. <i>Ai.eecs.umich.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ai.eecs.umich.edu&amp;rft.atitle=%22Lynn+Conway%3A+Fellow+Award+Acceptance+Speech%22%2C+Computer+History+Museum%2C+April+26%2C+2014&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FAwards%2FCHM%2FTalk%2FWhat_Words_Can_We_Leave_to_Guide_Them.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-114"><span><b><a href="#cite_ref-114">^</a></b></span> <span><cite id="CITEREFComputer_History_Museum2014">Computer History Museum (May 20, 2014). <a rel="nofollow" href="https://www.youtube.com/watch?v=d0mBjP-gBik">"2014 Fellow Lynn Conway"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/d0mBjP-gBik">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=2014+Fellow+Lynn+Conway&amp;rft.pub=YouTube&amp;rft.date=2014-05-20&amp;rft.au=Computer+History+Museum&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dd0mBjP-gBik&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-115"><span><b><a href="#cite_ref-115">^</a></b></span> <span><cite><a rel="nofollow" href="http://archive.computerhistory.org/resources/access/text/2014/05/102746864-05-01-acc.pdf">"Oral History of Lynn Conway"</a> <span>(PDF)</span>. <a href="https://en.wikipedia.org/wiki/Computer_History_Museum" title="Computer History Museum">Computer History Museum</a>. February 24, 2014.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Oral+History+of+Lynn+Conway&amp;rft.pub=Computer+History+Museum&amp;rft.date=2014-02-24&amp;rft_id=http%3A%2F%2Farchive.computerhistory.org%2Fresources%2Faccess%2Ftext%2F2014%2F05%2F102746864-05-01-acc.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-116"><span><b><a href="#cite_ref-116">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20170701145358/http://www.engin.umich.edu/college/about/news/stories/2014/april/thank-lynn-conway-for-your-cell-phone">"<span></span>"Thank Lynn Conway for your cell phone" by Nicole Casal Moore, Michigan Engineering, 2014-04-24"</a>. <i>Engin.umich.edu</i>. Archived from <a rel="nofollow" href="http://www.engin.umich.edu/college/about/news/stories/2014/april/thank-lynn-conway-for-your-cell-phone">the original</a> on July 1, 2017<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Engin.umich.edu&amp;rft.atitle=%22Thank+Lynn+Conway+for+your+cell+phone%22+by+Nicole+Casal+Moore%2C+Michigan+Engineering%2C+2014-04-24&amp;rft_id=http%3A%2F%2Fwww.engin.umich.edu%2Fcollege%2Fabout%2Fnews%2Fstories%2F2014%2Fapril%2Fthank-lynn-conway-for-your-cell-phone&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-117"><span><b><a href="#cite_ref-117">^</a></b></span> <span><a rel="nofollow" href="http://www.iit.edu/news/iittoday/?p=31501">"Illinois Institute of Technology, ITT Commencement"</a>, May 17, 2014.</span>
</li>
<li id="cite_note-118"><span><b><a href="#cite_ref-118">^</a></b></span> <span><cite><a rel="nofollow" href="http://muse.union.edu/ece/steinmetz-memorial-lecture/">"Electrical &amp; Computer Engineering ‹&nbsp;Log In"</a>. <i>Muse.union.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Muse.union.edu&amp;rft.atitle=Electrical+%26+Computer+Engineering+%E2%80%B9+Log+In&amp;rft_id=http%3A%2F%2Fmuse.union.edu%2Fece%2Fsteinmetz-memorial-lecture%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-119"><span><b><a href="#cite_ref-119">^</a></b></span> <span><cite id="CITEREFGregg_Millett2015">Gregg Millett (March 17, 2015). <a rel="nofollow" href="https://www.youtube.com/watch?v=vrB0NpiU1bo">"Steinmetz Memorial Lecture on Schenectady Today"</a>. <i>Muse.union.de</i>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/vrB0NpiU1bo">Archived</a> from the original on December 21, 2021<span>. Retrieved <span>April 10,</span> 2018</span> – via YouTube.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Muse.union.de&amp;rft.atitle=Steinmetz+Memorial+Lecture+on+Schenectady+Today&amp;rft.date=2015-03-17&amp;rft.au=Gregg+Millett&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DvrB0NpiU1bo&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-120"><span><b><a href="#cite_ref-120">^</a></b></span> <span><cite><a rel="nofollow" href="http://www.union.edu/news/stories/2015/04/prominent-woman-engineer-to-headline-steinmetz-memorial-lecture.php">"Technology innovator to headline Steinmetz Memorial Lecture"</a>. <i>Union.edu</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Union.edu&amp;rft.atitle=Technology+innovator+to+headline+Steinmetz+Memorial+Lecture&amp;rft_id=http%3A%2F%2Fwww.union.edu%2Fnews%2Fstories%2F2015%2F04%2Fprominent-woman-engineer-to-headline-steinmetz-memorial-lecture.php&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-121"><span><b><a href="#cite_ref-121">^</a></b></span> <span><cite><a rel="nofollow" href="http://sites.ieee.org/schenectady/files/2012/05/2015_Steinmetz_Lecture_by_Lynn_Conway.pdf">"<span></span>"IEEE Online (Slideshow): Our Travels Through Time: Envisioning Historical Waves of Technological Innovation", The 2015 Steinmetz Memorial Lecture by Lynn Conway, Union College, Apr 21, 2015"</a> <span>(PDF)</span>. <i>Sites.ieee.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Sites.ieee.org&amp;rft.atitle=%22IEEE+Online+%28Slideshow%29%3A+Our+Travels+Through+Time%3A+Envisioning+Historical+Waves+of+Technological+Innovation%22%2C+The+2015+Steinmetz+Memorial+Lecture+by+Lynn+Conway%2C+Union+College%2C+Apr+21%2C+2015&amp;rft_id=http%3A%2F%2Fsites.ieee.org%2Fschenectady%2Ffiles%2F2012%2F05%2F2015_Steinmetz_Lecture_by_Lynn_Conway.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-122"><span><b><a href="#cite_ref-122">^</a></b></span> <span><cite><a rel="nofollow" href="https://ny6mediashare.ensemblevideo.com/app/sites/index.aspx?destinationID=1JvzXqjt10qf5DOB2sKxBQ&amp;contentID=v3vM-7uVukayYz_pRLVZgg">"Steinmetz Memorial Lecture"</a>. <i>Ny6mediashare.ensemblevideo.com</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ny6mediashare.ensemblevideo.com&amp;rft.atitle=Steinmetz+Memorial+Lecture&amp;rft_id=https%3A%2F%2Fny6mediashare.ensemblevideo.com%2Fapp%2Fsites%2Findex.aspx%3FdestinationID%3D1JvzXqjt10qf5DOB2sKxBQ%26contentID%3Dv3vM-7uVukayYz_pRLVZgg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-123"><span><b><a href="#cite_ref-123">^</a></b></span> <span><a rel="nofollow" href="http://www.ieee.org/about/awards/medals/maxwell.html">"IEEE/RSE James Clerk Maxwell Medal"</a>, December 2014.</span>
</li>
<li id="cite_note-124"><span><b><a href="#cite_ref-124">^</a></b></span> <span><a rel="nofollow" href="http://www.engin.umich.edu/college/about/news/stories/2014/december/lynn-conway-to-receive-award">"Lynn Conway to receive 2015 IEEE/RSE James Clerk Maxwell Medal"</a> <a rel="nofollow" href="https://web.archive.org/web/20150402103451/http://www.engin.umich.edu/college/about/news/stories/2014/december/lynn-conway-to-receive-award">Archived</a> April 2, 2015, at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a>, Michigan Engineering News, December 15, 2014.</span>
</li>
<li id="cite_note-125"><span><b><a href="#cite_ref-125">^</a></b></span> <span><a rel="nofollow" href="https://ieeetv.ieee.org/history/2015-ieee-honors-ieee-rse-james-clerk-maxwell-medal-lynn-conway">"2015 IEEE Honors: IEEE-RSE James Clerk Maxwell Medal – Lynn Conway"</a>, IEEE TV, July 2, 2015.</span>
</li>
<li id="cite_note-126"><span><b><a href="#cite_ref-126">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=bw2mPAp4XGk">"IEEE/RSE 2015 James Clerk Maxwell Medal Ceremony and Lecture – Professor Lynn Conway"</a>. IEEE-TV. November 12, 2015.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IEEE%2FRSE+2015+James+Clerk+Maxwell+Medal+Ceremony+and+Lecture+%E2%80%93+Professor+Lynn+Conway&amp;rft.date=2015-11-12&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Dbw2mPAp4XGk&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-127"><span><b><a href="#cite_ref-127">^</a></b></span> <span><cite id="CITEREFConway2015">Conway, Lynn (November 12, 2015), <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/2015_RSE_Lecture_by_Lynn_Conway.pptx">"Our travels through time: envisioning historical waves of technological innovation"</a>, <i>IEEE/RSE James Clerk Maxwell Medal Lecture</i>, Royal Society of Edinburgh</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Our+travels+through+time%3A+envisioning+historical+waves+of+technological+innovation&amp;rft.btitle=IEEE%2FRSE+James+Clerk+Maxwell+Medal+Lecture&amp;rft.pub=Royal+Society+of+Edinburgh&amp;rft.date=2015-11-12&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2F2015_RSE_Lecture_by_Lynn_Conway.pptx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-128"><span><b><a href="#cite_ref-128">^</a></b></span> <span><cite id="CITEREFShoop2015">Shoop, Barry (November 12, 2015). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/Maxwell_Medal_Citation_by_Barry_Shoop.pdf">"IEEE/RSE Maxwell Medal Citation for Lynn Conway"</a> <span>(PDF)</span>. Royal Society of Edinburgh.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IEEE%2FRSE+Maxwell+Medal+Citation+for+Lynn+Conway&amp;rft.date=2015-11-12&amp;rft.aulast=Shoop&amp;rft.aufirst=Barry&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2FMaxwell_Medal_Citation_by_Barry_Shoop.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-129"><span><b><a href="#cite_ref-129">^</a></b></span> <span><cite id="CITEREFFarrar2015">Farrar, Steve (November 12, 2015). <a rel="nofollow" href="https://web.archive.org/web/20160324154326/https://www.royalsoced.org.uk/cms/files/events/reports/2014-2015/2015-IEEE-lecture-Lynn-Conway.pdf">"Review of Professor Lynn Conway's 2015 IEEE/RSE James Clerk Maxwell Medal Lecture"</a> <span>(PDF)</span>. Royal Society of Edinburgh. Archived from <a rel="nofollow" href="https://www.royalsoced.org.uk/cms/files/events/reports/2014-2015/2015-IEEE-lecture-Lynn-Conway.pdf">the original</a> <span>(PDF)</span> on March 24, 2016<span>. Retrieved <span>June 25,</span> 2016</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Review+of+Professor+Lynn+Conway%27s+2015+IEEE%2FRSE+James+Clerk+Maxwell+Medal+Lecture&amp;rft.date=2015-11-12&amp;rft.aulast=Farrar&amp;rft.aufirst=Steve&amp;rft_id=https%3A%2F%2Fwww.royalsoced.org.uk%2Fcms%2Ffiles%2Fevents%2Freports%2F2014-2015%2F2015-IEEE-lecture-Lynn-Conway.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-130"><span><b><a href="#cite_ref-130">^</a></b></span> <span><cite id="CITEREFLinklater2015">Linklater, Magnus (November 14, 2015). <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/RSE/Life_In_Stealth_of_Microchip_Genius_The_Times.pdf">"<span></span>'Life in stealth' of a microchip pioneer who migrated to a new identity: Lynn Conway beat transgender bias and began a revolution"</a> <span>(PDF)</span>. <i>The Times (UK), Scotland Edition</i>. pp.&nbsp;36–37.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Times+%28UK%29%2C+Scotland+Edition&amp;rft.atitle=%27Life+in+stealth%27+of+a+microchip+pioneer+who+migrated+to+a+new+identity%3A+Lynn+Conway+beat+transgender+bias+and+began+a+revolution&amp;rft.pages=36-37&amp;rft.date=2015-11-14&amp;rft.aulast=Linklater&amp;rft.aufirst=Magnus&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FRSE%2FLife_In_Stealth_of_Microchip_Genius_The_Times.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-131"><span><b><a href="#cite_ref-131">^</a></b></span> <span><cite id="CITEREFConway2016">Conway, Lynn (March 23, 2016), "Our Travels Through Techno-Social Space-Time: Envisioning Incoming Waves of Technological Innovation", <a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/Columbia/2016_Magill_Lecture.pptx"><i>2016 Magill Lecture in Science, Technology and the Arts</i></a>, Columbia University</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Our+Travels+Through+Techno-Social+Space-Time%3A+Envisioning+Incoming+Waves+of+Technological+Innovation&amp;rft.btitle=2016+Magill+Lecture+in+Science%2C+Technology+and+the+Arts&amp;rft.pub=Columbia+University&amp;rft.date=2016-03-23&amp;rft.aulast=Conway&amp;rft.aufirst=Lynn&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FColumbia%2F2016_Magill_Lecture.pptx&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-132"><span><b><a href="#cite_ref-132">^</a></b></span> <span><cite id="CITEREFAdams2016">Adams, Jesse (April 7, 2016). <a rel="nofollow" href="http://engineering.columbia.edu/visionary-engineer-lynn-conway-bs%E2%80%9962-ms%E2%80%9963-heralds-dawn-techno-social-age">"Magill Lecture: Visionary Engineer Lynn Conway BS'62, MS'63 Heralds Dawn of the Techno-Social Age"</a>. Columbia University.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=Magill+Lecture%3A+Visionary+Engineer+Lynn+Conway+BS%2762%2C+MS%2763+Heralds+Dawn+of+the+Techno-Social+Age&amp;rft.date=2016-04-07&amp;rft.aulast=Adams&amp;rft.aufirst=Jesse&amp;rft_id=http%3A%2F%2Fengineering.columbia.edu%2Fvisionary-engineer-lynn-conway-bs%25E2%2580%259962-ms%25E2%2580%259963-heralds-dawn-techno-social-age&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-133"><span><b><a href="#cite_ref-133">^</a></b></span> <span><a rel="nofollow" href="https://www.uvic.ca/home/about/campus-news/2016+nov-2016-honorary-degree-recipients+media-release?ticket=ST-1137198-ZQ5Ilc0GxZeV7Eye9oPi-jvm1">"University of Victoria News, Leaders in computing, athletics, telecommunications and public service receive honorary degrees"</a>, September 14, 2016.</span>
</li>
<li id="cite_note-134"><span><b><a href="#cite_ref-134">^</a></b></span> <span><cite id="CITEREFUVic_Transgender_Archives2016">UVic Transgender Archives (November 22, 2016). <a rel="nofollow" href="https://www.youtube.com/watch?v=PGx3h3mnIyI">"Lynn Conway UVic Convocation Nov. 9, 2016"</a>. <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a>. <a rel="nofollow" href="https://ghostarchive.org/varchive/youtube/20211221/PGx3h3mnIyI">Archived</a> from the original on December 21, 2021.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Lynn+Conway+UVic+Convocation+Nov.+9%2C+2016&amp;rft.pub=YouTube&amp;rft.date=2016-11-22&amp;rft.au=UVic+Transgender+Archives&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DPGx3h3mnIyI&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-135"><span><b><a href="#cite_ref-135">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.uvic.ca/research/transchair/assets/images/misc/conway_event_poster.jpg">"Lynn Conway: Honorary Doctor of Engineering"</a>. <i>University of Victoria</i>. November 9, 2016.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=Lynn+Conway%3A+Honorary+Doctor+of+Engineering&amp;rft.date=2016-11-09&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fresearch%2Ftranschair%2Fassets%2Fimages%2Fmisc%2Fconway_event_poster.jpg&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-136"><span><b><a href="#cite_ref-136">^</a></b></span> <span><cite id="CITEREFMary_Sanseverino,_orator2016">Mary Sanseverino, orator (November 9, 2016). <a rel="nofollow" href="https://web.archive.org/web/20170615073242/https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-oration.pdf">"Professor Lynn Conway's Citation for the Degree Doctor of Engineering, Honoris Causa"</a> <span>(PDF)</span>. <i>University of Victoria</i>. Original physical document archived at University of Victoria Libraries, Transgender Archives. Archived from <a rel="nofollow" href="https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-oration.pdf">the original</a> <span>(PDF)</span> on June 15, 2017.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=Professor+Lynn+Conway%27s+Citation+for+the+Degree+Doctor+of+Engineering%2C+Honoris+Causa&amp;rft.date=2016-11-09&amp;rft.au=Mary+Sanseverino%2C+orator&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fengineering%2Fassets%2Fdocs%2FLynn_Conway-2016Nov-honorand-oration.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-137"><span><b><a href="#cite_ref-137">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20170615060747/https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-quoem.pdf">"What Words Will You Leave to Guide Them"</a> <span>(PDF)</span>. <i>University of Victoria</i>. Lynn Conway Honorary Degree Comments &amp; Convocation Quoem. November 9, 2016. Archived from <a rel="nofollow" href="https://www.uvic.ca/engineering/assets/docs/Lynn_Conway-2016Nov-honorand-quoem.pdf">the original</a> <span>(PDF)</span> on June 15, 2017.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=University+of+Victoria&amp;rft.atitle=What+Words+Will+You+Leave+to+Guide+Them&amp;rft.date=2016-11-09&amp;rft_id=https%3A%2F%2Fwww.uvic.ca%2Fengineering%2Fassets%2Fdocs%2FLynn_Conway-2016Nov-honorand-quoem.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-138"><span><b><a href="#cite_ref-138">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20180307214436/https://www.aaas.org/fellow/conway-lynn">"Lynn Conway. AAAS"</a>. <i>Aaas.org</i>. Archived from <a rel="nofollow" href="https://www.aaas.org/fellow/conway-lynn">the original</a> on March 7, 2018<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=Lynn+Conway.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Ffellow%2Fconway-lynn&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-139"><span><b><a href="#cite_ref-139">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/2016-fellows">"2016 Fellow". AAAS"</a>. <i>Aaas.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=2016+Fellow%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2F2016-fellows&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-140"><span><b><a href="#cite_ref-140">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.aaas.org/blog/member-spotlight/sense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway">"O'Hara, Delia (28 August 2017). "Sense of Wonder Motivates VLSI Chip Revolutionary, Lynn Conway". AAAS"</a>. <i>Aaas.org</i><span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=O%27Hara%2C+Delia+%2828+August+2017%29.+%22Sense+of+Wonder+Motivates+VLSI+Chip+Revolutionary%2C+Lynn+Conway%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Fblog%2Fmember-spotlight%2Fsense-wonder-motivates-vlsi-chip-revolutionary-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-141"><span><b><a href="#cite_ref-141">^</a></b></span> <span><cite><a rel="nofollow" href="https://web.archive.org/web/20180307214804/https://www.aaas.org/taxonomy/term/3979/all/feed?page=3&amp;AMCV_242B6472541199F70A4C98A6%2540AdobeOrg_=793872103%257CMCIDTS%257C16834%257CMCMID%257C14052391524514714681898153359099533420%257CMCAID%257CNONE">"Member Spotlight. "Lynn Conway". AAAS"</a>. <i>Aaas.org</i>. Archived from <a rel="nofollow" href="https://www.aaas.org/taxonomy/term/3979/all/feed?page=3&amp;AMCV_242B6472541199F70A4C98A6%2540AdobeOrg_=793872103%257CMCIDTS%257C16834%257CMCMID%257C14052391524514714681898153359099533420%257CMCAID%257CNONE">the original</a> on March 7, 2018<span>. Retrieved <span>April 10,</span> 2018</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Aaas.org&amp;rft.atitle=Member+Spotlight.+%22Lynn+Conway%22.+AAAS&amp;rft_id=https%3A%2F%2Fwww.aaas.org%2Ftaxonomy%2Fterm%2F3979%2Fall%2Ffeed%3Fpage%3D3%26AMCV_242B6472541199F70A4C98A6%252540AdobeOrg_%3D793872103%25257CMCIDTS%25257C16834%25257CMCMID%25257C14052391524514714681898153359099533420%25257CMCAID%25257CNONE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-142"><span><b><a href="#cite_ref-142">^</a></b></span> <span><cite id="CITEREFRobertson2018">Robertson, Zach (October 18, 2018). <a rel="nofollow" href="https://news.engin.umich.edu/2018/10/computing-pioneer-to-receive-honorary-um-doctor-of-science-degree/">"Computing pioneer to receive honorary U-M doctorate"</a>. Michigan Engineering News. <a rel="nofollow" href="https://web.archive.org/web/20190615181704/https://news.engin.umich.edu/2018/10/computing-pioneer-to-receive-honorary-um-doctor-of-science-degree/">Archived</a> from the original on June 15, 2019.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Computing+pioneer+to+receive+honorary+U-M+doctorate&amp;rft.pub=Michigan+Engineering+News&amp;rft.date=2018-10-18&amp;rft.aulast=Robertson&amp;rft.aufirst=Zach&amp;rft_id=https%3A%2F%2Fnews.engin.umich.edu%2F2018%2F10%2Fcomputing-pioneer-to-receive-honorary-um-doctor-of-science-degree%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-143"><span><b><a href="#cite_ref-143">^</a></b></span> <span><cite id="CITEREFUniversity_of_Michigan,_Ann_Arbor,_Winter_2018_Commencement:_Honorary_Degree_Recipients2018">University of Michigan, Ann Arbor, Winter 2018 Commencement: Honorary Degree Recipients (December 16, 2018). <a rel="nofollow" href="https://www.youtube.com/watch?v=D78JVnip5v0&amp;feature=youtu.be&amp;t=2782">"University of Michigan Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. (t = 0:46:22 to 0:56:56).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=University+of+Michigan+Video&amp;rft.date=2018-12-16&amp;rft.au=University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement%3A+Honorary+Degree+Recipients&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD78JVnip5v0%26feature%3Dyoutu.be%26t%3D2782&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: location (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_location" title="Category:CS1 maint: location">link</a>) CS1 maint: multiple names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>) CS1 maint: numeric names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-144"><span><b><a href="#cite_ref-144">^</a></b></span> <span><cite><a rel="nofollow" href="https://ai.eecs.umich.edu/people/conway/Memoirs/Talks/UM_2018/Conway_Honorary%20_Degree_Citation.pdf">"Citation: Lynn Conway, honorary Doctor of Science, University of Michigan, Ann Arbor, Winter 2018 Commencement"</a> <span>(PDF)</span>. December 16, 2018.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Citation%3A+Lynn+Conway%2C+honorary+Doctor+of+Science%2C+University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement&amp;rft.date=2018-12-16&amp;rft_id=https%3A%2F%2Fai.eecs.umich.edu%2Fpeople%2Fconway%2FMemoirs%2FTalks%2FUM_2018%2FConway_Honorary%2520_Degree_Citation.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-145"><span><b><a href="#cite_ref-145">^</a></b></span> <span><cite id="CITEREFUniversity_of_Michigan,_Ann_Arbor,_Winter_2018_Commencement:_Lynn_Conway_Commencement_Address2018">University of Michigan, Ann Arbor, Winter 2018 Commencement: Lynn Conway Commencement Address (December 16, 2018). <a rel="nofollow" href="https://www.youtube.com/watch?v=D78JVnip5v0&amp;feature=youtu.be&amp;t=4300">"University of Michigan Video"</a>. <i><a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a></i>. (t = 1:11:40 to 1:20:52).</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=YouTube&amp;rft.atitle=University+of+Michigan+Video&amp;rft.date=2018-12-16&amp;rft.au=University+of+Michigan%2C+Ann+Arbor%2C+Winter+2018+Commencement%3A+Lynn+Conway+Commencement+Address&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DD78JVnip5v0%26feature%3Dyoutu.be%26t%3D4300&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span><span><code>{{<a href="https://en.wikipedia.org/wiki/Template:Cite_web" title="Template:Cite web">cite web</a>}}</code>:  CS1 maint: location (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_location" title="Category:CS1 maint: location">link</a>) CS1 maint: multiple names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_multiple_names:_authors_list" title="Category:CS1 maint: multiple names: authors list">link</a>) CS1 maint: numeric names: authors list (<a href="https://en.wikipedia.org/wiki/Category:CS1_maint:_numeric_names:_authors_list" title="Category:CS1 maint: numeric names: authors list">link</a>)</span></span>
</li>
<li id="cite_note-146"><span><b><a href="#cite_ref-146">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.ncwit.org/video/2019-ncwit-summit-lynn-conway-pioneer-award-ceremony">"2019 NCWIT Summit: Lynn Conway – Pioneer Award Ceremony"</a>. Nashville, TN. May 16, 2019.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=2019+NCWIT+Summit%3A+Lynn+Conway+%E2%80%93+Pioneer+Award+Ceremony&amp;rft.place=Nashville%2C+TN&amp;rft.date=2019-05-16&amp;rft_id=https%3A%2F%2Fwww.ncwit.org%2Fvideo%2F2019-ncwit-summit-lynn-conway-pioneer-award-ceremony&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-:0-147"><span>^ <a href="#cite_ref-:0_147-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-:0_147-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFAlicandri2020">Alicandri, Jeremy (November 18, 2020). <a rel="nofollow" href="https://www.forbes.com/sites/jeremyalicandri/2020/11/18/ibm-apologizes-for-firing-computer-pioneer/?sh=25cf659667d5">"IBM Apologizes For Firing Computer Pioneer For Being Transgender...52 Years Later"</a>. Forbes<span>. Retrieved <span>November 21,</span> 2020</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.atitle=IBM+Apologizes+For+Firing+Computer+Pioneer+For+Being+Transgender...52+Years+Later&amp;rft.date=2020-11-18&amp;rft.aulast=Alicandri&amp;rft.aufirst=Jeremy&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Fjeremyalicandri%2F2020%2F11%2F18%2Fibm-apologizes-for-firing-computer-pioneer%2F%3Fsh%3D25cf659667d5&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-148"><span><b><a href="#cite_ref-148">^</a></b></span> <span><cite><a rel="nofollow" href="https://cse.engin.umich.edu/stories/prof-emerita-lynn-conway-to-be-inducted-into-national-inventors-hall-of-fame">"Prof. Emerita Lynn Conway to be inducted into National Inventors Hall of Fame"</a>. <i>Computer Science &amp; Engineering News</i>. <a href="https://en.wikipedia.org/wiki/University_of_Michigan" title="University of Michigan">University of Michigan</a>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Computer+Science+%26+Engineering+News&amp;rft.atitle=Prof.+Emerita+Lynn+Conway+to+be+inducted+into+National+Inventors+Hall+of+Fame&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fcse.engin.umich.edu%2Fstories%2Fprof-emerita-lynn-conway-to-be-inducted-into-national-inventors-hall-of-fame&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-149"><span><b><a href="#cite_ref-149">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.invent.org/inductees/lynn-conway">"Lynn Conway, Very Large-Scale Integration (VLSI)"</a>. <i><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a></i>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=Lynn+Conway%2C+Very+Large-Scale+Integration+%28VLSI%29&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fwww.invent.org%2Finductees%2Flynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-150"><span><b><a href="#cite_ref-150">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.invent.org/sites/default/files/2022-12/2023_Fact_Sheet_Conway_FINAL.pdf">"10 Things You Need to Know About Lynn Conway"</a> <span>(PDF)</span>. <i><a href="https://en.wikipedia.org/wiki/National_Inventors_Hall_of_Fame" title="National Inventors Hall of Fame">National Inventors Hall of Fame</a></i>. January 6, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=10+Things+You+Need+to+Know+About+Lynn+Conway&amp;rft.date=2023-01-06&amp;rft_id=https%3A%2F%2Fwww.invent.org%2Fsites%2Fdefault%2Ffiles%2F2022-12%2F2023_Fact_Sheet_Conway_FINAL.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-151"><span><b><a href="#cite_ref-151">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.youtube.com/watch?v=H6tb8qBgWXU">"Providing Freedom: The Lynn Conway Story"</a>. <i>National Inventors Hall of Fame</i> (Video). October 26, 2023.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=National+Inventors+Hall+of+Fame&amp;rft.atitle=Providing+Freedom%3A+The+Lynn+Conway+Story&amp;rft.date=2023-10-26&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DH6tb8qBgWXU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-152"><span><b><a href="#cite_ref-152">^</a></b></span> <span><cite id="CITEREFDodds2023">Dodds, Io (November 25, 2023). <a rel="nofollow" href="https://www.independent.co.uk/news/world/americas/lynn-conway-biography-vlsi-transgender-b2452173.html">"<span></span>'I lived a pretty adventurous life': Meet Lynn Conway, the hidden figure behind the smartphone in your pocket"</a>. <i>The Telegraph (US Edition)</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Telegraph+%28US+Edition%29&amp;rft.atitle=%27I+lived+a+pretty+adventurous+life%27%3A+Meet+Lynn+Conway%2C+the+hidden+figure+behind+the+smartphone+in+your+pocket&amp;rft.date=2023-11-25&amp;rft.aulast=Dodds&amp;rft.aufirst=Io&amp;rft_id=https%3A%2F%2Fwww.independent.co.uk%2Fnews%2Fworld%2Famericas%2Flynn-conway-biography-vlsi-transgender-b2452173.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-153"><span><b><a href="#cite_ref-153">^</a></b></span> <span>Princeton awards five honorary degrees. (2023, May 30). Princeton University. <a rel="nofollow" href="https://www.princeton.edu/news/2023/05/30/princeton-awards-five-honorary-degrees">https://www.princeton.edu/news/2023/05/30/princeton-awards-five-honorary-degrees</a></span>
</li>
<li id="cite_note-154"><span><b><a href="#cite_ref-154">^</a></b></span> <span><cite><a rel="nofollow" href="https://news.syr.edu/blog/2024/04/19/5-honorary-degrees-to-be-presented-at-2024-commencement/">"5 Honorary Degrees to Be Presented at 2024 Commencement"</a>. April 19, 2024.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=5+Honorary+Degrees+to+Be+Presented+at+2024+Commencement&amp;rft.date=2024-04-19&amp;rft_id=https%3A%2F%2Fnews.syr.edu%2Fblog%2F2024%2F04%2F19%2F5-honorary-degrees-to-be-presented-at-2024-commencement%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-155"><span><b><a href="#cite_ref-155">^</a></b></span> <span><cite id="CITEREFMaurice2020">Maurice, Emma Powys (November 20, 2020). <a rel="nofollow" href="https://www.pinknews.co.uk/2020/11/20/ibm-lynn-conway-transgender-computer-scientist-pioneer-apology-vsli-chip-silicone-valley/">"Business giant IBM finally apologises for firing a computer pioneer 52 years ago just because she was trans"</a>. <i><a href="https://en.wikipedia.org/wiki/PinkNews" title="PinkNews">PinkNews</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=PinkNews&amp;rft.atitle=Business+giant+IBM+finally+apologises+for+firing+a+computer+pioneer+52+years+ago+just+because+she+was+trans&amp;rft.date=2020-11-20&amp;rft.aulast=Maurice&amp;rft.aufirst=Emma+Powys&amp;rft_id=https%3A%2F%2Fwww.pinknews.co.uk%2F2020%2F11%2F20%2Fibm-lynn-conway-transgender-computer-scientist-pioneer-apology-vsli-chip-silicone-valley%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-156"><span><b><a href="#cite_ref-156">^</a></b></span> <span><cite id="CITEREFHiltzik2020">Hiltzik, Michael (November 30, 2020). <a rel="nofollow" href="https://www.latimes.com/business/story/2020-11-23/ibm-apology-lynn-conway">"Column: IBM apologizes for firing a transgender pioneer, a half-century later"</a>. <i><a href="https://en.wikipedia.org/wiki/Los_Angeles_Times" title="Los Angeles Times">Los Angeles Times</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Los+Angeles+Times&amp;rft.atitle=Column%3A+IBM+apologizes+for+firing+a+transgender+pioneer%2C+a+half-century+later&amp;rft.date=2020-11-30&amp;rft.aulast=Hiltzik&amp;rft.aufirst=Michael&amp;rft_id=https%3A%2F%2Fwww.latimes.com%2Fbusiness%2Fstory%2F2020-11-23%2Fibm-apology-lynn-conway&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-157"><span><b><a href="#cite_ref-157">^</a></b></span> <span><cite id="CITEREFPage2020">Page, Sydney (November 23, 2020). <a rel="nofollow" href="https://www.thelily.com/in-1968-ibm-fired-lynn-conway-for-being-transgender-she-finally-got-an-apology/">"In 1968, IBM fired Lynn Conway for being transgender – She finally got an apology"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Lily_(Washington_Post)" title="The Lily (Washington Post)">The Lily (Washington Post)</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Lily+%28Washington+Post%29&amp;rft.atitle=In+1968%2C+IBM+fired+Lynn+Conway+for+being+transgender+%E2%80%93+She+finally+got+an+apology&amp;rft.date=2020-11-23&amp;rft.aulast=Page&amp;rft.aufirst=Sydney&amp;rft_id=https%3A%2F%2Fwww.thelily.com%2Fin-1968-ibm-fired-lynn-conway-for-being-transgender-she-finally-got-an-apology%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-158"><span><b><a href="#cite_ref-158">^</a></b></span> <span><cite id="CITEREFKane2020">Kane, Roni (November 29, 2020). <a rel="nofollow" href="https://www.michigandaily.com/section/academics/ibm-fired-%E2%80%98u%E2%80%99-professor-lynn-conway-changing-her-gender-identity-1968-52-years">"IBM fired U-M professor Lynn Conway for coming out as trans in 1968. 52 years later, the company apologized"</a>. <i><a href="https://en.wikipedia.org/wiki/The_Michigan_Daily" title="The Michigan Daily">The Michigan Daily</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+Michigan+Daily&amp;rft.atitle=IBM+fired+U-M+professor+Lynn+Conway+for+coming+out+as+trans+in+1968.+52+years+later%2C+the+company+apologized&amp;rft.date=2020-11-29&amp;rft.aulast=Kane&amp;rft.aufirst=Roni&amp;rft_id=https%3A%2F%2Fwww.michigandaily.com%2Fsection%2Facademics%2Fibm-fired-%25E2%2580%2598u%25E2%2580%2599-professor-lynn-conway-changing-her-gender-identity-1968-52-years&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-159"><span><b><a href="#cite_ref-159">^</a></b></span> <span><cite id="CITEREFAssunção2020">Assunção, Muri (November 20, 2020). <a rel="nofollow" href="https://www.nydailynews.com/news/national/ny-ibm-apologizes-trans-tech-pioneer-lynn-conway-firing-20201120-jfhvu2e4yjbplb5r6256ev7gya-story.html">"IBM apologizes to 'tech trailblazer' Lynn Conway for firing her for being transgender, 52 years after the fact"</a>. <i><a href="https://en.wikipedia.org/wiki/New_York_Daily_News" title="New York Daily News">New York Daily News</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+York+Daily+News&amp;rft.atitle=IBM+apologizes+to+%27tech+trailblazer%27+Lynn+Conway+for+firing+her+for+being+transgender%2C+52+years+after+the+fact&amp;rft.date=2020-11-20&amp;rft.aulast=Assun%C3%A7%C3%A3o&amp;rft.aufirst=Muri&amp;rft_id=https%3A%2F%2Fwww.nydailynews.com%2Fnews%2Fnational%2Fny-ibm-apologizes-trans-tech-pioneer-lynn-conway-firing-20201120-jfhvu2e4yjbplb5r6256ev7gya-story.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
<li id="cite_note-160"><span><b><a href="#cite_ref-160">^</a></b></span> <span><cite id="CITEREFCramer2020">Cramer, Maria (November 21, 2020). <a rel="nofollow" href="https://www.nytimes.com/2020/11/21/business/lynn-conway-ibm-transgender.html">"52 Years Later, IBM Apologizes for Firing Transgender Woman"</a>. <i><a href="https://en.wikipedia.org/wiki/The_New_York_Times" title="The New York Times">The New York Times</a></i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=52+Years+Later%2C+IBM+Apologizes+for+Firing+Transgender+Woman&amp;rft.date=2020-11-21&amp;rft.aulast=Cramer&amp;rft.aufirst=Maria&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2020%2F11%2F21%2Fbusiness%2Flynn-conway-ibm-transgender.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></span>
</li>
</ol></div>
<h2><span id="Further_reading">Further reading</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=13" title="Edit section: Further reading"><span>edit</span></a><span>]</span></span></h2>
<ul><li><cite id="CITEREFSaariAllison1996">Saari, Peggy; Allison, Stephen (1996). <a rel="nofollow" href="https://archive.org/details/scientistslives000saar"><i>Scientists: The Lives and Works of 150 Scientists</i></a>. New York [u.a.]: UXL. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a>&nbsp;<a href="https://en.wikipedia.org/wiki/Special:BookSources/9780787609603" title="Special:BookSources/9780787609603"><bdi>9780787609603</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Scientists%3A+The+Lives+and+Works+of+150+Scientists&amp;rft.place=New+York+%5Bu.a.%5D&amp;rft.pub=UXL&amp;rft.date=1996&amp;rft.isbn=9780787609603&amp;rft.aulast=Saari&amp;rft.aufirst=Peggy&amp;rft.au=Allison%2C+Stephen&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fscientistslives000saar&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALynn+Conway"></span></li></ul>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Lynn_Conway&amp;action=edit&amp;section=14" title="Edit section: External links"><span>edit</span></a><span>]</span></span></h2>
<p><span typeof="mw:File"><a href="https://en.wikipedia.org/wiki/File:Commons-logo.svg"><img alt="" src="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/12px-Commons-logo.svg.png" decoding="async" width="12" height="16" srcset="https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/18px-Commons-logo.svg.png 1.5x, https://upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/24px-Commons-logo.svg.png 2x" data-file-width="1024" data-file-height="1376"></a></span> Media related to <a href="https://commons.wikimedia.org/wiki/Category:Lynn_Conway" title="commons:Category:Lynn Conway">Lynn Conway</a> at Wikimedia Commons
</p>
<ul><li><span><span><a rel="nofollow" href="http://www.lynnconway.com/">Official website</a></span></span></li></ul>

<!-- 
NewPP limit report
Parsed by mw‐web.eqiad.main‐6d76fd97c7‐gnkwn
Cached time: 20240611182607
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 1.762 seconds
Real time usage: 2.048 seconds
Preprocessor visited node count: 10574/1000000
Post‐expand include size: 264432/2097152 bytes
Template argument size: 11422/2097152 bytes
Highest expansion depth: 18/100
Expensive parser function count: 20/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 507547/5000000 bytes
Lua time usage: 1.190/10.000 seconds
Lua memory usage: 11569930/52428800 bytes
Lua Profile:
    ?                                                                280 ms       23.3%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::callParserFunction      140 ms       11.7%
    <mw.lua:694>                                                     120 ms       10.0%
    dataWrapper <mw.lua:672>                                         120 ms       10.0%
    citation0 <Module:Citation/CS1:2613>                              80 ms        6.7%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::getEntityStatements       40 ms        3.3%
    init <Module:Citation/CS1/Identifiers>                            40 ms        3.3%
    makeMessage <mw.message.lua:76>                                   40 ms        3.3%
    <Module:Citation/CS1:813>                                         40 ms        3.3%
    MediaWiki\Extension\Scribunto\Engines\LuaSandbox\LuaSandboxCallback::gsub       40 ms        3.3%
    [others]                                                         260 ms       21.7%
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00% 1868.533      1 -total
 45.72%  854.337      1 Template:Reflist
 25.47%  475.986     80 Template:Cite_web
 15.92%  297.493      1 Template:Infobox_scientist
  9.14%  170.742     11 Template:Cite_book
  8.89%  166.178     24 Template:Cite_news
  7.16%  133.758      1 Template:Authority_control
  4.59%   85.776      1 Template:Short_description
  4.14%   77.280     10 Template:Cite_journal
  3.80%   71.068      1 Template:Marriage
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:747715-0!canonical and timestamp 20240611182607 and revision id 1228525334. Rendering was triggered because: page-view
 -->
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Coqui.ai TTS: A Deep Learning Toolkit for Text-to-Speech (115 pts)]]></title>
            <link>https://github.com/coqui-ai/TTS</link>
            <guid>40648193</guid>
            <pubDate>Tue, 11 Jun 2024 16:25:16 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/coqui-ai/TTS">https://github.com/coqui-ai/TTS</a>, See on <a href="https://news.ycombinator.com/item?id=40648193">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">🐸Coqui.ai News</h2><a id="user-content-coquiai-news" aria-label="Permalink: 🐸Coqui.ai News" href="#coquiai-news"></a></p>
<ul dir="auto">
<li>📣 ⓍTTSv2 is here with 16 languages and better performance across the board.</li>
<li>📣 ⓍTTS fine-tuning code is out. Check the <a href="https://github.com/coqui-ai/TTS/tree/dev/recipes/ljspeech">example recipes</a>.</li>
<li>📣 ⓍTTS can now stream with &lt;200ms latency.</li>
<li>📣 ⓍTTS, our production TTS model that can speak 13 languages, is released <a href="https://coqui.ai/blog/tts/open_xtts" rel="nofollow">Blog Post</a>, <a href="https://huggingface.co/spaces/coqui/xtts" rel="nofollow">Demo</a>, <a href="https://tts.readthedocs.io/en/dev/models/xtts.html" rel="nofollow">Docs</a></li>
<li>📣 <a href="https://github.com/suno-ai/bark">🐶Bark</a> is now available for inference with unconstrained voice cloning. <a href="https://tts.readthedocs.io/en/dev/models/bark.html" rel="nofollow">Docs</a></li>
<li>📣 You can use <a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms">~1100 Fairseq models</a> with 🐸TTS.</li>
<li>📣 🐸TTS now supports 🐢Tortoise with faster inference. <a href="https://tts.readthedocs.io/en/dev/models/tortoise.html" rel="nofollow">Docs</a></li>
</ul>

<hr>
<p dir="auto"><h2 tabindex="-1" dir="auto">💬 Where to ask questions</h2><a id="user-content--where-to-ask-questions" aria-label="Permalink: 💬 Where to ask questions" href="#-where-to-ask-questions"></a></p>
<p dir="auto">Please use our dedicated channels for questions and discussion. Help is much more valuable if it's shared publicly so that more people can benefit from it.</p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Platforms</th>
</tr>
</thead>
<tbody>
<tr>
<td>🚨 <strong>Bug Reports</strong></td>
<td><a href="https://github.com/coqui-ai/tts/issues">GitHub Issue Tracker</a></td>
</tr>
<tr>
<td>🎁 <strong>Feature Requests &amp; Ideas</strong></td>
<td><a href="https://github.com/coqui-ai/tts/issues">GitHub Issue Tracker</a></td>
</tr>
<tr>
<td>👩‍💻 <strong>Usage Questions</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/discussions">GitHub Discussions</a></td>
</tr>
<tr>
<td>🗯 <strong>General Discussion</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/discussions">GitHub Discussions</a> or <a href="https://discord.gg/5eXr5seRrv" rel="nofollow">Discord</a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">🔗 Links and Resources</h2><a id="user-content--links-and-resources" aria-label="Permalink: 🔗 Links and Resources" href="#-links-and-resources"></a></p>
<table>
<thead>
<tr>
<th>Type</th>
<th>Links</th>
</tr>
</thead>
<tbody>
<tr>
<td>💼 <strong>Documentation</strong></td>
<td><a href="https://tts.readthedocs.io/en/latest/" rel="nofollow">ReadTheDocs</a></td>
</tr>
<tr>
<td>💾 <strong>Installation</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/tree/dev#installation">TTS/README.md</a></td>
</tr>
<tr>
<td>👩‍💻 <strong>Contributing</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a></td>
</tr>
<tr>
<td>📌 <strong>Road Map</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/issues/378" data-hovercard-type="issue" data-hovercard-url="/coqui-ai/TTS/issues/378/hovercard">Main Development Plans</a></td>
</tr>
<tr>
<td>🚀 <strong>Released Models</strong></td>
<td><a href="https://github.com/coqui-ai/TTS/releases">TTS Releases</a> and <a href="https://github.com/coqui-ai/TTS/wiki/Experimental-Released-Models">Experimental Models</a></td>
</tr>
<tr>
<td>📰 <strong>Papers</strong></td>
<td><a href="https://github.com/erogol/TTS-papers">TTS Papers</a></td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">🥇 TTS Performance</h2><a id="user-content--tts-performance" aria-label="Permalink: 🥇 TTS Performance" href="#-tts-performance"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/coqui-ai/TTS/main/images/TTS-performance.png"><img src="https://raw.githubusercontent.com/coqui-ai/TTS/main/images/TTS-performance.png" width="800"></a></p>
<p dir="auto">Underlined "TTS*" and "Judy*" are <strong>internal</strong> 🐸TTS models that are not released open-source. They are here to show the potential. Models prefixed with a dot (.Jofish .Abe and .Janice) are real human voices.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>High-performance Deep Learning models for Text2Speech tasks.
<ul dir="auto">
<li>Text2Spec models (Tacotron, Tacotron2, Glow-TTS, SpeedySpeech).</li>
<li>Speaker Encoder to compute speaker embeddings efficiently.</li>
<li>Vocoder models (MelGAN, Multiband-MelGAN, GAN-TTS, ParallelWaveGAN, WaveGrad, WaveRNN)</li>
</ul>
</li>
<li>Fast and efficient model training.</li>
<li>Detailed training logs on the terminal and Tensorboard.</li>
<li>Support for Multi-speaker TTS.</li>
<li>Efficient, flexible, lightweight but feature complete <code>Trainer API</code>.</li>
<li>Released and ready-to-use models.</li>
<li>Tools to curate Text2Speech datasets under<code>dataset_analysis</code>.</li>
<li>Utilities to use and test your models.</li>
<li>Modular (but not too much) code base enabling easy implementation of new ideas.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Model Implementations</h2><a id="user-content-model-implementations" aria-label="Permalink: Model Implementations" href="#model-implementations"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Spectrogram models</h3><a id="user-content-spectrogram-models" aria-label="Permalink: Spectrogram models" href="#spectrogram-models"></a></p>
<ul dir="auto">
<li>Tacotron: <a href="https://arxiv.org/abs/1703.10135" rel="nofollow">paper</a></li>
<li>Tacotron2: <a href="https://arxiv.org/abs/1712.05884" rel="nofollow">paper</a></li>
<li>Glow-TTS: <a href="https://arxiv.org/abs/2005.11129" rel="nofollow">paper</a></li>
<li>Speedy-Speech: <a href="https://arxiv.org/abs/2008.03802" rel="nofollow">paper</a></li>
<li>Align-TTS: <a href="https://arxiv.org/abs/2003.01950" rel="nofollow">paper</a></li>
<li>FastPitch: <a href="https://arxiv.org/pdf/2006.06873.pdf" rel="nofollow">paper</a></li>
<li>FastSpeech: <a href="https://arxiv.org/abs/1905.09263" rel="nofollow">paper</a></li>
<li>FastSpeech2: <a href="https://arxiv.org/abs/2006.04558" rel="nofollow">paper</a></li>
<li>SC-GlowTTS: <a href="https://arxiv.org/abs/2104.05557" rel="nofollow">paper</a></li>
<li>Capacitron: <a href="https://arxiv.org/abs/1906.03402" rel="nofollow">paper</a></li>
<li>OverFlow: <a href="https://arxiv.org/abs/2211.06892" rel="nofollow">paper</a></li>
<li>Neural HMM TTS: <a href="https://arxiv.org/abs/2108.13320" rel="nofollow">paper</a></li>
<li>Delightful TTS: <a href="https://arxiv.org/abs/2110.12612" rel="nofollow">paper</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">End-to-End Models</h3><a id="user-content-end-to-end-models" aria-label="Permalink: End-to-End Models" href="#end-to-end-models"></a></p>
<ul dir="auto">
<li>ⓍTTS: <a href="https://coqui.ai/blog/tts/open_xtts" rel="nofollow">blog</a></li>
<li>VITS: <a href="https://arxiv.org/pdf/2106.06103" rel="nofollow">paper</a></li>
<li>🐸 YourTTS: <a href="https://arxiv.org/abs/2112.02418" rel="nofollow">paper</a></li>
<li>🐢 Tortoise: <a href="https://github.com/neonbjb/tortoise-tts">orig. repo</a></li>
<li>🐶 Bark: <a href="https://github.com/suno-ai/bark">orig. repo</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Attention Methods</h3><a id="user-content-attention-methods" aria-label="Permalink: Attention Methods" href="#attention-methods"></a></p>
<ul dir="auto">
<li>Guided Attention: <a href="https://arxiv.org/abs/1710.08969" rel="nofollow">paper</a></li>
<li>Forward Backward Decoding: <a href="https://arxiv.org/abs/1907.09006" rel="nofollow">paper</a></li>
<li>Graves Attention: <a href="https://arxiv.org/abs/1910.10288" rel="nofollow">paper</a></li>
<li>Double Decoder Consistency: <a href="https://erogol.com/solving-attention-problems-of-tts-models-with-double-decoder-consistency/" rel="nofollow">blog</a></li>
<li>Dynamic Convolutional Attention: <a href="https://arxiv.org/pdf/1910.10288.pdf" rel="nofollow">paper</a></li>
<li>Alignment Network: <a href="https://arxiv.org/abs/2108.10447" rel="nofollow">paper</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Speaker Encoder</h3><a id="user-content-speaker-encoder" aria-label="Permalink: Speaker Encoder" href="#speaker-encoder"></a></p>
<ul dir="auto">
<li>GE2E: <a href="https://arxiv.org/abs/1710.10467" rel="nofollow">paper</a></li>
<li>Angular Loss: <a href="https://arxiv.org/pdf/2003.11982.pdf" rel="nofollow">paper</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Vocoders</h3><a id="user-content-vocoders" aria-label="Permalink: Vocoders" href="#vocoders"></a></p>
<ul dir="auto">
<li>MelGAN: <a href="https://arxiv.org/abs/1910.06711" rel="nofollow">paper</a></li>
<li>MultiBandMelGAN: <a href="https://arxiv.org/abs/2005.05106" rel="nofollow">paper</a></li>
<li>ParallelWaveGAN: <a href="https://arxiv.org/abs/1910.11480" rel="nofollow">paper</a></li>
<li>GAN-TTS discriminators: <a href="https://arxiv.org/abs/1909.11646" rel="nofollow">paper</a></li>
<li>WaveRNN: <a href="https://github.com/fatchord/WaveRNN/">origin</a></li>
<li>WaveGrad: <a href="https://arxiv.org/abs/2009.00713" rel="nofollow">paper</a></li>
<li>HiFiGAN: <a href="https://arxiv.org/abs/2010.05646" rel="nofollow">paper</a></li>
<li>UnivNet: <a href="https://arxiv.org/abs/2106.07889" rel="nofollow">paper</a></li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Voice Conversion</h3><a id="user-content-voice-conversion" aria-label="Permalink: Voice Conversion" href="#voice-conversion"></a></p>
<ul dir="auto">
<li>FreeVC: <a href="https://arxiv.org/abs/2210.15418" rel="nofollow">paper</a></li>
</ul>
<p dir="auto">You can also help us implement more models.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">🐸TTS is tested on Ubuntu 18.04 with <strong>python &gt;= 3.9, &lt; 3.12.</strong>.</p>
<p dir="auto">If you are only interested in <a href="https://tts.readthedocs.io/en/latest/inference.html" rel="nofollow">synthesizing speech</a> with the released 🐸TTS models, installing from PyPI is the easiest option.</p>

<p dir="auto">If you plan to code or train models, clone 🐸TTS and install it locally.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/coqui-ai/TTS
pip install -e .[all,dev,notebooks]  # Select the relevant extras"><pre>git clone https://github.com/coqui-ai/TTS
pip install -e .[all,dev,notebooks]  <span><span>#</span> Select the relevant extras</span></pre></div>
<p dir="auto">If you are on Ubuntu (Debian), you can also run following commands for installation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ make system-deps  # intended to be used on Ubuntu (Debian). Let us know if you have a different OS.
$ make install"><pre>$ make system-deps  <span><span>#</span> intended to be used on Ubuntu (Debian). Let us know if you have a different OS.</span>
$ make install</pre></div>
<p dir="auto">If you are on Windows, 👑@GuyPaddock wrote installation instructions <a href="https://stackoverflow.com/questions/66726331/how-can-i-run-mozilla-tts-coqui-tts-training-with-cuda-on-a-windows-system" rel="nofollow">here</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Docker Image</h2><a id="user-content-docker-image" aria-label="Permalink: Docker Image" href="#docker-image"></a></p>
<p dir="auto">You can also try TTS without install with the docker image.
Simply run the following command and you will be able to run TTS without installing it.</p>
<div dir="auto" data-snippet-clipboard-copy-content="docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu
python3 TTS/server/server.py --list_models #To get the list of available models
python3 TTS/server/server.py --model_name tts_models/en/vctk/vits # To start a server"><pre>docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu
python3 TTS/server/server.py --list_models <span><span>#</span>To get the list of available models</span>
python3 TTS/server/server.py --model_name tts_models/en/vctk/vits <span><span>#</span> To start a server</span></pre></div>
<p dir="auto">You can then enjoy the TTS server <a href="http://%5B::1%5D:5002/" rel="nofollow">here</a>
More details about the docker images (like GPU support) can be found <a href="https://tts.readthedocs.io/en/latest/docker_images.html" rel="nofollow">here</a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Synthesizing speech by 🐸TTS</h2><a id="user-content-synthesizing-speech-by-tts" aria-label="Permalink: Synthesizing speech by 🐸TTS" href="#synthesizing-speech-by-tts"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">🐍 Python API</h3><a id="user-content--python-api" aria-label="Permalink: 🐍 Python API" href="#-python-api"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Running a multi-speaker and multi-lingual model</h4><a id="user-content-running-a-multi-speaker-and-multi-lingual-model" aria-label="Permalink: Running a multi-speaker and multi-lingual model" href="#running-a-multi-speaker-and-multi-lingual-model"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="import torch
from TTS.api import TTS

# Get device
device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;

# List available 🐸TTS models
print(TTS().list_models())

# Init TTS
tts = TTS(&quot;tts_models/multilingual/multi-dataset/xtts_v2&quot;).to(device)

# Run TTS
# ❗ Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language
# Text to speech list of amplitude values as output
wav = tts.tts(text=&quot;Hello world!&quot;, speaker_wav=&quot;my/cloning/audio.wav&quot;, language=&quot;en&quot;)
# Text to speech to a file
tts.tts_to_file(text=&quot;Hello world!&quot;, speaker_wav=&quot;my/cloning/audio.wav&quot;, language=&quot;en&quot;, file_path=&quot;output.wav&quot;)"><pre><span>import</span> <span>torch</span>
<span>from</span> <span>TTS</span>.<span>api</span> <span>import</span> <span>TTS</span>

<span># Get device</span>
<span>device</span> <span>=</span> <span>"cuda"</span> <span>if</span> <span>torch</span>.<span>cuda</span>.<span>is_available</span>() <span>else</span> <span>"cpu"</span>

<span># List available 🐸TTS models</span>
<span>print</span>(<span>TTS</span>().<span>list_models</span>())

<span># Init TTS</span>
<span>tts</span> <span>=</span> <span>TTS</span>(<span>"tts_models/multilingual/multi-dataset/xtts_v2"</span>).<span>to</span>(<span>device</span>)

<span># Run TTS</span>
<span># ❗ Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language</span>
<span># Text to speech list of amplitude values as output</span>
<span>wav</span> <span>=</span> <span>tts</span>.<span>tts</span>(<span>text</span><span>=</span><span>"Hello world!"</span>, <span>speaker_wav</span><span>=</span><span>"my/cloning/audio.wav"</span>, <span>language</span><span>=</span><span>"en"</span>)
<span># Text to speech to a file</span>
<span>tts</span>.<span>tts_to_file</span>(<span>text</span><span>=</span><span>"Hello world!"</span>, <span>speaker_wav</span><span>=</span><span>"my/cloning/audio.wav"</span>, <span>language</span><span>=</span><span>"en"</span>, <span>file_path</span><span>=</span><span>"output.wav"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Running a single speaker model</h4><a id="user-content-running-a-single-speaker-model" aria-label="Permalink: Running a single speaker model" href="#running-a-single-speaker-model"></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Init TTS with the target model name
tts = TTS(model_name=&quot;tts_models/de/thorsten/tacotron2-DDC&quot;, progress_bar=False).to(device)

# Run TTS
tts.tts_to_file(text=&quot;Ich bin eine Testnachricht.&quot;, file_path=OUTPUT_PATH)

# Example voice cloning with YourTTS in English, French and Portuguese
tts = TTS(model_name=&quot;tts_models/multilingual/multi-dataset/your_tts&quot;, progress_bar=False).to(device)
tts.tts_to_file(&quot;This is voice cloning.&quot;, speaker_wav=&quot;my/cloning/audio.wav&quot;, language=&quot;en&quot;, file_path=&quot;output.wav&quot;)
tts.tts_to_file(&quot;C'est le clonage de la voix.&quot;, speaker_wav=&quot;my/cloning/audio.wav&quot;, language=&quot;fr-fr&quot;, file_path=&quot;output.wav&quot;)
tts.tts_to_file(&quot;Isso é clonagem de voz.&quot;, speaker_wav=&quot;my/cloning/audio.wav&quot;, language=&quot;pt-br&quot;, file_path=&quot;output.wav&quot;)"><pre><span># Init TTS with the target model name</span>
<span>tts</span> <span>=</span> <span>TTS</span>(<span>model_name</span><span>=</span><span>"tts_models/de/thorsten/tacotron2-DDC"</span>, <span>progress_bar</span><span>=</span><span>False</span>).<span>to</span>(<span>device</span>)

<span># Run TTS</span>
<span>tts</span>.<span>tts_to_file</span>(<span>text</span><span>=</span><span>"Ich bin eine Testnachricht."</span>, <span>file_path</span><span>=</span><span>OUTPUT_PATH</span>)

<span># Example voice cloning with YourTTS in English, French and Portuguese</span>
<span>tts</span> <span>=</span> <span>TTS</span>(<span>model_name</span><span>=</span><span>"tts_models/multilingual/multi-dataset/your_tts"</span>, <span>progress_bar</span><span>=</span><span>False</span>).<span>to</span>(<span>device</span>)
<span>tts</span>.<span>tts_to_file</span>(<span>"This is voice cloning."</span>, <span>speaker_wav</span><span>=</span><span>"my/cloning/audio.wav"</span>, <span>language</span><span>=</span><span>"en"</span>, <span>file_path</span><span>=</span><span>"output.wav"</span>)
<span>tts</span>.<span>tts_to_file</span>(<span>"C'est le clonage de la voix."</span>, <span>speaker_wav</span><span>=</span><span>"my/cloning/audio.wav"</span>, <span>language</span><span>=</span><span>"fr-fr"</span>, <span>file_path</span><span>=</span><span>"output.wav"</span>)
<span>tts</span>.<span>tts_to_file</span>(<span>"Isso é clonagem de voz."</span>, <span>speaker_wav</span><span>=</span><span>"my/cloning/audio.wav"</span>, <span>language</span><span>=</span><span>"pt-br"</span>, <span>file_path</span><span>=</span><span>"output.wav"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example voice conversion</h4><a id="user-content-example-voice-conversion" aria-label="Permalink: Example voice conversion" href="#example-voice-conversion"></a></p>
<p dir="auto">Converting the voice in <code>source_wav</code> to the voice of <code>target_wav</code></p>
<div dir="auto" data-snippet-clipboard-copy-content="tts = TTS(model_name=&quot;voice_conversion_models/multilingual/vctk/freevc24&quot;, progress_bar=False).to(&quot;cuda&quot;)
tts.voice_conversion_to_file(source_wav=&quot;my/source.wav&quot;, target_wav=&quot;my/target.wav&quot;, file_path=&quot;output.wav&quot;)"><pre><span>tts</span> <span>=</span> <span>TTS</span>(<span>model_name</span><span>=</span><span>"voice_conversion_models/multilingual/vctk/freevc24"</span>, <span>progress_bar</span><span>=</span><span>False</span>).<span>to</span>(<span>"cuda"</span>)
<span>tts</span>.<span>voice_conversion_to_file</span>(<span>source_wav</span><span>=</span><span>"my/source.wav"</span>, <span>target_wav</span><span>=</span><span>"my/target.wav"</span>, <span>file_path</span><span>=</span><span>"output.wav"</span>)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example voice cloning together with the voice conversion model.</h4><a id="user-content-example-voice-cloning-together-with-the-voice-conversion-model" aria-label="Permalink: Example voice cloning together with the voice conversion model." href="#example-voice-cloning-together-with-the-voice-conversion-model"></a></p>
<p dir="auto">This way, you can clone voices by using any model in 🐸TTS.</p>
<div dir="auto" data-snippet-clipboard-copy-content="
tts = TTS(&quot;tts_models/de/thorsten/tacotron2-DDC&quot;)
tts.tts_with_vc_to_file(
    &quot;Wie sage ich auf Italienisch, dass ich dich liebe?&quot;,
    speaker_wav=&quot;target/speaker.wav&quot;,
    file_path=&quot;output.wav&quot;
)"><pre><span>tts</span> <span>=</span> <span>TTS</span>(<span>"tts_models/de/thorsten/tacotron2-DDC"</span>)
<span>tts</span>.<span>tts_with_vc_to_file</span>(
    <span>"Wie sage ich auf Italienisch, dass ich dich liebe?"</span>,
    <span>speaker_wav</span><span>=</span><span>"target/speaker.wav"</span>,
    <span>file_path</span><span>=</span><span>"output.wav"</span>
)</pre></div>
<p dir="auto"><h4 tabindex="-1" dir="auto">Example text to speech using <strong>Fairseq models in ~1100 languages</strong> 🤯.</h4><a id="user-content-example-text-to-speech-using-fairseq-models-in-1100-languages-" aria-label="Permalink: Example text to speech using Fairseq models in ~1100 languages 🤯." href="#example-text-to-speech-using-fairseq-models-in-1100-languages-"></a></p>
<p dir="auto">For Fairseq models, use the following name format: <code>tts_models/&lt;lang-iso_code&gt;/fairseq/vits</code>.
You can find the language ISO codes <a href="https://dl.fbaipublicfiles.com/mms/tts/all-tts-languages.html" rel="nofollow">here</a>
and learn about the Fairseq models <a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms">here</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# TTS with on the fly voice conversion
api = TTS(&quot;tts_models/deu/fairseq/vits&quot;)
api.tts_with_vc_to_file(
    &quot;Wie sage ich auf Italienisch, dass ich dich liebe?&quot;,
    speaker_wav=&quot;target/speaker.wav&quot;,
    file_path=&quot;output.wav&quot;
)"><pre><span># TTS with on the fly voice conversion</span>
<span>api</span> <span>=</span> <span>TTS</span>(<span>"tts_models/deu/fairseq/vits"</span>)
<span>api</span>.<span>tts_with_vc_to_file</span>(
    <span>"Wie sage ich auf Italienisch, dass ich dich liebe?"</span>,
    <span>speaker_wav</span><span>=</span><span>"target/speaker.wav"</span>,
    <span>file_path</span><span>=</span><span>"output.wav"</span>
)</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Command-line <code>tts</code></h3><a id="user-content-command-line-tts" aria-label="Permalink: Command-line tts" href="#command-line-tts"></a></p>

<p dir="auto">Synthesize speech on command line.</p>
<p dir="auto">You can either use your trained model or choose a model from the provided list.</p>
<p dir="auto">If you don't specify any models, then it uses LJSpeech based English model.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Single Speaker Models</h4><a id="user-content-single-speaker-models" aria-label="Permalink: Single Speaker Models" href="#single-speaker-models"></a></p>
<ul dir="auto">
<li>
<p dir="auto">List provided models:</p>

</li>
<li>
<p dir="auto">Get model info (for both tts_models and vocoder_models):</p>
<ul dir="auto">
<li>
<p dir="auto">Query by type/name:
The model_info_by_name uses the name as it from the --list_models.</p>
<div data-snippet-clipboard-copy-content="$ tts --model_info_by_name &quot;<model_type>/<language>/<dataset>/<model_name>&quot;"><pre><code>$ tts --model_info_by_name "&lt;model_type&gt;/&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;"
</code></pre></div>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="$ tts --model_info_by_name tts_models/tr/common-voice/glow-tts
$ tts --model_info_by_name vocoder_models/en/ljspeech/hifigan_v2"><pre><code>$ tts --model_info_by_name tts_models/tr/common-voice/glow-tts
$ tts --model_info_by_name vocoder_models/en/ljspeech/hifigan_v2
</code></pre></div>
</li>
<li>
<p dir="auto">Query by type/idx:
The model_query_idx uses the corresponding idx from --list_models.</p>
<div data-snippet-clipboard-copy-content="$ tts --model_info_by_idx &quot;<model_type>/<model_query_idx>&quot;"><pre><code>$ tts --model_info_by_idx "&lt;model_type&gt;/&lt;model_query_idx&gt;"
</code></pre></div>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="$ tts --model_info_by_idx tts_models/3"><pre><code>$ tts --model_info_by_idx tts_models/3
</code></pre></div>
</li>
<li>
<p dir="auto">Query info for model info by full name:</p>
<div data-snippet-clipboard-copy-content="$ tts --model_info_by_name &quot;<model_type>/<language>/<dataset>/<model_name>&quot;"><pre><code>$ tts --model_info_by_name "&lt;model_type&gt;/&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;"
</code></pre></div>
</li>
</ul>
</li>
<li>
<p dir="auto">Run TTS with default models:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --out_path output/path/speech.wav
</code></pre></div>
</li>
<li>
<p dir="auto">Run TTS and pipe out the generated TTS wav file data:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --pipe_out --out_path output/path/speech.wav | aplay"><pre><code>$ tts --text "Text for TTS" --pipe_out --out_path output/path/speech.wav | aplay
</code></pre></div>
</li>
<li>
<p dir="auto">Run a TTS model with its default vocoder model:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_name &quot;<model_type>/<language>/<dataset>/<model_name>&quot; --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --model_name "&lt;model_type&gt;/&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;" --out_path output/path/speech.wav
</code></pre></div>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_name &quot;tts_models/en/ljspeech/glow-tts&quot; --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --model_name "tts_models/en/ljspeech/glow-tts" --out_path output/path/speech.wav
</code></pre></div>
</li>
<li>
<p dir="auto">Run with specific TTS and vocoder models from the list:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_name &quot;<model_type>/<language>/<dataset>/<model_name>&quot; --vocoder_name &quot;<model_type>/<language>/<dataset>/<model_name>&quot; --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --model_name "&lt;model_type&gt;/&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;" --vocoder_name "&lt;model_type&gt;/&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;" --out_path output/path/speech.wav
</code></pre></div>
<p dir="auto">For example:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_name &quot;tts_models/en/ljspeech/glow-tts&quot; --vocoder_name &quot;vocoder_models/en/ljspeech/univnet&quot; --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --model_name "tts_models/en/ljspeech/glow-tts" --vocoder_name "vocoder_models/en/ljspeech/univnet" --out_path output/path/speech.wav
</code></pre></div>
</li>
<li>
<p dir="auto">Run your own TTS model (Using Griffin-Lim Vocoder):</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav"><pre><code>$ tts --text "Text for TTS" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav
</code></pre></div>
</li>
<li>
<p dir="auto">Run your own TTS and Vocoder models:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav
    --vocoder_path path/to/vocoder.pth --vocoder_config_path path/to/vocoder_config.json"><pre><code>$ tts --text "Text for TTS" --model_path path/to/model.pth --config_path path/to/config.json --out_path output/path/speech.wav
    --vocoder_path path/to/vocoder.pth --vocoder_config_path path/to/vocoder_config.json
</code></pre></div>
</li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Multi-speaker Models</h4><a id="user-content-multi-speaker-models" aria-label="Permalink: Multi-speaker Models" href="#multi-speaker-models"></a></p>
<ul dir="auto">
<li>
<p dir="auto">List the available speakers and choose a &lt;speaker_id&gt; among them:</p>
<div data-snippet-clipboard-copy-content="$ tts --model_name &quot;<language>/<dataset>/<model_name>&quot;  --list_speaker_idxs"><pre><code>$ tts --model_name "&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;"  --list_speaker_idxs
</code></pre></div>
</li>
<li>
<p dir="auto">Run the multi-speaker TTS model with the target speaker ID:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS.&quot; --out_path output/path/speech.wav --model_name &quot;<language>/<dataset>/<model_name>&quot;  --speaker_idx <speaker_id>"><pre><code>$ tts --text "Text for TTS." --out_path output/path/speech.wav --model_name "&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;"  --speaker_idx &lt;speaker_id&gt;
</code></pre></div>
</li>
<li>
<p dir="auto">Run your own multi-speaker TTS model:</p>
<div data-snippet-clipboard-copy-content="$ tts --text &quot;Text for TTS&quot; --out_path output/path/speech.wav --model_path path/to/model.pth --config_path path/to/config.json --speakers_file_path path/to/speaker.json --speaker_idx <speaker_id>"><pre><code>$ tts --text "Text for TTS" --out_path output/path/speech.wav --model_path path/to/model.pth --config_path path/to/config.json --speakers_file_path path/to/speaker.json --speaker_idx &lt;speaker_id&gt;
</code></pre></div>
</li>
</ul>
<p dir="auto"><h3 tabindex="-1" dir="auto">Voice Conversion Models</h3><a id="user-content-voice-conversion-models" aria-label="Permalink: Voice Conversion Models" href="#voice-conversion-models"></a></p>
<div data-snippet-clipboard-copy-content="$ tts --out_path output/path/speech.wav --model_name &quot;<language>/<dataset>/<model_name>&quot; --source_wav <path/to/speaker/wav> --target_wav <path/to/reference/wav>"><pre><code>$ tts --out_path output/path/speech.wav --model_name "&lt;language&gt;/&lt;dataset&gt;/&lt;model_name&gt;" --source_wav &lt;path/to/speaker/wav&gt; --target_wav &lt;path/to/reference/wav&gt;
</code></pre></div>

<p dir="auto"><h2 tabindex="-1" dir="auto">Directory Structure</h2><a id="user-content-directory-structure" aria-label="Permalink: Directory Structure" href="#directory-structure"></a></p>
<div data-snippet-clipboard-copy-content="|- notebooks/       (Jupyter Notebooks for model evaluation, parameter selection and data analysis.)
|- utils/           (common utilities.)
|- TTS
    |- bin/             (folder for all the executables.)
      |- train*.py                  (train your target model.)
      |- ...
    |- tts/             (text to speech models)
        |- layers/          (model layer definitions)
        |- models/          (model definitions)
        |- utils/           (model specific utilities.)
    |- speaker_encoder/ (Speaker Encoder models.)
        |- (same)
    |- vocoder/         (Vocoder models.)
        |- (same)"><pre><code>|- notebooks/       (Jupyter Notebooks for model evaluation, parameter selection and data analysis.)
|- utils/           (common utilities.)
|- TTS
    |- bin/             (folder for all the executables.)
      |- train*.py                  (train your target model.)
      |- ...
    |- tts/             (text to speech models)
        |- layers/          (model layer definitions)
        |- models/          (model definitions)
        |- utils/           (model specific utilities.)
    |- speaker_encoder/ (Speaker Encoder models.)
        |- (same)
    |- vocoder/         (Vocoder models.)
        |- (same)
</code></pre></div>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Google shuts down GPay app and P2P payments in the US (147 pts)]]></title>
            <link>https://9to5google.com/2024/06/09/gpay-us/</link>
            <guid>40647517</guid>
            <pubDate>Tue, 11 Jun 2024 15:36:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://9to5google.com/2024/06/09/gpay-us/">https://9to5google.com/2024/06/09/gpay-us/</a>, See on <a href="https://news.ycombinator.com/item?id=40647517">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5google.com/wp-content/uploads/sites/4/2023/03/gpay-logo-circle-3.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"></figure>

<p>As announced <a href="https://9to5google.com/2024/02/22/gpay-app-p2p/">in February</a>, “GPay” is no longer available in the US. The redesigned Google Pay was announced in 2020 to “make money simple, secure, and helpful” with plans for a “mobile-first bank account” that never came to fruition.</p>



<p>Starting on June 4, GPay — as was the name of the app on Android homescreens — automatically signed US users out. Attempting to login again explains how: “The Google Pay US app is no longer available. You can still tap to pay using the Google Wallet app.”</p>



<figure><img decoding="async" width="864" height="1920" src="https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?quality=82&amp;strip=all&amp;w=461" alt="" srcset="https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg 864w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=59,130 59w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=315,700 315w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=768,1707 768w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=461,1024 461w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=691,1536 691w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=158,350 158w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=140,311 140w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=450,1000 450w, https://9to5google.com/wp-content/uploads/sites/4/2024/06/gpay-app-us.jpg?resize=150,333 150w" sizes="(max-width: 864px) 100vw, 864px"></figure>



<p>Additionally, Google no longer offers peer-to-peer payments in the US. You can use the <a href="http://pay.google.com/">Google Pay website</a> to view and transfer your balance — money you’ve received or rewards— to a bank account after June.&nbsp;</p>



<p>The focus is now on Google Wallet and digitizing everything in your physical wallet. There’s no equivalent finance tracking functionality. Meanwhile, “Google Pay” still exists as the name for what you’re actually using when making a physical or online purchase with your phone.</p>



<ul>
<li><strong>Related</strong>: <a href="https://9to5google.com/2024/06/02/google-wallet-android-notifications/">Direct Google Wallet app notifications start rolling out</a></li>
</ul>



<p>The main premise of the big redesign was an app centered “around your relationships with people and businesses” with message-like conversations serving as a purchase history. You could also keep track of your bank account and credit card (via Plaid) in the “Insights” tab, while a lot of deals and cash back offers were presented.</p>






<p>At the November 2022 announcement, co-branded checking and saving “Plex Accounts” were also <a href="https://9to5google.com/2020/11/18/google-pay-plex-account/">previewed</a>. Google partnered with banks and credit unions, most notably Citi. There would have been a physical card&nbsp;</p>



<p>Savings and the ability to create customizable goals was the other big tentpole. You could create specific tasks with milestones to break things up. One option would have been to “round-up transfers” on all purchases to help meet the goal.</p>


<div><figure data-wp-context="{&quot;uploadedSrc&quot;:&quot;https:\/\/9to5google.com\/wp-content\/uploads\/sites\/4\/2020\/11\/google-pay-plex-account-card.jpg?quality=82\u0026strip=all&quot;,&quot;figureClassNames&quot;:&quot;tiled-gallery__item&quot;,&quot;figureStyles&quot;:null,&quot;imgClassNames&quot;:null,&quot;imgStyles&quot;:null,&quot;targetWidth&quot;:702,&quot;targetHeight&quot;:702,&quot;scaleAttr&quot;:false,&quot;ariaLabel&quot;:&quot;Enlarge image&quot;,&quot;alt&quot;:&quot;&quot;}" data-wp-interactive="core/image"><img decoding="async" data-wp-init="callbacks.setButtonStyles" data-wp-on--click="actions.showLightbox" data-wp-on--load="callbacks.setButtonStyles" data-wp-on-window--resize="callbacks.setButtonStyles" srcset="https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?strip=info&amp;w=600&amp;ssl=1 600w,https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?strip=info&amp;w=702&amp;ssl=1 702w" alt="" data-height="702" data-id="391045" data-link="https://9to5google.com/2020/11/18/google-pay-plex-account/google-pay-plex-account-card/" data-url="https://9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?quality=82&amp;strip=all" data-width="702" src="https://i2.wp.com/9to5google.com/wp-content/uploads/sites/4/2020/11/google-pay-plex-account-card.jpg?ssl=1" data-amp-layout="responsive"></figure></div>



<p>Plex was supposed to launch in 2021, but Google announced <a href="https://9to5google.com/2021/10/01/google-pay-abandons-plans-for-plex-bank-accounts-w-400000-on-the-waitlist/">that October</a> how the project was canceled. This was despite a waitlist of 400,000 people. Officially, Google was shifting to “delivering digital enablement for banks and other financial services providers rather than us serving as the provider of these services.”</p>



<hr>



	<p>
		<a target="_blank" rel="nofollow" href="https://news.google.com/publications/CAAqBwgKMMqA-Qow-c_gAg?hl=en-US&amp;gl=US&amp;ceid=US:en">
			<em>Add 9to5Google to your Google News feed.</em>&nbsp;
					</a>
	</p>
	<p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p>				</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[FDA denies petition against use of phthalates in food packaging (149 pts)]]></title>
            <link>https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications</link>
            <guid>40647491</guid>
            <pubDate>Tue, 11 Jun 2024 15:34:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications">https://www.fda.gov/food/cfsan-constituent-updates/fda-responds-petition-phthalates-food-packaging-and-food-contact-applications</a>, See on <a href="https://news.ycombinator.com/item?id=40647491">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>

                                 <article id="main-content" role="article">
          
                                                                <header role="heading" aria-level="1">
                         <div id="block-entityviewcontent-2" data-block-plugin-id="entity_view:node">

  <h2>FDA Responds to Petition on Phthalates in Food Packaging and Food Contact Applications</h2>
  
  	
    
 
</div>






                      </header>
                              
                                                                           <div role="main">

                            
                            
                            
                            
                                              
  
<h2>Constituent Update&nbsp;</h2>

<p>July 21, 2023&nbsp;</p>

<p>Today, the U.S. Food and Drug Administration (FDA) <a href="https://www.regulations.gov/document/FDA-2016-P-1171-0017"><u>denied a petition</u></a> requesting that the agency reconsider its denial of a <a href="https://www.regulations.gov/docket/FDA-2016-P-1171/document?sortBy=postedDate">citizen petition</a> issued on May 19, 2022. The citizen petition requested a ban on the use of eight <em>ortho</em>-phthalates<em> </em>and revocation of the prior sanctioned uses for five ortho-phthalates in food based on alleged safety concerns.</p>

<p><em>Ortho</em>-phthalates, often referred to as “phthalates,” are chemicals used in plastic products (most commonly in the specific type of plastic named polyvinyl chloride, also known as PVC or vinyl) to make the material soft and less brittle.</p>

<p>We evaluated the reconsideration petition and concluded that it does not provide a basis for modifying the FDA’s response to the original citizen petition. Our response explains that we adequately considered relevant information and views contained in the administrative record when responding to the original citizen petition. Additionally, we have considered the information submitted in the reconsideration petition and other relevant information in the administrative record. &nbsp;The FDA’s decision to deny the original petition remains unchanged.</p>

<p>We will continue to keep the food industry and the public informed of updates related to our activities on phthalates in food packaging and food contact applications. Up to date information is available on the FDA’s <a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="520c05e8-8501-4ffb-b7cd-9885329219a2" href="https://www.fda.gov/food/food-additives-and-gras-ingredients-information-consumers/phthalates-food-packaging-and-food-contact-applications" title="Phthalates in Food Packaging and Food Contact Applications ">phthalates</a> website.</p>

<p><strong>For More Information:</strong></p>

<ul><li><a data-entity-substitution="canonical" data-entity-type="node" data-entity-uuid="520c05e8-8501-4ffb-b7cd-9885329219a2" href="https://www.fda.gov/food/food-additives-and-gras-ingredients-information-consumers/phthalates-food-packaging-and-food-contact-applications" title="Phthalates in Food Packaging and Food Contact Applications ">Phthalates in Food Packaging and Food Contact Applications</a></li>
	<li>Constituent Update: <a href="https://www.fda.gov/food/cfsan-constituent-updates/fda-limits-use-certain-phthalates-food-packaging-and-issues-request-information-about-current-food">FDA Limits the Use of Certain Phthalates in Food Packaging and Issues Request for Information About Current Food Contact Uses and Safety Data</a>&nbsp;(September 2022)</li>
</ul>

<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->


<!--END WEBSITE FEEDBACK SNIPPET-->

<!--BEGIN QUALTRICS WEBSITE FEEDBACK SNIPPET-->



              
                                            
              
            </div>

                                                                                  
            

                                                                                
            
                 </article>        
      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Microsoft's official Minesweeper app has ads, pay-to-win, and is hundreds of MBs (327 pts)]]></title>
            <link>https://tech.lgbt/@nina_kali_nina/112594910070716090</link>
            <guid>40647278</guid>
            <pubDate>Tue, 11 Jun 2024 15:22:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://tech.lgbt/@nina_kali_nina/112594910070716090">https://tech.lgbt/@nina_kali_nina/112594910070716090</a>, See on <a href="https://news.ycombinator.com/item?id=40647278">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Meta Open-Sources Megalodon LLM for Efficient Long Sequence Modeling (119 pts)]]></title>
            <link>https://www.infoq.com/news/2024/06/meta-llm-megalodon/</link>
            <guid>40646820</guid>
            <pubDate>Tue, 11 Jun 2024 14:49:05 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.infoq.com/news/2024/06/meta-llm-megalodon/">https://www.infoq.com/news/2024/06/meta-llm-megalodon/</a>, See on <a href="https://news.ycombinator.com/item?id=40646820">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
								<p>Researchers from <a href="https://ai.meta.com/">Meta</a>, <a href="https://www.usc.edu/">University of Southern California</a>, <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, and <a href="https://ucsd.edu/">University of California San Diego</a> recently open-sourced <a href="https://arxiv.org/abs/2404.08801">MEGALODON</a>, a large language model (LLM) with an unlimited context length. MEGALODON has linear computational complexity and outperforms a similarly-sized <a href="https://www.infoq.com/news/2023/07/meta-new-ai-model/">Llama 2</a> model on a range of benchmarks.</p>

<p>MEGALODON is designed to address several shortcomings of the Transformer neural architecture underlying most LLMs. Instead of the standard multihead attention, MEGALODON uses a chunk-wise attention. The research team also introduced sequence-based parallelism during training, improving scalability for long-context training. When evaluated on standard LLM benchmarks, such as <a href="https://paperswithcode.com/dataset/winogrande">WinoGrande</a> and <a href="https://paperswithcode.com/dataset/mmlu">MMLU</a>, MEGALODON outperformed a Llama 2 model with the same amount of parameters, training data, and training compute budget. According to the researchers:&nbsp;</p>

<blockquote>
<p>MEGALODON achieves impressive improvements on both training perplexity and across downstream benchmarks. Importantly, experimental results on long-context modeling demonstrate MEGALODON’s ability to model sequences of unlimited length. Additional experiments on small/medium-scale benchmarks across different data modalities illustrate the robust improvements of MEGALODON, which lead to a potential direction of future work to apply MEGALODON for large-scale multi-modality pretraining.</p>
</blockquote>

<p>Although the Transformer architecture has become the standard for most Generative AI models, Transformers do have some drawbacks. In particular, their self-attention mechanism has quadratic complexity in both compute and storage, which limits the models' input context length. Several alternatives to the standard self-attention model have been developed recently, including structured state space models (SSMs) like <a href="https://arxiv.org/abs/2312.00752">Mamba</a>, which scales linearly with context length. Another scheme that InfoQ recently covered is the <a href="https://www.infoq.com/news/2024/03/rwkv-llm-eagle-7b/">RWKV Project's</a> attention-free Transformer model, which has no maximum input context length.</p>

<p>MEGALODON builds on the research team's previous model, <a href="https://github.com/facebookresearch/mega">MEGA</a> (exponential moving average with gated attention), with several new features. First, while MEGA uses a "classical" exponential moving average (EMA) within its attention mechanism, MEGALODON computes a <em>complex</em>&nbsp;EMA (CEMA). Mathematically, the CEMA component makes MEGALODON equivalent to a "simplified state space model with diagonal state matrix."</p>

<p>The research team trained a seven-billion parameter model, MEGALODON-7B, using the same 2-trillion token dataset that Llama2-7B used; they also used the same training hyperparameters. The team observed that MEGALODON-7B was more computationally efficient. When the Llama model was scaled up to a 32k context length, MEGALODON-7B was "significantly" faster.</p>

<p>Besides evaluating MEGALODON-7B on standard LLM benchmarks, the researchers also tested its performance on the <a href="https://paperswithcode.com/dataset/scrolls">SCROLLS</a> long-context question-answering benchmark, and compared its results with several baseline models, including the modified Llama 2 model with a 32k context length. MEGALODON outperformed all baseline models on the NarrativeQA subtask, and on all tasks achieved results "competitive" with Llama 2.</p>

<p>In a discussion about MEGALODON on Hacker News, one user <a href="https://news.ycombinator.com/item?id=40054901">wondered how well the model performed on recall tasks</a>, given that other non-Transformer models tend to perform poorly. Another user replied:</p>

<blockquote>
<p>For what it's worth, RWKV's website on that matter mentions that yes it's bad on recall, but for the vast majority of tasks you can just ask the question *before* the content, and it'll handle the task just fine.</p>
</blockquote>

<p>The <a href="https://github.com/XuezheMax/megalodon">MEGALODON code</a> is available on GitHub.</p>

								









  
    <div> <!-- main wrapper for authors section -->
        <h2>About the Author</h2> <!-- section title -->

        
            
                
            
            <div data-id="author-Anthony-Alford">
                    <h4><strong>Anthony Alford</strong></h4>
                    
                </div>
        
    </div>

							</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Revideo – Create Videos with Code (148 pts)]]></title>
            <link>https://github.com/redotvideo/revideo</link>
            <guid>40646741</guid>
            <pubDate>Tue, 11 Jun 2024 14:43:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/redotvideo/revideo">https://github.com/redotvideo/revideo</a>, See on <a href="https://news.ycombinator.com/item?id=40646741">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">
  <a href="https://re.video/" rel="nofollow">
    <themed-picture data-catalyst-inline="true"><picture>
      <source media="(prefers-color-scheme: dark)" srcset="https://github.com/redotvideo/revideo/raw/main/logo_dark.svg">
      <img width="360" alt="Revideo logo" src="https://github.com/redotvideo/revideo/raw/main/logo.svg">
    </picture></themed-picture>
  </a>
</p>
<p dir="auto">
  <a href="https://lerna.js.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/b571635460742aca2ea51bd97605e07b77d0eab420b7b2cb6c8c1bf28ffe6c53/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f7075626c6973686564253230776974682d6c65726e612d6330383466633f7374796c653d666c6174" alt="published with lerna" data-canonical-src="https://img.shields.io/badge/published%20with-lerna-c084fc?style=flat"></a>
  <a href="https://vitejs.dev/" rel="nofollow"><img src="https://camo.githubusercontent.com/680f523164e3b85654f193c2b921457a85669e42682dc19bf0fc057e1ad09e17/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706f776572656425323062792d766974652d3634366366663f7374796c653d666c6174" alt="powered by vite" data-canonical-src="https://img.shields.io/badge/powered%20by-vite-646cff?style=flat"></a>
  <a href="https://www.npmjs.com/package/@revideo/core" rel="nofollow"><img src="https://camo.githubusercontent.com/6ec1827e2139c8fe93f8262080c72bdce485423d9a1a42b7c1c73762cabdabf5/68747470733a2f2f696d672e736869656c64732e696f2f6e706d2f762f407265766964656f2f636f72653f7374796c653d666c6174" alt="npm package version" data-canonical-src="https://img.shields.io/npm/v/@revideo/core?style=flat"></a>
  <a href="https://discord.com/invite/JDjbfp6q2G" rel="nofollow"><img src="https://camo.githubusercontent.com/a7bddf0d10924f59bdfd2f96178b83f2705c40110216ff592d312e19db04c6c7/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313037313032393538313030393635373839363f7374796c653d666c6174266c6f676f3d646973636f7264266c6f676f436f6c6f723d66666626636f6c6f723d343034656564" alt="discord" data-canonical-src="https://img.shields.io/discord/1071029581009657896?style=flat&amp;logo=discord&amp;logoColor=fff&amp;color=404eed"></a>
</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Revideo - Create Videos with Code</h2><a id="user-content-revideo---create-videos-with-code" aria-label="Permalink: Revideo - Create Videos with Code" href="#revideo---create-videos-with-code"></a></p>
<p dir="auto">Revideo is an open source framework for programmatic video editing. It is forked
from the amazing <a href="https://motioncanvas.io/" rel="nofollow">Motion Canvas</a> editor, with the goal
of turning it from a standalone application into a library that developers can
use to build entire video editing apps.</p>
<p dir="auto">Revideo lets you create video templates in Typescript and deploy an API endpoint
to render them with dynamic inputs. It also provides a React player component to
preview changes in the browser in real-time. If you want to learn more, you can
check out our <a href="https://docs.re.video/" rel="nofollow">docs</a>, our
<a href="https://github.com/redotvideo/revideo-examples">examples repository</a>, and join
our <a href="https://discord.com/invite/MVJsrqjy3j" rel="nofollow">Discord server</a>.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">News 🔥</h4><a id="user-content-news-" aria-label="Permalink: News 🔥" href="#news-"></a></p>
<ul dir="auto">
<li>[05/21/2024] We released an
<a href="https://github.com/redotvideo/revideo-examples/tree/main/google-cloud-run-parallelized">example</a>
on how to parallelize rendering jobs with Google Cloud Functions</li>
<li>[05/20/2024] We have a <a href="https://re.video/" rel="nofollow">new website</a>!</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Getting Started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting Started" href="#getting-started"></a></p>
<p dir="auto">To create an example project, run the following command:</p>

<p dir="auto">The example project will have the following code, which defines the video shown
below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import {Audio, Img, Video, makeScene2D} from '@revideo/2d';
import {all, chain, createRef, waitFor} from '@revideo/core';

export default makeScene2D(function* (view) {
  const logoRef = createRef<Img>();

  yield view.add(
    <>
      <Video
        src={'https://revideo-example-assets.s3.amazonaws.com/stars.mp4'}
        size={['100%', '100%']}
        play={true}
      />
      <Audio
        src={'https://revideo-example-assets.s3.amazonaws.com/chill-beat.mp3'}
        play={true}
        time={17.0}
      />
    </>,
  );

  yield* waitFor(1);

  view.add(
    <Img
      width={'1%'}
      ref={logoRef}
      src={
        'https://revideo-example-assets.s3.amazonaws.com/revideo-logo-white.png'
      }
    />,
  );

  yield* chain(
    all(logoRef().scale(40, 2), logoRef().rotation(360, 2)),
    logoRef().scale(60, 1),
  );
});"><pre><span>import</span> <span>{</span><span>Audio</span><span>,</span> <span>Img</span><span>,</span> <span>Video</span><span>,</span> <span>makeScene2D</span><span>}</span> <span>from</span> <span>'@revideo/2d'</span><span>;</span>
<span>import</span> <span>{</span><span>all</span><span>,</span> <span>chain</span><span>,</span> <span>createRef</span><span>,</span> <span>waitFor</span><span>}</span> <span>from</span> <span>'@revideo/core'</span><span>;</span>

<span>export</span> <span>default</span> <span>makeScene2D</span><span>(</span><span>function</span><span>*</span> <span>(</span><span>view</span><span>)</span> <span>{</span>
  <span>const</span> <span>logoRef</span> <span>=</span> <span>createRef</span><span>&lt;</span><span>Img</span><span>&gt;</span><span>(</span><span>)</span><span>;</span>

  <span>yield</span> <span>view</span><span>.</span><span>add</span><span>(</span>
    <span>&lt;</span><span>&gt;</span>
      <span>&lt;</span><span>Video</span>
        <span>src</span><span>=</span><span>{</span><span>'https://revideo-example-assets.s3.amazonaws.com/stars.mp4'</span><span>}</span>
        <span>size</span><span>=</span><span>{</span><span>[</span><span>'100%'</span><span>,</span> <span>'100%'</span><span>]</span><span>}</span>
        <span>play</span><span>=</span><span>{</span><span>true</span><span>}</span>
      <span>/</span><span>&gt;</span>
      <span>&lt;</span><span>Audio</span>
        <span>src</span><span>=</span><span>{</span><span>'https://revideo-example-assets.s3.amazonaws.com/chill-beat.mp3'</span><span>}</span>
        <span>play</span><span>=</span><span>{</span><span>true</span><span>}</span>
        <span>time</span><span>=</span><span>{</span><span>17.0</span><span>}</span>
      <span>/</span><span>&gt;</span>
    <span>&lt;</span><span>/</span><span>&gt;</span><span>,</span>
  <span>)</span><span>;</span>

  <span>yield</span><span>*</span> <span>waitFor</span><span>(</span><span>1</span><span>)</span><span>;</span>

  <span>view</span><span>.</span><span>add</span><span>(</span>
    <span>&lt;</span><span>Img</span>
      <span>width</span><span>=</span><span>{</span><span>'1%'</span><span>}</span>
      <span>ref</span><span>=</span><span>{</span><span>logoRef</span><span>}</span>
      <span>src</span><span>=</span><span>{</span>
        <span>'https://revideo-example-assets.s3.amazonaws.com/revideo-logo-white.png'</span>
      <span>}</span>
    <span>/</span><span>&gt;</span><span>,</span>
  <span>)</span><span>;</span>

  <span>yield</span><span>*</span> <span>chain</span><span>(</span>
    <span>all</span><span>(</span><span>logoRef</span><span>(</span><span>)</span><span>.</span><span>scale</span><span>(</span><span>40</span><span>,</span> <span>2</span><span>)</span><span>,</span> <span>logoRef</span><span>(</span><span>)</span><span>.</span><span>rotation</span><span>(</span><span>360</span><span>,</span> <span>2</span><span>)</span><span>)</span><span>,</span>
    <span>logoRef</span><span>(</span><span>)</span><span>.</span><span>scale</span><span>(</span><span>60</span><span>,</span> <span>1</span><span>)</span><span>,</span>
  <span>)</span><span>;</span>
<span>}</span><span>)</span><span>;</span></pre></div>
<details open="">
  <summary>
    
    <span aria-label="Video description revideo-example.mp4">revideo-example.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/122226645/316335996-4d4e56ba-5143-4e4b-9acf-d8a04330d162.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTgxNDE3MDMsIm5iZiI6MTcxODE0MTQwMywicGF0aCI6Ii8xMjIyMjY2NDUvMzE2MzM1OTk2LTRkNGU1NmJhLTUxNDMtNGU0Yi05YWNmLWQ4YTA0MzMwZDE2Mi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYxMVQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YzEzYzVmMTQwZDZlYmUzZWQ3OTc4ZTllNDk3ZThhYTMwMmFjMWZkMDA4MTFjMDJkNGFkNzExZDFmYTQ4Y2ZmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.7SwI-YCuTZEK5eTDcg7YSHxFaKVVLs4ZaUesrFpSfzU" data-canonical-src="https://private-user-images.githubusercontent.com/122226645/316335996-4d4e56ba-5143-4e4b-9acf-d8a04330d162.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTgxNDE3MDMsIm5iZiI6MTcxODE0MTQwMywicGF0aCI6Ii8xMjIyMjY2NDUvMzE2MzM1OTk2LTRkNGU1NmJhLTUxNDMtNGU0Yi05YWNmLWQ4YTA0MzMwZDE2Mi5tcDQ_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjQwNjExJTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI0MDYxMVQyMTMwMDNaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT02YzEzYzVmMTQwZDZlYmUzZWQ3OTc4ZTllNDk3ZThhYTMwMmFjMWZkMDA4MTFjMDJkNGFkNzExZDFmYTQ4Y2ZmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCZhY3Rvcl9pZD0wJmtleV9pZD0wJnJlcG9faWQ9MCJ9.7SwI-YCuTZEK5eTDcg7YSHxFaKVVLs4ZaUesrFpSfzU" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto"><h2 tabindex="-1" dir="auto">Differences between Revideo and Motion Canvas</h2><a id="user-content-differences-between-revideo-and-motion-canvas" aria-label="Permalink: Differences between Revideo and Motion Canvas" href="#differences-between-revideo-and-motion-canvas"></a></p>
<p dir="auto">Motion Canvas aims to be a
<a href="https://github.com/orgs/motion-canvas/discussions/1015">standalone editor</a> for
animations. While it happens to be distributed as an npm package, the
maintainers don't intend for it to be used as a library.</p>
<p dir="auto">We started out as users of Motion Canvas ourselves but ran into these
limitations when we wanted to build a video editing app on top of it. After
building our initial version using Motion Canvas' plugin system, we realized
that we wanted to make more fundamental changes to the codebase that would be
difficult to implement while keeping compatibility with the existing Motion
Canvas API.</p>
<p dir="auto">That's why we decided to fork the project and turn it into Revideo. We wrote a
bit more about it on our <a href="https://re.video/blog/fork" rel="nofollow">blog</a>.</p>
<p dir="auto">Concretely, some of the differences to Motion Canvas are the following ones:</p>
<ul dir="auto">
<li><strong>Headless Rendering:</strong> Motion Canvas currently requires you to press a button
in its UI to render a video. We have exposed this functionality as a
<a href="https://docs.re.video/renderer/renderVideo/" rel="nofollow">function call</a> and are making it
possible to deploy a rendering API to services like Google Cloud Run
(<a href="https://github.com/redotvideo/revideo-examples/tree/main/google-cloud-run">example</a>,
or to use our CLI to expose a rendering endpoint from your Revideo project
(<a href="https://docs.re.video/render-endpoint" rel="nofollow">docs</a>)</li>
<li><strong>Faster Rendering:</strong> When building an app rather than creating videos for
yourself, rendering speeds are quite important. We have sped up rendering
speeds by enabling
<a href="https://github.com/redotvideo/revideo/pull/74" data-hovercard-type="pull_request" data-hovercard-url="/redotvideo/revideo/pull/74/hovercard">parallelized rendering</a> and
replacing the <code>seek()</code> operation for HTML video with our ffmpeg-based
<a href="https://github.com/redotvideo/revideo/pull/33" data-hovercard-type="pull_request" data-hovercard-url="/redotvideo/revideo/pull/33/hovercard">video frame extractor</a></li>
<li><strong>Better Audio Support:</strong> We have enabled audio export from <code>&lt;Video/&gt;</code> tags
during rendering, and have also added an <code>&lt;Audio/&gt;</code> tag that makes it easy to
synchronize audio with your animations.</li>
</ul>

<p dir="auto"><h2 tabindex="-1" dir="auto">Telemetry</h2><a id="user-content-telemetry" aria-label="Permalink: Telemetry" href="#telemetry"></a></p>
<p dir="auto">To understand how people use Revideo, we <strong>anonymously</strong> track how many videos
are rendered using the open-source tool
<a href="https://github.com/PostHog/posthog">Posthog</a>. You can find our code
implementing Posthog
<a href="https://github.com/redotvideo/revideo/tree/main/packages/telemetry">here</a>.</p>
<p dir="auto">If you want to disable telemetry, just set the following environent variable:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Learn More</h2><a id="user-content-learn-more" aria-label="Permalink: Learn More" href="#learn-more"></a></p>
<p dir="auto">To learn more about Revideo, feel free to check out our
<a href="http://docs.re.video/" rel="nofollow">documentation</a> or join our
<a href="https://discord.gg/hexYBZGBY8" rel="nofollow">Discord server</a>.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Norway discovers Europe's largest deposit of rare earth metals (231 pts)]]></title>
            <link>https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html</link>
            <guid>40646658</guid>
            <pubDate>Tue, 11 Jun 2024 14:36:34 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html">https://www.cnbc.com/2024/06/11/norway-discovers-europes-largest-deposit-of-rare-earth-metals.html</a>, See on <a href="https://news.ycombinator.com/item?id=40646658">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="SpecialReportArticle-ArticleBody-6" data-module="ArticleBody" data-test="articleBody-2" data-analytics="SpecialReportArticle-articleBody-6-2"><div id="ArticleBody-InlineImage-102737188" data-test="InlineImage"><p>Neodymium is displayed at the Inner Mongolia Baotou Steel Rare-Earth Hi-Tech Co. factory in Baotou, Inner Mongolia, China.</p><p>Nelson Ching | Bloomberg | Getty Images</p></div><div><p>Mining firm Rare Earths Norway says it has discovered Europe's largest proven deposit of <a href="https://www.cnbc.com/2024/02/14/us-energy-chief-concerned-about-chinas-critical-minerals-dominance.html">highly prized</a> rare earth elements, potentially reflecting a watershed moment for both the Nordic country and the broader region.</p><p>One of the few deposits not owned or controlled by China, the discovery of continental Europe's largest rare earths deposit is considered a welcome boost in Europe's bid to break <a href="https://www.cnbc.com/2024/01/29/norway-defends-deep-sea-mining-as-a-necessary-step-into-the-unknown.html">China's rare earths dominance</a>.</p><p>Demand for rare earths and critical minerals is expected to <a href="https://www.iea.org/topics/critical-minerals" target="_blank">grow exponentially</a> in the coming years as the <a href="https://www.cnbc.com/2023/12/13/countries-agree-to-deal-at-cop28-climate-summit.html">clean energy transition picks up pace</a>.</p><p>Rare Earths Norway <a href="https://rareearthsnorway.com/europes-largest-deposit-of-rare-earth-elements-discovered-at-fen-norway" target="_blank">said</a> in a June 6 statement that its Fen Carbonatite Complex in the southeast of the country boasts 8.8 million metric tons of total rare earth oxides (TREOs) with a reasonable prospect for economic extraction.</p><p>Within the TREOs, which are considered vital to the <a href="https://www.cnbc.com/2021/11/22/climate-how-to-navigate-the-energy-transition-away-from-fossil-fuels.html">global shift away from fossil fuels</a>, the company says there is an estimated 1.5 million metric tons of magnet-related rare earths which can be used in electric vehicles and wind turbines.</p><p>The discovery eclipses a massive rare earths deposit <a href="https://www.cnbc.com/2023/01/13/sweden-mining-company-lkap-finds-big-deposit-of-rare-earth-metals.html">found</a> last year in neighboring Sweden.</p><p>Alf Reistad, CEO of Rare Earths Norway, told CNBC that the discovery at Fen represents a "great milestone" for the company.</p><p>"It is important to state that there is absolutely no extraction of rare earth elements in Europe today," Reistad said via videoconference Monday.</p><p>One of the aims of the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_23_1661" target="_blank">Critical Raw Materials Act</a> is to extract at least 10% of the European Union's annual demand for rare earths by 2030 and Rare Earths Norway says it hopes to contribute to that goal.</p><p>Rare Earths Norway said the rare earths deposit in Telemark, roughly 210 kilometers (130 miles) southwest of Oslo, is likely to underscore Norway's position as an integral part of Europe's rare earth and critical raw material value chain.</p></div><h2><a id="headline0"></a>Rare earths 'more important' than oil and gas</h2><div><p>The International Energy Agency has <a href="https://www.iea.org/topics/critical-minerals" target="_blank">said</a> that today's supply falls short of what is needed to transform the energy sector. That's because there is a relatively high geographical concentration of the production of many energy transition elements.</p><p>Most rare earth elements are located in China, with the world's second-largest economy <a href="https://www.oxfordenergy.org/publications/chinas-rare-earths-dominance-and-policy-responses/" target="_blank">estimated</a> to account for 70% of global rare earth ore extraction and 90% of rare earth ore processing.</p><p>China was the EU's <a href="https://ec.europa.eu/eurostat/web/products-eurostat-news/w/ddn-20231113-1#:~:text" target="_blank">largest partner</a> for imports of rare earth elements in 2022, accounting for 40% of overall imports based on weight.</p></div><div id="ArticleBody-InlineImage-105939934" data-test="InlineImage"><p>Workers transport soil containing rare earth elements for export at a port in Lianyungang, Jiangsu province, China October 31, 2010.</p><p>Stringer | Reuters</p></div><div><p>Looking ahead, Rare Earths Norway said exploration work at the complex will continue, with further drilling scheduled for next month. The company said it is working to develop the first stage of mining by 2030.</p><p>Asked whether he believed the discovered resources could be considered of more value than Norway's <a href="https://www.cnbc.com/2023/01/26/russia-ukraine-war-norways-soaring-oil-and-gas-profits-stokes-debate.html">oil and gas supplies</a>, Rare Earths Norway's Reistad replied, "Not of more value but [European Commission President] Ursula von der Leyen has <a href="https://ec.europa.eu/commission/presscorner/detail/en/speech_22_5493" target="_blank">stated</a> that lithium and rare earth element will soon be more important than oil and gas."</p><p>"So, it will be more important but not have the same value, of course," he added.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Some people with insomnia think they're awake when they're asleep (202 pts)]]></title>
            <link>https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/</link>
            <guid>40646602</guid>
            <pubDate>Tue, 11 Jun 2024 14:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/">https://www.scientificamerican.com/article/some-people-with-insomnia-think-theyre-awake-when-theyre-asleep/</a>, See on <a href="https://news.ycombinator.com/item?id=40646602">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><h2><p>Up All Night? You May Have Actually Been Asleep<br></p></h2><p>You say you haven’t slept all night. Brain scans say you have. New science says both inferences may be right</p><figure><img src="https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=600" alt="Simple black and white vector illustration depicting a woman in bed, eyes closed, sleeping, with a white line scribble above her head" srcset="https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=600 600w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=900 900w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1000 1000w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1200 1200w, https://static.scientificamerican.com/dam/m/7edb6a67835a1e6/original/GettyImages-1699934248_WEB.jpg?w=1350 1350w" sizes="(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw" fetchpriority="high"><figcaption> <p>Sulukhana Boonyarithsripong/Getty Images</p></figcaption></figure></div><div><p data-block="sciam/paragraph">Desperate for sleep, you go to a sleep clinic, where your head is fitted with electrodes to record your brain waves through various sleep stages. In the morning, you report that you barely slept at all. Yet according to the test—polysomnography, the gold standard for sleep measurement—you slept all night.</p><p data-block="sciam/paragraph">You’re not the classic example of a person with insomnia who waits for sleep to come, maybe checks the clock, paces, reads and waits for morning. What you have has been called subjective insomnia, paradoxical insomnia or sleep misperception. Scientists have doggedly attacked this stubborn puzzle for decades without result—until now. Now they say that you have not been misrepresenting your sleep; they have been mismeasuring it.</p><p data-block="sciam/paragraph">The most recent <a href="https://onlinelibrary.wiley.com/doi/full/10.1111/jsr.14028">studies</a><u>,</u> using far more enhanced measurement, have found that many people with subjective insomnia show different brain activity from good sleepers—throughout the night. Neuroscientist Aurélie Stephan and colleagues at the Netherlands Institute for Neuroscience (NIN) realized that something unusual was going on after they asked people in their study to put onto their head a net of 256 electrodes rather than the typical six to 20 used in sleep clinics. In one <a href="https://www.cell.com/current-biology/pdf/S0960-9822(21)01366-X.pdf">series of experiments</a>, the researchers woke sleepers about 26 times on average during the night. The participants were asked whether they’d been asleep or awake and what they’d been thinking about.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href="https://www.scientificamerican.com/getsciam/">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block="sciam/paragraph">The most remarkable finding, Stephan says, is that these people showed pockets of arousal in the form of fast brain waves during rapid eye movement (REM) sleep. REM is the stage in normal sleep when your brain should completely disconnect from the systems that keep you aware and vigilant, Stephan says.</p><p data-block="sciam/paragraph">People with subjective insomnia with this interrupted REM do not experience their sleep as restful. When wakened, they reported having had thoughts similar to those when awake—adding lettuce to their shopping list, say, or reminding themselves to call their cousin. They were less likely to have what University of Montreal neuroscientist Claudia Picard-Deland calls immersive dreams, in which you feel physically present in the dream world and are fleeing down a dark hallway, feeling the hardness of the floor or battling a dragon, sensing its hot breath.</p><p data-block="sciam/paragraph">In a study of normal sleepers Picard-Deland recently presented at the <a href="https://www.cogneurosociety.org/symposia/">the Cognitive Neuroscience Society’s annual meeting</a>, participants said they felt most deeply asleep during immersive dreams, which occurred in the REM stage. People with interrupted REM, as Stephan’s research shows, do not report immersive dreams. They do not feel they’ve slept deeply, and they report fatigue similar to that of people who actually sleep very little.</p><p data-block="sciam/paragraph">Perhaps even more important, says NIN sleep scientist Eus van Someren, interrupted REM is strongly linked to disorders such as post-traumatic stress disorder (PTSD) and anxiety. If two people experience the same level of trauma, a good sleeper is probably less likely to develop PTSD than someone with disturbed sleep, he says. Those with disturbed sleep are therefore more vulnerable to developing PTSD. It’s a vicious cycle.</p><p data-block="sciam/paragraph">This occurs because interrupted REM interferes with the overnight dissolving of emotional distress that has accumulated throughout the daytime, which typically happens during good sleep. “Sound REM sleep is the only state during which the brain has a ‘<a href="https://journals.physiology.org/doi/full/10.1152/physrev.00046.2019">time-out</a>’ of noradrenaline [norepinephrine],” van Someren says. “The neurons are not firing anymore, so they don’t release noradrenaline downstream in the brain. But if you have even the slightest arousal from REM sleep..., then noradrenaline shoots up very fast.” He believes those with interrupted REM experience this arousal repeatedly and never reach the typical quiescent state that allows for the processing of troubled emotions.</p><p data-block="sciam/paragraph">A <a href="https://pubmed.ncbi.nlm.nih.gov/30590834/#:~:text=Conclusions%3A%20Our%20findings%20are%20the,actually%20aggravates%20physically%20perceived%20distress.">study</a> headed by van Someren’s former graduate student Rick Wassing, now at Macquarie University in Australia, demonstrates this experimentally. The researchers exposed people to a distressing emotional experience for three days in a row: they had to listen to a recording of themselves singing—often out of tune—to karaoke, which aroused shame. As measured by their physiological responses, normal sleepers felt less distress after a night’s sleep. Those with disturbed sleep felt more.</p><p data-block="sciam/paragraph">The percentage of people with insomnia that have interrupted REM is unknown, but these insights are suggesting new personalized treatments for insomnia, which is now understood as existing on a spectrum. Such treatments may be especially beneficial to people with insomnia who also have depression and anxiety disorders.</p><p data-block="sciam/paragraph">Currently, cognitive behavioral therapy for insomnia (CBTi) is the standard intervention for insomnia. People with insomnia learn to decrease their anxiety about sleeping and to employ behavioral strategies aimed at better sleep. But CBTi does not work for everyone. Those with interrupted REM, in particular, probably need different solutions.</p><p data-block="sciam/paragraph">One behavioral strategy used in CBTi—sleep restriction—does show promise for people with interrupted REM, however. Some sleep-restriction methods involve shortening a person’s time in bed to the average amount that they actually sleep per night. Other methods delay a person’s bedtime.” For example, If a person objectively sleeps for 5.5 hours, the experts allow the person to be in bed only for six hours. A preliminary lab <a href="https://www.nature.com/articles/s41598-021-03564-6">study</a> in which participants delayed their regular bedtime by two hours showed that such sleep restriction can reduce the number of arousals during REM. The researchers are hoping to replicate these results in a larger study of people sleeping at home.</p><p data-block="sciam/paragraph">This new science also opens the way for drug interventions. The NIN group is seeking approvals to test whether a beta-blocker typically prescribed to lower blood pressure might mitigate the effects of continuous bursts of norepinephrine. The researchers are also considering testing the blood pressure drug clonidine in the hopes that it may help the brain reach a more quiescent state.</p><p data-block="sciam/paragraph">Until these interventions are available, says sleep researcher Geoffroy Solelhac of the Center for Investigation and Research in Sleep in Switzerland, “just understanding that their sleep is objectively different is reassuring to patients. They feel a sort of relief.” Knowing all that may even help them sleep better.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[All three game console makers have now abandoned X integration (117 pts)]]></title>
            <link>https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed</link>
            <guid>40646518</guid>
            <pubDate>Tue, 11 Jun 2024 14:24:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed">https://www.theverge.com/2024/6/11/24175932/nintendo-switch-console-x-twitter-integration-removed</a>, See on <a href="https://news.ycombinator.com/item?id=40646518">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>As of June 10th, Nintendo has officially discontinued support for the Switch console’s integration with X (formerly Twitter), making it the last of the current-gen consoles to do so after <a href="https://www.theverge.com/2023/4/21/23692467/microsoft-disables-xbox-clip-sharing-to-twitter-from-consoles-and-pcs">Microsoft</a> and <a href="https://www.theverge.com/2023/11/6/23949343/playstation-x-sharing-options-ps5-ps4">Sony</a> disabled their own access last year.&nbsp;</p><p>The integration was removed as part of the <a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/22525/~/nintendo-switch-system-update-information">Nintendo Switch’s 18.1.0 update</a>, taking away the ability for users to link their X account with the console, or post in-game screenshots from <em>Super Smash Bros. Ultimate</em> directly to the social media platform. The removal of these features comprised the majority of the 18.1.0 update, which also includes some general stability improvements and ditches support for linking social media accounts via the Switch’s Friend Suggestions feature.</p><p>Nintendo announced these changes <a href="https://en-americas-support.nintendo.com/app/answers/detail/a_id/65057">last month</a> but didn’t explicitly state the reason for pulling support for X. Given Switch users can still share their content to Facebook, it likely has something to do with <a href="https://www.theverge.com/2023/3/30/23662832/twitter-api-tiers-free-bot-novelty-accounts-basic-enterprice-monthly-price">pricing changes to the X API</a> which now <em>starts</em> at <a href="https://developer.x.com/en/products/twitter-api/enterprise/enterprise-api-interest-form#:~:text=Enterprise%20API%20pricing%20starts%20at,based%20on%20usage%20and%20needs.&amp;text=Acknowledgment%20of%20X%20Terms%20%2D%20By,to%20accept%20messages%20from%20X.">$42,000 a month</a> for enterprise customers.</p><p>Microsoft didn’t mention X’s API update when it removed the ability for Xbox consoles to share game uploads to the service last April, nor did Sony when it followed suit in November for the PS5 and PS4. Cost may not be the only factor as <a href="https://www.theverge.com/2023/10/24/23930686/slack-x-twitter-integration-retires-api-pricing">Slack said it had also pulled support</a> because the API updates impacted the functionality of its own X integration, but regardless of the reason, console gamers will now have a hard time connecting directly with the platform.&nbsp;</p><p>That’s despite the <a href="https://www.theverge.com/2024/5/8/24152535/nintendo-switch-direct-sharing-to-x-twitter-ends-on-june-10th">X Gaming account saying</a> in a now-deleted post that its “partnership with Nintendo remains strong” after Nintendo announced its plans to kill Switch support.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Firefox 127 (142 pts)]]></title>
            <link>https://www.mozilla.org/en-US/firefox/127.0/releasenotes/</link>
            <guid>40646477</guid>
            <pubDate>Tue, 11 Jun 2024 14:20:57 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.mozilla.org/en-US/firefox/127.0/releasenotes/">https://www.mozilla.org/en-US/firefox/127.0/releasenotes/</a>, See on <a href="https://news.ycombinator.com/item?id=40646477">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="outer-wrapper">
      
<main>
  <article id="main-content">

    
    <header>
      <div>
          
            <p>Version 127.0, first offered to Release channel users on June 11, 2024</p>
            
          
        </div></header>
  

    <section>
    
      
        
          <div>
              <ul>
        
        
  <li id="note-790131">
    <p>You can now set Firefox to automatically launch whenever you start or restart your Windows computer. Setting Firefox to auto-launch optimizes efficiency in our browser-centric digital routines, eliminating manual startup delays and facilitating immediate web access. (<a href="https://support.mozilla.org/kb/open-firefox-automatically-when-you-start-computer">Learn more</a>)</p>
    
  </li>

        
      
        
        
  <li id="note-790141">
    <p>We completed work to optimize and enable DNS prefetching for HTTPS documents via the <code>rel="dns-prefetch"</code> link hint. This standard allows web developers to specify domain names for important assets that should be resolved preemptively.</p>
    
  </li>

        
      
        
        
  <li id="note-790170">
    <p>It is now possible to close all duplicate tabs in a window with the <em>Close duplicate tabs</em> command available from the <em>List all tabs</em>  widget in the tab bar or a tab context menu.</p>
    
  </li>

        
      
        
        
  <li id="note-790194">
    <div>
      <p>Firefox will now automatically try to <a href="https://blog.mozilla.org/security/2024/06/05/firefox-will-upgrade-more-mixed-content-in-version-127/">upgrade <code>&lt;img&gt;</code>, <code>&lt;audio&gt;</code>, and <code>&lt;video&gt;</code> elements from HTTP to HTTPS</a> if they are embedded within an HTTPS page. If these so-called mixed content elements do not support HTTPS, they will no longer load.</p>
      
      
    </div>
    
  </li>

        
      
        
        
  <li id="note-790195">
    <p>For added protection on MacOS and Windows, a device sign in (e.g. your operating system password, fingerprint, face or voice login if enabled) can be required when accessing and filling stored passwords in the <a href="https://support.mozilla.org/kb/password-manager-remember-delete-edit-logins">Firefox Password Manager</a> about:logins page.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      
        
          
        
      

      
        
          <div>
              <ul>
        
          
  <li id="note-790142">
    <p>To reduce user fingerprinting information and the risk of some website compatibility issues, the CPU architecture for 32-bit x86 Linux will now be reported as x86_64 in Firefox's User-Agent string and <code>navigator.platform</code> and <code>navigator.oscpu</code> Web APIs.</p>
    
  </li>

        
      
        
          
  <li id="note-790143">
    <p>Links and other focusable elements are now tab-navigable by default on macOS, instead of following macOS' "Keyboard navigation" setting. This is a more accessible default and matches the default in all other platforms. A checkbox in the settings page still allows users to restore the old behavior.</p>
    
  </li>

        
      
        
          
  <li id="note-790169">
    <p>The Screenshots feature in Firefox has gotten a big update! It now supports taking screenshots of file types like SVG, XML, and more as well as various about: pages within Firefox. We've also made the screenshot tool more accessible to everyone by implementing new keyboard shortcuts and adding theme compatibility and High Contrast Mode (HCM) support. And finally, performance for capturing large screenshots has been improved.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      
        
          <div>
              <ul>
        
        
  <li id="note-790196">
    <div>
      <p>You can find information about policy updates and enterprise-specific bug fixes in the <a href="https://support.mozilla.org/kb/firefox-enterprise-127-release-notes">Firefox for Enterprise 127 Release Notes</a>.</p>
      
      
    </div>
    
  </li>

        
              </ul>
            </div>
        
      

      
      

      
        
        
          
        
      

      
        
          <div>
              <ul>
        
        
  <li id="note-790171">
    <p><code>navigator.clipboard.read()/write()</code> has been enabled (see <a href="https://developer.mozilla.org/docs/Web/API/Clipboard_API">documentation</a>). A paste context menu will appear for the user to confirm when attempting to read clipboard content that is not originated from a <code>same-origin</code> page.</p>
    
  </li>

        
              </ul>
            </div>
        
      

      

      

      

      
        
          <div id="community">
            <ul>
        
        
  <li id="note-790193">
    <div>
      <p>With the release of Firefox 127, we are pleased to welcome the developers who contributed their first code change to Firefox in this release, 8 of whom were brand new volunteers! Please join us in thanking each of these diligent and enthusiastic individuals, and take a look at their contributions:</p>
<ul>
<li>alphare33: <a href="https://bugzilla.mozilla.org/1856611">1856611</a></li>
<li>ash: <a href="https://bugzilla.mozilla.org/1783183">1783183</a></li>
<li>Dongwoo Kang [:nyanrus]: <a href="https://bugzilla.mozilla.org/1891317">1891317</a></li>
<li>endington543: <a href="https://bugzilla.mozilla.org/1820570">1820570</a>, <a href="https://bugzilla.mozilla.org/1891816">1891816</a>, <a href="https://bugzilla.mozilla.org/1892348">1892348</a>, <a href="https://bugzilla.mozilla.org/1893985">1893985</a></li>
<li>jmc531: <a href="https://bugzilla.mozilla.org/1885695">1885695</a></li>
<li>Joseph Webster: <a href="https://bugzilla.mozilla.org/1825105">1825105</a>, <a href="https://bugzilla.mozilla.org/1893061">1893061</a>, <a href="https://bugzilla.mozilla.org/1894063">1894063</a></li>
<li>Leeya: <a href="https://bugzilla.mozilla.org/1742889">1742889</a></li>
<li>Steve P: <a href="https://bugzilla.mozilla.org/1836440">1836440</a>, <a href="https://bugzilla.mozilla.org/1844935">1844935</a>, <a href="https://bugzilla.mozilla.org/1880909">1880909</a></li>
</ul>
      
      
    </div>
    
  </li>

        
            </ul>
          </div>
        
      
    
    </section>

    <div>
      
      <p>
        <h2>Get the most recent version</h2>
        
      </p>
    </div>

    
    <section>
      <a href="https://www.mozilla.org/en-US/firefox/all/#product-desktop-release">All Firefox downloads</a>
    </section>
    

    
    
    
</article>
</main>


      
        




      

      
      
    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Self-Serve Dashboards (172 pts)]]></title>
            <link>https://briefer.cloud/blog/posts/self-serve-bi-myth/</link>
            <guid>40646312</guid>
            <pubDate>Tue, 11 Jun 2024 14:04:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://briefer.cloud/blog/posts/self-serve-bi-myth/">https://briefer.cloud/blog/posts/self-serve-bi-myth/</a>, See on <a href="https://news.ycombinator.com/item?id=40646312">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><article><p>Sales pitches are the only place where “self-serve dashboards" work. In the real world, it's a different story.</p>
<p>That story usually starts with an engineer or data scientist who's frustrated because they spend too much time writing queries and preparing dashboards for business people. They think that if they make BI easy enough, everyone will be able to “self-serve”, but that rarely ever happens.</p>
<p>What actually happens is that engineers and data scientists end up being the only people using the "self-serve" BI tool, which, ironically, makes it not self-serve at all.</p>
<br>
<h2>Why self-serve BI doesn't work</h2>
<p><strong>SQL is the only self-serve BI tool</strong>. Still, most "self-serve" BI vendors don't want to admit it, so they find ways to reinvent the wheel and disguise SQL as something else. Maybe that's what customers want to hear, or maybe they genuinely believe it, I'm not sure.</p>
<p>Either way, the problem with most approaches to "self-serve" BI is that they consider SQL to be the only barrier to business stakeholders querying data. That's not true.</p>
<p>Let's say you could wave a magic wand and make writing SQL queries as easy as writing an email. Do you think business stakeholders would suddenly start querying data? The answer is no.</p>
<p>Even if these people knew how to write SQL queries, they wouldn't understand the semantics of the data they're querying. They wouldn't know what the data means, where it comes from, or how it's calculated. They wouldn't know how to interpret the results, or how to validate them. In other words, writing the SQL query is actually the easy part.</p>
<p>Now, let's look at two attempts to make BI "self-serve" and see whether the hypothesis above holds.</p>
<br>
<h3>Attempt 1: The conventional "dropdowns and checkboxes" approach</h3>
<p>First, let's take a look at an example of a conventional "self-serve" BI interface which uses dropdowns and checkboxes as a way to make queries more accessible.</p>
<p><img src="https://briefer.cloud/posts/self-serve-bi/sql-by-mouse.png" alt=""></p>
<p>The first thing to notice is that this interface is just an attempt at what I call "SQL-by-mouse". I might be just an old grumpy person, but I don't see how this is any better than writing SQL. In fact, it's worse because it's slower, less reliable, more limited, and not generalizable to other tools.</p>
<p>In any case, I'll concede one thing: some non-technical people are just scared of any monospaced writing with syntax highlight, so this interface might be a good first step.</p>
<p>Anyway, let's ignore all these problems and just assume that this interface is the best thing since <a href="https://htmx.org/">htmx</a>. Let's assume that it's 100x easier to use than SQL.</p>
<p>Even if that were the case, your CFO, for example, wouldn't just go ahead and use these dropdowns and checkboxes to query data. The reason they wouldn't use it is that they don't have the context to understand the data they're querying, and they'll probably be insecure about the results, which they won't know how to validate because they don't understand how the data got there in the first place.</p>
<p>Now, I've got a question for you: if your CFO doesn't use this interface, who will? That's right, <em>you</em> will. And guess what's the first thing you'll do when you get to these dropdowns? Correct, you'll immediately look for somewhere to type in SQL. Oh, the irony.</p>
<br>
<h3>Attempt 2: The text-to-SQL approach</h3>
<p>Remember that magic wand that makes writing SQL queries as easy as writing an email? That's what text-to-SQL tools are. Nonetheless, they're not enough, just as I explained earlier.</p>
<p>Again, the problem is not the technology itself. In fact, LLMs are almost too effective at translating natural language into SQL. They will find a way to generate a query for any question you ask, even if that question doesn't make sense, which is exactly the problem.</p>
<p>On the other hand, a technical person would notice that the question doesn't make sense, and they would ask for more context. They would ask for details about the business person's hypothesis and the problem at hand. Then, they would explain what type of data is available, and work with the business person to formulate a precise and useful question.</p>
<p>Again, SQL is not the problem.</p>
<p>In any case, I do think LLMs could be the actual solution to self-serve BI, but not in its current form. For them to work, they'd need to be fed with more context, and <a href="https://allenpike.com/2024/llms-trained-on-internet">they need to get better at expressing uncertainty</a> and asking for more information.</p>
<br>
<h2>What actually works</h2>
<p>If we assume that the problem with self-serve BI is not SQL, but the context and semantics of the data, then it follows that the solution is to teach people about the data they're querying, regardless of interface.</p>
<p>The problem with this type of training is that it takes time, and most business stakeholders need answers this week, not next quarter.</p>
<p>Even in the best-case scenario, where companies train business stakeholders to understand the data they're querying, these people will need time to keep up with the changes in the database's schema, data models, and ETL processes.</p>
<p>Additionally, documenting all this knowledge generates significant overhead for the technical team, and it quickly gets out-of-date.</p>
<p>So what's the true solution to self-serve BI? The answer is simple: not to make BI self-serve for non-technical people. Instead, the solution is to make technical people support business stakeholders and help them do it more efficiently, using better tools.</p>
<p>The definition of a better tool may vary, but I have a few suggestions.</p>
<p>The first suggestion is to give LLMs to technical people, not business stakeholders. Even though text-to-SQL is not quite there in terms of understanding context and semantics, technical people <em>already</em> have context and semantics, so why not let <em>them</em> use it? That way, a single technical person can serve more business stakeholders, and do it faster.</p>
<p>The second suggestion is to give technical people more flexible tools. Instead of giving them dropdowns, or a SQL-only interface, let them play around with data using Python, R, or any other tool they're comfortable with. This way, they don't need to be passing data back and forth between different tools, and they're not limited by the capabilities of a BI tool.</p>
<p>The third and final suggestion is to make it easier for technical people to share their work. Notebooks and internal data applications are notoriously bad at that because they require others to deal with containers, dependencies, and infrastructure. It's a lot of overhead for a business stakeholder who just wants to see a chart. Instead, we need tools that have all the building blocks of a data application, but that are as easy to share as a Google Doc.</p>
<p>I'm obviously biased because I'm building <a href="https://briefer.cloud/">a data tool for technical people</a>, and it does exactly these three things. But what other choice do I have? I'd rather build tools that work than tools that don't. And, most importantly, I'd rather not pretend that the problem is something it's not.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[I like the RP2040 (399 pts)]]></title>
            <link>https://dgroshev.com/blog/rp2040/</link>
            <guid>40646061</guid>
            <pubDate>Tue, 11 Jun 2024 13:39:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://dgroshev.com/blog/rp2040/">https://dgroshev.com/blog/rp2040/</a>, See on <a href="https://news.ycombinator.com/item?id=40646061">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
      



  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/rp2040.jpg?hash=aa3e21f5" target="_blank">
  <img src="https://dgroshev.com/processed_images/rp2040.0c483830155c3532.jpg?hash=aa3e21f5" srcset="https://dgroshev.com/processed_images/rp2040.0c483830155c3532.jpg?hash=aa3e21f5, https://dgroshev.com/blog/rp2040/img/rp2040.jpg?hash=aa3e21f5 2x" alt="RaspberryPi's picture of a RP2040">
</a></p><p>The RP2040 is a microcontroller made by Raspberry Pi. Unlike their more widely known products, the
RP2040 is meant to be embedded in consumer electronics. It's cheap and available in tens of thousands
for immediate dispatch from your local Mouser.</p>
<p>I really like the RP2040 and I want you to know why.</p>
<h2 id="just-the-right-size">Just the right size</h2>
<p>Here is the Mouser stock for a microcontroller manufacturer Espressif:</p>




  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/espressif_stock.png?hash=7c8c85d9" target="_blank">
  <img src="https://dgroshev.com/processed_images/espressif_stock.72e7319c5dab554d.png?hash=7c8c85d9" srcset="https://dgroshev.com/processed_images/espressif_stock.72e7319c5dab554d.png?hash=7c8c85d9, https://dgroshev.com/blog/rp2040/img/espressif_stock.png?hash=7c8c85d9 2x" alt="A screenshot of the Mouser stock for Espressif microcontrollers">
</a></p><p>Dozens of slightly different controllers. Why?</p>
<p>Unlike software, physical products cost money to manufacture. Every cent saved on a gizmo's components
is a cent in earnings, which adds up when the gizmos are manufactured by the million. This creates an incentive 
to pick a microcontroller that is only just powerful enough (to "right size" it), and usually microcontroller 
manufacturers are happy to help, offering dozens of variations of the same microcontroller.</p>
<p>Here is the Mouser stock for Raspberry Pi:</p>




  
  

  
    
  


<p><a href="https://dgroshev.com/blog/rp2040/img/raspberry_stock.png?hash=4680aaa1" target="_blank">
  <img src="https://dgroshev.com/processed_images/raspberry_stock.6cd109cef39fc572.png?hash=4680aaa1" srcset="https://dgroshev.com/processed_images/raspberry_stock.6cd109cef39fc572.png?hash=4680aaa1, https://dgroshev.com/blog/rp2040/img/raspberry_stock.png?hash=4680aaa1 2x" alt="A screenshot of Mouser stock for Raspberry microcontrollers">
</a></p><p>(This is the same microcontroller, just two different packaging options<sup><a href="#1">1</a></sup>.)</p>
<p>What?</p>
<h2 id="as-long-as-it-s-black">…as long as it's black</h2>
<p>Raspberry Pi pulled a Henry Ford and boldly went with just one microcontroller.</p>
<p>There is no choice, no right sizing, but that might be OK! An RP2040 costs ~70 cents, and not all gizmos are produced
by the million.</p>
<p>In return, Raspberry Pi ensured that everyone on the planet works with the same part. Compared to more traditional
wide lineups, there is a disproportionate number of StackExchange questions, blog posts (including this one), 
experience, Github issues, libraries, and tools for the RP2040<sup><a href="#2">2</a></sup>.</p>
<p>This is a good tradeoff for projects like <a href="https://late-mate.com/">Late Mate</a>, which are likely to save more on 
development costs than on parts<sup><a href="#3">3</a></sup>. </p>
<h2 id="down-the-stack">Down the stack</h2>
<p>This single model pragmatism is evident in the choices Raspberry Pi made for the microcontroller itself.
It is designed to be a jack-of-all-trades, trading "excellent" for "sufficient and flexible":</p>
<ul>
<li>Two decent cores. The second core is there if you need it.</li>
<li>30 GPIO pins, a very average number. </li>
<li>No on-board flash, spending the budget on more internal RAM that is much harder to wire externally.</li>
<li>An OK ADC, good USB support, and the usual peripherals (UART/SPI/I2C/PWM).</li>
</ul>
<p>Less conventionally, the RP2040 comes with a peripheral called "PIO" for Programmable Input/Output.
It's like two tiny coprocessors that can execute your IO fast, with precise timing, and without spending CPU time.
Some cool things people do with PIO:</p>
<ul>
<li>communication protocols like <a href="https://github.com/peterkrull/dshot-pio">DShot ESC</a></li>
<li><a href="https://github.com/sekigon-gonnoc/Pico-PIO-USB">a fully featured USB stack on PIO</a>, giving RP2040 
a second USB controller</li>
<li>coupled with DMA, <a href="https://dmitry.gr/?r=06.%20Thoughts&amp;proj=09.ComplexPioMachines">display drivers</a> that
completely offload display+touch communication from the CPU</li>
</ul>
<p>The RP2040 is impossible to brick. It comes with a read-only bootloader that can either mount as a USB mass storage device
(firmware updates can just be copypasted to the "storage device"), or use 
<a href="https://github.com/raspberrypi/picotool">its own simple USB protocol</a>.</p>
<p>In the same pragmatic vein, the RP2040 doesn't engage in security theatre. Protecting the firmware from a dedicated
attacker is nearly impossible, but there are complexity and DX costs to trying, so I'm glad Raspberry Pi 
made the call.</p>
<p>I just love the deliberate design of this little square of silicon. When I work with it, I can see how 
smart people thought hard about the niche the RP2040 is in and drove the tradeoffs accordingly. As an engineer 
<sup>aspiring to be good someday</sup>, I appreciate it.</p>
<p><a href="https://news.ycombinator.com/item?id=40646061">Discuss on Hackernews</a></p>
<p>
  More of ^this^ on <a href="https://mastodon.social/@dangroshev" target="_blank">Mastodon</a>,
  <a href="https://twitter.com/dangroshev" target="_blank">Twitter</a>,
  <a href="https://dgroshev.com/atom.xml">RSS</a>, or a
  <a href="https://buttondown.email/dgroshev" target="_blank">very occasional newsletter</a>.
</p>
<p>
  Or just let me know what you think at
  <a href="mailto:dan@dgroshev.com">dan@dgroshev.com</a>!
</p>
<hr>




    </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[A new term, ‘slop’, has emerged to describe dubious A.I.-generated material (231 pts)]]></title>
            <link>https://www.nytimes.com/2024/06/11/style/ai-search-slop.html</link>
            <guid>40645983</guid>
            <pubDate>Tue, 11 Jun 2024 13:32:10 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/06/11/style/ai-search-slop.html">https://www.nytimes.com/2024/06/11/style/ai-search-slop.html</a>, See on <a href="https://news.ycombinator.com/item?id=40645983">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/06/11/style/ai-search-slop.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Unforget, the note-taking app I always wanted: offline first, encrypted (128 pts)]]></title>
            <link>https://unforget.computing-den.com/demo</link>
            <guid>40645743</guid>
            <pubDate>Tue, 11 Jun 2024 13:02:23 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://unforget.computing-den.com/demo">https://unforget.computing-den.com/demo</a>, See on <a href="https://news.ycombinator.com/item?id=40645743">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[The Titan Submersible Disaster. The Inside Story Is More Disturbing (111 pts)]]></title>
            <link>https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/</link>
            <guid>40645439</guid>
            <pubDate>Tue, 11 Jun 2024 12:29:24 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/">https://www.wired.com/story/titan-submersible-disaster-inside-story-oceangate-files/</a>, See on <a href="https://news.ycombinator.com/item?id=40645439">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-testid="ArticlePageChunks"><div data-journey-hook="client-content" data-testid="BodyWrapper"><p><span>The Ocean Sciences</span> Building at the University of Washington in Seattle is a brightly modern, four-story structure, with large glass windows reflecting the bay across the street.</p><p>On the afternoon of July 7, 2016, it was being slowly locked down.</p><p>Red lights began flashing at the entrances as students and faculty filed out under overcast skies. Eventually, just a handful of people remained inside, preparing to unleash one of the most destructive forces in the natural world: the crushing weight of about 2½ miles of ocean water.</p><p>In the building’s high-pressure testing facility, a black, pill-shaped capsule hung from a hoist on the ceiling. About 3 feet long, it was a scale model of a submersible called <em>Cyclops 2</em>, developed by a local startup called <a href="https://www.wired.com/story/titan-sub-oceangate-hull-failure-loss-tragedy/">OceanGate</a>. The company’s CEO, Stockton Rush, had cofounded the company in 2009 as a sort of submarine charter service, anticipating a growing need for commercial and research trips to the ocean floor. At first, Rush acquired older, steel-hulled subs for expeditions, but in 2013 OceanGate had begun designing what the company called “a revolutionary new manned submersible.” Among the sub’s innovations were its lightweight hull, which was built from carbon fiber and could accommodate more passengers than the spherical cabins traditionally used in deep-sea diving. By 2016, Rush’s dream was to take paying customers down to the most famous shipwreck of them all: the <em>Titanic</em>, 3,800 meters below the surface of the Atlantic Ocean.</p><p>Engineers carefully lowered the <em>Cyclops 2</em> model into the testing tank nose-first, like a bomb being loaded into a silo, and then screwed on the tank’s 3,600-pound lid. Then they began pumping in water, increasing the pressure to mimic a submersible’s dive. If you’re hanging out at sea level, the weight of the atmosphere above you exerts 14.7 pounds per square inch (psi). The deeper you go, the stronger that pressure; at the <em>Titanic</em>’s depth, the pressure is about 6,500 psi. Soon, the pressure gauge on UW’s test tank read 1,000 psi, and it kept ticking up—2,000 psi, 5,000 psi. At about the 73-minute mark, as the pressure in the tank reached 6,500 psi, there was a sudden roar and the tank shuddered violently.</p><p>“I felt it in my body,” an OceanGate employee wrote in an email later that night. “The building rocked, and my ears rang for a long time.”</p><p>“Scared the shit out of everyone,” he added.</p><p>The model had imploded thousands of meters short of the safety margin OceanGate had designed for.</p><p>In the high-stakes, high-cost world of crewed <a href="https://www.wired.com/tag/submarines/">submersibles</a>, most engineering teams would have gone back to the drawing board, or at least ordered more models to test. Rush’s company didn’t do either of those things. Instead, within months, OceanGate began building a full-scale <em>Cyclops 2</em> based on the imploded model. This submersible design, later renamed <em>Titan</em>, eventually made it down to the <em>Titanic</em> in 2021. It even returned to the site for expeditions the next two years. But nearly one year ago, on June 18, 2023, <em>Titan</em> dove to the infamous wreck and imploded, instantly <a href="https://www.wired.com/story/titan-sub-debris-found/">killing all five people onboard</a>, including Rush himself.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>The disaster captivated and horrified the world. Deep-sea experts criticized OceanGate’s choices, from <em>Titan</em>’s carbon-fiber construction to Rush’s public disdain for industry regulations, which he believed stifled innovation. Organizations that had worked with OceanGate, including the University of Washington as well as the Boeing Company, released statements denying that they contributed to <em>Titan</em>.</p><p>A trove of tens of thousands of internal OceanGate emails, documents, and photographs provided exclusively to WIRED by anonymous sources sheds new light on <em>Titan</em>’s development, from its initial design and manufacture through its first deep-sea operations. The documents, validated by interviews with two third-party suppliers and several former OceanGate employees with intimate knowledge of <em>Titan</em>, reveal never-before-reported details about the design and testing of the submersible. They show that Boeing and the University of Washington were both involved in the early stages of OceanGate’s carbon-fiber sub project, although their work did not make it into the final <em>Titan</em> design. The trove also reveals a company culture in which employees who questioned their bosses’ high-speed approach and decisions were dismissed as overly cautious or even fired. (The former employees who spoke to WIRED have asked not to be named for fear of being sued by the families of those who died aboard the vessel.) Most of all, the documents show how Rush, blinkered by his own ambition to be the Elon Musk of the deep seas, repeatedly overstated OceanGate’s progress and, on at least one occasion, outright lied about significant problems with <em>Titan</em>’s hull, which has not been previously reported.</p><p>A representative for OceanGate, which ceased all operations last summer, declined to comment on WIRED’s findings.</p><figure><p><span><p>OceanGate CEO Stockton Rush aboard the <em>Cyclops 1</em> in 2015.</p>
</span><span>Photograph: Courtesy of Mark Harris</span></p></figure><p><span>I met Stockton</span> Rush on June 24, 2015, while reporting on OceanGate for New Scientist magazine. A former flight engineer and tech investor, Rush was already styling himself a subaquatic Musk. “I wanted to be the first person on Mars until I realized there was nothing there,” Rush told me at a city center dock in Seattle. “But in the ocean, there are new life-forms, things people have never discovered.” Rush believed that Earth’s oceans, not outer space, were where humanity would find refuge from existential risks like climate change. “My goal is to move the needle,” he told me.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Around us, employees were prepping OceanGate’s prototype submersible, the <em>Cyclops 1</em>, for its deepest dive to date. The sub was a cylindrical, steel-hulled design rated for dives up to 500 meters. OceanGate had acquired it a few years earlier and refurbished it, adding LEDs and a PlayStation controller for easy steering, and replacing an ugly exterior cabin with a sleek white plastic fairing to protect components outside the hull. Together with the large acrylic viewport, the effect was a sort of one-eyed robot shark. Up to five people could squeeze inside—which is what Rush and I were about to do, for a test dive in Seattle’s Elliott Bay.</p><p>Ninety minutes later and 130 meters deeper, we were totally lost. First the thruster software had glitched, leaving us floating just above the seafloor. Now the sub’s compass was acting up. The shipwreck we aimed to explore, a rail ferry that had once carried Teddy Roosevelt, was nowhere to be seen. All I could spy outside the <em>Cyclops</em>’ forward dome was the occasional salmon dancing in the frigid water.</p><p>As I began to feel the chill seeping through the sub’s steel hull, Rush asked me to open my iPhone’s compass app. He wanted to compare it to the one on his phone. The headings did not match, but he rebooted the thrusters and we set off in what he was pretty sure was the right direction.</p><p>“You’re heading in exactly the wrong direction,” said a faint voice transmitted via an acoustic link from the support ship tracking us on the surface. We eventually located the sunken ship, its rotting bow emerging into the <em>Cyclops</em>’ headlight. It was an otherworldly experience, made more thrilling by the hint of danger.</p><p>Back at the dock, Rush brushed off the problems we had encountered. This is exactly why OceanGate started with the <em>Cyclops 1</em>, he said, rather than anything capable of diving deeper. “I could have built a multimillion-dollar version and all of a sudden I’ve got to figure out really stupid stuff like the magnetic compass,” he told me. “The <em>Cyclops 1</em> is getting us ready. When we do the <em>Cyclops 2</em>, then all these bugs will be out.”</p><p>The <em>Cyclops 2</em>, which Rush renamed <em>Titan</em> in 2018, was already on the drawing board. And Rush believed he had the biggest bug—how to make a vessel that could safely dive 20 times deeper than America’s nuclear subs—worked out. He would use a modern wonder material: carbon fiber.</p><p>Carbon-fiber composites are some of the strongest materials available to engineers. They are formed of thin strands of atomic carbon within plastic resins, layer upon layer, then cured carefully at high temperatures. The resulting composites can be both stronger and lighter than titanium, and it was this combination that caught Rush’s attention. A carbon-fiber <em>Titan</em> could be roughly the same size and weight as the steel <em>Cyclops</em> and yet be able to dive up to 12 times deeper. It would be much cheaper for a support vessel to carry and deploy at sea than a metal sub, and would also be more buoyant, reducing the risk of getting stranded on the ocean floor. While carbon fiber has been used in everything from cars to rockets, no one had ever dived in a deep-water carbon-fiber submersible. Rush wanted to be the first.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In 2013, OceanGate struck up a partnership with the University of Washington’s Applied Physics Laboratory to develop the new sub. The university has a long history of working with composites and designing its own underwater vehicles. It also already had a relationship with OceanGate, after using its subs for research; the physics lab helped write the software used by <em>Cyclops 1</em>. The university touted the arrangement in press releases at the time: “UW, Local Company Building Innovative Deep-Sea Manned Submarine,” read one headline from October 2013. The story was updated with a note in 2023 saying that “the vessel that resulted from this partnership” was the <em>Cyclops 1</em>. Emails from OceanGate leaked exclusively to WIRED indicate that UW researchers provided hundreds of detailed 3D CAD drawings of components for a carbon-fiber sub between 2013 and 2016, as part of a $5 million contract. But the relationship between the lab and OceanGate was contentious, according to emails.</p><p>UW claims that OceanGate and the lab parted ways after just $650,000 worth of work, and former OceanGate employees told WIRED that none of UW’s hardware or software work wound up in the finished sub.</p><p>OceanGate also announced that Boeing Research &amp; Technology was helping with the project. In October 2013, two engineers at Boeing, Mark Negley and William Koch, produced a detailed 70-page preliminary design containing renderings, manufacturing advice, and technical analysis. These details of Boeing’s involvement have not been reported before. “Boeing was not a partner on the <em>Titan</em> and did not design or build it,” Jessica Kowal, a spokesperson for Boeing, said in a statement. The company declined to answer on the record any other questions from WIRED. Negley and Koch, who are still employed by Boeing, did not respond to LinkedIn messages.</p><p>Even at this early stage, these engineers were warning of potential problems ahead.</p><p>Negley and Koch pointed out that although composites can be stronger than any metal, they have other challenges. Carbon fiber can get progressively weaker, sometimes in unexpected ways. The manufacturing process can introduce defects if the resin is cured too long or not long enough, if debris gets in, or if the material is laid or wound unevenly. And the more layers a structure has, the engineers wrote, the greater the risk of a defect that would weaken it. <em>Titan</em> would ultimately have 660 layers of carbon fiber. To mitigate these risks, the Boeing engineers suggested a rigorous quality assurance process during manufacture and ultrasound testing of the hull after it was made. Ultrasound scans could find defects or delaminations in the hull—places where the carbon-fiber layers had separated.</p><p>To manufacture the hull, Rush turned to a company called Spencer Composites. First, though, OceanGate needed a scaled-down model of the hull to test how it would fare against the intense pressures at the bottom of the sea. By 2015, according to a design document written by Spencer, OceanGate wanted its hull to be rated up to 6,000 meters and have a safety factor of up to 2.25—meaning that it should be stable to two and a quarter times that depth, or 13,500 meters. James Cameron’s record-setting <em>Deepsea Challenger</em> had a safety factor of 1.36. <em>Alvin</em>, the submersible that originally explored the <em>Titanic</em>, had a 1.8 or higher. (Spencer Composites did not respond to requests for comment.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>In June 2015, just before my trip in <em>Cyclops 1</em>, engineers placed a one-third scale model of <em>Titan</em> in an 8-foot-long testing tank at APL-UW for its first pressure test. This model was built entirely of carbon fiber, including the end domes, which ended up failing at pressures equating to around just 3,000 meters, according to a report written by Rush. OceanGate commissioned Spencer to make more domes, but these would take months to arrive. Meanwhile, the cylinder was tested again, this time with solid aluminum discs on the ends, and reached 4,100 meters without incident. But when OceanGate received the new carbon-fiber domes and tested the hull in March 2016, the new domes again imploded at 3,000 meters.</p><p>The test that “scared the shit out of everyone,” in one engineer’s words, was OceanGate’s fourth. This time, the hull (again with aluminum caps) reached the equivalent of 4,500 meters before imploding, giving it a miserly 1.18 safety factor for any dives to <em>Titanic</em> depths.</p><figure><p><span><p>Damage to the scale model after imploding in the testing tank.</p>
</span><span>Photograph: Courtesy of a former OceanGate employee</span></p></figure><p>“Over the next months we will analyze the data in detail … and then run a test with a new cylinder through at least 1,000 cycles to confirm its durability,” Rush wrote to shareholders at the time. That replacement scale model was not made, and the new tests never happened, former employees tell WIRED, in part because Rush trusted OceanGate’s computer models. Even when OceanGate decided to change the domes in the final design from carbon fiber to titanium, Rush didn’t commission models to test the interactions between the new materials; one former employee who was familiar with Rush’s decision says the CEO balked at the high price tag.</p><p>“The modeling says it’s OK. The analysis says it’s OK,” one former employee says. “We build airplanes on the same type of analysis and then we go throw people in them.”</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But a low-pressure environment, like flying, is different from a high-pressure one. Carbon fiber is inherently stronger when holding pressure in, like what happens with an aircraft in the stratosphere, than when keeping pressure out, as happens underwater. And all cylindrical vessels resist buckling better when the air pressure is higher inside.</p><p>Submersible experts not associated with OceanGate told WIRED that they would do much more testing on a new design. “We did at least 10 scale-model pressure hulls that we tested to destruction,” says Adam Wright, an engineer who had worked on explorer Steve Fossett’s 2005 carbon-fiber sub, which was shelved after Fossett died in a plane crash. And that was for a submersible that would only be used for a single mission. OceanGate was planning to use its submersible repeatedly—up to 10,000 times, according to internal design documents.</p><p>“Carbon fiber is a very sensible material if it’s been engineered correctly and manufactured in a controlled way,” says Chase Hogoboom, president and cofounder of Composite Energy Technologies, which has successfully tested small carbon-fiber vessels to the equivalent of 6,000 meters hundreds of times. “It takes millions of dollars and many years, but it’s not rocket science. It’s just connecting the dots.”</p><p>OceanGate tested the model hull to destruction only once, and never used the titanium components that would become fixtures on the final sub. Instead, the company simply increased the thickness of the carbon-fiber hull in its design specs from 4.5 to 5 inches, and commissioned Spencer to build the real thing. (Later, OceanGate engineers found that <em>Titan</em>’s full-size hull was too thick for portable ultrasonic scanners, and a coating Spencer had applied to it would further block the signals. Rush decided that moving the entire sub to a lab for scanning would be too expensive, says a former employee who was familiar with Rush’s thinking. As a result, no scans were made—going against the advice of both Boeing and OceanGate engineers.)</p><figure><p><span><p>Key components of the <em>Titan</em> submersible</p>
</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Unlike <em>Cyclops 1</em>, with its large, 180-degree viewing dome, <em>Titan</em>’s front dome was made of solid titanium, with a smaller 23-inch viewport in the center. The viewport, made from 9-inch-thick acrylic, was an entirely new design by Tony Nissen, OceanGate’s director of engineering, and it was going to be manufactured by a company called Hydrospace Group.</p><p>Will Kohnen, Hydrospace’s CEO, told WIRED that he had originally expected Rush to thoroughly test the viewport according to rigorous standards set by the American Society of Mechanical Engineers. Under those standards, OceanGate would test at least five windows to destruction at high pressure, cycle a viewport from low to high pressure a thousand times, and subject another viewport to five times the intended pressure for 300 consecutive hours to see how much the plastic slowly shrank under pressure, says Kohnen.</p><p>“The more innovative you get, the more testing you’ve got to do,” Kohnen says. “Over a period of years, it was pretty obvious that OceanGate wasn’t going to do the testing.” The former employees who spoke to WIRED also said that OceanGate wasn’t testing the viewport to the society’s standards.</p><p>By the fall of 2017, Kohnen was getting worried. As a last-ditch effort, in November he sent Rush an email offering “a serious discount” to build a second viewport using a design that had been tested and certified to 4,000 meters. It could be swapped out for the experimental window within 24 hours, he wrote. Kohnen says that Rush told him he wasn’t interested.</p><p>Kohnen delivered OceanGate’s viewport in December. He would rate it to only 650 meters—one-sixth of the depth to the <em>Titanic</em>. He also shared an analysis, done pro bono by an independent expert, concluding that OceanGate’s design might fail after only a few 4,000-meter dives. OceanGate nevertheless installed the viewport in <em>Titan</em> later that month. Construction on the sub was almost complete, and the company was already advertising its first expedition to the <em>Titanic</em> in May.</p><p><span>It was time</span> for the engineers to hand it over to OceanGate’s operations team for testing at sea. But there was another snag. David Lochridge, who oversaw marine operations at the company and who needed to sign off on the transfer, became convinced that <em>Titan</em> was unsafe. In January 2018, Lochridge sent Rush a quality-control inspection report detailing 27 issues with the vehicle, from questionable O-ring seals on the domes and missing bolts to flammable materials and more concerns about its carbon-fiber hull. Rush fired him the next day. (Although Lochridge later made a whistleblower report to the Occupational Safety and Health Administration about <em>Titan</em>, Rush sued him for breach of contract. The settlement of that lawsuit resulted in Lochridge dropping his complaint, paying OceanGate nearly $10,000, and signing an NDA. Lochridge did not respond to WIRED.)</p><p>Will Kohnen also couldn’t forget about <em>Titan</em>, and the foreboding he had about the whole enterprise. “We have a rogue element within the submersible industry,” he remembers thinking. If something went wrong with <em>Titan</em>, it might scare people off deep-sea exploration more widely. In March 2018, he drafted a letter, signed by more than 30 crewed submersible experts, urging Rush to test the vessel with an accredited outside group. (The letter was earlier <a href="https://www.nytimes.com/2023/06/20/us/oceangate-titanic-missing-submersible.html">reported</a> by the New York Times.)</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Virtually all marine vessels are certified by organizations such as the American Bureau of Shipping, DNV, or Lloyd’s Register, which ensure that they are built using approved materials and methods and carry appropriate safety gear. It has been widely reported that Rush was dismissive of such certification, but what has not been made public until now is that OceanGate pursued certification with DNV (then known as DNV GL) in 2017—until Rush saw the price. “[DNV] informed me that this was not an easy few thousand dollar project as [it] had presented, but would cost around $50,000,” he later wrote in an email to Rob McCallum, a deep-sea explorer who had also signed Kohnen’s letter.</p><p>“<em>Titan</em> and its safety systems are way beyond anything currently in use … I have grown tired of industry players who try to use a safety argument to stop innovation and new entrants from entering their small existing market,” Rush wrote to McCallum. “Since [starting] OceanGate we have heard the baseless cries of ‘you are going to kill someone’ way too often.”</p><p>Days later, Rush received an even more pointed warning from Boeing’s Mark Negley, who had stayed in contact with the CEO after he helped with a preliminary design. Negley had recently carried out an analysis of Spencer Composites’ hull based on information Rush had shared. He did not mince words when sharing his findings, which WIRED is reporting for the first time. “We think you are at a high risk of a significant failure at or before you reach 4,000 meters. We do not think you have any safety margin,” he wrote in an email on March 30. “Be cautious and careful.”</p><p>Negley provided a graph charting the strain on the submersible against depth. It shows a skull and crossbones in the region below 4,000 meters.</p><figure><p><span><p>The chart Mark Negley shared with Stockton Rush</p>
</span><span>Chart: Courtesy of a former OceanGate employee</span></p></figure></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>Despite repeated warnings, Rush seemed unfazed. His confidence in <em>Titan</em> was based in part on the new safety systems OceanGate had designed. “A lot of risk mitigation was supposed to ride on the real-time health monitoring,” says one former employee. The heart of that system, designed by an experienced electrical engineer and OceanGate board member named Mike Furlotti, was a suite of sensors and microchips that analyzed the hull’s acoustic emissions—the little pops made by carbon fibers as they break under compression. OceanGate’s theory was that the hull would be fairly noisy on its first few dives but would get quieter when taken to the same depths over and over, one former employee explains. If the acoustic monitoring system started getting really loud on a dive, that would be a clear indication to surface immediately. (Multiple attempts to contact Furlotti for comment were unsuccessful.)</p><p>Wright and other industry experts have been extremely critical of this setup. “I’m sure you can pick up these acoustic events fine, but you just don’t know when the end point is,” he says. “You don’t know how many pops is too many, and it could be different for every vessel.”</p><p>There was even skepticism within OceanGate itself. In September 2017, the engineer responsible for integrating Furlotti’s design into <em>Titan</em> sent an anxious email to management expressing concerns about the system’s ability to accurately track fiber breakage over time.</p><p>OceanGate hired an outside consultant named Allen Green to assess the acoustic monitoring. Green, an authority on the sounds that materials make under stress, endorsed the system in 2018. Later, though, when Green saw how Rush was describing the system to the public—the CEO claimed it could detect the sound of “micro-buckling” in the sub’s hull “way before it fails”—he wrote a concerned email to an OceanGate employee, reported here for the first time.</p><p>Rather than warning of failure, Green explained that the sounds indicated “irreversible” damage. “It is my belief, substantiated by many years of experience, that composite structures all have a finite lifetime,” wrote Green, who died in 2021. “While I do not intend to be an alarmist, I did not sleep well and arose early to send this message.”</p><p><span>Rush had pitched</span> OceanGate’s board and investors on a grand vision of what his company could be. By 2018, that included a fleet of self-driving <em>Titan</em>s that could dive to 6,000 meters, and satellite offices in Croatia, Israel, and the South Pacific. He imagined a world whose oceans were populated by OceanGate’s crewed underwater bases, which could be used for data storage or even “Plan B habitats” for billionaire preppers.</p><p>Reality was more prosaic. Like most startups, OceanGate was in constant need of funds. Rush was trying to save money wherever he could. Interns, who made up around a third of the engineering team, were paid as little as $13 an hour. (When a manager pointed out in 2016 that Washington’s minimum wage was just $9.47 an hour, Rush responded, “I agree we are high. $10 seems fair.”) Rush also downgraded the sub’s titanium components from aerospace grade 5 quality to weaker and cheaper grade 3, says one former employee.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>According to internal documents, by 2018 the company had raised around $9 million in venture capital and another $4 million from subsidiary companies that profited off OceanGate’s research and scientific missions. But the real business opportunity would be trips to the <em>Titanic</em>.</p><p>Rush had planned six missions to visit the legendary shipwreck in the summer of 2018, each with nine people paying $105,000. With every mission bringing in nearly a million dollars in revenue but costing OceanGate only an estimated $333,000, the more visits <em>Titan</em> could make to the bottom of the North Atlantic, the better. Although the plan was for the finished sub to make more than 30 dives in shallow water before going to deeper waters, OceanGate managed just 18.</p><p>In mid-April, <em>Titan</em> was transported to Marsh Harbour in the Bahamas, where deep water could be found very close to land. But before <em>Titan</em> was even moved into the water, it was hit by lightning, damaging its electronics. Some of the damaged equipment was replaced, but the sub was without many components for weeks. Rush nevertheless insisted on attempting a shallow dive during high, rolling seas.</p><p>Choppy waves ripped fairings and foam from <em>Titan</em> as it was being towed back from the dive site, causing it to sink. “I was merely ‘spam in the can’ with no comms for 9+ hours inside the sub,” Rush wrote the next day. “I could see parts of the sub floating away on my cameras, but could not communicate to the tow team—a remarkably surreal and frustrating experience.”</p><p>Rush had to face facts: There was now no chance of OceanGate reaching the <em>Titanic</em> in 2018. Eager ticket holders (and investors) would have to wait another year.</p><p>While they were still in the Bahamas, the team did manage to lower <em>Titan</em> on a series of uncrewed dives, eventually reaching 4,000 meters. But engineers found the hull was warping more under compression than it was meant to, by perhaps as much as 37 percent. Nevertheless, Rush wanted to keep diving deeper with <em>Titan</em>, with himself at the helm. When one engineer expressed concern about performing crewed tests at this point, Nissen wrote to him, “Yesterday I told you if you don’t have the stomach for this type of engineering then OceanGate isn’t for you.”</p><p>On December 10, Rush successfully dove <em>Titan</em> to a depth of 3,939 meters—just enough to get to the <em>Titanic</em>. Nissen wrote to the engineering team: “Diving to such deep depths is extremely complicated if you want to be untethered, communicate with the surface, be location tracked with reasonable accuracy, and monitor the health of your vehicle. And, we have delivered. You all have a lot to brag about.”</p><p><em>Titan</em> reached a similar depth again in April, with a crew of four including Rush. While OceanGate touted the dive as history-making proof of its submersible’s bona fides, even Rush was getting worried about loud noises the hull was making at depth. Then on June 7, three weeks before <em>Titan</em>’s maiden voyage to the <em>Titanic</em>, an OceanGate pilot inspecting the interior with a flashlight noticed a crack in the hull. He sent Rush an email warning that the crack was “pretty serious.” A detailed internal report later showed that at least 11 square feet of carbon fiber had delaminated—meaning the bonds between layers had separated.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>This time, Rush couldn’t ignore the data. The hull that was meant to last for 10,000 dives to the <em>Titanic</em> had made fewer than 50—and only three to 4,000 meters. It would have to be scrapped, and the <em>Titanic</em> missions would be delayed for yet another year. When Rush shared the news with <a data-offer-url="https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/&quot;}" href="https://www.geekwire.com/2019/oceangate-puts-off-plans-dive-titanic-shipwreck-due-topside-tangle/" rel="nofollow noopener" target="_blank">GeekWire</a> a few days later, however, he blamed the delay on legal complications with <em>Titan</em>’s support vessel.</p><p>It’s true that OceanGate ran into issues with maritime law, says one former employee: “The lie is that it was not the reason we delayed.”</p><p><span>After the crack</span> was found in <em>Titan</em>’s hull, OceanGate started searching for a new carbon-fiber contractor. By early 2020, many OceanGate engineers had been laid off or had left the company, insiders say. Tony Nissen was out, and a team that had once numbered more than 20 was reduced to just a handful. “Stockton never really wanted an engineering team, but he needed somebody to build it,” says one insider. “We were down to a skeleton team,” says another.</p><p>Rush then announced that the company had inked a partnership with NASA to “collaborate on the development, manufacturing, and testing” of a new carbon-fiber cylinder. (Covid-19 had other plans, shutting down NASA for months. Ultimately, the agency told ABC, “NASA did not conduct testing and manufacturing via its workforce or facilities.”)</p><p>The new hull would instead be made by two aerospace firms in Washington state, Electroimpact and Janicki Industries. Electroimpact laid the carbon fibers, and Janicki cured the material in its ovens, confirmed one former employee. Electroimpact did not provide a response to questions about its role, and Janicki declined to comment.</p><p>This time, OceanGate had two scale models made, which were once again tested at the University of Washington. Once again, the models imploded early, possibly due to warping of the hulls during manufacturing, says a former employee.</p><p>OceanGate scrambled to solve the issue. One idea: Rather than cure all the layers at once, they would cure the hull in stages. Electroimpact would wind about 100 layers of the hull, then ship it to Janicki to cure and settle. Then Janicki would send the hull back to Electroimpact to repeat the process. They were running out of time, so they went for it—skipping tests of the new procedure on samples and going straight to manufacturing the second hull. “The first time we did multiple cures was when we did the full hull,” says one former employee. The new hull was finished by January 2021. It passed pressure testing, similar to what was done at the University of Washington, but at a facility in Maryland that could accommodate the full-size cylinder.</p><p>OceanGate’s engineers now needed to integrate the new hull with the rest of <em>Titan</em>. But <em>Titan</em>’s two titanium domes were still attached to each end of the old hull, sitting on titanium rings glued to the carbon fiber with aerospace-grade epoxy adhesive. Commissioning new titanium interface rings and domes was ruled “an absolute no” by Rush, one former employee says, because of the extra cost and delay. The company that made the original titanium components told WIRED that it did not make new rings for Rush, and three former employees say that OceanGate did, in fact, salvage and reuse the originals.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>But staff had difficulty working out how to separate the old hull from the interface rings without damaging even a sliver of titanium. Gaps or bumps could have weakened the join with the new hull, say the sources. On dives, the hull and the rings needed to compress under pressure in perfect harmony. “I can’t imagine a situation where you could reuse the titanium rings,” Wright, the independent engineer, says. OceanGate somehow managed it.</p><p>By February 2021, photos of the newly reconstructed <em>Titan</em> were popping up on OceanGate’s Facebook page and other social media. After the implosion in 2023, one ex-employee looked back at these and noticed an unexpected addition: The company had added metal lifting points to both interface rings, apparently to provide a new way to hoist <em>Titan</em> into and out of the water. The addition of the lifting rings, reported by WIRED for the first time, was confirmed by a former employee who saw the engineering drawings, and by another source.</p><p>Previously, OceanGate had lifted <em>Titan</em> using a sling beneath the sub to avoid putting stress on the critical joins between the rings and the carbon-fiber hull. As far back as 2017, when the original <em>Titan</em> was first shipped to OceanGate, Nissen had warned the operations team to use only the sling: “The titanium cannot take load/tension.”</p><p>“Lifting points are a very serious part of a pressure vessel design and must be considered carefully, tested, and qualified,” says Will Kohnen. “Any lifting arrangement may impose loads and stresses into the pressure vessel, and this must be mitigated by analysis and test.” It is unclear whether such analysis or tests were carried out.</p><figure><p><span><p>OceanGate originally used a sling system to lower its sub into the water, shown here.</p>
</span><span>Photograph: Courtesy of a former OceanGate employee</span></p></figure><p>The diving season was about to begin, and after three years of expensive delays, OceanGate desperately needed income from the <em>Titanic</em> missions (whose tickets now cost $125,000 per person). “We were running out of time,” says a former OceanGate employee. <em>Titan</em> had only a few relatively shallow dives in Puget Sound before the company put it on a truck and sent it all the way across Canada to Newfoundland, the port closest to the <em>Titanic</em> wreck.</p></div><div data-journey-hook="client-content" data-testid="BodyWrapper"><p>On July 13, 2021, OceanGate’s <em>Titan</em> made its first successful dive to the <em>Titanic</em>, with Rush serving as the pilot. “We had to overcome tremendous engineering, operational, business, and finally Covid-19 challenges to get here, and I am so proud of this team and grateful for the support of our many partners,” Rush said in a <a data-offer-url="https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm" data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm&quot;}" href="https://www.prweb.com/releases/oceangate_inc_s_carbon_fiber_and_titanium_5_crewmember_submersible_dives_3800_meters_to_the_titanic_wreck_site/prweb18066066.htm" rel="nofollow noopener" target="_blank">press release</a>.</p><p>After the 2021 expedition, OceanGate was flush with success. The company announced plans for the following year’s expedition to document the wreck “in more detail than ever before” and urging “aspiring mission specialists” to get in touch.</p><p>The successes and warm media coverage continued in 2022. OceanGate was profiled by <em>CBS Sunday Morning</em>, which accompanied one of the missions that summer. When reporter David Pogue noticed how improvised the setup on the sub was, Rush reassured him. “The pressure vessel is not MacGyver at all, because that’s where we worked with Boeing and NASA and the University of Washington. Everything else can fail, your thrusters can go, your lights can go. You’re still going to be safe.” The rest of Pogue’s mission was sort of a farce—the sub got lost, things broke—but he came back safely.</p><p>That’s not what happened the following year. In June 2023, five eager people got ready to dive back down to the <em>Titanic</em>. They were Rush; Paul-Henri Nargeolet, a deep-sea explorer; and three paying passengers: a businessman named Hamish Harding and a father-son duo, Shahzada and Suleman Dawood. On June 18, they sealed <em>Titan</em> and dove. Within two hours, the support ship had lost contact with them.</p><p>Their disappearance set off a media frenzy. People speculated how long the crew might be able survive without power or aid. A massive search-and-rescue operation spent four days combing the sea before finding debris from the sub. The US Navy later confirmed it had detected loud sounds “consistent with an implosion” shortly after contact with <em>Titan</em> ended. OceanGate ceased its commercial and exploration activities a few weeks later.</p><p>The US Coast Guard is currently leading an international investigation into the deaths.</p><p>Several former employees said they were neither shocked nor surprised at OceanGate’s deadly accident. Three had left the company on safety grounds, and two separately described <em>Titan</em> as a ticking time bomb.</p><p>One former employee remembers preparing <em>Titan</em> for multiple successful <em>Titanic</em> missions, prior to 2023. “I put my heart and soul into building that sub,” he says. “Many, many hours inside the sub, outside the sub, building and testing it. She was my baby.”</p><p>Each time <em>Titan</em> was about to dip beneath the waves, he would pat her hull lightly. “I’d say, ‘Come on back to me baby, you’ll make it, you can do it.’ And when she’d come back up to the surface, I’d say, ‘Good job. You got everyone back up safe.’”</p><p>Until one day, she didn’t.</p><p>Now the bottom of the North Atlantic is littered with more evidence of human hubris, tiny pieces of a plastic video-game controller nestling among the barnacle-encrusted gold fixtures of the <em>Titanic</em>. Both vessels were at the cutting edge of technology, both exemplars of safety in the eyes of their overconfident creators. And in both cases, their passengers paid the price.</p></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Battery-swap networks are preventing emergency blackouts (124 pts)]]></title>
            <link>https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/</link>
            <guid>40644745</guid>
            <pubDate>Tue, 11 Jun 2024 10:54:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/">https://www.technologyreview.com/2024/06/11/1093465/battery-swap-gogoro-taiwan-earthquake/</a>, See on <a href="https://news.ycombinator.com/item?id=40644745">Hacker News</a></p>
<div id="readability-page-1" class="page"><div> <p>On the morning of April 3, Taiwan was hit by a 7.4 magnitude earthquake. Seconds later, hundreds of battery-swap stations in Taiwan sensed something else: the power frequency of the electric grid took a sudden drop, a signal that some power plants had been disconnected in the disaster. The grid was now struggling to meet energy demand.&nbsp;</p>  <p>These stations, built by the Taiwanese company Gogoro for electric-powered two-wheeled vehicles like scooters, mopeds, and bikes, reacted immediately. According to numbers provided by the company, 590 Gogoro battery-swap locations (some of which have more than one swap station) stopped drawing electricity from the grid, lowering local demand by a total six megawatts—enough to power thousands of homes. It took 12 minutes for the grid to recover, and the battery-swap stations then resumed normal operation.</p> </div><div> <p>Gogoro is not the only company working on battery-swapping for electric scooters (New York City <a href="https://www.technologyreview.com/2024/03/20/1089960/battery-swap-ebike-fires/">recently launched a pilot program</a> to give delivery drivers the option to charge this way), but it’s certainly one of the most successful. Founded in 2011, the firm has a network of over 12,500 stations across Taiwan and boasts over 600,000 monthly subscribers who pay to swap batteries in and out when required. Each station is roughly the size of two vending machines and can hold around 30 scooter batteries.</p>  <p>Now the company is putting the battery network to another use: Gogoro has been working with Enel X, an Italian company, to incorporate the stations into <a href="https://www.technologyreview.com/2024/02/07/1087836/how-virtual-power-plants-are-shaping-tomorrows-energy-system/">a virtual power plant (VPP) system that helps the Taiwanese grid stay more resilient in emergencies</a> like April’s earthquake.&nbsp;</p> 
 <p>Battery-swap stations work well for VPP programs because they offer so much more flexibility than charging at home, where an electric-bike owner usually has just one or two batteries and thus must charge immediately after one runs out. With dozens of batteries in a single station as a demand buffer, Gogoro can choose when it charges them—for instance, doing so at night when there’s less power demand and it’s cheaper. In the meantime, the batteries can give power back to the grid when it is stressed—hence the comparison to power plants.</p>  <p>“What is beautiful is that the stations’ economic interest is aligned with the grid—the [battery-swap companies] have the incentive to time their charges during the low utilization period, paying the low electricity price, while feeding electricity back to the grid during peak period, enjoying a higher price,” says S. Alex Yang, a professor of management science at London Business School.&nbsp;</p> 
 <p>Gogoro is uniquely positioned to become a vital part of the VPP network because “there’s a constant load in energy, and then at the same time, we’re on standby that we can either stop taking or giving back [power] to the grid to provide stability,” Horace Luke, cofounder and CEO of Gogoro, tells <em>MIT Technology Review</em>.&nbsp;</p>  <p>Luke estimates that only 10% of Gogoro batteries are actually on the road powering scooters at any given time, so the rest, sitting on the racks waiting for customers to pick up, become a valuable resource that can be utilized by the grid.&nbsp;</p>  <p>Today, out of the 2,500 Gogoro locations, over 1,000 are part of the VPP program. Gogoro promises that the system will automatically detect emergencies and, in response, immediately lower its consumption by a certain total amount.</p>  <p>Which stations get included in the VPP depends on where they are and how much capacity they have. A smaller station right outside a metro stop—meaning high demand and low supply—probably can’t afford to stop charging during an emergency because riders could come looking for a battery soon. But a megastation with 120 batteries in a residential area is probably safe to stop charging batteries for a while.</p> </div><div><p>Plus, the entire station doesn’t go dark—Gogoro has a built-in system that decides which or how many batteries in a station stop charging. “We know exactly which batteries to spin down, which station to spin down, how much to spin down,” says Luke. “That was all calculated in real time in the back side of the server.” It can even consolidate the power left in several batteries into one, so a customer who comes in can still leave with a fully charged battery even if the whole system is operating below capacity.</p>  <p>The earthquake and its aftermath in Taiwan this year put the VPP stations to the test—but also showed the system’s strength. On April 15, 12 days after the initial earthquake, the grid in Taiwan was still recovering from the damage when another power drop happened. This time, 818 Gogoro locations reacted in five seconds, reducing power consumption by 11 megawatts for 30 minutes.</p>  <p>Numbers like 6 MW and 11 MW are “not a trivial amount of power but still substantially smaller than a centralized power plant,” says Joshua Pearce, an engineering professor at Western University in Ontario, Canada. For comparison, Taiwan lost 3,200 MW of power supply right after the April earthquake, and the gap was mostly filled by solar power, centralized battery storage, and hydropower. But the entire Taiwanese VPP network combined, <a href="https://money.udn.com/money/story/11799/7963052">which has reached a capacity of 1,350 MW</a>, can make a significant difference. “It helps the grid maintain stability during disasters. The more smart loads there are on the grid, the more resilient it is,” he says.&nbsp;</p>  <p>However, the potential of these battery-swap stations has not been fully achieved yet; the majority of the stations have not started giving energy back to the grid.&nbsp;</p> 

 <p>“The tech system is ready, but the business and economics are not ready,” Luke says. There are 10 Gogoro battery-swapping stations that can return electricity to the grid in a pilot program, but other stations haven’t received the technological update.&nbsp;</p>  <p>Upgrading stations to bi-directional charging makes economic sense only if Gogoro can profit from selling the electricity back. While the Taiwanese state-owned utility company currently allows private energy generators like solar farms to sell electricity to the grid at a premium, it hasn’t allowed battery-storage companies like Gogoro to do so.&nbsp;</p>  <p>This challenge is not unique to Taiwan. Incorporating technologies like VPP requires making fundamental changes to the grid, which won’t happen without policy support. “The technology is there, but the practices are being held back by antiquated utility business models where they provide all electric services,” says Pearce. “Fair policies are needed to allow solar energy and battery owners to participate in the electric market for the best interest of all electricity consumers.” </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Jgs Font (126 pts)]]></title>
            <link>https://adelfaure.net/tools/jgs/</link>
            <guid>40643588</guid>
            <pubDate>Tue, 11 Jun 2024 07:36:12 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adelfaure.net/tools/jgs/">https://adelfaure.net/tools/jgs/</a>, See on <a href="https://news.ycombinator.com/item?id=40643588">Hacker News</a></p>
<div id="readability-page-1" class="page">
    <main>
<pre>Font                          Size                       Mode
<a id="jgs5">[<span> </span>] jgs5</a> <a id="jgs7">[<span> </span>] jgs7</a> <a id="jgs9">[<span> </span>] jgs9</a>    <a id="x1">[<span> </span>] * 1</a> <a id="x2">[<span> </span>] * 2</a> <a id="x3">[<span> </span>] * 3</a>    <a id="day">[<span> </span>] Day</a> <a id="night">[<span> </span>] Night</a>
================================================================================
                   __ _____ _____       _____ _____ _____ _____ 
                  |  |   __|   __|     |   __|     |     |     |
                __|  |  |  |__   |     |   __|  |  |  |  |     |
               |_____|_____|_____|     |__|  |_____|__|__||___| 

================================================================================
X <a href="https://gitlab.com/velvetyne/jgs/-/archive/main/jgs-main.zip">Download Jgs Font</a> (SIL Open Font License)
FR <a href="https://adelfaure.net/tools/jgs/index_fr.html">Version française</a>
================================================================================
     
Jgs Font is a font family made in tribute to Joan G. Stark (aka jgs, Spunk), a
pioneer of ASCII art.

Jgs Font glyphs can be combined from one character to another, from one line to
another. Thus from single characters it is possible to draw continuous lines,
frames and patterns.

In order to change font size while keeping these effects of continuity at
pixel scale, the family is declined in three fonts.

Jgs5 for sizes multiples of 10 : 10px, 20px, 30px etc.
Jgs7 for sizes multiples of 14 : 14px, 28px, 42px etc.
Jgs9 for sizes multiples of 18: 18px, 36px, 54px etc.


Notes
-----

Jgs is still an unfinished project. Some characters are still missing
and the formal correspondences between the sizes remain to be worked.

You will find <a href="https://adelfaure.net/tools/jgs/jgs_table.html">here</a> a table of characters and comparison between fonts.


Continuous characters
---------------------

..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
..................  ::::::::::::::::::  //////////////////  %%%%%%%%%%%%%%%%%%  
                                                                                
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
------------------  ==================  ||||||||||||||||||  ##################  
                                                                                
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
{}{}{}{}{}{}{}{}{}  ((((((((((((((((((  ««««««««««««««««««  ++++++++++++++++++  
                                                                                
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
\/\/\/\/\/\/\/\/\/  !!!!!!!!!!!!!!!!!!  ))))))))))))))))))  ******************  
/\/\/\/\/\/\/\/\/\  !!!!!!!!!!!!!!!!!!  ((((((((((((((((((  ******************  
                                                                                
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
(_)(_)(_)(_)(_)(_)  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
_)(_)(_)(_)(_)(_)(  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  
)(_)(_)(_)(_)(_)(_  ░░░░░░░░░░░░░░░░░░  ▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒  ▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓  


Curves
------

0.25 _._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._._
                                                                        
0.5 -._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.-._.
                                                                                
1 ._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-._.-~-
                                                                        
1.25    _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   _.-~"~-._   
     "~"         "~"         "~"         "~"         "~"         "~"         "~"
                                                                         
2.25           .-~"~-.           .-~"~-.           .-~"~-.           .-~"~-.    
     -._   _.-'       '-._   _.-'       `-._   _.-'       '-._   _.-'       `-._
        `~'               `~'               `~'               `~'               
                                                                
4.25                    .-'~"~`-.                   .-'~"~`-.                   
     `.               .'         `.               .'         '.               .'
       \             /             \             /             \             /  
        `-._     _.-'               `-._     _.-'               `-._     _.-'   
            `~"~'                       `~"~'                       `~"~'


Lines
-----

0/1 1/6 1/4 2/5 1/2 2/3 4/5 1/1 4/3 6/4 5/3 2/1 7/3 5/2 3/1 10/3 7/2 4/1 9/2
|   i   i   i   i   i   i   \   \   \   `.  `.  `.  `.  `-. `-.  `-. `~-.`~-._
|   |   |   |   !   !   !    \   \   `.   `.  `.  `.  `-.  `-. `-.  `~-. `~-. `~
|   |   |   !   `i   \   \    \   \    \    \   `.  `-.  `.   `-. `~-.  `-.  `~-
|   |   !   `i   !    i   \    \   `.   `.   `.   `.   `.  `-.   `-.  `-.  `~-.
|   |   `i   !   `i   !    \    \    \    \    `.   `.   `.   `.    `-.  `-.   `
|   !    |   `i   !    \    i    \    \    `.    \    `.   `-.  `-.    `-.  `~-.
|   `i   |    |   `i    i   !     \    \     \    `.    `.    `.   `.     `-.
|    |   !    !    !    !    \     \    `.    `.    `.    `.    `.   `-.     `-.
|    |   `i   `i   `i    \    \     \     \     \     \     `.    `-.   `.      
|    |    |    !    !     i    \     \     \     `.    `.     `.     `.   `-.   
|    |    |    `i   `i    !     i     \     \      \     `.     `.     `.    `. 
|    !    !     |    !     \    !      \     `.     `.     \      `.     `-.   `
|    `i   `i    !    `i     i    \      \      \      \     `.      `.      `.  
|     |    |    `i    !     !     \      \      \      `.     `.      `.      `.
|     |    |     |    `i     \     \      \      \       \      \       `.      
|     |    !     !     !      i     i      \      `.      `.     `.       `.
|     |    `i    `i    `i     !     !       \       \       \      `.       `.


Alphabet           
--------
 _____ _____ _____ ____  _____ _____ _____ _____ _____   ___ _____ ___   __ __
|  _  |  _  |     |    \|   __|   __|   __|  |  |     | |   |  |  |   | |  V  |
|     |  _ -|   --|  |  |   __|   __|  |  |     ||   | _|   |    -|   |_|     |
|__|__|_____|_____|____/|_____|__|  |_____|__|__|_____|_____|__|__|_____|__V__|
 _____ _____ _____ _____ _____ _____ _____ __ __ _____ _____ _____ _____ _____
|     |     |  _  |     |  _  |   __|     |  |  |  |  | | | |  |  |  |  |__   |
|  |  |  |  |   __|  | _|    _|__   |     |  |  |  |  | | | |-   -|  |  |   __|
|__|__|_____|__|  |_____|__\__|_____||___||_____|\___/|_____|__|__||___||_____|


Patterns           
--------

/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]
/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/||\||/|
=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=][=[]=]

(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
-\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/--\\/-
-/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\--/\\-
(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))(( ))
  
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-+|++|+-|-
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;&lt;|/\|\/|&gt;
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+-
|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;&gt;|()|[]|&lt;
 
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___
   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\
__///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\
\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///   /\\\\\///  
\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___///\\\\\/___

\////\\\\\/\\/\///////\/\/\\\//\////\\/\/\/////\\/\/\\/\\\\/\\\\\\\\/\\//\\\\\/\
///\///\/\\\\//\/\\/\/\\///\/\\/\\\//\//\///\/\///\///\\///\///\/\/\\\\/\\\///\\
\\///\\\\////\/\\\\\\/\///\\\/\\\///\\\\\/////\//\//\///\/\/\\\\\/\//\\/\\\\\\//
\/\/\/\\///\\\/\\\//\\\/\/\///\\\\\\///\\\\/\\\\/\\\/\/\/\\\//\/////\\///\\/\//\
\////\/\///////\\\\///////\//////\\\/\\\/\/\\/\\//\\\/\\\/////\//\//\/\//\/////\
//\\\//\//\\///\//\\///\\\\/\/\\\/\\/\\\\///\///\/\/\//\//\/\\\////\\\/\/\/\\///
\//\\/\//\\//\\/\////\\////\/\//\\///\\////\\/\\//\\//\\//\//\/\\/\/\\////\\//\\
//\/////\//\\\\///\\///\\/\\\\/\\/\/\\///\\\/\\\\//\/\/\//\\/\/\\//\\//\\\/\\\\\
\//////\/\\//\\////\////\/\/\\\/\//\\/\/\\//\/\\\///\\/\\\\\\///\\\\\/\\\\//////
//\//\/\\\/////\\\\//\\\\//\/\\\\\/\/\\/\\//\\//\/\\//\\\\\\\\//\\/\\\/\/\\////\
\\/\\/\\/////\///\\/\///\///\/\\\\//\///\\//\\\\//\//\///\\\\/\/\//\\\/\\///\\\/
///\//\\\/\\\\\\///\/\/\////\\\//\\\\\\/\//\\\////\\/\\////\\/\//\\\/\/////\\\//
\\\///\\//\\//\/\//\/\/\////\/\//\///\\\\\/\//\/\\\\\/\/\/\\////\/\\\//\/\\\/\//
//\\\\\\\\//////\///\\\\\\\////////\\\//\\\/\///\\\\//\/\\////\//\/\/\\/\\///\/\
\/////\\\\\\\/\\\/\\\\\\\//\//////\\/\/\\\////\\\\//\/\\///\///\\///\\\\\\///\/\
\\/\/\\\/\\/\\\/\\\/\///\\/\\//\/\\//\\\\///\//\//\\//\/\\/\//////\\////////\/\\

  :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   .   :   . 
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `
 `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.'
.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`
 `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:' `.' `:'
.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `.':`.' `


Faces
-----
                     
                                  .-'~~~`-.            
                                  |·.....·i            
         _..._                    |·.....·i                   _.---._       
       .~(|||)~.                .~!·.....·!~.               .(((|||))).     
      ((//'~`\\))               `·.._____..·'              (((/(((((\)))    
      (!__   __!)               ))! ~   ~ !((              ))! '   ` !((    
      (~(_)-(_)~)              (((. o   o .)))            (((. o   o .)))   
       |   L   |                )))   w   (((             i)))   &lt;   (((i   
       !  .-.  !               ((( \ `-' / )))           (((( \ )-( / ))))  
       (       )                )))!`---'!(((             ))))!`._.'!((((   
       /`~---~'\                  /`-._.-'\              ((((/       \))))  
  _.-~'  `. .'  `~-._        _.-~'\_/(_)\_/`~-._        _i))))       ((((i_ 
 '         V         `      '  \     / \     /  `      '(((((         )))))`
                                                                            
                                                                _._         
                                   _.---._                     (\!/)        
        .-~~~-.                  .(((|||))).                 .(|||||).      
       (//'~`\\)                (((//'~`\\)))               ((/·'~`·\))     
       ! .   . !                ))! '   ` !((               (! -   - !)     
      (. ·   · .)              (((. .   . .)))              (. o   o .)     
       7  (_)  &lt;                )))\  &lt;  /(((                 \  u  /       
      (    -    )              ((( |\.-./| )))                |\ - /|       
       `._   _.'                )))! \_/ !(((                 ! `-' !       
       /  `~'  \                  /`.___.'\                  /       \      
  _.-~'         `~-._        _.-~'`-.___.-'`~-._        _.-~'         `~-._ 
 '  \             /  `      '                   `      '  \             /  `
          ___                                                               
        .~...~.                                                             
       i·.....·i                   _.---._                                  
     .-!·.....·!-.               .(((|||))).                  .:=:=:.       
     `·.._____..·'              (((//'~`\\)))                i;'~ ~`:i      
     ((! ^   ^ !))              ))! `   ' !((                ! _   _ !      
     ((. o   o .))             (((. -   - .)))              (. .   . .)     
      ))   L   ((              i)))   U   (((i               !   L   !      
      (!   -   !)             (((( \  -  / ))))               \ ·-· /       
        \.___./                ))))!\._./!((((                !\._./!       
       /.     .\              ((((/`.___.'\))))              /'     `\      
  _.-~'  `. .'  `~-._        _i))))-.___.-((((i_        _.-~'.  \ /  .`~-._ 
 '         V         `      '(((((         )))))`      '      `-...-'   adl`
                     

Interior
--------

    i ||     |    .   ||   ||   ||   _______ ~-._ _.~ .-=-.  |(c)|       ||  .-=
    ! ||     |   / \  ||___||___||  |  ( )  |    Y    |(L)|  |/~\|       ||  |i 
      || .-° |  :---: ||   ||   ||  |-(( ))-|    |    |/~\|  `---'       ||  |: 
    i ||((   |  |  /| ||_  ||  _||  |___!___| .-.|    `---'              ||  |: 
    7 || )`. |  | //| || ~-||-~ ||           -'-`-       _               ||  |: 
. ~   ||(((  |  `---' |!   ||   !|  [=(O\=(O)}))_|      | |   .---.      ||  |: 
 .-~  || ;.\ |       _`-`. || .'-'   / .-.L_.-'  `-._.-.|_|   |adl|      ||  |! 
    ! ||(  \i| __ U / \&gt;_ `'`'____  !_-|  __  _  __  _ |       ~~~       !!  !/=
   .-.|| ;. !| \ (_)`-'[]\   |)--=)  ||| (( `'.\(( `' \| _.......__    ..-.   __
.-~ )||| ! ))| |`---------'  ||==-|  `L| .\\____.-~|· ·.' ........ `.  || |  ii 
 _.'|||| ((/ | |\  | ° | |   ||==-|._  |(  `~.--|| `--' .'  :   : `. `--. |  |:_
'_.:||||     |_||||¯¯¯|T||___|L_=o=_oi_| `..'   || ....':   :   :   :.... |   __
;-':||_|   _.' ||||.¯¯||||   |T.Y|.-Y| L;. \    || .    :   :   :   :   . |  ii 
;-;'~  ~-.:    `'||   `'|| : `' |Y  `'  . \ `.  || .    :   :   :   :   . |  |: 
.'  `.' ..(O ..  `'     `' :    `'   :     `. ~' | .    :   :   :   :   . |  |: 
.': '.`.`./|     :  ..     : ..     ..:      \   | .-.._:_ _:_ _:__.:..-. |  |! 
|;-.___Ov/)|    :          :           :      `. | :                   _: |  !_-
|=:---.||/)|   :         ..:      ..    : ..    || i~~--------------~~~|| |-.  `
|  ===·||/`'  :  ..        :             :      \|_|     ..   `.    .. \|_|  ~-.
)      !!    :             :..            :  ..               ..`.              


Landscape
---------

                                                                                
            .--..-.                        .--.  _.-.                           
           (    )  )                      (    )'    )                          
         .-'       `-.                  .-'.         `-.                        
  _     (   _.-~-._)-'              __ (    )       )   )                       
-~ ~-._ _.-~       ~-._..--~~--._.-~  ~~--..__-----' `-'                      _.
    _.-~               ~-._ _.-~              ~~--..__  ___...--~~~--..._ _.-~  
_.-~ ·          .          ~-._.                     .~~--..__ .      _.-~      
           ·     ·.            ~-._     .   .  ··  .       . .~~--..__      _.-~
v^vvv^vvVv ..VVVv.. v^^^Vvv^v^^v^Vv^ v.vv..v^vv^v VVv^vV.Vv^v^^vv^vv·..vVVvvv^vv
//\vv^vv^vv^/\vv^/\^vv^vv/\vvv^vV^v/\vv^vv^v^/\:\^vv^vv^/\^v/:\v/\v^vV^VV/\vv^vv
/,`\/\/\:/\/,`\//,`\\/:\/,`\/\/\/\/,`\/\/\://,`\\:/\:/\/,`\\/\//,`\:/\:\/,`\/\/\
/,`\`/,`\.:',`,:/,`\`/_:',`,:/,`\:',`,:/,`\:',`,:/,`\\'/,`\`,`'/,`\`,`\'/,`\`/,`
/,`\``,`\`/',`,\/,`\`||/',`,\`,`'/',`,\`,`'/',`,\`,`\`'/,`\`,`'/,`\`,`\'/,`\``,`
',`,:`,`,:,',`,:',`,: :,',`,`:,`:,',`,`:,`:,',`,`:,`,`:',`,:,`:',`,:,`,:',`,:`,`
',`,\`,`,/,',`,/',`,\,/,',`,`\,`/,',`,`\,`/,',`,`\,`,`/',`,\,`/',`,\,`,/',`,\`,`
',`,\``'/',',`,/',`,\:',',`,`\`'/,',`,`\`'/,',`,`\`','/',`,\`'/',`,\`''/',`,\``'
'ii`ii::'i''ii`i'ii`` '''ii`ii::'i'ii`i`::'''ii```::'ii'ii``::'iii``::'''ii`ii::
 || ||{0}|  || |.||'· '. || |||| | ||.|'||   ||  '|| || ||  .'\||| .||   || ||{0
.,...(\|/)_.,_..,..n,._._,._.,._,..,._..,...\|/..,..,._..../,` `.,_...,......(\|
.o:::.`o.`,\|/n..,:`.,·°o.::.·,'`::.:'.-.`:o:`,'.:`'-.`o\|/~`--'~..·`:`'`,:::.`o
=============================================================================adl
                                                                                
                                                                                
    ---__o         __o-        __o  ---    __o      ---             ---         
     _7\,L7      _7\,__o     __o,L7  __o _7\,__o                                
    (-)/'(-)    (|)_7\,L7  _7\,L7(-_7\,L7|)_7\,L7                               
                  (-)/'(-)(-)/'(-)(-)/'(-)(-)/'(-)
--------------------------------------------------------------------------------


Isometric view
--------------

:____:::::____:::::::____::/\  ·/    /\:::/   \ \  :   .  ::__::::__::::__:::/  
//_//:::://_//:::::://_//:/\ \  :  . \ \~~\  . \ \__:_   ::/_/:::/_/:::/_/::/   
/ //::::// //::_:::// //:/  \ \__:_   \ \  :  / \/::::  ::/_/:::/_/:::/_/::/    
¯¯¯:::::¯¯¯¯::/\\::¯¯¯¯:/  . \/::::  . \ \  :/ / ~~~~  :::::::::::::::::::/  .  
:::::::::::::/*//::::::/ .       _____  \ \  ·/       :::::::::::::::::::/      
:::::____:::/*//____::/\   .    /\:::/  .\ \  :   .  ::__::::__::::__:::/       
:::://_//::/*////_//:/\- _o   . \ \~~\    \ \__:_   ::/_/:::/_/:::/_/::/  .  .  
:::// //:::\//// //:/\_ !:: .    \ \  :  / \/::::  ::/_/:::/_/:::/_/::/         
:::¯¯¯¯::_::¯:¯¯¯¯:/\_\ //'    /\ \ \  :/ / ~~~~  :::::::::::::::::::/      .   
::::::::/\\:::::::/ :\_\`` \  /\/  \ \  ·/  .  . :::::::::::::::::::/   .      :
____:::/H//____::/   \\_\_\_\  / /\ \ \  :      ::__::::__::::__:::/   .  .   ::
/_//::/O////_//:/     :\_\_\_\  ·    \ \__:_ . ::/_/:::/_/:::/_/::/ :\/\     ::/
 //::/T//// //:/    .  \\_\_\_\ \  ·\ \/::::  ::/_/:::/_/:::/_/::/ / /\:    ::/_
¯¯::/E//:¯¯¯¯:/         :\_\_\_\  /\/  ~~~~  :::::::::::::::::::/ ' /:/\.  :::::
:::/L//::::::/           \\_\_\_\  / ·\  .  :::::::::::::::::::/   /\/ /  ::::::
:::\//::::::/     \       :\_\_\_\  /\:    ::__::::::::::__:::/\ \: / :  ::__:::
::::____:::/\              \\_\_\_\ \·    ::/_/::____:::/_/::/\_\  /`   ::/_/::_
:::/\___\:/\_:   .          :\_\_\_\   . ::/_/::/:/:/::/_/::/ _o \ \   ::/_/::/:
::/v/v/::/\_\_\      \       \\_\_\_\   :::::::/v/v/:::::::/\(::V \ _ _:_:_:_/v/
_/_/_/_:/\_\_\_:              :\_\_\_\ :_:_:_:/_/_/:_:_:_:/\_ ¡i  _|==========.=
\\:::\\=\_\_\_\_\          .   \\_\_\_\=\=\=\=\====:\=\=\=\_\ !L _\/ .     .  )-
=\\===:\=\_\_\_\_:      \       :\_\_\_\=\=\=\=\=\=\=\=\=\=\_\_ _\/ _  .  //\ )=
\=\= _________________________________\_\=\=\=\=\=\=: o :=\=\_\_\/ //\   (/\/))-
:~:~/\       /\____\   ___            \~:~:~:~:~:~:~ TJ)L~:~:~`~/ //o \   \// )=
:::/. \      \/____/  \___\            \   :::::::::/|C^|::::::/ . V://    ~  )-
::/\:\ \________________________________\   ::::::::0`'0':::::/     //      . )=
:/C \:./._._._._._._._./C16/._._._._./-/|    ::::::::::::::::/ .  .    . _    )-
(O 1 \/o/o/o/o/:/o/o/:/¯/¯/:/o/:/o/o/:/ |  -- ::::--::::--::/ //\    .  //\.  )=
:\\ 6/---------------/:/:/---------/:/: |      :::::::::::_/ (/\/\ .   //::\  )-
::\O/:::.--.:.--.:::/_/_/::::.--.:/_/'--i   .   :::::::::/\\ .\/\/)     \://  )=
:::·---'(_0/~(_0/`----------'(_0/`------'         o :::::\C\\  \// .  .  //   )-
:_:_:_:_:_:_:_:_:_::._._._._:::::::::::::   _._. /:):_:_/.\O\\  ~   .   .    ::¯
\=\=\=\=\=\=\=\=\=\=\=\=\=\=:::::::::::::: :\_\_'|¡ \=\/.-.\M\\  . //\      ::::
===========================\=\::::::::::::: \\_\_'! =\///\|.\P\\  (/\/\ .  :::::
 ____    .c---n.   .c---n. \\=:__::__::__::__:\_\_ _\/// /:/:\U\\  \/\/)  ::::::
(_°_°`. \ 0)/\¯¯¯\\ 0)/\¯¯¯\\\_\ \ \ \ \ \ \ \\\_\_\-^/^///:_:\T\\. \//  :::::::
 0) \¯¯¯\  \^/\___\  \^/\___\\\_: \ \ \ \ \ \ \:\_\_\\\///_/\\:\E\\  ~  ::::::::
\ \ ^\___\\ \^(___( \ \^(___( \\_\ \ \ \ \ \ \ \\\_\_\-^//\\//_:\R\\.  :::::::::
   \ ^|__|   0)\   \   0)\   \ \\_:_\ \_\ \_\ \_\:\_\_\_\\:\:/\\:\S\\ :::::::::/
  \ 0)    ) \ \(o==o) \ \(o==o) \)_\              \\_\_\_\\:\\//_:\//::::::adl/ 
     `º--º     ¯¯¯¯¯     ¯¯¯¯¯     _:      \       :\_\_\_\\:\:/\\:/:::::__::/  
  °  __        __        __   .     _\    .         \\_\_\_\\:\\///:/\/:/_/:/ . 
                                     _:              :\_\_\_\\:\_/::::_:__:/ //\
____  .   ____      °       .c---n. (\_\      \       \\_\_\_\\//:/\//-:/_/ (/\/
_°_°`.   (_°_°`.             0)/\¯¯¯\\\_:              :\_\_\_\/:_  _o _/\\ .\/\
0) \¯¯¯\\ 0) \¯¯¯\\     °   \ \^/\___\\\_\              \\_\_\_\=\ V::) \P\\  \/
 \ ^\___\  \ ^\___\            \^(___( \\_:      \       :\_\_\_\ .//  /.\H\\  ~
\ \ ^|__| \ \ ^|__| \ .       \ 0)\   \ \\_\         .    \\_\_\_\_  =/.-.\O\\ .
   0)    )   0)    )      .c_!   \(o==o) \\_:              :\_\_\_\=\///\|.\N\\ 
  \ `º--º   \ `º--º   \    !-!  \ ¯¯¯¯¯   \\_\      \       \\_\_\_\///\/:/:\E\\
                                                           

Copyright (c) 2022, Adel Faure contact@adelfaure.net, with Reserved Font Name
Jgs Font, jgs5, jgs7, jgs9.

This Font Software is licensed under the SIL Open Font License, Version 1.1.
This license is available with a FAQ at: http://scripts.sil.org/OFL

                                                                                
================================================================================

<a href="mailto:contact@adelfaure.net">contact@adelfaure.net</a> send me an email :-)

Find me on                                                                     
            <a href="https://adelfaure.itch.io/">Itch.io</a>
            <a href="https://www.gamejolt.com/@adelfaure">Gamejolt</a>
            <a href="https://www.gitlab.com/adelfaure">Gitlab</a>
            <a href="https://www.instagram.com/adelfaure">Instagram</a>
            <a href="https://www.reddit.com/user/AdelFaure">Reddit</a> (not often connected)
            <a href="https://www.twitter.com/adelfaure">Twitter</a>
            Soundcloud <a href="https://soundcloud.com/faureadel">2021</a> <a href="https://soundcloud.com/mostunderratedartist">2016</a> <a href="https://soundcloud.com/adelfaure">2014</a>

You can support me on <a href="https://ko-fi.com/adelfaure">Ko-fi</a>, you'll make my day \(♥3♥)/ !

================================================================================
/\ <a href="#top">Top</a>
================================================================================
</pre>
  
  

</main></div>]]></description>
        </item>
        <item>
            <title><![CDATA[POV-Ray – The Persistence of Vision Raytracer (291 pts)]]></title>
            <link>http://www.povray.org/</link>
            <guid>40643207</guid>
            <pubDate>Tue, 11 Jun 2024 06:36:44 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="http://www.povray.org/">http://www.povray.org/</a>, See on <a href="https://news.ycombinator.com/item?id=40643207">Hacker News</a></p>
<div id="readability-page-1" class="page"><div width="99%">


<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<p>
The <a href="http://www.povray.org/download/">Persistence of Vision Raytracer</a> is a high-quality, Free Software tool for
creating <a href="http://hof.povray.org/">stunning three-dimensional graphics</a>.
The source code is available for those wanting to do their own ports.
</p>
<!-- p align="center">
<a href="//hof.povray.org/ChristmasBaubles.html"><img src='//hof.povray.org/images/800x600/ChristmasBaubles.jpg' alt='Christmas Baubles' class='RaisedImage' border='0'></a> 
</p -->

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>

<p>
To navigate about this site please use the navigation links at the top of this page.
If you want to download POV-Ray, please visit our <b><a href="http://www.povray.org/download/">download page</a></b>.
</p>

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>

<p>
For general resources and support information, please visit our <a href="http://www.povray.org/resources/">resource and support page</a>.
For website-related issues <i>only</i>, please <a href="http://www.povray.org/webmaster.html">contact our webmaster</a>.
To contact us regarding licensing matters, please use the address given at the bottom of our <a href="http://www.povray.org/povlegal.html">license page</a>.
</p>

</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>
<table><tbody><tr><td>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<div><p>DKBTrace (foundation of POV-Ray) creator has kickstarter for educational IDE</p></div>

<!-- NC 3 20 -->
<div><p>
David K. Buck - the creator of DKBTrace, the pioneering raytracer that was the genesis of POV-Ray - has created a <a href="https://www.kickstarter.com/projects/pigeontalk/pigeontalk-a-programming-environment-to-explore-computing">KickStarter campaign to fund creation of an open-source IDE for PigeonTalk</a> (PigeonTalk is a smalltalk implementation created by David that is aimed at being a programming environment to explore computing).
</p>

<blockquote>
"I chose Smalltalk as a language because it provides the most immersive experience I've encountered.  Smalltalk allows you to create, use, and explore software in a very hands-on way.  It's an ideal environment for learning and playing with software.
This Kickstarter project is to provide a development environment for this Smalltalk which I'm calling PigeonTalk.  The development environment would run in a web browser and would communicate with the Smalltalk engine using WebSockets.  Once this is available, PigeonTalk becomes a viable programming environment that others could use."
</blockquote>

<p>
We wish David the best in this endeavor and are hopeful the Kickstarter will meet its goal as POV-Ray itself would not exist if it were not for David's kind contribution of the DKBTrace source code.
</p></div>
<div><p>
[February&nbsp;04,&nbsp;2022]
[<a href="http://www.povray.org/news/index.php#336">Permalink</a>]
</p></div><div><p>POV-Ray v3.8.0 beta tests available</p></div>

<!-- NC 6 20 -->
<p>POV-Ray 3.8 is now in beta-test. You may obtain beta releases via our <a href="https://github.com/POV-Ray/povray/releases/">GitHub</a> repository. Discussion regarding the betas should be directed to the <a href="http://news.povray.org/povray.beta-test/">beta-test group</a> in our forums.</p>
<div><p>
[August&nbsp;31,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#335">Permalink</a>]
</p></div><div><p>POV-Ray turns 30</p></div>

<!-- NC 9 20 -->
<div><p>30 years ago today, on July 29 1991, the first beta of what would become POV-Ray became available in the GRAPHDEV forum on CompuServe. See <a href="http://www.povray.org/documentation/view/3.6.1/7/">"The Early History of POV-Ray"</a>, <a href="http://www.povray.org/documentation/view/3.6.1/8/">"The Original Creation Message"</a>, <a href="http://www.povray.org/documentation/view/3.6.1/9/">"The Name"</a> and <a href="http://www.povray.org/documentation/view/3.6.1/10/">"A Historic Version History"</a> in our v3.6 documentation for more details about the early days of this project.</p></div>
<div><p>
[July&nbsp;29,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#334">Permalink</a>]
</p></div><div><p>Wiki back online</p></div>

<!-- NC 12 20 -->
<p>The <a href="http://wiki.povray.org/">POV-Wiki</a> is now back online and is running the latest version of MediaWiki. Additionally we have restored our <a href="http://bugs.povray.org/">legacy bugtracker</a>, which tracked issues prior to moving our source code to GitHub.</p>
<div><p>
[April&nbsp;12,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#333">Permalink</a>]
</p></div><div><p>Forums back online</p></div>

<!-- NC 13 20 -->
<p>Following more recovery work since the server crash we're happy to say our ... ... <i><a href="http://www.povray.org/news/index.php#332">[read more]</a></i></p>
<div><p>
[March&nbsp;28,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#332">Permalink</a>]
</p></div><div><p>Server Recovery</p></div>

<!-- NC 14 20 -->
<p>The www.povray.org site is now back in read-write mode ... ... <i><a href="http://www.povray.org/news/index.php#331">[read more]</a></i></p>
<div><p>
[March&nbsp;21,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#331">Permalink</a>]
</p></div><div><p>POV-Ray Server Downtime</p></div>

<!-- NC 15 20 -->
<p>Our server recently experienced a catastrophic hardware failure ... ... <i><a href="http://www.povray.org/news/index.php#330">[read more]</a></i></p>
<div><p>
[March&nbsp;15,&nbsp;2021]
[<a href="http://www.povray.org/news/index.php#330">Permalink</a>]
</p></div><div><p>Blender to Persistence of Vision</p></div>

<!-- NC 16 20 -->
<p>New Release: Blender to Persistence of Vision ... <i><a href="http://www.povray.org/news/index.php#329">[read more]</a></i></p>
<div><p>
[August&nbsp;01,&nbsp;2020]
[<a href="http://www.povray.org/news/index.php#329">Permalink</a>]
</p></div><div><p>white_dune VRML/X3D editor adds POV-Ray export</p></div>

<!-- NC 19 20 -->
<div><p>
The folks at the open-source white_dune 3d editor project let us know that they've added POV-Ray export capability. Neat! It looks like a useful tool, definitely worth checking out.
</p>

<p>
You can find their <a href="https://github.com/mufti11/white_dune/">github repo here</a> or if you prefer you can go straight to their <a href="http://wdune.ourproject.org/">project website</a> for downloads.
</p></div>
<div><p>
[July&nbsp;23,&nbsp;2020]
[<a href="http://www.povray.org/news/index.php#328">Permalink</a>]
</p></div><div><p>Call for papers: Ray Tracing Gems</p></div>

<!-- NC 20 20 -->
<p>Eric Haines dropped us a line to let us know that there is still time to submit papers to Ray Tracing Gems ... ... <i><a href="http://www.povray.org/news/index.php#326">[read more]</a></i></p>
<div><p>
[July&nbsp;01,&nbsp;2018]
[<a href="http://www.povray.org/news/index.php#326">Permalink</a>]
</p></div><div><p>Older News</p></div>
<div><ul>
<li><a href="http://www.povray.org/news/index.php#325">POV-Ray 3.7.1 enters beta phase</a></li>
<li><a href="http://www.povray.org/news/index.php#324">Converting POV-Ray scenes into 3D-printable STL meshes</a></li>
<li><a href="http://www.povray.org/news/index.php#323">POV-Ray turns 25 (or 30)</a></li>
<li><a href="http://www.povray.org/news/index.php#322">Python modeller for POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#321">Routing problems for some users in Sweden and Finland</a></li>
<li><a href="http://www.povray.org/news/index.php#320">POV-Ray 3.7 released</a></li>
<li><a href="http://www.povray.org/news/index.php#318">Lathe and Prism Utility Available</a></li>
<li><a href="http://www.povray.org/news/index.php#317">Viewshed Analysis with POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#316">POV-Ray Helps Visualize Bee Keeper Data</a></li>
<li><a href="http://www.povray.org/news/index.php#315">POV-Ray, Export &amp; View, for Mathematica</a></li>
<li><a href="http://www.povray.org/news/index.php#314">Koppi's Bullet Physics Playground</a></li>
<li><a href="http://www.povray.org/news/index.php#313">Parallella supercomputer kickstarter nearing end</a></li>
<li><a href="http://www.povray.org/news/index.php#312">Spectral Rendering with POV-Ray</a></li>
<li><a href="http://www.povray.org/news/index.php#311">ANIMUSIC 3 kickstarter campaign in its last week</a></li>
<li><a href="http://www.povray.org/news/index.php#310">Update of Insert Menus Add-on</a></li>
<li><a href="http://www.povray.org/news/index.php#309">Caedium Version 4 Available</a></li>
<li><a href="http://www.povray.org/news/index.php#308">Another PoseRay Update</a></li>
<li><a href="http://www.povray.org/news/index.php#307">Making of a Rose</a></li>
<li><a href="http://www.povray.org/news/index.php#306">Colored Leaves</a></li>
<li><a href="http://www.povray.org/news/index.php#305">PoseRay Beta Release</a></li>
</ul>
</div>
</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
<div><p>Visualization Library</p></div>

<!-- NC 3 20 -->
<p><a href="http://www.visualizationlibrary.com/jetcms/">Visualization Library</a> is a C++ middleware for high-performance 2D and 3D graphics applications based on the industry standard OpenGL 2.1, designed to develop portable applications for the Windows, Linux and Mac OS X operating systems.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#287">Permalink</a>]
</p></div><div><p>Jupiter Loses a Stripe</p></div>

<!-- NC 6 20 -->
<p>Lost: A giant <a href="http://science.nasa.gov/science-news/science-at-nasa/2010/20may_loststripe/">belt</a> of brown clouds big enough to swallow Earth twenty times over.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#285">Permalink</a>]
</p></div><div><p>OGRE 1.7.1</p></div>

<!-- NC 9 20 -->
<p>Since 2001, OGRE has grown to become one of the most popular open-source graphics rendering engines, and has been used in a large number of production projects. Check out the first maintenance release to the new 1.7 stable branch codenamed <a href="http://www.ogre3d.org/">Cthugha</a>.</p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#284">Permalink</a>]
</p></div><div><p>E-on Software Ships Vue 8.5</p></div>

<!-- NC 12 20 -->
<p>e-on software, maker of the leading solutions for Digital Nature, <a href="http://www.e-onsoftware.com/about/?page=PRIndex&amp;date=May%206,%202010">announced today</a> the immediate availability of Vue 8.5 xStream and Infinite, its professional solutions for the creation, animation and rendering of natural 3D environments. </p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#283">Permalink</a>]
</p></div><div><p>Solar Dynamics Observatory</p></div>

<!-- NC 13 20 -->
<p>NASA's Solar Dynamics Observatory ... <i><a href="http://www.povray.org/news/index.php#282">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#282">Permalink</a>]
</p></div><div><p>DAZ 3D-Gizmoz Introduces Digimi</p></div>

<!-- NC 14 20 -->
<p><a href="http://www.digimi.com/newsite/presite/home.jsp">Digimi</a> the ultimate platform for generating personalized avatars. ... <i><a href="http://www.povray.org/news/index.php#278">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#278">Permalink</a>]
</p></div><div><p>OpenTK Library 1.0 RC1</p></div>

<!-- NC 15 20 -->
<div><p>The <a href="http://www.opentk.com/">OpenTK</a> is an advanced, low-level C# library ... <i><a href="http://www.povray.org/news/index.php#277">[read more]</a></i></p></div>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#277">Permalink</a>]
</p></div><div><p>Rhino for OS X is in development</p></div>

<!-- NC 16 20 -->
<p>During development, pre-release Rhino OS X is free ... <i><a href="http://www.povray.org/news/index.php#274">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#274">Permalink</a>]
</p></div><div><p>SymLab RANS Flow</p></div>

<!-- NC 17 20 -->
<p><a href="http://www.symscape.com/">Symscape</a>'s commercial range of simulation products has now been expanded to include <a href="http://www.symscape.com/news/symlab-rans-flow-released">SymLab RANS Flow</a> for the simulation of realistic (viscous) ... <i><a href="http://www.povray.org/news/index.php#265">[read more]</a></i></p>
<div><p>
[June&nbsp;03,&nbsp;2010]
[<a href="http://www.povray.org/news/index.php#265">Permalink</a>]
</p></div></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
</td><td>&nbsp;</td><td>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="4" height="20" alt=""></td>
<td><span color="#ffffff">
<a href="http://hof.povray.org/rwmcgsphere2_final.html"><img src="http://hof.povray.org/images/thumb/rwmcgsphere2_final.jpg" width="320" height="320" alt="Hall of Fame Image"></a><br>
</span><center><span color="#ffffff"><span><b><cite>"My First CGSphere"</cite></b></span><p>
<a href="http://hof.povray.org/rwmdolphins.html"><img src="http://hof.povray.org/images/thumb/rwmdolphins.jpg" width="320" height="240" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Thanks for all the fish"</cite></b></span><p>
<a href="http://hof.povray.org/sherk-collins.html"><img src="http://hof.povray.org/images/thumb/sherk-collins.jpg" width="320" height="200" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Scherk-Collins sculpture"</cite></b></span><p>
<a href="http://hof.povray.org/BonsaiGirlA24.html"><img src="http://hof.povray.org/images/thumb/BonsaiGirlA24.jpg" width="320" height="400" alt="Hall of Fame Image"></a></p></span><center><span color="#ffffff"><span><b><cite>"Bonsai Life"</cite></b></span><p>
<a href="http://hof.povray.org/TopMod_StarBall.html"><img src="http://hof.povray.org/images/thumb/TopMod_StarBall.jpg" width="320" height="320" alt="Hall of Fame Image"></a></p><center><span><b><cite>"TopMod StarBall"</cite></b></span><p>
<span><a href="http://hof.povray.org/">See more images...</a> <a href="http://hof.povray.org/index-lb.html"><i>[dialup version]</i></a></span></p></center>
</span></center></center></center></center></td>
<td><img src="http://www.povray.org/i/fill.gif" width="4" height="20" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="2" alt=""></td></tr>
</tbody></table>
<br>
</td></tr></tbody></table>
<br>

<table>
<tbody><tr>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="2" height="4" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
<tr>
<td></td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
<td>
You may view our Privacy Policy <a href="http://www.povray.org/privacy.php">here</a>.
</td>
<td><img src="http://www.povray.org/i/fill.gif" width="8" height="1" alt=""></td>
</tr>
<tr><td></td><td colspan="3"><img src="http://www.povray.org/i/fill.gif" width="1" height="8" alt=""></td></tr>
</tbody></table>
<br>
</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[macOS Sequoia to Allow iCloud Logins in Virtual Machines on ARM Macs (126 pts)]]></title>
            <link>https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc</link>
            <guid>40643181</guid>
            <pubDate>Tue, 11 Jun 2024 06:31:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc">https://developer.apple.com/documentation/virtualization/using_icloud_with_macos_virtual_machines?language=objc</a>, See on <a href="https://news.ycombinator.com/item?id=40643181">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Exploring Gleam, a type-safe language on the BEAM (178 pts)]]></title>
            <link>https://christopher.engineering/en/blog/gleam-overview/</link>
            <guid>40643167</guid>
            <pubDate>Tue, 11 Jun 2024 06:29:49 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://christopher.engineering/en/blog/gleam-overview/">https://christopher.engineering/en/blog/gleam-overview/</a>, See on <a href="https://news.ycombinator.com/item?id=40643167">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>   <p>If you know me, you’d probably say, “Omg Chris, yet another new language???!!!“.
The truth is, this is the only way I found to keep my motivation as a software
engineer. A new language means a new way of both building and thinking. I’m
trying to stay open-minded when it comes to my craft. I’ll just get the best out
of this new experience and move on. In this article, I’m going to talk about
Gleam, how I found it, and why I’m already LOVING it.</p>
<p><img src="https://christopher.engineering/_astro/gleam-banner.CSmos0T3_Z2gg4CB.webp" alt="Pink star representing Gleam's logo, followed by the label 'Gleam'" width="1200" height="630" loading="lazy" decoding="async"></p><h2 id="how-i-heard-about-gleam">How I heard about Gleam?</h2>
<p>Gleam V1 launched on March 4th 2024. As a
<a href="https://youtu.be/0sxXyLJe2N8?si=0ExH3E5ViqdEGlMM&amp;t=12">built different engineer</a>,
I found out about it back in November 2023, when I started being seriously
interested in Elixir.</p>
<p>The thing that always kind of put me off regarding Elixir was the dynamic
typing. I’m a static typing person; it solves a LOT of common issues in my
day-to-day job and provides cool benefits like:</p>
<ul>
<li>Less runtime errors, since the compiler YELLS at you when something is wrong
about your code structure.</li>
<li>Trust in what goes to production, since it was approved by the boss (the
compiler).</li>
<li>Code with typing indications is often (not always, but still, often) clearer
and easier to understand. If the documentation is incomplete or non-existent,
you still have something to go by, and new engineers can start contributing
faster.</li>
<li>Coding by thinking about the data structure FIRST, and then, the
implementation matches my thinking process.</li>
</ul>
<p>Anyway, you get it, I a type-sexual.</p>
<p>So, one day, I was googling “Static typing elixir”, and I saw
<a href="https://gleam.run/">Gleam</a> in the results. What did I do? I just ignored the
thing and moved on.</p>
<p><strong>WHY ?</strong></p>
<p>Because I’m more mature than ever. Like look, I did my due diligence on Gleam:
adoption, use cases, versions (it was on v0.something), and I wasn’t impressed.
I thought that Gleam was super early, a cool gimmick, an experimental toy, but
it stayed somewhere in my brain, in the box where I put the stuff I might get
into, but not RIGHT NOW.</p>
<p><img src="https://christopher.engineering/_astro/things-to-learn.CBPM5iSX_ng9Ue.webp" alt="Drawing representing the things I want to keep an eye on vs the things that are requiring my immediate attention, Gleam falls into the things I want to keep an eye on category" width="2943" height="1206" loading="lazy" decoding="async"></p><h2 id="what-gleam-brings-to-the-table">What Gleam brings to the table</h2>
<p>Fast forward, it’s March 1st, 2024:
<a href="https://gleam.run/news/gleam-version-1/">Gleam is officially on V1</a>. I read the
changelog, I get the SDK to play with the language and folks… the vibes are
IMMACULATE. I’m starting to regret the time I had the occasion to be involved
super early (I know it’s dumb), but as they (idk who’s “they”) said, better late
than never.</p>
<p>I’ll go through the features I love the most and tell you what I like, and what
can be better.</p>
<h3 id="types-and-structures">Types and structures</h3>
<p>I think it’s BEAUTIFUL, like:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>What you’re seeing here is a Gleam <code>custom type</code> or <code>Record</code>, with <code>Vehicle</code>
being the type’s name, <code>Car</code>, <code>Skateboard</code>, and <code>Spaceship</code> being the
constructors available for this type. This is basically a tagged union, or if
you prefer, some sort of enumeration, where each member gets its own set of
attributes. It’s being used like:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>let</span><span> my_car </span><span>=</span><span> Car</span><span>(</span><span>"Honda"</span><span>, </span><span>"Civic"</span><span>)</span></span>
<span></span></code></pre>
<p>and it allows pretty cool structures, like this cute pattern matching:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicule: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicule {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>Let’s spend some time on the function above:</p>
<ol>
<li><code>get_driving_requirements</code> takes only one <code>Vehicle</code> type argument and returns
a <code>String</code>. Both Gleam’s compiler and LSP will let you know if any of those
conditions are not respected. Specifying what a function returns in Gleam is
optional; due to type inference, Gleam will understand it anyway.</li>
<li>In the function’s body, you can see the <code>case</code> structure. This is how you
perform pattern matching, which is essentially a switch control on steroids.
Using a <code>case</code>, you can execute code path if a specific pattern is matched
for a given variable. It’s pretty crazy how deeply you leverage this
technique. In my example, I check every possible constructor for the
<code>vehicle</code> variable. Once again, the tooling will alert you if your pattern
matching is not exhaustive (safety first!).</li>
</ol>
<p>It’s super expressive, the code is concise and elegant (to me).</p>
<h3 id="gleams-tooling">Gleam’s tooling…</h3>
<p>…is CRAZY. Like, crazy CRAZY. I spent so much time in the cursed lands of
Javascript that I forgot grass could be THIS green elsewhere. The only thing you
need to do it to install the <code>gleam</code> CLI. To do so, I used
<a href="https://asdf-vm.com/">asdf</a>, but you can do the same using any other package
manager like Homebrew. What does the <code>gleam</code> command do? Check this out:</p>
<pre tabindex="0" data-language="bash"><code><span><span>❯</span><span> gleam</span></span>
<span><span>gleam</span><span> 1.2.0-rc1</span></span>
<span></span>
<span><span>Usage:</span><span> gleam</span><span> &lt;</span><span>COMMAN</span><span>D</span><span>&gt;</span></span>
<span></span>
<span><span>Commands:</span></span>
<span><span>  add</span><span>      Add</span><span> new</span><span> project</span><span> dependencies</span></span>
<span><span>  build</span><span>    Build</span><span> the</span><span> project</span></span>
<span><span>  check</span><span>    Type</span><span> check</span><span> the</span><span> project</span></span>
<span><span>  clean</span><span>    Clean</span><span> build</span><span> artifacts</span></span>
<span><span>  deps</span><span>     Work</span><span> with</span><span> dependency</span><span> packages</span></span>
<span><span>  docs</span><span>     Render</span><span> HTML</span><span> documentation</span></span>
<span><span>  export</span><span>   Export something useful from the Gleam project</span></span>
<span><span>  fix</span><span>      Rewrite</span><span> deprecated</span><span> Gleam</span><span> code</span></span>
<span><span>  format</span><span>   Format</span><span> source</span><span> code</span></span>
<span><span>  help</span><span>     Print</span><span> this</span><span> message</span><span> or</span><span> the</span><span> help</span><span> of</span><span> the</span><span> given</span><span> subcommand</span><span>(</span><span>s</span><span>)</span></span>
<span><span>  hex</span><span>      Work</span><span> with</span><span> the</span><span> Hex</span><span> package</span><span> manager</span></span>
<span><span>  lsp</span><span>      Run</span><span> the</span><span> language</span><span> server,</span><span> to</span><span> be</span><span> used</span><span> by</span><span> editors</span></span>
<span><span>  new</span><span>      Create</span><span> a</span><span> new</span><span> project</span></span>
<span><span>  publish</span><span>  Publish</span><span> the</span><span> project</span><span> to</span><span> the</span><span> Hex</span><span> package</span><span> manager</span></span>
<span><span>  remove</span><span>   Remove</span><span> project</span><span> dependencies</span></span>
<span><span>  run</span><span>      Run</span><span> the</span><span> project</span></span>
<span><span>  shell</span><span>    Start</span><span> an</span><span> Erlang</span><span> shell</span></span>
<span><span>  test</span><span>     Run</span><span> the</span><span> project</span><span> tests</span></span>
<span><span>  update</span><span>   Update</span><span> dependency</span><span> packages</span><span> to</span><span> their</span><span> latest</span><span> versions</span></span>
<span></span>
<span><span>Options:</span></span>
<span><span>  -h,</span><span> --help</span><span>     Print</span><span> help</span></span>
<span><span>  -V,</span><span> --version</span><span>  Print</span><span> version</span></span>
<span></span></code></pre>
<ul>
<li>package manager ➡️ <code>gleam add</code></li>
<li>repl ➡️ <code>gleam shell</code></li>
<li>test runner ➡️ <code>gleam test</code></li>
<li>formatter ➡️ <code>gleam format</code></li>
<li>lsp ➡️ <code>gleam lsp</code></li>
<li>and more…</li>
</ul>
<p>All you need to get started with Gleam is already in this CLI. You dont’t have
ANYTHING else check, there’s ZERO decision paralysis: THIS-IS-WHAT-WE-WANT.
Javascript makes you pick a tool among hundred of options, for each tool
provided in Gleam’s CLI.</p>
<p>One more thing: each language version comes bundled with its own set of tools;
to prevent tooling incompabilities.</p>
<p>Let’s reuse the previous example:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span></span>
<span><span>/// This is some type related to type Vehicle</span></span>
<span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  /// Car type used for... a car I guess...</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicle: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicle {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> fn</span><span> main</span><span>() {</span></span>
<span><span>  get_driving_requirements</span><span>(</span><span>Car</span><span>(</span><span>make: </span><span>"Hyundai"</span><span>, </span><span>brand: </span><span>"Kona"</span><span>))</span></span>
<span><span>  io.</span><span>println</span><span>(</span><span>"Hello from gl_playground!"</span><span>)</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>When I hover my mouse <code>vehcule</code> in my function body, I’m seeing:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-1.DnMdKRE2_zvw3v.webp" alt="Screenshot showing when you hover on vehicule, your texte editor show your types and documentation thanks to the LSP." width="1694" height="450" loading="lazy" decoding="async"></p><p>LSP is capable of getting both type and documentation related to the variable.
Another exemple if, what happens when I hover on the <code>Car</code> constructor:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-2.DRJwV_aI_Z1lhYEl.webp" alt="Screenshot showing when you hover on Car, the LSP shows the custom type name and the constructor's documentation" width="1432" height="410" loading="lazy" decoding="async"></p><p>Here, the LSP shows both the parent custom type’name and the associated
documentation.</p>
<p>One last example, when I hover on <code>brand</code>, for the code block executed when
<code>Skateboard</code> is matched:</p>
<p><img src="https://christopher.engineering/_astro/lsp-example-3.DTLffvNX_Z1iSOR0.webp" alt="Screenshot showing that when your hover on brand, it shows the variable type" width="1790" height="980" loading="lazy" decoding="async"></p><p>The LSP understands that <code>brand</code> is the first attribute in <code>Skateboard</code>.</p>
<p>This is the attention to details that makes you love an ecosystem. It helps you
ship quality code, and it drives the language adoption up: this is a true
win-win situation.</p>
<h3 id="otp-implementation">OTP implementation</h3>
<p>Earlier, I told you that Gleam runs on the
<a href="https://en.wikipedia.org/wiki/BEAM_(Erlang_virtual_machine)">BEAM</a> (never
said that tbh). BEAM means Erlang, and Erlang means OTP. Please, sit down and
relax, cuz I’m about to try to tell you what OTP is about.</p>
<blockquote>
<p>OTP (Open Telecom Platform) is an architecture (and some kind of philosophy)
for building fault-tolerant and highly concurrent software. The key principle
is to divide a program into small execution units called <em>processes</em>
(unrelated to OS processes) and making those processes communicate through
message passing. Those processes can die at any time for any reason, so OTP
advise you to put them under a supervision tree, so that a supervisor (which
is also a process) can restart them. Erlang and Elixir give the developer the
abstractions needed to build on top of OTP, with the BEAM allowing you to run
MILLIONS of processes, even on a tiny server.</p>
</blockquote>
<p><img src="https://christopher.engineering/_astro/big-brain-opt-meme.DmwjBMXb_Z1Wneqo.webp" alt="Big brain meme with 'Me when I explain OTP' as a legend" width="568" height="500" loading="lazy" decoding="async"></p><p>Dang, I really gave my everything on this one, but now you kind of know what OTP
is. That being said, Gleam also has its own OTP primitives, using an
<a href="https://github.com/gleam-lang/otp">external official package</a>. The abstraction
I used the most is the <code>actor</code> (btw, you should learn about the actor model;
this thing is CRAZY). Let me show you how this works:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>int</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>erlang</span><span>/</span><span>process.{</span><span>type</span><span> Subject</span><span>}</span></span>
<span><span>import</span><span> gleam</span><span>/</span><span>otp</span><span>/</span><span>actor</span></span>
<span></span>
<span><span>type</span><span> AsyncTaskMessage</span><span> {</span></span>
<span><span>  Increment</span><span>(</span><span>reply_to: </span><span>Subject</span><span>(</span><span>Int</span><span>))</span></span>
<span><span>  Decrement</span><span>(</span><span>reply_to: </span><span>Subject</span><span>(</span><span>Int</span><span>))</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> handle_async_task</span><span>(</span><span>message: </span><span>AsyncTaskMessage</span><span>, </span><span>state: </span><span>Int</span><span>) {</span></span>
<span><span>  case</span><span> message {</span></span>
<span><span>    Increment</span><span>(client) </span><span>-&gt;</span><span> {</span></span>
<span><span>      let</span><span> new_value </span><span>=</span><span> state </span><span>+</span><span> 1</span></span>
<span><span>      process.</span><span>send</span><span>(client, new_value)</span></span>
<span><span>      actor.</span><span>continue</span><span>(new_value)</span></span>
<span><span>    }</span></span>
<span><span>    Decrement</span><span>(client) </span><span>-&gt;</span><span> {</span></span>
<span><span>      let</span><span> new_value </span><span>=</span><span> state </span><span>-</span><span> 1</span></span>
<span><span>      process.</span><span>send</span><span>(client, new_value)</span></span>
<span><span>      actor.</span><span>continue</span><span>(new_value)</span></span>
<span><span>    }</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> start_async_task</span><span>(</span><span>state: </span><span>Int</span><span>) {</span></span>
<span><span>  actor.</span><span>start</span><span>(state, handle_async_task)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> main</span><span>() {</span></span>
<span><span>  let</span><span> assert</span><span> Ok</span><span>(actor) </span><span>=</span><span> start_async_task</span><span>(</span><span>0</span><span>)</span></span>
<span><span>  let</span><span> response </span><span>=</span><span> actor.</span><span>call</span><span>(actor, </span><span>fn</span><span>(subject) { </span><span>Increment</span><span>(subject) }, </span><span>10_000</span><span>)</span></span>
<span><span>  io.</span><span>println</span><span>(</span><span>"New value: "</span><span> &lt;&gt;</span><span> int.</span><span>to_string</span><span>(response))</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>For a Gleam actor, you need a few things:</p>
<ol>
<li>A custom type for all kind of messages your actor can receive. It’s called
<code>AsyncTaskMessage</code> in this example.</li>
<li>A function which takes a message and a state (the state being whatever you’d
like) and returns a new state, or something indicating that the task should
end. This is <code>handle_async_task</code> in our example.</li>
<li>A function starting everything. In our example this is the <code>start_async</code>
function.</li>
</ol>
<p>With all of these pieces, you get a new stateful process that can live on its
own. You can send messages for it to do… stuffs, I guess. Yeah, I know the
demo is kind of lame, BUT it shows you how powerful Gleam’s type system is when
coupled with OTP. You cannot send any message to your process that isn’t
type-checked <strong>AT COMPILE TIME</strong>!</p>
<p>Something less cool, is the fact that OTP isn’t fully ported to Gleam. Few
features, like
<a href="https://medium.com/@StevenLeiva1/elixir-process-registries-a27f813d94e3">Registries</a>
are missing…</p>
<h3 id="lustre-a-curious-web-framework">Lustre, a curious web framework</h3>
<p><strong>YEAH, I KNOW</strong>, another new web framework. You have to understand, a new
language needs that kind of popular tooling. Some people (web devs) are waiting
for it. <a href="https://hexdocs.pm/lustre/4.2.4/">Lustre</a> is a Gleam web framework.
It’s been around in Gleam ecosystem for a long time and I think, is mature in
Gleam’s context.</p>
<p>I didn’t tried it yet, (it should be one of my next article), but we’re talking
about a tech with a lot of cool features:</p>
<ul>
<li>It’s isomorphic, it’s running on both backend and frontend.</li>
<li>It’s heavily inspired from <a href="https://elm-lang.org/">Elm</a>, this scary thing we
got from weed smoking Haskell geniuses (this is a compliment, huge respect for
them).</li>
<li>It’s opinionated, from an app to another, you supposed to see the same
conventions and code structure.</li>
</ul>
<p>I’ll let you check <a href="https://hexdocs.pm/lustre/4.2.4/">the documentation</a> and see
if it’s something that you’d be interrested in.</p>
<h3 id="javascript-interoperability">Javascript, interoperability</h3>
<p><img src="https://christopher.engineering/_astro/gleam-js.BZ_mi_eg_PHtwa.svg" alt="Edit show both Gleam's and Javascript logo" width="2105" height="2016" loading="lazy" decoding="async"></p><p>I JUST TOLD YOU!!! Gleam has a web framework and it’s ISOMORPHIC. How does it
run on web? It runs because Gleam can transpile to Javascript. This is an
interesting strategy. They are trying to convince the easiest crowd: Javascript
developers. Those people (me, I’m “these people”) are tired of Typescript /
Javascript nonsense. They’re looking for simplicity, robustness and Gleam has
all the tool they need for that. There’s few players in this space, like
<a href="https://reasonml.github.io/">ReasonML</a> and
<a href="https://rescript-lang.org/">ReScript</a>.</p>
<p>Check the code below:</p>
<pre tabindex="0" data-language="gleam"><code><span><span>import</span><span> gleam</span><span>/</span><span>io</span></span>
<span></span>
<span><span>type</span><span> Vehicle</span><span> {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>String</span><span>, </span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Skateboard</span><span>(</span><span>brand: </span><span>String</span><span>)</span></span>
<span><span>  Spaceship</span><span>(</span><span>year: </span><span>Int</span><span>)</span></span>
<span><span>}</span></span>
<span></span>
<span><span>fn</span><span> get_driving_requirements</span><span>(</span><span>vehicle: </span><span>Vehicle</span><span>) </span><span>-&gt;</span><span> String</span><span> {</span></span>
<span><span>  case</span><span> vehicle {</span></span>
<span><span>    Car</span><span>(make, brand) </span><span>-&gt;</span></span>
<span><span>      "To drive the car "</span></span>
<span><span>      &lt;&gt;</span><span> make</span></span>
<span><span>      &lt;&gt;</span><span> " "</span></span>
<span><span>      &lt;&gt;</span><span> brand</span></span>
<span><span>      &lt;&gt;</span><span> ", your need a driver licence."</span></span>
<span><span>    Spaceship</span><span>(</span><span>_</span><span>) </span><span>-&gt;</span><span> "You need to be a NASA astronaut for that!"</span></span>
<span><span>    Skateboard</span><span>(brand) </span><span>-&gt;</span><span> "Anybody can ride a "</span><span> &lt;&gt;</span><span> brand </span><span>&lt;&gt;</span><span> " skateboard!"</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> fn</span><span> main</span><span>() {</span></span>
<span><span>  Car</span><span>(</span><span>make: </span><span>"Hyundai"</span><span>, </span><span>brand: </span><span>"Kona"</span><span>)</span></span>
<span><span>  |&gt;</span><span> get_driving_requirements</span><span>()</span></span>
<span><span>  |&gt;</span><span> io.</span><span>println</span><span>()</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>This snippet is quite at exposing Gleam’s key features, there’s types, pattern
matching, pipe operator… See below the Javascript output after running
<code>gleam build --target javascript</code>:</p>
<pre tabindex="0" data-language="javascript"><code><span><span>import</span><span> *</span><span> as</span><span> $io </span><span>from</span><span> "../gleam_stdlib/gleam/io.mjs"</span><span>;</span></span>
<span><span>import</span><span> { CustomType </span><span>as</span><span> $CustomType } </span><span>from</span><span> "./gleam.mjs"</span><span>;</span></span>
<span></span>
<span><span>class</span><span> Car</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>make</span><span>, </span><span>brand</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.make </span><span>=</span><span> make;</span></span>
<span><span>    this</span><span>.brand </span><span>=</span><span> brand;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>class</span><span> Skateboard</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>brand</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.brand </span><span>=</span><span> brand;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>class</span><span> Spaceship</span><span> extends</span><span> $CustomType</span><span> {</span></span>
<span><span>  constructor</span><span>(</span><span>year</span><span>) {</span></span>
<span><span>    super</span><span>();</span></span>
<span><span>    this</span><span>.year </span><span>=</span><span> year;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>function</span><span> get_driving_requirements</span><span>(</span><span>vehicle</span><span>) {</span></span>
<span><span>  if</span><span> (vehicle </span><span>instanceof</span><span> Car</span><span>) {</span></span>
<span><span>    let</span><span> make </span><span>=</span><span> vehicle.make;</span></span>
<span><span>    let</span><span> brand </span><span>=</span><span> vehicle.brand;</span></span>
<span><span>    return</span><span> (</span></span>
<span><span>      "To drive the car "</span><span> +</span><span> make </span><span>+</span><span> " "</span><span> +</span><span> brand </span><span>+</span><span> ", your need a driver licence."</span></span>
<span><span>    );</span></span>
<span><span>  } </span><span>else</span><span> if</span><span> (vehicle </span><span>instanceof</span><span> Spaceship</span><span>) {</span></span>
<span><span>    return</span><span> "You need to be a NASA astronaut for that!"</span><span>;</span></span>
<span><span>  } </span><span>else</span><span> {</span></span>
<span><span>    let</span><span> brand </span><span>=</span><span> vehicle.brand;</span></span>
<span><span>    return</span><span> "Anybody can ride a "</span><span> +</span><span> brand </span><span>+</span><span> " skateboard!"</span><span>;</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>export</span><span> function</span><span> main</span><span>() {</span></span>
<span><span>  let</span><span> _pipe </span><span>=</span><span> new</span><span> Car</span><span>(</span><span>"Hyundai"</span><span>, </span><span>"Kona"</span><span>);</span></span>
<span><span>  let</span><span> _pipe$1 </span><span>=</span><span> get_driving_requirements</span><span>(_pipe);</span></span>
<span><span>  return</span><span> $io.</span><span>println</span><span>(_pipe$1);</span></span>
<span><span>}</span></span>
<span></span></code></pre>
<p>The JS code you’re getting is super understandable. You can read it, debug it
and understand how Gleam transforms Gleam code into Javascript code. There are
two important imports:</p>
<ol>
<li><code>$io</code>, which is library that matches what we have in the std lib <code>gleam/io</code>.</li>
<li><code>CustomType</code>, which is a class imported from <code>prelude.mjs</code>, that contains
stuff Gleam needs when operating in a Javascript context.</li>
</ol>
<h2 id="whats-next-with-gleam">What’s next with Gleam</h2>
<p>We spoke briefly about everything interesting with Gleam. As you may have
noticed, there’s nothing that I dislike, for now. I’ll keep experimenting while
doing <a href="https://app.codecrafters.io/join?via=Christopher2K">CodeCrafters puzzles</a>
(sponsored link). I’m currently building my own Redis with Gleam. Hit me up on
Twitter or Twitch if you want to talk about it.</p>  </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[NanoGPT: The simplest, fastest repository for training medium-sized GPTs (107 pts)]]></title>
            <link>https://github.com/karpathy/nanoGPT</link>
            <guid>40642871</guid>
            <pubDate>Tue, 11 Jun 2024 05:49:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/karpathy/nanoGPT">https://github.com/karpathy/nanoGPT</a>, See on <a href="https://news.ycombinator.com/item?id=40642871">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">nanoGPT</h2><a id="user-content-nanogpt" aria-label="Permalink: nanoGPT" href="#nanogpt"></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/nanoGPT/blob/master/assets/nanogpt.jpg"><img src="https://github.com/karpathy/nanoGPT/raw/master/assets/nanogpt.jpg" alt="nanoGPT"></a></p>
<p dir="auto">The simplest, fastest repository for training/finetuning medium-sized GPTs. It is a rewrite of <a href="https://github.com/karpathy/minGPT">minGPT</a> that prioritizes teeth over education. Still under active development, but currently the file <code>train.py</code> reproduces GPT-2 (124M) on OpenWebText, running on a single 8XA100 40GB node in about 4 days of training. The code itself is plain and readable: <code>train.py</code> is a ~300-line boilerplate training loop and <code>model.py</code> a ~300-line GPT model definition, which can optionally load the GPT-2 weights from OpenAI. That's it.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/karpathy/nanoGPT/blob/master/assets/gpt2_124M_loss.png"><img src="https://github.com/karpathy/nanoGPT/raw/master/assets/gpt2_124M_loss.png" alt="repro124m"></a></p>
<p dir="auto">Because the code is so simple, it is very easy to hack to your needs, train new models from scratch, or finetune pretrained checkpoints (e.g. biggest one currently available as a starting point would be the GPT-2 1.3B model from OpenAI).</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">install</h2><a id="user-content-install" aria-label="Permalink: install" href="#install"></a></p>
<div data-snippet-clipboard-copy-content="pip install torch numpy transformers datasets tiktoken wandb tqdm"><pre><code>pip install torch numpy transformers datasets tiktoken wandb tqdm
</code></pre></div>
<p dir="auto">Dependencies:</p>
<ul dir="auto">
<li><a href="https://pytorch.org/" rel="nofollow">pytorch</a> &lt;3</li>
<li><a href="https://numpy.org/install/" rel="nofollow">numpy</a> &lt;3</li>
<li><code>transformers</code> for huggingface transformers &lt;3 (to load GPT-2 checkpoints)</li>
<li><code>datasets</code> for huggingface datasets &lt;3 (if you want to download + preprocess OpenWebText)</li>
<li><code>tiktoken</code> for OpenAI's fast BPE code &lt;3</li>
<li><code>wandb</code> for optional logging &lt;3</li>
<li><code>tqdm</code> for progress bars &lt;3</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">quick start</h2><a id="user-content-quick-start" aria-label="Permalink: quick start" href="#quick-start"></a></p>
<p dir="auto">If you are not a deep learning professional and you just want to feel the magic and get your feet wet, the fastest way to get started is to train a character-level GPT on the works of Shakespeare. First, we download it as a single (1MB) file and turn it from raw text into one large stream of integers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python data/shakespeare_char/prepare.py"><pre>python data/shakespeare_char/prepare.py</pre></div>
<p dir="auto">This creates a <code>train.bin</code> and <code>val.bin</code> in that data directory. Now it is time to train your GPT. The size of it very much depends on the computational resources of your system:</p>
<p dir="auto"><strong>I have a GPU</strong>. Great, we can quickly train a baby GPT with the settings provided in the <a href="https://github.com/karpathy/nanoGPT/blob/master/config/train_shakespeare_char.py">config/train_shakespeare_char.py</a> config file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/train_shakespeare_char.py"><pre>python train.py config/train_shakespeare_char.py</pre></div>
<p dir="auto">If you peek inside it, you'll see that we're training a GPT with a context size of up to 256 characters, 384 feature channels, and it is a 6-layer Transformer with 6 heads in each layer. On one A100 GPU this training run takes about 3 minutes and the best validation loss is 1.4697. Based on the configuration, the model checkpoints are being written into the <code>--out_dir</code> directory <code>out-shakespeare-char</code>. So once the training finishes we can sample from the best model by pointing the sampling script at this directory:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py --out_dir=out-shakespeare-char"><pre>python sample.py --out_dir=out-shakespeare-char</pre></div>
<p dir="auto">This generates a few samples, for example:</p>
<div data-snippet-clipboard-copy-content="ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman."><pre><code>ANGELO:
And cowards it be strawn to my bed,
And thrust the gates of my threats,
Because he that ale away, and hang'd
An one with him.

DUKE VINCENTIO:
I thank your eyes against it.

DUKE VINCENTIO:
Then will answer him to save the malm:
And what have you tyrannous shall do this?

DUKE VINCENTIO:
If you have done evils of all disposition
To end his power, the day of thrust for a common men
That I leave, to fight with over-liking
Hasting in a roseman.
</code></pre></div>
<p dir="auto">lol  <code>¯\_(ツ)_/¯</code>. Not bad for a character-level model after 3 minutes of training on a GPU. Better results are quite likely obtainable by instead finetuning a pretrained GPT-2 model on this dataset (see finetuning section later).</p>
<p dir="auto"><strong>I only have a macbook</strong> (or other cheap computer). No worries, we can still train a GPT but we want to dial things down a notch. I recommend getting the bleeding edge PyTorch nightly (<a href="https://pytorch.org/get-started/locally/" rel="nofollow">select it here</a> when installing) as it is currently quite likely to make your code more efficient. But even without it, a simple train run could look as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0"><pre>python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0</pre></div>
<p dir="auto">Here, since we are running on CPU instead of GPU we must set both <code>--device=cpu</code> and also turn off PyTorch 2.0 compile with <code>--compile=False</code>. Then when we evaluate we get a bit more noisy but faster estimate (<code>--eval_iters=20</code>, down from 200), our context size is only 64 characters instead of 256, and the batch size only 12 examples per iteration, not 64. We'll also use a much smaller Transformer (4 layers, 4 heads, 128 embedding size), and decrease the number of iterations to 2000 (and correspondingly usually decay the learning rate to around max_iters with <code>--lr_decay_iters</code>). Because our network is so small we also ease down on regularization (<code>--dropout=0.0</code>). This still runs in about ~3 minutes, but gets us a loss of only 1.88 and therefore also worse samples, but it's still good fun:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py --out_dir=out-shakespeare-char --device=cpu"><pre>python sample.py --out_dir=out-shakespeare-char --device=cpu</pre></div>
<p dir="auto">Generates samples like this:</p>
<div data-snippet-clipboard-copy-content="GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear"><pre><code>GLEORKEN VINGHARD III:
Whell's the couse, the came light gacks,
And the for mought you in Aut fries the not high shee
bot thou the sought bechive in that to doth groan you,
No relving thee post mose the wear
</code></pre></div>
<p dir="auto">Not bad for ~3 minutes on a CPU, for a hint of the right character gestalt. If you're willing to wait longer, feel free to tune the hyperparameters, increase the size of the network, the context length (<code>--block_size</code>), the length of training, etc.</p>
<p dir="auto">Finally, on Apple Silicon Macbooks and with a recent PyTorch version make sure to add <code>--device=mps</code> (short for "Metal Performance Shaders"); PyTorch then uses the on-chip GPU that can <em>significantly</em> accelerate training (2-3X) and allow you to use larger networks. See <a href="https://github.com/karpathy/nanoGPT/issues/28" data-hovercard-type="issue" data-hovercard-url="/karpathy/nanoGPT/issues/28/hovercard">Issue 28</a> for more.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">reproducing GPT-2</h2><a id="user-content-reproducing-gpt-2" aria-label="Permalink: reproducing GPT-2" href="#reproducing-gpt-2"></a></p>
<p dir="auto">A more serious deep learning professional may be more interested in reproducing GPT-2 results. So here we go - we first tokenize the dataset, in this case the <a href="https://openwebtext2.readthedocs.io/en/latest/" rel="nofollow">OpenWebText</a>, an open reproduction of OpenAI's (private) WebText:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python data/openwebtext/prepare.py"><pre>python data/openwebtext/prepare.py</pre></div>
<p dir="auto">This downloads and tokenizes the <a href="https://huggingface.co/datasets/openwebtext" rel="nofollow">OpenWebText</a> dataset. It will create a <code>train.bin</code> and <code>val.bin</code> which holds the GPT2 BPE token ids in one sequence, stored as raw uint16 bytes. Then we're ready to kick off training. To reproduce GPT-2 (124M) you'll want at least an 8X A100 40GB node and run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py"><pre>torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py</pre></div>
<p dir="auto">This will run for about 4 days using PyTorch Distributed Data Parallel (DDP) and go down to loss of ~2.85. Now, a GPT-2 model just evaluated on OWT gets a val loss of about 3.11, but if you finetune it it will come down to ~2.85 territory (due to an apparent domain gap), making the two models ~match.</p>
<p dir="auto">If you're in a cluster environment and you are blessed with multiple GPU nodes you can make GPU go brrrr e.g. across 2 nodes like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Run on the first (master) node with example IP 123.456.123.456:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
# Run on the worker node:
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py"><pre><span><span>#</span> Run on the first (master) node with example IP 123.456.123.456:</span>
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py
<span><span>#</span> Run on the worker node:</span>
torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py</pre></div>
<p dir="auto">It is a good idea to benchmark your interconnect (e.g. iperf3). In particular, if you don't have Infiniband then also prepend <code>NCCL_IB_DISABLE=1</code> to the above launches. Your multinode training will work, but most likely <em>crawl</em>. By default checkpoints are periodically written to the <code>--out_dir</code>. We can sample from the model by simply <code>python sample.py</code>.</p>
<p dir="auto">Finally, to train on a single GPU simply run the <code>python train.py</code> script. Have a look at all of its args, the script tries to be very readable, hackable and transparent. You'll most likely want to tune a number of those variables depending on your needs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">baselines</h2><a id="user-content-baselines" aria-label="Permalink: baselines" href="#baselines"></a></p>
<p dir="auto">OpenAI GPT-2 checkpoints allow us to get some baselines in place for openwebtext. We can get the numbers as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py"><pre>$ python train.py config/eval_gpt2.py
$ python train.py config/eval_gpt2_medium.py
$ python train.py config/eval_gpt2_large.py
$ python train.py config/eval_gpt2_xl.py</pre></div>
<p dir="auto">and observe the following losses on train and val:</p>
<table>
<thead>
<tr>
<th>model</th>
<th>params</th>
<th>train loss</th>
<th>val loss</th>
</tr>
</thead>
<tbody>
<tr>
<td>gpt2</td>
<td>124M</td>
<td>3.11</td>
<td>3.12</td>
</tr>
<tr>
<td>gpt2-medium</td>
<td>350M</td>
<td>2.85</td>
<td>2.84</td>
</tr>
<tr>
<td>gpt2-large</td>
<td>774M</td>
<td>2.66</td>
<td>2.67</td>
</tr>
<tr>
<td>gpt2-xl</td>
<td>1558M</td>
<td>2.56</td>
<td>2.54</td>
</tr>
</tbody>
</table>
<p dir="auto">However, we have to note that GPT-2 was trained on (closed, never released) WebText, while OpenWebText is just a best-effort open reproduction of this dataset. This means there is a dataset domain gap. Indeed, taking the GPT-2 (124M) checkpoint and finetuning on OWT directly for a while reaches loss down to ~2.85. This then becomes the more appropriate baseline w.r.t. reproduction.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">finetuning</h2><a id="user-content-finetuning" aria-label="Permalink: finetuning" href="#finetuning"></a></p>
<p dir="auto">Finetuning is no different than training, we just make sure to initialize from a pretrained model and train with a smaller learning rate. For an example of how to finetune a GPT on new text go to <code>data/shakespeare</code> and run <code>prepare.py</code> to download the tiny shakespeare dataset and render it into a <code>train.bin</code> and <code>val.bin</code>, using the OpenAI BPE tokenizer from GPT-2. Unlike OpenWebText this will run in seconds. Finetuning can take very little time, e.g. on a single GPU just a few minutes. Run an example finetuning like:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python train.py config/finetune_shakespeare.py"><pre>python train.py config/finetune_shakespeare.py</pre></div>
<p dir="auto">This will load the config parameter overrides in <code>config/finetune_shakespeare.py</code> (I didn't tune them much though). Basically, we initialize from a GPT2 checkpoint with <code>init_from</code> and train as normal, except shorter and with a small learning rate. If you're running out of memory try decreasing the model size (they are <code>{'gpt2', 'gpt2-medium', 'gpt2-large', 'gpt2-xl'}</code>) or possibly decreasing the <code>block_size</code> (context length). The best checkpoint (lowest validation loss) will be in the <code>out_dir</code> directory, e.g. in <code>out-shakespeare</code> by default, per the config file. You can then run the code in <code>sample.py --out_dir=out-shakespeare</code>:</p>
<div data-snippet-clipboard-copy-content="THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold."><pre><code>THEODORE:
Thou shalt sell me to the highest bidder: if I die,
I sell thee to the first; if I go mad,
I sell thee to the second; if I
lie, I sell thee to the third; if I slay,
I sell thee to the fourth: so buy or sell,
I tell thee again, thou shalt not sell my
possession.

JULIET:
And if thou steal, thou shalt not sell thyself.

THEODORE:
I do not steal; I sell the stolen goods.

THEODORE:
Thou know'st not what thou sell'st; thou, a woman,
Thou art ever a victim, a thing of no worth:
Thou hast no right, no right, but to be sold.
</code></pre></div>
<p dir="auto">Whoa there, GPT, entering some dark place over there. I didn't really tune the hyperparameters in the config too much, feel free to try!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">sampling / inference</h2><a id="user-content-sampling--inference" aria-label="Permalink: sampling / inference" href="#sampling--inference"></a></p>
<p dir="auto">Use the script <code>sample.py</code> to sample either from pre-trained GPT-2 models released by OpenAI, or from a model you trained yourself. For example, here is a way to sample from the largest available <code>gpt2-xl</code> model:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py \
    --init_from=gpt2-xl \
    --start=&quot;What is the answer to life, the universe, and everything?&quot; \
    --num_samples=5 --max_new_tokens=100"><pre>python sample.py \
    --init_from=gpt2-xl \
    --start=<span><span>"</span>What is the answer to life, the universe, and everything?<span>"</span></span> \
    --num_samples=5 --max_new_tokens=100</pre></div>
<p dir="auto">If you'd like to sample from a model you trained, use the <code>--out_dir</code> to point the code appropriately. You can also prompt the model with some text from a file, e.g. <code>python sample.py --start=FILE:prompt.txt</code>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">efficiency notes</h2><a id="user-content-efficiency-notes" aria-label="Permalink: efficiency notes" href="#efficiency-notes"></a></p>
<p dir="auto">For simple model benchmarking and profiling, <code>bench.py</code> might be useful. It's identical to what happens in the meat of the training loop of <code>train.py</code>, but omits much of the other complexities.</p>
<p dir="auto">Note that the code by default uses <a href="https://pytorch.org/get-started/pytorch-2.0/" rel="nofollow">PyTorch 2.0</a>. At the time of writing (Dec 29, 2022) this makes <code>torch.compile()</code> available in the nightly release. The improvement from the one line of code is noticeable, e.g. cutting down iteration time from ~250ms / iter to 135ms / iter. Nice work PyTorch team!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">todos</h2><a id="user-content-todos" aria-label="Permalink: todos" href="#todos"></a></p>
<ul dir="auto">
<li>Investigate and add FSDP instead of DDP</li>
<li>Eval zero-shot perplexities on standard evals (e.g. LAMBADA? HELM? etc.)</li>
<li>Finetune the finetuning script, I think the hyperparams are not great</li>
<li>Schedule for linear batch size increase during training</li>
<li>Incorporate other embeddings (rotary, alibi)</li>
<li>Separate out the optim buffers from model params in checkpoints I think</li>
<li>Additional logging around network health (e.g. gradient clip events, magnitudes)</li>
<li>Few more investigations around better init etc.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">troubleshooting</h2><a id="user-content-troubleshooting" aria-label="Permalink: troubleshooting" href="#troubleshooting"></a></p>
<p dir="auto">Note that by default this repo uses PyTorch 2.0 (i.e. <code>torch.compile</code>). This is fairly new and experimental, and not yet available on all platforms (e.g. Windows). If you're running into related error messages try to disable this by adding <code>--compile=False</code> flag. This will slow down the code but at least it will run.</p>
<p dir="auto">For some context on this repository, GPT, and language modeling it might be helpful to watch my <a href="https://karpathy.ai/zero-to-hero.html" rel="nofollow">Zero To Hero series</a>. Specifically, the <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="nofollow">GPT video</a> is popular if you have some prior language modeling context.</p>
<p dir="auto">For more questions/discussions feel free to stop by <strong>#nanoGPT</strong> on Discord:</p>
<p dir="auto"><a href="https://discord.gg/3zy8kqD9Cp" rel="nofollow"><img src="https://camo.githubusercontent.com/f3b057ade47ec925300af6567ec645a7a1178b1a823f6285daf317cd42cb1fb9/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f337a79386b71443943703f636f6d706163743d74727565267374796c653d666c6174" alt="" data-canonical-src="https://dcbadge.vercel.app/api/server/3zy8kqD9Cp?compact=true&amp;style=flat"></a></p>
<p dir="auto"><h2 tabindex="-1" dir="auto">acknowledgements</h2><a id="user-content-acknowledgements" aria-label="Permalink: acknowledgements" href="#acknowledgements"></a></p>
<p dir="auto">All nanoGPT experiments are powered by GPUs on <a href="https://lambdalabs.com/" rel="nofollow">Lambda labs</a>, my favorite Cloud GPU provider. Thank you Lambda labs for sponsoring nanoGPT!</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[British duo arrested for SMS phishing via homemade cell tower (173 pts)]]></title>
            <link>https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/</link>
            <guid>40642801</guid>
            <pubDate>Tue, 11 Jun 2024 05:40:13 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/">https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/</a>, See on <a href="https://news.ycombinator.com/item?id=40642801">Hacker News</a></p>
Couldn't get https://www.cityoflondon.police.uk/news/city-of-london/news/2024/june/two-people-arrested-in-connection-with-investigation-into-homemade-mobile-antenna-used-to-send-thousands-of-smishing-text-messages-to-the-public/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[DuckDB Isn't Just Fast (101 pts)]]></title>
            <link>https://csvbase.com/blog/6</link>
            <guid>40642476</guid>
            <pubDate>Tue, 11 Jun 2024 04:51:55 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://csvbase.com/blog/6">https://csvbase.com/blog/6</a>, See on <a href="https://news.ycombinator.com/item?id=40642476">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
        <!-- DuckDB is more than just fast -->
<p>DuckDB is a single file SQL database.  It's designed for data analysis and so,
probably because of the bent of people who are into that sort of thing, a lot
of the evaluations of it end up being quantitative.  This isn't just true of
DuckDB - most comparisons of most data tools tend to focus on the measureable.</p>
<p>That means they
<a href="https://medium.com/@kayrnt/how-duckdb-can-be-up-to-1000x-more-efficient-than-bigquery-36bab2405259">mainly</a>
<a href="https://github.com/prrao87/duckdb-study">look</a>
<a href="https://www.fivetran.com/blog/how-fast-is-duckdb-really">at</a>
<a href="https://duckdblabs.github.io/db-benchmark/">speed</a>.  And DuckDB generally does
well.</p>
<p>The notes on benchmark performance graphs often read "higher is better" and
performance improvements are even called "optimisations".  But the truth is, at
least as a user, once performance reaches a satisfactory level - enough for
your own data analysis to complete in a reasonable about of time - there is no
further benefit from increased speed.  Instead of being called "performance
optimisation" it should probably be called "performance satisfaction" as once
it is satisfactory you have finished.</p>
<p>Usability is different.  The whole point of computers is as an aid to
productivity so user-friendliness is actually the bit you want to optimise.
Unlike speed, being easier to use is always better and there is very little
limit to that.  So it's "usability improvements" that should be called
"optimisations" but perhaps the relevant ships on all of these terms have
sailed.</p>
<p>Anyway to balance out the force out I want to demonstrate some usability
benefits of DuckDB.  Mostly, they cannot be measured:</p>
<ol>
<li>Good developer ergonomics</li>
<li>It handles larger than memory ("out of core") datasets</li>
<li>Easy to install &amp; run</li>
</ol>
<h2>Ergonomics</h2>
<p>DuckDB takes care to make the common stuff straightward.  For example, you can
create tables (including inferring the table schema) straight from <a href="https://csvbase.com/meripaterson/stock-exchanges">input
files</a>:</p>
<div><pre><span></span><span>-- loading a table from a parquet file</span>
<span>CREATE</span><span> </span><span>TABLE</span><span> </span><span>stock_exchanges</span><span> </span><span>AS</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_parquet</span><span>(</span><span></span>
<span>        </span><span>"https://csvbase.com/meripaterson/stock-exchanges.parquet"</span><span></span>
<span>);</span><span></span>
</pre></div>
<p>Looking at the schema of that table:</p>
<div><pre><span></span><span>-- the output of: .schema stock_exchanges</span>
<span>CREATE</span><span> </span><span>TABLE</span><span> </span><span>stock_exchanges</span><span> </span><span>(</span><span></span>
<span>    </span><span>csvbase_row_id</span><span> </span><span>bigint</span><span>,</span><span></span>
<span>    </span><span>Continent</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>Country</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>"Name"</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>MIC</span><span> </span><span>varchar</span><span>,</span><span></span>
<span>    </span><span>"Last changed"</span><span> </span><span>date</span><span></span>
<span>);</span><span></span>
</pre></div>
<p>DuckDB has inferred all the columns, including their types, from the Parquet
file.  Brill.  And as you can see, that Parquet file can come from anywhere on
the web, it need not be local.  That's perhaps not a big advance on some of the
common dataframe libraries, but it is a big advance in the world of SQL-based
tools, most of which can only read CSV (not Parquet) and then also require the
schema to be created beforehand.</p>
<p>And you don't actually have to create a table first in order to query the data.
The <code>read_parquet</code> function returns a relation and so can act as a sub-query.
A specific example of that, this time with a csv file:</p>
<div><pre><span></span><span>-- pulling down the most recent EUR:USD exchange rate</span>
<span>SELECT</span><span></span>
<span>    </span><span>rate</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_csv_auto</span><span>(</span><span>"https://csvbase.com/table-munger/eurofxref.csv"</span><span>)</span><span></span>
<span>WHERE</span><span></span>
<span>    </span><span>currency</span><span> </span><span>=</span><span> </span><span>'USD'</span><span>;</span><span></span>
</pre></div>
<p>So you can freely query parquet and csv files on the web with the minimum of
fuss.</p>
<p>But how much of SQL does DuckDB support?  A very wide swathe.  I haven't done
any comprehensive analysis but of the stuff I use in Postgres I haven't found
much if anything that isn't also implemented in DuckDB.</p>
<p>For example, window functions are fully supported:</p>
<div><pre><span></span><span>-- smoothed history of the eur:usd exchange rate</span>
<span>SELECT</span><span></span>
<span>    </span><span>date</span><span>,</span><span></span>
<span>    </span><span>avg</span><span>(</span><span>rate</span><span>)</span><span> </span><span>OVER</span><span> </span><span>(</span><span></span>
<span>        </span><span>ORDER</span><span> </span><span>BY</span><span> </span><span>date</span><span></span>
<span>        </span><span>ROWS</span><span> </span><span>BETWEEN</span><span> </span><span>100</span><span> </span><span>PRECEDING</span><span> </span><span>AND</span><span> </span><span>CURRENT</span><span> </span><span>ROW</span><span></span>
<span>    </span><span>)</span><span> </span><span>AS</span><span> </span><span>rolling</span><span></span>
<span>FROM</span><span></span>
<span>    </span><span>read_parquet</span><span>(</span><span>'https://csvbase.com/table-munger/eurofxref-hist.parquet'</span><span>)</span><span></span>
<span>WHERE</span><span></span>
<span>    </span><span>currency</span><span> </span><span>=</span><span> </span><span>'USD'</span><span>;</span><span></span>
</pre></div>
<p>And that's not the end of DuckDB making the simple stuff easy.  I did the above
query at the library on a slow internet connection and DuckDB helpfully started
to display a progress bar, which even Postgres doesn't have.</p>
<p>Then, when the query was done it politely avoided swamping my terminal with the
6500 lines of output by abbreviating them, just like Pandas does.</p>
<h2>Datasets larger than memory</h2>
<p>One of the problems that arises with more than a few data tools is that once
the dataset gets bigger than the computer memory (or gets within 50%) the tool
breaks down.</p>
<p>This is an underrated source of pain.  Sometimes I've seen someone write
something quickly with one tool as a quick prototype.  The prototype works
great and you want to run it on the full dataset - but wait - you can't.
You're getting memory errors, heavy swapping, etc.  The problem is that the
tool was loading the whole dataset into memory and so suddenly you have to
change technology.  Always an unpleasant discovery.</p>
<p>DuckDB fully supports datasets larger than memory.  That's in contrast to
Pandas, which starts to struggle once your dataframe is &gt;50% of system memory.
The majority of dataframe libraries do not support datasets larger than memory
or require <a href="https://docs.pola.rs/user-guide/concepts/streaming/">alternate, more limited, modes of
operation</a> when using
them - but in DuckDB everything works.</p>
<h2>Single file, single machine model - and the magic of WASM</h2>
<p>DuckDB (which, like <a href="https://github.com/calpaterson/csvbase">csvbase</a>, is <a href="https://github.com/duckdb/duckdb/">an
open source project</a>) gets compiled to a
single executable file, <code>duckdb</code>.  That means trying it out just means copying
<code>duckdb</code> onto your computer and running it.  Find the right executable for your
machine <a href="https://duckdb.org/docs/installation/">here</a>.</p>
<p>But it actually gets even easier than that.  Through the magic of
<a href="https://en.wikipedia.org/wiki/WebAssembly">WASM</a> you can experience the full
majesty of DuckDB directly in your browser on
<a href="https://shell.duckdb.org/">shell.duckdb.org</a>!</p>
<p><img src="https://csvbase.com/blog-static/shelldotduckdbdotorg.png" alt="screenshot of shell.duckdb.org in a web browser"></p>
<p><code>shell.duckdb.org</code> is an based on the <a href="https://en.wikipedia.org/wiki/WebAssembly">WASM (aka
WebAssembly)</a> target of the <code>duckdb</code>
build.  WASM is a newish binary format that allows you to run native code
(think: <code>.exe</code> files) inside a web browser.  It's <a href="https://www.usenix.org/conference/atc19/presentation/jangda">not quite as fast as real
native code</a>, but
it's usually close enough and has the key advantage that you can execute random
binaries in a sandboxed virtual machine - mostly without rewriting them.</p>
<p>As a result <code>shell.duckdb.org</code> is fully powered - it can be because everything
is running in your browser, not on a server.  You can use <code>shell.duckdb.org</code> to
import files off the web, you have the full SQL dialect, you can execute
long-running queries, whatever you want.  And you can even share sessions as
links.  Try this one:</p>
<p><a href="https://shell.duckdb.org/#queries=v0,select-*-from-read_parquet(%22https%3A%2F%2Fcsvbase.com%2Fmeripaterson%2Fstock%20exchanges.parquet%22)~">https://shell.duckdb.org/#queries=v0,select-*-from-read_parquet(%22https%3A%2F%2Fcsvbase.com%2Fmeripaterson%2Fstock%20exchanges.parquet%22)~</a></p>
<h2>DuckDB as a lo-fi dataframe library</h2>
<p>DuckDB also has good quality integration with the lingua franca of data
analysis.  For better or worse that means: Python.</p>
<p>First, install the DuckDB python library (and csvbase's client, which I will
use later).</p>
<div><pre><span></span>pip install duckdb csvbase-client
</pre></div>
<p>Now you can execute queries inside Python:</p>
<div><pre><span></span><span>import</span> <span>duckdb</span>

<span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"select 1"</span><span>)</span>
</pre></div>
<p>Easy enough.  But there is one more trick: you can query return values.</p>
<p>That means you you can start to do imperative-style programming to build up a
bigger data operation step by step - in an analogous way to how you would write
dataframe code.  A worked example:</p>
<div><pre><span></span><span># get all stock exchanges</span>
<span>stock_exchanges</span> <span>=</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>'''</span>
<span>    SELECT</span>
<span>        *</span>
<span>    FROM</span>
<span>        read_parquet(</span>
<span>            "https://csvbase.com/meripaterson/stock-exchanges.parquet"</span>
<span>        )</span>
<span>'''</span><span>)</span>

<span># exclude non-North American exchanges</span>
<span>na_stock_exchanges</span> <span>=</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>    SELECT</span>
<span>        *</span>
<span>    FROM</span>
<span>        stock_exchanges -- a variable reference to the above</span>
<span>    WHERE</span>
<span>        "Continent" = 'North America'</span>
<span>"""</span><span>)</span>

<span># get the MIC codes as a Python set</span>
<span>na_mic_codes</span> <span>=</span> <span>{</span>
    <span>t</span><span>[</span><span>0</span><span>]</span> <span>for</span> <span>t</span> <span>in</span> <span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>        SELECT</span>
<span>            "MIC"</span>
<span>        FROM</span>
<span>            na_stock_exchanges</span>
<span>    """</span><span>)</span><span>.</span><span>fetchall</span><span>()</span> <span>if</span> <span>t</span> <span>is</span> <span>not</span> <span>None</span>
<span>}</span>
</pre></div>
<p>Allowing for dataframe-style programming starts to bridge the benefits of SQL
with the benefits of dataframes.  You get all the benefits of SQL:</p>
<ol>
<li>Lazy evaluation</li>
<li>The query planner (ie: an optimising compiler)</li>
<li>That SQL is already very well known</li>
</ol>
<p>And then you also get the benefits of dataframes</p>
<ol start="4">
<li>
Easy to write larger programs by doing larger operations step-by-step<ul>
<li><em>without</em> resorting to string concat tricks or sprocs</li>
</ul>
</li>
<li>
Can use an imperative language to build up your data operation<ul>
<li>and wrap it</li>
</ul>
</li>
</ol>
<p>That's not to say that this is a fully developed replacement for Pandas.
Pandas' API still does a lot more than just this.  But being able to build up
larger programs using the dataframe-style of programming certainly makes them
easier to write.</p>
<h2>Saving your game with csvbase (fsspec)</h2>
<p>I <a href="https://csvbase.com/blog/7">wrote before</a> about how csvbase's client library
is designed to slot in to anything by being written against a standard API
called "fsspec".  I gave <a href="https://csvbase.com/faq/pandas">Pandas</a>, Polars and Dask as examples but
the same is true for <a href="https://csvbase.com/faq/duckdb">DuckDB</a>:</p>
<div><pre><span></span><span>import</span> <span>duckdb</span><span>,</span> <span>fsspec</span>

<span># you'd put this bit into __init__.py</span>
<span>duckdb</span><span>.</span><span>register_filesystem</span><span>(</span><span>fsspec</span><span>.</span><span>filesystem</span><span>(</span><span>'csvbase'</span><span>))</span>

<span>duckdb</span><span>.</span><span>sql</span><span>(</span><span>"""</span>
<span>    COPY stock_exchanges TO</span>
<span>    'csvbase://calpaterson/duckdb-example?public=true' (HEADER, DELIMITER ',')</span>
<span>"""</span><span>)</span>
</pre></div>
<p>And it's not just csvbase that implements fsspec but plenty of others like
Google Drive, SFTP, HFDS - there are lots and lots of implementations.  Find a
list of them this way:</p>
<div><pre><span></span><span>from</span> <span>fsspec.registry</span> <span>import</span> <span>known_implementations</span><span>;</span> <span>import</span> <span>pprint</span>

<span>pprint</span><span>.</span><span>pprint</span><span>(</span><span>known_implementations</span><span>)</span>
</pre></div>
<p>The majority of Python-based data libraries have support for fsspec so this is
nothing particularly special - but it's just nice to know that DuckDB can
easily plug into anything that already has an fsspec implementation.</p>
<h2>Scale - "lower is better"</h2>
<p>After speed, the next much-discussed quantitative dimension is "scalability".
Scale is probably an even more vexed topic than speed because while more speed
is not always better it at least does no harm.  Greater scale though, usually
comes with greater complexity.</p>
<p>DuckDB does not scale to thousands of machines.  Apache Spark does though, and
is now the established "big tech company" way to do larger data analyses.  But
the hassle involved in Spark is actually considerable.  Even the cloud services
that take a huge bite out of your team's monthly budget don't really make all
of the hassle go away.</p>
<p>In my view, scale is not just a one-way road.  Scaling <em>down</em> is just as
important - perhaps more - than scaling <em>up</em>.  Down, down, down - to a single
person trying to get stuff done, not an uncommon scale in the field of data
analysis.</p>
<p>DuckDB operates on this scale and it requires very little of you.  If you're
doing data analysis you probably already know SQL.  DuckDB supports
larger-than-memory data. And there isn't a lot to install.  That makes it a
highly desirable alternative to full blown Spark code for many many cases.</p>
<h2>See also</h2>
<p>csvbase now supports <a href="https://csvbase.com/faq/git">tables backed by git
repos</a>.  It's a nice way to get both easy reads
and writes as well as change history of git.  You can also use it to publish csv
files from repos onto the web (including private repos).</p>
<p>As I mentioned, <code>csvbase-client</code> <a href="https://csvbase.com/faq/duckdb">works with
DuckDB</a> via <a href="https://csvbase.com/blog/7">the magic of
fsspec</a>.  That includes the
<a href="https://csvbase.com/faq/csvbase-client-cache">cache</a> - so repeated references to a table don't
pointlessly re-download it each time.</p>
<p>I'm pretty interested in WASM.  Perhaps it would be possible to allow people to
upload their data cleanup/transformation scripts as wasm binaries and run them
on csvbase each time an upstream dataset changed?  <a href="mailto:cal@calpaterson.com">Write to
me</a> if you're interested in this.</p>
<p>DuckDB seems to have come out of the Netherland's national computer science and
maths institute,
<a href="https://en.wikipedia.org/wiki/Centrum_Wiskunde_%26_Informatica">CWI</a>.  Many
other columar databases have links with CWI, including
<a href="https://en.wikipedia.org/wiki/MonetDB">MonetDB</a> as well as
<a href="https://www.cwi.nl/en/news/cwi-born-technology-behind-record-ipo-company-snowflake/">Snowflake</a>.
Clearly there is something in the water at CWI.</p>
<p>DuckDB is obviously influenced by SQLite.  What's the difference?  SQLite uses a
<a href="https://calpaterson.com/how-a-sql-database-works.html">more traditional "row store" storage
system</a> which is ideal
for transaction-heavy workloads but less amenable to data analysis workloads
then the columnar form of DuckDB.</p>

      </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[macOS 15.0 supports Nested Virtualization on M3 chips (130 pts)]]></title>
            <link>https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported</link>
            <guid>40642328</guid>
            <pubDate>Tue, 11 Jun 2024 04:26:29 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported">https://developer.apple.com/documentation/virtualization/vzgenericplatformconfiguration/4360553-isnestedvirtualizationsupported</a>, See on <a href="https://news.ycombinator.com/item?id=40642328">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Biodiversity enhances immune regulation among daycare children (2020) (120 pts)]]></title>
            <link>https://www.science.org/doi/10.1126/sciadv.aba2578</link>
            <guid>40641704</guid>
            <pubDate>Tue, 11 Jun 2024 02:38:36 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.science.org/doi/10.1126/sciadv.aba2578">https://www.science.org/doi/10.1126/sciadv.aba2578</a>, See on <a href="https://news.ycombinator.com/item?id=40641704">Hacker News</a></p>
Couldn't get https://www.science.org/doi/10.1126/sciadv.aba2578: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Noam Chomsky 'no longer able to talk' after 'medical event' (267 pts)]]></title>
            <link>https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html</link>
            <guid>40641361</guid>
            <pubDate>Tue, 11 Jun 2024 01:39:35 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html">https://www.independent.co.uk/arts-entertainment/books/news/noam-chomsky-health-update-tributes-b2559831.html</a>, See on <a href="https://news.ycombinator.com/item?id=40641361">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="main"><div data-newsletter-key="receiveIndyBreakingNews"><p><img src="https://static.independent.co.uk/static-assets/images/newsletter/breaking-news/breaking-news-thumb.png" loading="lazy" alt="Breaking News"></p><div><p><h3 data-nosnippet="">For free real time breaking news alerts sent straight to your inbox sign up to our breaking news emails</h3><h3 data-nosnippet="">Sign up to our free breaking news emails</h3></p></div></div><p><a href="https://www.independent.co.uk/topic/noam-chomsky">Noam Chomsky</a>’s health has deterioriated following a medical event, leaving him unable to communicate, his former assistant has revealed. </p><p>The 95-year-old famed linguist has not been seen in public since June last year, with many commenting on the weight of his absence from the broader debate <a href="https://www.independent.co.uk/news/world/middle-east/israel-children-un-military-hamas-b2558864.html">surrounding the war</a> in <a href="https://www.independent.co.uk/topic/gaza">Gaza</a>. </p><p>Chomsky, who has been vocal about his support for the Palestinian cause and what he has called the “crimes” of the Israeli state, has been <a href="https://www.independent.co.uk/climate-change/news/trump-climate-change-noam-chomsky-book-interview-hitler-robert-pollin-b1374789.html">notably absent from demonstrations and discussions </a>on the issue over the last year. </p><p>In a <a rel="nofollow" target="_blank" href="https://www.facebook.com/MediaLensUK/posts/861747505988619">post shared by <em>Media Lens</em>,</a> it was revealed that the MIT professor is unlikely to ever return to the public eye following the deterioration of his health. </p><p>The post quoted Professor Chomsky’s former assistant Bev Stohl, who first shared<a rel="nofollow" target="_blank" href="https://www.reddit.com/r/chomsky/comments/1aj56hj/updates_on_noams_health_from_his_longtime_mit/"> the news on a reddit forum</a> as she explained why the usually responsive academic “hasn’t been returning emails, or interviewing”. </p><p>Stohl, who worked as Chomsky’s office manager at MIT for 24 years until her retirement in 2017, wrote on 5 February: “I’m in contact with a close family member, and we know the basics, and hope to know more in the near future. </p><p>“In a nutshell, Noam is 95-years-old and suffered a medical event in June. As many have noticed, he has not been writing, corresponding, or interviewing, as his health situation has taken the majority of his time and energy. </p><p>“He is still with us, now watching the news (he doesn’t look happy about what he’s watching).”</p><p>Stohl shared further details on the linguist’s ability to communicate, adding that he was no longer mobile or walking either.</p><div><figure><p><img src="https://static.independent.co.uk/2024/06/10/13/newFile.jpg" srcset="https://static.independent.co.uk/2024/06/10/13/newFile.jpg?quality=75&amp;width=320&amp;auto=webp 320w, https://static.independent.co.uk/2024/06/10/13/newFile.jpg?quality=75&amp;width=640&amp;auto=webp 640w" loading="lazy" alt="" on="tap:auto-image-gallery,inline-image-carousel.goToSlide(index=0)" tabindex="0" role="button" data-gallery-length="2"></p><figcaption><span>(<!-- -->AFP via Getty Images<!-- -->)</span></figcaption></figure></div><p>“His ability to speak is complicated by factors I can’t yet disclose,” she continued. “When the relative I’m in touch with visited him a month ago, he did not communicate with her. </p><p>“He is not ambulatory. I’m not sure for how long this will go on. He is not in pain. His eyes are open and he seems to be watching what’s happening around him.”</p><p>The assistant, who also wrote a memoir titled <em>Chomsky and Me</em> on her time working with the world-renowned thinker, provided an update in April as she wrote, “Noam has not made significant progress, I’m sorry to say. I doubt he will be able to return to the public eye, as he is not communicating much if at all.”</p><div><blockquote><p lang="en" dir="ltr">Chomsky has been unbelievably kind over the years I've known him. He treats everyone as an equal. Doesn't care who you are. He would give as much of his time to a high school student as some celebrity or NYT reporter. And devoted himself to attacking cruelty and injustice. <a rel="nofollow" target="_blank" href="https://t.co/6aQBZSSSQX">https://t.co/6aQBZSSSQX</a></p>— Nathan J Robinson (@NathanJRobinson) <a rel="nofollow" target="_blank" href="https://twitter.com/NathanJRobinson/status/1799518761063465286?ref_src=twsrc%5Etfw">June 8, 2024</a></blockquote> </div><p>Some of the comments have since been deleted as Stohl edited a post to say that Chomsky’s “family is very private” and she will “no longer be adding to this discussion”. </p><p><em>The Independent</em> has contacted Noam Chomsky and his literary agent for comment. </p><p>Tributes have poured in from across the media industry as many noted the linguist’s passion for language, having dedicated over seven decades to the study of words and communication, and expressed sadness at his now limited ability.</p><p>Nathan Robinson, founder and editor of socialist magazine, <em>Current Affairs</em>, is also co-author of Chomsky’s forthcoming book, <em>The Myth of American Idealism: How US Foreign Policy Endangers the World</em>. He wrote: “Chomsky has been unbelievably kind over the years I’ve known him. </p><p>“He treats everyone as an equal. Doesn’t care who you are. He would give as much of his time to a high school student as some celebrity or <em>NYT</em> reporter. And devoted himself to attacking cruelty and injustice.</p><p>“So many thousands of people have stories about how he has changed their lives. He certainly changed mine.”</p><p>British-American journalist and <em>Zeteo</em> founder Mehdi Hasan added, “Sending prayers Noam’s way. There has been no one else like him in our lifetime.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Ship Something Every Day (185 pts)]]></title>
            <link>https://maxleiter.com/blog/ship-every-day</link>
            <guid>40640927</guid>
            <pubDate>Tue, 11 Jun 2024 00:28:25 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://maxleiter.com/blog/ship-every-day">https://maxleiter.com/blog/ship-every-day</a>, See on <a href="https://news.ycombinator.com/item?id=40640927">Hacker News</a></p>
<div id="readability-page-1" class="page"><article><h2>Ship something every day</h2><p><strong>Edit</strong>: A better title would've been "<em>commit</em> every day <em>that you work</em>". I don't mean you should work on weekends or not take time off, and
whatever you work on doesn't need to "ship to prod".</p>
<hr>
<p>I don't feel particularly qualified to give advice (I blame imposter syndrome),
but I do have one tip to share that I think has been useful for me.
It applies both to professional software dev and personal projects.</p>
<p>You probably guessed it from the title: <strong>ship something every day</strong>.</p>
<p>It doesn't need to be a major feature or even a bug fix. It just needs to be something you can point to.</p>
<p>Why? A few reasons:</p>
<ul>
<li>The dopamine rush of your code being shipped</li>
<li>Your team sees you're working<!-- -->
<ul>
<li>There's more to this than just performance reviews; with remote work, it's easy for you and co-workers to feel isolated.</li>
</ul>
</li>
<li>It encourages incremental work. Your future self and co-workers will thank you</li>
<li>Your git commit streak looks good<!-- -->
<ul>
<li>Yes, people say this doesn't matter. But I'm sure people like recruiters look at GitHub profiles, and an empty page isn't a great look.</li>
</ul>
</li>
<li>The satisfaction and mental benefits of getting something done.</li>
</ul>
<br>
</article></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Siberia's 'mammoth graveyard' reveals 800-year human interactions with mammoths (122 pts)]]></title>
            <link>https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html</link>
            <guid>40640833</guid>
            <pubDate>Tue, 11 Jun 2024 00:15:00 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html">https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html</a>, See on <a href="https://news.ycombinator.com/item?id=40640833">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
										
<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/siberias-mammoth-grave-1.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/siberias-mammoth-grave-1.jpg" data-sub-html="Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/siberias-mammoth-grave-1.jpg" alt="Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts" title="Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024." width="800" height="530">
             <figcaption>
                Location of the Berelekh geoarchaeological complex within map view, b) termokarst landscape of the surrounding area, c) riverbank within the complex with mammoth bones on the water edge. Credit: Pitulko et al. 2024.
            </figcaption>        </figure>
    </div><p>Woolly mammoths are evocative of a bygone era, when Earth was gripped within an Ice Age. Current knowledge places early mammoth ancestors in the Pliocene (2.58–5.33 million years ago, Ma) before their populations expanded in the Pleistocene (2.58 Ma–11,700 years ago, kyr). However, as climate changed, their numbers dwindled to isolated populations in modern Siberia and Alaska, until their last dated survival 4 kyr ago.</p>


										      
																																	
<p>In the East Siberian Arctic (&gt;70 °N), there is not only evidence of significant woolly mammoth populations, but also how humans interacted with them, the focus of <a href="https://linkinghub.elsevier.com/retrieve/pii/S0277379124001938" target="_blank">new research</a> in <i>Quaternary Science Reviews</i>.</p>
<p>Along the Berelekh River, Russia, a 'mammoth graveyard' can be found. Here, thousands of disarticulated bones, representing a minimum of 156 individual mammoths, found alongside an <a href="https://phys.org/tags/archaeological+site/" rel="tag">archaeological site</a> indicate the close proximity of these two communities, forming the Berelekh geoarchaeological complex.</p>
<p>Dr. Vladimir Pitulko, of the Russian Academy of Sciences, and colleagues aimed to assess the relationship between the 'mammoth graveyard' and the archaeological site through a re-examination of stratigraphic and paleogeographic data obtained in 2009, with new fieldwork focused on the left riverbanks where <a href="https://phys.org/tags/mammoth+bones/" rel="tag">mammoth bones</a> have readily yielded from their home in the sediment and appeared on the water's edge. Alongside them are remains of Pleistocene hare, Arctic fox and wolves, as well as soot and charcoal from hearths and worked mammoth tusks (one being an unfinished throwing spear).</p>

																																						
																																			<p>The researchers suggest humans created these bone accumulations as a byproduct of the production of mammoth ivory technology, while hares may have been targeted for fur to produce winter clothing.</p>
<p>Notably, evidence of blowfly pupae activity on cavities in skulls and bones is indicative that the mammoth carcasses were added to the 'graveyard' de-fleshed. Indeed, there appears to be evidence of sorting of the bones, with only the most valuable transported to Berelekh from the area in which the mammoth was killed, leaving behind parts such as spinal columns, carpal ('hand') and tarsal ('foot') bones.</p>

<div data-thumb="https://scx1.b-cdn.net/csz/news/tmb/2024/siberias-mammoth-grave.jpg" data-src="https://scx2.b-cdn.net/gfx/news/hires/2024/siberias-mammoth-grave.jpg" data-sub-html="a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.">
        <figure>
            <img src="https://scx1.b-cdn.net/csz/news/800a/2024/siberias-mammoth-grave.jpg" alt="Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts" title="a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.">
             <figcaption>
                a) Radiocarbon ages showing the temporal overlap of unmodified and human-modified mammoth remains in the bone-bed and archaeological evidence of human settlement at the Berelekh geoarchaeological complex. b) Radiocarbon dating of human interaction with mammoths at the Yana Palaeolithic site, Siberia. Credit: Pitulko et al. 2024.
            </figcaption>        </figure>
    </div>
<p>There are three radiocarbon dated peaks in woolly mammoth accumulation at 11.8, 12.2 and 12.4 kyr ago, which fall within known human settlement of the area (11.2–12.4 kyr ago) during the Bølling-Allerød deglacial, when the <a href="https://phys.org/tags/northern+hemisphere/" rel="tag">northern hemisphere</a> warmed and pollen evidence suggests the region became more arid.</p>
<p>Fluctuations in the abundance of mammoths in the 'graveyard' suggest human settlement of the area may also have changed through time (frequent occupation but not permanent), which the researchers attribute to <a href="https://phys.org/tags/environmental+changes/" rel="tag">environmental changes</a> on the floodplain permitting suitability for erecting campsites.</p>
<p>Radiocarbon dating of mammoth remains identifies their presence here pre-dating human settlement (beginning ~12.5 kyr ago), but also shows that humans remained in the area (until ~11.2 kyr ago) after mass mammoth remains accumulation declined (~11.8 kyr ago).</p>

																																			<p>Given this, four possible causes are suggested by the scientists to explain such a significant mass accumulation of bones: 1) mass death by natural causes or human, 2) repeated group deaths in the same location, likely due to human predation, 3) concentration of remains by <a href="https://phys.org/tags/geological+processes/" rel="tag">geological processes</a>, such as river action, or 4) solely derived from human predation or scavenging from deceased carcasses.</p>
<p>However, the latter is considered to be the most likely to produce useful tools from ivory tusks, as well as meat to feed the community, as there is no evidence on the bones for a cause of mass death, radiocarbon ages do not cluster into multiple phases for recurrent death deposits and stream flows were unlikely to reach sufficient velocities to transport such heavy bones.</p>
<p>These findings are concurrent with mammoth remains at the Yana Paleolithic site, also in Siberia. Here, estimates suggest the 'graveyard' increased by 1–2 mammoths per year rather than a mass death event, a figure Dr. Pitulko and colleagues conclude could be similar or even higher for Berelekh.</p>
<p>This research is significant as it alters the previously-held belief that there was a lag of 50–80 years between mammoth bone accumulation from natural processes (such as deposition in flood channels) and <a href="https://phys.org/tags/human+settlement/" rel="tag">human settlement</a>, instead now defining a close relationship between the two over 700–800 years. Sadly, now that human-mammoth relationship has continued as ivory hunters have looted the site beyond further study.</p>


																																																					
																				<div>
																						<p><strong>More information:</strong>
												Vladimir V. Pitulko et al, From the Berelekh 'mammoth graveyard' to Berelekh geo-archaeological complex: Paleoenvironment, site formation processes, and human-mammoth relationships, <i>Quaternary Science Reviews</i> (2024). <a data-doi="1" href="https://dx.doi.org/10.1016/j.quascirev.2024.108692" target="_blank">DOI: 10.1016/j.quascirev.2024.108692</a>
																						
																						</p>
																					</div>
                               											
																															 <p>
												  © 2024 Science X Network
											 </p>
										                                        
										<!-- print only -->
										<div>
											 <p><strong>Citation</strong>:
												Siberia's 'mammoth graveyard' reveals 800-year human interactions with woolly beasts (2024, June 10)
												retrieved 11 June 2024
												from https://phys.org/news/2024-06-siberia-mammoth-graveyard-reveals-year.html
											 </p>
											 <p>
											 This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no
											 part may be reproduced without the written permission. The content is provided for information purposes only.
											 </p>
										</div>
                                        
									</div></div>]]></description>
        </item>
    </channel>
</rss>