<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>HN100 - Readable Contents</title>
        <link>https://hn.algolia.com/api/v1/search_by_date?tags=%28story,poll%29&amp;numericFilters=points%3E100</link>
        <description>Uses Readability to add bodies to the RSS feed</description>
        <lastBuildDate>Thu, 11 Apr 2024 12:00:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <item>
            <title><![CDATA[AI-generated sad girl with piano performs the text of the MIT License (575 pts)]]></title>
            <link>https://suno.com/song/da6d4a83-1001-4694-8c28-648a6e8bad0a/</link>
            <guid>39998849</guid>
            <pubDate>Thu, 11 Apr 2024 06:01:32 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://suno.com/song/da6d4a83-1001-4694-8c28-648a6e8bad0a/">https://suno.com/song/da6d4a83-1001-4694-8c28-648a6e8bad0a/</a>, See on <a href="https://news.ycombinator.com/item?id=39998849">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-theme="dark"><div data-theme="dark"><h2 data-theme="dark">Permission is hereby granted</h2><div data-theme="dark"><p data-theme="dark">Sad girl piano ballad; jazz-trained female singer-songwriter</p><p><span data-theme="dark">v3</span></p></div><p data-theme="dark">April 4, 2024</p></div><p data-theme="dark">Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[End of the Line? Saudi Arabia to scale back plans for desert megacity (143 pts)]]></title>
            <link>https://www.theguardian.com/world/2024/apr/10/the-line-saudi-arabia-scaling-back-plans-105-mile-long-desert-megacity-crown-prince</link>
            <guid>39998404</guid>
            <pubDate>Thu, 11 Apr 2024 04:33:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/world/2024/apr/10/the-line-saudi-arabia-scaling-back-plans-105-mile-long-desert-megacity-crown-prince">https://www.theguardian.com/world/2024/apr/10/the-line-saudi-arabia-scaling-back-plans-105-mile-long-desert-megacity-crown-prince</a>, See on <a href="https://news.ycombinator.com/item?id=39998404">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p>It was billed as a glass-walled city of the future, an ambitious centrepiece of the economic plan backed by Crown Prince <a href="https://www.theguardian.com/world/mohammed-bin-salman" data-link-name="in body link" data-component="auto-linked-tag">Mohammed bin Salman</a> to transition Saudi Arabia away from oil dependency.</p><p>Now, however, plans for the mirror-clad desert metropolis called the Line have been scaled down and the project, which was envisaged to stretch 105 miles (170km) is expected to reach just a mile and a half by 2030.</p><p>Dreamed up as a linear city that would eventually be home to about 9 million people on a footprint of just 13 sq miles, the Line is part of a wider Neom project. Now at least one contractor has begun dismissing workers.</p><figure id="b6dc75ec-f325-455e-927c-de89a8d9bcb9" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-1"><picture><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="A promotional image of Saudi Arabia’s Neom shows the design plan for the parallel structures, known collectively as the Line." src="https://i.guim.co.uk/img/media/54af0d2b2f224981b58a7872217d08a97d398efb/333_0_3333_2000/master/3333.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267.026702670267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>A promotional image of Saudi Arabia’s Neom shows the design plan for the parallel structures, known collectively as the Line.</span> Photograph: NEOM/AFP/Getty Images</figcaption></figure><p>The scaling down of Prince Mohammed’s most grandiose project was <a href="https://www.bloomberg.com/news/articles/2024-04-05/saudis-scale-back-ambition-for-1-5-trillion-desert-project-neom" data-link-name="in body link">reported by Bloomberg</a>, which said it had seen documents relating to the project.</p><figure id="446d42b7-0ddd-4f9f-8042-963e1da3cc7a" data-spacefinder-role="richLink" data-spacefinder-type="model.dotcomrendering.pageElements.RichLinkBlockElement"><gu-island name="RichLinkComponent" priority="feature" deferuntil="idle" props="{&quot;richLinkIndex&quot;:5,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;text&quot;:&quot;‘It’s being built on our blood’: the true cost of Saudi Arabia’s $500bn megacity&quot;,&quot;elementId&quot;:&quot;446d42b7-0ddd-4f9f-8042-963e1da3cc7a&quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/global-development/2020/may/04/its-being-built-on-our-blood-the-true-cost-of-saudi-arabia-5bn-mega-city-neom&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}" config="{&quot;renderingTarget&quot;:&quot;Web&quot;,&quot;darkModeAvailable&quot;:false}"></gu-island></figure><p>The project, which had been slated to cost $1.5tn (£1.2tn), was pitched as a reinvention of urban design. However, it has long attracted scepticism and criticism, not least after the reported execution of several members of the Howeitat tribe who had protested over plans to construct on their ancestral lands.</p><p>Then there were reports of Prince Mohammed’s changing vision for the project, budget overspends and an ever-changing roster of key staff, with some who have worked on the project describing it as “untethered from reality”.</p><figure id="de370cd5-5774-41f7-b6f5-6d8708947467" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="handout picture provided by Saudi’s Neom project in July 2022 shows the design plan for the 500-metre tall parallel structures, known collectively as The Line," src="https://i.guim.co.uk/img/media/010bfa1cccfada89d0b3bdb2afe6648934b24cf9/0_0_2500_3333/master/2500.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="593.274" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>The city was envisaged as being car-free and connected by one of the world’s fastest trains.</span> Photograph: NEOM/AFP/Getty Images</figcaption></figure><p>According to Bloomberg, the scaling back of the Line comes as the overall Neom budget for 2024 has yet to be approved by Saudi Arabia’s sovereign wealth fund amid declining cash reserves.</p><p>Promotional presentations had suggested something out of a science fiction novel running inland into Tabuk province from the mouth of the Gulf of Aqaba where it enters the Red Sea.</p><p>A few hundred metres wide, the linear city had been sold as the future of accessible urban planning, with amenities for residents within close walking distance to accommodation and districts connected by one of the world’s fastest trains.</p><p>Promotional material described the Line in almost mystical terms: a “cognitive city” and a “civilisation revolution” where amenities would be provided by artificial intelligence.</p><p>Prince Mohammed, who has long been accused of involvement in the killing of the Washington Post journalist Jamal Khashoggi in Istanbul in 2018, had described the city project as “tackling the challenges facing humanity in urban life today” to “shine a light on alternative ways to live”.</p><figure id="5b69d0cf-ba82-4f7e-99d6-c4a233b64e42" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Saudi Crown Prince Mohammed Bin Salman announces the Line in January 2021." src="https://i.guim.co.uk/img/media/f8e3beff8113b4039304dd8e5bed3cbf581f9424/0_34_3500_2100/master/3500.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="267" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Saudi Crown Prince Mohammed Bin Salman announces the Line in January 2021.</span> Photograph: Reuters</figcaption></figure><p>Not everyone, however, has been convinced by the prince’s glossy prospectus. Writing in the New York Times in 2021 at the time Neom released a video describing the prospects of living between the city’s silvered walls, the US journalist and author Robert Worth said: “To watch the crown prince’s promotional video is to be immersed in a distinctively Saudi form of arrogance, blending religious triumphalism and royal grandiosity.”</p><p>And hubris, too, apparently.</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Going in circles without a real-time clock (104 pts)]]></title>
            <link>https://rachelbythebay.com/w/2024/04/10/rtc/</link>
            <guid>39998346</guid>
            <pubDate>Thu, 11 Apr 2024 04:22:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rachelbythebay.com/w/2024/04/10/rtc/">https://rachelbythebay.com/w/2024/04/10/rtc/</a>, See on <a href="https://news.ycombinator.com/item?id=39998346">Hacker News</a></p>
Couldn't get https://rachelbythebay.com/w/2024/04/10/rtc/: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Amazon owes $525M in cloud-storage patent fight, US jury says (137 pts)]]></title>
            <link>https://www.reuters.com/legal/amazon-owes-525-mln-cloud-storage-patent-fight-us-jury-says-2024-04-11/</link>
            <guid>39997556</guid>
            <pubDate>Thu, 11 Apr 2024 01:33:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.reuters.com/legal/amazon-owes-525-mln-cloud-storage-patent-fight-us-jury-says-2024-04-11/">https://www.reuters.com/legal/amazon-owes-525-mln-cloud-storage-patent-fight-us-jury-says-2024-04-11/</a>, See on <a href="https://news.ycombinator.com/item?id=39997556">Hacker News</a></p>
Couldn't get https://www.reuters.com/legal/amazon-owes-525-mln-cloud-storage-patent-fight-us-jury-says-2024-04-11/: Error: Request failed with status code 401]]></description>
        </item>
        <item>
            <title><![CDATA[ETag and HTTP Caching (105 pts)]]></title>
            <link>https://rednafi.com/misc/etag_and_http_caching/</link>
            <guid>39996521</guid>
            <pubDate>Wed, 10 Apr 2024 22:51:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://rednafi.com/misc/etag_and_http_caching/">https://rednafi.com/misc/etag_and_http_caching/</a>, See on <a href="https://news.ycombinator.com/item?id=39996521">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>One neat use case for the HTTP <code>ETag</code> header is client-side HTTP caching for <code>GET</code> requests.
Along with the <code>ETag</code> header, the caching workflow requires you to fiddle with other
conditional HTTP headers like <code>If-Match</code> or <code>If-None-Match</code>. However, their interaction can
feel a bit confusing at times.</p><p>Every time I need to tackle this, I end up spending some time browsing through the relevant
MDN docs<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup><sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> to jog my memory. At this point, I’ve done it enough times to justify
spending the time to write this.</p><h2 id="caching-the-response-of-a-get-endpoint">Caching the response of a <code>GET</code> endpoint</h2><p>The basic workflow goes as follows:</p><ul><li>The client makes a <code>GET</code> request to the server.</li><li>The server responds with a <code>200 OK</code> status, including the content requested and an
<code>ETag</code> header.</li><li>The client caches the response and the <code>ETag</code> value.</li><li>For subsequent requests to the same resource, the client includes the <code>If-None-Match</code>
header with the <code>ETag</code> value it has cached.</li><li>The server regenerates the <code>ETag</code> independently and checks if the <code>ETag</code> value sent by
the client matches the generated one.<ul><li>If they match, the server responds with a <code>304 Not Modified</code> status, indicating that
the client’s cached version is still valid, and the client serves the resource from
the cache.</li><li>If they don’t match, the server responds with a <code>200 OK</code> status, including the new
content and a new <code>ETag</code> header, prompting the client to update its cache.</li></ul></li></ul><div><pre tabindex="0"><code data-lang="txt"><span><span>Client                                 Server
</span></span><span><span>  |                                       |
</span></span><span><span>  |----- GET Request --------------------&gt;|
</span></span><span><span>  |                                       |
</span></span><span><span>  |&lt;---- Response 200 OK + ETag ----------|
</span></span><span><span>  |     (Cache response locally)          |
</span></span><span><span>  |                                       |
</span></span><span><span>  |----- GET Request + If-None-Match ----&gt;|  (If-None-Match == previous ETag)
</span></span><span><span>  |                                       |
</span></span><span><span>  |       Does ETag match?                |
</span></span><span><span>  |&lt;---- Yes: 304 Not Modified -----------|  (No body sent; Use local cache)
</span></span><span><span>  |       No: 200 OK + New ETag ----------|  (Update cached response)
</span></span><span><span>  |                                       |
</span></span></code></pre></div><p>We can test this workflow with GitHub’s REST API suite via the GitHub CLI<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>. If you’ve
installed the CLI and authenticated yourself, you can make a request like this:</p><p>This asks for the data associated with the user <code>rednafi</code>. The response looks as follows:</p><div><pre tabindex="0"><code data-lang="txt"><span><span>HTTP/2.0 200 OK
</span></span><span><span>Etag: W/"b8fdfabd59aed6e0e602dd140c0a0ff48a665cac791dede458c5109bf4bf9463"
</span></span><span><span>
</span></span><span><span>{
</span></span><span><span>  "login":"rednafi",
</span></span><span><span>  "id":30027932,
</span></span><span><span>  ...
</span></span><span><span>}
</span></span></code></pre></div><p>I’ve truncated the response body and omitted the headers that aren’t relevant to this
discussion. You can see that the HTTP status code is <code>200 OK</code> and the server has included an
ETag header.</p><p>The <code>W/</code> prefix indicates that a weak validator<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> is used to validate the content of the
cache. Using a weak validator means when the server compares the response payload to
generate the hash, it doesn’t do it bit-by-bit. So, if your response is JSON, then changing
the format of the JSON won’t change the value of the <code>ETag</code> header since two JSON payloads
with the same content but with different formatting are semantically the same thing.</p><p>Let’s see what happens if we make the same request again while passing the value of the
<code>ETag</code> in the <code>If-None-Match</code> header.</p><div><pre tabindex="0"><code data-lang="sh"><span><span>gh api -i -H <span>\
</span></span></span><span><span><span></span>    <span>'If-None-Match: W/"b8fdfabd59aed6e0e602dd140c0a0ff48a665cac791dede458c5109bf4bf9463"'</span> <span>\
</span></span></span><span><span><span></span>    /users/rednafi
</span></span></code></pre></div><p>This returns:</p><div><pre tabindex="0"><code data-lang="txt"><span><span>HTTP/2.0 304 Not Modified
</span></span><span><span>Etag: "b8fdfabd59aed6e0e602dd140c0a0ff48a665cac791dede458c5109bf4bf9463"
</span></span><span><span>
</span></span><span><span>gh: HTTP 304
</span></span></code></pre></div><p>This means that the cached response in the client is still valid and it doesn’t need to
refetch that from the server. So, the client can be coded to serve the previously cached
data to the users when asked for.</p><p>A few key points to keep in mind:</p><ul><li><p>Always wrap your <code>ETag</code> values in double quotes when sending them with the
<code>If-None-Match</code> header, just as the spec says<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup>.</p></li><li><p>Using the <code>If-None-Match</code> header to pass the <code>ETag</code> value means that the client request
is considered successful when the <code>ETag</code> value from the client doesn’t match that of the
server. When the values match, the server will return <code>304 Not Modified</code> with no body.</p></li><li><p>If we’re writing a compliant server, when it comes to <code>If-None-Match</code>, the spec tells
us<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup> to use a weak comparison for ETags. This means that the client will still be able
to validate the cache with weak ETags, even if there have been slight changes to the
representation of the data.</p></li><li><p>If the client is a browser, it’ll automatically manage the cache and send conditional
requests without any extra work.</p></li></ul><h2 id="writing-a-server-that-enables-client-side-caching">Writing a server that enables client-side caching</h2><p>If you’re serving static content, you can configure your load balancer to enable this
caching workflow. But for dynamic <code>GET</code> requests, the server needs to do a bit more work to
allow client-side caching.</p><p>Here’s a simple server in Go that enables the above workflow for a dynamic <code>GET</code> request:</p><div><pre tabindex="0"><code data-lang="go"><span><span><span>package</span> <span>main</span>
</span></span><span><span>
</span></span><span><span><span>import</span> <span>(</span>
</span></span><span><span>    <span>"crypto/sha256"</span>
</span></span><span><span>    <span>"encoding/hex"</span>
</span></span><span><span>    <span>"fmt"</span>
</span></span><span><span>    <span>"net/http"</span>
</span></span><span><span>    <span>"strings"</span>
</span></span><span><span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>// calculateETag generates a weak ETag by SHA-256-hashing the content
</span></span></span><span><span><span>// and prefixing it with W/ to indicate a weak comparison
</span></span></span><span><span><span></span><span>func</span> <span>calculateETag</span><span>(</span><span>content</span> <span>string</span><span>)</span> <span>string</span> <span>{</span>
</span></span><span><span>    <span>hasher</span> <span>:=</span> <span>sha256</span><span>.</span><span>New</span><span>()</span>
</span></span><span><span>    <span>hasher</span><span>.</span><span>Write</span><span>([]</span><span>byte</span><span>(</span><span>content</span><span>))</span>
</span></span><span><span>    <span>hash</span> <span>:=</span> <span>hex</span><span>.</span><span>EncodeToString</span><span>(</span><span>hasher</span><span>.</span><span>Sum</span><span>(</span><span>nil</span><span>))</span>
</span></span><span><span>    <span>return</span> <span>fmt</span><span>.</span><span>Sprintf</span><span>(</span><span>"W/\"%s\""</span><span>,</span> <span>hash</span><span>)</span>
</span></span><span><span><span>}</span>
</span></span><span><span>
</span></span><span><span><span>func</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>    <span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>func</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
</span></span><span><span>        <span>// Define the content within the handler
</span></span></span><span><span><span></span>        <span>content</span> <span>:=</span> <span>`{"message": "Hello, world!"}`</span>
</span></span><span><span>        <span>eTag</span> <span>:=</span> <span>calculateETag</span><span>(</span><span>content</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>// Remove quotes and W/ prefix for If-None-Match header comparison
</span></span></span><span><span><span></span>        <span>ifNoneMatch</span> <span>:=</span> <span>strings</span><span>.</span><span>TrimPrefix</span><span>(</span>
</span></span><span><span>            <span>strings</span><span>.</span><span>Trim</span><span>(</span><span>r</span><span>.</span><span>Header</span><span>.</span><span>Get</span><span>(</span><span>"If-None-Match"</span><span>),</span> <span>"\""</span><span>),</span> <span>"W/"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>// Generate a hash of the content without the W/ prefix for comparison
</span></span></span><span><span><span></span>        <span>contentHash</span> <span>:=</span> <span>strings</span><span>.</span><span>TrimPrefix</span><span>(</span><span>eTag</span><span>,</span> <span>"W/"</span><span>)</span>
</span></span><span><span>
</span></span><span><span>        <span>// Check if the ETag matches; if so, return 304 Not Modified
</span></span></span><span><span><span></span>        <span>if</span> <span>ifNoneMatch</span> <span>==</span> <span>strings</span><span>.</span><span>Trim</span><span>(</span><span>contentHash</span><span>,</span> <span>"\""</span><span>)</span> <span>{</span>
</span></span><span><span>            <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>http</span><span>.</span><span>StatusNotModified</span><span>)</span>
</span></span><span><span>            <span>return</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>
</span></span><span><span>        <span>// If ETag does not match, return the content and the ETag
</span></span></span><span><span><span></span>        <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"ETag"</span><span>,</span> <span>eTag</span><span>)</span> <span>// Send weak ETag
</span></span></span><span><span><span></span>        <span>w</span><span>.</span><span>Header</span><span>().</span><span>Set</span><span>(</span><span>"Content-Type"</span><span>,</span> <span>"application/json"</span><span>)</span>
</span></span><span><span>        <span>w</span><span>.</span><span>WriteHeader</span><span>(</span><span>http</span><span>.</span><span>StatusOK</span><span>)</span>
</span></span><span><span>        <span>fmt</span><span>.</span><span>Fprint</span><span>(</span><span>w</span><span>,</span> <span>content</span><span>)</span>
</span></span><span><span>    <span>})</span>
</span></span><span><span>
</span></span><span><span>    <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>"Server is running on http://localhost:8080"</span><span>)</span>
</span></span><span><span>    <span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></div><ul><li><p>The server generates a weak <code>ETag</code> for its content by creating a SHA-256 hash and adding
<code>W/</code> to the front, indicating it’s meant for weak comparison.</p><p>You could make the <code>calculateETag</code> function format-agnostic, so the hash stays the same
if the JSON format changes but the content does not. The current <code>calculateETag</code>
implementation is susceptible to format changes, and I kept it that way to keep the code
shorter.</p></li><li><p>When delivering content, the server includes this weak <code>ETag</code> in the response headers,
allowing clients to cache the content along with the <code>ETag</code>.</p></li><li><p>For subsequent requests, the server checks if the client has sent an <code>ETag</code> in the
<code>If-None-Match</code> header and weakly compares it with the current content’s <code>ETag</code> by
independently generating the hash.</p></li><li><p>If the ETags match, indicating no significant content change, the server replies with a
<code>304 Not Modified</code> status. Otherwise, it sends the content again with a <code>200 OK</code> status
and updates the ETag. When this happens, the client knows that the existing cache is
still warm and can be served without any changes to it.</p></li></ul><p>You can spin up the server by running <code>go run main.go</code> and from a different console start
making requests to it like this:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>curl -i  http://localhost:8080/foo
</span></span></code></pre></div><p>This will return the ETag header along with the JSON response:</p><div><pre tabindex="0"><code data-lang="txt"><span><span>HTTP/1.1 200 OK
</span></span><span><span>Content-Type: application/json
</span></span><span><span>Etag: W/"1d3b4242cc9039faa663d7ca51a25798e91fbf7675c9007c2b0470b72c2ed2f3"
</span></span><span><span>Date: Wed, 10 Apr 2024 15:54:33 GMT
</span></span><span><span>Content-Length: 28
</span></span><span><span>
</span></span><span><span>{"message": "Hello, world!"}
</span></span></code></pre></div><p>Now, you can make another request with the value of</p><p>the <code>ETag</code> in the <code>If-None-Match</code> header:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>curl -i -H <span>\
</span></span></span><span><span><span></span>    <span>'If-None-Match: "1d3b4242cc9039faa663d7ca51a25798e91fbf7675c9007c2b0470b72c2ed2f3"'</span> <span>\
</span></span></span><span><span><span></span>    http://localhost:8080/foo
</span></span></code></pre></div><p>This will return a <code>304 Not Modified</code> response with no body:</p><div><pre tabindex="0"><code data-lang="txt"><span><span>HTTP/1.1 304 Not Modified
</span></span><span><span>Date: Wed, 10 Apr 2024 15:57:25 GMT
</span></span></code></pre></div><p>In a real-life scenario, you’ll probably factor out the caching part in middleware so that
all of your HTTP <code>GET</code> requests can be cached from the client-side without repetition.</p><h2 id="one-thing-to-look-out-for">One thing to look out for</h2><p>While writing a cache-enabled server, make sure the system is set up so that the server
always sends back the same <code>ETag</code> for the same content, even when there are multiple servers
working behind a load balancer. If these servers give out different ETags for the same
content, it can mess up how clients cache that content.</p><p>Clients use ETags to decide if content has changed. If the <code>ETag</code> value hasn’t changed, they
know the content is the same and don’t download it again, saving bandwidth and speeding up
access. But if ETags are inconsistent across servers, clients might download content they
already have, wasting bandwidth and slowing things down.</p><p>This inconsistency also means servers end up dealing with more requests for content that
clients could have just used from their cache if ETags were consistent.</p><h2>Recent posts</h2><li><a href="https://rednafi.com/misc/crossing_the_cors_crossroad/">Crossing the CORS crossroad</a></li><li><a href="https://rednafi.com/go/dysfunctional_options_pattern/">Dysfunctional options pattern in Go</a></li><li><a href="https://rednafi.com/zephyr/einstellung_effect/">Einstellung effect</a></li><li><a href="https://rednafi.com/go/strategy_pattern/">Strategy pattern in Go</a></li><li><a href="https://rednafi.com/go/anemic_stack_traces/">Anemic stack traces in Go</a></li><li><a href="https://rednafi.com/go/retry_function/">Retry function in Go</a></li><li><a href="https://rednafi.com/go/type_assertion_vs_type_switches/">Type assertion vs type switches in Go</a></li><li><a href="https://rednafi.com/python/patch_pydantic_settings_in_pytest/">Patching pydantic settings in pytest</a></li><li><a href="https://rednafi.com/go/omit_dev_dependencies_in_binaries/">Omitting dev dependencies in Go binaries</a></li><li><a href="https://rednafi.com/misc/eschewing_black_box_api_calls/">Eschewing black box API calls</a></li></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[EPA Says 'Forever Chemicals' Must Be Removed from Tap Water (217 pts)]]></title>
            <link>https://www.nytimes.com/2024/04/10/climate/epa-pfas-drinking-water.html</link>
            <guid>39996433</guid>
            <pubDate>Wed, 10 Apr 2024 22:37:52 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.nytimes.com/2024/04/10/climate/epa-pfas-drinking-water.html">https://www.nytimes.com/2024/04/10/climate/epa-pfas-drinking-water.html</a>, See on <a href="https://news.ycombinator.com/item?id=39996433">Hacker News</a></p>
Couldn't get https://www.nytimes.com/2024/04/10/climate/epa-pfas-drinking-water.html: Error: Request failed with status code 403]]></description>
        </item>
        <item>
            <title><![CDATA[Why can't my mom email me? (207 pts)]]></title>
            <link>https://matduggan.com/why-cant-my-mom-email-me/</link>
            <guid>39996314</guid>
            <pubDate>Wed, 10 Apr 2024 22:21:48 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://matduggan.com/why-cant-my-mom-email-me/">https://matduggan.com/why-cant-my-mom-email-me/</a>, See on <a href="https://news.ycombinator.com/item?id=39996314">Hacker News</a></p>
<div id="readability-page-1" class="page"><section>
<p>An investigation into Proton encrypted email. </p><h3 id="suddenly-silence">Suddenly Silence</h3><p>I'm a big user of email, preferring long chains to messaging apps for a lot of my friends and contacts. It's nice that it isn't tied to a single device or platform and since I own my domain, I can move it from service to service whenever I want and the sender doesn't have to learn some new address. However in the last two months I suddenly stopped getting emails from a percentage of my friends and even my mom. </p><p>What I was getting instead was PGP encrypted emails with blank bodies that looked like the following:</p><figure><img src="https://matduggan.com/content/images/2024/04/image-2.png" alt="" loading="lazy" width="839" height="336" srcset="https://matduggan.com/content/images/size/w600/2024/04/image-2.png 600w, https://matduggan.com/content/images/2024/04/image-2.png 839w" sizes="(min-width: 720px) 720px"></figure><p>If I inspected the message, it was clearly an encrypted email which Fastmail doesn't support. They have a whole blog post on why they don't here: <a href="https://www.fastmail.com/blog/why-we-dont-offer-pgp/">https://www.fastmail.com/blog/why-we-dont-offer-pgp/</a> but up to this point I haven't really cared one way or the other since nobody sends me encrypted emails. </p><p>Now I knew that Proton would send encrypted emails to <em>other Proton email addresses</em>, but obviously this isn't a Proton hosted email address which it would be able to tell pretty easily with DNS. Then it got even stranger when I tried my work email and <strong>got the same error. </strong></p><figure><img src="https://matduggan.com/content/images/2024/04/image-3.png" alt="" loading="lazy" width="736" height="364" srcset="https://matduggan.com/content/images/size/w600/2024/04/image-3.png 600w, https://matduggan.com/content/images/2024/04/image-3.png 736w" sizes="(min-width: 720px) 720px"></figure><p>Checking the raw message and there it is, Proton has encrypted this email. Now this address is hosted on Google Workspaces, so at this point I'm just baffled. Can Proton email users not send emails to people on Google Workspaces email addresses? That can't possibly be right? My friends and mom using Proton would have noticed that their emails seem to always disappear into the ether for the majority of the people they email. </p><p>I open a ticket with Fastmail hoping they've seen this problem before, but no luck. Then I opened a ticket with Proton but didn't hear back as of the time of me writing this. </p><h3 id="how-proton-seems-to-work">How Proton Seems To Work</h3><p>So the reason why so many people I know are moving to Proton is they seem to be the only game in town that has cracked sending encrypted emails in the least annoying way possible. Their encryption uses asymmetric PGP key pairs with lookup for other users public keys happening on their key server. This in conjunction with their Key Transparency technology that compares lookup requests by the client with requests on the server-side allows for easy encrypted message exchanges with a high degree of safety, at least according to them. </p><p>There seems to be three classes of keys at Proton. </p><ul><li>User keys: encrypt account-specific stuff like contacts. Not shared.</li><li>Address keys: for encrypting messages and data. </li><li>Other keys: part of a key tree that leads back to the address key as the primary external key for people to use. </li></ul><p>So that makes sense that Proton can lookup address keys for users on their system. But where are my keys coming from? So in their Proton Key Transparency whitepaper they have this little snippet on page 10:</p><blockquote>For External Addresses, the server may return email encryption keys that it<br>found in the Web Key Directory (WKD) [6] (since email is hosted elsewhere).<br>The server may also return data encryption keys, used e.g. for Proton Drive.<br>The former should have an absence proof in KT, and the latter should have an<br>inclusion proof.<br>For Non-Proton Addresses, the server may also return keys that it found in the<br>WKD. This way clients can automatically encrypt emails to it. These keys won’t<br>be in ProtonKT, thus KT should return an absence proof.</blockquote><h3 id="what-the-hell-is-wkd">What The Hell Is WKD?</h3><p>WKD, or OpenPGP Web Key Directory is an IETF draft by Werner Koch. It describes a service where you can lookup OpenPGP keys by mail addresses using a service. It also allows the key owner and the mail provider to publish and revoke keys. The whole thing is very clever, an interesting way to get around the annoying parts of PGP encryption of email. You can read it here: <a href="https://www.ietf.org/archive/id/draft-koch-openpgp-webkey-service-16.txt">https://www.ietf.org/archive/id/draft-koch-openpgp-webkey-service-16.txt</a></p><p>It outlines an enrollment process by which I would signal to a WKD service that I have a key that I want to enroll into the process. The only problem is I never did that, or at least certainly can't remember doing that. I'm certainly not hosting a page with any key verification stuff. </p><p>There seems to be a way to set a CNAME record to point towards keys.openpgp.org where I do have a key set, but that isn't set up on my domain. </p><pre><code>nslookup openpgpkey.matduggan.com
Server:		2a01:4f8:c2c:123f::1
Address:	2a01:4f8:c2c:123f::1#53

Non-authoritative answer:
*** Can't find openpgpkey.matduggan.com: No answer</code></pre><p>Source here: <a href="https://keys.openpgp.org/about/usage">https://keys.openpgp.org/about/usage</a></p><p>I can't seem to find why Proton thinks they can use this key BUT I can confirm this is the key they're encrypting the emails with. </p><figure><img src="https://matduggan.com/content/images/2024/04/image-4.png" alt="" loading="lazy" width="744" height="475" srcset="https://matduggan.com/content/images/size/w600/2024/04/image-4.png 600w, https://matduggan.com/content/images/2024/04/image-4.png 744w" sizes="(min-width: 720px) 720px"></figure><h3 id="what">What?</h3><p>So it seems if your email address returns a key from <code>keys.openpgp.org</code> then Proton will encrypt the message with your public key from there, even though (as far as I can tell) I haven't opted into them using this service. I also can't seem to figure out a way to signal to them they shouldn't do it. </p><p>Alright so what happens if I just remove my key from <code>keys.openpgp.org</code>. The process is pretty simple, just go to: <a href="https://keys.openpgp.org/manage">https://keys.openpgp.org/manage</a> and follow the instructions in the email. It seems to work more or less instantly. </p><figure><img src="https://matduggan.com/content/images/2024/04/image-5.png" alt="" loading="lazy" width="662" height="258" srcset="https://matduggan.com/content/images/size/w600/2024/04/image-5.png 600w, https://matduggan.com/content/images/2024/04/image-5.png 662w"></figure><p>Alright looks like we figured it out!</p><figure><img src="https://matduggan.com/content/images/2024/04/image-6.png" alt="" loading="lazy" width="870" height="218" srcset="https://matduggan.com/content/images/size/w600/2024/04/image-6.png 600w, https://matduggan.com/content/images/2024/04/image-6.png 870w" sizes="(min-width: 720px) 720px"></figure><h3 id="proton-seriously-what-the-hell">Proton Seriously What The Hell?</h3><p>I'm at a little bit of a loss here. I totally understand sending me encrypted emails if I've gone through the steps to set the CNAME that indicates that I want to do that, but it doesn't seem like that's how the service works. As far as I can tell, the act of uploading a OpenPGP-compatible key seems to trigger their service to send it as an end-to-end encrypted message. </p><p>I'll update this with whatever I hear back from Proton but in the meantime if you stumble across this post after getting blank emails from people for months, you'll at least be able to fix it. </p><p>Is there some flag I've accidentally set somewhere that tells Proton to send me encrypted emails? Let me know at: <a href="https://c.im/@matdevdug">https://c.im/@matdevdug</a></p>
</section></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Aider: AI pair programming in your terminal (343 pts)]]></title>
            <link>https://github.com/paul-gauthier/aider</link>
            <guid>39995725</guid>
            <pubDate>Wed, 10 Apr 2024 21:06:42 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/paul-gauthier/aider">https://github.com/paul-gauthier/aider</a>, See on <a href="https://news.ycombinator.com/item?id=39995725">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">aider is AI pair programming in your terminal</h2><a id="user-content-aider-is-ai-pair-programming-in-your-terminal" aria-label="Permalink: aider is AI pair programming in your terminal" href="#aider-is-ai-pair-programming-in-your-terminal"></a></p>
<p dir="auto">Aider is a command line tool that lets you pair program with GPT-3.5/GPT-4,
to edit code stored in your local git repository.
Aider will directly edit the code in your local source files,
and <a href="https://aider.chat/docs/faq.html#how-does-aider-use-git" rel="nofollow">git commit the changes</a>
with sensible commit messages.
You can start a new project or work with an existing git repo.
Aider is unique in that it lets you ask for changes to <a href="https://aider.chat/docs/repomap.html" rel="nofollow">pre-existing, larger codebases</a>.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/paul-gauthier/aider/blob/main/assets/screencast.svg"><img src="https://github.com/paul-gauthier/aider/raw/main/assets/screencast.svg" alt="aider screencast"></a>
</p>
<p dir="auto">
  <a href="https://discord.gg/Tv2uQnR88V" rel="nofollow">
    <img src="https://camo.githubusercontent.com/dfd919a27895c138700ce36a0a5e888d3c603d28784f798648443ca0006d1418/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4a6f696e2d446973636f72642d626c75652e737667" data-canonical-src="https://img.shields.io/badge/Join-Discord-blue.svg">
  </a>
</p>
<ul dir="auto">
<li><a href="#getting-started">Getting started</a></li>
<li><a href="#example-chat-transcripts">Example chat transcripts</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="https://aider.chat/docs/install.html#tutorial-videos" rel="nofollow">Tutorial videos</a></li>
<li><a href="#in-chat-commands">In-chat commands</a></li>
<li><a href="#tips">Tips</a></li>
<li><a href="https://aider.chat/docs/install.html" rel="nofollow">Installation</a></li>
<li><a href="https://aider.chat/docs/voice.html" rel="nofollow">Voice-to-code</a></li>
<li><a href="https://aider.chat/docs/faq.html" rel="nofollow">FAQ</a></li>
<li><a href="https://discord.gg/Tv2uQnR88V" rel="nofollow">Discord</a></li>
<li><a href="https://aider.chat/blog/" rel="nofollow">Blog</a></li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Getting started</h2><a id="user-content-getting-started" aria-label="Permalink: Getting started" href="#getting-started"></a></p>
<p dir="auto">See the
<a href="https://aider.chat/docs/install.html" rel="nofollow">installation instructions</a>
for more details, but you can
get started quickly like this:</p>
<div data-snippet-clipboard-copy-content="$ pip install aider-chat
$ export OPENAI_API_KEY=your-key-goes-here
$ aider hello.js

Using git repo: .git
Added hello.js to the chat.

hello.js> write a js script that prints hello world"><pre><code>$ pip install aider-chat
$ export OPENAI_API_KEY=your-key-goes-here
$ aider hello.js

Using git repo: .git
Added hello.js to the chat.

hello.js&gt; write a js script that prints hello world
</code></pre></div>
<p dir="auto"><h2 tabindex="-1" dir="auto">Example chat transcripts</h2><a id="user-content-example-chat-transcripts" aria-label="Permalink: Example chat transcripts" href="#example-chat-transcripts"></a></p>
<p dir="auto">Here are some example transcripts that show how you can chat with <code>aider</code> to write and edit code with GPT-4.</p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://aider.chat/examples/hello-world-flask.html" rel="nofollow"><strong>Hello World Flask App</strong></a>: Start from scratch and have GPT create a simple Flask app with various endpoints, such as adding two numbers and calculating the Fibonacci sequence.</p>
</li>
<li>
<p dir="auto"><a href="https://aider.chat/examples/2048-game.html" rel="nofollow"><strong>Javascript Game Modification</strong></a>: Dive into an existing open-source repo, and get GPT's help to understand it and make modifications.</p>
</li>
<li>
<p dir="auto"><a href="https://aider.chat/examples/complex-change.html" rel="nofollow"><strong>Complex Multi-file Change with Debugging</strong></a>: GPT makes a complex code change that is coordinated across multiple source files, and resolves bugs by reviewing error output and doc snippets.</p>
</li>
<li>
<p dir="auto"><a href="https://aider.chat/examples/add-test.html" rel="nofollow"><strong>Create a Black Box Test Case</strong></a>: GPT creates a "black box" test case without access to the source of the method being tested, using only a
<a href="https://aider.chat/docs/repomap.html" rel="nofollow">high level map of the repository based on tree-sitter</a>.</p>
</li>
</ul>
<p dir="auto">You can find more chat transcripts on the <a href="https://aider.chat/examples/" rel="nofollow">examples page</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Features</h2><a id="user-content-features" aria-label="Permalink: Features" href="#features"></a></p>
<ul dir="auto">
<li>Chat with GPT about your code by launching <code>aider</code> from the command line with set of source files to discuss and edit together. Aider lets GPT see and edit the content of those files.</li>
<li>GPT can write and edit code in most popular languages: python, javascript, typescript, html, css, etc.</li>
<li>Request new features, changes, improvements, or bug fixes to your code. Ask for new test cases, updated documentation or code refactors.</li>
<li>Aider will apply the edits suggested by GPT directly to your source files.</li>
<li>Aider will <a href="https://aider.chat/docs/faq.html#how-does-aider-use-git" rel="nofollow">automatically commit each changeset to your local git repo</a> with a descriptive commit message. These frequent, automatic commits provide a safety net. It's easy to undo changes or use standard git workflows to manage longer sequences of changes.</li>
<li>You can use aider with multiple source files at once, so GPT can make coordinated code changes across all of them in a single changeset/commit.</li>
<li>Aider can <a href="https://aider.chat/docs/repomap.html" rel="nofollow">give <em>GPT-4</em> a map of your entire git repo</a>, which helps it understand and modify large codebases.</li>
<li>You can also edit files by hand using your editor while chatting with aider. Aider will notice these out-of-band edits and keep GPT up to date with the latest versions of your files. This lets you bounce back and forth between the aider chat and your editor, to collaboratively code with GPT.</li>
<li>If you are using gpt-4 through openai directly, you can add image files to your context which will automatically switch you to the gpt-4-vision-preview model</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">Run the <code>aider</code> tool by executing the following command:</p>
<div data-snippet-clipboard-copy-content="aider <file1> <file2> ..."><pre><code>aider &lt;file1&gt; &lt;file2&gt; ...
</code></pre></div>
<p dir="auto">If your pip install did not place the <code>aider</code> executable on your path, you can invoke aider like this:</p>
<div data-snippet-clipboard-copy-content="python -m aider.main <file1> <file2>"><pre><code>python -m aider.main &lt;file1&gt; &lt;file2&gt;
</code></pre></div>
<p dir="auto">Replace <code>&lt;file1&gt;</code>, <code>&lt;file2&gt;</code>, etc., with the paths to the source code files you want to work on.
These files will be "added to the chat session", so that GPT can see their contents and edit them according to your instructions.</p>
<p dir="auto">You can also just launch <code>aider</code> anywhere in a git repo without naming
files on the command line.  It will discover all the files in the
repo.  You can then add and remove individual files in the chat
session with the <code>/add</code> and <code>/drop</code> chat commands described below.
If you or GPT mention one of the repo's filenames in the conversation,
aider will ask if you'd like to add it to the chat.</p>
<p dir="auto">Think about the change you want to make and which files will need
to be edited -- add those files to the chat.
Don't add <em>all</em> the files in your repo to the chat.
Be selective, and just add the files that GPT will need to edit.
If you add a bunch of unrelated files, GPT can get overwhelmed
and confused (and it costs more tokens).
Aider will automatically
share snippets from other, related files with GPT so it can
<a href="https://aider.chat/docs/repomap.html" rel="nofollow">understand the rest of your code base</a>.</p>
<p dir="auto">Aider also has many
additional command-line options, environment variables or configuration file
to set many options. See <code>aider --help</code> for details.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">In-chat commands</h2><a id="user-content-in-chat-commands" aria-label="Permalink: In-chat commands" href="#in-chat-commands"></a></p>
<p dir="auto">Aider supports commands from within the chat, which all start with <code>/</code>. Here are some of the most useful in-chat commands:</p>
<ul dir="auto">
<li><code>/add &lt;file&gt;</code>: Add matching files to the chat session.</li>
<li><code>/drop &lt;file&gt;</code>: Remove matching files from the chat session.</li>
<li><code>/undo</code>: Undo the last git commit if it was done by aider.</li>
<li><code>/diff</code>: Display the diff of the last aider commit.</li>
<li><code>/run &lt;command&gt;</code>: Run a shell command and optionally add the output to the chat.</li>
<li><code>/voice</code>: Speak to aider to <a href="https://aider.chat/docs/voice.html" rel="nofollow">request code changes with your voice</a>.</li>
<li><code>/help</code>: Show help about all commands.</li>
</ul>
<p dir="auto">See the <a href="https://aider.chat/docs/commands.html" rel="nofollow">full command docs</a> for more information.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Tips</h2><a id="user-content-tips" aria-label="Permalink: Tips" href="#tips"></a></p>
<ul dir="auto">
<li>Think about which files need to be edited to make your change and add them to the chat.
Aider has some ability to help GPT figure out which files to edit all by itself, but the most effective approach is to explicitly add the needed files to the chat yourself.</li>
<li>Large changes are best performed as a sequence of thoughtful bite sized steps, where you plan out the approach and overall design. Walk GPT through changes like you might with a junior dev. Ask for a refactor to prepare, then ask for the actual change. Spend the time to ask for code quality/structure improvements.</li>
<li>Use Control-C to safely interrupt GPT if it isn't providing a useful response. The partial response remains in the conversation, so you can refer to it when you reply to GPT with more information or direction.</li>
<li>Use the <code>/run</code> command to run tests, linters, etc and show the output to GPT so it can fix any issues.</li>
<li>Use Meta-ENTER (Esc+ENTER in some environments) to enter multiline chat messages. Or enter <code>{</code> alone on the first line to start a multiline message and <code>}</code> alone on the last line to end it.</li>
<li>If your code is throwing an error, share the error output with GPT using <code>/run</code> or by pasting it into the chat. Let GPT figure out and fix the bug.</li>
<li>GPT knows about a lot of standard tools and libraries, but may get some of the fine details wrong about APIs and function arguments. You can paste doc snippets into the chat to resolve these issues.</li>
<li>GPT can only see the content of the files you specifically "add to the chat". Aider also sends GPT-4 a <a href="https://aider.chat/docs/repomap.html" rel="nofollow">map of your entire git repo</a>. So GPT may ask to see additional files if it feels that's needed for your requests.</li>
<li>I also shared some general <a href="https://news.ycombinator.com/item?id=36211879" rel="nofollow">GPT coding tips on Hacker News</a>.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Installation</h2><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto">See the <a href="https://aider.chat/docs/install.html" rel="nofollow">installation instructions</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">FAQ</h2><a id="user-content-faq" aria-label="Permalink: FAQ" href="#faq"></a></p>
<p dir="auto">For more information, see the <a href="https://aider.chat/docs/faq.html" rel="nofollow">FAQ</a>.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Kind words from users</h2><a id="user-content-kind-words-from-users" aria-label="Permalink: Kind words from users" href="#kind-words-from-users"></a></p>
<ul dir="auto">
<li><em>The best AI coding assistant so far.</em> -- <a href="https://www.youtube.com/watch?v=df8afeb1FY8" rel="nofollow">Matthew Berman</a></li>
<li><em>Hands down, this is the best AI coding assistant tool so far.</em> -- <a href="https://www.youtube.com/watch?v=MPYFPvxfGZs" rel="nofollow">IndyDevDan</a></li>
<li><em>Aider ... has easily quadrupled my coding productivity.</em> -- <a href="https://news.ycombinator.com/item?id=36212100" rel="nofollow">SOLAR_FIELDS</a></li>
<li><em>It's a cool workflow... Aider's ergonomics are perfect for me.</em> -- <a href="https://news.ycombinator.com/item?id=38185326" rel="nofollow">qup</a></li>
<li><em>It's really like having your senior developer live right in your Git repo - truly amazing!</em> -- <a href="https://github.com/paul-gauthier/aider/issues/124" data-hovercard-type="issue" data-hovercard-url="/paul-gauthier/aider/issues/124/hovercard">rappster</a></li>
<li><em>What an amazing tool. It's incredible.</em> -- <a href="https://github.com/paul-gauthier/aider/issues/6#issue-1722897858" data-hovercard-type="issue" data-hovercard-url="/paul-gauthier/aider/issues/6/hovercard">valyagolev</a></li>
<li><em>Aider is such an astounding thing!</em> -- <a href="https://github.com/paul-gauthier/aider/issues/82#issuecomment-1631876700" data-hovercard-type="issue" data-hovercard-url="/paul-gauthier/aider/issues/82/hovercard">cgrothaus</a></li>
<li><em>It was WAY faster than I would be getting off the ground and making the first few working versions.</em> -- <a href="https://twitter.com/d_feldman/status/1662295077387923456" rel="nofollow">Daniel Feldman</a></li>
<li><em>THANK YOU for Aider! It really feels like a glimpse into the future of coding.</em> -- <a href="https://news.ycombinator.com/item?id=38205643" rel="nofollow">derwiki</a></li>
<li><em>It's just amazing.  It is freeing me to do things I felt were out my comfort zone before.</em> -- <a href="https://discord.com/channels/1131200896827654144/1174002618058678323/1174084556257775656" rel="nofollow">Dougie</a></li>
<li><em>This project is stellar.</em> -- <a href="https://github.com/paul-gauthier/aider/issues/112#issuecomment-1637429008" data-hovercard-type="issue" data-hovercard-url="/paul-gauthier/aider/issues/112/hovercard">funkytaco</a></li>
<li><em>Amazing project, definitely the best AI coding assistant I've used.</em> -- <a href="https://github.com/paul-gauthier/aider/issues/84" data-hovercard-type="issue" data-hovercard-url="/paul-gauthier/aider/issues/84/hovercard">joshuavial</a></li>
<li><em>I am an aider addict. I'm getting so much more work done, but in less time.</em> -- <a href="https://discord.com/channels/1131200896827654144/1131200896827654149/1135913253483069470" rel="nofollow">dandandan</a></li>
<li><em>After wasting $100 on tokens trying to find something better, I'm back to Aider. It blows everything else out of the water hands down, there's no competition whatsoever.</em> -- <a href="https://discord.com/channels/1131200896827654144/1131200896827654149/1178736602797846548" rel="nofollow">SystemSculpt</a></li>
<li><em>Best agent for actual dev work in existing codebases.</em> -- <a href="https://twitter.com/NickADobos/status/1690408967963652097?s=20" rel="nofollow">Nick Dobos</a></li>
</ul>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Nimble: A new columnar file format by Meta [video] (108 pts)]]></title>
            <link>https://www.youtube.com/watch?v=bISBNVtXZ6M</link>
            <guid>39995112</guid>
            <pubDate>Wed, 10 Apr 2024 20:00:21 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.youtube.com/watch?v=bISBNVtXZ6M">https://www.youtube.com/watch?v=bISBNVtXZ6M</a>, See on <a href="https://news.ycombinator.com/item?id=39995112">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Libgourou: A Free Implementation of Adobe's Adept DRM on ePub/PDF Files (186 pts)]]></title>
            <link>https://forge.soutade.fr/soutade/libgourou</link>
            <guid>39994339</guid>
            <pubDate>Wed, 10 Apr 2024 18:49:47 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://forge.soutade.fr/soutade/libgourou">https://forge.soutade.fr/soutade/libgourou</a>, See on <a href="https://news.ycombinator.com/item?id=39994339">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
			
				<h2 id="user-content-introduction" dir="auto">Introduction</h2>
<p dir="auto">libgourou is a free implementation of Adobe's ADEPT protocol used to add DRM on ePub/PDF files. It overcome the lacks of Adobe support for Linux platforms.</p>
<h2 id="user-content-architecture" dir="auto">Architecture</h2>
<p dir="auto">Like RMSDK, libgourou has a client/server scheme. All platform specific functions (crypto, network...) has to be implemented in a client class (that derives from DRMProcessorClient) while server implements ADEPT protocol.
A reference implementation using cURL, OpenSSL and libzip is provided (in <em>utils</em> directory).</p>
<p dir="auto">Main fucntions to use from gourou::DRMProcessor are :</p>
<ul dir="auto">
<li>Get an ePub from an ACSM file : <em>fulfill()</em> and <em>download()</em></li>
<li>Create a new device : <em>createDRMProcessor()</em></li>
<li>Register a new device : <em>signIn()</em> and <em>activateDevice()</em></li>
<li>Remove DRM : <em>removeDRM()</em></li>
<li>Return loaned book : <em>returnLoan()</em></li>
</ul>
<p dir="auto">You can import configuration from (at least) :</p>
<ul dir="auto">
<li>Kobo device    : .adept/device.xml, .adept/devicesalt  and .adept/activation.xml</li>
<li>Bookeen device : .adobe-digital-editions/device.xml, root/devkey.bin and .adobe-digital-editions/activation.xml</li>
</ul>
<p dir="auto">Or create a new one. Be careful : there is a limited number of devices that can be created bye one account.</p>
<p dir="auto">ePub are encrypted using a shared key : one account / multiple devices, so you can create and register a device into your computer and read downloaded (and encrypted) ePub file with your eReader configured using the same AdobeID account.</p>
<p dir="auto">For those who wants to remove DRM without adept_remove, you can export your private key and import it within <a href="https://calibre-ebook.com/" rel="nofollow">Calibre</a> an its DeDRM plugin.</p>
<h2 id="user-content-dependencies" dir="auto">Dependencies</h2>
<p dir="auto">For libgourou :</p>
<p dir="auto"><em>externals</em> :</p>
<ul dir="auto">
<li>libpugixml</li>
</ul>
<p dir="auto"><em>internals</em> :</p>
<ul dir="auto">
<li>uPDFParser</li>
</ul>
<p dir="auto">For utils :</p>
<ul dir="auto">
<li>libcurl</li>
<li>OpenSSL</li>
<li>libzip</li>
<li>libpugixml</li>
</ul>
<p dir="auto">Internal libraries are automatically fetched and statically compiled during the first run.
When you update libgourou's repository, <strong>don't forget to update internal libraries</strong> with :</p>
<pre><code>make update_lib
</code></pre>
<h2 id="user-content-compilation" dir="auto">Compilation</h2>
<p dir="auto">Use <em>make</em> command</p>
<pre><code>make [CROSS=XXX] [DEBUG=(0*|1)] [STATIC_UTILS=(0*|1)] [BUILD_UTILS=(0|1*)] [BUILD_STATIC=(0*|1)] [BUILD_SHARED=(0|1*)] [all*|clean|ultraclean|build_utils|install|uninstall]
</code></pre>
<p dir="auto">CROSS can define a cross compiler prefix (ie arm-linux-gnueabihf-)</p>
<p dir="auto">DEBUG can be set to compile in DEBUG mode</p>
<p dir="auto">BUILD_UTILS to build utils or not</p>
<p dir="auto">STATIC_UTILS to build utils with static library (libgourou.a) instead of default dynamic one (libgourou.so)</p>
<p dir="auto">BUILD_STATIC build libgourou.a if 1, nothing if 0, can be combined with BUILD_SHARED</p>
<p dir="auto">BUILD_SHARED build libgourou.so if 1, nothing if 0, can be combined with BUILD_STATIC</p>
<p dir="auto">other variables are DESTDIR and PREFIX to handle destination install directory</p>
<ul dir="auto">
<li>Default value</li>
</ul>
<h2 id="user-content-utils" dir="auto">Utils</h2>
<p dir="auto">First, add libgourou.so to your LD_LIBRARY_PATH</p>
<pre><code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$PWD
</code></pre>
<p dir="auto">You can optionaly specify your .adept directory</p>
<pre><code>export ADEPT_DIR=/home/XXX
</code></pre>
<p dir="auto">Then, use utils as following :</p>
<p dir="auto">You can import configuration from your eReader or create a new one with <em>utils/adept_activate</em> :</p>
<pre><code>./utils/adept_activate -u &lt;AdobeID USERNAME&gt;
</code></pre>
<p dir="auto">Then a <em>/home//.config/adept</em> directory is created with all configuration file</p>
<p dir="auto">To download an ePub/PDF :</p>
<pre><code>./utils/acsmdownloader &lt;ACSM_FILE&gt;
</code></pre>
<p dir="auto">To export your private key (for DeDRM software) :</p>
<pre><code>./utils/acsmdownloader --export-private-key [-o adobekey_1.der]
</code></pre>
<p dir="auto">To remove ADEPT DRM :</p>
<pre><code>./utils/adept_remove &lt;encryptedFile&gt;
</code></pre>
<p dir="auto">To list loaned books :</p>
<pre><code>./utils/adept_loan_mgt [-l]
</code></pre>
<p dir="auto">To return a loaned book :</p>
<pre><code>./utils/adept_loan_mgt -r &lt;id&gt;
</code></pre>
<p dir="auto">You can get utils full options description with -h or --help switch</p>
<h2 id="user-content-docker" dir="auto">Docker</h2>
<p dir="auto">A docker image (by bcliang) is available at <a href="https://github.com/bcliang/docker-libgourou/" rel="nofollow">https://github.com/bcliang/docker-libgourou/</a></p>
<h2 id="user-content-copyright" dir="auto">Copyright</h2>
<p dir="auto">Grégory Soutadé</p>
<h2 id="user-content-license" dir="auto">License</h2>
<p dir="auto">libgourou : LGPL v3 or later</p>
<p dir="auto">utils     : BSD</p>
<h2 id="user-content-special-thanks" dir="auto">Special thanks</h2>
<ul dir="auto">
<li><em>Jens</em> for all test samples and utils testing</li>
<li><em>Milian</em> for debug &amp; code</li>
<li><em>Berwyn H</em> for all test samples, feedbacks, patches and kind donation</li>
</ul>

			
		</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Lens sort, a masked pixel sort glitch effect (109 pts)]]></title>
            <link>https://github.com/BernardZhao/lenssort</link>
            <guid>39994301</guid>
            <pubDate>Wed, 10 Apr 2024 18:47:04 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/BernardZhao/lenssort">https://github.com/BernardZhao/lenssort</a>, See on <a href="https://news.ycombinator.com/item?id=39994301">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">Lenssort</h2><a id="user-content-lenssort" aria-label="Permalink: Lenssort" href="#lenssort"></a></p>
<p dir="auto">Using facial recognition and pixelsorting on images to create glitched, Snapchat-like lenses.</p>
<p dir="auto">Utilizes <a href="https://github.com/satyarth/pixelsort">pixelsort</a>, another project I am involved in. Make sure to check it out!</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Usage</h2><a id="user-content-usage" aria-label="Permalink: Usage" href="#usage"></a></p>
<p dir="auto">With Docker:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/BernardZhao/lenssort.git
cd lenssort
docker-compose up
# Make sure to include the -o flag, previews won't show up in the container.
docker-compose run lenssort python -m lenssort examples/example1.jpg -m face -o example_result.png"><pre>git clone https://github.com/BernardZhao/lenssort.git
<span>cd</span> lenssort
docker-compose up
<span><span>#</span> Make sure to include the -o flag, previews won't show up in the container.</span>
docker-compose run lenssort python -m lenssort examples/example1.jpg -m face -o example_result.png</pre></div>
<p dir="auto">Manually:</p>
<p dir="auto">Requires Python 3.6 &gt;=.
Make sure you have <a href="https://gist.github.com/ageitgey/629d75c1baac34dfa5ca2a1928a7aeaf">dlib Python bindings</a> installed!</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/BernardZhao/lenssort.git
cd lenssort

# Can skip virtual environment if desired
python -m venv venv 
source venv/bin/activate

pip install -r requirements.txt

python -m lenssort %PathToImage% [mask_type] [params]"><pre>git clone https://github.com/BernardZhao/lenssort.git
<span>cd</span> lenssort

<span><span>#</span> Can skip virtual environment if desired</span>
python -m venv venv 
<span>source</span> venv/bin/activate

pip install -r requirements.txt

python -m lenssort %PathToImage% [mask_type] [params]</pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Mask types:</h3><a id="user-content-mask-types" aria-label="Permalink: Mask types:" href="#mask-types"></a></p>
<table>
<thead>
<tr>
<th>Mask name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>eyes</code></td>
<td>Sort the eyes.</td>
</tr>
<tr>
<td><code>face</code></td>
<td>Sort the face, within the brows and chin.</td>
</tr>
<tr>
<td><code>shuffle</code></td>
<td>Sort a polygon randomly generated over facial features.</td>
</tr>
<tr>
<td><code>censored</code></td>
<td>Sort the eye area with a thick bar.</td>
</tr>
<tr>
<td><code>facemask</code></td>
<td>Sort the area of the face under the eyes.</td>
</tr>
<tr>
<td><code>tears</code></td>
<td>Sort tear-like lines below the eyes.</td>
</tr>
</tbody>
</table>
<p dir="auto"><h3 tabindex="-1" dir="auto">Parameters:</h3><a id="user-content-parameters" aria-label="Permalink: Parameters:" href="#parameters"></a></p>
<table>
<thead>
<tr>
<th>Parameter</th>
<th>Flag</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Invert</td>
<td><code>-i</code></td>
<td>Inverts the mask. May produce cool results.</td>
</tr>
<tr>
<td>Angle</td>
<td><code>-a</code></td>
<td>Sorting angle. Overrides internal default for the mask.</td>
</tr>
<tr>
<td>Output path</td>
<td><code>-o</code></td>
<td>File output path. Previews image if not provided.</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto"><code>python -m lenssort examples/example1.jpg -m face</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example1_face.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example1_face.png" alt="example1_face_i_a90"></a></p>
<p dir="auto"><code>python -m lenssort examples/example1.jpg -m face -i -a 90</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example1_face_i_a90.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example1_face_i_a90.png" alt="example1_face_i_a90"></a></p>
<p dir="auto"><code>python -m lenssort examples/example1.jpg -m eyes -i</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example1_eyes_i.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example1_eyes_i.png" alt="example1_eyes_i"></a></p>
<p dir="auto"><code>python -m lenssort examples/example3.jpg -m facemask</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example3_facemask.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example3_facemask.png" alt="example1_eyes_i"></a></p>
<p dir="auto"><code>python -m lenssort examples/example3.jpg -m shuffle</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example3_shuffle.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example3_shuffle.png" alt="example1_eyes_i"></a></p>
<p dir="auto"><code>python -m lenssort examples/example2.jpg -m censored</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/BernardZhao/lenssort/blob/master/examples/results/example2_censored.png"><img src="https://github.com/BernardZhao/lenssort/raw/master/examples/results/example2_censored.png" alt="example1_eyes_i"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Todo</h3><a id="user-content-todo" aria-label="Permalink: Todo" href="#todo"></a></p>
<ul>
<li> Expose pixelsort args: sorting function, interval function, etc.</li>
<li> Validate mask: No out of bounds</li>
<li> Mask compositions: Ex: (face - eyes + ...)</li>
</ul>
<p dir="auto">And more masks ofc 😪</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Code search is hard (250 pts)]]></title>
            <link>https://blog.val.town/blog/search-notes/</link>
            <guid>39993976</guid>
            <pubDate>Wed, 10 Apr 2024 18:15:08 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://blog.val.town/blog/search-notes/">https://blog.val.town/blog/search-notes/</a>, See on <a href="https://news.ycombinator.com/item?id=39993976">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-astro-cid-bvzihdzo=""> <article itemscope="" itemtype="https://schema.org/Article" data-astro-cid-bvzihdzo=""> <div data-astro-cid-bvzihdzo=""> <div data-astro-cid-bvzihdzo="">  <p><img src="https://blog.val.town/_astro/tom.Cx99M2g4_Z1L13eJ.webp" srcset="https://blog.val.town/_astro/tom.Cx99M2g4_Z2jf3OO.webp 1x, https://blog.val.town/_astro/tom.Cx99M2g4_Z2f6MW8.webp 2x, https://blog.val.town/_astro/tom.Cx99M2g4_Z2aXx4r.webp 3x" alt="Tom MacWright" }="true" data-astro-cid-bvzihdzo="" width="20" height="20" loading="lazy" decoding="async"> 
on
<time datetime="2024-04-10T00:00:00.000Z"> Apr 10, 2024 </time> </p> </div> <p>Val Town’s search functionality isn’t very good. Right now it’s built on the Postgres <a href="https://www.postgresql.org/docs/current/functions-matching.html">ILIKE</a> functionality, which just performs a substring search: if your search term is in the code, it appears in search results. There’s virtually no ranking involved, and queries with multiple words are pretty poorly supported.
Better search is <a href="https://github.com/val-town/val-town-product/discussions/69">one of our most-requested features</a>.</p>
<p>I’m working on improving this, but we haven’t found a solution that fits our needs yet.
Here are some notes from our research. So far what we’ve learned is that:</p>
<ul>
<li>Mainstream search solutions are designed for natural language, not code.</li>
<li>Big companies with code search needs have spent a lot of time and money
building their own custom solutions.</li>
<li>We have a lot of data already, and need a solution that scales well.</li>
<li>The infrastructure and complexity tradeoffs involved in using a separate
search service instead of a database extension are important.</li>
</ul>
<h3 id="code-search-versus-natural-language-search">Code search versus natural language search</h3>
<p>A common issue with off-the shelf search solutions is that they’re designed to work with English and other natural languages. For example, here are some of the algorithms you get by default with a usual FTS setup:</p>
<ul>
<li><strong>Stop words removal</strong>: words like “the” and “it” are removed from text before it is indexed, because they’re so common that they cause more problems for performance than they’re worth.</li>
<li><strong>Stemming</strong>: this mostly <a href="https://en.wikipedia.org/wiki/Grammatical_conjugation">reverses conjugation</a>, turning a word like “running” into “run” before it is added to the index, and doing the same for search queries, so that you can search for “runs” and get a search result for a document with the term “running.”</li>
<li><strong>Lemmatization</strong>: some search indexes are even fancy enough to substitute synonyms for more common words, so that you can search for “excellent” and get results for documents including “great.”</li>
</ul>
<p>All together, this means that the vector derived from a document that you’re storing in the index does not look like the document at all:</p>
<div><figure><pre tabindex="0"><code><div><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> to_tsvector(</span><span>'english'</span><span>, </span><span>'I am writing this example sentence'</span><span>);</span></p></div><div><p><span>--- 'exampl':5 'sentenc':6 'write':3</span></p></div></code></pre></figure></div>
<p>The problem with all of these rules is that they wreak havoc on code. <code>the</code> is not a stop-word in TypeScript: it’s a valid variable name that you might want to search for. Word boundaries aren’t the same, and stemming function names doesn’t make much sense.</p>
<div><figure><pre tabindex="0"><code><div><p><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> to_tsvector(</span><span>'english'</span><span>,</span></p></div><div><p><span>&nbsp; </span><span>'function stringifyNumber(a: number): string { return a.toString() }'</span><span>);</span></p></div><div><p><span>-- 'a.tostring':7 'function':1 'number':4 'return':6 'string':5 'stringifynumb':2</span></p></div></code></pre></figure></div>
<p>This is a pretty bad index: it has words that should be stop words, like <code>function</code>, and won’t split <code>a.toString()</code> into two tokens because <code>.</code> is not a default word boundary.</p>
<h3 id="full-text-search">Full Text Search</h3>
<p>Postgres has a <a href="https://www.postgresql.org/docs/current/textsearch.html">Full Text Search</a> extension which is supported by our hosting provider, <a href="https://docs.render.com/postgresql-extensions">Render</a>. I’ve used FTS in previous projects, and for certain scales, it works great. You can try and <a href="https://www.amazingcto.com/postgres-for-everything/">use Postgres for everything</a>, and frankly, so far we have: we’ve been using the heck out of Postgres. It’s a fantastic piece of technology with great documentation that is well-supported by our hosting provider.</p>
<p>If we can use Postgres for something, we will: keeping infrastructure as simple as possible is essential with a small team.</p>
<p>However, the previous projects I’ve used FTS for have run into performance problems and struggled to scale - <a href="https://observablehq.com/">Observable</a> ended up
moving to Elasticsearch. We have a ton of vals, and are testing the limits of a single-node Postgres cluster. It’s hard to find any accounts of code-search using FTS, though people might be quietly succeeding with it. I wanted to avoid this as a first option but keep it in my back pocket.</p>
<h3 id="pg_trgrm">pg_trgrm</h3>
<p>The solution that we’ve soft-launched as the v2 search algorithm is based on <a href="https://www.postgresql.org/docs/current/pgtrgm.html"><code>pg_trgrm</code></a>, which implements <a href="https://en.wikipedia.org/wiki/Trigram_search">trigram search</a> in Postgres. Code search <em>does</em> seem to succeed with trigrams: <a href="https://swtch.com/~rsc/regexp/regexp4.html">Russ Cox’s famous (to me?) piece from 2012 tells the story of how Google Code Search</a> used trigram indexes and a special regex implementation to succeed, technically. GitHub’s <a href="https://github.blog/2023-02-06-the-technology-behind-githubs-new-code-search/">new search system</a> uses trigram search too, in addition to a lot of technology that I’m jealous of. <a href="https://github.com/sourcegraph/zoekt">Sourcegraph</a> has a trigram-based search tool that they’ve inherited from Google, too.</p>
<p>Our work with the Postgres <code>pg_trgrm</code> approach has been heavily informed by <a href="https://devlog.hexops.com/2021/postgres-regex-search-over-10000-github-repositories/">Stephen Gutekanst’s blog post series about indexing repositories locally</a> in Postgres. We’ve created a <a href="https://www.postgresql.org/docs/current/gin.html">GIN</a> index with <code>gin_trgm_ops</code> on a column containing search text.</p>
<p>The conclusion so far is that this is a great solution for regex search, but we’re not doing regex search: most searches are more freeform. We’re using <a href="https://www.postgresql.org/docs/current/pgtrgm.html#PGTRGM-FUNCS-OPS">word_similarity</a> for search ranking, and it has been very hard to coax the algorithm into giving us anything like a reasonable ranking.</p>
<h3 id="the-universe-of-options">The universe of options</h3>
<table><thead><tr><th>Option</th><th>Architecture</th><th>Language</th><th>Stars</th></tr></thead><tbody><tr><td><a href="https://www.meilisearch.com/">Meilisearch</a></td><td>Standalone</td><td>Rust</td><td>41k</td></tr><tr><td><a href="https://typesense.org/">Typesense</a></td><td>Standalone</td><td>C++</td><td>17k</td></tr><tr><td><a href="https://github.com/sourcegraph/zoekt">Zoekt</a></td><td>Standalone</td><td>Go</td><td>406</td></tr><tr><td><a href="https://www.paradedb.com/">ParadeDB</a></td><td>Postgres extension</td><td>Rust</td><td>3.2k</td></tr><tr><td><a href="https://github.com/valeriansaliou/sonic">Sonic</a></td><td>Standalone</td><td>Rust</td><td>19.4k</td></tr></tbody></table>
<p>There are code-specific tools that exist, but most of them are closed-source: GitHub’s search is excellent, but is obviously the work of a dedicated team with a real time budget.</p>
<ul>
<li>Sourcegraph’s maintained fork of <a href="https://github.com/google/zoekt">Zoekt</a> is pretty cool, but is pretty fearfully niche and would be a big, new infrastructure commitment.</li>
<li><a href="https://github.com/elastic/elasticsearch">Elasticsearch</a> might be the eventual,
unavoidable solution to this problem. It doesn’t have code-specific handling, but can be
customized in nearly infinite ways. We’re not excited to start learning about Java memory
tuning and to introduce the first persistent disk storage to our application, as well as
an additional source of truth for our data. Possibly we could use Elasticsearch
<a href="https://www.elastic.co/cloud">Cloud</a> to avoid the maintenance overhead.</li>
<li><a href="https://github.com/meilisearch/meilisearch">Meilisearch</a> seems like a promising ES alternative with the shininess of ✨Rust✨, but they <a href="https://blog.meilisearch.com/meilisearch-vs-elasticsearch/">seem to emphasize latency over scalability</a>, and we’re not sure if the infrastructure commitment would be any lower.</li>
<li><a href="https://www.paradedb.com/">ParadeDB</a> promises to be like Elasticsearch but “just Postgres,” which is very appealing, but we <a href="https://docs.render.com/postgresql-extensions">can’t use their extension in Render yet</a>.</li>
</ul>
<hr>
<p>In short, we’re still working on it. Searching code instead of English makes the difficulty level a bit higher. For a small team, with an incentive to keep infrastructure simple, development environments easy to set up, and data in the same place, we’re trying to be careful not to commit to something that requires constant upkeep. There’s a reason why most mid and large-sized companies have a search “team,” not just a search service.</p> <a href="https://github.com/val-town/val-town-blog/edit/main/src/content/blog/search-notes.md" data-astro-cid-npoeh54f=""><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" data-astro-cid-npoeh54f=""><path stroke-linecap="round" stroke-linejoin="round" d="M16.862 4.487l1.687-1.688a1.875 1.875 0 112.652 2.652L6.832 19.82a4.5 4.5 0 01-1.897 1.13l-2.685.8.8-2.685a4.5 4.5 0 011.13-1.897L16.863 4.487zm0 0L19.5 7.125" data-astro-cid-npoeh54f=""></path></svg>
Edit this page
</a> </div> </article> </div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Udio: Generate music in your favorite styles with a text prompt (192 pts)]]></title>
            <link>https://twitter.com/udiomusic/status/1778045322654003448</link>
            <guid>39993930</guid>
            <pubDate>Wed, 10 Apr 2024 18:10:31 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://twitter.com/udiomusic/status/1778045322654003448">https://twitter.com/udiomusic/status/1778045322654003448</a>, See on <a href="https://news.ycombinator.com/item?id=39993930">Hacker News</a></p>
Couldn't get https://twitter.com/udiomusic/status/1778045322654003448: Error: Request failed with status code 400]]></description>
        </item>
        <item>
            <title><![CDATA[Implementation of Google's Griffin Architecture – RNN LLM (204 pts)]]></title>
            <link>https://github.com/google-deepmind/recurrentgemma</link>
            <guid>39993626</guid>
            <pubDate>Wed, 10 Apr 2024 17:47:11 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://github.com/google-deepmind/recurrentgemma">https://github.com/google-deepmind/recurrentgemma</a>, See on <a href="https://news.ycombinator.com/item?id=39993626">Hacker News</a></p>
<div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><h2 tabindex="-1" dir="auto">RecurrentGemma</h2><a id="user-content-recurrentgemma" aria-label="Permalink: RecurrentGemma" href="#recurrentgemma"></a></p>
<p dir="auto">RecurrentGemma is a family of open-weights Language Models by <a href="https://deepmind.google/" rel="nofollow">Google DeepMind</a>, based on the novel <a href="https://arxiv.org/abs/2402.19427" rel="nofollow">Griffin architecture</a>. This architecture achieves fast inference when generating long sequences by replacing global attention with a mixture of local attention and linear recurrences.</p>
<p dir="auto">This repository contains the model implementation and examples for sampling and fine-tuning. We recommend most users adopt the <a href="https://github.com/google/flax">Flax</a> implementation, which is highly optimized. We also provide an un-optimized <a href="https://github.com/pytorch/pytorch">PyTorch</a> implementation for reference.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Learn more about RecurrentGemma</h3><a id="user-content-learn-more-about-recurrentgemma" aria-label="Permalink: Learn more about RecurrentGemma" href="#learn-more-about-recurrentgemma"></a></p>
<ul dir="auto">
<li>The RecurrentGemma <a href="https://storage.googleapis.com/deepmind-media/gemma/recurrentgemma-report.pdf" rel="nofollow">technical report</a> gives specific details on the training and evaluation of RecurrentGemma.</li>
<li>The <a href="https://arxiv.org/abs/2402.19427" rel="nofollow">Griffin paper</a> describes the underlying model architecture.</li>
</ul>
<p dir="auto"><h2 tabindex="-1" dir="auto">Quick start</h2><a id="user-content-quick-start" aria-label="Permalink: Quick start" href="#quick-start"></a></p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Installation</h3><a id="user-content-installation" aria-label="Permalink: Installation" href="#installation"></a></p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using Poetry</h4><a id="user-content-using-poetry" aria-label="Permalink: Using Poetry" href="#using-poetry"></a></p>
<p dir="auto">RecurrentGemma uses <a href="https://python-poetry.org/docs/" rel="nofollow">Poetry</a> for dependency
management.</p>
<p dir="auto">To install dependencies for the full project:</p>
<ul dir="auto">
<li>Checkout the code.</li>
<li><code>poetry install -E full</code> to create a virtual environment with all dependencies.</li>
<li><code>poetry shell</code> to activate the created virtual environment.</li>
</ul>
<p dir="auto">If you only need to install a subset of dependencies use one of the alternative
library-specific commands below.</p>
<p dir="auto"><h4 tabindex="-1" dir="auto">Using pip</h4><a id="user-content-using-pip" aria-label="Permalink: Using pip" href="#using-pip"></a></p>
<p dir="auto">If you want to use <code>pip</code> instead of Poetry,
then create a virtual environment (run <code>python -m venv recurrentgemma-demo</code> and <code>. recurrentgemma-demo/bin/activate</code>) and:</p>
<ul dir="auto">
<li>Checkout the code.</li>
<li><code>pip install .[full]</code></li>
</ul>
<p dir="auto"><h4 tabindex="-1" dir="auto">Installing library-specific packages</h4><a id="user-content-installing-library-specific-packages" aria-label="Permalink: Installing library-specific packages" href="#installing-library-specific-packages"></a></p>
<p dir="auto"><h5 tabindex="-1" dir="auto">JAX</h5><a id="user-content-jax" aria-label="Permalink: JAX" href="#jax"></a></p>
<p dir="auto">To install dependencies only for the JAX pathway use:
<code>poetry install -E jax</code> or (<code>pip install .[jax]</code>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">PyTorch</h5><a id="user-content-pytorch" aria-label="Permalink: PyTorch" href="#pytorch"></a></p>
<p dir="auto">To install dependencies only for the PyTorch pathway use:
<code>poetry install -E torch</code> (or <code>pip install .[torch]</code>).</p>
<p dir="auto"><h5 tabindex="-1" dir="auto">Tests</h5><a id="user-content-tests" aria-label="Permalink: Tests" href="#tests"></a></p>
<p dir="auto">To install dependencies required for running unit tests use:
<code>poetry install -E test</code> (or <code>pip install .[test]</code>)</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Downloading the models</h3><a id="user-content-downloading-the-models" aria-label="Permalink: Downloading the models" href="#downloading-the-models"></a></p>
<p dir="auto">The model checkpoints are available through Kaggle at
<a href="http://kaggle.com/models/google/recurrentgemma" rel="nofollow">http://kaggle.com/models/google/recurrentgemma</a>.
Select either the <strong>Flax</strong> or <strong>PyTorch</strong> model variations, click the ⤓ button
to download the model archive, then extract the contents to a local directory.</p>
<p dir="auto">In both cases, the archive contains both the model weights and
the tokenizer.</p>
<p dir="auto"><h3 tabindex="-1" dir="auto">Running the unit tests</h3><a id="user-content-running-the-unit-tests" aria-label="Permalink: Running the unit tests" href="#running-the-unit-tests"></a></p>
<p dir="auto">To run the tests, install the optional <code>[test]</code> dependencies (e.g. using <code>pip install .[test]</code>) from the root of the source tree, then:</p>

<p dir="auto"><h2 tabindex="-1" dir="auto">Examples</h2><a id="user-content-examples" aria-label="Permalink: Examples" href="#examples"></a></p>
<p dir="auto">To run the example sampling script, pass the paths to the weights directory and tokenizer:</p>
<div data-snippet-clipboard-copy-content="python examples/sampling_jax.py \
  --path_checkpoint=/path/to/archive/contents/2b/ \
  --path_tokenizer=/path/to/archive/contents/tokenizer.model"><pre><code>python examples/sampling_jax.py \
  --path_checkpoint=/path/to/archive/contents/2b/ \
  --path_tokenizer=/path/to/archive/contents/tokenizer.model
</code></pre></div>
<p dir="auto"><h3 tabindex="-1" dir="auto">Colab notebook tutorials</h3><a id="user-content-colab-notebook-tutorials" aria-label="Permalink: Colab notebook tutorials" href="#colab-notebook-tutorials"></a></p>
<ul dir="auto">
<li>
<p dir="auto"><a href="https://colab.sandbox.google.com/github/google-deepmind/recurrentgemma/blob/main/colabs/sampling_tutorial_jax.ipynb" rel="nofollow"><code>colabs/sampling_tutorial_jax.ipynb</code></a>
contains a <a href="http://colab.google/" rel="nofollow">Colab</a> notebook with a sampling example using JAX.</p>
</li>
<li>
<p dir="auto"><a href="https://colab.sandbox.google.com/github/google-deepmind/recurrentgemma/blob/main/colabs/sampling_tutorial_pytorch.ipynb" rel="nofollow"><code>colabs/sampling_tutorial_pytorch.ipynb</code></a>
contains a <a href="http://colab.google/" rel="nofollow">Colab</a> notebook with a sampling example using PyTorch.</p>
</li>
<li>
<p dir="auto"><a href="https://colab.sandbox.google.com/github/google-deepmind/recurrentgemma/blob/main/colabs/fine_tuning_tutorial_jax.ipynb" rel="nofollow"><code>colabs/fine_tuning_tutorial_jax.ipynb</code></a>
contains a <a href="http://colab.google/" rel="nofollow">Colab</a> with a basic tutorial on how to
fine-tune RecurrentGemma for a task, such as English to French translation, using JAX.</p>
</li>
</ul>
<p dir="auto">To run these notebooks you will need to have a Kaggle account and first read and accept
the Gemma license terms and conditions from the <a href="http://kaggle.com/models/google/recurrentgemma" rel="nofollow">RecurrentGemma page</a>.
After this you can run the notebooks, which will automatically download the weights and tokenizer from there.</p>
<p dir="auto">Currently different notebooks are supported under the following hardware:</p>
<table>
<thead>
<tr>
<th>Hardware</th>
<th>T4</th>
<th>P100</th>
<th>V100</th>
<th>A100</th>
<th>TPUv2</th>
<th>TPUv3+</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sampling in Jax</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Sampling in PyTorch</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Finetuning in Jax</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>❌</td>
<td>✅</td>
</tr>
</tbody>
</table>
<p dir="auto"><h2 tabindex="-1" dir="auto">System Requirements</h2><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"></a></p>
<p dir="auto">RecurrentGemma code can run on CPU, GPU or TPU.
The code has been optimized for running on TPU using the Flax implementation,
which contains a low level <a href="https://jax.readthedocs.io/en/latest/pallas/index.html" rel="nofollow">Pallas</a> kernel to perform the linear scan in the recurrent layers.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Contributing</h2><a id="user-content-contributing" aria-label="Permalink: Contributing" href="#contributing"></a></p>
<p dir="auto">We are open to bug reports and issues. Please see
<a href="https://github.com/google-deepmind/recurrentgemma/blob/main/CONTRIBUTING.md">CONTRIBUTING.md</a> for details on PRs.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">License</h2><a id="user-content-license" aria-label="Permalink: License" href="#license"></a></p>
<p dir="auto">Copyright 2024 DeepMind Technologies Limited</p>
<p dir="auto">This code is licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License. You may obtain
a copy of the License at <a href="http://www.apache.org/licenses/LICENSE-2.0" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a>.</p>
<p dir="auto">Unless required by applicable law or agreed to in writing, software distributed
under the License is distributed on an AS IS BASIS, WITHOUT WARRANTIES OR
CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.</p>
<p dir="auto"><h2 tabindex="-1" dir="auto">Disclaimer</h2><a id="user-content-disclaimer" aria-label="Permalink: Disclaimer" href="#disclaimer"></a></p>
<p dir="auto">This is not an official Google product.</p>
</article></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: Sonauto – a more controllable AI music creator (381 pts)]]></title>
            <link>https://sonauto.ai/</link>
            <guid>39992817</guid>
            <pubDate>Wed, 10 Apr 2024 16:48:01 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://sonauto.ai/">https://sonauto.ai/</a>, See on <a href="https://news.ycombinator.com/item?id=39992817">Hacker News</a></p>
&lt;Unparsable&gt;]]></description>
        </item>
        <item>
            <title><![CDATA[Ronda Rousey: "I never wanted to talk about concussion" (161 pts)]]></title>
            <link>https://www.theguardian.com/sport/2024/mar/31/ronda-rousey-i-never-wanted-to-talk-about-concussion-it-felt-like-a-weakness</link>
            <guid>39991815</guid>
            <pubDate>Wed, 10 Apr 2024 15:28:38 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theguardian.com/sport/2024/mar/31/ronda-rousey-i-never-wanted-to-talk-about-concussion-it-felt-like-a-weakness">https://www.theguardian.com/sport/2024/mar/31/ronda-rousey-i-never-wanted-to-talk-about-concussion-it-felt-like-a-weakness</a>, See on <a href="https://news.ycombinator.com/item?id=39991815">Hacker News</a></p>
<div id="readability-page-1" class="page"><div id="maincontent"><p><span>‘I</span> worry about it because we already have Alzheimer’s and dementia in our family, and those family members did not get whacked on the head a whole bunch,” <a href="https://www.theguardian.com/sport/ronda-rousey" data-link-name="in body link" data-component="auto-linked-tag">Ronda Rousey</a> says as she considers a future shrouded by the consequences of concussion and a past where she broke so many barriers for women before a shattering fall.</p><p>At her peak, in 2015, Rousey was described by <em>Sports Illustrated</em> as “the <a href="https://www.si.com/mma/2015/05/12/ronda-rousey-ufc-mma-fighter-armbar." data-link-name="in body link">world’s most dominant athlete</a>”. She had changed a brutal sport to become <a href="https://www.theguardian.com/sport/blog/2018/jan/30/ufc-ronda-rousey-wwe-mixed-martial-arts" data-link-name="in body link">the face of the UFC</a>, the billion-dollar juggernaut which drives the popularity of Mixed&nbsp;Martial Arts.</p><p>Apart from being the first woman signed by the deeply conservative <a href="https://www.theguardian.com/sport/ufc" data-link-name="in body link" data-component="auto-linked-tag">UFC</a> in 2012, Rousey had built a formidable 15-0 record in which her bouts lasted an average 34 seconds. But her ferocity was built on a hidden vulnerability. Rousey had suffered so many concussions in judo that she knew her brain could not withstand multiple more blows to the head. It was vital that she brought her fights in the UFC to a violent conclusion before she absorbed much punishment.</p><p>Rousey can now share her secret and is moving and amusing company as she reflects on the consequences of so many concussions. “Every time I forget my keys or lose my phone, I’m like: ‘I’m DYING! It’s OVER!” she says as she shouts out those words with comic flair.</p><p>She has just turned 37 and Rousey is thoughtful again. “Part of me has declined and I have moments where I’ll be singing my daughter a lullaby and I’ll get a word wrong. I’ll be like: ‘Oh my God! This is it [the onset of dementia]!’ On the drive home this morning, after dropping off my daughter for her first day of pre-school, I was passing corners I’d passed hundreds of times and, for a moment, I was like ‘Where am I?’ And then it’s a case of ‘Oh yeah’.”</p><figure id="08726153-d708-4ed2-8ef4-a98aa36f82a8" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-2"><picture><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Ronda Rousey launches an attack on Sarah Kaufman during the Strikeforce event in 2012." src="https://i.guim.co.uk/img/media/385987113fe55cf70259948aaf7dfb02c0b1c4f5/0_0_3000_2000/master/3000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="296.66666666666663" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Ronda Rousey launches an attack on Sarah Kaufman during the Strikeforce event in 2012.</span> Photograph: Esther Lin/Forza LLC/Getty Images</figcaption></figure><p>We all have moments of brain-fade but, for Rousey, it carries a tangled undertow. Her <a href="https://www.penguin.co.uk/books/456155/our-fight-by-rousey-ronda/9781529912388" data-link-name="in body link">new book</a>, written with her sister Maria Burns Ortiz, is often gripping and, at its best, offers a raw personal history of concussion. She began judo at the age of 11 and, driven by the aim of winning an Olympic gold medal, Rousey tried to evade the fact “I’d been compounding concussion after concussion for so many years”.</p><p>She shrugs when I ask how many concussions she might have had in a calendar year as a young woman. “It’s hard to say because I wouldn’t rest when I had a concussion. I would continue to train and keep re-aggravating it. So instead of having symptoms for a few days, I would have them for weeks or even months. Most of the year I would be having concussion symptoms. There are grades of severity but my worst was being thrown on the back of my head at the Pan-American [Judo] Championships in Argentina. I completely blacked out till the next&nbsp;morning.”</p><p>Rousey’s concerns were ignored. “I’d be treated like I was complaining about a headache. People would say: ‘Your head hurts? Suck it up. What if your head hurts during the Olympics?’ That’s how I was taught to deal with it from a very young age. It became a way of life.”</p><p>Her mother, AnnMaria [Burns], had become the first American to win the world judo championships in 1984. She then lost her husband, and Ronda her father, after Ron Rousey took his life. Ronda was eight years old. Amid such adversity, AnnMaria began coaching Ronda and helped her win a gold medal at the 2004 World Junior Judo Championships and bronze at the 2008 Olympic Games.</p><p>When Ronda was a girl, there was little scientific knowledge about concussion in the public domain. “My mother just didn’t understand concussion,” she says. “Nobody did because research only started coming out towards the end of my judo career. I was afraid of it and tried to suppress it. I’d had so many more concussions than anybody else in a 10-year judo career and so when I started doing <a href="https://www.theguardian.com/sport/mma" data-link-name="in body link" data-component="auto-linked-tag">MMA</a> I didn’t want anyone to know. They already had enough reasons to try and stop me going into MMA and then the UFC. I didn’t want to give them any more about concussion and I was lucky to have the skills to win most fights really quick.” Rousey is suitably scathing about the ignorant machismo that haunts MMA and boxing: “People talk about your ‘chin’ with such reverence. It’s thrown around like it’s a personality trait or a sign of your willpower to absorb blows. That’s another reason why I never wanted to talk about concussion. It felt like it was a personal weakness and not a neurological degeneration I’ve been experiencing since I was a child.”</p><figure id="5a07215e-110a-482c-948e-934f4d6858b8" data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-3"><picture><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="United States’ Ronda Rousey (blue) and Germany’s Annett Boehm compete in their women’s -70kg judo bronze medal match of the 2008 Beijing Olympic Games." src="https://i.guim.co.uk/img/media/11997e243a9274b1005bac946d1172deb3113d91/0_0_2436_1544/master/2436.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="282.0525451559934" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Ronda Rousey (blue) on her way to beating Germany’s Annett Boehm in their women’s -70kg judo bronze medal match at the 2008 Olympic Games.</span> Photograph: Olivier Morin/AFP/Getty Images</figcaption></figure><p>She pushes her glasses higher up on the bridge of her nose. “It sucks because you see what happened to a lot of these fighters. <a href="https://www.theguardian.com/sport/muhammad-ali?page=2" data-link-name="in body link">Muhammad Ali</a> is one of my heroes and he had the greatest chin. But look what happened. I am not judging anyone as I would also accept living my life in a wheelchair if that was the price I had to pay to achieve all I did. I respect Ali for being willing to live that life because that’s something I tried to do as well.</p><p>“I hope I don’t end up that way but you never know. It might be decades later when you understand you’ve taken one hit too many. When you have kids and family, it’s much harder to gamble on your&nbsp;future. I went from being the most eligible bachelorette on earth to instant family, and it completely changes your priorities.”</p><p>Rousey experienced a whirlpool of fame which she has now gladly exchanged for a serene life on a regenerative farm she runs with her husband Travis Browne, the former UFC fighter, who has two teenage boys. The couple have two young children of their own and, surrounded by family and animals, Rousey has found a way to heal herself after the catastrophic end to her UFC domination.</p><p>The most powerful pages in Rousey’s book document the aftermath of her <a href="https://www.youtube.com/watch?v=vGhdcHWdW4o" data-link-name="in body link">crushing first defeat</a> when the former boxer <a href="https://www.theguardian.com/sport/2015/nov/15/holly-holm-stuns-ronda-rousey-for-ufc-womens-bantamweight-title" data-link-name="in body link">Holly Holm knocked her out</a> in front of the UFC’s then largest-ever crowd of 56,000 fans in Melbourne, and more than a million people who had paid to watch the broadcast in November 2015. Holm’s first punch concussed Rousey. It also split the champion’s lower lip wide open.</p><p>At the end of the round, Rousey bit off a small chunk of distended flesh, “ripping my teeth into my own lip like you would an apple”, and spat it out. She still feels the missing part of her inside lip today and remembers the desolation of her locker room after being knocked out in the second round.</p><figure id="0d8eb601-92ca-4d31-b927-f1438e58c57c" data-spacefinder-role="showcase" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-4"><picture><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=880&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=880&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=800&amp;dpr=2&amp;s=none" media="(min-width: 1140px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1140px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=800&amp;dpr=1&amp;s=none" media="(min-width: 1140px)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=640&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=640&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Ronda Rousey is on the canvas after being knocked out by Holly Holm in their UFC women’s bantamweight championship bout in 2015." src="https://i.guim.co.uk/img/media/a9144fcfaa2bf4b2eb81149d91635d9fe1dff68e/0_0_4000_2710/master/4000.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="301.4875" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Ronda Rousey is on the canvas after being knocked out by Holly Holm in their UFC women’s bantamweight championship bout in 2015.</span> Photograph: Scott Barbour/Zuffa LLC/Getty Images</figcaption></figure><p>Rousey “sat alone on the cold, grey concrete floor” and “tears ran down my cheeks”. She was barefoot, silent and shivering. “I could taste the blood in my mouth, my tongue against a gaping hole of flesh and muscle where my inside bottom lip had once been.”</p><p>She could hear people outside revelling in her devastating defeat. “It was the worst moment of my life. It was the most intense pain, misery, embarrassment and shame I had ever felt. I wanted to kill myself. I wanted to swallow a bottle of painkillers, close my eyes, and end it.”</p><figure data-spacefinder-role="inline" data-spacefinder-type="model.dotcomrendering.pageElements.NewsletterSignupBlockElement"><a data-ignore="global-link-styling" href="#EmailSignup-skip-link-20">skip past newsletter promotion</a><p id="EmailSignup-skip-link-20" tabindex="0" aria-label="after newsletter promotion" role="note">after newsletter promotion</p></figure><p>Only one man could talk properly to her. Travis found the words as, while she sobbed in his arms, he reminded her: “You are so much more than a fighter.”</p><p>Rousey had been venerated for so long and pressured into fighting for the UFC so often. But after that defeat and another early<a href="https://www.theguardian.com/sport/blog/2016/dec/31/ronda-rousey-amanda-nunes-ufc" data-link-name="in body link"> stoppage loss to Amanda Nunes</a> in December 2016, <a href="https://www.theguardian.com/sport/2015/nov/17/holly-holm-defends-ronda-rousey-people-can-be-pretty-brutal" data-link-name="in body link">Rousey was ridiculed relentlessly</a> in a defining example of social media’s desire to destroy a famous figure as they stumble. She finally found a way out of such distress. It helped that Rousey knew she had to protect her brain and no longer risk being punched or kicked in the head. She also tells me how, with patience and humour, Travis showed her how to live normally again.</p><figure id="0e8aec81-ea04-4fc7-be75-66b320ed0a4b" data-spacefinder-role="supporting" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-5"><picture><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=380&amp;dpr=2&amp;s=none" media="(min-width: 1300px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 1300px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=380&amp;dpr=1&amp;s=none" media="(min-width: 1300px)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=300&amp;dpr=2&amp;s=none" media="(min-width: 980px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 980px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=300&amp;dpr=1&amp;s=none" media="(min-width: 980px)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=620&amp;dpr=2&amp;s=none" media="(min-width: 660px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 660px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=620&amp;dpr=1&amp;s=none" media="(min-width: 660px)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=605&amp;dpr=2&amp;s=none" media="(min-width: 480px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 480px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=605&amp;dpr=1&amp;s=none" media="(min-width: 480px)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=445&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=445&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Ronda Rousey with husband Travis Browne." src="https://i.guim.co.uk/img/media/4f29ea792a69686bcd88eaa9eebed1da7e59caef/4_440_1790_2274/master/1790.jpg?width=445&amp;dpr=1&amp;s=none" width="445" height="565.3240223463688" loading="lazy"></picture></div><figcaption><span><svg width="18" height="13" viewBox="0 0 18 13"><path d="M18 3.5v8l-1.5 1.5h-15l-1.5-1.5v-8l1.5-1.5h3.5l2-2h4l2 2h3.5l1.5 1.5zm-9 7.5c1.9 0 3.5-1.6 3.5-3.5s-1.6-3.5-3.5-3.5-3.5 1.6-3.5 3.5 1.6 3.5 3.5 3.5z"></path></svg></span><span>Ronda Rousey with husband Travis Browne.</span> Photograph: Eric Williams</figcaption></figure><p>“He was one of the very few people who saw me as more than just Ronda Rousey, the UFC champion. Here’s a perfect way to sum up Travis. When we first got together I told him that there was no way I was ever going to cook for a man. So for a year he cooked every single meal we had together because he loved me. Then one day I said: ‘I can make really nice pancakes. I want to make you some pancakes.’”</p><p>Rousey laughs in delight. “So I started making pancakes and then more and more meals. I wanted to show I loved him by cooking for him, as he had done for me. And then he did this really smart thing. He changed the voice on the GPS so that it had an Australian accent. It&nbsp;was because he didn’t want me to&nbsp;have any bad association with my&nbsp;defeat in Melbourne. To this day we still hear an Australian voice on&nbsp;our GPS.”</p><p>In California they have “our regenerative ranch where we started with one seed and we now have hundreds of acres of grassland”. “We’re figuring out how to use our animals and natural processes to bring this ecosystem to its fullest potential. We now have herds of antelope coming through and roe deer and migrating geese. We’ve taken this land that was so neglected and abused and made it a real refuge for all the wildlife in the area as well as raising our animals humanely so they can exhibit all their natural behaviours.</p><p>“We could have taken <a href="https://www.theguardian.com/sport/2015/aug/26/ronda-rousey-jabs-floyd-mayweather-again" data-link-name="in body link">the money we made</a> from fighting and put it into property and just been landlords. But I don’t want to leave our kids a pile of money that’s on fire because the world is burning. Regenerative agriculture is one of the most scalable solutions to combat climate change. I really believe in it.”</p><p>Rousey worked for a while as a wrestler in the WWE and she quickly discovered that, even in that circus, women were treated badly. But she is proud of how she changed combat sport and made women fighters integral to the business of the UFC. “I tried to win as quickly as possible, taking zero damage and I’m really proud of what I was able to accomplish – especially with my limitations.”</p><figure id="c930078f-4aa8-4081-b6d1-745122285b28" data-spacefinder-role="thumbnail" data-spacefinder-type="model.dotcomrendering.pageElements.ImageBlockElement"><div id="img-6"><picture><source srcset="https://i.guim.co.uk/img/media/f9425015ee99558919ebd19c1c403f9c34adca8a/0_0_1838_2775/master/1838.jpg?width=140&amp;dpr=2&amp;s=none" media="(min-width: 740px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 740px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9425015ee99558919ebd19c1c403f9c34adca8a/0_0_1838_2775/master/1838.jpg?width=140&amp;dpr=1&amp;s=none" media="(min-width: 740px)"><source srcset="https://i.guim.co.uk/img/media/f9425015ee99558919ebd19c1c403f9c34adca8a/0_0_1838_2775/master/1838.jpg?width=120&amp;dpr=2&amp;s=none" media="(min-width: 320px) and (-webkit-min-device-pixel-ratio: 1.25), (min-width: 320px) and (min-resolution: 120dpi)"><source srcset="https://i.guim.co.uk/img/media/f9425015ee99558919ebd19c1c403f9c34adca8a/0_0_1838_2775/master/1838.jpg?width=120&amp;dpr=1&amp;s=none" media="(min-width: 320px)"><img alt="Front cover of Ronda Rousey autobiography entitled Our Fight" src="https://i.guim.co.uk/img/media/f9425015ee99558919ebd19c1c403f9c34adca8a/0_0_1838_2775/master/1838.jpg?width=120&amp;dpr=1&amp;s=none" width="120" height="181.1751904243743" loading="lazy"></picture></div></figure><p>She has also found peace even if she cannot be certain of the future health of her brain. “I need to enjoy the moment and be happy where I’m at,” Rousey says after an hour of sombre reflection and riotous laughter. “I don’t want my body to be perfect when it’s buried in the ground.</p><p>“I have no regrets and if I get to a point where you can just park me in front of the ocean and all I can do is sit and watch the whales, I should be happy with that. I would do it all again, but I wish I could do it with a little more science and knowledge in mind.”</p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Kobo announces color e-readers (371 pts)]]></title>
            <link>https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink</link>
            <guid>39991693</guid>
            <pubDate>Wed, 10 Apr 2024 15:18:27 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink">https://www.theverge.com/2024/4/10/24124411/kobo-libra-colour-clara-colour-e-reader-kindle-e-ink</a>, See on <a href="https://news.ycombinator.com/item?id=39991693">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><p>Rakuten Kobo is launching its first color e-readers, the <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fus.kobobooks.com%2Fproducts%2Fkobo-libra-colour">Kobo Libra Colour</a> and the <a href="https://go.skimresources.com/?id=1025X1701640&amp;xs=1&amp;url=https%3A%2F%2Fus.kobobooks.com%2Fcollections%2Fereaders%2Fproducts%2Fkobo-clara-colour">Kobo Clara Colour</a>. Both use E Ink’s latest Kaledio color screen technology, which has subtle, pastel-like hues and drops from a 300ppi grayscale resolution to 150ppi when you view content in color.</p><p>I’ll be testing both e-readers soon, but so far, they look like small upgrades to Kobo’s existing e-readers. That’s not a bad thing, though! The seven-inch Kobo Libra 2 is <a href="https://www.theverge.com/23769068/best-ebook-readers">my favorite e-reader</a> outside of Amazon’s ecosystem, offering the <a href="https://www.theverge.com/22745670/amazon-kindle-paperwhite-2021-review-usb-c-signature-edition-display-e-reader-books">Kindle Paperwhite’s</a> IPX8 waterproof design but with extras like physical page-turning buttons, no lockscreen ads, and more storage. </p><div><div><div role="button" aria-label="Zoom" tabindex="0"><p><span><span></span><img alt="The Kobo Libra Colour comes with physical page-turning buttons and is compatible with the Kobo Stylus 2 for taking notes." loading="lazy" decoding="async" data-nimg="responsive" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 350px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/256x256/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/376x376/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/384x384/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/415x415/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/480x480/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/540x540/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/640x640/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/750x750/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/828x828/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1080x1080/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1200x1200/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1440x1440/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1920x1920/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2048x2048/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382616/9_Libra_White_EN_Device_Angled_1080x1080.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><div><figcaption><em>The Kobo Libra Colour comes with physical page-turning buttons and is compatible with the Kobo Stylus 2 for taking notes.</em></figcaption> <p><cite>Image: Rakuten Kobo</cite></p></div></div><div><div role="button" aria-label="Zoom" tabindex="0"><p><span><span></span><img alt="The Kobo Clara Colour is just like the Clara 2E but with color, an improved processor, and more storage." loading="lazy" decoding="async" data-nimg="responsive" sizes="(max-width: 639px) 100vw, (max-width: 1023px) 50vw, 350px" srcset="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/256x256/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 256w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/376x376/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/384x384/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/415x415/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/480x480/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/540x540/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/640x640/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/750x750/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/828x828/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1080x1080/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1200x1200/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1440x1440/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/1920x1920/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2048x2048/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg 2400w" src="https://duet-cdn.vox-cdn.com/thumbor/0x0:1080x1080/2400x2400/filters:focal(540x540:541x541):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/25382621/2_Clara_Colour_EN_Device_Angled_1080x1080.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></span></p></div><div><figcaption><em>The Kobo Clara Colour is just like the Clara 2E but with color, an improved processor, and more storage.</em></figcaption> <p><cite>Image: Rakuten Kobo</cite></p></div></div></div><p>The $219.99 Kobo Libra Colour retains all of those features but is also now compatible with the <a href="https://help.kobo.com/hc/en-us/articles/10733885674391-About-Kobo-Stylus-2#:~:text=Note%3A%20Kobo%20Stylus%202%20only,Elipsa%2C%20and%20Kobo%20Elipsa%202E.">Kobo Stylus 2</a>, just like the <a href="https://www.theverge.com/2023/4/5/23669572/kobo-elipsa-2e-e-reader-tablet-kindle-scribe-onyx-remarkable">Kobo Elipsa 2E</a>. However, it’s $30 more expensive than the Kobo Libra 2, and you’ll have to buy the stylus separately for $69.99. </p><p>The $149.99 Kobo Clara Colour is slightly more distinct from its closest sibling, the $139.99 <a href="https://www.theverge.com/23542918/kobo-clara-2e-ereader-review-amazon-kindle">Kobo Clara 2E</a>. It offers the same six-inch display and IPX8 waterproof design but now comes with 16GB of storage, as well as an improved processor. I hope so; the Kobo Clara 2E’s sluggish performance was one of my chief complaints.</p><p>Kobo also introduced an upgraded black-and-white Kobo Clara BW, with the same storage and processor upgrades, for $129.99.</p><p>All of the devices are available to preorder starting today and will ship on April 30th. </p></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Meta MTIA v2 – Meta Training and Inference Accelerator (184 pts)]]></title>
            <link>https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/</link>
            <guid>39991675</guid>
            <pubDate>Wed, 10 Apr 2024 15:16:22 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/">https://ai.meta.com/blog/next-generation-meta-training-inference-accelerator-AI-MTIA/</a>, See on <a href="https://news.ycombinator.com/item?id=39991675">Hacker News</a></p>
<div id="readability-page-1" class="page"><div><div id="u_0_a_Cw"><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.8562-6/341873634_933206851214321_6656088855482877648_n.svg?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=mGUHpaVA17EAb65o-qY&amp;_nc_ht=scontent.fzrh3-1.fna&amp;oh=00_AfBv4J_M2o8wil-9g4XTkhIXsd0XdjTBo_RbqYXE-3H1aw&amp;oe=661C9BF7" height="30" width="109" alt="Featured label"></p><p>Our next-generation Meta Training and Inference Accelerator</p><p>April 10, 2024 · 8 min read</p></div><div><div><p>The next generation of Meta’s large-scale infrastructure is <a href="https://about.fb.com/news/2023/05/metas-infrastructure-for-ai/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;blog_newsroom-reimagine&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_h_bf">being built with AI in mind</a>, including supporting new generative AI (GenAI) products and services, recommendation systems, and advanced AI research. It’s an investment <a href="https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;blog_engineering-building&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_i_sa">we expect will grow</a> in the years ahead as the compute requirements to support AI models increase alongside the models’ sophistication.</p><p>Last year, we unveiled the <a href="https://ai.meta.com/blog/meta-training-inference-accelerator-AI-MTIA/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_internal-link&quot;,&quot;creative_detail&quot;:&quot;blog_ai-mtiav1-intro&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_j_5/">Meta Training and Inference Accelerator (MTIA) v1</a>, our first-generation AI inference accelerator that we designed in-house with Meta’s AI workloads in mind – specifically our deep learning recommendation models that are improving a variety of experiences across our products.</p><p>MTIA is a long-term venture to provide the most efficient architecture for Meta’s unique workloads. As AI workloads become increasingly important to our products and services, this efficiency will improve our ability to provide the best experiences for our users around the world. MTIA v1 was an important step in improving the compute efficiency of our infrastructure and better supporting our software developers as they build AI models that will facilitate new and better user experiences.</p><p>Now, we’re sharing details about the next generation of MTIA.</p></div><div><p> Next generation MTIA chip model. Drag to rotate.<br></p></div><p>This inference accelerator is part of our broader full-stack development program for custom, domain-specific silicon that addresses our unique workloads and systems. This new version of MTIA more than doubles the compute and memory bandwidth of our previous solution while maintaining our close tie-in to our workloads. It is designed to efficiently serve the ranking and recommendation models that provide high-quality recommendations to users.</p></div><div id="u_0_l_LC"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Close up photograph of a hand holding a chip" id="u_0_m_uf"></p></div><div><div><h2> Under the hood<br></h2><p>This chip’s architecture is fundamentally focused on providing the right balance of compute, memory bandwidth, and memory capacity for serving ranking and recommendation models. In inference we need to be able to provide relatively high utilization, even when our batch sizes are relatively low. By focusing on providing outsized SRAM capacity, relative to typical GPUs, we can provide high utilization in cases where batch sizes are limited and provide enough compute when we experience larger amounts of potential concurrent work.</p></div><div><p>This accelerator consists of an 8x8 grid of processing elements (PEs). These PEs provide significantly increased dense compute performance (3.5x over MTIA v1) and sparse compute performance (7x improvement). This comes partly from improvements in the architecture associated with pipelining of sparse compute. It also comes from how we feed the PE grid: We have tripled the size of the local PE storage, doubled the on-chip SRAM and increased its bandwidth by 3.5X, and doubled the capacity of LPDDR5.</p></div><div><p>Our new MTIA design also features an improved network on chip (NoC) architecture that doubles the bandwidth and allows us to coordinate between different PEs at low latency. These and other new functions in the PEs form the key technologies that are vital to our long-term roadmap to scale MTIA to a wider variety of more challenging workloads.</p></div></div><div><div><div><h2>The hardware</h2><p>Serving our workloads effectively is not simply a silicon challenge. Co-designing the hardware system and the software stack along with the silicon is essential for the success of the overall inference solution.</p></div><div><p>To support the next-generation silicon we have developed a large, rack-based system that holds up to 72 accelerators. This consists of three chassis, each containing 12 boards that house two accelerators each. We specifically designed the system so that we could clock the chip at 1.35GHz (up from 800 MHz) and run it at 90 watts compared to 25 watts for our first-generation design. Our design ensures we provide denser capabilities with higher compute, memory bandwidth, and memory capacity. This density allows us to more easily accommodate a broad range of model complexities and sizes.</p></div></div><div><div id="u_0_x_hb"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Photograph of a person placing a motherboard into a server"></p></div><div id="u_0_y_g2"><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Photograph of a server rack with wires and chips"></p></div></div><div><p>Beyond this, we have upgraded the fabric between the accelerators and between the host and accelerators to PCIe Gen5 to increase the bandwidth and scalability of our system. There is also the option to add an RDMA NIC if we choose to scale out beyond the rack.</p></div></div><div><div><h2>The software stack</h2><p>Software has been one of our key areas of focus from the start of our investment in MTIA. <a href="https://ai.meta.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_internal-link&quot;,&quot;creative_detail&quot;:&quot;blog_ai-pytorch-builds&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_z_p9">As the initial developers of PyTorch</a>, we value programmability and developer efficiency. Our MTIA stack is designed to fully integrate with PyTorch 2.0 and features like TorchDynamo and TorchInductor. Frontend graph-level capturing, analysis, transformation, and extraction mechanisms (such as TorchDynamo, torch.export, etc.) are agnostic to MTIA and are being reused The lower level compiler for MTIA takes the outputs from the frontend and produces highly efficient and device-specific code. This lower level compiler itself consists of a few components that are responsible for generating executable code for models and kernels.</p></div><div id="u_0_10_xe"><p><img src="https://scontent.fzrh3-1.fna.fbcdn.net/v/t39.8562-6/434734036_1552580315589962_4953415076977263638_n.jpg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=_BJ5OdmLZfIAb5B55YB&amp;_nc_ht=scontent.fzrh3-1.fna&amp;oh=00_AfAZ86-X42WMruek_42kZa0zrA2Ffc8TmgNIIxQ34Iha3w&amp;oe=661C95E6" alt=""></p></div><div><div><p>Below this sits the runtime stack responsible for interfacing with the driver/firmware. The MTIA Streaming interface abstraction provides the basic and essential operations that both inference and (in the future) training software require to manage the device memory, as well as run operators and execute compiled graphs on the device. Finally, the runtime interacts with the driver, which sits in user space – a decision we made to enable us to iterate faster on the driver and firmware within our production stack.</p><p>In many ways this new chip system runs the software stack similarly to MTIA v1, which made it much faster for the team to deploy since we had already done much of the necessary integration and development work needed to be able to run our applications on this architecture. The new MTIA is designed to be compatible with code developed for MTIA v1. Since we had already integrated the full software stack to the silicon, we were up and running our traffic with this new chip in a matter of days. This allowed us to land this next-generation MTIA silicon rapidly, going from first silicon to production models running in 16 regions in less than nine months.</p></div><h3> Triton-MTIA<br></h3><div><p>We’ve further optimized the software stack by creating the Triton-MTIA compiler backend to generate high-performance code for the MTIA hardware. <a href="https://github.com/openai/triton" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;github_triton&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_11_hC">Triton</a> is an open source language and compiler for writing highly efficient ML compute kernels. It improves developer productivity for writing GPU code and we have found that the Triton language is sufficiently hardware-agnostic to be applicable to non-GPU hardware architectures like MTIA.</p><p>The Triton-MTIA backend performs optimizations to maximize hardware utilization and support high-performance kernels. It also exposes key knobs to leverage Triton and MTIA auto-tuning infrastructures to explore the kernel configuration and optimization space.</p><p>We have implemented support for the features of the Triton language and integration into PyTorch 2, providing extensive coverage for PyTorch operators. Thanks to TorchInductor, for example, our developers can leverage Triton-MTIA in both ahead-of-time (AOT) and just-in-time (JIT) workflows.</p><p>We observed dramatically improved developer efficiency with Triton-MTIA, which allowed us to scale up compute kernel authoring and significantly expand the support of PyTorch operators.</p></div></div></div><div><p><img src="https://static.xx.fbcdn.net/rsrc.php/v3/y4/r/-PAXP-deijE.gif" alt="Dark Meta gradient" id="u_0_12_Q7"></p><div><h2>Performance Results</h2><p>The results so far show that this MTIA chip can handle both the low complexity (LC) and high complexity (HC) ranking and recommendation models that are components of Meta’s products. Across these models, there can be a ~10x-100x difference in model size and the amount of compute per input sample. Because we control the whole stack, we can achieve greater efficiency compared to commercially available GPUs. Realizing these gains is an ongoing effort and we continue to improve performance per watt as we build up and deploy MTIA chips in our systems.</p><div><p>Early results show that this next generation silicon has already improved performance by 3x over our first generation chip across four key models we evaluated. At the platform level, with 2x the number of devices and a powerful 2-socket CPU, we are able to achieve 6x model serving throughput and a 1.5x performance per watt improvement over the first generation MTIA system. To achieve this, we have made significant progress optimizing kernels, compiler, runtime, and host serving stack. The time to optimize models is going down as the developer ecosystem matures, yet there is more headroom to improve efficiency in the future. </p><div><p>3x</p><p>improved performance over our first gen chip</p></div></div><p>MTIA has been deployed in the data center and is now serving models in production. We are already seeing the positive results of this program as it's allowing us to dedicate and invest in more compute power for our more intensive AI workloads. It is proving to be highly complementary to commercially available GPUs in delivering the optimal mix of performance and efficiency on Meta-specific workloads.</p></div></div><div><h2>Meta’s ongoing investment in custom silicon</h2><div><p>MTIA will be an important piece of our long-term roadmap to build and scale the most powerful and efficient infrastructure possible for Meta’s unique AI workloads.</p><p>We’re designing our custom silicon to work in cooperation with our existing infrastructure as well as with new, more advanced hardware (including next-generation GPUs) that we may leverage in the future. Meeting our ambitions for our custom silicon means investing not only in compute silicon but also in memory bandwidth, networking and capacity as well as other next-generation hardware systems.</p><p>We currently have several programs underway aimed at expanding the scope of MTIA, including support for GenAI workloads.</p><p>We’re only at the beginning of this journey, and we’re inviting people who want to be a part of it to visit <a href="https://www.metacareers.com/innovation" data-ms-clickable="true" data-ms="{&quot;creative&quot;:&quot;click_external-link&quot;,&quot;creative_detail&quot;:&quot;careers_innovation-open-roles&quot;}" target="_blank" rel="noreferrer noopener" data-lnfb-mode="ie" id="u_0_14_H+">Meta Careers</a> to learn about our open positions.</p></div></div><div><h4>Written by:</h4><h4>Eran Tal, Nicolaas Viljoen and Joel Coburn</h4></div></div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Twitter's pivot to x.com is a gift to phishers (351 pts)]]></title>
            <link>https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/</link>
            <guid>39991173</guid>
            <pubDate>Wed, 10 Apr 2024 14:35:37 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/">https://krebsonsecurity.com/2024/04/twitters-clumsy-pivot-to-x-com-is-a-gift-to-phishers/</a>, See on <a href="https://news.ycombinator.com/item?id=39991173">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
												<p>On April 9, Twitter/X began automatically modifying links that mention “twitter.com” to read “x.com” instead. But over the past 48 hours, dozens of new domain names have been registered that demonstrate how this change could be used to craft convincing phishing links — such as <strong>fedetwitter[.]com</strong>, which until very recently rendered as <strong>fedex.com</strong> in tweets.</p>
<div id="attachment_67139"><p><img aria-describedby="caption-attachment-67139" decoding="async" src="https://krebsonsecurity.com/wp-content/uploads/2024/04/ruseriousx.png" alt="" width="652" height="698"></p><p id="caption-attachment-67139">The message displayed when one visits carfatwitter.com, which Twitter/X displayed as carfax.com in tweets and messages.</p></div>
<p>A search at <a href="https://www.domaintools.com/" target="_blank" rel="noopener">DomainTools.com</a> shows at least 60 domain names have been registered over the past two days for domains ending in “twitter.com,” although research so far shows the majority of these domains have been registered “defensively” by private individuals to prevent the domains from being purchased by scammers.</p>
<p>Those include <strong>carfatwitter.com</strong>, which Twitter/X truncated to carfax.com when the domain appeared in user messages or tweets. Visiting this domain currently displays a message that begins, “Are you serious, X Corp?”</p>
<p><strong>Update:</strong> It appears Twitter/X has corrected its mistake, and no longer truncates any domain ending in “twitter.com” to “x.com.”</p>
<p><em>Original story:</em></p>
<p>The same message is on other newly registered domains, including <strong>goodrtwitter.com</strong> (goodrx.com), <strong>neobutwitter.com</strong> (neobux.com), <strong>roblotwitter.com</strong> (roblox.com), <strong>square-enitwitter.com</strong> (square-enix.com) and yandetwitter.com (yandex.com). The message left on these domains indicates they were defensively registered by <a href="https://compostintraining.club/@prplecake" target="_blank" rel="noopener">a user on Mastodon</a> whose bio says they are a systems admin/engineer. That profile has not responded to requests for comment.</p>
<p>A number of these new domains including “twitter.com” appear to be registered defensively by Twitter/X users in Japan. The domain netflitwitter.com (netflix.com, to Twitter/X users) now displays a message saying it was “acquired to prevent its use for malicious purposes,” along with a Twitter/X username.</p>
<p>The domain mentioned at the beginning of this story — fedetwitter.com — redirects users to the blog of a Japanese technology enthusiast. A user with the handle “amplest0e” appears to have registered <strong>space-twitter.com</strong>, which Twitter/X users would see as the CEO’s “space-x.com.” The domain “ametwitter.com” already redirects to the real americanexpress.com.<span id="more-67137"></span></p>
<p>Some of the domains registered recently and ending in “twitter.com” currently do not resolve and contain no useful contact information in their registration records. Those include <strong>firefotwitter[.]com</strong> (firefox.com), <strong>ngintwitter[.]com</strong> (nginx.com), and <strong>webetwitter[.]com</strong> (webex.com).</p>
<div id="attachment_67144"><p><img aria-describedby="caption-attachment-67144" decoding="async" loading="lazy" src="https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter.png" alt="" width="750" height="491" srcset="https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter.png 1299w, https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter-768x503.png 768w, https://krebsonsecurity.com/wp-content/uploads/2024/04/sextwitter-782x512.png 782w" sizes="(max-width: 750px) 100vw, 750px"></p><p id="caption-attachment-67144">The domain setwitter.com, which Twitter/X until very recently rendered as “sex.com,” redirects to this blog post warning about the recent changes and their potential use for phishing.</p></div>
<p><strong>Sean McNee</strong>, vice president of research and data at DomainTools, told KrebsOnSecurity it appears Twitter/X did not properly limit its redirection efforts.</p>
<p>“Bad actors could register domains as a way to divert traffic from legitimate sites or brands given the opportunity — many such brands in the top million domains end in x, such as webex, hbomax, xerox, xbox, and more,” McNee said. “It is also notable that several other globally popular brands, such as Rolex and Linux, were also on the list of registered domains.”</p>
<p>The apparent oversight by Twitter/X was cause for amusement and amazement from many former users who have migrated to other social media platforms since the new CEO took over. <strong>Matthew Garrett</strong>, a lecturer at U.C. Berkeley’s School of Information, <a href="https://infosec.exchange/@mjg59@nondeterministic.computer/112243298637438787" target="_blank" rel="noopener">summed up</a> the Schadenfreude thusly:</p>
<p>“Twitter just doing a ‘redirect links in tweets that go to x.com to twitter.com instead but accidentally do so for all domains that end x.com like eg spacex.com going to spacetwitter.com’ is not absolutely the funniest thing I could imagine but it’s high up there.”</p>
											</div></div>]]></description>
        </item>
        <item>
            <title><![CDATA[Show HN: ADS-B visualizer (295 pts)]]></title>
            <link>https://adsb.exposed/</link>
            <guid>39990346</guid>
            <pubDate>Wed, 10 Apr 2024 13:15:02 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://adsb.exposed/">https://adsb.exposed/</a>, See on <a href="https://news.ycombinator.com/item?id=39990346">Hacker News</a></p>
<div id="readability-page-1" class="page">
    
    <p>Examples:
        <span>Altitude &amp; Velocity</span>
        <span>Boeing vs. Airbus</span>
        <span>Helicopters</span>
        <span>Hi-Performance</span>
        <span>Light</span>
        <span>Gliders</span>
        <span>Ultralight</span>
        <span>Military</span>
        <span>Vertical Speed</span>
        <span>Roll Angle</span>
        <span>Steep</span>
        <span>Year</span>
        <span>A380</span>
        <span>IL-76</span>
        <span>F-16</span>
        <span>KLM</span>
        <span>N2163J</span>
        <span>Event Time</span>
        <span>Weekends</span>
        <span>Emergency</span>
        <span>Balloons</span>
        <span>Ground Vehicles</span>
        <span>Elon Musk</span>
        <span>All Airlines</span>
    </p>
    
    
    
    <p><span id="picture-copyright">Picture from Wikipedia, © the details at the corresponding page.</span></p>
    
    <p>👁</p>
    <p><img src="https://adsb.exposed/pointer.svg"></p>

    <p id="provider">
        <form>
            <label>
                
                Race
            </label>
            <br>
            <label>
                
                Cloud
            </label>
            <br>
            <label>
                
                Self-hosted (Intel)
            </label>
            <br>
            <label>
                
                Self-hosted (Graviton)
            </label>
        </form>
    </p>

    
    
    


</div>]]></description>
        </item>
        <item>
            <title><![CDATA[2023 ACM Turing Prize awarded to Avi Wigderson (259 pts)]]></title>
            <link>https://awards.acm.org/about/2023-turing</link>
            <guid>39990004</guid>
            <pubDate>Wed, 10 Apr 2024 12:36:43 GMT</pubDate>
            <description><![CDATA[<p>URL: <a href="https://awards.acm.org/about/2023-turing">https://awards.acm.org/about/2023-turing</a>, See on <a href="https://news.ycombinator.com/item?id=39990004">Hacker News</a></p>
<div id="readability-page-1" class="page"><div>
<p>ACM has named <a href="https://awards.acm.org/award-recipients/wigderson_3844537">Avi Wigderson</a> as recipient of the 2023 ACM A.M. Turing Award for foundational contributions to the theory of computation, including reshaping our understanding of the role of randomness in computation, and for his decades of intellectual leadership in theoretical computer science.</p>
<p>Wigderson is the Herbert H. Maass Professor in the School of Mathematics at the Institute for Advanced Study in Princeton, New Jersey. He has been a leading figure in areas including computational complexity theory, algorithms and optimization, randomness and cryptography, parallel and distributed computation, combinatorics, and graph theory, as well as connections between theoretical computer science and mathematics and science.</p>
<p>The ACM A.M. Turing Award, often referred to as the “Nobel Prize of Computing,” carries a $1 million prize with financial support provided by Google, Inc. The award is named for Alan M. Turing, the British mathematician who articulated the mathematical foundations of computing.</p>
<p><u>What is Theoretical Computer Science?</u></p>
<p>Theoretical computer science is concerned with the mathematical underpinnings of the field. It poses questions such as “Is this problem solvable through computation?” or “If this problem is solvable through computation, how much time and other resources will be required?”</p>
<p>Theoretical computer science also explores the design of efficient algorithms. Every computing technology that touches our lives is made possible by algorithms. Understanding the principles that make for powerful and efficient algorithms deepens our understanding not only of computer science, but also the laws of nature. While theoretical computer science is known as a field that presents exciting intellectual challenges and is often not directly concerned with improving the practical applications of computing, research breakthroughs in this discipline have led to advances in almost every area of the field—from cryptography and computational biology to network design, machine learning, and quantum computing.</p>
<p><u>Why is Randomness Important?</u></p>
<p>Fundamentally, computers are <em>deterministic</em> systems; the set of instructions of an algorithm applied to any given input uniquely determines its computation and, in particular, its output. In other words, the deterministic algorithm is following a predictable pattern. <em> Randomness </em> , by contrast, lacks a well-defined pattern, or predictability in events or outcomes. Because the world we live in seems full of random events (weather systems, biological and quantum phenomena, etc.), computer scientists have enriched algorithms by allowing them to make random choices in the course of their computation, in the hope of improving their efficiency. And indeed, many problems for which no efficient deterministic algorithm was known have been solved efficiently by probabilistic algorithms, albeit with some small probability of error (that can be efficiently reduced). But is randomness essential, or can it be removed? And what is the quality of randomness needed for the success of probabilistic algorithms?</p>
<p>These, and many other fundamental questions lie at the heart of understanding randomness and pseudorandomness in computation. An improved understanding of the dynamics of randomness in computation can lead us to develop better algorithms as well as deepen our understanding of the nature of computation itself.</p>
<p><u>Wigderson’s Contributions</u></p>
<p>A leader in theoretical computer science research for four decades, Wigderson has made foundational contributions to the understanding of the role of randomness and pseudorandomness in computation.</p>
<p>Computer scientists have discovered a remarkable connection between randomness and computational difficulty (i.e., identifying natural problems that have no efficient algorithms). Working with colleagues, Wigderson authored a highly influential series of works on trading hardness for randomness. They proved that, under standard and widely believed computational assumptions, every probabilistic polynomial time algorithm can be efficiently derandomized (namely, made fully deterministic). In other words, randomness is not necessary for efficient computation. This sequence of works revolutionized our understanding of the role of randomness in computation, and the way we think about randomness. This series of influential papers include the following three:</p>
<ul>
<li>“<a href="https://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/NOAM/HARDNESS/final.pdf">Hardness vs. Randomness</a>” (co-authored with Noam Nisan)<br>
Among other findings, this paper introduced a new type of pseudorandom generator, and proved that efficient deterministic simulation of randomized algorithms is possible under much weaker assumptions than previously known.</li>
<li>“<a href="https://link.springer.com/article/10.1007/BF01275486">BPP Has Subexponential Time Simulations Unless EXPTIME has Publishable Proofs</a>” (co-authored with László Babai, Lance Fortnow, and Noam Nisan)<br>
This paper used `hardness amplification’ to demonstrate that bounded-error probabilistic polynomial time (BPP) can be simulated in subexponential time for infinitely many input lengths under weaker assumptions.</li>
<li>“<a href="https://dl.acm.org/doi/pdf/10.1145/258533.258590">P = BPP if E Requires Exponential Circuits: Derandomizing the XOR Lemma</a>” (co-authored with Russell Impagliazzo)<br>
This paper introduces a stronger pseudo-random generator with essentially optimal hardness vs randomness trade-offs.</li>
</ul>
<p>Importantly, the impact of these three papers by Wigderson goes far beyond the areas of randomness and derandomization. Ideas from these papers were subsequently used in many areas of theoretical computer science and led to impactful papers by several leading figures in the field.</p>
<p>Still working within the broad area of randomness in computation, in <a href="https://www.math.ias.edu/~avi/PUBLICATIONS/MYPAPERS/CRVW01/crvw01.pdf"> papers</a>&nbsp;with Omer Reingold, Salil Vadhan, and Michael Capalbo, Wigderson gave the first efficient combinatorial constructions of expander graphs, which are sparse graphs that have strong connectivity properties. They have many important applications in both mathematics and theoretical computer science.</p>
<p>Outside of his work in randomness, Wigderson has been an intellectual leader in several other areas of theoretical computer science, including multi-prover interactive proofs, cryptography, and circuit complexity.</p>
<p><u>Mentoring</u></p>
<p>In addition to his groundbreaking technical contributions, Wigderson is recognized as an esteemed mentor and colleague who has advised countless young researchers. His vast knowledge and unrivaled technical proficiency—coupled with his friendliness, enthusiasm, and generosity—have attracted many of the best young minds to pursue careers in theoretical computer science.</p>
<p>“It’s important to point out that Avi Wigderson also received the Abel Prize, which is considered the most important honor for lifetime achievements in the field of mathematics,” explained ACM President Yannis Ioannidis. “Being selected for the ACM A.M. Turing Award is a fitting follow-up—as mathematics is foundational to computer science and Wigderson’s work has connected a wide range of mathematical sub-areas to theoretical computer science. Wigderson is a towering intellectual force in theoretical computer science, an exciting discipline that attracts some of the most promising young researchers to work on the most difficult challenges. This year’s Turing Award recognizes Wigderson’s specific work on randomness, as well as the indirect but substantial impact he has had on the entire field of theoretical computer science.”</p>
<p>"Avi Wigderson’s work on randomness and other topics has set the agenda in theoretical computer science for the past three decades,” explained Jeff Dean, Senior Vice President, Google. “From the earliest days of computer science, researchers have recognized that incorporating randomness was a way to design faster algorithms for a wide range of applications. Efforts to better understand randomness continue to yield important benefits to our field, and Wigderson has opened new horizons in this area. Google also salutes Wigderson’s role as a mentor. His colleagues credit him with generating great ideas and research directions, and then motivating a new generation of smart young researchers to work on them. We congratulate Avi Wigderson on receiving the ACM A.M. Turing Award—computing’s highest honor.”</p>
<p><strong><a href="https://www.acm.org/media-center/2024/april/turing-award-2023">News Release</a> | <a href="https://awards.acm.org/binaries/content/assets/press-releases/2024/april/news-release_wigderson_turing-award.pdf">Printable PDF</a></strong></p></div></div>]]></description>
        </item>
    </channel>
</rss>